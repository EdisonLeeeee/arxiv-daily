[
  {
    "id": "arXiv:2205.01671",
    "title": "The scope for AI-augmented interpretation of building blueprints in  commercial and industrial property insurance",
    "abstract": "This report, commissioned by the WTW research network, investigates the use\nof AI in property risk assessment. It (i) reviews existing work on risk\nassessment in commercial and industrial properties and automated information\nextraction from building blueprints; and (ii) presents an exploratory 'proof-of\nconcept-solution' exploring the feasibility of using machine learning for the\nautomated extraction of information from building blueprints to support\ninsurance risk assessment.",
    "descriptor": "\nComments: 36 pages, 30 figures. arXiv admin note: text overlap with arXiv:1907.09408 by other authors\n",
    "authors": [
      "Long Chen",
      "Mao Ye",
      "Alistair Milne",
      "John Hillier",
      "Frances Oglesby"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.01671"
  },
  {
    "id": "arXiv:2205.01672",
    "title": "Branch & Learn for Recursively and Iteratively Solvable Problems in  Predict+Optimize",
    "abstract": "This paper proposes Branch & Learn, a framework for Predict+Optimize to\ntackle optimization problems containing parameters that are unknown at the time\nof solving. Given an optimization problem solvable by a recursive algorithm\nsatisfying simple conditions, we show how a corresponding learning algorithm\ncan be constructed directly and methodically from the recursive algorithm. Our\nframework applies also to iterative algorithms by viewing them as a degenerate\nform of recursion. Extensive experimentation shows better performance for our\nproposal over classical and state-of-the-art approaches.",
    "descriptor": "",
    "authors": [
      "Xinyi Hu",
      "Jasper C.H. Lee",
      "Jimmy H.M. Lee",
      "Allen Z. Zhong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.01672"
  },
  {
    "id": "arXiv:2205.01681",
    "title": "Growing Isotropic Neural Cellular Automata",
    "abstract": "Modeling the ability of multicellular organisms to build and maintain their\nbodies through local interactions between individual cells (morphogenesis) is a\nlong-standing challenge of developmental biology. Recently, the Neural Cellular\nAutomata (NCA) model was proposed as a way to find local system rules that\nproduce a desired global behaviour, such as growing and persisting a predefined\npattern, by repeatedly applying the same rule over a grid starting from a\nsingle cell. In this work we argue that the original Growing NCA model has an\nimportant limitation: anisotropy of the learned update rule. This implies the\npresence of an external factor that orients the cells in a particular\ndirection. In other words, 'physical' rules of the underlying system are not\ninvariant to rotation, thus prohibiting the existence of differently oriented\ninstances of the target pattern on the same grid. We propose a modified\nIsotropic NCA model that does not have this limitation. We demonstrate that\ncell systems can be trained to grow accurate asymmetrical patterns through\neither of two methods: by breaking symmetries using structured seeds; or by\nintroducing a rotation-reflection invariant training objective and relying on\nsymmetry breaking caused by asynchronous cell updates.",
    "descriptor": "",
    "authors": [
      "Alexander Mordvintsev",
      "Ettore Randazzo",
      "Craig Fouts"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Cell Behavior (q-bio.CB)"
    ],
    "url": "https://arxiv.org/abs/2205.01681"
  },
  {
    "id": "arXiv:2205.01685",
    "title": "Deep Sequence Modeling for Anomalous ISP Traffic Prediction",
    "abstract": "Internet traffic in the real world is susceptible to various external and\ninternal factors which may abruptly change the normal traffic flow. Those\nunexpected changes are considered outliers in traffic. However, deep sequence\nmodels have been used to predict complex IP traffic, but their comparative\nperformance for anomalous traffic has not been studied extensively. In this\npaper, we investigated and evaluated the performance of different deep sequence\nmodels for anomalous traffic prediction. Several deep sequences models were\nimplemented to predict real traffic without and with outliers and show the\nsignificance of outlier detection in real-world traffic prediction. First, two\ndifferent outlier detection techniques, such as the Three-Sigma rule and\nIsolation Forest, were applied to identify the anomaly. Second, we adjusted\nthose abnormal data points using the Backward Filling technique before training\nthe model. Finally, the performance of different models was compared for\nabnormal and adjusted traffic. LSTM_Encoder_Decoder (LSTM_En_De) is the best\nprediction model in our experiment, reducing the deviation between actual and\npredicted traffic by more than 11\\% after adjusting the outliers. All other\nmodels, including Recurrent Neural Network (RNN), Long Short-Term Memory\n(LSTM), LSTM_En_De with Attention layer (LSTM_En_De_Atn), Gated Recurrent Unit\n(GRU), show better prediction after replacing the outliers and decreasing\nprediction error by more than 29%, 24%, 19%, and 10% respectively. Our\nexperimental results indicate that the outliers in the data can significantly\nimpact the quality of the prediction. Thus, outlier detection and mitigation\nassist the deep sequence model in learning the general trend and making better\npredictions.",
    "descriptor": "\nComments: 6 pages, 6 images, To appear in the Proceedings of IEEE International Conference on Communications, Seoul, South Korea, 2022. arXiv admin note: substantial text overlap with arXiv:2205.01300\n",
    "authors": [
      "Sajal Saha",
      "Anwar Haque",
      "Greg Sidebottom"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.01685"
  },
  {
    "id": "arXiv:2205.01686",
    "title": "Smart City Intersections: Intelligence Nodes for Future Metropolises",
    "abstract": "Traffic intersections are the most suitable locations for the deployment of\ncomputing, communications, and intelligence services for smart cities of the\nfuture. The abundance of data to be collected and processed, in combination\nwith privacy and security concerns, motivates the use of the edge-computing\nparadigm which aligns well with physical intersections in metropolises. This\npaper focuses on high-bandwidth, low-latency applications, and in that context\nit describes: (i) system design considerations for smart city intersection\nintelligence nodes; (ii) key technological components including sensors,\nnetworking, edge computing, low latency design, and AI-based intelligence; and\n(iii) applications such as privacy preservation, cloud-connected vehicles, a\nreal-time \"radar-screen\", traffic management, and monitoring of pedestrian\nbehavior during pandemics. The results of the experimental studies performed on\nthe COSMOS testbed located in New York City are illustrated. Future challenges\nin designing human-centered smart city intersections are summarized.",
    "descriptor": "",
    "authors": [
      "Zoran Kosti\u0107",
      "Alex Angus",
      "Zhengye Yang",
      "Zhuoxu Duan",
      "Ivan Seskar",
      "Gil Zussman",
      "Dipankar Raychaudhuri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.01686"
  },
  {
    "id": "arXiv:2205.01694",
    "title": "End2End Multi-View Feature Matching using Differentiable Pose  Optimization",
    "abstract": "Learning-based approaches have become indispensable for camera pose\nestimation. However, feature detection, description, matching, and pose\noptimization are often approached in an isolated fashion. In particular,\nerroneous feature matches have severe impact on subsequent camera pose\nestimation and often require additional measures such as outlier rejection. Our\nmethod tackles this challenge by addressing feature matching and pose\noptimization jointly: first, we integrate information from multiple views into\nthe matching by spanning a graph attention network across multiple frames to\npredict their matches all at once. Second, the resulting matches along with\ntheir predicted confidences are used for robust pose optimization with a\ndifferentiable Gauss-Newton solver. End-to-end training combined with\nmulti-view feature matching boosts the pose estimation metrics compared to\nSuperGlue by 8.9% on ScanNet and 10.7% on MegaDepth on average. Our approach\nimproves both pose estimation and matching accuracy over state-of-the-art\nmatching networks. Training feature matching across multiple views with\ngradients from pose optimization naturally learns to disregard outliers,\nthereby rendering additional outlier handling unnecessary, which is highly\ndesirable for pose estimation systems.",
    "descriptor": "\nComments: Video: this https URL\n",
    "authors": [
      "Barbara Roessle",
      "Matthias Nie\u00dfner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01694"
  },
  {
    "id": "arXiv:2205.01703",
    "title": "Improving In-Context Few-Shot Learning via Self-Supervised Training",
    "abstract": "Self-supervised pretraining has made few-shot learning possible for many NLP\ntasks. But the pretraining objectives are not typically adapted specifically\nfor in-context few-shot learning. In this paper, we propose to use\nself-supervision in an intermediate training stage between pretraining and\ndownstream few-shot usage with the goal to teach the model to perform\nin-context few shot learning. We propose and evaluate four self-supervised\nobjectives on two benchmarks. We find that the intermediate self-supervision\nstage produces models that outperform strong baselines. Ablation study shows\nthat several factors affect the downstream performance, such as the amount of\ntraining data and the diversity of the self-supervised objectives.\nHuman-annotated cross-task supervision and self-supervision are complementary.\nQualitative analysis suggests that the self-supervised-trained models are\nbetter at following task requirements.",
    "descriptor": "\nComments: NAACL 2022\n",
    "authors": [
      "Mingda Chen",
      "Jingfei Du",
      "Ramakanth Pasunuru",
      "Todor Mihaylov",
      "Srini Iyer",
      "Veselin Stoyanov",
      "Zornitsa Kozareva"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01703"
  },
  {
    "id": "arXiv:2205.01706",
    "title": "Object Class Aware Video Anomaly Detection through Image Translation",
    "abstract": "Semi-supervised video anomaly detection (VAD) methods formulate the task of\nanomaly detection as detection of deviations from the learned normal patterns.\nPrevious works in the field (reconstruction or prediction-based methods) suffer\nfrom two drawbacks: 1) They focus on low-level features, and they (especially\nholistic approaches) do not effectively consider the object classes. 2)\nObject-centric approaches neglect some of the context information (such as\nlocation). To tackle these challenges, this paper proposes a novel two-stream\nobject-aware VAD method that learns the normal appearance and motion patterns\nthrough image translation tasks. The appearance branch translates the input\nimage to the target semantic segmentation map produced by Mask-RCNN, and the\nmotion branch associates each frame with its expected optical flow magnitude.\nAny deviation from the expected appearance or motion in the inference stage\nshows the degree of potential abnormality. We evaluated our proposed method on\nthe ShanghaiTech, UCSD-Ped1, and UCSD-Ped2 datasets and the results show\ncompetitive performance compared with state-of-the-art works. Most importantly,\nthe results show that, as significant improvements to previous methods,\ndetections by our method are completely explainable and anomalies are localized\naccurately in the frames.",
    "descriptor": "\nComments: Accepted to CRV2022\n",
    "authors": [
      "Mohammad Baradaran",
      "Robert Bergevin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01706"
  },
  {
    "id": "arXiv:2205.01707",
    "title": "MemSE: Fast MSE Prediction for Noisy Memristor-Based DNN Accelerators",
    "abstract": "Memristors enable the computation of matrix-vector multiplications (MVM) in\nmemory and, therefore, show great potential in highly increasing the energy\nefficiency of deep neural network (DNN) inference accelerators. However,\ncomputations in memristors suffer from hardware non-idealities and are subject\nto different sources of noise that may negatively impact system performance. In\nthis work, we theoretically analyze the mean squared error of DNNs that use\nmemristor crossbars to compute MVM. We take into account both the quantization\nnoise, due to the necessity of reducing the DNN model size, and the programming\nnoise, stemming from the variability during the programming of the memristance\nvalue. Simulations on pre-trained DNN models showcase the accuracy of the\nanalytical prediction. Furthermore the proposed method is almost two order of\nmagnitude faster than Monte-Carlo simulation, thus making it possible to\noptimize the implementation parameters to achieve minimal error for a given\npower constraint.",
    "descriptor": "\nComments: To be presented at AICAS 2022\n",
    "authors": [
      "Jonathan Kern",
      "S\u00e9bastien Henwood",
      "Gon\u00e7alo Mordido",
      "Elsa Dupraz",
      "Abdeldjalil A\u00efssa-El-Bey",
      "Yvon Savaria",
      "Fran\u00e7ois Leduc-Primeau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Emerging Technologies (cs.ET)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.01707"
  },
  {
    "id": "arXiv:2205.01708",
    "title": "Convergence Analysis of Waveform Relaxation Method to Compute Coupled  Advection-Diffusion-Reaction Equations",
    "abstract": "We study the computation of coupled advection-diffusion-reaction equations by\nthe Schwarz waveform relaxation method. The study starts with linear equations,\nand it analyzes the convergence of the computation with a Dirichlet condition,\na Robin condition, and a combination of them as the transmission conditions.\nThen, an optimized algorithm for the Dirichlet condition is presented to\naccelerate the convergence, and numerical examples show a substantial speedup\nin the convergence. Furthermore, the optimized algorithm is extended to the\ncomputation of nonlinear equations, including the viscous Burgers equation, and\nnumerical experiments indicate the algorithm may largely remain effective in\nthe speedup of convergence.",
    "descriptor": "\nComments: 20 pages, 9 figures\n",
    "authors": [
      "Wenbin Dong",
      "Hansong Tang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.01708"
  },
  {
    "id": "arXiv:2205.01711",
    "title": "On the Level Crossing Rate of Fluid Antenna Systems",
    "abstract": "Multiple-input multiple-output (MIMO) technology has significantly impacted\nwireless communication, by providing extraordinary performance gains. However,\na minimum inter-antenna space constraint in MIMO systems does not allow its\nintegration in devices with limited space. In this context, the concept of\nfluid antenna systems (FASs) appears to be a potent solution, where there is no\nsuch restriction. In this paper, we investigate the average level crossing rate\n(LCR) of such FASs. Specifically, we derive closed-form analytical expressions\nof the LCR of such systems and extensive Monte-Carlo simulations validate the\nproposed analytical framework. Moreover, we also demonstrate that under certain\nconditions, the LCR obtained coincides with that of a conventional selection\ncombining-based receiver. Finally, the numerical results also provide insights\nregarding the selection of appropriate parameters that enhance the system\nperformance.",
    "descriptor": "\nComments: To appear in IEEE International Workshop on Signal Processing Advances in Wireless Communications (SPAWC) 2022\n",
    "authors": [
      "Priyadarshi Mukherjee",
      "Constantinos Psomas",
      "Ioannis Krikidis"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.01711"
  },
  {
    "id": "arXiv:2205.01713",
    "title": "A Typechecker for a Set-Based Constraint Logic Programming Language",
    "abstract": "{log} (read 'setlog') is a Constraint Logic Programming (CLP) language and\nsatisfiability solver whose constraint domain is the theory of finite sets.\nRooted in CLP and Prolog, {log} essentially provides an untyped language. As\nsuch it can accept formulas that make the solver to produce unwanted behaviors.\nBesides, {log} users may make mistakes in their programs that would normally be\ncaught by a typechecker. In particular, {log} has been proposed as a\nprototyping language for B and Z specifications, which are typed formalisms.\nThen, without a type system for {log} there is a gap that users need to fill\nmanually. Therefore, in this paper we define a type system and implement a\ntypechecker for {log}. The type system is proved to be safe (sound) by adapting\nthe functional programming formulation of type safety to the CLP context. We\nalso show how types and CLP can be combined to provide stronger assurances on\nprogram correctness. Finally, we apply the type system, the typechecker and\ntheir combination with CLP to a real-world case study from the aeronautic\ndomain.",
    "descriptor": "",
    "authors": [
      "Maximiliano Cristi\u00e1",
      "Gianfranco Rossi"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2205.01713"
  },
  {
    "id": "arXiv:2205.01714",
    "title": "Don't sweat the small stuff, classify the rest: Sample Shielding to  protect text classifiers against adversarial attacks",
    "abstract": "Deep learning (DL) is being used extensively for text classification.\nHowever, researchers have demonstrated the vulnerability of such classifiers to\nadversarial attacks. Attackers modify the text in a way which misleads the\nclassifier while keeping the original meaning close to intact. State-of-the-art\n(SOTA) attack algorithms follow the general principle of making minimal changes\nto the text so as to not jeopardize semantics. Taking advantage of this we\npropose a novel and intuitive defense strategy called Sample Shielding. It is\nattacker and classifier agnostic, does not require any reconfiguration of the\nclassifier or external resources and is simple to implement. Essentially, we\nsample subsets of the input text, classify them and summarize these into a\nfinal decision. We shield three popular DL text classifiers with Sample\nShielding, test their resilience against four SOTA attackers across three\ndatasets in a realistic threat setting. Even when given the advantage of\nknowing about our shielding strategy the adversary's attack success rate is\n<=10% with only one exception and often < 5%. Additionally, Sample Shielding\nmaintains near original accuracy when applied to original texts. Crucially, we\nshow that the `make minimal changes' approach of SOTA attackers leads to\ncritical vulnerabilities that can be defended against with an intuitive\nsampling strategy.",
    "descriptor": "\nComments: 9 pages, 8 figures, Accepted to NAACL 2022\n",
    "authors": [
      "Jonathan Rusert",
      "Padmini Srinivasan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01714"
  },
  {
    "id": "arXiv:2205.01716",
    "title": "Experiments with Unit Disk Cover Algorithms for Covering Massive  Pointsets",
    "abstract": "Given a set of $n$ points in the plane, the Unit Disk Cover (UDC) problem\nasks to compute the minimum number of unit disks required to cover the points,\nalong with a placement of the disks. The problem is NP-hard and several\napproximation algorithms have been designed over the last three decades. In\nthis paper, we have engineered and experimentally compared practical\nperformances of some of these algorithms on massive pointsets. The goal is to\ninvestigate which algorithms run fast and give good approximation in practice.\nWe present a simple $7$-approximation algorithm for UDC that runs in $O(n)$\nexpected time and uses $O(s)$ extra space, where $s$ denotes the size of the\ngenerated cover. In our experiments, it turned out to be the speediest of all.\nWe also present two heuristics to reduce the sizes of covers generated by it\nwithout slowing it down by much.\nTo our knowledge, this is the first work that experimentally compares\ngeometric covering algorithms. Experiments with them using massive pointsets\n(in the order of millions) throw light on their practical uses. We share the\nengineered algorithms via GitHub -\nhttps://github.com/ghoshanirban/UnitDiskCoverAlgorithms for broader uses and\nfuture research in the domain of geometric optimization.",
    "descriptor": "",
    "authors": [
      "Rachel Friederich",
      "Matthew Graham",
      "Anirban Ghosh",
      "Brian Hicks",
      "Ronald Shevchenko"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2205.01716"
  },
  {
    "id": "arXiv:2205.01721",
    "title": "In Defense of Image Pre-Training for Spatiotemporal Recognition",
    "abstract": "Image pre-training, the current de-facto paradigm for a wide range of visual\ntasks, is generally less favored in the field of video recognition. By\ncontrast, a common strategy is to directly train with spatiotemporal\nconvolutional neural networks (CNNs) from scratch. Nonetheless, interestingly,\nby taking a closer look at these from-scratch learned CNNs, we note there exist\ncertain 3D kernels that exhibit much stronger appearance modeling ability than\nothers, arguably suggesting appearance information is already well disentangled\nin learning. Inspired by this observation, we hypothesize that the key to\neffectively leveraging image pre-training lies in the decomposition of learning\nspatial and temporal features, and revisiting image pre-training as the\nappearance prior to initializing 3D kernels. In addition, we propose\nSpatial-Temporal Separable (STS) convolution, which explicitly splits the\nfeature channels into spatial and temporal groups, to further enable a more\nthorough decomposition of spatiotemporal features for fine-tuning 3D CNNs. Our\nexperiments show that simply replacing 3D convolution with STS notably improves\na wide range of 3D CNNs without increasing parameters and computation on both\nKinetics-400 and Something-Something V2. Moreover, this new training pipeline\nconsistently achieves better results on video recognition with significant\nspeedup. For instance, we achieve +0.6% top-1 of Slowfast on Kinetics-400 over\nthe strong 256-epoch 128-GPU baseline while fine-tuning for only 50 epochs with\n4 GPUs. The code and models are available at\nhttps://github.com/UCSC-VLAA/Image-Pretraining-for-Video.",
    "descriptor": "",
    "authors": [
      "Xianhang Li",
      "Huiyu Wang",
      "Chen Wei",
      "Jieru Mei",
      "Alan Yuille",
      "Yuyin Zhou",
      "Cihang Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01721"
  },
  {
    "id": "arXiv:2205.01722",
    "title": "Optimal Time-Backlog Tradeoffs for the Variable-Processor Cup Game",
    "abstract": "The \\emph{$ p$-processor cup game} is a classic and widely studied scheduling\nproblem that captures the setting in which a $p$-processor machine must assign\ntasks to processors over time in order to ensure that no individual task ever\nfalls too far behind. The problem is formalized as a multi-round game in which\ntwo players, a filler (who assigns work to tasks) and an emptier (who schedules\ntasks) compete. The emptier's goal is to minimize backlog, which is the maximum\namount of outstanding work for any task.\nRecently, Kuszmaul and Westover (ITCS, 2021) proposed the\n\\emph{variable-processor cup game}, which considers the same problem, except\nthat the amount of resources available to the players (i.e., the number $p$ of\nprocessors) fluctuates between rounds of the game. They showed that this\nseemingly small modification fundamentally changes the dynamics of the game:\nwhereas the optimal backlog in the fixed $p$-processor game is $\\Theta(\\log\nn)$, independent of $p$, the optimal backlog in the variable-processor game is\n$\\Theta(n)$. The latter result was only known to apply to games with\n\\emph{exponentially many} rounds, however, and it has remained an open question\nwhat the optimal tradeoff between time and backlog is for shorter games.\nThis paper establishes a tight trade-off curve between time and backlog in\nthe variable-processor cup game. Importantly, we prove that for a game\nconsisting of $t$ rounds, the optimal backlog is $\\Theta(n)$ if and only if $t\n\\ge \\Omega(n^3)$. Our techniques also allow for us to resolve several other\nopen questions concerning how the variable-processor cup game behaves in\nbeyond-worst-case-analysis settings.",
    "descriptor": "\nComments: 40 pages, to appear in ICALP 2022. Abstract abridged for arXiv submission: see paper for full abstract\n",
    "authors": [
      "William Kuszmaul",
      "Shyam Narayanan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2205.01722"
  },
  {
    "id": "arXiv:2205.01724",
    "title": "License Plate Privacy in Collaborative Visual Analysis of Traffic Scenes",
    "abstract": "Traffic scene analysis is important for emerging technologies such as smart\ntraffic management and autonomous vehicles. However, such analysis also poses\npotential privacy threats. For example, a system that can recognize license\nplates may construct patterns of behavior of the corresponding vehicles' owners\nand use that for various illegal purposes. In this paper we present a system\nthat enables traffic scene analysis while at the same time preserving license\nplate privacy. The system is based on a multi-task model whose latent space is\nselectively compressed depending on the amount of information the specific\nfeatures carry about analysis tasks and private information. Effectiveness of\nthe proposed method is illustrated by experiments on the Cityscapes dataset,\nfor which we also provide license plate annotations.",
    "descriptor": "\nComments: submitted to IEEE MIPR'22\n",
    "authors": [
      "Saeed Ranjbar Alvar",
      "Korcan Uyanik",
      "Ivan V. Baji\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.01724"
  },
  {
    "id": "arXiv:2205.01727",
    "title": "How to choose features to improve prediction performance in  lane-changing intention: A meta-analysis",
    "abstract": "Lane-change is a fundamental driving behavior and highly associated with\nvarious types of collisions, such as rear-end collisions, sideswipe collisions,\nand angle collisions and the increased risk of a traffic crash. This study\ninvestigates effectiveness of different features categories combination in\nlane-changing intention prediction. Studies related to lane-changing intention\nprediction have been selected followed by strict standards. Then the\nmeta-analysis was employed to not only evaluate the effectiveness of different\nfeatures categories combination in lane-changing intention but also capture\nheterogeneity, effect size combination, and publication bias. According to the\nmeta-analysis and reviewed research papers, results indicate that using input\nfeatures from different types can lead to different performances. And vehicle\ninput type has a better performance in lane-changing intention, prediction,\ncompared with environment or even driver combination input type. Finally, some\npotential future research directions are proposed based on the findings of the\npaper.",
    "descriptor": "\nComments: 15pages\n",
    "authors": [
      "Ruifeng Gu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2205.01727"
  },
  {
    "id": "arXiv:2205.01728",
    "title": "A Secure File Sharing System Based on IPFS and Blockchain",
    "abstract": "There is a great interest in many approaches towards blockchain in providing\na solution to record transactions in a decentralized way. However, there are\nsome limitations when storing large files or documents on the blockchain. In\norder to meet the requirements of storing relatively large data, a\ndecentralized storage medium is produced. IPFS is a distributed file system\nwhich is content-addressable. It works very similar to the blockchain network.\nThere are some attempts which take advantage of the blockchain concept and IPFS\nto design new approaches. Unfortunately, there are some inefficiencies in\nsharing data using the combination of IPFS and blockchain. In this paper, we\nproposed a secure file sharing system that brings a distributed access control\nand group key management by the adoption of the IPFS proxy. The IPFS proxy\nwhich plays an important role in the design is adopted to take responsibility\nfor the control policies. The combination of the IPFS server and the blockchain\nnetwork with the adoption of the IPFS proxy make a secure file sharing system\nwhich the members on the system can create new groups or join different groups\nby their own choice. Although there is no access control mechanism in IPFS\nserver and blockchain network, the secure file sharing system manages the\naccess control policies. The members access files only belong to the group they\nauthorized.",
    "descriptor": "\nComments: 4 pages, 4 figures, published in Proceedings of the 2020 2nd International Electronics Communication Conference\n",
    "authors": [
      "Hsiao-Shan Huang",
      "Tian-Sheuan Chang",
      "Jhih-Yi Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.01728"
  },
  {
    "id": "arXiv:2205.01729",
    "title": "Pre-RTL DNN Hardware Evaluator With Fused Layer Support",
    "abstract": "With the popularity of the deep neural network (DNN), hardware accelerators\nare demanded for real time execution. However, lengthy design process and fast\nevolving DNN models make hardware evaluation hard to meet the time to market\nneed. This paper proposes a pre-RTL DNN hardware evaluator that supports\nconventional layer-by-layer processing as well as the fused layer processing\nfor low external bandwidth requirement. The evaluator supports two\nstate-of-the-art accelerator architectures and finds the best hardware and\nlayer fusion group The experimental results show the layer fusion scheme can\nachieve 55.6% memory bandwidth reduction, 36.7% latency improvement and 49.2%\nenergy reduction compared with layer-by-layer operation.",
    "descriptor": "\nComments: 2 pages, 2 figures, published in IEEE ISOCC 2021\n",
    "authors": [
      "Chih-Chyau Yang",
      "Tian-Sheuan Chang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01729"
  },
  {
    "id": "arXiv:2205.01730",
    "title": "Quiz Design Task: Helping Teachers Create Quizzes with Automated  Question Generation",
    "abstract": "Question generation (QGen) models are often evaluated with standardized NLG\nmetrics that are based on n-gram overlap. In this paper, we measure whether\nthese metric improvements translate to gains in a practical setting, focusing\non the use case of helping teachers automate the generation of reading\ncomprehension quizzes. In our study, teachers building a quiz receive question\nsuggestions, which they can either accept or refuse with a reason. Even though\nwe find that recent progress in QGen leads to a significant increase in\nquestion acceptance rates, there is still large room for improvement, with the\nbest model having only 68.4% of its questions accepted by the ten teachers who\nparticipated in our study. We then leverage the annotations we collected to\nanalyze standard NLG metrics and find that model performance has reached\nprojected upper-bounds, suggesting new automatic metrics are needed to guide\nQGen research forward.",
    "descriptor": "\nComments: Accepted at NAACL 2022 Special HCI Theme (Findings, short paper), 10 pages, 6 figures\n",
    "authors": [
      "Philippe Laban",
      "Chien-Sheng Wu",
      "Lidiya Murakhovs'ka",
      "Wenhao Liu",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.01730"
  },
  {
    "id": "arXiv:2205.01731",
    "title": "Themes of Revenge: Automatic Identification of Vengeful Content in  Textual Data",
    "abstract": "Revenge is a powerful motivating force reported to underlie the behavior of\nvarious solo perpetrators, from school shooters to right wing terrorists. In\nthis paper, we develop an automated methodology for identifying vengeful themes\nin textual data. Testing the model on four datasets (vengeful texts from social\nmedia, school shooters, Right Wing terrorist and Islamic terrorists), we\npresent promising results, even when the methodology is tested on extremely\nimbalanced datasets. The paper not only presents a simple and powerful\nmethodology that may be used for the screening of solo perpetrators but also\nvalidate the simple theoretical model of revenge.",
    "descriptor": "",
    "authors": [
      "Yair Neuman",
      "Eden Shalom Erez",
      "Joshua Tschantret",
      "Hayden Weiss"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01731"
  },
  {
    "id": "arXiv:2205.01733",
    "title": "Application of belief functions to medical image segmentation: A review",
    "abstract": "Belief function theory, a formal framework for uncertainty analysis and\nmultiple evidence fusion, has made significant contributions in the medical\ndomain, especially since the development of deep learning. Medical image\nsegmentation with belief function theory has shown significant benefits in\nclinical diagnosis and medical image research. In this paper, we provide a\nreview of medical image segmentation methods using belief function theory. We\nclassify the methods according to the fusion step and explain how information\nwith uncertainty or imprecision is modeled and fused with belief function\ntheory. In addition, we discuss the challenges and limitations of present\nbelief function-based medical image segmentation and propose orientations for\nfuture research. Future research could investigate both belief function theory\nand deep learning to achieve more promising and reliable segmentation results.",
    "descriptor": "\nComments: Preprint submitted to Medical Image Analysis\n",
    "authors": [
      "Ling Huang",
      "Su Ruan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01733"
  },
  {
    "id": "arXiv:2205.01736",
    "title": "Krylov-aware stochastic trace estimation",
    "abstract": "We introduce an algorithm for estimating the trace of a matrix function f(A)\nusing implicit products with a symmetric matrix A. Existing methods for\nimplicit trace estimation of a matrix function tend to treat matrix-vector\nproducts with f(A) as a black-box to be computed by a Krylov subspace method.\nLike other algorithms for implicit trace estimation, our approach is based on a\ncombination of deflation and stochastic trace estimation. However, we take a\ncloser look at how products with f(A) are integrated into these approaches\nwhich enables several efficiencies not present in previously studied methods.",
    "descriptor": "",
    "authors": [
      "Tyler Chen",
      "Eric Hallman"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.01736"
  },
  {
    "id": "arXiv:2205.01739",
    "title": "Intelligent Reflecting Surface Networks with Multi-Order-Reflection  Effect: System Modelling and Critical Bounds",
    "abstract": "In this paper, we model, analyze and optimize the multi-user and\nmulti-order-reflection (MUMOR) intelligent reflecting surface (IRS) networks.\nWe first derive a complete MUMOR IRS network model applicable for the arbitrary\ntimes of reflections, size and number of IRSs/reflectors. The optimal condition\nfor achieving sum-rate upper bound with one IRS in a closed-form function and\nthe analytical condition to achieve interference-free transmission are derived,\nrespectively. Leveraging this optimal condition, we obtain the MUMOR sum-rate\nupper bound of the IRS network with different network topologies, where the\nlinear graph (LG), complete graph (CG) and null graph (NG) topologies are\nconsidered. Simulation results verify our theories and derivations and\ndemonstrate that the sum-rate upper bounds of different network topologies are\nunder a K-fold improvement given K-piece IRS.",
    "descriptor": "",
    "authors": [
      "Yihong Liu",
      "Lei Zhang",
      "Feifei Gao",
      "Muhammad Ali Imran"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.01739"
  },
  {
    "id": "arXiv:2205.01741",
    "title": "Comparison of CoModGANs, LaMa and GLIDE for Art Inpainting- Completing  M.C Escher's Print Gallery",
    "abstract": "Digital art restoration has benefited from inpainting models to correct the\ndegradation or missing sections of a painting. This work compares three current\nstate-of-the art models for inpainting of large missing regions. We provide\nqualitative and quantitative comparison of the performance by CoModGANs, LaMa\nand GLIDE in inpainting of blurry and missing sections of images. We use\nEscher's incomplete painting Print Gallery as our test study since it presents\nseveral of the challenges commonly present in restorative inpainting.",
    "descriptor": "\nComments: CVPR-NITRE workshop 2022\n",
    "authors": [
      "Lucia Cipolina-Kun",
      "Simone Caenazzo",
      "Gaston Mazzei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01741"
  },
  {
    "id": "arXiv:2205.01748",
    "title": "Bounds on the Capacity of the Multiple Access Diamond Channel with  Cooperating Base-Stations",
    "abstract": "A diamond network is considered in which the central processor is connected,\nvia backhaul noiseless links, to multiple conferencing base stations, which\ncommunicate with a single user over a multiple access channel. We propose\ncoding techniques along with lower and upper bounds on the capacity. Our\nachievability scheme uses a common cloud coding strategy based on the technique\nproposed by Wand, Wigger, and Zaidi (2018) and extends it beyond two relays.\nOur upper bounds generalize the method proposed by Bidokhti and Kramer for the\ntwo relay diamond network without cooperation (2016) and lead to new bounds for\nthe multiple relay setting. Specializing our upper bounds for the two relay\nscenario (with cooperation), we provide new bounds and improve\nstate-of-the-art.",
    "descriptor": "\nComments: Complementary proofs for the ISIT2022 conference paper\n",
    "authors": [
      "Michael Dikshtein",
      "Shirin Saeedi Bidokhti",
      "Shlomo Shamai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.01748"
  },
  {
    "id": "arXiv:2205.01749",
    "title": "Mixed-effects transformers for hierarchical adaptation",
    "abstract": "Language use differs dramatically from context to context. To some degree,\nmodern language models like GPT-3 are able to account for such variance by\nconditioning on a string of previous input text, or prompt. Yet prompting is\nineffective when contexts are sparse, out-of-sample, or extra-textual; for\ninstance, accounting for when and where the text was produced or who produced\nit. In this paper, we introduce the mixed-effects transformer (MET), a novel\napproach for learning hierarchically-structured prefixes -- lightweight modules\nprepended to the input -- to account for structured variation. Specifically, we\nshow how the popular class of mixed-effects models may be extended to\ntransformer-based architectures using a regularized prefix-tuning procedure\nwith dropout. We evaluate this approach on several domain-adaptation\nbenchmarks, finding that it efficiently adapts to novel contexts with minimal\ndata while still effectively generalizing to unseen contexts.",
    "descriptor": "",
    "authors": [
      "Julia White",
      "Noah Goodman",
      "Robert Hawkins"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01749"
  },
  {
    "id": "arXiv:2205.01751",
    "title": "On monoaural speech enhancement for automatic recognition of real noisy  speech using mixture invariant training",
    "abstract": "In this paper, we explore an improved framework to train a monoaural neural\nenhancement model for robust speech recognition. The designed training\nframework extends the existing mixture invariant training criterion to exploit\nboth unpaired clean speech and real noisy data. It is found that the unpaired\nclean speech is crucial to improve quality of separated speech from real noisy\nspeech. The proposed method also performs remixing of processed and unprocessed\nsignals to alleviate the processing artifacts. Experiments on the\nsingle-channel CHiME-3 real test sets show that the proposed method improves\nsignificantly in terms of speech recognition performance over the enhancement\nsystem trained either on the mismatched simulated data in a supervised fashion\nor on the matched real data in an unsupervised fashion. Between 16% and 39%\nrelative WER reduction has been achieved by the proposed system compared to the\nunprocessed signal using end-to-end and hybrid acoustic models without\nretraining on distorted data.",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Jisi Zhang",
      "Catalin Zorila",
      "Rama Doddipatla",
      "Jon Barker"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.01751"
  },
  {
    "id": "arXiv:2205.01756",
    "title": "Social Practice Cards: Research material to study social contexts as  interwoven practice constellations",
    "abstract": "Studying how social contexts shape technology interactions and how we\nexperience them is hard. One challenge is that social contexts are very dynamic\nand shaped by the situated practices of everyone involved. As a result, the\nsame human-technology interaction can be experienced quite differently\ndepending on what other people around us do. As a first step to study\ninterpersonal and interpractice dynamics, we collected a broad range of visual\nrepresentations of practices, such as \"riding a bike\" or \"skipping the rope\".\nThis material can be used to further explore how different, co-located\npractices relate to each other.",
    "descriptor": "\nComments: 4 pages, 2 figures\n",
    "authors": [
      "Alarith Uhde",
      "Mena Mesenh\u00f6ller",
      "Marc Hassenzahl"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.01756"
  },
  {
    "id": "arXiv:2205.01757",
    "title": "XLTime: A Cross-Lingual Knowledge Transfer Framework for Temporal  Expression Extraction",
    "abstract": "Temporal Expression Extraction (TEE) is essential for understanding time in\nnatural language. It has applications in Natural Language Processing (NLP)\ntasks such as question answering, information retrieval, and causal inference.\nTo date, work in this area has mostly focused on English as there is a scarcity\nof labeled data for other languages. We propose XLTime, a novel framework for\nmultilingual TEE. XLTime works on top of pre-trained language models and\nleverages multi-task learning to prompt cross-language knowledge transfer both\nfrom English and within the non-English languages. XLTime alleviates problems\ncaused by a shortage of data in the target language. We apply XLTime with\ndifferent language models and show that it outperforms the previous automatic\nSOTA methods on French, Spanish, Portuguese, and Basque, by large margins.\nXLTime also closes the gap considerably on the handcrafted HeidelTime method.",
    "descriptor": "\nComments: This paper is accepted by the Findings of NAACL 2022\n",
    "authors": [
      "Yuwei Cao",
      "William Groves",
      "Tanay Kumar Saha",
      "Joel R. Tetreault",
      "Alex Jaimes",
      "Hao Peng",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01757"
  },
  {
    "id": "arXiv:2205.01758",
    "title": "Differentiable Simulation of Soft Multi-body Systems",
    "abstract": "We present a method for differentiable simulation of soft articulated bodies.\nOur work enables the integration of differentiable physical dynamics into\ngradient-based pipelines. We develop a top-down matrix assembly algorithm\nwithin Projective Dynamics and derive a generalized dry friction model for soft\ncontinuum using a new matrix splitting strategy. We derive a differentiable\ncontrol framework for soft articulated bodies driven by muscles, joint torques,\nor pneumatic tubes. The experiments demonstrate that our designs make soft body\nsimulation more stable and realistic compared to other frameworks. Our method\naccelerates the solution of system identification problems by more than an\norder of magnitude, and enables efficient gradient-based learning of motion\ncontrol with soft robots.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Yi-Ling Qiao",
      "Junbang Liang",
      "Vladlen Koltun",
      "Ming C. Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Graphics (cs.GR)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.01758"
  },
  {
    "id": "arXiv:2205.01759",
    "title": "Explain and Conquer: Personalised Text-based Reviews to Achieve  Transparency",
    "abstract": "There are many contexts where dyadic data is present. Social networking is a\nwell-known example, where transparency has grown on importance. In these\ncontexts, pairs of items are linked building a network where interactions play\na crucial role. Explaining why these relationships are established is core to\naddress transparency. These explanations are often presented using text, thanks\nto the spread of the natural language understanding tasks.\nWe have focused on the TripAdvisor platform, considering the applicability to\nother dyadic data contexts. The items are a subset of users and restaurants and\nthe interactions the reviews posted by these users. Our aim is to represent and\nexplain pairs (user, restaurant) established by agents (e.g., a recommender\nsystem or a paid promotion mechanism), so that personalisation is taken into\naccount. We propose the PTER (Personalised TExt-based Reviews) model. We\npredict, from the available reviews for a given restaurant, those that fit to\nthe specific user interactions.\nPTER leverages the BERT (Bidirectional Encoders Representations from\nTransformers) language model. We customised a deep neural network following the\nfeature-based approach. The performance metrics show the validity of our\nlabelling proposal. We defined an evaluation framework based on a clustering\nprocess to assess our personalised representation. PTER clearly outperforms the\nproposed adversary in 5 of the 6 datasets, with a minimum ratio improvement of\n4%.",
    "descriptor": "",
    "authors": [
      "I\u00f1igo L\u00f3pez-Riob\u00f3o Botana",
      "Ver\u00f3nica Bol\u00f3n-Canedo",
      "Bertha Guijarro-Berdi\u00f1as",
      "Amparo Alonso-Betanzos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.01759"
  },
  {
    "id": "arXiv:2205.01763",
    "title": "Analyzing and Simulating User Utterance Reformulation in Conversational  Recommender Systems",
    "abstract": "User simulation has been a cost-effective technique for evaluating\nconversational recommender systems. However, building a human-like simulator is\nstill an open challenge. In this work, we focus on how users reformulate their\nutterances when a conversational agent fails to understand them. First, we\nperform a user study, involving five conversational agents across different\ndomains, to identify common reformulation types and their transition\nrelationships. A common pattern that emerges is that persistent users would\nfirst try to rephrase, then simplify, before giving up. Next, to incorporate\nthe observed reformulation behavior in a user simulator, we introduce the task\nof reformulation sequence generation: to generate a sequence of reformulated\nutterances with a given intent (rephrase or simplify). We develop methods by\nextending transformer models guided by the reformulation type and perform\nfurther filtering based on estimated reading difficulty. We demonstrate the\neffectiveness of our approach using both automatic and human evaluation.",
    "descriptor": "\nComments: Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval\n",
    "authors": [
      "Shuo Zhang",
      "Mu-Chun Wang",
      "Krisztian Balog"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.01763"
  },
  {
    "id": "arXiv:2205.01768",
    "title": "Traversing Supervisor Problem: An Approximately Optimal Approach to  Multi-Robot Assistance",
    "abstract": "The number of multi-robot systems deployed in field applications has\nincreased dramatically over the years. Despite the recent advancement of\nnavigation algorithms, autonomous robots often encounter challenging situations\nwhere the control policy fails and the human assistance is required to resume\nrobot tasks. Human-robot collaboration can help achieve high-levels of\nautonomy, but monitoring and managing multiple robots at once by a single human\nsupervisor remains a challenging problem. Our goal is to help a supervisor\ndecide which robots to assist in which order such that the team performance can\nbe maximized. We formulate the one-to-many supervision problem in uncertain\nenvironments as a dynamic graph traversal problem. An approximation algorithm\nbased on the profitable tour problem on a static graph is developed to solve\nthe original problem, and the approximation error is bounded and analyzed. Our\ncase study on a simulated autonomous farm demonstrates superior team\nperformance than baseline methods in task completion time and human working\ntime, and that our method can be deployed in real-time for robot fleets with\nmoderate size.",
    "descriptor": "\nComments: RSS 2022 Camera Ready Version\n",
    "authors": [
      "Tianchen Ji",
      "Roy Dong",
      "Katherine Driggs-Campbell"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.01768"
  },
  {
    "id": "arXiv:2205.01772",
    "title": "Os Dados dos Brasileiros sob Risco na Era da Intelig\u00eancia Artificial?",
    "abstract": "Advances in image processing and analysis as well as machine learning\ntechniques have contributed to the use of biometric recognition systems in\ndaily people tasks. These tasks range from simple access to mobile devices to\ntagging friends in photos shared on social networks and complex financial\noperations on self-service devices for banking transactions. In China, the use\nof these systems goes beyond personal use becoming a country's government\npolicy with the objective of monitoring the behavior of its population. On July\n05th 2021, the Brazilian government announced acquisition of a biometric\nrecognition system to be used nationwide. In the opposite direction to China,\nEurope and some American cities have already started the discussion about the\nlegality of using biometric systems in public places, even banning this\npractice in their territory. In order to open a deeper discussion about the\nrisks and legality of using these systems, this work exposes the\nvulnerabilities of biometric recognition systems, focusing its efforts on the\nface modality. Furthermore, it shows how it is possible to fool a biometric\nsystem through a well-known presentation attack approach in the literature\ncalled morphing. Finally, a list of ten concerns was created to start the\ndiscussion about the security of citizen data and data privacy law in the Age\nof Artificial Intelligence (AI).",
    "descriptor": "\nComments: 8 pages in Portuguese and 5 figures\n",
    "authors": [
      "Raoni F. da S. Teixeira",
      "Rafael B. Januzi",
      "Fabio A. Faria"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.01772"
  },
  {
    "id": "arXiv:2205.01782",
    "title": "Learning Multi-dimensional Edge Feature-based AU Relation Graph for  Facial Action Unit Recognition",
    "abstract": "The activations of Facial Action Units (AUs) mutually influence one another.\nWhile the relationship between a pair of AUs can be complex and unique,\nexisting approaches fail to specifically and explicitly represent such cues for\neach pair of AUs in each facial display. This paper proposes an AU relationship\nmodelling approach that deep learns a unique graph to explicitly describe the\nrelationship between each pair of AUs of the target facial display. Our\napproach first encodes each AU's activation status and its association with\nother AUs into a node feature. Then, it learns a pair of multi-dimensional edge\nfeatures to describe multiple task-specific relationship cues between each pair\nof AUs. During both node and edge feature learning, our approach also considers\nthe influence of the unique facial display on AUs' relationship by taking the\nfull face representation as an input. Experimental results on BP4D and DISFA\ndatasets show that both node and edge feature learning modules provide large\nperformance improvements for CNN and transformer-based backbones, with our best\nsystems achieving the state-of-the-art AU recognition results. Our approach not\nonly has a strong capability in modelling relationship cues for AU recognition\nbut also can be easily incorporated into various backbones. Our PyTorch code is\nmade available.",
    "descriptor": "\nComments: IJCAI 2022 conference (accepted)\n",
    "authors": [
      "Cheng Luo",
      "Siyang Song",
      "Weicheng Xie",
      "Linlin Shen",
      "Hatice Gunes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01782"
  },
  {
    "id": "arXiv:2205.01783",
    "title": "A Pre-study on Data Processing Pipelines for Roadside Object Detection  Systems Towards Safer Road Infrastructure",
    "abstract": "Single-vehicle accidents are the most common type of fatal accidents in\nSweden, where a car drives off the road and runs into hazardous roadside\nobjects. Proper installation and maintenance of protective objects, such as\ncrash cushions and guard rails, may reduce the chance and severity of such\naccidents. Moreover, efficient detection and management of hazardous roadside\nobjects also plays an important role in improving road safety. To better\nunderstand the state-of-the-art and system requirements, in this pre-study, we\ninvestigate the feasibility, implementation, limitations and scaling up of data\nprocessing pipelines for roadside object detection. In particular, we divide\nour investigation into three parts: the target of interest, the sensors of\nchoice and the algorithm design. The data sources we consider in this study\ncover two common setups: 1) road surveying fleet - annual scans conducted by\nTrafikverket, the Swedish Transport Administration, and 2) consumer vehicle -\ndata collected using a research vehicle from the laboratory of Resource for\nvehicle research at Chalmers (REVERE). The goal of this report is to\ninvestigate how to implement a scalable roadside object detection system\ntowards safe road infrastructure and Sweden's Vision Zero.",
    "descriptor": "",
    "authors": [
      "Yinan Yu",
      "Samuel Scheidegger",
      "John-Fredrik Gr\u00f6nvall",
      "Magnus Palm",
      "Erik Svanberg",
      "Johan Amoruso Wennerby",
      "J\u00f6rg Bakker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.01783"
  },
  {
    "id": "arXiv:2205.01785",
    "title": "The limitations of the theoretical analysis of applied algorithms",
    "abstract": "The theoretical analysis of performance has been an important tool in the\nengineering of algorithms in many application domains. Its goals are to predict\nthe empirical performance of an algorithm and to be a yardstick that drives the\ndesign of novel algorithms that perform well in practice. While these goals\nhave been achieved in many instances, they have not been achieved in some other\ncrucial application domains. In this paper, I focus on the example of\nsequencing bioinformatics, an inter-disciplinary field that uses algorithms to\nextract biological meaning from genome sequencing data. I will demonstrate two\nconcrete examples of how theoretical analysis has failed to achieve its goals\nbut also give one encouraging example of success. I will then catalog some of\nthe challenges of applying theoretical analysis to sequencing bioinformatics,\nargue why empirical analysis is not enough, and give a vision for improving the\nrelevance of theoretical analysis to sequencing bioinformatics and other\napplication domains. By recognizing the problem, understanding its roots, and\nproviding potential solutions, this work can hopefully be a crucial first step\ntowards making theoretical analysis more relevant in modern application\ndomains.",
    "descriptor": "",
    "authors": [
      "Paul Medvedev"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.01785"
  },
  {
    "id": "arXiv:2205.01789",
    "title": "Do More Negative Samples Necessarily Hurt in Contrastive Learning?",
    "abstract": "Recent investigations in noise contrastive estimation suggest, both\nempirically as well as theoretically, that while having more \"negative samples\"\nin the contrastive loss improves downstream classification performance\ninitially, beyond a threshold, it hurts downstream performance due to a\n\"collision-coverage\" trade-off. But is such a phenomenon inherent in\ncontrastive learning? We show in a simple theoretical setting, where positive\npairs are generated by sampling from the underlying latent class (introduced by\nSaunshi et al. (ICML 2019)), that the downstream performance of the\nrepresentation optimizing the (population) contrastive loss in fact does not\ndegrade with the number of negative samples. Along the way, we give a\nstructural characterization of the optimal representation in our framework, for\nnoise contrastive estimation. We also provide empirical support for our\ntheoretical results on CIFAR-10 and CIFAR-100 datasets.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Pranjal Awasthi",
      "Nishanth Dikkala",
      "Pritish Kamath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.01789"
  },
  {
    "id": "arXiv:2205.01791",
    "title": "TartanDrive: A Large-Scale Dataset for Learning Off-Road Dynamics Models",
    "abstract": "We present TartanDrive, a large scale dataset for learning dynamics models\nfor off-road driving. We collected a dataset of roughly 200,000 off-road\ndriving interactions on a modified Yamaha Viking ATV with seven unique sensing\nmodalities in diverse terrains. To the authors' knowledge, this is the largest\nreal-world multi-modal off-road driving dataset, both in terms of number of\ninteractions and sensing modalities. We also benchmark several state-of-the-art\nmethods for model-based reinforcement learning from high-dimensional\nobservations on this dataset. We find that extending these models to\nmulti-modality leads to significant performance on off-road dynamics\nprediction, especially in more challenging terrains. We also identify some\nshortcomings with current neural network architectures for the off-road driving\ntask. Our dataset is available at https://github.com/castacks/tartan_drive.",
    "descriptor": "",
    "authors": [
      "Samuel Triest",
      "Matthew Sivaprakasam",
      "Sean J. Wang",
      "Wenshan Wang",
      "Aaron M. Johnson",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.01791"
  },
  {
    "id": "arXiv:2205.01797",
    "title": "Coded Transaction Broadcasting for High-throughput Blockchains",
    "abstract": "High-throughput blockchains require efficient transaction broadcast\nmechanisms that can deliver transactions to most network nodes with low\nbandwidth overhead and latency. Existing schemes coordinate transmissions\nacross peers to avoid sending redundant data, but they either incur a high\nlatency or are not robust against adversarial network nodes. We present\nStrokkur, a new transaction broadcasting mechanism that provides both low\nbandwidth overhead and low latency. The core idea behind Strokkur is to avoid\nexplicit coordination through randomized transaction coding. Rather than\nforward individual transactions. Strokkur nodes send out codewords -- XOR sums\nof multiple transactions selected at random. Since almost every codeword is\nuseful for the receiver to decode new transactions, Strokkur nodes do not\nrequire coordination, for example, to determine which transactions the receiver\nis missing. Strokkur's coding strategy builds on LT codes, a popular class of\nrateless erasure codes, and extends them to support multiple uncoordinated\nsenders with partially-overlapping continual streams of transaction data.\nStrokkur introduces mechanisms to cope with adversarial senders that may send\ncorrupt codewords, and a simple rate control algorithm that enables each node\nto independently determine an appropriate sending rate of codewords for each\npeer. Our implementation of Strokkur in Golang supports 647k transactions per\nsecond using only one CPU core. Our evaluation across a 19-node Internet\ndeployment and large-scale simulation show that Strokkur consumes 2--7.6x less\nbandwidth than the existing scheme in Bitcoin, and 9x lower latency that Shrec\nwhen only 4% of nodes are adversarial.",
    "descriptor": "",
    "authors": [
      "Lei Yang",
      "Yossi Gilad",
      "Mohammad Alizadeh"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.01797"
  },
  {
    "id": "arXiv:2205.01800",
    "title": "Synthesized Speech Detection Using Convolutional Transformer-Based  Spectrogram Analysis",
    "abstract": "Synthesized speech is common today due to the prevalence of virtual\nassistants, easy-to-use tools for generating and modifying speech signals, and\nremote work practices. Synthesized speech can also be used for nefarious\npurposes, including creating a purported speech signal and attributing it to\nsomeone who did not speak the content of the signal. We need methods to detect\nif a speech signal is synthesized. In this paper, we analyze speech signals in\nthe form of spectrograms with a Compact Convolutional Transformer (CCT) for\nsynthesized speech detection. A CCT utilizes a convolutional layer that\nintroduces inductive biases and shared weights into a network, allowing a\ntransformer architecture to perform well with fewer data samples used for\ntraining. The CCT uses an attention mechanism to incorporate information from\nall parts of a signal under analysis. Trained on both genuine human voice\nsignals and synthesized human voice signals, we demonstrate that our CCT\napproach successfully differentiates between genuine and synthesized speech\nsignals.",
    "descriptor": "\nComments: Accepted to the 2021 IEEE Asilomar Conference on Signals, Systems, and Computers\n",
    "authors": [
      "Emily R. Bartusiak",
      "Edward J. Delp"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.01800"
  },
  {
    "id": "arXiv:2205.01802",
    "title": "A Review on Pushing the Limits of Baseline Recommendation Systems with  the integration of Opinion Mining & Information Retrieval Techniques",
    "abstract": "Recommendations Systems allow users to identify trending items among a\ncommunity while being timely and relevant to the user's expectations. When the\npurpose of various Recommendation Systems differs, the required type of\nrecommendations also differs for each use case. While one Recommendation System\nmay focus on recommending popular items, another may focus on recommending\nitems that are comparable to the user's interests. Content-based filtering,\nuser-to-user & item-to-item Collaborative filtering, and more recently; Deep\nLearning methods have been brought forward by the researchers to achieve better\nquality recommendations.\nEven though each of these methods has proven to perform well individually,\nthere have been attempts to push the boundaries of their limitations. Following\na wide range of methods, researchers have tried to expand on the capabilities\nof standard recommendation systems to provide the most effective\nrecommendations to users while being more profitable from a business's\nperspective. This has been achieved by taking a hybrid approach when building\nmodels and architectures for Recommendation Systems.\nThis paper is a review of the novel models & architectures of hybrid\nRecommendation Systems. The author identifies possibilities of expanding the\ncapabilities of baseline models & the advantages and drawbacks of each model\nwith selected use cases in this review.",
    "descriptor": "",
    "authors": [
      "Dinuka Ravijaya Piyadigama",
      "Guhanathan Poravi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.01802"
  },
  {
    "id": "arXiv:2205.01805",
    "title": "Splicing Detection and Localization In Satellite Imagery Using  Conditional GANs",
    "abstract": "The widespread availability of image editing tools and improvements in image\nprocessing techniques allow image manipulation to be very easy. Oftentimes,\neasy-to-use yet sophisticated image manipulation tools yields\ndistortions/changes imperceptible to the human observer. Distribution of forged\nimages can have drastic ramifications, especially when coupled with the speed\nand vastness of the Internet. Therefore, verifying image integrity poses an\nimmense and important challenge to the digital forensic community. Satellite\nimages specifically can be modified in a number of ways, including the\ninsertion of objects to hide existing scenes and structures. In this paper, we\ndescribe the use of a Conditional Generative Adversarial Network (cGAN) to\nidentify the presence of such spliced forgeries within satellite images.\nAdditionally, we identify their locations and shapes. Trained on pristine and\nfalsified images, our method achieves high success on these detection and\nlocalization objectives.",
    "descriptor": "\nComments: Accepted to the 2019 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)\n",
    "authors": [
      "Emily R. Bartusiak",
      "Sri Kalyan Yarlagadda",
      "David G\u00fcera",
      "Paolo Bestagini",
      "Stefano Tubaro",
      "Fengqing M. Zhu",
      "Edward J. Delp"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.01805"
  },
  {
    "id": "arXiv:2205.01806",
    "title": "Frequency Domain-Based Detection of Generated Audio",
    "abstract": "Attackers may manipulate audio with the intent of presenting falsified\nreports, changing an opinion of a public figure, and winning influence and\npower. The prevalence of inauthentic multimedia continues to rise, so it is\nimperative to develop a set of tools that determines the legitimacy of media.\nWe present a method that analyzes audio signals to determine whether they\ncontain real human voices or fake human voices (i.e., voices generated by\nneural acoustic and waveform models). Instead of analyzing the audio signals\ndirectly, the proposed approach converts the audio signals into spectrogram\nimages displaying frequency, intensity, and temporal content and evaluates them\nwith a Convolutional Neural Network (CNN). Trained on both genuine human voice\nsignals and synthesized voice signals, we show our approach achieves high\naccuracy on this classification task.",
    "descriptor": "\nComments: Accepted to the 2021 Media Watermarking, Security, and Forensics Conference, IS&T Electronic Imaging Symposium (EI)\n",
    "authors": [
      "Emily R. Bartusiak",
      "Edward J. Delp"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.01806"
  },
  {
    "id": "arXiv:2205.01807",
    "title": "Learning Dynamic Bipedal Walking Across Stepping Stones",
    "abstract": "In this work, we propose a learning approach for 3D dynamic bipedal walking\nwhen footsteps are constrained to stepping stones. While recent work has shown\nprogress on this problem, real-world demonstrations have been limited to\nrelatively simple open-loop, perception-free scenarios. Our main contribution\nis a more advanced learning approach that enables real-world demonstrations,\nusing the Cassie robot, of closed-loop dynamic walking over moderately\ndifficult stepping-stone patterns. Our approach first uses reinforcement\nlearning (RL) in simulation to train a controller that maps footstep commands\nonto joint actions without any reference motion information. We then learn a\nmodel of that controller's capabilities, which enables prediction of feasible\nfootsteps given the robot's current dynamic state. The resulting controller and\nmodel are then integrated with a real-time overhead camera system for detecting\nstepping stone locations. For evaluation, we develop a benchmark set of\nstepping stone patterns, which are used to test performance in both simulation\nand the real world. Overall, we demonstrate that sim-to-real learning is\nextremely promising for enabling dynamic locomotion over stepping stones. We\nalso identify challenges remaining that motivate important future research\ndirections.",
    "descriptor": "\nComments: Video will be uploaded later\n",
    "authors": [
      "Helei Duan",
      "Ashish Malik",
      "Mohitvishnu S. Gadde",
      "Jeremy Dao",
      "Alan Fern",
      "Jonathan Hurst"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.01807"
  },
  {
    "id": "arXiv:2205.01809",
    "title": "Scientific Explanation and Natural Language: A Unified  Epistemological-Linguistic Perspective for Explainable AI",
    "abstract": "A fundamental research goal for Explainable AI (XAI) is to build models that\nare capable of reasoning through the generation of natural language\nexplanations. However, the methodologies to design and evaluate\nexplanation-based inference models are still poorly informed by theoretical\naccounts on the nature of explanation. As an attempt to provide an\nepistemologically grounded characterisation for XAI, this paper focuses on the\nscientific domain, aiming to bridge the gap between theory and practice on the\nnotion of a scientific explanation. Specifically, the paper combines a detailed\nsurvey of the modern accounts of scientific explanation in Philosophy of\nScience with a systematic analysis of corpora of natural language explanations,\nclarifying the nature and function of explanatory arguments from both a\ntop-down (categorical) and a bottom-up (corpus-based) perspective. Through a\nmixture of quantitative and qualitative methodologies, the presented study\nallows deriving the following main conclusions: (1) Explanations cannot be\nentirely characterised in terms of inductive or deductive arguments as their\nmain function is to perform unification; (2) An explanation must cite causes\nand mechanisms that are responsible for the occurrence of the event to be\nexplained; (3) While natural language explanations possess an intrinsic\ncausal-mechanistic nature, they are not limited to causes and mechanisms, also\naccounting for pragmatic elements such as definitions, properties and taxonomic\nrelations (4) Patterns of unification naturally emerge in corpora of\nexplanations even if not intentionally modelled; (5) Unification is realised\nthrough a process of abstraction, whose function is to provide the inference\nsubstrate for subsuming the event to be explained under recurring patterns and\nhigh-level regularities.",
    "descriptor": "",
    "authors": [
      "Marco Valentino",
      "Andr\u00e9 Freitas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01809"
  },
  {
    "id": "arXiv:2205.01811",
    "title": "Assessing Dataset Bias in Computer Vision",
    "abstract": "A biased dataset is a dataset that generally has attributes with an uneven\nclass distribution. These biases have the tendency to propagate to the models\nthat train on them, often leading to a poor performance in the minority class.\nIn this project, we will explore the extent to which various data augmentation\nmethods alleviate intrinsic biases within the dataset. We will apply several\naugmentation techniques on a sample of the UTKFace dataset, such as\nundersampling, geometric transformations, variational autoencoders (VAEs), and\ngenerative adversarial networks (GANs). We then trained a classifier for each\nof the augmented datasets and evaluated their performance on the native test\nset and on external facial recognition datasets. We have also compared their\nperformance to the state-of-the-art attribute classifier trained on the\nFairFace dataset. Through experimentation, we were able to find that training\nthe model on StarGAN-generated images led to the best overall performance. We\nalso found that training on geometrically transformed images lead to a similar\nperformance with a much quicker training time. Additionally, the best\nperforming models also exhibit a uniform performance across the classes within\neach attribute. This signifies that the model was also able to mitigate the\nbiases present in the baseline model that was trained on the original training\nset. Finally, we were able to show that our model has a better overall\nperformance and consistency on age and ethnicity classification on multiple\ndatasets when compared with the FairFace model. Our final model has an accuracy\non the UTKFace test set of 91.75%, 91.30%, and 87.20% for the gender, age, and\nethnicity attribute respectively, with a standard deviation of less than 0.1\nbetween the accuracies of the classes of each attribute.",
    "descriptor": "\nComments: 51 pages\n",
    "authors": [
      "Athiya Deviyani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01811"
  },
  {
    "id": "arXiv:2205.01813",
    "title": "Diverse Image Captioning with Grounded Style",
    "abstract": "Stylized image captioning as presented in prior work aims to generate\ncaptions that reflect characteristics beyond a factual description of the scene\ncomposition, such as sentiments. Such prior work relies on given sentiment\nidentifiers, which are used to express a certain global style in the caption,\ne.g. positive or negative, however without taking into account the stylistic\ncontent of the visual scene. To address this shortcoming, we first analyze the\nlimitations of current stylized captioning datasets and propose COCO\nattribute-based augmentations to obtain varied stylized captions from COCO\nannotations. Furthermore, we encode the stylized information in the latent\nspace of a Variational Autoencoder; specifically, we leverage extracted image\nattributes to explicitly structure its sequential latent space according to\ndifferent localized style characteristics. Our experiments on the Senticap and\nCOCO datasets show the ability of our approach to generate accurate captions\nwith diversity in styles that are grounded in the image.",
    "descriptor": "\nComments: In the 43rd DAGM German Conference on Pattern Recognition (GCPR) 2021\n",
    "authors": [
      "Franz Klein",
      "Shweta Mahajan",
      "Stefan Roth"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01813"
  },
  {
    "id": "arXiv:2205.01817",
    "title": "A Holistic Framework for Analyzing the COVID-19 Vaccine Debate",
    "abstract": "The Covid-19 pandemic has led to infodemic of low quality information leading\nto poor health decisions. Combating the outcomes of this infodemic is not only\na question of identifying false claims, but also reasoning about the decisions\nindividuals make. In this work we propose a holistic analysis framework\nconnecting stance and reason analysis, and fine-grained entity level moral\nsentiment analysis. We study how to model the dependencies between the\ndifferent level of analysis and incorporate human insights into the learning\nprocess. Experiments show that our framework provides reliable predictions even\nin the low-supervision settings.",
    "descriptor": "\nComments: Accepted to NAACL 2022\n",
    "authors": [
      "Maria Leonor Pacheco",
      "Tunazzina Islam",
      "Monal Mahajan",
      "Andrey Shor",
      "Ming Yin",
      "Lyle Ungar",
      "Dan Goldwasser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.01817"
  },
  {
    "id": "arXiv:2205.01818",
    "title": "i-Code: An Integrative and Composable Multimodal Learning Framework",
    "abstract": "Human intelligence is multimodal; we integrate visual, linguistic, and\nacoustic signals to maintain a holistic worldview. Most current pretraining\nmethods, however, are limited to one or two modalities. We present i-Code, a\nself-supervised pretraining framework where users may flexibly combine the\nmodalities of vision, speech, and language into unified and general-purpose\nvector representations. In this framework, data from each modality are first\ngiven to pretrained single-modality encoders. The encoder outputs are then\nintegrated with a multimodal fusion network, which uses novel attention\nmechanisms and other architectural innovations to effectively combine\ninformation from the different modalities. The entire system is pretrained\nend-to-end with new objectives including masked modality unit modeling and\ncross-modality contrastive learning. Unlike previous research using only video\nfor pretraining, the i-Code framework can dynamically process single, dual, and\ntriple-modality data during training and inference, flexibly projecting\ndifferent combinations of modalities into a single representation space.\nExperimental results demonstrate how i-Code can outperform state-of-the-art\ntechniques on five video understanding tasks and the GLUE NLP benchmark,\nimproving by as much as 11% and demonstrating the power of integrative\nmultimodal pretraining.",
    "descriptor": "",
    "authors": [
      "Ziyi Yang",
      "Yuwei Fang",
      "Chenguang Zhu",
      "Reid Pryzant",
      "Dongdong Chen",
      "Yu Shi",
      "Yichong Xu",
      "Yao Qian",
      "Mei Gao",
      "Yi-Ling Chen",
      "Liyang Lu",
      "Yujia Xie",
      "Robert Gmyr",
      "Noel Codella",
      "Naoyuki Kanda",
      "Bin Xiao",
      "Yuan Lu",
      "Takuya Yoshioka",
      "Michael Zeng",
      "Xuedong Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.01818"
  },
  {
    "id": "arXiv:2205.01821",
    "title": "Zero-shot Sonnet Generation with Discourse-level Planning and Aesthetics  Features",
    "abstract": "Poetry generation, and creative language generation in general, usually\nsuffers from the lack of large training data. In this paper, we present a novel\nframework to generate sonnets that does not require training on poems. We\ndesign a hierarchical framework which plans the poem sketch before decoding.\nSpecifically, a content planning module is trained on non-poetic texts to\nobtain discourse-level coherence; then a rhyme module generates rhyme words and\na polishing module introduces imagery and similes for aesthetics purposes.\nFinally, we design a constrained decoding algorithm to impose the\nmeter-and-rhyme constraint of the generated sonnets. Automatic and human\nevaluation show that our multi-stage approach without training on poem corpora\ngenerates more coherent, poetic, and creative sonnets than several strong\nbaselines.",
    "descriptor": "\nComments: To appear in NAACL 2022\n",
    "authors": [
      "Yufei Tian",
      "Nanyun Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01821"
  },
  {
    "id": "arXiv:2205.01823",
    "title": "Symmetry and Uncertainty-Aware Object SLAM for 6DoF Object Pose  Estimation",
    "abstract": "We propose a keypoint-based object-level SLAM framework that can provide\nglobally consistent 6DoF pose estimates for symmetric and asymmetric objects\nalike. To the best of our knowledge, our system is among the first to utilize\nthe camera pose information from SLAM to provide prior knowledge for tracking\nkeypoints on symmetric objects -- ensuring that new measurements are consistent\nwith the current 3D scene. Moreover, our semantic keypoint network is trained\nto predict the Gaussian covariance for the keypoints that captures the true\nerror of the prediction, and thus is not only useful as a weight for the\nresiduals in the system's optimization problems, but also as a means to detect\nharmful statistical outliers without choosing a manual threshold. Experiments\nshow that our method provides competitive performance to the state of the art\nin 6DoF object pose estimation, and at a real-time speed. Our code, pre-trained\nmodels, and keypoint labels are available https://github.com/rpng/suo_slam.",
    "descriptor": "\nComments: Accepted to CVPR2022\n",
    "authors": [
      "Nathaniel Merrill",
      "Yuliang Guo",
      "Xingxing Zuo",
      "Xinyu Huang",
      "Stefan Leutenegger",
      "Xi Peng",
      "Liu Ren",
      "Guoquan Huang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.01823"
  },
  {
    "id": "arXiv:2205.01825",
    "title": "AmbiPun: Generating Humorous Puns with Ambiguous Context",
    "abstract": "In this paper, we propose a simple yet effective way to generate pun\nsentences that does not require any training on existing puns. Our approach is\ninspired by humor theories that ambiguity comes from the context rather than\nthe pun word itself. Given a pair of definitions of a pun word, our model first\nproduces a list of related concepts through a reverse dictionary. We then\nutilize one-shot GPT3 to generate context words and then generate puns\nincorporating context words from both concepts. Human evaluation shows that our\nmethod successfully generates pun 52\\% of the time, outperforming well-crafted\nbaselines and the state-of-the-art models by a large margin.",
    "descriptor": "\nComments: To appear in NAACL 2022\n",
    "authors": [
      "Anirudh Mittal",
      "Yufei Tian",
      "Nanyun Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01825"
  },
  {
    "id": "arXiv:2205.01826",
    "title": "Unified Semantic Typing with Meaningful Label Inference",
    "abstract": "Semantic typing aims at classifying tokens or spans of interest in a textual\ncontext into semantic categories such as relations, entity types, and event\ntypes. The inferred labels of semantic categories meaningfully interpret how\nmachines understand components of text. In this paper, we present UniST, a\nunified framework for semantic typing that captures label semantics by\nprojecting both inputs and labels into a joint semantic embedding space. To\nformulate different lexical and relational semantic typing tasks as a unified\ntask, we incorporate task descriptions to be jointly encoded with the input,\nallowing UniST to be adapted to different tasks without introducing\ntask-specific model components. UniST optimizes a margin ranking loss such that\nthe semantic relatedness of the input and labels is reflected from their\nembedding similarity. Our experiments demonstrate that UniST achieves strong\nperformance across three semantic typing tasks: entity typing, relation\nclassification and event typing. Meanwhile, UniST effectively transfers\nsemantic knowledge of labels and substantially improves generalizability on\ninferring rarely seen and unseen types. In addition, multiple semantic typing\ntasks can be jointly trained within the unified framework, leading to a single\ncompact multi-tasking model that performs comparably to dedicated single-task\nmodels, while offering even better transferability.",
    "descriptor": "\nComments: NAACL 2022\n",
    "authors": [
      "James Y. Huang",
      "Bangzheng Li",
      "Jiashu Xu",
      "Muhao Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01826"
  },
  {
    "id": "arXiv:2205.01833",
    "title": "OpenAlex: A fully-open index of scholarly works, authors, venues,  institutions, and concepts",
    "abstract": "OpenAlex is a new, fully-open scientific knowledge graph (SKG), launched to\nreplace the discontinued Microsoft Academic Graph (MAG). It contains metadata\nfor 209M works (journal articles, books, etc); 2013M disambiguated authors;\n124k venues (places that host works, such as journals and online repositories);\n109k institutions; and 65k Wikidata concepts (linked to works via an automated\nhierarchical multi-tag classifier). The dataset is fully and freely available\nvia a web-based GUI, a full data dump, and high-volume REST API. The resource\nis under active development and future work will improve accuracy and coverage\nof citation information and author/institution parsing and deduplication.",
    "descriptor": "\nComments: Submitted to the 26th International Conference on Science, Technology and Innovation Indicators (STI 2022)\n",
    "authors": [
      "Jason Priem",
      "Heather Piwowar",
      "Richard Orr"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2205.01833"
  },
  {
    "id": "arXiv:2205.01836",
    "title": "Explainable Knowledge Graph Embedding: Inference Reconciliation for  Knowledge Inferences Supporting Robot Actions",
    "abstract": "Learned knowledge graph representations supporting robots contain a wealth of\ndomain knowledge that drives robot behavior. However, there does not exist an\ninference reconciliation framework that expresses how a knowledge graph\nrepresentation affects a robot's sequential decision making. We use a\npedagogical approach to explain the inferences of a learned, black-box\nknowledge graph representation, a knowledge graph embedding. Our interpretable\nmodel, uses a decision tree classifier to locally approximate the predictions\nof the black-box model, and provides natural language explanations\ninterpretable by non-experts. Results from our algorithmic evaluation affirm\nour model design choices, and the results of our user studies with non-experts\nsupport the need for the proposed inference reconciliation framework.\nCritically, results from our simulated robot evaluation indicate that our\nexplanations enable non-experts to correct erratic robot behaviors due to\nnonsensical beliefs within the black-box.",
    "descriptor": "\nComments: Submitted to IROS 2022\n",
    "authors": [
      "Angel Daruna",
      "Devleena Das",
      "Sonia Chernova"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.01836"
  },
  {
    "id": "arXiv:2205.01840",
    "title": "FedMix: Mixed Supervised Federated Learning for Medical Image  Segmentation",
    "abstract": "The purpose of federated learning is to enable multiple clients to jointly\ntrain a machine learning model without sharing data. However, the existing\nmethods for training an image segmentation model have been based on an\nunrealistic assumption that the training set for each local client is annotated\nin a similar fashion and thus follows the same image supervision level. To\nrelax this assumption, in this work, we propose a label-agnostic unified\nfederated learning framework, named FedMix, for medical image segmentation\nbased on mixed image labels. In FedMix, each client updates the federated model\nby integrating and effectively making use of all available labeled data ranging\nfrom strong pixel-level labels, weak bounding box labels, to weakest\nimage-level class labels. Based on these local models, we further propose an\nadaptive weight assignment procedure across local clients, where each client\nlearns an aggregation weight during the global model update. Compared to the\nexisting methods, FedMix not only breaks through the constraint of a single\nlevel of image supervision, but also can dynamically adjust the aggregation\nweight of each local client, achieving rich yet discriminative feature\nrepresentations. To evaluate its effectiveness, experiments have been carried\nout on two challenging medical image segmentation tasks, i.e., breast tumor\nsegmentation and skin lesion segmentation. The results validate that our\nproposed FedMix outperforms the state-of-the-art method by a large margin.",
    "descriptor": "",
    "authors": [
      "Jeffry Wicaksana",
      "Zengqiang Yan",
      "Dong Zhang",
      "Xijie Huang",
      "Huimin Wu",
      "Xin Yang",
      "Kwang-Ting Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01840"
  },
  {
    "id": "arXiv:2205.01841",
    "title": "Great Truths are Always Simple: A Rather Simple Knowledge Encoder for  Enhancing the Commonsense Reasoning Capacity of Pre-Trained Models",
    "abstract": "Commonsense reasoning in natural language is a desired ability of artificial\nintelligent systems. For solving complex commonsense reasoning tasks, a typical\nsolution is to enhance pre-trained language models~(PTMs) with a\nknowledge-aware graph neural network~(GNN) encoder that models a commonsense\nknowledge graph~(CSKG). Despite the effectiveness, these approaches are built\non heavy architectures, and can't clearly explain how external knowledge\nresources improve the reasoning capacity of PTMs. Considering this issue, we\nconduct a deep empirical analysis, and find that it is indeed relation features\nfrom CSKGs (but not node features) that mainly contribute to the performance\nimprovement of PTMs. Based on this finding, we design a simple MLP-based\nknowledge encoder that utilizes statistical relation paths as features.\nExtensive experiments conducted on five benchmarks demonstrate the\neffectiveness of our approach, which also largely reduces the parameters for\nencoding CSKGs. Our codes and data are publicly available at\nhttps://github.com/RUCAIBox/SAFE.",
    "descriptor": "\nComments: 12 pages, NAACL-Findings-2022\n",
    "authors": [
      "Jinhao Jiang",
      "Kun Zhou",
      "Wayne Xin Zhao",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01841"
  },
  {
    "id": "arXiv:2205.01842",
    "title": "An Empirical Study on Maintainable Method Size in Java",
    "abstract": "Code metrics have been widely used to estimate software maintenance effort.\nMetrics have generally been used to guide developer effort to reduce or avoid\nfuture maintenance burdens. Size is the simplest and most widely deployed\nmetric. The size metric is pervasive because size correlates with many other\ncommon metrics (e.g., McCabe complexity, readability, etc.). Given the ease of\ncomputing a method's size, and the ubiquity of these metrics in industrial\nsettings, it is surprising that no systematic study has been performed to\nprovide developers with meaningful method size guidelines with respect to\nfuture maintenance effort. In this paper we examine the evolution of around\n785K Java methods and show that developers should strive to keep their Java\nmethods under 24 lines in length. Additionally, we show that decomposing larger\nmethods to smaller methods also decreases overall maintenance efforts. Taken\ntogether, these findings provide empirical guidelines to help developers design\ntheir systems in a way that can reduce future maintenance.",
    "descriptor": "",
    "authors": [
      "Shaiful Alam Chowdhury",
      "Gias Uddin",
      "Reid Holmes"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.01842"
  },
  {
    "id": "arXiv:2205.01845",
    "title": "Seed-Guided Topic Discovery with Out-of-Vocabulary Seeds",
    "abstract": "Discovering latent topics from text corpora has been studied for decades.\nMany existing topic models adopt a fully unsupervised setting, and their\ndiscovered topics may not cater to users' particular interests due to their\ninability of leveraging user guidance. Although there exist seed-guided topic\ndiscovery approaches that leverage user-provided seeds to discover\ntopic-representative terms, they are less concerned with two factors: (1) the\nexistence of out-of-vocabulary seeds and (2) the power of pre-trained language\nmodels (PLMs). In this paper, we generalize the task of seed-guided topic\ndiscovery to allow out-of-vocabulary seeds. We propose a novel framework, named\nSeeTopic, wherein the general knowledge of PLMs and the local semantics learned\nfrom the input corpus can mutually benefit each other. Experiments on three\nreal datasets from different domains demonstrate the effectiveness of SeeTopic\nin terms of topic coherence, accuracy, and diversity.",
    "descriptor": "\nComments: 12 pages; Accepted to NAACL 2022\n",
    "authors": [
      "Yu Zhang",
      "Yu Meng",
      "Xuan Wang",
      "Sheng Wang",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01845"
  },
  {
    "id": "arXiv:2205.01848",
    "title": "Optimizing Mixture of Experts using Dynamic Recompilations",
    "abstract": "The Mixture of Experts architecture allows for outrageously large neural\nnetworks by scaling model parameter size independently from computational\ndemand (FLOPs). However, current DNN frameworks cannot effectively support the\ndynamic data flow in Mixture of Experts, and implementations on top of these\nframeworks need to use workarounds that introduce significant overheads. To\naddress the limitation of these frameworks, we present DynaMoE, a DNN library\nthat uses dynamic recompilations to optimize and adapt the use of computational\nresources to the dynamic needs of Mixture of Experts models. Our evaluation\nshows that DynaMoE achieves a 1.8x speedup and supports 2.3x larger model sizes\nwhen compared to existing MoE systems, even when not using recompilations. We\nthen present further optimizations enabled by dynamic recompilations that yield\nan additional 1.7x speedup while simultaneously reducing memory pressure and\nimproving model quality.",
    "descriptor": "\nComments: 13 pages, 15 figures\n",
    "authors": [
      "Ferdinand Kossmann",
      "Zhihao Jia",
      "Alex Aiken"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.01848"
  },
  {
    "id": "arXiv:2205.01850",
    "title": "Visual Commonsense in Pretrained Unimodal and Multimodal Models",
    "abstract": "Our commonsense knowledge about objects includes their typical visual\nattributes; we know that bananas are typically yellow or green, and not purple.\nText and image corpora, being subject to reporting bias, represent this\nworld-knowledge to varying degrees of faithfulness. In this paper, we\ninvestigate to what degree unimodal (language-only) and multimodal (image and\nlanguage) models capture a broad range of visually salient attributes. To that\nend, we create the Visual Commonsense Tests (ViComTe) dataset covering 5\nproperty types (color, shape, material, size, and visual co-occurrence) for\nover 5000 subjects. We validate this dataset by showing that our grounded color\ndata correlates much better than ungrounded text-only data with crowdsourced\ncolor judgments provided by Paik et al. (2021). We then use our dataset to\nevaluate pretrained unimodal models and multimodal models. Our results indicate\nthat multimodal models better reconstruct attribute distributions, but are\nstill subject to reporting bias. Moreover, increasing model size does not\nenhance performance, suggesting that the key to visual commonsense lies in the\ndata.",
    "descriptor": "\nComments: To appear in NAACL 2022\n",
    "authors": [
      "Chenyu Zhang",
      "Benjamin Van Durme",
      "Zhuowan Li",
      "Elias Stengel-Eskin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01850"
  },
  {
    "id": "arXiv:2205.01851",
    "title": "Toward Data-Driven Digital Therapeutics Analytics: Literature Review and  Research Directions",
    "abstract": "With the advent of Digital Therapeutics (DTx), the development of software as\na medical device (SaMD) for mobile and wearable devices has gained significant\nattention in recent years. Existing DTx evaluations, such as randomized\nclinical trials, mostly focus on verifying the effectiveness of DTx products.\nTo acquire a deeper understanding of DTx engagement and behavioral adherence,\nbeyond efficacy, a large amount of contextual and interaction data from mobile\nand wearable devices during field deployment would be required for analysis. In\nthis work, the overall flow of the data-driven DTx analytics is reviewed to\nhelp researchers and practitioners to explore DTx datasets, to investigate\ncontextual patterns associated with DTx usage, and to establish the (causal)\nrelationship of DTx engagement and behavioral adherence. This review of the key\ncomponents of data-driven analytics provides novel research directions in the\nanalysis of mobile sensor and interaction datasets, which helps to iteratively\nimprove the receptivity of existing DTx.",
    "descriptor": "",
    "authors": [
      "Uichin Lee",
      "Gyuwon Jung",
      "Eunyeol Ma",
      "Jin San Kim",
      "Heepyung Kim",
      "Hyunsoo Lee",
      "Jumabek Alikhanov",
      "Youngtae Noh",
      "Heeyoung Kim"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.01851"
  },
  {
    "id": "arXiv:2205.01852",
    "title": "Stochastic Image Transmission with CoAP for Extreme Environments",
    "abstract": "Communication in extreme environments is an important research topic for\nvarious use cases including environmental monitoring. A typical example is\nunderwater acoustic communication for 6G mobile networks. The major challenges\nin such environments are extremely high-latency and high-error rate. They make\nreal-time image transmission difficult using existing communication protocols.\nThis is partly because frequent retransmission in noisy networks increases\nlatency and leads to serious deterioration of real-timeness. To address this\nproblem, this paper proposes a stochastic image transmission with Constrained\nApplication Protocol (CoAP) for extreme environments. The goal of the proposed\nidea is to achieve approximate real-time image transmission without\nretransmission using CoAP over UDP. To this end, an image is divided into\nblocks, and value is assigned for each block based on the requirement. By the\nstochastic transmission of blocks, the reception probability is guaranteed\nwithout retransmission even when packets are lost in networks. We implemented\nthe proposed scheme using Raspberry Pi 4 to demonstrate the feasibility. The\nperformance of the proposed image transmission was confirmed from the\nexperimental results.",
    "descriptor": "",
    "authors": [
      "Erina Takeshita",
      "Asahi Sakaguchi",
      "Daisuke Hisano",
      "Yoshiaki Inoue",
      "Kazuki Maruta",
      "Yuko Hara-Azumi",
      "Yu Nakayama"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.01852"
  },
  {
    "id": "arXiv:2205.01853",
    "title": "SMLT: A Serverless Framework for Scalable and Adaptive Machine Learning  Design and Training",
    "abstract": "In today's production machine learning (ML) systems, models are continuously\ntrained, improved, and deployed. ML design and training are becoming a\ncontinuous workflow of various tasks that have dynamic resource demands.\nServerless computing is an emerging cloud paradigm that provides transparent\nresource management and scaling for users and has the potential to\nrevolutionize the routine of ML design and training. However, hosting modern ML\nworkflows on existing serverless platforms has non-trivial challenges due to\ntheir intrinsic design limitations such as stateless nature, limited\ncommunication support across function instances, and limited function execution\nduration. These limitations result in a lack of an overarching view and\nadaptation mechanism for training dynamics and an amplification of existing\nproblems in ML workflows.\nTo address the above challenges, we propose SMLT, an automated, scalable, and\nadaptive serverless framework to enable efficient and user-centric ML design\nand training. SMLT employs an automated and adaptive scheduling mechanism to\ndynamically optimize the deployment and resource scaling for ML tasks during\ntraining. SMLT further enables user-centric ML workflow execution by supporting\nuser-specified training deadlines and budget limits. In addition, by providing\nan end-to-end design, SMLT solves the intrinsic problems in serverless\nplatforms such as the communication overhead, limited function execution\nduration, need for repeated initialization, and also provides explicit fault\ntolerance for ML training. SMLT is open-sourced and compatible with all major\nML frameworks. Our experimental evaluation with large, sophisticated modern ML\nmodels demonstrate that SMLT outperforms the state-of-the-art VM based systems\nand existing serverless ML training frameworks in both training speed (up to\n8X) and monetary cost (up to 3X)",
    "descriptor": "",
    "authors": [
      "Ahsan Ali",
      "Syed Zawad",
      "Paarijaat Aditya",
      "Istemi Ekin Akkus",
      "Ruichuan Chen",
      "Feng Yan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01853"
  },
  {
    "id": "arXiv:2205.01859",
    "title": "DEAR: A Novel Deep Learning-based Approach for Automated Program Repair",
    "abstract": "The existing deep learning (DL)-based automated program repair (APR) models\nare limited in fixing general software defects. % We present {\\tool}, a\nDL-based approach that supports fixing for the general bugs that require\ndependent changes at once to one or multiple consecutive statements in one or\nmultiple hunks of code. % We first design a novel fault localization (FL)\ntechnique for multi-hunk, multi-statement fixes that combines traditional\nspectrum-based (SB) FL with deep learning and data-flow analysis. It takes the\nbuggy statements returned by the SBFL model, detects the buggy hunks to be\nfixed at once, and expands a buggy statement $s$ in a hunk to include other\nsuspicious statements around $s$. We design a two-tier, tree-based LSTM model\nthat incorporates cycle training and uses a divide-and-conquer strategy to\nlearn proper code transformations for fixing multiple statements in the\nsuitable fixing context consisting of surrounding subtrees. We conducted\nseveral experiments to evaluate {\\tool} on three datasets: Defects4J (395\nbugs), BigFix (+26k bugs), and CPatMiner (+44k bugs). On Defects4J dataset,\n{\\tool} outperforms the baselines from 42\\%--683\\% in terms of the number of\nauto-fixed bugs with only the top-1 patches. On BigFix dataset, it fixes\n31--145 more bugs than existing DL-based APR models with the top-1 patches. On\nCPatMiner dataset, among 667 fixed bugs, there are 169 (25.3\\%)\nmulti-hunk/multi-statement bugs. {\\tool} fixes 71 and 164 more bugs, including\n52 and 61 more multi-hunk/multi-statement bugs, than the state-of-the-art,\nDL-based APR models.",
    "descriptor": "",
    "authors": [
      "Yi Li",
      "Shaohua Wang",
      "Tien N. Nguyen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.01859"
  },
  {
    "id": "arXiv:2205.01861",
    "title": "Convergence analysis of the Newton-Schur method for the symmetric  elliptic eigenvalue problem",
    "abstract": "In this paper, we consider the Newton-Schur method in Hilbert space and\nobtain quadratic convergence. For the symmetric elliptic eigenvalue problem\ndiscretized by the standard finite element method and non-overlapping domain\ndecomposition method, we use the Steklov-Poincar\\'e operator to reduce the\neigenvalue problem on the domain $\\Omega$ into the nonlinear eigenvalue\nsubproblem on $\\Gamma$, which is the union of subdomain boundaries. We prove\nthat the convergence rate for the Newton-Schur method is $\\epsilon_{N}\\leq\nCH^{2}(1+\\ln(H/h))^{2}\\epsilon^{2}$, where the constant $C$ is independent of\nthe fine mesh size $h$ and coarse mesh size $H$, and $\\epsilon_{N}$ and\n$\\epsilon$ are errors after and before one iteration step respectively.\nNumerical experiments confirm our theoretical analysis.",
    "descriptor": "",
    "authors": [
      "Nian Shao",
      "Wenbin Chen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.01861"
  },
  {
    "id": "arXiv:2205.01863",
    "title": "Provably Confidential Language Modelling",
    "abstract": "Large language models are shown to memorize privacy information such as\nsocial security numbers in training data. Given the sheer scale of the training\ncorpus, it is challenging to screen and filter these privacy data, either\nmanually or automatically. In this paper, we propose Confidentially Redacted\nTraining (CRT), a method to train language generation models while protecting\nthe confidential segments. We borrow ideas from differential privacy (which\nsolves a related but distinct problem) and show that our method is able to\nprovably prevent unintended memorization by randomizing parts of the training\nprocess. Moreover, we show that redaction with an approximately correct\nscreening policy amplifies the confidentiality guarantee. We implement the\nmethod for both LSTM and GPT language models. Our experimental results show\nthat the models trained by CRT obtain almost the same perplexity while\npreserving strong confidentiality.",
    "descriptor": "\nComments: NAACL 2022\n",
    "authors": [
      "Xuandong Zhao",
      "Lei Li",
      "Yu-Xiang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01863"
  },
  {
    "id": "arXiv:2205.01868",
    "title": "Hazard Exposure Heterophily: A Latent Characteristic in Socio-Spatial  Networks Influencing Community Resilience",
    "abstract": "We present a latent characteristic in socio-spatial networks, hazard-exposure\nheterophily, to capture the extent to which populations with similar hazard\nexposure could assist each other through social ties. Heterophily is the\ntendency of unlike individuals to form social ties. Conversely, populations in\nspatial areas with significant hazard exposure similarity, homophily, would\nlack sufficient resourcefulness to aid each other to lessen the impact of\nhazards. In the context of the Houston metropolitan area, we use Meta's Social\nConnectedness data to construct a socio-spatial network in juxtaposition with\nflood exposure data from National Flood Hazard Layer to analyze flood hazard\nexposure of spatial areas. The results reveal the extent and spatial variation\nof hazard-exposure heterophily in the study area. Notably, the results show\nthat lower-income areas have lower hazard-exposure heterophily possibly caused\nby income segregation and the tendency of affordable housing development to be\nlocated in flood zones. Less resourceful social ties due to high\nhazard-exposure homophily may inhibit low-income areas from better coping with\nhazard impacts and could contribute to their slower recovery. Overall, the\nresults underscore the significance of characterizing hazard-exposure\nheterophily in socio-spatial networks to reveal community vulnerability and\nresilience to hazards.",
    "descriptor": "\nComments: 14 pages, 6 figures\n",
    "authors": [
      "Chia-Fu Liu",
      "Ali Mostafavi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.01868"
  },
  {
    "id": "arXiv:2205.01871",
    "title": "UCL-Dehaze: Towards Real-world Image Dehazing via Unsupervised  Contrastive Learning",
    "abstract": "While the wisdom of training an image dehazing model on synthetic hazy data\ncan alleviate the difficulty of collecting real-world hazy/clean image pairs,\nit brings the well-known domain shift problem. From a different yet new\nperspective, this paper explores contrastive learning with an adversarial\ntraining effort to leverage unpaired real-world hazy and clean images, thus\nbridging the gap between synthetic and real-world haze is avoided. We propose\nan effective unsupervised contrastive learning paradigm for image dehazing,\ndubbed UCL-Dehaze. Unpaired real-world clean and hazy images are easily\ncaptured, and will serve as the important positive and negative samples\nrespectively when training our UCL-Dehaze network. To train the network more\neffectively, we formulate a new self-contrastive perceptual loss function,\nwhich encourages the restored images to approach the positive samples and keep\naway from the negative samples in the embedding space. Besides the overall\nnetwork architecture of UCL-Dehaze, adversarial training is utilized to align\nthe distributions between the positive samples and the dehazed images. Compared\nwith recent image dehazing works, UCL-Dehaze does not require paired data\nduring training and utilizes unpaired positive/negative data to better enhance\nthe dehazing performance. We conduct comprehensive experiments to evaluate our\nUCL-Dehaze and demonstrate its superiority over the state-of-the-arts, even\nonly 1,800 unpaired real-world images are used to train our network. Source\ncode has been available at https://github.com/yz-wang/UCL-Dehaze.",
    "descriptor": "\nComments: 14 pages, 9 figures, 9 tables\n",
    "authors": [
      "Yongzhen Wang",
      "Xuefeng Yan",
      "Fu Lee Wang",
      "Haoran Xie",
      "Wenhan Yang",
      "Mingqiang Wei",
      "Jing Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01871"
  },
  {
    "id": "arXiv:2205.01873",
    "title": "Wasserstein Adversarial Learning based Temporal Knowledge Graph  Embedding",
    "abstract": "Research on knowledge graph embedding (KGE) has emerged as an active field in\nwhich most existing KGE approaches mainly focus on static structural data and\nignore the influence of temporal variation involved in time-aware triples. In\norder to deal with this issue, several temporal knowledge graph embedding\n(TKGE) approaches have been proposed to integrate temporal and structural\ninformation in recent years. However, these methods only employ a uniformly\nrandom sampling to construct negative facts. As a consequence, the corrupted\nsamples are often too simplistic for training an effective model. In this\npaper, we propose a new temporal knowledge graph embedding framework by\nintroducing adversarial learning to further refine the performance of\ntraditional TKGE models. In our framework, a generator is utilized to construct\nhigh-quality plausible quadruples and a discriminator learns to obtain the\nembeddings of entities and relations based on both positive and negative\nsamples. Meanwhile, we also apply a Gumbel-Softmax relaxation and the\nWasserstein distance to prevent vanishing gradient problems on discrete data;\nan inherent flaw in traditional generative adversarial networks. Through\ncomprehensive experimentation on temporal datasets, the results indicate that\nour proposed framework can attain significant improvements based on benchmark\nmodels and also demonstrate the effectiveness and applicability of our\nframework.",
    "descriptor": "",
    "authors": [
      "Yuanfei Dai",
      "Wenzhong Guo",
      "Carsten Eickhoff"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.01873"
  },
  {
    "id": "arXiv:2205.01876",
    "title": "fairlib: A Unified Framework for Assessing and Improving Classification  Fairness",
    "abstract": "This paper presents fairlib, an open-source framework for assessing and\nimproving classification fairness. It provides a systematic framework for\nquickly reproducing existing baseline models, developing new methods,\nevaluating models with different metrics, and visualizing their results. Its\nmodularity and extensibility enable the framework to be used for diverse types\nof inputs, including natural language, images, and audio. In detail, we\nimplement 14 debiasing methods, including pre-processing, at-training-time, and\npost-processing approaches. The built-in metrics cover the most commonly used\nfairness criterion and can be further generalized and customized for fairness\nevaluation.",
    "descriptor": "\nComments: pre-print, 9 pages\n",
    "authors": [
      "Xudong Han",
      "Aili Shen",
      "Yitong Li",
      "Lea Frermann",
      "Timothy Baldwin",
      "Trevor Cohn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.01876"
  },
  {
    "id": "arXiv:2205.01878",
    "title": "Exploring Entity Interactions for Few-Shot Relation Learning (Student  Abstract)",
    "abstract": "Few-shot relation learning refers to infer facts for relations with a limited\nnumber of observed triples. Existing metric-learning methods for this problem\nmostly neglect entity interactions within and between triples. In this paper,\nwe explore this kind of fine-grained semantic meanings and propose our model\nTransAM. Specifically, we serialize reference entities and query entities into\nsequence and apply transformer structure with local-global attention to capture\nboth intra- and inter-triple entity interactions. Experiments on two public\nbenchmark datasets NELL-One and Wiki-One with 1-shot setting prove the\neffectiveness of TransAM.",
    "descriptor": "\nComments: Accepted as a Finalist Paper of Student Abstract Session of AAAI 2022\n",
    "authors": [
      "YI Liang",
      "Shuai Zhao",
      "Bo Cheng",
      "Yuwei Yin",
      "Hao Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01878"
  },
  {
    "id": "arXiv:2205.01879",
    "title": "A Nonlinear Car-following Controller Design Inspired By Human-driving  Behaviors to Increase Comfort and Enhance Safety",
    "abstract": "This paper investigates the car-following problem and proposes a nonlinear\ncontroller that considers driving comfort, safety concerns, steady-state\nresponse and transient response. This controller is designed based on the\ndemands of lower cost, faster response, increased comfort, enhanced safety and\nelevated extendability from the automotive industry. Design insights and\nintuitions are provided in detail. Also, theoretical analysis are performed on\nplant stability, string stability and tracking performance of the closed-loop\nsystem. Conditions and guidelines are provided on the selection of control\nparameters. Comprehensive simulations are conducted to demonstrate the efficacy\nof the proposed controller in different driving scenarios.",
    "descriptor": "\nComments: 13 pages, 10 figures, submitted to IEEE Transactions on Vehicular Technology\n",
    "authors": [
      "Wubing B. Qin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.01879"
  },
  {
    "id": "arXiv:2205.01883",
    "title": "All You May Need for VQA are Image Captions",
    "abstract": "Visual Question Answering (VQA) has benefited from increasingly sophisticated\nmodels, but has not enjoyed the same level of engagement in terms of data\ncreation. In this paper, we propose a method that automatically derives VQA\nexamples at volume, by leveraging the abundance of existing image-caption\nannotations combined with neural models for textual question generation. We\nshow that the resulting data is of high-quality. VQA models trained on our data\nimprove state-of-the-art zero-shot accuracy by double digits and achieve a\nlevel of robustness that lacks in the same model trained on human-annotated VQA\ndata.",
    "descriptor": "\nComments: 2022 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL 2022)\n",
    "authors": [
      "Soravit Changpinyo",
      "Doron Kukliansky",
      "Idan Szpektor",
      "Xi Chen",
      "Nan Ding",
      "Radu Soricut"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01883"
  },
  {
    "id": "arXiv:2205.01884",
    "title": "A deep domain decomposition method based on Fourier features",
    "abstract": "In this paper we present a Fourier feature based deep domain decomposition\nmethod (F-D3M) for partial differential equations (PDEs). Currently, deep\nneural network based methods are actively developed for solving PDEs, but their\nefficiency can degenerate for problems with high frequency modes. In this new\nF-D3M strategy, overlapping domain decomposition is conducted for the spatial\ndomain, such that high frequency modes can be reduced to relatively low\nfrequency ones. In each local subdomain, multi Fourier feature networks\n(MFFNets) are constructed, where efficient boundary and interface treatments\nare applied for the corresponding loss functions. We present a general\nmathematical framework of F-D3M, validate its accuracy and demonstrate its\nefficiency with numerical experiments.",
    "descriptor": "",
    "authors": [
      "Sen Li",
      "Yingzhi Xia",
      "Yu Liu",
      "Qifeng Liao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.01884"
  },
  {
    "id": "arXiv:2205.01886",
    "title": "P$^3$ Ranker: Mitigating the Gaps between Pre-training and Ranking  Fine-tuning with Prompt-based Learning and Pre-finetuning",
    "abstract": "Compared to other language tasks, applying pre-trained language models (PLMs)\nfor search ranking often requires more nuances and training signals. In this\npaper, we identify and study the two mismatches between pre-training and\nranking fine-tuning: the training schema gap regarding the differences in\ntraining objectives and model architectures, and the task knowledge gap\nconsidering the discrepancy between the knowledge needed in ranking and that\nlearned during pre-training. To mitigate these gaps, we propose Pre-trained,\nPrompt-learned and Pre-finetuned Neural Ranker (P$^3$ Ranker). P$^3$ Ranker\nleverages prompt-based learning to convert the ranking task into a pre-training\nlike schema and uses pre-finetuning to initialize the model on intermediate\nsupervised tasks. Experiments on MS MARCO and Robust04 show the superior\nperformances of P$^3$ Ranker in few-shot ranking. Analyses reveal that P$^3$\nRanker is able to better accustom to the ranking task through prompt-based\nlearning and retrieve necessary ranking-oriented knowledge gleaned in\npre-finetuning, resulting in data-efficient PLM adaptation. Our code is\navailable at \\url{https://github.com/NEUIR/P3Ranker}.",
    "descriptor": "\nComments: Accepted by SIGIR 2022\n",
    "authors": [
      "Xiaomeng Hu",
      "Shi Yu",
      "Chenyan Xiong",
      "Zhenghao Liu",
      "Zhiyuan Liu",
      "Ge Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01886"
  },
  {
    "id": "arXiv:2205.01887",
    "title": "Uncertainty estimation of pedestrian future trajectory using Bayesian  approximation",
    "abstract": "Past research on pedestrian trajectory forecasting mainly focused on\ndeterministic predictions which provide only point estimates of future states.\nThese future estimates can help an autonomous vehicle plan its trajectory and\navoid collision. However, under dynamic traffic scenarios, planning based on\ndeterministic predictions is not trustworthy. Rather, estimating the\nuncertainty associated with the predicted states with a certain level of\nconfidence can lead to robust path planning. Hence, the authors propose to\nquantify this uncertainty during forecasting using stochastic approximation\nwhich deterministic approaches fail to capture. The current method is simple\nand applies Bayesian approximation during inference to standard neural network\narchitectures for estimating uncertainty. The authors compared the predictions\nbetween the probabilistic neural network (NN) models with the standard\ndeterministic models. The results indicate that the mean predicted path of\nprobabilistic models was closer to the ground truth when compared with the\ndeterministic prediction. Further, the effect of stochastic dropout of weights\nand long-term prediction on future state uncertainty has been studied. It was\nfound that the probabilistic models produced better performance metrics like\naverage displacement error (ADE) and final displacement error (FDE). Finally,\nthe study has been extended to multiple datasets providing a comprehensive\ncomparison for each model.",
    "descriptor": "\nComments: 12 pages, 17 figures, 1 table\n",
    "authors": [
      "Anshul Nayak",
      "Azim Eskandarian",
      "Zachary Doerzaph"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01887"
  },
  {
    "id": "arXiv:2205.01889",
    "title": "Improving Multi-Document Summarization through Referenced Flexible  Extraction with Credit-Awareness",
    "abstract": "A notable challenge in Multi-Document Summarization (MDS) is the\nextremely-long length of the input. In this paper, we present an\nextract-then-abstract Transformer framework to overcome the problem.\nSpecifically, we leverage pre-trained language models to construct a\nhierarchical extractor for salient sentence selection across documents and an\nabstractor for rewriting the selected contents as summaries. However, learning\nsuch a framework is challenging since the optimal contents for the abstractor\nare generally unknown. Previous works typically create pseudo extraction oracle\nto enable the supervised learning for both the extractor and the abstractor.\nNevertheless, we argue that the performance of such methods could be restricted\ndue to the insufficient information for prediction and inconsistent objectives\nbetween training and testing. To this end, we propose a loss weighting\nmechanism that makes the model aware of the unequal importance for the\nsentences not in the pseudo extraction oracle, and leverage the fine-tuned\nabstractor to generate summary references as auxiliary signals for learning the\nextractor. Moreover, we propose a reinforcement learning method that can\nefficiently apply to the extractor for harmonizing the optimization between\ntraining and testing. Experiment results show that our framework substantially\noutperforms strong baselines with comparable model sizes and achieves the best\nresults on the Multi-News, Multi-XScience, and WikiCatSum corpora.",
    "descriptor": "",
    "authors": [
      "Yun-Zhu Song",
      "Yi-Syuan Chen",
      "Hong-Han Shuai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01889"
  },
  {
    "id": "arXiv:2205.01892",
    "title": "Unsupervised Domain Adaptation Learning for Hierarchical Infant Pose  Recognition with Synthetic Data",
    "abstract": "The Alberta Infant Motor Scale (AIMS) is a well-known assessment scheme that\nevaluates the gross motor development of infants by recording the number of\nspecific poses achieved. With the aid of the image-based pose recognition\nmodel, the AIMS evaluation procedure can be shortened and automated, providing\nearly diagnosis or indicator of potential developmental disorder. Due to\nlimited public infant-related datasets, many works use the SMIL-based method to\ngenerate synthetic infant images for training. However, this domain mismatch\nbetween real and synthetic training samples often leads to performance\ndegradation during inference. In this paper, we present a CNN-based model which\ntakes any infant image as input and predicts the coarse and fine-level pose\nlabels. The model consists of an image branch and a pose branch, which\nrespectively generates the coarse-level logits facilitated by the unsupervised\ndomain adaptation and the 3D keypoints using the HRNet with SMPLify\noptimization. Then the outputs of these branches will be sent into the\nhierarchical pose recognition module to estimate the fine-level pose labels. We\nalso collect and label a new AIMS dataset, which contains 750 real and 4000\nsynthetic infants images with AIMS pose labels. Our experimental results show\nthat the proposed method can significantly align the distribution of synthetic\nand real-world datasets, thus achieving accurate performance on fine-grained\ninfant pose recognition.",
    "descriptor": "\nComments: Accepted as a conference paper at ICME 2022\n",
    "authors": [
      "Cheng-Yen Yang",
      "Zhongyu Jiang",
      "Shih-Yu Gu",
      "Jenq-Neng Hwang",
      "Jang-Hee Yoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01892"
  },
  {
    "id": "arXiv:2205.01893",
    "title": "Crystal Twins: Self-supervised Learning for Crystalline Material  Property Prediction",
    "abstract": "Machine learning (ML) models have been widely successful in the prediction of\nmaterial properties. However, large labeled datasets required for training\naccurate ML models are elusive and computationally expensive to generate.\nRecent advances in Self-Supervised Learning (SSL) frameworks capable of\ntraining ML models on unlabeled data have mitigated this problem and\ndemonstrated superior performance in computer vision and natural language\nprocessing tasks. Drawing inspiration from the developments in SSL, we\nintroduce Crystal Twins (CT): an SSL method for crystalline materials property\nprediction. Using a large unlabeled dataset, we pre-train a Graph Neural\nNetwork (GNN) by applying the redundancy reduction principle to the graph\nlatent embeddings of augmented instances obtained from the same crystalline\nsystem. By sharing the pre-trained weights when fine-tuning the GNN for\nregression tasks, we significantly improve the performance for 7 challenging\nmaterial property prediction benchmarks",
    "descriptor": "\nComments: Preprint - Under review 20 pages, 3 figures\n",
    "authors": [
      "Rishikesh Magar",
      "Yuyang Wang",
      "Amir Barati Farimani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)"
    ],
    "url": "https://arxiv.org/abs/2205.01893"
  },
  {
    "id": "arXiv:2205.01896",
    "title": "An Online Generalized Multiscale finite element method for heat and mass  transfer problem with artificial ground freezing",
    "abstract": "In this paper, we present an Online Generalized Multiscale Finite Element\nMethod(Online GMsFEM) for heat and mass transfer problem in heterogeneous media\nwith artificial ground freezing pipes. The mathematical model of the process is\nbased on the classical Stefan model, which describes heat transfer with a phase\ntransition and takes into account filtration in a porous medium. The model is\ndescribed by a system of equations for temperature and pressure. For fine grid\nsolution, we use a finite element method using the fictitious domain method. To\nderive a solution on the coarse grid, we use a model reduction procedure based\non Online GMsFEM. Online version of GMsFEM allows to us to take less number of\noffline multiscale basis functions. In our approach, we use decoupled offline\nbasis functions constructed with snapshot space and based on spectral problems.\nThis is the standard approach of basis construction. To take into account\nartificial ground freezing pipes, we compute an additional basis functions on\nthe offline stage. For the accurate approximation of phase change we add online\nmultiscale basis functions. We construct online basis that minimizes error by\nvalues of local residuals. Online procedure is significantly improves the\naccuracy of standard GMsFEM. We present numerical results in two-dimensional\ndomain with layered heterogeneity. To investigate accuracy of the method, we\npresent results with different number of offline and online basis functions.\nThe presented results show that Online GMsFEM can produce solution with high\naccuracy and requires small computational resources.",
    "descriptor": "",
    "authors": [
      "Denis Spiridonov",
      "Sergei Stepanov",
      "Vasil`ev Vasiliy"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.01896"
  },
  {
    "id": "arXiv:2205.01898",
    "title": "Go Back in Time: Generating Flashbacks in Stories with Event Temporal  Prompts",
    "abstract": "Stories or narratives are comprised of a sequence of events. To compose\ninteresting stories, professional writers often leverage a creative writing\ntechnique called flashback that inserts past events into current storylines as\nwe commonly observe in novels and plays. However, it is challenging for\nmachines to generate flashback as it requires a solid understanding of event\ntemporal order (e.g. \"feeling hungry\" before \"eat,\" not vice versa), and the\ncreativity to arrange storylines so that earlier events do not always appear\nfirst in narrative order. Two major issues in existing systems that exacerbate\nthe challenges: 1) temporal bias in pertaining and story datasets that leads to\nmonotonic event temporal orders; 2) lack of explicit guidance that helps\nmachines decide where to insert flashbacks. We propose to address these issues\nusing structured storylines to encode events and their pair-wise temporal\nrelations (before, after and vague) as temporal prompts that guide how stories\nshould unfold temporally. We leverage a Plan-and-Write framework enhanced by\nreinforcement learning to generate storylines and stories end-to-end.\nEvaluation results show that the proposed method can generate more interesting\nstories with flashbacks while maintaining textual diversity, fluency, and\ntemporal coherence.",
    "descriptor": "\nComments: Accepted by the main conference proceedings of NAACL 2022\n",
    "authors": [
      "Rujun Han",
      "Hong Chen",
      "Yufei Tian",
      "Nanyun Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01898"
  },
  {
    "id": "arXiv:2205.01901",
    "title": "Spatial-Temporal Meta-path Guided Explainable Crime Prediction",
    "abstract": "Exposure to crime and violence can harm individuals' quality of life and the\neconomic growth of communities. In light of the rapid development in machine\nlearning, there is a rise in the need to explore automated solutions to prevent\ncrimes. With the increasing availability of both fine-grained urban and public\nservice data, there is a recent surge in fusing such cross-domain information\nto facilitate crime prediction. By capturing the information about social\nstructure, environment, and crime trends, existing machine learning predictive\nmodels have explored the dynamic crime patterns from different views. However,\nthese approaches mostly convert such multi-source knowledge into implicit and\nlatent representations (e.g., learned embeddings of districts), making it still\na challenge to investigate the impacts of explicit factors for the occurrences\nof crimes behind the scenes. In this paper, we present a Spatial-Temporal\nMetapath guided Explainable Crime prediction (STMEC) framework to capture\ndynamic patterns of crime behaviours and explicitly characterize how the\nenvironmental and social factors mutually interact to produce the forecasts.\nExtensive experiments show the superiority of STMEC compared with other\nadvanced spatiotemporal models, especially in predicting felonies (e.g.,\nrobberies and assaults with dangerous weapons).",
    "descriptor": "\nComments: submitted to Information Fusion\n",
    "authors": [
      "Yuting Sun",
      "Tong Chen",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.01901"
  },
  {
    "id": "arXiv:2205.01902",
    "title": "Pik-Fix: Restoring and Colorizing Old Photo",
    "abstract": "Restoring and inpainting the visual memories that are present, but often\nimpaired, in old photos remains an intriguing but unsolved research topic.\nDecades-old photos often suffer from severe and commingled degradation such as\ncracks, defocus, and color-fading, which are difficult to treat individually\nand harder to repair when they interact. Deep learning presents a plausible\navenue, but the lack of large-scale datasets of old photos makes addressing\nthis restoration task very challenging. Here we present a novel reference-based\nend-to-end learning framework that is able to both repair and colorize old and\ndegraded pictures. Our proposed framework consists of three modules: a\nrestoration sub-network that conducts restoration from degradations, a\nsimilarity sub-network that performs color histogram matching and color\ntransfer, and a colorization subnet that learns to predict the chroma elements\nof images that have been conditioned on chromatic reference signals. The\noverall system makes uses of color histogram priors from reference images,\nwhich greatly reduces the need for large-scale training data. We have also\ncreated a first-of-a-kind public dataset of real old photos that are paired\nwith ground truth \"pristine\" photos that have been that have been manually\nrestored by PhotoShop experts. We conducted extensive experiments on this\ndataset and synthetic datasets, and found that our method significantly\noutperforms previous state-of-the-art models using both qualitative comparisons\nand quantitative measurements.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2202.02606\n",
    "authors": [
      "Runsheng Xu",
      "Zhengzhong Tu",
      "Yuanqi Du",
      "Xiaoyu Dong",
      "Jinlong Li",
      "Zibo Meng",
      "Jiaqi Ma",
      "Alan Bovik",
      "Hongkai Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01902"
  },
  {
    "id": "arXiv:2205.01903",
    "title": "Self-Taught Metric Learning without Labels",
    "abstract": "We present a novel self-taught framework for unsupervised metric learning,\nwhich alternates between predicting class-equivalence relations between data\nthrough a moving average of an embedding model and learning the model with the\npredicted relations as pseudo labels. At the heart of our framework lies an\nalgorithm that investigates contexts of data on the embedding space to predict\ntheir class-equivalence relations as pseudo labels. The algorithm enables\nefficient end-to-end training since it demands no off-the-shelf module for\npseudo labeling. Also, the class-equivalence relations provide rich supervisory\nsignals for learning an embedding space. On standard benchmarks for metric\nlearning, it clearly outperforms existing unsupervised learning methods and\nsometimes even beats supervised learning models using the same backbone\nnetwork. It is also applied to semi-supervised metric learning as a way of\nexploiting additional unlabeled data, and achieves the state of the art by\nboosting performance of supervised learning substantially.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Sungyeon Kim",
      "Dongwon Kim",
      "Minsu Cho",
      "Suha Kwak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01903"
  },
  {
    "id": "arXiv:2205.01904",
    "title": "ImAiR : Airwriting Recognition framework using Image Representation of  IMU Signals",
    "abstract": "The problem of Airwriting Recognition is focused on identifying letters\nwritten by movement of finger in free space. It is a type of gesture\nrecognition where the dictionary corresponds to letters in a specific language.\nIn particular, airwriting recognition using sensor data from wrist-worn devices\ncan be used as a medium of user input for applications in Human-Computer\nInteraction (HCI). Recognition of in-air trajectories using such wrist-worn\ndevices is limited in literature and forms the basis of the current work. In\nthis paper, we propose an airwriting recognition framework by first encoding\nthe time-series data obtained from a wearable Inertial Measurement Unit (IMU)\non the wrist as images and then utilizing deep learning-based models for\nidentifying the written alphabets. The signals recorded from 3-axis\naccelerometer and gyroscope in IMU are encoded as images using different\ntechniques such as Self Similarity Matrix (SSM), Gramian Angular Field (GAF)\nand Markov Transition Field (MTF) to form two sets of 3-channel images. These\nare then fed to two separate classification models and letter prediction is\nmade based on an average of the class conditional probabilities obtained from\nthe two models. Several standard model architectures for image classification\nsuch as variants of ResNet, DenseNet, VGGNet, AlexNet and GoogleNet have been\nutilized. Experiments performed on two publicly available datasets demonstrate\nthe efficacy of the proposed strategy. The code for our implementation will be\nmade available at https://github.com/ayushayt/ImAiR.",
    "descriptor": "",
    "authors": [
      "Ayush Tripathi",
      "Arnab Kumar Mondal",
      "Lalan Kumar",
      "Prathosh A.P"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.01904"
  },
  {
    "id": "arXiv:2205.01905",
    "title": "Three-dimensional Geospatial Interlinking with JedAI-spatial",
    "abstract": "Geospatial data constitutes a considerable part of (Semantic) Web data, but\nso far, its sources are inadequately interlinked in the Linked Open Data cloud.\nGeospatial Interlinking aims to cover this gap by associating geometries with\ntopological relations like those of the Dimensionally Extended 9-Intersection\nModel. Due to its quadratic time complexity, various algorithms aim to carry\nout Geospatial Interlinking efficiently. We present JedAI-spatial, a novel,\nopen-source system that organizes these algorithms according to three\ndimensions: (i) Space Tiling, which determines the approach that reduces the\nsearch space, (ii) Budget-awareness, which distinguishes interlinking\nalgorithms into batch and progressive ones, and (iii) Execution mode, which\ndiscerns between serial algorithms, running on a single CPU-core, and parallel\nones, running on top of Apache Spark. We analytically describe JedAI-spatial's\narchitecture and capabilities and perform thorough experiments to provide\ninteresting insights about the relative performance of its algorithms.",
    "descriptor": "",
    "authors": [
      "Marios Papamichalopoulos",
      "George Papadakis",
      "George Mandilaras",
      "Maria Despoina Siampou",
      "Nikos Mamoulis",
      "Manolis Koubarakis"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2205.01905"
  },
  {
    "id": "arXiv:2205.01906",
    "title": "ASE: Large-Scale Reusable Adversarial Skill Embeddings for Physically  Simulated Characters",
    "abstract": "The incredible feats of athleticism demonstrated by humans are made possible\nin part by a vast repertoire of general-purpose motor skills, acquired through\nyears of practice and experience. These skills not only enable humans to\nperform complex tasks, but also provide powerful priors for guiding their\nbehaviors when learning new tasks. This is in stark contrast to what is common\npractice in physics-based character animation, where control policies are most\ntypically trained from scratch for each task. In this work, we present a\nlarge-scale data-driven framework for learning versatile and reusable skill\nembeddings for physically simulated characters. Our approach combines\ntechniques from adversarial imitation learning and unsupervised reinforcement\nlearning to develop skill embeddings that produce life-like behaviors, while\nalso providing an easy to control representation for use on new downstream\ntasks. Our models can be trained using large datasets of unstructured motion\nclips, without requiring any task-specific annotation or segmentation of the\nmotion data. By leveraging a massively parallel GPU-based simulator, we are\nable to train skill embeddings using over a decade of simulated experiences,\nenabling our model to learn a rich and versatile repertoire of skills. We show\nthat a single pre-trained model can be effectively applied to perform a diverse\nset of new tasks. Our system also allows users to specify tasks through simple\nreward functions, and the skill embedding then enables the character to\nautomatically synthesize complex and naturalistic strategies in order to\nachieve the task objectives.",
    "descriptor": "",
    "authors": [
      "Xue Bin Peng",
      "Yunrong Guo",
      "Lina Halper",
      "Sergey Levine",
      "Sanja Fidler"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01906"
  },
  {
    "id": "arXiv:2205.01907",
    "title": "Cross-lingual Word Embeddings in Hyperbolic Space",
    "abstract": "Cross-lingual word embeddings can be applied to several natural language\nprocessing applications across multiple languages. Unlike prior works that use\nword embeddings based on the Euclidean space, this short paper presents a\nsimple and effective cross-lingual Word2Vec model that adapts to the Poincar\\'e\nball model of hyperbolic space to learn unsupervised cross-lingual word\nrepresentations from a German-English parallel corpus. It has been shown that\nhyperbolic embeddings can capture and preserve hierarchical relationships. We\nevaluate the model on both hypernymy and analogy tasks. The proposed model\nachieves comparable performance with the vanilla Word2Vec model on the\ncross-lingual analogy task, the hypernymy task shows that the cross-lingual\nPoincar\\'e Word2Vec model can capture latent hierarchical structure from free\ntext across languages, which are absent from the Euclidean-based Word2Vec\nrepresentations. Our results show that by preserving the latent hierarchical\ninformation, hyperbolic spaces can offer better representations for\ncross-lingual embeddings.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Chandni Saxena",
      "Mudit Chaudhary",
      "Helen Meng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01907"
  },
  {
    "id": "arXiv:2205.01909",
    "title": "Modeling Task Interactions in Document-Level Joint Entity and Relation  Extraction",
    "abstract": "We target on the document-level relation extraction in an end-to-end setting,\nwhere the model needs to jointly perform mention extraction, coreference\nresolution (COREF) and relation extraction (RE) at once, and gets evaluated in\nan entity-centric way. Especially, we address the two-way interaction between\nCOREF and RE that has not been the focus by previous work, and propose to\nintroduce explicit interaction namely Graph Compatibility (GC) that is\nspecifically designed to leverage task characteristics, bridging decisions of\ntwo tasks for direct task interference. Our experiments are conducted on DocRED\nand DWIE; in addition to GC, we implement and compare different multi-task\nsettings commonly adopted in previous work, including pipeline, shared\nencoders, graph propagation, to examine the effectiveness of different\ninteractions. The result shows that GC achieves the best performance by up to\n2.3/5.1 F1 improvement over the baseline.",
    "descriptor": "\nComments: Accepted to NAACL 2022\n",
    "authors": [
      "Liyan Xu",
      "Jinho D. Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01909"
  },
  {
    "id": "arXiv:2205.01915",
    "title": "Generalized Knowledge Distillation via Relationship Matching",
    "abstract": "The knowledge of a well-trained deep neural network (a.k.a. the \"teacher\") is\nvaluable for learning similar tasks. Knowledge distillation extracts knowledge\nfrom the teacher and integrates it with the target model (a.k.a. the\n\"student\"), which expands the student's knowledge and improves its learning\nefficacy. Instead of enforcing the teacher to work on the same task as the\nstudent, we borrow the knowledge from a teacher trained from a general label\nspace -- in this \"Generalized Knowledge Distillation (GKD)\", the classes of the\nteacher and the student may be the same, completely different, or partially\noverlapped. We claim that the comparison ability between instances acts as an\nessential factor threading knowledge across tasks, and propose the RElationship\nFacIlitated Local cLassifiEr Distillation (REFILLED) approach, which decouples\nthe GKD flow of the embedding and the top-layer classifier. In particular,\ndifferent from reconciling the instance-label confidence between models,\nREFILLED requires the teacher to reweight the hard tuples pushed forward by the\nstudent and then matches the similarity comparison levels between instances. An\nembedding-induced classifier based on the teacher model supervises the\nstudent's classification confidence and adaptively emphasizes the most related\nsupervision from the teacher. REFILLED demonstrates strong discriminative\nability when the classes of the teacher vary from the same to a fully\nnon-overlapped set w.r.t. the student. It also achieves state-of-the-art\nperformance on standard knowledge distillation, one-step incremental learning,\nand few-shot learning tasks.",
    "descriptor": "\nComments: This manuscript has been accepted by TPAMI\n",
    "authors": [
      "Han-Jia Ye",
      "Su Lu",
      "De-Chuan Zhan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01915"
  },
  {
    "id": "arXiv:2205.01917",
    "title": "CoCa: Contrastive Captioners are Image-Text Foundation Models",
    "abstract": "Exploring large-scale pretrained foundation models is of significant interest\nin computer vision because these models can be quickly transferred to many\ndownstream tasks. This paper presents Contrastive Captioner (CoCa), a\nminimalist design to pretrain an image-text encoder-decoder foundation model\njointly with contrastive loss and captioning loss, thereby subsuming model\ncapabilities from contrastive approaches like CLIP and generative methods like\nSimVLM. In contrast to standard encoder-decoder transformers where all decoder\nlayers attend to encoder outputs, CoCa omits cross-attention in the first half\nof decoder layers to encode unimodal text representations, and cascades the\nremaining decoder layers which cross-attend to the image encoder for multimodal\nimage-text representations. We apply a contrastive loss between unimodal image\nand text embeddings, in addition to a captioning loss on the multimodal decoder\noutputs which predicts text tokens autoregressively. By sharing the same\ncomputational graph, the two training objectives are computed efficiently with\nminimal overhead. CoCa is pretrained end-to-end and from scratch on both\nweb-scale alt-text data and annotated images by treating all labels simply as\ntext, seamlessly unifying natural language supervision for representation\nlearning. Empirically, CoCa achieves state-of-the-art performance with\nzero-shot transfer or minimal task-specific adaptation on a broad range of\ndownstream tasks, spanning visual recognition (ImageNet, Kinetics-400/600/700,\nMoments-in-Time), crossmodal retrieval (MSCOCO, Flickr30K, MSR-VTT), multimodal\nunderstanding (VQA, SNLI-VE, NLVR2), and image captioning (MSCOCO, NoCaps).\nNotably on ImageNet classification, CoCa obtains 86.3% zero-shot top-1\naccuracy, 90.6% with a frozen encoder and learned classification head, and new\nstate-of-the-art 91.0% top-1 accuracy on ImageNet with a finetuned encoder.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Jiahui Yu",
      "Zirui Wang",
      "Vijay Vasudevan",
      "Legg Yeung",
      "Mojtaba Seyedhosseini",
      "Yonghui Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2205.01917"
  },
  {
    "id": "arXiv:2205.01920",
    "title": "Scene Clustering Based Pseudo-labeling Strategy for Multi-modal Aerial  View Object Classification",
    "abstract": "Multi-modal aerial view object classification (MAVOC) in Automatic target\nrecognition (ATR), although an important and challenging problem, has been\nunder studied. This paper firstly finds that fine-grained data, class imbalance\nand various shooting conditions preclude the representational ability of\ngeneral image classification. Moreover, the MAVOC dataset has scene aggregation\ncharacteristics. By exploiting these properties, we propose Scene Clustering\nBased Pseudo-labeling Strategy (SCP-Label), a simple yet effective method to\nemploy in post-processing. The SCP-Label brings greater accuracy by assigning\nthe same label to objects within the same scene while also mitigating bias and\nconfusion with model ensembles. Its performance surpasses the official baseline\nby a large margin of +20.57% Accuracy on Track 1 (SAR), and +31.86% Accuracy on\nTrack 2 (SAR+EO), demonstrating the potential of SCP-Label as post-processing.\nFinally, we win the championship both on Track1 and Track2 in the CVPR 2022\nPerception Beyond the Visible Spectrum (PBVS) Workshop MAVOC Challenge. Our\ncode is available at https://github.com/HowieChangchn/SCP-Label.",
    "descriptor": "",
    "authors": [
      "Jun Yu",
      "Hao Chang",
      "Keda Lu",
      "Liwen Zhang",
      "Shenshen Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01920"
  },
  {
    "id": "arXiv:2205.01921",
    "title": "Second Order Path Variationals in Non-Stationary Online Learning",
    "abstract": "We consider the problem of universal dynamic regret minimization under\nexp-concave and smooth losses. We show that appropriately designed Strongly\nAdaptive algorithms achieve a dynamic regret of $\\tilde O(d^2 n^{1/5} C_n^{2/5}\n\\vee d^2)$, where $n$ is the time horizon and $C_n$ a path variational based on\nsecond order differences of the comparator sequence. Such a path variational\nnaturally encodes comparator sequences that are piecewise linear -- a powerful\nfamily that tracks a variety of non-stationarity patterns in practice (Kim et\nal, 2009). The aforementioned dynamic regret rate is shown to be optimal modulo\ndimension dependencies and poly-logarithmic factors of $n$. Our proof\ntechniques rely on analysing the KKT conditions of the offline oracle and\nrequires several non-trivial generalizations of the ideas in Baby and Wang,\n2021, where the latter work only leads to a slower dynamic regret rate of\n$\\tilde O(d^{2.5}n^{1/3}C_n^{2/3} \\vee d^{2.5})$ for the current problem.",
    "descriptor": "",
    "authors": [
      "Dheeraj Baby",
      "Yu-Xiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.01921"
  },
  {
    "id": "arXiv:2205.01922",
    "title": "Performance evaluations on the parallel CHAracteristic-Spectral-Mixed  (CHASM) scheme",
    "abstract": "Performance evaluations on the deterministic algorithms for 6-D problems are\nrarely found in literatures except some recent advances in the Vlasov and\nBoltzmann community [Dimarco et al. (2018), Kormann et al. (2019)], due to the\nextremely high complexity. Thus a detailed comparison among various techniques\nshall be useful to the researchers in the related fields. We try to make a\nthorough evaluation on a parallel CHAracteristic-Spectral-Mixed (CHASM) scheme\nto support its usage. CHASM utilizes the cubic B-spline expansion in the\nspatial space and spectral expansion in the momentum space, which many\npotentially overcome the computational burden in solving classical and quantum\nkinetic equations in 6-D phase space. Our purpose is three-pronged. First, we\nwould like show that by imposing some effective Hermite boundary conditions,\nthe local cubic spline can approximate to the global one as accurately as\npossible. Second, we will illustrate the necessity of adopting the truncated\nkernel method in calculating the pseudodifferential operator with a singular\nsymbol, since the widely used pseudo-spectral method [Ringhofer (1990)] might\nfail to properly tackle the singularity. Finally, we make a comparison among\nnon-splitting Lawson schemes and Strang operator splitting. Our numerical\nresults demonstrate the advantage of the one-stage Lawson predictor-corrector\nscheme over multi-stage ones as well as the splitting scheme in both accuracy\nand stability.",
    "descriptor": "",
    "authors": [
      "Yunfeng Xiong",
      "Yong Zhang",
      "Sihong Shao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.01922"
  },
  {
    "id": "arXiv:2205.01924",
    "title": "Zero-Episode Few-Shot Contrastive Predictive Coding: Solving  intelligence tests without prior training",
    "abstract": "Video prediction models often combine three components: an encoder from pixel\nspace to a small latent space, a latent space prediction model, and a\ngenerative model back to pixel space. However, the large and unpredictable\npixel space makes training such models difficult, requiring many training\nexamples. We argue that finding a predictive latent variable and using it to\nevaluate the consistency of a future image enables data-efficient predictions\nbecause it precludes the necessity of a generative model training. To\ndemonstrate it, we created sequence completion intelligence tests in which the\ntask is to identify a predictably changing feature in a sequence of images and\nuse this prediction to select the subsequent image. We show that a\none-dimensional Markov Contrastive Predictive Coding (M-CPC_1D) model solves\nthese tests efficiently, with only five examples. Finally, we demonstrate the\nusefulness of M-CPC_1D in solving two tasks without prior training: anomaly\ndetection and stochastic movement video prediction.",
    "descriptor": "",
    "authors": [
      "T. Barak",
      "Y. Loewenstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01924"
  },
  {
    "id": "arXiv:2205.01927",
    "title": "Probabilistic Symmetry for Improved Trajectory Forecasting",
    "abstract": "Trajectory prediction is a core AI problem with broad applications in\nrobotics and autonomous driving. While most existing works focus on\ndeterministic prediction, producing probabilistic forecasts to quantify\nprediction uncertainty is critical for downstream decision-making tasks such as\nrisk assessment, motion planning, and safety guarantees. We introduce a new\nmetric, mean regional score (MRS), to evaluate the quality of probabilistic\ntrajectory forecasts. We propose a novel probabilistic trajectory prediction\nmodel, Probabilistic Equivariant Continuous COnvolution (PECCO) and show that\nleveraging symmetry, specifically rotation equivariance, can improve the\npredictions' accuracy as well as coverage. On both vehicle and pedestrian\ndatasets, PECCO shows state-of-the-art prediction performance and improved\ncalibration compared to baselines.",
    "descriptor": "",
    "authors": [
      "Sophia Sun",
      "Robin Walters",
      "Jinxi Li",
      "Rose Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.01927"
  },
  {
    "id": "arXiv:2205.01929",
    "title": "Explain to Not Forget: Defending Against Catastrophic Forgetting with  XAI",
    "abstract": "The ability to continuously process and retain new information like we do\nnaturally as humans is a feat that is highly sought after when training neural\nnetworks. Unfortunately, the traditional optimization algorithms often require\nlarge amounts of data available during training time and updates wrt. new data\nare difficult after the training process has been completed. In fact, when new\ndata or tasks arise, previous progress may be lost as neural networks are prone\nto catastrophic forgetting. Catastrophic forgetting describes the phenomenon\nwhen a neural network completely forgets previous knowledge when given new\ninformation. We propose a novel training algorithm called training by\nexplaining in which we leverage Layer-wise Relevance Propagation in order to\nretain the information a neural network has already learned in previous tasks\nwhen training on new data. The method is evaluated on a range of benchmark\ndatasets as well as more complex data. Our method not only successfully retains\nthe knowledge of old tasks within the neural networks but does so more\nresource-efficiently than other state-of-the-art solutions.",
    "descriptor": "\nComments: 14 pages including appendix, 5 figures, 2 tables, 1 algorithm listing\n",
    "authors": [
      "Sami Ede",
      "Serop Baghdadlian",
      "Leander Weber",
      "Wojciech Samek",
      "Sebastian Lapuschkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01929"
  },
  {
    "id": "arXiv:2205.01930",
    "title": "Explainable Anomaly Detection for Industrial Control System  Cybersecurity",
    "abstract": "Industrial Control Systems (ICSs) are becoming more and more important in\nmanaging the operation of many important systems in smart manufacturing, such\nas power stations, water supply systems, and manufacturing sites. While massive\ndigital data can be a driving force for system performance, data security has\nraised serious concerns. Anomaly detection, therefore, is essential for\npreventing network security intrusions and system attacks. Many AI-based\nanomaly detection methods have been proposed and achieved high detection\nperformance, however, are still a \"black box\" that is hard to be interpreted.\nIn this study, we suggest using Explainable Artificial Intelligence to enhance\nthe perspective and reliable results of an LSTM-based Autoencoder-OCSVM\nlearning model for anomaly detection in ICS. We demonstrate the performance of\nour proposed method based on a well-known SCADA dataset.",
    "descriptor": "\nComments: Copyright \\copyright ~ 2022, IFAC (International Federation of Automatic Control)\n",
    "authors": [
      "Do Thu Ha",
      "Nguyen Xuan Hoang",
      "Nguyen Viet Hoang",
      "Nguyen Huu Du",
      "Truong Thu Huong",
      "Kim Phuc Tran"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.01930"
  },
  {
    "id": "arXiv:2205.01931",
    "title": "Self-supervised learning unveils morphological clusters behind lung  cancer types and prognosis",
    "abstract": "Histopathological images of tumors contain abundant information about how\ntumors grow and how they interact with their micro-environment. Characterizing\nand improving our understanding of phenotypes could reveal factors related to\ntumor progression and their underpinning biological processes, ultimately\nimproving diagnosis and treatment. In recent years, the field of histological\ndeep learning applications has seen great progress, yet most of these\napplications focus on a supervised approach, relating tissue and associated\nsample annotations. Supervised approaches have their impact limited by two\nfactors. Firstly, high-quality labels are expensive in time and effort, which\nmakes them not easily scalable. Secondly, these methods focus on predicting\nannotations from histological images, fundamentally restricting the discovery\nof new tissue phenotypes. These limitations emphasize the importance of using\nnew methods that can characterize tissue by the features enclosed in the image,\nwithout pre-defined annotation or supervision. We present Phenotype\nRepresentation Learning (PRL), a methodology to extract histomorphological\nphenotypes through self-supervised learning and community detection. PRL\ncreates phenotype clusters by identifying tissue patterns that share common\nmorphological and cellular features, allowing to describe whole slide images\nthrough compositional representations of cluster contributions. We used this\nframework to analyze histopathology slides of LUAD and LUSC lung cancer\nsubtypes from TCGA and NYU cohorts. We show that PRL achieves a robust lung\nsubtype prediction providing statistically relevant phenotypes for each lung\nsubtype. We further demonstrate the significance of these phenotypes in lung\nadenocarcinoma overall and recurrence free survival, relating clusters with\npatient outcomes, cell types, grown patterns, and omic-based immune signatures.",
    "descriptor": "",
    "authors": [
      "Adalberto Claudio Quiros",
      "Nicolas Coudray",
      "Anna Yeaton",
      "Xinyu Yang",
      "Luis Chiriboga",
      "Afreen Karimkhan",
      "Navneet Narula",
      "Harvey Pass",
      "Andre L. Moreira",
      "John Le Quesne",
      "Aristotelis Tsirigos",
      "Ke Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01931"
  },
  {
    "id": "arXiv:2205.01932",
    "title": "Early Detection of Spam Domains with Passive DNS and SPF",
    "abstract": "Spam domains are sources of unsolicited mails and one of the primary vehicles\nfor fraud and malicious activities such as phishing campaigns or malware\ndistribution. Spam domain detection is a race: as soon as the spam mails are\nsent, taking down the domain or blacklisting it is of relative use, as spammers\nhave to register a new domain for their next campaign. To prevent malicious\nactors from sending mails, we need to detect them as fast as possible and,\nideally, even before the campaign is launched. In this paper, using\nnear-real-time passive DNS data from Farsight Security, we monitor the DNS\ntraffic of newly registered domains and the contents of their TXT records, in\nparticular, the configuration of the Sender Policy Framework, an anti-spoofing\nprotocol for domain names and the first line of defense against devastating\nBusiness Email Compromise scams. Because spammers and benign domains have\ndifferent SPF rules and different traffic profiles, we build a new method to\ndetect spam domains using features collected from passive DNS traffic. Using\nthe SPF configuration and the traffic to the TXT records of a domain, we\naccurately detect a significant proportion of spam domains with a low false\npositives rate demonstrating its potential in real-world deployments. Our\nclassification scheme can detect spam domains before they send any mail, using\nonly a single DNS query and later on, it can refine its classification by\nmonitoring more traffic to the domain name.",
    "descriptor": "",
    "authors": [
      "Simon Fernandez",
      "Maciej Korczy\u0144ski",
      "Andrzej Duda"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.01932"
  },
  {
    "id": "arXiv:2205.01937",
    "title": "Homography-Based Loss Function for Camera Pose Regression",
    "abstract": "Some recent visual-based relocalization algorithms rely on deep learning\nmethods to perform camera pose regression from image data. This paper focuses\non the loss functions that embed the error between two poses to perform deep\nlearning based camera pose regression. Existing loss functions are either\ndifficult-to-tune multi-objective functions or present unstable reprojection\nerrors that rely on ground truth 3D scene points and require a two-step\ntraining. To deal with these issues, we introduce a novel loss function which\nis based on a multiplane homography integration. This new function does not\nrequire prior initialization and only depends on physically interpretable\nhyperparameters. Furthermore, the experiments carried out on well established\nrelocalization datasets show that it minimizes best the mean square\nreprojection error during training when compared with existing loss functions.",
    "descriptor": "",
    "authors": [
      "Cl\u00e9mentin Boittiaux",
      "Ricard Marxer",
      "Claire Dune",
      "Aur\u00e9lien Arnaubec",
      "Vincent Hugel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.01937"
  },
  {
    "id": "arXiv:2205.01938",
    "title": "DeepFD: Automated Fault Diagnosis and Localization for Deep Learning  Programs",
    "abstract": "As Deep Learning (DL) systems are widely deployed for mission-critical\napplications, debugging such systems becomes essential. Most existing works\nidentify and repair suspicious neurons on the trained Deep Neural Network\n(DNN), which, unfortunately, might be a detour. Specifically, several existing\nstudies have reported that many unsatisfactory behaviors are actually\noriginated from the faults residing in DL programs. Besides, locating faulty\nneurons is not actionable for developers, while locating the faulty statements\nin DL programs can provide developers with more useful information for\ndebugging. Though a few recent studies were proposed to pinpoint the faulty\nstatements in DL programs or the training settings (e.g. too large learning\nrate), they were mainly designed based on predefined rules, leading to many\nfalse alarms or false negatives, especially when the faults are beyond their\ncapabilities.\nIn view of these limitations, in this paper, we proposed DeepFD, a\nlearning-based fault diagnosis and localization framework which maps the fault\nlocalization task to a learning problem. In particular, it infers the\nsuspicious fault types via monitoring the runtime features extracted during DNN\nmodel training and then locates the diagnosed faults in DL programs. It\novercomes the limitations by identifying the root causes of faults in DL\nprograms instead of neurons and diagnosing the faults by a learning approach\ninstead of a set of hard-coded rules. The evaluation exhibits the potential of\nDeepFD. It correctly diagnoses 52% faulty DL programs, compared with around\nhalf (27%) achieved by the best state-of-the-art works. Besides, for fault\nlocalization, DeepFD also outperforms the existing works, correctly locating\n42% faulty programs, which almost doubles the best result (23%) achieved by the\nexisting works.",
    "descriptor": "\nComments: Accepted by ICSE 2022. 11 pages for main content, 2 pages for reference\n",
    "authors": [
      "Jialun Cao",
      "Meiziniu Li",
      "Xiao Chen",
      "Ming Wen",
      "Yongqiang Tian",
      "Bo Wu",
      "Shing-Chi Cheung"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01938"
  },
  {
    "id": "arXiv:2205.01940",
    "title": "Towards Theoretical Analysis of Transformation Complexity of ReLU DNNs",
    "abstract": "This paper aims to theoretically analyze the complexity of feature\ntransformations encoded in DNNs with ReLU layers. We propose metrics to measure\nthree types of complexities of transformations based on the information theory.\nWe further discover and prove the strong correlation between the complexity and\nthe disentanglement of transformations. Based on the proposed metrics, we\nanalyze two typical phenomena of the change of the transformation complexity\nduring the training process, and explore the ceiling of a DNN's complexity. The\nproposed metrics can also be used as a loss to learn a DNN with the minimum\ncomplexity, which also controls the over-fitting level of the DNN and\ninfluences adversarial robustness, adversarial transferability, and knowledge\nconsistency. Comprehensive comparative studies have provided new perspectives\nto understand the DNN.",
    "descriptor": "",
    "authors": [
      "Jie Ren",
      "Mingjie Li",
      "Meng Zhou",
      "Shih-Han Chan",
      "Quanshi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01940"
  },
  {
    "id": "arXiv:2205.01941",
    "title": "Lexical Knowledge Internalization for Neural Dialog Generation",
    "abstract": "We propose knowledge internalization (KI), which aims to complement the\nlexical knowledge into neural dialog models. Instead of further conditioning\nthe knowledge-grounded dialog (KGD) models on externally retrieved knowledge,\nwe seek to integrate knowledge about each input token internally into the\nmodel's parameters. To tackle the challenge due to the large scale of lexical\nknowledge, we adopt the contrastive learning approach and create an effective\ntoken-level lexical knowledge retriever that requires only weak supervision\nmined from Wikipedia. We demonstrate the effectiveness and general\napplicability of our approach on various datasets and diversified model\nstructures.",
    "descriptor": "\nComments: To appear at ACL 2022 main conference\n",
    "authors": [
      "Zhiyong Wu",
      "Wei Bi",
      "Xiang Li",
      "Lingpeng Kong",
      "Ben Kao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01941"
  },
  {
    "id": "arXiv:2205.01944",
    "title": "Joint Compute-Caching-Communication Control for Online Data-Intensive  Service Delivery",
    "abstract": "Emerging Metaverse applications, designed to deliver highly interactive and\nimmersive experiences that seamlessly blend physical reality and digital\nvirtuality, are accelerating the need for distributed compute platforms with\nunprecedented storage, computation, and communication requirements. To this\nend, the integrated evolution of next-generation networks (e.g., 5G and beyond)\nand distributed cloud technologies (e.g., fog and mobile edge computing), have\nemerged as a promising paradigm to address the interaction- and\nresource-intensive nature of Metaverse applications. In this paper, we focus on\nthe design of control policies for the joint orchestration of compute, caching,\nand communication (3C) resources in next-generation distributed cloud networks\nfor the efficient delivery of Metaverse applications that require the real-time\naggregation, processing, and distribution of multiple live media streams and\npre-stored digital assets. We describe Metaverse applications via directed\nacyclic graphs able to model the combination of real-time stream-processing and\ncontent distribution pipelines. We design the first throughput-optimal control\npolicy that coordinates joint decisions around (i) routing paths and processing\nlocations for live data streams, together with (ii) cache selection and\ndistribution paths for associated data objects. We then extend the proposed\nsolution to include a max-throughput database placement policy and two\nefficient replacement policies. In addition, we characterize the network\nstability regions for all studied scenarios. Numerical results demonstrate the\nsuperior performance obtained via the novel multi-pipeline flow control and 3C\nresource orchestration mechanisms of the proposed policy, compared with\nstate-of-the-art algorithms that lack full 3C integrated control.",
    "descriptor": "",
    "authors": [
      "Yang Cai",
      "Jaime Llorca",
      "Antonia M. Tulino",
      "Andreas F. Molisch"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.01944"
  },
  {
    "id": "arXiv:2205.01945",
    "title": "Optimal Network Charge for Peer-to-Peer Energy Trading: A Grid  Perspective",
    "abstract": "Peer-to-peer (P2P) energy trading is a promising market scheme to accommodate\nthe increasing distributed energy resources (DERs). However, how P2P to be\nintegrated into the existing power systems remains to be investigated. In this\npaper, we apply network charge as a means for the grid operator to attribute\ntransmission loss and ensure network constraints for empowering P2P\ntransaction. The interaction between the grid operator and the prosumers is\nmodeled as a Stackelberg game, which yields a bi-level optimization problem. We\nprove that the Stackelberg game admits an equilibrium network charge price.\nBesides, we propose a method to obtain the network charge price by converting\nthe bi-level optimization into a single-level mixed-integer quadratic\nprogramming (MIQP), which can handle a reasonable scale of prosumers\nefficiently. Simulations on the IEEE bus systems show that the proposed optimal\nnetwork charge is favorable as it can benefit both the grid operator and the\nprosumers for empowering the P2P market, and achieves near-optimal social\nwelfare. Moreover, the results show that the presence of energy storage will\nmake the prosumers more sensitive to the network charge price changes.",
    "descriptor": "\nComments: 12 pages, 16 figures\n",
    "authors": [
      "Yu Yang",
      "Yue Chen",
      "Guoqiang Hu",
      "Costas J. Spanos"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2205.01945"
  },
  {
    "id": "arXiv:2205.01947",
    "title": "EllSeg-Gen, towards Domain Generalization for head-mounted eyetracking",
    "abstract": "The study of human gaze behavior in natural contexts requires algorithms for\ngaze estimation that are robust to a wide range of imaging conditions. However,\nalgorithms often fail to identify features such as the iris and pupil centroid\nin the presence of reflective artifacts and occlusions. Previous work has shown\nthat convolutional networks excel at extracting gaze features despite the\npresence of such artifacts. However, these networks often perform poorly on\ndata unseen during training. This work follows the intuition that jointly\ntraining a convolutional network with multiple datasets learns a generalized\nrepresentation of eye parts. We compare the performance of a single model\ntrained with multiple datasets against a pool of models trained on individual\ndatasets. Results indicate that models tested on datasets in which eye images\nexhibit higher appearance variability benefit from multiset training. In\ncontrast, dataset-specific models generalize better onto eye images with lower\nappearance variability.",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Rakshit S. Kothari",
      "Reynold J. Bailey",
      "Christopher Kanan",
      "Jeff B. Pelz",
      "Gabriel J. Diaz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.01947"
  },
  {
    "id": "arXiv:2205.01948",
    "title": "Dynamic Median Consensus for Marine Multi-Robot Systems Using Acoustic  Communication",
    "abstract": "In this paper, we present a dynamic median consensus protocol for multi-agent\nsystems using acoustic communication. The motivating target scenario is a\nmulti-agent system consisting of underwater robots acting as intelligent\nsensors, applied to continuous monitoring of the state of a marine environment.\nThe proposed protocol allows each agent to track the median value of individual\nmeasurements of all agents through local communication with neighbouring\nagents. Median is chosen as a measure robust to outliers, as opposed to average\nvalue, which is usually used. In contrast to the existing consensus protocols,\nthe proposed protocol is dynamic, uses a switching communication topology and\nconverges to median of measured signals. Stability and correctness of the\nprotocol are theoretically proven. The protocol is tested in simulation, and\naccuracy and influence of protocol parameters on the system output are\nanalyzed. The protocol is implemented and validated by a set of experiments on\nan underwater group of robots comprising of aMussel units. This experimental\nsetup is one of the first deployments of any type of consensus protocol for an\nunderwater setting. Both simulation and experimental results confirm the\ncorrectness of the presented approach.",
    "descriptor": "",
    "authors": [
      "Goran Vasiljevic",
      "Tamara Petrovic",
      "Barbara Arbanas",
      "Stjepan Bogdan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.01948"
  },
  {
    "id": "arXiv:2205.01949",
    "title": "Compatible $L^2$ norm convergence of variable-step L1 scheme for the  time-fractional MBE mobel with slope selection",
    "abstract": "The convergence of variable-step L1 scheme is studied for the time-fractional\nmolecular beam epitaxy (MBE) model with slope selection.A novel asymptotically\ncompatible $L^2$ norm error estimate of the variable-step L1 scheme is\nestablished under a convergence-solvability-stability (CSS)-consistent\ntime-step constraint. The CSS-consistent condition means that the maximum\nstep-size limit required for convergence is of the same order to that for\nsolvability and stability (in certain norms) as the small interface parameter\n$\\epsilon\\rightarrow 0^+$. To the best of our knowledge, it is the first time\nto establish such error estimate for nonlinear subdiffusion problems. The\nasymptotically compatible convergence means that the error estimate is\ncompatible with that of backward Euler scheme for the classical MBE model as\nthe fractional order $\\alpha\\rightarrow 1^-$. Just as the backward Euler scheme\ncan maintain the physical properties of the MBE equation, the variable-step L1\nscheme can also preserve the corresponding properties of the time-fractional\nMBE model, including the volume conservation, variational energy dissipation\nlaw and $L^2$ norm boundedness. Numerical experiments are presented to support\nour theoretical results.",
    "descriptor": "\nComments: 23 pages,21 figures,4 tables\n",
    "authors": [
      "Yin Yang",
      "Jindi Wang",
      "Yanping Chen",
      "Hong-lin Liao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.01949"
  },
  {
    "id": "arXiv:2205.01950",
    "title": "Uncertainty-Autoencoder-Based Privacy and Utility Preserving Data Type  Conscious Transformation",
    "abstract": "We propose an adversarial learning framework that deals with the\nprivacy-utility tradeoff problem under two types of conditions: data-type\nignorant, and data-type aware. Under data-type aware conditions, the privacy\nmechanism provides a one-hot encoding of categorical features, representing\nexactly one class, while under data-type ignorant conditions the categorical\nvariables are represented by a collection of scores, one for each class. We use\na neural network architecture consisting of a generator and a discriminator,\nwhere the generator consists of an encoder-decoder pair, and the discriminator\nconsists of an adversary and a utility provider. Unlike previous research\nconsidering this kind of architecture, which leverages autoencoders (AEs)\nwithout introducing any randomness, or variational autoencoders (VAEs) based on\nlearning latent representations which are then forced into a Gaussian\nassumption, our proposed technique introduces randomness and removes the\nGaussian assumption restriction on the latent variables, only focusing on the\nend-to-end stochastic mapping of the input to privatized data. We test our\nframework on different datasets: MNIST, FashionMNIST, UCI Adult, and US Census\nDemographic Data, providing a wide range of possible private and utility\nattributes. We use multiple adversaries simultaneously to test our privacy\nmechanism -- some trained from the ground truth data and some trained from the\nperturbed data generated by our privacy mechanism. Through comparative\nanalysis, our results demonstrate better privacy and utility guarantees than\nthe existing works under similar, data-type ignorant conditions, even when the\nlatter are considered under their original restrictive single-adversary model.",
    "descriptor": "\nComments: Paper accepted at the 2022 IEEE International Joint Conference on Neural Networks (IJCNN)\n",
    "authors": [
      "Bishwas Mandal",
      "George Amariucai",
      "Shuangqing Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.01950"
  },
  {
    "id": "arXiv:2205.01952",
    "title": "A Generic Solution to Register-bounded Synthesis with an Application to  Discrete Orders",
    "abstract": "We study synthesis of reactive systems interacting with environments using an\ninfinite data domain. A popular formalism for specifying and modelling such\nsystems is register automata and transducers. They extend finite-state automata\nby adding registers to store data values and to compare the incoming data\nvalues against stored ones. Synthesis from nondeterministic or universal\nregister automata is undecidable in general. However, its register-bounded\nvariant, where additionally a bound on the number of registers in a sought\ntransducer is given, is known to be decidable for universal register automata\nwhich can compare data for equality, i.e., for data domain $(N,=)$. This paper\nextends the decidability border to the domain $(N,<)$ of natural numbers with\nlinear order. Our solution is generic: we define a sufficient condition on data\ndomains (regular approximability) for decidability of register-bounded\nsynthesis. The condition is satisfied by natural data domains like $(N,<)$. It\nallows one to use simple language-theoretic arguments and avoid technical\ngame-theoretic reasoning. Further, by defining a generic notion of reducibility\nbetween data domains, we show the decidability of synthesis in the domain\n$(N^d,<^d)$ of tuples of numbers equipped with the component-wise partial order\nand in the domain $(\\Sigma^*,\\prec)$ of finite strings with the prefix\nrelation.",
    "descriptor": "\nComments: full version of the paper (includes appendices)\n",
    "authors": [
      "L\u00e9o Exibard",
      "Emmanuel Filiot",
      "Ayrat Khalimov"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2205.01952"
  },
  {
    "id": "arXiv:2205.01953",
    "title": "A Global Asymptotic Convergent Observer for SLAM",
    "abstract": "This paper examines the global convergence problem of SLAM algorithms, an\nissue that faces topological obstructions. This is because the state-space of\nattitude dynamics is defined on a non-contractible manifold: the special\northogonal group of order three SO(3). Therefore, this paper presents a novel,\ngradient-based hybrid observer to overcome these topological obstacles. The\nLyapunov stability theorem is used to prove the globally asymptotic convergence\nof the proposed algorithm. Finally, comparative analyses of two simulations\nwere conducted to evaluate the performance of the proposed scheme and to\ndemonstrate the superiority of the proposed hybrid observer to a smooth\nobserver.",
    "descriptor": "\nComments: 7 pages, 8 figures, conference\n",
    "authors": [
      "Seyed Hamed Hashemi",
      "Jouni Mattila"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.01953"
  },
  {
    "id": "arXiv:2205.01954",
    "title": "Word Tour: One-dimensional Word Embeddings via the Traveling Salesman  Problem",
    "abstract": "Word embeddings are one of the most fundamental technologies used in natural\nlanguage processing. Existing word embeddings are high-dimensional and consume\nconsiderable computational resources. In this study, we propose WordTour,\nunsupervised one-dimensional word embeddings. To achieve the challenging goal,\nwe propose a decomposition of the desiderata of word embeddings into two parts,\ncompleteness and soundness, and focus on soundness in this paper. Owing to the\nsingle dimensionality, WordTour is extremely efficient and provides a minimal\nmeans to handle word embeddings. We experimentally confirmed the effectiveness\nof the proposed method via user study and document classification.",
    "descriptor": "\nComments: NAACL 2022\n",
    "authors": [
      "Ryoma Sato"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01954"
  },
  {
    "id": "arXiv:2205.01955",
    "title": "Fuzzy Simulations and Bisimulations between Fuzzy Automata",
    "abstract": "Simulations and bisimulations between two fuzzy automata over a complete\nresiduated lattice were defined by \\'Ciri\\'c et al. (2012) as fuzzy relations\nbetween the sets of states of the automata. However, they act as a crisp\nrelationship between the automata. In particular, if there exists a (forward)\nbisimulation between two fuzzy automata, then the fuzzy languages recognized by\nthem are crisply equal. Approximate simulations and bisimulations introduced by\nStanimirovi\\'c et al. (2020) aim at fuzzifying this phenomenon. However, they\nare defined only for fuzzy automata over a complete Heyting algebra and do not\ngive the exact relationship between states of the automata. In this article, we\nintroduce and study fuzzy simulations and bisimulations between fuzzy automata\nover a complete residuated lattice. These notions are novel and have good\nproperties. They are defined for fuzzy automata over any complete residuated\nlattice. We prove that the fuzzy language recognized by a fuzzy automaton is\nfuzzily preserved by fuzzy simulations and fuzzily invariant under fuzzy\nbisimulations. We also prove that the notions of fuzzy simulation and\nbisimulation have the Hennessy-Milner properties, which are a logical\ncharacterization of the greatest fuzzy simulation or bisimulation between two\nfuzzy automata. In addition, we provide results showing that our notions of\nfuzzy simulation and bisimulation are more general and refined than the notions\nof simulation and bisimulation introduced by \\'Ciri\\'c et al. and the notions\nof approximate simulation and bisimulation introduced by Stanimirovi\\'c et al.",
    "descriptor": "",
    "authors": [
      "Linh Anh Nguyen"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2205.01955"
  },
  {
    "id": "arXiv:2205.01959",
    "title": "Birkhoff-von Neumann Quantum Logic as an Assertion Language for Quantum  Programs",
    "abstract": "A first-order logic with quantum variables is needed as an assertion language\nfor specifying and reasoning about various properties (e.g. correctness) of\nquantum programs. Surprisingly, such a logic is missing in the literature, and\nthe existing first-order Birkhoff-von Neumann quantum logic deals with only\nclassical variables and quantifications over them. In this paper, we fill in\nthis gap by introducing a first-order extension of Birkhoff-von Neumann quantum\nlogic with universal and existential quantifiers over quantum variables.\nExamples are presented to show our logic is particularly suitable for\nspecifying some important properties studied in quantum computation and quantum\ninformation. We further incorporate this logic into quantum Hoare logic as an\nassertion logic so that it can play a role similar to that of first-order logic\nfor classical Hoare logic and BI-logic for separation logic. In particular, we\nshow how it can be used to define and derive quantum generalisations of some\nadaptation rules that have been applied to significantly simplify verification\nof classical programs. It is expected that the assertion logic defined in this\npaper - first-order quantum logic with quantum variables - can be combined with\nvarious quantum program logics to serve as a solid logical foundation upon\nwhich verification tools can be built using proof assistants such as Coq and\nIsabelle/HOL.",
    "descriptor": "",
    "authors": [
      "Mingsheng Ying"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2205.01959"
  },
  {
    "id": "arXiv:2205.01965",
    "title": "State Representation Learning for Goal-Conditioned Reinforcement  Learning",
    "abstract": "This paper presents a novel state representation for reward-free Markov\ndecision processes. The idea is to learn, in a self-supervised manner, an\nembedding space where distances between pairs of embedded states correspond to\nthe minimum number of actions needed to transition between them. Compared to\nprevious methods, our approach does not require any domain knowledge, learning\nfrom offline and unlabeled data. We show how this representation can be\nleveraged to learn goal-conditioned policies, providing a notion of similarity\nbetween states and goals and a useful heuristic distance to guide planning and\nreinforcement learning algorithms. Finally, we empirically validate our method\nin classic control domains and multi-goal environments, demonstrating that our\nmethod can successfully learn representations in large and/or continuous\ndomains.",
    "descriptor": "",
    "authors": [
      "Lorenzo Steccanella",
      "Anders Jonsson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01965"
  },
  {
    "id": "arXiv:2205.01966",
    "title": "Non-Autoregressive Machine Translation: It's Not as Fast as it Seems",
    "abstract": "Efficient machine translation models are commercially important as they can\nincrease inference speeds, and reduce costs and carbon emissions. Recently,\nthere has been much interest in non-autoregressive (NAR) models, which promise\nfaster translation. In parallel to the research on NAR models, there have been\nsuccessful attempts to create optimized autoregressive models as part of the\nWMT shared task on efficient translation. In this paper, we point out flaws in\nthe evaluation methodology present in the literature on NAR models and we\nprovide a fair comparison between a state-of-the-art NAR model and the\nautoregressive submissions to the shared task. We make the case for consistent\nevaluation of NAR models, and also for the importance of comparing NAR models\nwith other widely used methods for improving efficiency. We run experiments\nwith a connectionist-temporal-classification-based (CTC) NAR model implemented\nin C++ and compare it with AR models using wall clock times. Our results show\nthat, although NAR models are faster on GPUs, with small batch sizes, they are\nalmost always slower under more realistic usage conditions. We call for more\nrealistic and extensive evaluation of NAR models in future work.",
    "descriptor": "\nComments: NAACL 2022, Camera-ready\n",
    "authors": [
      "Jind\u0159ich Helcl",
      "Barry Haddow",
      "Alexandra Birch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01966"
  },
  {
    "id": "arXiv:2205.01968",
    "title": "Numerical approximation of probabilistically weak and strong solutions  of the stochastic total variation flow",
    "abstract": "We propose a fully practical numerical scheme for the simulation of the\nstochastic total variation flow (STFV). The approximation is based on a stable\ntime-implicit finite element space-time approximation of a regularized STVF\nequation. The approximation also involves a finite dimensional discretization\nof the noise that makes the scheme fully implementable on physical hardware. We\nshow that the proposed numerical scheme converges to a solution that is defined\nin the sense of stochastic variational inequalities (SVIs). As a by product of\nour convergence analysis we provide a generalization of the concept of\nprobabilistically weak solutions of stochastic partial differential equation\n(SPDEs) to the setting of SVIs. We also prove convergence of the numerical\nscheme to a probabilistically strong solution in probability if pathwise\nuniqueness holds. We perform numerical simulations to illustrate the behavior\nof the proposed numerical scheme {as well as its non-conforming variant} in the\ncontext of image denoising.",
    "descriptor": "",
    "authors": [
      "\u013dubom\u00edr Ba\u0148as",
      "Martin Ondrej\u00e1t"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.01968"
  },
  {
    "id": "arXiv:2205.01969",
    "title": "Positional Accuracy Assessment of Historical Google Earth Imagery",
    "abstract": "Google Earth is the most popular virtual globe in use today. Given its\npopularity and usefulness, most users do not pay close attention to the\npositional accuracy of the imagery, and there is limited information on the\nsubject. This study evaluates the horizontal accuracy of historical GE imagery\nat four epochs between year 2000 and 2018, and the vertical accuracy of its\nelevation data within Lagos State in Nigeria, West Africa. The horizontal\naccuracies of the images were evaluated by comparison with a very high\nresolution (VHR) digital orthophoto while the vertical accuracy was assessed by\ncomparison with a network of 558 ground control points. The GE elevations were\nalso compared to elevation data from two readily available 30m digital\nelevation models (DEMs), the Shuttle Radar Topography Mission (SRTM) v3.0 and\nthe Advanced Land Observing Satellite World 3D (AW3D) DEM v2.1. The most recent\nGE imagery (year 2018) was the most accurate while year 2000 was the least\naccurate. This shows a continuous enhancement in the accuracy and reliability\nof satellite imagery data sources which form the source of Google Earth data.\nIn terms of the vertical accuracy, GE elevation data had the highest RMSE of\n6.213m followed by AW3D with an RMSE of 4.388m and SRTM with an RMSE of 3.682m.\nAlthough the vertical accuracy of SRTM and AW3D are superior, Google Earth\nstill presents clear advantages in terms of its ease of use and contextual\nawareness.",
    "descriptor": "\nComments: 36 pages\n",
    "authors": [
      "Peter C. Nwilo.",
      "Chukwuma J. Okolie",
      "Johanson C. Onyegbula",
      "Ikenna D. Arungwa",
      "Owolabi Q. Ayoade",
      "Olagoke E. Daramola",
      "Michael J. Orji",
      "Ikechukwu D. Maduako",
      "Imeime I. Uyo"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.01969"
  },
  {
    "id": "arXiv:2205.01970",
    "title": "Nonstationary Bandit Learning via Predictive Sampling",
    "abstract": "We propose predictive sampling as an approach to selecting actions that\nbalance between exploration and exploitation in nonstationary bandit\nenvironments. When specialized to stationary environments, predictive sampling\nis equivalent to Thompson sampling. However, predictive sampling is effective\nacross a range of nonstationary environments in which Thompson sampling\nsuffers. We establish a general information-theoretic bound on the Bayesian\nregret of predictive sampling. We then specialize this bound to study a\nmodulated Bernoulli bandit environment. Our analysis highlights a key advantage\nof predictive sampling over Thompson sampling: predictive sampling\ndeprioritizes investments in exploration where acquired information will\nquickly become less relevant.",
    "descriptor": "",
    "authors": [
      "Yueyang Liu",
      "Benjamin Van Roy",
      "Kuang Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.01970"
  },
  {
    "id": "arXiv:2205.01972",
    "title": "Sequencer: Deep LSTM for Image Classification",
    "abstract": "In recent computer vision research, the advent of the Vision Transformer\n(ViT) has rapidly revolutionized various architectural design efforts: ViT\nachieved state-of-the-art image classification performance using self-attention\nfound in natural language processing, and MLP-Mixer achieved competitive\nperformance using simple multi-layer perceptrons. In contrast, several studies\nhave also suggested that carefully redesigned convolutional neural networks\n(CNNs) can achieve advanced performance comparable to ViT without resorting to\nthese new ideas. Against this background, there is growing interest in what\ninductive bias is suitable for computer vision. Here we propose Sequencer, a\nnovel and competitive architecture alternative to ViT that provides a new\nperspective on these issues. Unlike ViTs, Sequencer models long-range\ndependencies using LSTMs rather than self-attention layers. We also propose a\ntwo-dimensional version of Sequencer module, where an LSTM is decomposed into\nvertical and horizontal LSTMs to enhance performance. Despite its simplicity,\nseveral experiments demonstrate that Sequencer performs impressively well:\nSequencer2D-L, with 54M parameters, realizes 84.6\\% top-1 accuracy on only\nImageNet-1K. Not only that, we show that it has good transferability and the\nrobust resolution adaptability on double resolution-band.",
    "descriptor": "",
    "authors": [
      "Yuki Tatsunami",
      "Masato Taki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01972"
  },
  {
    "id": "arXiv:2205.01973",
    "title": "V'CER: Efficient Certificate Validation in Constrained Networks",
    "abstract": "We address the challenging problem of efficient trust establishment in\nconstrained networks, i.e., networks that are composed of a large and dynamic\nset of (possibly heterogeneous) devices with limited bandwidth, connectivity,\nstorage, and computational capabilities. Constrained networks are an integral\npart of many emerging application domains, from IoT meshes to satellite\nnetworks. A particularly difficult challenge is how to enforce timely\nrevocation of compromised or faulty devices. Unfortunately, current solutions\nand techniques cannot cope with idiosyncrasies of constrained networks, since\nthey mandate frequent real-time communication with centralized entities,\nstorage and maintenance of large amounts of revocation information, and incur\nconsiderable bandwidth overhead.\nTo address the shortcomings of existing solutions, we design V'CER, a secure\nand efficient scheme for certificate validation that augments and benefits a\nPKI for constrained networks. V'CER utilizes unique features of Sparse Merkle\nTrees (SMTs) to perform lightweight revocation checks, while enabling\ncollaborative operations among devices to keep them up-to-date when\nconnectivity to external authorities is limited. V'CER can complement any PKI\nscheme to increase its flexibility and applicability, while ensuring fast\ndissemination of validation information independent of the network routing or\ntopology. V'CER requires under 3KB storage per node covering 106 certificates.\nWe developed and deployed a prototype of V'CER on an in-orbit satellite and our\nlarge-scale simulations demonstrate that V'CER decreases the number of requests\nfor updates from external authorities by over 93%, when nodes are\nintermittently connected.",
    "descriptor": "\nComments: 18 pages, 7 figures, to be published at USENIX Security 2022\n",
    "authors": [
      "David Koisser",
      "Patrick Jauernig",
      "Gene Tsudik",
      "Ahmad-Reza Sadeghi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.01973"
  },
  {
    "id": "arXiv:2205.01975",
    "title": "Aligning to Social Norms and Values in Interactive Narratives",
    "abstract": "We focus on creating agents that act in alignment with socially beneficial\nnorms and values in interactive narratives or text-based games -- environments\nwherein an agent perceives and interacts with a world through natural language.\nSuch interactive agents are often trained via reinforcement learning to\noptimize task performance, even when such rewards may lead to agent behaviors\nthat violate societal norms -- causing harm either to the agent itself or other\nentities in the environment. Social value alignment refers to creating agents\nwhose behaviors conform to expected moral and social norms for a given context\nand group of people -- in our case, it means agents that behave in a manner\nthat is less harmful and more beneficial for themselves and others.\nWe build on the Jiminy Cricket benchmark (Hendrycks et al. 2021), a set of 25\nannotated interactive narratives containing thousands of morally salient\nscenarios covering everything from theft and bodily harm to altruism. We\nintroduce the GALAD (Game-value ALignment through Action Distillation) agent\nthat uses the social commonsense knowledge present in specially trained\nlanguage models to contextually restrict its action space to only those actions\nthat are aligned with socially beneficial values. An experimental study shows\nthat the GALAD agent makes decisions efficiently enough to improve\nstate-of-the-art task performance by 4% while reducing the frequency of\nsocially harmful behaviors by 25% compared to strong contemporary value\nalignment approaches.",
    "descriptor": "\nComments: In Proceedings of NAACL-2022\n",
    "authors": [
      "Prithviraj Ammanabrolu",
      "Liwei Jiang",
      "Maarten Sap",
      "Hannaneh Hajishirzi",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01975"
  },
  {
    "id": "arXiv:2205.01977",
    "title": "Collision Resolution with Deep Reinforcement Learning for Random Access  in Machine-Type Communication",
    "abstract": "Grant-free random access (RA) techniques are suitable for machine-type\ncommunication (MTC) networks but they need to be adaptive to the MTC traffic,\nwhich is different from the human-type communication. Conventional RA protocols\nsuch as exponential backoff (EB) schemes for slotted-ALOHA suffer from a high\nnumber of collisions and they are not directly applicable to the MTC traffic\nmodels. In this work, we propose to use multi-agent deep Q-network (DQN) with\nparameter sharing to find a single policy applied to all machine-type devices\n(MTDs) in the network to resolve collisions. Moreover, we consider binary\nbroadcast feedback common to all devices to reduce signalling overhead. We\ncompare the performance of our proposed DQN-RA scheme with EB schemes for up to\n500 MTDs and show that the proposed scheme outperforms EB policies and provides\na better balance between throughput, delay and collision rate",
    "descriptor": "\nComments: 6 pages, 7 Figure, accepted in the proceedings of IEEE VTC Spring-2022 Workshops\n",
    "authors": [
      "Muhammad Awais Jadoon",
      "Adriano Pastore",
      "Monica Navarro"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.01977"
  },
  {
    "id": "arXiv:2205.01979",
    "title": "ASP-Based Declarative Process Mining",
    "abstract": "We put forward Answer Set Programming (ASP) as a solution approach for three\nclassical problems in Declarative Process Mining: Log Generation, Query\nChecking, and Conformance Checking. These problems correspond to different ways\nof analyzing business processes under execution, starting from sequences of\nrecorded events, a.k.a. event logs. We tackle them in their data-aware variant,\ni.e., by considering events that carry a payload (set of attribute-value\npairs), in addition to the performed activity, specifying processes\ndeclaratively with an extension of linear-time temporal logic over finite\ntraces (LTLf). The data-aware setting is significantly more challenging than\nthe control-flow one: Query Checking is still open, while the existing\napproaches for the other two problems do not scale well. The contributions of\nthe work include an ASP encoding schema for the three problems, their solution,\nand experiments showing the feasibility of the approach.",
    "descriptor": "",
    "authors": [
      "Francesco Chiariello",
      "Fabrizio Maria Maggi",
      "Fabio Patrizi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01979"
  },
  {
    "id": "arXiv:2205.01980",
    "title": "EqVIO: An Equivariant Filter for Visual Inertial Odometry",
    "abstract": "Visual Inertial Odometry (VIO) is the problem of estimating a robot's\ntrajectory by combining information from an inertial measurement unit (IMU) and\na camera, and is of great interest to the robotics community. This paper\ndevelops a novel Lie group symmetry for the VIO problem and applies the\nrecently proposed equivariant filter. The symmetry is shown to be compatible\nwith the invariance of the VIO reference frame, lead to exact linearisation of\nbias-free IMU dynamics, and provide equivariance of the visual measurement\nfunction. As a result, the equivariant filter (EqF) based on this Lie group is\na consistent estimator for VIO with lower linearisation error in the\npropagation of state dynamics and a higher order equivariant output\napproximation than standard formulations. Experimental results on the popular\nEuRoC and UZH-FPV datasets demonstrate that the proposed system outperforms\nother state-of-the-art VIO algorithms in terms of both speed and accuracy.",
    "descriptor": "\nComments: 21 pages, 8 figures, submitted to IEEE TRO\n",
    "authors": [
      "Pieter van Goor",
      "Robert Mahony"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.01980"
  },
  {
    "id": "arXiv:2205.01981",
    "title": "The Isabelle ENIGMA",
    "abstract": "We significantly improve the performance of the E automated theorem prover on\nthe Isabelle Sledgehammer problems by combining learning and theorem proving in\nseveral ways. In particular, we develop targeted versions of the ENIGMA\nguidance for the Isabelle problems, targeted versions of neural premise\nselection, and targeted strategies for E. The methods are trained in several\niterations over hundreds of thousands untyped and typed first-order problems\nextracted from Isabelle. Our final best single-strategy ENIGMA and premise\nselection system improves the best previous version of E by 25.3% in 15\nseconds, outperforming also all other previous ATP and SMT systems.",
    "descriptor": "\nComments: 21 pages, 12 tables, ITP 2022\n",
    "authors": [
      "Zarathustra A. Goertzel",
      "Jan Jakub\u016fv",
      "Cezary Kaliszyk",
      "Miroslav Ol\u0161\u00e1k",
      "Jelle Piepenbrock",
      "Josef Urban"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.01981"
  },
  {
    "id": "arXiv:2205.01982",
    "title": "Lifelong Ensemble Learning based on Multiple Representations for  Few-Shot Object Recognition",
    "abstract": "Service robots are integrating more and more into our daily lives to help us\nwith various tasks. In such environments, robots frequently face new objects\nwhile working in the environment and need to learn them in an open-ended\nfashion. Furthermore, such robots must be able to recognize a wide range of\nobject categories. In this paper, we present a lifelong ensemble learning\napproach based on multiple representations to address the few-shot object\nrecognition problem. In particular, we form ensemble methods based on deep\nrepresentations and handcrafted 3D shape descriptors. To facilitate lifelong\nlearning, each approach is equipped with a memory unit for storing and\nretrieving object information instantly. The proposed model is suitable for\nopen-ended learning scenarios where the number of 3D object categories is not\nfixed and can grow over time. We have performed extensive sets of experiments\nto assess the performance of the proposed approach in offline, and open-ended\nscenarios. For the evaluation purpose, in addition to real object datasets, we\ngenerate a large synthetic household objects dataset consisting of 27000 views\nof 90 objects. Experimental results demonstrate the effectiveness of the\nproposed method on 3D object recognition tasks, as well as its superior\nperformance over the state-of-the-art approaches. Additionally, we demonstrated\nthe effectiveness of our approach in both simulated and real-robot settings,\nwhere the robot rapidly learned new categories from limited examples.",
    "descriptor": "",
    "authors": [
      "Hamidreza Kasaei",
      "Songsong Xiong"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01982"
  },
  {
    "id": "arXiv:2205.01985",
    "title": "Sampling from the ferromagnetic Ising model with external fields",
    "abstract": "We study the sampling problem for ferromagnetic Ising models with consistent\nexternal fields. We show that the edge-flipping dynamics for a corresponding\nweighted random cluster model is rapidly mixing. Consequences include rapid\nmixing of the Swendsen-Wang dynamics and perfect samplers for both models.",
    "descriptor": "",
    "authors": [
      "Weiming Feng",
      "Heng Guo",
      "Jiaheng Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2205.01985"
  },
  {
    "id": "arXiv:2205.01987",
    "title": "ON-TRAC Consortium Systems for the IWSLT 2022 Dialect and Low-resource  Speech Translation Tasks",
    "abstract": "This paper describes the ON-TRAC Consortium translation systems developed for\ntwo challenge tracks featured in the Evaluation Campaign of IWSLT 2022:\nlow-resource and dialect speech translation. For the Tunisian Arabic-English\ndataset (low-resource and dialect tracks), we build an end-to-end model as our\njoint primary submission, and compare it against cascaded models that leverage\na large fine-tuned wav2vec 2.0 model for ASR. Our results show that in our\nsettings pipeline approaches are still very competitive, and that with the use\nof transfer learning, they can outperform end-to-end models for speech\ntranslation (ST). For the Tamasheq-French dataset (low-resource track) our\nprimary submission leverages intermediate representations from a wav2vec 2.0\nmodel trained on 234 hours of Tamasheq audio, while our contrastive model uses\na French phonetic transcription of the Tamasheq audio as input in a Conformer\nspeech translation architecture jointly trained on automatic speech\nrecognition, ST and machine translation losses. Our results highlight that\nself-supervised models trained on smaller sets of target data are more\neffective to low-resource end-to-end ST fine-tuning, compared to large\noff-the-shelf models. Results also illustrate that even approximate phonetic\ntranscriptions can improve ST scores.",
    "descriptor": "\nComments: IWSLT 2022 system paper\n",
    "authors": [
      "Marcely Zanon Boito",
      "John Ortega",
      "Hugo Riguidel",
      "Antoine Laurent",
      "Lo\u00efc Barrault",
      "Fethi Bougares",
      "Firas Chaabani",
      "Ha Nguyen",
      "Florentin Barbier",
      "Souhir Gahbiche",
      "Yannick Est\u00e8ve"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.01987"
  },
  {
    "id": "arXiv:2205.01988",
    "title": "Modelling calibration uncertainty in networks of environmental sensors",
    "abstract": "Networks of low-cost sensors are becoming ubiquitous, but often suffer from\nlow accuracies and drift. Regular colocation with reference sensors allows\nrecalibration but is often complicated and expensive. Alternatively the\ncalibration can be transferred using low-cost, mobile sensors, often at very\nlow cost. However inferring appropriate estimates of the calibration functions\n(with uncertainty) for the network of sensors becomes difficult, especially as\nthe network of visits by the mobile, low-cost sensors becomes large. We propose\na variational approach to model the calibration across the network of sensors.\nWe demonstrate the approach on both synthetic and real air pollution data, and\nfind it can perform better than the state of the art (multi-hop calibration).\nWe extend it to categorical data, combining classifications of insects by\nnon-expert citizen scientists. Achieving uncertainty-quantified calibration has\nbeen one of the major barriers to low-cost sensor deployment and\ncitizen-science research. We hope that the methods described will enable such\nprojects.",
    "descriptor": "\nComments: 31 pages (23 pages of content, 4 pages of references, 4 supplementary). 11 figures. 4 tables. Submitted to Journal of the Royal Statistical Society. Series C\n",
    "authors": [
      "Michael Thomas Smith",
      "Magnus Ross",
      "Joel Ssematimba",
      "Pablo A. Alvarado",
      "Mauricio Alverez",
      "Engineer Bainomugisha",
      "Richard Wilkinson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01988"
  },
  {
    "id": "arXiv:2205.01989",
    "title": "MM-Claims: A Dataset for Multimodal Claim Detection in Social Media",
    "abstract": "In recent years, the problem of misinformation on the web has become\nwidespread across languages, countries, and various social media platforms.\nAlthough there has been much work on automated fake news detection, the role of\nimages and their variety are not well explored. In this paper, we investigate\nthe roles of image and text at an earlier stage of the fake news detection\npipeline, called claim detection. For this purpose, we introduce a novel\ndataset, MM-Claims, which consists of tweets and corresponding images over\nthree topics: COVID-19, Climate Change and broadly Technology. The dataset\ncontains roughly 86000 tweets, out of which 3400 are labeled manually by\nmultiple annotators for the training and evaluation of multimodal models. We\ndescribe the dataset in detail, evaluate strong unimodal and multimodal\nbaselines, and analyze the potential and drawbacks of current models.",
    "descriptor": "\nComments: Accepted to Findings of NAACL 2022\n",
    "authors": [
      "Gullal S. Cheema",
      "Sherzod Hakimov",
      "Abdul Sittar",
      "Eric M\u00fcller-Budack",
      "Christian Otto",
      "Ralph Ewerth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.01989"
  },
  {
    "id": "arXiv:2205.01992",
    "title": "Wild Patterns Reloaded: A Survey of Machine Learning Security against  Training Data Poisoning",
    "abstract": "The success of machine learning is fueled by the increasing availability of\ncomputing power and large training datasets. The training data is used to learn\nnew models or update existing ones, assuming that it is sufficiently\nrepresentative of the data that will be encountered at test time. This\nassumption is challenged by the threat of poisoning, an attack that manipulates\nthe training data to compromise the model's performance at test time. Although\npoisoning has been acknowledged as a relevant threat in industry applications,\nand a variety of different attacks and defenses have been proposed so far, a\ncomplete systematization and critical review of the field is still missing. In\nthis survey, we provide a comprehensive systematization of poisoning attacks\nand defenses in machine learning, reviewing more than 200 papers published in\nthe field in the last 15 years. We start by categorizing the current threat\nmodels and attacks, and then organize existing defenses accordingly. While we\nfocus mostly on computer-vision applications, we argue that our systematization\nalso encompasses state-of-the-art attacks and defenses for other data\nmodalities. Finally, we discuss existing resources for research in poisoning,\nand shed light on the current limitations and open research questions in this\nresearch field.",
    "descriptor": "\nComments: 35 pages, submitted to ACM\n",
    "authors": [
      "Antonio Emanuele Cin\u00e0",
      "Kathrin Grosse",
      "Ambra Demontis",
      "Sebastiano Vascon",
      "Werner Zellinger",
      "Bernhard A. Moser",
      "Alina Oprea",
      "Battista Biggio",
      "Marcello Pelillo",
      "Fabio Roli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.01992"
  },
  {
    "id": "arXiv:2205.01996",
    "title": "EmoBank: Studying the Impact of Annotation Perspective and  Representation Format on Dimensional Emotion Analysis",
    "abstract": "We describe EmoBank, a corpus of 10k English sentences balancing multiple\ngenres, which we annotated with dimensional emotion metadata in the\nValence-Arousal-Dominance (VAD) representation format. EmoBank excels with a\nbi-perspectival and bi-representational design. On the one hand, we distinguish\nbetween writer's and reader's emotions, on the other hand, a subset of the\ncorpus complements dimensional VAD annotations with categorical ones based on\nBasic Emotions. We find evidence for the supremacy of the reader's perspective\nin terms of IAA and rating intensity, and achieve close-to-human performance\nwhen mapping between dimensional and categorical formats.",
    "descriptor": "\nComments: Originally published at EACL 2017. Revised version with fixed typos and an additional appendix featuring the original instructions of the dataset\n",
    "authors": [
      "Sven Buechel",
      "Udo Hahn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01996"
  },
  {
    "id": "arXiv:2205.01997",
    "title": "Impact of a DCT-driven Loss in Attention-based Knowledge-Distillation  for Scene Recognition",
    "abstract": "Knowledge Distillation (KD) is a strategy for the definition of a set of\ntransferability gangways to improve the efficiency of Convolutional Neural\nNetworks. Feature-based Knowledge Distillation is a subfield of KD that relies\non intermediate network representations, either unaltered or depth-reduced via\nmaximum activation maps, as the source knowledge. In this paper, we propose and\nanalyse the use of a 2D frequency transform of the activation maps before\ntransferring them. We pose that\\textemdash by using global image cues rather\nthan pixel estimates, this strategy enhances knowledge transferability in tasks\nsuch as scene recognition, defined by strong spatial and contextual\nrelationships between multiple and varied concepts. To validate the proposed\nmethod, an extensive evaluation of the state-of-the-art in scene recognition is\npresented. Experimental results provide strong evidences that the proposed\nstrategy enables the student network to better focus on the relevant image\nareas learnt by the teacher network, hence leading to better descriptive\nfeatures and higher transferred performance than every other state-of-the-art\nalternative. We publicly release the training and evaluation framework used\nalong this paper at\nthis http URL",
    "descriptor": "\nComments: Preprint under review in Elsevier Pattern Recognition Journal\n",
    "authors": [
      "Alejandro L\u00f3pez-Cifuentes",
      "Marcos Escudero-Vi\u00f1olo",
      "Jes\u00fas Besc\u00f3s",
      "Juan C. SanMiguel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01997"
  },
  {
    "id": "arXiv:2205.02001",
    "title": "Design of a novel Korean learning application for efficient  pronunciation correction",
    "abstract": "The Korean wave, which denotes the global popularity of South Korea's\ncultural economy, contributes to the increasing demand for the Korean language.\nHowever, as there does not exist any application for foreigners to learn\nKorean, this paper suggested a design of a novel Korean learning application.\nSpeech recognition, speech-to-text, and speech-to-waveform are the three key\nsystems in the proposed system. The Google API and the librosa library will\ntransform the user's voice into a sentence and MFCC. The software will then\ndisplay the user's phrase and answer, with mispronounced elements highlighted\nin red, allowing users to more easily recognize the incorrect parts of their\npronunciation. Furthermore, the Siamese network might utilize those translated\nspectrograms to provide a similarity score, which could subsequently be used to\noffer feedback to the user. Despite the fact that we were unable to collect\nsufficient foreigner data for this research, it is notable that we presented a\nnovel Korean pronunciation correction method for foreigners.",
    "descriptor": "",
    "authors": [
      "Minjong Cheon",
      "Minseon Kim",
      "Hanseon Joo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.02001"
  },
  {
    "id": "arXiv:2205.02003",
    "title": "Multi-subgoal Robot Navigation in Crowds with History Information and  Interactions",
    "abstract": "Robot navigation in dynamic environments shared with humans is an important\nbut challenging task, which suffers from performance deterioration as the crowd\ngrows. In this paper, multi-subgoal robot navigation approach based on deep\nreinforcement learning is proposed, which can reason about more comprehensive\nrelationships among all agents (robot and humans). Specifically, the next\nposition point is planned for the robot by introducing history information and\ninteractions in our work. Firstly, based on subgraph network, the history\ninformation of all agents is aggregated before encoding interactions through a\ngraph neural network, so as to improve the ability of the robot to anticipate\nthe future scenarios implicitly. Further consideration, in order to reduce the\nprobability of unreliable next position points, the selection module is\ndesigned after policy network in the reinforcement learning framework. In\naddition, the next position point generated from the selection module satisfied\nthe task requirements better than that obtained directly from the policy\nnetwork. The experiments demonstrate that our approach outperforms\nstate-of-the-art approaches in terms of both success rate and collision rate,\nespecially in crowded human environments.",
    "descriptor": "",
    "authors": [
      "Xinyi Yu",
      "Jianan Hu",
      "Yuehai Fan",
      "Wancai Zheng",
      "Linlin Ou"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.02003"
  },
  {
    "id": "arXiv:2205.02005",
    "title": "A Framework to Generate High-Quality Datapoints for Multiple Novel  Intent Detection",
    "abstract": "Systems like Voice-command based conversational agents are characterized by a\npre-defined set of skills or intents to perform user specified tasks. In the\ncourse of time, newer intents may emerge requiring retraining. However, the\nnewer intents may not be explicitly announced and need to be inferred\ndynamically. Thus, there are two important tasks at hand (a). identifying\nemerging new intents, (b). annotating data of the new intents so that the\nunderlying classifier can be retrained efficiently. The tasks become specially\nchallenging when a large number of new intents emerge simultaneously and there\nis a limited budget of manual annotation. In this paper, we propose MNID\n(Multiple Novel Intent Detection) which is a cluster based framework to detect\nmultiple novel intents with budgeted human annotation cost. Empirical results\non various benchmark datasets (of different sizes) demonstrate that MNID, by\nintelligently using the budget for annotation, outperforms the baseline methods\nin terms of accuracy and F1-score.",
    "descriptor": "\nComments: Accepted as Full Paper at Findings of NAACL, 2022\n",
    "authors": [
      "Ankan Mullick",
      "Sukannya Purkayastha",
      "Pawan Goyal",
      "Niloy Ganguly"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.02005"
  },
  {
    "id": "arXiv:2205.02007",
    "title": "A Computational Inflection for Scientific Discovery",
    "abstract": "We stand at the foot of a significant inflection in the trajectory of\nscientific discovery. As society continues on its fast-paced digital\ntransformation, so does humankind's collective scientific knowledge and\ndiscourse. We now read and write papers in digitized form, and a great deal of\nthe formal and informal processes of science are captured digitally --\nincluding papers, preprints and books, code and datasets, conference\npresentations, and interactions in social networks and communication platforms.\nThe transition has led to the growth of a tremendous amount of information,\nopening exciting opportunities for computational models and systems that\nanalyze and harness it. In parallel, exponential growth in data processing\npower has fueled remarkable advances in AI, including self-supervised neural\nmodels capable of learning powerful representations from large-scale\nunstructured text without costly human supervision. The confluence of societal\nand computational trends suggests that computer science is poised to ignite a\nrevolution in the scientific process itself.\nHowever, the explosion of scientific data, results and publications stands in\nstark contrast to the constancy of human cognitive capacity. While scientific\nknowledge is expanding with rapidity, our minds have remained static, with\nsevere limitations on the capacity for finding, assimilating and manipulating\ninformation. We propose a research agenda of task-guided knowledge retrieval,\nin which systems counter humans' bounded capacity by ingesting corpora of\nscientific knowledge and retrieving inspirations, explanations, solutions and\nevidence synthesized to directly augment human performance on salient tasks in\nscientific endeavors. We present initial progress on methods and prototypes,\nand lay out important opportunities and challenges ahead with computational\napproaches that have the potential to revolutionize science.",
    "descriptor": "",
    "authors": [
      "Tom Hope",
      "Doug Downey",
      "Oren Etzioni",
      "Daniel S. Weld",
      "Eric Horvitz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.02007"
  },
  {
    "id": "arXiv:2205.02013",
    "title": "A simple nonconforming tetrahedral element for the Stokes equations",
    "abstract": "In this paper we apply a nonconforming rotated bilinear tetrahedral element\nto the Stokes problem in $\\mathbb{R}^3$. We show that the element is stable in\ncombination with a piecewise linear, continuous, approximation of the pressure.\nThis gives an approximation similar to the well known continuous $P^2-P^1$\nTaylor$-$Hood element, but with fewer degrees of freedom. The element is a\nstable non-conforming low order element which fulfils Korn's inequality,\nleading to stability also in the case where the Stokes equations are written on\nstress form for use in the case of free surface flow.",
    "descriptor": "",
    "authors": [
      "Peter Hansbo",
      "Mats G. Larson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.02013"
  },
  {
    "id": "arXiv:2205.02014",
    "title": "On Continual Model Refinement in Out-of-Distribution Data Streams",
    "abstract": "Real-world natural language processing (NLP) models need to be continually\nupdated to fix the prediction errors in out-of-distribution (OOD) data streams\nwhile overcoming catastrophic forgetting. However, existing continual learning\n(CL) problem setups cannot cover such a realistic and complex scenario. In\nresponse to this, we propose a new CL problem formulation dubbed continual\nmodel refinement (CMR). Compared to prior CL settings, CMR is more practical\nand introduces unique challenges (boundary-agnostic and non-stationary\ndistribution shift, diverse mixtures of multiple OOD data clusters,\nerror-centric streams, etc.). We extend several existing CL approaches to the\nCMR setting and evaluate them extensively. For benchmarking and analysis, we\npropose a general sampling algorithm to obtain dynamic OOD data streams with\ncontrollable non-stationarity, as well as a suite of metrics measuring various\naspects of online performance. Our experiments and detailed analysis reveal the\npromise and challenges of the CMR problem, supporting that studying CMR in\ndynamic OOD streams can benefit the longevity of deployed NLP models in\nproduction.",
    "descriptor": "\nComments: Accepted to ACL 2022; Project website: this https URL\n",
    "authors": [
      "Bill Yuchen Lin",
      "Sida Wang",
      "Xi Victoria Lin",
      "Robin Jia",
      "Lin Xiao",
      "Xiang Ren",
      "Wen-tau Yih"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02014"
  },
  {
    "id": "arXiv:2205.02021",
    "title": "Max-Min $k$-Dispersion on a Convex Polygon",
    "abstract": "In this paper, we consider the following $k$-dispersion problem. Given a set\n$S$ of $n$ points placed in the plane in a convex position, and an integer $k$\n($0<k<n$), the objective is to compute a subset $S'\\subset S$ such that\n$|S'|=k$ and the minimum distance between a pair of points in $S'$ is\nmaximized. Based on the bounded search tree method we propose an exact\nfixed-parameter algorithm in $O(2^k(n^2\\log n+n(\\log^2 n)(\\log k)))$ time, for\nthis problem, where $k$ is the parameter. The proposed exact algorithm is\nbetter than the current best exact exponential algorithm\n[$n^{O(\\sqrt{k})}$-time algorithm by Akagi et al.,(2018)] whenever\n$k<c\\log^2{n}$ for some constant $c$. We then present an $O(\\log{n})$-time\n$\\frac{1}{2\\sqrt{2}}$-approximation algorithm for the problem when $k=3$ if the\npoints are given in convex position order.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Vishwanath R. Singireddy",
      "Manjanna Basappa"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2205.02021"
  },
  {
    "id": "arXiv:2205.02022",
    "title": "A Few Thousand Translations Go a Long Way! Leveraging Pre-trained Models  for African News Translation",
    "abstract": "Recent advances in the pre-training of language models leverage large-scale\ndatasets to create multilingual models. However, low-resource languages are\nmostly left out in these datasets. This is primarily because many widely spoken\nlanguages are not well represented on the web and therefore excluded from the\nlarge-scale crawls used to create datasets. Furthermore, downstream users of\nthese models are restricted to the selection of languages originally chosen for\npre-training. This work investigates how to optimally leverage existing\npre-trained models to create low-resource translation systems for 16 African\nlanguages. We focus on two questions: 1) How can pre-trained models be used for\nlanguages not included in the initial pre-training? and 2) How can the\nresulting translation models effectively transfer to new domains? To answer\nthese questions, we create a new African news corpus covering 16 languages, of\nwhich eight languages are not part of any existing evaluation dataset. We\ndemonstrate that the most effective strategy for transferring both to\nadditional languages and to additional domains is to fine-tune large\npre-trained models on small quantities of high-quality translation data.",
    "descriptor": "\nComments: Accepted to NAACL 2022\n",
    "authors": [
      "David Ifeoluwa Adelani",
      "Jesujoba Oluwadara Alabi",
      "Angela Fan",
      "Julia Kreutzer",
      "Xiaoyu Shen",
      "Machel Reid",
      "Dana Ruiter",
      "Dietrich Klakow",
      "Peter Nabende",
      "Ernie Chang",
      "Tajuddeen Gwadabe",
      "Freshia Sackey",
      "Bonaventure F. P. Dossou",
      "Chris Chinenye Emezue",
      "Colin Leong",
      "Michael Beukman",
      "Shamsuddeen Hassan Muhammad",
      "Guyo Dub Jarso",
      "Oreen Yousuf",
      "Andre Niyongabo Rubungo",
      "Gilles Hacheme",
      "Eric Peter Wairagala",
      "Muhammad Umair Nasir",
      "Benjamin Ayoade Ajibade",
      "Tunde Oluwaseyi Ajayi",
      "Yvonne Wambui Gitau",
      "Jade Abbott",
      "Mohamed Ahmed",
      "Millicent Ochieng",
      "Anuoluwapo Aremu",
      "Perez Ogayo",
      "Jonathan Mukiibi",
      "Fatoumata Ouoba Kabore",
      "Godson Koffi Kalipe",
      "Derguene Mbaye",
      "Allahsera Auguste Tapo",
      "Victoire Memdjokam Koagne",
      "Edwin Munkoh-Buabeng",
      "Valencia Wagner",
      "Idris Abdulmumin",
      "Ayodele Awokoya",
      "Happy Buzaaba",
      "Blessing Sibanda"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.02022"
  },
  {
    "id": "arXiv:2205.02023",
    "title": "Same Neurons, Different Languages: Probing Morphosyntax in Multilingual  Pre-trained Models",
    "abstract": "The success of multilingual pre-trained models is underpinned by their\nability to learn representations shared by multiple languages even in absence\nof any explicit supervision. However, it remains unclear how these models learn\nto generalise across languages. In this work, we conjecture that multilingual\npre-trained models can derive language-universal abstractions about grammar. In\nparticular, we investigate whether morphosyntactic information is encoded in\nthe same subset of neurons in different languages. We conduct the first\nlarge-scale empirical study over 43 languages and 14 morphosyntactic categories\nwith a state-of-the-art neuron-level probe. Our findings show that the\ncross-lingual overlap between neurons is significant, but its extent may vary\nacross categories and depends on language proximity and pre-training data size.",
    "descriptor": "\nComments: Accepted at NAACL 2022 (Main Conference)\n",
    "authors": [
      "Karolina Sta\u0144czak",
      "Edoardo Ponti",
      "Lucas Torroba Hennigen",
      "Ryan Cotterell",
      "Isabelle Augenstein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.02023"
  },
  {
    "id": "arXiv:2205.02028",
    "title": "TransRank: Self-supervised Video Representation Learning via  Ranking-based Transformation Recognition",
    "abstract": "Recognizing transformation types applied to a video clip (RecogTrans) is a\nlong-established paradigm for self-supervised video representation learning,\nwhich achieves much inferior performance compared to instance discrimination\napproaches (InstDisc) in recent works. However, based on a thorough comparison\nof representative RecogTrans and InstDisc methods, we observe the great\npotential of RecogTrans on both semantic-related and temporal-related\ndownstream tasks. Based on hard-label classification, existing RecogTrans\napproaches suffer from noisy supervision signals in pre-training. To mitigate\nthis problem, we developed TransRank, a unified framework for recognizing\nTransformations in a Ranking formulation. TransRank provides accurate\nsupervision signals by recognizing transformations relatively, consistently\noutperforming the classification-based formulation. Meanwhile, the unified\nframework can be instantiated with an arbitrary set of temporal or spatial\ntransformations, demonstrating good generality. With a ranking-based\nformulation and several empirical practices, we achieve competitive performance\non video retrieval and action recognition. Under the same setting, TransRank\nsurpasses the previous state-of-the-art method by 6.4% on UCF101 and 8.3% on\nHMDB51 for action recognition (Top1 Acc); improves video retrieval on UCF101 by\n20.4% (R@1). The promising results validate that RecogTrans is still a worth\nexploring paradigm for video self-supervised learning. Codes will be released\nat https://github.com/kennymckormick/TransRank.",
    "descriptor": "\nComments: CVPR 2022 Oral\n",
    "authors": [
      "Haodong Duan",
      "Nanxuan Zhao",
      "Kai Chen",
      "Dahua Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.02028"
  },
  {
    "id": "arXiv:2205.02029",
    "title": "CODE-MVP: Learning to Represent Source Code from Multiple Views with  Contrastive Pre-Training",
    "abstract": "Recent years have witnessed increasing interest in code representation\nlearning, which aims to represent the semantics of source code into distributed\nvectors. Currently, various works have been proposed to represent the complex\nsemantics of source code from different views, including plain text, Abstract\nSyntax Tree (AST), and several kinds of code graphs (e.g., Control/Data Flow\nGraph). However, most of them only consider a single view of source code\nindependently, ignoring the correspondences among different views. In this\npaper, we propose to integrate different views with the natural-language\ndescription of source code into a unified framework with Multi-View contrastive\nPre-training, and name our model as CODE-MVP. Specifically, we first extract\nmultiple code views using compiler tools, and learn the complementary\ninformation among them under a contrastive learning framework. Inspired by the\ntype checking in compilation, we also design a fine-grained type inference\nobjective in the pre-training. Experiments on three downstream tasks over five\ndatasets demonstrate the superiority of CODE-MVP when compared with several\nstate-of-the-art baselines. For example, we achieve 2.4/2.3/1.1 gain in terms\nof MRR/MAP/Accuracy metrics on natural language code retrieval, code\nsimilarity, and code defect detection tasks, respectively.",
    "descriptor": "\nComments: Accepted by NAACL 2022\n",
    "authors": [
      "Xin Wang",
      "Yasheng Wang",
      "Yao Wan",
      "Jiawei Wang",
      "Pingyi Zhou",
      "Li Li",
      "Hao Wu",
      "Jin Liu"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.02029"
  },
  {
    "id": "arXiv:2205.02031",
    "title": "Self-Supervised Super-Resolution for Multi-Exposure Push-Frame  Satellites",
    "abstract": "Modern Earth observation satellites capture multi-exposure bursts of\npush-frame images that can be super-resolved via computational means. In this\nwork, we propose a super-resolution method for such multi-exposure sequences, a\nproblem that has received very little attention in the literature. The proposed\nmethod can handle the signal-dependent noise in the inputs, process sequences\nof any length, and be robust to inaccuracies in the exposure times.\nFurthermore, it can be trained end-to-end with self-supervision, without\nrequiring ground truth high resolution frames, which makes it especially suited\nto handle real data. Central to our method are three key contributions: i) a\nbase-detail decomposition for handling errors in the exposure times, ii) a\nnoise-level-aware feature encoding for improved fusion of frames with varying\nsignal-to-noise ratio and iii) a permutation invariant fusion strategy by\ntemporal pooling operators. We evaluate the proposed method on synthetic and\nreal data and show that it outperforms by a significant margin existing\nsingle-exposure approaches that we adapted to the multi-exposure case.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Ngoc Long Nguyen",
      "J\u00e9r\u00e9my Anger",
      "Axel Davy",
      "Pablo Arias",
      "Gabriele Facciolo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.02031"
  },
  {
    "id": "arXiv:2205.02033",
    "title": "How Does Author Affiliation Affect Preprint Citation Count? Analyzing  Citation Bias at the Institution and Country Level",
    "abstract": "Citing is an important aspect of scientific discourse and important for\nquantifying the scientific impact quantification of researchers. Previous works\nobserved that citations are made not only based on the pure scholarly\ncontributions but also based on non-scholarly attributes, such as the\naffiliation or gender of authors. In this way, citation bias is produced.\nExisting works, however, have not analyzed preprints with respect to citation\nbias, although they play an increasingly important role in modern scholarly\ncommunication. In this paper, we investigate whether preprints are affected by\ncitation bias with respect to the author affiliation. We measure citation bias\nfor bioRxiv preprints and their publisher versions at the institution level and\ncountry level, using the Lorenz curve and Gini coefficient. This allows us to\nmitigate the effects of confounding factors and see whether or not citation\nbiases related to author affiliation have an increased effect on preprint\ncitations. We observe consistent higher Gini coefficients for preprints than\nthose for publisher versions. Thus, we can confirm that citation bias exists\nand that it is more severe in case of preprints. As preprints are on the rise,\naffiliation-based citation bias is, thus, an important topic not only for\nauthors (e.g., when deciding what to cite), but also to people and institutions\nthat use citations for scientific impact quantification (e.g., funding agencies\ndeciding about funding based on citation counts).",
    "descriptor": "\nComments: Accepted at the ACM/IEEE Joint Conference on Digital Libraries (JCDL) 2022\n",
    "authors": [
      "Chifumi Nishioka",
      "Michael F\u00e4rber",
      "Tarek Saier"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2205.02033"
  },
  {
    "id": "arXiv:2205.02035",
    "title": "Masked Summarization to Generate Factually Inconsistent Summaries for  Improved Factual Consistency Checking",
    "abstract": "Despite the recent advances in abstractive summarization systems, it is still\ndifficult to determine whether a generated summary is factual consistent with\nthe source text. To this end, the latest approach is to train a factual\nconsistency classifier on factually consistent and inconsistent summaries.\nLuckily, the former is readily available as reference summaries in existing\nsummarization datasets. However, generating the latter remains a challenge, as\nthey need to be factually inconsistent, yet closely relevant to the source text\nto be effective. In this paper, we propose to generate factually inconsistent\nsummaries using source texts and reference summaries with key information\nmasked. Experiments on seven benchmark datasets demonstrate that factual\nconsistency classifiers trained on summaries generated using our method\ngenerally outperform existing models and show a competitive correlation with\nhuman judgments. We also analyze the characteristics of the summaries generated\nusing our method. We will release the pre-trained model and the code at\nhttps://github.com/hwanheelee1993/MFMA.",
    "descriptor": "\nComments: NAACL 2022 Findings\n",
    "authors": [
      "Hwanhee Lee",
      "Kang Min Yoo",
      "Joonsuk Park",
      "Hwaran Lee",
      "Kyomin Jung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.02035"
  },
  {
    "id": "arXiv:2205.02041",
    "title": "Who Will Support My Project? Interactive Search of Potential  Crowdfunding Investors Through InSearch",
    "abstract": "Crowdfunding provides project founders with a convenient way to reach online\ninvestors. However, it is challenging for founders to find the most potential\ninvestors and successfully raise money for their projects on crowdfunding\nplatforms. A few machine learning based methods have been proposed to recommend\ninvestors' interest in a specific crowdfunding project, but they fail to\nprovide project founders with explanations in detail for these recommendations,\nthereby leading to an erosion of trust in predicted investors. To help\ncrowdfunding founders find truly interested investors, we conducted\nsemi-structured interviews with four crowdfunding experts and presents\ninSearch, a visual analytic system. inSearch allows founders to search for\ninvestors interactively on crowdfunding platforms. It supports an effective\noverview of potential investors by leveraging a Graph Neural Network to model\ninvestor preferences. Besides, it enables interactive exploration and\ncomparison of the temporal evolution of different investors' investment\ndetails.",
    "descriptor": "",
    "authors": [
      "Zhang",
      "Songheng",
      "Wang",
      "Yong",
      "Haotian",
      "Zhang",
      "Wanyu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.02041"
  },
  {
    "id": "arXiv:2205.02046",
    "title": "DNA Pre-alignment Filter using Processing Near Racetrack Memory",
    "abstract": "Recent DNA pre-alignment filter designs employ DRAM for storing the reference\ngenome and its associated meta-data. However, DRAM incurs increasingly high\nenergy consumption background and refresh energy as devices scale. To overcome\nthis problem, this paper explores a design with racetrack memory (RTM)--an\nemerging non-volatile memory that promises higher storage density, faster\naccess latency, and lower energy consumption. Multi-bit storage cells in RTM\nare inherently sequential and thus require data placement strategies to\nmitigate the performance and energy impacts of shifting during data accesses.\nWe propose a near-memory pre-alignment filter with a novel data mapping and\nseveral shift reduction strategies designed explicitly for RTM. On a set of\nfour input genomes from the 1000 Genome Project, our approach improves\nperformance and energy efficiency by 68% and 52%, respectively, compared to the\nstate of the art proposed DRAM-based architecture.",
    "descriptor": "",
    "authors": [
      "Fazal Hameed",
      "Asif Ali Khan",
      "Sebastien Ollivier",
      "Alex K. Jones",
      "Jeronimo Castrillon"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2205.02046"
  },
  {
    "id": "arXiv:2205.02047",
    "title": "Hyperbolic Relevance Matching for Neural Keyphrase Extraction",
    "abstract": "Keyphrase extraction is a fundamental task in natural language processing and\ninformation retrieval that aims to extract a set of phrases with important\ninformation from a source document. Identifying important keyphrase is the\ncentral component of the keyphrase extraction task, and its main challenge is\nhow to represent information comprehensively and discriminate importance\naccurately. In this paper, to address these issues, we design a new hyperbolic\nmatching model (HyperMatch) to represent phrases and documents in the same\nhyperbolic space and explicitly estimate the phrase-document relevance via the\nPoincar\\'e distance as the important score of each phrase. Specifically, to\ncapture the hierarchical syntactic and semantic structure information,\nHyperMatch takes advantage of the hidden representations in multiple layers of\nRoBERTa and integrates them as the word embeddings via an adaptive mixing\nlayer. Meanwhile, considering the hierarchical structure hidden in the\ndocument, HyperMatch embeds both phrases and documents in the same hyperbolic\nspace via a hyperbolic phrase encoder and a hyperbolic document encoder. This\nstrategy can further enhance the estimation of phrase-document relevance due to\nthe good properties of hyperbolic space. In this setting, the keyphrase\nextraction can be taken as a matching problem and effectively implemented by\nminimizing a hyperbolic margin-based triplet loss. Extensive experiments are\nconducted on six benchmarks and demonstrate that HyperMatch outperforms the\nstate-of-the-art baselines.",
    "descriptor": "\nComments: 12 pages, 3 figures, Accepted by NAACL 2022 (main conference)\n",
    "authors": [
      "Mingyang Song",
      "Yi Feng",
      "Liping Jing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.02047"
  },
  {
    "id": "arXiv:2205.02048",
    "title": "Few-Shot Document-Level Relation Extraction",
    "abstract": "We present FREDo, a few-shot document-level relation extraction (FSDLRE)\nbenchmark. As opposed to existing benchmarks which are built on sentence-level\nrelation extraction corpora, we argue that document-level corpora provide more\nrealism, particularly regarding none-of-the-above (NOTA) distributions.\nTherefore, we propose a set of FSDLRE tasks and construct a benchmark based on\ntwo existing supervised learning data sets, DocRED and sciERC. We adapt the\nstate-of-the-art sentence-level method MNAV to the document-level and develop\nit further for improved domain adaptation. We find FSDLRE to be a challenging\nsetting with interesting new characteristics such as the ability to sample NOTA\ninstances from the support set. The data, code, and trained models are\navailable online (https://github.com/nicpopovic/FREDo).",
    "descriptor": "\nComments: Accepted to NAACL2022\n",
    "authors": [
      "Nicholas Popovic",
      "Michael F\u00e4rber"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02048"
  },
  {
    "id": "arXiv:2205.02049",
    "title": "Self-Supervised Learning for Invariant Representations from  Multi-Spectral and SAR Images",
    "abstract": "Self-Supervised learning (SSL) has become the new state-of-art in several\ndomain classification and segmentation tasks. Of these, one popular category in\nSSL is distillation networks such as BYOL. This work proposes RSDnet, which\napplies the distillation network (BYOL) in the remote sensing (RS) domain where\ndata is non-trivially different from natural RGB images. Since Multi-spectral\n(MS) and synthetic aperture radar (SAR) sensors provide varied spectral and\nspatial resolution information, we utilised them as an implicit augmentation to\nlearn invariant feature embeddings. In order to learn RS based invariant\nfeatures with SSL, we trained RSDnet in two ways, i.e., single channel feature\nlearning and three channel feature learning. This work explores the usefulness\nof single channel feature learning from random MS and SAR bands compared to the\ncommon notion of using three or more bands. In our linear evaluation, these\nsingle channel features reached a 0.92 F1 score on the EuroSAT classification\ntask and 59.6 mIoU on the DFC segmentation task for certain single bands. We\nalso compared our results with ImageNet weights and showed that the RS based\nSSL model outperforms the supervised ImageNet based model. We further explored\nthe usefulness of multi-modal data compared to single modality data, and it is\nshown that utilising MS and SAR data learn better invariant representations\nthan utilising only MS data.",
    "descriptor": "\nComments: Under review at IEEE JSTAR\n",
    "authors": [
      "Pallavi Jain",
      "Bianca Schoen-Phelan",
      "Robert Ross"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.02049"
  },
  {
    "id": "arXiv:2205.02050",
    "title": "A Perfect Sampler for Hypergraph Independent Sets",
    "abstract": "The problem of uniformly sampling hypergraph independent sets is revisited.\nWe design an efficient perfect sampler for the problem under a similar\ncondition to the asymmetric Lov\\'asz Local Lemma. When specialized to\n$d$-regular $k$-uniform hypergraphs on $n$ vertices, our sampler terminates in\nexpected $O(n\\log n)$ time provided $d\\le c\\cdot 2^{\\frac{k}{2}}$ where $c>0$\nis a constant, matching the rapid mixing condition for Glauber dynamics in\n[HSZ19]. The analysis of our algorithm is simple and clean.",
    "descriptor": "\nComments: To appear in ICALP'22\n",
    "authors": [
      "Guoliang Qiu",
      "Yanheng Wang",
      "Chihao Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2205.02050"
  },
  {
    "id": "arXiv:2205.02052",
    "title": "Exploring Rawlsian Fairness for K-Means Clustering",
    "abstract": "We conduct an exploratory study that looks at incorporating John Rawls' ideas\non fairness into existing unsupervised machine learning algorithms. Our focus\nis on the task of clustering, specifically the k-means clustering algorithm. To\nthe best of our knowledge, this is the first work that uses Rawlsian ideas in\nclustering. Towards this, we attempt to develop a postprocessing technique\ni.e., one that operates on the cluster assignment generated by the standard\nk-means clustering algorithm. Our technique perturbs this assignment over a\nnumber of iterations to make it fairer according to Rawls' difference principle\nwhile minimally affecting the overall utility. As the first step, we consider\ntwo simple perturbation operators -- $\\mathbf{R_1}$ and $\\mathbf{R_2}$ -- that\nreassign examples in a given cluster assignment to new clusters; $\\mathbf{R_1}$\nassigning a single example to a new cluster, and $\\mathbf{R_2}$ a pair of\nexamples to new clusters. Our experiments on a sample of the Adult dataset\ndemonstrate that both operators make meaningful perturbations in the cluster\nassignment towards incorporating Rawls' difference principle, with\n$\\mathbf{R_2}$ being more efficient than $\\mathbf{R_1}$ in terms of the number\nof iterations. However, we observe that there is still a need to design\noperators that make significantly better perturbations. Nevertheless, both\noperators provide good baselines for designing and comparing any future\noperator, and we hope our findings would aid future work in this direction.",
    "descriptor": "\nComments: Accepted at ICDSE 2021\n",
    "authors": [
      "Stanley Simoes",
      "Deepak P",
      "Muiris MacCarthaigh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02052"
  },
  {
    "id": "arXiv:2205.02054",
    "title": "Measuring and Improving Compositional Generalization in Text-to-SQL via  Component Alignment",
    "abstract": "In text-to-SQL tasks -- as in much of NLP -- compositional generalization is\na major challenge: neural networks struggle with compositional generalization\nwhere training and test distributions differ. However, most recent attempts to\nimprove this are based on word-level synthetic data or specific dataset splits\nto generate compositional biases. In this work, we propose a clause-level\ncompositional example generation method. We first split the sentences in the\nSpider text-to-SQL dataset into sub-sentences, annotating each sub-sentence\nwith its corresponding SQL clause, resulting in a new dataset Spider-SS. We\nthen construct a further dataset, Spider-CG, by composing Spider-SS\nsub-sentences in different combinations, to test the ability of models to\ngeneralize compositionally. Experiments show that existing models suffer\nsignificant performance degradation when evaluated on Spider-CG, even though\nevery sub-sentence is seen during training. To deal with this problem, we\nmodify a number of state-of-the-art models to train on the segmented data of\nSpider-SS, and we show that this method improves the generalization\nperformance.",
    "descriptor": "\nComments: To appear in Findings of NAACL 2022\n",
    "authors": [
      "Yujian Gan",
      "Xinyun Chen",
      "Qiuping Huang",
      "Matthew Purver"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.02054"
  },
  {
    "id": "arXiv:2205.02055",
    "title": "Planning a Cost-Effective Delay-Constrained Passive Optical Network for  5G Fronthaul",
    "abstract": "With the rapid growth in the telecommunications industry moving towards 5G\nand beyond (5GB) and the emergence of data-hungry and time-sensitive\napplications, Mobile Network Operators (MNOs) are faced with a considerable\nchallenge to keep up with these new demands. Cloud radio access network (CRAN)\nhas emerged as a cost-effective architecture that improves 5GB performance. The\nfronthaul segment of the CRAN necessitates a high-capacity and low-latency\nconnection. Optical technologies presented by Passive Optical Networks (PON)\nhave gained attention as a promising technology to meet the fronthaul\nchallenges. In this paper, we proposed an Integer Linear Program (ILP) that\noptimizes the total cost of ownership (TCO) for 5G using CRAN architecture\nunder different delay thresholds. We considered the Time and Wavelength\nDivision Multiplexing Passive Optical Network (TWDM-PON) as a fronthaul with\ndifferent splitting ratios.",
    "descriptor": "",
    "authors": [
      "Abdulhalim Fayad",
      "Manish Jha",
      "Tibor Cinkler",
      "Jacek Rak"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.02055"
  },
  {
    "id": "arXiv:2205.02056",
    "title": "On the Complexity of Majority Illusion in Social Networks",
    "abstract": "Majority illusion occurs in a social network when the majority of the network\nnodes belong to a certain type but each node's neighbours mostly belong to a\ndifferent type, therefore creating the wrong perception, i.e., the illusion,\nthat the majority type is different from the actual one. From a system\nengineering point of view, we want to devise algorithms to detect and,\ncrucially, correct this undesirable phenomenon. In this paper we initiate the\ncomputational study of majority illusion in social networks, providing\ncomplexity results for its occurrence and avoidance. Namely, we show that\nidentifying whether a network can be labelled such that majority illusion is\npresent, as well as the problem of removing an illusion by adding or deleting\nedges of the network, are NP-complete problems.",
    "descriptor": "",
    "authors": [
      "Umberto Grandi",
      "Grzegorz Lisowski",
      "M.S. Ramanujan",
      "Paolo Turrini"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2205.02056"
  },
  {
    "id": "arXiv:2205.02057",
    "title": "Reinforcement Learning for Improved Random Access in Delay-Constrained  Heterogeneous Wireless Networks",
    "abstract": "In this paper, we for the first time investigate the random access problem\nfor a delay-constrained heterogeneous wireless network. We begin with a simple\ntwo-device problem where two devices deliver delay-constrained traffic to an\naccess point (AP) via a common unreliable collision channel. By assuming that\none device (called Device 1) adopts ALOHA, we aim to optimize the random access\nscheme of the other device (called Device 2). The most intriguing part of this\nproblem is that Device 2 does not know the information of Device 1 but needs to\nmaximize the system timely throughput. We first propose a Markov Decision\nProcess (MDP) formulation to derive a model-based upper bound so as to quantify\nthe performance gap of certain random access schemes. We then utilize\nreinforcement learning (RL) to design an R-learning-based random access scheme,\ncalled tiny state-space R-learning random access (TSRA), which is subsequently\nextended for the tackling of the general multi-device problem. We carry out\nextensive simulations to show that the proposed TSRA simultaneously achieves\nhigher timely throughput, lower computation complexity, and lower power\nconsumption than the existing baseline--deep-reinforcement learning multiple\naccess (DLMA). This indicates that our proposed TSRA scheme is a promising\nmeans for efficient random access over massive mobile devices with limited\ncomputation and battery capabilities.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2103.14917\n",
    "authors": [
      "Lei Deng",
      "Danzhou Wu",
      "Zilong Liu",
      "Yijin Zhang",
      "Yunghsiang S. Han"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.02057"
  },
  {
    "id": "arXiv:2205.02058",
    "title": "SVTS: Scalable Video-to-Speech Synthesis",
    "abstract": "Video-to-speech synthesis (also known as lip-to-speech) refers to the\ntranslation of silent lip movements into the corresponding audio. This task has\nreceived an increasing amount of attention due to its self-supervised nature\n(i.e., can be trained without manual labelling) combined with the ever-growing\ncollection of audio-visual data available online. Despite these strong\nmotivations, contemporary video-to-speech works focus mainly on small- to\nmedium-sized corpora with substantial constraints in both vocabulary and\nsetting. In this work, we introduce a scalable video-to-speech framework\nconsisting of two components: a video-to-spectrogram predictor and a\npre-trained neural vocoder, which converts the mel-frequency spectrograms into\nwaveform audio. We achieve state-of-the art results for GRID and considerably\noutperform previous approaches on LRW. More importantly, by focusing on\nspectrogram prediction using a simple feedforward model, we can efficiently and\neffectively scale our method to very large and unconstrained datasets: To the\nbest of our knowledge, we are the first to show intelligible results on the\nchallenging LRS3 dataset.",
    "descriptor": "\nComments: submitted to INTERSPEECH 2022\n",
    "authors": [
      "Rodrigo Mira",
      "Alexandros Haliassos",
      "Stavros Petridis",
      "Bj\u00f6rn W. Schuller",
      "Maja Pantic"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.02058"
  },
  {
    "id": "arXiv:2205.02060",
    "title": "Estimation of Standard Auction Models",
    "abstract": "We provide efficient estimation methods for first- and second-price auctions\nunder independent (asymmetric) private values and partial observability. Given\na finite set of observations, each comprising the identity of the winner and\nthe price they paid in a sequence of identical auctions, we provide algorithms\nfor non-parametrically estimating the bid distribution of each bidder, as well\nas their value distributions under equilibrium assumptions. We provide\nfinite-sample estimation bounds which are uniform in that their error rates do\nnot depend on the bid/value distributions being estimated. Our estimation\nguarantees advance a body of work in Econometrics wherein only identification\nresults have been obtained, unless the setting is symmetric, parametric, or all\nbids are observable. Our guarantees also provide computationally and\nstatistically effective alternatives to classical techniques from reliability\ntheory. Finally, our results are immediately applicable to Dutch and English\nauctions.",
    "descriptor": "",
    "authors": [
      "Yeshwanth Cherapanamjeri",
      "Constantinos Daskalakis",
      "Andrew Ilyas",
      "Manolis Zampetakis"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.02060"
  },
  {
    "id": "arXiv:2205.02061",
    "title": "Creating Teams of Simple Agents for Specified Tasks: A Computational  Complexity Perspective",
    "abstract": "Teams of interacting and co-operating agents have been proposed as an\nefficient and robust alternative to monolithic centralized control for carrying\nout specified tasks in a variety of applications. A number of different team\nand agent architectures have been investigated, e.g., teams based on single vs\nmultiple behaviorally-distinct types of agents (homogeneous vs heterogeneous\nteams), simple vs complex agents, direct vs indirect agent-to-agent\ncommunication. A consensus is emerging that (1) heterogeneous teams composed of\nsimple agents that communicate indirectly are preferable and (2) automated\nmethods for verifying and designing such teams are necessary. In this paper, we\nuse computational complexity analysis to assess viable algorithmic options for\nsuch automated methods for various types of teams. Building on recent\ncomplexity analyses addressing related questions in swarm robotics, we prove\nthat automated team verification and design are by large both exact and\napproximate polynomial-time intractable in general for the most basic types of\nhomogeneous and heterogeneous teams consisting of simple agents that\ncommunicate indirectly. Our results suggest that tractability for these\nproblems must be sought relative to additional restrictions on teams, agents,\noperating environments, and tasks.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "T. Wareham"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2205.02061"
  },
  {
    "id": "arXiv:2205.02065",
    "title": "Mobile-URSONet: an Embeddable Neural Network for Onboard Spacecraft Pose  Estimation",
    "abstract": "Spacecraft pose estimation is an essential computer vision application that\ncan improve the autonomy of in-orbit operations. An ESA/Stanford competition\nbrought out solutions that seem hardly compatible with the constraints imposed\non spacecraft onboard computers. URSONet is among the best in the competition\nfor its generalization capabilities but at the cost of a tremendous number of\nparameters and high computational complexity. In this paper, we propose\nMobile-URSONet: a spacecraft pose estimation convolutional neural network with\n178 times fewer parameters while degrading accuracy by no more than four times\ncompared to URSONet.",
    "descriptor": "",
    "authors": [
      "Julien Posso",
      "Guy Bois",
      "Yvon Savaria"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.02065"
  },
  {
    "id": "arXiv:2205.02068",
    "title": "Compositional Task-Oriented Parsing as Abstractive Question Answering",
    "abstract": "Task-oriented parsing (TOP) aims to convert natural language into\nmachine-readable representations of specific tasks, such as setting an alarm. A\npopular approach to TOP is to apply seq2seq models to generate linearized parse\ntrees. A more recent line of work argues that pretrained seq2seq models are\nbetter at generating outputs that are themselves natural language, so they\nreplace linearized parse trees with canonical natural-language paraphrases that\ncan then be easily translated into parse trees, resulting in so-called\nnaturalized parsers. In this work we continue to explore naturalized semantic\nparsing by presenting a general reduction of TOP to abstractive question\nanswering that overcomes some limitations of canonical paraphrasing.\nExperimental results show that our QA-based technique outperforms\nstate-of-the-art methods in full-data settings while achieving dramatic\nimprovements in few-shot settings.",
    "descriptor": "\nComments: accepted at NAACL'22\n",
    "authors": [
      "Wenting Zhao",
      "Konstantine Arkoudas",
      "Weiqi Sun",
      "Claire Cardie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.02068"
  },
  {
    "id": "arXiv:2205.02069",
    "title": "Dual Branch Neural Network for Sea Fog Detection in Geostationary Ocean  Color Imager",
    "abstract": "Sea fog significantly threatens the safety of maritime activities. This paper\ndevelops a sea fog dataset (SFDD) and a dual branch sea fog detection network\n(DB-SFNet). We investigate all the observed sea fog events in the Yellow Sea\nand the Bohai Sea (118.1{\\deg}E-128.1{\\deg}E, 29.5{\\deg}N-43.8{\\deg}N) from\n2010 to 2020, and collect the sea fog images for each event from the\nGeostationary Ocean Color Imager (GOCI) to comprise the dataset SFDD. The\nlocation of the sea fog in each image in SFDD is accurately marked. The\nproposed dataset is characterized by a long-time span, large number of samples,\nand accurate labeling, that can substantially improve the robustness of various\nsea fog detection models. Furthermore, this paper proposes a dual branch sea\nfog detection network to achieve accurate and holistic sea fog detection. The\npoporsed DB-SFNet is composed of a knowledge extraction module and a dual\nbranch optional encoding decoding module. The two modules jointly extracts\ndiscriminative features from both visual and statistical domain. Experiments\nshow promising sea fog detection results with an F1-score of 0.77 and a\ncritical success index of 0.63. Compared with existing advanced deep learning\nnetworks, DB-SFNet is superior in detection performance and stability,\nparticularly in the mixed cloud and fog areas.",
    "descriptor": "",
    "authors": [
      "Yuan Zhou",
      "Keran Chen",
      "Xiaofeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.02069"
  },
  {
    "id": "arXiv:2205.02070",
    "title": "DeepPortraitDrawing: Generating Human Body Images from Freehand Sketches",
    "abstract": "Researchers have explored various ways to generate realistic images from\nfreehand sketches, e.g., for objects and human faces. However, how to generate\nrealistic human body images from sketches is still a challenging problem. It\nis, first because of the sensitivity to human shapes, second because of the\ncomplexity of human images caused by body shape and pose changes, and third\nbecause of the domain gap between realistic images and freehand sketches. In\nthis work, we present DeepPortraitDrawing, a deep generative framework for\nconverting roughly drawn sketches to realistic human body images. To encode\ncomplicated body shapes under various poses, we take a local-to-global\napproach. Locally, we employ semantic part auto-encoders to construct\npart-level shape spaces, which are useful for refining the geometry of an input\npre-segmented hand-drawn sketch. Globally, we employ a cascaded spatial\ntransformer network to refine the structure of body parts by adjusting their\nspatial locations and relative proportions. Finally, we use a global synthesis\nnetwork for the sketch-to-image translation task, and a face refinement network\nto enhance facial details. Extensive experiments have shown that given roughly\nsketched human portraits, our method produces more realistic images than the\nstate-of-the-art sketch-to-image synthesis techniques.",
    "descriptor": "",
    "authors": [
      "Xian Wu",
      "Chen Wang",
      "Hongbo Fu",
      "Ariel Shamir",
      "Song-Hai Zhang",
      "Shi-Min Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.02070"
  },
  {
    "id": "arXiv:2205.02071",
    "title": "ANUBIS: Review and Benchmark Skeleton-Based Action Recognition Methods  with a New Dataset",
    "abstract": "Skeleton-based action recognition, as a subarea of action recognition, is\nswiftly accumulating attention and popularity. The task is to recognize actions\nperformed by human articulation points. Compared with other data modalities, 3D\nhuman skeleton representations have extensive unique desirable characteristics,\nincluding succinctness, robustness, racial-impartiality, and many more. We aim\nto provide a roadmap for new and existing researchers a on the landscapes of\nskeleton-based action recognition for new and existing researchers. To this\nend, we present a review in the form of a taxonomy on existing works of\nskeleton-based action recognition. We partition them into four major\ncategories: (1) datasets; (2) extracting spatial features; (3) capturing\ntemporal patterns; (4) improving signal quality. For each method, we provide\nconcise yet informatively-sufficient descriptions. To promote more fair and\ncomprehensive evaluation on existing approaches of skeleton-based action\nrecognition, we collect ANUBIS, a large-scale human skeleton dataset. Compared\nwith previously collected dataset, ANUBIS are advantageous in the following\nfour aspects: (1) employing more recently released sensors; (2) containing\nnovel back view; (3) encouraging high enthusiasm of subjects; (4) including\nactions of the COVID pandemic era. Using ANUBIS, we comparably benchmark\nperformance of current skeleton-based action recognizers. At the end of this\npaper, we outlook future development of skeleton-based action recognition by\nlisting several new technical problems. We believe they are valuable to solve\nin order to commercialize skeleton-based action recognition in the near future.\nThe dataset of ANUBIS is available at:\nthis http URL",
    "descriptor": "",
    "authors": [
      "Zhenyue Qin",
      "Yang Liu",
      "Madhawa Perera",
      "Saeed Anwar",
      "Tom Gedeon",
      "Pan Ji",
      "Dongwoo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.02071"
  },
  {
    "id": "arXiv:2205.02079",
    "title": "SDF-based RGB-D Camera Tracking in Neural Scene Representations",
    "abstract": "We consider the problem of tracking the 6D pose of a moving RGB-D camera in a\nneural scene representation. Different such representations have recently\nemerged, and we investigate the suitability of them for the task of camera\ntracking. In particular, we propose to track an RGB-D camera using a signed\ndistance field-based representation and show that compared to density-based\nrepresentations, tracking can be sped up, which enables more robust and\naccurate pose estimates when computation time is limited.",
    "descriptor": "\nComments: Accepted to the \"Motion Planning with Implicit Neural Representations of Geometry\" Workshop at ICRA 2022\n",
    "authors": [
      "Leonard Bruns",
      "Fereidoon Zangeneh",
      "Patric Jensfelt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.02079"
  },
  {
    "id": "arXiv:2205.02084",
    "title": "Video Extrapolationin Space and Time",
    "abstract": "Novel view synthesis (NVS) and video prediction (VP) are typically considered\ndisjoint tasks in computer vision. However, they can both be seen as ways to\nobserve the spatial-temporal world: NVS aims to synthesize a scene from a new\npoint of view, while VP aims to see a scene from a new point of time. These two\ntasks provide complementary signals to obtain a scene representation, as\nviewpoint changes from spatial observations inform depth, and temporal\nobservations inform the motion of cameras and individual objects. Inspired by\nthese observations, we propose to study the problem of Video Extrapolation in\nSpace and Time (VEST). We propose a model that leverages the self-supervision\nand the complementary cues from both tasks, while existing methods can only\nsolve one of them. Experiments show that our method achieves performance better\nthan or comparable to several state-of-the-art NVS and VP methods on indoor and\noutdoor real-world datasets.",
    "descriptor": "\nComments: project website: this https URL\n",
    "authors": [
      "Yunzhi Zhang",
      "Jiajun wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.02084"
  },
  {
    "id": "arXiv:2205.02087",
    "title": "Hypercomplex Image-to-Image Translation",
    "abstract": "Image-to-image translation (I2I) aims at transferring the content\nrepresentation from an input domain to an output one, bouncing along different\ntarget domains. Recent I2I generative models, which gain outstanding results in\nthis task, comprise a set of diverse deep networks each with tens of million\nparameters. Moreover, images are usually three-dimensional being composed of\nRGB channels and common neural models do not take dimensions correlation into\naccount, losing beneficial information. In this paper, we propose to leverage\nhypercomplex algebra properties to define lightweight I2I generative models\ncapable of preserving pre-existing relations among image dimensions, thus\nexploiting additional input information. On manifold I2I benchmarks, we show\nhow the proposed Quaternion StarGANv2 and parameterized hypercomplex StarGANv2\n(PHStarGANv2) reduce parameters and storage memory amount while ensuring high\ndomain translation performance and good image quality as measured by FID and\nLPIPS scores. Full code is available at: https://github.com/ispamm/HI2I.",
    "descriptor": "",
    "authors": [
      "Eleonora Grassucci",
      "Luigi Sigillo",
      "Aurelio Uncini",
      "Danilo Comminiello"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02087"
  },
  {
    "id": "arXiv:2205.02089",
    "title": "A New Dimensionality Reduction Method Based on Hensel's Compression for  Privacy Protection in Federated Learning",
    "abstract": "Differential privacy (DP) is considered a de-facto standard for protecting\nusers' privacy in data analysis, machine, and deep learning. Existing DP-based\nprivacy-preserving training approaches consist of adding noise to the clients'\ngradients before sharing them with the server. However, implementing DP on the\ngradient is not efficient as the privacy leakage increases by increasing the\nsynchronization training epochs due to the composition theorem. Recently\nresearchers were able to recover images used in the training dataset using\nGenerative Regression Neural Network (GRNN) even when the gradient was\nprotected by DP. In this paper, we propose two layers of privacy protection\napproach to overcome the limitations of the existing DP-based approaches. The\nfirst layer reduces the dimension of the training dataset based on Hensel's\nLemma. We are the first to use Hensel's Lemma for reducing the dimension (i.e.,\ncompress) of a dataset. The new dimensionality reduction method allows reducing\nthe dimension of a dataset without losing information since Hensel's Lemma\nguarantees uniqueness. The second layer applies DP to the compressed dataset\ngenerated by the first layer. The proposed approach overcomes the problem of\nprivacy leakage due to composition by applying DP only once before the\ntraining; clients train their local model on the privacy-preserving dataset\ngenerated by the second layer. Experimental results show that the proposed\napproach ensures strong privacy protection while achieving good accuracy. The\nnew dimensionality reduction method achieves an accuracy of 97%, with only 25 %\nof the original data size.",
    "descriptor": "\nComments: 6 pages, 7 figures\n",
    "authors": [
      "Ahmed El Ouadrhiri",
      "Ahmed Abdelhadi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.02089"
  },
  {
    "id": "arXiv:2205.02090",
    "title": "Improve Discourse Dependency Parsing with Contextualized Representations",
    "abstract": "Recent works show that discourse analysis benefits from modeling intra- and\ninter-sentential levels separately, where proper representations for text units\nof different granularities are desired to capture both the meaning of text\nunits and their relations to the context. In this paper, we propose to take\nadvantage of transformers to encode contextualized representations of units of\ndifferent levels to dynamically capture the information required for discourse\ndependency analysis on intra- and inter-sentential levels. Motivated by the\nobservation of writing patterns commonly shared across articles, we propose a\nnovel method that treats discourse relation identification as a sequence\nlabelling task, which takes advantage of structural information from the\ncontext of extracted discourse trees, and substantially outperforms traditional\ndirect-classification methods. Experiments show that our model achieves\nstate-of-the-art results on both English and Chinese datasets.",
    "descriptor": "\nComments: Naacl 2022 (findings)\n",
    "authors": [
      "Yifei Zhou",
      "Yansong Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.02090"
  },
  {
    "id": "arXiv:2205.02092",
    "title": "Learning Abstract and Transferable Representations for Planning",
    "abstract": "We are concerned with the question of how an agent can acquire its own\nrepresentations from sensory data. We restrict our focus to learning\nrepresentations for long-term planning, a class of problems that\nstate-of-the-art learning methods are unable to solve. We propose a framework\nfor autonomously learning state abstractions of an agent's environment, given a\nset of skills. Importantly, these abstractions are task-independent, and so can\nbe reused to solve new tasks. We demonstrate how an agent can use an existing\nset of options to acquire representations from ego- and object-centric\nobservations. These abstractions can immediately be reused by the same agent in\nnew environments. We show how to combine these portable representations with\nproblem-specific ones to generate a sound description of a specific task that\ncan be used for abstract planning. Finally, we show how to autonomously\nconstruct a multi-level hierarchy consisting of increasingly abstract\nrepresentations. Since these hierarchies are transferable, higher-order\nconcepts can be reused in new tasks, relieving the agent from relearning them\nand improving sample efficiency. Our results demonstrate that our approach\nallows an agent to transfer previous knowledge to new tasks, improving sample\nefficiency as the number of tasks increases.",
    "descriptor": "\nComments: Accepted to the 5th Multi-disciplinary Conference on Reinforcement Learning and Decision Making (RLDM), 2022\n",
    "authors": [
      "Steven James",
      "Benjamin Rosman",
      "George Konidaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.02092"
  },
  {
    "id": "arXiv:2205.02093",
    "title": "A Novel Fully Annotated Thermal Infrared Face Dataset: Recorded in  Various Environment Conditions and Distances From The Camera",
    "abstract": "Facial thermography is one of the most popular research areas in infrared\nthermal imaging, with diverse applications in medical, surveillance, and\nenvironmental monitoring. However, in contrast to facial imagery in the visual\nspectrum, the lack of public datasets on facial thermal images is an obstacle\nto research improvement in this area. Thermal face imagery is still a\nrelatively new research area to be evaluated and studied in different\ndomains.The current thermal face datasets are limited in regards to the\nsubjects' distance from the camera, the ambient temperature variation, and\nfacial landmarks' localization. We address these gaps by presenting a new\nfacial thermography dataset. This article makes two main contributions to the\nbody of knowledge. First, it presents a comprehensive review and comparison of\ncurrent public datasets in facial thermography. Second, it introduces and\nstudies a novel public dataset on facial thermography, which we call it\nCharlotte-ThermalFace. Charlotte-ThermalFace contains more than10000 infrared\nthermal images in varying thermal conditions, several distances from the\ncamera, and different head positions. The data is fully annotated with the\nfacial landmarks, ambient temperature, relative humidity, the air speed of the\nroom, distance to the camera, and subject thermal sensation at the time of\ncapturing each image. Our dataset is the first publicly available thermal\ndataset annotated with the thermal sensation of each subject in different\nthermal conditions and one of the few datasets in raw 16-bit format. Finally,\nwe present a preliminary analysis of the dataset to show the applicability and\nimportance of the thermal conditions in facial thermography. The full dataset,\nincluding annotations, are freely available for research purpose at\nhttps://github.com/TeCSAR-UNCC/UNCC-ThermalFace",
    "descriptor": "",
    "authors": [
      "Roshanak Ashrafi",
      "Mona Azarbayjania",
      "Hamed Tabkhi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.02093"
  },
  {
    "id": "arXiv:2205.02100",
    "title": "MAD: Self-Supervised Masked Anomaly Detection Task for Multivariate Time  Series",
    "abstract": "In this paper, we introduce Masked Anomaly Detection (MAD), a general\nself-supervised learning task for multivariate time series anomaly detection.\nWith the increasing availability of sensor data from industrial systems, being\nable to detecting anomalies from streams of multivariate time series data is of\nsignificant importance. Given the scarcity of anomalies in real-world\napplications, the majority of literature has been focusing on modeling\nnormality. The learned normal representations can empower anomaly detection as\nthe model has learned to capture certain key underlying data regularities. A\ntypical formulation is to learn a predictive model, i.e., use a window of time\nseries data to predict future data values. In this paper, we propose an\nalternative self-supervised learning task. By randomly masking a portion of the\ninputs and training a model to estimate them using the remaining ones, MAD is\nan improvement over the traditional left-to-right next step prediction (NSP)\ntask. Our experimental results demonstrate that MAD can achieve better anomaly\ndetection rates over traditional NSP approaches when using exactly the same\nneural network (NN) base models, and can be modified to run as fast as NSP\nmodels during test time on the same hardware, thus making it an ideal upgrade\nfor many existing NSP-based NN anomaly detection models.",
    "descriptor": "\nComments: Accepted by the 2022 International Joint Conference on Neural Networks (IJCNN 2022)\n",
    "authors": [
      "Yiwei Fu",
      "Feng Xue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.02100"
  },
  {
    "id": "arXiv:2205.02101",
    "title": "Dynamic Sparse R-CNN",
    "abstract": "Sparse R-CNN is a recent strong object detection baseline by set prediction\non sparse, learnable proposal boxes and proposal features. In this work, we\npropose to improve Sparse R-CNN with two dynamic designs. First, Sparse R-CNN\nadopts a one-to-one label assignment scheme, where the Hungarian algorithm is\napplied to match only one positive sample for each ground truth. Such\none-to-one assignment may not be optimal for the matching between the learned\nproposal boxes and ground truths. To address this problem, we propose dynamic\nlabel assignment (DLA) based on the optimal transport algorithm to assign\nincreasing positive samples in the iterative training stages of Sparse R-CNN.\nWe constrain the matching to be gradually looser in the sequential stages as\nthe later stage produces the refined proposals with improved precision. Second,\nthe learned proposal boxes and features remain fixed for different images in\nthe inference process of Sparse R-CNN. Motivated by dynamic convolution, we\npropose dynamic proposal generation (DPG) to assemble multiple proposal experts\ndynamically for providing better initial proposal boxes and features for the\nconsecutive training stages. DPG thereby can derive sample-dependent proposal\nboxes and features for inference. Experiments demonstrate that our method,\nnamed Dynamic Sparse R-CNN, can boost the strong Sparse R-CNN baseline with\ndifferent backbones for object detection. Particularly, Dynamic Sparse R-CNN\nreaches the state-of-the-art 47.2% AP on the COCO 2017 validation set,\nsurpassing Sparse R-CNN by 2.2% AP with the same ResNet-50 backbone.",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Qinghang Hong",
      "Fengming Liu",
      "Dong Li",
      "Ji Liu",
      "Lu Tian",
      "Yi Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02101"
  },
  {
    "id": "arXiv:2205.02102",
    "title": "Concept Activation Vectors for Generating User-Defined 3D Shapes",
    "abstract": "We explore the interpretability of 3D geometric deep learning models in the\ncontext of Computer-Aided Design (CAD). The field of parametric CAD can be\nlimited by the difficulty of expressing high-level design concepts in terms of\na few numeric parameters. In this paper, we use a deep learning architectures\nto encode high dimensional 3D shapes into a vectorized latent representation\nthat can be used to describe arbitrary concepts. Specifically, we train a\nsimple auto-encoder to parameterize a dataset of complex shapes. To understand\nthe latent encoded space, we use the idea of Concept Activation Vectors (CAV)\nto reinterpret the latent space in terms of user-defined concepts. This allows\nmodification of a reference design to exhibit more or fewer characteristics of\na chosen concept or group of concepts. We also test the statistical\nsignificance of the identified concepts and determine the sensitivity of a\nphysical quantity of interest across the dataset.",
    "descriptor": "",
    "authors": [
      "Stefan Druc",
      "Aditya Balu",
      "Peter Wooldridge",
      "Adarsh Krishnamurthy",
      "Soumik Sarkar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02102"
  },
  {
    "id": "arXiv:2205.02103",
    "title": "Efficient Accelerator for Dilated and Transposed Convolution with  Decomposition",
    "abstract": "Hardware acceleration for dilated and transposed convolution enables real\ntime execution of related tasks like segmentation, but current designs are\nspecific for these convolutional types or suffer from complex control for\nreconfigurable designs. This paper presents a design that decomposes input or\nweight for dilated and transposed convolutions respectively to skip redundant\ncomputations and thus executes efficiently on existing dense CNN hardware as\nwell. The proposed architecture can cut down 87.8\\% of the cycle counts to\nachieve 8.2X speedup over a naive execution for the ENet case.",
    "descriptor": "\nComments: 10 pages, 12 figures, published in IEEE ISCAS 2020\n",
    "authors": [
      "Kuo-Wei Chang",
      "Tian-Sheuan Chang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02103"
  },
  {
    "id": "arXiv:2205.02105",
    "title": "Neuroevolutionary Multi-objective approaches to Trajectory Prediction in  Autonomous Vehicles",
    "abstract": "The incentive for using Evolutionary Algorithms (EAs) for the automated\noptimization and training of deep neural networks (DNNs), a process referred to\nas neuroevolution, has gained momentum in recent years. The configuration and\ntraining of these networks can be posed as optimization problems. Indeed, most\nof the recent works on neuroevolution have focused their attention on\nsingle-objective optimization. Moreover, from the little research that has been\ndone at the intersection of neuroevolution and evolutionary multi-objective\noptimization (EMO), all the research that has been carried out has focused\npredominantly on the use of one type of DNN: convolutional neural networks\n(CNNs), using well-established standard benchmark problems such as MNIST. In\nthis work, we make a leap in the understanding of these two areas\n(neuroevolution and EMO), regarded in this work as neuroevolutionary\nmulti-objective, by using and studying a rich DNN composed of a CNN and\nLong-short Term Memory network. Moreover, we use a robust and challenging\nvehicle trajectory prediction problem. By using the well-known Non-dominated\nSorting Genetic Algorithm-II, we study the effects of five different\nobjectives, tested in categories of three, allowing us to show how these\nobjectives have either a positive or detrimental effect in neuroevolution for\ntrajectory prediction in autonomous vehicles.",
    "descriptor": "\nComments: 4 pages, 1 figure, 6 tables\n",
    "authors": [
      "Fergal Stapleton",
      "Edgar Galv\u00e1n",
      "Ganesh Sistu",
      "Senthil Yogamani"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.02105"
  },
  {
    "id": "arXiv:2205.02106",
    "title": "Babel: A Framework for Developing Performant and Dependable Distributed  Protocols",
    "abstract": "Prototyping and implementing distributed algorithms, particularly those that\naddress challenges related with fault-tolerance and dependability, is a time\nconsuming task. This is, in part, due to the need of addressing low level\naspects such as management of communication channels, controlling timeouts or\nperiodic tasks, and dealing with concurrency issues. This has a significant\nimpact for researchers that want to build prototypes for conducting\nexperimental evaluation; practitioners that want to compare different design\nalternatives/solutions; and even for practical teaching activities on\ndistributed algorithms courses.\nIn this paper we present Babel, a novel framework to develop, implement, and\nexecute distributed protocols and systems. Babel promotes an event driven\nprogramming and execution model that simplifies the task of translating typical\nspecifications or descriptions of algorithms into performant prototypes, while\nallowing the programmer to focus on the relevant challenges of these algorithms\nby transparently handling time consuming low level aspects. Furthermore, Babel\nprovides, and allows the definition of, networking components that can capture\ndifferent network capabilities (e.g., P2P, Client/Server, phi-accrual Failure\nDetector), making the code mostly independent from the underlying communication\naspects. Babel was built to be generic and can be used to implement a wide\nvariety of different classes of distributed protocols.\nWe conduct our experimental work with two relevant case studies, a\nPeer-to-Peer application and a State Machine Replication application, that show\nthe generality and ease of use of Babel and present competitive performance\nwhen compared with significantly more complex implementations.",
    "descriptor": "\nComments: 18 pages, 2 figures\n",
    "authors": [
      "Pedro Fouto",
      "Pedro \u00c1kos Costa",
      "Nuno Pregui\u00e7a",
      "Jo\u00e3o Leit\u00e3o"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.02106"
  },
  {
    "id": "arXiv:2205.02107",
    "title": "Prediction of fish location by combining fisheries data and sea bottom  temperature forecasting",
    "abstract": "This paper combines fisheries dependent data and environmental data to be\nused in a machine learning pipeline to predict the spatio-temporal abundance of\ntwo species (plaice and sole) commonly caught by the Belgian fishery in the\nNorth Sea. By combining fisheries related features with environmental data, sea\nbottom temperature derived from remote sensing, a higher accuracy can be\nachieved. In a forecast setting, the predictive accuracy is further improved by\npredicting, using a recurrent deep neural network, the sea bottom temperature\nup to four days in advance instead of relying on the last previous temperature\nmeasurement.",
    "descriptor": "\nComments: Accepted at 21st International Conference on Image Analysis and Processing (ICIAP 2021)\n",
    "authors": [
      "Matthieu Ospici",
      "Klaas Sys",
      "Sophie Guegan-Marat"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02107"
  },
  {
    "id": "arXiv:2205.02108",
    "title": "Using Deep Reinforcement Learning to solve Optimal Power Flow problem  with generator failures",
    "abstract": "Deep Reinforcement Learning (DRL) is being used in many domains. One of the\nbiggest advantages of DRL is that it enables the continuous improvement of a\nlearning agent. Secondly, the DRL framework is robust and flexible enough to be\napplicable to problems of varying nature and domain. Presented work is evidence\nof using the DRL technique to solve an Optimal Power Flow (OPF) problem. Two\nclassical algorithms have been presented to solve the OPF problem. The\ndrawbacks of the vanilla DRL application are discussed, and an algorithm is\nsuggested to improve the performance. Secondly, a reward function for the OPF\nproblem is presented that enables the solution of inherent issues in DRL.\nReasons for divergence and degeneration in DRL are discussed, and the correct\nstrategy to deal with them with respect to OPF is presented.",
    "descriptor": "",
    "authors": [
      "Muhammad Usman Awais"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.02108"
  },
  {
    "id": "arXiv:2205.02111",
    "title": "Improved Orientation Estimation and Detection with Hybrid Object  Detection Networks for Automotive Radar",
    "abstract": "This paper presents novel hybrid architectures that combine grid- and\npoint-based processing to improve the detection performance and orientation\nestimation of radar-based object detection networks. Purely grid-based\ndetection models operate on a bird's-eye-view (BEV) projection of the input\npoint cloud. These approaches suffer from a loss of detailed information\nthrough the discrete grid resolution. This applies in particular to radar\nobject detection, where relatively coarse grid resolutions are commonly used to\naccount for the sparsity of radar point clouds. In contrast, point-based models\nare not affected by this problem as they continuously process point clouds.\nHowever, they generally exhibit worse detection performances than grid-based\nmethods.\nWe show that a point-based model can extract neighborhood features,\nleveraging the exact relative positions of points, before grid rendering. This\nhas significant benefits for a following convolutional detection backbone. In\nexperiments on the public nuScenes dataset our hybrid architecture achieves\nimprovements in terms of detection performance and orientation estimates over\nnetworks from previous literature.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Michael Ulrich",
      "Sascha Braun",
      "Daniel K\u00f6hler",
      "Daniel Niederl\u00f6hner",
      "Florian Faion",
      "Claudius Gl\u00e4ser",
      "Holger Blume"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.02111"
  },
  {
    "id": "arXiv:2205.02112",
    "title": "Combining Reciprocity and CSI Feedback in MIMO Systems",
    "abstract": "Reciprocity-based time-division duplex (TDD) Massive MIMO (multiple-input\nmultiple-output) systems utilize channel estimates obtained in the uplink to\nperform precoding in the downlink. However, this method has been criticized of\nbreaking down, in the sense that the channel estimates are not good enough to\nspatially separate multiple user terminals, at low uplink reference signal\nsignal-to-noise ratios, due to insufficient channel estimation quality.\nInstead, codebook-based downlink precoding has been advocated for as an\nalternative solution in order to bypass this problem. We analyze this problem\nby considering a \"grid-of-beams world\" with a finite number of possible\ndownlink channel realizations. Assuming that the terminal accurately can detect\nthe downlink channel, we show that in the case where reciprocity holds,\ncarefully designing a mapping between the downlink channel and the uplink\nreference signals will perform better than both the conventional TDD Massive\nMIMO and frequency-division duplex (FDD) Massive MIMO approach. We derive\nelegant metrics for designing this mapping, and further, we propose algorithms\nthat find good sequence mappings.",
    "descriptor": "\nComments: 32 pages, 7 figures, submitted to IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Ema Becirovic",
      "Emil Bj\u00f6rnson",
      "Erik G. Larsson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.02112"
  },
  {
    "id": "arXiv:2205.02113",
    "title": "Predicting vacant parking space availability zone-wisely: a graph based  spatio-temporal prediction approach",
    "abstract": "Vacant parking space (VPS) prediction is one of the key issues of intelligent\nparking guidance systems. Accurately predicting VPS information plays a crucial\nrole in intelligent parking guidance systems, which can help drivers find\nparking space quickly, reducing unnecessary waste of time and excessive\nenvironmental pollution. Through the simple analysis of historical data, we\nfound that there not only exists a obvious temporal correlation in each parking\nlot, but also a clear spatial correlation between different parking lots. In\nview of this, this paper proposed a graph data-based model ST-GBGRU\n(Spatial-Temporal Graph Based Gated Recurrent Unit), the number of VPSs can be\npredicted both in short-term (i.e., within 30 min) and in long-term (i.e., over\n30min). On the one hand, the temporal correlation of historical VPS data is\nextracted by GRU, on the other hand, the spatial correlation of historical VPS\ndata is extracted by GCN inside GRU. Two prediction methods, namely direct\nprediction and iterative prediction, are combined with the proposed model.\nFinally, the prediction model is applied to predict the number VPSs of 8 public\nparking lots in Santa Monica. The results show that in the short-term and\nlong-term prediction tasks, ST-GBGRU model can achieve high accuracy and have\ngood application prospects.",
    "descriptor": "",
    "authors": [
      "Yajing Feng",
      "Qian Hu",
      "Zhenzhou Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02113"
  },
  {
    "id": "arXiv:2205.02115",
    "title": "Axonal Delay As a Short-Term Memory for Feed Forward Deep Spiking Neural  Networks",
    "abstract": "The information of spiking neural networks (SNNs) are propagated between the\nadjacent biological neuron by spikes, which provides a computing paradigm with\nthe promise of simulating the human brain. Recent studies have found that the\ntime delay of neurons plays an important role in the learning process.\nTherefore, configuring the precise timing of the spike is a promising direction\nfor understanding and improving the transmission process of temporal\ninformation in SNNs. However, most of the existing learning methods for spiking\nneurons are focusing on the adjustment of synaptic weight, while very few\nresearch has been working on axonal delay. In this paper, we verify the\neffectiveness of integrating time delay into supervised learning and propose a\nmodule that modulates the axonal delay through short-term memory. To this end,\na rectified axonal delay (RAD) module is integrated with the spiking model to\nalign the spike timing and thus improve the characterization learning ability\nof temporal features. Experiments on three neuromorphic benchmark datasets :\nNMNIST, DVS Gesture and N-TIDIGITS18 show that the proposed method achieves the\nstate-of-the-art performance while using the fewest parameters.",
    "descriptor": "\nComments: Accepted at IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Singapore, 2022\n",
    "authors": [
      "Pengfei Sun",
      "Longwei Zhu",
      "Dick Botteldooren"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2205.02115"
  },
  {
    "id": "arXiv:2205.02116",
    "title": "Optimizing One-pixel Black-box Adversarial Attacks",
    "abstract": "The output of Deep Neural Networks (DNN) can be altered by a small\nperturbation of the input in a black box setting by making multiple calls to\nthe DNN. However, the high computation and time required makes the existing\napproaches unusable. This work seeks to improve the One-pixel (few-pixel)\nblack-box adversarial attacks to reduce the number of calls to the network\nunder attack. The One-pixel attack uses a non-gradient optimization algorithm\nto find pixel-level perturbations under the constraint of a fixed number of\npixels, which causes the network to predict the wrong label for a given image.\nWe show through experimental results how the choice of the optimization\nalgorithm and initial positions to search can reduce function calls and\nincrease attack success significantly, making the attack more practical in\nreal-world settings.",
    "descriptor": "\nComments: 9 pasges, 4 figures\n",
    "authors": [
      "Tianxun Zhou",
      "Shubhankar Agrawal",
      "Prateek Manocha"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02116"
  },
  {
    "id": "arXiv:2205.02117",
    "title": "ATDD: Fine-Grained Assured Time-Sensitive Data Deletion Scheme in Cloud  Storage",
    "abstract": "With the rapid development of general cloud services, more and more\nindividuals or collectives use cloud platforms to store data. Assured data\ndeletion deserves investigation in cloud storage. In time-sensitive data\nstorage scenarios, it is necessary for cloud platforms to automatically destroy\ndata after the data owner-specified expiration time. Therefore, assured\ntimesensitive data deletion should be sought. In this paper, a finegrained\nassured time-sensitive data deletion (ATDD) scheme in cloud storage is proposed\nby embedding the time trapdoor in Ciphertext-Policy Attribute-Based Encryption\n(CP-ABE). Timesensitive data is self-destructed after the data owner-specified\nexpiration time so that the authorized users cannot get access to the related\ndata. In addition, a credential is returned to the data owner for data deletion\nverification. This proposed scheme provides solutions for fine-grained access\ncontrol and verifiable data self-destruction. Detailed security and performance\nanalysis demonstrate the security and the practicability of the proposed\nscheme.",
    "descriptor": "",
    "authors": [
      "Zhengyu Yue",
      "Yuanzhi Yao",
      "Weihai Li",
      "Nenghai Yu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.02117"
  },
  {
    "id": "arXiv:2205.02125",
    "title": "Engineering deep learning methods on automatic detection of damage in  infrastructure due to extreme events",
    "abstract": "This paper presents a few comprehensive experimental studies for automated\nStructural Damage Detection (SDD) in extreme events using deep learning methods\nfor processing 2D images. In the first study, a 152-layer Residual network\n(ResNet) is utilized to classify multiple classes in eight SDD tasks, which\ninclude identification of scene levels, damage levels, material types, etc. The\nproposed ResNet achieved high accuracy for each task while the positions of the\ndamage are not identifiable. In the second study, the existing ResNet and a\nsegmentation network (U-Net) are combined into a new pipeline, cascaded\nnetworks, for categorizing and locating structural damage. The results show\nthat the accuracy of damage detection is significantly improved compared to\nonly using a segmentation network. In the third and fourth studies, end-to-end\nnetworks are developed and tested as a new solution to directly detect cracks\nand spalling in the image collections of recent large earthquakes. One of the\nproposed networks can achieve an accuracy above 67.6% for all tested images at\nvarious scales and resolutions, and shows its robustness for these human-free\ndetection tasks. As a preliminary field study, we applied the proposed method\nto detect damage in a concrete structure that was tested to study its\nprogressive collapse performance. The experiments indicate that these solutions\nfor automatic detection of structural damage using deep learning methods are\nfeasible and promising. The training datasets and codes will be made available\nfor the public upon the publication of this paper.",
    "descriptor": "\nComments: Thanks for the revivers' help for improving this paper. Structural Health Monitoring (2022)\n",
    "authors": [
      "Yongsheng Bai",
      "Bing Zha",
      "Halil Sezen",
      "Alper Yilmaz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.02125"
  },
  {
    "id": "arXiv:2205.02129",
    "title": "Are All the Datasets in Benchmark Necessary? A Pilot Study of Dataset  Evaluation for Text Classification",
    "abstract": "In this paper, we ask the research question of whether all the datasets in\nthe benchmark are necessary. We approach this by first characterizing the\ndistinguishability of datasets when comparing different systems. Experiments on\n9 datasets and 36 systems show that several existing benchmark datasets\ncontribute little to discriminating top-scoring systems, while those less used\ndatasets exhibit impressive discriminative power. We further, taking the text\nclassification task as a case study, investigate the possibility of predicting\ndataset discrimination based on its properties (e.g., average sentence length).\nOur preliminary experiments promisingly show that given a sufficient number of\ntraining experimental records, a meaningful predictor can be learned to\nestimate dataset discrimination over unseen datasets. We released all datasets\nwith features explored in this work on DataLab:\n\\url{https://datalab.nlpedia.ai}.",
    "descriptor": "\nComments: 9 pages, 9 figures\n",
    "authors": [
      "Yang Xiao",
      "Jinlan Fu",
      "See-Kiong Ng",
      "Pengfei Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.02129"
  },
  {
    "id": "arXiv:2205.02130",
    "title": "The Limits of Word Level Differential Privacy",
    "abstract": "As the issues of privacy and trust are receiving increasing attention within\nthe research community, various attempts have been made to anonymize textual\ndata. A significant subset of these approaches incorporate differentially\nprivate mechanisms to perturb word embeddings, thus replacing individual words\nin a sentence. While these methods represent very important contributions, have\nvarious advantages over other techniques and do show anonymization\ncapabilities, they have several shortcomings. In this paper, we investigate\nthese weaknesses and demonstrate significant mathematical constraints\ndiminishing the theoretical privacy guarantee as well as major practical\nshortcomings with regard to the protection against deanonymization attacks, the\npreservation of content of the original sentences as well as the quality of the\nlanguage output. Finally, we propose a new method for text anonymization based\non transformer based language models fine-tuned for paraphrasing that\ncircumvents most of the identified weaknesses and also offers a formal privacy\nguarantee. We evaluate the performance of our method via thorough\nexperimentation and demonstrate superior performance over the discussed\nmechanisms.",
    "descriptor": "",
    "authors": [
      "Justus Mattern",
      "Benjamin Weggenmann",
      "Florian Kerschbaum"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02130"
  },
  {
    "id": "arXiv:2205.02131",
    "title": "Domino Saliency Metrics: Improving Existing Channel Saliency Metrics  with Structural Information",
    "abstract": "Channel pruning is used to reduce the number of weights in a Convolutional\nNeural Network (CNN). Channel pruning removes slices of the weight tensor so\nthat the convolution layer remains dense. The removal of these weight slices\nfrom a single layer causes mismatching number of feature maps between layers of\nthe network. A simple solution is to force the number of feature map between\nlayers to match through the removal of weight slices from subsequent layers.\nThis additional constraint becomes more apparent in DNNs with branches where\nmultiple channels need to be pruned together to keep the network dense. Popular\npruning saliency metrics do not factor in the structural dependencies that\narise in DNNs with branches. We propose Domino metrics (built on existing\nchannel saliency metrics) to reflect these structural constraints. We test\nDomino saliency metrics against the baseline channel saliency metrics on\nmultiple networks with branches. Domino saliency metrics improved pruning rates\nin most tested networks and up to 25% in AlexNet on CIFAR-10.",
    "descriptor": "",
    "authors": [
      "Kaveena Persand",
      "Andrew Anderson",
      "David Gregg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02131"
  },
  {
    "id": "arXiv:2205.02132",
    "title": "Multi-Granularity Semantic Aware Graph Model for Reducing Position Bias  in Emotion-Cause Pair Extraction",
    "abstract": "The Emotion-Cause Pair Extraction (ECPE) task aims to extract emotions and\ncauses as pairs from documents. We observe that the relative distance\ndistribution of emotions and causes is extremely imbalanced in the typical ECPE\ndataset. Existing methods have set a fixed size window to capture relations\nbetween neighboring clauses. However, they neglect the effective semantic\nconnections between distant clauses, leading to poor generalization ability\ntowards position-insensitive data. To alleviate the problem, we propose a novel\n\\textbf{M}ulti-\\textbf{G}ranularity \\textbf{S}emantic \\textbf{A}ware\n\\textbf{G}raph model (MGSAG) to incorporate fine-grained and coarse-grained\nsemantic features jointly, without regard to distance limitation. In\nparticular, we first explore semantic dependencies between clauses and keywords\nextracted from the document that convey fine-grained semantic features,\nobtaining keywords enhanced clause representations. Besides, a clause graph is\nalso established to model coarse-grained semantic relations between clauses.\nExperimental results indicate that MGSAG surpasses the existing\nstate-of-the-art ECPE models. Especially, MGSAG outperforms other models\nsignificantly in the condition of position-insensitive data.",
    "descriptor": "\nComments: Accepted by the Findings of ACL 2022\n",
    "authors": [
      "Yinan Bao",
      "Qianwen Ma",
      "Lingwei Wei",
      "Wei Zhou",
      "Songlin Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.02132"
  },
  {
    "id": "arXiv:2205.02134",
    "title": "Hodge Decomposition and General Laplacian Solvers for Embedded  Simplicial Complexes",
    "abstract": "We describe a nearly-linear time algorithm to solve the linear system $L_1x =\nb$ parameterized by the first Betti number of the complex, where $L_1$ is the\n1-Laplacian of a simplicial complex $K$ that is a subcomplex of a collapsible\ncomplex $X$ linearly embedded in $\\mathbb{R}^{3}$. Our algorithm generalizes\nthe work of Black et al.~[SODA2022] that solved the same problem but required\nthat $K$ have trivial first homology. Our algorithm works for complexes $K$\nwith arbitrary first homology with running time that is nearly-linear with\nrespect to the size of the complex and polynomial with respect to the first\nBetti number. The key to our solver is a new algorithm for computing the Hodge\ndecomposition of 1-chains of $K$ in nearly-linear time. Additionally, our\nalgorithm implies a nearly quadratic solver and nearly quadratic Hodge\ndecomposition for the 1-Laplacian of any simplicial complex $K$ embedded in\n$\\mathbb{R}^{3}$, as $K$ can always be expanded to a collapsible embedded\ncomplex of quadratic complexity.",
    "descriptor": "\nComments: Accepted to ICALP 2022\n",
    "authors": [
      "Mitchell Black",
      "Amir Nayyeri"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2205.02134"
  },
  {
    "id": "arXiv:2205.02135",
    "title": "Human-to-Human Strokes Recordings for Tactile Apparent Motion",
    "abstract": "The main objective of this study is to investigate whether one can use\nrecordings of human-to-human touch, such as a caress, to improve tactile\napparent motion interfaces to make them feel more natural. We report here\npreliminary recordings of natural and continuous human-to-human caresses. To do\nthis, six accelerometers were positioned on the receiving hand next to the\nstimulated area while a finger gently stroked the skin. The results suggest\nthat we are able to capture signals from real human caresses that can be\ncompared to signals produced by apparent motion stimuli. This is encouraging\nfor our plan to continue the study in the second stage, which consists of\ntuning vibrotactile actuators to reproduce a similar pattern of vibrational\nresponses in the accelerometers. In this way, the actuators mimic human\nbehavior.",
    "descriptor": "",
    "authors": [
      "Basil Duvernoy",
      "Sarah McIntyre"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.02135"
  },
  {
    "id": "arXiv:2205.02141",
    "title": "RecipeSnap -- a lightweight image-to-recipe model",
    "abstract": "In this paper we want to address the problem of automation for recognition of\nphotographed cooking dishes and generating the corresponding food recipes.\nCurrent image-to-recipe models are computation expensive and require powerful\nGPUs for model training and implementation. High computational cost prevents\nthose existing models from being deployed on portable devices, like smart\nphones. To solve this issue we introduce a lightweight image-to-recipe\nprediction model, RecipeSnap, that reduces memory cost and computational cost\nby more than 90% while still achieving 2.0 MedR, which is in line with the\nstate-of-the-art model. A pre-trained recipe encoder was used to compute recipe\nembeddings. Recipes from Recipe1M dataset and corresponding recipe embeddings\nare collected as a recipe library, which are used for image encoder training\nand image query later. We use MobileNet-V2 as image encoder backbone, which\nmakes our model suitable to portable devices. This model can be further\ndeveloped into an application for smart phones with a few effort. A comparison\nof the performance between this lightweight model to other heavy models are\npresented in this paper. Code, data and models are publicly accessible on\ngithub.",
    "descriptor": "\nComments: 7 pages, 3 figures\n",
    "authors": [
      "Jianfa Chen",
      "Yue Yin",
      "Yifan Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.02141"
  },
  {
    "id": "arXiv:2205.02142",
    "title": "Semimodules and the (syntactically-)linear lambda calculus",
    "abstract": "In a recent paper, the $\\mathcal L^{\\mathcal S}$-calculus has been defined.\nIt is a proof-language for a significant fragment of intuitionistic linear\nlogic. Its main feature is that the linearity properties can be expressed in\nits syntax, since it has interstitial logical rules whose proof-terms are a sum\nand a multiplication by scalar.\nThe calculus is parametrized on the structure $\\mathcal S$. This structure\nwas originally identified with the field of complex numbers, since the calculus\nis designed as a quantum lambda calculus. However, in this paper we show that a\nsemiring is enough, and we provide a categorical semantics for this calculus in\nthe category of cancellative semimodules over the given semiring. We prove the\nsemantics to be sound and adequate.",
    "descriptor": "",
    "authors": [
      "Alejandro D\u00edaz-Caro",
      "Octavio Malherbe"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.02142"
  },
  {
    "id": "arXiv:2205.02146",
    "title": "An Analysis of Generative Methods for Multiple Image Inpainting",
    "abstract": "Image inpainting refers to the restoration of an image with missing regions\nin a way that is not detectable by the observer. The inpainting regions can be\nof any size and shape. This is an ill-posed inverse problem that does not have\na unique solution. In this work, we focus on learning-based image completion\nmethods for multiple and diverse inpainting which goal is to provide a set of\ndistinct solutions for a given damaged image. These methods capitalize on the\nprobabilistic nature of certain generative models to sample various solutions\nthat coherently restore the missing content. Along the chapter, we will analyze\nthe underlying theory and analyze the recent proposals for multiple inpainting.\nTo investigate the pros and cons of each method, we present quantitative and\nqualitative comparisons, on common datasets, regarding both the quality and the\ndiversity of the set of inpainted solutions. Our analysis allows us to identify\nthe most successful generative strategies in both inpainting quality and\ninpainting diversity. This task is closely related to the learning of an\naccurate probability distribution of images. Depending on the dataset in use,\nthe challenges that entail the training of such a model will be discussed\nthrough the analysis.",
    "descriptor": "",
    "authors": [
      "Coloma Ballester",
      "Aurelie Bugeau",
      "Samuel Hurault",
      "Simone Parisotto",
      "Patricia Vitoria"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.02146"
  },
  {
    "id": "arXiv:2205.02149",
    "title": "Degree-restricted strength decompositions and algebraic branching  programs",
    "abstract": "We analyze Kumar's recent quadratic algebraic branching program size lower\nbound proof method (CCC 2017). We provide a refinement of this method and show\nexamples in which the refined method gives a better lower bound than the\noriginal one.\nThe lower bound relies on Noether-Lefschetz type conditions on the\nhypersurface defined by the homogeneous polynomial. In the explicit example\nthat we provide, the lower bound is proved resorting to classical intersection\ntheory.\nFurther, we use similar methods to improve the known lower bound methods for\nslice rank of polynomials. We give a sequence of polynomials for which the\nimproved lower bound matches the known upper bound.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Purnata Ghosal",
      "Fulvio Gesmundo",
      "Christian Ikenmeyer",
      "Vladimir Lysikov"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2205.02149"
  },
  {
    "id": "arXiv:2205.02151",
    "title": "Dual Cross-Attention Learning for Fine-Grained Visual Categorization and  Object Re-Identification",
    "abstract": "Recently, self-attention mechanisms have shown impressive performance in\nvarious NLP and CV tasks, which can help capture sequential characteristics and\nderive global information. In this work, we explore how to extend\nself-attention modules to better learn subtle feature embeddings for\nrecognizing fine-grained objects, e.g., different bird species or person\nidentities. To this end, we propose a dual cross-attention learning (DCAL)\nalgorithm to coordinate with self-attention learning. First, we propose\nglobal-local cross-attention (GLCA) to enhance the interactions between global\nimages and local high-response regions, which can help reinforce the\nspatial-wise discriminative clues for recognition. Second, we propose pair-wise\ncross-attention (PWCA) to establish the interactions between image pairs. PWCA\ncan regularize the attention learning of an image by treating another image as\ndistractor and will be removed during inference. We observe that DCAL can\nreduce misleading attentions and diffuse the attention response to discover\nmore complementary parts for recognition. We conduct extensive evaluations on\nfine-grained visual categorization and object re-identification. Experiments\ndemonstrate that DCAL performs on par with state-of-the-art methods and\nconsistently improves multiple self-attention baselines, e.g., surpassing\nDeiT-Tiny and ViT-Base by 2.8% and 2.4% mAP on MSMT17, respectively.",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Haowei Zhu",
      "Wenjing Ke",
      "Dong Li",
      "Ji Liu",
      "Lu Tian",
      "Yi Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02151"
  },
  {
    "id": "arXiv:2205.02161",
    "title": "Is the Algorithmic Kadison-Singer Problem Hard?",
    "abstract": "We study the following $\\mathsf{KS}_2(c)$ problem: let $c \\in\\mathbb{R}^+$ be\nsome constant, and $v_1,\\ldots, v_m\\in\\mathbb{R}^d$ be vectors such that\n$\\|v_i\\|^2\\leq \\alpha$ for any $i\\in[m]$ and $\\sum_{i=1}^m \\langle v_i,\nx\\rangle^2 =1$ for any $x\\in\\mathbb{R}^d$ with $\\|x\\|=1$. The\n$\\mathsf{KS}_2(c)$ problem asks to find some $S\\subset [m]$, such that it holds\nfor all $x \\in \\mathbb{R}^d$ with $\\|x\\| = 1$ that \\[ \\left|\\sum_{i \\in S}\n\\langle v_i, x\\rangle^2 - \\frac{1}{2}\\right| \\leq c\\cdot\\sqrt{\\alpha},\\] or\nreport no if such $S$ doesn't exist. Based on the work of Marcus et al. and\nWeaver, the $\\mathsf{KS}_2(c)$ problem can be seen as the algorithmic\nKadison-Singer problem with parameter $c\\in\\mathbb{R}^+$.\nOur first result is a randomised algorithm with one-sided error for the\n$\\mathsf{KS}_2(c)$ problem such that (1) our algorithm finds a valid set $S\n\\subset [m]$ with probability at least $1-2/d$, if such $S$ exists, or (2)\nreports no with probability $1$, if no valid sets exist. The algorithm has\nrunning time \\[ O\\left(\\binom{m}{n}\\cdot \\mathrm{poly}(m, d)\\right)~\\mbox{ for\n}~n = O\\left(\\frac{d}{\\epsilon^2} \\log(d)\n\\log\\left(\\frac{1}{c\\sqrt{\\alpha}}\\right)\\right). \\] This presents the first\nalgorithm for the Kadison-Singer problem whose running time is quasi-polynomial\nin $m$, although having exponential dependency on $d$. Moreover, it shows that\nthe algorithmic Kadison-Singer problem is easier to solve in low dimensions.\nOur second result is on the computational complexity of the\n$\\mathsf{KS}_2(c)$ problem. We show that the $\\mathsf{KS}_2(1/(4\\sqrt{2}))$\nproblem is $\\mathsf{FNP}$-hard for general values of $d$, and solving the\n$\\mathsf{KS}_2(1/(4\\sqrt{2}))$ problem is as hard as solving the\n$\\mathsf{NAE\\mbox{-}3SAT}$ problem.",
    "descriptor": "",
    "authors": [
      "Ben Jourdan",
      "Peter Macgregor",
      "He Sun"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.02161"
  },
  {
    "id": "arXiv:2205.02162",
    "title": "UnrealNAS: Can We Search Neural Architectures with Unreal Data?",
    "abstract": "Neural architecture search (NAS) has shown great success in the automatic\ndesign of deep neural networks (DNNs). However, the best way to use data to\nsearch network architectures is still unclear and under exploration. Previous\nwork [19, 46] has analyzed the necessity of having ground-truth labels in NAS\nand inspired broad interest. In this work, we take a further step to question\nwhether real data is necessary for NAS to be effective. The answer to this\nquestion is important for applications with limited amount of accessible data,\nand can help people improve NAS by leveraging the extra flexibility of data\ngeneration. To explore if NAS needs real data, we construct three types of\nunreal datasets using: 1) randomly labeled real images; 2) generated images and\nlabels; and 3) generated Gaussian noise with random labels. These datasets\nfacilitate to analyze the generalization and expressivity of the searched\narchitectures. We study the performance of architectures searched on these\nconstructed datasets using popular differentiable NAS methods. Extensive\nexperiments on CIFAR, ImageNet and CheXpert [12] show that the searched\narchitectures can achieve promising results compared with those derived from\nthe conventional NAS pipeline with real labeled data, suggesting the\nfeasibility of performing NAS with unreal data.",
    "descriptor": "",
    "authors": [
      "Zhen Dong",
      "Kaicheng Zhou",
      "Guohao Li",
      "Qiang Zhou",
      "Mingfei Guo",
      "Bernard Ghanem",
      "Kurt Keutzer",
      "Shanghang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.02162"
  },
  {
    "id": "arXiv:2205.02168",
    "title": "Separations in Proof Complexity and TFNP",
    "abstract": "It is well-known that Resolution proofs can be efficiently simulated by\nSherali--Adams~(SA) proofs. We show, however, that any such simulation needs to\nexploit huge coefficients: Resolution cannot be efficiently simulated by SA\nwhen the coefficients are written in unary. We also show that \\emph{Reversible\nResolution} (a variant of MaxSAT Resolution) cannot be efficiently simulated by\nNullstellensatz (NS).\nThese results can be interpreted in the language of total $\\textsf{NP}$\nsearch problems. We show that $\\textsf{PPADS}$, $\\textsf{PPAD}$,\n$\\textsf{SOPL}$ are captured by unary-SA, unary-NS, and Reversible Resolution,\nrespectively. Consequently, relative to an oracle,\n$\\textsf{PLS}\\not\\subseteq\\textsf{PPADS}$ and\n$\\textsf{SOPL}\\not\\subseteq\\textsf{PPA}$.",
    "descriptor": "",
    "authors": [
      "Mika G\u00f6\u00f6s",
      "Alexandros Hollender",
      "Siddhartha Jain",
      "Gilbert Maystre",
      "William Pires",
      "Robert Robere",
      "Ran Tao"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2205.02168"
  },
  {
    "id": "arXiv:2205.02170",
    "title": "Efficient Few-Shot Fine-Tuning for Opinion Summarization",
    "abstract": "Abstractive summarization models are typically pre-trained on large amounts\nof generic texts, then fine-tuned on tens or hundreds of thousands of annotated\nsamples. However, in opinion summarization, large annotated datasets of reviews\npaired with reference summaries are not available and would be expensive to\ncreate. This calls for fine-tuning methods robust to overfitting on small\ndatasets. In addition, generically pre-trained models are often not accustomed\nto the specifics of customer reviews and, after fine-tuning, yield summaries\nwith disfluencies and semantic mistakes. To address these problems, we utilize\nan efficient few-shot method based on adapters which, as we show, can easily\nstore in-domain knowledge. Instead of fine-tuning the entire model, we add\nadapters and pre-train them in a task-specific way on a large corpus of\nunannotated customer reviews, using held-out reviews as pseudo summaries. Then,\nfine-tune the adapters on the small available human-annotated dataset. We show\nthat this self-supervised adapter pre-training improves summary quality over\nstandard fine-tuning by 2.0 and 1.3 ROUGE-L points on the Amazon and Yelp\ndatasets, respectively. Finally, for summary personalization, we condition on\naspect keyword queries, automatically created from generic datasets. In the\nsame vein, we pre-train the adapters in a query-based manner on customer\nreviews and then fine-tune them on annotated datasets. This results in\nbetter-organized summary content reflected in improved coherence and fewer\nredundancies.",
    "descriptor": "\nComments: NAACL 2022\n",
    "authors": [
      "Arthur Bra\u017einskas",
      "Ramesh Nallapati",
      "Mohit Bansal",
      "Markus Dreyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02170"
  },
  {
    "id": "arXiv:2205.02172",
    "title": "Using virtual edges to extract keywords from texts modeled as complex  networks",
    "abstract": "Detecting keywords in texts is important for many text mining applications.\nGraph-based methods have been commonly used to automatically find the key\nconcepts in texts, however, relevant information provided by embeddings has not\nbeen widely used to enrich the graph structure. Here we modeled texts\nco-occurrence networks, where nodes are words and edges are established either\nby contextual or semantical similarity. We compared two embedding approaches --\nWord2vec and BERT -- to check whether edges created via word embeddings can\nimprove the quality of the keyword extraction method. We found that, in fact,\nthe use of virtual edges can improve the discriminability of co-occurrence\nnetworks. The best performance was obtained when we considered low percentages\nof addition of virtual (embedding) edges. A comparative analysis of structural\nand dynamical network metrics revealed the degree, PageRank, and accessibility\nare the metrics displaying the best performance in the model enriched with\nvirtual edges.",
    "descriptor": "",
    "authors": [
      "Jorge A. V. Tohalino",
      "Thiago C. Silva",
      "Diego R. Amancio"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.02172"
  },
  {
    "id": "arXiv:2205.02177",
    "title": "Tangle 2.0 Leaderless Nakamoto Consensus on the Heaviest DAG",
    "abstract": "We introduce the theoretical foundations of the Tangle 2.0, a probabilistic\nleaderless consensus protocol based on a directed acyclic graph (DAG) called\nthe Tangle. The Tangle naturally succeeds the blockchain as its next\nevolutionary step as it offers features suited to establish more efficient and\nscalable distributed ledger solutions.\nConsensus is no longer found in the longest chain but on the heaviest DAG,\nwhere PoW is replaced by a stake- or reputation-based weight function. The DAG\nstructure and the underlying Reality-based UTXO Ledger allow parallel\nvalidation of transactions without the need for total ordering. Moreover, it\nenables the removal of the intermediary of miners and validators, allowing a\npure two-step process that follows the \\emph{propose-vote} paradigm at the node\nlevel and not at the validator level.\nWe propose a framework to analyse liveness and safety under different\ncommunication and adversary models. This allows providing impossibility results\nin some edge cases and in the asynchronous communication model. We provide\nformal proof of the security of the protocol assuming a common random coin.",
    "descriptor": "",
    "authors": [
      "Sebastian M\u00fcller",
      "Andreas Penzkofer",
      "Nikita Polyanskii",
      "Jonas Theis",
      "William Sanders",
      "Hans Moog"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.02177"
  },
  {
    "id": "arXiv:2205.02182",
    "title": "Reproducibility Beyond the Research Community: Experience from NLP  Beginners",
    "abstract": "As NLP research attracts public attention and excitement, it becomes\nincreasingly important for it to be accessible to a broad audience. As the\nresearch community works to democratize NLP, it remains unclear whether\nbeginners to the field can easily apply the latest developments. To understand\ntheir needs, we conducted a study with 93 students in an introductory NLP\ncourse, where students reproduced results of recent NLP papers. Surprisingly,\nour results suggest that their technical skill (i.e., programming experience)\nhas limited impact on their effort spent completing the exercise. Instead, we\nfind accessibility efforts by research authors to be key to a successful\nexperience, including thorough documentation and easy access to required models\nand datasets.",
    "descriptor": "\nComments: Accepted to NAACL 2022\n",
    "authors": [
      "Shane Storks",
      "Keunwoo Peter Yu",
      "Joyce Chai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.02182"
  },
  {
    "id": "arXiv:2205.02189",
    "title": "Maximum-utility popular matchings with bounded instability",
    "abstract": "In a graph where vertices have preferences over their neighbors, a matching\nis called popular if it does not lose a head-to-head election against any other\nmatching when the vertices vote between the matchings. Popular matchings can be\nseen as an intermediate category between stable matchings and maximum-size\nmatchings. In this paper, we aim to maximize the utility of a matching that is\npopular but admits only a few blocking edges.\nFor general graphs already finding a popular matching with at most one\nblocking edge is NP-complete. For bipartite instances, we study the problem of\nfinding a maximum-utility popular matching with a bound on the number (or more\ngenerally, the cost) of blocking edges applying a multivariate approach. We\nshow classical and parameterized hardness results for severely restricted\ninstances. By contrast, we design an algorithm for instances where preferences\non one side admit a master list, and show that this algorithm is optimal.",
    "descriptor": "",
    "authors": [
      "Ildik\u00f3 Schlotter",
      "\u00c1gnes Cseh"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.02189"
  },
  {
    "id": "arXiv:2205.02190",
    "title": "Ontology-Mediated Querying on Databases of Bounded Cliquewidth",
    "abstract": "We study the evaluation of ontology-mediated queries (OMQs) on databases of\nbounded cliquewidth from the viewpoint of parameterized complexity theory. As\nthe ontology language, we consider the description logics $\\mathcal{ALC}$ and\n$\\mathcal{ALCI}$ as well as the guarded two-variable fragment GF$_2$ of\nfirst-order logic. Queries are atomic queries (AQs), conjunctive queries (CQs),\nand unions of CQs. All studied OMQ problems are fixed-parameter linear (FPL)\nwhen the parameter is the size of the OMQ plus the cliquewidth. Our main\ncontribution is a detailed analysis of the dependence of the running time on\nthe parameter, exhibiting several interesting effects.",
    "descriptor": "",
    "authors": [
      "Carsten Lutz",
      "Leif Sabellek",
      "Lukas Schulze"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.02190"
  },
  {
    "id": "arXiv:2205.02202",
    "title": "Two-step Planning of Dynamic UAV Trajectories using Iterative  $\u03b4$-Spaces",
    "abstract": "UAV trajectory planning is often done in a two-step approach, where a\nlow-dimensional path is refined to a dynamic trajectory. The resulting\ntrajectories are only locally optimal, however. On the other hand, direct\nplanning in higher-dimensional state spaces generates globally optimal\nsolutions but is time-consuming and thus infeasible for time-constrained\napplications. To address this issue, we propose $\\delta$-Spaces, a pruned\nhigh-dimensional state space representation for trajectory refinement. It does\nnot only contain the area around a single lower-dimensional path but consists\nof the union of multiple near-optimal paths. Thus, it is less prone to local\nminima. Furthermore, we propose an anytime algorithm using $\\delta$-Spaces of\nincreasing sizes. We compare our method against state-of-the-art search-based\ntrajectory planning methods and evaluate it in 2D and 3D environments to\ngenerate second-order and third-order UAV trajectories.",
    "descriptor": "\nComments: Accepted for 17th International Conference on Intelligent Autonomous Systems (IAS), Zagreb, Croatia, to appear June 2022\n",
    "authors": [
      "Sebastian Schr\u00e4der",
      "Daniel Schleich",
      "Sven Behnke"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.02202"
  },
  {
    "id": "arXiv:2205.02203",
    "title": "Graphical Games for UAV Swarm Control Under Time-Varying Communication  Networks",
    "abstract": "We propose a unified framework for coordinating Unmanned Aerial Vehicle (UAV)\nswarms operating under time-varying communication networks. Our framework\nbuilds on the concept of graphical games, which we argue provides a compelling\nparadigm to subsume the interaction structures found in networked UAV swarms\nthanks to the shared local neighborhood properties. We present a general-sum,\nfactorizable payoff function for cooperative UAV swarms based on the aggregated\nlocal states and yield a Nash equilibrium for the stage games. Further, we\npropose a decomposition-based approach to solve stage-graphical games in a\nscalable and decentralized fashion by approximating virtual, mean\nneighborhoods. Finally, we discuss extending the proposed framework toward\ngeneral-sum stochastic games by leveraging deep Q-learning and model-predictive\ncontrol.",
    "descriptor": "\nComments: Presented in Workshop on Intelligent Aerial Robotics, International Conference on Robotics and Automation, 2022\n",
    "authors": [
      "Malintha Fernando",
      "Ransalu Senanayake",
      "Ariful Azad",
      "Martin Swany"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.02203"
  },
  {
    "id": "arXiv:2205.02206",
    "title": "Numerical analysis of non-local calculus on finite weighted graphs, with  application to reduced-order modelling of dynamical systems",
    "abstract": "We present an approach to reduced-order modelling that builds off recent\ngraph-theoretic work for representation, exploration, and analysis of computed\nstates of physical systems (Banerjee et al., Comp. Meth. App. Mech. Eng., 351,\n501-530, 2019). We extend a non-local calculus on finite weighted graphs to\nbuild such models by exploiting polynomial expansions and Taylor series. In the\ngeneral framework for non-local calculus on graphs, the graph edge weights are\nintricately linked to the embedding of the graph, and consequently to the\ndefinition of the derivatives. In a previous communication (Duschenes and\nGarikipati, arXiv:2105.01740), we have shown that radially symmetric,\ncontinuous edge weights derived from, for example Gaussian functions, yield\ninconsistent results in the resulting non-local derivatives when compared\nagainst the corresponding local, differential derivative definitions. Taking\ninspiration from finite difference methods, we algorithmically compute edge\nweights, considering the embedding of the local neighborhood of each graph\nvertex. Given this procedure, we ensure the consistency of the non-local\nderivatives in this setting, a crucial requirement for numerical applications.\nWe show that we can achieve any desired orders of accuracy of derivatives, in a\nchosen number of dimensions without symmetry assumptions in the underlying\ndata. Finally, we present two example applications of extracting reduced-order\nmodels using this non-local calculus, in the form of ordinary differential\nequations from parabolic partial differential equations of progressively\ngreater complexity.",
    "descriptor": "\nComments: 68 pages, 23 figures\n",
    "authors": [
      "Matthew Duschenes",
      "Siddhartha Srivastava",
      "Krishna Garikipati"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.02206"
  },
  {
    "id": "arXiv:2205.02208",
    "title": "WeakSATD: Detecting Weak Self-admitted Technical Debt",
    "abstract": "Speeding up development may produce technical debt, i.e., not-quite-right\ncode for which the effort to make it right increases with time as a sort of\ninterest. Developers may be aware of the debt as they admit it in their code\ncomments. Literature reports that such a self-admitted technical debt survives\nfor a long time in a program, but it is not yet clear its impact on the quality\nof the code in the long term. We argue that self-admitted technical debt\ncontains a number of different weaknesses that may affect the security of a\nprogram. Therefore, the longer a debt is not paid back the higher is the risk\nthat the weaknesses can be exploited. To discuss our claim and rise the\ndevelopers' awareness of the vulnerability of the self-admitted technical debt\nthat is not paid back, we explore the self-admitted technical debt in the\nChromium C-code to detect any known weaknesses. In this preliminary study, we\nfirst mine the Common Weakness Enumeration repository to define heuristics for\nthe automatic detection and fix of weak code. Then, we parse the C-code to find\nself-admitted technical debt and the code block it refers to. Finally, we use\nthe heuristics to find weak code snippets associated to self-admitted technical\ndebt and recommend their potential mitigation to developers. Such knowledge can\nbe used to prioritize self-admitted technical debt for repair. A prototype has\nbeen developed and applied to the Chromium code. Initial findings report that\n55\\% of self-admitted technical debt code contains weak code of 14 different\ntypes.",
    "descriptor": "\nComments: short paper\n",
    "authors": [
      "Barbara Russo",
      "Matteo Camilli",
      "Moritz Mock"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.02208"
  },
  {
    "id": "arXiv:2205.02209",
    "title": "Semi-Supervised Cascaded Clustering for Classification of Noisy Label  Data",
    "abstract": "The performance of supervised classification techniques often deteriorates\nwhen the data has noisy labels. Even the semi-supervised classification\napproaches have largely focused only on the problem of handling missing labels.\nMost of the approaches addressing the noisy label data rely on deep neural\nnetworks (DNN) that require huge datasets for classification tasks. This poses\na serious challenge especially in process and manufacturing industries, where\nthe data is limited and labels are noisy. We propose a semi-supervised cascaded\nclustering (SSCC) algorithm to extract patterns and generate a cascaded tree of\nclasses in such datasets. A novel cluster evaluation matrix (CEM) with\nconfigurable hyperparameters is introduced to localize and eliminate the noisy\nlabels and invoke a pruning criterion on cascaded clustering. The algorithm\nreduces the dependency on expensive human expertise for assessing the accuracy\nof labels. A classifier generated based on SSCC is found to be accurate and\nconsistent even when trained on noisy label datasets. It performed better in\ncomparison with the support vector machines (SVM) when tested on multiple\nnoisy-label datasets, including an industrial dataset. The proposed approach\ncan be effectively used for deriving actionable insights in industrial settings\nwith minimal human expertise.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Ashit Gupta",
      "Anirudh Deodhar",
      "Tathagata Mukherjee",
      "Venkataramana Runkana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.02209"
  },
  {
    "id": "arXiv:2205.02211",
    "title": "User-Centric Gender Rewriting",
    "abstract": "In this paper, we define the task of gender rewriting in contexts involving\ntwo users (I and/or You) - first and second grammatical persons with\nindependent grammatical gender preferences. We focus on Arabic, a\ngender-marking morphologically rich language. We develop a multi-step system\nthat combines the positive aspects of both rule-based and neural rewriting\nmodels. Our results successfully demonstrate the viability of this approach on\na recently created corpus for Arabic gender rewriting, achieving 88.42 M2 F0.5\non a blind test set. Our proposed system improves over previous work on the\nfirst-person-only version of this task, by 3.05 absolute increase in M2 F0.5.\nWe demonstrate a use case of our gender rewriting system by using it to\npost-edit the output of a commercial MT system to provide personalized outputs\nbased on the users' grammatical gender preferences. We make our code, data, and\nmodels publicly available.",
    "descriptor": "\nComments: Accepted at NAACL 2022\n",
    "authors": [
      "Bashar Alhafni",
      "Nizar Habash",
      "Houda Bouamor"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.02211"
  },
  {
    "id": "arXiv:2205.02215",
    "title": "FEDNEST: Federated Bilevel, Minimax, and Compositional Optimization",
    "abstract": "Standard federated optimization methods successfully apply to stochastic\nproblems with \\textit{single-level} structure. However, many contemporary ML\nproblems -- including adversarial robustness, hyperparameter tuning, and\nactor-critic -- fall under nested bilevel programming that subsumes minimax and\ncompositional optimization. In this work, we propose FedNest: A federated\nalternating stochastic gradient method to address general nested problems. We\nestablish provable convergence rates for FedNest in the presence of\nheterogeneous data and introduce variations for bilevel, minimax, and\ncompositional optimization. FedNest introduces multiple innovations including\nfederated hypergradient computation and variance reduction to address\ninner-level heterogeneity. We complement our theory with experiments on\nhyperparameter \\& hyper-representation learning and minimax optimization that\ndemonstrate the benefits of our method in practice. Code is available at\nhttps://github.com/mc-nya/FedNest.",
    "descriptor": "",
    "authors": [
      "Davoud Ataee Tarzanagh",
      "Mingchen Li",
      "Christos Thrampoulidis",
      "Samet Oymak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.02215"
  },
  {
    "id": "arXiv:2205.02216",
    "title": "The Extremal GDoF Gain of Optimal versus Binary Power Control in $K$  User Interference Networks Is $\u0398(\\sqrt{K})$",
    "abstract": "Using ideas from Generalized Degrees of Freedom (GDoF) analyses and extremal\nnetwork theory, this work studies the extremal gain of optimal power control\nover binary power control, especially in large interference networks, in search\nof new theoretical insights. Whereas numerical studies have established that in\nmost practical settings binary power control is close to optimal, the extremal\nanalysis shows not only there exist settings where the gain from optimal power\ncontrol can be quite significant, but also bounds the extremal values of such\ngains from a GDoF perspective. As its main contribution, we explicitly\ncharacterizes the extremal GDoF gain of optimal over binary power control as\n$\\Theta(\\sqrt{K})$ for all $K$. In particular, the extremal gain is bounded\nbetween $\\lfloor \\sqrt{K}\\rfloor$ and $2.5\\sqrt{K}$ for every $K$. For\n$K=2,3,4,5,6$ users, the precise extremal gain is $1, 3/2, 2, 9/4$ and $41/16$,\nrespectively. Networks shown to achieve the extremal gain may be interpreted as\nmulti-tier heterogeneous networks. It is worthwhile to note that because of\ntheir focus on asymptotic analysis, the sharp characterizations of extremal\ngains are valuable primarily from a theoretical perspective, and not as\ncontradictions to the conventional wisdom that binary power control is\ngenerally close to optimal in practical, non-asymptotic settings.",
    "descriptor": "\nComments: 18 pages, 5 figures\n",
    "authors": [
      "Yao-Chia Chan",
      "Pouya Pezeshkpour",
      "Chunhua Geng",
      "Syed A. Jafar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.02216"
  },
  {
    "id": "arXiv:2205.02220",
    "title": "Chasing Streams with Existential Rules",
    "abstract": "We study reasoning with existential rules to perform query answering over\nstreams of data. On static databases, this problem has been widely studied, but\nits extension to rapidly changing data has not yet been considered. To bridge\nthis gap, we extend LARS, a well-known framework for rule-based stream\nreasoning, to support existential rules. For that, we show how to translate\nLARS with existentials into a semantics-preserving set of existential rules. As\nquery answering with such rules is undecidable in general, we describe how to\nleverage the temporal nature of streams and present suitable notions of\nacyclicity that ensure decidability.",
    "descriptor": "\nComments: Accepted at KR 2022\n",
    "authors": [
      "Jacopo Urbani",
      "Markus Kr\u00f6tzsch",
      "Thomas Eiter"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2205.02220"
  },
  {
    "id": "arXiv:2205.02222",
    "title": "COOPERNAUT: End-to-End Driving with Cooperative Perception for Networked  Vehicles",
    "abstract": "Optical sensors and learning algorithms for autonomous vehicles have\ndramatically advanced in the past few years. Nonetheless, the reliability of\ntoday's autonomous vehicles is hindered by the limited line-of-sight sensing\ncapability and the brittleness of data-driven methods in handling extreme\nsituations. With recent developments of telecommunication technologies,\ncooperative perception with vehicle-to-vehicle communications has become a\npromising paradigm to enhance autonomous driving in dangerous or emergency\nsituations. We introduce COOPERNAUT, an end-to-end learning model that uses\ncross-vehicle perception for vision-based cooperative driving. Our model\nencodes LiDAR information into compact point-based representations that can be\ntransmitted as messages between vehicles via realistic wireless channels. To\nevaluate our model, we develop AutoCastSim, a network-augmented driving\nsimulation framework with example accident-prone scenarios. Our experiments on\nAutoCastSim suggest that our cooperative perception driving models lead to a\n40% improvement in average success rate over egocentric driving models in these\nchallenging driving situations and a 5 times smaller bandwidth requirement than\nprior work V2VNet. COOPERNAUT and AUTOCASTSIM are available at\nhttps://ut-austin-rpl.github.io/Coopernaut/.",
    "descriptor": "",
    "authors": [
      "Jiaxun Cui",
      "Hang Qiu",
      "Dian Chen",
      "Peter Stone",
      "Yuke Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.02222"
  },
  {
    "id": "arXiv:2205.02223",
    "title": "Semi-supervised learning approaches for predicting South African  political sentiment for local government elections",
    "abstract": "This study aims to understand the South African political context by\nanalysing the sentiments shared on Twitter during the local government\nelections. An emphasis on the analysis was placed on understanding the\ndiscussions led around four predominant political parties ANC, DA, EFF and\nActionSA. A semi-supervised approach by means of a graph-based technique to\nlabel the vast accessible Twitter data for the classification of tweets into\nnegative and positive sentiment was used. The tweets expressing negative\nsentiment were further analysed through latent topic extraction to uncover\nhidden topics of concern associated with each of the political parties. Our\nfindings demonstrated that the general sentiment across South African Twitter\nusers is negative towards all four predominant parties with the worst negative\nsentiment among users projected towards the current ruling party, ANC, relating\nto concerns cantered around corruption, incompetence and loadshedding.",
    "descriptor": "\nComments: Accepted for DGO 2022\n",
    "authors": [
      "Mashadi Ledwaba",
      "Vukosi Marivate"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.02223"
  },
  {
    "id": "arXiv:2205.02225",
    "title": "HiURE: Hierarchical Exemplar Contrastive Learning for Unsupervised  Relation Extraction",
    "abstract": "Unsupervised relation extraction aims to extract the relationship between\nentities from natural language sentences without prior information on\nrelational scope or distribution. Existing works either utilize self-supervised\nschemes to refine relational feature signals by iteratively leveraging adaptive\nclustering and classification that provoke gradual drift problems, or adopt\ninstance-wise contrastive learning which unreasonably pushes apart those\nsentence pairs that are semantically similar. To overcome these defects, we\npropose a novel contrastive learning framework named HiURE, which has the\ncapability to derive hierarchical signals from relational feature space using\ncross hierarchy attention and effectively optimize relation representation of\nsentences under exemplar-wise contrastive learning. Experimental results on two\npublic datasets demonstrate the advanced effectiveness and robustness of HiURE\non unsupervised relation extraction when compared with state-of-the-art models.",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Shuliang Liu",
      "Xuming Hu",
      "Chenwei Zhang",
      "Shu`ang Li",
      "Lijie Wen",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.02225"
  },
  {
    "id": "arXiv:2205.02226",
    "title": "Density functions of periodic sequences",
    "abstract": "Periodic point sets model all solid crystalline materials whose structures\nare determined in a rigid form and should be studied up to rigid motion or\nisometry preserving inter-point distances. In 2021 H.Edelsbrunner et al.\nintroduced an infinite sequence of density functions that are continuous\nisometry invariants of periodic point sets. These density functions turned out\nto be highly non-trivial even in dimension 1 for periodic sequences of points\nin the line. This paper fully describes the density functions of any periodic\nsequence and their symmetry properties. The explicit description theoretically\nconfirms coincidences of density functions that were previously computed only\nthrough finite samples.",
    "descriptor": "\nComments: 12 pages, 4 figures, the latest version is at this http URL arXiv admin note: substantial text overlap with arXiv:2103.02749\n",
    "authors": [
      "Olga Anosova",
      "Vitaliy Kurlin"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2205.02226"
  },
  {
    "id": "arXiv:2205.01673",
    "title": "A Deep Learning-based Integrated Framework for Quality-aware  Undersampled Cine Cardiac MRI Reconstruction and Analysis",
    "abstract": "Cine cardiac magnetic resonance (CMR) imaging is considered the gold standard\nfor cardiac function evaluation. However, cine CMR acquisition is inherently\nslow and in recent decades considerable effort has been put into accelerating\nscan times without compromising image quality or the accuracy of derived\nresults. In this paper, we present a fully-automated, quality-controlled\nintegrated framework for reconstruction, segmentation and downstream analysis\nof undersampled cine CMR data. The framework enables active acquisition of\nradial k-space data, in which acquisition can be stopped as soon as acquired\ndata are sufficient to produce high quality reconstructions and segmentations.\nThis results in reduced scan times and automated analysis, enabling robust and\naccurate estimation of functional biomarkers. To demonstrate the feasibility of\nthe proposed approach, we perform realistic simulations of radial k-space\nacquisitions on a dataset of subjects from the UK Biobank and present results\non in-vivo cine CMR k-space data collected from healthy subjects. The results\ndemonstrate that our method can produce quality-controlled images in a mean\nscan time reduced from 12 to 4 seconds per slice, and that image quality is\nsufficient to allow clinically relevant parameters to be automatically\nestimated to within 5% mean absolute difference.",
    "descriptor": "",
    "authors": [
      "In\u00eas P. Machado",
      "Esther Puyol-Ant\u00f3n",
      "Kerstin Hammernik",
      "Gast\u00e3o Cruz",
      "Devran Ugurlu",
      "Ihsane Olakorede",
      "Ilkay Oksuz",
      "Bram Ruijsink",
      "Miguel Castelo-Branco",
      "Alistair A. Young",
      "Claudia Prieto",
      "Julia A. Schnabel",
      "Andrew P. King"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01673"
  },
  {
    "id": "arXiv:2205.01674",
    "title": "MIRST-DM: Multi-Instance RST with Drop-Max Layer for Robust  Classification of Breast Cancer",
    "abstract": "Robust self-training (RST) can augment the adversarial robustness of image\nclassification models without significantly sacrificing models'\ngeneralizability. However, RST and other state-of-the-art defense approaches\nfailed to preserve the generalizability and reproduce their good adversarial\nrobustness on small medical image sets. In this work, we propose the\nMulti-instance RST with a drop-max layer, namely MIRST-DM, which involves a\nsequence of iteratively generated adversarial instances during training to\nlearn smoother decision boundaries on small datasets. The proposed drop-max\nlayer eliminates unstable features and helps learn representations that are\nrobust to image perturbations. The proposed approach was validated using a\nsmall breast ultrasound dataset with 1,190 images. The results demonstrate that\nthe proposed approach achieves state-of-the-art adversarial robustness against\nthree prevalent attacks.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Shoukun Sun",
      "Min Xian",
      "Aleksandar Vakanski",
      "Hossny Ghanem"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01674"
  },
  {
    "id": "arXiv:2205.01675",
    "title": "Deep Learning Framework for Real-time Fetal Brain Segmentation in MRI",
    "abstract": "Fetal brain segmentation is an important first step for slice-level motion\ncorrection and slice-to-volume reconstruction in fetal MRI. Fast and accurate\nsegmentation of the fetal brain on fetal MRI is required to achieve real-time\nfetal head pose estimation and motion tracking for slice re-acquisition and\nsteering. To address this critical unmet need, in this work we analyzed the\nspeed-accuracy performance of a variety of deep neural network models, and\ndevised a symbolically small convolutional neural network that combines spatial\ndetails at high resolution with context features extracted at lower\nresolutions. We used multiple branches with skip connections to maintain high\naccuracy while devising a parallel combination of convolution and pooling\noperations as an input downsampling module to further reduce inference time. We\ntrained our model as well as eight alternative, state-of-the-art networks with\nmanually-labeled fetal brain MRI slices and tested on two sets of normal and\nchallenging test cases. Experimental results show that our network achieved the\nhighest accuracy and lowest inference time among all of the compared\nstate-of-the-art real-time segmentation methods. We achieved average Dice\nscores of 97.99\\% and 84.04\\% on the normal and challenging test sets,\nrespectively, with an inference time of 3.36 milliseconds per image on an\nNVIDIA GeForce RTX 2080 Ti. Code, data, and the trained models are available at\nhttps://github.com/bchimagine/real_time_fetal_brain_segmentation.",
    "descriptor": "\nComments: 11 pages, 5 figures, submitted to Medical Image Computing and Computer Assisted Intervention (MICCAI) Conference\n",
    "authors": [
      "Razieh Faghihpirayesh",
      "Davood Karimi",
      "Deniz Erdogmus",
      "Ali Gholipour"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01675"
  },
  {
    "id": "arXiv:2205.01676",
    "title": "FundusQ-Net: a Regression Quality Assessment Deep Learning Algorithm for  Fundus Images Quality Grading",
    "abstract": "Objective: Ophthalmological pathologies such as glaucoma, diabetic\nretinopathy and age-related macular degeneration are major causes of blindness\nand vision impairment. There is a need for novel decision support tools that\ncan simplify and speed up the diagnosis of these pathologies. A key step in\nthis process is to automatically estimate the quality of the fundus images to\nmake sure these are interpretable by a human operator or a machine learning\nmodel. We present a novel fundus image quality scale and deep learning (DL)\nmodel that can estimate fundus image quality relative to this new scale.\nMethods: A total of 1,245 images were graded for quality by two\nophthalmologists within the range 1-10, with a resolution of 0.5. A DL\nregression model was trained for fundus image quality assessment. The\narchitecture used was Inception-V3. The model was developed using a total of\n89,947 images from 6 databases, of which 1,245 were labeled by the specialists\nand the remaining 88,702 images were used for pre-training and semi-supervised\nlearning. The final DL model was evaluated on an internal test set (n=209) as\nwell as an external test set (n=194).\nResults: The final DL model, denoted FundusQ-Net, achieved a mean absolute\nerror of 0.61 (0.54-0.68) on the internal test set. When evaluated as a binary\nclassification model on the public DRIMDB database as an external test set the\nmodel obtained an accuracy of 99%.\nSignificance: the proposed algorithm provides a new robust tool for automated\nquality grading of fundus images.",
    "descriptor": "\nComments: 7 pages, 7 figures, submitted to Computer Methods and Programs in Biomedicine\n",
    "authors": [
      "Or Abramovich",
      "Hadas Pizem",
      "Jan Van Eijgen",
      "Ingeborg Stalmans",
      "Eytan Blumenthal",
      "Joachim A. Behar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01676"
  },
  {
    "id": "arXiv:2205.01677",
    "title": "ASTROMER: A transformer-based embedding for the representation of light  curves",
    "abstract": "Taking inspiration from natural language embeddings, we present ASTROMER, a\ntransformer-based model to create representations of light curves. ASTROMER was\ntrained on millions of MACHO R-band samples, and it can be easily fine-tuned to\nmatch specific domains associated with downstream tasks. As an example, this\npaper shows the benefits of using pre-trained representations to classify\nvariable stars. In addition, we provide a python library including all\nfunctionalities employed in this work. Our library includes the pre-trained\nmodels that can be used to enhance the performance of deep learning models,\ndecreasing computational resources while achieving state-of-the-art results.",
    "descriptor": "",
    "authors": [
      "C. Donoso-Oliva",
      "I. Becker",
      "P. Protopapas",
      "G. Cabrera-Vives",
      "Vishnu M.",
      "Harsh Vardhan"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01677"
  },
  {
    "id": "arXiv:2205.01679",
    "title": "Physics to the Rescue: Deep Non-line-of-sight Reconstruction for  High-speed Imaging",
    "abstract": "Computational approach to imaging around the corner, or non-line-of-sight\n(NLOS) imaging, is becoming a reality thanks to major advances in imaging\nhardware and reconstruction algorithms. A recent development towards practical\nNLOS imaging, Nam et al. demonstrated a high-speed non-confocal imaging system\nthat operates at 5Hz, 100x faster than the prior art. This enormous gain in\nacquisition rate, however, necessitates numerous approximations in light\ntransport, breaking many existing NLOS reconstruction methods that assume an\nidealized image formation model. To bridge the gap, we present a novel deep\nmodel that incorporates the complementary physics priors of wave propagation\nand volume rendering into a neural network for high-quality and robust NLOS\nreconstruction. This orchestrated design regularizes the solution space by\nrelaxing the image formation model, resulting in a deep model that generalizes\nwell on real captures despite being exclusively trained on synthetic data.\nFurther, we devise a unified learning framework that enables our model to be\nflexibly trained using diverse supervision signals, including target intensity\nimages or even raw NLOS transient measurements. Once trained, our model renders\nboth intensity and depth images at inference time in a single forward pass,\ncapable of processing more than 5 captures per second on a high-end GPU.\nThrough extensive qualitative and quantitative experiments, we show that our\nmethod outperforms prior physics and learning based approaches on both\nsynthetic and real measurements. We anticipate that our method along with the\nfast capturing system will accelerate future development of NLOS imaging for\nreal world applications that require high-speed imaging.",
    "descriptor": "\nComments: Tech report\n",
    "authors": [
      "Fangzhou Mu",
      "Sicheng Mo",
      "Jiayong Peng",
      "Xiaochun Liu",
      "Ji Hyun Nam",
      "Siddeshwar Raghavan",
      "Andreas Velten",
      "Yin Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01679"
  },
  {
    "id": "arXiv:2205.01683",
    "title": "SpineNetV2: Automated Detection, Labelling and Radiological Grading Of  Clinical MR Scans",
    "abstract": "This technical report presents SpineNetV2, an automated tool which: (i)\ndetects and labels vertebral bodies in clinical spinal magnetic resonance (MR)\nscans across a range of commonly used sequences; and (ii) performs radiological\ngrading of lumbar intervertebral discs in T2-weighted scans for a range of\ncommon degenerative changes. SpineNetV2 improves over the original SpineNet\nsoftware in two ways: (1) The vertebral body detection stage is significantly\nfaster, more accurate and works across a range of fields-of-view (as opposed to\njust lumbar scans). (2) Radiological grading adopts a more powerful\narchitecture, adding several new grading schemes without loss in performance. A\ndemo of the software is available at the project website:\nthis http URL",
    "descriptor": "\nComments: Technical Report, 22 pages, 9 Figures\n",
    "authors": [
      "Rhydian Windsor",
      "Amir Jamaludin",
      "Timor Kadir",
      "Andrew Zisserman"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01683"
  },
  {
    "id": "arXiv:2205.01684",
    "title": "Effect of Random Histogram Equalization on Breast Calcification Analysis  Using Deep Learning",
    "abstract": "Early detection and analysis of calcifications in mammogram images is crucial\nin a breast cancer diagnosis workflow. Management of calcifications that\nrequire immediate follow-up and further analyzing its benignancy or malignancy\ncan result in a better prognosis. Recent studies have shown that deep\nlearning-based algorithms can learn robust representations to analyze\nsuspicious calcifications in mammography. In this work, we demonstrate that\nrandomly equalizing the histograms of calcification patches as a data\naugmentation technique can significantly improve the classification performance\nfor analyzing suspicious calcifications. We validate our approach by using the\nCBIS-DDSM dataset for two classification tasks. The results on both the tasks\nshow that the proposed methodology gains more than 1% mean accuracy and\nF1-score when equalizing the data with a probability of 0.4 when compared to\nnot using histogram equalization. This is further supported by the t-tests,\nwhere we obtain a p-value of p<0.0001, thus showing the statistical\nsignificance of our approach.",
    "descriptor": "\nComments: Accepted at Bildverarbeitung f\\\"ur die Medizin (BVM) Workshop 2022\n",
    "authors": [
      "Adarsh Bhandary Panambur",
      "Prathmesh Madhu",
      "Andreas Maier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01684"
  },
  {
    "id": "arXiv:2205.01698",
    "title": "On Circuit Depth Scaling For Quantum Approximate Optimization",
    "abstract": "Variational quantum algorithms are the centerpiece of modern quantum\nprogramming. These algorithms involve training parameterized quantum circuits\nusing a classical co-processor, an approach adapted partly from classical\nmachine learning. An important subclass of these algorithms, designed for\ncombinatorial optimization on currrent quantum hardware, is the quantum\napproximate optimization algorithm (QAOA). It is known that problem density - a\nproblem constraint to variable ratio - induces under-parametrization in fixed\ndepth QAOA. Density dependent performance has been reported in the literature,\nyet the circuit depth required to achieve fixed performance (henceforth called\ncritical depth) remained unknown. Here, we propose a predictive model, based on\na logistic saturation conjecture for critical depth scaling with respect to\ndensity. Focusing on random instances of MAX-2-SAT, we test our predictive\nmodel against simulated data with up to 15 qubits. We report the average\ncritical depth, required to attain a success probability of 0.7, saturates at a\nvalue of 10 for densities beyond 4. We observe the predictive model to describe\nthe simulated data within a $3\\sigma$ confidence interval. Furthermore, based\non the model, a linear trend for the critical depth with respect problem size\nis recovered for the range of 5 to 15 qubits.",
    "descriptor": "\nComments: REVTeX, 6+2 pages, 4 figures\n",
    "authors": [
      "V. Akshay",
      "H. Philathong",
      "E. Campos",
      "D. Rabinovich",
      "I. Zacharov",
      "Xiao-Ming Zhang",
      "J. Biamonte"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01698"
  },
  {
    "id": "arXiv:2205.01753",
    "title": "Self-focusing virtual screening with active design space pruning",
    "abstract": "High-throughput virtual screening is an indispensable technique utilized in\nthe discovery of small molecules. In cases where the library of molecules is\nexceedingly large, the cost of an exhaustive virtual screen may be prohibitive.\nModel-guided optimization has been employed to lower these costs through\ndramatic increases in sample efficiency compared to random selection. However,\nthese techniques introduce new costs to the workflow through the surrogate\nmodel training and inference steps. In this study, we propose an extension to\nthe framework of model-guided optimization that mitigates inferences costs\nusing a technique we refer to as design space pruning (DSP), which irreversibly\nremoves poor-performing candidates from consideration. We study the application\nof DSP to a variety of optimization tasks and observe significant reductions in\noverhead costs while exhibiting similar performance to the baseline\noptimization. DSP represents an attractive extension of model-guided\noptimization that can limit overhead costs in optimization settings where these\ncosts are non-negligible relative to objective costs, such as docking.",
    "descriptor": "\nComments: 47 pages, 26 figures, 3 tables\n",
    "authors": [
      "David E. Graff",
      "Matteo Aldeghi",
      "Joseph A. Morrone",
      "Kirk E. Jordan",
      "Edward O. Pyzer-Knapp",
      "Connor W. Coley"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01753"
  },
  {
    "id": "arXiv:2205.01754",
    "title": "B\u00e9zier Curve Gaussian Processes",
    "abstract": "Probabilistic models for sequential data are the basis for a variety of\napplications concerned with processing timely ordered information. The\npredominant approach in this domain is given by neural networks, which\nincorporate either stochastic units or components. This paper proposes a new\nprobabilistic sequence model building on probabilistic B\\'ezier curves. Using\nGaussian distributed control points, these parametric curves pose a special\ncase for Gaussian processes (GP). Combined with a Mixture Density network,\nBayesian conditional inference can be performed without the need for mean field\nvariational approximation or Monte Carlo simulation, which is a requirement of\ncommon approaches. For assessing this hybrid model's viability, it is applied\nto an exemplary sequence prediction task. In this case the model is used for\npedestrian trajectory prediction, where a generated prediction also serves as a\nGP prior. Following this, the initial prediction can be refined using the GP\nframework by calculating different posterior distributions, in order to adapt\nmore towards a given observed trajectory segment.",
    "descriptor": "",
    "authors": [
      "Ronny Hug",
      "Stefan Becker",
      "Wolfgang H\u00fcbner",
      "Michael Arens",
      "J\u00fcrgen Beyerer"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01754"
  },
  {
    "id": "arXiv:2205.01770",
    "title": "Data-Consistent Non-Cartesian Deep Subspace Learning for Efficient  Dynamic MR Image Reconstruction",
    "abstract": "Non-Cartesian sampling with subspace-constrained image reconstruction is a\npopular approach to dynamic MRI, but slow iterative reconstruction limits its\nclinical application. Data-consistent (DC) deep learning can accelerate\nreconstruction with good image quality, but has not been formulated for\nnon-Cartesian subspace imaging. In this study, we propose a DC non-Cartesian\ndeep subspace learning framework for fast, accurate dynamic MR image\nreconstruction. Four novel DC formulations are developed and evaluated: two\ngradient decent approaches, a directly solved approach, and a conjugate\ngradient approach. We applied a U-Net model with and without DC layers to\nreconstruct T1-weighted images for cardiac MR Multitasking (an advanced\nmultidimensional imaging method), comparing our results to the iteratively\nreconstructed reference. Experimental results show that the proposed framework\nsignificantly improves reconstruction accuracy over the U-Net model without DC,\nwhile significantly accelerating the reconstruction over conventional iterative\nreconstruction.",
    "descriptor": "\nComments: Accepted by IEEE ISBI 2022\n",
    "authors": [
      "Zihao Chen",
      "Yuhua Chen",
      "Yibin Xie",
      "Debiao Li",
      "Anthony G. Christodoulou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01770"
  },
  {
    "id": "arXiv:2205.01773",
    "title": "Optimal minimization of the covariance loss",
    "abstract": "Let $X$ be a random vector valued in $\\mathbb{R}^{m}$ such that $\\|X\\|_{2}\n\\le 1$ almost surely. For every $k\\ge 3$, we show that there exists a sigma\nalgebra $\\mathcal{F}$ generated by a partition of $\\mathbb{R}^{m}$ into $k$\nsets such that\n\\[\\|\\operatorname{Cov}(X) - \\operatorname{Cov}(\\mathbb{E}[X\\mid\\mathcal{F}])\n\\|_{\\mathrm{F}} \\lesssim \\frac{1}{\\sqrt{\\log{k}}}.\\] This is optimal up to\nthe implicit constant and improves on a previous bound due to Boedihardjo,\nStrohmer, and Vershynin.\nOur proof provides an efficient algorithm for constructing $\\mathcal{F}$ and\nleads to improved accuracy guarantees for $k$-anonymous or differentially\nprivate synthetic data. We also establish a connection between the above\nproblem of minimizing the covariance loss and the pinning lemma from\nstatistical physics, providing an alternate (and much simpler) algorithmic\nproof in the important case when $X \\in \\{\\pm 1\\}^m/\\sqrt{m}$ almost surely.",
    "descriptor": "\nComments: 9 pages; comments welcome\n",
    "authors": [
      "Vishesh Jain",
      "Ashwin Sah",
      "Mehtaab Sawhney"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.01773"
  },
  {
    "id": "arXiv:2205.01775",
    "title": "Proximal stabilized Interior Point Methods for quadratic programming and  low-frequency-updates preconditioning techniques",
    "abstract": "In this work, in the context of Linear and Quadratic Programming, we\ninterpret Primal Dual Regularized Interior Point Methods (PDR-IPMs) in the\nframework of the Proximal Point Method. The resulting Proximal Stabilized IPM\n(PS-IPM) is strongly supported by theoretical results concerning convergence\nand the rate of convergence, and can handle degenerate problems. Moreover, in\nthe second part of this work, we analyse the interactions between the\nregularization parameters and the computational foot-print of the linear\nalgebra routines used to solve the Newton linear systems. In particular, when\nthese systems are solved using an iterative Krylov method, we propose general\npurpose preconditioners which, exploiting the regularization and a new\nrearrangement of the Schur complement, remain attractive for a series of\nsubsequent IPM iterations. Therefore they need to be recomputed only in a\nfraction of the total IPM iterations. The resulting regularized second order\nmethods, for which low-frequency-updates of the preconditioners are allowed,\npave the path for an alternative third way in-between first and second order\nmethods.",
    "descriptor": "",
    "authors": [
      "Stefano Cipolla",
      "Jacek Gondzio"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.01775"
  },
  {
    "id": "arXiv:2205.01777",
    "title": "Deep Multi-Scale U-Net Architecture and Noise-Robust Training Strategies  for Histopathological Image Segmentation",
    "abstract": "Although the U-Net architecture has been extensively used for segmentation of\nmedical images, we address two of its shortcomings in this work. Firstly, the\naccuracy of vanilla U-Net degrades when the target regions for segmentation\nexhibit significant variations in shape and size. Even though the U-Net already\npossesses some capability to analyze features at various scales, we propose to\nexplicitly add multi-scale feature maps in each convolutional module of the\nU-Net encoder to improve segmentation of histology images. Secondly, the\naccuracy of a U-Net model also suffers when the annotations for supervised\nlearning are noisy or incomplete. This can happen due to the inherent\ndifficulty for a human expert to identify and delineate all instances of\nspecific pathology very precisely and accurately. We address this challenge by\nintroducing auxiliary confidence maps that emphasize less on the boundaries of\nthe given target regions. Further, we utilize the bootstrapping properties of\nthe deep network to address the missing annotation problem intelligently. In\nour experiments on a private dataset of breast cancer lymph nodes, where the\nprimary task was to segment germinal centres and sinus histiocytosis, we\nobserved substantial improvement over a U-Net baseline based on the two\nproposed augmentations.",
    "descriptor": "\nComments: 12 pages, 4 figures , 2 tables\n",
    "authors": [
      "Nikhil Cherian Kurian",
      "Amit Lohan",
      "Gregory Verghese",
      "Nimish Dharamshi",
      "Swati Meena",
      "Mengyuan Li",
      "Fangfang Liu",
      "Cheryl Gillet",
      "Swapnil Rane",
      "Anita Grigoriadis",
      "Amit Sethi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01777"
  },
  {
    "id": "arXiv:2205.01780",
    "title": "The ICML 2022 Expressive Vocalizations Workshop and Competition:  Recognizing, Generating, and Personalizing Vocal Bursts",
    "abstract": "The ICML Expressive Vocalization (ExVo) Competition is focused on\nunderstanding and generating vocal bursts: laughs, gasps, cries, and other\nnon-verbal vocalizations that are central to emotional expression and\ncommunication. ExVo 2022, includes three competition tracks using a large-scale\ndataset of 59,201 vocalizations from 1,702 speakers. The first, ExVo-MultiTask,\nrequires participants to train a multi-task model to recognize expressed\nemotions and demographic traits from vocal bursts. The second, ExVo-Generate,\nrequires participants to train a generative model that produces vocal bursts\nconveying ten different emotions. The third, ExVo-FewShot, requires\nparticipants to leverage few-shot learning incorporating speaker identity to\ntrain a model for the recognition of 10 emotions conveyed by vocal bursts. This\npaper describes the three tracks and provides performance measures for baseline\nmodels using state-of-the-art machine learning strategies. The baseline for\neach track is as follows, for ExVo-MultiTask, a combined score, computing the\nharmonic mean of Concordance Correlation Coefficient (CCC), Unweighted Average\nRecall (UAR), and inverted Mean Absolute Error (MAE) ($S_{MTL}$) is at best,\n0.335 $S_{MTL}$; for ExVo-Generate, we report Fr\\'echet inception distance\n(FID) scores ranging from 4.81 to 8.27 (depending on the emotion) between the\ntraining set and generated samples. We then combine the inverted FID with\nperceptual ratings of the generated samples ($S_{Gen}$) and obtain 0.174\n$S_{Gen}$; and for ExVo-FewShot, a mean CCC of 0.444 is obtained.",
    "descriptor": "",
    "authors": [
      "Alice Baird",
      "Panagiotis Tzirakis",
      "Gauthier Gidel",
      "Marco Jiralerspong",
      "Eilif B. Muller",
      "Kory Mathewson",
      "Bj\u00f6rn Schuller",
      "Erik Cambria",
      "Dacher Keltner",
      "Alan Cowen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2205.01780"
  },
  {
    "id": "arXiv:2205.01794",
    "title": "Meta-Cognition. An Inverse-Inverse Reinforcement Learning Approach for  Cognitive Radars",
    "abstract": "This paper considers meta-cognitive radars in an adversarial setting. A\ncognitive radar optimally adapts its waveform (response) in response to\nmaneuvers (probes) of a possibly adversarial moving target. A meta-cognitive\nradar is aware of the adversarial nature of the target and seeks to mitigate\nthe adversarial target. How should the meta-cognitive radar choose its\nresponses to sufficiently confuse the adversary trying to estimate the radar's\nutility function? This paper abstracts the radar's meta-cognition problem in\nterms of the spectra (eigenvalues) of the state and observation noise\ncovariance matrices, and embeds the algebraic Riccati equation into an\neconomics-based utility maximization setup. This adversarial target is an\ninverse reinforcement learner. By observing a noisy sequence of radar's\nresponses (waveforms), the adversarial target uses a statistical hypothesis\ntest to detect if the radar is a utility maximizer. In turn, the meta-cognitive\nradar deliberately chooses sub-optimal responses that increasing its Type-I\nerror probability of the adversary's detector. We call this counter-adversarial\nstep taken by the meta-cognitive radar as inverse inverse reinforcement\nlearning (I-IRL). We illustrate the meta-cognition results of this paper via\nsimple numerical examples. Our approach for meta-cognition in this paper is\nbased on revealed preference theory in micro-economics and inspired by results\nin differential privacy and adversarial obfuscation in machine learning.",
    "descriptor": "",
    "authors": [
      "Kunal Pattanayak",
      "Vikram Krishnamurthy",
      "Christopher Berry"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01794"
  },
  {
    "id": "arXiv:2205.01858",
    "title": "DeeptDCS: Deep Learning-Based Estimation of Currents Induced During  Transcranial Direct Current Stimulation",
    "abstract": "Objective: Transcranial direct current stimulation (tDCS) is a non-invasive\nbrain stimulation technique used to generate conduction currents in the head\nand disrupt brain functions. To rapidly evaluate the tDCS-induced current\ndensity in near real-time, this paper proposes a deep learning-based emulator,\nnamed DeeptDCS. Methods: The emulator leverages Attention U-net taking the\nvolume conductor models (VCMs) of head tissues as inputs and outputting the\nthree-dimensional current density distribution across the entire head. The\nelectrode configurations are also incorporated into VCMs without increasing the\nnumber of input channels; this enables the straightforward incorporation of the\nnon-parametric features of electrodes (e.g., thickness, shape, size, and\nposition) in the training and testing of the proposed emulator. Results:\nAttention U-net outperforms standard U-net and its other three variants\n(Residual U-net, Attention Residual U-net, and Multi-scale Residual U-net) in\nterms of accuracy. The generalization ability of DeeptDCS to non-trained\nelectrode positions can be greatly enhanced through fine-tuning the model. The\ncomputational time required by one emulation via DeeptDCS is a fraction of a\nsecond. Conclusion: DeeptDCS is at least two orders of magnitudes faster than a\nphysics-based open-source simulator, while providing satisfactorily accurate\nresults. Significance: The high computational efficiency permits the use of\nDeeptDCS in applications requiring its repetitive execution, such as\nuncertainty quantification and optimization studies of tDCS.",
    "descriptor": "",
    "authors": [
      "Xiaofan Jia",
      "Sadeed Bin Sayed",
      "Nahian Ibn Hasan",
      "Luis J. Gomez",
      "Guang-Bin Huang",
      "Abdulkadir C. Yucel"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.01858"
  },
  {
    "id": "arXiv:2205.01869",
    "title": "The College Application Problem",
    "abstract": "This paper considers the maximization of the expected maximum value of a\nportfolio of random variables subject to a budget constraint. We refer to this\nas the optimal college application problem. When each variable's cost, or each\ncollege's application fee, is identical, we show that the optimal portfolios\nare nested in the budget constraint, yielding an exact polynomial-time\nalgorithm. When colleges differ in their application fees, we show that the\nproblem is NP-complete. We provide four algorithms for this more general setup:\na branch-and-bound routine, a dynamic program that produces an exact solution\nin pseudopolynomial time, a different dynamic program that yields a fully\npolynomial-time approximation scheme, and a simulated-annealing heuristic.\nNumerical experiments demonstrate the algorithms' accuracy and efficiency.",
    "descriptor": "\nComments: 31 pages, 3 figures. We welcome comments\n",
    "authors": [
      "Max Kapur",
      "Sung-Pil Hong"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.01869"
  },
  {
    "id": "arXiv:2205.01874",
    "title": "Joint Image Compression and Denoising via Latent-Space Scalability",
    "abstract": "When it comes to image compression in digital cameras, denoising is\ntraditionally performed prior to compression. However, there are applications\nwhere image noise may be necessary to demonstrate the trustworthiness of the\nimage, such as court evidence and image forensics. This means that noise itself\nneeds to be coded, in addition to the clean image itself. In this paper, we\npresent a learnt image compression framework where image denoising and\ncompression are performed jointly. The latent space of the image codec is\norganized in a scalable manner such that the clean image can be decoded from a\nsubset of the latent space at a lower rate, while the noisy image is decoded\nfrom the full latent space at a higher rate. The proposed codec is compared\nagainst established compression and denoising benchmarks, and the experiments\nreveal considerable bitrate savings of up to 80% compared to cascade\ncompression and denoising.",
    "descriptor": "",
    "authors": [
      "Saeed Ranjbar Alvar",
      "Mateen Ulhaq",
      "Hyomin Choi",
      "Ivan V. Baji\u0107"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01874"
  },
  {
    "id": "arXiv:2205.01875",
    "title": "Machine Learning based Framework for Robust Price-Sensitivity Estimation  with Application to Airline Pricing",
    "abstract": "We consider the problem of dynamic pricing of a product in the presence of\nfeature-dependent price sensitivity. Based on the Poisson semi-parametric\napproach, we construct a flexible yet interpretable demand model where the\nprice related part is parametric while the remaining (nuisance) part of the\nmodel is non-parametric and can be modeled via sophisticated ML techniques. The\nestimation of price-sensitivity parameters of this model via direct one-stage\nregression techniques may lead to biased estimates. We propose a two-stage\nestimation methodology which makes the estimation of the price-sensitivity\nparameters robust to biases in the nuisance parameters of the model. In the\nfirst-stage we construct the estimators of observed purchases and price given\nthe feature vector using sophisticated ML estimators like deep neural networks.\nUtilizing the estimators from the first-stage, in the second-stage we leverage\na Bayesian dynamic generalized linear model to estimate the price-sensitivity\nparameters. We test the performance of the proposed estimation schemes on\nsimulated and real sales transaction data from Airline industry. Our numerical\nstudies demonstrate that the two-stage approach provides more accurate\nestimates of price-sensitivity parameters as compared to direct one-stage\napproach.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Ravi Kumar",
      "Shahin Boluki",
      "Karl Isler",
      "Jonas Rauch",
      "Darius Walczak"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2205.01875"
  },
  {
    "id": "arXiv:2205.01897",
    "title": "Virtual Analog Modeling of Distortion Circuits Using Neural Ordinary  Differential Equations",
    "abstract": "Recent research in deep learning has shown that neural networks can learn\ndifferential equations governing dynamical systems. In this paper, we adapt\nthis concept to Virtual Analog (VA) modeling to learn the ordinary differential\nequations (ODEs) governing the first-order and the second-order diode clipper.\nThe proposed models achieve performance comparable to state-of-the-art\nrecurrent neural networks (RNNs) albeit using fewer parameters. We show that\nthis approach does not require oversampling and allows to increase the sampling\nrate after the training has completed, which results in increased accuracy.\nUsing a sophisticated numerical solver allows to increase the accuracy at the\ncost of slower processing. ODEs learned this way do not require closed forms\nbut are still physically interpretable.",
    "descriptor": "\nComments: 8 pages, 10 figures, submitted to DAFx 2022 conference, for associated audio examples, see this https URL\n",
    "authors": [
      "Jan Wilczek",
      "Alec Wright",
      "Vesa V\u00e4lim\u00e4ki",
      "Emanu\u00ebl Habets"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01897"
  },
  {
    "id": "arXiv:2205.01951",
    "title": "Proximal ADMM for Nonconvex and Nonsmooth Optimization",
    "abstract": "By enabling the nodes or agents to solve small-sized subproblems to achieve\ncoordination, distributed algorithms are favored by many networked systems for\nefficient and scalable computation. While for convex problems, substantial\ndistributed algorithms are available, the results for the more broad nonconvex\ncounterparts are extremely lacking. This paper develops a distributed algorithm\nfor a class of nonconvex and nonsmooth problems featured by i) a nonconvex\nobjective formed by both separate and composite objective components regarding\nthe decision components of interconnected agents, ii) local bounded convex\nconstraints, and iii) coupled linear constraints. This problem is directly\noriginated from smart buildings and is also broad in other domains. To provide\na distributed algorithm with convergence guarantee, we revise the powerful tool\nof alternating direction method of multiplier (ADMM) and proposed a proximal\nADMM. Specifically, noting that the main difficulty to establish the\nconvergence for the nonconvex and nonsmooth optimization within the ADMM\nframework is to assume the boundness of dual updates, we propose to update the\ndual variables in a discounted manner. This leads to the establishment of a\nso-called sufficiently decreasing and lower bounded Lyapunov function, which is\ncritical to establish the convergence. We prove that the method converges to\nsome approximate stationary points. We besides showcase the efficacy and\nperformance of the method by a numerical example and the concrete application\nto multi-zone heating, ventilation, and air-conditioning (HVAC) control in\nsmart buildings.",
    "descriptor": "\nComments: 15 pges, 3 figures\n",
    "authors": [
      "Yu Yang",
      "Qing-Shan Jia",
      "Zhanbo Xu",
      "Xiaohong Guan",
      "Costas J. Spanos"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.01951"
  },
  {
    "id": "arXiv:2205.02024",
    "title": "Angular Control Charts: A New Perspective for Monitoring Reliability of  Multi-State Systems",
    "abstract": "Control charts, as had been used traditionally for quality monitoring, were\napplied alternatively to monitor systems' reliability. In other words, they can\nbe applied to detect changes in the failure behavior of systems. Such purpose\nimposed modifying traditional control charts in addition to developing charts\nthat are more compatible with reliability monitoring. The latter developed\ncategory is known as probability limits control charts. The existing\nreliability monitoring control charts were only dedicated to binary-state\nsystems, and they can't be used to monitor several states simultaneously.\nTherefore, this paper develops a design of control charts that accommodates\nmulti-state systems, called here as the Angular Control Chart, which represents\na new version of the probability limits control charts. This design is able to\nmonitor state transitions simultaneously and individually in addition.\nIllustrative system examples are implemented to explore the monitoring\nprocedure of the new design and to demonstrate its efficiency, effectiveness,\nand limitations.",
    "descriptor": "\nComments: 18 pages; 13 figures\n",
    "authors": [
      "Khaled Janada",
      "Hassan Soltan",
      "Mohamed-Sobeih Hussein",
      "Ahmad Abdel-Shafi"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.02024"
  },
  {
    "id": "arXiv:2205.02036",
    "title": "Rate-Splitting Multiple Access for 6G -- Part III: Interplay with  Reconfigurable Intelligent Surfaces",
    "abstract": "This letter is the third part of a three-part tutorial that focuses on\nrate-splitting multiple access (RSMA) for 6G. As Part III of the tutorial, this\nletter provides an overview of integrating RSMA and reconfigurable intelligent\nsurface (RIS). We first introduce two potential PHY layer techniques, namely,\nRSMA and RIS, including the need for integrating RSMA with RIS and how they\ncould help each other. Next, we provide a general model of an RIS-aided RSMA\nsystem and summarize some key performance metrics. Then, we discuss the major\nadvantages of RIS-aided RSMA networks, and illustrate the rate region of\nRIS-aided RSMA for both perfect and imperfect channel conditions. Finally, we\nsummarize the research challenges and open problems for RIS-aided RSMA systems.\nIn conclusion, RSMA is a promising technology for next generation multiple\naccess (NGMA) and future networks such as 6G and beyond.",
    "descriptor": "\nComments: 5 pages, 3 figures, submitted to Communications Letters\n",
    "authors": [
      "Hongyu Li",
      "Yijie Mao",
      "Onur Dizdar",
      "Bruno Clerckx"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.02036"
  },
  {
    "id": "arXiv:2205.02043",
    "title": "A Manifold Two-Sample Test Study: Integral Probability Metric with  Neural Networks",
    "abstract": "Two-sample tests are important areas aiming to determine whether two\ncollections of observations follow the same distribution or not. We propose\ntwo-sample tests based on integral probability metric (IPM) for\nhigh-dimensional samples supported on a low-dimensional manifold. We\ncharacterize the properties of proposed tests with respect to the number of\nsamples $n$ and the structure of the manifold with intrinsic dimension $d$.\nWhen an atlas is given, we propose two-step test to identify the difference\nbetween general distributions, which achieves the type-II risk in the order of\n$n^{-1/\\max\\{d,2\\}}$. When an atlas is not given, we propose H\\\"older IPM test\nthat applies for data distributions with $(s,\\beta)$-H\\\"older densities, which\nachieves the type-II risk in the order of $n^{-(s+\\beta)/d}$. To mitigate the\nheavy computation burden of evaluating the H\\\"older IPM, we approximate the\nH\\\"older function class using neural networks. Based on the approximation\ntheory of neural networks, we show that the neural network IPM test has the\ntype-II risk in the order of $n^{-(s+\\beta)/d}$, which is in the same order of\nthe type-II risk as the H\\\"older IPM test. Our proposed tests are adaptive to\nlow-dimensional geometric structure because their performance crucially depends\non the intrinsic dimension instead of the data dimension.",
    "descriptor": "\nComments: 31 pages, 2 figures\n",
    "authors": [
      "Jie Wang",
      "Minshuo Chen",
      "Tuo Zhao",
      "Wenjing Liao",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2205.02043"
  },
  {
    "id": "arXiv:2205.02051",
    "title": "Weight distribution of random linear codes and Krawchouk polynomials",
    "abstract": "For $0 < \\lambda < 1$ and $n \\rightarrow \\infty$ pick uniformly at random\n$\\lambda n$ vectors in $\\{0,1\\}^n$ and let $C$ be the orthogonal complement of\ntheir span. Given $0 < \\gamma < \\frac12$ with $0 < \\lambda < h(\\gamma)$, let\n$X$ be the random variable that counts the number of words in $C$ of Hamming\nweight $i = \\gamma n$ (where $i$ is assumed to be an even integer). Linial and\nMosheiff determined the asymptotics of the moments of $X$ of all orders\n$o\\left(\\frac{n}{\\log n}\\right)$. In this paper we extend their estimates up to\nmoments of linear order. Our key observation is that the behavior of the\nsuitably normalized $k^{th}$ moment of $X$ is essentially determined by the\n$k^{th}$ norm of the Krawchouk polynomial $K_i$.",
    "descriptor": "",
    "authors": [
      "Alex Samorodnitsky"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.02051"
  },
  {
    "id": "arXiv:2205.02085",
    "title": "Does a PESQNet (Loss) Require a Clean Reference Input? The Original PESQ  Does, But ACR Listening Tests Don't",
    "abstract": "Perceptual evaluation of speech quality (PESQ) requires a clean speech\nreference as input, but predicts the results from (reference-free) absolute\ncategory rating (ACR) tests. In this work, we train a fully convolutional\nrecurrent neural network (FCRN) as deep noise suppression (DNS) model, with\neither a non-intrusive or an intrusive PESQNet, where only the latter has\naccess to a clean speech reference. The PESQNet is used as a mediator providing\na perceptual loss during the DNS training to maximize the PESQ score of the\nenhanced speech signal. For the intrusive PESQNet, we investigate two\ntopologies, called early-fusion (EF) and middle-fusion (MF) PESQNet, and\ncompare to the non-intrusive PESQNet to evaluate and to quantify the benefits\nof employing a clean speech reference input during DNS training. Detailed\nanalyses show that the DNS trained with the MF-intrusive PESQNet outperforms\nthe Interspeech 2021 DNS Challenge baseline and the same DNS trained with an\nMSE loss by 0.23 and 0.12 PESQ points, respectively. Furthermore, we can show\nthat only marginal benefits are obtained compared to the DNS trained with the\nnon-intrusive PESQNet. Therefore, as ACR listening tests, the PESQNet does not\nnecessarily require a clean speech reference input, opening the possibility of\nusing real data for DNS training.",
    "descriptor": "",
    "authors": [
      "Ziyi Xu",
      "Maximilian Strake",
      "Tim Fingscheidt"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2205.02085"
  },
  {
    "id": "arXiv:2205.02096",
    "title": "Data Cleansing for Indoor Positioning Wi-Fi Fingerprinting Datasets",
    "abstract": "Wearable and IoT devices requiring positioning and localisation services grow\nin number exponentially every year. This rapid growth also produces millions of\ndata entries that need to be pre-processed prior to being used in any indoor\npositioning system to ensure the data quality and provide a high Quality of\nService (QoS) to the end-user. In this paper, we offer a novel and\nstraightforward data cleansing algorithm for WLAN fingerprinting radio maps.\nThis algorithm is based on the correlation among fingerprints using the\nReceived Signal Strength (RSS) values and the Access Points (APs)'s identifier.\nWe use those to compute the correlation among all samples in the dataset and\nremove fingerprints with low level of correlation from the dataset. We\nevaluated the proposed method on 14 independent publicly-available datasets. As\na result, an average of 14% of fingerprints were removed from the datasets. The\n2D positioning error was reduced by 2.7% and 3D positioning error by 5.3% with\na slight increase in the floor hit rate by 1.2% on average. Consequently, the\naverage speed of position prediction was also increased by 14%.",
    "descriptor": "\nComments: Submitted to ALIAS2022/MDM2022\n",
    "authors": [
      "Darwin Quezada-Gaibor",
      "Lucie Klus",
      "Joaqu\u00edn Torres-Sospedra",
      "Elena Simona Lohan",
      "Jari Nurmi",
      "Carlos Granell",
      "Joaqu\u00edn Huerta"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02096"
  },
  {
    "id": "arXiv:2205.02110",
    "title": "Vehicle Noise: Comparison of Loudness Ratings in the Field and the  Laboratory",
    "abstract": "Objective: Distorted loudness perception is one of the main complaints of\nhearing aid users. Being able to measure loudness perception correctly in the\nclinic is essential for fitting hearing aids. For this, experiments in the\nclinic should be able to reflect and capture loudness perception as in\neveryday-life situations. Little research has been done comparing loudness\nperception in the field and in the laboratory. Design: Participants rated the\nloudness in the field and in the laboratory of 36 driving actions done by four\ndifferent vehicles. The field measurements were done in a restricted street and\nrecorded with a 360deg camera and a tetrahedral microphone. The recorded\nstimuli, which are openly accessible, were presented in three different\nconditions in the laboratory: 360deg video recordings with a head-mounted\ndisplay, video recordings with a desktop monitor, and audio-only. Sample:\nThirteen normal-hearing participants and 18 hearing-impaired participants\nparticipated in the study. Results: The driving actions were rated\nsignificantly louder in the laboratory than in the field for the audio-only\ncondition. These loudness rating differences were bigger for louder sounds in\ntwo laboratory conditions, i.e., the higher the sound level of a driving action\nwas the more likely it was to be rated louder in the laboratory. There were no\nsignificant differences in the loudness ratings between the three laboratory\nconditions and between groups. Conclusions: The results of this experiment\nfurther remark the importance of increasing the realism and immersion when\nmeasuring loudness in the clinic.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Gerard Llorach",
      "Dirk Oetting",
      "Matthias Vormann",
      "Markus Meis",
      "Volker Hohmann"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.02110"
  },
  {
    "id": "arXiv:2205.02119",
    "title": "Processing Network Controls via Deep Reinforcement Learning",
    "abstract": "Novel advanced policy gradient (APG) algorithms, such as proximal policy\noptimization (PPO), trust region policy optimization, and their variations,\nhave become the dominant reinforcement learning (RL) algorithms because of\ntheir ease of implementation and good practical performance. This dissertation\nis concerned with theoretical justification and practical application of the\nAPG algorithms for solving processing network control optimization problems.\nProcessing network control problems are typically formulated as Markov decision\nprocess (MDP) or semi-Markov decision process (SMDP) problems that have several\nunconventional for RL features: infinite state spaces, unbounded costs,\nlong-run average cost objectives. Policy improvement bounds play a crucial role\nin the theoretical justification of the APG algorithms. In this thesis we\nrefine existing bounds for MDPs with finite state spaces and prove novel policy\nimprovement bounds for classes of MDPs and SMDPs used to model processing\nnetwork operations. We consider two examples of processing network control\nproblems and customize the PPO algorithm to solve them. First, we consider\nparallel-server and multiclass queueing networks controls. Second, we consider\nthe drivers repositioning problem in a ride-hailing service system. For both\nexamples the PPO algorithm with auxiliary modifications consistently generates\ncontrol policies that outperform state-of-art heuristics.",
    "descriptor": "\nComments: PhD thesis\n",
    "authors": [
      "Mark Gluzman"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02119"
  },
  {
    "id": "arXiv:2205.02121",
    "title": "Accelerating phase-field-based simulation via machine learning",
    "abstract": "Phase-field-based models have become common in material science, mechanics,\nphysics, biology, chemistry, and engineering for the simulation of\nmicrostructure evolution. Yet, they suffer from the drawback of being\ncomputationally very costly when applied to large, complex systems. To reduce\nsuch computational costs, a Unet-based artificial neural network is developed\nas a surrogate model in the current work. Training input for this network is\nobtained from the results of the numerical solution of initial-boundary-value\nproblems (IBVPs) based on the Fan-Chen model for grain microstructure\nevolution. In particular, about 250 different simulations with varying initial\norder parameters are carried out and 200 frames of the time evolution of the\nphase fields are stored for each simulation. The network is trained with 90% of\nthis data, taking the $i$-th frame of a simulation, i.e. order parameter field,\nas input, and producing the $(i+1)$-th frame as the output. Evaluation of the\nnetwork is carried out with a test dataset consisting of 2200 microstructures\nbased on different configurations than originally used for training. The\ntrained network is applied recursively on initial order parameters to calculate\nthe time evolution of the phase fields. The results are compared to the ones\nobtained from the conventional numerical solution in terms of the errors in\norder parameters and the system's free energy. The resulting order parameter\nerror averaged over all points and all simulation cases is 0.005 and the\nrelative error in the total free energy in all simulation boxes does not exceed\n1%.",
    "descriptor": "",
    "authors": [
      "Iman Peivaste",
      "Nima H. Siboni",
      "Ghasem Alahyarizadeh",
      "Reza Ghaderi",
      "Bob Svendsen",
      "Dierk Raabe",
      "Jaber R. Mianroodi"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.02121"
  },
  {
    "id": "arXiv:2205.02128",
    "title": "Rate of convergence of the smoothed empirical Wasserstein distance",
    "abstract": "Consider an empirical measure $\\mathbb{P}_n$ induced by $n$ iid samples from\na $d$-dimensional $K$-subgaussian distribution $\\mathbb{P}$ and let $\\gamma =\n\\mathcal{N}(0,\\sigma^2 I_d)$ be the isotropic Gaussian measure. We study the\nspeed of convergence of the smoothed Wasserstein distance $W_2(\\mathbb{P}_n *\n\\gamma, \\mathbb{P}*\\gamma) = n^{-\\alpha + o(1)}$ with $*$ being the convolution\nof measures. For $K<\\sigma$ and in any dimension $d\\ge 1$ we show that $\\alpha\n= {1\\over2}$. For $K>\\sigma$ in dimension $d=1$ we show that the rate is slower\nand is given by $\\alpha = {(\\sigma^2 + K^2)^2\\over 4 (\\sigma^4 + K^4)} < 1/2$.\nThis resolves several open problems in \\cite{goldfeld2020convergence}, and in\nparticular precisely identifies the amount of smoothing $\\sigma$ needed to\nobtain a parametric rate. In addition, we also establish that\n$D_{KL}(\\mathbb{P}_n * \\gamma \\|\\mathbb{P}*\\gamma)$ has rate $O(1/n)$ for\n$K<\\sigma$ but only slows down to $O({(\\log n)^{d+1}\\over n})$ for $K>\\sigma$.\nThe surprising difference of the behavior of $W_2^2$ and KL implies the failure\nof $T_{2}$-transportation inequality when $\\sigma < K$. Consequently, the\nrequirement $K<\\sigma$ is necessary for validity of the log-Sobolev inequality\n(LSI) for the Gaussian mixture $\\mathbb{P} * \\mathcal{N}(0, \\sigma^{2})$,\nclosing an open problem in \\cite{wang2016functional}, who established the LSI\nunder precisely this condition.",
    "descriptor": "",
    "authors": [
      "Adam Block",
      "Zeyu Jia",
      "Yury Polyanskiy",
      "Alexander Rakhlin"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2205.02128"
  },
  {
    "id": "arXiv:2205.02152",
    "title": "Evaluating Transferability for Covid 3D Localization Using CT SARS-CoV-2  segmentation models",
    "abstract": "Recent studies indicate that detecting radiographic patterns on CT scans can\nyield high sensitivity and specificity for COVID-19 localization. In this\npaper, we investigate the appropriateness of deep learning models\ntransferability, for semantic segmentation of pneumonia-infected areas in CT\nimages. Transfer learning allows for the fast initialization/ reutilization of\ndetection models, given that large volumes of training are not available. Our\nwork explores the efficacy of using pre-trained U-Net architectures, on a\nspecific CT data set, for identifying Covid-19 side-effects over images from\ndifferent datasets. Experimental results indicate improvement in the\nsegmentation accuracy of identifying COVID-19 infected regions.",
    "descriptor": "",
    "authors": [
      "Constantine Maganaris",
      "Eftychios Protopapadakis",
      "Nikolaos Bakalos",
      "Nikolaos Doulamis",
      "Dimitris Kalogeras",
      "Aikaterini Angeli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02152"
  },
  {
    "id": "arXiv:2205.02156",
    "title": "Approximations of dispersive PDEs in the presence of low-regularity  randomness",
    "abstract": "We introduce a new class of numerical schemes which allow for low regularity\napproximations to the expectation $ \\mathbb{E}(|u_{k}(\\tau, v^{\\eta})|^2)$,\nwhere $u_k$ denotes the $k$-th Fourier coefficient of the solution $u$ of the\ndispersive equation and $ v^{\\eta}(x) $ the associated random initial data.\nThis quantity plays an important role in physics, in particular in the study of\nwave turbulence where one needs to adopt a statistical approach in order to\nobtain deep insight into the generic long-time behaviour of solutions to\ndispersive equations. Our new class of schemes is based on Wick's theorem and\nFeynman diagrams together with a resonance based discretisation (see\narXiv:2005.01649) set in a more general context: we introduce a novel\ncombinatorial structure called paired decorated forests which are two decorated\ntrees whose decorations on the leaves come in pair. The character of the scheme\ndraws its inspiration from the treatment of singular stochastic partial\ndifferential equations via Regularity Structures. In contrast to classical\napproaches, we do not discretize the PDE itself, but rather its expectation.\nThis allows us to heavily exploit the optimal resonance structure and\nunderlying gain in regularity on the finite dimensional (discrete) level.",
    "descriptor": "\nComments: 43 pages\n",
    "authors": [
      "Yvonne Alama Bronsard",
      "Yvain Bruned",
      "Katharina Schratz"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2205.02156"
  },
  {
    "id": "arXiv:2205.02160",
    "title": "Making SGD Parameter-Free",
    "abstract": "We develop an algorithm for parameter-free stochastic convex optimization\n(SCO) whose rate of convergence is only a double-logarithmic factor larger than\nthe optimal rate for the corresponding known-parameter setting. In contrast,\nthe best previously known rates for parameter-free SCO are based on online\nparameter-free regret bounds, which contain unavoidable excess logarithmic\nterms compared to their known-parameter counterparts. Our algorithm is\nconceptually simple, has high-probability guarantees, and is also partially\nadaptive to unknown gradient norms, smoothness, and strong convexity. At the\nheart of our results is a novel parameter-free certificate for SGD step size\nchoice, and a time-uniform concentration result that assumes no a-priori bounds\non SGD iterates.",
    "descriptor": "",
    "authors": [
      "Yair Carmon",
      "Oliver Hinder"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.02160"
  },
  {
    "id": "arXiv:2205.02164",
    "title": "The Policy Implications of Economic Complexity",
    "abstract": "In recent years economic complexity has grown into an active field of\nfundamental and applied research. Yet, despite important advances, the policy\nimplications of economic complexity remain unclear. Here I organize the policy\nimplications of economic complexity in a framework grounded on 4 Ws: \"what\"\napproaches, focused on identifying target activities and/or locations; \"when\"\napproaches, focused on when to time support for developing related and\nunrelated activities; \"where\" approaches, focused on the geographic diffusion\nof knowledge; and \"who\" approaches, focused on the role played by agents of\nstructural change. The goal of this framework is to clarify the policy\nimplications of recent work in economic complexity and to facilitate its\ncontinued use in regional and international development efforts.",
    "descriptor": "\nComments: 8700 words\n",
    "authors": [
      "C\u00e9sar A. Hidalgo"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.02164"
  },
  {
    "id": "arXiv:2205.02169",
    "title": "Compound virtual screening by learning-to-rank with gradient boosting  decision tree and enrichment-based cumulative gain",
    "abstract": "Learning-to-rank, a machine learning technique widely used in information\nretrieval, has recently been applied to the problem of ligand-based virtual\nscreening, to accelerate the early stages of new drug development. Ranking\nprediction models learn based on ordinal relationships, making them suitable\nfor integrating assay data from various environments. Existing studies of rank\nprediction in compound screening have generally used a learning-to-rank method\ncalled RankSVM. However, they have not been compared with or validated against\nthe gradient boosting decision tree (GBDT)-based learning-to-rank methods that\nhave gained popularity recently. Furthermore, although the ranking metric\ncalled Normalized Discounted Cumulative Gain (NDCG) is widely used in\ninformation retrieval, it only determines whether the predictions are better\nthan those of other models. In other words, NDCG is incapable of recognizing\nwhen a prediction model produces worse than random results. Nevertheless, NDCG\nis still used in the performance evaluation of compound screening using\nlearning-to-rank. This study used the GBDT model with ranking loss functions,\ncalled lambdarank and lambdaloss, for ligand-based virtual screening; results\nwere compared with existing RankSVM methods and GBDT models using regression.\nWe also proposed a new ranking metric, Normalized Enrichment Discounted\nCumulative Gain (NEDCG), which aims to properly evaluate the goodness of\nranking predictions. Results showed that the GBDT model with learning-to-rank\noutperformed existing regression methods using GBDT and RankSVM on diverse\ndatasets. Moreover, NEDCG showed that predictions by regression were comparable\nto random predictions in multi-assay, multi-family datasets, demonstrating its\nusefulness for a more direct assessment of compound screening performance.",
    "descriptor": "\nComments: submitted to IEEE CIBCB 2022\n",
    "authors": [
      "Kairi Furui",
      "Masahito Ohue"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02169"
  },
  {
    "id": "arXiv:2205.02191",
    "title": "Wavelet neural operator: a neural operator for parametric partial  differential equations",
    "abstract": "With massive advancements in sensor technologies and Internet-of-things, we\nnow have access to terabytes of historical data; however, there is a lack of\nclarity in how to best exploit the data to predict future events. One possible\nalternative in this context is to utilize operator learning algorithm that\ndirectly learn nonlinear mapping between two functional spaces; this\nfacilitates real-time prediction of naturally arising complex evolutionary\ndynamics. In this work, we introduce a novel operator learning algorithm\nreferred to as the Wavelet Neural Operator (WNO) that blends integral kernel\nwith wavelet transformation. WNO harnesses the superiority of the wavelets in\ntime-frequency localization of the functions and enables accurate tracking of\npatterns in spatial domain and effective learning of the functional mappings.\nSince the wavelets are localized in both time/space and frequency, WNO can\nprovide high spatial and frequency resolution. This offers learning of the\nfiner details of the parametric dependencies in the solution for complex\nproblems. The efficacy and robustness of the proposed WNO are illustrated on a\nwide array of problems involving Burger's equation, Darcy flow, Navier-Stokes\nequation, Allen-Cahn equation, and Wave advection equation. Comparative study\nwith respect to existing operator learning frameworks are presented. Finally,\nthe proposed approach is used to build a digital twin capable of predicting\nEarth's air temperature based on available historical data.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Tapas Tripura",
      "Souvik Chakraborty"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02191"
  },
  {
    "id": "arXiv:2205.02210",
    "title": "Symmetric Layer-Rainbow Colorations of Cubes",
    "abstract": "Can we color the $n^3$ cells of an $n\\times n\\times n$ cube $L$ with $n^2$\ncolors in such a way that each layer parallel to each face contains each color\nexactly once and that the coloring is symmetric so that $L_{ij\\ell}=L_{j\\ell\ni}=L_{\\ell ij}$ for distinct $i,j,\\ell \\in \\{1,\\dots,n\\}$, and $L_{iij}=L_{jj\ni}, L_{iji}=L_{jij}, L_{ij j}=L_{jii}$ for $i,j\\in \\{1,\\dots,n\\}$?\nUsing transportation networks, we show that such a coloring is possible if\nand only if $n\\equiv 0,2 \\mod 3$ (with two exceptions, $n=1$ and $n\\neq 3$).\nMotivated by the designs of experiments, the study of these objects (without\nsymmetry) was initiated by Kishen and Fisher in the 1940's. These objects are\nalso closely related to orthogonal arrays whose existence has been extensively\ninvestigated, and they are natural three-dimensional analogues of symmetric\nlatin squares.",
    "descriptor": "\nComments: 9 pages, 1 figure\n",
    "authors": [
      "Amin Bahmanian"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2205.02210"
  },
  {
    "id": "arXiv:1811.03026",
    "title": "Learning Task Constraints from Demonstration for Hybrid Force/Position  Control",
    "abstract": "Comments: Presented at 2019 IEEE-RAS International Conference on Humanoid Robots (Humanoids)",
    "descriptor": "\nComments: Presented at 2019 IEEE-RAS International Conference on Humanoid Robots (Humanoids)\n",
    "authors": [
      "Adam Conkey",
      "Tucker Hermans"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/1811.03026"
  },
  {
    "id": "arXiv:1906.12072",
    "title": "Multiple Testing and Variable Selection along the path of the Least  Angle Regression",
    "abstract": "Comments: FINAL version (the paper has improved and we advise you to disregard the previous versions); NEW: link with the Polyhedral lemma is now explicit and the conditional law of the estimation of the variance is given",
    "descriptor": "\nComments: FINAL version (the paper has improved and we advise you to disregard the previous versions); NEW: link with the Polyhedral lemma is now explicit and the conditional law of the estimation of the variance is given\n",
    "authors": [
      "J.-M. Aza\u00efs",
      "Y. De Castro"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.12072"
  },
  {
    "id": "arXiv:1907.00277",
    "title": "Active Learning of Probabilistic Movement Primitives",
    "abstract": "Comments: Presented at 2019 IEEE-RAS International Conference on Humanoid Robots (Humanoids)",
    "descriptor": "\nComments: Presented at 2019 IEEE-RAS International Conference on Humanoid Robots (Humanoids)\n",
    "authors": [
      "Adam Conkey",
      "Tucker Hermans"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/1907.00277"
  },
  {
    "id": "arXiv:1910.02760",
    "title": "Negative Sampling in Variational Autoencoders",
    "abstract": "Negative Sampling in Variational Autoencoders",
    "descriptor": "",
    "authors": [
      "Adri\u00e1n Csisz\u00e1rik",
      "Beatrix Benk\u0151",
      "D\u00e1niel Varga"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1910.02760"
  },
  {
    "id": "arXiv:1910.06247",
    "title": "Repairnator patches programs automatically",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:1810.05806",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1810.05806\n",
    "authors": [
      "Martin Monperrus",
      "Simon Urli",
      "Thomas Durieux",
      "Matias Martinez",
      "Benoit Baudry",
      "Lionel Seinturier"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/1910.06247"
  },
  {
    "id": "arXiv:1911.07381",
    "title": "Visual Similarity Attention",
    "abstract": "Comments: 10 pages, 7 figures, 4 tables",
    "descriptor": "\nComments: 10 pages, 7 figures, 4 tables\n",
    "authors": [
      "Meng Zheng",
      "Srikrishna Karanam",
      "Terrence Chen",
      "Richard J. Radke",
      "Ziyan Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1911.07381"
  },
  {
    "id": "arXiv:2001.00562",
    "title": "Optimal Entropy Compression and Purification in Quantum Bits",
    "abstract": "Comments: 27 pages, 11 + 1 (external) figures; v4: revised manuscript",
    "descriptor": "\nComments: 27 pages, 11 + 1 (external) figures; v4: revised manuscript\n",
    "authors": [
      "Varad R. Pande"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2001.00562"
  },
  {
    "id": "arXiv:2001.03867",
    "title": "Gaussian Multiple and Random Access in the Finite Blocklength Regime",
    "abstract": "Comments: 27 pages, IEEE Transactions on Information Theory, ISIT 2020",
    "descriptor": "\nComments: 27 pages, IEEE Transactions on Information Theory, ISIT 2020\n",
    "authors": [
      "Recep Can Yavas",
      "Victoria Kostina",
      "Michelle Effros"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2001.03867"
  },
  {
    "id": "arXiv:2004.04371",
    "title": "MDCNN-SID: Multi-scale Dilated Convolution Network for Singer  Identification",
    "abstract": "Comments: Accepted by IJCNN2022 (The 2022 International Joint Conference on Neural Networks)",
    "descriptor": "\nComments: Accepted by IJCNN2022 (The 2022 International Joint Conference on Neural Networks)\n",
    "authors": [
      "Xulong Zhang",
      "Jianzong Wang",
      "Ning Cheng",
      "Jing Xiao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2004.04371"
  },
  {
    "id": "arXiv:2004.12061",
    "title": "Nonlinear Dynamic Systems Parameterization Using Interval-Based Global  Optimization: Computing Lipschitz Constants and Beyond",
    "abstract": "Comments: IEEE Transactions on Automatic Control",
    "descriptor": "\nComments: IEEE Transactions on Automatic Control\n",
    "authors": [
      "Sebastian A. Nugroho",
      "Ahmad F. Taha",
      "and Vu Hoang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2004.12061"
  },
  {
    "id": "arXiv:2005.00345",
    "title": "Optimal Power Flow with State Estimation In the Loop for Distribution  Networks",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1909.12763",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1909.12763\n",
    "authors": [
      "Yi Guo",
      "Xinyang Zhou",
      "Changhong Zhao",
      "Lijun Chen",
      "Tyler H. Summers"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2005.00345"
  },
  {
    "id": "arXiv:2005.00497",
    "title": "The Grammar of Interactive Explanatory Model Analysis",
    "abstract": "Comments: 35 pages, 17 figures, 8 tables",
    "descriptor": "\nComments: 35 pages, 17 figures, 8 tables\n",
    "authors": [
      "Hubert Baniecki",
      "Dariusz Parzych",
      "Przemyslaw Biecek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.00497"
  },
  {
    "id": "arXiv:2006.04335",
    "title": "Visual-based Lifelong Kinematics and Pose Estimation for Skid-Steering  Robots",
    "abstract": "Comments: 18 pages in total; Submission to a journal",
    "descriptor": "\nComments: 18 pages in total; Submission to a journal\n",
    "authors": [
      "Xingxing Zuo",
      "Mingming Zhang",
      "Yiming Chen",
      "Guoquan Huang",
      "Yong Liu",
      "Mingyang Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2006.04335"
  },
  {
    "id": "arXiv:2006.05256",
    "title": "Recurrent Flow Networks: A Recurrent Latent Variable Model for Density  Modelling of Urban Mobility",
    "abstract": "Comments: 16 pages, 6 figures",
    "descriptor": "\nComments: 16 pages, 6 figures\n",
    "authors": [
      "Daniele Gammelli",
      "Filipe Rodrigues"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.05256"
  },
  {
    "id": "arXiv:2006.07507",
    "title": "Better Parameter-free Stochastic Optimization with ODE Updates for  Coin-Betting",
    "abstract": "Better Parameter-free Stochastic Optimization with ODE Updates for  Coin-Betting",
    "descriptor": "",
    "authors": [
      "Keyi Chen",
      "John Langford",
      "Francesco Orabona"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.07507"
  },
  {
    "id": "arXiv:2007.00156",
    "title": "Enabling Compute-Communication Overlap in Distributed Deep Learning  Training Platforms",
    "abstract": "Enabling Compute-Communication Overlap in Distributed Deep Learning  Training Platforms",
    "descriptor": "",
    "authors": [
      "Saeed Rashidi",
      "Matthew Denton",
      "Srinivas Sridharan",
      "Sudarshan Srinivasan",
      "Amoghavarsha Suresh",
      "Jade Ni",
      "Tushar Krishna"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2007.00156"
  },
  {
    "id": "arXiv:2007.09600",
    "title": "EllSeg: An Ellipse Segmentation Framework for Robust Gaze Tracking",
    "abstract": "Comments: Code available at this https URL",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Rakshit S. Kothari",
      "Aayush K. Chaudhary",
      "Reynold J. Bailey",
      "Jeff B. Pelz",
      "Gabriel J. Diaz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.09600"
  },
  {
    "id": "arXiv:2007.09874",
    "title": "A Note on Stabbing Convex Bodies with Points, Lines, and Flats",
    "abstract": "Comments: 13 pages, 6 figures; updated with improved constructions of $(k, \\varepsilon)$-nets for $k \\geq 1$",
    "descriptor": "\nComments: 13 pages, 6 figures; updated with improved constructions of $(k, \\varepsilon)$-nets for $k \\geq 1$\n",
    "authors": [
      "Sariel Har-Peled",
      "Mitchell Jones"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2007.09874"
  },
  {
    "id": "arXiv:2008.00843",
    "title": "Profiles of dynamical systems and their algebra",
    "abstract": "Comments: 12 pages, 2 figures",
    "descriptor": "\nComments: 12 pages, 2 figures\n",
    "authors": [
      "Caroline Gaze-Maillot",
      "Antonio E. Porreca"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Commutative Algebra (math.AC)"
    ],
    "url": "https://arxiv.org/abs/2008.00843"
  },
  {
    "id": "arXiv:2009.04822",
    "title": "Generalized Multi-Output Gaussian Process Censored Regression",
    "abstract": "Comments: 17 pages, 6 figures, 3 tables",
    "descriptor": "\nComments: 17 pages, 6 figures, 3 tables\n",
    "authors": [
      "Daniele Gammelli",
      "Kasper Pryds Rolsted",
      "Dario Pacino",
      "Filipe Rodrigues"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.04822"
  },
  {
    "id": "arXiv:2009.09961",
    "title": "Adjusting for Confounders with Text: Challenges and an Empirical  Evaluation Framework for Causal Inference",
    "abstract": "Comments: to appear at ICWSM 2022",
    "descriptor": "\nComments: to appear at ICWSM 2022\n",
    "authors": [
      "Galen Weld",
      "Peter West",
      "Maria Glenski",
      "David Arbour",
      "Ryan Rossi",
      "Tim Althoff"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2009.09961"
  },
  {
    "id": "arXiv:2011.07142",
    "title": "Sparse Representations of Positive Functions via First and Second-Order  Pseudo-Mirror Descent",
    "abstract": "Sparse Representations of Positive Functions via First and Second-Order  Pseudo-Mirror Descent",
    "descriptor": "",
    "authors": [
      "Abhishek Chakraborty",
      "Ketan Rajawat",
      "Alec Koppel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2011.07142"
  },
  {
    "id": "arXiv:2011.08470",
    "title": "Towards All-around Knowledge Transferring: Learning From Task-irrelevant  Labels",
    "abstract": "Comments: An updated version of this work has been available at arXiv:2102.10955",
    "descriptor": "\nComments: An updated version of this work has been available at arXiv:2102.10955\n",
    "authors": [
      "Yinghui Li",
      "Ruiyang Liu",
      "ZiHao Zhang",
      "Ning Ding",
      "Ying Shen",
      "Linmi Tao",
      "Hai-Tao Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.08470"
  },
  {
    "id": "arXiv:2011.14482",
    "title": "A Near-Optimal Parallel Algorithm for Joining Binary Relations",
    "abstract": "A Near-Optimal Parallel Algorithm for Joining Binary Relations",
    "descriptor": "",
    "authors": [
      "Bas Ketsman",
      "Dan Suciu",
      "Yufei Tao"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2011.14482"
  },
  {
    "id": "arXiv:2011.15108",
    "title": "Difference-restriction algebras of partial functions: axiomatisations  and representations",
    "abstract": "Comments: 32 pages. Sections 3 and 4 have been re-arranged",
    "descriptor": "\nComments: 32 pages. Sections 3 and 4 have been re-arranged\n",
    "authors": [
      "C\u00e9lia Borlido",
      "Brett McLean"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2011.15108"
  },
  {
    "id": "arXiv:2012.00224",
    "title": "Difference-restriction algebras of partial functions with operators:  discrete duality and completion",
    "abstract": "Comments: 34 pages. Small improvements throughout",
    "descriptor": "\nComments: 34 pages. Small improvements throughout\n",
    "authors": [
      "C\u00e9lia Borlido",
      "Brett McLean"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2012.00224"
  },
  {
    "id": "arXiv:2012.01685",
    "title": "Cross-Loss Influence Functions to Explain Deep Network Representations",
    "abstract": "Cross-Loss Influence Functions to Explain Deep Network Representations",
    "descriptor": "",
    "authors": [
      "Andrew Silva",
      "Rohit Chopra",
      "Matthew Gombolay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.01685"
  },
  {
    "id": "arXiv:2012.01879",
    "title": "Learning Two-Stream CNN for Multi-Modal Age-related Macular Degeneration  Categorization",
    "abstract": "Comments: Accepted by IEEE Journal of Biomedical and Health Informatics (J-BHI)",
    "descriptor": "\nComments: Accepted by IEEE Journal of Biomedical and Health Informatics (J-BHI)\n",
    "authors": [
      "Weisen Wang",
      "Xirong Li",
      "Zhiyan Xu",
      "Weihong Yu",
      "Jianchun Zhao",
      "Dayong Ding",
      "Youxin Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.01879"
  },
  {
    "id": "arXiv:2012.04764",
    "title": "Conditional Generation of Medical Images via Disentangled Adversarial  Inference",
    "abstract": "Comments: Published in Medical Image Analysis",
    "descriptor": "\nComments: Published in Medical Image Analysis\n",
    "authors": [
      "Mohammad Havaei",
      "Ximeng Mao",
      "Yiping Wang",
      "Qicheng Lao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.04764"
  },
  {
    "id": "arXiv:2012.14020",
    "title": "Towards Understanding Sensor and Control Nodes Selection in Nonlinear  Dynamic Systems: Lyapunov Theory Meets Branch-and-Bound",
    "abstract": "Towards Understanding Sensor and Control Nodes Selection in Nonlinear  Dynamic Systems: Lyapunov Theory Meets Branch-and-Bound",
    "descriptor": "",
    "authors": [
      "Sebastian A. Nugroho",
      "Ahmad F. Taha"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2012.14020"
  },
  {
    "id": "arXiv:2012.14610",
    "title": "UniK-QA: Unified Representations of Structured and Unstructured  Knowledge for Open-Domain Question Answering",
    "abstract": "Comments: NAACL-HLT 2022 Findings",
    "descriptor": "\nComments: NAACL-HLT 2022 Findings\n",
    "authors": [
      "Barlas Oguz",
      "Xilun Chen",
      "Vladimir Karpukhin",
      "Stan Peshterliev",
      "Dmytro Okhonko",
      "Michael Schlichtkrull",
      "Sonal Gupta",
      "Yashar Mehdad",
      "Scott Yih"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.14610"
  },
  {
    "id": "arXiv:2101.07067",
    "title": "Data Obsolescence Detection in the Light of Newly Acquired Valid  Observations",
    "abstract": "Data Obsolescence Detection in the Light of Newly Acquired Valid  Observations",
    "descriptor": "",
    "authors": [
      "Salma Chaieb",
      "Brahim Hnich",
      "Ali Ben Mrad"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.07067"
  },
  {
    "id": "arXiv:2101.09122",
    "title": "A Universal Deep Learning Framework for Real-Time Denoising of  Ultrasound Images",
    "abstract": "Comments: 21 pages, 14 figures, 5 tables",
    "descriptor": "\nComments: 21 pages, 14 figures, 5 tables\n",
    "authors": [
      "Simone Cammarasana",
      "Paolo Nicolardi",
      "Giuseppe Patan\u00e8"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.09122"
  },
  {
    "id": "arXiv:2101.10357",
    "title": "Regret-Optimal Filtering for Prediction and Estimation",
    "abstract": "Comments: Short version published in AISTATS 2021 as this https URL",
    "descriptor": "\nComments: Short version published in AISTATS 2021 as this https URL\n",
    "authors": [
      "Oron Sabag",
      "Babak Hassibi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.10357"
  },
  {
    "id": "arXiv:2102.07711",
    "title": "Saving Stochastic Bandits from Poisoning Attacks via Limited Data  Verification",
    "abstract": "Comments: Accepted to AAAI 2022",
    "descriptor": "\nComments: Accepted to AAAI 2022\n",
    "authors": [
      "Anshuka Rangi",
      "Long Tran-Thanh",
      "Haifeng Xu",
      "Massimo Franceschetti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.07711"
  },
  {
    "id": "arXiv:2102.10955",
    "title": "Learning Purified Feature Representations from Task-irrelevant Labels",
    "abstract": "Comments: Accepted by IJCNN 2022. arXiv admin note: substantial text overlap with arXiv:2011.08470",
    "descriptor": "\nComments: Accepted by IJCNN 2022. arXiv admin note: substantial text overlap with arXiv:2011.08470\n",
    "authors": [
      "Yinghui Li",
      "Chen Wang",
      "Li Yangning",
      "Ning Ding",
      "Hai-Tao Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.10955"
  },
  {
    "id": "arXiv:2103.00111",
    "title": "Graph Self-Supervised Learning: A Survey",
    "abstract": "Comments: 26 pages, 9 figures, 9 tables",
    "descriptor": "\nComments: 26 pages, 9 figures, 9 tables\n",
    "authors": [
      "Yixin Liu",
      "Ming Jin",
      "Shirui Pan",
      "Chuan Zhou",
      "Yu Zheng",
      "Feng Xia",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.00111"
  },
  {
    "id": "arXiv:2103.03825",
    "title": "Real-Time Forecasting of Driver-Vehicle Dynamics on 3D Roads: a  Deep-Learning Framework Leveraging Bayesian Optimisation",
    "abstract": "Comments: 12 pages, 10 figures, 2 tables. This work has been submitted to Elsevier for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: 12 pages, 10 figures, 2 tables. This work has been submitted to Elsevier for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Luca Paparusso",
      "Stefano Melzi",
      "Francesco Braghin"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.03825"
  },
  {
    "id": "arXiv:2103.16561",
    "title": "Diagnosing Vision-and-Language Navigation: What Really Matters",
    "abstract": "Comments: NAACL 2022",
    "descriptor": "\nComments: NAACL 2022\n",
    "authors": [
      "Wanrong Zhu",
      "Yuankai Qi",
      "Pradyumna Narayana",
      "Kazoo Sone",
      "Sugato Basu",
      "Xin Eric Wang",
      "Qi Wu",
      "Miguel Eckstein",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.16561"
  },
  {
    "id": "arXiv:2104.03690",
    "title": "Determinisability of register and timed automata",
    "abstract": "Comments: journal version of a CONCUR'20 paper. arXiv admin note: substantial text overlap with arXiv:2007.09340",
    "descriptor": "\nComments: journal version of a CONCUR'20 paper. arXiv admin note: substantial text overlap with arXiv:2007.09340\n",
    "authors": [
      "Lorenzo Clemente",
      "S\u0142awomir Lasota",
      "Rados\u0142aw Pi\u00f3rkowski"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2104.03690"
  },
  {
    "id": "arXiv:2105.00373",
    "title": "Investigating the Impact of Multi-LiDAR Placement on Object Detection  for Autonomous Driving",
    "abstract": "Comments: CVPR 2022 camera-ready version:15 pages, 14 figures, 9 tables",
    "descriptor": "\nComments: CVPR 2022 camera-ready version:15 pages, 14 figures, 9 tables\n",
    "authors": [
      "Hanjiang Hu",
      "Zuxin Liu",
      "Sharad Chitlangia",
      "Akhil Agnihotri",
      "Ding Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.00373"
  },
  {
    "id": "arXiv:2105.01765",
    "title": "Enabling 3D Object Detection with a Low-Resolution LiDAR",
    "abstract": "Enabling 3D Object Detection with a Low-Resolution LiDAR",
    "descriptor": "",
    "authors": [
      "Lin Bai",
      "Yiming Zhao",
      "Xinming Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.01765"
  },
  {
    "id": "arXiv:2105.06097",
    "title": "Thematic Fit Bits: Annotation Quality and Quantity Interplay for Event  Participant Representation",
    "abstract": "Comments: Published in LREC 2022; 8.5 pages before references, 11 pages total",
    "descriptor": "\nComments: Published in LREC 2022; 8.5 pages before references, 11 pages total\n",
    "authors": [
      "Yuval Marton",
      "Asad Sayeed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.06097"
  },
  {
    "id": "arXiv:2105.11561",
    "title": "Powered Prosthesis Locomotion on Varying Terrains: Model-Dependent  Control with Real-Time Force Sensing",
    "abstract": "Comments: 8 pages, 7 figures, accepted by RA-L and ICRA 2022",
    "descriptor": "\nComments: 8 pages, 7 figures, accepted by RA-L and ICRA 2022\n",
    "authors": [
      "Rachel Gehlhar",
      "Je-han Yang",
      "Aaron D. Ames"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.11561"
  },
  {
    "id": "arXiv:2106.03323",
    "title": "A Comprehensive Survey and Taxonomy on Image Dehazing Based on Deep  Learning",
    "abstract": "A Comprehensive Survey and Taxonomy on Image Dehazing Based on Deep  Learning",
    "descriptor": "",
    "authors": [
      "Jie Gui",
      "Xiaofeng Cong",
      "Yuan Cao",
      "Wenqi Ren",
      "Jun Zhang",
      "Jing Zhang",
      "Jiuxin Cao",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03323"
  },
  {
    "id": "arXiv:2106.05039",
    "title": "AdaptOver: Adaptive Overshadowing Attacks in Cellular Networks",
    "abstract": "Comments: This version introduces uplink overshadowing",
    "descriptor": "\nComments: This version introduces uplink overshadowing\n",
    "authors": [
      "Simon Erni",
      "Martin Kotuliak",
      "Patrick Leu",
      "Marc R\u00f6schlin",
      "Srdjan \u010capkun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.05039"
  },
  {
    "id": "arXiv:2106.08043",
    "title": "CausalNLP: A Practical Toolkit for Causal Inference with Text",
    "abstract": "Comments: 9 pages",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Arun S. Maiya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08043"
  },
  {
    "id": "arXiv:2106.09385",
    "title": "On Deep Neural Network Calibration by Regularization and its Impact on  Refinement",
    "abstract": "Comments: There is an error with the assumption of proof required for equation 8 in section 2.1 which invalidates the results",
    "descriptor": "\nComments: There is an error with the assumption of proof required for equation 8 in section 2.1 which invalidates the results\n",
    "authors": [
      "Aditya Singh",
      "Alessandro Bay",
      "Biswa Sengupta",
      "Andrea Mirabile"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09385"
  },
  {
    "id": "arXiv:2106.11053",
    "title": "Leveraging Language to Learn Program Abstractions and Search Heuristics",
    "abstract": "Comments: appeared in Thirty-eighth International Conference on Machine Learning (ICML 2021)",
    "descriptor": "\nComments: appeared in Thirty-eighth International Conference on Machine Learning (ICML 2021)\n",
    "authors": [
      "Catherine Wong",
      "Kevin Ellis",
      "Joshua B. Tenenbaum",
      "Jacob Andreas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.11053"
  },
  {
    "id": "arXiv:2106.13852",
    "title": "Decomposition of transition systems into sets of synchronizing state  machines",
    "abstract": "Decomposition of transition systems into sets of synchronizing state  machines",
    "descriptor": "",
    "authors": [
      "Viktor Teren",
      "Jordi Cortadella",
      "Tiziano Villa"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Hardware Architecture (cs.AR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.13852"
  },
  {
    "id": "arXiv:2106.13882",
    "title": "Can Buyers Reveal for a Better Deal?",
    "abstract": "Can Buyers Reveal for a Better Deal?",
    "descriptor": "",
    "authors": [
      "Daniel Halpern",
      "Gregory Kehne",
      "Jamie Tucker-Foltz"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.13882"
  },
  {
    "id": "arXiv:2106.14387",
    "title": "Political Ideology and Polarization of Policy Positions: A  Multi-dimensional Approach",
    "abstract": "Comments: NAACL 2022 Camera Ready",
    "descriptor": "\nComments: NAACL 2022 Camera Ready\n",
    "authors": [
      "Barea Sinno",
      "Bernardo Oviedo",
      "Katherine Atwell",
      "Malihe Alikhani",
      "Junyi Jessy Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.14387"
  },
  {
    "id": "arXiv:2107.00358",
    "title": "Cross-domain Few-shot Learning with Task-specific Adapters",
    "abstract": "Comments: CVPR2022, Code will be available at this https URL",
    "descriptor": "\nComments: CVPR2022, Code will be available at this https URL\n",
    "authors": [
      "Wei-Hong Li",
      "Xialei Liu",
      "Hakan Bilen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00358"
  },
  {
    "id": "arXiv:2107.06126",
    "title": "DiCOVA-Net: Diagnosing COVID-19 using Acoustics based on Deep Residual  Network for the DiCOVA Challenge 2021",
    "abstract": "Comments: 5 figures",
    "descriptor": "\nComments: 5 figures\n",
    "authors": [
      "Jiangeng Chang",
      "Shaoze Cui",
      "Mengling Feng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.06126"
  },
  {
    "id": "arXiv:2107.13184",
    "title": "Numerical wave propagation aided by deep learning",
    "abstract": "Numerical wave propagation aided by deep learning",
    "descriptor": "",
    "authors": [
      "Hieu Nguyen",
      "Richard Tsai"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.13184"
  },
  {
    "id": "arXiv:2107.13735",
    "title": "Learning the temporal evolution of multivariate densities via  normalizing flows",
    "abstract": "Learning the temporal evolution of multivariate densities via  normalizing flows",
    "descriptor": "",
    "authors": [
      "Yubin Lu",
      "Romit Maulik",
      "Ting Gao",
      "Felix Dietrich",
      "Ioannis G. Kevrekidis",
      "Jinqiao Duan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2107.13735"
  },
  {
    "id": "arXiv:2108.01794",
    "title": "Explicit RIP matrices: an update",
    "abstract": "Comments: Minor corrections",
    "descriptor": "\nComments: Minor corrections\n",
    "authors": [
      "Kevin Ford",
      "Denka Kutzarova",
      "George Shakan"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2108.01794"
  },
  {
    "id": "arXiv:2108.05517",
    "title": "Masked Acoustic Unit for Mispronunciation Detection and Correction",
    "abstract": "Comments: 5 pages",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Zhan Zhang",
      "Yuehai Wang",
      "Jianyi Yang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2108.05517"
  },
  {
    "id": "arXiv:2108.10682",
    "title": "Hybrid deep learning methods for phenotype prediction from clinical  notes",
    "abstract": "Hybrid deep learning methods for phenotype prediction from clinical  notes",
    "descriptor": "",
    "authors": [
      "Sahar Khalafi",
      "Nasser Ghadiri",
      "Milad Moradi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2108.10682"
  },
  {
    "id": "arXiv:2108.12144",
    "title": "Lyra: A Benchmark for Turducken-Style Code Generation",
    "abstract": "Lyra: A Benchmark for Turducken-Style Code Generation",
    "descriptor": "",
    "authors": [
      "Qingyuan Liang",
      "Zeyu Sun",
      "Qihao Zhu",
      "Wenjie Zhang",
      "Lian Yu",
      "Yingfei Xiong",
      "Lu Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.12144"
  },
  {
    "id": "arXiv:2108.12724",
    "title": "DEGREE: A Data-Efficient Generation-Based Event Extraction Model",
    "abstract": "Comments: Paper accepted by NAACL 2022. The first two authors contribute equally. Our code and models can be found at this https URL",
    "descriptor": "\nComments: Paper accepted by NAACL 2022. The first two authors contribute equally. Our code and models can be found at this https URL\n",
    "authors": [
      "I-Hung Hsu",
      "Kuan-Hao Huang",
      "Elizabeth Boschee",
      "Scott Miller",
      "Prem Natarajan",
      "Kai-Wei Chang",
      "Nanyun Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.12724"
  },
  {
    "id": "arXiv:2108.13205",
    "title": "Model Predictive Contouring Control for Time-Optimal Quadrotor Flight",
    "abstract": "Comments: 17 pages, 16 figures. Video: this https URL This paper has been accepted for publication in the IEEE Transactions on Robotics (T-RO), 2022",
    "descriptor": "\nComments: 17 pages, 16 figures. Video: this https URL This paper has been accepted for publication in the IEEE Transactions on Robotics (T-RO), 2022\n",
    "authors": [
      "Angel Romero",
      "Sihao Sun",
      "Philipp Foehn",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.13205"
  },
  {
    "id": "arXiv:2109.00302",
    "title": "Slipping to the Extreme: A Mixed Method to Explain How Extreme Opinions  Infiltrate Online Discussions",
    "abstract": "Comments: ICWSM 2022",
    "descriptor": "\nComments: ICWSM 2022\n",
    "authors": [
      "Quyu Kong",
      "Emily Booth",
      "Francesco Bailo",
      "Amelia Johns",
      "Marian-Andrei Rizoiu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2109.00302"
  },
  {
    "id": "arXiv:2109.02431",
    "title": "On Length Divergence Bias in Textual Matching Models",
    "abstract": "Comments: Accepted to Findings of ACL 2022",
    "descriptor": "\nComments: Accepted to Findings of ACL 2022\n",
    "authors": [
      "Lan Jiang",
      "Tianshu Lyu",
      "Yankai Lin",
      "Meng Chong",
      "Xiaoyong Lyu",
      "Dawei Yin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.02431"
  },
  {
    "id": "arXiv:2109.04786",
    "title": "Wi-Fi Meets ML: A Survey on Improving IEEE 802.11 Performance with  Machine Learning",
    "abstract": "Comments: 54 pages, 23 figures, 384 references",
    "descriptor": "\nComments: 54 pages, 23 figures, 384 references\n",
    "authors": [
      "Szymon Szott",
      "Katarzyna Kosek-Szott",
      "Piotr Gaw\u0142owicz",
      "Jorge Torres G\u00f3mez",
      "Boris Bellalta",
      "Anatolij Zubow",
      "Falko Dressler"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2109.04786"
  },
  {
    "id": "arXiv:2109.06368",
    "title": "Policy Optimization Using Semi-parametric Models for Dynamic Pricing",
    "abstract": "Comments: 71 pages, Major Revision",
    "descriptor": "\nComments: 71 pages, Major Revision\n",
    "authors": [
      "Jianqing Fan",
      "Yongyi Guo",
      "Mengxin Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Optimization and Control (math.OC)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.06368"
  },
  {
    "id": "arXiv:2109.07313",
    "title": "Approximately EFX Allocations for Indivisible Chores",
    "abstract": "Comments: 13 pages, 1 figures",
    "descriptor": "\nComments: 13 pages, 1 figures\n",
    "authors": [
      "Shengwei Zhou",
      "Xiaowei Wu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2109.07313"
  },
  {
    "id": "arXiv:2109.07726",
    "title": "MOVER: Mask, Over-generate and Rank for Hyperbole Generation",
    "abstract": "Comments: Accepted to NAACL 2022",
    "descriptor": "\nComments: Accepted to NAACL 2022\n",
    "authors": [
      "Yunxiang Zhang",
      "Xiaojun Wan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07726"
  },
  {
    "id": "arXiv:2109.08265",
    "title": "Stability Analysis of Planar Probabilistic Piecewise Constant Derivative  Systems",
    "abstract": "Comments: 21 pages, 2 figures",
    "descriptor": "\nComments: 21 pages, 2 figures\n",
    "authors": [
      "Spandan Das",
      "Pavithra Prabhakar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.08265"
  },
  {
    "id": "arXiv:2109.09589",
    "title": "Local versions of sum-of-norms clustering",
    "abstract": "Comments: 20 pages, 2 figures; expositional improvements and minor error fixes in this version",
    "descriptor": "\nComments: 20 pages, 2 figures; expositional improvements and minor error fixes in this version\n",
    "authors": [
      "Alexander Dunlap",
      "Jean-Christophe Mourrat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.09589"
  },
  {
    "id": "arXiv:2109.11661",
    "title": "Deep Reinforcement Learning-Based Long-Range Autonomous Valet Parking  for Smart Cities",
    "abstract": "Comments: 6 Figures, 1 Table",
    "descriptor": "\nComments: 6 Figures, 1 Table\n",
    "authors": [
      "Muhammad Khalid",
      "Liang Wang",
      "Kezhi Wang",
      "Cunhua Pan",
      "Nauman Aslam",
      "Yue Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.11661"
  },
  {
    "id": "arXiv:2109.13099",
    "title": "Clone-based code method usage pattern mining",
    "abstract": "Comments: 5 pages, accepted by ICPC2022-ERA",
    "descriptor": "\nComments: 5 pages, accepted by ICPC2022-ERA\n",
    "authors": [
      "Zhipeng Xue",
      "Yuanliang Zhang",
      "Rulin Xu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.13099"
  },
  {
    "id": "arXiv:2109.13582",
    "title": "PPL-MCTS: Constrained Textual Generation Through Discriminator-Guided  MCTS Decoding",
    "abstract": "Comments: 15 pages, 5 tables, 7 figures, accepted to NAACL 2022",
    "descriptor": "\nComments: 15 pages, 5 tables, 7 figures, accepted to NAACL 2022\n",
    "authors": [
      "Antoine Chaffin",
      "Vincent Claveau",
      "Ewa Kijak"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.13582"
  },
  {
    "id": "arXiv:2110.00135",
    "title": "UserIdentifier: Implicit User Representations for Simple and Effective  Personalized Sentiment Analysis",
    "abstract": "UserIdentifier: Implicit User Representations for Simple and Effective  Personalized Sentiment Analysis",
    "descriptor": "",
    "authors": [
      "Fatemehsadat Mireshghallah",
      "Vaishnavi Shrivastava",
      "Milad Shokouhi",
      "Taylor Berg-Kirkpatrick",
      "Robert Sim",
      "Dimitrios Dimitriadis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.00135"
  },
  {
    "id": "arXiv:2110.00275",
    "title": "SALSA: Spatial Cue-Augmented Log-Spectrogram Features for Polyphonic  Sound Event Localization and Detection",
    "abstract": "Comments: Accepted for the IEEE/ACM Transactions on Audio Speech and Language Processing (TASLP). (c) 2022 IEEE",
    "descriptor": "\nComments: Accepted for the IEEE/ACM Transactions on Audio Speech and Language Processing (TASLP). (c) 2022 IEEE\n",
    "authors": [
      "Thi Ngoc Tho Nguyen",
      "Karn N. Watcharasupat",
      "Ngoc Khanh Nguyen",
      "Douglas L. Jones",
      "Woon-Seng Gan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.00275"
  },
  {
    "id": "arXiv:2110.04067",
    "title": "Deep Slap Fingerprint Segmentation for Juveniles and Adults",
    "abstract": "Deep Slap Fingerprint Segmentation for Juveniles and Adults",
    "descriptor": "",
    "authors": [
      "M. G. Sarwar Murshed",
      "Robert Kline",
      "Keivan Bahmani",
      "Faraz Hussain",
      "Stephanie Schuckers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.04067"
  },
  {
    "id": "arXiv:2110.04478",
    "title": "Themis: A Network Bandwidth-Aware Collective Scheduling Policy for  Distributed Training of DL Models",
    "abstract": "Themis: A Network Bandwidth-Aware Collective Scheduling Policy for  Distributed Training of DL Models",
    "descriptor": "",
    "authors": [
      "Saeed Rashidi",
      "William Won",
      "Sudarshan Srinivasan",
      "Srinivas Sridharan",
      "Tushar Krishna"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.04478"
  },
  {
    "id": "arXiv:2110.06650",
    "title": "Multistage linguistic conditioning of convolutional layers for speech  emotion recognition",
    "abstract": "Multistage linguistic conditioning of convolutional layers for speech  emotion recognition",
    "descriptor": "",
    "authors": [
      "Andreas Triantafyllopoulos",
      "Uwe Reichel",
      "Shuo Liu",
      "Stephan Huber",
      "Florian Eyben",
      "Bj\u00f6rn W. Schuller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06650"
  },
  {
    "id": "arXiv:2110.07270",
    "title": "Spherical polar coordinate transformation for integration of singular  functions on tetrahedra",
    "abstract": "Spherical polar coordinate transformation for integration of singular  functions on tetrahedra",
    "descriptor": "",
    "authors": [
      "Michael J. Carley"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.07270"
  },
  {
    "id": "arXiv:2110.08555",
    "title": "On the Robustness of Reading Comprehension Models to Entity Renaming",
    "abstract": "Comments: Accepted to NAACL 2022",
    "descriptor": "\nComments: Accepted to NAACL 2022\n",
    "authors": [
      "Jun Yan",
      "Yang Xiao",
      "Sagnik Mukherjee",
      "Bill Yuchen Lin",
      "Robin Jia",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08555"
  },
  {
    "id": "arXiv:2110.08743",
    "title": "GNN-LM: Language Modeling based on Global Contexts via GNN",
    "abstract": "Comments: To appear at ICLR 2022",
    "descriptor": "\nComments: To appear at ICLR 2022\n",
    "authors": [
      "Yuxian Meng",
      "Shi Zong",
      "Xiaoya Li",
      "Xiaofei Sun",
      "Tianwei Zhang",
      "Fei Wu",
      "Jiwei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08743"
  },
  {
    "id": "arXiv:2110.12683",
    "title": "Information-Theoretic Limits of Integrated Sensing and Communication  with Correlated Sensing and Channel States for Vehicular Networks",
    "abstract": "Information-Theoretic Limits of Integrated Sensing and Communication  with Correlated Sensing and Channel States for Vehicular Networks",
    "descriptor": "",
    "authors": [
      "Yao Liu",
      "Min Li",
      "An Liu",
      "Jianmin Lu",
      "Tony Xiao Han"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.12683"
  },
  {
    "id": "arXiv:2110.14782",
    "title": "When is BERT Multilingual? Isolating Crucial Ingredients for  Cross-lingual Transfer",
    "abstract": "Comments: Accepted at NAACL 2022",
    "descriptor": "\nComments: Accepted at NAACL 2022\n",
    "authors": [
      "Ameet Deshpande",
      "Partha Talukdar",
      "Karthik Narasimhan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14782"
  },
  {
    "id": "arXiv:2110.15105",
    "title": "A Game-Theoretic Approach for Improving Generalization Ability of TSP  Solvers",
    "abstract": "Comments: ICLR2022 Gamification and Multiagent Solutions Workshop Spotlight Presentation",
    "descriptor": "\nComments: ICLR2022 Gamification and Multiagent Solutions Workshop Spotlight Presentation\n",
    "authors": [
      "Chenguang Wang",
      "Yaodong Yang",
      "Oliver Slumbers",
      "Congying Han",
      "Tiande Guo",
      "Haifeng Zhang",
      "Jun Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15105"
  },
  {
    "id": "arXiv:2110.15163",
    "title": "Authentication Attacks on Projection-based Cancelable Biometric Schemes  (long version)",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1910.01389 by other authors",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1910.01389 by other authors\n",
    "authors": [
      "Axel Durbet",
      "Pascal Lafourcade",
      "Denis Migdal",
      "Kevin Thiry-Atighehchi",
      "Paul-Marie Grollemund"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15163"
  },
  {
    "id": "arXiv:2111.03701",
    "title": "Functional Choreographic Programming",
    "abstract": "Functional Choreographic Programming",
    "descriptor": "",
    "authors": [
      "Lu\u00eds Cruz-Filipe",
      "Eva Graversen",
      "Lovro Lugovi\u0107",
      "Fabrizio Montesi",
      "Marco Peressotti"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.03701"
  },
  {
    "id": "arXiv:2111.05826",
    "title": "Palette: Image-to-Image Diffusion Models",
    "abstract": "Palette: Image-to-Image Diffusion Models",
    "descriptor": "",
    "authors": [
      "Chitwan Saharia",
      "William Chan",
      "Huiwen Chang",
      "Chris A. Lee",
      "Jonathan Ho",
      "Tim Salimans",
      "David J. Fleet",
      "Mohammad Norouzi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.05826"
  },
  {
    "id": "arXiv:2111.05835",
    "title": "What Makes Online Communities 'Better'? Measuring Values, Consensus, and  Conflict across Thousands of Subreddits",
    "abstract": "Comments: 12 pages, 8 figures, 4 tables; to appear at ICWSM 2022",
    "descriptor": "\nComments: 12 pages, 8 figures, 4 tables; to appear at ICWSM 2022\n",
    "authors": [
      "Galen Weld",
      "Amy X. Zhang",
      "Tim Althoff"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.05835"
  },
  {
    "id": "arXiv:2111.07274",
    "title": "Choriented Maps: Visualizing SDG Data on Mobile Devices",
    "abstract": "Comments: Accepted for publication in the Cartographic Journal",
    "descriptor": "\nComments: Accepted for publication in the Cartographic Journal\n",
    "authors": [
      "Viktor Gorte",
      "Auriol Degbelo"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.07274"
  },
  {
    "id": "arXiv:2111.08192",
    "title": "SALSA-Lite: A Fast and Effective Feature for Polyphonic Sound Event  Localization and Detection with Microphone Arrays",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2110.00275",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2110.00275\n",
    "authors": [
      "Thi Ngoc Tho Nguyen",
      "Douglas L. Jones",
      "Karn N. Watcharasupat",
      "Huy Phan",
      "Woon-Seng Gan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.08192"
  },
  {
    "id": "arXiv:2111.08366",
    "title": "Multi-Vector Models with Textual Guidance for Fine-Grained Scientific  Document Similarity",
    "abstract": "Comments: NAACL 2022 camera-ready",
    "descriptor": "\nComments: NAACL 2022 camera-ready\n",
    "authors": [
      "Sheshera Mysore",
      "Arman Cohan",
      "Tom Hope"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.08366"
  },
  {
    "id": "arXiv:2111.08693",
    "title": "Inverting brain grey matter models with likelihood-free inference: a  tool for trustable cytoarchitecture measurements",
    "abstract": "Inverting brain grey matter models with likelihood-free inference: a  tool for trustable cytoarchitecture measurements",
    "descriptor": "",
    "authors": [
      "Ma\u00ebliss Jallais",
      "Pedro Luiz Coelho Rodrigues",
      "Alexandre Gramfort",
      "Demian Wassermann"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08693"
  },
  {
    "id": "arXiv:2111.09453",
    "title": "RoBERTuito: a pre-trained language model for social media text in  Spanish",
    "abstract": "Comments: LREC 2022",
    "descriptor": "\nComments: LREC 2022\n",
    "authors": [
      "Juan Manuel P\u00e9rez",
      "Dami\u00e1n A. Furman",
      "Laura Alonso Alemany",
      "Franco Luque"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.09453"
  },
  {
    "id": "arXiv:2111.11843",
    "title": "U-shape Transformer for Underwater Image Enhancement",
    "abstract": "Comments: under review",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Lintao Peng",
      "Chunli Zhu",
      "Liheng Bian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.11843"
  },
  {
    "id": "arXiv:2111.14893",
    "title": "Learning Multiple Dense Prediction Tasks from Partially Annotated Data",
    "abstract": "Comments: CVPR2022, Multi-task Partially-supervised Learning, Code will be available at this https URL",
    "descriptor": "\nComments: CVPR2022, Multi-task Partially-supervised Learning, Code will be available at this https URL\n",
    "authors": [
      "Wei-Hong Li",
      "Xialei Liu",
      "Hakan Bilen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.14893"
  },
  {
    "id": "arXiv:2112.01455",
    "title": "Zero-Shot Text-Guided Object Generation with Dream Fields",
    "abstract": "Comments: CVPR 2022. 13 pages. Website: this https URL",
    "descriptor": "\nComments: CVPR 2022. 13 pages. Website: this https URL\n",
    "authors": [
      "Ajay Jain",
      "Ben Mildenhall",
      "Jonathan T. Barron",
      "Pieter Abbeel",
      "Ben Poole"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01455"
  },
  {
    "id": "arXiv:2112.01806",
    "title": "Music-to-Dance Generation with Optimal Transport",
    "abstract": "Comments: IJCAI 2022",
    "descriptor": "\nComments: IJCAI 2022\n",
    "authors": [
      "Shuang Wu",
      "Shijian Lu",
      "Li Cheng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.01806"
  },
  {
    "id": "arXiv:2112.01953",
    "title": "Improving the Robustness of Reinforcement Learning Policies with  $\\mathcal{L}_{1}$ Adaptive Control",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2106.02249",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2106.02249\n",
    "authors": [
      "Y. Cheng",
      "P. Zhao",
      "F. Wang",
      "D. J. Block",
      "N. Hovakimyan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.01953"
  },
  {
    "id": "arXiv:2112.02682",
    "title": "BERTMap: A BERT-based Ontology Alignment System",
    "abstract": "Comments: Full version (with appendix) of the accepted paper in 36th AAAI Conference on Artificial Intelligence 2022",
    "descriptor": "\nComments: Full version (with appendix) of the accepted paper in 36th AAAI Conference on Artificial Intelligence 2022\n",
    "authors": [
      "Yuan He",
      "Jiaoyan Chen",
      "Denvar Antonyrajah",
      "Ian Horrocks"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.02682"
  },
  {
    "id": "arXiv:2112.03051",
    "title": "Controllable Animation of Fluid Elements in Still Images",
    "abstract": "Controllable Animation of Fluid Elements in Still Images",
    "descriptor": "",
    "authors": [
      "Aniruddha Mahapatra",
      "Kuldeep Kulkarni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03051"
  },
  {
    "id": "arXiv:2112.05854",
    "title": "Transversal GRAND for Network Coded Data",
    "abstract": "Comments: 6 pages, 3 figures. To be published in the proceedings of the 2022 IEEE International Symposium on Information Theory (ISIT 2022)",
    "descriptor": "\nComments: 6 pages, 3 figures. To be published in the proceedings of the 2022 IEEE International Symposium on Information Theory (ISIT 2022)\n",
    "authors": [
      "Ioannis Chatzigeorgiou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.05854"
  },
  {
    "id": "arXiv:2112.06598",
    "title": "WECHSEL: Effective initialization of subword embeddings for  cross-lingual transfer of monolingual language models",
    "abstract": "Comments: NAACL 2022",
    "descriptor": "\nComments: NAACL 2022\n",
    "authors": [
      "Benjamin Minixhofer",
      "Fabian Paischer",
      "Navid Rekabsaz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.06598"
  },
  {
    "id": "arXiv:2112.06796",
    "title": "Depth Uncertainty Networks for Active Learning",
    "abstract": "Depth Uncertainty Networks for Active Learning",
    "descriptor": "",
    "authors": [
      "Chelsea Murray",
      "James U. Allingham",
      "Javier Antor\u00e1n",
      "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.06796"
  },
  {
    "id": "arXiv:2112.06848",
    "title": "Peer-to-Peer Communication Trade-Offs for Smart Grid Applications",
    "abstract": "Comments: 10 pages, 6 figures",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Purboday Ghosh",
      "Shashank Shekhar",
      "Yashen Lin",
      "Ulrich Muenz",
      "Gabor Karsai"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.06848"
  },
  {
    "id": "arXiv:2112.07210",
    "title": "Simple Local Attentions Remain Competitive for Long-Context Tasks",
    "abstract": "Comments: NAACL 2022 Main Conference",
    "descriptor": "\nComments: NAACL 2022 Main Conference\n",
    "authors": [
      "Wenhan Xiong",
      "Barlas O\u011fuz",
      "Anchit Gupta",
      "Xilun Chen",
      "Diana Liskovich",
      "Omer Levy",
      "Wen-tau Yih",
      "Yashar Mehdad"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07210"
  },
  {
    "id": "arXiv:2112.08185",
    "title": "Learning Cross-Lingual IR from an English Retriever",
    "abstract": "Comments: 9 pages",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Yulong Li",
      "Martin Franz",
      "Md Arafat Sultan",
      "Bhavani Iyer",
      "Young-Suk Lee",
      "Avirup Sil"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08185"
  },
  {
    "id": "arXiv:2112.08348",
    "title": "Prompt Waywardness: The Curious Case of Discretized Interpretation of  Continuous Prompts",
    "abstract": "Comments: NAACL 2022",
    "descriptor": "\nComments: NAACL 2022\n",
    "authors": [
      "Daniel Khashabi",
      "Shane Lyu",
      "Sewon Min",
      "Lianhui Qin",
      "Kyle Richardson",
      "Sean Welleck",
      "Hannaneh Hajishirzi",
      "Tushar Khot",
      "Ashish Sabharwal",
      "Sameer Singh",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08348"
  },
  {
    "id": "arXiv:2112.08466",
    "title": "ErAConD : Error Annotated Conversational Dialog Dataset for Grammatical  Error Correction",
    "abstract": "ErAConD : Error Annotated Conversational Dialog Dataset for Grammatical  Error Correction",
    "descriptor": "",
    "authors": [
      "Xun Yuan",
      "Derek Pham",
      "Sam Davidson",
      "Zhou Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08466"
  },
  {
    "id": "arXiv:2112.08703",
    "title": "ADEPT: Automatic Differentiable DEsign of Photonic Tensor Cores",
    "abstract": "Comments: Accepted to ACM/IEEE Design Automation Conference (DAC), 2022",
    "descriptor": "\nComments: Accepted to ACM/IEEE Design Automation Conference (DAC), 2022\n",
    "authors": [
      "Jiaqi Gu",
      "Hanqing Zhu",
      "Chenghao Feng",
      "Zixuan Jiang",
      "Mingjie Liu",
      "Shuhan Zhang",
      "Ray T. Chen",
      "David Z. Pan"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2112.08703"
  },
  {
    "id": "arXiv:2112.09130",
    "title": "Ensembling Off-the-shelf Models for GAN Training",
    "abstract": "Comments: CVPR 2022 (Oral). GitHub: this https URL Project webpage: this https URL",
    "descriptor": "\nComments: CVPR 2022 (Oral). GitHub: this https URL Project webpage: this https URL\n",
    "authors": [
      "Nupur Kumari",
      "Richard Zhang",
      "Eli Shechtman",
      "Jun-Yan Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.09130"
  },
  {
    "id": "arXiv:2112.09384",
    "title": "An Exact Algorithm for the Linear Tape Scheduling Problem",
    "abstract": "An Exact Algorithm for the Linear Tape Scheduling Problem",
    "descriptor": "",
    "authors": [
      "Valentin Honor\u00e9",
      "Bertrand Simon",
      "Fr\u00e9d\u00e9ric Suter"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.09384"
  },
  {
    "id": "arXiv:2112.09809",
    "title": "A Streaming Volumetric Image Generation Framework for Development and  Evaluation of Out-of-Core Methods",
    "abstract": "A Streaming Volumetric Image Generation Framework for Development and  Evaluation of Out-of-Core Methods",
    "descriptor": "",
    "authors": [
      "Dominik Drees",
      "Xiaoyi Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.09809"
  },
  {
    "id": "arXiv:2112.10728",
    "title": "MuMuQA: Multimedia Multi-Hop News Question Answering via Cross-Media  Knowledge Extraction and Grounding",
    "abstract": "Comments: Accepted at AAAI 2022",
    "descriptor": "\nComments: Accepted at AAAI 2022\n",
    "authors": [
      "Revanth Gangi Reddy",
      "Xilin Rui",
      "Manling Li",
      "Xudong Lin",
      "Haoyang Wen",
      "Jaemin Cho",
      "Lifu Huang",
      "Mohit Bansal",
      "Avirup Sil",
      "Shih-Fu Chang",
      "Alexander Schwing",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.10728"
  },
  {
    "id": "arXiv:2112.11833",
    "title": "Deep learning for brain metastasis detection and segmentation in  longitudinal MRI data",
    "abstract": "Deep learning for brain metastasis detection and segmentation in  longitudinal MRI data",
    "descriptor": "",
    "authors": [
      "Yixing Huang",
      "Christoph Bert",
      "Philipp Sommer",
      "Benjamin Frey",
      "Udo Gaipl",
      "Luitpold V. Distel",
      "Thomas Weissmann",
      "Michael Uder",
      "Manuel A. Schmidt",
      "Arnd D\u00f6rfler",
      "Andreas Maier",
      "Rainer Fietkau",
      "Florian Putz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.11833"
  },
  {
    "id": "arXiv:2112.12522",
    "title": "Multi-Variant Consistency based Self-supervised Learning for Robust  Automatic Speech Recognition",
    "abstract": "Comments: 6 pages, 3 figures",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Changfeng Gao",
      "Gaofeng Cheng",
      "Pengyuan Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.12522"
  },
  {
    "id": "arXiv:2112.13079",
    "title": "Aligning random graphs with a sub-tree similarity message-passing  algorithm",
    "abstract": "Comments: 36 pages, 14 figures, submitted to Journal of Statistical Mechanics: Theory and Experiment. Corrected typos. Modified Figure 1 for clarity. Added references' titles in bibliography. Added definition of \"quasi-aligned\". Added clarifications about the significance of Nishimori experiments",
    "descriptor": "\nComments: 36 pages, 14 figures, submitted to Journal of Statistical Mechanics: Theory and Experiment. Corrected typos. Modified Figure 1 for clarity. Added references' titles in bibliography. Added definition of \"quasi-aligned\". Added clarifications about the significance of Nishimori experiments\n",
    "authors": [
      "Giovanni Piccioli",
      "Guilhem Semerjian",
      "Gabriele Sicuro",
      "Lenka Zdeborov\u00e1"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2112.13079"
  },
  {
    "id": "arXiv:2201.00008",
    "title": "A Lightweight and Accurate Spatial-Temporal Transformer for Traffic  Forecasting",
    "abstract": "A Lightweight and Accurate Spatial-Temporal Transformer for Traffic  Forecasting",
    "descriptor": "",
    "authors": [
      "Guanyao Li",
      "Shuhan Zhong",
      "S.-H. Gary Chan",
      "Ruiyuan Li",
      "Chih-Chieh Hung",
      "Wen-Chih Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.00008"
  },
  {
    "id": "arXiv:2201.01441",
    "title": "Balsa: Learning a Query Optimizer Without Expert Demonstrations",
    "abstract": "Comments: SIGMOD 2022; code released at: this https URL",
    "descriptor": "\nComments: SIGMOD 2022; code released at: this https URL\n",
    "authors": [
      "Zongheng Yang",
      "Wei-Lin Chiang",
      "Sifei Luan",
      "Gautam Mittal",
      "Michael Luo",
      "Ion Stoica"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.01441"
  },
  {
    "id": "arXiv:2201.01461",
    "title": "Towards Maximizing a Perceptual Sweet Spot",
    "abstract": "Comments: 24 pages, 3 figures. Modified the perceptual model to account for binaural effects. Updated the methods and experiments accordingly",
    "descriptor": "\nComments: 24 pages, 3 figures. Modified the perceptual model to account for binaural effects. Updated the methods and experiments accordingly\n",
    "authors": [
      "Pedro Izquierdo Lehmann",
      "Rodrigo F. Cadiz",
      "Carlos A. Sing Long"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2201.01461"
  },
  {
    "id": "arXiv:2201.05978",
    "title": "Discrete Simulation Optimization for Tuning Machine Learning Method  Hyperparameters",
    "abstract": "Discrete Simulation Optimization for Tuning Machine Learning Method  Hyperparameters",
    "descriptor": "",
    "authors": [
      "Varun Ramamohan",
      "Shobhit Singhal",
      "Aditya Raj Gupta",
      "Nomesh Bhojkumar Bolia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.05978"
  },
  {
    "id": "arXiv:2201.05989",
    "title": "Instant Neural Graphics Primitives with a Multiresolution Hash Encoding",
    "abstract": "Comments: To appear in ACM Transactions on Graphics (SIGGRAPH 2022). 15 pages, 13 figures, 3 tables",
    "descriptor": "\nComments: To appear in ACM Transactions on Graphics (SIGGRAPH 2022). 15 pages, 13 figures, 3 tables\n",
    "authors": [
      "Thomas M\u00fcller",
      "Alex Evans",
      "Christoph Schied",
      "Alexander Keller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.05989"
  },
  {
    "id": "arXiv:2201.06995",
    "title": "Improved Receivers for Optical Wireless OFDM: An Information Theoretic  Perspective",
    "abstract": "Comments: 15 pages, 17 figures.To appear in IEEE Transactions on Communications",
    "descriptor": "\nComments: 15 pages, 17 figures.To appear in IEEE Transactions on Communications\n",
    "authors": [
      "Xiaozhen Liu",
      "Jing Zhou",
      "Nuo Huang",
      "Wenyi Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.06995"
  },
  {
    "id": "arXiv:2201.08026",
    "title": "Several Proofs of Coerciveness of First-Order System Least-Squares  Methods for General Second-Order Elliptic PDEs",
    "abstract": "Several Proofs of Coerciveness of First-Order System Least-Squares  Methods for General Second-Order Elliptic PDEs",
    "descriptor": "",
    "authors": [
      "Shun Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.08026"
  },
  {
    "id": "arXiv:2201.10092",
    "title": "Stochastic Coded Federated Learning with Convergence and Privacy  Guarantees",
    "abstract": "Stochastic Coded Federated Learning with Convergence and Privacy  Guarantees",
    "descriptor": "",
    "authors": [
      "Yuchang Sun",
      "Jiawei Shao",
      "Songze Li",
      "Yuyi Mao",
      "Jun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.10092"
  },
  {
    "id": "arXiv:2201.12868",
    "title": "Anticipation-Free Training for Simultaneous Machine Translation",
    "abstract": "Comments: Accepted to IWSLT 2022",
    "descriptor": "\nComments: Accepted to IWSLT 2022\n",
    "authors": [
      "Chih-Chiang Chang",
      "Shun-Po Chuang",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.12868"
  },
  {
    "id": "arXiv:2201.13178",
    "title": "Few-Shot Backdoor Attacks on Visual Object Tracking",
    "abstract": "Comments: This work is accepted by the ICLR 2022. The first two authors contributed equally to this work. In this version, we fix some typos and errors contained in the last one. 21 pages",
    "descriptor": "\nComments: This work is accepted by the ICLR 2022. The first two authors contributed equally to this work. In this version, we fix some typos and errors contained in the last one. 21 pages\n",
    "authors": [
      "Yiming Li",
      "Haoxiang Zhong",
      "Xingjun Ma",
      "Yong Jiang",
      "Shu-Tao Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.13178"
  },
  {
    "id": "arXiv:2202.00450",
    "title": "Approximation of Images via Generalized Higher Order Singular Value  Decomposition over Finite-dimensional Commutative Semisimple Algebra",
    "abstract": "Comments: 20 pages, a typo in equation (59) of the appendix corrected",
    "descriptor": "\nComments: 20 pages, a typo in equation (59) of the appendix corrected\n",
    "authors": [
      "Liang Liao",
      "Sen Lin",
      "Lun Li",
      "Xiuwei Zhang",
      "Song Zhao",
      "Yan Wang",
      "Xinqiang Wang",
      "Qi Gao",
      "Jingyu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Commutative Algebra (math.AC)",
      "Representation Theory (math.RT)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.00450"
  },
  {
    "id": "arXiv:2202.01380",
    "title": "Learning Mechanically Driven Emergent Behavior with Message Passing  Neural Networks",
    "abstract": "Comments: 24 pages, 14 figures; added section 3.5 and Appendix C; fixed minor typos",
    "descriptor": "\nComments: 24 pages, 14 figures; added section 3.5 and Appendix C; fixed minor typos\n",
    "authors": [
      "Peerasait Prachaseree",
      "Emma Lejeune"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2202.01380"
  },
  {
    "id": "arXiv:2202.02093",
    "title": "Temporal Attention for Language Models",
    "abstract": "Comments: Findings of NAACL 2022. 9 pages",
    "descriptor": "\nComments: Findings of NAACL 2022. 9 pages\n",
    "authors": [
      "Guy D. Rosin",
      "Kira Radinsky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.02093"
  },
  {
    "id": "arXiv:2202.04246",
    "title": "The decision problem for perfect matchings in dense hypergraphs",
    "abstract": "Comments: 15 pages, To appear in ICALP 2022",
    "descriptor": "\nComments: 15 pages, To appear in ICALP 2022\n",
    "authors": [
      "Luyining Gan",
      "Jie Han"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.04246"
  },
  {
    "id": "arXiv:2202.04801",
    "title": "The leap to ordinal: detailed functional prognosis after traumatic brain  injury with a flexible modelling approach",
    "abstract": "Comments: 68 pages, 4 figures, 4 tables, 1 appendix, 6 supplementary figures, 4 supplementary tables, 3 supplementary methods, 1 supplementary result",
    "descriptor": "\nComments: 68 pages, 4 figures, 4 tables, 1 appendix, 6 supplementary figures, 4 supplementary tables, 3 supplementary methods, 1 supplementary result\n",
    "authors": [
      "Shubhayu Bhattacharyay",
      "Ioan Milosevic",
      "Lindsay Wilson",
      "David K. Menon",
      "Robert D. Stevens",
      "Ewout W. Steyerberg",
      "David W. Nelson",
      "Ari Ercole",
      "CENTER-TBI investigators/participants"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04801"
  },
  {
    "id": "arXiv:2202.09338",
    "title": "Signal Decomposition Using Masked Proximal Operators",
    "abstract": "Comments: The manuscript has 60 pages, 22 figures and 2 tables. Also hosted at this https URL For code, see this https URL",
    "descriptor": "\nComments: The manuscript has 60 pages, 22 figures and 2 tables. Also hosted at this https URL For code, see this https URL\n",
    "authors": [
      "Bennet E. Meyers",
      "Stephen P. Boyd"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.09338"
  },
  {
    "id": "arXiv:2202.11087",
    "title": "Semi-Blind Joint Channel and Symbol Estimation in IRS-Assisted  Multi-User MIMO Networks",
    "abstract": "Semi-Blind Joint Channel and Symbol Estimation in IRS-Assisted  Multi-User MIMO Networks",
    "descriptor": "",
    "authors": [
      "Gilderlan Tavares de Ara\u00fajo",
      "Paulo Ricardo Brboza Gomes",
      "Andr\u00e9 Lima F\u00e9rrer de Almeida",
      "Gabor Fodor",
      "Behrooz Makki"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.11087"
  },
  {
    "id": "arXiv:2202.11271",
    "title": "ViKiNG: Vision-Based Kilometer-Scale Navigation with Geographic Hints",
    "abstract": "Comments: Accepted for presentation at XVII Robotics: Science and Systems (RSS 2022), New York City, USA. Project page this https URL",
    "descriptor": "\nComments: Accepted for presentation at XVII Robotics: Science and Systems (RSS 2022), New York City, USA. Project page this https URL\n",
    "authors": [
      "Dhruv Shah",
      "Sergey Levine"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.11271"
  },
  {
    "id": "arXiv:2202.12416",
    "title": "Microgrid Day-Ahead Scheduling Considering Neural Network based Battery  Degradation Model",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Cunzhi Zhao",
      "Xingpeng Li"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12416"
  },
  {
    "id": "arXiv:2202.13169",
    "title": "A Systematic Evaluation of Large Language Models of Code",
    "abstract": "Comments: DL4C@ICLR 2022, and MAPS@PLDI 2022",
    "descriptor": "\nComments: DL4C@ICLR 2022, and MAPS@PLDI 2022\n",
    "authors": [
      "Frank F. Xu",
      "Uri Alon",
      "Graham Neubig",
      "Vincent J. Hellendoorn"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.13169"
  },
  {
    "id": "arXiv:2202.13254",
    "title": "Observers for Differential Algebraic Equation Models of Power Networks:  Jointly Estimating Dynamic and Algebraic States",
    "abstract": "Observers for Differential Algebraic Equation Models of Power Networks:  Jointly Estimating Dynamic and Algebraic States",
    "descriptor": "",
    "authors": [
      "Sebastian Nugroho",
      "Ahmad Taha",
      "Nikolaos Gatsis",
      "Junbo Zhao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.13254"
  },
  {
    "id": "arXiv:2202.13693",
    "title": "Explainable deepfake and spoofing detection: an attack analysis using  SHapley Additive exPlanations",
    "abstract": "Comments: Accepted to Speaker Odyssey Workshop 2022",
    "descriptor": "\nComments: Accepted to Speaker Odyssey Workshop 2022\n",
    "authors": [
      "Wanying Ge",
      "Massimiliano Todisco",
      "Nicholas Evans"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.13693"
  },
  {
    "id": "arXiv:2203.03515",
    "title": "Identifying Scenarios in Field Data to Enable Validation of Highly  Automated Driving Systems",
    "abstract": "Comments: 9 pages, 5 figures",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Christian Reichenb\u00e4cher",
      "Maximilian Rasch",
      "Zafer Kayatas",
      "Florian Wirthm\u00fcller",
      "Jochen Hipp",
      "Thao Dang",
      "Oliver Bringmann"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.03515"
  },
  {
    "id": "arXiv:2203.04203",
    "title": "AssistQ: Affordance-centric Question-driven Task Completion for  Egocentric Assistant",
    "abstract": "Comments: 16 pages. Equal contribution: Benita Wong, Joya Chen, You Wu; Corresponding author: Mike Zheng Shou",
    "descriptor": "\nComments: 16 pages. Equal contribution: Benita Wong, Joya Chen, You Wu; Corresponding author: Mike Zheng Shou\n",
    "authors": [
      "Benita Wong",
      "Joya Chen",
      "You Wu",
      "Stan Weixian Lei",
      "Dongxing Mao",
      "Difei Gao",
      "Mike Zheng Shou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04203"
  },
  {
    "id": "arXiv:2203.05325",
    "title": "AIFB-WebScience at SemEval-2022 Task 12: Relation Extraction First --  Using Relation Extraction to Identify Entities",
    "abstract": "Comments: Camera ready version",
    "descriptor": "\nComments: Camera ready version\n",
    "authors": [
      "Nicholas Popovic",
      "Walter Laurito",
      "Michael F\u00e4rber"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05325"
  },
  {
    "id": "arXiv:2203.05838",
    "title": "Staking Pools on Blockchains",
    "abstract": "Staking Pools on Blockchains",
    "descriptor": "",
    "authors": [
      "Hans Gersbach",
      "Akaki Mamageishvili",
      "Manvir Schneider"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2203.05838"
  },
  {
    "id": "arXiv:2203.06855",
    "title": "DIAS: A Domain-Independent Alife-Based Problem-Solving System",
    "abstract": "Comments: 9 pages, 6 figures",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Babak Hodjat",
      "Hormoz Shahrzad",
      "Risto Miikkulainen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2203.06855"
  },
  {
    "id": "arXiv:2203.07589",
    "title": "Sim-to-Real Learning of Footstep-Constrained Bipedal Dynamic Walking",
    "abstract": "Comments: Accepted at ICRA 2022. Video at this https URL",
    "descriptor": "\nComments: Accepted at ICRA 2022. Video at this https URL\n",
    "authors": [
      "Helei Duan",
      "Ashish Malik",
      "Jeremy Dao",
      "Aseem Saxena",
      "Kevin Green",
      "Jonah Siekmann",
      "Alan Fern",
      "Jonathan Hurst"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.07589"
  },
  {
    "id": "arXiv:2203.07836",
    "title": "Graph Pre-training for AMR Parsing and Generation",
    "abstract": "Comments: ACL2022 camera-ready final version",
    "descriptor": "\nComments: ACL2022 camera-ready final version\n",
    "authors": [
      "Xuefeng Bai",
      "Yulong Chen",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.07836"
  },
  {
    "id": "arXiv:2203.11444",
    "title": "Root-aligned SMILES: A Tight Representation for Chemical Reaction  Prediction",
    "abstract": "Comments: Main paper: 23 pages, 5 figures, and 3 table; supplementary information: 12 pages, 5 figures and 2 tables. Code repository: this https URL",
    "descriptor": "\nComments: Main paper: 23 pages, 5 figures, and 3 table; supplementary information: 12 pages, 5 figures and 2 tables. Code repository: this https URL\n",
    "authors": [
      "Zipeng Zhong",
      "Jie Song",
      "Zunlei Feng",
      "Tiantao Liu",
      "Lingxiang Jia",
      "Shaolun Yao",
      "Min Wu",
      "Tingjun Hou",
      "Mingli Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2203.11444"
  },
  {
    "id": "arXiv:2203.12324",
    "title": "Proportional Budget Allocations: Towards a Systematization",
    "abstract": "Comments: 17 pages",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Maaike Los",
      "Zo\u00e9 Christoff",
      "Davide Grossi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2203.12324"
  },
  {
    "id": "arXiv:2203.12481",
    "title": "Prompt-based Pre-trained Model for Personality and Interpersonal  Reactivity Prediction",
    "abstract": "Prompt-based Pre-trained Model for Personality and Interpersonal  Reactivity Prediction",
    "descriptor": "",
    "authors": [
      "Bin Li",
      "Yixuan Weng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.12481"
  },
  {
    "id": "arXiv:2203.12728",
    "title": "Risk, Resilience and Reward: Impacts of Shifting to Digital Sex Work",
    "abstract": "Risk, Resilience and Reward: Impacts of Shifting to Digital Sex Work",
    "descriptor": "",
    "authors": [
      "Vaughn Hamilton",
      "Hanna Barakat",
      "Elissa M. Redmiles"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.12728"
  },
  {
    "id": "arXiv:2203.13658",
    "title": "MDsrv -- visual sharing and analysis of molecular dynamics simulations",
    "abstract": "Comments: 9 pages, 3 figures",
    "descriptor": "\nComments: 9 pages, 3 figures\n",
    "authors": [
      "Michelle Kampfrath",
      "Ren\u00e9 Staritzbichler",
      "Guillermo P\u00e9rez Hern\u00e1ndez",
      "Alexander S. Rose",
      "Johanna K.S. Tiemann",
      "Gerik Scheuermann",
      "Daniel Wiegreffe",
      "Peter W. Hildebrand"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.13658"
  },
  {
    "id": "arXiv:2203.16165",
    "title": "Symbolic music generation conditioned on continuous-valued emotions",
    "abstract": "Comments: Published in IEEE Access",
    "descriptor": "\nComments: Published in IEEE Access\n",
    "authors": [
      "Serkan Sulun",
      "Matthew E. P. Davies",
      "Paula Viana"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2203.16165"
  },
  {
    "id": "arXiv:2203.16773",
    "title": "An Exploration of Prompt Tuning on Generative Spoken Language Model for  Speech Processing Tasks",
    "abstract": "Comments: The original version is submitted to Interspeech 2022",
    "descriptor": "\nComments: The original version is submitted to Interspeech 2022\n",
    "authors": [
      "Kai-Wei Chang",
      "Wei-Cheng Tseng",
      "Shang-Wen Li",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.16773"
  },
  {
    "id": "arXiv:2204.02296",
    "title": "iSDF: Real-Time Neural Signed Distance Fields for Robot Perception",
    "abstract": "Comments: Published in Robotics: Science and Systems (RSS) 2022. Project page: this https URL",
    "descriptor": "\nComments: Published in Robotics: Science and Systems (RSS) 2022. Project page: this https URL\n",
    "authors": [
      "Joseph Ortiz",
      "Alexander Clegg",
      "Jing Dong",
      "Edgar Sucar",
      "David Novotny",
      "Michael Zollhoefer",
      "Mustafa Mukadam"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02296"
  },
  {
    "id": "arXiv:2204.02546",
    "title": "Quick Starting Dialog Systems with Paraphrase Generation",
    "abstract": "Quick Starting Dialog Systems with Paraphrase Generation",
    "descriptor": "",
    "authors": [
      "Louis Marceau",
      "Raouf Belbahar",
      "Marc Queudot",
      "Nada Naji",
      "Eric Charton",
      "Marie-Jean Meurs"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.02546"
  },
  {
    "id": "arXiv:2204.03740",
    "title": "Successes and critical failures of neural networks in capturing  human-like speech recognition",
    "abstract": "Successes and critical failures of neural networks in capturing  human-like speech recognition",
    "descriptor": "",
    "authors": [
      "Federico Adolfi",
      "Jeffrey S. Bowers",
      "David Poeppel"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2204.03740"
  },
  {
    "id": "arXiv:2204.04487",
    "title": "Informativeness and Invariance: Two Perspectives on Spurious  Correlations in Natural Language",
    "abstract": "Comments: NAACL 2022",
    "descriptor": "\nComments: NAACL 2022\n",
    "authors": [
      "Jacob Eisenstein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04487"
  },
  {
    "id": "arXiv:2204.05011",
    "title": "FederatedScope: A Flexible Federated Learning Platform for Heterogeneity",
    "abstract": "Comments: We have released FederatedScope for users on this https URL",
    "descriptor": "\nComments: We have released FederatedScope for users on this https URL\n",
    "authors": [
      "Yuexiang Xie",
      "Zhen Wang",
      "Daoyuan Chen",
      "Dawei Gao",
      "Liuyi Yao",
      "Weirui Kuang",
      "Yaliang Li",
      "Bolin Ding",
      "Jingren Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05011"
  },
  {
    "id": "arXiv:2204.05112",
    "title": "FastMapSVM: Classifying Complex Objects Using the FastMap Algorithm and  Support-Vector Machines",
    "abstract": "Comments: 27 pages, 12 figures",
    "descriptor": "\nComments: 27 pages, 12 figures\n",
    "authors": [
      "Malcolm C. A. White",
      "Kushal Sharma",
      "Ang Li",
      "T. K. Satish Kumar",
      "Nori Nakata"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.05112"
  },
  {
    "id": "arXiv:2204.06131",
    "title": "Timeloops: Automatic System Call Policy Learning for Containerized  Microservices",
    "abstract": "Timeloops: Automatic System Call Policy Learning for Containerized  Microservices",
    "descriptor": "",
    "authors": [
      "Meghna Pancholi",
      "Andreas D. Kellas",
      "Vasileios P. Kemerlis",
      "Simha Sethumadhavan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.06131"
  },
  {
    "id": "arXiv:2204.06283",
    "title": "Curriculum: A Broad-Coverage Benchmark for Linguistic Phenomena in  Natural Language Understanding",
    "abstract": "Comments: NAACL 2022 (Main Conference), Camera-ready Version",
    "descriptor": "\nComments: NAACL 2022 (Main Conference), Camera-ready Version\n",
    "authors": [
      "Zeming Chen",
      "Qiyue Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.06283"
  },
  {
    "id": "arXiv:2204.06389",
    "title": "CRUSH: Contextually Regularized and User anchored Self-supervised Hate  speech Detection",
    "abstract": "Comments: Accepted in NAACL HLT 2022 (Long Paper)",
    "descriptor": "\nComments: Accepted in NAACL HLT 2022 (Long Paper)\n",
    "authors": [
      "Souvic Chakraborty",
      "Parag Dutta",
      "Sumegh Roychowdhury",
      "Animesh Mukherjee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2204.06389"
  },
  {
    "id": "arXiv:2204.06676",
    "title": "DRAGON : A suite of Hardware Simulation and Optimization tools for  Modern Workloads",
    "abstract": "DRAGON : A suite of Hardware Simulation and Optimization tools for  Modern Workloads",
    "descriptor": "",
    "authors": [
      "Khushal Sethi"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2204.06676"
  },
  {
    "id": "arXiv:2204.06885",
    "title": "Shedding New Light on the Language of the Dark Web",
    "abstract": "Comments: To appear at NAACL 2022 (main conference)",
    "descriptor": "\nComments: To appear at NAACL 2022 (main conference)\n",
    "authors": [
      "Youngjin Jin",
      "Eugene Jang",
      "Yongjae Lee",
      "Seungwon Shin",
      "Jin-Woo Chung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.06885"
  },
  {
    "id": "arXiv:2204.07075",
    "title": "Learning and controlling the source-filter representation of speech with  a variational autoencoder",
    "abstract": "Comments: 17 pages, 4 figures, companion website: this https URL",
    "descriptor": "\nComments: 17 pages, 4 figures, companion website: this https URL\n",
    "authors": [
      "Samir Sadok",
      "Simon Leglaive",
      "Laurent Girin",
      "Xavier Alameda-Pineda",
      "Renaud S\u00e9guier"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.07075"
  },
  {
    "id": "arXiv:2204.07261",
    "title": "Convergence and Implicit Regularization Properties of Gradient Descent  for Deep Residual Networks",
    "abstract": "Convergence and Implicit Regularization Properties of Gradient Descent  for Deep Residual Networks",
    "descriptor": "",
    "authors": [
      "Rama Cont",
      "Alain Rossier",
      "RenYuan Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.07261"
  },
  {
    "id": "arXiv:2204.07356",
    "title": "Vision-and-Language Pretrained Models: A Survey",
    "abstract": "Comments: Accepted in IJCAI 2022",
    "descriptor": "\nComments: Accepted in IJCAI 2022\n",
    "authors": [
      "Siqu Long",
      "Feiqi Cao",
      "Soyeon Caren Han",
      "Haiqin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07356"
  },
  {
    "id": "arXiv:2204.08269",
    "title": "Differentiable Time-Frequency Scattering in Kymatio",
    "abstract": "Comments: 8 pages, 6 figures. Submitted to the International Conference on Digital Audio Effects (DAFX) 2022",
    "descriptor": "\nComments: 8 pages, 6 figures. Submitted to the International Conference on Digital Audio Effects (DAFX) 2022\n",
    "authors": [
      "John Muradeli",
      "Cyrus Vahidi",
      "Changhong Wang",
      "Han Han",
      "Vincent Lostanlen",
      "Mathieu Lagrange",
      "George Fazekas"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.08269"
  },
  {
    "id": "arXiv:2204.08816",
    "title": "Radio Galaxy Zoo: Using semi-supervised learning to leverage large  unlabelled data-sets for radio galaxy classification under data-set shift",
    "abstract": "Comments: Accepted to MNRAS. 14 pages",
    "descriptor": "\nComments: Accepted to MNRAS. 14 pages\n",
    "authors": [
      "Inigo V. Slijepcevic",
      "Anna M. M. Scaife",
      "Mike Walmsley",
      "Micah Bowles",
      "Ivy Wong",
      "Stanislav S. Shabala",
      "Hongming Tang"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.08816"
  },
  {
    "id": "arXiv:2204.09042",
    "title": "Accelerating Inhibitor Discovery for Multiple SARS-CoV-2 Targets with a  Single, Sequence-Guided Deep Generative Framework",
    "abstract": "Comments: Fixed dates, added data availability, minor changes",
    "descriptor": "\nComments: Fixed dates, added data availability, minor changes\n",
    "authors": [
      "Vijil Chenthamarakshan",
      "Samuel C. Hoffman",
      "C. David Owen",
      "Petra Lukacik",
      "Claire Strain-Damerell",
      "Daren Fearon",
      "Tika R. Malla",
      "Anthony Tumber",
      "Christopher J. Schofield",
      "Helen M.E. Duyvesteyn",
      "Wanwisa Dejnirattisai",
      "Loic Carrique",
      "Thomas S. Walter",
      "Gavin R. Screaton",
      "Tetiana Matviiuk",
      "Aleksandra Mojsilovic",
      "Jason Crain",
      "Martin A. Walsh",
      "David I. Stuart",
      "Payel Das"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.09042"
  },
  {
    "id": "arXiv:2204.09105",
    "title": "An improved central limit theorem and fast convergence rates for  entropic transportation costs",
    "abstract": "An improved central limit theorem and fast convergence rates for  entropic transportation costs",
    "descriptor": "",
    "authors": [
      "Eustasio del Barrio",
      "Alberto Gonzalez-Sanz",
      "Jean-Michel Loubes",
      "Jonathan Niles-Weed"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2204.09105"
  },
  {
    "id": "arXiv:2204.09560",
    "title": "Understanding and Preventing Capacity Loss in Reinforcement Learning",
    "abstract": "Comments: Presented at ICLR 2022",
    "descriptor": "\nComments: Presented at ICLR 2022\n",
    "authors": [
      "Clare Lyle",
      "Mark Rowland",
      "Will Dabney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.09560"
  },
  {
    "id": "arXiv:2204.09805",
    "title": "fairDMS: Rapid Model Training by Data and Model Reuse",
    "abstract": "fairDMS: Rapid Model Training by Data and Model Reuse",
    "descriptor": "",
    "authors": [
      "Ahsan Ali",
      "Hemant Sharma",
      "Rajkumar Kettimuthu",
      "Peter Kenesei",
      "Dennis Trujillo",
      "Antonino Miceli",
      "Ian Foster",
      "Ryan Coffee",
      "Jana Thayer",
      "Zhengchun Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.09805"
  },
  {
    "id": "arXiv:2204.10310",
    "title": "Share With Thy Neighbors: Single-View Reconstruction by Cross-Instance  Consistency",
    "abstract": "Comments: Project webpage with code and videos: this http URL",
    "descriptor": "\nComments: Project webpage with code and videos: this http URL\n",
    "authors": [
      "Tom Monnier",
      "Matthew Fisher",
      "Alexei A. Efros",
      "Mathieu Aubry"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2204.10310"
  },
  {
    "id": "arXiv:2204.10477",
    "title": "Learning Dynamic View Synthesis With Few RGBD Cameras",
    "abstract": "Comments: One of the coauthors believes that this work should be improved more before releasing it on arXiv, and thus suggested withdrawing this paper. There will not be a replacement for this paper",
    "descriptor": "\nComments: One of the coauthors believes that this work should be improved more before releasing it on arXiv, and thus suggested withdrawing this paper. There will not be a replacement for this paper\n",
    "authors": [
      "Shengze Wang",
      "YoungJoong Kwon",
      "Yuan Shen",
      "Qian Zhang",
      "Andrei State",
      "Jia-Bin Huang",
      "Henry Fuchs"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2204.10477"
  },
  {
    "id": "arXiv:2204.10479",
    "title": "Analysis of Temporal Difference Learning: Linear System Approach",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2112.14417",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2112.14417\n",
    "authors": [
      "Donghwan Lee",
      "Do Wan Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.10479"
  },
  {
    "id": "arXiv:2204.10756",
    "title": "Reference Vector Adaptation and Mating Selection Strategy via Adaptive  Resonance Theory-based Clustering for Many-objective Optimization",
    "abstract": "Comments: This paper is currently under review",
    "descriptor": "\nComments: This paper is currently under review\n",
    "authors": [
      "Takato Kinoshita",
      "Naoki Masuyama",
      "Yiping Liu",
      "Yusuke Nojima",
      "Hisao Ishibuchi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.10756"
  },
  {
    "id": "arXiv:2204.10851",
    "title": "Exploiting Session Information in BERT-based Session-aware Sequential  Recommendation",
    "abstract": "Comments: 6 pages, accepted in The 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR) 2022, short paper",
    "descriptor": "\nComments: 6 pages, accepted in The 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR) 2022, short paper\n",
    "authors": [
      "Jinseok Seol",
      "Youngrok Ko",
      "Sang-goo Lee"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.10851"
  },
  {
    "id": "arXiv:2204.10994",
    "title": "MuCGEC: a Multi-Reference Multi-Source Evaluation Dataset for Chinese  Grammatical Error Correction",
    "abstract": "Comments: Accepted by NAACL2022 (main conference)",
    "descriptor": "\nComments: Accepted by NAACL2022 (main conference)\n",
    "authors": [
      "Yue Zhang",
      "Zhenghua Li",
      "Zuyi Bao",
      "Jiacheng Li",
      "Bo Zhang",
      "Chen Li",
      "Fei Huang",
      "Min Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.10994"
  },
  {
    "id": "arXiv:2204.11467",
    "title": "Local Hypergraph-based Nested Named Entity Recognition as Query-based  Sequence Labeling",
    "abstract": "Local Hypergraph-based Nested Named Entity Recognition as Query-based  Sequence Labeling",
    "descriptor": "",
    "authors": [
      "Yukun Yan",
      "Sen Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.11467"
  },
  {
    "id": "arXiv:2204.11790",
    "title": "Can Rationalization Improve Robustness?",
    "abstract": "Comments: Accepted to NAACL 2022; The code is available at this https URL",
    "descriptor": "\nComments: Accepted to NAACL 2022; The code is available at this https URL\n",
    "authors": [
      "Howard Chen",
      "Jacqueline He",
      "Karthik Narasimhan",
      "Danqi Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.11790"
  },
  {
    "id": "arXiv:2204.12063",
    "title": "A Review-aware Graph Contrastive Learning Framework for Recommendation",
    "abstract": "Comments: Accepted by SIGIR 2022",
    "descriptor": "\nComments: Accepted by SIGIR 2022\n",
    "authors": [
      "Jie Shuai",
      "Kun Zhang",
      "Le Wu",
      "Peijie Sun",
      "Richang Hong",
      "Meng Wang",
      "Yong Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.12063"
  },
  {
    "id": "arXiv:2204.13324",
    "title": "Controllable Image Captioning",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:1908.11782, arXiv:2107.14178 by other authors",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1908.11782, arXiv:2107.14178 by other authors\n",
    "authors": [
      "Luka Maxwell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.13324"
  },
  {
    "id": "arXiv:2204.13385",
    "title": "Fuzzy Expert System for Stock Portfolio Selection: An Application to  Bombay Stock Exchange",
    "abstract": "Fuzzy Expert System for Stock Portfolio Selection: An Application to  Bombay Stock Exchange",
    "descriptor": "",
    "authors": [
      "Gour Sundar Mitra Thakur",
      "Rupak Bhattacharyya",
      "Seema Sarkar"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Computational Finance (q-fin.CP)"
    ],
    "url": "https://arxiv.org/abs/2204.13385"
  },
  {
    "id": "arXiv:2204.13955",
    "title": "A Directional Vibrotactile Feedback Interface for Ergonomic Postural  Adjustment",
    "abstract": "Comments: 12 pages. 13 figures. Now published in IEEE Transactions on Haptics DOI: 10.1109/TOH.2021.3112795",
    "descriptor": "\nComments: 12 pages. 13 figures. Now published in IEEE Transactions on Haptics DOI: 10.1109/TOH.2021.3112795\n",
    "authors": [
      "Wansoo Kim",
      "Virginia Ruiz Garate",
      "Juan M. Gandarias",
      "Marta Lorenzini",
      "Arash Ajoudani"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.13955"
  },
  {
    "id": "arXiv:2204.14166",
    "title": "OPERA:Operation-Pivoted Discrete Reasoning over Text",
    "abstract": "Comments: Accepted to NAACL 2022",
    "descriptor": "\nComments: Accepted to NAACL 2022\n",
    "authors": [
      "Yongwei Zhou",
      "Junwei Bao",
      "Chaoqun Duan",
      "Haipeng Sun",
      "Jiahui Liang",
      "Yifan Wang",
      "Jing Zhao",
      "Youzheng Wu",
      "Xiaodong He",
      "Tiejun Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.14166"
  },
  {
    "id": "arXiv:2204.14243",
    "title": "Training Naturalized Semantic Parsers with Very Little Data",
    "abstract": "Comments: IJCAI 2022",
    "descriptor": "\nComments: IJCAI 2022\n",
    "authors": [
      "Subendhu Rongali",
      "Konstantine Arkoudas",
      "Melanie Rubino",
      "Wael Hamza"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.14243"
  },
  {
    "id": "arXiv:2205.00001",
    "title": "Brainish: Formalizing A Multimodal Language for Intelligence and  Consciousness",
    "abstract": "Brainish: Formalizing A Multimodal Language for Intelligence and  Consciousness",
    "descriptor": "",
    "authors": [
      "Paul Pu Liang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.00001"
  },
  {
    "id": "arXiv:2205.00034",
    "title": "What do we Really Know about State of the Art NER?",
    "abstract": "Comments: LREC 2022",
    "descriptor": "\nComments: LREC 2022\n",
    "authors": [
      "Sowmya Vajjala",
      "Ramya Balasubramaniam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.00034"
  },
  {
    "id": "arXiv:2205.00119",
    "title": "MiCS: Near-linear Scaling for Training Gigantic Model on Public Cloud",
    "abstract": "MiCS: Near-linear Scaling for Training Gigantic Model on Public Cloud",
    "descriptor": "",
    "authors": [
      "Zhen Zhang",
      "Shuai Zheng",
      "Yida Wang",
      "Justin Chiu",
      "George Karypis",
      "Trishul Chilimbi",
      "Mu Li",
      "Xin Jin"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.00119"
  },
  {
    "id": "arXiv:2205.00429",
    "title": "Closed-form max-min power control for some cellular and cell-free  massive MIMO networks",
    "abstract": "Closed-form max-min power control for some cellular and cell-free  massive MIMO networks",
    "descriptor": "",
    "authors": [
      "Lorenzo Miretti",
      "Renato L. G. Cavalcante",
      "Slawomir Stanczak",
      "Martin Schubert",
      "Ronald Boehnke",
      "Wen Xu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.00429"
  },
  {
    "id": "arXiv:2205.00534",
    "title": "Generalized Reference Kernel for One-class Classification",
    "abstract": "Generalized Reference Kernel for One-class Classification",
    "descriptor": "",
    "authors": [
      "Jenni Raitoharju",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.00534"
  },
  {
    "id": "arXiv:2205.00551",
    "title": "Gender Bias in Masked Language Models for Multiple Languages",
    "abstract": "Comments: NAACL 2022",
    "descriptor": "\nComments: NAACL 2022\n",
    "authors": [
      "Masahiro Kaneko",
      "Aizhan Imankulova",
      "Danushka Bollegala",
      "Naoaki Okazaki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.00551"
  },
  {
    "id": "arXiv:2205.00617",
    "title": "A high-order deferred correction method for the solution of free  boundary problems using penalty iteration, with an application to American  option pricing",
    "abstract": "Comments: 40 pages",
    "descriptor": "\nComments: 40 pages\n",
    "authors": [
      "Dawei Wang",
      "Kirill Serkh",
      "Christina christara"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2205.00617"
  },
  {
    "id": "arXiv:2205.00629",
    "title": "Re-defining Radiology Quality Assurance (QA) -- Artificial Intelligence  (AI)-Based QA by Restricted Investigation of Unequal Scores (AQUARIUS)",
    "abstract": "Comments: 9 pages, conference",
    "descriptor": "\nComments: 9 pages, conference\n",
    "authors": [
      "Axel Wismueller",
      "Larry Stockmaster",
      "Ali Vosoughi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.00629"
  },
  {
    "id": "arXiv:2205.00692",
    "title": "Energy-efficient Caching and Task offloading for Timely Status Updates  in UAV-assisted VANETs",
    "abstract": "Energy-efficient Caching and Task offloading for Timely Status Updates  in UAV-assisted VANETs",
    "descriptor": "",
    "authors": [
      "Nan Hu",
      "Xiaoqi Qin",
      "Nan Ma",
      "Yiming Liu",
      "Yuanyuan Yao",
      "Ping Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.00692"
  },
  {
    "id": "arXiv:2205.00718",
    "title": "What a Publication Tells You -- Benefits of Narrative Information Access  in Digital Libraries",
    "abstract": "Comments: Accepted at JCDL2022, 8 pages, 1 figure",
    "descriptor": "\nComments: Accepted at JCDL2022, 8 pages, 1 figure\n",
    "authors": [
      "Hermann Kroll",
      "Florian Pl\u00f6tzky",
      "Jan Pirklbauer",
      "Wolf-Tilo Balke"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2205.00718"
  },
  {
    "id": "arXiv:2205.00748",
    "title": "Dual networks based 3D Multi-Person Pose Estimation from Monocular Video",
    "abstract": "Comments: Accepted by TPAMI 2022. arXiv admin note: substantial text overlap with arXiv:2104.01797",
    "descriptor": "\nComments: Accepted by TPAMI 2022. arXiv admin note: substantial text overlap with arXiv:2104.01797\n",
    "authors": [
      "Yu Cheng",
      "Bo Wang",
      "Robby T. Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.00748"
  },
  {
    "id": "arXiv:2205.00756",
    "title": "VICE: Variational Inference for Concept Embeddings",
    "abstract": "VICE: Variational Inference for Concept Embeddings",
    "descriptor": "",
    "authors": [
      "Lukas Muttenthaler",
      "Charles Y. Zheng",
      "Patrick McClure",
      "Robert A. Vandermeulen",
      "Martin N. Hebart",
      "Francisco Pereira"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.00756"
  },
  {
    "id": "arXiv:2205.00872",
    "title": "COSPLAY: Concept Set Guided Personalized Dialogue Generation Across Both  Party Personas",
    "abstract": "Comments: Accepted by SIGIR 2022 as full paper, 11 pages, 9 figures",
    "descriptor": "\nComments: Accepted by SIGIR 2022 as full paper, 11 pages, 9 figures\n",
    "authors": [
      "Chen Xu",
      "Piji Li",
      "Wei Wang",
      "Haoran Yang",
      "Siyun Wang",
      "Chuangbai Xiao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.00872"
  },
  {
    "id": "arXiv:2205.00932",
    "title": "Understanding CNNs from excitations",
    "abstract": "Understanding CNNs from excitations",
    "descriptor": "",
    "authors": [
      "Zijian Ying",
      "Qianmu Li",
      "Zhichao Lian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.00932"
  },
  {
    "id": "arXiv:2205.01017",
    "title": "Flood Risk Mitigation and Valve Control in Stormwater Systems:  State-Space Modeling, Control Algorithms, and Case Studies",
    "abstract": "Flood Risk Mitigation and Valve Control in Stormwater Systems:  State-Space Modeling, Control Algorithms, and Case Studies",
    "descriptor": "",
    "authors": [
      "Marcus N. Gomes Junior",
      "Marcio H. Giacomoni",
      "Ahmad F. Taha",
      "Eduardo M. Mendiondo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.01017"
  },
  {
    "id": "arXiv:2205.01038",
    "title": "Demographic-Reliant Algorithmic Fairness: Characterizing the Risks of  Demographic Data Collection in the Pursuit of Fairness",
    "abstract": "Comments: 21 pages, accepted to FAccT 2022. Updated to camera ready version: added a section defining how we use demographic data, clarified distinction between sections 5.2 and 6.2, additional line edits",
    "descriptor": "\nComments: 21 pages, accepted to FAccT 2022. Updated to camera ready version: added a section defining how we use demographic data, clarified distinction between sections 5.2 and 6.2, additional line edits\n",
    "authors": [
      "McKane Andrus",
      "Sarah Villeneuve"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01038"
  },
  {
    "id": "arXiv:2205.01296",
    "title": "Visual Knowledge Discovery with Artificial Intelligence: Challenges and  Future Directions",
    "abstract": "Visual Knowledge Discovery with Artificial Intelligence: Challenges and  Future Directions",
    "descriptor": "",
    "authors": [
      "Boris Kovalerchuk",
      "R\u0103zvan Andonie",
      "Nuno Datia",
      "Kawa Nazemi",
      "Ebad Banissi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01296"
  },
  {
    "id": "arXiv:2205.01316",
    "title": "HL-Net: Heterophily Learning Network for Scene Graph Generation",
    "abstract": "Comments: Accepted to CVPR 2022",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Xin Lin",
      "Changxing Ding",
      "Yibing Zhan",
      "Zijian Li",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01316"
  },
  {
    "id": "arXiv:2205.01362",
    "title": "TracInAD: Measuring Influence for Anomaly Detection",
    "abstract": "TracInAD: Measuring Influence for Anomaly Detection",
    "descriptor": "",
    "authors": [
      "Hugo Thimonier",
      "Fabrice Popineau",
      "Arpad Rimmel",
      "Bich-Li\u00ean Doan",
      "Fabrice Daniel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01362"
  },
  {
    "id": "arXiv:2205.01366",
    "title": "Finding patterns in Knowledge Attribution for Transformers",
    "abstract": "Comments: Remove unnecessary files; Correct Typos;",
    "descriptor": "\nComments: Remove unnecessary files; Correct Typos;\n",
    "authors": [
      "Jeevesh Juneja",
      "Ritu Agarwal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01366"
  },
  {
    "id": "arXiv:2205.01392",
    "title": "A Unified Framework for Verification of Observational Properties for  Partially-Observed Discrete-Event Systems",
    "abstract": "A Unified Framework for Verification of Observational Properties for  Partially-Observed Discrete-Event Systems",
    "descriptor": "",
    "authors": [
      "Jianing Zhao",
      "Xiang Yin",
      "Shaoyuan Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.01392"
  },
  {
    "id": "arXiv:2205.01398",
    "title": "Neural language models for network configuration: Opportunities and  reality check",
    "abstract": "Neural language models for network configuration: Opportunities and  reality check",
    "descriptor": "",
    "authors": [
      "Zied Ben Houidi",
      "Dario Rossi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.01398"
  },
  {
    "id": "arXiv:2205.01416",
    "title": "Exact Paired-Permutation Testing for Structured Test Statistics",
    "abstract": "Exact Paired-Permutation Testing for Structured Test Statistics",
    "descriptor": "",
    "authors": [
      "Ran Zmigrod",
      "Tim Vieira",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01416"
  },
  {
    "id": "arXiv:2205.01488",
    "title": "On the stability of strong-stability-preserving modified Patankar  Runge-Kutta schemes",
    "abstract": "Comments: 23 pages, 10 figures",
    "descriptor": "\nComments: 23 pages, 10 figures\n",
    "authors": [
      "Juntao Huang",
      "Thomas Izgin",
      "Stefan Kopecz",
      "Andreas Meister",
      "Chi-Wang Shu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.01488"
  },
  {
    "id": "arXiv:2205.01527",
    "title": "Extended Abstract: Productive Parallel Programming with Parsl",
    "abstract": "Extended Abstract: Productive Parallel Programming with Parsl",
    "descriptor": "",
    "authors": [
      "Kyle Chard",
      "Yadu Babuji",
      "Anna Woodard",
      "Ben Clifford",
      "Zhuozhao Li",
      "Mihael Hategan",
      "Ian Foster",
      "Mike Wilde",
      "Daniel S. Katz"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.01527"
  },
  {
    "id": "arXiv:2205.01550",
    "title": "Point Cloud Semantic Segmentation using Multi Scale Sparse Convolution  Neural Network",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2202.10047, arXiv:2102.04530 by other authors",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2202.10047, arXiv:2102.04530 by other authors\n",
    "authors": [
      "Yunzheng Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.01550"
  },
  {
    "id": "arXiv:2205.01624",
    "title": "Practical Saccade Prediction for Head-Mounted Displays: Towards a  Comprehensive Model",
    "abstract": "Practical Saccade Prediction for Head-Mounted Displays: Towards a  Comprehensive Model",
    "descriptor": "",
    "authors": [
      "Elena Arabadzhiyska",
      "Cara Tursun",
      "Hans-Peter Seidel",
      "Piotr Didyk"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2205.01624"
  },
  {
    "id": "arXiv:2205.01647",
    "title": "Intelligent Trajectory Design for RIS-NOMA aided Multi-robot  Communications",
    "abstract": "Comments: Some authors won't publish this at this time",
    "descriptor": "\nComments: Some authors won't publish this at this time\n",
    "authors": [
      "Xinyu Gao",
      "Xidong Mu",
      "Wenqiang Yi",
      "Yuanwei Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.01647"
  },
  {
    "id": "arXiv:2205.01663",
    "title": "Adversarial Training for High-Stakes Reliability",
    "abstract": "Comments: 31 pages, 6 figures, small tweak",
    "descriptor": "\nComments: 31 pages, 6 figures, small tweak\n",
    "authors": [
      "Daniel M. Ziegler",
      "Seraphina Nix",
      "Lawrence Chan",
      "Tim Bauman",
      "Peter Schmidt-Nielsen",
      "Tao Lin",
      "Adam Scherlis",
      "Noa Nabeshima",
      "Ben Weinstein-Raun",
      "Daniel de Haas",
      "Buck Shlegeris",
      "Nate Thomas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01663"
  }
]
[
  {
    "id": "arXiv:2205.09115",
    "title": "AutoQML: Automated Quantum Machine Learning for Wi-Fi Integrated Sensing  and Communications",
    "abstract": "Commercial Wi-Fi devices can be used for integrated sensing and\ncommunications (ISAC) to jointly exchange data and monitor indoor environment.\nIn this paper, we investigate a proof-of-concept approach using automated\nquantum machine learning (AutoQML) framework called AutoAnsatz to recognize\nhuman gesture. We address how to efficiently design quantum circuits to\nconfigure quantum neural networks (QNN). The effectiveness of AutoQML is\nvalidated by an in-house experiment for human pose recognition, achieving\nstate-of-the-art performance greater than 80% accuracy for a limited data size\nwith a significantly small number of trainable parameters.",
    "descriptor": "\nComments: 5 pages, 9 figures, IEEE SAM 2022. arXiv admin note: text overlap with arXiv:2205.08590\n",
    "authors": [
      "Toshiaki Koike-Akino",
      "Pu Wang",
      "Ye Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.09115"
  },
  {
    "id": "arXiv:2205.09117",
    "title": "Neighborhood Mixup Experience Replay: Local Convex Interpolation for  Improved Sample Efficiency in Continuous Control Tasks",
    "abstract": "Experience replay plays a crucial role in improving the sample efficiency of\ndeep reinforcement learning agents. Recent advances in experience replay\npropose using Mixup (Zhang et al., 2018) to further improve sample efficiency\nvia synthetic sample generation. We build upon this technique with Neighborhood\nMixup Experience Replay (NMER), a geometrically-grounded replay buffer that\ninterpolates transitions with their closest neighbors in state-action space.\nNMER preserves a locally linear approximation of the transition manifold by\nonly applying Mixup between transitions with vicinal state-action features.\nUnder NMER, a given transition's set of state action neighbors is dynamic and\nepisode agnostic, in turn encouraging greater policy generalizability via\ninter-episode interpolation. We combine our approach with recent off-policy\ndeep reinforcement learning algorithms and evaluate on continuous control\nenvironments. We observe that NMER improves sample efficiency by an average 94%\n(TD3) and 29% (SAC) over baseline replay buffers, enabling agents to\neffectively recombine previous experiences and learn from limited data.",
    "descriptor": "\nComments: Accepted to L4DC 2022\n",
    "authors": [
      "Ryan Sander",
      "Wilko Schwarting",
      "Tim Seyde",
      "Igor Gilitschenski",
      "Sertac Karaman",
      "Daniela Rus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.09117"
  },
  {
    "id": "arXiv:2205.09120",
    "title": "Fast matrix multiplication for binary and ternary CNNs on ARM CPU",
    "abstract": "Low-bit quantized neural networks are of great interest in practical\napplications because they significantly reduce the consumption of both memory\nand computational resources. Binary neural networks are memory and\ncomputationally efficient as they require only one bit per weight and\nactivation and can be computed using Boolean logic and bit count operations.\nQNNs with ternary weights and activations and binary weights and ternary\nactivations aim to improve recognition quality compared to BNNs while\npreserving low bit-width. However, their efficient implementation is usually\nconsidered on ASICs and FPGAs, limiting their applicability in real-life tasks.\nAt the same time, one of the areas where efficient recognition is most in\ndemand is recognition on mobile devices using their CPUs. However, there are no\nknown fast implementations of TBNs and TNN, only the daBNN library for BNNs\ninference. In this paper, we propose novel fast algorithms of ternary,\nternary-binary, and binary matrix multiplication for mobile devices with ARM\narchitecture. In our algorithms, ternary weights are represented using 2-bit\nencoding and binary - using one bit. It allows us to replace matrix\nmultiplication with Boolean logic operations that can be computed on 128-bits\nsimultaneously, using ARM NEON SIMD extension. The matrix multiplication\nresults are accumulated in 16-bit integer registers. We also use special\nreordering of values in left and right matrices. All that allows us to\nefficiently compute a matrix product while minimizing the number of loads and\nstores compared to the algorithm from daBNN. Our algorithms can be used to\nimplement inference of convolutional and fully connected layers of TNNs, TBNs,\nand BNNs. We evaluate them experimentally on ARM Cortex-A73 CPU and compare\ntheir inference speed to efficient implementations of full-precision, 8-bit,\nand 4-bit quantized matrix multiplications.",
    "descriptor": "\nComments: Accepted to 26th International Conference on Pattern Recognition (ICPR 2022)\n",
    "authors": [
      "Anton Trusov",
      "Elena Limonova",
      "Dmitry Nikolaev",
      "Vladimir V. Arlazarov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09120"
  },
  {
    "id": "arXiv:2205.09121",
    "title": "On the efficiency of Stochastic Quasi-Newton Methods for Deep Learning",
    "abstract": "While first-order methods are popular for solving optimization problems that\narise in large-scale deep learning problems, they come with some acute\ndeficiencies. To diminish such shortcomings, there has been recent interest in\napplying second-order methods such as quasi-Newton based methods which\nconstruct Hessians approximations using only gradient information. The main\nfocus of our work is to study the behaviour of stochastic quasi-Newton\nalgorithms for training deep neural networks. We have analyzed the performance\nof two well-known quasi-Newton updates, the limited memory\nBroyden-Fletcher-Goldfarb-Shanno (BFGS) and the Symmetric Rank One (SR1). This\nstudy fills a gap concerning the real performance of both updates and analyzes\nwhether more efficient training is obtained when using the more robust BFGS\nupdate or the cheaper SR1 formula which allows for indefinite Hessian\napproximations and thus can potentially help to better navigate the\npathological saddle points present in the non-convex loss functions found in\ndeep learning. We present and discuss the results of an extensive experimental\nstudy which includes the effect of batch normalization and network's\narchitecture, the limited memory parameter, the batch size and the type of\nsampling strategy. we show that stochastic quasi-Newton optimizers are\nefficient and able to outperform in some instances the well-known first-order\nAdam optimizer run with the optimal combination of its numerous\nhyperparameters.",
    "descriptor": "",
    "authors": [
      "Mahsa Yousefi",
      "Angeles Martinez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.09121"
  },
  {
    "id": "arXiv:2205.09123",
    "title": "A2C is a special case of PPO",
    "abstract": "Advantage Actor-critic (A2C) and Proximal Policy Optimization (PPO) are\npopular deep reinforcement learning algorithms used for game AI in recent\nyears. A common understanding is that A2C and PPO are separate algorithms\nbecause PPO's clipped objective appears significantly different than A2C's\nobjective. In this paper, however, we show A2C is a special case of PPO. We\npresent theoretical justifications and pseudocode analysis to demonstrate why.\nTo validate our claim, we conduct an empirical experiment using\n\\texttt{Stable-baselines3}, showing A2C and PPO produce the \\textit{exact} same\nmodels when other settings are controlled.",
    "descriptor": "",
    "authors": [
      "Shengyi Huang",
      "Anssi Kanervisto",
      "Antonin Raffin",
      "Weixun Wang",
      "Santiago Onta\u00f1\u00f3n",
      "Rousslan Fernand Julien Dossa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09123"
  },
  {
    "id": "arXiv:2205.09140",
    "title": "Relational representation learning with spike trains",
    "abstract": "Relational representation learning has lately received an increase in\ninterest due to its flexibility in modeling a variety of systems like\ninteracting particles, materials and industrial projects for, e.g., the design\nof spacecraft. A prominent method for dealing with relational data are\nknowledge graph embedding algorithms, where entities and relations of a\nknowledge graph are mapped to a low-dimensional vector space while preserving\nits semantic structure. Recently, a graph embedding method has been proposed\nthat maps graph elements to the temporal domain of spiking neural networks.\nHowever, it relies on encoding graph elements through populations of neurons\nthat only spike once. Here, we present a model that allows us to learn spike\ntrain-based embeddings of knowledge graphs, requiring only one neuron per graph\nelement by fully utilizing the temporal domain of spike patterns. This coding\nscheme can be implemented with arbitrary spiking neuron models as long as\ngradients with respect to spike times can be calculated, which we demonstrate\nfor the integrate-and-fire neuron model. In general, the presented results show\nhow relational knowledge can be integrated into spike-based systems, opening up\nthe possibility of merging event-based computing and relational data to build\npowerful and energy efficient artificial intelligence applications and\nreasoning systems.",
    "descriptor": "\nComments: Accepted for publication at the WCCI 2022 (IJCNN)\n",
    "authors": [
      "Dominik Dold"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2205.09140"
  },
  {
    "id": "arXiv:2205.09148",
    "title": "DDXPlus: A new Dataset for Medical Automatic Diagnosis",
    "abstract": "There has been rapidly growing interests in Automatic Diagnosis (AD) and\nAutomatic Symptom Detection (ASD) systems in the machine learning research\nliterature, aiming to assist doctors in telemedicine services. These systems\nare designed to interact with patients, collect evidence relevant to their\nconcerns, and make predictions about the underlying diseases. Doctors would\nreview the interaction, including the evidence and the predictions, before\nmaking their final decisions. Despite the recent progress, an important piece\nof doctors' interactions with patients is missing in the design of AD and ASD\nsystems, namely the differential diagnosis. Its absence is largely due to the\nlack of datasets that include such information for models to train on. In this\nwork, we present a large-scale synthetic dataset that includes a differential\ndiagnosis, along with the ground truth pathology, for each patient. In\naddition, this dataset includes more pathologies, as well as types of symtoms\nand antecedents. As a proof-of-concept, we extend several existing AD and ASD\nsystems to incorporate differential diagnosis, and provide empirical evidence\nthat using differentials in training signals is essential for such systems to\nlearn to predict differentials. Dataset available at\nhttps://github.com/bruzwen/ddxplus",
    "descriptor": "",
    "authors": [
      "Arsene Fansi Tchango",
      "Zhi Wen",
      "Rishab Goel",
      "Joumana Ghosn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09148"
  },
  {
    "id": "arXiv:2205.09151",
    "title": "An Approach to Investigate Public Opinion, Views, and Perspectives  Towards Exoskeleton Technology",
    "abstract": "Over the last decade, exoskeletons have had an extensive impact on different\ndisciplines and application domains such as assisted living, military,\nhealthcare, firefighting, and industries, on account of their diverse and\ndynamic functionalities to augment human abilities, stamina, potential, and\nperformance in a multitude of ways. In view of this wide-scale applicability\nand use-cases of exoskeletons, it is crucial to investigate and analyze the\npublic opinion, views, and perspectives towards exoskeletons which would help\nto interpret the effectiveness of the underlining human-robot, human-machine,\nand human-technology interactions. The Internet of Everything era of today's\nliving, characterized by people spending more time on the internet than ever\nbefore, holds the potential for the investigation of the same by mining and\nanalyzing relevant web behavior, specifically from social media, that can be\ninterpreted to understand public opinion, views, and perspectives towards a\ntopic or set of topics. Therefore, this paper aims to address this research\nchallenge related to exoskeletons by utilizing the potential of web\nbehavior-based Big Data mining in the modern-day Internet of Everything era. As\nTwitter is one of the most popular social media platforms on a global scale -\ncharacterized by both the number of users and the amount of time spent by its\nusers on the platform - this work focused on investigating web behavior on\nTwitter to interpret the public opinion, views, and perspectives towards\nexoskeleton technology. A total of approximately 20,000 tweets related to\nexoskeletons were used to evaluate the effectiveness of the proposed approach.\nThe results presented and discussed uphold the efficacy of the proposed\napproach to interpret and analyze the public opinion, views, and perspectives\ntowards exoskeletons from the associated tweets.",
    "descriptor": "\nComments: Proceedings of the 7th International Conference on Human Interaction & Emerging Technologies: Artificial Intelligence & Future Applications (IHIET-AI 2022), Lausanne, Switzerland, April 21-23, 2022\n",
    "authors": [
      "Nirmalya Thakur",
      "Cat Luong",
      "Chia Y. Han"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.09151"
  },
  {
    "id": "arXiv:2205.09153",
    "title": "ERNIE-Search: Bridging Cross-Encoder with Dual-Encoder via Self  On-the-fly Distillation for Dense Passage Retrieval",
    "abstract": "Neural retrievers based on pre-trained language models (PLMs), such as\ndual-encoders, have achieved promising performance on the task of open-domain\nquestion answering (QA). Their effectiveness can further reach new\nstate-of-the-arts by incorporating cross-architecture knowledge distillation.\nHowever, most of the existing studies just directly apply conventional\ndistillation methods. They fail to consider the particular situation where the\nteacher and student have different structures. In this paper, we propose a\nnovel distillation method that significantly advances cross-architecture\ndistillation for dual-encoders. Our method 1) introduces a self on-the-fly\ndistillation method that can effectively distill late interaction (i.e.,\nColBERT) to vanilla dual-encoder, and 2) incorporates a cascade distillation\nprocess to further improve the performance with a cross-encoder teacher.\nExtensive experiments are conducted to validate that our proposed solution\noutperforms strong baselines and establish a new state-of-the-art on\nopen-domain QA benchmarks.",
    "descriptor": "",
    "authors": [
      "Yuxiang Lu",
      "Yiding Liu",
      "Jiaxiang Liu",
      "Yunsheng Shi",
      "Zhengjie Huang",
      "Shikun Feng Yu Sun",
      "Hao Tian",
      "Hua Wu",
      "Shuaiqiang Wang",
      "Dawei Yin",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09153"
  },
  {
    "id": "arXiv:2205.09163",
    "title": "Fast Mapping of Flexibility Regions at TSO-DSO Interfaces under  Uncertainty",
    "abstract": "The gradual decommissioning of fossil fuel-driven power plants, that\ntraditionally provide most operational flexibility in power systems, has led to\nmore frequent grid stability issues. To compensate for the lack of flexible\nresources, Distributed Energy Resources (DERs) in distribution networks can be\nemployed. To facilitate the use of DERs, the aggregated flexibility in a\ndistribution grid is commonly represented on a $PQ$-plane displaying the\nfeasible active and reactive power exchange with the upstream grid. This paper\nproposes a fast feasible operating region mapping mechanism that utilizes a\nlinear power flow approximation in combination with linearized generator,\ncurrent, and voltage constraints to construct a high-dimensional polyhedral\nfeasible set of DER power injections. The obtained polytope is projected onto\nthe $PQ$-plane using Fourier-Motzkin Elimination to represent the aggregate\nnetwork flexibility. Additionally, uncertainty in DER generation is addressed\nusing chance-constraints. Our analysis of a modified 33-bus IEEE test system\ndemonstrates that the proposed method obtains more accurate approximations than\nformer geometric methods and is ten times faster than the tested\noptimization-based method.",
    "descriptor": "",
    "authors": [
      "Alice Patig",
      "Ognjen Stanojev",
      "Petros Aristidou",
      "Aristides Kiprakis",
      "Gabriela Hug"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.09163"
  },
  {
    "id": "arXiv:2205.09167",
    "title": "Backdoor Attacks on Bayesian Neural Networks using Reverse Distribution",
    "abstract": "Due to cost and time-to-market constraints, many industries outsource the\ntraining process of machine learning models (ML) to third-party cloud service\nproviders, popularly known as ML-asa-Service (MLaaS). MLaaS creates opportunity\nfor an adversary to provide users with backdoored ML models to produce\nincorrect predictions only in extremely rare (attacker-chosen) scenarios.\nBayesian neural networks (BNN) are inherently immune against backdoor attacks\nsince the weights are designed to be marginal distributions to quantify the\nuncertainty. In this paper, we propose a novel backdoor attack based on\neffective learning and targeted utilization of reverse distribution. This paper\nmakes three important contributions. (1) To the best of our knowledge, this is\nthe first backdoor attack that can effectively break the robustness of BNNs.\n(2) We produce reverse distributions to cancel the original distributions when\nthe trigger is activated. (3) We propose an efficient solution for merging\nprobability distributions in BNNs. Experimental results on diverse benchmark\ndatasets demonstrate that our proposed attack can achieve the attack success\nrate (ASR) of 100%, while the ASR of the state-of-the-art attacks is lower than\n60%.",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Zhixin Pan",
      "Prabhat Mishra"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09167"
  },
  {
    "id": "arXiv:2205.09170",
    "title": "Adaptive Hybrid Heterogeneous IDS for 6LoWPAN",
    "abstract": "IPv6 over Low-powered Wireless Personal Area Networks (6LoWPAN) have grown in\nimportance in recent years, with the Routing Protocol for Low Power and Lossy\nNetworks (RPL) emerging as a major enabler. However, RPL can be subject to\nattack, with severe consequences. Most proposed IDSs have been limited to\nspecific RPL attacks and typically assume a stationary environment. In this\narticle, we propose the first adaptive hybrid IDS to efficiently detect and\nidentify a wide range of RPL attacks (including DIO Suppression, Increase Rank,\nand Worst Parent attacks, which have been overlooked in the literature) in\nevolving data environments. We apply our framework to networks under various\nlevels of node mobility and maliciousness. We experiment with several\nincremental machine learning (ML) approaches and various 'concept-drift\ndetection' mechanisms (e.g. ADWIN, DDM, and EDDM) to determine the best\nunderlying settings for the proposed scheme.",
    "descriptor": "",
    "authors": [
      "Aryan Mohammadi Pasikhani",
      "John A Clark",
      "Prosanta Gope"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.09170"
  },
  {
    "id": "arXiv:2205.09172",
    "title": "Color Overmodification Emerges from Data-Driven Learning and Pragmatic  Reasoning",
    "abstract": "Speakers' referential expressions often depart from communicative ideals in\nways that help illuminate the nature of pragmatic language use. Patterns of\novermodification, in which a speaker uses a modifier that is redundant given\ntheir communicative goal, have proven especially informative in this regard. It\nseems likely that these patterns are shaped by the environment a speaker is\nexposed to in complex ways. Unfortunately, systematically manipulating these\nfactors during human language acquisition is impossible. In this paper, we\npropose to address this limitation by adopting neural networks (NN) as learning\nagents. By systematically varying the environments in which these agents are\ntrained, while keeping the NN architecture constant, we show that\novermodification is more likely with environmental features that are infrequent\nor salient. We show that these findings emerge naturally in the context of a\nprobabilistic model of pragmatic communication.",
    "descriptor": "\nComments: Proceedings of the Annual Meeting of the Cognitive Science Society (2022)\n",
    "authors": [
      "Fei Fang",
      "Kunal Sinha",
      "Noah D. Goodman",
      "Christopher Potts",
      "Elisa Kreiss"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09172"
  },
  {
    "id": "arXiv:2205.09174",
    "title": "Cordial Miners: A Family of Simple, Efficient and Self-Contained  Consensus Protocols for Every Eventuality",
    "abstract": "Cordial Miners is a family of simple, efficient, self-contained, Byzantine\nAtomic Broadcast protocols, with optimal instances for asynchrony and eventual\nsynchrony. Its simplicity-cum-efficiency stems from using the blocklace -- a\npartially-ordered generalization of the totally-ordered blockchain -- for all\nkey algorithmic tasks, including block dissemination, equivocation exclusion,\nleader finality, block ordering, and for the identification and exclusion of\nfaulty miners. The algorithm employs piecemeal topological sort of the\npartially-ordered blocklace into a totally-ordered sequence of blocks,\nexcluding equivocations as well as the Byzantine miners perpetrating them along\nthe way. The conversion process is monotonic in that the output sequence only\nextends as the input blocklace increases, which implies (i) safety -- the\noutputs of two correct miners are consistent (one is a prefix of the other),\nand (ii) finality -- any output of a correct miner is final.\nWe present two instances of the protocol family: One for the eventual\nsynchrony model, employing deterministic/predicted leader selection and 3\nrounds of communication to leader finality in the good case, which is\nthree-quarters of the latency of state-of-the-art protocols. The second for the\nasynchrony model, employing retroactive random leader selection, 6 rounds to\nleader finality in the good case, and 9 rounds in the expected case, which is\nhalf the latency of state-of-the-art protocols in the good case and\nthree-quarters of their latency in the expected case. In both protocols,\nmessage complexity is the same as the state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Idit Keidar",
      "Oded Naor",
      "Ehud Shapiro"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.09174"
  },
  {
    "id": "arXiv:2205.09175",
    "title": "Carbon Figures of Merit Knowledge Creation with a Hybrid Solution and  Carbon Tables API",
    "abstract": "Nowadays there are algorithms, methods, and platforms that are being created\nto accelerate the discovery of materials that are able to absorb or adsorb\n$CO_2$ molecules that are in the atmosphere or during the combustion in power\nplants, for instance. In this work an asynchronous REST API is described to\naccelerate the creation of Carbon figures of merit knowledge, called Carbon\nTables, because the knowledge is created from tables in scientific PDF\ndocuments and stored in knowledge graphs. The figures of merit knowledge\ncreation solution uses a hybrid approach, in which heuristics and machine\nlearning are part of. As a result, one can search the knowledge with mature and\nsophisticated cognitive tools, and create more with regards to Carbon figures\nof merit.",
    "descriptor": "",
    "authors": [
      "Maira Gatti de Bayser"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.09175"
  },
  {
    "id": "arXiv:2205.09178",
    "title": "PreQuEL: Quality Estimation of Machine Translation Outputs in Advance",
    "abstract": "We present the task of PreQuEL, Pre-(Quality-Estimation) Learning. A PreQuEL\nsystem predicts how well a given sentence will be translated, without recourse\nto the actual translation, thus eschewing unnecessary resource allocation when\ntranslation quality is bound to be low. PreQuEL can be defined relative to a\ngiven MT system (e.g., some industry service) or generally relative to the\nstate-of-the-art. From a theoretical perspective, PreQuEL places the focus on\nthe source text, tracing properties, possibly linguistic features, that make a\nsentence harder to machine translate.\nWe develop a baseline model for the task and analyze its performance. We also\ndevelop a data augmentation method (from parallel corpora), that improves\nresults substantially. We show that this augmentation method can improve the\nperformance of the Quality-Estimation task as well. We investigate the\nproperties of the input text that our model is sensitive to, by testing it on\nchallenge sets and different languages. We conclude that it is aware of\nsyntactic and semantic distinctions, and correlates and even over-emphasizes\nthe importance of standard NLP features.",
    "descriptor": "",
    "authors": [
      "Shachar Don-Yehiya",
      "Leshem Choshen",
      "Omri Abend"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09178"
  },
  {
    "id": "arXiv:2205.09180",
    "title": "LeRaC: Learning Rate Curriculum",
    "abstract": "Most curriculum learning methods require an approach to sort the data samples\nby difficulty, which is often cumbersome to perform. In this work, we propose a\nnovel curriculum learning approach termed Learning Rate Curriculum (LeRaC),\nwhich leverages the use of a different learning rate for each layer of a neural\nnetwork to create a data-free curriculum during the initial training epochs.\nMore specifically, LeRaC assigns higher learning rates to neural layers closer\nto the input, gradually decreasing the learning rates as the layers are placed\nfarther away from the input. The learning rates increase at various paces\nduring the first training iterations, until they all reach the same value. From\nthis point on, the neural model is trained as usual. This creates a model-level\ncurriculum learning strategy that does not require sorting the examples by\ndifficulty and is compatible with any neural network, generating higher\nperformance levels regardless of the architecture. We conduct comprehensive\nexperiments on eight datasets from the computer vision (CIFAR-10, CIFAR-100,\nTiny ImageNet), language (BoolQ, QNLI, RTE) and audio (ESC-50, CREMA-D)\ndomains, considering various convolutional (ResNet-18, Wide-ResNet-50,\nDenseNet-121), recurrent (LSTM) and transformer (CvT, BERT, SepTr)\narchitectures, comparing our approach with the conventional training regime.\nMoreover, we also compare with Curriculum by Smoothing (CBS), a\nstate-of-the-art data-free curriculum learning approach. Unlike CBS, our\nperformance improvements over the standard training regime are consistent\nacross all datasets and models. Furthermore, we significantly surpass CBS in\nterms of training time (there is no additional cost over the standard training\nregime for LeRaC).",
    "descriptor": "",
    "authors": [
      "Florinel-Alin Croitoru",
      "Nicolae-Catalin Ristea",
      "Radu Tudor Ionescu",
      "Nicu Sebe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09180"
  },
  {
    "id": "arXiv:2205.09182",
    "title": "Computing the ensemble spread from deterministic weather predictions  using conditional generative adversarial networks",
    "abstract": "Ensemble prediction systems are an invaluable tool for weather forecasting.\nPractically, ensemble predictions are obtained by running several perturbations\nof the deterministic control forecast. However, ensemble prediction is\nassociated with a high computational cost and often involves statistical\npost-processing steps to improve its quality. Here we propose to use\ndeep-learning-based algorithms to learn the statistical properties of an\nensemble prediction system, the ensemble spread, given only the deterministic\ncontrol forecast. Thus, once trained, the costly ensemble prediction system\nwill not be needed anymore to obtain future ensemble forecasts, and the\nstatistical properties of the ensemble can be derived from a single\ndeterministic forecast. We adapt the classical pix2pix architecture to a\nthree-dimensional model and also experiment with a shared latent space\nencoder-decoder model, and train them against several years of operational\n(ensemble) weather forecasts for the 500 hPa geopotential height. The results\ndemonstrate that the trained models indeed allow obtaining a highly accurate\nensemble spread from the control forecast only.",
    "descriptor": "\nComments: 9 pages, 4 figures, 3 tables; release version\n",
    "authors": [
      "R\u00fcdiger Brecht",
      "Alex Bihlo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2205.09182"
  },
  {
    "id": "arXiv:2205.09190",
    "title": "On eventual non-negativity and positivity for the weighted sum of powers  of matrices",
    "abstract": "The long run behaviour of linear dynamical systems is often studied by\nlooking at eventual properties of matrices and recurrences that underlie the\nsystem. A basic problem that lies at the core of many questions in this setting\nis the following: given a set of pairs of rational weights and matrices {(w_1 ,\nA_1 ), . . . , (w_m , A_m )}, we ask if the weighted sum of powers of these\nmatrices is eventually non-negative P (resp. n positive), i.e., does there\nexist an integer N s.t for all n greater than N , (w_1 A_1^n + ... + w_m A_m^n)\nis atmost 0 (resp. greater than 0). The restricted setting when m = w_1 = 1,\nresults in so-called eventually non-negative (or eventually positive) matrices,\nwhich enjoy nice spectral properties and have been well-studied in control\ntheory. More applications arise in varied contexts, ranging from program\nverification to partially observable and multi-modal systems.\nOur goal is to investigate this problem and its link to linear recurrence\nsequences. Our first result is that for m at least 2, the problem is as hard as\nthe ultimate positivity of linear recurrences, a long standing open question\n(known to be coNP-hard). Our second result is a reduction in the other\ndirection showing that for any m at least 1, the problem reduces to ultimate\npositivity of linear recurrences. This shows precise upper bounds for several\nsubclasses of matrices by exploiting known results on linear recurrence\nsequences. Our third main result is a novel reduction technique for a large\nclass of problems (including those mentioned above) over rational\ndiagonalizable matrices to the corresponding problem over simple real-algebraic\nmatrices. This yields effective decision procedures for diagonalizable\nmatrices.",
    "descriptor": "\nComments: Long version of paper to appear at IJCAR 2022\n",
    "authors": [
      "S Akshay",
      "Supratik Chakraborty",
      "Debtanu Pal"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.09190"
  },
  {
    "id": "arXiv:2205.09191",
    "title": "High-Order Multilinear Discriminant Analysis via Order-$\\textit{n}$  Tensor Eigendecomposition",
    "abstract": "Higher-order data with high dimensionality is of immense importance in many\nareas of machine learning, computer vision, and video analytics.\nMultidimensional arrays (commonly referred to as tensors) are used for\narranging higher-order data structures while keeping the natural representation\nof the data samples. In the past decade, great efforts have been made to extend\nthe classic linear discriminant analysis for higher-order data classification\ngenerally referred to as multilinear discriminant analysis (MDA). Most of the\nexisting approaches are based on the Tucker decomposition and $\\textit{n}$-mode\ntensor-matrix products. The current paper presents a new approach to\ntensor-based multilinear discriminant analysis referred to as High-Order\nMultilinear Discriminant Analysis (HOMLDA). This approach is based upon the\ntensor decomposition where an order-$\\textit{n}$ tensor can be written as a\nproduct of order-$\\textit{n}$ tensors and has a natural extension to\ntraditional linear discriminant analysis (LDA). Furthermore, the resulting\nframework, HOMLDA, might produce a within-class scatter tensor that is close to\nsingular. Thus, computing the inverse inaccurately may distort the discriminant\nanalysis. To address this problem, an improved method referred to as Robust\nHigh-Order Multilinear Discriminant Analysis (RHOMLDA) is introduced.\nExperimental results on multiple data sets illustrate that our proposed\napproach provides improved classification performance with respect to the\ncurrent Tucker decomposition-based supervised learning methods.",
    "descriptor": "",
    "authors": [
      "Cagri Ozdemir",
      "Randy C. Hoover",
      "Kyle Caudle",
      "Karen Braman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09191"
  },
  {
    "id": "arXiv:2205.09194",
    "title": "Sim-to-Real Strategy for Spatially Aware Robot Navigation in Uneven  Outdoor Environments",
    "abstract": "Deep Reinforcement Learning (DRL) is hugely successful due to the\navailability of realistic simulated environments. However, performance\ndegradation during simulation to real-world transfer still remains a\nchallenging problem for the policies trained in simulated environments. To\nclose this sim-to-real gap, we present a novel hybrid architecture that\nutilizes an intermediate output from a fully trained attention DRL policy as a\nnavigation cost map for outdoor navigation. Our attention DRL network\nincorporates a robot-centric elevation map, IMU data, the robot's pose,\nprevious actions, and goal information as inputs to compute a navigation\ncost-map that highlights non-traversable regions. We compute least-cost\nwaypoints on the cost map and utilize the Dynamic Window Approach (DWA) with\nvelocity constraints on high cost regions to follow the waypoints in highly\nuneven outdoor environments. Our formulation generates dynamically feasible\nvelocities along stable, traversable regions to reach the robot's goals. We\nobserve an increase of 5% in terms of success rate, 13.09% of the decrease in\naverage robot vibration, and a 19.33% reduction in average velocity compared to\nend-to-end DRL method and state-of-the-art methods in complex outdoor\nenvironments. We evaluate the benefits of our method using a Clearpath Husky\nrobot in both simulated and real-world uneven environments.",
    "descriptor": "",
    "authors": [
      "Kasun Weerakoon",
      "Adarsh Jagan Sathyamoorthy",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.09194"
  },
  {
    "id": "arXiv:2205.09196",
    "title": "Hybrid Machine Learning Modeling of Engineering Systems -- A  Probabilistic Perspective Tested on a Multiphase Flow Modeling Case Study",
    "abstract": "To operate process engineering systems in a safe and reliable manner,\npredictive models are often used in decision making. In many cases, these are\nmechanistic first principles models which aim to accurately describe the\nprocess. In practice, the parameters of these models need to be tuned to the\nprocess conditions at hand. If the conditions change, which is common in\npractice, the model becomes inaccurate and needs to be re-tuned. In this paper,\nwe propose a hybrid modeling machine learning framework that allows tuning\nfirst principles models to process conditions using two different types of\nBayesian Neural Networks. Our approach not only estimates the expected values\nof the first principles model parameters but also quantifies the uncertainty of\nthese estimates. Such an approach of hybrid machine learning modeling is not\nyet well described in the literature, so we believe this paper will provide an\nadditional angle at which hybrid machine learning modeling of physical systems\ncan be considered. As an example, we choose a multiphase pipe flow process for\nwhich we constructed a three-phase steady state model based on the drift-flux\napproach which can be used for modeling of pipe and well flow behavior in oil\nand gas production systems with or without the neural network tuning. In the\nsimulation results, we show how uncertainty estimates of the resulting hybrid\nmodels can be used to make better operation decisions.",
    "descriptor": "\nComments: 20 pages, 10 figures, not published in any journal\n",
    "authors": [
      "Timur Bikmukhametov",
      "Johannes J\u00e4schke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.09196"
  },
  {
    "id": "arXiv:2205.09199",
    "title": "A False Sense of Security? Revisiting the State of Machine  Learning-Based Industrial Intrusion Detection",
    "abstract": "Anomaly-based intrusion detection promises to detect novel or unknown attacks\non industrial control systems by modeling expected system behavior and raising\ncorresponding alarms for any deviations.As manually creating these behavioral\nmodels is tedious and error-prone, research focuses on machine learning to\ntrain them automatically, achieving detection rates upwards of 99%. However,\nthese approaches are typically trained not only on benign traffic but also on\nattacks and then evaluated against the same type of attack used for training.\nHence, their actual, real-world performance on unknown (not trained on) attacks\nremains unclear. In turn, the reported near-perfect detection rates of machine\nlearning-based intrusion detection might create a false sense of security. To\nassess this situation and clarify the real potential of machine learning-based\nindustrial intrusion detection, we develop an evaluation methodology and\nexamine multiple approaches from literature for their performance on unknown\nattacks (excluded from training). Our results highlight an ineffectiveness in\ndetecting unknown attacks, with detection rates dropping to between 3.2% and\n14.7% for some types of attacks. Moving forward, we derive recommendations for\nfurther research on machine learning-based approaches to ensure clarity on\ntheir ability to detect unknown attacks.",
    "descriptor": "\nComments: ACM CPSS'22\n",
    "authors": [
      "Dominik Kus",
      "Eric Wagner",
      "Jan Pennekamp",
      "Konrad Wolsing",
      "Ina Berenice Fink",
      "Markus Dahlmanns",
      "Klaus Wehrle",
      "Martin Henze"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09199"
  },
  {
    "id": "arXiv:2205.09201",
    "title": "Mimicking Behaviors in Separated Domains",
    "abstract": "Devising a strategy to make a system mimicking behaviors from another system\nis a problem that naturally arises in many areas of Computer Science. In this\nwork, we interpret this problem in the context of intelligent agents, from the\nperspective of LTLf, a formalism commonly used in AI for expressing\nfinite-trace properties. Our model consists of two separated dynamic domains,\nD_A and D_B, and an LTLf specification that formalizes the notion of mimicking\nby mapping properties on behaviors (traces) of D_A into properties on behaviors\nof D_B. The goal is to synthesize a strategy that step-by-step maps every\nbehavior of D_A into a behavior of D_B so that the specification is met. We\nconsider several forms of mapping specifications, ranging from simple ones to\nfull LTLf, and for each we study synthesis algorithms and computational\nproperties.",
    "descriptor": "",
    "authors": [
      "Giuseppe De Giacomo",
      "Dror Fried",
      "Fabio Patrizi",
      "Shufang Zhu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09201"
  },
  {
    "id": "arXiv:2205.09202",
    "title": "Integrated Access and Backhaul in Millimeter-Wave Cellular: Benefits and  Challenges",
    "abstract": "The recently proposed NR-ready integrated access and backhaul (IAB)\narchitecture promises to bring a cost-efficient deployment solution for both\ncoverage extension and capacity boosting in future 5G/5G+ systems. While its\nimpact on the coverage extension was thoughtfully addressed in the literature,\nthe effect of advanced functionalities such as multi-hop, multi-connectivity,\nand multi-beam operations on the throughput remains unclear. We review and\ncharacterize the system-level impact of these capabilities on the performance\nof self-backhauled IAB systems operating in half-duplex mode and utilizing\nmillimeter-wave (mmWave) technology across both access and backhaul. Our\nresults indicate that the throughput gain of multi-hopping and multi-beaming is\nsignificant even without multi-connectivity operation. Another important\nlearning is that in all-mmWave systems with link blockage, multi-connectivity\nwith link switching allows achieving self-load balancing. Finally, we outline\nfuture research directions.",
    "descriptor": "\nComments: Accepted for publishing in the IEEE Communications Magazine\n",
    "authors": [
      "Yekaterina Sadovaya",
      "Dmitri Moltchanov",
      "Wei Mao",
      "Oner Orhan",
      "Shu-ping Yeh",
      "Hosein Nikopour",
      "Shilpa Talwar",
      "Sergey Andreev"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.09202"
  },
  {
    "id": "arXiv:2205.09208",
    "title": "Torchhd: An Open-Source Python Library to Support Hyperdimensional  Computing Research",
    "abstract": "Hyperdimensional Computing (HDC) is a neuro-inspired computing framework that\nexploits high-dimensional random vector spaces. HDC uses extremely\nparallelizable arithmetic to provide computational solutions that balance\naccuracy, efficiency and robustness. This has proven especially useful in\nresource-limited scenarios such as embedded systems. The commitment of the\nscientific community to aggregate and disseminate research in this particularly\nmultidisciplinary field has been fundamental for its advancement. Adding to\nthis effort, we propose Torchhd, a high-performance open-source Python library\nfor HDC. Torchhd seeks to make HDC more accessible and serves as an efficient\nfoundation for research and application development. The easy-to-use library\nbuilds on top of PyTorch and features state-of-the-art HDC functionality, clear\ndocumentation and implementation examples from notable publications. Comparing\npublicly available code with their Torchhd implementation shows that\nexperiments can run up to 104$\\times$ faster. Torchhd is available at:\nhttps://github.com/hyperdimensional-computing/torchhd",
    "descriptor": "",
    "authors": [
      "Mike Heddes",
      "Igor Nunes",
      "Pere Verg\u00e9s",
      "Dheyay Desai",
      "Tony Givargis",
      "Alexandru Nicolau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09208"
  },
  {
    "id": "arXiv:2205.09209",
    "title": "\"I'm sorry to hear that\": finding bias in language models with a  holistic descriptor dataset",
    "abstract": "As language models grow in popularity, their biases across all possible\nmarkers of demographic identity should be measured and addressed in order to\navoid perpetuating existing societal harms. Many datasets for measuring bias\ncurrently exist, but they are restricted in their coverage of demographic axes,\nand are commonly used with preset bias tests that presuppose which types of\nbiases the models exhibit. In this work, we present a new, more inclusive\ndataset, HOLISTICBIAS, which consists of nearly 600 descriptor terms across 13\ndifferent demographic axes. HOLISTICBIAS was assembled in conversation with\nexperts and community members with lived experience through a participatory\nprocess. We use these descriptors combinatorially in a set of bias measurement\ntemplates to produce over 450,000 unique sentence prompts, and we use these\nprompts to explore, identify, and reduce novel forms of bias in several\ngenerative models. We demonstrate that our dataset is highly efficacious for\nmeasuring previously unmeasurable biases in token likelihoods and generations\nfrom language models, as well as in an offensiveness classifier. We will invite\nadditions and amendments to the dataset, and we hope it will help serve as a\nbasis for easy-to-use and more standardized methods for evaluating bias in NLP\nmodels.",
    "descriptor": "",
    "authors": [
      "Eric Michael Smith",
      "Melissa Hall Melanie Kambadur",
      "Eleonora Presani",
      "Adina Williams"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.09209"
  },
  {
    "id": "arXiv:2205.09210",
    "title": "Reconfiguration of Digraph Homomorphisms",
    "abstract": "For a fixed graph H, the H-Recoloring problem asks whether for two given\nhomomorphisms from a graph G to H, we can transform one into the other by\nchanging the image of a single vertex of G in each step and maintaining a\nhomomorphism from G to H throughout. We extend an algorithm of Wrochna for\nH-Recoloring where H is a square-free loopless undirected graph to the more\ngeneral setting of directed graphs. We obtain a polynomial-time algorithm for\nH-Recoloring in this setting whenever H is a loopless digraph that does not\ncontain a 4-cycle of algebraic girth zero and whenever H is a reflexive digraph\nthat contains neither a 3-cycle of algebraic girth 1 nor a 4-cycle of algebraic\ngirth zero.",
    "descriptor": "",
    "authors": [
      "Benjamin L\u00e9v\u00eaque",
      "Moritz M\u00fchlenthaler",
      "Thomas Suzan"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2205.09210"
  },
  {
    "id": "arXiv:2205.09214",
    "title": "Mobility Support for Millimeter Wave Communications: Opportunities and  Challenges",
    "abstract": "Millimeter-wave (mmWave) communication technology offers a potential and\npromising solution to support 5G and B5G wireless networks in dynamic scenarios\nand applications. However, mobility introduces many challenges as well as\nopportunities to mmWave applications. To address these problems, we conduct a\nsurvey of the opportunities and technologies to support mmWave communications\nin mobile scenarios. Firstly, we summarize the mobile scenarios where mmWave\ncommunications are exploited, including indoor wireless local area network\n(WLAN) or wireless personal area network (WPAN), cellular access,\nvehicle-to-everything (V2X), high speed train (HST), unmanned aerial vehicle\n(UAV), and the new space-air-ground-sea communication scenarios. Then, to\naddress users' mobility impact on the system performance in different\napplication scenarios, we introduce several representative mobility models in\nmmWave systems, including human mobility, vehicular mobility, high speed train\nmobility and ship mobility. Next we survey the key challenges and existing\nsolutions to mmWave applications, such as channel modeling, channel estimation,\nanti-blockage, and capacity improvement. Lastly, we discuss the open issues\nconcerning mobility-aware mmWave communications that deserve further\ninvestigation. In particular, we highlight future heterogeneous mobile\nnetworks, dynamic resource management, artificial intelligence (AI) for\nmobility and integration of geographical information, deployment of large\nintelligent surface and reconfigurable antenna technology, and finally, the\nevolution to Terahertz (THz) communications.",
    "descriptor": "\nComments: 25 pages,11 figures,journal\n",
    "authors": [
      "Jing Li",
      "Yong Niu",
      "Hao Wu",
      "Bo Ai",
      "Sheng Chen",
      "Zhiyong Feng",
      "Zhangdui Zhong",
      "Ning Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.09214"
  },
  {
    "id": "arXiv:2205.09219",
    "title": "A Classification of $G$-invariant Shallow Neural Networks",
    "abstract": "When trying to fit a deep neural network (DNN) to a $G$-invariant target\nfunction with respect to a group $G$, it only makes sense to constrain the DNN\nto be $G$-invariant as well. However, there can be many different ways to do\nthis, thus raising the problem of \"$G$-invariant neural architecture design\":\nWhat is the optimal $G$-invariant architecture for a given problem? Before we\ncan consider the optimization problem itself, we must understand the search\nspace, the architectures in it, and how they relate to one another. In this\npaper, we take a first step towards this goal; we prove a theorem that gives a\nclassification of all $G$-invariant single-hidden-layer or \"shallow\" neural\nnetwork ($G$-SNN) architectures with ReLU activation for any finite orthogonal\ngroup $G$. The proof is based on a correspondence of every $G$-SNN to a signed\npermutation representation of $G$ acting on the hidden neurons. The\nclassification is equivalently given in terms of the first cohomology classes\nof $G$, thus admitting a topological interpretation. Based on a code\nimplementation, we enumerate the $G$-SNN architectures for some example groups\n$G$ and visualize their structure. We draw the network morphisms between the\nenumerated architectures that can be leveraged during neural architecture\nsearch (NAS). Finally, we prove that architectures corresponding to\ninequivalent cohomology classes in a given cohomology ring coincide in function\nspace only when their weight matrices are zero, and we discuss the implications\nof this in the context of NAS.",
    "descriptor": "\nComments: 29 pages, 8 figures. Submitted to NeurIPS 2022\n",
    "authors": [
      "Devanshu Agrawal",
      "James Ostrowski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.09219"
  },
  {
    "id": "arXiv:2205.09220",
    "title": "A Case Study of Building Shared Understanding of Non-Functional  Requirements in a Remote Software Organization",
    "abstract": "Building a shared understanding of non-functional requirements (NFRs) is a\nknown but understudied challenge in requirements engineering, especially in\norganizations that adopt continuous software engineering (CSE) practices.\nDuring the peak of the COVID-19 pandemic, many CSE organizations complied with\nworking remotely due to the imposed health restrictions; some continued to work\nremotely while implementing business processes to facilitate team communication\nand productivity. In remote CSE organizations, managing NFRs becomes more\nchallenging due to the limitations to team communication coupled with the\nincentive to deliver products quickly. While previous research has identified\nthe factors that lead to a lack of shared understanding of NFRs in CSE, we\nstill have a significant gap in understanding how CSE organizations,\nparticularly in remote work, build a shared understanding of NFRs in their\nsoftware development. We conduct a three-month ethnography-informed case study\nof a remote CSE organization. Through thematic analysis of our qualitative data\nfrom interviews and observations, we identify a number of practices in\ndeveloping a shared understanding of NFRs. The collaborative workspace the\norganization uses for remote interaction is Gather, which simulates physical\nworkspaces, and which our findings suggest allows for informal communications\ninstrumental for building shared understanding. As actionable insights, we\ndiscuss our findings in light of proactive practices that represent\nopportunities for software organizations to invest in building a shared\nunderstanding of NFRs in their development.",
    "descriptor": "\nComments: 12 pages, to be published in 30th IEEE International Requirements Engineering Conference (RE'22)\n",
    "authors": [
      "Laura Okpara",
      "Colin Werner",
      "Adam Murray",
      "Daniela Damian"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.09220"
  },
  {
    "id": "arXiv:2205.09224",
    "title": "Entailment Tree Explanations via Iterative Retrieval-Generation Reasoner",
    "abstract": "Large language models have achieved high performance on various question\nanswering (QA) benchmarks, but the explainability of their output remains\nelusive. Structured explanations, called entailment trees, were recently\nsuggested as a way to explain and inspect a QA system's answer. In order to\nbetter generate such entailment trees, we propose an architecture called\nIterative Retrieval-Generation Reasoner (IRGR). Our model is able to explain a\ngiven hypothesis by systematically generating a step-by-step explanation from\ntextual premises. The IRGR model iteratively searches for suitable premises,\nconstructing a single entailment step at a time. Contrary to previous\napproaches, our method combines generation steps and retrieval of premises,\nallowing the model to leverage intermediate conclusions, and mitigating the\ninput size limit of baseline encoder-decoder models. We conduct experiments\nusing the EntailmentBank dataset, where we outperform existing benchmarks on\npremise retrieval and entailment tree generation, with around 300% gain in\noverall correctness.",
    "descriptor": "\nComments: published in NAACL 2022\n",
    "authors": [
      "Danilo Ribeiro",
      "Shen Wang",
      "Xiaofei Ma",
      "Rui Dong",
      "Xiaokai Wei",
      "Henry Zhu",
      "Xinchi Chen",
      "Zhiheng Huang",
      "Peng Xu",
      "Andrew Arnold",
      "Dan Roth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09224"
  },
  {
    "id": "arXiv:2205.09226",
    "title": "Modeling Multi-hop Question Answering as Single Sequence Prediction",
    "abstract": "Fusion-in-decoder (Fid) (Izacard and Grave, 2020) is a generative question\nanswering (QA) model that leverages passage retrieval with a pre-trained\ntransformer and pushed the state of the art on single-hop QA. However, the\ncomplexity of multi-hop QA hinders the effectiveness of the generative QA\napproach. In this work, we propose a simple generative approach (PathFid) that\nextends the task beyond just answer generation by explicitly modeling the\nreasoning process to resolve the answer for multi-hop questions. By linearizing\nthe hierarchical reasoning path of supporting passages, their key sentences,\nand finally the factoid answer, we cast the problem as a single sequence\nprediction task. To facilitate complex reasoning with multiple clues, we\nfurther extend the unified flat representation of multiple input documents by\nencoding cross-passage interactions. Our extensive experiments demonstrate that\nPathFid leads to strong performance gains on two multi-hop QA datasets:\nHotpotQA and IIRC. Besides the performance gains, PathFid is more\ninterpretable, which in turn yields answers that are more faithfully grounded\nto the supporting passages and facts compared to the baseline Fid model.",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Semih Yavuz",
      "Kazuma Hashimoto",
      "Yingbo Zhou",
      "Nitish Shirish Keskar",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09226"
  },
  {
    "id": "arXiv:2205.09228",
    "title": "Scalable Multi-view Clustering with Graph Filtering",
    "abstract": "With the explosive growth of multi-source data, multi-view clustering has\nattracted great attention in recent years. Most existing multi-view methods\noperate in raw feature space and heavily depend on the quality of original\nfeature representation. Moreover, they are often designed for feature data and\nignore the rich topology structure information. Accordingly, in this paper, we\npropose a generic framework to cluster both attribute and graph data with\nheterogeneous features. It is capable of exploring the interplay between\nfeature and structure. Specifically, we first adopt graph filtering technique\nto eliminate high-frequency noise to achieve a clustering-friendly smooth\nrepresentation. To handle the scalability challenge, we develop a novel\nsampling strategy to improve the quality of anchors. Extensive experiments on\nattribute and graph benchmarks demonstrate the superiority of our approach with\nrespect to state-of-the-art approaches.",
    "descriptor": "",
    "authors": [
      "Liang Liu",
      "Peng Chen",
      "Guangchun Luo",
      "Zhao Kang",
      "Yonggang Luo",
      "Sanchu Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.09228"
  },
  {
    "id": "arXiv:2205.09229",
    "title": "PromptDA: Label-guided Data Augmentation for Prompt-based Few Shot  Learners",
    "abstract": "Recent advances on large pre-trained language models (PLMs) lead impressive\ngains on natural language understanding (NLU) tasks with task-specific\nfine-tuning. However, direct fine-tuning PLMs heavily relies on large amount of\nlabeled instances, which are expensive and time-consuming to obtain.\nPrompt-based tuning on PLMs has proven valuable for few shot tasks. Existing\nworks studying prompt-based tuning for few-shot NLU mainly focus on deriving\nproper label words with a verbalizer or generating prompt templates for\neliciting semantics from PLMs. In addition, conventional data augmentation\nmethods have also been verified useful for few-shot tasks. However, there\ncurrently are few data augmentation methods designed for the prompt-based\ntuning paradigm. Therefore, we study a new problem of data augmentation for\nprompt-based few shot learners. Since label semantics are helpful in\nprompt-based tuning, we propose a novel label-guided data augmentation method\nPromptDA which exploits the enriched label semantic information for data\naugmentation. Experimental results on several few shot text classification\ntasks show that our proposed framework achieves superior performance by\neffectively leveraging label semantics and data augmentation in language\nunderstanding.",
    "descriptor": "",
    "authors": [
      "Canyu Chen",
      "Kai Shu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09229"
  },
  {
    "id": "arXiv:2205.09230",
    "title": "ExploitWP2Docker: a Platform for Automating the Generation of Vulnerable  WordPress Environments for Cyber Ranges",
    "abstract": "A cyber range is a realistic simulation of an organization's network\ninfrastructure, commonly used for cyber security training purposes. It provides\na safe environment to assess competencies in both offensive and defensive\ntechniques. An important step during the realization of a cyber range is the\ngeneration of vulnerable machines. This step is challenging and requires a\nlaborious manual configuration. Several works aim to reduce this overhead, but\nthe current state-of-the-art focuses on generating network services without\nconsidering the effort required to build vulnerable environments for web\napplications. A cyber range should represent a real system, and nowadays,\nalmost all the companies develop their company site by using WordPress, a\ncommon Content Management System (CMS), which is also one of the most critical\nattackers' entry points. The presented work proposes an approach to\nautomatically create and configure vulnerable WordPress applications by using\nthe information presented in public exploits. Our platform automatically\nextracts information from the most well-known publicly available exploit\ndatabase in order to generate and configure vulnerable environments. The\ncontainer-based virtualization is used to generate lightweight and easily\ndeployable infrastructures. A final evaluation highlights promising results\nregarding the possibility of automating the generation of vulnerable\nenvironments through our approach.",
    "descriptor": "\nComments: 7 pages, 3 figures\n",
    "authors": [
      "Francesco Caturano",
      "Nicola d'Ambrosio",
      "Gaetano Perrone",
      "Luigi Previdente",
      "Simon Pietro Romano"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.09230"
  },
  {
    "id": "arXiv:2205.09232",
    "title": "The anachronism of whole-GPU accounting",
    "abstract": "NVIDIA has been making steady progress in increasing the compute performance\nof its GPUs, resulting in order of magnitude compute throughput improvements\nover the years. With several models of GPUs coexisting in many deployments, the\ntraditional accounting method of treating all GPUs as being equal is not\nreflecting compute output anymore. Moreover, for applications that require\nsignificant CPU-based compute to complement the GPU-based compute, it is\nbecoming harder and harder to make full use of the newer GPUs, requiring\nsharing of those GPUs between multiple applications in order to maximize the\nachievable science output. This further reduces the value of whole-GPU\naccounting, especially when the sharing is done at the infrastructure level. We\nthus argue that GPU accounting for throughput-oriented infrastructures should\nbe expressed in GPU core hours, much like it is normally done for the CPUs.\nWhile GPU core compute throughput does change between GPU generations, the\nvariability is similar to what we expect to see among CPU cores. To validate\nour position, we present an extensive set of run time measurements of two\nIceCube photon propagation workflows on 14 GPU models, using both on-prem and\nCloud resources. The measurements also outline the influence of GPU sharing at\nboth HTCondor and Kubernetes infrastructure level.",
    "descriptor": "\nComments: 6 pages, 2 tables, 1 figure, to be published in proceedings of PEARC22\n",
    "authors": [
      "Igor Sfiligoi",
      "David Schultz",
      "Frank W\u00fcrthwein",
      "Benedikt Riedel",
      "Dmitry Y. Mishin"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.09232"
  },
  {
    "id": "arXiv:2205.09233",
    "title": "Rensets and Renaming-Based Recursion for Syntax with Bindings",
    "abstract": "I introduce renaming-enriched sets (rensets for short), which are algebraic\nstructures axiomatizing fundamental properties of renaming (also known as\nvariable-for-variable substitution) on syntax with bindings. Rensets compare\nfavorably in some respects with the well-known foundation based on nominal\nsets. In particular, renaming is a more fundamental operator than the nominal\nswapping operator and enjoys a simpler, equationally expressed relationship\nwith the variable freshness predicate. Together with some natural axioms\nmatching properties of the syntactic constructors, rensets yield a truly\nminimalistic characterization of lambda-calculus terms as an abstract datatype\n-- the first one in the literature that involves a recursively enumerable set\nof unconditional equations, referring only to the most fundamental term\noperators: the constructors and renaming. This characterization yields a\nrecursion principle, which (similarly to the case of nominal sets) can be\nimproved by incorporating Barendregt's variable convention. When interpreting\nsyntax in semantic domains, my renaming-based recursor is easier to deploy than\nthe nominal recursor. My results have been validated with the proof assistant\nIsabelle/HOL.",
    "descriptor": "\nComments: This is an extended technical report associated to an identically titled conference paper that will appear in IJCAR 2022\n",
    "authors": [
      "Andrei Popescu"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.09233"
  },
  {
    "id": "arXiv:2205.09239",
    "title": "Readle: A Formal Framework for Designing AI-based Edge Systems",
    "abstract": "With the wide spread use of AI-driven systems in the edge (a.k.a edge\nintelligence systems), such as autonomous driving vehicles, wearable biotech\ndevices, intelligent manufacturing, etc., such systems are becoming very\ncritical for our day-to-day lives. A challenge in designing edge intelligence\nsystems is that we have to deal with a large number of constraints in two\ndesign spaces that form the basis of such systems: the edge design space and\nthe deep learning design space. Thus in this work, a new systematic,\nextendable, manual approach, READLE, is proposed for creating representations\nof specifications in edge intelligent systems, capturing constraints in the\nedge system design space (e.g. timing constraints and other performance\nconstraints) and constraints in the deep learning space (e.g. model training\nduration, required level of accuracy) in a coherent fashion. In particular,\nREADLE leverages benefits of real-time logic and binary decision diagrams to\ngenerate unified specifications. Several insights learned in building READLE\nare also discussed, which should help in future research in the domain of\nformal specifications for edge intelligent systems.",
    "descriptor": "",
    "authors": [
      "Aftab Hussain"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.09239"
  },
  {
    "id": "arXiv:2205.09240",
    "title": "Debiasing Neural Retrieval via In-batch Balancing Regularization",
    "abstract": "People frequently interact with information retrieval (IR) systems, however,\nIR models exhibit biases and discrimination towards various demographics. The\nin-processing fair ranking methods provide a trade-offs between accuracy and\nfairness through adding a fairness-related regularization term in the loss\nfunction. However, there haven't been intuitive objective functions that depend\non the click probability and user engagement to directly optimize towards this.\nIn this work, we propose the In-Batch Balancing Regularization (IBBR) to\nmitigate the ranking disparity among subgroups. In particular, we develop a\ndifferentiable \\textit{normed Pairwise Ranking Fairness} (nPRF) and leverage\nthe T-statistics on top of nPRF over subgroups as a regularization to improve\nfairness. Empirical results with the BERT-based neural rankers on the MS MARCO\nPassage Retrieval dataset with the human-annotated non-gendered queries\nbenchmark \\citep{rekabsaz2020neural} show that our IBBR method with nPRF\nachieves significantly less bias with minimal degradation in ranking\nperformance compared with the baseline.",
    "descriptor": "\nComments: 9 pages, 1 figure, and 3 tables. A version appears in the Proceedings of the 4th Workshop on Gender Bias in Natural Language Processing (GeBNLP), 2022\n",
    "authors": [
      "Yuantong Li",
      "Xiaokai Wei",
      "Zijian Wang",
      "Shen Wang",
      "Parminder Bhatia",
      "Xiaofei Ma",
      "Andrew Arnold"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.09240"
  },
  {
    "id": "arXiv:2205.09243",
    "title": "Frequency-Competitive Query Strategies to Maintain Low Congestion  Potential Among Moving Entities",
    "abstract": "We consider the problem of using location queries to monitor the congestion\npotential among a collection of entities moving, with bounded speed but\notherwise unpredictably, in $d$-dimensional Euclidean space. Uncertainty in\nentity locations due to potential motion between queries gives rise to a space\nof possible entity configurations at each moment in time, with possibly very\ndifferent congestion properties. We define different measures of what we call\nthe congestion potential of such spaces, in terms of the (dynamic) intersection\ngraph of the uncertainty regions associated with entities, to describe the\ncongestion that might actually occur.\nPrevious work [SoCG'13, EuroCG'14, SICOMP'16, SODA'19], in the same\nuncertainty model, addressed the problem of minimizing congestion potential\nusing location queries of some bounded frequency. It was shown that it is\npossible to design a query scheme that is $O(1)$-competitive, in terms of\nworst-case congestion potential, with other, even clairvoyant query schemes\n(that know the trajectories of all entities), subject to the same bound on\nquery frequency.\nIn this paper we address the dual problem: how to guarantee a fixed bound on\ncongestion potential while minimizing the query frequency, measured in terms of\ntotal number of queries or the minimum spacing between queries (granularity),\nover any fixed time interval. This complementary objective necessitates quite\ndifferent algorithms and analyses. Nevertheless, our results parallel those of\nthe earlier papers, specifically tight competitive bounds on required query\nfrequency, with a few surprising differences.",
    "descriptor": "",
    "authors": [
      "William Evans",
      "David Kirkpatrick"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.09243"
  },
  {
    "id": "arXiv:2205.09244",
    "title": "Riemannian Metric Learning via Optimal Transport",
    "abstract": "We introduce an optimal transport-based model for learning a metric tensor\nfrom cross-sectional samples of evolving probability measures on a common\nRiemannian manifold. We neurally parametrize the metric as a spatially-varying\nmatrix field and efficiently optimize our model's objective using\nbackpropagation. Using this learned metric, we can nonlinearly interpolate\nbetween probability measures and compute geodesics on the manifold. We show\nthat metrics learned using our method improve the quality of trajectory\ninference on scRNA and bird migration data at the cost of little additional\ncross-sectional data.",
    "descriptor": "",
    "authors": [
      "Christopher Scarvelis",
      "Justin Solomon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.09244"
  },
  {
    "id": "arXiv:2205.09245",
    "title": "Deterministic Near-Optimal Distributed Listing of Cliques",
    "abstract": "The importance of classifying connections in large graphs has been the\nmotivation for a rich line of work on distributed subgraph finding that has led\nto exciting recent breakthroughs. A crucial aspect that remained open was\nwhether deterministic algorithms can be as efficient as their randomized\ncounterparts, where the latter are known to be tight up to polylogarithmic\nfactors.\nWe give deterministic distributed algorithms for listing cliques of size $p$\nin $n^{1 - 2/p + o(1)}$ rounds in the \\congest model. For triangles, our\n$n^{1/3+o(1)}$ round complexity improves upon the previous state of the art of\n$n^{2/3+o(1)}$ rounds [Chang and Saranurak, FOCS 2020]. For cliques of size $p\n\\geq 4$, ours are the first non-trivial deterministic distributed algorithms.\nGiven known lower bounds, for all values $p \\geq 3$ our algorithms are tight up\nto a $n^{o(1)}$ subpolynomial factor, which comes from the deterministic\nrouting procedure we use.",
    "descriptor": "\nComments: To appear in PODC 2022\n",
    "authors": [
      "Keren Censor-Hillel",
      "Dean Leitersdorf",
      "David Vulakh"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.09245"
  },
  {
    "id": "arXiv:2205.09246",
    "title": "Transformer-based Program Synthesis for Low-Data Environments",
    "abstract": "Recent advancements in large pre-trained transformer models (GPT2/3, T5) have\nfound use in program synthesis to generate programs that satisfy a set of\ninput/output examples. However, these models perform poorly on long-horizon and\nlow-data tasks, and often don't seem to understand the semantics of the\nlanguages they generate. We investigate an approach that tackles both of these\nissues, by using attributed context-free-grammars of programming languages to\ngenerate programs, and then analyzing generated programs so that they can be\nannotated with compile and runtime attributes, such as types, so that\ninformation about the program can be remembered during long-horizon generation.\nWe firstly find that synthesized datasets can be made efficiently and can\nprovide transformer models with enough data in order to perform well on some\nsynthesis tasks. We also find that giving models access to program attributes\nis especially effective in low-data environments, and tends improve the quality\nand reduce errors of transformer-generated programs.",
    "descriptor": "\nComments: 11 pages. Corpus can be found at this https URL\n",
    "authors": [
      "Jack Roper"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09246"
  },
  {
    "id": "arXiv:2205.09248",
    "title": "MESH2IR: Neural Acoustic Impulse Response Generator for Complex 3D  Scenes",
    "abstract": "We propose a mesh-based neural network (MESH2IR) to generate acoustic impulse\nresponses (IRs) for indoor 3D scenes represented using a mesh. The IRs are used\nto create a high-quality sound experience in interactive applications and audio\nprocessing. Our method can handle input triangular meshes with arbitrary\ntopologies (2K - 3M triangles). We present a novel training technique to train\nMESH2IR using energy decay relief and highlight its benefits. We also show that\ntraining MESH2IR on IRs preprocessed using our proposed technique significantly\nimproves the accuracy of IR generation. We reduce the non-linearity in the mesh\nspace by transforming 3D scene meshes to latent space using a graph convolution\nnetwork. Our MESH2IR is more than 200 times faster than a geometric acoustic\nalgorithm on a CPU and can generate more than 10,000 IRs per second on an\nNVIDIA GeForce RTX 2080 Ti GPU for a given furnished indoor 3D scene. The\nacoustic metrics are used to characterize the acoustic environment. We show\nthat the acoustic metrics of the IRs predicted from our MESH2IR match the\nground truth with less than 10% error. We also highlight the benefits of\nMESH2IR on audio and speech processing applications such as speech\ndereverberation and speech separation. To the best of our knowledge, ours is\nthe first neural-network-based approach to predict IRs from a given 3D scene\nmesh in real-time.",
    "descriptor": "\nComments: More results and source code is available at this https URL\n",
    "authors": [
      "Anton Ratnarajah",
      "Zhenyu Tang",
      "Rohith Chandrashekar Aralikatti",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.09248"
  },
  {
    "id": "arXiv:2205.09249",
    "title": "On the Limits of Evaluating Embodied Agent Model Generalization Using  Validation Sets",
    "abstract": "Natural language guided embodied task completion is a challenging problem\nsince it requires understanding natural language instructions, aligning them\nwith egocentric visual observations, and choosing appropriate actions to\nexecute in the environment to produce desired changes. We experiment with\naugmenting a transformer model for this task with modules that effectively\nutilize a wider field of view and learn to choose whether the next step\nrequires a navigation or manipulation action. We observed that the proposed\nmodules resulted in improved, and in fact state-of-the-art performance on an\nunseen validation set of a popular benchmark dataset, ALFRED. However, our best\nmodel selected using the unseen validation set underperforms on the unseen test\nsplit of ALFRED, indicating that performance on the unseen validation set may\nnot in itself be a sufficient indicator of whether model improvements\ngeneralize to unseen test sets. We highlight this result as we believe it may\nbe a wider phenomenon in machine learning tasks but primarily noticeable only\nin benchmarks that limit evaluations on test splits, and highlights the need to\nmodify benchmark design to better account for variance in model performance.",
    "descriptor": "\nComments: ACL 2022 Insights Workshop (6 pages)\n",
    "authors": [
      "Hyounghun Kim",
      "Aishwarya Padmakumar",
      "Di Jin",
      "Mohit Bansal",
      "Dilek Hakkani-Tur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.09249"
  },
  {
    "id": "arXiv:2205.09250",
    "title": "Bayesian Convolutional Neural Networks for Limited Data Hyperspectral  Remote Sensing Image Classification",
    "abstract": "Employing deep neural networks for Hyper-spectral remote sensing (HSRS) image\nclassification is a challenging task. HSRS images have high dimensionality and\na large number of channels with substantial redundancy between channels. In\naddition, the training data for classifying HSRS images is limited and the\namount of available training data is much smaller compared to other\nclassification tasks. These factors complicate the training process of deep\nneural networks with many parameters and cause them to not perform well even\ncompared to conventional models. Moreover, convolutional neural networks\nproduce over-confident predictions, which is highly undesirable considering the\naforementioned problem.\nIn this work, we use a special class of deep neural networks, namely Bayesian\nneural network, to classify HSRS images. To the extent of our knowledge, this\nis the first time that this class of neural networks has been used in HSRS\nimage classification. Bayesian neural networks provide an inherent tool for\nmeasuring uncertainty. We show that a Bayesian network can outperform a\nsimilarly-constructed non-Bayesian convolutional neural network (CNN) and an\noff-the-shelf Random Forest (RF). Moreover, experimental results for the Pavia\nCentre, Salinas, and Botswana datasets show that the Bayesian network is more\nstable and robust to model pruning. Furthermore, we analyze the prediction\nuncertainty of the Bayesian model and show that the prediction uncertainty\nmetric can provide information about the model predictions and has a positive\ncorrelation with the prediction error.",
    "descriptor": "",
    "authors": [
      "Mohammad Joshaghani",
      "Amirabbas Davari",
      "Faezeh Nejati Hatamian",
      "Andreas Maier",
      "Christian Riess"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09250"
  },
  {
    "id": "arXiv:2205.09251",
    "title": "IL-flOw: Imitation Learning from Observation using Normalizing Flows",
    "abstract": "We present an algorithm for Inverse Reinforcement Learning (IRL) from expert\nstate observations only. Our approach decouples reward modelling from policy\nlearning, unlike state-of-the-art adversarial methods which require updating\nthe reward model during policy search and are known to be unstable and\ndifficult to optimize. Our method, IL-flOw, recovers the expert policy by\nmodelling state-state transitions, by generating rewards using deep density\nestimators trained on the demonstration trajectories, avoiding the instability\nissues of adversarial methods. We demonstrate that using the state transition\nlog-probability density as a reward signal for forward reinforcement learning\ntranslates to matching the trajectory distribution of the expert\ndemonstrations, and experimentally show good recovery of the true reward signal\nas well as state of the art results for imitation from observation on\nlocomotion and robotic continuous control tasks.",
    "descriptor": "\nComments: Presented at the 4th Robot Learning Workshop at NeurIPS 2021\n",
    "authors": [
      "Wei-Di Chang",
      "Juan Camilo Gamboa Higuera",
      "Scott Fujimoto",
      "David Meger",
      "Gregory Dudek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.09251"
  },
  {
    "id": "arXiv:2205.09255",
    "title": "CALIPSO: A Differentiable Solver for Trajectory Optimization with Conic  and Complementarity Constraints",
    "abstract": "We present a new solver for non-convex trajectory optimization problems that\nis specialized for robotics applications. CALIPSO, or the Conic Augmented\nLagrangian Interior-Point SOlver, combines several strategies for constrained\nnumerical optimization to natively handle second-order cones and\ncomplementarity constraints. It reliably solves challenging motion-planning\nproblems that include contact-implicit formulations of impacts and Coulomb\nfriction, thrust limits subject to conic constraints, and state-triggered\nconstraints where general-purpose nonlinear programming solvers like SNOPT and\nIpopt fail to converge. Additionally, CALIPSO supports efficient\ndifferentiation of solutions with respect to problem data, enabling bi-level\noptimization applications like auto-tuning of feedback policies. Reliable\nconvergence of the solver is demonstrated on a range of problems from\nmanipulation, locomotion, and aerospace domains. An open-source implementation\nof this solver is available.",
    "descriptor": "",
    "authors": [
      "Taylor A. Howell",
      "Simon Le Cleac'h",
      "Kevin Tracy",
      "Zachary Manchester"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.09255"
  },
  {
    "id": "arXiv:2205.09256",
    "title": "Training Vision-Language Transformers from Captions Alone",
    "abstract": "We show that Vision-Language Transformers can be learned without human labels\n(e.g. class labels, bounding boxes, etc). Existing work, whether explicitly\nutilizing bounding boxes or patches, assumes that the visual backbone must\nfirst be trained on ImageNet class prediction before being integrated into a\nmultimodal linguistic pipeline. We show that this is not necessary and\nintroduce a new model Vision-Language from Captions (VLC) built on top of\nMasked Auto-Encoders that does not require this supervision. In fact, in a\nhead-to-head comparison between ViLT, the current state-of-the-art patch-based\nvision-language transformer which is pretrained with supervised object\nclassification, and our model, VLC, we find that our approach 1. outperforms\nViLT on standard benchmarks, 2. provides more interpretable and intuitive patch\nvisualizations, and 3. is competitive with many larger models that utilize ROIs\ntrained on annotated bounding-boxes.",
    "descriptor": "",
    "authors": [
      "Liangke Gui",
      "Qiuyuan Huang",
      "Alex Hauptmann",
      "Yonatan Bisk",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2205.09256"
  },
  {
    "id": "arXiv:2205.09257",
    "title": "Mining Observation and Cognitive Behavior Process Patterns of Bridge  Inspector",
    "abstract": "In bridge inspection, engineers should diagnose the observed bridge defects\nby identifying the factors underlying those defects. Traditionally, engineers\nsearch and organize structural condition-related information based on visual\ninspections. Even following the same qualitative inspection standards,\nexperienced engineers tend to find the critical defects and predict the\nunderlying reasons more reliably than less experienced ones. Unique bridge and\nsite conditions, quality of available data, and personal skills and knowledge\ncollectively influence such a subjective nature of data-driven bridge\ndiagnosis. Unfortunately, the lack of detailed data about how experienced\nengineers observe bridge defects and identify failure modes makes it hard to\ncomprehend what engineers' behaviors form the best practice of producing\nreliable bridge inspection. Besides, even experienced engineers could sometimes\nfail to notice critical defects, thereby producing inconsistent, conflicting\ncondition assessments. Therefore, a detailed cognitive behavior analysis of\nbridge inspectors is critical for enabling a proactive inspector coaching\nsystem that uses inspectors' behavior histories to complement personal\nlimitations. This paper presents a computational framework for revealing\nengineers' observation and cognitive-behavioral processes to identify bridge\ndefects and produce diagnosis conclusions. The authors designed a bridge\ninspection game consisting of FEM simulation data and inspection reports to\ncapture and analyze experienced and inexperienced engineers' diagnosis\nbehaviors. Mining these behavioral logs have revealed reusable behavioral\nprocess patterns that map critical bridge defects and diagnosis conclusions.\nThe results indicate that the proposed method can proactively share inspection\nexperiences and improve inspection processes' explainability and reliability.",
    "descriptor": "",
    "authors": [
      "Pengkun Liu",
      "Ruoxin Xiong",
      "Pingbo Tang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.09257"
  },
  {
    "id": "arXiv:2205.09259",
    "title": "Centralized Model-Predictive Control with Human-Driver Interaction for  Platooning",
    "abstract": "Cooperative adaptive cruise control presents an opportunity to improve road\ntransportation through increase in road capacity and reduction in energy use\nand accidents. Clever design of control algorithms and communication systems is\nrequired to ensure that the vehicle platoon is stable and meets desired safety\nrequirements. In this paper, we propose a centralized model predictive\ncontroller for a heterogeneous platoon of vehicles to reach a desired platoon\nvelocity and individual inter-vehicle distances with driver-selected headway\ntime. In our approach, we allow for interruption from a human driver in the\nplatoon that temporarily takes control of their vehicle with the assumption\nthat the driver will, at minimum, obey legal velocity limits and the physical\nperformance constraints of their vehicle. The finite horizon cost function of\nour proposed platoon controller is inspired from the infinite horizon design.\nTo the best of our knowledge, this is the first platoon controller that\nintegrates human-driven vehicles. We illustrate the performance of our proposed\ndesign with a numerical study.",
    "descriptor": "\nComments: 15 pages, 5 figures\n",
    "authors": [
      "Justin M. Kennedy",
      "Julian Heinovski",
      "Daniel E. Quevedo",
      "Falko Dressler"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.09259"
  },
  {
    "id": "arXiv:2205.09263",
    "title": "A Mutually Exciting Latent Space Hawkes Process Model for  Continuous-time Networks",
    "abstract": "Networks and temporal point processes serve as fundamental building blocks\nfor modeling complex dynamic relational data in various domains. We propose the\nlatent space Hawkes (LSH) model, a novel generative model for continuous-time\nnetworks of relational events, using a latent space representation for nodes.\nWe model relational events between nodes using mutually exciting Hawkes\nprocesses with baseline intensities dependent upon the distances between the\nnodes in the latent space and sender and receiver specific effects. We propose\nan alternating minimization algorithm to jointly estimate the latent positions\nof the nodes and other model parameters. We demonstrate that our proposed LSH\nmodel can replicate many features observed in real temporal networks including\nreciprocity and transitivity, while also achieves superior prediction accuracy\nand provides more interpretability compared to existing models.",
    "descriptor": "\nComments: Accepted by UAI 2022\n",
    "authors": [
      "Zhipeng Huang",
      "Hadeel Soliman",
      "Subhadeep Paul",
      "Kevin S. Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.09263"
  },
  {
    "id": "arXiv:2205.09269",
    "title": "Threshold Designer Adaptation: Improved Adaptation for Designers in  Co-creative Systems",
    "abstract": "To best assist human designers with different styles, Machine Learning (ML)\nsystems need to be able to adapt to them. However, there has been relatively\nlittle prior work on how and when to best adapt an ML system to a co-designer.\nIn this paper we present threshold designer adaptation: a novel method for\nadapting a creative ML model to an individual designer. We evaluate our\napproach with a human subject study using a co-creative rhythm game design\ntool. We find that designers prefer our proposed method and produce higher\nquality content in comparison to an existing baseline.",
    "descriptor": "\nComments: 6 pages, 2 figures, International Joint Conference on Artificial Intelligence (IJCAI), Special Topic on AI, the Arts, and Creativity\n",
    "authors": [
      "Emily Halina",
      "Matthew Guzdial"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.09269"
  },
  {
    "id": "arXiv:2205.09273",
    "title": "Twist Decoding: Diverse Generators Guide Each Other",
    "abstract": "Natural language generation technology has recently seen remarkable progress\nwith large-scale training, and many natural language applications are now built\nupon a wide range of generation models. Combining diverse models may lead to\nfurther progress, but conventional ensembling (e.g., shallow fusion) requires\nthat they share vocabulary/tokenization schemes. We introduce Twist decoding, a\nsimple and general inference algorithm that generates text while benefiting\nfrom diverse models. Our method does not assume the vocabulary, tokenization or\neven generation order is shared. Our extensive evaluations on machine\ntranslation and scientific paper summarization demonstrate that Twist decoding\nsubstantially outperforms each model decoded in isolation over various\nscenarios, including cases where domain-specific and general-purpose models are\nboth available. Twist decoding also consistently outperforms the popular\nreranking heuristic where output candidates from one model is rescored by\nanother. We hope that our work will encourage researchers and practitioners to\nexamine generation models collectively, not just independently, and to seek out\nmodels with complementary strengths to the currently available models.",
    "descriptor": "\nComments: Code is available at this https URL\n",
    "authors": [
      "Jungo Kasai",
      "Keisuke Sakaguchi",
      "Ronan Le Bras",
      "Hao Peng",
      "Ximing Lu",
      "Dragomir Radev",
      "Yejin Choi",
      "Noah A. Smith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09273"
  },
  {
    "id": "arXiv:2205.09278",
    "title": "Modeling Exemplification in Long-form Question Answering via Retrieval",
    "abstract": "Exemplification is a process by which writers explain or clarify a concept by\nproviding an example. While common in all forms of writing, exemplification is\nparticularly useful in the task of long-form question answering (LFQA), where a\ncomplicated answer can be made more understandable through simple examples. In\nthis paper, we provide the first computational study of exemplification in QA,\nperforming a fine-grained annotation of different types of examples (e.g.,\nhypotheticals, anecdotes) in three corpora. We show that not only do\nstate-of-the-art LFQA models struggle to generate relevant examples, but also\nthat standard evaluation metrics such as ROUGE are insufficient to judge\nexemplification quality. We propose to treat exemplification as a\n\\emph{retrieval} problem in which a partially-written answer is used to query a\nlarge set of human-written examples extracted from a corpus. Our approach\nallows a reliable ranking-type automatic metrics that correlates well with\nhuman evaluation. A human evaluation shows that our model's retrieved examples\nare more relevant than examples generated from a state-of-the-art LFQA model.",
    "descriptor": "\nComments: 2022 Annual Conference of the North American Chapter of the Association for Computational Linguistics\n",
    "authors": [
      "Shufan Wang",
      "Fangyuan Xu",
      "Laure Thompson",
      "Eunsol Choi",
      "Mohit Iyyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09278"
  },
  {
    "id": "arXiv:2205.09281",
    "title": "Causal Inference from Small High-dimensional Datasets",
    "abstract": "Many methods have been proposed to estimate treatment effects with\nobservational data. Often, the choice of the method considers the application's\ncharacteristics, such as type of treatment and outcome, confounding effect, and\nthe complexity of the data. These methods implicitly assume that the sample\nsize is large enough to train such models, especially the neural network-based\nestimators. What if this is not the case? In this work, we propose\nCausal-Batle, a methodology to estimate treatment effects in small\nhigh-dimensional datasets in the presence of another high-dimensional dataset\nin the same feature space. We adopt an approach that brings transfer learning\ntechniques into causal inference. Our experiments show that such an approach\nhelps to bring stability to neural network-based methods and improve the\ntreatment effect estimates in small high-dimensional datasets.",
    "descriptor": "\nComments: 12 pages, 3 figures\n",
    "authors": [
      "Raquel Aoki",
      "Martin Ester"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.09281"
  },
  {
    "id": "arXiv:2205.09284",
    "title": "Towards Applicable Reinforcement Learning: Improving the Generalization  and Sample Efficiency with Policy Ensemble",
    "abstract": "It is challenging for reinforcement learning (RL) algorithms to succeed in\nreal-world applications like financial trading and logistic system due to the\nnoisy observation and environment shifting between training and evaluation.\nThus, it requires both high sample efficiency and generalization for resolving\nreal-world tasks. However, directly applying typical RL algorithms can lead to\npoor performance in such scenarios. Considering the great performance of\nensemble methods on both accuracy and generalization in supervised learning\n(SL), we design a robust and applicable method named Ensemble Proximal Policy\nOptimization (EPPO), which learns ensemble policies in an end-to-end manner.\nNotably, EPPO combines each policy and the policy ensemble organically and\noptimizes both simultaneously. In addition, EPPO adopts a diversity enhancement\nregularization over the policy space which helps to generalize to unseen states\nand promotes exploration. We theoretically prove EPPO increases exploration\nefficacy, and through comprehensive experimental evaluations on various tasks,\nwe demonstrate that EPPO achieves higher efficiency and is robust for\nreal-world applications compared with vanilla policy optimization algorithms\nand other ensemble methods. Code and supplemental materials are available at\nhttps://seqml.github.io/eppo.",
    "descriptor": "\nComments: Accepted in IJCAI 2022. The codes are available at this https URL\n",
    "authors": [
      "Zhengyu Yang",
      "Kan Ren",
      "Xufang Luo",
      "Minghuan Liu",
      "Weiqing Liu",
      "Jiang Bian",
      "Weinan Zhang",
      "Dongsheng Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09284"
  },
  {
    "id": "arXiv:2205.09289",
    "title": "Routing and Placement of Macros using Deep Reinforcement Learning",
    "abstract": "Chip placement has been one of the most time consuming task in any semi\nconductor area, Due to this negligence, many projects are pushed and chips\navailability in real markets get delayed. An engineer placing macros on a chip\nalso needs to place it optimally to reduce the three important factors like\npower, performance and time. Looking at these prior problems we wanted to\nintroduce a new method using Reinforcement Learning where we train the model to\nplace the nodes of a chip netlist onto a chip canvas. We want to build a neural\narchitecture that will accurately reward the agent across a wide variety of\ninput netlist correctly.",
    "descriptor": "",
    "authors": [
      "Mrinal Mathur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09289"
  },
  {
    "id": "arXiv:2205.09292",
    "title": "Free Lunch for Surgical Video Understanding by Distilling  Self-Supervisions",
    "abstract": "Self-supervised learning has witnessed great progress in vision and NLP;\nrecently, it also attracted much attention to various medical imaging\nmodalities such as X-ray, CT, and MRI. Existing methods mostly focus on\nbuilding new pretext self-supervision tasks such as reconstruction,\norientation, and masking identification according to the properties of medical\nimages. However, the publicly available self-supervision models are not fully\nexploited. In this paper, we present a powerful yet efficient self-supervision\nframework for surgical video understanding. Our key insight is to distill\nknowledge from publicly available models trained on large generic datasets4 to\nfacilitate the self-supervised learning of surgical videos. To this end, we\nfirst introduce a semantic-preserving training scheme to obtain our teacher\nmodel, which not only contains semantics from the publicly available models,\nbut also can produce accurate knowledge for surgical data. Besides training\nwith only contrastive learning, we also introduce a distillation objective to\ntransfer the rich learned information from the teacher model to self-supervised\nlearning on surgical data. Extensive experiments on two surgical phase\nrecognition benchmarks show that our framework can significantly improve the\nperformance of existing self-supervised learning methods. Notably, our\nframework demonstrates a compelling advantage under a low-data regime. Our code\nis available at https://github.com/xmed-lab/DistillingSelf.",
    "descriptor": "",
    "authors": [
      "Xinpeng Ding",
      "Ziwei Liu",
      "Xiaomeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09292"
  },
  {
    "id": "arXiv:2205.09295",
    "title": "Are Prompt-based Models Clueless?",
    "abstract": "Finetuning large pre-trained language models with a task-specific head has\nadvanced the state-of-the-art on many natural language understanding\nbenchmarks. However, models with a task-specific head require a lot of training\ndata, making them susceptible to learning and exploiting dataset-specific\nsuperficial cues that do not generalize to other datasets. Prompting has\nreduced the data requirement by reusing the language model head and formatting\nthe task input to match the pre-training objective. Therefore, it is expected\nthat few-shot prompt-based models do not exploit superficial cues. This paper\npresents an empirical examination of whether few-shot prompt-based models also\nexploit superficial cues. Analyzing few-shot prompt-based models on MNLI, SNLI,\nHANS, and COPA has revealed that prompt-based models also exploit superficial\ncues. While the models perform well on instances with superficial cues, they\noften underperform or only marginally outperform random accuracy on instances\nwithout superficial cues.",
    "descriptor": "",
    "authors": [
      "Pride Kavumba",
      "Ryo Takahashi",
      "Yasuke Oda"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09295"
  },
  {
    "id": "arXiv:2205.09296",
    "title": "Opinion Manipulation on Farsi Twitter",
    "abstract": "For Iranians and the Iranian diaspora, the Farsi Twittersphere provides an\nimportant alternative to state media and an outlet for political discourse. But\nthis understudied online space has become an opinion manipulation battleground,\nwith diverse actors using inauthentic accounts to advance their goals and shape\nonline narratives. Examining trending discussions crossing social cleavages in\nIran, we explore how the dynamics of opinion manipulation differ across diverse\nissue areas. Our analysis suggests that opinion manipulation by inauthentic\naccounts is more prevalent in divisive political discussions than non-divisive\nor apolitical discussions. We show how Twitter's network structures help to\nreinforce the content propagated by clusters of inauthentic accounts in\ndivisive political discussions. Analyzing both the content and structure of\nonline discussions in the Iranian Twittersphere, this work contributes to a\ngrowing body of literature exploring the dynamics of online opinion\nmanipulation, while improving our understanding of how information is\ncontrolled in the digital age.",
    "descriptor": "\nComments: 21 pages, 9 figures, two appendices\n",
    "authors": [
      "Amirhossein Farzam",
      "Parham Moradi",
      "Saeedeh Mohammadi",
      "Zahra Padar",
      "Alexandra A. Siegel"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.09296"
  },
  {
    "id": "arXiv:2205.09297",
    "title": "Strong approximation for fractional wave equation forced by fractional  Brownian motion with Hurst parameter $H\\in(0,\\frac{1}{2})$",
    "abstract": "We consider the time discretization of fractional stochastic wave equation\nwith Gaussian noise, which is negatively correlated. Major obstacles to design\nand analyze time discretization of stochastic wave equation come from the\napproximation of stochastic convolution with respect to fractional Brownian\nmotion. Firstly, we discuss the smoothing properties of stochastic convolution\nby using integration by parts and covariance function of fractional Brownian\nmotion. Then the regularity estimates of the mild solution of fractional\nstochastic wave equation are obtained. Next, we design the time discretization\nof stochastic convolution by integration by parts. Combining stochastic\ntrigonometric method and approximation of stochastic convolution, the time\ndiscretization of stochastic wave equation is achieved. We derive the error\nestimates of the time discretization. Under certain assumptions, the strong\nconvergence rate of the numerical scheme proposed in this paper can reach\n$\\frac{1}{2}+H$. Finally, the convergence rate and computational efficiency of\nthe numerical scheme are illustrated by numerical experiments.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Xing Liu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.09297"
  },
  {
    "id": "arXiv:2205.09299",
    "title": "3DConvCaps: 3DUnet with Convolutional Capsule Encoder for Medical Image  Segmentation",
    "abstract": "Convolutional Neural Networks (CNNs) have achieved promising results in\nmedical image segmentation. However, CNNs require lots of training data and are\nincapable of handling pose and deformation of objects. Furthermore, their\npooling layers tend to discard important information such as positions as well\nas CNNs are sensitive to rotation and affine transformation. Capsule network is\na recent new architecture that has achieved better robustness in part-whole\nrepresentation learning by replacing pooling layers with dynamic routing and\nconvolutional strides, which has shown potential results on popular tasks such\nas digit classification and object segmentation. In this paper, we propose a 3D\nencoder-decoder network with Convolutional Capsule Encoder (called 3DConvCaps)\nto learn lower-level features (short-range attention) with convolutional layers\nwhile modeling the higher-level features (long-range dependence) with capsule\nlayers. Our experiments on multiple datasets including iSeg-2017, Hippocampus,\nand Cardiac demonstrate that our 3D 3DConvCaps network considerably outperforms\nprevious capsule networks and 3D-UNets. We further conduct ablation studies of\nnetwork efficiency and segmentation performance under various configurations of\nconvolution layers and capsule layers at both contracting and expanding paths.",
    "descriptor": "\nComments: Accepted to ICPR 2022\n",
    "authors": [
      "Minh Tran",
      "Viet-Khoa Vo-Ho",
      "Ngan T.H. Le"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09299"
  },
  {
    "id": "arXiv:2205.09305",
    "title": "FedILC: Weighted Geometric Mean and Invariant Gradient Covariance for  Federated Learning on Non-IID Data",
    "abstract": "Federated learning is a distributed machine learning approach which enables a\nshared server model to learn by aggregating the locally-computed parameter\nupdates with the training data from spatially-distributed client silos. Though\nsuccessfully possessing advantages in both scale and privacy, federated\nlearning is hurt by domain shift problems, where the learning models are unable\nto generalize to unseen domains whose data distribution is non-i.i.d. with\nrespect to the training domains. In this study, we propose the Federated\nInvariant Learning Consistency (FedILC) approach, which leverages the gradient\ncovariance and the geometric mean of Hessians to capture both inter-silo and\nintra-silo consistencies of environments and unravel the domain shift problems\nin federated networks. The benchmark and real-world dataset experiments bring\nevidence that our proposed algorithm outperforms conventional baselines and\nsimilar federated learning algorithms. This is relevant to various fields such\nas medical healthcare, computer vision, and the Internet of Things (IoT). The\ncode is released at https://github.com/mikemikezhu/FedILC.",
    "descriptor": "",
    "authors": [
      "Mike He Zhu",
      "L\u00e9na N\u00e9hale Ezzine",
      "Dianbo Liu",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.09305"
  },
  {
    "id": "arXiv:2205.09306",
    "title": "Joint Device Selection and Power Control for Wireless Federated Learning",
    "abstract": "This paper studies the joint device selection and power control scheme for\nwireless federated learning (FL), considering both the downlink and uplink\ncommunications between the parameter server (PS) and the terminal devices. In\neach round of model training, the PS first broadcasts the global model to the\nterminal devices in an analog fashion, and then the terminal devices perform\nlocal training and upload the updated model parameters to the PS via\nover-the-air computation (AirComp). First, we propose an AirComp-based adaptive\nreweighing scheme for the aggregation of local updated models, where the model\naggregation weights are directly determined by the uplink transmit power values\nof the selected devices and which enables the joint learning and communication\noptimization simply by the device selection and power control. Furthermore, we\nprovide a convergence analysis for the proposed wireless FL algorithm and the\nupper bound on the expected optimality gap between the expected and optimal\nglobal loss values is derived. With instantaneous channel state information\n(CSI), we formulate the optimality gap minimization problems under both the\nindividual and sum uplink transmit power constraints, respectively, which are\nshown to be solved by the semidefinite programming (SDR) technique. Numerical\nresults reveal that our proposed wireless FL algorithm achieves close to the\nbest performance by using the ideal FedAvg scheme with error-free model\nexchange and full device participation.",
    "descriptor": "",
    "authors": [
      "Wei Guo",
      "Ran Li",
      "Chuan Huang",
      "Xiaoqi Qin",
      "Kaiming Shen",
      "Wei Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.09306"
  },
  {
    "id": "arXiv:2205.09307",
    "title": "Support-set based Multi-modal Representation Enhancement for Video  Captioning",
    "abstract": "Video captioning is a challenging task that necessitates a thorough\ncomprehension of visual scenes. Existing methods follow a typical one-to-one\nmapping, which concentrates on a limited sample space while ignoring the\nintrinsic semantic associations between samples, resulting in rigid and\nuninformative expressions. To address this issue, we propose a novel and\nflexible framework, namely Support-set based Multi-modal Representation\nEnhancement (SMRE) model, to mine rich information in a semantic subspace\nshared between samples. Specifically, we propose a Support-set Construction\n(SC) module to construct a support-set to learn underlying connections between\nsamples and obtain semantic-related visual elements. During this process, we\ndesign a Semantic Space Transformation (SST) module to constrain relative\ndistance and administrate multi-modal interactions in a self-supervised way.\nExtensive experiments on MSVD and MSR-VTT datasets demonstrate that our SMRE\nachieves state-of-the-art performance.",
    "descriptor": "",
    "authors": [
      "Xiaoya Chen",
      "Jingkuan Song",
      "Pengpeng Zeng",
      "Lianli Gao",
      "Heng Tao Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09307"
  },
  {
    "id": "arXiv:2205.09310",
    "title": "Mitigating Neural Network Overconfidence with Logit Normalization",
    "abstract": "Detecting out-of-distribution inputs is critical for safe deployment of\nmachine learning models in the real world. However, neural networks are known\nto suffer from the overconfidence issue, where they produce abnormally high\nconfidence for both in- and out-of-distribution inputs. In this work, we show\nthat this issue can be mitigated through Logit Normalization (LogitNorm) -- a\nsimple fix to the cross-entropy loss -- by enforcing a constant vector norm on\nthe logits in training. Our method is motivated by the analysis that the norm\nof the logit keeps increasing during training, leading to overconfident output.\nOur key idea behind LogitNorm is thus to decouple the influence of output's\nnorm during network optimization. Trained with LogitNorm, neural networks\nproduce highly distinguishable confidence scores between in- and\nout-of-distribution data. Extensive experiments demonstrate the superiority of\nLogitNorm, reducing the average FPR95 by up to 42.30% on common benchmarks.",
    "descriptor": "\nComments: Accepted by ICML 2022\n",
    "authors": [
      "Hongxin Wei",
      "Renchunzi Xie",
      "Hao Cheng",
      "Lei Feng",
      "Bo An",
      "Yixuan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09310"
  },
  {
    "id": "arXiv:2205.09314",
    "title": "Target-Guided Dialogue Response Generation Using Commonsense and Data  Augmentation",
    "abstract": "Target-guided response generation enables dialogue systems to smoothly\ntransition a conversation from a dialogue context toward a target sentence.\nSuch control is useful for designing dialogue systems that direct a\nconversation toward specific goals, such as creating non-obtrusive\nrecommendations or introducing new topics in the conversation. In this paper,\nwe introduce a new technique for target-guided response generation, which first\nfinds a bridging path of commonsense knowledge concepts between the source and\nthe target, and then uses the identified bridging path to generate transition\nresponses. Additionally, we propose techniques to re-purpose existing dialogue\ndatasets for target-guided generation. Experiments reveal that the proposed\ntechniques outperform various baselines on this task. Finally, we observe that\nthe existing automated metrics for this task correlate poorly with human\njudgement ratings. We propose a novel evaluation metric that we demonstrate is\nmore reliable for target-guided response evaluation. Our work generally enables\ndialogue system designers to exercise more control over the conversations that\ntheir systems produce.",
    "descriptor": "\nComments: Accepted at NAACL 2022 (Findings)\n",
    "authors": [
      "Prakhar Gupta",
      "Harsh Jhamtani",
      "Jeffrey P. Bigham"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09314"
  },
  {
    "id": "arXiv:2205.09316",
    "title": "Dynamic Clustering and Power Control for Two-Tier Wireless Federated  Learning",
    "abstract": "Federated learning (FL) has been recognized as a promising distributed\nlearning paradigm to support intelligent applications at the wireless edge,\nwhere a global model is trained iteratively through the collaboration of the\nedge devices without sharing their data. However, due to the relatively large\ncommunication cost between the devices and parameter server (PS), direct\ncomputing based on the information from the devices may not be resource\nefficient. This paper studies the joint communication and learning design for\nthe over-the-air computation (AirComp)-based two-tier wireless FL scheme, where\nthe lead devices first collect the local gradients from their nearby\nsubordinate devices, and then send the merged results to the PS for the second\nround of aggregation. We establish a convergence result for the proposed scheme\nand derive the upper bound on the optimality gap between the expected and\noptimal global loss values. Next, based on the device distance and data\nimportance, we propose a hierarchical clustering method to build the two-tier\nstructure. Then, with only the instantaneous channel state information (CSI),\nwe formulate the optimality gap minimization problem and solve it by using an\nefficient alternating minimization method. Numerical results show that the\nproposed scheme outperforms the baseline ones.",
    "descriptor": "",
    "authors": [
      "Wei Guo",
      "Chuan Huang",
      "Xiaoqi Qin",
      "Lian Yang",
      "Wei Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.09316"
  },
  {
    "id": "arXiv:2205.09318",
    "title": "On Demographic Bias in Fingerprint Recognition",
    "abstract": "Fingerprint recognition systems have been deployed globally in numerous\napplications including personal devices, forensics, law enforcement, banking,\nand national identity systems. For these systems to be socially acceptable and\ntrustworthy, it is critical that they perform equally well across different\ndemographic groups. In this work, we propose a formal statistical framework to\ntest for the existence of bias (demographic differentials) in fingerprint\nrecognition across four major demographic groups (white male, white female,\nblack male, and black female) for two state-of-the-art (SOTA) fingerprint\nmatchers operating in verification and identification modes. Experiments on two\ndifferent fingerprint databases (with 15,468 and 1,014 subjects) show that\ndemographic differentials in SOTA fingerprint recognition systems decrease as\nthe matcher accuracy increases and any small bias that may be evident is likely\ndue to certain outlier, low-quality fingerprint images.",
    "descriptor": "",
    "authors": [
      "Akash Godbole",
      "Steven A. Grosz",
      "Karthik Nandakumar",
      "Anil K. Jain"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09318"
  },
  {
    "id": "arXiv:2205.09324",
    "title": "Learning from Bootstrapping and Stepwise Reinforcement Reward: A  Semi-Supervised Framework for Text Style Transfer",
    "abstract": "Text style transfer is an important task in controllable language generation.\nSupervised approaches have pushed performance improvement on style-oriented\nrewriting such as formality conversion. However, challenges remain due to the\nscarcity of large-scale parallel data in many domains. While unsupervised\napproaches do not rely on annotated sentence pairs for each style, they are\noften plagued with instability issues such as mode collapse or quality\ndegradation. To take advantage of both supervised and unsupervised paradigms\nand tackle the challenges, in this work, we propose a semi-supervised framework\nfor text style transfer. First, the learning process is bootstrapped with\nsupervision guided by automatically constructed pseudo-parallel pairs using\nlexical and semantic-based methods. Then the model learns from unlabeled data\nvia reinforcement rewards. Specifically, we propose to improve the\nsequence-to-sequence policy gradient via stepwise reward optimization,\nproviding fine-grained learning signals and stabilizing the reinforced learning\nprocess. Experimental results show that the proposed approach achieves\nstate-of-the-art performance on multiple datasets, and produces effective\ngeneration with as minimal as 10\\% of training data.",
    "descriptor": "\nComments: In Findings of NAACL 2022\n",
    "authors": [
      "Zhengyuan Liu",
      "Nancy F. Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09324"
  },
  {
    "id": "arXiv:2205.09325",
    "title": "Cloudprofiler: TSC-based inter-node profiling and high-throughput data  ingestion for cloud streaming workloads",
    "abstract": "To conduct real-time analytics computations, big data stream processing\nengines are required to process unbounded data streams at millions of events\nper second. However, current streaming engines exhibit low throughput and high\ntuple processing latency. Performance engineering is complicated by the fact\nthat streaming engines constitute complex distributed systems consisting of\nmultiple nodes in the cloud. A profiling technique is required that is capable\nof measuring time durations at high accuracy across nodes. Standard clock\nsynchronization techniques such as the network time protocol (NTP) are limited\nto millisecond accuracy, and hence cannot be used.\nWe propose a profiling technique that relates the time-stamp counters (TSCs)\nof nodes to measure the duration of events in a streaming framework. The\nprecision of the TSC relation determines the accuracy of the measured duration.\nThe TSC relation is conducted in quiescent periods of the network to achieve\naccuracy in the tens of microseconds. We propose a throughput-controlled data\ngenerator to reliably determine the sustainable throughput of a streaming\nengine. To facilitate high-throughput data ingestion, we propose a concurrent\nobject factory that moves the deserialization overhead of incoming data tuples\noff the critical path of the streaming framework. The evaluation of the\nproposed techniques within the Apache Storm streaming framework on the Google\nCompute Engine public cloud shows that data ingestion increases from $700$\n$\\text{k}$ to $4.68$ $\\text{M}$ tuples per second, and that time durations can\nbe profiled at a measurement accuracy of $92$ $\\mu\\text{s}$, which is three\norders of magnitude higher than the accuracy of NTP, and one order of magnitude\nhigher than prior work.",
    "descriptor": "",
    "authors": [
      "Shinhyung Yang",
      "Jiun Jeong",
      "Bernhard Scholz",
      "Bernd Burgstaller"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.09325"
  },
  {
    "id": "arXiv:2205.09327",
    "title": "Let's Talk! Striking Up Conversations via Conversational Visual Question  Generation",
    "abstract": "An engaging and provocative question can open up a great conversation. In\nthis work, we explore a novel scenario: a conversation agent views a set of the\nuser's photos (for example, from social media platforms) and asks an engaging\nquestion to initiate a conversation with the user. The existing\nvision-to-question models mostly generate tedious and obvious questions, which\nmight not be ideals conversation starters. This paper introduces a two-phase\nframework that first generates a visual story for the photo set and then uses\nthe story to produce an interesting question. The human evaluation shows that\nour framework generates more response-provoking questions for starting\nconversations than other vision-to-question baselines.",
    "descriptor": "\nComments: Accepted as a full talk paper on AAAI-DEEPDIAL'21\n",
    "authors": [
      "Shih-Han Chan",
      "Tsai-Lun Yang",
      "Yun-Wei Chu",
      "Chi-Yang Hsu",
      "Ting-Hao Huang",
      "Yu-Shian Chiu",
      "Lun-Wei Ku"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09327"
  },
  {
    "id": "arXiv:2205.09328",
    "title": "TransTab: Learning Transferable Tabular Transformers Across Tables",
    "abstract": "Tabular data (or tables) are the most widely used data format in machine\nlearning (ML). However, ML models often assume the table structure keeps fixed\nin training and testing. Before ML modeling, heavy data cleaning is required to\nmerge disparate tables with different columns. This preprocessing often incurs\nsignificant data waste (e.g., removing unmatched columns and samples). How to\nlearn ML models from multiple tables with partially overlapping columns? How to\nincrementally update ML models as more columns become available over time? Can\nwe leverage model pretraining on multiple distinct tables? How to train an ML\nmodel which can predict on an unseen table?\nTo answer all those questions, we propose to relax fixed table structures by\nintroducing a Transferable Tabular Transformer (TransTab) for tables. The goal\nof TransTab is to convert each sample (a row in the table) to a generalizable\nembedding vector, and then apply stacked transformers for feature encoding. One\nmethodology insight is combining column description and table cells as the raw\ninput to a gated transformer model. The other insight is to introduce\nsupervised and self-supervised pretraining to improve model performance. We\ncompare TransTab with multiple baseline methods on diverse benchmark datasets\nand five oncology clinical trial datasets. Overall, TransTab ranks 1.00, 1.00,\n1.78 out of 12 methods in supervised learning, feature incremental learning,\nand transfer learning scenarios, respectively; and the proposed pretraining\nleads to 2.3\\% AUC lift on average over the supervised learning.}",
    "descriptor": "",
    "authors": [
      "Zifeng Wang",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09328"
  },
  {
    "id": "arXiv:2205.09329",
    "title": "Dataset Pruning: Reducing Training Data by Examining Generalization  Influence",
    "abstract": "The great success of deep learning heavily relies on increasingly larger\ntraining data, which comes at a price of huge computational and infrastructural\ncosts. This poses crucial questions that, do all training data contribute to\nmodel's performance? How much does each individual training sample or a\nsub-training-set affect the model's generalization, and how to construct a\nsmallest subset from the entire training data as a proxy training set without\nsignificantly sacrificing the model's performance? To answer these, we propose\ndataset pruning, an optimization-based sample selection method that can (1)\nexamine the influence of removing a particular set of training samples on\nmodel's generalization ability with theoretical guarantee, and (2) construct a\nsmallest subset of training data that yields strictly constrained\ngeneralization gap. The empirically observed generalization gap of dataset\npruning is substantially consistent with our theoretical expectations.\nFurthermore, the proposed method prunes 40% training examples on the CIFAR-10\ndataset, halves the convergence time with only 1.3% test accuracy decrease,\nwhich is superior to previous score-based sample selection methods.",
    "descriptor": "",
    "authors": [
      "Shuo Yang",
      "Zeke Xie",
      "Hanyu Peng",
      "Min Xu",
      "Mingming Sun",
      "Ping Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09329"
  },
  {
    "id": "arXiv:2205.09330",
    "title": "CHARLES: Channel-Quality-Adaptive Over-the-Air Federated Learning over  Wireless Networks",
    "abstract": "Over-the-air federated learning (OTA-FL) has emerged as an efficient\nmechanism that exploits the superposition property of the wireless medium and\nperforms model aggregation for federated learning in the air. OTA-FL is\nnaturally sensitive to wireless channel fading, which could significantly\ndiminish its learning accuracy. To address this challenge, in this paper, we\npropose an OTA-FL algorithm called CHARLES (channel-quality-aware over-the-air\nlocal estimating and scaling). Our CHARLES algorithm performs channel state\ninformation (CSI) estimation and adaptive scaling to mitigate the impacts of\nwireless channel fading. We establish the theoretical convergence rate\nperformance of CHARLES and analyze the impacts of CSI error on the convergence\nof CHARLES. We show that the adaptive channel inversion scaling scheme in\nCHARLES is robust under imperfect CSI scenarios. We also demonstrate through\nnumerical results that CHARLES outperforms existing OTA-FL algorithms with\nheterogeneous data under imperfect CSI.",
    "descriptor": "",
    "authors": [
      "Jiayu Mao",
      "Haibo Yang",
      "Peiwen Qiu",
      "Jia Liu",
      "Aylin Yener"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.09330"
  },
  {
    "id": "arXiv:2205.09332",
    "title": "Accelerated Training of Physics Informed Neural Networks (PINNs) using  Meshless Discretizations",
    "abstract": "We present a new technique for the accelerated training of physics-informed\nneural networks (PINNs): discretely-trained PINNs (DT-PINNs). The repeated\ncomputation of partial derivative terms in the PINN loss functions via\nautomatic differentiation during training is known to be computationally\nexpensive, especially for higher-order derivatives. DT-PINNs are trained by\nreplacing these exact spatial derivatives with high-order accurate numerical\ndiscretizations computed using meshless radial basis function-finite\ndifferences (RBF-FD) and applied via sparse-matrix vector multiplication. The\nuse of RBF-FD allows for DT-PINNs to be trained even on point cloud samples\nplaced on irregular domain geometries. Additionally, though traditional PINNs\n(vanilla-PINNs) are typically stored and trained in 32-bit floating-point\n(fp32) on the GPU, we show that for DT-PINNs, using fp64 on the GPU leads to\nsignificantly faster training times than fp32 vanilla-PINNs with comparable\naccuracy. We demonstrate the efficiency and accuracy of DT-PINNs via a series\nof experiments. First, we explore the effect of network depth on both numerical\nand automatic differentiation of a neural network with random weights and show\nthat RBF-FD approximations of third-order accuracy and above are more efficient\nwhile being sufficiently accurate. We then compare the DT-PINNs to\nvanilla-PINNs on both linear and nonlinear Poisson equations and show that\nDT-PINNs achieve similar losses with 2-4x faster training times on a consumer\nGPU. Finally, we also demonstrate that similar results can be obtained for the\nPINN solution to the heat equation (a space-time problem) by discretizing the\nspatial derivatives using RBF-FD and using automatic differentiation for the\ntemporal derivative. Our results show that fp64 DT-PINNs offer a superior\ncost-accuracy profile to fp32 vanilla-PINNs.",
    "descriptor": "\nComments: Submitted to the 36th Annual Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Ramansh Sharma",
      "Varun Shankar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09332"
  },
  {
    "id": "arXiv:2205.09335",
    "title": "A Simple Yet Effective SVD-GCN for Directed Graphs",
    "abstract": "In this paper, we propose a simple yet effective graph neural network for\ndirected graphs (digraph) based on the classic Singular Value Decomposition\n(SVD), named SVD-GCN. The new graph neural network is built upon the graph\nSVD-framelet to better decompose graph signals on the SVD ``frequency'' bands.\nFurther the new framelet SVD-GCN is also scaled up for larger scale graphs via\nusing Chebyshev polynomial approximation. Through empirical experiments\nconducted on several node classification datasets, we have found that SVD-GCN\nhas remarkable improvements in a variety of graph node learning tasks and it\noutperforms GCN and many other state-of-the-art graph neural networks for\ndigraphs. Moreover, we empirically demonstate that the SVD-GCN has great\ndenoising capability and robustness to high level graph data attacks. The\ntheoretical and experimental results prove that the SVD-GCN is effective on a\nvariant of graph datasets, meanwhile maintaining stable and even better\nperformance than the state-of-the-arts.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Chunya Zou",
      "Andi Han",
      "Lequan Lin",
      "Junbin Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.09335"
  },
  {
    "id": "arXiv:2205.09336",
    "title": "Creating Star Worlds -- Modelling Concave Obstacles for Reactive Motion  Planning",
    "abstract": "Motion planning methods like navigation functions and harmonic potential\nfields provide (almost) global convergence and are suitable for obstacle\navoidance in dynamically changing environments due to their reactive nature. A\ncommon assumption in the control design is that the robot operates in a\ndisjoint star world, i.e. all obstacles are strictly starshaped and mutually\ndisjoint. However, in real-life scenarios obstacles may intersect due to\nexpanded obstacle regions corresponding to robot radius or safety margins. To\nbroaden the applicability of aforementioned reactive motion planning methods,\nwe propose a method to transform a workspace of intersecting obstacles to a\ndisjoint star world. The algorithm is based on two novel concepts presented\nhere, namely admissible kernel and starshaped hull with specified kernel, which\nare closely related to the notion of starshaped hull. The utilization of the\nproposed method is illustrated with examples of a robot operating in a 2D\nworkspace using a harmonic potential field approach in combination with the\ndeveloped algorithm.",
    "descriptor": "",
    "authors": [
      "Albin Dahlin",
      "Yiannis Karayiannidis"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.09336"
  },
  {
    "id": "arXiv:2205.09337",
    "title": "Deep Learning in Business Analytics: A Clash of Expectations and Reality",
    "abstract": "Our fast-paced digital economy shaped by global competition requires\nincreased data-driven decision-making based on artificial intelligence (AI) and\nmachine learning (ML). The benefits of deep learning (DL) are manifold, but it\ncomes with limitations that have - so far - interfered with widespread industry\nadoption. This paper explains why DL - despite its popularity - has\ndifficulties speeding up its adoption within business analytics. It is shown -\nby a mixture of content analysis and empirical study - that the adoption of\ndeep learning is not only affected by computational complexity, lacking big\ndata architecture, lack of transparency (black-box), and skill shortage, but\nalso by the fact that DL does not outperform traditional ML models in the case\nof structured datasets with fixed-length feature vectors. Deep learning should\nbe regarded as a powerful addition to the existing body of ML models instead of\na one size fits all solution.",
    "descriptor": "\nComments: Submitted to the International Journal of Information Management Data Insights, 21 pages, 4 figures\n",
    "authors": [
      "Marc Andreas Schmitt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2205.09337"
  },
  {
    "id": "arXiv:2205.09343",
    "title": "Physically-Based Editing of Indoor Scene Lighting from a Single Image",
    "abstract": "We present a method to edit complex indoor lighting from a single image with\nits predicted depth and light source segmentation masks. This is an extremely\nchallenging problem that requires modeling complex light transport, and\ndisentangling HDR lighting from material and geometry with only a partial LDR\nobservation of the scene. We tackle this problem using two novel components: 1)\na holistic scene reconstruction method that estimates scene reflectance and\nparametric 3D lighting, and 2) a neural rendering framework that re-renders the\nscene from our predictions. We use physically-based indoor light\nrepresentations that allow for intuitive editing, and infer both visible and\ninvisible light sources. Our neural rendering framework combines\nphysically-based direct illumination and shadow rendering with deep networks to\napproximate global illumination. It can capture challenging lighting effects,\nsuch as soft shadows, directional lighting, specular materials, and\ninterreflections. Previous single image inverse rendering methods usually\nentangle scene lighting and geometry and only support applications like object\ninsertion. Instead, by combining parametric 3D lighting estimation with neural\nscene rendering, we demonstrate the first automatic method to achieve full\nscene relighting, including light source insertion, removal, and replacement,\nfrom a single image. All source code and data will be publicly released.",
    "descriptor": "",
    "authors": [
      "Zhengqin Li",
      "Jia Shi",
      "Sai Bi",
      "Rui Zhu",
      "Kalyan Sunkavalli",
      "Milo\u0161 Ha\u0161an",
      "Zexiang Xu",
      "Ravi Ramamoorthi",
      "Manmohan Chandraker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09343"
  },
  {
    "id": "arXiv:2205.09347",
    "title": "Bypassing Logits Bias in Online Class-Incremental Learning with a  Generative Framework",
    "abstract": "Continual learning requires the model to maintain the learned knowledge while\nlearning from a non-i.i.d data stream continually. Due to the single-pass\ntraining setting, online continual learning is very challenging, but it is\ncloser to the real-world scenarios where quick adaptation to new data is\nappealing. In this paper, we focus on online class-incremental learning setting\nin which new classes emerge over time. Almost all existing methods are\nreplay-based with a softmax classifier. However, the inherent logits bias\nproblem in the softmax classifier is a main cause of catastrophic forgetting\nwhile existing solutions are not applicable for online settings. To bypass this\nproblem, we abandon the softmax classifier and propose a novel generative\nframework based on the feature space. In our framework, a generative classifier\nwhich utilizes replay memory is used for inference, and the training objective\nis a pair-based metric learning loss which is proven theoretically to optimize\nthe feature space in a generative way. In order to improve the ability to learn\nnew data, we further propose a hybrid of generative and discriminative loss to\ntrain the model. Extensive experiments on several benchmarks, including newly\nintroduced task-free datasets, show that our method beats a series of\nstate-of-the-art replay-based methods with discriminative classifiers, and\nreduces catastrophic forgetting consistently with a remarkable margin.",
    "descriptor": "",
    "authors": [
      "Gehui Shen",
      "Shibo Jie",
      "Ziheng Li",
      "Zhi-Hong Deng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09347"
  },
  {
    "id": "arXiv:2205.09348",
    "title": "Analyzing Echo-state Networks Using Fractal Dimension",
    "abstract": "This work joins aspects of reservoir optimization, information-theoretic\noptimal encoding, and at its center fractal analysis. We build on the\nobservation that, due to the recursive nature of recurrent neural networks,\ninput sequences appear as fractal patterns in their hidden state\nrepresentation. These patterns have a fractal dimension that is lower than the\nnumber of units in the reservoir. We show potential usage of this fractal\ndimension with regard to optimization of recurrent neural network\ninitialization. We connect the idea of `ideal' reservoirs to lossless optimal\nencoding using arithmetic encoders. Our investigation suggests that the fractal\ndimension of the mapping from input to hidden state shall be close to the\nnumber of units in the network. This connection between fractal dimension and\nnetwork connectivity is an interesting new direction for recurrent neural\nnetwork initialization and reservoir computing.",
    "descriptor": "\nComments: Copyright is with IEEE\n",
    "authors": [
      "Norbert Michael Mayer",
      "Oliver Obst"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.09348"
  },
  {
    "id": "arXiv:2205.09350",
    "title": "Cross-lingual Inflection as a Data Augmentation Method for Parsing",
    "abstract": "We propose a morphology-based method for low-resource (LR) dependency\nparsing. We train a morphological inflector for target LR languages, and apply\nit to related rich-resource (RR) treebanks to create cross-lingual\n(x-inflected) treebanks that resemble the target LR language. We use such\ninflected treebanks to train parsers in zero- (training on x-inflected\ntreebanks) and few-shot (training on x-inflected and target language treebanks)\nsetups. The results show that the method sometimes improves the baselines, but\nnot consistently.",
    "descriptor": "\nComments: 10 pages, 7 tables, 5 figures. Workshop on Insights from Negative Results in NLP 2022 (co-located with ACL)\n",
    "authors": [
      "Alberto Mu\u00f1oz Ortiz",
      "Carlos G\u00f3mez-Rodr\u00edguez",
      "David Vilares"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09350"
  },
  {
    "id": "arXiv:2205.09351",
    "title": "Mip-NeRF RGB-D: Depth Assisted Fast Neural Radiance Fields",
    "abstract": "Neural scene representations, such as neural radiance fields (NeRF), are\nbased on training a multilayer perceptron (MLP) using a set of color images\nwith known poses. An increasing number of devices now produce RGB-D\ninformation, which has been shown to be very important for a wide range of\ntasks. Therefore, the aim of this paper is to investigate what improvements can\nbe made to these promising implicit representations by incorporating depth\ninformation with the color images. In particular, the recently proposed\nMip-NeRF approach, which uses conical frustums instead of rays for volume\nrendering, allows one to account for the varying area of a pixel with distance\nfrom the camera center. The proposed method additionally models depth\nuncertainty. This allows to address major limitations of NeRF-based approaches\nincluding improving the accuracy of geometry, reduced artifacts, faster\ntraining time, and shortened prediction time. Experiments are performed on\nwell-known benchmark scenes, and comparisons show improved accuracy in scene\ngeometry and photometric reconstruction, while reducing the training time by 3\n- 5 times.",
    "descriptor": "",
    "authors": [
      "Arnab Dey",
      "Yassine Ahmine",
      "Andrew I. Comport"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09351"
  },
  {
    "id": "arXiv:2205.09352",
    "title": "Analysis of relay-based feedback compensation of Coulomb friction",
    "abstract": "Standard problem of one-degree-of-freedom mechanical systems with Coulomb\nfriction is revised for a relay-based feedback stabilization. It is recalled\nthat a system with Coulomb friction is asymptotically stabilizable via a\nrelay-based output feedback, as formerly demonstrated in [1]. Assuming an upper\nbounded Coulomb friction disturbance, a time optimal gain of the relay-based\nfeedback control is found by minimizing the derivative of the Lyapunov function\nproposed in [2] for the twisting algorithm. Furthermore, changing from the\ndiscontinuous Coulomb friction to a more physical discontinuity-free one, which\nimplies a transient presliding phase at motion reversals, we analyze the\nresidual steady-state oscillations, in the sense of stable limit cycles, in\naddition to chattering caused the by the actuator dynamics. The numerical\nexamples and an experimental case study accompany the provided analysis.",
    "descriptor": "\nComments: 6 pages, 5 figures\n",
    "authors": [
      "Michael Ruderman",
      "Leonid Fridman"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.09352"
  },
  {
    "id": "arXiv:2205.09353",
    "title": "Physics Informed LSTM Network for Flexibility Identification in  Evaporative Cooling Systems",
    "abstract": "In energy intensive industrial systems, an evaporative cooling process may\nintroduce operational flexibility. Such flexibility refers to a systems ability\nto deviate from its scheduled energy consumption. Identifying the flexibility,\nand therefore, designing control that ensures efficient and reliable operation\npresents a great challenge due to the inherently complex dynamics of industrial\nsystems. Recently, machine learning models have attracted attention for\nidentifying flexibility, due to their ability to model complex nonlinear\nbehavior. This research presents machine learning based methods that integrate\nsystem dynamics into the machine learning models (e.g., Neural Networks) for\nbetter adherence to physical constraints. We define and evaluate physics\ninformed long-short term memory networks (PhyLSTM) and physics informed neural\nnetworks (PhyNN) for the identification of flexibility in the evaporative\ncooling process. These physics informed networks approximate the time-dependent\nrelationship between control input and system response while enforcing the\ndynamics of the process in the neural network architecture. Our proposed\nPhyLSTM provides less than 2% system response estimation error, converges in\nless than half iterations compared to a baseline Neural Network (NN), and\naccurately estimates the defined flexibility metrics. We include a detailed\nanalysis of the impact of training data size on the performance and\noptimization of our proposed models.",
    "descriptor": "",
    "authors": [
      "Manu Lahariya",
      "Farzaneh Karami",
      "Chris Develder",
      "Guillaume Crevecoeur"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.09353"
  },
  {
    "id": "arXiv:2205.09357",
    "title": "Continual Pre-Training Mitigates Forgetting in Language and Vision",
    "abstract": "Pre-trained models are nowadays a fundamental component of machine learning\nresearch. In continual learning, they are commonly used to initialize the model\nbefore training on the stream of non-stationary data. However, pre-training is\nrarely applied during continual learning. We formalize and investigate the\ncharacteristics of the continual pre-training scenario in both language and\nvision environments, where a model is continually pre-trained on a stream of\nincoming data and only later fine-tuned to different downstream tasks. We show\nthat continually pre-trained models are robust against catastrophic forgetting\nand we provide strong empirical evidence supporting the fact that\nself-supervised pre-training is more effective in retaining previous knowledge\nthan supervised protocols. Code is provided at\nhttps://github.com/AndreaCossu/continual-pretraining-nlp-vision .",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Andrea Cossu",
      "Tinne Tuytelaars",
      "Antonio Carta",
      "Lucia Passaro",
      "Vincenzo Lomonaco",
      "Davide Bacciu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09357"
  },
  {
    "id": "arXiv:2205.09360",
    "title": "Evaluating Subtitle Segmentation for End-to-end Generation Systems",
    "abstract": "Subtitles appear on screen as short pieces of text, segmented based on formal\nconstraints (length) and syntactic/semantic criteria. Subtitle segmentation can\nbe evaluated with sequence segmentation metrics against a human reference.\nHowever, standard segmentation metrics cannot be applied when systems generate\noutputs different than the reference, e.g. with end-to-end subtitling systems.\nIn this paper, we study ways to conduct reference-based evaluations of\nsegmentation accuracy irrespective of the textual content. We first conduct a\nsystematic analysis of existing metrics for evaluating subtitle segmentation.\nWe then introduce $Sigma$, a new Subtitle Segmentation Score derived from an\napproximate upper-bound of BLEU on segmentation boundaries, which allows us to\ndisentangle the effect of good segmentation from text quality. To compare\n$Sigma$ with existing metrics, we further propose a boundary projection method\nfrom imperfect hypotheses to the true reference. Results show that all metrics\nare able to reward high quality output but for similar outputs system ranking\ndepends on each metric's sensitivity to error type. Our thorough analyses\nsuggest $Sigma$ is a promising segmentation candidate but its reliability over\nother segmentation metrics remains to be validated through correlations with\nhuman judgements.",
    "descriptor": "\nComments: Accepted at LREC 2022\n",
    "authors": [
      "Alina Karakanta",
      "Fran\u00e7ois Buet",
      "Mauro Cettolo",
      "Fran\u00e7ois Yvon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09360"
  },
  {
    "id": "arXiv:2205.09362",
    "title": "Sparse Adversarial Attack in Multi-agent Reinforcement Learning",
    "abstract": "Cooperative multi-agent reinforcement learning (cMARL) has many real\napplications, but the policy trained by existing cMARL algorithms is not robust\nenough when deployed. There exist also many methods about adversarial attacks\non the RL system, which implies that the RL system can suffer from adversarial\nattacks, but most of them focused on single agent RL. In this paper, we propose\na \\textit{sparse adversarial attack} on cMARL systems. We use (MA)RL with\nregularization to train the attack policy. Our experiments show that the policy\ntrained by the current cMARL algorithm can obtain poor performance when only\none or a few agents in the team (e.g., 1 of 8 or 5 of 25) were attacked at a\nfew timesteps (e.g., attack 3 of total 40 timesteps).",
    "descriptor": "",
    "authors": [
      "Yizheng Hu",
      "Zhihua Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09362"
  },
  {
    "id": "arXiv:2205.09363",
    "title": "Plane Geometry Diagram Parsing",
    "abstract": "Geometry diagram parsing plays a key role in geometry problem solving,\nwherein the primitive extraction and relation parsing remain challenging due to\nthe complex layout and between-primitive relationship. In this paper, we\npropose a powerful diagram parser based on deep learning and graph reasoning.\nSpecifically, a modified instance segmentation method is proposed to extract\ngeometric primitives, and the graph neural network (GNN) is leveraged to\nrealize relation parsing and primitive classification incorporating geometric\nfeatures and prior knowledge. All the modules are integrated into an end-to-end\nmodel called PGDPNet to perform all the sub-tasks simultaneously. In addition,\nwe build a new large-scale geometry diagram dataset named PGDP5K with primitive\nlevel annotations. Experiments on PGDP5K and an existing dataset IMP-Geometry3K\nshow that our model outperforms state-of-the-art methods in four sub-tasks\nremarkably. Our code, dataset and appendix material are available at\nhttps://github.com/mingliangzhang2018/PGDP.",
    "descriptor": "\nComments: Accepted to IJCAI 2022\n",
    "authors": [
      "Ming-Liang Zhang",
      "Fei Yin",
      "Yi-Han Hao",
      "Cheng-Lin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09363"
  },
  {
    "id": "arXiv:2205.09370",
    "title": "TC-Driver: Trajectory Conditioned Driving for Robust Autonomous Racing  -- A Reinforcement Learning Approach",
    "abstract": "Autonomous racing is becoming popular for academic and industry researchers\nas a test for general autonomous driving by pushing perception, planning, and\ncontrol algorithms to their limits. While traditional control methods such as\nMPC are capable of generating an optimal control sequence at the edge of the\nvehicles physical controllability, these methods are sensitive to the accuracy\nof the modeling parameters. This paper presents TC-Driver, a RL approach for\nrobust control in autonomous racing. In particular, the TC-Driver agent is\nconditioned by a trajectory generated by any arbitrary traditional high-level\nplanner. The proposed TC-Driver addresses the tire parameter modeling\ninaccuracies by exploiting the heuristic nature of RL while leveraging the\nreliability of traditional planning methods in a hierarchical control\nstructure. We train the agent under varying tire conditions, allowing it to\ngeneralize to different model parameters, aiming to increase the racing\ncapabilities of the system in practice. The proposed RL method outperforms a\nnon-learning-based MPC with a 2.7 lower crash ratio in a model mismatch\nsetting, underlining robustness to parameter discrepancies. In addition, the\naverage RL inference duration is 0.25 ms compared to the average MPC solving\ntime of 11.5 ms, yielding a nearly 40-fold speedup, allowing for complex\ncontrol deployment in computationally constrained devices. Lastly, we show that\nthe frequently utilized end-to-end RL architecture, as a control policy\ndirectly learned from sensory input, is not well suited to model mismatch\nrobustness nor track generalization. Our realistic simulations show that\nTC-Driver achieves a 6.7 and 3-fold lower crash ratio under model mismatch and\ntrack generalization settings, while simultaneously achieving lower lap times\nthan an end-to-end approach, demonstrating the viability of TC-driver to robust\nautonomous racing.",
    "descriptor": "\nComments: 6 pages, 4 figures, 3 tables, ICRA, OPPORTUNITIES AND CHALLENGES WITH AUTONOMOUS RACING, IEEE\n",
    "authors": [
      "Edoardo Ghignone",
      "Nicolas Baumann",
      "Mike Boss",
      "Michele Magno"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.09370"
  },
  {
    "id": "arXiv:2205.09373",
    "title": "Diversity Matters: Fully Exploiting Depth Clues for Reliable Monocular  3D Object Detection",
    "abstract": "As an inherently ill-posed problem, depth estimation from single images is\nthe most challenging part of monocular 3D object detection (M3OD). Many\nexisting methods rely on preconceived assumptions to bridge the missing spatial\ninformation in monocular images, and predict a sole depth value for every\nobject of interest. However, these assumptions do not always hold in practical\napplications. To tackle this problem, we propose a depth solving system that\nfully explores the visual clues from the subtasks in M3OD and generates\nmultiple estimations for the depth of each target. Since the depth estimations\nrely on different assumptions in essence, they present diverse distributions.\nEven if some assumptions collapse, the estimations established on the remaining\nassumptions are still reliable. In addition, we develop a depth selection and\ncombination strategy. This strategy is able to remove abnormal estimations\ncaused by collapsed assumptions, and adaptively combine the remaining\nestimations into a single one. In this way, our depth solving system becomes\nmore precise and robust. Exploiting the clues from multiple subtasks of M3OD\nand without introducing any extra information, our method surpasses the current\nbest method by more than 20% relatively on the Moderate level of test split in\nthe KITTI 3D object detection benchmark, while still maintaining real-time\nefficiency.",
    "descriptor": "\nComments: This paper has been accepted as an oral presentation of CVPR2022\n",
    "authors": [
      "Zhuoling Li",
      "Zhan Qu",
      "Yang Zhou",
      "Jianzhuang Liu",
      "Haoqian Wang",
      "Lihui Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09373"
  },
  {
    "id": "arXiv:2205.09376",
    "title": "Multi-DNN Accelerators for Next-Generation AI Systems",
    "abstract": "As the use of AI-powered applications widens across multiple domains, so do\nincrease the computational demands. Primary driver of AI technology are the\ndeep neural networks (DNNs). When focusing either on cloud-based systems that\nserve multiple AI queries from different users each with their own DNN model,\nor on mobile robots and smartphones employing pipelines of various models or\nparallel DNNs for the concurrent processing of multi-modal data, the next\ngeneration of AI systems will have multi-DNN workloads at their core.\nLarge-scale deployment of AI services and integration across mobile and\nembedded systems require additional breakthroughs in the computer architecture\nfront, with processors that can maintain high performance as the number of DNNs\nincreases while meeting the quality-of-service requirements, giving rise to the\ntopic of multi-DNN accelerator design.",
    "descriptor": "\nComments: Accepted for publication at the IEEE Computer journal, 2022\n",
    "authors": [
      "Stylianos I. Venieris",
      "Christos-Savvas Bouganis",
      "Nicholas D. Lane"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09376"
  },
  {
    "id": "arXiv:2205.09377",
    "title": "Coexistence between Task- and Data-Oriented Communications: A Whittle's  Index Guided Multi-Agent Reinforcement Learning Approach",
    "abstract": "We investigate the coexistence of task-oriented and data-oriented\ncommunications in a IoT system that shares a group of channels, and study the\nscheduling problem to jointly optimize the weighted age of incorrect\ninformation (AoII) and throughput, which are the performance metrics of the two\ntypes of communications, respectively. This problem is formulated as a Markov\ndecision problem, which is difficult to solve due to the large discrete action\nspace and the time-varying action constraints induced by the stochastic\navailability of channels. By exploiting the intrinsic properties of this\nproblem and reformulating the reward function based on channel statistics, we\nfirst simplify the solution space, state space, and optimality criteria, and\nconvert it to an equivalent Markov game, for which the large discrete action\nspace issue is greatly relieved. Then, we propose a Whittle's index guided\nmulti-agent proximal policy optimization (WI-MAPPO) algorithm to solve the\nconsidered game, where the embedded Whittle's index module further shrinks the\naction space, and the proposed offline training algorithm extends the training\nkernel of conventional MAPPO to address the issue of time-varying constraints.\nFinally, numerical results validate that the proposed algorithm significantly\noutperforms state-of-the-art age of information (AoI) based algorithms under\nscenarios with insufficient channel resources.",
    "descriptor": "",
    "authors": [
      "Ran Li",
      "Chuan Huang",
      "Xiaoqi Qin",
      "Shengpei Jiang",
      "Nan Ma",
      "Shuguang Cui"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.09377"
  },
  {
    "id": "arXiv:2205.09378",
    "title": "Sum-Rate Optimal Relay Selection and Power Control in Multi-Hop Networks",
    "abstract": "In this paper, we focus on the achievable sum-rate optimization problem of a\nmulti-user, multi-hop relay network. We analyze the joint relay selection and\npower control in the presence of interference such that the achievable sum-rate\nis maximized. First, we evaluate the achievable sum-rate under five relay\nselection strategies when the transmit power is fixed. We show that the dynamic\nprogramming based max-min relay selection with the objective of maximizing the\nminimum signal-to-noise-ratio results in the highest achievable sum-rate gain\nfor larger networks. Next, we combine the relay selection problem using the\nmax-min relay selection and the power control problem using a tight lower bound\napproximation and propose a novel iterative algorithm, which maximizes the\nachievable sum-rate. We also provide a comprehensive comparison of the proposed\nalgorithm with respect to existing resource allocation techniques, and observe\nthat our proposed algorithm provides significant sum-rate gains. Finally, we\nprove that for the special case of two-user networks, binary power allocation\nis optimum for at least two transmitting nodes. Extensive numerical examples\nare provided to illustrate the accuracy of our results.",
    "descriptor": "",
    "authors": [
      "Shalanika Dayarathna",
      "Rajitha Senanayake",
      "Jamie Evans"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.09378"
  },
  {
    "id": "arXiv:2205.09379",
    "title": "GitRanking: A Ranking of GitHub Topics for Software Classification using  Active Sampling",
    "abstract": "GitHub is the world's largest host of source code, with more than 150M\nrepositories. However, most of these repositories are not labeled or\ninadequately so, making it harder for users to find relevant projects. There\nhave been various proposals for software application domain classification over\nthe past years. However, these approaches lack a well-defined taxonomy that is\nhierarchical, grounded in a knowledge base, and free of irrelevant terms. This\nwork proposes GitRanking, a framework for creating a classification ranked into\ndiscrete levels based on how general or specific their meaning is. We collected\n121K topics from GitHub and considered $60\\%$ of the most frequent ones for the\nranking. GitRanking 1) uses active sampling to ensure a minimal number of\nrequired annotations; and 2) links each topic to Wikidata, reducing ambiguities\nand improving the reusability of the taxonomy. Our results show that\ndevelopers, when annotating their projects, avoid using terms with a high\ndegree of specificity. This makes the finding and discovery of their projects\nmore challenging for other users. Furthermore, we show that GitRanking can\neffectively rank terms according to their general or specific meaning. This\nranking would be an essential asset for developers to build upon, allowing them\nto complement their annotations with more precise topics. Finally, we show that\nGitRanking is a dynamically extensible method: it can currently accept further\nterms to be ranked with a minimum number of annotations ($\\sim$ 15). This paper\nis the first collective attempt to build a ground-up taxonomy of software\ndomains.",
    "descriptor": "\nComments: 11 pages, 6 figures, 3 tables\n",
    "authors": [
      "Cezar Sas",
      "Andrea Capiluppi",
      "Claudio Di Sipio",
      "Juri Di Rocco",
      "Davide Di Ruscio"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09379"
  },
  {
    "id": "arXiv:2205.09383",
    "title": "Unconventional Visual Sensors for Autonomous Vehicles",
    "abstract": "Autonomous vehicles rely on perception systems to understand their\nsurroundings for further navigation missions. Cameras are essential for\nperception systems due to the advantages of object detection and recognition\nprovided by modern computer vision algorithms, comparing to other sensors, such\nas LiDARs and radars. However, limited by its inherent imaging principle, a\nstandard RGB camera may perform poorly in a variety of adverse scenarios,\nincluding but not limited to: low illumination, high contrast, bad weather such\nas fog/rain/snow, etc. Meanwhile, estimating the 3D information from the 2D\nimage detection is generally more difficult when compared to LiDARs or radars.\nSeveral new sensing technologies have emerged in recent years to address the\nlimitations of conventional RGB cameras. In this paper, we review the\nprinciples of four novel image sensors: infrared cameras, range-gated cameras,\npolarization cameras, and event cameras. Their comparative advantages, existing\nor potential applications, and corresponding data processing algorithms are all\npresented in a systematic manner. We expect that this study will assist\npractitioners in the autonomous driving society with new perspectives and\ninsights.",
    "descriptor": "",
    "authors": [
      "You Li",
      "Julien Moreau",
      "Javier Ibanez-Guzman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.09383"
  },
  {
    "id": "arXiv:2205.09386",
    "title": "Two-Winner Election Using Favorite-Candidate Voting Rule",
    "abstract": "We investigate two-winner election problem seeking to minimize the social\ncost. We are interested in strategy-proof mechanisms where each voter only\nreports a single candidate. In our model, candidates and voters are located in\nEuclidean space and candidates' locations are known to the mechanism. The\nquality of a mechanism is measured by its distortion, defined as the worst-case\nratio between the social cost achieved by the mechanism and the optimal one. We\nfind that the ratio between the maximum and minimum distances among every two\ncandidates plays a vital role in the distortion of mechanisms. When there are\nthree candidates, the problem is solved mainly by previous work. We mainly\nfocus on the problem with at least four candidates. When voters and candidates\nare embedded in 1-dimensional space, we establish several lower bounds of the\ndistortion. When voters and candidates are embedded in at least 3-dimensional\nspace, we give a tight bound of the distortion.",
    "descriptor": "",
    "authors": [
      "Zeyu Ren",
      "Zihe Wang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2205.09386"
  },
  {
    "id": "arXiv:2205.09388",
    "title": "Smart Material Implication Using Spin-Transfer Torque Magnetic Tunnel  Junctions for Logic-in-Memory Computing",
    "abstract": "Smart material implication (SIMPLY) logic has been recently proposed for the\ndesign of energy-efficient Logic-in-Memory (LIM) architectures based on\nnon-volatile resistive memory devices. The SIMPLY logic is enabled by adding a\ncomparator to the conventional IMPLY scheme. This allows performing a\npreliminary READ operation and hence the SET operation only in the case it is\nactually required. This work explores the SIMPLY logic scheme using nanoscale\nspin-transfer torque magnetic tunnel junction (STT-MTJ) devices. The\nperformance of the STT-MTJ based SIMPLY architecture is analyzed by varying the\nload resistor and applied voltages to implement both READ and SET operations,\nwhile also investigating the effect of temperature on circuit operation.\nObtained results show an existing tradeoff between error rate and energy\nconsumption, which can be effectively managed by properly setting the values of\nload resistor and applied voltages. In addition, our analysis proves that\ntracking the temperature dependence of the MTJ properties through a\nproportional to absolute temperature (PTAT) reference voltage at the input of\nthe comparator is beneficial to mitigate the reliability degradation under\ntemperature variations.",
    "descriptor": "",
    "authors": [
      "Raffaele De Rose",
      "Tommaso Zanotti",
      "Francesco Maria Puglisi",
      "Felice Crupi",
      "Paolo Pavan",
      "Marco Lanuzza"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.09388"
  },
  {
    "id": "arXiv:2205.09389",
    "title": "Simplifying Node Classification on Heterophilous Graphs with Compatible  Label Propagation",
    "abstract": "Graph Neural Networks (GNNs) have been predominant for graph learning tasks;\nhowever, recent studies showed that a well-known graph algorithm, Label\nPropagation (LP), combined with a shallow neural network can achieve comparable\nperformance to GNNs in semi-supervised node classification on graphs with high\nhomophily. In this paper, we show that this approach falls short on graphs with\nlow homophily, where nodes often connect to the nodes of the opposite classes.\nTo overcome this, we carefully design a combination of a base predictor with LP\nalgorithm that enjoys a closed-form solution as well as convergence guarantees.\nOur algorithm first learns the class compatibility matrix and then aggregates\nlabel predictions using LP algorithm weighted by class compatibilities. On a\nwide variety of benchmarks, we show that our approach achieves the leading\nperformance on graphs with various levels of homophily. Meanwhile, it has\norders of magnitude fewer parameters and requires less execution time.\nEmpirical evaluations demonstrate that simple adaptations of LP can be\ncompetitive in semi-supervised node classification in both homophily and\nheterophily regimes.",
    "descriptor": "",
    "authors": [
      "Zhiqiang Zhong",
      "Sergey Ivanov",
      "Jun Pang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.09389"
  },
  {
    "id": "arXiv:2205.09391",
    "title": "Transformers as Neural Augmentors: Class Conditional Sentence Generation  via Variational Bayes",
    "abstract": "Data augmentation methods for Natural Language Processing tasks are explored\nin recent years, however they are limited and it is hard to capture the\ndiversity on sentence level. Besides, it is not always possible to perform data\naugmentation on supervised tasks. To address those problems, we propose a\nneural data augmentation method, which is a combination of Conditional\nVariational Autoencoder and encoder-decoder Transformer model. While encoding\nand decoding the input sentence, our model captures the syntactic and semantic\nrepresentation of the input language with its class condition. Following the\ndevelopments in the past years on pre-trained language models, we train and\nevaluate our models on several benchmarks to strengthen the downstream tasks.\nWe compare our method with 3 different augmentation techniques. The presented\nresults show that, our model increases the performance of current models\ncompared to other data augmentation techniques with a small amount of\ncomputation power.",
    "descriptor": "",
    "authors": [
      "M. \u015eafak Bilici",
      "Mehmet Fatih Amasyali"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09391"
  },
  {
    "id": "arXiv:2205.09392",
    "title": "UIF: An Objective Quality Assessment for Underwater Image Enhancement",
    "abstract": "Due to complex and volatile lighting environment, underwater imaging can be\nreadily impaired by light scattering, warping, and noises. To improve the\nvisual quality, Underwater Image Enhancement (UIE) techniques have been widely\nstudied. Recent efforts have also been contributed to evaluate and compare the\nUIE performances with subjective and objective methods. However, the subjective\nevaluation is time-consuming and uneconomic for all images, while existing\nobjective methods have limited capabilities for the newly-developed UIE\napproaches based on deep learning. To fill this gap, we propose an Underwater\nImage Fidelity (UIF) metric for objective evaluation of enhanced underwater\nimages. By exploiting the statistical features of these images, we present to\nextract naturalness-related, sharpness-related, and structure-related features.\nAmong them, the naturalness-related and sharpness-related features evaluate\nvisual improvement of enhanced images; the structure-related feature indicates\nstructural similarity between images before and after UIE. Then, we employ\nsupport vector regression to fuse the above three features into a final UIF\nmetric. In addition, we have also established a large-scale UIE database with\nsubjective scores, namely Underwater Image Enhancement Database (UIED), which\nis utilized as a benchmark to compare all objective metrics. Experimental\nresults confirm that the proposed UIF outperforms a variety of underwater and\ngeneral-purpose image quality metrics.",
    "descriptor": "\nComments: This paper was submitted to ACMMM 2021\n",
    "authors": [
      "Yannan Zheng",
      "Weiling Chen",
      "Rongfu Lin",
      "Tiesong Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.09392"
  },
  {
    "id": "arXiv:2205.09393",
    "title": "Two-Step Question Retrieval for Open-Domain QA",
    "abstract": "The retriever-reader pipeline has shown promising performance in open-domain\nQA but suffers from a very slow inference speed. Recently proposed question\nretrieval models tackle this problem by indexing question-answer pairs and\nsearching for similar questions. These models have shown a significant increase\nin inference speed, but at the cost of lower QA performance compared to the\nretriever-reader models. This paper proposes a two-step question retrieval\nmodel, SQuID (Sequential Question-Indexed Dense retrieval) and distant\nsupervision for training. SQuID uses two bi-encoders for question retrieval.\nThe first-step retriever selects top-k similar questions, and the second-step\nretriever finds the most similar question from the top-k questions. We evaluate\nthe performance and the computational efficiency of SQuID. The results show\nthat SQuID significantly increases the performance of existing question\nretrieval models with a negligible loss on inference speed.",
    "descriptor": "\nComments: ACL2022-Findings\n",
    "authors": [
      "Yeon Seonwoo",
      "Juhee Son",
      "Jiho Jin",
      "Sang-Woo Lee",
      "Ji-Hoon Kim",
      "Jung-Woo Ha",
      "Alice Oh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09393"
  },
  {
    "id": "arXiv:2205.09394",
    "title": "AutoFAS: Automatic Feature and Architecture Selection for Pre-Ranking  System",
    "abstract": "Industrial search and recommendation systems mostly follow the classic\nmulti-stage information retrieval paradigm: matching, pre-ranking, ranking, and\nre-ranking stages. To account for system efficiency, simple vector-product\nbased models are commonly deployed in the pre-ranking stage. Recent works\nconsider distilling the high knowledge of large ranking models to small\npre-ranking models for better effectiveness. However, two major challenges in\npre-ranking system still exist: (i) without explicitly modeling the performance\ngain versus computation cost, the predefined latency constraint in the\npre-ranking stage inevitably leads to suboptimal solutions; (ii) transferring\nthe ranking teacher's knowledge to a pre-ranking student with a predetermined\nhandcrafted architecture still suffers from the loss of model performance. In\nthis work, a novel framework AutoFAS is proposed which jointly optimizes the\nefficiency and effectiveness of the pre-ranking model: (i) AutoFAS for the\nfirst time simultaneously selects the most valuable features and network\narchitectures using Neural Architecture Search (NAS) technique; (ii) equipped\nwith ranking model guided reward during NAS procedure, AutoFAS can select the\nbest pre-ranking architecture for a given ranking teacher without any\ncomputation overhead. Experimental results in our real world search system show\nAutoFAS consistently outperforms the previous state-of-the-art (SOTA)\napproaches at a lower computing cost. Notably, our model has been adopted in\nthe pre-ranking module in the search system of Meituan, bringing significant\nimprovements.",
    "descriptor": "",
    "authors": [
      "Xiang Li",
      "Xiaojiang Zhou",
      "Yao Xiao",
      "Peihao Huang",
      "Dayao Chen",
      "Sheng Chen",
      "Yunsen Xian"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.09394"
  },
  {
    "id": "arXiv:2205.09402",
    "title": "Predictive Maintenance using Machine Learning",
    "abstract": "Predictive maintenance (PdM) is a concept, which is implemented to\neffectively manage maintenance plans of the assets by predicting their failures\nwith data driven techniques. In these scenarios, data is collected over a\ncertain period of time to monitor the state of equipment. The objective is to\nfind some correlations and patterns that can help predict and ultimately\nprevent failures. Equipment in manufacturing industry are often utilized\nwithout a planned maintenance approach. Such practise frequently results in\nunexpected downtime, owing to certain unexpected failures. In scheduled\nmaintenance, the condition of the manufacturing equipment is checked after\nfixed time interval and if any fault occurs, the component is replaced to avoid\nunexpected equipment stoppages. On the flip side, this leads to increase in\ntime for which machine is non-functioning and cost of carrying out the\nmaintenance. The emergence of Industry 4.0 and smart systems have led to\nincreasing emphasis on predictive maintenance (PdM) strategies that can reduce\nthe cost of downtime and increase the availability (utilization rate) of\nmanufacturing equipment. PdM also has the potential to bring about new\nsustainable practices in manufacturing by fully utilizing the useful lives of\ncomponents.",
    "descriptor": "",
    "authors": [
      "Archit P. Kane",
      "Ashutosh S. Kore",
      "Advait N. Khandale",
      "Sarish S. Nigade",
      "Pranjali P. Joshi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09402"
  },
  {
    "id": "arXiv:2205.09403",
    "title": "On Natural Language User Profiles for Transparent and Scrutable  Recommendation",
    "abstract": "Natural interaction with recommendation and personalized search systems has\nreceived tremendous attention in recent years. We focus on the challenge of\nsupporting people's understanding and control of these systems and explore a\nfundamentally new way of thinking about representation of knowledge in\nrecommendation and personalization systems. Specifically, we argue that it may\nbe both desirable and possible for algorithms that use natural language\nrepresentations of users' preferences to be developed. We make the case that\nthis could provide significantly greater transparency, as well as affordances\nfor practical actionable interrogation of, and control over, recommendations.\nMoreover, we argue that such an approach, if successfully applied, may enable a\nmajor step towards systems that rely less on noisy implicit observations while\nincreasing portability of knowledge of one's interests.",
    "descriptor": "\nComments: Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '22), 2022\n",
    "authors": [
      "Filip Radlinski",
      "Krisztian Balog",
      "Fernando Diaz",
      "Lucas Dixon",
      "Ben Wedin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.09403"
  },
  {
    "id": "arXiv:2205.09404",
    "title": "Binary completely reachable automata",
    "abstract": "We characterize complete deterministic finite automata with two input letters\nin which every non-empty set of states occurs as the image of the whole state\nset under the action of a suitable input word. The characterization leads to a\npolynomial-time algorithm for recognizing this class of automata.",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "David Casas",
      "Mikhail V. Volkov"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2205.09404"
  },
  {
    "id": "arXiv:2205.09411",
    "title": "Geometric multigrid method for solving Poisson's equation on octree  grids with irregular boundaries",
    "abstract": "A method is presented to include irregular domain boundaries in a geometric\nmultigrid solver. Dirichlet boundary conditions can be imposed on an irregular\nboundary defined by a level set function. Our implementation employs\nquadtree/octree grids with adaptive refinement, a cell-centered discretization\nand pointwise smoothing. Boundary locations are determined at a subgrid\nresolution by performing line searches. For grid blocks near the interface,\ncustom operator stencils are stored that take the interface into account. For\ngrid block away from boundaries, a standard second-order accurate\ndiscretization is used. The convergence properties, robustness and\ncomputational cost of the method are illustrated with several test cases.",
    "descriptor": "",
    "authors": [
      "Jannis Teunissen",
      "Francesca Schiavello"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.09411"
  },
  {
    "id": "arXiv:2205.09415",
    "title": "On Efficiently Partitioning a Topic in Apache Kafka",
    "abstract": "Apache Kafka addresses the general problem of delivering extreme high volume\nevent data to diverse consumers via a publish-subscribe messaging system. It\nuses partitions to scale a topic across many brokers for producers to write\ndata in parallel, and also to facilitate parallel reading of consumers. Even\nthough Apache Kafka provides some out of the box optimizations, it does not\nstrictly define how each topic shall be efficiently distributed into\npartitions. The well-formulated fine-tuning that is needed in order to improve\nan Apache Kafka cluster performance is still an open research problem. In this\npaper, we first model the Apache Kafka topic partitioning process for a given\ntopic. Then, given the set of brokers, constraints and application requirements\non throughput, OS load, replication latency and unavailability, we formulate\nthe optimization problem of finding how many partitions are needed and show\nthat it is computationally intractable, being an integer program. Furthermore,\nwe propose two simple, yet efficient heuristics to solve the problem: the first\ntries to minimize and the second to maximize the number of brokers used in the\ncluster. Finally, we evaluate its performance via large-scale simulations,\nconsidering as benchmarks some Apache Kafka cluster configuration\nrecommendations provided by Microsoft and Confluent. We demonstrate that,\nunlike the recommendations, the proposed heuristics respect the hard\nconstraints on replication latency and perform better w.r.t. unavailability\ntime and OS load, using the system resources in a more prudent way.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. This work was funded by the European Union's Horizon 2020 research and innovation programme MARVEL under grant agreement No 957337\n",
    "authors": [
      "Theofanis P. Raptis",
      "Andrea Passarella"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.09415"
  },
  {
    "id": "arXiv:2205.09416",
    "title": "A Weakly-Supervised Iterative Graph-Based Approach to Retrieve COVID-19  Misinformation Topics",
    "abstract": "The COVID-19 pandemic has been accompanied by an `infodemic' -- of accurate\nand inaccurate health information across social media. Detecting misinformation\namidst dynamically changing information landscape is challenging; identifying\nrelevant keywords and posts is arduous due to the large amount of human effort\nrequired to inspect the content and sources of posts. We aim to reduce the\nresource cost of this process by introducing a weakly-supervised iterative\ngraph-based approach to detect keywords, topics, and themes related to\nmisinformation, with a focus on COVID-19. Our approach can successfully detect\nspecific topics from general misinformation-related seed words in a few seed\ntexts. Our approach utilizes the BERT-based Word Graph Search (BWGS) algorithm\nthat builds on context-based neural network embeddings for retrieving\nmisinformation-related posts. We utilize Latent Dirichlet Allocation (LDA)\ntopic modeling for obtaining misinformation-related themes from the texts\nreturned by BWGS. Furthermore, we propose the BERT-based Multi-directional Word\nGraph Search (BMDWGS) algorithm that utilizes greater starting context\ninformation for misinformation extraction. In addition to a qualitative\nanalysis of our approach, our quantitative analyses show that BWGS and BMDWGS\nare effective in extracting misinformation-related content compared to common\nbaselines in low data resource settings. Extracting such content is useful for\nuncovering prevalent misconceptions and concerns and for facilitating precision\npublic health messaging campaigns to improve health behaviors.",
    "descriptor": "\nComments: accepted at CySoc2022\n",
    "authors": [
      "Harry Wang",
      "Sharath Chandra Guntuku"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.09416"
  },
  {
    "id": "arXiv:2205.09418",
    "title": "Leveraging Dynamic Objects for Relative Localization COrrection in a  Connected Autonomous Vehicle Network",
    "abstract": "High-accurate localization is crucial for the safety and reliability of\nautonomous driving, especially for the information fusion of collective\nperception that aims to further improve road safety by sharing information in a\ncommunication network of ConnectedAutonomous Vehicles (CAV). In this scenario,\nsmall localization errors can impose additional difficulty on fusing the\ninformation from different CAVs. In this paper, we propose a RANSAC-based\n(RANdom SAmple Consensus) method to correct the relative localization errors\nbetween two CAVs in order to ease the information fusion among the CAVs.\nDifferent from previous LiDAR-based localization algorithms that only take the\nstatic environmental information into consideration, this method also leverages\nthe dynamic objects for localization thanks to the real-time data sharing\nbetween CAVs. Specifically, in addition to the static objects like poles,\nfences, and facades, the object centers of the detected dynamic vehicles are\nalso used as keypoints for the matching of two point sets. The experiments on\nthe synthetic dataset COMAP show that the proposed method can greatly decrease\nthe relative localization error between two CAVs to less than 20cmas far as\nthere are enough vehicles and poles are correctly detected by bothCAVs.\nBesides, our proposed method is also highly efficient in runtime and can be\nused in real-time scenarios of autonomous driving.",
    "descriptor": "\nComments: ISPRS congress 2022\n",
    "authors": [
      "Yunshuang Yuan",
      "Monika Sester"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.09418"
  },
  {
    "id": "arXiv:2205.09420",
    "title": "Multicast Scheduling for Multi-Message over Multi-Channel: A  Permutation-based Wolpertinger Deep Reinforcement Learning Method",
    "abstract": "Multicasting is an efficient technique to simultaneously transmit common\nmessages from the base station (BS) to multiple mobile users (MUs). The\nmulticast scheduling problem for multiple messages over multiple channels,\nwhich jointly minimizes the energy consumption of the BS and the latency of\nserving asynchronized requests from the MUs, is formulated as an\ninfinite-horizon Markov decision process (MDP) with large discrete action space\nand multiple time-varying constraints, which has not been efficiently addressed\nin the literatures. By studying the intrinsic features of this MDP under\nstationary policies and refining the reward function, we first simplify it to\nan equivalent form with a much smaller state space. Then, we propose a modified\ndeep reinforcement learning (DRL) algorithm, namely the permutation-based\nWolpertinger deep deterministic policy gradient (PW-DDPG), to solve the\nsimplified problem. Specifically, PW-DDPG utilizes a permutation-based action\nembedding module to address the large discrete action space issue and a\nfeasible exploration module to deal with the time-varying constraints.\nMoreover, as a benchmark, an upper bound of the considered MDP is derived by\nsolving an integer programming problem. Numerical results validate that the\nproposed algorithm achieves close performance to the derived benchmark.",
    "descriptor": "",
    "authors": [
      "Ran Li",
      "Chuan Huang",
      "Han Zhang",
      "Shengpei Jiang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.09420"
  },
  {
    "id": "arXiv:2205.09422",
    "title": "Inferring extended summary causal graphs from observational time series",
    "abstract": "This study addresses the problem of learning an extended summary causal graph\non time series. The algorithms we propose fit within the well-known\nconstraint-based framework for causal discovery and make use of\ninformation-theoretic measures to determine (in)dependencies between time\nseries. We first introduce generalizations of the causation entropy measure to\nany lagged or instantaneous relations, prior to using this measure to construct\nextended summary causal graphs by adapting two well-known algorithms, namely PC\nand FCI. The behavior of our methods is illustrated through several experiments\nrun on simulated and real datasets.",
    "descriptor": "",
    "authors": [
      "Charles K. Assaad",
      "Emilie Devijver",
      "Eric Gaussier"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.09422"
  },
  {
    "id": "arXiv:2205.09428",
    "title": "Which bugs are missed in code reviews: An empirical study on SmartSHARK  dataset",
    "abstract": "In pull-based development systems, code reviews and pull request comments\nplay important roles in improving code quality. In such systems, reviewers\nattempt to carefully check a piece of code by different unit tests.\nUnfortunately, sometimes they miss bugs in their review of pull requests, which\nlead to quality degradations of the systems. In other words, disastrous\nconsequences occur when bugs are observed after merging the pull requests. The\nlack of a concrete understanding of these bugs led us to investigate and\ncategorize them. In this research, we try to identify missed bugs in pull\nrequests of SmartSHARK dataset projects. Our contribution is twofold. First, we\nhypothesized merged pull requests that have code reviews, code review comments,\nor pull request comments after merging, may have missed bugs after the code\nreview. We considered these merged pull requests as candidate pull requests\nhaving missed bugs. Based on our assumption, we obtained 3,261 candidate pull\nrequests from 77 open-source GitHub projects. After two rounds of restrictive\nmanual analysis, we found 187 bugs missed in 173 pull requests. In the first\nstep, we found 224 buggy pull requests containing missed bugs after merging the\npull requests. Secondly, we defined and finalized a taxonomy that is\nappropriate for the bugs that we found and then found the distribution of bug\ncategories after analysing those pull requests all over again. The categories\nof missed bugs in pull requests and their distributions are: semantic (51.34%),\nbuild (15.5%), analysis checks (9.09%), compatibility (7.49%), concurrency\n(4.28%), configuration (4.28%), GUI (2.14%), API (2.14%), security (2.14%), and\nmemory (1.6%).",
    "descriptor": "\nComments: 5 pages, 3 figures. This study has been accepted for publication at: The 19th International Conference on Mining Software Repositories (MSR 2022)\n",
    "authors": [
      "F. Khoshnoud",
      "A. Rezaei Nasab",
      "Z. Toudeji",
      "A. Sami"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.09428"
  },
  {
    "id": "arXiv:2205.09430",
    "title": "Action Conditioned Tactile Prediction: a case study on slip prediction",
    "abstract": "Tactile predictive models can be useful across several robotic manipulation\ntasks, e.g. robotic pushing, robotic grasping, slip avoidance, and in-hand\nmanipulation. However, available tactile prediction models are mostly studied\nfor image-based tactile sensors and there is no comparison study indicating the\nbest performing models. In this paper, we presented two novel data-driven\naction-conditioned models for predicting tactile signals during real-world\nphysical robot interaction tasks (1) action condition tactile prediction and\n(2) action conditioned tactile-video prediction models. We use a magnetic-based\ntactile sensor that is challenging to analyse and test state-of-the-art\npredictive models and the only existing bespoke tactile prediction model. We\ncompare the performance of these models with those of our proposed models. We\nperform the comparison study using our novel tactile enabled dataset containing\n51,000 tactile frames of a real-world robotic manipulation task with 11\nflat-surfaced household objects. Our experimental results demonstrate the\nsuperiority of our proposed tactile prediction models in terms of qualitative,\nquantitative and slip prediction scores.",
    "descriptor": "\nComments: To appear in the proceeding of Robotics: Science and Systems (RSS 2022)\n",
    "authors": [
      "Willow Mandil",
      "Kiyanoush Nazari",
      "Amir Ghalamzan E"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09430"
  },
  {
    "id": "arXiv:2205.09433",
    "title": "CAMEO: Curiosity Augmented Metropolis for Exploratory Optimal Policies",
    "abstract": "Reinforcement Learning has drawn huge interest as a tool for solving optimal\ncontrol problems. Solving a given problem (task or environment) involves\nconverging towards an optimal policy. However, there might exist multiple\noptimal policies that can dramatically differ in their behaviour; for example,\nsome may be faster than the others but at the expense of greater risk. We\nconsider and study a distribution of optimal policies. We design a\ncuriosity-augmented Metropolis algorithm (CAMEO), such that we can sample\noptimal policies, and such that these policies effectively adopt diverse\nbehaviours, since this implies greater coverage of the different possible\noptimal policies. In experimental simulations we show that CAMEO indeed obtains\npolicies that all solve classic control problems, and even in the challenging\ncase of environments that provide sparse rewards. We further show that the\ndifferent policies we sample present different risk profiles, corresponding to\ninteresting practical applications in interpretability, and represents a first\nstep towards learning the distribution of optimal policies itself.",
    "descriptor": "\nComments: Published on EUSIPCO 2022 conference\n",
    "authors": [
      "Mohamed Alami Chehboune",
      "Fernando Llorente",
      "Rim Kaddah",
      "Luca Martino",
      "Jesse Read"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09433"
  },
  {
    "id": "arXiv:2205.09438",
    "title": "Gold-standard solutions to the Schr\u00f6dinger equation using deep  learning: How much physics do we need?",
    "abstract": "Finding accurate solutions to the Schr\\\"odinger equation is the key unsolved\nchallenge of computational chemistry. Given its importance for the development\nof new chemical compounds, decades of research have been dedicated to this\nproblem, but due to the large dimensionality even the best available methods do\nnot yet reach the desired accuracy. Recently the combination of deep learning\nwith Monte Carlo methods has emerged as a promising way to obtain highly\naccurate energies and moderate scaling of computational cost. In this paper we\nsignificantly contribute towards this goal by introducing a novel deep-learning\narchitecture that achieves 40-70% lower energy error at 8x lower computational\ncost compared to previous approaches. Using our method we establish a new\nbenchmark by calculating the most accurate variational ground state energies\never published for a number of different atoms and molecules. We systematically\nbreak down and measure our improvements, focusing in particular on the effect\nof increasing physical prior knowledge. We surprisingly find that increasing\nthe prior knowledge given to the architecture can actually decrease accuracy.",
    "descriptor": "\nComments: 10 pages + apppendix, 7 figures\n",
    "authors": [
      "Leon Gerard",
      "Michael Scherbela",
      "Philipp Marquetand",
      "Philipp Grohs"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.09438"
  },
  {
    "id": "arXiv:2205.09442",
    "title": "Oracle-MNIST: a Realistic Image Dataset for Benchmarking Machine  Learning Algorithms",
    "abstract": "We introduce the Oracle-MNIST dataset, comprising of 28$\\times $28 grayscale\nimages of 30,222 ancient characters from 10 categories, for benchmarking\npattern classification, with particular challenges on image noise and\ndistortion. The training set totally consists of 27,222 images, and the test\nset contains 300 images per class. Oracle-MNIST shares the same data format\nwith the original MNIST dataset, allowing for direct compatibility with all\nexisting classifiers and systems, but it constitutes a more challenging\nclassification task than MNIST. The images of ancient characters suffer from 1)\nextremely serious and unique noises caused by three-thousand years of burial\nand aging and 2) dramatically variant writing styles by ancient Chinese, which\nall make them realistic for machine learning research. The dataset is freely\navailable at https://github.com/wm-bupt/oracle-mnist.",
    "descriptor": "",
    "authors": [
      "Mei Wang",
      "Weihong Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09442"
  },
  {
    "id": "arXiv:2205.09443",
    "title": "PYSKL: Towards Good Practices for Skeleton Action Recognition",
    "abstract": "We present PYSKL: an open-source toolbox for skeleton-based action\nrecognition based on PyTorch. The toolbox supports a wide variety of skeleton\naction recognition algorithms, including approaches based on GCN and CNN. In\ncontrast to existing open-source skeleton action recognition projects that\ninclude only one or two algorithms, PYSKL implements six different algorithms\nunder a unified framework with both the latest and original good practices to\nease the comparison of efficacy and efficiency. We also provide an original\nGCN-based skeleton action recognition model named ST-GCN++, which achieves\ncompetitive recognition performance without any complicated attention schemes,\nserving as a strong baseline. Meanwhile, PYSKL supports the training and\ntesting of nine skeleton-based action recognition benchmarks and achieves\nstate-of-the-art recognition performance on eight of them. To facilitate future\nresearch on skeleton action recognition, we also provide a large number of\ntrained models and detailed benchmark results to give some insights. PYSKL is\nreleased at https://github.com/kennymckormick/pyskl and is actively maintained.\nWe will update this report when we add new features or benchmarks. The current\nversion corresponds to PYSKL v0.2.",
    "descriptor": "\nComments: Tech Report\n",
    "authors": [
      "Haodong Duan",
      "Jiaqi Wang",
      "Kai Chen",
      "Dahua Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09443"
  },
  {
    "id": "arXiv:2205.09445",
    "title": "Cross-Enhancement Transformer for Action Segmentation",
    "abstract": "Temporal convolutions have been the paradigm of choice in action\nsegmentation, which enhances long-term receptive fields by increasing\nconvolution layers. However, high layers cause the loss of local information\nnecessary for frame recognition. To solve the above problem, a novel\nencoder-decoder structure is proposed in this paper, called Cross-Enhancement\nTransformer. Our approach can be effective learning of temporal structure\nrepresentation with interactive self-attention mechanism. Concatenated each\nlayer convolutional feature maps in encoder with a set of features in decoder\nproduced via self-attention. Therefore, local and global information are used\nin a series of frame actions simultaneously. In addition, a new loss function\nis proposed to enhance the training process that penalizes over-segmentation\nerrors. Experiments show that our framework performs state-of-the-art on three\nchallenging datasets: 50Salads, Georgia Tech Egocentric Activities and the\nBreakfast dataset.",
    "descriptor": "",
    "authors": [
      "Jiahui Wang",
      "Zhenyou Wang",
      "Shanna Zhuang",
      "Hui Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09445"
  },
  {
    "id": "arXiv:2205.09448",
    "title": "Image Augmentation Based Momentum Memory Intrinsic Reward for Sparse  Reward Visual Scenes",
    "abstract": "Many scenes in real life can be abstracted to the sparse reward visual\nscenes, where it is difficult for an agent to tackle the task under the\ncondition of only accepting images and sparse rewards. We propose to decompose\nthis problem into two sub-problems: the visual representation and the sparse\nreward. To address them, a novel framework IAMMIR combining the self-supervised\nrepresentation learning with the intrinsic motivation is presented. For visual\nrepresentation, a representation driven by a combination of the imageaugmented\nforward dynamics and the reward is acquired. For sparse rewards, a new type of\nintrinsic reward is designed, the Momentum Memory Intrinsic Reward (MMIR). It\nutilizes the difference of the outputs from the current model (online network)\nand the historical model (target network) to present the agent's state\nfamiliarity. Our method is evaluated on the visual navigation task with sparse\nrewards in Vizdoom. Experiments demonstrate that our method achieves the state\nof the art performance in sample efficiency, at least 2 times faster than the\nexisting methods reaching 100% success rate.",
    "descriptor": "",
    "authors": [
      "Zheng Fang",
      "Biao Zhao",
      "Guizhong Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09448"
  },
  {
    "id": "arXiv:2205.09452",
    "title": "Learning-based AC-OPF Solvers on Realistic Network and Realistic Loads",
    "abstract": "Deep learning approaches for the Alternating Current-Optimal Power Flow\n(AC-OPF) problem are under active research in recent years. A common\nshortcoming in this area of research is the lack of a dataset that includes\nboth a realistic power network topology and the corresponding realistic loads.\nTo address this issue, we construct an AC-OPF formulation-ready dataset called\nTAS-97 that contains realistic network information and realistic bus loads from\nTasmania's electricity network. We found that the realistic loads in Tasmania\nare correlated between buses and they show signs of an underlying multivariate\nnormal distribution. Feasibility-optimized end-to-end deep neural network\nmodels are trained and tested on the constructed dataset. Trained on samples\nwith bus loads generated from a fitted multivariate normal distribution, our\nlearning-based AC-OPF solver achieves 0.13% cost optimality gap, 99.73%\nfeasibility rate, and 38.62 times of speedup on realistic testing samples when\ncompared to PYPOWER.",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Tsun Ho Aaron Cheung",
      "Min Zhou",
      "Minghua Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.09452"
  },
  {
    "id": "arXiv:2205.09453",
    "title": "Differential Privacy: What is all the noise about?",
    "abstract": "Differential Privacy (DP) is a formal definition of privacy that provides\nrigorous guarantees against risks of privacy breaches during data processing.\nIt makes no assumptions about the knowledge or computational power of\nadversaries, and provides an interpretable, quantifiable and composable\nformalism. DP has been actively researched during the last 15 years, but it is\nstill hard to master for many Machine Learning (ML)) practitioners. This paper\naims to provide an overview of the most important ideas, concepts and uses of\nDP in ML, with special focus on its intersection with Federated Learning (FL).",
    "descriptor": "\nComments: 27 pages, 7 figures\n",
    "authors": [
      "Roxana Danger"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09453"
  },
  {
    "id": "arXiv:2205.09456",
    "title": "Insights on Neural Representations for End-to-End Speech Recognition",
    "abstract": "End-to-end automatic speech recognition (ASR) models aim to learn a\ngeneralised speech representation. However, there are limited tools available\nto understand the internal functions and the effect of hierarchical\ndependencies within the model architecture. It is crucial to understand the\ncorrelations between the layer-wise representations, to derive insights on the\nrelationship between neural representations and performance.\nPrevious investigations of network similarities using correlation analysis\ntechniques have not been explored for End-to-End ASR models. This paper\nanalyses and explores the internal dynamics between layers during training with\nCNN, LSTM and Transformer based approaches using Canonical correlation analysis\n(CCA) and centered kernel alignment (CKA) for the experiments. It was found\nthat neural representations within CNN layers exhibit hierarchical correlation\ndependencies as layer depth increases but this is mostly limited to cases where\nneural representation correlates more closely. This behaviour is not observed\nin LSTM architecture, however there is a bottom-up pattern observed across the\ntraining process, while Transformer encoder layers exhibit irregular\ncoefficiency correlation as neural depth increases. Altogether, these results\nprovide new insights into the role that neural architectures have upon speech\nrecognition performance. More specifically, these techniques can be used as\nindicators to build better performing speech recognition models.",
    "descriptor": "\nComments: Submitted to Interspeech 2021\n",
    "authors": [
      "Anna Ollerenshaw",
      "Md Asif Jalal",
      "Thomas Hain"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.09456"
  },
  {
    "id": "arXiv:2205.09459",
    "title": "Neural Network Architecture Beyond Width and Depth",
    "abstract": "This paper proposes a new neural network architecture by introducing an\nadditional dimension called height beyond width and depth. Neural network\narchitectures with height, width, and depth as hyperparameters are called\nthree-dimensional architectures. It is shown that neural networks with\nthree-dimensional architectures are significantly more expressive than the ones\nwith two-dimensional architectures (those with only width and depth as\nhyperparameters), e.g., standard fully connected networks. The new network\narchitecture is constructed recursively via a nested structure, and hence we\ncall a network with the new architecture nested network (NestNet). A NestNet of\nheight $s$ is built with each hidden neuron activated by a NestNet of height\n$\\le s-1$. When $s=1$, a NestNet degenerates to a standard network with a\ntwo-dimensional architecture. It is proved by construction that height-$s$ ReLU\nNestNets with $\\mathcal{O}(n)$ parameters can approximate Lipschitz continuous\nfunctions on $[0,1]^d$ with an error $\\mathcal{O}(n^{-(s+1)/d})$, while the\noptimal approximation error of standard ReLU networks with $\\mathcal{O}(n)$\nparameters is $\\mathcal{O}(n^{-2/d})$. Furthermore, such a result is extended\nto generic continuous functions on $[0,1]^d$ with the approximation error\ncharacterized by the modulus of continuity. Finally, a numerical example is\nprovided to explore the advantages of the super approximation power of ReLU\nNestNets.",
    "descriptor": "",
    "authors": [
      "Zuowei Shen",
      "Haizhao Yang",
      "Shijun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.09459"
  },
  {
    "id": "arXiv:2205.09460",
    "title": "Why only Micro-F1? Class Weighting of Measures for Relation  Classification",
    "abstract": "Relation classification models are conventionally evaluated using only a\nsingle measure, e.g., micro-F1, macro-F1 or AUC. In this work, we analyze\nweighting schemes, such as micro and macro, for imbalanced datasets. We\nintroduce a framework for weighting schemes, where existing schemes are\nextremes, and two new intermediate schemes. We show that reporting results of\ndifferent weighting schemes better highlights strengths and weaknesses of a\nmodel.",
    "descriptor": "\nComments: NLP Power! The First Workshop on Efficient Benchmarking in NLP (ACL 2022)\n",
    "authors": [
      "David Harbecke",
      "Yuxuan Chen",
      "Leonhard Hennig",
      "Christoph Alt"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09460"
  },
  {
    "id": "arXiv:2205.09462",
    "title": "Personalized Interventions for Online Moderation",
    "abstract": "Current online moderation follows a one-size-fits-all approach, where each\nintervention is applied in the same way to all users. This naive approach is\nchallenged by established socio-behavioral theories and by recent empirical\nresults that showed the limited effectiveness of such interventions. We propose\na paradigm-shift in online moderation by moving towards a personalized and\nuser-centered approach. Our multidisciplinary vision combines state-of-the-art\ntheories and practices in diverse fields such as computer science, sociology\nand psychology, to design personalized moderation interventions (PMIs). In\noutlining the path leading to the next-generation of moderation interventions,\nwe also discuss the most prominent challenges introduced by such a disruptive\nchange.",
    "descriptor": "\nComments: The 33rd ACM Conference on Hypertext and Social Media (HT '22)\n",
    "authors": [
      "Stefano Cresci",
      "Amaury Trujillo",
      "Tiziano Fagni"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09462"
  },
  {
    "id": "arXiv:2205.09465",
    "title": "Parallel bi-objective evolutionary algorithms for scalable feature  subset selection via migration strategy under Spark",
    "abstract": "Feature subset selection (FSS) for classification is inherently a\nbi-objective optimization problem, where the task is to obtain a feature subset\nwhich yields the maximum possible area under the receiver operator\ncharacteristic curve (AUC) with minimum cardinality of the feature subset. In\ntodays world, a humungous amount of data is generated in all activities of\nhumans. To mine such voluminous data, which is often high-dimensional, there is\na need to develop parallel and scalable frameworks. In the first-of-its-kind\nstudy, we propose and develop an iterative MapReduce-based framework for\nbi-objective evolutionary algorithms (EAs) based wrappers under Apache spark\nwith the migration strategy. In order to accomplish this, we parallelized the\nnon-dominated sorting based algorithms namely non dominated sorting algorithm\n(NSGA-II), and non-dominated sorting particle swarm optimization (NSPSO), also\nthe decomposition-based algorithm, namely the multi-objective evolutionary\nalgorithm based on decomposition (MOEA-D), and named them P-NSGA-II-IS,\nP-NSPSO-IS, P-MOEA-D-IS, respectively. We proposed a modified MOEA-D by\nincorporating the non-dominated sorting principle while parallelizing it.\nThroughout the study, AUC is computed by logistic regression (LR). We test the\neffectiveness of the proposed methodology on various datasets. It is noteworthy\nthat the P-NSGA-II turns out to be statistically significant by being in the\ntop 2 positions on most datasets. We also reported the empirical attainment\nplots, speed up analysis, and mean AUC obtained by the most repeated feature\nsubset and the least cardinal feature subset with the highest AUC, and\ndiversity analysis using hypervolume.",
    "descriptor": "\nComments: 32 pages, 11 Tables, 8 figures\n",
    "authors": [
      "Yelleti Vivek",
      "Vadlamani Ravi",
      "P. Radha Krishna"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.09465"
  },
  {
    "id": "arXiv:2205.09470",
    "title": "Nebula-I: A General Framework for Collaboratively Training Deep Learning  Models on Low-Bandwidth Cloud Clusters",
    "abstract": "The ever-growing model size and scale of compute have attracted increasing\ninterests in training deep learning models over multiple nodes. However, when\nit comes to training on cloud clusters, especially across remote clusters, huge\nchallenges are faced. In this work, we introduce a general framework, Nebula-I,\nfor collaboratively training deep learning models over remote heterogeneous\nclusters, the connections between which are low-bandwidth wide area networks\n(WANs). We took natural language processing (NLP) as an example to show how\nNebula-I works in different training phases that include: a) pre-training a\nmultilingual language model using two remote clusters; and b) fine-tuning a\nmachine translation model using knowledge distilled from pre-trained models,\nwhich run through the most popular paradigm of recent deep learning. To balance\nthe accuracy and communication efficiency, in Nebula-I, parameter-efficient\ntraining strategies, hybrid parallel computing methods and adaptive\ncommunication acceleration techniques are jointly applied. Meanwhile, security\nstrategies are employed to guarantee the safety, reliability and privacy in\nintra-cluster computation and inter-cluster communication. Nebula-I is\nimplemented with the PaddlePaddle deep learning framework, which can support\ncollaborative training over heterogeneous hardware, e.g. GPU and NPU.\nExperiments demonstrate that the proposed framework could substantially\nmaximize the training efficiency while preserving satisfactory NLP performance.\nBy using Nebula-I, users can run large-scale training tasks over cloud clusters\nwith minimum developments, and the utility of existed large pre-trained models\ncould be further promoted. We also introduced new state-of-the-art results on\ncross-lingual natural language inference tasks, which are generated based upon\na novel learning framework and Nebula-I.",
    "descriptor": "\nComments: 20 pages, 10 figures, technical report\n",
    "authors": [
      "Yang Xiang",
      "Zhihua Wu",
      "Weibao Gong",
      "Siyu Ding",
      "Xianjie Mo",
      "Yuang Liu",
      "Shuohuan Wang",
      "Peng Liu",
      "Yongshuai Hou",
      "Long Li",
      "Bin Wang",
      "Shaohuai Shi",
      "Yaqian Han",
      "Yue Yu",
      "Ge Li",
      "Yu Sun",
      "Yanjun Ma",
      "Dianhai Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.09470"
  },
  {
    "id": "arXiv:2205.09479",
    "title": "Neural ODEs with Irregular and Noisy Data",
    "abstract": "Measurement noise is an integral part while collecting data of a physical\nprocess. Thus, noise removal is necessary to draw conclusions from these data,\nand it often becomes essential to construct dynamical models using these data.\nWe discuss a methodology to learn differential equation(s) using noisy and\nirregular sampled measurements. In our methodology, the main innovation can be\nseen in the integration of deep neural networks with the neural ordinary\ndifferential equations (ODEs) approach. Precisely, we aim at learning a neural\nnetwork that provides (approximately) an implicit representation of the data\nand an additional neural network that models the vector fields of the dependent\nvariables. We combine these two networks by constraining using neural ODEs. The\nproposed framework to learn a model describing the vector field is highly\neffective under noisy measurements. The approach can handle scenarios where\ndependent variables are not available at the same temporal grid. Moreover, a\nparticular structure, e.g., second-order with respect to time, can easily be\nincorporated. We demonstrate the effectiveness of the proposed method for\nlearning models using data obtained from various differential equations and\npresent a comparison with the neural ODE method that does not make any special\ntreatment to noise.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2109.11446\n",
    "authors": [
      "Pawan Goyal",
      "Peter Benner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.09479"
  },
  {
    "id": "arXiv:2205.09482",
    "title": "Scheduling of UAV-assisted Millimeter Wave Communications for High-Speed  Railway",
    "abstract": "To exploit richer spectrum resources for even better service quality,\nmillimeter wave (mmWave) communication has been considered for high-speed\nrailway (HSR) communication systems. In this paper, we focus on scheduling as\nmany flows as possible while satisfying their QoS requirements. Due to\ninterference, eavesdropping, or other problems, some flows may not be directly\ntransmitted from the track-side BS. In this paper, we propose an UAV-assisted\nscheduling scheme which utilizes a UAV to serve as relay for such flows. The\nproposed scheme also utilize two mmWave bands, one for the BS links and the\nother for the UAV links. The proposed algorithm aims to maximize the number of\nflows with their QoS requirements satisfied. Simulations demonstrate that the\nproposed scheme achieves a superior performance on the number of completed\nflows and the system throughput over two baseline schemes.",
    "descriptor": "\nComments: 11 pages, 7 figures, article\n",
    "authors": [
      "Yibing Wang",
      "Yong Niu",
      "Hao Wu",
      "Shiwen Mao",
      "Bo Ai",
      "Zhangdui Zhong",
      "Ning Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.09482"
  },
  {
    "id": "arXiv:2205.09485",
    "title": "A Boosting Algorithm for Positive-Unlabeled Learning",
    "abstract": "Positive-unlabeled (PU) learning deals with binary classification problems\nwhen only positive (P) and unlabeled (U) data are available. A lot of PU\nmethods based on linear models and neural networks have been proposed; however,\nthere still lacks study on how the theoretically sound boosting-style\nalgorithms could work with P and U data. Considering that in some scenarios\nwhen neural networks cannot perform as good as boosting algorithms even with\nfully-supervised data, we propose a novel boosting algorithm for PU learning:\nAda-PU, which compares against neural networks. Ada-PU follows the general\nprocedure of AdaBoost while two different distributions of P data are\nmaintained and updated. After a weak classifier is learned on the newly updated\ndistribution, the corresponding combining weight for the final ensemble is\nestimated using only PU data. We demonstrated that with a smaller set of base\nclassifiers, the proposed method is guaranteed to keep the theoretical\nproperties of boosting algorithm. In experiments, we showed that Ada-PU\noutperforms neural networks on benchmark PU datasets. We also study a\nreal-world dataset UNSW-NB15 in cyber security and demonstrated that Ada-PU has\nsuperior performance for malicious activities detection.",
    "descriptor": "\nComments: 34 pages, 16 figures\n",
    "authors": [
      "Yawen Zhao",
      "Mingzhe Zhang",
      "Chenhao Zhang",
      "Tony Chen",
      "Nan Ye",
      "Miao Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09485"
  },
  {
    "id": "arXiv:2205.09488",
    "title": "PSI Draft Specification",
    "abstract": "This document presents the draft specification for delivering machine\nlearning services over HTTP, developed as part of the Protocols and Structures\nfor Inference project, which concluded in 2013. It presents the motivation for\nproviding machine learning as a service, followed by a description of the\nessential and optional components of such a service.",
    "descriptor": "\nComments: Software specification for PSI machine learning web services. 42 pages, 2 figures\n",
    "authors": [
      "Mark Reid",
      "James Montgomery",
      "Barry Drake",
      "Avraham Ruderman"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.09488"
  },
  {
    "id": "arXiv:2205.09489",
    "title": "Spatial Autoregressive Coding for Graph Neural Recommendation",
    "abstract": "Graph embedding methods including traditional shallow models and deep Graph\nNeural Networks (GNNs) have led to promising applications in recommendation.\nNevertheless, shallow models especially random-walk-based algorithms fail to\nadequately exploit neighbor proximity in sampled subgraphs or sequences due to\ntheir optimization paradigm. GNN-based algorithms suffer from the insufficient\nutilization of high-order information and easily cause over-smoothing problems\nwhen stacking too much layers, which may deteriorate the recommendations of\nlow-degree (long-tail) items, limiting the expressiveness and scalability. In\nthis paper, we propose a novel framework SAC, namely Spatial Autoregressive\nCoding, to solve the above problems in a unified way. To adequately leverage\nneighbor proximity and high-order information, we design a novel spatial\nautoregressive paradigm. Specifically, we first randomly mask multi-hop\nneighbors and embed the target node by integrating all other surrounding\nneighbors with an explicit multi-hop attention. Then we reinforce the model to\nlearn a neighbor-predictive coding for the target node by contrasting the\ncoding and the masked neighbors' embedding, equipped with a new hard negative\nsampling strategy. To learn the minimal sufficient representation for the\ntarget-to-neighbor prediction task and remove the redundancy of neighbors, we\ndevise Neighbor Information Bottleneck by maximizing the mutual information\nbetween target predictive coding and the masked neighbors' embedding, and\nsimultaneously constraining those between the coding and surrounding neighbors'\nembedding. Experimental results on both public recommendation datasets and a\nreal scenario web-scale dataset Douyin-Friend-Recommendation demonstrate the\nsuperiority of SAC compared with state-of-the-art methods.",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Jiayi Zheng",
      "Ling Yang",
      "Heyuan Wang",
      "Cheng Yang",
      "Yinghong Li",
      "Xiaowei Hu",
      "Shenda Hong"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09489"
  },
  {
    "id": "arXiv:2205.09493",
    "title": "Dockerized Android: a container-based platform to build mobile Android  scenarios for Cyber Ranges",
    "abstract": "The best way to train people about security is through Cyber Ranges, i.e.,\nthe virtual platform used by cyber-security experts to learn new skills and\nattack vectors. In order to realize such virtual scenarios, container-based\nvirtualization is commonly adopted, as it provides several benefits in terms of\nperformance, resource usage, and portability. Unfortunately, the current\ngeneration of Cyber Ranges does not consider mobile devices, which nowadays are\nubiquitous in our daily lives. Such devices do often represent the very first\nentry point for hackers into target networks. It is thus important to make\navailable tools allowing to emulate mobile devices in a safe environment\nwithout incurring the risk of causing any damage in the real world. This work\naims to propose Dockerized Android, i.e., a framework that addresses the\nproblem of realizing vulnerable environments for mobile devices in the next\ngeneration of Cyber Ranges. We show the platform's design and implementation\nand show how it is possible to use the implemented features to realize complex\nvirtual mobile kill-chains scenarios.",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Daniele Capone",
      "Francesco Caturano",
      "Angelo Delicato",
      "Gaetano Perrone",
      "Simon Pietro Romano"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.09493"
  },
  {
    "id": "arXiv:2205.09495",
    "title": "Learning Feature Fusion for Unsupervised Domain Adaptive Person  Re-identification",
    "abstract": "Unsupervised domain adaptive (UDA) person re-identification (ReID) has gained\nincreasing attention for its effectiveness on the target domain without manual\nannotations. Most fine-tuning based UDA person ReID methods focus on encoding\nglobal features for pseudo labels generation, neglecting the local feature that\ncan provide for the fine-grained information. To handle this issue, we propose\na Learning Feature Fusion (LF2) framework for adaptively learning to fuse\nglobal and local features to obtain a more comprehensive fusion feature\nrepresentation. Specifically, we first pre-train our model within a source\ndomain, then fine-tune the model on unlabeled target domain based on the\nteacher-student training strategy. The average weighting teacher network is\ndesigned to encode global features, while the student network updating at each\niteration is responsible for fine-grained local features. By fusing these\nmulti-view features, multi-level clustering is adopted to generate diverse\npseudo labels. In particular, a learnable Fusion Module (FM) for giving\nprominence to fine-grained local information within the global feature is also\nproposed to avoid obscure learning of multiple pseudo labels. Experiments show\nthat our proposed LF2 framework outperforms the state-of-the-art with 73.5% mAP\nand 83.7% Rank1 on Market1501 to DukeMTMC-ReID, and achieves 83.2% mAP and\n92.8% Rank1 on DukeMTMC-ReID to Market1501.",
    "descriptor": "\nComments: Accepted by ICPR2022\n",
    "authors": [
      "Jin Ding",
      "Xue Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09495"
  },
  {
    "id": "arXiv:2205.09497",
    "title": "Psychiatric Scale Guided Risky Post Screening for Early Detection of  Depression",
    "abstract": "Depression is a prominent health challenge to the world, and early risk\ndetection (ERD) of depression from online posts can be a promising technique\nfor combating the threat. Early depression detection faces the challenge of\nefficiently tackling streaming data, balancing the tradeoff between timeliness,\naccuracy and explainability. To tackle these challenges, we propose a\npsychiatric scale guided risky post screening method that can capture risky\nposts related to the dimensions defined in clinical depression scales, and\nproviding interpretable diagnostic basis. A Hierarchical Attentional Network\nequipped with BERT (HAN-BERT) is proposed to further advance explainable\npredictions. For ERD, we propose an online algorithm based on an evolving queue\nof risky posts that can significantly reduce the number of model inferences to\nboost efficiency. Experiments show that our method outperforms the competitive\nfeature-based and neural models under conventional depression detection\nsettings, and achieves simultaneous improvement in both efficacy and efficiency\nfor ERD.",
    "descriptor": "\nComments: IJCAI 2022 AI for Good\n",
    "authors": [
      "Zhiling Zhang",
      "Siyuan Chen",
      "Mengyue Wu",
      "Kenny Q. Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09497"
  },
  {
    "id": "arXiv:2205.09501",
    "title": "SDS-200: A Swiss German Speech to Standard German Text Corpus",
    "abstract": "We present SDS-200, a corpus of Swiss German dialectal speech with Standard\nGerman text translations, annotated with dialect, age, and gender information\nof the speakers. The dataset allows for training speech translation, dialect\nrecognition, and speech synthesis systems, among others. The data was collected\nusing a web recording tool that is open to the public. Each participant was\ngiven a text in Standard German and asked to translate it to their Swiss German\ndialect before recording it. To increase the corpus quality, recordings were\nvalidated by other participants. The data consists of 200 hours of speech by\naround 4000 different speakers and covers a large part of the Swiss-German\ndialect landscape. We release SDS-200 alongside a baseline speech translation\nmodel, which achieves a word error rate (WER) of 30.3 and a BLEU score of 53.1\non the SDS-200 test set. Furthermore, we use SDS-200 to fine-tune a pre-trained\nXLS-R model, achieving 21.6 WER and 64.0 BLEU.",
    "descriptor": "",
    "authors": [
      "Michel Pl\u00fcss",
      "Manuela H\u00fcrlimann",
      "Marc Cuny",
      "Alla St\u00f6ckli",
      "Nikolaos Kapotis",
      "Julia Hartmann",
      "Malgorzata Anna Ulasik",
      "Christian Scheller",
      "Yanick Schraner",
      "Amit Jain",
      "Jan Deriu",
      "Mark Cieliebak",
      "Manfred Vogel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09501"
  },
  {
    "id": "arXiv:2205.09504",
    "title": "Automatic Generation of Complete Polynomial Interpolation Hardware  Design Space",
    "abstract": "Hardware implementations of complex functions regularly deploy piecewise\npolynomial approximations. This work determines the complete design space of\npiecewise polynomial approximations meeting a given accuracy specification.\nKnowledge of this design space determines the minimum number of regions\nrequired to approximate the function accurately enough and facilitates the\ngeneration of optimized hardware which is competitive against the state of the\nart. Targeting alternative hardware technologies simply requires a modified\ndecision procedure to explore the space.",
    "descriptor": "",
    "authors": [
      "Bryce Orloski",
      "Samuel Coward",
      "Theo Drane"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2205.09504"
  },
  {
    "id": "arXiv:2205.09511",
    "title": "The Impact of COVID-19 Pandemic on LGBTQ Online Communitie",
    "abstract": "The COVID-19 pandemic has disproportionately impacted the lives of\nminorities, such as members of the LGBTQ community (lesbian, gay, bisexual,\ntransgender, and queer) due to pre-existing social disadvantages and health\ndisparities. Although extensive research has been carried out on the impact of\nthe COVID-19 pandemic on different aspects of the general population's lives,\nfew studies are focused on the LGBTQ population. In this paper, we identify a\ngroup of Twitter users who self-disclose to belong to the LGBTQ community. We\ndevelop and evaluate two sets of machine learning classifiers using a\npre-pandemic and a during pandemic dataset to identify Twitter posts exhibiting\nminority stress, which is a unique pressure faced by the members of the LGBTQ\npopulation due to their sexual and gender identities. For this task, we collect\na set of 20,593,823 posts by 7,241 self-disclosed LGBTQ users and annotate a\nrandomly selected subset of 2800 posts. We demonstrate that our best\npre-pandemic and during pandemic models show strong and stable performance for\ndetecting posts that contain minority stress. We investigate the linguistic\ndifferences in minority stress posts across pre- and during-pandemic periods.\nWe find that anger words are strongly associated with minority stress during\nthe COVID-19 pandemic. We explore the impact of the pandemic on the emotional\nstates of the LGBTQ population by conducting controlled comparisons with the\ngeneral population. We adopt propensity score-based matching to perform a\ncausal analysis. The results show that the LBGTQ population have a greater\nincrease in the usage of cognitive words and worsened observable attribute in\nthe usage of positive emotion words than the group of the general population\nwith similar pre-pandemic behavioral attributes.",
    "descriptor": "\nComments: 11 pages, 9 figures\n",
    "authors": [
      "Yunhao Yuan",
      "Gaurav Verma",
      "Barbara Keller",
      "Talayeh Aledavood"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09511"
  },
  {
    "id": "arXiv:2205.09513",
    "title": "Federated Learning: Applications, Challenges and Future Scopes",
    "abstract": "Federated learning (FL) is a system in which a central aggregator coordinates\nthe efforts of multiple clients to solve machine learning problems. This\nsetting allows training data to be dispersed in order to protect privacy. The\npurpose of this paper is to provide an overview of FL systems with a focus on\nhealthcare. FL is evaluated here based on its frameworks, architectures, and\napplications. It is shown here that FL solves the preceding issues with a\nshared global deep learning (DL) model via a central aggregator server. This\npaper examines recent developments and provides a comprehensive list of\nunresolved issues, inspired by the rapid growth of FL research. In the context\nof FL, several privacy methods are described, including secure multiparty\ncomputation, homomorphic encryption, differential privacy, and stochastic\ngradient descent. Furthermore, a review of various FL classes, such as\nhorizontal and vertical FL and federated transfer learning, is provided. FL has\napplications in wireless communication, service recommendation, intelligent\nmedical diagnosis systems, and healthcare, all of which are discussed in this\npaper. We also present a thorough review of existing FL challenges, such as\nprivacy protection, communication cost, system heterogeneity, and unreliable\nmodel upload, followed by future research directions.",
    "descriptor": "\nComments: 28 pages, 2 figures\n",
    "authors": [
      "Subrato Bharati",
      "M. Rubaiyat Hossain Mondal",
      "Prajoy Podder",
      "V. B. Surya Prasath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.09513"
  },
  {
    "id": "arXiv:2205.09518",
    "title": "Enhancing the Transferability of Adversarial Examples via a Few Queries",
    "abstract": "Due to the vulnerability of deep neural networks, the black-box attack has\ndrawn great attention from the community. Though transferable priors decrease\nthe query number of the black-box query attacks in recent efforts, the average\nnumber of queries is still larger than 100, which is easily affected by the\nnumber of queries limit policy. In this work, we propose a novel method called\nquery prior-based method to enhance the family of fast gradient sign methods\nand improve their attack transferability by using a few queries. Specifically,\nfor the untargeted attack, we find that the successful attacked adversarial\nexamples prefer to be classified as the wrong categories with higher\nprobability by the victim model. Therefore, the weighted augmented\ncross-entropy loss is proposed to reduce the gradient angle between the\nsurrogate model and the victim model for enhancing the transferability of the\nadversarial examples. Theoretical analysis and extensive experiments\ndemonstrate that our method could significantly improve the transferability of\ngradient-based adversarial attacks on CIFAR10/100 and ImageNet and outperform\nthe black-box query attack with the same few queries.",
    "descriptor": "",
    "authors": [
      "Xiangyuan Yang",
      "Jie Lin",
      "Hanlin Zhang",
      "Xinyu Yang",
      "Peng Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09518"
  },
  {
    "id": "arXiv:2205.09519",
    "title": "Design and Mathematical Modelling of Inter Spike Interval of Temporal  Neuromorphic Encoder for Image Recognition",
    "abstract": "Neuromorphic computing systems emulate the electrophysiological behavior of\nthe biological nervous system using mixed-mode analog or digital VLSI circuits.\nThese systems show superior accuracy and power efficiency in carrying out\ncognitive tasks. The neural network architecture used in neuromorphic computing\nsystems is spiking neural networks (SNNs) analogous to the biological nervous\nsystem. SNN operates on spike trains as a function of time. A neuromorphic\nencoder converts sensory data into spike trains. In this paper, a low-power\nneuromorphic encoder for image processing is implemented. A mathematical model\nbetween pixels of an image and the inter-spike intervals is also formulated.\nWherein an exponential relationship between pixels and inter-spike intervals is\nobtained. Finally, the mathematical equation is validated with circuit\nsimulation.",
    "descriptor": "\nComments: 4 pages, 6 figures, one table, IEEE ICEE 2020 conference proceeding\n",
    "authors": [
      "Aadhitiya VS",
      "Jani Babu Shaik",
      "Sonal Singhal",
      "Siona Menezes Picardo",
      "Nilesh Goel"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.09519"
  },
  {
    "id": "arXiv:2205.09520",
    "title": "Dynamic SAFFRON: Disease Control Over Time Via Group Testing",
    "abstract": "We consider the dynamic infection spread model that is based on the discrete\nSIR model which assumes infections to be spread over time via infected and\nnon-isolated individuals. In our system, the main objective is not to minimize\nthe number of required tests to identify every infection, but instead, to\nutilize the available, given testing capacity $T$ at each time instance to\nefficiently control the infection spread. We introduce and study a novel\nperformance metric, which we coin as $\\epsilon$-disease control time. This\nmetric can be used to measure how fast a given algorithm can control the spread\nof a disease. We characterize the performance of dynamic individual testing\nalgorithm and introduce a novel dynamic SAFFRON based group testing algorithm.\nWe present theoretical results and implement the proposed algorithms to compare\ntheir performances.",
    "descriptor": "",
    "authors": [
      "Batuhan Arasli",
      "Sennur Ulukus"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Data Structures and Algorithms (cs.DS)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2205.09520"
  },
  {
    "id": "arXiv:2205.09522",
    "title": "Defending Against Adversarial Attacks by Energy Storage Facility",
    "abstract": "Adversarial attacks on data-driven algorithms applied in pow-er system will\nbe a new type of threat on grid security. Litera-ture has demonstrated the\nadversarial attack on deep-neural network can significantly misleading the load\nforecast of a power system. However, it is unclear how the new type of at-tack\nimpact on the operation of grid system. In this research, we manifest that the\nadversarial algorithm attack induces a significant cost-increase risk which\nwill be exacerbated by the growing penetration of intermittent renewable\nenergy. In Texas, a 5% adversarial attack can increase the total generation\ncost by 17% in a quarter, which account for around 20 million dollars. When\nwind-energy penetration increases to over 40%, the 5% adver-sarial attack will\ninflate the generation cost by 23%. Our re-search discovers a novel approach of\ndefending against the adversarial attack: investing on energy-storage system.\nAll current literature focuses on developing algorithm to defending against\nadversarial attack. We are the first research revealing the capability of using\nfacility in physical system to defending against the adversarial algorithm\nattack in a system of Internet of Thing, such as smart grid system.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1904.06606 by other authors\n",
    "authors": [
      "Jiawei Li",
      "Jianxiao Wang",
      "Lin Chen",
      "Yang Yu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.09522"
  },
  {
    "id": "arXiv:2205.09524",
    "title": "Security Analysis of DeFi: Vulnerabilities, Attacks and Advances",
    "abstract": "Decentralized finance (DeFi) in Ethereum is a financial ecosystem built on\nthe blockchain that has locked over 200 billion USD until April 2022. All\ntransaction information is transparent and open when transacting through the\nDeFi protocol, which has led to a series of attacks. Several studies have\nattempted to optimize it from both economic and technical perspectives.\nHowever, few works analyze the vulnerabilities and optimizations of the entire\nDeFi system. In this paper, we first systematically analyze vulnerabilities\nrelated to DeFi in Ethereum at several levels, then we investigate real-world\nattacks. Finally, we summarize the achievements of DeFi optimization and\nprovide some future directions.",
    "descriptor": "",
    "authors": [
      "Wenkai Li",
      "Jiuyang Bu",
      "Xiaoqi Li",
      "Xianyi Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.09524"
  },
  {
    "id": "arXiv:2205.09526",
    "title": "Simple Regularisation for Uncertainty-Aware Knowledge Distillation",
    "abstract": "Considering uncertainty estimation of modern neural networks (NNs) is one of\nthe most important steps towards deploying machine learning systems to\nmeaningful real-world applications such as in medicine, finance or autonomous\nsystems. At the moment, ensembles of different NNs constitute the\nstate-of-the-art in both accuracy and uncertainty estimation in different\ntasks. However, ensembles of NNs are unpractical under real-world constraints,\nsince their computation and memory consumption scale linearly with the size of\nthe ensemble, which increase their latency and deployment cost. In this work,\nwe examine a simple regularisation approach for distribution-free knowledge\ndistillation of ensemble of machine learning models into a single NN. The aim\nof the regularisation is to preserve the diversity, accuracy and uncertainty\nestimation characteristics of the original ensemble without any intricacies,\nsuch as fine-tuning. We demonstrate the generality of the approach on\ncombinations of toy data, SVHN/CIFAR-10, simple to complex NN architectures and\ndifferent tasks.",
    "descriptor": "\nComments: Accepted to the ICML 2022 Workshop on Distribution-Free Uncertainty Quantification. The code can be found at: this https URL\n",
    "authors": [
      "Martin Ferianc",
      "Miguel Rodrigues"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09526"
  },
  {
    "id": "arXiv:2205.09529",
    "title": "Mobility, Communication and Computation Aware Federated Learning for  Internet of Vehicles",
    "abstract": "While privacy concerns entice connected and automated vehicles to incorporate\non-board federated learning (FL) solutions, an integrated vehicle-to-everything\ncommunication with heterogeneous computation power aware learning platform is\nurgently necessary to make it a reality. Motivated by this, we propose a novel\nmobility, communication and computation aware online FL platform that uses\non-road vehicles as learning agents. Thanks to the advanced features of modern\nvehicles, the on-board sensors can collect data as vehicles travel along their\ntrajectories, while the on-board processors can train machine learning models\nusing the collected data. To take the high mobility of vehicles into account,\nwe consider the delay as a learning parameter and restrict it to be less than a\ntolerable threshold. To satisfy this threshold, the central server accepts\npartially trained models, the distributed roadside units (a) perform downlink\nmulticast beamforming to minimize global model distribution delay and (b)\nallocate optimal uplink radio resources to minimize local model offloading\ndelay, and the vehicle agents conduct heterogeneous local model training. Using\nreal-world vehicle trace datasets, we validate our FL solutions. Simulation\nshows that the proposed integrated FL platform is robust and outperforms\nbaseline models. With reasonable local training episodes, it can effectively\nsatisfy all constraints and deliver near ground truth multi-horizon velocity\nand vehicle-specific power predictions.",
    "descriptor": "\nComments: 9 pages, 12 figures\n",
    "authors": [
      "Md Ferdous Pervej",
      "Jianlin Guo",
      "Kyeong Jin Kim",
      "Kieran Parsons",
      "Philip Orlik",
      "Stefano Di Cairano",
      "Marcel Menner",
      "Karl Berntorp",
      "Yukimasa Nagai",
      "Huaiyu Dai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.09529"
  },
  {
    "id": "arXiv:2205.09534",
    "title": "IFTT-PIN: A PIN-Entry Method Leveraging the Self-Calibration Paradigm",
    "abstract": "IFTT-PIN is a self-calibrating version of the PIN-entry method introduced in\nRoth et al. (2004) [1]. In [1], digits are split into two sets and assigned a\ncolor respectively. To communicate their digit, users press the button with the\nsame color that is assigned to their digit, which can thus be identified by\nelimination after a few iterations. IFTT-PIN uses the same principle but does\nnot pre-assign colors to each button. Instead, users are free to choose which\nbutton to use for each color. The button-to-color mapping only exists in the\nuser's mind and is never directly communicated to the interface. In other\nwords, IFTT-PIN infers both the user's PIN and their preferred button-to-color\nmapping at the same time, a process called self-calibration. In this paper, we\npresent online interactive demonstrations of IFTT-PIN (available at\nhttps://github.com/jgrizou/IFTT-PIN), with and without self-calibration, and\nintroduce the key concepts and assumptions making self-calibration possible. We\nreview related work in the field of brain-computer interface and further\npropose self-calibration as a novel approach to protect users against shoulder\nsurfing attacks. Finally, we introduce a vault cracking challenge as a test of\nusability and security that was informally tested at our institute. With\nIFTT-PIN, we wish to demonstrate a new interactive experience where users can\ndecide actively and on-the-fly how to use an interface. The self-calibration\nparadigm might lead to novel opportunities for interaction in other\napplications or domains. We hope this work will inspire the community to invent\nthem.",
    "descriptor": "",
    "authors": [
      "Jonathan Grizou"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09534"
  },
  {
    "id": "arXiv:2205.09536",
    "title": "A Simple yet Effective Relation Information Guided Approach for Few-Shot  Relation Extraction",
    "abstract": "Few-Shot Relation Extraction aims at predicting the relation for a pair of\nentities in a sentence by training with a few labelled examples in each\nrelation. Some recent works have introduced relation information (i.e.,\nrelation labels or descriptions) to assist model learning based on Prototype\nNetwork. However, most of them constrain the prototypes of each relation class\nimplicitly with relation information, generally through designing complex\nnetwork structures, like generating hybrid features, combining with contrastive\nlearning or attention networks. We argue that relation information can be\nintroduced more explicitly and effectively into the model. Thus, this paper\nproposes a direct addition approach to introduce relation information.\nSpecifically, for each relation class, the relation representation is first\ngenerated by concatenating two views of relations (i.e., [CLS] token embedding\nand the mean value of embeddings of all tokens) and then directly added to the\noriginal prototype for both train and prediction. Experimental results on the\nbenchmark dataset FewRel 1.0 show significant improvements and achieve\ncomparable results to the state-of-the-art, which demonstrates the\neffectiveness of our proposed approach. Besides, further analyses verify that\nthe direct addition is a much more effective way to integrate the relation\nrepresentations and the original prototypes.",
    "descriptor": "\nComments: accepted to ACL2022 findings\n",
    "authors": [
      "Yang Liu",
      "Jinpeng Hu",
      "Xiang Wan",
      "Tsung-Hui Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09536"
  },
  {
    "id": "arXiv:2205.09539",
    "title": "Data-driven prediction of Air Traffic Controllers reactions to resolving  conflicts",
    "abstract": "With the aim to enhance automation in conflict detection and resolution\n(CD&R) tasks in the Air Traffic Management domain, in this paper we propose\ndeep learning techniques (DL) that can learn models of Air Traffic Controllers'\n(ATCO) reactions in resolving conflicts that can violate separation minimum\nconstraints among aircraft trajectories: This implies learning when the ATCO\nwill react towards resolving a conflict, and how he/she will react. Timely\nreactions, to which this paper aims, focus on when do reactions happen, aiming\nto predict the trajectory points, as the trajectory evolves, that the ATCO\nissues a conflict resolution action, while also predicting the type of\nresolution action (if any). Towards this goal, the paper formulates the ATCO\nreactions prediction problem for CD&R, and presents DL methods that can model\nATCO timely reactions and evaluates these methods in real-world data sets,\nshowing their efficacy in prediction with very high accuracy.",
    "descriptor": "\nComments: 40 pages, 7 Tables, 5 Figures, 30 References\n",
    "authors": [
      "Alevizos Bastas",
      "George A. Vouros"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09539"
  },
  {
    "id": "arXiv:2205.09542",
    "title": "Domain Enhanced Arbitrary Image Style Transfer via Contrastive Learning",
    "abstract": "In this work, we tackle the challenging problem of arbitrary image style\ntransfer using a novel style feature representation learning method. A suitable\nstyle representation, as a key component in image stylization tasks, is\nessential to achieve satisfactory results. Existing deep neural network based\napproaches achieve reasonable results with the guidance from second-order\nstatistics such as Gram matrix of content features. However, they do not\nleverage sufficient style information, which results in artifacts such as local\ndistortions and style inconsistency. To address these issues, we propose to\nlearn style representation directly from image features instead of their\nsecond-order statistics, by analyzing the similarities and differences between\nmultiple styles and considering the style distribution. Specifically, we\npresent Contrastive Arbitrary Style Transfer (CAST), which is a new style\nrepresentation learning and style transfer method via contrastive learning. Our\nframework consists of three key components, i.e., a multi-layer style projector\nfor style code encoding, a domain enhancement module for effective learning of\nstyle distribution, and a generative network for image style transfer. We\nconduct qualitative and quantitative evaluations comprehensively to demonstrate\nthat our approach achieves significantly better results compared to those\nobtained via state-of-the-art methods. Code and models are available at\nhttps://github.com/zyxElsa/CAST_pytorch",
    "descriptor": "\nComments: Accepted by SIGGRAPH 2022\n",
    "authors": [
      "Yuxin Zhang",
      "Fan Tang",
      "Weiming Dong",
      "Haibin Huang",
      "Chongyang Ma",
      "Tong-Yee Lee",
      "Changsheng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2205.09542"
  },
  {
    "id": "arXiv:2205.09543",
    "title": "Parallel bandit architecture based on laser chaos for reinforcement  learning",
    "abstract": "Accelerating artificial intelligence by photonics is an active field of study\naiming to exploit the unique properties of photons. Reinforcement learning is\nan important branch of machine learning, and photonic decision-making\nprinciples have been demonstrated with respect to the multi-armed bandit\nproblems. However, reinforcement learning could involve a massive number of\nstates, unlike previously demonstrated bandit problems where the number of\nstates is only one. Q-learning is a well-known approach in reinforcement\nlearning that can deal with many states. The architecture of Q-learning,\nhowever, does not fit well photonic implementations due to its separation of\nupdate rule and the action selection. In this study, we organize a new\narchitecture for multi-state reinforcement learning as a parallel array of\nbandit problems in order to benefit from photonic decision-makers, which we\ncall parallel bandit architecture for reinforcement learning or PBRL in short.\nTaking a cart-pole balancing problem as an instance, we demonstrate that PBRL\nadapts to the environment in fewer time steps than Q-learning. Furthermore,\nPBRL yields faster adaptation when operated with a chaotic laser time series\nthan the case with uniformly distributed pseudorandom numbers where the\nautocorrelation inherent in the laser chaos provides a positive effect. We also\nfind that the variety of states that the system undergoes during the learning\nphase exhibits completely different properties between PBRL and Q-learning. The\ninsights obtained through the present study are also beneficial for existing\ncomputing platforms, not just photonic realizations, in accelerating\nperformances by the PBRL algorithms and correlated random sequences.",
    "descriptor": "",
    "authors": [
      "Takashi Urushibara",
      "Nicolas Chauvet",
      "Satoshi Kochi",
      "Satoshi Sunada",
      "Kazutaka Kanno",
      "Atsushi Uchida",
      "Ryoichi Horisaki",
      "Makoto Naruse"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.09543"
  },
  {
    "id": "arXiv:2205.09549",
    "title": "Politeness Counts: Perceptions of Peacekeeping Robots",
    "abstract": "The 'intuitive' trust people feel when encountering robots in public spaces\nis a key determinant of their willingness to cooperate with these robots. We\nconducted four experiments to study this topic in the context of peacekeeping\nrobots. Participants viewed scenarios, presented as static images or\nanimations, involving a robot or a human guard performing an access-control\ntask. The guards interacted more or less politely with younger and older male\nand female people. Our results show strong effects of the guard's politeness.\nAge and sex of the people interacting with the guard had no significant effect\non participants' impressions of its attributes. There were no differences\nbetween responses to robot and human guards. This study advances the notion\nthat politeness is a crucial determinant of people's perception of peacekeeping\nrobots.",
    "descriptor": "",
    "authors": [
      "Ohad Inbar",
      "Joachim Meyer"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.09549"
  },
  {
    "id": "arXiv:2205.09550",
    "title": "Data Valuation for Offline Reinforcement Learning",
    "abstract": "The success of deep reinforcement learning (DRL) hinges on the availability\nof training data, which is typically obtained via a large number of environment\ninteractions. In many real-world scenarios, costs and risks are associated with\ngathering these data. The field of offline reinforcement learning addresses\nthese issues through outsourcing the collection of data to a domain expert or a\ncarefully monitored program and subsequently searching for a batch-constrained\noptimal policy. With the emergence of data markets, an alternative to\nconstructing a dataset in-house is to purchase external data. However, while\nstate-of-the-art offline reinforcement learning approaches have shown a lot of\npromise, they currently rely on carefully constructed datasets that are well\naligned with the intended target domains. This raises questions regarding the\ntransferability and robustness of an offline reinforcement learning agent\ntrained on externally acquired data. In this paper, we empirically evaluate the\nability of the current state-of-the-art offline reinforcement learning\napproaches to coping with the source-target domain mismatch within two MuJoCo\nenvironments, finding that current state-of-the-art offline reinforcement\nlearning algorithms underperform in the target domain. To address this, we\npropose data valuation for offline reinforcement learning (DVORL), which allows\nus to identify relevant and high-quality transitions, improving the performance\nand transferability of policies learned by offline reinforcement learning\nalgorithms. The results show that our method outperforms offline reinforcement\nlearning baselines on two MuJoCo environments.",
    "descriptor": "\nComments: 9 pages, 3 figures, 2 tables\n",
    "authors": [
      "Amir Abolfazli",
      "Gregory Palmer",
      "Daniel Kudenko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09550"
  },
  {
    "id": "arXiv:2205.09552",
    "title": "Hybrid Intelligent Testing in Simulation-Based Verification",
    "abstract": "Efficient and effective testing for simulation-based hardware verification is\nchallenging. Using constrained random test generation, several millions of\ntests may be required to achieve coverage goals. The vast majority of tests do\nnot contribute to coverage progress, yet they consume verification resources.\nIn this paper, we propose a hybrid intelligent testing approach combining two\nmethods that have previously been treated separately, namely Coverage-Directed\nTest Selection and Novelty-Driven Verification. Coverage-Directed Test\nSelection learns from coverage feedback to bias testing towards the most\neffective tests. Novelty-Driven Verification learns to identify and simulate\nstimuli that differ from previous stimuli, thereby reducing the number of\nsimulations and increasing testing efficiency. We discuss the strengths and\nlimitations of each method, and we show how our approach addresses each\nmethod's limitations, leading to hardware testing that is both efficient and\neffective.",
    "descriptor": "",
    "authors": [
      "Nyasha Masamba",
      "Kerstin Eder",
      "Tim Blackmore"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.09552"
  },
  {
    "id": "arXiv:2205.09555",
    "title": "LPV Modeling of the Atmospheric Flight Dynamics of a Generic Parafoil  Return Vehicle",
    "abstract": "Obtaining models that can be used for control is of utmost importance to\nensure the guidance and navigation of spacecraft, like a Generic Parafoil\nReturn Vehicle (GPRV). In this paper, we convert a nonlinear model of the\natmospheric flight dynamics of an GPRV to a Linear Parameter-Varying (LPV)\ndescription, such that the LPV model is suitable for navigation control design.\nAutomated conversion methods for nonlinear models can result in complex LPV\nrepresentation, which are not suitable for controller synthesis. We apply\nseveral state-of-the-art techniques, including learning based approaches, to\noptimize the complexity and conservatism of the LPV embedding for an GPRV. The\nresults show that we can obtain an LPV embedding that approximates the complex\nnonlinear dynamics sufficiently well, where the balance between complexity,\nconservatism and model performance is optimal.",
    "descriptor": "\nComments: Submitted to the 5th IFAC Workshop on Linear Parameter Varying Systems (LPVS) of the Joint IFAC Conference (SSSC2022-TDS2022-LPVS2022)\n",
    "authors": [
      "Matthis H. de Lange",
      "Chris Verhoek",
      "Valentin Preda",
      "Roland T\u00f3th"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.09555"
  },
  {
    "id": "arXiv:2205.09556",
    "title": "Neural Networks in Imandra: Matrix Representation as a Verification  Choice",
    "abstract": "The demand for formal verification tools for neural networks has increased as\nneural networks have been deployed in a growing number of safety-critical\napplications. Matrices are a data structure essential to formalising neural\nnetworks. Functional programming languages encourage diverse approaches to\nmatrix definitions. This feature has already been successfully exploited in\ndifferent applications. The question we ask is whether, and how, these ideas\ncan be applied in neural network verification. A functional programming\nlanguage Imandra combines the syntax of a functional programming language and\nthe power of an automated theorem prover. Using these two key features of\nImandra, we explore how different implementations of matrices can influence\nautomation of neural network verification.",
    "descriptor": "\nComments: Submitted as informal talk to FOMLAS'22\n",
    "authors": [
      "Remi Desmartin",
      "Grant Passmore",
      "Ekaterina Komendantskaya"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2205.09556"
  },
  {
    "id": "arXiv:2205.09564",
    "title": "Automatic Spoken Language Identification using a Time-Delay Neural  Network",
    "abstract": "Closed-set spoken language identification is the task of recognizing the\nlanguage being spoken in a recorded audio clip from a set of known languages.\nIn this study, a language identification system was built and trained to\ndistinguish between Arabic, Spanish, French, and Turkish based on nothing more\nthan recorded speech. A pre-existing multilingual dataset was used to train a\nseries of acoustic models based on the Tedlium TDNN model to perform automatic\nspeech recognition. The system was provided with a custom multilingual language\nmodel and a specialized pronunciation lexicon with language names prepended to\nphones. The trained model was used to generate phone alignments to test data\nfrom all four languages, and languages were predicted based on a voting scheme\nchoosing the most common language prepend in an utterance. Accuracy was\nmeasured by comparing predicted languages to known languages, and was\ndetermined to be very high in identifying Spanish and Arabic, and somewhat\nlower in identifying Turkish and French.",
    "descriptor": "\nComments: 6 pages, 6 figures, Technical Report Recognition Technologies, Inc\n",
    "authors": [
      "Benjamin Kepecs",
      "Homayoon Beigi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.09564"
  },
  {
    "id": "arXiv:2205.09569",
    "title": "Provably Precise, Succinct and Efficient Explanations for Decision Trees",
    "abstract": "Decision trees (DTs) embody interpretable classifiers. DTs have been\nadvocated for deployment in high-risk applications, but also for explaining\nother complex classifiers. Nevertheless, recent work has demonstrated that\npredictions in DTs ought to be explained with rigorous approaches. Although\nrigorous explanations can be computed in polynomial time for DTs, their size\nmay be beyond the cognitive limits of human decision makers. This paper\ninvestigates the computation of {\\delta}-relevant sets for DTs.\n{\\delta}-relevant sets denote explanations that are succinct and provably\nprecise. These sets represent generalizations of rigorous explanations, which\nare precise with probability one, and so they enable trading off explanation\nsize for precision. The paper proposes two logic encodings for computing\nsmallest {\\delta}-relevant sets for DTs. The paper further devises a\npolynomial-time algorithm for computing {\\delta}-relevant sets which are not\nguaranteed to be subset-minimal, but for which the experiments show to be most\noften subset-minimal in practice. The experimental results also demonstrate the\npractical efficiency of computing smallest {\\delta}-relevant sets.",
    "descriptor": "",
    "authors": [
      "Yacine Izza",
      "Alexey Ignatiev",
      "Nina Narodytska",
      "Martin C. Cooper",
      "Joao Marques-Silva"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09569"
  },
  {
    "id": "arXiv:2205.09570",
    "title": "Approaching Reflex Predictions as a Classification Problem Using  Extended Phonological Alignments",
    "abstract": "This work describes an implementation of the \"extended alignment\" (or\n\"multitiers\") approach for cognate reflex prediction, submitted to \"Prediction\nof Cognate Reflexes\" shared task. Similarly to List2022d, the technique\ninvolves an automatic extension of sequence alignments with multilayered\nvectors that encode informational tiers on both site-specific traits, such as\nsound classes and distinctive features, as well as contextual and\nsuprasegmental ones, conveyed by cross-site referrals and replication. The\nmethod allows to generalize the problem of cognate reflex prediction as a\nclassification problem, with models trained using a parallel corpus of cognate\nsets. A model using random forests is trained and evaluated on the shared task\nfor reflex prediction, and the experimental results are presented and discussed\nalong with some differences to other implementations.",
    "descriptor": "\nComments: 8 pages, SIGTYP \"Prediction of Cognate Reflexes\" shared task\n",
    "authors": [
      "Tiago Tresoldi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09570"
  },
  {
    "id": "arXiv:2205.09573",
    "title": "Jacobian Granger Causal Neural Networks for Analysis of Stationary and  Nonstationary Data",
    "abstract": "Granger causality is a commonly used method for uncovering information flow\nand dependencies in a time series. Here we introduce JGC (Jacobian Granger\nCausality), a neural network-based approach to Granger causality using the\nJacobian as a measure of variable importance, and propose a thresholding\nprocedure for inferring Granger causal variables using this measure. The\nresulting approach performs consistently well compared to other approaches in\nidentifying Granger causal variables, the associated time lags, as well as\ninteraction signs. Lastly, through the inclusion of a time variable, we show\nthat this approach is able to learn the temporal dependencies for nonstationary\nsystems whose Granger causal structures change in time.",
    "descriptor": "",
    "authors": [
      "Suryadi",
      "Yew-Soon Ong",
      "Lock Yue Chew"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09573"
  },
  {
    "id": "arXiv:2205.09575",
    "title": "Learning Graph Structure from Convolutional Mixtures",
    "abstract": "Machine learning frameworks such as graph neural networks typically rely on a\ngiven, fixed graph to exploit relational inductive biases and thus effectively\nlearn from network data. However, when said graphs are (partially) unobserved,\nnoisy, or dynamic, the problem of inferring graph structure from data becomes\nrelevant. In this paper, we postulate a graph convolutional relationship\nbetween the observed and latent graphs, and formulate the graph learning task\nas a network inverse (deconvolution) problem. In lieu of\neigendecomposition-based spectral methods or iterative optimization solutions,\nwe unroll and truncate proximal gradient iterations to arrive at a\nparameterized neural network architecture that we call a Graph Deconvolution\nNetwork (GDN). GDNs can learn a distribution of graphs in a supervised fashion,\nperform link prediction or edge-weight regression tasks by adapting the loss\nfunction, and they are inherently inductive. We corroborate GDN's superior\ngraph recovery performance and its generalization to larger graphs using\nsynthetic data in supervised settings. Furthermore, we demonstrate the\nrobustness and representation power of GDNs on real world neuroimaging and\nsocial network datasets.",
    "descriptor": "",
    "authors": [
      "Max Wasserman",
      "Saurabh Sihag",
      "Gonzalo Mateos",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.09575"
  },
  {
    "id": "arXiv:2205.09576",
    "title": "Discovering Dynamic Functional Brain Networks via Spatial and  Channel-wise Attention",
    "abstract": "Using deep learning models to recognize functional brain networks (FBNs) in\nfunctional magnetic resonance imaging (fMRI) has been attracting increasing\ninterest recently. However, most existing work focuses on detecting static FBNs\nfrom entire fMRI signals, such as correlation-based functional connectivity.\nSliding-window is a widely used strategy to capture the dynamics of FBNs, but\nit is still limited in representing intrinsic functional interactive dynamics\nat each time step. And the number of FBNs usually need to be set manually. More\nover, due to the complexity of dynamic interactions in brain, traditional\nlinear and shallow models are insufficient in identifying complex and spatially\noverlapped FBNs across each time step. In this paper, we propose a novel\nSpatial and Channel-wise Attention Autoencoder (SCAAE) for discovering FBNs\ndynamically. The core idea of SCAAE is to apply attention mechanism to FBNs\nconstruction. Specifically, we designed two attention modules: 1) spatial-wise\nattention (SA) module to discover FBNs in the spatial domain and 2) a\nchannel-wise attention (CA) module to weigh the channels for selecting the FBNs\nautomatically. We evaluated our approach on ADHD200 dataset and our results\nindicate that the proposed SCAAE method can effectively recover the dynamic\nchanges of the FBNs at each fMRI time step, without using sliding windows. More\nimportantly, our proposed hybrid attention modules (SA and CA) do not enforce\nassumptions of linearity and independence as previous methods, and thus provide\na novel approach to better understanding dynamic functional brain networks.",
    "descriptor": "\nComments: 12 pages,6 figures, submitted to 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Yiheng Liu",
      "Enjie Ge",
      "Mengshen He",
      "Zhengliang Liu",
      "Shijie Zhao",
      "Xintao Hu",
      "Dajiang Zhu",
      "Tianming Liu",
      "Bao Ge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.09576"
  },
  {
    "id": "arXiv:2205.09578",
    "title": "A machine transliteration tool between Uzbek alphabets",
    "abstract": "Machine transliteration, as defined in this paper, is a process of\nautomatically transforming written script of words from a source alphabet into\nwords of another target alphabet within the same language, while preserving\ntheir meaning, as well as pronunciation. The main goal of this paper is to\npresent a machine transliteration tool between three common scripts used in\nlow-resource Uzbek language: the old Cyrillic, currently official Latin, and\nnewly announced New Latin alphabets. The tool has been created using a\ncombination of rule-based and fine-tuning approaches. The created tool is\navailable as an open-source Python package, as well as a web-based application\nincluding a public API. To our knowledge, this is the first machine\ntransliteration tool that supports the newly announced Latin alphabet of the\nUzbek language.",
    "descriptor": "\nComments: Preprint of a conference paper: The International Conference on Agglutinative Language Technologies as a challenge of Natural Language Processing (ALTNLP)\n",
    "authors": [
      "Ulugbek Salaev",
      "Elmurod Kuriyozov",
      "Carlos G\u00f3mez-Rodr\u00edguez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09578"
  },
  {
    "id": "arXiv:2205.09579",
    "title": "TRT-ViT: TensorRT-oriented Vision Transformer",
    "abstract": "We revisit the existing excellent Transformers from the perspective of\npractical application. Most of them are not even as efficient as the basic\nResNets series and deviate from the realistic deployment scenario. It may be\ndue to the current criterion to measure computation efficiency, such as FLOPs\nor parameters is one-sided, sub-optimal, and hardware-insensitive. Thus, this\npaper directly treats the TensorRT latency on the specific hardware as an\nefficiency metric, which provides more comprehensive feedback involving\ncomputational capacity, memory cost, and bandwidth. Based on a series of\ncontrolled experiments, this work derives four practical guidelines for\nTensorRT-oriented and deployment-friendly network design, e.g., early CNN and\nlate Transformer at stage-level, early Transformer and late CNN at block-level.\nAccordingly, a family of TensortRT-oriented Transformers is presented,\nabbreviated as TRT-ViT. Extensive experiments demonstrate that TRT-ViT\nsignificantly outperforms existing ConvNets and vision Transformers with\nrespect to the latency/accuracy trade-off across diverse visual tasks, e.g.,\nimage classification, object detection and semantic segmentation. For example,\nat 82.7% ImageNet-1k top-1 accuracy, TRT-ViT is 2.7$\\times$ faster than CSWin\nand 2.0$\\times$ faster than Twins. On the MS-COCO object detection task,\nTRT-ViT achieves comparable performance with Twins, while the inference speed\nis increased by 2.8$\\times$.",
    "descriptor": "",
    "authors": [
      "Xin Xia",
      "Jiashi Li",
      "Jie Wu",
      "Xing Wang",
      "Mingkai Wang",
      "Xuefeng Xiao",
      "Min Zheng",
      "Rui Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09579"
  },
  {
    "id": "arXiv:2205.09583",
    "title": "Evonne: Interactive Proof Visualization for Description Logics (System  Description) -- Extended Version",
    "abstract": "Explanations for description logic (DL) entailments provide important support\nfor the maintenance of large ontologies. The \"justifications\" usually employed\nfor this purpose in ontology editors pinpoint the parts of the ontology\nresponsible for a given entailment. Proofs for entailments make the\nintermediate reasoning steps explicit, and thus explain how a consequence can\nactually be derived. We present an interactive system for exploring description\nlogic proofs, called Evonne, which visualizes proofs of consequences for\nontologies written in expressive DLs. We describe the methods used for\ncomputing those proofs, together with a feature called signature-based proof\ncondensation. Moreover, we evaluate the quality of generated proofs using real\nontologies.",
    "descriptor": "",
    "authors": [
      "Christian Alrabbaa",
      "Franz Baader",
      "Stefan Borgwardt",
      "Raimund Dachselt",
      "Patrick Koopmann",
      "Juli\u00e1n M\u00e9ndez"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09583"
  },
  {
    "id": "arXiv:2205.09584",
    "title": "Multi-Armed Bandits in Brain-Computer Interfaces",
    "abstract": "The multi-armed bandit (MAB) problem models a decision-maker that optimizes\nits actions based on current and acquired new knowledge to maximize its reward.\nThis type of online decision is prominent in many procedures of Brain-Computer\nInterfaces (BCIs) and MAB has previously been used to investigate, e.g., what\nmental commands to use to optimize BCI performance. However, MAB optimization\nin the context of BCI is still relatively unexplored, even though it has the\npotential to improve BCI performance during both calibration and real-time\nimplementation. Therefore, this review aims to further introduce MABs to the\nBCI community. The review includes a background on MAB problems and standard\nsolution methods, and interpretations related to BCI systems. Moreover, it\nincludes state-of-the-art concepts of MAB in BCI and suggestions for future\nresearch.",
    "descriptor": "",
    "authors": [
      "Frida Heskebeck",
      "Carolina Bergeling",
      "Bo Bernhardsson"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.09584"
  },
  {
    "id": "arXiv:2205.09586",
    "title": "On Trace of PGD-Like Adversarial Attacks",
    "abstract": "Adversarial attacks pose safety and security concerns for deep learning\napplications. Yet largely imperceptible, a strong PGD-like attack may leave\nstrong trace in the adversarial example. Since attack triggers the local\nlinearity of a network, we speculate network behaves in different extents of\nlinearity for benign examples and adversarial examples. Thus, we construct\nAdversarial Response Characteristics (ARC) features to reflect the model's\ngradient consistency around the input to indicate the extent of linearity.\nUnder certain conditions, it shows a gradually varying pattern from benign\nexample to adversarial example, as the later leads to Sequel Attack Effect\n(SAE). ARC feature can be used for informed attack detection (perturbation\nmagnitude is known) with binary classifier, or uninformed attack detection\n(perturbation magnitude is unknown) with ordinal regression. Due to the\nuniqueness of SAE to PGD-like attacks, ARC is also capable of inferring other\nattack details such as loss function, or the ground-truth label as a\npost-processing defense. Qualitative and quantitative evaluations manifest the\neffectiveness of ARC feature on CIFAR-10 w/ ResNet-18 and ImageNet w/\nResNet-152 and SwinT-B-IN1K with considerable generalization among PGD-like\nattacks despite domain shift. Our method is intuitive, light-weighted,\nnon-intrusive, and data-undemanding.",
    "descriptor": "",
    "authors": [
      "Mo Zhou",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09586"
  },
  {
    "id": "arXiv:2205.09588",
    "title": "How catastrophic can catastrophic forgetting be in linear regression?",
    "abstract": "To better understand catastrophic forgetting, we study fitting an\noverparameterized linear model to a sequence of tasks with different input\ndistributions. We analyze how much the model forgets the true labels of earlier\ntasks after training on subsequent tasks, obtaining exact expressions and\nbounds. We establish connections between continual learning in the linear\nsetting and two other research areas: alternating projections and the Kaczmarz\nmethod. In specific settings, we highlight differences between forgetting and\nconvergence to the offline solution as studied in those areas. In particular,\nwhen T tasks in d dimensions are presented cyclically for k iterations, we\nprove an upper bound of T^2 * min{1/sqrt(k), d/k} on the forgetting. This\nstands in contrast to the convergence to the offline solution, which can be\narbitrarily slow according to existing alternating projection results. We\nfurther show that the T^2 factor can be lifted when tasks are presented in a\nrandom ordering.",
    "descriptor": "",
    "authors": [
      "Itay Evron",
      "Edward Moroshko",
      "Rachel Ward",
      "Nati Srebro",
      "Daniel Soudry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.09588"
  },
  {
    "id": "arXiv:2205.09589",
    "title": "Learning Energy Networks with Generalized Fenchel-Young Losses",
    "abstract": "Energy-based models, a.k.a. energy networks, perform inference by optimizing\nan energy function, typically parametrized by a neural network. This allows one\nto capture potentially complex relationships between inputs and outputs. To\nlearn the parameters of the energy function, the solution to that optimization\nproblem is typically fed into a loss function. The key challenge for training\nenergy networks lies in computing loss gradients, as this typically requires\nargmin/argmax differentiation. In this paper, building upon a generalized\nnotion of conjugate function, which replaces the usual bilinear pairing with a\ngeneral energy function, we propose generalized Fenchel-Young losses, a natural\nloss construction for learning energy networks. Our losses enjoy many desirable\nproperties and their gradients can be computed efficiently without\nargmin/argmax differentiation. We also prove the calibration of their excess\nrisk in the case of linear-concave energies. We demonstrate our losses on\nmultilabel classification and imitation learning tasks.",
    "descriptor": "",
    "authors": [
      "Mathieu Blondel",
      "Felipe Llinares-L\u00f3pez",
      "Robert Dadashi",
      "L\u00e9onard Hussenot",
      "Matthieu Geist"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.09589"
  },
  {
    "id": "arXiv:2205.09591",
    "title": "Breathing Life into Models: The Next Generation of Enterprise Modeling",
    "abstract": "Edsger W. Dijkstra has frequently suggested building a \"firewall\" between the\ntechnology- and application-side of computer science. His justification: The\nmethods to attack the computer scientists' formal, mathematical \"correctness\nproblem\" differ fundamentally from the methods to attack the applicants'\ninformal \"pleasantness problem\". In this setting, a model is always confined to\none side or the other of this wall. This keynote shows that a seamless\ntransition between both sides can be achieved by a framework with architecture,\nstatics, and dynamics as the three pillars of modeling computer-integrated\nsystems. Selected examples justify this framework. It allows to \"breath life\"\ninto (static) models, and it implies a new understanding of the \"pleasantness\"\nof computer-integrated systems, which is well-needed in the age of \"digital\nfirst\".",
    "descriptor": "\nComments: 8 pages, 11 figures, author prepared version of final manuscript based on the invited keynote at ICSOFT 2022, this http URL\n",
    "authors": [
      "Peter Fettke",
      "Wolfgang Reisig"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.09591"
  },
  {
    "id": "arXiv:2205.09592",
    "title": "Transferable Physical Attack against Object Detection with Separable  Attention",
    "abstract": "Transferable adversarial attack is always in the spotlight since deep\nlearning models have been demonstrated to be vulnerable to adversarial samples.\nHowever, existing physical attack methods do not pay enough attention on\ntransferability to unseen models, thus leading to the poor performance of\nblack-box attack.In this paper, we put forward a novel method of generating\nphysically realizable adversarial camouflage to achieve transferable attack\nagainst detection models. More specifically, we first introduce multi-scale\nattention maps based on detection models to capture features of objects with\nvarious resolutions. Meanwhile, we adopt a sequence of composite\ntransformations to obtain the averaged attention maps, which could curb\nmodel-specific noise in the attention and thus further boost transferability.\nUnlike the general visualization interpretation methods where model attention\nshould be put on the foreground object as much as possible, we carry out attack\non separable attention from the opposite perspective, i.e. suppressing\nattention of the foreground and enhancing that of the background. Consequently,\ntransferable adversarial camouflage could be yielded efficiently with our novel\nattention-based loss function. Extensive comparison experiments verify the\nsuperiority of our method to state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Yu Zhang",
      "Zhiqiang Gong",
      "Yichuang Zhang",
      "YongQian Li",
      "Kangcheng Bin",
      "Jiahao Qi",
      "Wei Xue",
      "Ping Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09592"
  },
  {
    "id": "arXiv:2205.09593",
    "title": "Improving Micro-video Recommendation via Contrastive Multiple Interests",
    "abstract": "With the rapid increase of micro-video creators and viewers, how to make\npersonalized recommendations from a large number of candidates to viewers\nbegins to attract more and more attention. However, existing micro-video\nrecommendation models rely on expensive multi-modal information and learn an\noverall interest embedding that cannot reflect the user's multiple interests in\nmicro-videos. Recently, contrastive learning provides a new opportunity for\nrefining the existing recommendation techniques. Therefore, in this paper, we\npropose to extract contrastive multi-interests and devise a micro-video\nrecommendation model CMI. Specifically, CMI learns multiple interest embeddings\nfor each user from his/her historical interaction sequence, in which the\nimplicit orthogonal micro-video categories are used to decouple multiple user\ninterests. Moreover, it establishes the contrastive multi-interest loss to\nimprove the robustness of interest embeddings and the performance of\nrecommendations. The results of experiments on two micro-video datasets\ndemonstrate that CMI achieves state-of-the-art performance over existing\nbaselines.",
    "descriptor": "",
    "authors": [
      "Beibei Li",
      "Beihong Jin",
      "Jiageng Song",
      "Yisong Yu",
      "Yiyuan Zheng",
      "Wei Zhuo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.09593"
  },
  {
    "id": "arXiv:2205.09594",
    "title": "A Comparative Study of Feature Expansion Unit for 3D Point Cloud  Upsampling",
    "abstract": "Recently, deep learning methods have shown great success in 3D point cloud\nupsampling. Among these methods, many feature expansion units were proposed to\ncomplete point expansion at the end. In this paper, we compare various feature\nexpansion units by both theoretical analysis and quantitative experiments. We\nshow that most of the existing feature expansion units process each point\nfeature independently, while ignoring the feature interaction among different\npoints. Further, inspired by upsampling module of image super-resolution and\nrecent success of dynamic graph CNN on point clouds, we propose a novel feature\nexpansion units named ProEdgeShuffle. Experiments show that our proposed method\ncan achieve considerable improvement over previous feature expansion units.",
    "descriptor": "",
    "authors": [
      "Qiang Li",
      "Tao Dai",
      "Shu-Tao Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09594"
  },
  {
    "id": "arXiv:2205.09596",
    "title": "An Extended Kalman Filter for Distance Estimation and Power Control in  Mobile Molecular Communication",
    "abstract": "In this paper, we consider a mobile molecular communication (MC) system\nconsisting of two mobile nanomachines, a transmitter and a receiver, propelled\nby a positive drift velocity and Brownian motion in a realistic\nblood-vessel-type flow regime. Considering the nonlinear movement of the\nnanomachines, an extended Kalman filter is employed to estimate the distance\nfrom the transmitter. Furthermore, based on the predicted distance, to keep the\nnumber of received molecules for bit 1 at a stable level, we employ power\ncontrol on the number of transmitted molecules based on the distance between\nthe transmitter and the receiver and the residual molecules in the channel from\nthe previous transmission. Finally, the optimal detection threshold is obtained\nby minimizing the error probability. It is verified that a fixed optimal\ndetection threshold can be effective for the power control scheme in the mobile\nMC. The bit error rate (BER) performance of our scheme is verified via\nsimulation results.",
    "descriptor": "\nComments: Accepted for publication in IEEE Transactions on Communications\n",
    "authors": [
      "Dongliang Jing",
      "Yongzhao Li",
      "Andrew W. Eckford"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.09596"
  },
  {
    "id": "arXiv:2205.09601",
    "title": "CORPS: Cost-free Rigorous Pseudo-labeling based on Similarity-ranking  for Brain MRI Segmentation",
    "abstract": "Segmentation of brain magnetic resonance images (MRI) is crucial for the\nanalysis of the human brain and diagnosis of various brain disorders. The\ndrawbacks of time-consuming and error-prone manual delineation procedures are\naimed to be alleviated by atlas-based and supervised machine learning methods\nwhere the former methods are computationally intense and the latter methods\nlack a sufficiently large number of labeled data. With this motivation, we\npropose CORPS, a semi-supervised segmentation framework built upon a novel\natlas-based pseudo-labeling method and a 3D deep convolutional neural network\n(DCNN) for 3D brain MRI segmentation. In this work, we propose to generate\nexpert-level pseudo-labels for unlabeled set of images in an order based on a\nlocal intensity-based similarity score to existing labeled set of images and\nusing a novel atlas-based label fusion method. Then, we propose to train a 3D\nDCNN on the combination of expert and pseudo labeled images for binary\nsegmentation of each anatomical structure. The binary segmentation approach is\nproposed to avoid the poor performance of multi-class segmentation methods on\nlimited and imbalanced data. This also allows to employ a lightweight and\nefficient 3D DCNN in terms of the number of filters and reserve memory\nresources for training the binary networks on full-scale and full-resolution 3D\nMRI volumes instead of 2D/3D patches or 2D slices. Thus, the proposed framework\ncan encapsulate the spatial contiguity in each dimension and enhance\ncontext-awareness. The experimental results demonstrate the superiority of the\nproposed framework over the baseline method both qualitatively and\nquantitatively without additional labeling cost for manual labeling.",
    "descriptor": "",
    "authors": [
      "Can Taylan Sari",
      "Sila Kurugol",
      "Onur Afacan",
      "Simon K. Warfield"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09601"
  },
  {
    "id": "arXiv:2205.09607",
    "title": "LAGr: Label Aligned Graphs for Better Systematic Generalization in  Semantic Parsing",
    "abstract": "Semantic parsing is the task of producing structured meaning representations\nfor natural language sentences. Recent research has pointed out that the\ncommonly-used sequence-to-sequence (seq2seq) semantic parsers struggle to\ngeneralize systematically, i.e. to handle examples that require recombining\nknown knowledge in novel settings. In this work, we show that better systematic\ngeneralization can be achieved by producing the meaning representation directly\nas a graph and not as a sequence. To this end we propose LAGr (Label Aligned\nGraphs), a general framework to produce semantic parses by independently\npredicting node and edge labels for a complete multi-layer input-aligned graph.\nThe strongly-supervised LAGr algorithm requires aligned graphs as inputs,\nwhereas weakly-supervised LAGr infers alignments for originally unaligned\ntarget graphs using approximate maximum-a-posteriori inference. Experiments\ndemonstrate that LAGr achieves significant improvements in systematic\ngeneralization upon the baseline seq2seq parsers in both strongly- and\nweakly-supervised settings.",
    "descriptor": "\nComments: published in ACL'22. arXiv admin note: substantial text overlap with arXiv:2110.07572\n",
    "authors": [
      "Dora Jambor",
      "Dzmitry Bahdanau"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09607"
  },
  {
    "id": "arXiv:2205.09612",
    "title": "CLCNet: Rethinking of Ensemble Modeling with Classification Confidence  Network",
    "abstract": "In this paper, we propose a Classification Confidence Network (CLCNet) that\ncan determine whether the classification model classifies input samples\ncorrectly. It can take a classification result in the form of vector in any\ndimension, and return a confidence score as output, which represents the\nprobability of an instance being classified correctly. We can utilize CLCNet in\na simple cascade structure system consisting of several SOTA (state-of-the-art)\nclassification models, and our experiments show that the system can achieve the\nfollowing advantages: 1. The system can customize the average computation\nrequirement (FLOPs) per image while inference. 2. Under the same computation\nrequirement, the performance of the system can exceed any model that has\nidentical structure with the model in the system, but different in size. In\nfact, this is a new type of ensemble modeling. Like general ensemble modeling,\nit can achieve higher performance than single classification model, yet our\nsystem requires much less computation than general ensemble modeling. We have\nuploaded our code to a github repository:\nhttps://github.com/yaoching0/CLCNet-Rethinking-of-Ensemble-Modeling.",
    "descriptor": "",
    "authors": [
      "Yao-Ching Yu",
      "Shi-Jinn Horng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09612"
  },
  {
    "id": "arXiv:2205.09613",
    "title": "Integral Migrating Pre-trained Transformer Encoder-decoders for Visual  Object Detection",
    "abstract": "Modern object detectors have taken the advantages of pre-trained vision\ntransformers by using them as backbone networks. However, except for the\nbackbone networks, other detector components, such as the detector head and the\nfeature pyramid network, remain randomly initialized, which hinders the\nconsistency between detectors and pre-trained models. In this study, we propose\nto integrally migrate the pre-trained transformer encoder-decoders (imTED) for\nobject detection, constructing a feature extraction-operation path that is not\nonly \"fully pre-trained\" but also consistent with pre-trained models. The\nessential improvements of imTED over existing transformer-based detectors are\ntwofold: (1) it embeds the pre-trained transformer decoder to the detector\nhead; and (2) it removes the feature pyramid network from the feature\nextraction path. Such improvements significantly reduce the proportion of\nrandomly initialized parameters and enhance the generation capability of\ndetectors. Experiments on MS COCO dataset demonstrate that imTED consistently\noutperforms its counterparts by ~2.8% AP. Without bells and whistles, imTED\nimproves the state-of-the-art of few-shot object detection by up to 7.6% AP,\ndemonstrating significantly higher generalization capability. Code will be made\npublicly available.",
    "descriptor": "\nComments: 12 pages,5 figures\n",
    "authors": [
      "Xiaosong Zhang",
      "Feng Liu",
      "Zhiliang Peng",
      "Zonghao Guo",
      "Fang Wan",
      "Xiangyang Ji",
      "Qixiang Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09613"
  },
  {
    "id": "arXiv:2205.09615",
    "title": "EXACT: How to Train Your Accuracy",
    "abstract": "Classification tasks are usually evaluated in terms of accuracy. However,\naccuracy is discontinuous and cannot be directly optimized using gradient\nascent. Popular methods minimize cross-entropy, Hinge loss, or other surrogate\nlosses, which can lead to suboptimal results. In this paper, we propose a new\noptimization framework by introducing stochasticity to a model's output and\noptimizing expected accuracy, i.e. accuracy of the stochastic model. Extensive\nexperiments on image classification show that the proposed optimization method\nis a powerful alternative to widely used classification losses.",
    "descriptor": "",
    "authors": [
      "Ivan Karpukhin",
      "Stanislav Dereka",
      "Sergey Kolesnikov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09615"
  },
  {
    "id": "arXiv:2205.09616",
    "title": "Masked Image Modeling with Denoising Contrast",
    "abstract": "Since the development of self-supervised visual representation learning from\ncontrastive learning to masked image modeling, there is no significant\ndifference in essence, that is, how to design proper pretext tasks for vision\ndictionary look-up. Masked image modeling recently dominates this line of\nresearch with state-of-the-art performance on vision Transformers, where the\ncore is to enhance the patch-level visual context capturing of the network via\ndenoising auto-encoding mechanism. Rather than tailoring image tokenizers with\nextra training stages as in previous works, we unleash the great potential of\ncontrastive learning on denoising auto-encoding and introduce a new\npre-training method, ConMIM, to produce simple intra-image inter-patch\ncontrastive constraints as the learning objectives for masked patch prediction.\nWe further strengthen the denoising mechanism with asymmetric designs,\nincluding image perturbations and model progress rates, to improve the network\npre-training. ConMIM-pretrained vision Transformers with various scales achieve\npromising results on downstream image classification, semantic segmentation,\nobject detection, and instance segmentation tasks.",
    "descriptor": "",
    "authors": [
      "Kun Yi",
      "Yixiao Ge",
      "Xiaotong Li",
      "Shusheng Yang",
      "Dian Li",
      "Jianping Wu",
      "Ying Shan",
      "Xiaohu Qie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09616"
  },
  {
    "id": "arXiv:2205.09617",
    "title": "A Topological Approach for Semi-Supervised Learning",
    "abstract": "Nowadays, Machine Learning and Deep Learning methods have become the\nstate-of-the-art approach to solve data classification tasks. In order to use\nthose methods, it is necessary to acquire and label a considerable amount of\ndata; however, this is not straightforward in some fields, since data\nannotation is time consuming and might require expert knowledge. This challenge\ncan be tackled by means of semi-supervised learning methods that take advantage\nof both labelled and unlabelled data. In this work, we present new\nsemi-supervised learning methods based on techniques from Topological Data\nAnalysis (TDA), a field that is gaining importance for analysing large amounts\nof data with high variety and dimensionality. In particular, we have created\ntwo semi-supervised learning methods following two different topological\napproaches. In the former, we have used a homological approach that consists in\nstudying the persistence diagrams associated with the data using the Bottleneck\nand Wasserstein distances. In the latter, we have taken into account the\nconnectivity of the data. In addition, we have carried out a thorough analysis\nof the developed methods using 3 synthetic datasets, 5 structured datasets, and\n2 datasets of images. The results show that the semi-supervised methods\ndeveloped in this work outperform both the results obtained with models trained\nwith only manually labelled data, and those obtained with classical\nsemi-supervised learning methods, reaching improvements of up to a 16%.",
    "descriptor": "",
    "authors": [
      "Adri\u00e1n In\u00e9s",
      "C\u00e9sar Dom\u00ednguez",
      "J\u00f3nathan Heras",
      "Gadea Mata",
      "Julio Rubio"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09617"
  },
  {
    "id": "arXiv:2205.09618",
    "title": "Eco-driving Trajectory Planning of a Heterogeneous Platoon in Urban  Environments",
    "abstract": "Given the increasing popularity and demand for connected and autonomous\nvehicles (CAVs), Eco-driving and platooning in highways and urban areas to\nincrease the efficiency of the traffic system is becoming a possibility. This\npaper presents Eco-driving trajectory planning for a platoon of heterogeneous\nelectric vehicles (EVs) in urban environments. The proposed control strategy\nfor the platoon considers energy consumption, mobility and passenger comfort,\nwith which vehicles may pass signalized intersections with no stops. For a\ngiven urban route, first, the platoon's leader vehicle employs dynamic\nprogramming (DP) to plan a trajectory for the anticipated path with the aim of\nbalancing energy consumption, mobility and passenger comfort. Then, every other\nfollowing CAV in the platoon either follows its preceding vehicle using a\nPID-based cooperative adaptive cruise control or plans its own trajectory by\nchecking whether it can pass the next intersection without stopping.\nFurthermore, a heavy-duty vehicle that cannot efficiently follow a light-weight\nvehicle would instead employ the DP-based trajectory planner. Simulation\nstudies demonstrate the efficacy of the proposed control strategy with which\nthe platoon's energy consumption is shown to reduce while the mobility is not\ncompromised.",
    "descriptor": "\nComments: Accepted for presentation at the 10th IFAC International Symposium on Advances in Automotive Control (AAC2022)\n",
    "authors": [
      "Hao Zhen",
      "Sahand Mosharafian",
      "Jidong J. Yang",
      "Javad Mohammadpour Velni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.09618"
  },
  {
    "id": "arXiv:2205.09619",
    "title": "Improving Robustness against Real-World and Worst-Case Distribution  Shifts through Decision Region Quantification",
    "abstract": "The reliability of neural networks is essential for their use in\nsafety-critical applications. Existing approaches generally aim at improving\nthe robustness of neural networks to either real-world distribution shifts\n(e.g., common corruptions and perturbations, spatial transformations, and\nnatural adversarial examples) or worst-case distribution shifts (e.g.,\noptimized adversarial examples). In this work, we propose the Decision Region\nQuantification (DRQ) algorithm to improve the robustness of any differentiable\npre-trained model against both real-world and worst-case distribution shifts in\nthe data. DRQ analyzes the robustness of local decision regions in the vicinity\nof a given data point to make more reliable predictions. We theoretically\nmotivate the DRQ algorithm by showing that it effectively smooths spurious\nlocal extrema in the decision surface. Furthermore, we propose an\nimplementation using targeted and untargeted adversarial attacks. An extensive\nempirical evaluation shows that DRQ increases the robustness of adversarially\nand non-adversarially trained models against real-world and worst-case\ndistribution shifts on several computer vision benchmark datasets.",
    "descriptor": "",
    "authors": [
      "Leo Schwinn",
      "Leon Bungert",
      "An Nguyen",
      "Ren\u00e9 Raab",
      "Falk Pulsmeyer",
      "Doina Precup",
      "Bj\u00f6rn Eskofier",
      "Dario Zanca"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09619"
  },
  {
    "id": "arXiv:2205.09620",
    "title": "Towards a Theory of Faithfulness: Faithful Explanations of  Differentiable Classifiers over Continuous Data",
    "abstract": "There is broad agreement in the literature that explanation methods should be\nfaithful to the model that they explain, but faithfulness remains a rather\nvague term. We revisit faithfulness in the context of continuous data and\npropose two formal definitions of faithfulness for feature attribution methods.\nQualitative faithfulness demands that scores reflect the true qualitative\neffect (positive vs. negative) of the feature on the model and quanitative\nfaithfulness that the magnitude of scores reflect the true quantitative effect.\nWe discuss under which conditions these requirements can be satisfied to which\nextent (local vs global). As an application of the conceptual idea, we look at\ndifferentiable classifiers over continuous data and characterize\nGradient-scores as follows: every qualitatively faithful feature attribution\nmethod is qualitatively equivalent to Gradient-scores. Furthermore, if an\nattribution method is quantitatively faithful in the sense that changes of the\noutput of the classifier are proportional to the scores of features, then it is\neither equivalent to gradient-scoring or it is based on an inferior\napproximation of the classifier. To illustrate the practical relevance of the\ntheory, we experimentally demonstrate that popular attribution methods can fail\nto give faithful explanations in the setting where the data is continuous and\nthe classifier differentiable.",
    "descriptor": "",
    "authors": [
      "Nico Potyka",
      "Xiang Yin",
      "Francesca Toni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09620"
  },
  {
    "id": "arXiv:2205.09622",
    "title": "What Is Fairness? Implications For FairML",
    "abstract": "A growing body of literature in fairness-aware ML (fairML) aspires to\nmitigate machine learning (ML)-related unfairness in automated decision making\n(ADM) by defining metrics that measure fairness of an ML model and by proposing\nmethods that ensure that trained ML models achieve low values in those\nmeasures. However, the underlying concept of fairness, i.e., the question of\nwhat fairness is, is rarely discussed, leaving a considerable gap between\ncenturies of philosophical discussion and recent adoption of the concept in the\nML community. In this work, we try to bridge this gap by formalizing a\nconsistent concept of fairness and by translating the philosophical\nconsiderations into a formal framework for the evaluation of ML models in ADM\nsystems. We derive that fairness problems can already arise without the\npresence of protected attributes, pointing out that fairness and predictive\nperformance are not irreconcilable counterparts, but rather that the latter is\nnecessary to achieve the former. Moreover, we argue why and how causal\nconsiderations are necessary when assessing fairness in the presence of\nprotected attributes. Eventually, we achieve greater linguistic clarity for the\ndiscussion of fairML by clearly assigning responsibilities to stakeholders\ninside and outside ML.",
    "descriptor": "",
    "authors": [
      "Ludwig Bothmann",
      "Kristina Peters",
      "Bernd Bischl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.09622"
  },
  {
    "id": "arXiv:2205.09624",
    "title": "Focused Adversarial Attacks",
    "abstract": "Recent advances in machine learning show that neural models are vulnerable to\nminimally perturbed inputs, or adversarial examples. Adversarial algorithms are\noptimization problems that minimize the accuracy of ML models by perturbing\ninputs, often using a model's loss function to craft such perturbations.\nState-of-the-art object detection models are characterized by very large output\nmanifolds due to the number of possible locations and sizes of objects in an\nimage. This leads to their outputs being sparse and optimization problems that\nuse them incur a lot of unnecessary computation.\nWe propose to use a very limited subset of a model's learned manifold to\ncompute adversarial examples. Our \\textit{Focused Adversarial Attacks} (FA)\nalgorithm identifies a small subset of sensitive regions to perform\ngradient-based adversarial attacks. FA is significantly faster than other\ngradient-based attacks when a model's manifold is sparsely activated. Also, its\nperturbations are more efficient than other methods under the same perturbation\nconstraints. We evaluate FA on the COCO 2017 and Pascal VOC 2007 detection\ndatasets.",
    "descriptor": "",
    "authors": [
      "Thomas Cilloni",
      "Charles Walter",
      "Charles Fleming"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.09624"
  },
  {
    "id": "arXiv:2205.09626",
    "title": "BARS: Towards Open Benchmarking for Recommender Systems",
    "abstract": "The past two decades have witnessed the rapid development of personalized\nrecommendation techniques. Despite the significant progress made in both\nresearch and practice of recommender systems, to date, there is a lack of a\nwidely-recognized benchmarking system in this field. Many of the existing\nstudies perform model evaluations and comparisons in an ad-hoc manner, for\nexample, by employing their own private data splits or using a different\nexperimental setting. However, such conventions not only increase the\ndifficulty in reproducing existing studies, but also lead to inconsistent\nexperimental results among them. This largely limits the credibility and\npractical value of research results in this field. To tackle these issues, we\npresent an initiative project aimed for open benchamrking for recommender\nsystems. In contrast to some earlier attempts towards this goal, we take one\nfurther step by setting up a standardized benchmarking pipeline for\nreproducible research, which integrates all the details about datasets, source\ncode, hyper-parameter settings, running logs, and evaluation results. The\nbenchmark is designed with comprehensiveness and sustainability in mind. It\nspans both matching and ranking tasks, and also allows anyone to easily follow\nand contribute. We believe that our benchmark could not only reduce the\nredundant efforts of researchers to re-implement existing baselines, but also\ndrive more solid and reproducible research on recommender systems.",
    "descriptor": "\nComments: Accepted in SIGIR'2022. See BARS benchmark at this https URL\n",
    "authors": [
      "Jieming Zhu",
      "Kelong Mao",
      "Quanyu Dai",
      "Liangcai Su",
      "Rong Ma",
      "Jinyang Liu",
      "Guohao Cai",
      "Zhicheng Dou",
      "Xi Xiao",
      "Rui Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.09626"
  },
  {
    "id": "arXiv:2205.09628",
    "title": "What killed the Convex Booster ?",
    "abstract": "A landmark negative result of Long and Servedio established a worst-case\nspectacular failure of a supervised learning trio (loss, algorithm, model)\notherwise praised for its high precision machinery. Hundreds of papers followed\nup on the two suspected culprits: the loss (for being convex) and/or the\nalgorithm (for fitting a classical boosting blueprint). Here, we call to the\nhalf-century+ founding theory of losses for class probability estimation\n(properness), an extension of Long and Servedio's results and a new general\nboosting algorithm to demonstrate that the real culprit in their specific\ncontext was in fact the (linear) model class. We advocate for a more general\nstanpoint on the problem as we argue that the source of the negative result\nlies in the dark side of a pervasive -- and otherwise prized -- aspect of ML:\n\\textit{parameterisation}.",
    "descriptor": "",
    "authors": [
      "Yishay Mansour",
      "Richard Nock",
      "Robert C. Williamson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09628"
  },
  {
    "id": "arXiv:2205.09629",
    "title": "Stress-constrained topology optimization of lattice-like structures  using component-wise reduced order models",
    "abstract": "Lattice-like structures can provide a combination of high stiffness with\nlight weight that is useful in many applications, but a resolved finite element\nmesh of such structures results in a computationally expensive discretization.\nThis computational expense may be particularly burdensome in many-query\napplications, such as optimization. We develop a stress-constrained topology\noptimization method for lattice-like structures that uses component-wise\nreduced order models as a cheap surrogate, providing accurate computation of\nstress fields while greatly reducing run time relative to a full order model.\nWe demonstrate the ability of our method to produce large reductions in mass\nwhile respecting a constraint on the maximum stress in a pair of test problems.\nThe ROM methodology provides a speedup of about 150x in forward solves compared\nto full order static condensation and provides a relative error of less than 5%\nin the relaxed stress.",
    "descriptor": "\nComments: 25 pages, 9 figure; submitted to Computer Methods in Applied Mechanics and Engineering\n",
    "authors": [
      "Sean McBane",
      "Youngsoo Choi",
      "Karen Willcox"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.09629"
  },
  {
    "id": "arXiv:2205.09630",
    "title": "Acceptability Judgements via Examining the Topology of Attention Maps",
    "abstract": "The role of the attention mechanism in encoding linguistic knowledge has\nreceived special interest in NLP. However, the ability of the attention heads\nto judge the grammatical acceptability of a sentence has been underexplored.\nThis paper approaches the paradigm of acceptability judgments with topological\ndata analysis (TDA), showing that the geometric properties of the attention\ngraph can be efficiently exploited for two standard practices in linguistics:\nbinary judgments and linguistic minimal pairs. Topological features enhance the\nBERT-based acceptability classifier scores by $8$%-$24$% on CoLA in three\nlanguages (English, Italian, and Swedish). By revealing the topological\ndiscrepancy between attention maps of minimal pairs, we achieve the human-level\nperformance on the BLiMP benchmark, outperforming nine statistical and\nTransformer LM baselines. At the same time, TDA provides the foundation for\nanalyzing the linguistic functions of attention heads and interpreting the\ncorrespondence between the graph features and grammatical phenomena.",
    "descriptor": "",
    "authors": [
      "Daniil Cherniavskii",
      "Eduard Tulchinskii",
      "Vladislav Mikhailov",
      "Irina Proskurina",
      "Laida Kushnareva",
      "Ekaterina Artemova",
      "Serguei Barannikov",
      "Irina Piontkovskaya",
      "Dmitri Piontkovski",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09630"
  },
  {
    "id": "arXiv:2205.09634",
    "title": "Phylogeny-Inspired Adaptation of Multilingual Models to New Languages",
    "abstract": "Large pretrained multilingual models, trained on dozens of languages, have\ndelivered promising results due to cross-lingual learning capabilities on\nvariety of language tasks. Further adapting these models to specific languages,\nespecially ones unseen during pre-training, is an important goal towards\nexpanding the coverage of language technologies. In this study, we show how we\ncan use language phylogenetic information to improve cross-lingual transfer\nleveraging closely related languages in a structured, linguistically-informed\nmanner. We perform adapter-based training on languages from diverse language\nfamilies (Germanic, Uralic, Tupian, Uto-Aztecan) and evaluate on both syntactic\nand semantic tasks, obtaining more than 20% relative performance improvements\nover strong commonly used baselines, especially on languages unseen during\npre-training.",
    "descriptor": "",
    "authors": [
      "Fahim Faisal",
      "Antonios Anastasopoulos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09634"
  },
  {
    "id": "arXiv:2205.09635",
    "title": "BP-MAC: Fast Authentication for Short Messages",
    "abstract": "Resource-constrained devices increasingly rely on wireless communication for\nthe reliable and low-latency transmission of short messages. However,\nespecially the implementation of adequate integrity protection of time-critical\nmessages places a significant burden on these devices. We address this issue by\nproposing BP-MAC, a fast and memory-efficient approach for computing message\nauthentication codes based on the well-established Carter-Wegman construction.\nOur key idea is to offload resource-intensive computations to idle phases and\nthus save valuable time in latency-critical phases, i.e., when new data awaits\nprocessing. Therefore, BP-MAC leverages a universal hash function designed for\nthe bitwise preprocessing of integrity protection to later only require a few\nXOR operations during the latency-critical phase. Our evaluation on embedded\nhardware shows that BP-MAC outperforms the state-of-the-art in terms of latency\nand memory overhead, notably for small messages, as required to adequately\nprotect resource-constrained devices with stringent security and latency\nrequirements.",
    "descriptor": "\nComments: ACM WiSec'22\n",
    "authors": [
      "Eric Wagner",
      "Martin Serror",
      "Klaus Wehrle",
      "Martin Henze"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.09635"
  },
  {
    "id": "arXiv:2205.09638",
    "title": "Certified Error Control of Candidate Set Pruning for Two-Stage Relevance  Ranking",
    "abstract": "In information retrieval (IR), candidate set pruning has been commonly used\nto speed up two-stage relevance ranking. However, such an approach lacks\naccurate error control and often trades accuracy off against computational\nefficiency in an empirical fashion, lacking theoretical guarantees. In this\npaper, we propose the concept of certified error control of candidate set\npruning for relevance ranking, which means that the test error after pruning is\nguaranteed to be controlled under a user-specified threshold with high\nprobability. Both in-domain and out-of-domain experiments show that our method\nsuccessfully prunes the first-stage retrieved candidate sets to improve the\nsecond-stage reranking speed while satisfying the pre-specified accuracy\nconstraints in both settings. For example, on MS MARCO Passage v1, our method\nyields an average candidate set size of 27 out of 1,000 which increases the\nreranking speed by about 37 times, while the MRR@10 is greater than a\npre-specified value of 0.38 with about 90% empirical coverage and the empirical\nbaselines fail to provide such guarantee. Code and data are available at:\nhttps://github.com/alexlimh/CEC-Ranking.",
    "descriptor": "",
    "authors": [
      "Minghan Li",
      "Xinyu Zhang",
      "Ji Xin",
      "Hongyang Zhang",
      "Jimmy Lin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09638"
  },
  {
    "id": "arXiv:2205.09639",
    "title": "Multilevel Picard approximation algorithm for semilinear partial  integro-differential equations and its complexity analysis",
    "abstract": "In this paper we introduce a multilevel Picard approximation algorithm for\nsemilinear parabolic partial integro-differential equations (PIDEs). We prove\nthat the numerical approximation scheme converges to the unique viscosity\nsolution of the PIDE under consideration. To that end, we derive a Feynman-Kac\nrepresentation for the unique viscosity solution of the semilinear PIDE,\nextending the classical Feynman-Kac representation for linear PIDEs.\nFurthermore, we show that the algorithm does not suffer from the curse of\ndimensionality, i.e. the computational complexity of the algorithm is bounded\npolynomially in the dimension $d$ and the prescribed reciprocal of the accuracy\n$\\varepsilon$.",
    "descriptor": "",
    "authors": [
      "Ariel Neufeld",
      "Sizhou Wu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2205.09639"
  },
  {
    "id": "arXiv:2205.09641",
    "title": "SNaC: Coherence Error Detection for Narrative Summarization",
    "abstract": "Progress in summarizing long texts is inhibited by the lack of appropriate\nevaluation frameworks. When a long summary must be produced to appropriately\ncover the facets of that text, that summary needs to present a coherent\nnarrative to be understandable by a reader, but current automatic and human\nevaluation methods fail to identify gaps in coherence. In this work, we\nintroduce SNaC, a narrative coherence evaluation framework rooted in\nfine-grained annotations for long summaries. We develop a taxonomy of coherence\nerrors in generated narrative summaries and collect span-level annotations for\n6.6k sentences across 150 book and movie screenplay summaries. Our work\nprovides the first characterization of coherence errors generated by\nstate-of-the-art summarization models and a protocol for eliciting coherence\njudgments from crowd annotators. Furthermore, we show that the collected\nannotations allow us to train a strong classifier for automatically localizing\ncoherence errors in generated summaries as well as benchmarking past work in\ncoherence modeling. Finally, our SNaC framework can support future work in long\ndocument summarization and coherence evaluation, including improved\nsummarization modeling and post-hoc summary correction.",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Tanya Goyal",
      "Junyi Jessy Li",
      "Greg Durrett"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09641"
  },
  {
    "id": "arXiv:2205.09646",
    "title": "Great Power, Great Responsibility: Recommendations for Reducing Energy  for Training Language Models",
    "abstract": "The energy requirements of current natural language processing models\ncontinue to grow at a rapid, unsustainable pace. Recent works highlighting this\nproblem conclude there is an urgent need for methods that reduce the energy\nneeds of NLP and machine learning more broadly. In this article, we investigate\ntechniques that can be used to reduce the energy consumption of common NLP\napplications. In particular, we focus on techniques to measure energy usage and\ndifferent hardware and datacenter-oriented settings that can be tuned to reduce\nenergy consumption for training and inference for language models. We\ncharacterize the impact of these settings on metrics such as computational\nperformance and energy consumption through experiments conducted on a high\nperformance computing system as well as popular cloud computing platforms.\nThese techniques can lead to significant reduction in energy consumption when\ntraining language models or their use for inference. For example,\npower-capping, which limits the maximum power a GPU can consume, can enable a\n15\\% decrease in energy usage with marginal increase in overall computation\ntime when training a transformer-based language model.",
    "descriptor": "",
    "authors": [
      "Joseph McDonald",
      "Baolin Li",
      "Nathan Frey",
      "Devesh Tiwari",
      "Vijay Gadepally",
      "Siddharth Samsi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2205.09646"
  },
  {
    "id": "arXiv:2205.09648",
    "title": "Are Graph Representation Learning Methods Robust to Graph Sparsity and  Asymmetric Node Information?",
    "abstract": "The growing popularity of Graph Representation Learning (GRL) methods has\nresulted in the development of a large number of models applied to a miscellany\nof domains. Behind this diversity of domains, there is a strong heterogeneity\nof graphs, making it difficult to estimate the expected performance of a model\non a new graph, especially when the graph has distinctive characteristics that\nhave not been encountered in the benchmark yet. To address this, we have\ndeveloped an experimental pipeline, to assess the impact of a given property on\nthe models performances. In this paper, we use this pipeline to study the\neffect of two specificities encountered on banks transactional graphs resulting\nfrom the partial view a bank has on all the individuals and transactions\ncarried out on the market. These specific features are graph sparsity and\nasymmetric node information. This study demonstrates the robustness of GRL\nmethods to these distinctive characteristics. We believe that this work can\nease the evaluation of GRL methods to specific characteristics and foster the\ndevelopment of such methods on transactional graphs.",
    "descriptor": "\nComments: 9 paages, 3 figures\n",
    "authors": [
      "Pierre Sevestre",
      "Marine Neyret"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09648"
  },
  {
    "id": "arXiv:2205.09651",
    "title": "Named Entity Recognition, Multi-Task Learning, Nested Entities, BERT,  Arabic NER Corpus",
    "abstract": "This paper presents Wojood, a corpus for Arabic nested Named Entity\nRecognition (NER). Nested entities occur when one entity mention is embedded\ninside another entity mention. Wojood consists of about 550K Modern Standard\nArabic (MSA) and dialect tokens that are manually annotated with 21 entity\ntypes including person, organization, location, event and date. More\nimportantly, the corpus is annotated with nested entities instead of the more\ncommon flat annotations. The data contains about 75K entities and 22.5% of\nwhich are nested. The inter-annotator evaluation of the corpus demonstrated a\nstrong agreement with Cohen's Kappa of 0.979 and an F1-score of 0.976. To\nvalidate our data, we used the corpus to train a nested NER model based on\nmulti-task learning and AraBERT (Arabic BERT). The model achieved an overall\nmicro F1-score of 0.884. Our corpus, the annotation guidelines, the source code\nand the pre-trained model are publicly available.",
    "descriptor": "\nComments: In Proceedings of the International Conference on Language Resources and Evaluation (LREC 2022), Marseille, France\n",
    "authors": [
      "Mustafa Jarrar",
      "Mohammed Khalilia",
      "Sana Ghanem"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09651"
  },
  {
    "id": "arXiv:2205.09655",
    "title": "Primrose: Selecting Container Data Types by their Properties",
    "abstract": "Container data types are ubiquitous in computer programming, enabling\ndevelopers to efficiently store and process collections of data with an\neasy-to-use programming interface. Many programming languages offer a variety\nof container implementations in their standard libraries based on data\nstructures offering different capabilities and performance characteristics.\nChoosing the best container for an application is not straightforward, as\nperformance characteristics can change drastically in different scenarios, and\nreal-world performance is not always correlated to theoretical complexity. In\nthis paper, we present Primrose, a language-agnostic tool for selecting the\nbest performing valid container implementation from a set of container data\ntypes that satisfy the given properties. Semantic properties allow application\ndevelopers to specify the expected behaviour of a container as a type\nrefinement, e.g., if the container should only contain unique values (such as a\nset) or should satisfy the LIFO property of a stack. Semantic properties nicely\ncomplement syntactic properties (i.e., traits, interfaces, or type classes),\nallowing developers to specify a container's programming interface and\nbehaviour without committing to a concrete implementation. Primrose\nautomatically select the set of valid container implementations for which the\nlibrary specifications, written by the developers of container libraries,\nsatisfies the specified properties. Finally, Primrose ranks the valid library\nimplementations based on their runtime performance. We present our prototype\nimplementation of Primrose that preprocesses annotated Rust code, selecting the\nbest performing container implementation. Primrose is easy to integrate in\nother programming languages. We encode properties and library specifications\ninto verification conditions in a SMT solver to determine the set of valid\ncontainer implementations.",
    "descriptor": "",
    "authors": [
      "Xueying Qin",
      "Liam O'Connor",
      "Michel Steuwer"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.09655"
  },
  {
    "id": "arXiv:2205.09658",
    "title": "Image-Based Conditioning for Action Policy Smoothness in Autonomous  Miniature Car Racing with Reinforcement Learning",
    "abstract": "In recent years, deep reinforcement learning has achieved significant results\nin low-level controlling tasks. However, the problem of control smoothness has\nless attention. In autonomous driving, unstable control is inevitable since the\nvehicle might suddenly change its actions. This problem will lower the\ncontrolling system's efficiency, induces excessive mechanical wear, and causes\nuncontrollable, dangerous behavior to the vehicle. In this paper, we apply the\nConditioning for Action Policy Smoothness (CAPS) with image-based input to\nsmooth the control of an autonomous miniature car racing. Applying CAPS and\nsim-to-real transfer methods helps to stabilize the control at a higher speed.\nEspecially, the agent with CAPS and CycleGAN reduces 21.80% of the average\nfinishing lap time. Moreover, we also conduct extensive experiments to analyze\nthe impact of CAPS components.",
    "descriptor": "",
    "authors": [
      "Bo-Jiun Hsu",
      "Hoang-Giang Cao",
      "I Lee",
      "Chih-Yu Kao",
      "Jin-Bo Huang",
      "I-Chen Wu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.09658"
  },
  {
    "id": "arXiv:2205.09659",
    "title": "An Efficient Piggybacking Design Framework with Sub-packetization $l\\le  r$ for All-Node Repair",
    "abstract": "Piggybacking design has been widely applied in distributed storage systems\nsince it can greatly reduce the repair bandwidth with small sub-packetization.\nCompared with other existing erasure codes, piggybacking is more convenient to\noperate and the I/O cost is lower. In this paper, we propose a new efficient\ndesign which can further reduce the repair bandwidth with the sub-packetization\n$l\\le r$ where $r = n-k$. Generally, we let $l\\le 8$. Compared with other\nanalogous designs, our design has lower $l$ and the value of $l$ is more\nflexible. Moreover, our design can repair all nodes with small repair\nbandwidth. Therefore our piggybacking design is more feasible.",
    "descriptor": "",
    "authors": [
      "Ke Wang",
      "Zhifang Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.09659"
  },
  {
    "id": "arXiv:2205.09661",
    "title": "Self-augmented Data Selection for Few-shot Dialogue Generation",
    "abstract": "The natural language generation (NLG) module in task-oriented dialogue\nsystems translates structured meaning representations (MRs) into text\nresponses, which has a great impact on users' experience as the human-machine\ninteraction interface. However, in practice, developers often only have a few\nwell-annotated data and confront a high data collection cost to build the NLG\nmodule. In this work, we adopt the self-training framework to deal with the\nfew-shot MR-to-Text generation problem. We leverage the pre-trained language\nmodel to self-augment many pseudo-labeled data. To prevent the gradual drift\nfrom target data distribution to noisy augmented data distribution, we propose\na novel data selection strategy to select the data that our generation model is\nmost uncertain about. Compared with existing data selection methods, our method\nis: (1) parameter-efficient, which does not require training any additional\nneural models, (2) computation-efficient, which only needs to apply several\nstochastic forward passes of the model to estimate the uncertainty. We conduct\nempirical experiments on two benchmark datasets: FewShotWOZ and FewShotSGD, and\nshow that our proposed framework consistently outperforms other baselines in\nterms of BLEU and ERR.",
    "descriptor": "",
    "authors": [
      "Wanyu Du",
      "Hanjie Chen",
      "Yangfeng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09661"
  },
  {
    "id": "arXiv:2205.09663",
    "title": "Collision Detection Accelerated: An Optimization Perspective",
    "abstract": "Collision detection between two convex shapes is an essential feature of any\nphysics engine or robot motion planner. It has often been tackled as a\ncomputational geometry problem, with the Gilbert, Johnson and Keerthi (GJK)\nalgorithm being the most common approach today. In this work we leverage the\nfact that collision detection is fundamentally a convex optimization problem.\nIn particular, we establish that the GJK algorithm is a specific sub-case of\nthe well-established Frank-Wolfe (FW) algorithm in convex optimization. We\nintroduce a new collision detection algorithm by adapting recent works linking\nNesterov acceleration and Frank-Wolfe methods. We benchmark the proposed\naccelerated collision detection method on two datasets composed of strictly\nconvex and non-strictly convex shapes. Our results show that our approach\nsignificantly reduces the number of iterations to solve collision detection\nproblems compared to the state-of-the-art GJK algorithm, leading to up to two\ntimes faster computation times.",
    "descriptor": "\nComments: RSS 2022, 12 pages, 9 figures, 2 tables\n",
    "authors": [
      "Louis Montaut",
      "Quentin Le Lidec",
      "Josef Sivic",
      "Justin Carpentier"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.09663"
  },
  {
    "id": "arXiv:2205.09664",
    "title": "The Arabic Ontology -- An Arabic Wordnet with Ontologically Clean  Content",
    "abstract": "We present a formal Arabic wordnet built on the basis of a carefully designed\nontology hereby referred to as the Arabic Ontology. The ontology provides a\nformal representation of the concepts that the Arabic terms convey, and its\ncontent was built with ontological analysis in mind, and benchmarked to\nscientific advances and rigorous knowledge sources as much as this is possible,\nrather than to only speakers' beliefs as lexicons typically are. A\ncomprehensive evaluation was conducted thereby demonstrating that the current\nversion of the top-levels of the ontology can top the majority of the Arabic\nmeanings. The ontology consists currently of about 1,300 well-investigated\nconcepts in addition to 11,000 concepts that are partially validated. The\nontology is accessible and searchable through a lexicographic search engine\n(https://ontology.birzeit.edu) that also includes about 150 Arabic-multilingual\nlexicons, and which are being mapped and enriched using the ontology. The\nontology is fully mapped with Princeton WordNet, Wikidata, and other resources.",
    "descriptor": "",
    "authors": [
      "Mustafa Jarrar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.09664"
  },
  {
    "id": "arXiv:2205.09665",
    "title": "Automated Crossword Solving",
    "abstract": "We present the Berkeley Crossword Solver, a state-of-the-art approach for\nautomatically solving crossword puzzles. Our system works by generating answer\ncandidates for each crossword clue using neural question answering models and\nthen combines loopy belief propagation with local search to find full puzzle\nsolutions. Compared to existing approaches, our system improves exact puzzle\naccuracy from 57% to 82% on crosswords from The New York Times and obtains\n99.9% letter accuracy on themeless puzzles. Our system also won first place at\nthe top human crossword tournament, which marks the first time that a computer\nprogram has surpassed human performance at this event. To facilitate research\non question answering and crossword solving, we analyze our system's remaining\nerrors and release a dataset of over six million question-answer pairs.",
    "descriptor": "",
    "authors": [
      "Eric Wallace",
      "Nicholas Tomlin",
      "Albert Xu",
      "Kevin Yang",
      "Eshaan Pathak",
      "Matthew Ginsberg",
      "Dan Klein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09665"
  },
  {
    "id": "arXiv:2205.09666",
    "title": "Personalized Prompts for Sequential Recommendation",
    "abstract": "Pre-training models have shown their power in sequential recommendation.\nRecently, prompt has been widely explored and verified for tuning in NLP\npre-training, which could help to more effectively and efficiently extract\nuseful knowledge from pre-training models for downstream tasks, especially in\ncold-start scenarios. However, it is challenging to bring prompt-tuning from\nNLP to recommendation, since the tokens in recommendation (i.e., items) do not\nhave explicit explainable semantics, and the sequence modeling should be\npersonalized. In this work, we first introduces prompt to recommendation and\npropose a novel Personalized prompt-based recommendation (PPR) framework for\ncold-start recommendation. Specifically, we build the personalized soft prefix\nprompt via a prompt generator based on user profiles and enable a sufficient\ntraining of prompts via a prompt-oriented contrastive learning with both\nprompt- and behavior-based augmentations. We conduct extensive evaluations on\nvarious tasks. In both few-shot and zero-shot recommendation, PPR models\nachieve significant improvements over baselines on various metrics in three\nlarge-scale open datasets. We also conduct ablation tests and sparsity analysis\nfor a better understanding of PPR. Moreover, We further verify PPR's\nuniversality on different pre-training models, and conduct explorations on\nPPR's other promising downstream tasks including cross-domain recommendation\nand user profile prediction.",
    "descriptor": "",
    "authors": [
      "Yiqing Wu",
      "Ruobing Xie",
      "Yongchun Zhu",
      "Fuzhen Zhuang",
      "Xu Zhang",
      "Leyu Lin",
      "Qing He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.09666"
  },
  {
    "id": "arXiv:2205.09667",
    "title": "The AI Mechanic: Acoustic Vehicle Characterization Neural Networks",
    "abstract": "In a world increasingly dependent on road-based transportation, it is\nessential to understand vehicles. We introduce the AI mechanic, an acoustic\nvehicle characterization deep learning system, as an integrated approach using\nsound captured from mobile devices to enhance transparency and understanding of\nvehicles and their condition for non-expert users. We develop and implement\nnovel cascading architectures for vehicle understanding, which we define as\nsequential, conditional, multi-level networks that process raw audio to extract\nhighly-granular insights. To showcase the viability of cascading architectures,\nwe build a multi-task convolutional neural network that predicts and cascades\nvehicle attributes to enhance fault detection. We train and test these models\non a synthesized dataset reflecting more than 40 hours of augmented audio and\nachieve >92% validation set accuracy on attributes (fuel type, engine\nconfiguration, cylinder count and aspiration type). Our cascading architecture\nadditionally achieved 93.6% validation and 86.8% test set accuracy on misfire\nfault prediction, demonstrating margins of 16.4% / 7.8% and 4.2% / 1.5%\nimprovement over na\\\"ive and parallel baselines. We explore experimental\nstudies focused on acoustic features, data augmentation, feature fusion, and\ndata reliability. Finally, we conclude with a discussion of broader\nimplications, future directions, and application areas for this work.",
    "descriptor": "\nComments: 34 pages, 12 figures, 28 tables\n",
    "authors": [
      "Adam M. Terwilliger",
      "Joshua E. Siegel"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.09667"
  },
  {
    "id": "arXiv:2205.09669",
    "title": "Semi-WTC: A Practical Semi-supervised Framework for Attack  Categorization through Weight-Task Consistency",
    "abstract": "Supervised learning has been widely used for attack detection, which requires\nlarge amounts of high-quality data and labels. However, the data is often\nimbalanced and sufficient annotations are difficult to obtain. Moreover, these\nsupervised models are subject to real-world deployment issues, such as\ndefending against unseen artificial attacks. We propose a semi-supervised\nfine-grained attack categorization framework consisting of an encoder and a\ntwo-branch structure to integrate information from labeled and unlabeled data\nto tackle these practical challenges. This framework can be generalized to\ndifferent supervised models. The multilayer perceptron with residual connection\nand batch normalization is used as the encoder to extract features and reduce\nthe complexity. The Recurrent Prototype Module (RPM) is proposed to train the\nencoder effectively in a semi-supervised manner. To alleviate the problem of\ndata imbalance, we introduce the Weight-Task Consistency (WTC) into the\niterative process of RPM by assigning larger weights to classes with fewer\nsamples in the loss function. In addition, to cope with new attacks in\nreal-world deployment, we further propose an Active Adaption Resampling (AAR)\nmethod, which can better discover the distribution of the unseen sample data\nand adapt the parameters of the encoder. Experimental results show that our\nmodel outperforms the state-of-the-art semi-supervised attack detection methods\nwith a general 5% improvement in classification accuracy and a 90% reduction in\ntraining time.",
    "descriptor": "",
    "authors": [
      "Zihan Li",
      "Wentao Chen",
      "Zhiqing Wei",
      "Xingqi Luo",
      "Bing Su"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09669"
  },
  {
    "id": "arXiv:2205.09670",
    "title": "A Unified Collaborative Representation Learning for Neural-Network based  Recommender Systems",
    "abstract": "Most NN-RSs focus on accuracy by building representations from the direct\nuser-item interactions (e.g., user-item rating matrix), while ignoring the\nunderlying relatedness between users and items (e.g., users who rate the same\nratings for the same items should be embedded into similar representations),\nwhich is an ideological disadvantage. On the other hand, ME models directly\nemploy inner products as a default loss function metric that cannot project\nusers and items into a proper latent space, which is a methodological\ndisadvantage. In this paper, we propose a supervised collaborative\nrepresentation learning model - Magnetic Metric Learning (MML) - to map users\nand items into a unified latent vector space, enhancing the representation\nlearning for NN-RSs. Firstly, MML utilizes dual triplets to model not only the\nobserved relationships between users and items, but also the underlying\nrelationships between users as well as items to overcome the ideological\ndisadvantage. Specifically, a modified metric-based dual loss function is\nproposed in MML to gather similar entities and disperse the dissimilar ones.\nWith MML, we can easily compare all the relationships (user to user, item to\nitem, user to item) according to the weighted metric, which overcomes the\nmethodological disadvantage. We conduct extensive experiments on four\nreal-world datasets with large item space. The results demonstrate that MML can\nlearn a proper unified latent space for representations from the user-item\nmatrix with high accuracy and effectiveness, and lead to a performance gain\nover the state-of-the-art RS models by an average of 17%.",
    "descriptor": "\nComments: Accepted by IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING(TKDE)\n",
    "authors": [
      "Yuanbo Xu",
      "En Wang",
      "Yongjian Yang",
      "Yi Chang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.09670"
  },
  {
    "id": "arXiv:2205.09671",
    "title": "A graph-transformer for whole slide image classification",
    "abstract": "Deep learning is a powerful tool for whole slide image (WSI) analysis.\nTypically, when performing supervised deep learning, a WSI is divided into\nsmall patches, trained and the outcomes are aggregated to estimate disease\ngrade. However, patch-based methods introduce label noise during training by\nassuming that each patch is independent with the same label as the WSI and\nneglect overall WSI-level information that is significant in disease grading.\nHere we present a Graph-Transformer (GT) that fuses a graph-based\nrepresentation of an WSI and a vision transformer for processing pathology\nimages, called GTP, to predict disease grade. We selected $4,818$ WSIs from the\nClinical Proteomic Tumor Analysis Consortium (CPTAC), the National Lung\nScreening Trial (NLST), and The Cancer Genome Atlas (TCGA), and used GTP to\ndistinguish adenocarcinoma (LUAD) and squamous cell carcinoma (LSCC) from\nadjacent non-cancerous tissue (normal). First, using NLST data, we developed a\ncontrastive learning framework to generate a feature extractor. This allowed us\nto compute feature vectors of individual WSI patches, which were used to\nrepresent the nodes of the graph followed by construction of the GTP framework.\nOur model trained on the CPTAC data achieved consistently high performance on\nthree-label classification (normal versus LUAD versus LSCC: mean accuracy$=\n91.2$ $\\pm$ $2.5\\%$) based on five-fold cross-validation, and mean accuracy $=\n82.3$ $\\pm$ $1.0\\%$ on external test data (TCGA). We also introduced a\ngraph-based saliency mapping technique, called GraphCAM, that can identify\nregions that are highly associated with the class label. Our findings\ndemonstrate GTP as an interpretable and effective deep learning framework for\nWSI-level classification.",
    "descriptor": "",
    "authors": [
      "Yi Zheng",
      "Rushin H. Gindra",
      "Emily J. Green",
      "Eric J. Burks",
      "Margrit Betke",
      "Jennifer E. Beane",
      "Vijaya B. Kolachalama"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09671"
  },
  {
    "id": "arXiv:2205.09672",
    "title": "A Note on Categories about Rough Sets",
    "abstract": "Using the concepts of category and functor, we provide some insights and\nprove an intrinsic property of the category ${\\bf AprS}$ of approximation\nspaces and relation-preserving functions, the category ${\\bf RCls}$ of rough\nclosure spaces and continuous functions, and the category ${\\bf RInt}$ of rough\ninterior spaces and continuous functions. Furthermore, we define the category\n${\\bf IS}$ of information systems and O-A-D homomorphisms, and establish the\nrelationship between the category ${\\bf IS}$ and the category ${\\bf AprS}$ by\nconsidering a subcategory ${\\bf NeIS}$ of ${\\bf IS}$ whose objects are\ninformation systems and whose arrows are non-expensive O-A-D homomorphisms with\nsurjective attribute mappings.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Y.R. Syau",
      "E.B. Lin",
      "C.J. Liau"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.09672"
  },
  {
    "id": "arXiv:2205.09673",
    "title": "Detect Professional Malicious User with Metric Learning in Recommender  Systems",
    "abstract": "In e-commerce, online retailers are usually suffering from professional\nmalicious users (PMUs), who utilize negative reviews and low ratings to their\nconsumed products on purpose to threaten the retailers for illegal profits.\nSpecifically, there are three challenges for PMU detection: 1) professional\nmalicious users do not conduct any abnormal or illegal interactions (they never\nconcurrently leave too many negative reviews and low ratings at the same time),\nand they conduct masking strategies to disguise themselves. Therefore,\nconventional outlier detection methods are confused by their masking\nstrategies. 2) the PMU detection model should take both ratings and reviews\ninto consideration, which makes PMU detection a multi-modal problem. 3) there\nare no datasets with labels for professional malicious users in public, which\nmakes PMU detection an unsupervised learning problem. To this end, we propose\nan unsupervised multi-modal learning model: MMD, which employs Metric learning\nfor professional Malicious users Detection with both ratings and reviews. MMD\nfirst utilizes a modified RNN to project the informational review into a\nsentiment score, which jointly considers the ratings and reviews. Then\nprofessional malicious user profiling (MUP) is proposed to catch the sentiment\ngap between sentiment scores and ratings. MUP filters the users and builds a\ncandidate PMU set. We apply a metric learning-based clustering to learn a\nproper metric matrix for PMU detection. Finally, we can utilize this metric and\nlabeled users to detect PMUs. Specifically, we apply the attention mechanism in\nmetric learning to improve the model's performance. The extensive experiments\nin four datasets demonstrate that our proposed method can solve this\nunsupervised detection problem. Moreover, the performance of the\nstate-of-the-art recommender models is enhanced by taking MMD as a\npreprocessing stage.",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Knowledge and Data Engineering (TKDE)\n",
    "authors": [
      "Yuanbo Xu",
      "Yongjian Yang",
      "En Wang",
      "Fuzhen Zhuang",
      "Hui Xiong"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09673"
  },
  {
    "id": "arXiv:2205.09674",
    "title": "Disentangling Active and Passive Cosponsorship in the U.S. Congress",
    "abstract": "In the U.S. Congress, legislators can use active and passive cosponsorship to\nsupport bills. We show that these two types of cosponsorship are driven by two\ndifferent motivations: the backing of political colleagues and the backing of\nthe bill's content. To this end, we develop an Encoder+RGCN based model that\nlearns legislator representations from bill texts and speech transcripts. These\nrepresentations predict active and passive cosponsorship with an F1-score of\n0.88. Applying our representations to predict voting decisions, we show that\nthey are interpretable and generalize to unseen tasks.",
    "descriptor": "\nComments: 20 pages, 10 figures, 6 tables\n",
    "authors": [
      "Giuseppe Russo",
      "Christoph Gote",
      "Laurence Brandenberger",
      "Sophia Schlosser",
      "Frank Schweitzer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.09674"
  },
  {
    "id": "arXiv:2205.09676",
    "title": "Beyond Greedy Search: Tracking by Multi-Agent Reinforcement  Learning-based Beam Search",
    "abstract": "Existing trackers usually select a location or proposal with the maximum\nscore as tracking result for each frame. However, such greedy search scheme\nmaybe not the optimal choice, especially when encountering challenging tracking\nscenarios like heavy occlusions and fast motion. Since the accumulated errors\nwould make response scores not reliable anymore. In this paper, we propose a\nnovel multi-agent reinforcement learning based beam search strategy (termed\nBeamTracking) to address this issue. Specifically, we formulate the tracking as\na sample selection problem fulfilled by multiple parallel decision-making\nprocesses, each of which aims at picking out one sample as their tracking\nresult in each frame. We take the target feature, proposal feature, and its\nresponse score as state, and also consider actions predicted by nearby agent,\nto train multi-agents to select their actions. When all the frames are\nprocessed, we select the trajectory with the maximum accumulated score as the\ntracking result. Extensive experiments on seven popular tracking benchmark\ndatasets validated the effectiveness of the proposed algorithm.",
    "descriptor": "\nComments: In Peer Review\n",
    "authors": [
      "Xiao Wang",
      "Zhe Chen",
      "Jin Tang",
      "Bin Luo",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09676"
  },
  {
    "id": "arXiv:2205.09678",
    "title": "Semi-Supervised Learning for Image Classification using Compact Networks  in the BioMedical Context",
    "abstract": "The development of mobile and on the edge applications that embed deep\nconvolutional neural models has the potential to revolutionise biomedicine.\nHowever, most deep learning models require computational resources that are not\navailable in smartphones or edge devices; an issue that can be faced by means\nof compact models. The problem with such models is that they are, at least\nusually, less accurate than bigger models. In this work, we study how this\nlimitation can be addressed with the application of semi-supervised learning\ntechniques. We conduct several statistical analyses to compare performance of\ndeep compact architectures when trained using semi-supervised learning methods\nfor tackling image classification tasks in the biomedical context. In\nparticular, we explore three families of compact networks, and two families of\nsemi-supervised learning techniques for 10 biomedical tasks. By combining\nsemi-supervised learning methods with compact networks, it is possible to\nobtain a similar performance to standard size networks. In general, the best\nresults are obtained when combining data distillation with MixNet, and plain\ndistillation with ResNet-18. Also, in general, NAS networks obtain better\nresults than manually designed networks and quantized networks. The work\npresented in this paper shows the benefits of apply semi-supervised methods to\ncompact networks; this allow us to create compact models that are not only as\naccurate as standard size models, but also faster and lighter. Finally, we have\ndeveloped a library that simplifies the construction of compact models using\nsemi-supervised learning methods.",
    "descriptor": "",
    "authors": [
      "Adri\u00e1n In\u00e9s",
      "Andr\u00e9s D\u00edaz-Pinto",
      "C\u00e9sar Dom\u00ednguez",
      "J\u00f3nathan Heras",
      "Eloy Mata",
      "Vico Pascual"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09678"
  },
  {
    "id": "arXiv:2205.09681",
    "title": "Bridging the Gap between Data Integration and ML Systems",
    "abstract": "The data needed for machine learning (ML) model training and inference, can\nreside in different separate sites often termed data silos. For data-intensive\nML applications, data silos present a major challenge: the integration and\ntransformation of data, demand a lot of manual work and computational\nresources. Sometimes, data cannot leave the local store, and the model has to\nbe trained in a decentralized manner. In this work, we propose three\nmatrix-based dataset relationship representations, which bridge the classical\ndata integration (DI) techniques with the requirements of modern machine\nlearning. We discuss how those matrices pave the path for utilizing DI\nformalisms and techniques for our vision of ML optimization and automation over\ndata silos.",
    "descriptor": "",
    "authors": [
      "Rihan Hai",
      "Yan Kang",
      "Christos Koutras",
      "Andra Ionescu",
      "Asterios Katsifodimos"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2205.09681"
  },
  {
    "id": "arXiv:2205.09682",
    "title": "Comparing single-node and multi-node performance of an important fusion  HPC code benchmark",
    "abstract": "Fusion simulations have traditionally required the use of leadership scale\nHigh Performance Computing (HPC) resources in order to produce advances in\nphysics. The impressive improvements in compute and memory capacity of many-GPU\ncompute nodes are now allowing for some problems that once required a\nmulti-node setup to be also solvable on a single node. When possible, the\nincreased interconnect bandwidth can result in order of magnitude higher\nscience throughput, especially for communication-heavy applications. In this\npaper we analyze the performance of the fusion simulation tool CGYRO, an\nEulerian gyrokinetic turbulence solver designed and optimized for collisional,\nelectromagnetic, multiscale simulation, which is widely used in the fusion\nresearch community. Due to the nature of the problem, the application has to\nwork on a large multi-dimensional computational mesh as a whole, requiring\nfrequent exchange of large amounts of data between the compute processes. In\nparticular, we show that the average-scale nl03 benchmark CGYRO simulation can\nbe run at an acceptable speed on a single Google Cloud instance with 16 A100\nGPUs, outperforming 8 NERSC Perlmutter Phase1 nodes, 16 ORNL Summit nodes and\n256 NERSC Cori nodes. Moving from a multi-node to a single-node GPU setup we\nget comparable simulation times using less than half the number of GPUs. Larger\nbenchmark problems, however, still require a multi-node HPC setup due to GPU\nmemory capacity needs, since at the time of writing no vendor offers nodes with\na sufficient GPU memory setup. The upcoming external NVSWITCH does however\npromise to deliver an almost equivalent solution for up to 256 NVIDIA GPUs.",
    "descriptor": "\nComments: 6 pages, 1 table, 1 figure, to be published in proceedings of PEARC22\n",
    "authors": [
      "Emily A. Belli",
      "Jeff Candy",
      "Igor Sfiligoi",
      "Frank W\u00fcrthwein"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Plasma Physics (physics.plasm-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.09682"
  },
  {
    "id": "arXiv:2205.09683",
    "title": "Dexterous Robotic Manipulation using Deep Reinforcement Learning and  Knowledge Transfer for Complex Sparse Reward-based Tasks",
    "abstract": "This paper describes a deep reinforcement learning (DRL) approach that won\nPhase 1 of the Real Robot Challenge (RRC) 2021, and then extends this method to\na more difficult manipulation task. The RRC consisted of using a TriFinger\nrobot to manipulate a cube along a specified positional trajectory, but with no\nrequirement for the cube to have any specific orientation. We used a relatively\nsimple reward function, a combination of goal-based sparse reward and distance\nreward, in conjunction with Hindsight Experience Replay (HER) to guide the\nlearning of the DRL agent (Deep Deterministic Policy Gradient (DDPG)). Our\napproach allowed our agents to acquire dexterous robotic manipulation\nstrategies in simulation. These strategies were then applied to the real robot\nand outperformed all other competition submissions, including those using more\ntraditional robotic control techniques, in the final evaluation stage of the\nRRC. Here we extend this method, by modifying the task of Phase 1 of the RRC to\nrequire the robot to maintain the cube in a particular orientation, while the\ncube is moved along the required positional trajectory. The requirement to also\norient the cube makes the agent unable to learn the task through blind\nexploration due to increased problem complexity. To circumvent this issue, we\nmake novel use of a Knowledge Transfer (KT) technique that allows the\nstrategies learned by the agent in the original task (which was agnostic to\ncube orientation) to be transferred to this task (where orientation matters).\nKT allowed the agent to learn and perform the extended task in the simulator,\nwhich improved the average positional deviation from 0.134 m to 0.02 m, and\naverage orientation deviation from 142{\\deg} to 76{\\deg} during evaluation.\nThis KT concept shows good generalisation properties and could be applied to\nany actor-critic learning algorithm.",
    "descriptor": "\nComments: This paper has been summited to Expert Systems: the Journal of Knowledge Engineering for reviewing\n",
    "authors": [
      "Qiang Wang",
      "Francisco Roldan Sanchez",
      "Robert McCarthy",
      "David Cordova Bulens",
      "Kevin McGuinness",
      "Noel O'Connor",
      "Manuel W\u00fcthrich",
      "Felix Widmaier",
      "Stefan Bauer",
      "Stephen J. Redmond"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09683"
  },
  {
    "id": "arXiv:2205.09685",
    "title": "ArabGlossBERT: Fine-Tuning BERT on Context-Gloss Pairs for WSD",
    "abstract": "Using pre-trained transformer models such as BERT has proven to be effective\nin many NLP tasks. This paper presents our work to fine-tune BERT models for\nArabic Word Sense Disambiguation (WSD). We treated the WSD task as a\nsentence-pair binary classification task. First, we constructed a dataset of\nlabeled Arabic context-gloss pairs (~167k pairs) we extracted from the Arabic\nOntology and the large lexicographic database available at Birzeit University.\nEach pair was labeled as True or False and target words in each context were\nidentified and annotated. Second, we used this dataset for fine-tuning three\npre-trained Arabic BERT models. Third, we experimented the use of different\nsupervised signals used to emphasize target words in context. Our experiments\nachieved promising results (accuracy of 84%) although we used a large set of\nsenses in the experiment.",
    "descriptor": "",
    "authors": [
      "Moustafa Al-Hajj",
      "Mustafa Jarrar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09685"
  },
  {
    "id": "arXiv:2205.09690",
    "title": "VNT-Net: Rotational Invariant Vector Neuron Transformers",
    "abstract": "Learning 3D point sets with rotational invariance is an important and\nchallenging problem in machine learning. Through rotational invariant\narchitectures, 3D point cloud neural networks are relieved from requiring a\ncanonical global pose and from exhaustive data augmentation with all possible\nrotations. In this work, we introduce a rotational invariant neural network by\ncombining recently introduced vector neurons with self-attention layers to\nbuild a point cloud vector neuron transformer network (VNT-Net). Vector neurons\nare known for their simplicity and versatility in representing SO(3) actions\nand are thereby incorporated in common neural operations. Similarly,\nTransformer architectures have gained popularity and recently were shown\nsuccessful for images by applying directly on sequences of image patches and\nachieving superior performance and convergence. In order to benefit from both\nworlds, we combine the two structures by mainly showing how to adapt the\nmulti-headed attention layers to comply with vector neurons operations. Through\nthis adaptation attention layers become SO(3) and the overall network becomes\nrotational invariant. Experiments demonstrate that our network efficiently\nhandles 3D point cloud objects in arbitrary poses. We also show that our\nnetwork achieves higher accuracy when compared to related state-of-the-art\nmethods and requires less training due to a smaller number of hyperparameters\nin common classification and segmentation tasks.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2104.12229 by other authors\n",
    "authors": [
      "Hedi Zisling",
      "Andrei Sharf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09690"
  },
  {
    "id": "arXiv:2205.09692",
    "title": "Curras + Baladi: Towards a Levantine Corpus",
    "abstract": "The processing of the Arabic language is a complex field of research. This is\ndue to many factors, including the complex and rich morphology of Arabic, its\nhigh degree of ambiguity, and the presence of several regional varieties that\nneed to be processed while taking into account their unique characteristics.\nWhen its dialects are taken into account, this language pushes the limits of\nNLP to find solutions to problems posed by its inherent nature. It is a\ndiglossic language; the standard language is used in formal settings and in\neducation and is quite different from the vernacular languages spoken in the\ndifferent regions and influenced by older languages that were historically\nspoken in those regions. This should encourage NLP specialists to create\ndialect-specific corpora such as the Palestinian morphologically annotated\nCurras corpus of Birzeit University. In this work, we present the Lebanese\nCorpus Baladi that consists of around 9.6K morphologically annotated tokens.\nSince Lebanese and Palestinian dialects are part of the same Levantine\ndialectal continuum, and thus highly mutually intelligible, our proposed corpus\nwas constructed to be used to (1) enrich Curras and transform it into a more\ngeneral Levantine corpus and (2) improve Curras by solving detected errors.",
    "descriptor": "",
    "authors": [
      "Karim El Haff",
      "Mustafa Jarrar",
      "Tymaa Hammouda",
      "Fadi Zaraket"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09692"
  },
  {
    "id": "arXiv:2205.09693",
    "title": "Individual and Collective Performance Deteriorate in a New Team: A Case  Study of CS:GO Tournaments",
    "abstract": "How does the team formation relates to team performance in professional video\ngame playing? This study examined one aspect of group dynamics - team switching\n- and aims to answer how changing a team affects individual and collective\nperformance in eSports tournaments. In this study we test the hypothesis that\nswitching teams can be detrimental to individual and team performance both in\nshort term and in a long run. We collected data from professional tournaments\nof a popular first-person shooter game {\\itshape Counter-Strike: Global\nOffensive (CS:GO)} and perform two natural experiments. We found that the\nplayer's performance was inversely correlated with the number of teams a player\nhad joined. After a player switched to a new team, both the individual and the\ncollective performance dropped initially, and then slowly recovered. The\nfindings in this study can provide insights for understanding group dynamics in\neSports team play and eventually emphasize the importance of team cohesion in\nfacilitating team collaboration, coordination, and knowledge sharing in\nteamwork in general.",
    "descriptor": "",
    "authors": [
      "Weiwei Zhang",
      "Goran Muric",
      "Emilio Ferrara"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.09693"
  },
  {
    "id": "arXiv:2205.09696",
    "title": "Who Goes First? Influences of Human-AI Workflow on Decision Making in  Clinical Imaging",
    "abstract": "Details of the designs and mechanisms in support of human-AI collaboration\nmust be considered in the real-world fielding of AI technologies. A critical\naspect of interaction design for AI-assisted human decision making are policies\nabout the display and sequencing of AI inferences within larger decision-making\nworkflows. We have a poor understanding of the influences of making AI\ninferences available before versus after human review of a diagnostic task at\nhand. We explore the effects of providing AI assistance at the start of a\ndiagnostic session in radiology versus after the radiologist has made a\nprovisional decision. We conducted a user study where 19 veterinary\nradiologists identified radiographic findings present in patients' X-ray\nimages, with the aid of an AI tool. We employed two workflow configurations to\nanalyze (i) anchoring effects, (ii) human-AI team diagnostic performance and\nagreement, (iii) time spent and confidence in decision making, and (iv)\nperceived usefulness of the AI. We found that participants who are asked to\nregister provisional responses in advance of reviewing AI inferences are less\nlikely to agree with the AI regardless of whether the advice is accurate and,\nin instances of disagreement with the AI, are less likely to seek the second\nopinion of a colleague. These participants also reported the AI advice to be\nless useful. Surprisingly, requiring provisional decisions on cases in advance\nof the display of AI inferences did not lengthen the time participants spent on\nthe task. The study provides generalizable and actionable insights for the\ndeployment of clinical AI tools in human-in-the-loop systems and introduces a\nmethodology for studying alternative designs for human-AI collaboration. We\nmake our experimental platform available as open source to facilitate future\nresearch on the influence of alternate designs on human-AI workflows.",
    "descriptor": "\nComments: Accepted at ACM Conference on Fairness, Accountability, and Transparency (FAccT), 2022\n",
    "authors": [
      "Riccardo Fogliato",
      "Shreya Chappidi",
      "Matthew Lungren",
      "Michael Fitzke",
      "Mark Parkinson",
      "Diane Wilson",
      "Paul Fisher",
      "Eric Horvitz",
      "Kori Inkpen",
      "Besmira Nushi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09696"
  },
  {
    "id": "arXiv:2205.09701",
    "title": "Homophily and Incentive Effects in Use of Algorithms",
    "abstract": "As algorithmic tools increasingly aid experts in making consequential\ndecisions, the need to understand the precise factors that mediate their\ninfluence has grown commensurately. In this paper, we present a crowdsourcing\nvignette study designed to assess the impacts of two plausible factors on\nAI-informed decision-making. First, we examine homophily -- do people defer\nmore to models that tend to agree with them? -- by manipulating the agreement\nduring training between participants and the algorithmic tool. Second, we\nconsidered incentives -- how do people incorporate a (known) cost structure in\nthe hybrid decision-making setting? -- by varying rewards associated with true\npositives vs. true negatives. Surprisingly, we found limited influence of\neither homophily and no evidence of incentive effects, despite participants\nperforming similarly to previous studies. Higher levels of agreement between\nthe participant and the AI tool yielded more confident predictions, but only\nwhen outcome feedback was absent. These results highlight the complexity of\ncharacterizing human-algorithm interactions, and suggest that findings from\nsocial psychology may require re-examination when humans interact with\nalgorithms.",
    "descriptor": "\nComments: Accepted at CogSci, 2022\n",
    "authors": [
      "Riccardo Fogliato",
      "Sina Fazelpour",
      "Shantanu Gupta",
      "Zachary Lipton",
      "David Danks"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.09701"
  },
  {
    "id": "arXiv:2205.09702",
    "title": "Parallel and Distributed Graph Neural Networks: An In-Depth Concurrency  Analysis",
    "abstract": "Graph neural networks (GNNs) are among the most powerful tools in deep\nlearning. They routinely solve complex problems on unstructured networks, such\nas node classification, graph classification, or link prediction, with high\naccuracy. However, both inference and training of GNNs are complex, and they\nuniquely combine the features of irregular graph processing with dense and\nregular computations. This complexity makes it very challenging to execute GNNs\nefficiently on modern massively parallel architectures. To alleviate this, we\nfirst design a taxonomy of parallelism in GNNs, considering data and model\nparallelism, and different forms of pipelining. Then, we use this taxonomy to\ninvestigate the amount of parallelism in numerous GNN models, GNN-driven\nmachine learning tasks, software frameworks, or hardware accelerators. We use\nthe work-depth model, and we also assess communication volume and\nsynchronization. We specifically focus on the sparsity/density of the\nassociated tensors, in order to understand how to effectively apply techniques\nsuch as vectorization. We also formally analyze GNN pipelining, and we\ngeneralize the established Message-Passing class of GNN models to cover\narbitrary pipeline depths, facilitating future optimizations. Finally, we\ninvestigate different forms of asynchronicity, navigating the path for future\nasynchronous parallel GNN pipelines. The outcomes of our analysis are\nsynthesized in a set of insights that help to maximize GNN performance, and a\ncomprehensive list of challenges and opportunities for further research into\nefficient GNN computations. Our work will help to advance the design of future\nGNNs.",
    "descriptor": "",
    "authors": [
      "Maciej Besta",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.09702"
  },
  {
    "id": "arXiv:2205.09703",
    "title": "Extract Dynamic Information To Improve Time Series Modeling: a Case  Study with Scientific Workflow",
    "abstract": "In modeling time series data, we often need to augment the existing data\nrecords to increase the modeling accuracy. In this work, we describe a number\nof techniques to extract dynamic information about the current state of a large\nscientific workflow, which could be generalized to other types of applications.\nThe specific task to be modeled is the time needed for transferring a file from\nan experimental facility to a data center. The key idea of our approach is to\nfind recent past data transfer events that match the current event in some\nways. Tests showed that we could identify recent events matching some recorded\nproperties and reduce the prediction error by about 12% compared to the similar\nmodels with only static features. We additionally explored an application\nspecific technique to extract information about the data production process,\nand was able to reduce the average prediction error by 44%.",
    "descriptor": "",
    "authors": [
      "Jeeyung Kim",
      "Mengtian Jin",
      "Youkow Homma",
      "Alex Sim",
      "Wilko Kroeger",
      "Kesheng Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)",
      "Systems and Control (eess.SY)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2205.09703"
  },
  {
    "id": "arXiv:2205.09705",
    "title": "Distributed Multi-Agent Deep Reinforcement Learning for Robust  Coordination against Noise",
    "abstract": "In multi-agent systems, noise reduction techniques are important for\nimproving the overall system reliability as agents are required to rely on\nlimited environmental information to develop cooperative and coordinated\nbehaviors with the surrounding agents. However, previous studies have often\napplied centralized noise reduction methods to build robust and versatile\ncoordination in noisy multi-agent environments, while distributed and\ndecentralized autonomous agents are more plausible for real-world application.\nIn this paper, we introduce a \\emph{distributed attentional actor architecture\nmodel for a multi-agent system} (DA3-X), using which we demonstrate that agents\nwith DA3-X can selectively learn the noisy environment and behave\ncooperatively. We experimentally evaluate the effectiveness of DA3-X by\ncomparing learning methods with and without DA3-X and show that agents with\nDA3-X can achieve better performance than baseline agents. Furthermore, we\nvisualize heatmaps of \\emph{attentional weights} from the DA3-X to analyze how\nthe decision-making process and coordinated behavior are influenced by noise.",
    "descriptor": "\nComments: Accepted to The 2022 International Joint Conference on Neural Networks (IJCNN 2022)\n",
    "authors": [
      "Yoshinari Motokawa",
      "Toshiharu Sugawara"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09705"
  },
  {
    "id": "arXiv:2205.09707",
    "title": "PLAID: An Efficient Engine for Late Interaction Retrieval",
    "abstract": "Pre-trained language models are increasingly important components across\nmultiple information retrieval (IR) paradigms. Late interaction, introduced\nwith the ColBERT model and recently refined in ColBERTv2, is a popular paradigm\nthat holds state-of-the-art status across many benchmarks. To dramatically\nspeed up the search latency of late interaction, we introduce the\nPerformance-optimized Late Interaction Driver (PLAID). Without impacting\nquality, PLAID swiftly eliminates low-scoring passages using a novel centroid\ninteraction mechanism that treats every passage as a lightweight bag of\ncentroids. PLAID uses centroid interaction as well as centroid pruning, a\nmechanism for sparsifying the bag of centroids, within a highly-optimized\nengine to reduce late interaction search latency by up to 7$\\times$ on a GPU\nand 45$\\times$ on a CPU against vanilla ColBERTv2, while continuing to deliver\nstate-of-the-art retrieval quality. This allows the PLAID engine with ColBERTv2\nto achieve latency of tens of milliseconds on a GPU and tens or just few\nhundreds of milliseconds on a CPU at large scale, even at the largest scales we\nevaluate with 140M passages.",
    "descriptor": "\nComments: Preprint. Omar and Keshav contributed equally to this work\n",
    "authors": [
      "Keshav Santhanam",
      "Omar Khattab",
      "Christopher Potts",
      "Matei Zaharia"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09707"
  },
  {
    "id": "arXiv:2205.09710",
    "title": "Voxel-informed Language Grounding",
    "abstract": "Natural language applied to natural 2D images describes a fundamentally 3D\nworld. We present the Voxel-informed Language Grounder (VLG), a language\ngrounding model that leverages 3D geometric information in the form of voxel\nmaps derived from the visual input using a volumetric reconstruction model. We\nshow that VLG significantly improves grounding accuracy on SNARE, an object\nreference game task. At the time of writing, VLG holds the top place on the\nSNARE leaderboard, achieving SOTA results with a 2.0% absolute improvement.",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Rodolfo Corona",
      "Shizhan Zhu",
      "Dan Klein",
      "Trevor Darrell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09710"
  },
  {
    "id": "arXiv:2205.09712",
    "title": "Selection-Inference: Exploiting Large Language Models for Interpretable  Logical Reasoning",
    "abstract": "Large language models (LLMs) have been shown to be capable of impressive\nfew-shot generalisation to new tasks. However, they still tend to perform\npoorly on multi-step logical reasoning problems. Here we carry out a\ncomprehensive evaluation of LLMs on 50 tasks that probe different aspects of\nlogical reasoning. We show that language models tend to perform fairly well at\nsingle step inference or entailment tasks, but struggle to chain together\nmultiple reasoning steps to solve more complex problems. In light of this, we\npropose a Selection-Inference (SI) framework that exploits pre-trained LLMs as\ngeneral processing modules, and alternates between selection and inference to\ngenerate a series of interpretable, casual reasoning steps leading to the final\nanswer. We show that a 7B parameter LLM used within the SI framework in a\n5-shot generalisation setting, with no fine-tuning, yields a performance\nimprovement of over 100% compared to an equivalent vanilla baseline on a suite\nof 10 logical reasoning tasks. The same model in the same setting even\noutperforms a significantly larger 280B parameter baseline on the same suite of\ntasks. Moreover, answers produced by the SI framework are accompanied by a\ncausal natural-language-based reasoning trace, which has important implications\nfor the safety and trustworthiness of the system.",
    "descriptor": "",
    "authors": [
      "Antonia Creswell",
      "Murray Shanahan",
      "Irina Higgins"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09712"
  },
  {
    "id": "arXiv:2205.09717",
    "title": "Flexible Modeling and Multitask Learning using Differentiable Tree  Ensembles",
    "abstract": "Decision tree ensembles are widely used and competitive learning models.\nDespite their success, popular toolkits for learning tree ensembles have\nlimited modeling capabilities. For instance, these toolkits support a limited\nnumber of loss functions and are restricted to single task learning. We propose\na flexible framework for learning tree ensembles, which goes beyond existing\ntoolkits to support arbitrary loss functions, missing responses, and multi-task\nlearning. Our framework builds on differentiable (a.k.a. soft) tree ensembles,\nwhich can be trained using first-order methods. However, unlike classical\ntrees, differentiable trees are difficult to scale. We therefore propose a\nnovel tensor-based formulation of differentiable trees that allows for\nefficient vectorization on GPUs. We perform experiments on a collection of 28\nreal open-source and proprietary datasets, which demonstrate that our framework\ncan lead to 100x more compact and 23% more expressive tree ensembles than those\nby popular toolkits.",
    "descriptor": "\nComments: Accepted at SIGKDD'2022\n",
    "authors": [
      "Shibal Ibrahim",
      "Hussein Hazimeh",
      "Rahul Mazumder"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.09717"
  },
  {
    "id": "arXiv:2205.09721",
    "title": "HyperAid: Denoising in hyperbolic spaces for tree-fitting and  hierarchical clustering",
    "abstract": "The problem of fitting distances by tree-metrics has received significant\nattention in the theoretical computer science and machine learning communities\nalike, due to many applications in natural language processing, phylogeny,\ncancer genomics and a myriad of problem areas that involve hierarchical\nclustering. Despite the existence of several provably exact algorithms for\ntree-metric fitting of data that inherently obeys tree-metric constraints, much\nless is known about how to best fit tree-metrics for data whose structure\nmoderately (or substantially) differs from a tree. For such noisy data, most\navailable algorithms perform poorly and often produce negative edge weights in\nrepresentative trees. Furthermore, it is currently not known how to choose the\nmost suitable approximation objective for noisy fitting. Our contributions are\nas follows. First, we propose a new approach to tree-metric denoising\n(HyperAid) in hyperbolic spaces which transforms the original data into data\nthat is ``more'' tree-like, when evaluated in terms of Gromov's $\\delta$\nhyperbolicity. Second, we perform an ablation study involving two choices for\nthe approximation objective, $\\ell_p$ norms and the Dasgupta loss. Third, we\nintegrate HyperAid with schemes for enforcing nonnegative edge-weights. As a\nresult, the HyperAid platform outperforms all other existing methods in the\nliterature, including Neighbor Joining (NJ), TreeRep and T-REX, both on\nsynthetic and real-world data. Synthetic data is represented by edge-augmented\ntrees and shortest-distance metrics while the real-world datasets include Zoo,\nIris, Glass, Segmentation and SpamBase; on these datasets, the average\nimprovement with respect to NJ is $125.94\\%$.",
    "descriptor": "\nComments: To appear in KDD 2022\n",
    "authors": [
      "Eli Chien",
      "Puoya Tabaghi",
      "Olgica Milenkovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09721"
  },
  {
    "id": "arXiv:2205.09722",
    "title": "Light In The Black: An Evaluation of Data Augmentation Techniques for  COVID-19 CT's Semantic Segmentation",
    "abstract": "With the COVID-19 global pandemic, computer-assisted diagnoses of medical\nimages have gained much attention, and robust methods of Semantic Segmentation\nof Computed Tomography (CT) became highly desirable. Semantic Segmentation of\nCT is one of many research fields of automatic detection of COVID-19 and has\nbeen widely explored since the COVID-19 outbreak. In this work, we propose an\nextensive analysis of how different data augmentation techniques improve the\ntraining of encoder-decoder neural networks on this problem. Twenty different\ndata augmentation techniques were evaluated on five different datasets. Each\ndataset was validated through a five-fold cross-validation strategy, thus\nresulting in over 3,000 experiments. Our findings show that spatial level\ntransformations are the most promising to improve the learning of neural\nnetworks on this problem.",
    "descriptor": "",
    "authors": [
      "Bruno A. Krinski",
      "Daniel V. Ruiz",
      "Eduardo Todt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09722"
  },
  {
    "id": "arXiv:2205.09723",
    "title": "Robust and Efficient Medical Imaging with Self-Supervision",
    "abstract": "Recent progress in Medical Artificial Intelligence (AI) has delivered systems\nthat can reach clinical expert level performance. However, such systems tend to\ndemonstrate sub-optimal \"out-of-distribution\" performance when evaluated in\nclinical settings different from the training environment. A common mitigation\nstrategy is to develop separate systems for each clinical setting using\nsite-specific data [1]. However, this quickly becomes impractical as medical\ndata is time-consuming to acquire and expensive to annotate [2]. Thus, the\nproblem of \"data-efficient generalization\" presents an ongoing difficulty for\nMedical AI development. Although progress in representation learning shows\npromise, their benefits have not been rigorously studied, specifically for\nout-of-distribution settings. To meet these challenges, we present REMEDIS, a\nunified representation learning strategy to improve robustness and\ndata-efficiency of medical imaging AI. REMEDIS uses a generic combination of\nlarge-scale supervised transfer learning with self-supervised learning and\nrequires little task-specific customization. We study a diverse range of\nmedical imaging tasks and simulate three realistic application scenarios using\nretrospective data. REMEDIS exhibits significantly improved in-distribution\nperformance with up to 11.5% relative improvement in diagnostic accuracy over a\nstrong supervised baseline. More importantly, our strategy leads to strong\ndata-efficient generalization of medical imaging AI, matching strong supervised\nbaselines using between 1% to 33% of retraining data across tasks. These\nresults suggest that REMEDIS can significantly accelerate the life-cycle of\nmedical imaging AI development thereby presenting an important step forward for\nmedical imaging AI to deliver broad impact.",
    "descriptor": "",
    "authors": [
      "Shekoofeh Azizi",
      "Laura Culp",
      "Jan Freyberg",
      "Basil Mustafa",
      "Sebastien Baur",
      "Simon Kornblith",
      "Ting Chen",
      "Patricia MacWilliams",
      "S. Sara Mahdavi",
      "Ellery Wulczyn",
      "Boris Babenko",
      "Megan Wilson",
      "Aaron Loh",
      "Po-Hsuan Cameron Chen",
      "Yuan Liu",
      "Pinal Bavishi",
      "Scott Mayer McKinney",
      "Jim Winkens",
      "Abhijit Guha Roy",
      "Zach Beaver",
      "Fiona Ryan",
      "Justin Krogue",
      "Mozziyar Etemadi",
      "Umesh Telang",
      "Yun Liu",
      "Lily Peng",
      "Greg S. Corrado",
      "Dale R. Webster",
      "David Fleet",
      "Geoffrey Hinton",
      "Neil Houlsby",
      "Alan Karthikesalingam",
      "Mohammad Norouzi",
      "Vivek Natarajan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09723"
  },
  {
    "id": "arXiv:2205.09726",
    "title": "RankGen: Improving Text Generation with Large Ranking Models",
    "abstract": "Given an input sequence (or prefix), modern language models often assign high\nprobabilities to output sequences that are repetitive, incoherent, or\nirrelevant to the prefix; as such, model-generated text also contains such\nartifacts. To address these issues, we present RankGen, an encoder model (1.2B\nparameters) that scores model generations given a prefix. RankGen can be\nflexibly incorporated as a scoring function in beam search and used to decode\nfrom any pretrained language model. We train RankGen using large-scale\ncontrastive learning to map a prefix close to the ground-truth sequence that\nfollows it and far away from two types of negatives: (1) random sequences from\nthe same document as the prefix, and, which discourage topically-similar but\nirrelevant generations; (2) sequences generated from a large language model\nconditioned on the prefix, which discourage repetition and hallucination.\nExperiments across four different language models (345M-11B parameters) and two\ndomains show that RankGen significantly outperforms decoding algorithms like\nnucleus, top-k, and typical sampling on both automatic metrics (85.0 vs 77.3\nMAUVE) as well as human evaluations with English writers (74.5% human\npreference over nucleus sampling). Analysis reveals that RankGen outputs are\nmore relevant to the prefix and improve continuity and coherence compared to\nbaselines. We open source our model checkpoints, code, and human preferences\nwith detailed explanations for future research.",
    "descriptor": "\nComments: Preprint (34 pages), code and pretrained model checkpoints will be provided at this https URL\n",
    "authors": [
      "Kalpesh Krishna",
      "Yapei Chang",
      "John Wieting",
      "Mohit Iyyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09726"
  },
  {
    "id": "arXiv:2205.09729",
    "title": "Reinforcement Learning with Brain-Inspired Modulation can Improve  Adaptation to Environmental Changes",
    "abstract": "Developments in reinforcement learning (RL) have allowed algorithms to\nachieve impressive performance in highly complex, but largely static problems.\nIn contrast, biological learning seems to value efficiency of adaptation to a\nconstantly-changing world. Here we build on a recently-proposed neuronal\nlearning rule that assumes each neuron can optimize its energy balance by\npredicting its own future activity. That assumption leads to a neuronal\nlearning rule that uses presynaptic input to modulate prediction error. We\nargue that an analogous RL rule would use action probability to modulate reward\nprediction error. This modulation makes the agent more sensitive to negative\nexperiences, and more careful in forming preferences. We embed the proposed\nrule in both tabular and deep-Q-network RL algorithms, and find that it\noutperforms conventional algorithms in simple, but highly-dynamic tasks. We\nsuggest that the new rule encapsulates a core principle of biological\nintelligence; an important component for allowing algorithms to adapt to change\nin a human-like way.",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Eric Chalmers",
      "Artur Luczak"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09729"
  },
  {
    "id": "arXiv:2205.09730",
    "title": "Dissemination Control in Dynamic Data Clustering For Dense IIoT Against  False Data Injection Attack",
    "abstract": "The IoT has made possible the development of increasingly driven services,\nlike industrial IIoT services, that often deal with massive amounts of data.\nMeantime, as IIoT networks grow, the threats are even greater, and false data\ninjection attacks (FDI) stand out as being one of the most aggressive. The\nmajority of current solutions to handle this attack do not take into account\nthe data validation, especially on the data clustering service. Aiming to\nadvance on the issue, this work introduces CONFINIT, an intrusion detection\nsystem for mitigating FDI attacks on the data dissemination service performing\nin dense IIoT networks. CONFINIT combines watchdog surveillance and\ncollaborative consensus strategies for assertively excluding various FDI\nattacks. The simulations showed that CONFINIT compared to DDFC increased by up\nto 35% - 40% the number of clusters without attackers in a gas pressure IIoT\nenvironment. CONFINIT achieved attack detection rates of 99%, accuracy of 90\nand F1 score of 0.81 in multiple IIoT scenarios, with only up to 3.2% and 3.6%\nof false negatives and positives rates, respectively. Moreover, under two\nvariants of FDI attacks, called Churn and Sensitive attacks, CONFINIT achieved\ndetection rates of 100%, accuracy of 99 and F1 of 0.93 with less than 2% of\nfalse positives and negatives rates.",
    "descriptor": "",
    "authors": [
      "Carlos Pedroso",
      "Aldri Santos"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.09730"
  },
  {
    "id": "arXiv:2205.09731",
    "title": "Towards Unified Keyframe Propagation Models",
    "abstract": "Many video editing tasks such as rotoscoping or object removal require the\npropagation of context across frames. While transformers and other\nattention-based approaches that aggregate features globally have demonstrated\ngreat success at propagating object masks from keyframes to the whole video,\nthey struggle to propagate high-frequency details such as textures faithfully.\nWe hypothesize that this is due to an inherent bias of global attention towards\nlow-frequency features. To overcome this limitation, we present a two-stream\napproach, where high-frequency features interact locally and low-frequency\nfeatures interact globally. The global interaction stream remains robust in\ndifficult situations such as large camera motions, where explicit alignment\nfails. The local interaction stream propagates high-frequency details through\ndeformable feature aggregation and, informed by the global interaction stream,\nlearns to detect and correct errors of the deformation field. We evaluate our\ntwo-stream approach for inpainting tasks, where experiments show that it\nimproves both the propagation of features within a single frame as required for\nimage inpainting, as well as their propagation from keyframes to target frames.\nApplied to video inpainting, our approach leads to 44% and 26% improvements in\nFID and LPIPS scores. Code at https://github.com/runwayml/guided-inpainting",
    "descriptor": "\nComments: CVPRW 2022 - AI for Content Creation Workshop. Code at this https URL\n",
    "authors": [
      "Patrick Esser",
      "Peter Michael",
      "Soumyadip Sengupta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09731"
  },
  {
    "id": "arXiv:2205.09732",
    "title": "Enhancing Slot Tagging with Intent Features for Task Oriented Natural  Language Understanding using BERT",
    "abstract": "Recent joint intent detection and slot tagging models have seen improved\nperformance when compared to individual models. In many real-world datasets,\nthe slot labels and values have a strong correlation with their intent labels.\nIn such cases, the intent label information may act as a useful feature to the\nslot tagging model. In this paper, we examine the effect of leveraging intent\nlabel features through 3 techniques in the slot tagging task of joint intent\nand slot detection models. We evaluate our techniques on benchmark spoken\nlanguage datasets SNIPS and ATIS, as well as over a large private Bixby dataset\nand observe an improved slot-tagging performance over state-of-the-art models.",
    "descriptor": "\nComments: 11 pages, 1 figure\n",
    "authors": [
      "Shruthi Hariharan",
      "Vignesh Kumar Krishnamurthy",
      "Utkarsh",
      "Jayantha Gowda Sarapanahalli"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09732"
  },
  {
    "id": "arXiv:2205.09735",
    "title": "Foundation Posteriors for Approximate Probabilistic Inference",
    "abstract": "Probabilistic programs provide an expressive representation language for\ngenerative models. Given a probabilistic program, we are interested in the task\nof posterior inference: estimating a latent variable given a set of observed\nvariables. Existing techniques for inference in probabilistic programs often\nrequire choosing many hyper-parameters, are computationally expensive, and/or\nonly work for restricted classes of programs. Here we formulate inference as\nmasked language modeling: given a program, we generate a supervised dataset of\nvariables and assignments, and randomly mask a subset of the assignments. We\nthen train a neural network to unmask the random values, defining an\napproximate posterior distribution. By optimizing a single neural network\nacross a range of programs we amortize the cost of training, yielding a\n``foundation'' posterior able to do zero-shot inference for new programs. The\nfoundation posterior can also be fine-tuned for a particular program and\ndataset by optimizing a variational inference objective. We show the efficacy\nof the approach, zero-shot and fine-tuned, on a benchmark of STAN programs.",
    "descriptor": "\nComments: 9 pages without appendix\n",
    "authors": [
      "Mike Wu",
      "Noah Goodman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.09735"
  },
  {
    "id": "arXiv:2205.09738",
    "title": "AIGenC: AI generalisation via creativity",
    "abstract": "This paper introduces a computational model of creative problem-solving in\ndeep reinforcement learning agents, inspired by cognitive theories of\ncreativity. The AIGenC model aims at enabling artificial agents to learn, use\nand generate transferable representations. AIGenC is embedded in a deep\nlearning architecture that includes three main components: concept processing,\nreflective reasoning, and blending of concepts. The first component extracts\nobjects and affordances from sensory input and encodes them in a concept space,\nrepresented as a hierarchical graph structure. Concept representations are\nstored in a dual memory system. Goal-directed and temporal information acquired\nby the agent during deep reinforcement learning enriches the representations\ncreating a higher level of abstraction in the concept space. In parallel, a\nprocess akin to reflective reasoning detects and recovers from memory concepts\nrelevant to the task according to a matching process that calculates a\nsimilarity value between the current state and memory graph structures. Once an\ninteraction is finalised, rewards and temporal information are added to the\ngraph structure, creating a higher abstraction level. If reflective reasoning\nfails to offer a suitable solution, a blending process comes into place to\ncreate new concepts by combining past information. We discuss the model's\ncapability to yield better out-of-distribution generalisation in artificial\nagents, thus advancing toward artificial general intelligence. To the best of\nour knowledge, this is the first computational model, beyond mere formal\ntheories, that posits a solution to creative problem solving within a deep\nlearning architecture.",
    "descriptor": "",
    "authors": [
      "Corina Catarau-Cotutiu",
      "Esther Mondragon",
      "Eduardo Alonso"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09738"
  },
  {
    "id": "arXiv:2205.09739",
    "title": "Diverse Weight Averaging for Out-of-Distribution Generalization",
    "abstract": "Standard neural networks struggle to generalize under distribution shifts.\nFor out-of-distribution generalization in computer vision, the best current\napproach averages the weights along a training run. In this paper, we propose\nDiverse Weight Averaging (DiWA) that makes a simple change to this strategy:\nDiWA averages the weights obtained from several independent training runs\nrather than from a single run. Perhaps surprisingly, averaging these weights\nperforms well under soft constraints despite the network's nonlinearities. The\nmain motivation behind DiWA is to increase the functional diversity across\naveraged models. Indeed, models obtained from different runs are more diverse\nthan those collected along a single run thanks to differences in\nhyperparameters and training procedures. We motivate the need for diversity by\na new bias-variance-covariance-locality decomposition of the expected error,\nexploiting similarities between DiWA and standard functional ensembling.\nMoreover, this decomposition highlights that DiWA succeeds when the variance\nterm dominates, which we show happens when the marginal distribution changes at\ntest time. Experimentally, DiWA consistently improves the state of the art on\nthe competitive DomainBed benchmark without inference overhead.",
    "descriptor": "\nComments: 31 pages, 14 figures, 11 tables\n",
    "authors": [
      "Alexandre Rame",
      "Matthieu Kirchmeyer",
      "Thibaud Rahier",
      "Alain Rakotomamonjy",
      "Patrick Gallinari",
      "Matthieu Cord"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09739"
  },
  {
    "id": "arXiv:2205.09743",
    "title": "BEVerse: Unified Perception and Prediction in Birds-Eye-View for  Vision-Centric Autonomous Driving",
    "abstract": "In this paper, we present BEVerse, a unified framework for 3D perception and\nprediction based on multi-camera systems. Unlike existing studies focusing on\nthe improvement of single-task approaches, BEVerse features in producing\nspatio-temporal Birds-Eye-View (BEV) representations from multi-camera videos\nand jointly reasoning about multiple tasks for vision-centric autonomous\ndriving. Specifically, BEVerse first performs shared feature extraction and\nlifting to generate 4D BEV representations from multi-timestamp and multi-view\nimages. After the ego-motion alignment, the spatio-temporal encoder is utilized\nfor further feature extraction in BEV. Finally, multiple task decoders are\nattached for joint reasoning and prediction. Within the decoders, we propose\nthe grid sampler to generate BEV features with different ranges and\ngranularities for different tasks. Also, we design the method of iterative flow\nfor memory-efficient future prediction. We show that the temporal information\nimproves 3D object detection and semantic map construction, while the\nmulti-task learning can implicitly benefit motion prediction. With extensive\nexperiments on the nuScenes dataset, we show that the multi-task BEVerse\noutperforms existing single-task methods on 3D object detection, semantic map\nconstruction, and motion prediction. Compared with the sequential paradigm,\nBEVerse also favors in significantly improved efficiency. The code and trained\nmodels will be released at https://github.com/zhangyp15/BEVerse.",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Yunpeng Zhang",
      "Zheng Zhu",
      "Wenzhao Zheng",
      "Junjie Huang",
      "Guan Huang",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09743"
  },
  {
    "id": "arXiv:2205.09744",
    "title": "Overcoming Language Disparity in Online Content Classification with  Multimodal Learning",
    "abstract": "Advances in Natural Language Processing (NLP) have revolutionized the way\nresearchers and practitioners address crucial societal problems. Large language\nmodels are now the standard to develop state-of-the-art solutions for text\ndetection and classification tasks. However, the development of advanced\ncomputational techniques and resources is disproportionately focused on the\nEnglish language, sidelining a majority of the languages spoken globally. While\nexisting research has developed better multilingual and monolingual language\nmodels to bridge this language disparity between English and non-English\nlanguages, we explore the promise of incorporating the information contained in\nimages via multimodal machine learning. Our comparative analyses on three\ndetection tasks focusing on crisis information, fake news, and emotion\nrecognition, as well as five high-resource non-English languages, demonstrate\nthat: (a) detection frameworks based on pre-trained large language models like\nBERT and multilingual-BERT systematically perform better on the English\nlanguage compared against non-English languages, and (b) including images via\nmultimodal learning bridges this performance gap. We situate our findings with\nrespect to existing work on the pitfalls of large language models, and discuss\ntheir theoretical and practical implications. Resources for this paper are\navailable at https://multimodality-language-disparity.github.io/.",
    "descriptor": "\nComments: Accepted for publication at ICWSM 2022 as a full paper\n",
    "authors": [
      "Gaurav Verma",
      "Rohit Mujumdar",
      "Zijie J. Wang",
      "Munmun De Choudhury",
      "Srijan Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2205.09744"
  },
  {
    "id": "arXiv:2205.09745",
    "title": "Understanding Gradient Descent on Edge of Stability in Deep Learning",
    "abstract": "Deep learning experiments in Cohen et al. (2021) using deterministic Gradient\nDescent (GD) revealed an {\\em Edge of Stability (EoS)} phase when learning rate\n(LR) and sharpness (\\emph{i.e.}, the largest eigenvalue of Hessian) no longer\nbehave as in traditional optimization. Sharpness stabilizes around $2/$LR and\nloss goes up and down across iterations, yet still with an overall downward\ntrend. The current paper mathematically analyzes a new mechanism of implicit\nregularization in the EoS phase, whereby GD updates due to non-smooth loss\nlandscape turn out to evolve along some deterministic flow on the manifold of\nminimum loss. This is in contrast to many previous results about implicit bias\neither relying on infinitesimal updates or noise in gradient. Formally, for any\nsmooth function $L$ with certain regularity condition, this effect is\ndemonstrated for (1) {\\em Normalized GD}, i.e., GD with a varying LR $ \\eta_t\n=\\frac{ \\eta }{ || \\nabla L(x(t)) || } $ and loss $L$; (2) GD with constant LR\nand loss $\\sqrt{L}$. Both provably enter the Edge of Stability, with the\nassociated flow on the manifold minimizing $\\lambda_{\\max}(\\nabla^2 L)$. The\nabove theoretical results have been corroborated by an experimental study.",
    "descriptor": "\nComments: This paper has been accepted for conference proceedings in the 39th International Conference on Machine Learning (ICML), 2022\n",
    "authors": [
      "Sanjeev Arora",
      "Zhiyuan Li",
      "Abhishek Panigrahi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.09745"
  },
  {
    "id": "arXiv:2205.09747",
    "title": "HandoverSim: A Simulation Framework and Benchmark for Human-to-Robot  Object Handovers",
    "abstract": "We introduce a new simulation benchmark \"HandoverSim\" for human-to-robot\nobject handovers. To simulate the giver's motion, we leverage a recent motion\ncapture dataset of hand grasping of objects. We create training and evaluation\nenvironments for the receiver with standardized protocols and metrics. We\nanalyze the performance of a set of baselines and show a correlation with a\nreal-world evaluation. Code is open sourced at https://handover-sim.github.io.",
    "descriptor": "\nComments: Accepted to ICRA 2022\n",
    "authors": [
      "Yu-Wei Chao",
      "Chris Paxton",
      "Yu Xiang",
      "Wei Yang",
      "Balakumar Sundaralingam",
      "Tao Chen",
      "Adithyavairavan Murali",
      "Maya Cakmak",
      "Dieter Fox"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09747"
  },
  {
    "id": "arXiv:2107.09744",
    "title": "Turbulent field fluctuations in gyrokinetic and fluid plasmas",
    "abstract": "A key uncertainty in the design and development of magnetic confinement\nfusion energy reactors is predicting edge plasma turbulence. An essential step\nin overcoming this uncertainty is the validation in accuracy of reduced\nturbulent transport models. Drift-reduced Braginskii two-fluid theory is one\nsuch set of reduced equations that has for decades simulated boundary plasmas\nin experiment, but significant questions exist regarding its predictive\nability. To this end, using a novel physics-informed deep learning framework,\nwe demonstrate the first ever direct quantitative comparisons of turbulent\nfield fluctuations between electrostatic two-fluid theory and electromagnetic\ngyrokinetic modelling with good overall agreement found in magnetized helical\nplasmas at low normalized pressure. This framework is readily adaptable to\nexperimental and astrophysical environments, and presents a new technique for\nthe numerical validation and discovery of reduced global plasma turbulence\nmodels.",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "Abhilash Mathews",
      "Noah Mandell",
      "Manaure Francisquez",
      "Jerry Hughes",
      "Ammar Hakim"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.09744"
  },
  {
    "id": "arXiv:2205.03090",
    "title": "PTFlash : A deep learning framework for isothermal two-phase equilibrium  calculations",
    "abstract": "Phase equilibrium calculations are an essential part of numerical simulations\nof multi-component multi-phase flow in porous media, accounting for the largest\nshare of the computational time. In this work, we introduce a GPUenabled, fast,\nand parallel framework, PTFlash, that vectorizes algorithms required for\nisothermal two-phase flash calculations using PyTorch, and can facilitate a\nwide range of downstream applications. In addition, to further accelerate\nPTFlash, we design two task-specific neural networks, one for predicting the\nstability of given mixtures and the other for providing estimates of the\ndistribution coefficients, which are trained offline and help shorten\ncomputation time by sidestepping stability analysis and reducing the number of\niterations to reach convergence. The evaluation of PTFlash was conducted on\nthree case studies involving hydrocarbons, CO 2 and N 2 , for which the phase\nequilibrium was tested over a large range of temperature, pressure and\ncomposition conditions, using the Soave-Redlich-Kwong (SRK) equation of state.\nWe compare PTFlash with an in-house thermodynamic library, Carnot, written in\nC++ and performing flash calculations one by one on CPU. Results show speed-ups\non large scale calculations up to two order of magnitudes, while maintaining\nperfect precision with the reference solution provided by Carnot.",
    "descriptor": "",
    "authors": [
      "Jingang Qu",
      "Thibault Faney",
      "Jean-Charles de Hemptinne",
      "Soleiman Yousef",
      "Patrick Gallinari"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.03090"
  },
  {
    "id": "arXiv:2205.08530",
    "title": "High-resolution landscape-scale biomass mapping using a spatiotemporal  patchwork of LiDAR coverages",
    "abstract": "Estimating forest aboveground biomass at fine spatial scales has become\nincreasingly important for greenhouse gas estimation, monitoring, and\nverification efforts to mitigate climate change. Airborne LiDAR continues to be\na valuable source of remote sensing data for estimating aboveground biomass.\nHowever airborne LiDAR collections may take place at local or regional scales\ncovering irregular, non-contiguous footprints, resulting in a 'patchwork' of\ndifferent landscape segments at different points in time. Here we addressed\ncommon obstacles including selection of training data, the investigation of\nregional or coverage specific patterns in bias and error, and map agreement,\nand model-based precision assessments at multiple scales.\nThree machine learning algorithms and an ensemble model were trained using\nfield inventory data (FIA), airborne LiDAR, and topographic, climatic and\ncadastral geodata. Using strict selection criteria, 801 FIA plots were selected\nwith co-located point clouds drawn from a patchwork of 17 leaf-off LiDAR\ncoverages 2014-2019). Our ensemble model created 30m AGB prediction surfaces\nwithin a predictor-defined area of applicability (98% of LiDAR coverage) and\nresulting AGB predictions were compared with FIA plot-level and areal estimates\nat multiple scales of aggregation. Our model was overall accurate (% RMSE\n13-33%), had very low bias (MBE $\\leq$ $\\pm$5 Mg ha$^{-1}$), explained most\nfield-observed variation (R$^2$ 0.74-0.93), produced estimates that were both\nlargely consistent with FIA's aggregate summaries (86% of estimates within 95%\nCI), as well as precise when aggregated to arbitrary small-areas (mean\nbootstrap standard error 0.37 Mg ha$^{-1}$). We share practical solutions to\nchallenges faced when using spatiotemporal patchworks of LiDAR to meet growing\nneeds for biomass prediction and mapping, and applications in carbon accounting\nand ecosystem stewardship.",
    "descriptor": "\nComments: Manuscript: 19 pages, 7 figures; Supplements: 14 pages, 5 figures; Submitted to: Environmental Research Letters, Carbon Monitoring Systems Research and Applications focus collection\n",
    "authors": [
      "Lucas K. Johnson",
      "Michael J. Mahoney",
      "Eddie Bevilacqua",
      "Stephen V. Stehman",
      "Grant Domke",
      "Colin M. Beier"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.08530"
  },
  {
    "id": "arXiv:2205.09114",
    "title": "Dark Solitons in Bose-Einstein Condensates: A Dataset for Many-body  Physics Research",
    "abstract": "We establish a dataset of over $1.6\\times10^4$ experimental images of\nBose-Einstein condensates containing solitonic excitations to enable machine\nlearning (ML) for many-body physics research. About 33 % of this dataset has\nmanually assigned and carefully curated labels. The remainder is automatically\nlabeled using SolDet -- an implementation of a physics-informed ML data\nanalysis framework -- consisting of a convolutional-neural-network-based\nclassifier and object detector as well as a statistically motivated\nphysics-informed classifier and a quality metric. This technical note\nconstitutes the definitive reference of the dataset, providing an opportunity\nfor the data science community to develop more sophisticated analysis tools, to\nfurther understand nonlinear many-body physics, and even advance cold atom\nexperiments.",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Amilson R. Fritsch",
      "Shangjie Guo",
      "Sophia M. Koh",
      "I. B. Spielman",
      "Justyna P. Zwolak"
    ],
    "subjectives": [
      "Quantum Gases (cond-mat.quant-gas)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.09114"
  },
  {
    "id": "arXiv:2205.09116",
    "title": "Exploring the Adjugate Matrix Approach to Quaternion Pose Extraction",
    "abstract": "Quaternions are important for a wide variety of rotation-related problems in\ncomputer graphics, machine vision, and robotics. We study the nontrivial\ngeometry of the relationship between quaternions and rotation matrices by\nexploiting the adjugate matrix of the characteristic equation of a related\neigenvalue problem to obtain the manifold of the space of a quaternion\neigenvector. We argue that quaternions parameterized by their corresponding\nrotation matrices cannot be expressed, for example, in machine learning tasks,\nas single-valued functions: the quaternion solution must instead be treated as\na manifold, with different algebraic solutions for each of several\nsingle-valued sectors represented by the adjugate matrix. We conclude with\nnovel constructions exploiting the quaternion adjugate variables to revisit\nseveral classic pose estimation applications: 2D point-cloud matching, 2D\npoint-cloud-to-projection matching, 3D point-cloud matching, 3D orthographic\npoint-cloud-to-projection matching, and 3D perspective\npoint-cloud-to-projection matching. We find an exact solution to the 3D\northographic least squares pose extraction problem, and apply it successfully\nalso to the perspective pose extraction problem with results that improve on\nexisting methods.",
    "descriptor": "\nComments: 67 pages, 5 appendices, 9 figures\n",
    "authors": [
      "Andrew J. Hanson",
      "Sonya M. Hanson"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2205.09116"
  },
  {
    "id": "arXiv:2205.09159",
    "title": "Stochastic uncertainty analysis of gravity gradient tensor components  and their combinations",
    "abstract": "Full tensor gravity (FTG) devices provide up to five independent components\nof the gravity gradient tensor. However, we do not yet have a quantitative\nunderstanding of which tensor components or combinations of components are more\nimportant to recover a subsurface density model by gravity inversion. This is\nmainly because different components may be more appropriate in different\nscenarios or purposes. Knowledge of these components in different environments\ncan aid with selection of optimal selection of component combinations. In this\nwork, we propose to apply stochastic inversion to assess the uncertainty of\ngravity gradient tensor components and their combinations. The method is\ntherefore a quantitative approach. The applied method here is based on the\ngeostatistical inversion (Gaussian process regression) concept using cokriging.\nThe cokriging variances (variance function of the GP) are found to be a useful\nindicator for distinguishing the gravity gradient tensor components. This\napproach is applied to the New Found dataset to demonstrate its effectiveness\nin real-world applications.",
    "descriptor": "\nComments: 26 pages, 10 figures\n",
    "authors": [
      "Pejman Shamsipour",
      "Amin Aghaee",
      "Tedd Kourkounakis",
      "Shawn Hood"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09159"
  },
  {
    "id": "arXiv:2205.09162",
    "title": "An Invariant Matching Property for Distribution Generalization under  Intervened Response",
    "abstract": "The task of distribution generalization concerns making reliable prediction\nof a response in unseen environments. The structural causal models are shown to\nbe useful to model distribution changes through intervention. Motivated by the\nfundamental invariance principle, it is often assumed that the conditional\ndistribution of the response given its predictors remains the same across\nenvironments. However, this assumption might be violated in practical settings\nwhen the response is intervened. In this work, we investigate a class of model\nwith an intervened response. We identify a novel form of invariance by\nincorporating the estimates of certain features as additional predictors.\nEffectively, we show this invariance is equivalent to having a deterministic\nlinear matching that makes the generalization possible. We provide an explicit\ncharacterization of the linear matching and present our simulation results\nunder various intervention settings.",
    "descriptor": "\nComments: Accepted to the European Signal Processing Conference (EUSIPCO) 2022\n",
    "authors": [
      "Kang Du",
      "Yu Xiang"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09162"
  },
  {
    "id": "arXiv:2205.09169",
    "title": "Anonymous conference key agreement in linear quantum networks",
    "abstract": "Sharing multi-partite quantum entanglement between parties allows for diverse\nsecure communication tasks to be performed. Among them, conference key\nagreement (CKA), an extension of key distribution to multiple parties, has\nreceived much attention recently. Interestingly, CKA can also be performed in a\nway that protects the identities of the participating parties, therefore\nproviding anonymity. In this work, we propose an anonymous CKA protocol for\nthree parties that is implemented in a highly practical network setting.\nSpecifically, a line of quantum repeater nodes is used to build a linear\ncluster state among all nodes, which is then used to anonymously establish a\nsecret key between any three of them. The nodes need only share maximally\nentangled pairs with their neighbours, therefore avoiding the necessity of a\ncentral server sharing entangled states. This repeater setup makes our protocol\nan excellent candidate for implementation in future quantum networks. We\nexplicitly prove that our protocol protects the identities of the participants\nfrom one another and perform an analysis of the key rate in the finite regime,\ncontributing to the quest of identifying feasible quantum communication tasks\nfor network architectures beyond point-to-point.",
    "descriptor": "\nComments: 10 pages of main text, 3 figures in main text, 3 tables in main text, 10 pages of appendices, 1 figure in appendices, 3 tables in appendices\n",
    "authors": [
      "Jarn de Jong",
      "Frederik Hahn",
      "Jens Eisert",
      "Nathan Walk",
      "Anna Pappa"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.09169"
  },
  {
    "id": "arXiv:2205.09185",
    "title": "AI-assisted Optimization of the ECCE Tracking System at the Electron Ion  Collider",
    "abstract": "The Electron-Ion Collider (EIC) is a cutting-edge accelerator facility that\nwill study the nature of the \"glue\" that binds the building blocks of the\nvisible matter in the universe. The proposed experiment will be realized at\nBrookhaven National Laboratory in approximately 10 years from now, with\ndetector design and R&D currently ongoing. Notably, EIC is one of the first\nlarge-scale facilities to leverage Artificial Intelligence (AI) already\nstarting from the design and R&D phases. The EIC Comprehensive Chromodynamics\nExperiment (ECCE) is a consortium that proposed a detector design based on a\n1.5T solenoid. The EIC detector proposal review concluded that the ECCE design\nwill serve as the reference design for an EIC detector. Herein we describe a\ncomprehensive optimization of the ECCE tracker using AI. The work required a\ncomplex parametrization of the simulated detector system. Our approach dealt\nwith an optimization problem in a multidimensional design space driven by\nmultiple objectives that encode the detector performance, while satisfying\nseveral mechanical constraints. We describe our strategy and show results\nobtained for the ECCE tracking system. The AI-assisted design is agnostic to\nthe simulation framework and can be extended to other sub-detectors or to a\nsystem of sub-detectors to further optimize the performance of the EIC\ndetector.",
    "descriptor": "\nComments: 16 pages, 18 figures, 2 appendices, 3 tables\n",
    "authors": [
      "C. Fanelli",
      "Z. Papandreou",
      "K. Suresh",
      "J. K. Adkins",
      "Y. Akiba",
      "A. Albataineh",
      "M. Amaryan",
      "I. C. Arsene",
      "C. Ayerbe Gayoso",
      "J. Bae",
      "X. Bai",
      "M.D. Baker",
      "M. Bashkanov",
      "R. Bellwied",
      "F. Benmokhtar",
      "V. Berdnikov",
      "J. C. Bernauer",
      "F. Bock",
      "W. Boeglin",
      "M. Borysova",
      "E. Brash",
      "P. Brindza",
      "W. J. Briscoe",
      "M. Brooks",
      "S. Bueltmann",
      "M. H. S. Bukhari",
      "A. Bylinkin",
      "R. Capobianco",
      "W.-C. Chang",
      "Y. Cheon",
      "K. Chen",
      "K.-F. Chen",
      "K.-Y. Cheng",
      "M. Chiu",
      "T. Chujo",
      "Z. Citron",
      "E. Cline",
      "E. Cohen",
      "T. Cormier",
      "Y. Corrales Morales",
      "C. Cotton",
      "J. Crafts",
      "C. Crawford",
      "S. Creekmore",
      "C.Cuevas",
      "J. Cunningham",
      "G. David",
      "C. T. Dean",
      "M. Demarteau",
      "S. Diehl",
      "N. Doshita",
      "R. Dupre",
      "J. M. Durham",
      "R. Dzhygadlo",
      "R. Ehlers",
      "L. El Fassi",
      "A. Emmert",
      "R. Ent",
      "C. Fanelli",
      "R. Fatemi",
      "S. Fegan",
      "M. Finger",
      "M. Finger Jr.",
      "J. Frantz",
      "M. Friedman"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "Nuclear Experiment (nucl-ex)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.09185"
  },
  {
    "id": "arXiv:2205.09198",
    "title": "Macedonian Speech Synthesis for Assistive Technology Applications",
    "abstract": "Speech technology is becoming ever more ubiquitous with the advance of speech\nenabled devices and services. The use of speech synthesis in Augmentative and\nAlternative Communication tools, has facilitated inclusion of individuals with\nspeech impediments allowing them to communicate with their surroundings using\nspeech. Although there are numerous speech synthesis systems for the most\nspoken world languages, there is still a limited offer for smaller languages.\nWe propose and compare three models built using parametric and deep learning\ntechniques for Macedonian trained on a newly recorded corpus. We target\nlow-resource edge deployment for Augmentative and Alternative Communication and\nassistive technologies, such as communication boards and screen readers. The\nlistening test results show that parametric speech synthesis is as performant\ncompared to the more advanced deep learning models. Since it also requires less\nresources, and offers full speech rate and pitch control, it is the preferred\nchoice for building a Macedonian TTS system for this application scenario.",
    "descriptor": "\nComments: 5 pages, 2 figures, EUSIPCO conference 2022\n",
    "authors": [
      "Bojan Sofronievski",
      "Elena Velovska",
      "Martin Velichkovski",
      "Violeta Argirova",
      "Tea Veljkovikj",
      "Risto Chavdarov",
      "Stefan Janev",
      "Kristijan Lazarev",
      "Toni Bachvarovski",
      "Zoran Ivanovski",
      "Dimitar Tashkovski",
      "Branislav Gerazov"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2205.09198"
  },
  {
    "id": "arXiv:2205.09200",
    "title": "On the multi-stage shortest path problem under distributional  uncertainty",
    "abstract": "In this paper we consider an ambiguity-averse multi-stage network game\nbetween a user and an attacker. The arc costs are assumed to be random\nvariables that satisfy prescribed first-order moment constraints for some\nsubsets of arcs and individual probability constraints for some particular\narcs. The user aims at minimizing its cumulative expected loss by traversing\nbetween two fixed nodes in the network, while the attacker maximizes the user's\nobjective function by selecting a distribution of arc costs from the family of\nadmissible distributions. In contrast to most of the previous studies in the\nrelated literature, both the user and the attacker can dynamically adjust their\ndecisions at each node of the user's path. By observing the user's decisions,\nthe attacker needs to reveal some additional distributional information\nassociated with the arcs emanated from the current user's position. It is shown\nthat the resulting multi-stage distributionally robust shortest path problem\nadmits a linear mixed-integer programming reformulation (MIP). In particular,\nwe distinguish between acyclic and general graphs by introducing different\nforms of non-anticipativity constraints. Finally, we perform a numerical study,\nwhere the quality of adaptive decisions and computational tractability of the\nproposed MIP reformulation are explored with respect to several classes of\nsynthetic network instances.",
    "descriptor": "",
    "authors": [
      "Sergey S. Ketkov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2205.09200"
  },
  {
    "id": "arXiv:2205.09235",
    "title": "Constraint-Based Causal Structure Learning from Undersampled Graphs",
    "abstract": "Graphical structures estimated by causal learning algorithms from time series\ndata can provide highly misleading causal information if the causal timescale\nof the generating process fails to match the measurement timescale of the data.\nAlthough this problem has been recently recognized, practitioners have limited\nresources to respond to it, and so must continue using models that they know\nare likely misleading. Existing methods either (a) require that the difference\nbetween causal and measurement timescales is known; or (b) can handle only very\nsmall number of random variables when the timescale difference is unknown; or\n(c) apply to only pairs of variables, though with fewer assumptions about prior\nknowledge; or (d) return impractically too many solutions. This paper addresses\nall four challenges. We combine constraint programming with both theoretical\ninsights into the problem structure and prior information about admissible\ncausal interactions. The resulting system provides a practical approach that\nscales to significantly larger sets (>100) of random variables, does not\nrequire precise knowledge of the timescale difference, supports edge\nmisidentification and parametric connection strengths, and can provide the\noptimum choice among many possible solutions. The cumulative impact of these\nimprovements is gain of multiple orders of magnitude in speed and\ninformativeness.",
    "descriptor": "",
    "authors": [
      "Mohammadsajad Abavisani",
      "David Danks",
      "Sergey Plis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09235"
  },
  {
    "id": "arXiv:2205.09241",
    "title": "Neural ODE Control for Trajectory Approximation of Continuity Equation",
    "abstract": "We consider the controllability problem for the continuity equation,\ncorresponding to neural ordinary differential equations (ODEs), which describes\nhow a probability measure is pushedforward by the flow. We show that the\ncontrolled continuity equation has very strong controllability properties.\nParticularly, a given solution of the continuity equation corresponding to a\nbounded Lipschitz vector field defines a trajectory on the set of probability\nmeasures. For this trajectory, we show that there exist piecewise constant\ntraining weights for a neural ODE such that the solution of the continuity\nequation corresponding to the neural ODE is arbitrarily close to it. As a\ncorollary to this result, we establish that the continuity equation of the\nneural ODE is approximately controllable on the set of compactly supported\nprobability measures that are absolutely continuous with respect to the\nLebesgue measure.",
    "descriptor": "",
    "authors": [
      "Karthik Elamvazhuthi",
      "Bahman Gharesifard",
      "Andrea Bertozzi",
      "Stanley Osher"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.09241"
  },
  {
    "id": "arXiv:2205.09303",
    "title": "Quantum Money Generated by Multiple Untrustworthy Banks",
    "abstract": "While classical money can be copied, it is impossible to copy quantum money\nin principle, with only the bank that issues it knowing how to generate it,\nmeaning only the bank can make exact copies. Not all reliable banks, such as\ncentral banks, will issue quantum money, so there is the possibility that\nuntrustworthy banks are distributing fake or multiple copies of the same\nquantum money without the users' knowledge. As such, we propose a quantum\npatchwork money scheme in which banks cannot distribute exact copies to users.\nThis scheme involves multiple banks providing public-key quantum money as\nshards and generating quantum patchwork money by combining them. The banks can\nuse the quantum patchwork money without completely trusting the other banks. In\naddition, nonbank users can use safely the quantum patchwork money without\ntrusting any banks potentially focused on self-interest by adding a protocol\nfor monitoring the distribution of copies.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Yuichi Sano"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.09303"
  },
  {
    "id": "arXiv:2205.09315",
    "title": "A Sub-pixel Accurate Quantification of Joint Space Narrowing Progression  in Rheumatoid Arthritis",
    "abstract": "Rheumatoid arthritis (RA) is a chronic autoimmune disease that primarily\naffects peripheral synovial joints, like fingers, wrist and feet. Radiology\nplays a critical role in the diagnosis and monitoring of RA. Limited by the\ncurrent spatial resolution of radiographic imaging, joint space narrowing (JSN)\nprogression of RA with the same reason above can be less than one pixel per\nyear with universal spatial resolution. Insensitive monitoring of JSN can\nhinder the radiologist/rheumatologist from making a proper and timely clinical\njudgment. In this paper, we propose a novel and sensitive method that we call\npartial image phase-only correlation which aims to automatically quantify JSN\nprogression in the early stages of RA. The majority of the current literature\nutilizes the mean error, root-mean-square deviation and standard deviation to\nreport the accuracy at pixel level. Our work measures JSN progression between a\nbaseline and its follow-up finger joint images by using the phase spectrum in\nthe frequency domain. Using this study, the mean error can be reduced to\n0.0130mm when applied to phantom radiographs with ground truth, and 0.0519mm\nstandard deviation for clinical radiography. With its sub-pixel accuracy far\nbeyond manual measurement, we are optimistic that our work is promising for\nautomatically quantifying JSN progression.",
    "descriptor": "",
    "authors": [
      "Yafei Ou",
      "Prasoon Ambalathankandy",
      "Ryunosuke Furuya",
      "Seiya Kawada",
      "Tianyu Zeng",
      "Yujie An",
      "Tamotsu Kamishima",
      "Kenichi Tamura",
      "Masayuki Ikebe"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09315"
  },
  {
    "id": "arXiv:2205.09317",
    "title": "Odd coloring of two subclasses of planar graphs",
    "abstract": "A proper coloring of a graph is odd if every non-isolated vertex has some\ncolor that appears an odd number of times on its neighborhood. Petru\\v{s}evski\nand \\v{S}krekovski conjectured in 2021 that every planar graph admits an odd\n$5$-coloring. We confirm this conjecture for outer-1-planar graphs and\n2-boundary planar graphs, which are two subclasses of planar graphs.",
    "descriptor": "\nComments: 11 pages, 2 figures\n",
    "authors": [
      "Mengke Qi",
      "Xin Zhang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2205.09317"
  },
  {
    "id": "arXiv:2205.09322",
    "title": "Hierarchical Ensemble Kalman Methods with Sparsity-Promoting Generalized  Gamma Hyperpriors",
    "abstract": "This paper introduces a computational framework to incorporate flexible\nregularization techniques in ensemble Kalman methods for nonlinear inverse\nproblems. The proposed methodology approximates the maximum a posteriori (MAP)\nestimate of a hierarchical Bayesian model characterized by a conditionally\nGaussian prior and generalized gamma hyperpriors. Suitable choices of\nhyperparameters yield sparsity-promoting regularization. We propose an\niterative algorithm for MAP estimation, which alternates between updating the\nunknown with an ensemble Kalman method and updating the hyperparameters in the\nregularization to promote sparsity. The effectiveness of our methodology is\ndemonstrated in several computed examples, including compressed sensing and\nsubsurface flow inverse problems.",
    "descriptor": "",
    "authors": [
      "Hwanwoo Kim",
      "Daniel Sanz-Alonso",
      "Alexander Strang"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2205.09322"
  },
  {
    "id": "arXiv:2205.09342",
    "title": "Consistent Interpolating Ensembles via the Manifold-Hilbert Kernel",
    "abstract": "Recent research in the theory of overparametrized learning has sought to\nestablish generalization guarantees in the interpolating regime. Such results\nhave been established for a few common classes of methods, but so far not for\nensemble methods. We devise an ensemble classification method that\nsimultaneously interpolates the training data, and is consistent for a broad\nclass of data distributions. To this end, we define the manifold-Hilbert kernel\nfor data distributed on a Riemannian manifold. We prove that kernel smoothing\nregression using the manifold-Hilbert kernel is weakly consistent in the\nsetting of Devroye et al. 1998. For the sphere, we show that the\nmanifold-Hilbert kernel can be realized as a weighted random partition kernel,\nwhich arises as an infinite ensemble of partition-based classifiers.",
    "descriptor": "",
    "authors": [
      "Yutong Wang",
      "Clayton D. Scott"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09342"
  },
  {
    "id": "arXiv:2205.09382",
    "title": "BabyNet: Residual Transformer Module for Birth Weight Prediction on  Fetal Ultrasound Video",
    "abstract": "Predicting fetal weight at birth is an important aspect of perinatal care,\nparticularly in the context of antenatal management, which includes the planned\ntiming and the mode of delivery. Accurate prediction of weight using prenatal\nultrasound is challenging as it requires images of specific fetal body parts\nduring advanced pregnancy which is difficult to capture due to poor quality of\nimages caused by the lack of amniotic fluid. As a consequence, predictions\nwhich rely on standard methods often suffer from significant errors. In this\npaper we propose the Residual Transformer Module which extends a 3D\nResNet-based network for analysis of 2D+t spatio-temporal ultrasound video\nscans. Our end-to-end method, called BabyNet, automatically predicts fetal\nbirth weight based on fetal ultrasound video scans. We evaluate BabyNet using a\ndedicated clinical set comprising 225 2D fetal ultrasound videos of pregnancies\nfrom 75 patients performed one day prior to delivery. Experimental results show\nthat BabyNet outperforms several state-of-the-art methods and estimates the\nweight at birth with accuracy comparable to human experts. Furthermore,\ncombining estimates provided by human experts with those computed by BabyNet\nyields the best results, outperforming either of other methods by a significant\nmargin. The source code of BabyNet is available at\nhttps://github.com/SanoScience/BabyNet.",
    "descriptor": "\nComments: Early accepted for 25th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI) 2022, Singapore\n",
    "authors": [
      "Szymon P\u0142otka",
      "Micha\u0142 K. Grzeszczyk",
      "Robert Brawura-Biskupski-Samaha",
      "Pawe\u0142 Gutaj",
      "Micha\u0142 Lipa",
      "Tomasz Trzci\u0144ski",
      "Arkadiusz Sitek"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09382"
  },
  {
    "id": "arXiv:2205.09390",
    "title": "Truncated tensor Schatten p-norm based approach for spatiotemporal  traffic data imputation with complicated missing patterns",
    "abstract": "Rapid advances in sensor, wireless communication, cloud computing and data\nscience have brought unprecedented amount of data to assist transportation\nengineers and researchers in making better decisions. However, traffic data in\nreality often has corrupted or incomplete values due to detector and\ncommunication malfunctions. Data imputation is thus required to ensure the\neffectiveness of downstream data-driven applications. To this end, numerous\ntensor-based methods treating the imputation problem as the low-rank tensor\ncompletion (LRTC) have been attempted in previous works. To tackle rank\nminimization, which is at the core of the LRTC, most of aforementioned methods\nutilize the tensor nuclear norm (NN) as a convex surrogate for the\nminimization. However, the over-relaxation issue in NN refrains it from\ndesirable performance in practice. In this paper, we define an innovative\nnonconvex truncated Schatten p-norm for tensors (TSpN) to approximate tensor\nrank and impute missing spatiotemporal traffic data under the LRTC framework.\nWe model traffic data into a third-order tensor structure of (time\nintervals,locations (sensors),days) and introduce four complicated missing\npatterns, including random missing and three fiber-like missing cases according\nto the tensor mode-n fibers. Despite nonconvexity of the objective function in\nour model, we derive the global optimal solutions by integrating the\nalternating direction method of multipliers (ADMM) with generalized\nsoft-thresholding (GST). In addition, we design a truncation rate decay\nstrategy to deal with varying missing rate scenarios. Comprehensive experiments\nare finally conducted using real-world spatiotemporal datasets, which\ndemonstrate that the proposed LRTC-TSpN method performs well under various\nmissing cases, meanwhile outperforming other SOTA tensor-based imputation\nmodels in almost all scenarios.",
    "descriptor": "",
    "authors": [
      "Tong Nie",
      "Guoyang Qin",
      "Jian Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09390"
  },
  {
    "id": "arXiv:2205.09396",
    "title": "A segregated reduced order model of a pressure-based solver for  turbulent compressible flows",
    "abstract": "This article provides a reduced order modelling framework for turbulent\ncompressible flows discretized by the use of finite volume approaches. The\nbasic idea behind this work is the construction of reduced order models capable\nof providing fully consistent solutions with respect to the high fidelity flow\nfields. Full order solutions are often obtained through the use of segregated\nsolvers, employing slightly modified conservation laws so that they can be\ndecoupled and then solved one at a time. Classical reduction architectures, on\nthe contrary, rely on the Galerkin projection of a complete Navier-Stokes\nsystem to be projected all at once, causing a mild discrepancy with the high\norder solutions. In this article we rely on segregated reduced order algorithms\nfor the resolution of turbulent and compressible flows in the context of\nphysical and geometrical parameters. At the full order level turbulence is\nmodeled using an eddy viscosity approach. Since there are a variety of\ndifferent turbulence models for the approximation of this supplementary\nviscosity, one of the aims of this work is to provide reduced order models\nwhich are independent on this selection. This goal is reached by the\napplication of hybrid methods where Navier-Stokes equations are projected in a\nstandard way while the viscosity field is approximated by the use of\ndata-driven interpolation methods or by the evaluation of a properly trained\nneural network. By exploiting the aforementioned expedients it is possible to\nreduced the computational cost associated wit fluid flow problems characterized\nby high Reynolds numbers and elevated Mach numbers.",
    "descriptor": "",
    "authors": [
      "Matteo Zancanaro",
      "Giovanni Stabile",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.09396"
  },
  {
    "id": "arXiv:2205.09401",
    "title": "Bias Analysis of Spatial Coherence-Based RTF Vector Estimation for  Acoustic Sensor Networks in a Diffuse Sound Field",
    "abstract": "In many multi-microphone algorithms, an estimate of the relative transfer\nfunctions (RTFs) of the desired speaker is required. Recently, a\ncomputationally efficient RTF vector estimation method was proposed for\nacoustic sensor networks, assuming that the spatial coherence (SC) of the noise\ncomponent between a local microphone array and multiple external microphones is\nlow. Aiming at optimizing the output signal-to-noise ratio (SNR), this method\nlinearly combines multiple RTF vector estimates, where the complex-valued\nweights are computed using a generalized eigenvalue decomposition (GEVD). In\nthis paper, we perform a theoretical bias analysis for the SC-based RTF vector\nestimation method with multiple external microphones. Assuming a certain model\nfor the noise field, we derive an analytical expression for the weights,\nshowing that the optimal model-based weights are real-valued and only depend on\nthe input SNR in the external microphones. Simulations with real-world\nrecordings show a good accordance of the GEVD-based and the model-based\nweights. Nevertheless, the results also indicate that in practice, estimation\nerrors occur which the model-based weights cannot account for.",
    "descriptor": "",
    "authors": [
      "Wiebke Middelberg",
      "Simon Doclo"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.09401"
  },
  {
    "id": "arXiv:2205.09409",
    "title": "Joint Communication and Sensing: Models and Potentials of Using MIMO",
    "abstract": "The sixth-generation (6G) network is envisioned to integrate communication\nand sensing functions, so as to improve the spectrum efficiency (SE) and\nsupport explosive novel applications. Although the similarities of wireless\ncommunication and radio sensing lay the foundation for their combinations,\ntheir different requirements for electromagnetic signals make the joint system\ndesign a hard task. To simultaneously guarantee sensing accuracy and\ncommunication capacity, the multiple-input and multiple-output (MIMO) technique\nplays an important role, due to its unique capability of spatial beamforming\nand waveform shaping. However, the configuration of MIMO also brings high\nhardware cost, high power consumption, and high signal processing complexity.\nHow to efficiently apply MIMO in the joint communication and sensing (JCAS)\nsystem is still open. In this survey, we discuss JCAS in the context of MIMO\nconfigurations. We first outline the roles of MIMO in the progress of\ncommunication and radar sensing. Then, we review current advances in both\ncommunication and sensing coexistence and integration in detail. Three novel\nJCAS MIMO models are subsequently discussed by introducing the promising 6G\nenablers, i.e., the unmanned aerial vehicle (UAV) and the reconfigurable\nintelligent surface (RIS). With the aim of building a compatible dual-function\nsystem, the benefits and challenges of MIMO in JCAS are summarized in each\nsubsection. Promising solutions are also discussed from the system perspective\nwith simple, intelligent and robust principles. In the end, open issues are\noutlined to envisage a comprehensive JCAS network in the near future.",
    "descriptor": "",
    "authors": [
      "Xinran Fang",
      "Wei Feng",
      "Yunfei Chen",
      "Ning Ge",
      "Yan Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.09409"
  },
  {
    "id": "arXiv:2205.09414",
    "title": "Machine learning applications for noisy intermediate-scale quantum  computers",
    "abstract": "Quantum machine learning has proven to be a fruitful area in which to search\nfor potential applications of quantum computers. This is particularly true for\nthose available in the near term, so called noisy intermediate-scale quantum\n(NISQ) devices. In this Thesis, we develop and study three quantum machine\nlearning applications suitable for NISQ computers, ordered in terms of\nincreasing complexity of data presented to them. These algorithms are\nvariational in nature and use parameterised quantum circuits (PQCs) as the\nunderlying quantum machine learning model. The first application area is\nquantum classification using PQCs, where the data is classical feature vectors\nand their corresponding labels. Here, we study the robustness of certain data\nencoding strategies in such models against noise present in a quantum computer.\nThe second area is generative modelling using quantum computers, where we use\nquantum circuit Born machines to learn and sample from complex probability\ndistributions. We discuss and present a framework for quantum advantage for\nsuch models, propose gradient-based training methods and demonstrate these both\nnumerically and on the Rigetti quantum computer up to 28 qubits. For our final\napplication, we propose a variational algorithm in the area of approximate\nquantum cloning, where the data becomes quantum in nature. For the algorithm,\nwe derive differentiable cost functions, prove theoretical guarantees such as\nfaithfulness, and incorporate state of the art methods such as quantum\narchitecture search. Furthermore, we demonstrate how this algorithm is useful\nin discovering novel implementable attacks on quantum cryptographic protocols,\nfocusing on quantum coin flipping and key distribution as examples.",
    "descriptor": "\nComments: PhD Thesis. Defended 26th November 2021, University of Edinburgh\n",
    "authors": [
      "Brian Coyle"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09414"
  },
  {
    "id": "arXiv:2205.09431",
    "title": "Pitch-axis supermanoeuvrability in a biomimetic morphing-wing aircraft",
    "abstract": "Birds and bats are extraordinarily adept flyers: whether in hunting prey, or\nevading predators, their agility and manoeuvrability in flight are\ncharacteristics of vital importance. Their performance, in this regard, greatly\nexceeds that of conventional aircraft. Attempts to close this gap in capability\nhave typically focused on thrust-vectoring technology - the domain of classical\nsupermanoeuvrability - at the expense of biomimicry. In this work, however, we\nshow that these approaches are not incompatible: biomimetic wing morphing is an\navenue both to classical supermanoeuvrability, and to new forms of\nbiologically-inspired supermanoeuvrability. Using a state-of-the-art flight\nsimulator, equipped with a multibody model of lifting surface motion and a\nGoman-Khrabrov dynamic stall model for all lifting surfaces, we demonstrate the\ncapability of a biomimetic morphing-wing unmanned aerial vehicles (UAV) for two\nkey forms of supermanoeuvrability: the Pugachev cobra, and ballistic\ntransition. Conclusions are drawn as to the mechanism by which these manoeuvres\ncan be performed, and their feasibility in practical biomimetic unmanned aerial\nvehicle (UAV). These conclusions have wide relevance to both the design of\nsupermanoeuvrable UAVs, and the study of biological flight dynamics across\nmultiple species.",
    "descriptor": "",
    "authors": [
      "Arion Pons",
      "Fehmi Cirak"
    ],
    "subjectives": [
      "Biological Physics (physics.bio-ph)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.09431"
  },
  {
    "id": "arXiv:2205.09435",
    "title": "Smooth densities and generative modeling with unsupervised random  forests",
    "abstract": "Density estimation is a fundamental problem in statistics, and any attempt to\ndo so in high dimensions typically requires strong assumptions or complex deep\nlearning architectures. An important application for density estimators is\nsynthetic data generation, an area currently dominated by neural networks that\noften demand enormous training datasets and extensive tuning. We propose a new\nmethod based on unsupervised random forests for estimating smooth densities in\narbitrary dimensions without parametric constraints, as well as generating\nrealistic synthetic data. We prove the consistency of our approach and\ndemonstrate its advantages over existing tree-based density estimators, which\ngenerally rely on ill-chosen split criteria and do not scale well with data\ndimensionality. Experiments illustrate that our algorithm compares favorably to\nstate-of-the-art deep learning generative models, achieving superior\nperformance in a range of benchmark trials while executing about two orders of\nmagnitude faster on average. Our method is implemented in easy-to-use\n$\\texttt{R}$ and Python packages.",
    "descriptor": "\nComments: 18 pages, 4 figures\n",
    "authors": [
      "David S. Watson",
      "Kristin Blesch",
      "Jan Kapar",
      "Marvin N. Wright"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2205.09435"
  },
  {
    "id": "arXiv:2205.09436",
    "title": "Outdoor-to-Indoor 28 GHz Wireless Measurements in Manhattan: Path Loss,  Environmental Effects, and 90% Coverage",
    "abstract": "Outdoor-to-indoor (OtI) signal propagation further challenges the already\ntight link budgets at millimeter-wave (mmWave). To gain insight into OtI mmWave\nscenarios at 28 GHz, we conducted an extensive measurement campaign consisting\nof over 2,200 link measurements. In total, 43 OtI scenarios were measured in\nWest Harlem, New York City, covering seven highly diverse buildings. The\nmeasured OtI path gain can vary by up to 40 dB for a given link distance, and\nthe empirical path gain model for all data shows an average of 30 dB excess\nloss over free space at distances beyond 50 m, with an RMS fitting error of\n11.7 dB. The type of glass is found to be the single dominant feature for OtI\nloss, with 20 dB observed difference between empirical path gain models for\nscenarios with low-loss and high-loss glass. The presence of scaffolding, tree\nfoliage, or elevated subway tracks, as well as difference in floor height are\neach found to have an impact between 5-10 dB. We show that for urban buildings\nwith high-loss glass, OtI coverage can support 500 Mbps for 90% of indoor user\nequipment (UEs) with a base station (BS) antenna placed up to 49 m away. For\nbuildings with low-loss glass, such as our case study covering multiple\nclassrooms of a public school, data rates over 2.5/1.2 Gbps are possible from a\nBS 68/175 m away from the school building, when a line-of-sight path is\navailable. We expect these results to be useful for the deployment of mmWave\nnetworks in dense urban environments as well as the development of relevant\nscheduling and beam management algorithms.",
    "descriptor": "\nComments: 13 pages, 13 figures. Submitted to MobiHoc 2022\n",
    "authors": [
      "Manav Kohli",
      "Abhishek Adhikari",
      "Gulnur Avci",
      "Sienna Brent",
      "Aditya Dash",
      "Jared Moser",
      "Sabbir Hossain",
      "Igor Kadota",
      "Carson Garland",
      "Shivan Mukherjee",
      "Rodolfo Feick",
      "Dmitry Chizhik",
      "Jinfeng Du",
      "Reinaldo A. Valenzuela",
      "Gil Zussman"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.09436"
  },
  {
    "id": "arXiv:2205.09463",
    "title": "A fast dynamic smooth adaptive meshing scheme with applications to  compressible flow",
    "abstract": "We develop a fast-running smooth adaptive meshing (SAM) algorithm for dynamic\ncurvilinear mesh generation, which is based on a fast solution strategy of the\ntime-dependent Monge-Amp\\`{e}re (MA) equation, $\\det \\nabla \\psi(x,t) =\n\\mathsf{G} \\circ\\psi (x,t)$. The novelty of our approach is a new so-called\n\\emph{perturbation formulation} of MA, which constructs the solution map $\\psi$\nvia composition of a sequence of near identity deformations of a uniform\nreference mesh. This allows us to utilize a simple, fast, and high order\naccurate implementation of the deformation method. We design SAM to satisfy\nboth internal and external consistency requirements between stability,\naccuracy, and efficiency constraints, and show that the scheme is of optimal\ncomplexity when applied to time-dependent mesh generation for solutions to\nhyperbolic systems such as the Euler equations of gas dynamics. We perform a\nseries of challenging mesh generation experiments for grids with large\ndeformations, and demonstrate that SAM is able to produce smooth meshes\ncomparable to state-of-the-art solvers, while running approximately 50-100\ntimes faster. The SAM algorithm is then coupled to a simple Arbitrary\nLagrangian Eulerian (ALE) scheme for 2$D$ gas dynamics. Specifically, we\nimplement the $C$-method and develop a new ALE interface tracking algorithm for\ncontact discontinuities. We perform numerical experiments for both the Noh\nimplosion problem as well as a classical Rayleigh-Taylor instability problem.\nResults confirm that low-resolution simulations using our SAM-ALE algorithm\ncompare favorably with high-resolution uniform mesh runs.",
    "descriptor": "\nComments: 58 pages, 21 figures\n",
    "authors": [
      "Raaghav Ramani",
      "Steve Shkoller"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2205.09463"
  },
  {
    "id": "arXiv:2205.09476",
    "title": "The Quantum Internet: Enhancing Classical Internet Services one Qubit at  a Time",
    "abstract": "Nowadays, the classical Internet has mainly envisioned as the underlying\ncommunication infrastructure of the Quantum Internet, aimed at providing\nservices such as signaling and coordination messages. However, the interplay\nbetween classical and Quantum Internet is complex and its understanding is\npivotal for an effective design of the Quantum Internet protocol stack. The aim\nof the paper is to shed the light on this interplay, by highlighting that such\nan interplay is indeed bidirectional rather than unidirectional. And the\nQuantum Internet exhibits the potential of supporting and even enhancing\nclassical Internet functionalities.",
    "descriptor": "",
    "authors": [
      "Angela Sara Cacciapuoti",
      "Jessica Illiano",
      "Seid Koudia",
      "Kyrylo Simonov",
      "Marcello Caleffi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.09476"
  },
  {
    "id": "arXiv:2205.09494",
    "title": "Differentially private Riemannian optimization",
    "abstract": "In this paper, we study the differentially private empirical risk\nminimization problem where the parameter is constrained to a Riemannian\nmanifold. We introduce a framework of differentially private Riemannian\noptimization by adding noise to the Riemannian gradient on the tangent space.\nThe noise follows a Gaussian distribution intrinsically defined with respect to\nthe Riemannian metric. We adapt the Gaussian mechanism from the Euclidean space\nto the tangent space compatible to such generalized Gaussian distribution. We\nshow that this strategy presents a simple analysis as compared to directly\nadding noise on the manifold. We further show privacy guarantees of the\nproposed differentially private Riemannian (stochastic) gradient descent using\nan extension of the moments accountant technique. Additionally, we prove\nutility guarantees under geodesic (strongly) convex, general nonconvex\nobjectives as well as under the Riemannian Polyak-{\\L}ojasiewicz condition. We\nshow the efficacy of the proposed framework in several applications.",
    "descriptor": "",
    "authors": [
      "Andi Han",
      "Bamdev Mishra",
      "Pratik Jawanpuria",
      "Junbin Gao"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.09494"
  },
  {
    "id": "arXiv:2205.09498",
    "title": "Demonstration of fully integrated parity-time-symmetric electronics",
    "abstract": "Harnessing parity-time (PT) symmetry with balanced gain and loss profiles has\ncreated a variety of opportunities in electronics from wireless energy transfer\nto telemetry sensing and topological defect engineering. However, existing\nimplementations often employ ad-hoc approaches at low operating frequencies and\nare unable to accommodate large-scale integration. Here, we report a fully\nintegrated realization of PT-symmetry in a standard complementary\nmetal-oxide-semiconductor technology. Our work demonstrates salient PT-symmetry\nfeatures such as phase transition as well as the ability to manipulate\nbroadband microwave generation and propagation beyond the limitations\nencountered by exiting schemes. The system shows 2.1 times bandwidth and 30\npercentage noise reduction compared to conventional microwave generation in\noscillatory mode and displays large non-reciprocal microwave transport from\n2.75 to 3.10 gigahertz in non-oscillatory mode due to enhanced nonlinearities.\nThis approach could enrich integrated circuit (IC) design methodology beyond\nwell-established performance limits and enable the use of scalable IC\ntechnology to study topological effects in high-dimensional non-Hermitian\nsystems.",
    "descriptor": "\nComments: 62 pages (29 pages Main Text, 33 pages Supplementary Materials), 27 figures (4 figures Main Text, 23 figures Supplementary Materials), 96 references (50 references Main Text, 46 references Supplementary Materials)\n",
    "authors": [
      "Weidong Cao",
      "Changqing Wang",
      "Weijian Chen",
      "Song Hu",
      "Hua Wang",
      "Lan Yang",
      "Xuan Zhang"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Hardware Architecture (cs.AR)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2205.09498"
  },
  {
    "id": "arXiv:2205.09508",
    "title": "Practical Skills Demand Forecasting via Representation Learning of  Temporal Dynamics",
    "abstract": "Rapid technological innovation threatens to leave much of the global\nworkforce behind. Today's economy juxtaposes white-hot demand for skilled labor\nagainst stagnant employment prospects for workers unprepared to participate in\na digital economy. It is a moment of peril and opportunity for every country,\nwith outcomes measured in long-term capital allocation and the life\nsatisfaction of billions of workers. To meet the moment, governments and\nmarkets must find ways to quicken the rate at which the supply of skills reacts\nto changes in demand. More fully and quickly understanding labor market\nintelligence is one route. In this work, we explore the utility of time series\nforecasts to enhance the value of skill demand data gathered from online job\nadvertisements. This paper presents a pipeline which makes one-shot multi-step\nforecasts into the future using a decade of monthly skill demand observations\nbased on a set of recurrent neural network methods. We compare the performance\nof a multivariate model versus a univariate one, analyze how correlation\nbetween skills can influence multivariate model results, and present\npredictions of demand for a selection of skills practiced by workers in the\ninformation technology industry.",
    "descriptor": "\nComments: 15 pages, 5th AAAI/ACM Conference on AI, Ethics, and Society\n",
    "authors": [
      "Maysa M. Garcia de Macedo",
      "Wyatt Clarke",
      "Eli Lucherini",
      "Tyler Baldwin",
      "Dilermando Queiroz Neto",
      "Rogerio de Paula",
      "Subhro Das"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09508"
  },
  {
    "id": "arXiv:2205.09510",
    "title": "An Introduction to Quantum Machine Learning for Engineers",
    "abstract": "In the current noisy intermediate-scale quantum (NISQ) era, quantum machine\nlearning is emerging as a dominant paradigm to program gate-based quantum\ncomputers. In quantum machine learning, the gates of a quantum circuit are\nparametrized, and the parameters are tuned via classical optimization based on\ndata and on measurements of the outputs of the circuit. Parametrized quantum\ncircuits (PQCs) can efficiently address combinatorial optimization problems,\nimplement probabilistic generative models, and carry out inference\n(classification and regression). This monograph provides a self-contained\nintroduction to quantum machine learning for an audience of engineers with a\nbackground in probability and linear algebra. It first describes the necessary\nbackground, concepts, and tools necessary to describe quantum operations and\nmeasurements. Then, it covers parametrized quantum circuits, the variational\nquantum eigensolver, as well as unsupervised and supervised quantum machine\nlearning formulations.",
    "descriptor": "\nComments: This is a first draft and is currently under review. Comments are very welcome, including corrections\n",
    "authors": [
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09510"
  },
  {
    "id": "arXiv:2205.09515",
    "title": "Variational Inference for Bayesian Bridge Regression",
    "abstract": "We study the implementation of Automatic Differentiation Variational\ninference (ADVI) for Bayesian inference on regression models with bridge\npenalization. The bridge approach uses $\\ell_{\\alpha}$ norm, with $\\alpha \\in\n(0, +\\infty)$ to define a penalization on large values of the regression\ncoefficients, which includes the Lasso ($\\alpha = 1$) and ridge $(\\alpha = 2)$\npenalizations as special cases. Full Bayesian inference seamlessly provides\njoint uncertainty estimates for all model parameters. Although MCMC aproaches\nare available for bridge regression, it can be slow for large dataset,\nspecially in high dimensions. The ADVI implementation allows the use of small\nbatches of data at each iteration (due to stochastic gradient based\nalgorithms), therefore speeding up computational time in comparison with MCMC.\nWe illustrate the approach on non-parametric regression models with B-splines,\nalthough the method works seamlessly for other choices of basis functions. A\nsimulation study shows the main properties of the proposed method.",
    "descriptor": "\nComments: 24 pages, 12 figures\n",
    "authors": [
      "Carlos Tadeu Pagani Zanini",
      "Helio dos Santos Migon",
      "Ronaldo Dias"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2205.09515"
  },
  {
    "id": "arXiv:2205.09523",
    "title": "scICML: Information-theoretic Co-clustering-based Multi-view Learning  for the Integrative Analysis of Single-cell Multi-omics data",
    "abstract": "Modern high-throughput sequencing technologies have enabled us to profile\nmultiple molecular modalities from the same single cell, providing\nunprecedented opportunities to assay celluar heterogeneity from multiple\nbiological layers. However, the datasets generated from these technologies tend\nto have high level of noise and are highly sparse, bringing challenges to data\nanalysis. In this paper, we develop a novel information-theoretic\nco-clustering-based multi-view learning (scICML) method for multi-omics\nsingle-cell data integration. scICML utilizes co-clusterings to aggregate\nsimilar features for each view of data and uncover the common clustering\npattern for cells. In addition, scICML automatically matches the clusters of\nthe linked features across different data types for considering the biological\ndependency structure across different types of genomic features. Our\nexperiments on four real-world datasets demonstrate that scICML improves the\noverall clustering performance and provides biological insights into the data\nanalysis of peripheral blood mononuclear cells.",
    "descriptor": "\nComments: 11 pages; 1 figure\n",
    "authors": [
      "Pengcheng Zeng",
      "Zhixiang Lin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09523"
  },
  {
    "id": "arXiv:2205.09533",
    "title": "Estimating the ultrasound attenuation coefficient using convolutional  neural networks -- a feasibility study",
    "abstract": "Attenuation coefficient (AC) is a fundamental measure of tissue acoustical\nproperties, which can be used in medical diagnostics. In this work, we\ninvestigate the feasibility of using convolutional neural networks (CNNs) to\ndirectly estimate AC from radio-frequency (RF) ultrasound signals. To develop\nthe CNNs we used RF signals collected from tissue mimicking numerical phantoms\nfor the AC values in a range from 0.1 to 1.5 dB/(MHz*cm). The models were\ntrained based on 1-D patches of RF data. We obtained mean absolute AC\nestimation errors of 0.08, 0.12, 0.20, 0.25 for the patch lengths: 10 mm, 5 mm,\n2 mm and 1 mm, respectively. We explain the performance of the model by\nvisualizing the frequency content associated with convolutional filters. Our\nstudy presents that the AC can be calculated using deep learning, and the\nweights of the CNNs can have physical interpretation.",
    "descriptor": "\nComments: 4 figures\n",
    "authors": [
      "Piotr Jarosik",
      "Michal Byra",
      "Marcin Lewandowski",
      "Ziemowit Klimonda"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09533"
  },
  {
    "id": "arXiv:2205.09546",
    "title": "Closing the gap: Exact maximum likelihood training of generative  autoencoders using invertible layers",
    "abstract": "In this work, we provide an exact likelihood alternative to the variational\ntraining of generative autoencoders. We show that VAE-style autoencoders can be\nconstructed using invertible layers, which offer a tractable exact likelihood\nwithout the need for any regularization terms. This is achieved while leaving\ncomplete freedom in the choice of encoder, decoder and prior architectures,\nmaking our approach a drop-in replacement for the training of existing VAEs and\nVAE-style models. We refer to the resulting models as Autoencoders within Flows\n(AEF), since the encoder, decoder and prior are defined as individual layers of\nan overall invertible architecture. We show that the approach results in\nstrikingly higher performance than architecturally equivalent VAEs in term of\nlog-likelihood, sample quality and denoising performance. In a broad sense, the\nmain ambition of this work is to close the gap between the normalizing flow and\nautoencoder literature under the common framework of invertibility and exact\nmaximum likelihood.",
    "descriptor": "",
    "authors": [
      "Gianluigi Silvestri",
      "Daan Roos",
      "Luca Ambrogioni"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09546"
  },
  {
    "id": "arXiv:2205.09548",
    "title": "ODBO: Bayesian Optimization with Search Space Prescreening for Directed  Protein Evolution",
    "abstract": "Directed evolution is a versatile technique in protein engineering that\nmimics the process of natural selection by iteratively alternating between\nmutagenesis and screening in order to search for sequences that optimize a\ngiven property of interest, such as catalytic activity and binding affinity to\na specified target. However, the space of possible proteins is too large to\nsearch exhaustively in the laboratory, and functional proteins are scarce in\nthe vast sequence space. Machine learning (ML) approaches can accelerate\ndirected evolution by learning to map protein sequences to functions without\nbuilding a detailed model of the underlying physics, chemistry and biological\npathways. Despite the great potentials held by these ML methods, they encounter\nsevere challenges in identifying the most suitable sequences for a targeted\nfunction. These failures can be attributed to the common practice of adopting a\nhigh-dimensional feature representation for protein sequences and inefficient\nsearch methods. To address these issues, we propose an efficient, experimental\ndesign-oriented closed-loop optimization framework for protein directed\nevolution, termed ODBO, which employs a combination of novel low-dimensional\nprotein encoding strategy and Bayesian optimization enhanced with search space\nprescreening via outlier detection. We further design an initial sample\nselection strategy to minimize the number of experimental samples for training\nML models. We conduct and report four protein directed evolution experiments\nthat substantiate the capability of the proposed framework for finding of the\nvariants with properties of interest. We expect the ODBO framework to greatly\nreduce the experimental cost and time cost of directed evolution, and can be\nfurther generalized as a powerful tool for adaptive experimental design in a\nbroader context.",
    "descriptor": "\nComments: 24 pages, 10 figures\n",
    "authors": [
      "Lixue Cheng",
      "Ziyi Yang",
      "Benben Liao",
      "Changyu Hsieh",
      "Shengyu Zhang"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2205.09548"
  },
  {
    "id": "arXiv:2205.09558",
    "title": "Live load matrix recovery from scattering data in linear elasticity",
    "abstract": "We study the numerical approximation of the inverse scattering problem in the\ntwo-dimensional homogeneous isotropic linear elasticity with an unknown linear\nload given by a square matrix. For both backscattering data and fixed-angle\nscattering data, we show how to obtain numerical approximations of the\nso-called Born approximations and propose new iterative algorithms that provide\nsequences of approximations to the unknown load. Numerical evidences of the\nconvergence for not too large loads are also given.",
    "descriptor": "",
    "authors": [
      "J.A. Barcel\u00f3",
      "C. Castro",
      "M.C. Vilela"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.09558"
  },
  {
    "id": "arXiv:2205.09574",
    "title": "Online Optimization of Dynamical Systems with Deep Learning Perception",
    "abstract": "This paper considers the problem of controlling a dynamical system when the\nstate cannot be directly measured and the control performance metrics are\nunknown or partially known. In particular, we focus on the design of\ndata-driven controllers to regulate a dynamical system to the solution of a\nconstrained convex optimization problem where: i) the state must be estimated\nfrom nonlinear and possibly high-dimensional data; and, ii) the cost of the\noptimization problem -- which models control objectives associated with inputs\nand states of the system -- is not available and must be learned from data. We\npropose a data-driven feedback controller that is based on adaptations of a\nprojected gradient-flow method; the controller includes neural networks as\nintegral components for the estimation of the unknown functions. Leveraging\nstability theory for perturbed systems, we derive sufficient conditions to\nguarantee exponential input-to-state stability (ISS) of the control loop. In\nparticular, we show that the interconnected system is ISS with respect to the\napproximation errors of the neural network and unknown disturbances affecting\nthe system. The transient bounds combine the universal approximation property\nof deep neural networks with the ISS characterization. Illustrative numerical\nresults are presented in the context of control of epidemics.",
    "descriptor": "\nComments: This is an extended version of the paper submitted to the IEEE Open Journal of Control Systems - Special Section on Machine Learning with Control, containing proofs\n",
    "authors": [
      "Liliaokeawawa Cothren",
      "Gianluca Bianchin",
      "Emiliano Dall'Anese"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.09574"
  },
  {
    "id": "arXiv:2205.09580",
    "title": "Line Planning in Public Transport: Bypassing Line Pool Generation",
    "abstract": "Line planning, i.e. choosing paths which are operated by one vehicle\nend-to-end, is an important aspect of public transport planning. While there\nexists heuristic procedures for generating lines from scratch, most theoretical\nobservations consider the problem of choosing lines from a predefined line\npool. In this paper, we consider the complexity of the line planning problem\nwhen all simple paths can be used as lines. Depending on the cost structure, we\nshow that the problem can be NP-hard even for paths and stars and that no\npolynomial time approximation of sub-linear performance is possible.\nAdditionally, we identify polynomially solvable cases and present a\npseudo-polynomial solution approach for trees.",
    "descriptor": "\nComments: 20 pages, 4 figures, submitted to ESA 2022\n",
    "authors": [
      "Irene Heinrich",
      "Philine Schiewe",
      "Constantin Seebach"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.09580"
  },
  {
    "id": "arXiv:2205.09644",
    "title": "Neural network for multi-exponential sound energy decay analysis",
    "abstract": "An established model for sound energy decay functions (EDFs) is the\nsuperposition of multiple exponentials and a noise term. This work proposes a\nneural-network-based approach for estimating the model parameters from EDFs.\nThe network is trained on synthetic EDFs and evaluated on two large datasets of\nover 20000 EDF measurements conducted in various acoustic environments. The\nevaluation shows that the proposed neural network architecture robustly\nestimates the model parameters from large datasets of measured EDFs, while\nbeing lightweight and computationally efficient. An implementation of the\nproposed neural network is publicly available.",
    "descriptor": "\nComments: The following article has been submitted to the Journal of the Acoustical Society of America (JASA). After it is published, it will be found at this http URL\n",
    "authors": [
      "Georg G\u00f6tz",
      "Ricardo Falc\u00f3n P\u00e9rez",
      "Sebastian J. Schlecht",
      "Ville Pulkki"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2205.09644"
  },
  {
    "id": "arXiv:2205.09647",
    "title": "The First Optimal Acceleration of High-Order Methods in Smooth Convex  Optimization",
    "abstract": "In this paper, we study the fundamental open question of finding the optimal\nhigh-order algorithm for solving smooth convex minimization problems. Arjevani\net al. (2019) established the lower bound\n$\\Omega\\left(\\epsilon^{-2/(3p+1)}\\right)$ on the number of the $p$-th order\noracle calls required by an algorithm to find an $\\epsilon$-accurate solution\nto the problem, where the $p$-th order oracle stands for the computation of the\nobjective function value and the derivatives up to the order $p$. However, the\nexisting state-of-the-art high-order methods of Gasnikov et al. (2019b); Bubeck\net al. (2019); Jiang et al. (2019) achieve the oracle complexity\n$\\mathcal{O}\\left(\\epsilon^{-2/(3p+1)} \\log (1/\\epsilon)\\right)$, which does\nnot match the lower bound. The reason for this is that these algorithms require\nperforming a complex binary search procedure, which makes them neither optimal\nnor practical. We fix this fundamental issue by providing the first algorithm\nwith $\\mathcal{O}\\left(\\epsilon^{-2/(3p+1)}\\right)$ $p$-th order oracle\ncomplexity.",
    "descriptor": "",
    "authors": [
      "Dmitry Kovalev",
      "Alexander Gasnikov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09647"
  },
  {
    "id": "arXiv:2205.09653",
    "title": "Self-Consistent Dynamical Field Theory of Kernel Evolution in Wide  Neural Networks",
    "abstract": "We analyze feature learning in infinite width neural networks trained with\ngradient flow through a self-consistent dynamical field theory. We construct a\ncollection of deterministic dynamical order parameters which are inner-product\nkernels for hidden unit activations and gradients in each layer at pairs of\ntime points, providing a reduced description of network activity through\ntraining. These kernel order parameters collectively define the hidden layer\nactivation distribution, the evolution of the neural tangent kernel, and\nconsequently output predictions. For deep linear networks, these kernels\nsatisfy a set of algebraic matrix equations. For nonlinear networks, we provide\nan alternating sampling procedure to self-consistently solve for the kernel\norder parameters. We provide comparisons of the self-consistent solution to\nvarious approximation schemes including the static NTK approximation, gradient\nindependence assumption, and leading order perturbation theory, showing that\neach of these approximations can break down in regimes where general\nself-consistent solutions still provide an accurate description. Lastly, we\nprovide experiments in more realistic settings which demonstrate that the loss\nand kernel dynamics of CNNs at fixed feature learning strength is preserved\nacross different widths on a CIFAR classification task.",
    "descriptor": "\nComments: 42 pages\n",
    "authors": [
      "Blake Bordelon",
      "Cengiz Pehlevan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09653"
  },
  {
    "id": "arXiv:2205.09679",
    "title": "Dynamic Pricing Provides Robust Equilibria in Stochastic Ridesharing  Networks",
    "abstract": "Ridesharing markets are complex: drivers are strategic, rider demand and\ndriver availability are stochastic, and complex city-scale phenomena like\nweather induce large scale correlation across space and time. At the same time,\npast work has focused on a subset of these challenges. We propose a model of\nridesharing networks with strategic drivers, spatiotemporal dynamics, and\nstochasticity. Supporting both computational tractability and better modeling\nflexibility than classical fluid limits, we use a two-level stochastic model\nthat allows correlated shocks caused by weather or large public events.\nUsing this model, we propose a novel pricing mechanism: stochastic\nspatiotemporal pricing (SSP). We show that the SSP mechanism is asymptotically\nincentive-compatible and that all (approximate) equilibria of the resulting\ngame are asymptotically welfare-maximizing when the market is large enough. The\nSSP mechanism iteratively recomputes prices based on realized demand and\nsupply, and in this sense prices dynamically. We show that this is critical:\nwhile a static variant of the SSP mechanism (whose prices vary with the\nmarket-level stochastic scenario but not individual rider and driver decisions)\nhas a sequence of asymptotically welfare-optimal approximate equilibria, we\ndemonstrate that it also has other equilibria producing extremely low social\nwelfare. Thus, we argue that dynamic pricing is important for ensuring\nrobustness in stochastic ride-sharing networks.",
    "descriptor": "",
    "authors": [
      "J. Massey Cashore",
      "Peter I. Frazier",
      "Eva Tardos"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2205.09679"
  },
  {
    "id": "arXiv:2205.09680",
    "title": "Metrics of calibration for probabilistic predictions",
    "abstract": "Predictions are often probabilities; e.g., a prediction could be for\nprecipitation tomorrow, but with only a 30% chance. Given such probabilistic\npredictions together with the actual outcomes, \"reliability diagrams\" help\ndetect and diagnose statistically significant discrepancies -- so-called\n\"miscalibration\" -- between the predictions and the outcomes. The canonical\nreliability diagrams histogram the observed and expected values of the\npredictions; replacing the hard histogram binning with soft kernel density\nestimation is another common practice. But, which widths of bins or kernels are\nbest? Plots of the cumulative differences between the observed and expected\nvalues largely avoid this question, by displaying miscalibration directly as\nthe slopes of secant lines for the graphs. Slope is easy to perceive with\nquantitative precision, even when the constant offsets of the secant lines are\nirrelevant; there is no need to bin or perform kernel density estimation.\nThe existing standard metrics of miscalibration each summarize a reliability\ndiagram as a single scalar statistic. The cumulative plots naturally lead to\nscalar metrics for the deviation of the graph of cumulative differences away\nfrom zero; good calibration corresponds to a horizontal, flat graph which\ndeviates little from zero. The cumulative approach is currently unconventional,\nyet offers many favorable statistical properties, guaranteed via mathematical\ntheory backed by rigorous proofs and illustrative numerical examples. In\nparticular, metrics based on binning or kernel density estimation unavoidably\nmust trade-off statistical confidence for the ability to resolve variations as\na function of the predicted probability or vice versa. Widening the bins or\nkernels averages away random noise while giving up some resolving power.\nNarrowing the bins or kernels enhances resolving power while not averaging away\nas much noise.",
    "descriptor": "\nComments: 50 pages, 36 figures\n",
    "authors": [
      "Imanol Arrieta-Ibarra",
      "Paman Gujral",
      "Jonathan Tannen",
      "Mark Tygert",
      "Cherie Xu"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2205.09680"
  },
  {
    "id": "arXiv:2205.09699",
    "title": "Neural network topological snake models for locating general phase  diagrams",
    "abstract": "Machine learning for locating phase diagram has received intensive research\ninterest in recent years. However, its application in automatically locating\nphase diagram is limited to single closed phase boundary. In this paper, in\norder to locate phase diagrams with multiple phases and complex boundaries, we\nintroduce (i) a network-shaped snake model and (ii) a topologically\ntransformable snake with discriminative cooperative networks, respectively. The\nphase diagrams of both quantum and classical spin-1 model are obtained. Our\nmethod is flexible to determine the phase diagram with just snapshots of\nconfigurations from the cold-atom or other experiments.",
    "descriptor": "\nComments: 6 pages, 5 figures\n",
    "authors": [
      "Wanzhou Zhang",
      "Huijiong Yang",
      "Nan Wu"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Quantum Gases (cond-mat.quant-gas)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09699"
  },
  {
    "id": "arXiv:2205.09706",
    "title": "k-strip: A novel segmentation algorithm in k-space for the application  of skull stripping",
    "abstract": "Objectives: Present a novel deep learning-based skull stripping algorithm for\nmagnetic resonance imaging (MRI) that works directly in the information rich\nk-space.\nMaterials and Methods: Using two datasets from different institutions with a\ntotal of 36,900 MRI slices, we trained a deep learning-based model to work\ndirectly with the complex raw k-space data. Skull stripping performed by HD-BET\n(Brain Extraction Tool) in the image domain were used as the ground truth.\nResults: Both datasets were very similar to the ground truth (DICE scores of\n92\\%-98\\% and Hausdorff distances of under 5.5 mm). Results on slices above the\neye-region reach DICE scores of up to 99\\%, while the accuracy drops in regions\naround the eyes and below, with partially blurred output. The output of k-strip\noften smoothed edges at the demarcation to the skull. Binary masks are created\nwith an appropriate threshold.\nConclusion: With this proof-of-concept study, we were able to show the\nfeasibility of working in the k-space frequency domain, preserving phase\ninformation, with consistent results. Future research should be dedicated to\ndiscovering additional ways the k-space can be used for innovative image\nanalysis and further workflows.",
    "descriptor": "\nComments: 11 pages, 6 figures, 2 tables\n",
    "authors": [
      "Moritz Rempe",
      "Florian Mentzel",
      "Kelsey L. Pomykala",
      "Johannes Haubold",
      "Felix Nensa",
      "Kevin Kr\u00f6ninger",
      "Jan Egger",
      "Jens Kleesiek"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09706"
  },
  {
    "id": "arXiv:2205.09709",
    "title": "Bi-LSTM Scoring Based Similarity Measurement with Agglomerative  Hierarchical Clustering (AHC) for Speaker Diarization",
    "abstract": "Majority of speech signals across different scenarios are never available\nwith well-defined audio segments containing only a single speaker. A typical\nconversation between two speakers consists of segments where their voices\noverlap, interrupt each other or halt their speech in between multiple\nsentences. Recent advancements in diarization technology leverage neural\nnetwork-based approaches to improvise multiple subsystems of speaker\ndiarization system comprising of extracting segment-wise embedding features and\ndetecting changes in the speaker during conversation. However, to identify\nspeaker through clustering, models depend on methodologies like PLDA to\ngenerate similarity measure between two extracted segments from a given\nconversational audio. Since these algorithms ignore the temporal structure of\nconversations, they tend to achieve a higher Diarization Error Rate (DER), thus\nleading to misdetections both in terms of speaker and change identification.\nTherefore, to compare similarity of two speech segments both independently and\nsequentially, we propose a Bi-directional Long Short-term Memory network for\nestimating the elements present in the similarity matrix. Once the similarity\nmatrix is generated, Agglomerative Hierarchical Clustering (AHC) is applied to\nfurther identify speaker segments based on thresholding. To evaluate the\nperformance, Diarization Error Rate (DER%) metric is used. The proposed model\nachieves a low DER of 34.80% on a test set of audio samples derived from ICSI\nMeeting Corpus as compared to traditional PLDA based similarity measurement\nmechanism which achieved a DER of 39.90%.",
    "descriptor": "\nComments: 8 pages, 3 figures, 2 tables, 1 algorithm, Technical Report: Recognition Technologies, Inc\n",
    "authors": [
      "Siddharth S. Nijhawan",
      "Homayoon Beigi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09709"
  },
  {
    "id": "arXiv:2205.09724",
    "title": "Chemotactically induced search and defense strategies in a tritrophic  system",
    "abstract": "In this paper we study the question of the survival of a predator which in a\nstatic scenario vanishes. we analyze the role of migration on the coexistence\nof three species interacting through a intraguild relationship.",
    "descriptor": "\nComments: 27 pages, 15 figures\n",
    "authors": [
      "Nestor Anaya",
      "Manuel Falconi",
      "Guilmer Gonz\u00e1lez"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.09724"
  },
  {
    "id": "arXiv:2205.09727",
    "title": "The Franz-Parisi Criterion and Computational Trade-offs in High  Dimensional Statistics",
    "abstract": "Many high-dimensional statistical inference problems are believed to possess\ninherent computational hardness. Various frameworks have been proposed to give\nrigorous evidence for such hardness, including lower bounds against restricted\nmodels of computation (such as low-degree functions), as well as methods rooted\nin statistical physics that are based on free energy landscapes. This paper\naims to make a rigorous connection between the seemingly different low-degree\nand free-energy based approaches. We define a free-energy based criterion for\nhardness and formally connect it to the well-established notion of low-degree\nhardness for a broad class of statistical problems, namely all Gaussian\nadditive models and certain models with a sparse planted signal. By leveraging\nthese rigorous connections we are able to: establish that for Gaussian additive\nmodels the \"algebraic\" notion of low-degree hardness implies failure of\n\"geometric\" local MCMC algorithms, and provide new low-degree lower bounds for\nsparse linear regression which seem difficult to prove directly. These results\nprovide both conceptual insights into the connections between different notions\nof hardness, as well as concrete technical tools such as new methods for\nproving low-degree lower bounds.",
    "descriptor": "\nComments: 51 pages, 1 figure\n",
    "authors": [
      "Afonso S. Bandeira",
      "Ahmed El Alaoui",
      "Samuel B. Hopkins",
      "Tselil Schramm",
      "Alexander S. Wein",
      "Ilias Zadik"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.09727"
  },
  {
    "id": "arXiv:1806.04884",
    "title": "Spurious Local Minima of Deep ReLU Neural Networks in the Neural Tangent  Kernel Regime",
    "abstract": "Comments: 12 pages, 6 figures. We relocated the results obtained in the previous version into the NTK regime, and changed the paper title",
    "descriptor": "\nComments: 12 pages, 6 figures. We relocated the results obtained in the previous version into the NTK regime, and changed the paper title\n",
    "authors": [
      "Tohru Nitta"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1806.04884"
  },
  {
    "id": "arXiv:2006.06926",
    "title": "Bayesian Network Structure Learning using Digital Annealer",
    "abstract": "Comments: 11 pages, 2 tables, 3 figures, NeurIPS 2022 (under review)",
    "descriptor": "\nComments: 11 pages, 2 tables, 3 figures, NeurIPS 2022 (under review)\n",
    "authors": [
      "Yuta Shikuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.06926"
  },
  {
    "id": "arXiv:2006.13382",
    "title": "Spherical Perspective on Learning with Normalization Layers",
    "abstract": "Spherical Perspective on Learning with Normalization Layers",
    "descriptor": "",
    "authors": [
      "Simon Roburin",
      "Yann de Mont-Marin",
      "Andrei Bursuc",
      "Renaud Marlet",
      "Patrick P\u00e9rez",
      "Mathieu Aubry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.13382"
  },
  {
    "id": "arXiv:2007.01033",
    "title": "Characteristic Logics for Behavioural Hemimetrics via Fuzzy Lax  Extensions",
    "abstract": "Characteristic Logics for Behavioural Hemimetrics via Fuzzy Lax  Extensions",
    "descriptor": "",
    "authors": [
      "Paul Wild",
      "Lutz Schr\u00f6der"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2007.01033"
  },
  {
    "id": "arXiv:2008.06699",
    "title": "On multiple scattering in Compton scattering tomography and its impact  on fan-beam CT",
    "abstract": "Comments: 26 pages, 12 figures",
    "descriptor": "\nComments: 26 pages, 12 figures\n",
    "authors": [
      "Lorenz Kuger",
      "Gael Rigaud"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2008.06699"
  },
  {
    "id": "arXiv:2008.08401",
    "title": "Coverage-Based Debloating for Java Bytecode",
    "abstract": "Coverage-Based Debloating for Java Bytecode",
    "descriptor": "",
    "authors": [
      "C\u00e9sar Soto-Valero",
      "Thomas Durieux",
      "Nicolas Harrand",
      "Benoit Baudry"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2008.08401"
  },
  {
    "id": "arXiv:2009.11841",
    "title": "The Limits of an Information Intermediary in Auction Design",
    "abstract": "Comments: Accepted to ACM EC 2022",
    "descriptor": "\nComments: Accepted to ACM EC 2022\n",
    "authors": [
      "Reza Alijani",
      "Siddhartha Banerjee",
      "Kamesh Munagala",
      "Kangning Wang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2009.11841"
  },
  {
    "id": "arXiv:2009.12494",
    "title": "SEMI: Self-supervised Exploration via Multisensory Incongruity",
    "abstract": "Comments: Accepted at ICRA 2022",
    "descriptor": "\nComments: Accepted at ICRA 2022\n",
    "authors": [
      "Jianren Wang",
      "Ziwen Zhuang",
      "Hang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.12494"
  },
  {
    "id": "arXiv:2011.03669",
    "title": "PS-ORAM: Efficient Crash Consistency Support for Oblivious RAM on NVM",
    "abstract": "Comments: In Proceedings of The 49th Annual International Symposium on Computer Architecture (ISCA' 22)",
    "descriptor": "\nComments: In Proceedings of The 49th Annual International Symposium on Computer Architecture (ISCA' 22)\n",
    "authors": [
      "Gang Liu",
      "Kenli Li",
      "Zheng Xiao",
      "Rujia Wang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2011.03669"
  },
  {
    "id": "arXiv:2011.08641",
    "title": "A Review of Generalized Zero-Shot Learning Methods",
    "abstract": "Comments: 24 pages, 12 figures",
    "descriptor": "\nComments: 24 pages, 12 figures\n",
    "authors": [
      "Farhad Pourpanah",
      "Moloud Abdar",
      "Yuxuan Luo",
      "Xinlei Zhou",
      "Ran Wang",
      "Chee Peng Lim",
      "Xi-Zhao Wang",
      "Q. M. Jonathan Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.08641"
  },
  {
    "id": "arXiv:2011.09926",
    "title": "Challenges in Deploying Machine Learning: a Survey of Case Studies",
    "abstract": "Comments: v3 accepted to publication at ACM Computer Surveys in 2022; v2 presented at The ML-Retrospectives, Surveys & Meta-Analyses Workshop, NeurIPS 2020",
    "descriptor": "\nComments: v3 accepted to publication at ACM Computer Surveys in 2022; v2 presented at The ML-Retrospectives, Surveys & Meta-Analyses Workshop, NeurIPS 2020\n",
    "authors": [
      "Andrei Paleyes",
      "Raoul-Gabriel Urma",
      "Neil D. Lawrence"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.09926"
  },
  {
    "id": "arXiv:2011.12815",
    "title": "Learning Multiscale Convolutional Dictionaries for Image Reconstruction",
    "abstract": "Learning Multiscale Convolutional Dictionaries for Image Reconstruction",
    "descriptor": "",
    "authors": [
      "Tianlin Liu",
      "Anadi Chaman",
      "David Belius",
      "Ivan Dokmani\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2011.12815"
  },
  {
    "id": "arXiv:2012.01821",
    "title": "D-Unet: A Dual-encoder U-Net for Image Splicing Forgery Detection and  Localization",
    "abstract": "Comments: 13 pages, 13 figures",
    "descriptor": "\nComments: 13 pages, 13 figures\n",
    "authors": [
      "Xiuli Bi",
      "Ranglei Wu",
      "Bin Xiao",
      "Weisheng Li",
      "Guoyin Wang",
      "Xinbo Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.01821"
  },
  {
    "id": "arXiv:2012.03389",
    "title": "Traffic Assignment Problem for Footpath Networks with Bidirectional  Links",
    "abstract": "Traffic Assignment Problem for Footpath Networks with Bidirectional  Links",
    "descriptor": "",
    "authors": [
      "Tanapon Lilasathapornkit",
      "David Rey",
      "Wei Liu",
      "Meead Saberi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2012.03389"
  },
  {
    "id": "arXiv:2012.07804",
    "title": "Improved Maximally Recoverable LRCs using Skew Polynomials",
    "abstract": "Improved Maximally Recoverable LRCs using Skew Polynomials",
    "descriptor": "",
    "authors": [
      "Sivakanth Gopi",
      "Venkatesan Guruswami"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computational Complexity (cs.CC)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2012.07804"
  },
  {
    "id": "arXiv:2101.04425",
    "title": "Envy-free matchings with cost-controlled quotas",
    "abstract": "Comments: 28 pages, 10 figures, stronger results, empirical evaluations",
    "descriptor": "\nComments: 28 pages, 10 figures, stronger results, empirical evaluations\n",
    "authors": [
      "Girija Limaye",
      "Meghana Nasre"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2101.04425"
  },
  {
    "id": "arXiv:2102.00610",
    "title": "The Harrington Yowlumne Narrative Corpus",
    "abstract": "The Harrington Yowlumne Narrative Corpus",
    "descriptor": "",
    "authors": [
      "Nathan M. White",
      "Timothy Henry-Rodriguez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2102.00610"
  },
  {
    "id": "arXiv:2103.00858",
    "title": "CARMI: A Cache-Aware Learned Index with a Cost-based Construction  Algorithm",
    "abstract": "Comments: 21 pages, 24 figures, 9 tables",
    "descriptor": "\nComments: 21 pages, 24 figures, 9 tables\n",
    "authors": [
      "Jiaoyi Zhang",
      "Yihan Gao"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.00858"
  },
  {
    "id": "arXiv:2103.08560",
    "title": "Take a Bite of the Reality Sandwich: Revisiting the Security of  Progressive Message Authentication Codes",
    "abstract": "Comments: ACM WiSec'22",
    "descriptor": "\nComments: ACM WiSec'22\n",
    "authors": [
      "Eric Wagner",
      "Jan Bauer",
      "Martin Henze"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2103.08560"
  },
  {
    "id": "arXiv:2103.11900",
    "title": "Study of a measure of efficiency as a tool for applying the principle of  least effort to the derivation of the Zipf and the Pareto laws",
    "abstract": "Comments: 25 pages, 5 figures",
    "descriptor": "\nComments: 25 pages, 5 figures\n",
    "authors": [
      "A. El Kaabouchi",
      "F.X. Machu",
      "J. Cocks",
      "R. Wang",
      "Y.Y. Zhu",
      "Q.A. Wang"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2103.11900"
  },
  {
    "id": "arXiv:2103.16156",
    "title": "Uniform Envelopes",
    "abstract": "Uniform Envelopes",
    "descriptor": "",
    "authors": [
      "Eike Neumann"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2103.16156"
  },
  {
    "id": "arXiv:2104.02230",
    "title": "Achieving Domain Generalization in Underwater Object Detection by Domain  Mixup and Contrastive Learning",
    "abstract": "Achieving Domain Generalization in Underwater Object Detection by Domain  Mixup and Contrastive Learning",
    "descriptor": "",
    "authors": [
      "Pinhao Song",
      "Linhui Dai",
      "Peipei Yuan",
      "Hong Liu",
      "Runwei Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.02230"
  },
  {
    "id": "arXiv:2105.10410",
    "title": "Multi-objective Optimisation of Digital Circuits based on Cell Mapping  in an Industrial EDA Flow",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication\n",
    "authors": [
      "Linan Cao",
      "Simon J. Bale",
      "Martin A. Trefzer"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.10410"
  },
  {
    "id": "arXiv:2105.10699",
    "title": "Denoising Noisy Neural Networks: A Bayesian Approach with Compensation",
    "abstract": "Comments: Keywords: Noisy neural network, denoiser, wireless transmission of neural networks, federated edge learning, analog device. 18 pages, 9 figures",
    "descriptor": "\nComments: Keywords: Noisy neural network, denoiser, wireless transmission of neural networks, federated edge learning, analog device. 18 pages, 9 figures\n",
    "authors": [
      "Yulin Shao",
      "Soung Chang Liew",
      "Deniz Gunduz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.10699"
  },
  {
    "id": "arXiv:2105.14139",
    "title": "On a class of data-driven mixed-integer programming problems under  uncertainty: a distributionally robust approach",
    "abstract": "Comments: The paper has been substantially revised with respect to the definition of weak and strong optimality as well as the related theoretical results (Theorems 1-4). Furthermore, some additional results for the unweighted knapsack problem are provided",
    "descriptor": "\nComments: The paper has been substantially revised with respect to the definition of weak and strong optimality as well as the related theoretical results (Theorems 1-4). Furthermore, some additional results for the unweighted knapsack problem are provided\n",
    "authors": [
      "Sergey S. Ketkov",
      "Andrei S. Shilov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2105.14139"
  },
  {
    "id": "arXiv:2105.15183",
    "title": "Efficient and Modular Implicit Differentiation",
    "abstract": "Comments: V3: added more related work and Jacobian precision figure",
    "descriptor": "\nComments: V3: added more related work and Jacobian precision figure\n",
    "authors": [
      "Mathieu Blondel",
      "Quentin Berthet",
      "Marco Cuturi",
      "Roy Frostig",
      "Stephan Hoyer",
      "Felipe Llinares-L\u00f3pez",
      "Fabian Pedregosa",
      "Jean-Philippe Vert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.15183"
  },
  {
    "id": "arXiv:2106.02566",
    "title": "BR-NPA: A Non-Parametric High-Resolution Attention Model to improve the  Interpretability of Attention",
    "abstract": "BR-NPA: A Non-Parametric High-Resolution Attention Model to improve the  Interpretability of Attention",
    "descriptor": "",
    "authors": [
      "Tristan Gomez",
      "Suiyi Ling",
      "Thomas Fr\u00e9our",
      "Harold Mouch\u00e8re"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02566"
  },
  {
    "id": "arXiv:2106.09917",
    "title": "Envy-freeness and Relaxed Stability for Lower-Quotas : A Parameterized  Perspective",
    "abstract": "Comments: 15 pages, 2 figures. improved presentation",
    "descriptor": "\nComments: 15 pages, 2 figures. improved presentation\n",
    "authors": [
      "Girija Limaye"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.09917"
  },
  {
    "id": "arXiv:2106.10595",
    "title": "Heterogeneous Multi-task Learning with Expert Diversity",
    "abstract": "Comments: 10 pages, 7 figures, BIOKDD, IEEE/ACM",
    "descriptor": "\nComments: 10 pages, 7 figures, BIOKDD, IEEE/ACM\n",
    "authors": [
      "Raquel Aoki",
      "Frederick Tung",
      "Gabriel L. Oliveira"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10595"
  },
  {
    "id": "arXiv:2107.02567",
    "title": "On a tracial version of Haemers bound",
    "abstract": "Comments: Accepted for publication at IEEE transactions on information theory. Close to the published version",
    "descriptor": "\nComments: Accepted for publication at IEEE transactions on information theory. Close to the published version\n",
    "authors": [
      "Li Gao",
      "Sander Gribling",
      "Yinan Li"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2107.02567"
  },
  {
    "id": "arXiv:2107.02772",
    "title": "A Causal Bandit Approach to Learning Good Atomic Interventions in  Presence of Unobserved Confounders",
    "abstract": "Comments: 36 pages; metadata changed",
    "descriptor": "\nComments: 36 pages; metadata changed\n",
    "authors": [
      "Aurghya Maiti",
      "Vineet Nair",
      "Gaurav Sinha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.02772"
  },
  {
    "id": "arXiv:2107.05924",
    "title": "An Improvement of a Key Exchange Protocol Relying on Polynomial Maps",
    "abstract": "An Improvement of a Key Exchange Protocol Relying on Polynomial Maps",
    "descriptor": "",
    "authors": [
      "Keita Suzuki",
      "Koji Nuida"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.05924"
  },
  {
    "id": "arXiv:2107.06048",
    "title": "A Graph Data Augmentation Strategy with Entropy Preservation",
    "abstract": "A Graph Data Augmentation Strategy with Entropy Preservation",
    "descriptor": "",
    "authors": [
      "Xue Liu",
      "Dan Sun",
      "Wei Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06048"
  },
  {
    "id": "arXiv:2108.03443",
    "title": "NODEO: A Neural Ordinary Differential Equation Based Optimization  Framework for Deformable Image Registration",
    "abstract": "NODEO: A Neural Ordinary Differential Equation Based Optimization  Framework for Deformable Image Registration",
    "descriptor": "",
    "authors": [
      "Yifan Wu",
      "Tom Z. Jiahao",
      "Jiancong Wang",
      "Paul A. Yushkevich",
      "M. Ani Hsieh",
      "James C. Gee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.03443"
  },
  {
    "id": "arXiv:2108.05018",
    "title": "Are Neural Ranking Models Robust?",
    "abstract": "Comments: Accepted by TOIS",
    "descriptor": "\nComments: Accepted by TOIS\n",
    "authors": [
      "Chen Wu",
      "Ruqing Zhang",
      "Jiafeng Guo",
      "Yixing Fan",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2108.05018"
  },
  {
    "id": "arXiv:2108.08735",
    "title": "SiReN: Sign-Aware Recommendation Using Graph Neural Networks",
    "abstract": "Comments: 15 pages, 5 figures, 3 tables; to appear in the IEEE Transactions on Neural Networks and Learning Systems (Special Issue on Deep Neural Networks for Graphs: Theory, Models, Algorithms and Applications) (Please cite our journal version that will appear in an upcoming issue.)",
    "descriptor": "\nComments: 15 pages, 5 figures, 3 tables; to appear in the IEEE Transactions on Neural Networks and Learning Systems (Special Issue on Deep Neural Networks for Graphs: Theory, Models, Algorithms and Applications) (Please cite our journal version that will appear in an upcoming issue.)\n",
    "authors": [
      "Changwon Seo",
      "Kyeong-Joong Jeong",
      "Sungsu Lim",
      "Won-Yong Shin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2108.08735"
  },
  {
    "id": "arXiv:2108.10480",
    "title": "Fast Evaluation of Smooth Distance Constraints on Co-Dimensional  Geometry",
    "abstract": "Comments: 17 pages, 23 figures",
    "descriptor": "\nComments: 17 pages, 23 figures\n",
    "authors": [
      "Abhishek Madan",
      "David I.W. Levin"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2108.10480"
  },
  {
    "id": "arXiv:2109.01040",
    "title": "Inverse linear-quadratic discrete-time finite-horizon optimal control  for indistinguishable systems: a convex optimization approach",
    "abstract": "Comments: 17 pages, 4 figures. Revision; in particular, somewhat larger updates to sections 4 and 6",
    "descriptor": "\nComments: 17 pages, 4 figures. Revision; in particular, somewhat larger updates to sections 4 and 6\n",
    "authors": [
      "Han Zhang",
      "Axel Ringh"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.01040"
  },
  {
    "id": "arXiv:2109.01901",
    "title": "The anatomy of Boris type solvers and the Lie operator formalism for  deriving large time-step magnetic field integrators",
    "abstract": "Comments: Completely revised with 32 pages and 18 figures",
    "descriptor": "\nComments: Completely revised with 32 pages and 18 figures\n",
    "authors": [
      "Siu A. Chin",
      "Durward Cator"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.01901"
  },
  {
    "id": "arXiv:2109.03748",
    "title": "A robust approach for deep neural networks in presence of label noise:  relabelling and filtering instances during training",
    "abstract": "Comments: 24 pages, 5 figures",
    "descriptor": "\nComments: 24 pages, 5 figures\n",
    "authors": [
      "Anabel G\u00f3mez-R\u00edos",
      "Juli\u00e1n Luengo",
      "Francisco Herrera"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2109.03748"
  },
  {
    "id": "arXiv:2109.07060",
    "title": "Analyzing Multiagent Interactions in Traffic Scenes via Topological  Braids",
    "abstract": "Comments: Accepted at ICRA",
    "descriptor": "\nComments: Accepted at ICRA\n",
    "authors": [
      "Christoforos Mavrogiannis",
      "Jonathan DeCastro",
      "Siddhartha S. Srinivasa"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07060"
  },
  {
    "id": "arXiv:2109.07348",
    "title": "Cross-lingual Transfer of Monolingual Models",
    "abstract": "Comments: Accepted to LREC 2022",
    "descriptor": "\nComments: Accepted to LREC 2022\n",
    "authors": [
      "Evangelia Gogoulou",
      "Ariel Ekgren",
      "Tim Isbister",
      "Magnus Sahlgren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07348"
  },
  {
    "id": "arXiv:2109.11094",
    "title": "PredictionNet: Real-Time Joint Probabilistic Traffic Prediction for  Planning, Control, and Simulation",
    "abstract": "Comments: 7 pages, 7 figures, accepted to ICRA 2022 conference, for associated video file, see this https URL",
    "descriptor": "\nComments: 7 pages, 7 figures, accepted to ICRA 2022 conference, for associated video file, see this https URL\n",
    "authors": [
      "Alexey Kamenev",
      "Lirui Wang",
      "Ollin Boer Bohan",
      "Ishwar Kulkarni",
      "Bilal Kartal",
      "Artem Molchanov",
      "Stan Birchfield",
      "David Nist\u00e9r",
      "Nikolai Smolyanskiy"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.11094"
  },
  {
    "id": "arXiv:2109.11726",
    "title": "Morse-STF: Improved Protocols for Privacy-Preserving Machine Learning",
    "abstract": "Morse-STF: Improved Protocols for Privacy-Preserving Machine Learning",
    "descriptor": "",
    "authors": [
      "Qizhi Zhang",
      "Sijun Tan",
      "Lichun Li",
      "Yun Zhao",
      "Dong Yin",
      "Shan Yin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2109.11726"
  },
  {
    "id": "arXiv:2109.11788",
    "title": "Parameter-free Reduction of the Estimation Bias in Deep Reinforcement  Learning for Deterministic Policy Gradients",
    "abstract": "Parameter-free Reduction of the Estimation Bias in Deep Reinforcement  Learning for Deterministic Policy Gradients",
    "descriptor": "",
    "authors": [
      "Baturay Saglam",
      "Furkan Burak Mutlu",
      "Dogan Can Cicek",
      "Suleyman Serdar Kozat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.11788"
  },
  {
    "id": "arXiv:2109.12555",
    "title": "On Stability and Consensus of Signed Networks: A Self-loop Compensation  Perspective",
    "abstract": "On Stability and Consensus of Signed Networks: A Self-loop Compensation  Perspective",
    "descriptor": "",
    "authors": [
      "Haibin Shao",
      "Lulu Pan",
      "Dewei Li",
      "Yugeng Xi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2109.12555"
  },
  {
    "id": "arXiv:2109.13046",
    "title": "The Spread of Propaganda by Coordinated Communities on Social Media",
    "abstract": "Comments: The 14th ACM Web Science Conference 2022 (WebSci '22)",
    "descriptor": "\nComments: The 14th ACM Web Science Conference 2022 (WebSci '22)\n",
    "authors": [
      "Kristina Hristakieva",
      "Stefano Cresci",
      "Giovanni Da San Martino",
      "Mauro Conti",
      "Preslav Nakov"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.13046"
  },
  {
    "id": "arXiv:2110.00265",
    "title": "A New Approach for Verification of Delay Coobservability of  Discrete-Event Systems",
    "abstract": "A New Approach for Verification of Delay Coobservability of  Discrete-Event Systems",
    "descriptor": "",
    "authors": [
      "Yunfeng Hou",
      "Qingdu Li",
      "Yunfeng Ji",
      "Gang Wang",
      "Ching-Yen Weng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.00265"
  },
  {
    "id": "arXiv:2110.01150",
    "title": "Spiked Covariance Estimation from Modulo-Reduced Measurements",
    "abstract": "Comments: AISTATS, 2022",
    "descriptor": "\nComments: AISTATS, 2022\n",
    "authors": [
      "Elad Romanov",
      "Or Ordentlich"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.01150"
  },
  {
    "id": "arXiv:2110.01276",
    "title": "Characterizing Omega-Regularity through Finite-Memory Determinacy of  Games on Infinite Graphs",
    "abstract": "Comments: Full version of STACS 2022 conference paper. 41 pages, 14 figures",
    "descriptor": "\nComments: Full version of STACS 2022 conference paper. 41 pages, 14 figures\n",
    "authors": [
      "Patricia Bouyer",
      "Mickael Randour",
      "Pierre Vandenhove"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.01276"
  },
  {
    "id": "arXiv:2110.03224",
    "title": "Darts: User-Friendly Modern Machine Learning for Time Series",
    "abstract": "Comments: Darts Github repository: this https URL",
    "descriptor": "\nComments: Darts Github repository: this https URL\n",
    "authors": [
      "Julien Herzen",
      "Francesco L\u00e4ssig",
      "Samuele Giuliano Piazzetta",
      "Thomas Neuer",
      "L\u00e9o Tafti",
      "Guillaume Raille",
      "Tomas Van Pottelbergh",
      "Marek Pasieka",
      "Andrzej Skrodzki",
      "Nicolas Huguenin",
      "Maxime Dumonal",
      "Jan Ko\u015bcisz",
      "Dennis Bader",
      "Fr\u00e9d\u00e9rick Gusset",
      "Mounir Benheddi",
      "Camila Williamson",
      "Michal Kosinski",
      "Matej Petrik",
      "Ga\u00ebl Grosch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.03224"
  },
  {
    "id": "arXiv:2110.03905",
    "title": "COVID-19 Monitoring System using Social Distancing and Face Mask  Detection on Surveillance video datasets",
    "abstract": "COVID-19 Monitoring System using Social Distancing and Face Mask  Detection on Surveillance video datasets",
    "descriptor": "",
    "authors": [
      "Sahana Srinivasan",
      "Rujula Singh R",
      "Ruchita Biradar",
      "Nikhil Nayak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03905"
  },
  {
    "id": "arXiv:2110.04482",
    "title": "Towards Lifelong Learning of Multilingual Text-To-Speech Synthesis",
    "abstract": "Comments: Accepted to ICASSP 2022. Camera-ready",
    "descriptor": "\nComments: Accepted to ICASSP 2022. Camera-ready\n",
    "authors": [
      "Mu Yang",
      "Shaojin Ding",
      "Tianlong Chen",
      "Tong Wang",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04482"
  },
  {
    "id": "arXiv:2110.05706",
    "title": "Deep Fusion Prior for Multi-Focus Image Super Resolution Fusion",
    "abstract": "Comments: 21 pages, 9 figures",
    "descriptor": "\nComments: 21 pages, 9 figures\n",
    "authors": [
      "Yuanjie Gu",
      "Zhibo Xiao",
      "Hailun Wang",
      "Cheng Liu",
      "Shouyu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.05706"
  },
  {
    "id": "arXiv:2110.06274",
    "title": "LiST: Lite Prompted Self-training Makes Parameter-Efficient Few-shot  Learners",
    "abstract": "Comments: Accepted by NAACL findings. Code is this https URL",
    "descriptor": "\nComments: Accepted by NAACL findings. Code is this https URL\n",
    "authors": [
      "Yaqing Wang",
      "Subhabrata Mukherjee",
      "Xiaodong Liu",
      "Jing Gao",
      "Ahmed Hassan Awadallah",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06274"
  },
  {
    "id": "arXiv:2110.06304",
    "title": "Generalized Time Domain Velocity Vector",
    "abstract": "Comments: Submitted",
    "descriptor": "\nComments: Submitted\n",
    "authors": [
      "Sr\u0111an Kiti\u0107",
      "J\u00e9r\u00f4me Daniel"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.06304"
  },
  {
    "id": "arXiv:2110.09473",
    "title": "DBSegment: Fast and robust segmentation of deep brain structures --  Evaluation of transportability across acquisition domains",
    "abstract": "Comments: The data used have mistakes. No one has time to correct the data and add a new version, that is why we would like to retract it. Once we have the correct version we will resubmit to arxiv",
    "descriptor": "\nComments: The data used have mistakes. No one has time to correct the data and add a new version, that is why we would like to retract it. Once we have the correct version we will resubmit to arxiv\n",
    "authors": [
      "Mehri Baniasadi",
      "Mikkel V. Petersen",
      "Jorge Goncalves",
      "Andreas Horn",
      "Vanja Vlasov",
      "Frank Hertel",
      "Andreas Husch"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2110.09473"
  },
  {
    "id": "arXiv:2111.04678",
    "title": "Joint Optimization of Uplink Power and Computational Resources in Mobile  Edge Computing-Enabled Cell-Free Massive MIMO",
    "abstract": "Comments: This paper has been submitted for publication in an IEEE journal. {\\copyright} 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses",
    "descriptor": "\nComments: This paper has been submitted for publication in an IEEE journal. {\\copyright} 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses\n",
    "authors": [
      "Giovanni Interdonato",
      "Stefano Buzzi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.04678"
  },
  {
    "id": "arXiv:2111.04878",
    "title": "Automated generation of 0D and 1D reduced-order models of  patient-specific blood flow",
    "abstract": "Automated generation of 0D and 1D reduced-order models of  patient-specific blood flow",
    "descriptor": "",
    "authors": [
      "Martin R. Pfaller",
      "Jonathan Pham",
      "Aekaansh Verma",
      "Luca Pegolotti",
      "Nathan M. Wilson",
      "David W. Parker",
      "Weiguang Yang",
      "Alison L. Marsden"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2111.04878"
  },
  {
    "id": "arXiv:2111.05070",
    "title": "Universal Lower Bound for Learning Causal DAGs with Atomic Interventions",
    "abstract": "Comments: Extended version of AISTATS 2022 paper. Added results for multi-node interventions, and shortened title",
    "descriptor": "\nComments: Extended version of AISTATS 2022 paper. Added results for multi-node interventions, and shortened title\n",
    "authors": [
      "Vibhor Porwal",
      "Piyush Srivastava",
      "Gaurav Sinha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.05070"
  },
  {
    "id": "arXiv:2111.06832",
    "title": "Speeding Up Entmax",
    "abstract": "Comments: Findings of NAACL 2022",
    "descriptor": "\nComments: Findings of NAACL 2022\n",
    "authors": [
      "Maxat Tezekbayev",
      "Vassilina Nikoulina",
      "Matthias Gall\u00e9",
      "Zhenisbek Assylbekov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.06832"
  },
  {
    "id": "arXiv:2111.07398",
    "title": "Single- versus Multi-Carrier Terahertz-Band Communications: A  Comparative Study",
    "abstract": "Comments: 18 pages, 12 figures, journal",
    "descriptor": "\nComments: 18 pages, 12 figures, journal\n",
    "authors": [
      "Simon Tarboush",
      "Hadi Sarieddeen",
      "Mohamed-Slim Alouini",
      "Tareq Y. Al-Naffouri"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2111.07398"
  },
  {
    "id": "arXiv:2111.08940",
    "title": "Transparent Human Evaluation for Image Captioning",
    "abstract": "Comments: Proc. of NAACL 2022",
    "descriptor": "\nComments: Proc. of NAACL 2022\n",
    "authors": [
      "Jungo Kasai",
      "Keisuke Sakaguchi",
      "Lavinia Dunagan",
      "Jacob Morrison",
      "Ronan Le Bras",
      "Yejin Choi",
      "Noah A. Smith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08940"
  },
  {
    "id": "arXiv:2111.09212",
    "title": "Single-pass Object-adaptive Data Undersampling and Reconstruction for  MRI",
    "abstract": "Single-pass Object-adaptive Data Undersampling and Reconstruction for  MRI",
    "descriptor": "",
    "authors": [
      "Zhishen Huang",
      "Saiprasad Ravishankar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.09212"
  },
  {
    "id": "arXiv:2111.13415",
    "title": "ESCADA: Efficient Safety and Context Aware Dose Allocation for Precision  Medicine",
    "abstract": "Comments: 18 pages, 10 figures",
    "descriptor": "\nComments: 18 pages, 10 figures\n",
    "authors": [
      "Ilker Demirel",
      "Ahmet Alparslan Celik",
      "Cem Tekin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.13415"
  },
  {
    "id": "arXiv:2112.01298",
    "title": "Meaningful human control: actionable properties for AI system  development",
    "abstract": "Comments: Preprint. Published AI and Ethics (2022): this https URL",
    "descriptor": "\nComments: Preprint. Published AI and Ethics (2022): this https URL\n",
    "authors": [
      "Luciano Cavalcante Siebert",
      "Maria Luce Lupetti",
      "Evgeni Aizenberg",
      "Niek Beckers",
      "Arkady Zgonnikov",
      "Herman Veluwenkamp",
      "David Abbink",
      "Elisa Giaccardi",
      "Geert-Jan Houben",
      "Catholijn M. Jonker",
      "Jeroen van den Hoven",
      "Deborah Forster",
      "Reginald L. Lagendijk"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.01298"
  },
  {
    "id": "arXiv:2112.04139",
    "title": "Bidimensional Leaderboards: Generate and Evaluate Language Hand in Hand",
    "abstract": "Comments: Proc. of NAACL 2022",
    "descriptor": "\nComments: Proc. of NAACL 2022\n",
    "authors": [
      "Jungo Kasai",
      "Keisuke Sakaguchi",
      "Ronan Le Bras",
      "Lavinia Dunagan",
      "Jacob Morrison",
      "Alexander R. Fabbri",
      "Yejin Choi",
      "Noah A. Smith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.04139"
  },
  {
    "id": "arXiv:2112.04564",
    "title": "CoSSL: Co-Learning of Representation and Classifier for Imbalanced  Semi-Supervised Learning",
    "abstract": "Comments: Published at CVPR 2022 as a conference paper. Code at this https URL",
    "descriptor": "\nComments: Published at CVPR 2022 as a conference paper. Code at this https URL\n",
    "authors": [
      "Yue Fan",
      "Dengxin Dai",
      "Anna Kukleva",
      "Bernt Schiele"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04564"
  },
  {
    "id": "arXiv:2112.07574",
    "title": "M3E2: Multi-gate Mixture-of-experts for Multi-treatment Effect  Estimation",
    "abstract": "Comments: 4 figures, 10 pages",
    "descriptor": "\nComments: 4 figures, 10 pages\n",
    "authors": [
      "Raquel Aoki",
      "Yizhou Chen",
      "Martin Ester"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.07574"
  },
  {
    "id": "arXiv:2112.09436",
    "title": "Privacy preserving n-party scalar product protocol",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Florian van Daalen",
      "Inigo Bermejo",
      "Lianne Ippel",
      "Andre Dekkers"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.09436"
  },
  {
    "id": "arXiv:2112.09811",
    "title": "Playing Against Fair Adversaries in Stochastic Games with Total Rewards",
    "abstract": "Playing Against Fair Adversaries in Stochastic Games with Total Rewards",
    "descriptor": "",
    "authors": [
      "Pablo F. Castro",
      "Pedro R. D'Argenio",
      "Luciano Putruele",
      "Ramiro Demasi"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.09811"
  },
  {
    "id": "arXiv:2112.09990",
    "title": "FlowPool: Pooling Graph Representations with Wasserstein Gradient Flows",
    "abstract": "FlowPool: Pooling Graph Representations with Wasserstein Gradient Flows",
    "descriptor": "",
    "authors": [
      "Effrosyni Simou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.09990"
  },
  {
    "id": "arXiv:2112.10692",
    "title": "Space-time upscaling of reactive transport in porous media",
    "abstract": "Space-time upscaling of reactive transport in porous media",
    "descriptor": "",
    "authors": [
      "Nicolae Suciu",
      "Florin A. Radu",
      "Iuliu S. Pop"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.10692"
  },
  {
    "id": "arXiv:2201.04196",
    "title": "A polynomial-time approximation scheme for parallel two-stage flowshops  under makespan constraint",
    "abstract": "Comments: Theoretical Computer Science (2022)",
    "descriptor": "\nComments: Theoretical Computer Science (2022)\n",
    "authors": [
      "Weitian Tong",
      "Yao Xu",
      "Huili Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2201.04196"
  },
  {
    "id": "arXiv:2201.04929",
    "title": "Improving VAE based molecular representations for compound property  prediction",
    "abstract": "Improving VAE based molecular representations for compound property  prediction",
    "descriptor": "",
    "authors": [
      "A. Tevosyan",
      "L. Khondkaryan",
      "H. Khachatrian",
      "G. Tadevosyan",
      "L. Apresyan",
      "N. Babayan",
      "H. Stopper",
      "Z. Navoyan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.04929"
  },
  {
    "id": "arXiv:2201.05314",
    "title": "A Novel Skeleton-Based Human Activity Discovery Using Particle Swarm  Optimization with Gaussian Mutation",
    "abstract": "A Novel Skeleton-Based Human Activity Discovery Using Particle Swarm  Optimization with Gaussian Mutation",
    "descriptor": "",
    "authors": [
      "Parham Hadikhani",
      "Daphne Teck Ching Lai",
      "Wee-Hong Ong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.05314"
  },
  {
    "id": "arXiv:2201.05534",
    "title": "Uniform continuity bound for sandwiched R\u00e9nyi conditional entropy",
    "abstract": "Comments: v2 is the published version. We have added some citations and corrected some typos",
    "descriptor": "\nComments: v2 is the published version. We have added some citations and corrected some typos\n",
    "authors": [
      "Ashutosh Marwah",
      "Fr\u00e9d\u00e9ric Dupuis"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2201.05534"
  },
  {
    "id": "arXiv:2201.06651",
    "title": "Limited Information Shared Control: A Potential Game Approach",
    "abstract": "Limited Information Shared Control: A Potential Game Approach",
    "descriptor": "",
    "authors": [
      "Balint Varga",
      "Jairo Inga",
      "Soeren Hohmann"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2201.06651"
  },
  {
    "id": "arXiv:2201.06723",
    "title": "Emojis as Anchors to Detect Arabic Offensive Language and Hate Speech",
    "abstract": "Emojis as Anchors to Detect Arabic Offensive Language and Hate Speech",
    "descriptor": "",
    "authors": [
      "Hamdy Mubarak",
      "Sabit Hassan",
      "Shammur Absar Chowdhury"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.06723"
  },
  {
    "id": "arXiv:2201.07006",
    "title": "Time Series Generation with Masked Autoencoder",
    "abstract": "Time Series Generation with Masked Autoencoder",
    "descriptor": "",
    "authors": [
      "Mengyue Zha",
      "SiuTim Wong",
      "Mengqi Liu",
      "Tong Zhang",
      "Kani Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.07006"
  },
  {
    "id": "arXiv:2201.07391",
    "title": "MetaV: A Meta-Verifier Approach to Task-Agnostic Model Fingerprinting",
    "abstract": "Comments: To Appear in KDD'2022",
    "descriptor": "\nComments: To Appear in KDD'2022\n",
    "authors": [
      "Xudong Pan",
      "Yifan Yan",
      "Mi Zhang",
      "Min Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.07391"
  },
  {
    "id": "arXiv:2201.07449",
    "title": "TourBERT: A pretrained language model for the tourism industry",
    "abstract": "Comments: Identified a mistake in our calculations. Will fix the problem within the next weeks and resubmit",
    "descriptor": "\nComments: Identified a mistake in our calculations. Will fix the problem within the next weeks and resubmit\n",
    "authors": [
      "Veronika Arefieva",
      "Roman Egger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.07449"
  },
  {
    "id": "arXiv:2201.08433",
    "title": "Finite difference and finite element methods for partial differential  equations on fractals",
    "abstract": "Finite difference and finite element methods for partial differential  equations on fractals",
    "descriptor": "",
    "authors": [
      "Fernando Contreras",
      "Juan Galvis"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.08433"
  },
  {
    "id": "arXiv:2201.09857",
    "title": "STOPS: Short-Term-based Volatility-controlled Policy Search and its  Global Convergence",
    "abstract": "STOPS: Short-Term-based Volatility-controlled Policy Search and its  Global Convergence",
    "descriptor": "",
    "authors": [
      "Liangliang Xu",
      "Daoming Lyu",
      "Yangchen Pan",
      "Aiwen Jiang",
      "Bo Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.09857"
  },
  {
    "id": "arXiv:2201.10239",
    "title": "Design choice and machine learning model performances",
    "abstract": "Comments: Supplemental material at the end of the manuscript. 7 tables, 8 figures. Quality and Reliability Engineering International (2022)",
    "descriptor": "\nComments: Supplemental material at the end of the manuscript. 7 tables, 8 figures. Quality and Reliability Engineering International (2022)\n",
    "authors": [
      "Rosa Arboretti",
      "Riccardo Ceccato",
      "Luca Pegoraro",
      "Luigi Salmaso"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.10239"
  },
  {
    "id": "arXiv:2201.10737",
    "title": "Class-Aware Generative Adversarial Transformers for Medical Image  Segmentation",
    "abstract": "Class-Aware Generative Adversarial Transformers for Medical Image  Segmentation",
    "descriptor": "",
    "authors": [
      "Chenyu You",
      "Ruihan Zhao",
      "Fenglin Liu",
      "Siyuan Dong",
      "Sandeep Chinchali",
      "Ufuk Topcu",
      "Lawrence Staib",
      "James S. Duncan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2201.10737"
  },
  {
    "id": "arXiv:2201.12414",
    "title": "Posterior Matching for Arbitrary Conditioning",
    "abstract": "Posterior Matching for Arbitrary Conditioning",
    "descriptor": "",
    "authors": [
      "Ryan R. Strauss",
      "Junier B. Oliva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.12414"
  },
  {
    "id": "arXiv:2202.00645",
    "title": "Generalization Analysis of Message Passing Neural Networks on Large  Random Graphs",
    "abstract": "Comments: Preprint in Review",
    "descriptor": "\nComments: Preprint in Review\n",
    "authors": [
      "Sohir Maskey",
      "Ron Levie",
      "Yunseok Lee",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2202.00645"
  },
  {
    "id": "arXiv:2202.01477",
    "title": "Unsourced Random Access with a Massive MIMO Receiver Using Multiple  Stages of Orthogonal Pilots",
    "abstract": "Unsourced Random Access with a Massive MIMO Receiver Using Multiple  Stages of Orthogonal Pilots",
    "descriptor": "",
    "authors": [
      "Mohammad Javad Ahmadi",
      "Tolga M. Duman"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.01477"
  },
  {
    "id": "arXiv:2202.02393",
    "title": "Deep Dynamic Effective Connectivity Estimation from Multivariate Time  Series",
    "abstract": "Comments: Accepted at IJCNN 2022",
    "descriptor": "\nComments: Accepted at IJCNN 2022\n",
    "authors": [
      "Usman Mahmood",
      "Zening Fu",
      "Vince Calhoun",
      "Sergey Plis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02393"
  },
  {
    "id": "arXiv:2202.03609",
    "title": "Backdoor Detection in Reinforcement Learning",
    "abstract": "Backdoor Detection in Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Junfeng Guo",
      "Ang Li",
      "Cong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03609"
  },
  {
    "id": "arXiv:2202.03918",
    "title": "Network Coding Multicast Key-Capacity",
    "abstract": "Network Coding Multicast Key-Capacity",
    "descriptor": "",
    "authors": [
      "Michael Langberg",
      "Michelle Effros"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.03918"
  },
  {
    "id": "arXiv:2202.04533",
    "title": "NIMBLE: A Non-rigid Hand Model with Bones and Muscles",
    "abstract": "Comments: 16 pages, 18 figures",
    "descriptor": "\nComments: 16 pages, 18 figures\n",
    "authors": [
      "Yuwei Li",
      "Longwen Zhang",
      "Zesong Qiu",
      "Yingwenqi Jiang",
      "Nianyi Li",
      "Yuexin Ma",
      "Yuyao Zhang",
      "Lan Xu",
      "Jingyi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2202.04533"
  },
  {
    "id": "arXiv:2202.05267",
    "title": "On Real-time Image Reconstruction with Neural Networks for MRI-guided  Radiotherapy",
    "abstract": "Comments: 12 pages, 6 figures, 1 table. v2 has a typo in eqn 1 corrected and references added to the discussion",
    "descriptor": "\nComments: 12 pages, 6 figures, 1 table. v2 has a typo in eqn 1 corrected and references added to the discussion\n",
    "authors": [
      "David E. J. Waddington",
      "Nicholas Hindley",
      "Neha Koonjoo",
      "Christopher Chiu",
      "Tess Reynolds",
      "Paul Z. Y. Liu",
      "Bo Zhu",
      "Danyal Bhutto",
      "Chiara Paganelli",
      "Paul J. Keall",
      "Matthew S. Rosen"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.05267"
  },
  {
    "id": "arXiv:2202.10842",
    "title": "KuaiRec: A Fully-observed Dataset for Recommender Systems",
    "abstract": "Comments: 11 pages, 7 figures",
    "descriptor": "\nComments: 11 pages, 7 figures\n",
    "authors": [
      "Chongming Gao",
      "Shijun Li",
      "Wenqiang Lei",
      "Biao Li",
      "Peng Jiang",
      "Jiawei Chen",
      "Xiangnan He",
      "Jiaxin Mao",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.10842"
  },
  {
    "id": "arXiv:2202.11094",
    "title": "GroupViT: Semantic Segmentation Emerges from Text Supervision",
    "abstract": "Comments: CVPR 2022. Project page and code: this https URL",
    "descriptor": "\nComments: CVPR 2022. Project page and code: this https URL\n",
    "authors": [
      "Jiarui Xu",
      "Shalini De Mello",
      "Sifei Liu",
      "Wonmin Byeon",
      "Thomas Breuel",
      "Jan Kautz",
      "Xiaolong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.11094"
  },
  {
    "id": "arXiv:2203.00213",
    "title": "Optimal Routing for Multi-user Multi-hop Relay Networks via Dynamic  Programming",
    "abstract": "Comments: Extended Version, Accepted to IEEE Wireless Communications Letters",
    "descriptor": "\nComments: Extended Version, Accepted to IEEE Wireless Communications Letters\n",
    "authors": [
      "Shalanika Dayarathna",
      "Rajitha Senanayake",
      "Jamie Evans"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.00213"
  },
  {
    "id": "arXiv:2203.02057",
    "title": "Interpretable Latent Variables in Deep State Space Models",
    "abstract": "Interpretable Latent Variables in Deep State Space Models",
    "descriptor": "",
    "authors": [
      "Haoxuan Wu",
      "David S. Matteson",
      "Martin T. Wells"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.02057"
  },
  {
    "id": "arXiv:2203.05241",
    "title": "Theory of Network Wave",
    "abstract": "Theory of Network Wave",
    "descriptor": "",
    "authors": [
      "Bo Li",
      "Mao Yang",
      "Zhongjiang Yan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.05241"
  },
  {
    "id": "arXiv:2203.07921",
    "title": "Unsupervised Extractive Opinion Summarization Using Sparse Coding",
    "abstract": "Comments: Accepted at ACL 2022",
    "descriptor": "\nComments: Accepted at ACL 2022\n",
    "authors": [
      "Somnath Basu Roy Chowdhury",
      "Chao Zhao",
      "Snigdha Chaturvedi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.07921"
  },
  {
    "id": "arXiv:2203.08410",
    "title": "Thinking about GPT-3 In-Context Learning for Biomedical IE? Think Again",
    "abstract": "Comments: 16 pages, 4 figures",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Bernal Jim\u00e9nez Guti\u00e9rrez",
      "Nikolas McNeal",
      "Clay Washington",
      "You Chen",
      "Lang Li",
      "Huan Sun",
      "Yu Su"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.08410"
  },
  {
    "id": "arXiv:2203.09185",
    "title": "Phase Optimization for Massive IRS-aided Two-way Relay Network",
    "abstract": "Comments: 9 pages,10 figures",
    "descriptor": "\nComments: 9 pages,10 figures\n",
    "authors": [
      "Peng Zhang",
      "Xuehui Wang",
      "Siling Feng",
      "Zhongwen Sun",
      "Feng Shu",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.09185"
  },
  {
    "id": "arXiv:2203.09581",
    "title": "SepTr: Separable Transformer for Audio Spectrogram Processing",
    "abstract": "Comments: Submitted to INTERSPEECH 2022",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Nicolae-Catalin Ristea",
      "Radu Tudor Ionescu",
      "Fahad Shahbaz Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09581"
  },
  {
    "id": "arXiv:2203.09872",
    "title": "Effect of Active and Passive Protective Soft Skins on Collision Forces  in Human-robot Collaboration",
    "abstract": "Comments: 18 pages, 15 figures",
    "descriptor": "\nComments: 18 pages, 15 figures\n",
    "authors": [
      "Petr Svarny",
      "Jakub Rozlivek",
      "Lukas Rustler",
      "Martin Sramek",
      "Ozgur Deli",
      "Michael Zillich",
      "Matej Hoffmann"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.09872"
  },
  {
    "id": "arXiv:2203.12481",
    "title": "Prompt-based System for Personality and Interpersonal Reactivity  Prediction",
    "abstract": "Comments: Published in Software Impacts",
    "descriptor": "\nComments: Published in Software Impacts\n",
    "authors": [
      "Bin Li",
      "Yixuan Weng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.12481"
  },
  {
    "id": "arXiv:2203.13236",
    "title": "Differential Assessment of Black-Box AI Agents",
    "abstract": "Comments: AAAI 2022",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Rashmeet Kaur Nayyar",
      "Pulkit Verma",
      "Siddharth Srivastava"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.13236"
  },
  {
    "id": "arXiv:2203.13544",
    "title": "Performance evaluation of switching between WiFi and LiFi under a common  virtual network interface",
    "abstract": "Comments: 6 pages, 12 figures (including subfigures), 2 tables, conference paper",
    "descriptor": "\nComments: 6 pages, 12 figures (including subfigures), 2 tables, conference paper\n",
    "authors": [
      "Loreto Pescosolido",
      "Emilio Ancillotti",
      "Andrea Passarella"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.13544"
  },
  {
    "id": "arXiv:2203.14343",
    "title": "Diagonal State Spaces are as Effective as Structured State Spaces",
    "abstract": "Comments: updated version with simpler DSS variants, RNN view for autoregressive decoding, ablation analysis, analysis of trained model parameters and kernels",
    "descriptor": "\nComments: updated version with simpler DSS variants, RNN view for autoregressive decoding, ablation analysis, analysis of trained model parameters and kernels\n",
    "authors": [
      "Ankit Gupta",
      "Albert Gu",
      "Jonathan Berant"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.14343"
  },
  {
    "id": "arXiv:2203.16004",
    "title": "Theory of Acceleration of Decision Making by Correlated Time Sequences",
    "abstract": "Theory of Acceleration of Decision Making by Correlated Time Sequences",
    "descriptor": "",
    "authors": [
      "Norihiro Okada",
      "Tomoki Yamagami",
      "Nicolas Chauvet",
      "Yusuke Ito",
      "Mikio Hasegawa",
      "Makoto Naruse"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2203.16004"
  },
  {
    "id": "arXiv:2203.16662",
    "title": "Overcoming challenges in leveraging GANs for few-shot data augmentation",
    "abstract": "Comments: v2 of the paper, updated with better figures and with semi-supervised results",
    "descriptor": "\nComments: v2 of the paper, updated with better figures and with semi-supervised results\n",
    "authors": [
      "Christopher Beckham",
      "Issam Laradji",
      "Pau Rodriguez",
      "David Vazquez",
      "Derek Nowrouzezahrai",
      "Christopher Pal"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16662"
  },
  {
    "id": "arXiv:2203.17066",
    "title": "Cross-modal Learning of Graph Representations using Radar Point Cloud  for Long-Range Gesture Recognition",
    "abstract": "Comments: Accepted by IEEE Sensor Array and Multichannel Signal Processing Workshop (SAM 2022)",
    "descriptor": "\nComments: Accepted by IEEE Sensor Array and Multichannel Signal Processing Workshop (SAM 2022)\n",
    "authors": [
      "Souvik Hazra",
      "Hao Feng",
      "Gamze Naz Kiprit",
      "Michael Stephan",
      "Lorenzo Servadei",
      "Robert Wille",
      "Robert Weigel",
      "Avik Santra"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.17066"
  },
  {
    "id": "arXiv:2204.02329",
    "title": "Can language models learn from explanations in context?",
    "abstract": "Can language models learn from explanations in context?",
    "descriptor": "",
    "authors": [
      "Andrew K. Lampinen",
      "Ishita Dasgupta",
      "Stephanie C. Y. Chan",
      "Kory Matthewson",
      "Michael Henry Tessler",
      "Antonia Creswell",
      "James L. McClelland",
      "Jane X. Wang",
      "Felix Hill"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02329"
  },
  {
    "id": "arXiv:2204.02964",
    "title": "Unleashing Vanilla Vision Transformer with Masked Image Modeling for  Object Detection",
    "abstract": "Comments: v2: more analysis & stronger results. Preprint. Work in progress. Code and pre-trained models are available at this https URL",
    "descriptor": "\nComments: v2: more analysis & stronger results. Preprint. Work in progress. Code and pre-trained models are available at this https URL\n",
    "authors": [
      "Yuxin Fang",
      "Shusheng Yang",
      "Shijie Wang",
      "Yixiao Ge",
      "Ying Shan",
      "Xinggang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02964"
  },
  {
    "id": "arXiv:2204.04540",
    "title": "Peekaboo: A Hub-Based Approach to Enable Transparency in Data Processing  within Smart Homes (Extended Technical Report)",
    "abstract": "Comments: 19 pages",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Haojian Jin",
      "Gram Liu",
      "David Hwang",
      "Swarun Kumar",
      "Yuvraj Agarwal",
      "Jason I. Hong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.04540"
  },
  {
    "id": "arXiv:2204.06520",
    "title": "Bayesian Negative Sampling for Recommendation",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Bin Liu",
      "Bang Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.06520"
  },
  {
    "id": "arXiv:2204.07539",
    "title": "Stability and Robustness of a Hybrid Control Law for the Half-bridge  Inverter",
    "abstract": "Stability and Robustness of a Hybrid Control Law for the Half-bridge  Inverter",
    "descriptor": "",
    "authors": [
      "Gabriel E. Col\u00f3n-Reyes",
      "Kaylene C. Stocking",
      "Duncan S. Callaway",
      "Claire J. Tomlin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.07539"
  },
  {
    "id": "arXiv:2204.07953",
    "title": "Learning with Signatures",
    "abstract": "Learning with Signatures",
    "descriptor": "",
    "authors": [
      "J. de Curt\u00f2",
      "I. de Zarz\u00e0",
      "Hong Yan",
      "Carlos T. Calafate"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07953"
  },
  {
    "id": "arXiv:2204.08083",
    "title": "AfriWOZ: Corpus for Exploiting Cross-Lingual Transferability for  Generation of Dialogues in Low-Resource, African Languages",
    "abstract": "Comments: 14 pages, 1 figure, 8 tables",
    "descriptor": "\nComments: 14 pages, 1 figure, 8 tables\n",
    "authors": [
      "Tosin Adewumi",
      "Mofetoluwa Adeyemi",
      "Aremu Anuoluwapo",
      "Bukola Peters",
      "Happy Buzaaba",
      "Oyerinde Samuel",
      "Amina Mardiyyah Rufai",
      "Benjamin Ajibade",
      "Tajudeen Gwadabe",
      "Mory Moussou Koulibaly Traore",
      "Tunde Ajayi",
      "Shamsuddeen Muhammad",
      "Ahmed Baruwa",
      "Paul Owoicho",
      "Tolulope Ogunremi",
      "Phylis Ngigi",
      "Orevaoghene Ahia",
      "Ruqayya Nasir",
      "Foteini Liwicki",
      "Marcus Liwicki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.08083"
  },
  {
    "id": "arXiv:2204.08383",
    "title": "'I think I discovered a military base in the middle of the ocean' --  Null Island, the most real of fictional places",
    "abstract": "Comments: IEEE Access. \\c{opyright}2022 IEEE. Personal use of this material is permitted. Permission from must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
    "descriptor": "\nComments: IEEE Access. \\c{opyright}2022 IEEE. Personal use of this material is permitted. Permission from must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Levente Juhasz",
      "Peter Mooney"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2204.08383"
  },
  {
    "id": "arXiv:2204.09155",
    "title": "Approximating Persistent Homology for Large Datasets",
    "abstract": "Comments: 24 pages, 9 figures",
    "descriptor": "\nComments: 24 pages, 9 figures\n",
    "authors": [
      "Yueqi Cao",
      "Anthea Monod"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2204.09155"
  },
  {
    "id": "arXiv:2204.09803",
    "title": "GUARD: Graph Universal Adversarial Defense",
    "abstract": "Comments: Preprint. Code is publicly available at this https URL",
    "descriptor": "\nComments: Preprint. Code is publicly available at this https URL\n",
    "authors": [
      "Jintang Li",
      "Jie Liao",
      "Ruofan Wu",
      "Liang Chen",
      "Jiawang Dan",
      "Changhua Meng",
      "Zibin Zheng",
      "Weiqiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.09803"
  },
  {
    "id": "arXiv:2204.10305",
    "title": "People are not coins. Morally distinct types of predictions necessitate  different fairness constraints",
    "abstract": "People are not coins. Morally distinct types of predictions necessitate  different fairness constraints",
    "descriptor": "",
    "authors": [
      "Eleonora Vigano'",
      "Corinna Hertweck",
      "Christoph Heitz",
      "Michele Loi"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2204.10305"
  },
  {
    "id": "arXiv:2204.11525",
    "title": "A Polynomial-Time Algorithm for 1/3-Approximate Nash Equilibria in  Bimatrix Games",
    "abstract": "A Polynomial-Time Algorithm for 1/3-Approximate Nash Equilibria in  Bimatrix Games",
    "descriptor": "",
    "authors": [
      "Argyrios Deligkas",
      "Michail Fasoulakis",
      "Evangelos Markakis"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2204.11525"
  },
  {
    "id": "arXiv:2204.11887",
    "title": "Evolutionary latent space search for driving human portrait generation",
    "abstract": "Comments: This paper was accepted and presented during the 2021 IEEE Latin American Conference on Computational Intelligence (LA-CCI)",
    "descriptor": "\nComments: This paper was accepted and presented during the 2021 IEEE Latin American Conference on Computational Intelligence (LA-CCI)\n",
    "authors": [
      "Benjam\u00edn Mach\u00edn",
      "Sergio Nesmachnow",
      "Jamal Toutouh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.11887"
  },
  {
    "id": "arXiv:2205.00199",
    "title": "Cracking White-box DNN Watermarks via Invariant Neuron Transforms",
    "abstract": "Comments: in submission; a preprint version",
    "descriptor": "\nComments: in submission; a preprint version\n",
    "authors": [
      "Yifan Yan",
      "Xudong Pan",
      "Yining Wang",
      "Mi Zhang",
      "Min Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.00199"
  },
  {
    "id": "arXiv:2205.01920",
    "title": "Scene Clustering Based Pseudo-labeling Strategy for Multi-modal Aerial  View Object Classification",
    "abstract": "Scene Clustering Based Pseudo-labeling Strategy for Multi-modal Aerial  View Object Classification",
    "descriptor": "",
    "authors": [
      "Jun Yu",
      "Hao Chang",
      "Keda Lu",
      "Liwen Zhang",
      "Shenshen Du",
      "Zhong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01920"
  },
  {
    "id": "arXiv:2205.02152",
    "title": "Evaluating Transferability for Covid 3D Localization Using CT SARS-CoV-2  segmentation models",
    "abstract": "Evaluating Transferability for Covid 3D Localization Using CT SARS-CoV-2  segmentation models",
    "descriptor": "",
    "authors": [
      "Constantine Maganaris",
      "Eftychios Protopapadakis",
      "Nikolaos Bakalos",
      "Nikolaos Doulamis",
      "Dimitris Kalogeras",
      "Aikaterini Angeli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02152"
  },
  {
    "id": "arXiv:2205.02162",
    "title": "UnrealNAS: Can We Search Neural Architectures with Unreal Data?",
    "abstract": "UnrealNAS: Can We Search Neural Architectures with Unreal Data?",
    "descriptor": "",
    "authors": [
      "Zhen Dong",
      "Kaicheng Zhou",
      "Guohao Li",
      "Qiang Zhou",
      "Mingfei Guo",
      "Bernard Ghanem",
      "Kurt Keutzer",
      "Shanghang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.02162"
  },
  {
    "id": "arXiv:2205.02260",
    "title": "Multivariate Prediction Intervals for Random Forests",
    "abstract": "Comments: 9 pages, 4 figures. Submitted to NeurIPS 2022",
    "descriptor": "\nComments: 9 pages, 4 figures. Submitted to NeurIPS 2022\n",
    "authors": [
      "Brendan Folie",
      "Maxwell Hutchinson"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02260"
  },
  {
    "id": "arXiv:2205.02517",
    "title": "A Simple Contrastive Learning Objective for Alleviating Neural Text  Degeneration",
    "abstract": "Comments: 22 pages, 11 figures, 8 tables",
    "descriptor": "\nComments: 22 pages, 11 figures, 8 tables\n",
    "authors": [
      "Shaojie Jiang",
      "Ruqing Zhang",
      "Svitlana Vakulenko",
      "Maarten de Rijke"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.02517"
  },
  {
    "id": "arXiv:2205.03026",
    "title": "Hearing voices at the National Library -- a speech corpus and acoustic  model for the Swedish language",
    "abstract": "Hearing voices at the National Library -- a speech corpus and acoustic  model for the Swedish language",
    "descriptor": "",
    "authors": [
      "Martin Malmsten",
      "Chris Haffenden",
      "Love B\u00f6rjeson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.03026"
  },
  {
    "id": "arXiv:2205.03090",
    "title": "PTFlash : A deep learning framework for isothermal two-phase equilibrium  calculations",
    "abstract": "PTFlash : A deep learning framework for isothermal two-phase equilibrium  calculations",
    "descriptor": "",
    "authors": [
      "Jingang Qu",
      "Thibault Faney",
      "Jean-Charles de Hemptinne",
      "Soleiman Yousef",
      "Patrick Gallinari"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.03090"
  },
  {
    "id": "arXiv:2205.03146",
    "title": "CLIP-CLOP: CLIP-Guided Collage and Photomontage",
    "abstract": "Comments: 5 pages, 7 figures, accepted at the International Conference on Computational Creativity (ICCC) 2022 as Short Paper: Demo",
    "descriptor": "\nComments: 5 pages, 7 figures, accepted at the International Conference on Computational Creativity (ICCC) 2022 as Short Paper: Demo\n",
    "authors": [
      "Piotr Mirowski",
      "Dylan Banarse",
      "Mateusz Malinowski",
      "Simon Osindero",
      "Chrisantha Fernando"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.03146"
  },
  {
    "id": "arXiv:2205.03892",
    "title": "ConvMAE: Masked Convolution Meets Masked Autoencoders",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Peng Gao",
      "Teli Ma",
      "Hongsheng Li",
      "Ziyi Lin",
      "Jifeng Dai",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.03892"
  },
  {
    "id": "arXiv:2205.04042",
    "title": "Incremental-DETR: Incremental Few-Shot Object Detection via  Self-Supervised Learning",
    "abstract": "Comments: 11 pages, 2 figures",
    "descriptor": "\nComments: 11 pages, 2 figures\n",
    "authors": [
      "Na Dong",
      "Yongqiang Zhang",
      "Mingli Ding",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.04042"
  },
  {
    "id": "arXiv:2205.04051",
    "title": "Unsupervised Learning of Rydberg Atom Array Phase Diagram with Siamese  Neural Networks",
    "abstract": "Unsupervised Learning of Rydberg Atom Array Phase Diagram with Siamese  Neural Networks",
    "descriptor": "",
    "authors": [
      "Zakaria Patel",
      "Ejaaz Merali",
      "Sebastian J. Wetzel"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Quantum Gases (cond-mat.quant-gas)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.04051"
  },
  {
    "id": "arXiv:2205.04183",
    "title": "Attracting and Dispersing: A Simple Approach for Source-free Domain  Adaptation",
    "abstract": "Comments: Update the hyperparameter section",
    "descriptor": "\nComments: Update the hyperparameter section\n",
    "authors": [
      "Shiqi Yang",
      "Yaxing Wang",
      "Kai Wang",
      "Shangling Jui",
      "Joost van de Weijer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.04183"
  },
  {
    "id": "arXiv:2205.04687",
    "title": "Optimal Price Discrimination for Randomized Mechanisms",
    "abstract": "Comments: Appears in ACM EC 2022",
    "descriptor": "\nComments: Appears in ACM EC 2022\n",
    "authors": [
      "Shao-Heng Ko",
      "Kamesh Munagala"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2205.04687"
  },
  {
    "id": "arXiv:2205.05435",
    "title": "Building for Tomorrow: Assessing the Temporal Persistence of Text  Classifiers",
    "abstract": "Building for Tomorrow: Assessing the Temporal Persistence of Text  Classifiers",
    "descriptor": "",
    "authors": [
      "Rabab Alkhalifa",
      "Elena Kochkina",
      "Arkaitz Zubiaga"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.05435"
  },
  {
    "id": "arXiv:2205.05781",
    "title": "VyZX : A Vision for Verifying the ZX Calculus",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Adrian Lehmann",
      "Ben Caldwell",
      "Robert Rand"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2205.05781"
  },
  {
    "id": "arXiv:2205.05800",
    "title": "Stochastic first-order methods for average-reward Markov decision  processes",
    "abstract": "Stochastic first-order methods for average-reward Markov decision  processes",
    "descriptor": "",
    "authors": [
      "Tianjiao Li",
      "Feiyang Wu",
      "Guanghui Lan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.05800"
  },
  {
    "id": "arXiv:2205.05832",
    "title": "NFLAT: Non-Flat-Lattice Transformer for Chinese Named Entity Recognition",
    "abstract": "Comments: 18 pages, 6 figures, 8 tables, Under Review for NeurIPS 2022",
    "descriptor": "\nComments: 18 pages, 6 figures, 8 tables, Under Review for NeurIPS 2022\n",
    "authors": [
      "Shuang Wu",
      "Xiaoning Song",
      "Zhenhua Feng",
      "Xiao-Jun Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.05832"
  },
  {
    "id": "arXiv:2205.05874",
    "title": "Distinction Maximization Loss: Efficiently Improving Classification  Accuracy, Uncertainty Estimation, and Out-of-Distribution Detection Simply  Replacing the Loss and Calibrating",
    "abstract": "Distinction Maximization Loss: Efficiently Improving Classification  Accuracy, Uncertainty Estimation, and Out-of-Distribution Detection Simply  Replacing the Loss and Calibrating",
    "descriptor": "",
    "authors": [
      "David Mac\u00eado",
      "Cleber Zanchettin",
      "Teresa Ludermir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.05874"
  },
  {
    "id": "arXiv:2205.05943",
    "title": "Exploiting Inductive Bias in Transformers for Unsupervised  Disentanglement of Syntax and Semantics with VAEs",
    "abstract": "Comments: Accepted @ NAACL 2022",
    "descriptor": "\nComments: Accepted @ NAACL 2022\n",
    "authors": [
      "Ghazi Felhi",
      "Joseph Le Roux",
      "Djam\u00e9 Seddah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05943"
  },
  {
    "id": "arXiv:2205.06175",
    "title": "A Generalist Agent",
    "abstract": "A Generalist Agent",
    "descriptor": "",
    "authors": [
      "Scott Reed",
      "Konrad Zolna",
      "Emilio Parisotto",
      "Sergio Gomez Colmenarejo",
      "Alexander Novikov",
      "Gabriel Barth-Maron",
      "Mai Gimenez",
      "Yury Sulsky",
      "Jackie Kay",
      "Jost Tobias Springenberg",
      "Tom Eccles",
      "Jake Bruce",
      "Ali Razavi",
      "Ashley Edwards",
      "Nicolas Heess",
      "Yutian Chen",
      "Raia Hadsell",
      "Oriol Vinyals",
      "Mahyar Bordbar",
      "Nando de Freitas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.06175"
  },
  {
    "id": "arXiv:2205.06296",
    "title": "Integrating User and Item Reviews in Deep Cooperative Neural Networks  for Movie Ranking Prediction",
    "abstract": "Comments: 13 pages, typos corrected, references added",
    "descriptor": "\nComments: 13 pages, typos corrected, references added\n",
    "authors": [
      "Aristeidis Karras",
      "Christos Karras"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.06296"
  },
  {
    "id": "arXiv:2205.06427",
    "title": "Test-time Fourier Style Calibration for Domain Generalization",
    "abstract": "Comments: 31st International Joint Conference on Artificial Intelligence (IJCAI) 2022",
    "descriptor": "\nComments: 31st International Joint Conference on Artificial Intelligence (IJCAI) 2022\n",
    "authors": [
      "Xingchen Zhao",
      "Chang Liu",
      "Anthony Sicilia",
      "Seong Jae Hwang",
      "Yun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.06427"
  },
  {
    "id": "arXiv:2205.06997",
    "title": "PAS: A Position-Aware Similarity Measurement for Sequential  Recommendation",
    "abstract": "Comments: International Joint Conference on Neural Networks (IJCNN 2022, Padua, Italy), 8 pages, Camera-Ready Version",
    "descriptor": "\nComments: International Joint Conference on Neural Networks (IJCNN 2022, Padua, Italy), 8 pages, Camera-Ready Version\n",
    "authors": [
      "Zijie Zeng",
      "Jing Lin",
      "Weike Pan",
      "Zhong Ming",
      "Zhongqi Lu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.06997"
  },
  {
    "id": "arXiv:2205.07146",
    "title": "Trajectory Inference via Mean-field Langevin in Path Space",
    "abstract": "Trajectory Inference via Mean-field Langevin in Path Space",
    "descriptor": "",
    "authors": [
      "L\u00e9na\u00efc Chizat",
      "Stephen Zhang",
      "Matthieu Heitz",
      "Geoffrey Schiebinger"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.07146"
  },
  {
    "id": "arXiv:2205.07403",
    "title": "PillarNet: Real-Time and High-Performance Pillar-based 3D Object  Detection",
    "abstract": "PillarNet: Real-Time and High-Performance Pillar-based 3D Object  Detection",
    "descriptor": "",
    "authors": [
      "Guangsheng Shi",
      "Ruifeng Li",
      "Chao Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.07403"
  },
  {
    "id": "arXiv:2205.07422",
    "title": "PrEF: Percolation-based Evolutionary Framework for the  diffusion-source-localization problem in large networks",
    "abstract": "PrEF: Percolation-based Evolutionary Framework for the  diffusion-source-localization problem in large networks",
    "descriptor": "",
    "authors": [
      "Yang Liu",
      "Xiaoqi Wang",
      "Xi Wang",
      "Zhen Wang",
      "J\u00fcrgen Kurths"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.07422"
  },
  {
    "id": "arXiv:2205.07979",
    "title": "The Budge programming language",
    "abstract": "The Budge programming language",
    "descriptor": "",
    "authors": [
      "Boro Sitnikovski"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Computation and Language (cs.CL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.07979"
  },
  {
    "id": "arXiv:2205.08056",
    "title": "\"What makes a question inquisitive?\" A Study on Type-Controlled  Inquisitive Question Generation",
    "abstract": "Comments: Accepted at the 11th Joint Conference on Lexical and Computational Semantics (*SEM) Conference, NAACL 2022",
    "descriptor": "\nComments: Accepted at the 11th Joint Conference on Lexical and Computational Semantics (*SEM) Conference, NAACL 2022\n",
    "authors": [
      "Lingyu Gao",
      "Debanjan Ghosh",
      "Kevin Gimpel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.08056"
  },
  {
    "id": "arXiv:2205.08084",
    "title": "M6-Rec: Generative Pretrained Language Models are Open-Ended Recommender  Systems",
    "abstract": "Comments: 10 pages, 8 figures, proudly rejected by KDD 2022",
    "descriptor": "\nComments: 10 pages, 8 figures, proudly rejected by KDD 2022\n",
    "authors": [
      "Zeyu Cui",
      "Jianxin Ma",
      "Chang Zhou",
      "Jingren Zhou",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.08084"
  },
  {
    "id": "arXiv:2205.08151",
    "title": "Cluster on Wheels",
    "abstract": "Comments: 8 pages, 7 figures, 2022 International Conference for Advancement in Technology(ICONAT). It is about the work of the mapping robot cluster computer platform",
    "descriptor": "\nComments: 8 pages, 7 figures, 2022 International Conference for Advancement in Technology(ICONAT). It is about the work of the mapping robot cluster computer platform\n",
    "authors": [
      "Yuanyuan Yang",
      "Delin Feng",
      "S\u00f6ren Schwertfeger"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.08151"
  },
  {
    "id": "arXiv:2205.08175",
    "title": "Probabilistic Automata of Bounded Ambiguity",
    "abstract": "Comments: Short version in CONCUR'17, Long version in Information and Computation (special issue on Weighted Automata)",
    "descriptor": "\nComments: Short version in CONCUR'17, Long version in Information and Computation (special issue on Weighted Automata)\n",
    "authors": [
      "Nathana\u00ebl Fijalkow",
      "Cristian Riveros",
      "James Worrell"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2205.08175"
  },
  {
    "id": "arXiv:2205.08176",
    "title": "On the Convergence of Policy in Unregularized Policy Mirror Descent",
    "abstract": "On the Convergence of Policy in Unregularized Policy Mirror Descent",
    "descriptor": "",
    "authors": [
      "Dachao Lin",
      "Zhihua Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.08176"
  },
  {
    "id": "arXiv:2205.08218",
    "title": "Is hyperinterpolation efficient in the approximation of singular and  oscillatory functions?",
    "abstract": "Comments: A new theorem, Theorem 2.1, is presented",
    "descriptor": "\nComments: A new theorem, Theorem 2.1, is presented\n",
    "authors": [
      "Congpei An",
      "Hao-Ning Wu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.08218"
  },
  {
    "id": "arXiv:2205.08425",
    "title": "Twenty-two years since revealing cross-site scripting attacks: a  systematic mapping and a comprehensive survey",
    "abstract": "Twenty-two years since revealing cross-site scripting attacks: a  systematic mapping and a comprehensive survey",
    "descriptor": "",
    "authors": [
      "Abdelhakim Hannousse",
      "Salima Yahiouche",
      "Mohamed Cherif Nait-Hamoud"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.08425"
  },
  {
    "id": "arXiv:2205.08565",
    "title": "Text Detection & Recognition in the Wild for Robot Localization",
    "abstract": "Comments: 6 papged, VI section, typos corrected, revison changes, no result changes",
    "descriptor": "\nComments: 6 papged, VI section, typos corrected, revison changes, no result changes\n",
    "authors": [
      "Zobeir Raisi",
      "John Zelek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.08565"
  },
  {
    "id": "arXiv:2205.08689",
    "title": "Spatial-Temporal Interactive Dynamic Graph Convolution Network for  Traffic Forecasting",
    "abstract": "Spatial-Temporal Interactive Dynamic Graph Convolution Network for  Traffic Forecasting",
    "descriptor": "",
    "authors": [
      "Aoyu Liu",
      "Yaying Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.08689"
  },
  {
    "id": "arXiv:2205.08706",
    "title": "SemiCurv: Semi-Supervised Curvilinear Structure Segmentation",
    "abstract": "Comments: IEEE Transactions on Image Processing",
    "descriptor": "\nComments: IEEE Transactions on Image Processing\n",
    "authors": [
      "Xun Xu",
      "Manh Cuong Nguyen",
      "Yasin Yazici",
      "Kangkang Lu",
      "Hlaing Min",
      "Chuan-Sheng Foo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.08706"
  },
  {
    "id": "arXiv:2205.08768",
    "title": "Global Type Inference for Featherweight Generic Java",
    "abstract": "Comments: 33 pages, abridged version appears in ECOOP 2022",
    "descriptor": "\nComments: 33 pages, abridged version appears in ECOOP 2022\n",
    "authors": [
      "Andreas Stadelmeier",
      "Martin Pl\u00fcmicke",
      "Peter Thiemann"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2205.08768"
  },
  {
    "id": "arXiv:2205.08776",
    "title": "AdaMCT: Adaptive Mixture of CNN-Transformer for Sequential  Recommendation",
    "abstract": "AdaMCT: Adaptive Mixture of CNN-Transformer for Sequential  Recommendation",
    "descriptor": "",
    "authors": [
      "Juyong Jiang",
      "Jae Boum Kim",
      "Yingtao Luo",
      "Kai Zhang",
      "Sunghun Kim"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.08776"
  },
  {
    "id": "arXiv:2205.08853",
    "title": "A Method for Self-Service Rehabilitation Training of Human Lower Limbs",
    "abstract": "A Method for Self-Service Rehabilitation Training of Human Lower Limbs",
    "descriptor": "",
    "authors": [
      "Zhaowen Shao",
      "Jun Li",
      "Lingtao Yu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.08853"
  },
  {
    "id": "arXiv:2205.08924",
    "title": "Financial Time Series Data Augmentation with Generative Adversarial  Networks and Extended Intertemporal Return Plots",
    "abstract": "Financial Time Series Data Augmentation with Generative Adversarial  Networks and Extended Intertemporal Return Plots",
    "descriptor": "",
    "authors": [
      "Justin Hellermann",
      "Qinzhuan Qian",
      "Ankit Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.08924"
  },
  {
    "id": "arXiv:2205.08972",
    "title": "The Structure of Configurations in One-Dimensional Majority Cellular  Automata: From Cell Stability to Configuration Periodicity",
    "abstract": "The Structure of Configurations in One-Dimensional Majority Cellular  Automata: From Cell Stability to Configuration Periodicity",
    "descriptor": "",
    "authors": [
      "Yonatan Nakar",
      "Dana Ron"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2205.08972"
  },
  {
    "id": "arXiv:2205.09036",
    "title": "Stop the Spread: A Contextual Integrity Perspective on the  Appropriateness of COVID-19 Vaccination Certificates",
    "abstract": "Stop the Spread: A Contextual Integrity Perspective on the  Appropriateness of COVID-19 Vaccination Certificates",
    "descriptor": "",
    "authors": [
      "Shikun Zhang",
      "Yan Shvartzshnaider",
      "Yuanyuan Feng",
      "Helen Nissenbaum",
      "Norman Sadeh"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.09036"
  },
  {
    "id": "arXiv:2205.09067",
    "title": "Automatic Rule Induction for Efficient Semi-Supervised Learning",
    "abstract": "Automatic Rule Induction for Efficient Semi-Supervised Learning",
    "descriptor": "",
    "authors": [
      "Reid Pryzant",
      "Ziyi Yang",
      "Yichong Xu",
      "Chenguang Zhu",
      "Michael Zeng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09067"
  },
  {
    "id": "arXiv:2205.09095",
    "title": "Conformalized Online Learning: Online Calibration Without a Holdout Set",
    "abstract": "Conformalized Online Learning: Online Calibration Without a Holdout Set",
    "descriptor": "",
    "authors": [
      "Shai Feldman",
      "Stephen Bates",
      "Yaniv Romano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.09095"
  }
]
[
  {
    "id": "arXiv:2205.01091",
    "title": "Blockchain in a nutshell",
    "abstract": "Blockchain enables a digital society where people can contribute,\ncollaborate, and transact without having to second-guess trust and\ntransparency. It is the technology behind the success of Bitcoin, Ethereum, and\nmany disruptive applications and platforms that have positive impact in\nnumerous sectors, including finance, education, health care, environment,\ntransportation, and philanthropy, to name a few. This chapter provides a\nfriendly description of essential concepts, mathematics, and algorithms that\nlay the foundation for blockchain technology.",
    "descriptor": "\nComments: Pre-print. Book chapter (50 pages) in \"Handbook on Blockchain\". Duc A. Tran, My T. Thai, and Bhaskar Krishnamachari (eds). Springer Nature Publisher, 2022\n",
    "authors": [
      "Duc A. Tran",
      "Bhaskar Krishnamachari"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2205.01091"
  },
  {
    "id": "arXiv:2205.01094",
    "title": "A Word is Worth A Thousand Dollars: Adversarial Attack on Tweets Fools  Stock Prediction",
    "abstract": "More and more investors and machine learning models rely on social media\n(e.g., Twitter and Reddit) to gather real-time information and sentiment to\npredict stock price movements. Although text-based models are known to be\nvulnerable to adversarial attacks, whether stock prediction models have similar\nvulnerability is underexplored. In this paper, we experiment with a variety of\nadversarial attack configurations to fool three stock prediction victim models.\nWe address the task of adversarial generation by solving combinatorial\noptimization problems with semantics and budget constraints. Our results show\nthat the proposed attack method can achieve consistent success rates and cause\nsignificant monetary loss in trading simulation by simply concatenating a\nperturbed but semantically similar tweet.",
    "descriptor": "\nComments: NAACL short paper, github: this https URL\n",
    "authors": [
      "Yong Xie",
      "Dakuo Wang",
      "Pin-Yu Chen",
      "Jinjun Xiong",
      "Sijia Liu",
      "Sanmi Koyejo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Statistical Finance (q-fin.ST)"
    ],
    "url": "https://arxiv.org/abs/2205.01094"
  },
  {
    "id": "arXiv:2205.01098",
    "title": "Initial Access for Millimeter-Wave and Terahertz Communications with  Hybrid Beamforming",
    "abstract": "In order to achieve terabits-per-second (Tbps) data rates in the\nsixth-generation (6G) mobile system, wireless communications are required to\nexploit the abundant spectrum in the millimeter-wave (mmWave) and terahertz\n(THz) bands. However, high-frequency transmission heavily relies on high\nbeamforming gain to compensate for severe propagation loss. A beam-based system\nfaces a barrier in the process of initial access, where a base station must\nbroadcast synchronization signals and system information to all users within\nits coverage. Hence, this paper proposes a novel omnidirectional broadcasting\nscheme for mmWave and THz systems with hybrid beamforming. It provides an\ninstantaneously equal gain over all directions by forming complementary beams\nover sub-arrays. Numerical results verify that it can achieve omnidirectional\ncoverage with a performance that remarkably outperforms the previous scheme.",
    "descriptor": "\nComments: 2022 IEEE International Conference on Communications (ICC), May 2022, Seoul, South Korea. arXiv admin note: substantial text overlap with arXiv:2205.00691\n",
    "authors": [
      "Wei Jiang",
      "Hans D. Schotten"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.01098"
  },
  {
    "id": "arXiv:2205.01100",
    "title": "Knowledge Management Strategies and Emerging Technologies -- An Overview  Of the Underpinning Concepts",
    "abstract": "Among the essential elements of knowledge management is the use of\ninformation and data, as well as the knowledge, skills, and abilities inherent\nwithin communities, as well as their ideas, commitments, and motivations for\nmaking good decisions as emerging technologies become more prevalent. Numerous\nleading social scientists in this field have asserted that organisational\nknowledge should be regarded as a strategic asset. There is a growing awareness\nof the importance of gathering, locating, capturing, and sharing collective\nknowledge and expertise of societies, and societies are urged to develop\neffective and efficient methods of gathering, locating, capturing, and sharing\nthat knowledge in order to deal with problems and to benefit from\nopportunities. People living in many countries and regions are interested in\nimplementing knowledge management processes and technologies, and many of them\nhave included knowledge management as an integral part of their overall\ndevelopment strategies. The management of knowledge plays an increasingly\nimportant role in global economic development (Bell, 1973, 1978). In order to\nremain relevant in the modern world, organisations should not ignore knowledge\nmanagement and emerging technologies.",
    "descriptor": "",
    "authors": [
      "Siddhartha Paul Tiwari"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.01100"
  },
  {
    "id": "arXiv:2205.01128",
    "title": "Neurocompositional computing: From the Central Paradox of Cognition to a  new generation of AI systems",
    "abstract": "What explains the dramatic progress from 20th-century to 21st-century AI, and\nhow can the remaining limitations of current AI be overcome? The widely\naccepted narrative attributes this progress to massive increases in the\nquantity of computational and data resources available to support statistical\nlearning in deep artificial neural networks. We show that an additional crucial\nfactor is the development of a new type of computation. Neurocompositional\ncomputing adopts two principles that must be simultaneously respected to enable\nhuman-level cognition: the principles of Compositionality and Continuity. These\nhave seemed irreconcilable until the recent mathematical discovery that\ncompositionality can be realized not only through discrete methods of symbolic\ncomputing, but also through novel forms of continuous neural computing. The\nrevolutionary recent progress in AI has resulted from the use of limited forms\nof neurocompositional computing. New, deeper forms of neurocompositional\ncomputing create AI systems that are more robust, accurate, and comprehensible.",
    "descriptor": "\nComments: 21 pages, 6 figures. For a general AI audience: to appear in AI Magazine. A more extensive presentation of this work is \"Neurocompositional computing in human and machine intelligence: A tutorial\", Microsoft Technical Report MSR-TR-2022-5; see this https URL\n",
    "authors": [
      "Paul Smolensky",
      "R. Thomas McCoy",
      "Roland Fernandez",
      "Matthew Goldrick",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2205.01128"
  },
  {
    "id": "arXiv:2205.01133",
    "title": "Hausa Visual Genome: A Dataset for Multi-Modal English to Hausa Machine  Translation",
    "abstract": "Multi-modal Machine Translation (MMT) enables the use of visual information\nto enhance the quality of translations. The visual information can serve as a\nvaluable piece of context information to decrease the ambiguity of input\nsentences. Despite the increasing popularity of such a technique, good and\nsizeable datasets are scarce, limiting the full extent of their potential.\nHausa, a Chadic language, is a member of the Afro-Asiatic language family. It\nis estimated that about 100 to 150 million people speak the language, with more\nthan 80 million indigenous speakers. This is more than any of the other Chadic\nlanguages. Despite a large number of speakers, the Hausa language is considered\nlow-resource in natural language processing (NLP). This is due to the absence\nof sufficient resources to implement most NLP tasks. While some datasets exist,\nthey are either scarce, machine-generated, or in the religious domain.\nTherefore, there is a need to create training and evaluation data for\nimplementing machine learning tasks and bridging the research gap in the\nlanguage. This work presents the Hausa Visual Genome (HaVG), a dataset that\ncontains the description of an image or a section within the image in Hausa and\nits equivalent in English. To prepare the dataset, we started by translating\nthe English description of the images in the Hindi Visual Genome (HVG) into\nHausa automatically. Afterward, the synthetic Hausa data was carefully\npost-edited considering the respective images. The dataset comprises 32,923\nimages and their descriptions that are divided into training, development,\ntest, and challenge test set. The Hausa Visual Genome is the first dataset of\nits kind and can be used for Hausa-English machine translation, multi-modal\nresearch, and image description, among various other natural language\nprocessing and generation tasks.",
    "descriptor": "\nComments: Accepted at Language Resources and Evaluation Conference 2022 (LREC2022)\n",
    "authors": [
      "Idris Abdulmumin",
      "Satya Ranjan Dash",
      "Musa Abdullahi Dawud",
      "Shantipriya Parida",
      "Shamsuddeen Hassan Muhammad",
      "Ibrahim Sa'id Ahmad",
      "Subhadarshi Panda",
      "Ond\u0159ej Bojar",
      "Bashir Shehu Galadanci",
      "Bello Shehu Bello"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01133"
  },
  {
    "id": "arXiv:2205.01135",
    "title": "D-DPCC: Deep Dynamic Point Cloud Compression via 3D Motion Prediction",
    "abstract": "The non-uniformly distributed nature of the 3D dynamic point cloud (DPC)\nbrings significant challenges to its high-efficient inter-frame compression.\nThis paper proposes a novel 3D sparse convolution-based Deep Dynamic Point\nCloud Compression (D-DPCC) network to compensate and compress the DPC geometry\nwith 3D motion estimation and motion compensation in the feature space. In the\nproposed D-DPCC network, we design a {\\it Multi-scale Motion Fusion} (MMF)\nmodule to accurately estimate the 3D optical flow between the feature\nrepresentations of adjacent point cloud frames. Specifically, we utilize a 3D\nsparse convolution-based encoder to obtain the latent representation for motion\nestimation in the feature space and introduce the proposed MMF module for fused\n3D motion embedding. Besides, for motion compensation, we propose a 3D {\\it\nAdaptively Weighted Interpolation} (3DAWI) algorithm with a penalty coefficient\nto adaptively decrease the impact of distant neighbors. We compress the motion\nembedding and the residual with a lossy autoencoder-based network. To our\nknowledge, this paper is the first work proposing an end-to-end deep dynamic\npoint cloud compression framework. The experimental result shows that the\nproposed D-DPCC framework achieves an average 76\\% BD-Rate (Bjontegaard Delta\nRate) gains against state-of-the-art Video-based Point Cloud Compression\n(V-PCC) v13 in inter mode.",
    "descriptor": "",
    "authors": [
      "Tingyu Fan",
      "Linyao Gao",
      "Yiling Xu",
      "Zhu Li",
      "Dong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.01135"
  },
  {
    "id": "arXiv:2205.01138",
    "title": "Transformers in Time-series Analysis: A Tutorial",
    "abstract": "Transformer architecture has widespread applications, particularly in Natural\nLanguage Processing and computer vision. Recently Transformers have been\nemployed in various aspects of time-series analysis. This tutorial provides an\noverview of the Transformer architecture, its applications, and a collection of\nexamples from recent research papers in time-series analysis. We delve into an\nexplanation of the core components of the Transformer, including the\nself-attention mechanism, positional encoding, multi-head, and encoder/decoder.\nSeveral enhancements to the initial, Transformer architecture are highlighted\nto tackle time-series tasks. The tutorial also provides best practices and\ntechniques to overcome the challenge of effectively training Transformers for\ntime-series analysis.",
    "descriptor": "\nComments: 28 pages, 17 figures\n",
    "authors": [
      "Sabeen Ahmed",
      "Ian E. Nielsen",
      "Aakash Tripathi",
      "Shamoon Siddiqui",
      "Ghulam Rasool",
      "Ravi P. Ramachandran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01138"
  },
  {
    "id": "arXiv:2205.01142",
    "title": "Cost-Aware Comparison of LiDAR-based 3D Object Detectors",
    "abstract": "Considerable research efforts have been devoted to LiDAR-based 3D object\ndetection and its empirical performance has been significantly improved. While\nthe progress has been encouraging, we observe an overlooked issue: it is not\nyet common practice to compare different 3D detectors under the same cost,\ne.g., inference latency. This makes it difficult to quantify the true\nperformance gain brought by recently proposed architecture designs. The goal of\nthis work is to conduct a fair comparison of LiDAR-based 3D object detectors.\nSpecifically, we focus on SECOND, a simple grid-based one-stage detector, and\nanalyze its performance under different costs by scaling its original\narchitecture. Then we compare the family of scaled SECOND with recent 3D\ndetection methods, such as Voxel R-CNN and PV-RCNN++. The results are\nsurprising. We find that, if allowed to use the same latency, SECOND can match\nthe performance of PV-RCNN++, the current state-of-the-art method on the Waymo\nOpen Dataset. Scaled SECOND also easily outperforms many recent 3D detection\nmethods published during the past year. We recommend future research control\nthe inference cost in their empirical comparison and include the family of\nscaled SECOND as a strong baseline when presenting novel 3D detection methods.",
    "descriptor": "",
    "authors": [
      "Xiaofang Wang",
      "Kris M. Kitani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01142"
  },
  {
    "id": "arXiv:2205.01155",
    "title": "Emotion-Controllable Generalized Talking Face Generation",
    "abstract": "Despite the significant progress in recent years, very few of the AI-based\ntalking face generation methods attempt to render natural emotions. Moreover,\nthe scope of the methods is majorly limited to the characteristics of the\ntraining dataset, hence they fail to generalize to arbitrary unseen faces. In\nthis paper, we propose a one-shot facial geometry-aware emotional talking face\ngeneration method that can generalize to arbitrary faces. We propose a graph\nconvolutional neural network that uses speech content feature, along with an\nindependent emotion input to generate emotion and speech-induced motion on\nfacial geometry-aware landmark representation. This representation is further\nused in our optical flow-guided texture generation network for producing the\ntexture. We propose a two-branch texture generation network, with motion and\ntexture branches designed to consider the motion and texture content\nindependently. Compared to the previous emotion talking face methods, our\nmethod can adapt to arbitrary faces captured in-the-wild by fine-tuning with\nonly a single image of the target identity in neutral emotion.",
    "descriptor": "\nComments: Accepted at IJCAI 2022\n",
    "authors": [
      "Sanjana Sinha",
      "Sandika Biswas",
      "Ravindra Yadav",
      "Brojeshwar Bhowmick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2205.01155"
  },
  {
    "id": "arXiv:2205.01156",
    "title": "SELC: Self-Ensemble Label Correction Improves Learning with Noisy Labels",
    "abstract": "Deep neural networks are prone to overfitting noisy labels, resulting in poor\ngeneralization performance. To overcome this problem, we present a simple and\neffective method self-ensemble label correction (SELC) to progressively correct\nnoisy labels and refine the model. We look deeper into the memorization\nbehavior in training with noisy labels and observe that the network outputs are\nreliable in the early stage. To retain this reliable knowledge, SELC uses\nensemble predictions formed by an exponential moving average of network outputs\nto update the original noisy labels. We show that training with SELC refines\nthe model by gradually reducing supervision from noisy labels and increasing\nsupervision from ensemble predictions. Despite its simplicity, compared with\nmany state-of-the-art methods, SELC obtains more promising and stable results\nin the presence of class-conditional, instance-dependent, and real-world label\nnoise. The code is available at https://github.com/MacLLL/SELC.",
    "descriptor": "\nComments: Accepted to IJCAI 2022\n",
    "authors": [
      "Yangdi Lu",
      "Wenbo He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01156"
  },
  {
    "id": "arXiv:2205.01157",
    "title": "Leximax Approximations and Representative Cohort Selection",
    "abstract": "Finding a representative cohort from a broad pool of candidates is a goal\nthat arises in many contexts such as choosing governing committees and consumer\npanels. While there are many ways to define the degree to which a cohort\nrepresents a population, a very appealing solution concept is lexicographic\nmaximality (leximax) which offers a natural (pareto-optimal like)\ninterpretation that the utility of no population can be increased without\ndecreasing the utility of a population that is already worse off. However,\nfinding a leximax solution can be highly dependent on small variations in the\nutility of certain groups. In this work, we explore new notions of approximate\nleximax solutions with three distinct motivations: better algorithmic\nefficiency, exploiting significant utility improvements, and robustness to\nnoise. Among other definitional contributions, we give a new notion of an\napproximate leximax that satisfies a similarly appealing semantic\ninterpretation and relate it to algorithmically-feasible approximate leximax\nnotions. When group utilities are linear over cohort candidates, we give an\nefficient polynomial-time algorithm for finding a leximax distribution over\ncohort candidates in the exact as well as in the approximate setting.\nFurthermore, we show that finding an integer solution to leximax cohort\nselection with linear utilities is NP-Hard.",
    "descriptor": "\nComments: 27 pages. Shortened version to appear in FORC 2022\n",
    "authors": [
      "Monika Henzinger",
      "Charlotte Peale",
      "Omer Reingold",
      "Judy Shen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.01157"
  },
  {
    "id": "arXiv:2205.01159",
    "title": "Saliency map using features derived from spiking neural networks of  primate visual cortex",
    "abstract": "We propose a framework inspired by biological vision systems to produce\nsaliency maps of digital images. Well-known computational models for receptive\nfields of areas in the visual cortex that are specialized for color and\norientation perception are used. To model the connectivity between these areas\nwe use the CARLsim library which is a spiking neural network(SNN) simulator.\nThe spikes generated by CARLsim, then serve as extracted features and input to\nour saliency detection algorithm. This new method of saliency detection is\ndescribed and applied to benchmark images.",
    "descriptor": "\nComments: 19 pages, 8 figures, 1 table\n",
    "authors": [
      "Reza Hojjaty Saeedy",
      "Richard A. Messner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01159"
  },
  {
    "id": "arXiv:2205.01163",
    "title": "Paving the Way for Mature Secondary Research: The Seven Types of  Literature Review",
    "abstract": "Confusion over different kinds of secondary research, and their divergent\npurposes, is undermining the effectiveness and usefulness of secondary studies\nin software engineering. This short paper therefore explains the differences\nbetween ad hoc reviews, case surveys, critical reviews, meta-analyses (aka\nsystematic literature reviews), meta-synthesis (aka thematic analysis), rapid\nreviews and scoping reviews (aka systematic mapping studies). We envision that\nthese guidelines will help researchers better select and describe their\nliterature reviews, while helping reviewers select more appropriate evaluation\ncriteria.",
    "descriptor": "\nComments: 5 pages, 1 table\n",
    "authors": [
      "Paul Ralph",
      "Sebastian Baltes"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.01163"
  },
  {
    "id": "arXiv:2205.01166",
    "title": "The Theory of Artificial Immutability: Protecting Algorithmic Groups  Under Anti-Discrimination Law",
    "abstract": "Artificial Intelligence (AI) is increasingly used to make important decisions\nabout people. While issues of AI bias and proxy discrimination are well\nexplored, less focus has been paid to the harms created by profiling based on\ngroups that do not map to or correlate with legally protected groups such as\nsex or ethnicity. This raises a question: are existing equality laws able to\nprotect against emergent AI-driven inequality? This article examines the legal\nstatus of algorithmic groups in North American and European non-discrimination\ndoctrine, law, and jurisprudence and will show that algorithmic groups are not\ncomparable to traditional protected groups. Nonetheless, these new groups are\nworthy of protection. I propose a new theory of harm - \"the theory of\nartificial immutability\" - that aims to bring AI groups within the scope of the\nlaw. My theory describes how algorithmic groups act as de facto immutable\ncharacteristics in practice that limit people's autonomy and prevent them from\nachieving important goals.",
    "descriptor": "\nComments: 97 Tul. L. Review. XX (2022-2023)\n",
    "authors": [
      "Sandra Wachter"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01166"
  },
  {
    "id": "arXiv:2205.01167",
    "title": "3D Convolutional Neural Networks for Dendrite Segmentation Using  Fine-Tuning and Hyperparameter Optimization",
    "abstract": "Dendritic microstructures are ubiquitous in nature and are the primary\nsolidification morphologies in metallic materials. Techniques such as x-ray\ncomputed tomography (XCT) have provided new insights into dendritic phase\ntransformation phenomena. However, manual identification of dendritic\nmorphologies in microscopy data can be both labor intensive and potentially\nambiguous. The analysis of 3D datasets is particularly challenging due to their\nlarge sizes (terabytes) and the presence of artifacts scattered within the\nimaged volumes. In this study, we trained 3D convolutional neural networks\n(CNNs) to segment 3D datasets. Three CNN architectures were investigated,\nincluding a new 3D version of FCDense. We show that using hyperparameter\noptimization (HPO) and fine-tuning techniques, both 2D and 3D CNN architectures\ncan be trained to outperform the previous state of the art. The 3D U-Net\narchitecture trained in this study produced the best segmentations according to\nquantitative metrics (pixel-wise accuracy of 99.84% and a boundary displacement\nerror of 0.58 pixels), while 3D FCDense produced the smoothest boundaries and\nbest segmentations according to visual inspection. The trained 3D CNNs are able\nto segment entire 852 x 852 x 250 voxel 3D volumes in only ~60 seconds, thus\nhastening the progress towards a deeper understanding of phase transformation\nphenomena such as dendritic solidification.",
    "descriptor": "",
    "authors": [
      "Jim James",
      "Nathan Pruyne",
      "Tiberiu Stan",
      "Marcus Schwarting",
      "Jiwon Yeom",
      "Seungbum Hong",
      "Peter Voorhees",
      "Ben Blaiszik",
      "Ian Foster"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.01167"
  },
  {
    "id": "arXiv:2205.01168",
    "title": "A Case Study on Parallel HDF5 Dataset Concatenation for High Energy  Physics Data Analysis",
    "abstract": "In High Energy Physics (HEP), experimentalists generate large volumes of data\nthat, when analyzed, helps us better understand the fundamental particles and\ntheir interactions. This data is often captured in many files of small size,\ncreating a data management challenge for scientists. In order to better\nfacilitate data management, transfer, and analysis on large scale platforms, it\nis advantageous to aggregate data further into a smaller number of larger\nfiles. However, this translation process can consume significant time and\nresources, and if performed incorrectly the resulting aggregated files can be\ninefficient for highly parallel access during analysis on large scale\nplatforms. In this paper, we present our case study on parallel I/O strategies\nand HDF5 features for reducing data aggregation time, making effective use of\ncompression, and ensuring efficient access to the resulting data during\nanalysis at scale. We focus on NOvA detector data in this case study, a\nlarge-scale HEP experiment generating many terabytes of data. The lessons\nlearned from our case study inform the handling of similar datasets, thus\nexpanding community knowledge related to this common data management task.",
    "descriptor": "",
    "authors": [
      "Sunwoo Lee",
      "Kai-yuan Hou",
      "Kewei Wang",
      "Saba Sehrish",
      "Marc Paterno",
      "James Kowalkowski",
      "Quincey Koziol",
      "Robert Ross",
      "Ankit Agrawal",
      "Alok Choudhary",
      "Wei-keng Liao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.01168"
  },
  {
    "id": "arXiv:2205.01171",
    "title": "Reversing an Imperative Concurrent Programming Language",
    "abstract": "We introduce a method of reversing the execution of imperative concurrent\nprograms. Given an irreversible program, we describe the process of producing\ntwo versions. The first performs forward execution and saves information\nnecessary for reversal. The second uses this saved information to simulate\nreversal. We propose using identifiers to overcome challenges of reversing\nconcurrent programs. We prove this reversibility to be correct, showing that\nthe initial program state is restored and that all saved information is used\n(garbage-free).",
    "descriptor": "\nComments: 48 pages, 21 figures\n",
    "authors": [
      "James Hoey",
      "Irek Ulidowski"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2205.01171"
  },
  {
    "id": "arXiv:2205.01179",
    "title": "VAE-Loco: Versatile Quadruped Locomotion by Learning a Disentangled Gait  Representation",
    "abstract": "Quadruped locomotion is rapidly maturing to a degree where robots now\nroutinely traverse a variety of unstructured terrains. However, while gaits can\nbe varied typically by selecting from a range of pre-computed styles, current\nplanners are unable to vary key gait parameters continuously while the robot is\nin motion. The synthesis, on-the-fly, of gaits with unexpected operational\ncharacteristics or even the blending of dynamic manoeuvres lies beyond the\ncapabilities of the current state-of-the-art. In this work we address this\nlimitation by learning a latent space capturing the key stance phases\nconstituting a particular gait. This is achieved via a generative model trained\non a single trot style, which encourages disentanglement such that application\nof a drive signal to a single dimension of the latent state induces holistic\nplans synthesising a continuous variety of trot styles. We demonstrate that\nspecific properties of the drive signal map directly to gait parameters such as\ncadence, footstep height and full stance duration. Due to the nature of our\napproach these synthesised gaits are continuously variable online during robot\noperation and robustly capture a richness of movement significantly exceeding\nthe relatively narrow behaviour seen during training. In addition, the use of a\ngenerative model facilitates the detection and mitigation of disturbances to\nprovide a versatile and robust planning framework. We evaluate our approach on\ntwo versions of the real ANYmal quadruped robots and demonstrate that our\nmethod achieves a continuous blend of dynamic trot styles whilst being robust\nand reactive to external perturbations.",
    "descriptor": "\nComments: 15 pages, 13 figures, 1 table, submitted to IEEE Transactions on Robotics (T-RO). arXiv admin note: substantial text overlap with arXiv:2112.04809\n",
    "authors": [
      "Alexander L. Mitchell",
      "Wolfgang Merkt",
      "Mathieu Geisert",
      "Siddhant Gangapurwala",
      "Martin Engelcke",
      "Oiwi Parker Jones",
      "Ioannis Havoutis",
      "Ingmar Posner"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01179"
  },
  {
    "id": "arXiv:2205.01180",
    "title": "Using Machine Learning to Evaluate Real Estate Prices Using Location Big  Data",
    "abstract": "With everyone trying to enter the real estate market nowadays, knowing the\nproper valuations for residential and commercial properties has become crucial.\nPast researchers have been known to utilize static real estate data (e.g.\nnumber of beds, baths, square footage) or even a combination of real estate and\ndemographic information to predict property prices. In this investigation, we\nattempted to improve upon past research. So we decided to explore a unique\napproach: we wanted to determine if mobile location data could be used to\nimprove the predictive power of popular regression and tree-based models. To\nprepare our data for our models, we processed the mobility data by attaching it\nto individual properties from the real estate data that aggregated users within\n500 meters of the property for each day of the week. We removed people that\nlived within 500 meters of each property, so each property's aggregated\nmobility data only contained non-resident census features. On top of these\ndynamic census features, we also included static census features, including the\nnumber of people in the area, the average proportion of people commuting, and\nthe number of residents in the area. Finally, we tested multiple models to\npredict real estate prices. Our proposed model is two stacked random forest\nmodules combined using a ridge regression that uses the random forest outputs\nas predictors. The first random forest model used static features only and the\nsecond random forest model used dynamic features only. Comparing our models\nwith and without the dynamic mobile location features concludes the model with\ndynamic mobile location features achieves 3/% percent lower mean squared error\nthan the same model but without dynamic mobile location features.",
    "descriptor": "",
    "authors": [
      "Walter Coleman",
      "Ben Johann",
      "Nicholas Pasternak",
      "Jaya Vellayan",
      "Natasha Foutz",
      "Heman Shakeri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01180"
  },
  {
    "id": "arXiv:2205.01183",
    "title": "A fast in-place interpreter for WebAssembly",
    "abstract": "WebAssembly (Wasm) is a compact, well-specified bytecode format that offers a\nportable compilation target with near-native execution speed. The bytecode\nformat was specifically designed to be fast to parse, validate, and compile,\npositioning itself as a portable alternative to native code. It was pointedly\nnot designed to be interpreted directly. Instead, design considerations at the\ntime focused on competing with native code, utilizing optimizing compilers as\nthe primary execution tier. Yet, in JIT scenarios, compilation time and memory\nconsumption critically impact application startup, leading many Wasm engines to\nlater deploy baseline (single-pass) compilers. Though faster, baseline\ncompilers still take time and waste code space for infrequently executed code.\nA typical interpreter being infeasible, some engines resort to compiling Wasm\nnot to machine code, but to a more compact, but easy to interpret format. This\nstill takes time and wastes memory. Instead, we introduce in this article a\nfast in-place interpreter for WebAssembly, where no rewrite and no separate\nformat is necessary. Our evaluation shows that in-place interpretation of Wasm\ncode is space-efficient and fast, achieving performance on-par with\ninterpreting a custom-designed internal format. This fills a hole in the\nexecution tier space for Wasm, allowing for even faster startup and lower\nmemory footprint than previous engine configurations.",
    "descriptor": "",
    "authors": [
      "Ben L. Titzer"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2205.01183"
  },
  {
    "id": "arXiv:2205.01184",
    "title": "Performance Weighting for Robust Federated Learning Against Corrupted  Sources",
    "abstract": "Federated Learning has emerged as a dominant computational paradigm for\ndistributed machine learning. Its unique data privacy properties allow us to\ncollaboratively train models while offering participating clients certain\nprivacy-preserving guarantees. However, in real-world applications, a federated\nenvironment may consist of a mixture of benevolent and malicious clients, with\nthe latter aiming to corrupt and degrade federated model's performance.\nDifferent corruption schemes may be applied such as model poisoning and data\ncorruption. Here, we focus on the latter, the susceptibility of federated\nlearning to various data corruption attacks. We show that the standard global\naggregation scheme of local weights is inefficient in the presence of corrupted\nclients. To mitigate this problem, we propose a class of task-oriented\nperformance-based methods computed over a distributed validation dataset with\nthe goal to detect and mitigate corrupted clients. Specifically, we construct a\nrobust weight aggregation scheme based on geometric mean and demonstrate its\neffectiveness under random label shuffling and targeted label flipping attacks.",
    "descriptor": "\nComments: 27 pages, 40 figures\n",
    "authors": [
      "Dimitris Stripelis",
      "Marcin Abram",
      "Jose Luis Ambite"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.01184"
  },
  {
    "id": "arXiv:2205.01188",
    "title": "Predicting Time-to-conversion for Dementia of Alzheimer's Type using  Multi-modal Deep Survival Analysis",
    "abstract": "Dementia of Alzheimer's Type (DAT) is a complex disorder influenced by\nnumerous factors, but it is unclear how each factor contributes to disease\nprogression. An in-depth examination of these factors may yield an accurate\nestimate of time-to-conversion to DAT for patients at various disease stages.\nWe used 401 subjects with 63 features from MRI, genetic, and CDC (Cognitive\ntests, Demographic, and CSF) data modalities in the Alzheimer's Disease\nNeuroimaging Initiative (ADNI) database. We used a deep learning-based survival\nanalysis model that extends the classic Cox regression model to predict\ntime-to-conversion to DAT. Our findings showed that genetic features\ncontributed the least to survival analysis, while CDC features contributed the\nmost. Combining MRI and genetic features improved survival prediction over\nusing either modality alone, but adding CDC to any combination of features only\nworked as well as using only CDC features. Consequently, our study demonstrated\nthat using the current clinical procedure, which includes gathering cognitive\ntest results, can outperform survival analysis results produced using costly\ngenetic or CSF data.",
    "descriptor": "",
    "authors": [
      "Ghazal Mirabnahrazam",
      "Da Ma",
      "C\u00e9dric Beaulac",
      "Sieun Lee",
      "Karteek Popuri",
      "Hyunwoo Lee",
      "Jiguo Cao",
      "James E Galvin",
      "Lei Wang",
      "Mirza Faisal Beg",
      "Alzheimer's Disease Neuroimaging Initiative"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01188"
  },
  {
    "id": "arXiv:2205.01189",
    "title": "A Critique of Uribe's \"P vs. NP\"",
    "abstract": "In this critique, we examine the technical report by Daniel Uribe entitled \"P\nvs. NP.\" The paper claims to show an exponential lower bound on the runtime of\nalgorithms that decide CLIQUE. We show that the paper's proofs fail to\ngeneralize to all possible algorithms and that, even on those algorithms to\nwhich the proofs do apply, the proofs' arguments are flawed.",
    "descriptor": "\nComments: 7 pages, 2 figures\n",
    "authors": [
      "Henry B. Welles"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2205.01189"
  },
  {
    "id": "arXiv:2205.01197",
    "title": "Boosting Video Object Segmentation based on Scale Inconsistency",
    "abstract": "We present a refinement framework to boost the performance of pre-trained\nsemi-supervised video object segmentation (VOS) models. Our work is based on\nscale inconsistency, which is motivated by the observation that existing VOS\nmodels generate inconsistent predictions from input frames with different\nsizes. We use the scale inconsistency as a clue to devise a pixel-level\nattention module that aggregates the advantages of the predictions from\ndifferent-size inputs. The scale inconsistency is also used to regularize the\ntraining based on a pixel-level variance measured by an uncertainty estimation.\nWe further present a self-supervised online adaptation, tailored for test-time\noptimization, that bootstraps the predictions without ground-truth masks based\non the scale inconsistency. Experiments on DAVIS 16 and DAVIS 17 datasets show\nthat our framework can be generically applied to various VOS models and improve\ntheir performance.",
    "descriptor": "",
    "authors": [
      "Hengyi Wang",
      "Changjae Oh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01197"
  },
  {
    "id": "arXiv:2205.01198",
    "title": "NHA12D: A New Pavement Crack Dataset and a Comparison Study Of Crack  Detection Algorithms",
    "abstract": "Crack detection plays a key role in automated pavement inspection. Although a\nlarge number of algorithms have been developed in recent years to further boost\nperformance, there are still remaining challenges in practice, due to the\ncomplexity of pavement images. To further accelerate the development and\nidentify the remaining challenges, this paper conducts a comparison study to\nevaluate the performance of the state of the art crack detection algorithms\nquantitatively and objectively. A more comprehensive annotated pavement crack\ndataset (NHA12D) that contains images with different viewpoints and pavements\ntypes is proposed. In the comparison study, crack detection algorithms were\ntrained equally on the largest public crack dataset collected and evaluated on\nthe proposed dataset (NHA12D). Overall, the U-Net model with VGG-16 as backbone\nhas the best all-around performance, but models generally fail to distinguish\ncracks from concrete joints, leading to a high false-positive rate. It also\nfound that detecting cracks from concrete pavement images still has huge room\nfor improvement. Dataset for concrete pavement images is also missing in the\nliterature. Future directions in this area include filling the gap for concrete\npavement images and using domain adaptation techniques to enhance the detection\nresults on unseen datasets.",
    "descriptor": "\nComments: Accepted at EC3 2022\n",
    "authors": [
      "Zhening Huang",
      "Weiwei Chen",
      "Abir Al-Tabbaa",
      "Ioannis Brilakis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.01198"
  },
  {
    "id": "arXiv:2205.01202",
    "title": "POCD: Probabilistic Object-Level Change Detection and Volumetric Mapping  in Semi-Static Scenes",
    "abstract": "Maintaining an up-to-date map to reflect recent changes in the scene is very\nimportant, particularly in situations involving repeated traversals by a robot\noperating in an environment over an extended period. Undetected changes may\ncause a deterioration in map quality, leading to poor localization, inefficient\noperations, and lost robots. Volumetric methods, such as truncated signed\ndistance functions (TSDFs), have quickly gained traction due to their real-time\nproduction of a dense and detailed map, though map updating in scenes that\nchange over time remains a challenge. We propose a framework that introduces a\nnovel probabilistic object state representation to track object pose changes in\nsemi-static scenes. The representation jointly models a stationarity score and\na TSDF change measure for each object. A Bayesian update rule that incorporates\nboth geometric and semantic information is derived to achieve consistent online\nmap maintenance. To extensively evaluate our approach alongside the\nstate-of-the-art, we release a novel real-world dataset in a warehouse\nenvironment. We also evaluate on the public ToyCar dataset. Our method\noutperforms state-of-the-art methods on the reconstruction quality of\nsemi-static environments.",
    "descriptor": "\nComments: Conditionally accepted to 2022 Robotics: Science and Systems (RSS)\n",
    "authors": [
      "Jingxing Qian",
      "Veronica Chatrath",
      "Jun Yang",
      "James Servos",
      "Angela P. Schoellig",
      "Steven L. Waslander"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.01202"
  },
  {
    "id": "arXiv:2205.01204",
    "title": "Multi-Task Text Classification using Graph Convolutional Networks for  Large-Scale Low Resource Language",
    "abstract": "Graph Convolutional Networks (GCN) have achieved state-of-art results on\nsingle text classification tasks like sentiment analysis, emotion detection,\netc. However, the performance is achieved by testing and reporting on\nresource-rich languages like English. Applying GCN for multi-task text\nclassification is an unexplored area. Moreover, training a GCN or adopting an\nEnglish GCN for Indian languages is often limited by data availability, rich\nmorphological variation, syntax, and semantic differences. In this paper, we\nstudy the use of GCN for the Telugu language in single and multi-task settings\nfor four natural language processing (NLP) tasks, viz. sentiment analysis (SA),\nemotion identification (EI), hate-speech (HS), and sarcasm detection (SAR). In\norder to evaluate the performance of GCN with one of the Indian languages,\nTelugu, we analyze the GCN based models with extensive experiments on four\ndownstream tasks. In addition, we created an annotated Telugu dataset, TEL-NLP,\nfor the four NLP tasks. Further, we propose a supervised graph reconstruction\nmethod, Multi-Task Text GCN (MT-Text GCN) on the Telugu that leverages to\nsimultaneously (i) learn the low-dimensional word and sentence graph embeddings\nfrom word-sentence graph reconstruction using graph autoencoder (GAE) and (ii)\nperform multi-task text classification using these latent sentence graph\nembeddings. We argue that our proposed MT-Text GCN achieves significant\nimprovements on TEL-NLP over existing Telugu pretrained word embeddings, and\nmultilingual pretrained Transformer models: mBERT, and XLM-R. On TEL-NLP, we\nachieve a high F1-score for four NLP tasks: SA (0.84), EI (0.55), HS (0.83) and\nSAR (0.66). Finally, we show our model's quantitative and qualitative analysis\non the four NLP tasks in Telugu.",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Mounika Marreddy",
      "Subba Reddy Oota",
      "Lakshmi Sireesha Vakada",
      "Venkata Charan Chinni",
      "Radhika Mamidi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01204"
  },
  {
    "id": "arXiv:2205.01206",
    "title": "A stable sampling method for inverse scattering from periodic media",
    "abstract": "This paper is concerned with the inverse problem of determining the shape of\npenetrable periodic scatterers from scattered field data. We propose a sampling\nmethod with a new imaging functional for solving this inverse problem. This\nimaging functional is very simple to implement, robust against noise in the\ndata, and does not require regularization. The resolution and stability\nanalysis of the imaging functional is analyzed. Our numerical study shows that\nthe proposed sampling method is more stable than the factorization method and\nmore efficient than the orthogonality sampling method in reconstructing\nperiodic scattering media.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Dinh-Liem Nguyen",
      "Kale Stahl",
      "Trung Truong"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.01206"
  },
  {
    "id": "arXiv:2205.01210",
    "title": "Applications of Deep Learning to the Design of Enhanced Wireless  Communication Systems",
    "abstract": "Innovation in the physical layer of communication systems has traditionally\nbeen achieved by breaking down the transceivers into sets of processing blocks,\neach optimized independently based on mathematical models. Conversely, deep\nlearning (DL)-based systems are able to handle increasingly complex tasks for\nwhich no tractable models are available. This thesis aims at comparing\ndifferent approaches to unlock the full potential of DL in the physical layer.\nFirst, we describe a neural network (NN)-based block strategy, where an NN is\noptimized to replace a block in a communication system. We apply this strategy\nto introduce a multi-user multiple-input multiple-output (MU-MIMO) detector\nthat builds on top of an existing DL-based architecture. Second, we detail an\nend-to-end strategy, in which the transmitter and receiver are modeled as an\nautoencoder. This approach is illustrated with the design of waveforms that\nachieve high throughputs while satisfying peak-to-average power ratio (PAPR)\nand adjacent channel leakage ratio (ACLR) constraints. Lastly, we propose a\nhybrid strategy, where multiple DL components are inserted into a traditional\narchitecture but are trained to optimize the end-to-end performance. To\ndemonstrate its benefits, we propose a DL-enhanced MU-MIMO receiver that both\nenable lower bit error rates (BERs) compared to a conventional receiver and\nremains scalable to any number of users.\nEach approach has its own strengths and shortcomings. While the first one is\nthe easiest to implement, its individual block optimization does not ensure the\noverall system optimality. On the other hand, systems designed with the second\napproach are computationally complex but allow for new opportunities such as\npilotless transmissions. Finally, the combined flexibility and end-to-end\nperformance gains of the third approach motivate its use for short-term\npractical implementations.",
    "descriptor": "\nComments: 168 pages, PhD thesis\n",
    "authors": [
      "Mathieu Goutay"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.01210"
  },
  {
    "id": "arXiv:2205.01212",
    "title": "Streaming Inference for Infinite Non-Stationary Clustering",
    "abstract": "Learning from a continuous stream of non-stationary data in an unsupervised\nmanner is arguably one of the most common and most challenging settings facing\nintelligent agents. Here, we attack learning under all three conditions\n(unsupervised, streaming, non-stationary) in the context of clustering, also\nknown as mixture modeling. We introduce a novel clustering algorithm that\nendows mixture models with the ability to create new clusters online, as\ndemanded by the data, in a probabilistic, time-varying, and principled manner.\nTo achieve this, we first define a novel stochastic process called the\nDynamical Chinese Restaurant Process (Dynamical CRP), which is a\nnon-exchangeable distribution over partitions of a set; next, we show that the\nDynamical CRP provides a non-stationary prior over cluster assignments and\nyields an efficient streaming variational inference algorithm. We conclude with\nexperiments showing that the Dynamical CRP can be applied on diverse synthetic\nand real data with Gaussian and non-Gaussian likelihoods.",
    "descriptor": "\nComments: Published at the Workshop on Agent Learning in Open-Endedness (ALOE) at ICLR 2022\n",
    "authors": [
      "Rylan Schaeffer",
      "Gabrielle Kaili-May Liu",
      "Yilun Du",
      "Scott Linderman",
      "Ila Rani Fiete"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01212"
  },
  {
    "id": "arXiv:2205.01213",
    "title": "Line-of-Sight MIMO via Reflection From a Smooth Surface",
    "abstract": "We provide a deterministic channel model for a scenario where wireless\nconnectivity is established through a reflection from a planar smooth surface\nof an infinite extent. The developed model is rigorously built upon the physics\nof wave propagation, and is as precise as tight are the unboundedness and\nsmoothness assumptions on the surface. This model allows establishing that\nline-of-sight spatial multiplexing can take place via reflection off an\nelectrically large surface, a situation of high interest for mmWave and\nterahertz frequencies.",
    "descriptor": "\nComments: 5 pages, 5 figures, accepted for presentation at the 2022 IEEE Veh. Techn. Conf. (VTC)\n",
    "authors": [
      "Andrea Pizzo",
      "Angel Lozano",
      "Sundeep Rangan",
      "Thomas Marzetta"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.01213"
  },
  {
    "id": "arXiv:2205.01214",
    "title": "An improvement to a result about graph isomorphism networks using the  prime factorization theorem",
    "abstract": "The unique prime factorization theorem is used to show the existence of a\nfunction on a countable set $\\mathcal{X}$ so that the sum aggregator function\nis injective on all multisets of $\\mathcal{X}$ of finite size.",
    "descriptor": "\nComments: 2 pages\n",
    "authors": [
      "Rahul Sarkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01214"
  },
  {
    "id": "arXiv:2205.01215",
    "title": "The state of stress and strain adjacent to notches in a new class of  nonlinear elastic bodies",
    "abstract": "In this paper we study the deformation of a body with a notch subject to an\nanti-plane state of stress within the context of a new class of elastic models.\nThese models stem as approximations of constitutive response functions for an\nelastic body that is defined within the context of an implicit constitutive\nrelation between the stress and the deformation gradient. Gum metal and many\nmetallic alloys are described well by such constitutive relations. We consider\nthe state of anti-plane stress of a body with a smoothened V-notch within the\ncontext of constitutive relations for the linearized strain in terms of a\npower-law for the stretch. The problem is solved numerically and the\nconvergence and the stability of the solution is studied.",
    "descriptor": "\nComments: This version of the article has been accepted for publication, after peer review and is subject to Springer Nature's AM terms of use, but is not the Version of Record and does not reflect post-acceptance improvements, or any corrections. The Version of Record is available online at: this https URL\n",
    "authors": [
      "Vojt\u011bch Kulvait",
      "Josef M\u00e1lek",
      "K.R. Rajagopal"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.01215"
  },
  {
    "id": "arXiv:2205.01217",
    "title": "Insider Stories: Analyzing Internal Sustainability Efforts of Major US  Companies from Online Reviews",
    "abstract": "It is hard to establish whether a company supports gender equality,\ndiversity, and general staff welfare, not least because of lack of\nmethodologies operationalizing these internal sustainability practices, and of\ndata honestly documenting such efforts. We developed and validated a\nsix-dimension framework reflecting Internal Sustainability Efforts (ISEs),\ngathered more than 350K employee reviews of 104 major companies across the\nwhole US for the (2008-2020) years, and developed a deep-learning framework\nscoring these reviews in terms of the six ISEs. Commitment to ISEs manifested\nitself not only at micro-level (companies scoring high in ISEs enjoyed high\nstock growth) but also at macro-level (states hosting these companies were\neconomically wealthy and equal, and attracted the so-called creative class).\nThis new conceptualization of ISEs offers both theoretical implications for the\nliterature in corporate sustainability and economic geography, and practical\nimplications for companies and policy makers.",
    "descriptor": "",
    "authors": [
      "Indira Sen",
      "Daniele Quercia",
      "Licia Capra",
      "Matteo Montecchi",
      "Sanja \u0160\u0107epanovi\u0107"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.01217"
  },
  {
    "id": "arXiv:2205.01224",
    "title": "COMET Flows: Towards Generative Modeling of Multivariate Extremes and  Tail Dependence",
    "abstract": "Normalizing flows, a popular class of deep generative models, often fail to\nrepresent extreme phenomena observed in real-world processes. In particular,\nexisting normalizing flow architectures struggle to model multivariate\nextremes, characterized by heavy-tailed marginal distributions and asymmetric\ntail dependence among variables. In light of this shortcoming, we propose COMET\n(COpula Multivariate ExTreme) Flows, which decompose the process of modeling a\njoint distribution into two parts: (i) modeling its marginal distributions, and\n(ii) modeling its copula distribution. COMET Flows capture heavy-tailed\nmarginal distributions by combining a parametric tail belief at extreme\nquantiles of the marginals with an empirical kernel density function at\nmid-quantiles. In addition, COMET Flows capture asymmetric tail dependence\namong multivariate extremes by viewing such dependence as inducing a\nlow-dimensional manifold structure in feature space. Experimental results on\nboth synthetic and real-world datasets demonstrate the effectiveness of COMET\nFlows in capturing both heavy-tailed marginals and asymmetric tail dependence\ncompared to other state-of-the-art baseline architectures. All code is\navailable on GitHub at https://github.com/andrewmcdonald27/COMETFlows.",
    "descriptor": "\nComments: 7 pages, 4 figures, accepted to IJCAI'22\n",
    "authors": [
      "Andrew McDonald",
      "Pang-Ning Tan",
      "Lifeng Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.01224"
  },
  {
    "id": "arXiv:2205.01225",
    "title": "A Hybrid Defense Method against Adversarial Attacks on Traffic Sign  Classifiers in Autonomous Vehicles",
    "abstract": "Adversarial attacks can make deep neural network (DNN) models predict\nincorrect output labels, such as misclassified traffic signs, for autonomous\nvehicle (AV) perception modules. Resilience against adversarial attacks can\nhelp AVs navigate safely on the road by avoiding misclassication of signs or\nobjects. This DNN-based study develops a resilient traffic sign classifier for\nAVs that uses a hybrid defense method. We use transfer learning to retrain the\nInception-V3 and Resnet-152 models as traffic sign classifiers. This method\nalso utilizes a combination of three different strategies: random filtering,\nensembling, and local feature mapping. We use the random cropping and resizing\ntechnique for random filtering, plurality voting as ensembling strategy and an\noptical character recognition model as a local feature mapper. This DNN-based\nhybrid defense method has been tested for the no attack scenario and against\nwell-known untargeted adversarial attacks (e.g., Projected Gradient Descent or\nPGD, Fast Gradient Sign Method or FGSM, Momentum Iterative Method or MIM\nattack, and Carlini and Wagner or C&W). We find that our hybrid defense method\nachieves 99% average traffic sign classification accuracy for the no attack\nscenario and 88% average traffic sign classification accuracy for all attack\nscenarios. Moreover, the hybrid defense method, presented in this study,\nimproves the accuracy for traffic sign classification compared to the\ntraditional defense methods (i.e., JPEG filtering, feature squeezing, binary\nfiltering, and random filtering) up to 6%, 50%, and 55% for FGSM, MIM, and PGD\nattacks, respectively.",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Zadid Khan",
      "Mashrur Chowdhury",
      "Sakib Mahmud Khan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01225"
  },
  {
    "id": "arXiv:2205.01226",
    "title": "Adversarial attacks on an optical neural network",
    "abstract": "Adversarial attacks have been extensively investigated for machine learning\nsystems including deep learning in the digital domain. However, the adversarial\nattacks on optical neural networks (ONN) have been seldom considered\npreviously. In this work, we first construct an accurate image classifier with\nan ONN using a mesh of interconnected Mach-Zehnder interferometers (MZI). Then\na corresponding adversarial attack scheme is proposed for the first time. The\nattacked images are visually very similar to the original ones but the ONN\nsystem becomes malfunctioned and generates wrong classification results in most\ntime. The results indicate that adversarial attack is also a significant issue\nfor optical machine learning systems.",
    "descriptor": "",
    "authors": [
      "Shuming Jiao",
      "Ziwei Song",
      "Shuiying Xiang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01226"
  },
  {
    "id": "arXiv:2205.01228",
    "title": "Paragraph-based Transformer Pre-training for Multi-Sentence Inference",
    "abstract": "Inference tasks such as answer sentence selection (AS2) or fact verification\nare typically solved by fine-tuning transformer-based models as individual\nsentence-pair classifiers. Recent studies show that these tasks benefit from\nmodeling dependencies across multiple candidate sentences jointly. In this\npaper, we first show that popular pre-trained transformers perform poorly when\nused for fine-tuning on multi-candidate inference tasks. We then propose a new\npre-training objective that models the paragraph-level semantics across\nmultiple input sentences. Our evaluation on three AS2 and one fact verification\ndatasets demonstrates the superiority of our pre-training technique over the\ntraditional ones for transformers used as joint models for multi-candidate\ninference tasks, as well as when used as cross-encoders for sentence-pair\nformulations of these tasks.",
    "descriptor": "\nComments: Accepted at NAACL 2022\n",
    "authors": [
      "Luca Di Liello",
      "Siddhant Garg",
      "Luca Soldaini",
      "Alessandro Moschitti"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01228"
  },
  {
    "id": "arXiv:2205.01229",
    "title": "DCoflow: Deadline-Aware Scheduling Algorithm for Coflows in Datacenter  Networks",
    "abstract": "Datacenter networks routinely support the data transfers of distributed\ncomputing frameworks in the form of coflows, i.e., sets of concurrent flows\nrelated to a common task. The vast majority of the literature has focused on\nthe problem of scheduling coflows for completion time minimization, i.e., to\nmaximize the average rate at which coflows are dispatched in the network\nfabric. Modern applications, though, may generate coflows dedicated to online\nservices and mission-critical computing tasks which have to comply with\nspecific completion deadlines. In this paper, we introduce $\\mathtt{DCoflow}$,\na lightweight deadline-aware scheduler for time-critical coflows in datacenter\nnetworks. The algorithm combines an online joint admission control and\nscheduling logic and returns a $\\sigma$-order schedule which maximizes the\nnumber of coflows that attain their deadlines. Extensive numerical results\ndemonstrate that the proposed solution outperforms existing ones.",
    "descriptor": "\nComments: Accepted to IFIP Networking 2022 (Catania, Italy)\n",
    "authors": [
      "Quang-Trung Luu",
      "Olivier Brun",
      "Rachid El-Azouzi",
      "Francesco De Pellegrini",
      "Balakrishna J. Prabhu",
      "C\u00e9dric Richier"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.01229"
  },
  {
    "id": "arXiv:2205.01230",
    "title": "Retrieval-Enhanced Machine Learning",
    "abstract": "Although information access systems have long supported people in\naccomplishing a wide range of tasks, we propose broadening the scope of users\nof information access systems to include task-driven machines, such as machine\nlearning models. In this way, the core principles of indexing, representation,\nretrieval, and ranking can be applied and extended to substantially improve\nmodel generalization, scalability, robustness, and interpretability. We\ndescribe a generic retrieval-enhanced machine learning (REML) framework, which\nincludes a number of existing models as special cases. REML challenges\ninformation retrieval conventions, presenting opportunities for novel advances\nin core areas, including optimization. The REML research agenda lays a\nfoundation for a new style of information access research and paves a path\ntowards advancing machine learning and artificial intelligence.",
    "descriptor": "\nComments: To appear in proceedings of ACM SIGIR 2022\n",
    "authors": [
      "Hamed Zamani",
      "Fernando Diaz",
      "Mostafa Dehghani",
      "Donald Metzler",
      "Michael Bendersky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.01230"
  },
  {
    "id": "arXiv:2205.01231",
    "title": "ADDAI: Anomaly Detection using Distributed AI",
    "abstract": "When dealing with the Internet of Things (IoT), especially industrial IoT\n(IIoT), two manifest challenges leap to mind. First is the massive amount of\ndata streaming to and from IoT devices, and second is the fast pace at which\nthese systems must operate. Distributed computing in the form of edge/cloud\nstructure is a popular technique to overcome these two challenges. In this\npaper, we propose ADDAI (Anomaly Detection using Distributed AI) that can\neasily span out geographically to cover a large number of IoT sources. Due to\nits distributed nature, it guarantees critical IIoT requirements such as high\nspeed, robustness against a single point of failure, low communication\noverhead, privacy, and scalability. Through empirical proof, we show the\ncommunication cost is minimized, and the performance improves significantly\nwhile maintaining the privacy of raw data at the local layer. ADDAI provides\npredictions for new random samples with an average success rate of 98.4% while\nreducing the communication overhead by half compared with the traditional\ntechnique of offloading all the raw sensor data to the cloud.",
    "descriptor": "",
    "authors": [
      "Maede Zolanvari",
      "Ali Ghubaish",
      "Raj Jain"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01231"
  },
  {
    "id": "arXiv:2205.01232",
    "title": "TRUST XAI: Model-Agnostic Explanations for AI With a Case Study on IIoT  Security",
    "abstract": "Despite AI's significant growth, its \"black box\" nature creates challenges in\ngenerating adequate trust. Thus, it is seldom utilized as a standalone unit in\nIoT high-risk applications, such as critical industrial infrastructures,\nmedical systems, and financial applications, etc. Explainable AI (XAI) has\nemerged to help with this problem. However, designing appropriately fast and\naccurate XAI is still challenging, especially in numerical applications. Here,\nwe propose a universal XAI model named Transparency Relying Upon Statistical\nTheory (TRUST), which is model-agnostic, high-performing, and suitable for\nnumerical applications. Simply put, TRUST XAI models the statistical behavior\nof the AI's outputs in an AI-based system. Factor analysis is used to transform\nthe input features into a new set of latent variables. We use mutual\ninformation to rank these variables and pick only the most influential ones on\nthe AI's outputs and call them \"representatives\" of the classes. Then we use\nmulti-modal Gaussian distributions to determine the likelihood of any new\nsample belonging to each class. We demonstrate the effectiveness of TRUST in a\ncase study on cybersecurity of the industrial Internet of things (IIoT) using\nthree different cybersecurity datasets. As IIoT is a prominent application that\ndeals with numerical data. The results show that TRUST XAI provides\nexplanations for new random samples with an average success rate of 98%.\nCompared with LIME, a popular XAI model, TRUST is shown to be superior in the\ncontext of performance, speed, and the method of explainability. In the end, we\nalso show how TRUST is explained to the user.",
    "descriptor": "",
    "authors": [
      "Maede Zolanvari",
      "Zebo Yang",
      "Khaled Khan",
      "Raj Jain",
      "Nader Meskin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.01232"
  },
  {
    "id": "arXiv:2205.01233",
    "title": "One Weird Trick to Improve Your Semi-Weakly Supervised Semantic  Segmentation Model",
    "abstract": "Semi-weakly supervised semantic segmentation (SWSSS) aims to train a model to\nidentify objects in images based on a small number of images with pixel-level\nlabels, and many more images with only image-level labels. Most existing SWSSS\nalgorithms extract pixel-level pseudo-labels from an image classifier - a very\ndifficult task to do well, hence requiring complicated architectures and\nextensive hyperparameter tuning on fully-supervised validation sets. We propose\na method called prediction filtering, which instead of extracting\npseudo-labels, just uses the classifier as a classifier: it ignores any\nsegmentation predictions from classes which the classifier is confident are not\npresent. Adding this simple post-processing method to baselines gives results\ncompetitive with or better than prior SWSSS algorithms. Moreover, it is\ncompatible with pseudo-label methods: adding prediction filtering to existing\nSWSSS algorithms further improves segmentation performance.",
    "descriptor": "",
    "authors": [
      "Wonho Bae",
      "Junhyug Noh",
      "Milad Jalali Asadabadi",
      "Danica J. Sutherland"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01233"
  },
  {
    "id": "arXiv:2205.01234",
    "title": "Scalable Tail Latency Estimation for Data Center Networks",
    "abstract": "In this paper, we consider how to provide fast estimates of flow-level tail\nlatency performance for very large scale data center networks. Network tail\nlatency is often a crucial metric for cloud application performance that can be\naffected by a wide variety of factors, including network load, inter-rack\ntraffic skew, traffic burstiness, flow size distributions, oversubscription,\nand topology asymmetry. Network simulators such as ns-3 and OMNeT++ can provide\naccurate answers, but are very hard to parallelize, taking hours or days to\nanswer what if questions for a single configuration at even moderate scale.\nRecent work with MimicNet has shown how to use machine learning to improve\nsimulation performance, but at a cost of including a long training step per\nconfiguration, and with assumptions about workload and topology uniformity that\ntypically do not hold in practice.\nWe address this gap by developing a set of techniques to provide fast\nperformance estimates for large scale networks with general traffic matrices\nand topologies. A key step is to decompose the problem into a large number of\nparallel independent single-link simulations; we carefully combine these\nlink-level simulations to produce accurate estimates of end-to-end flow level\nperformance distributions for the entire network. Like MimicNet, we exploit\nsymmetry where possible to gain additional speedups, but without relying on\nmachine learning, so there is no training delay. On large-scale networks where\nns-3 takes 11 to 27 hours to simulate five seconds of network behavior, our\ntechniques run in one to two minutes with 99th percentile accuracy within 9%\nfor flow completion times.",
    "descriptor": "",
    "authors": [
      "Kevin Zhao",
      "Prateesh Goyal",
      "Mohammad Alizadeh",
      "Thomas E. Anderson"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.01234"
  },
  {
    "id": "arXiv:2205.01235",
    "title": "Triangular Dropout: Variable Network Width without Retraining",
    "abstract": "One of the most fundamental design choices in neural networks is layer width:\nit affects the capacity of what a network can learn and determines the\ncomplexity of the solution. This latter property is often exploited when\nintroducing information bottlenecks, forcing a network to learn compressed\nrepresentations. However, such an architecture decision is typically immutable\nonce training begins; switching to a more compressed architecture requires\nretraining. In this paper we present a new layer design, called Triangular\nDropout, which does not have this limitation. After training, the layer can be\narbitrarily reduced in width to exchange performance for narrowness. We\ndemonstrate the construction and potential use cases of such a mechanism in\nthree areas. Firstly, we describe the formulation of Triangular Dropout in\nautoencoders, creating models with selectable compression after training.\nSecondly, we add Triangular Dropout to VGG19 on ImageNet, creating a powerful\nnetwork which, without retraining, can be significantly reduced in parameters.\nLastly, we explore the application of Triangular Dropout to reinforcement\nlearning (RL) policies on selected control problems.",
    "descriptor": "",
    "authors": [
      "Edward W. Staley",
      "Jared Markowitz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.01235"
  },
  {
    "id": "arXiv:2205.01240",
    "title": "Using Constraint Programming and Graph Representation Learning for  Generating Interpretable Cloud Security Policies",
    "abstract": "Modern software systems rely on mining insights from business sensitive data\nstored in public clouds. A data breach usually incurs significant (monetary)\nloss for a commercial organization. Conceptually, cloud security heavily relies\non Identity Access Management (IAM) policies that IT admins need to properly\nconfigure and periodically update. Security negligence and human errors often\nlead to misconfiguring IAM policies which may open a backdoor for attackers. To\naddress these challenges, first, we develop a novel framework that encodes\ngenerating optimal IAM policies using constraint programming (CP). We identify\nreducing dark permissions of cloud users as an optimality criterion, which\nintuitively implies minimizing unnecessary datastore access permissions.\nSecond, to make IAM policies interpretable, we use graph representation\nlearning applied to historical access patterns of users to augment our CP model\nwith similarity constraints: similar users should be grouped together and share\ncommon IAM policies. Third, we describe multiple attack models and show that\nour optimized IAM policies significantly reduce the impact of security attacks\nusing real data from 8 commercial organizations, and synthetic instances.",
    "descriptor": "\nComments: to be published in IJCAI/ECCAI'22\n",
    "authors": [
      "Mikhail Kazdagli",
      "Mohit Tiwari",
      "Akshat Kumar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01240"
  },
  {
    "id": "arXiv:2205.01241",
    "title": "Propositional Equality for Gradual Dependently Typed Programming",
    "abstract": "Gradual dependent types can help with the incremental adoption of dependently\ntyped code by providing a principled semantics for imprecise types and proofs,\nwhere some parts have been omitted. Current theories of gradual dependent\ntypes, though, lack a central feature of type theory: propositional equality.\nLennon-Bertrand et al. show that, when the reflexive proof $\\mathit{refl}$ is\nthe only closed value of an equality type, a gradual extension of CIC with\npropositional equality violates static observational equivalences.\nExtensionally-equal functions should be indistinguishable at run time, but the\ncombination of equality and type imprecision allows for contexts that\ndistinguish extensionally-equal but syntactically-different functions.\nThis work presents a gradually typed language that supports propositional\nequality. We avoid the above issues by devising an equality type where\n$\\mathit{refl}$ is not the only closed inhabitant. Instead, each equality proof\ncarries a term that is at least as precise as the equated terms, acting as a\nwitness of their plausible equality. These witnesses track partial type\ninformation as a program runs, raising errors when that information shows that\ntwo equated terms are undeniably inconsistent. Composition of type information\nis internalized as a construct of the language, and is deferred for function\nbodies whose evaluation is blocked by variables. By deferring, we ensure that\nextensionally equal functions compose without error, thereby preventing\ncontexts from distinguishing them. We describe the challenges of designing\nconsistency and precision relations for this system, along with solutions to\nthese challenges. Finally, we prove important metatheory: type-safety,\nconservative embedding of CIC, canonicity, and the gradual guarantees of Siek\net al.",
    "descriptor": "\nComments: Under submission to ICFP 2022\n",
    "authors": [
      "Joseph Eremondi",
      "Ronald Garcia",
      "\u00c9ric Tanter"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2205.01241"
  },
  {
    "id": "arXiv:2205.01242",
    "title": "Physics-Based Inverse Rendering using Combined Implicit and Explicit  Geometries",
    "abstract": "Mathematically representing the shape of an object is a key ingredient for\nsolving inverse rendering problems. Explicit representations like meshes are\nefficient to render in a differentiable fashion but have difficulties handling\ntopology changes. Implicit representations like signed-distance functions, on\nthe other hand, offer better support of topology changes but are much more\ndifficult to use for physics-based differentiable rendering. We introduce a new\nphysics-based inverse rendering pipeline that uses both implicit and explicit\nrepresentations. Our technique enjoys the benefit of both representations by\nsupporting both topology changes and differentiable rendering of complex\neffects such as environmental illumination, soft shadows, and interreflection.\nWe demonstrate the effectiveness of our technique using several synthetic and\nreal examples.",
    "descriptor": "",
    "authors": [
      "Guangyan Cai",
      "Kai Yan",
      "Zhao Dong",
      "Ioannis Gkioulekas",
      "Shuang Zhao"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2205.01242"
  },
  {
    "id": "arXiv:2205.01243",
    "title": "Meaningful Context, a Red Flag, or Both? Users' Preferences for Enhanced  Misinformation Warnings on Twitter",
    "abstract": "Warning users about misinformation on social media is not a simple usability\ntask. Soft moderation has to balance between debunking falsehoods and avoiding\nmoderation bias while preserving the social media consumption flow. Platforms\nthus employ minimally distinguishable warning tags with generic text under a\nsuspected misinformation content. This approach resulted in an unfavorable\noutcome where the warnings \"backfired\" and users believed the misinformation\nmore, not less. In response, we developed enhancements to the misinformation\nwarnings where users are advised on the context of the information hazard and\nexposed to standard warning iconography. We ran an A/B evaluation with the\nTwitter's original warning tags in a 337 participant usability study. The\nmajority of the participants preferred the enhancements as a nudge toward\nrecognizing and avoiding misinformation. The enhanced warning tags were most\nfavored by the politically left-leaning and to a lesser degree moderate\nparticipants, but they also appealed to roughly a third of the right-leaning\nparticipants. The education level was the only demographic factor shaping\nparticipants' preferences. We use our findings to propose user-tailored\nimprovements in the soft moderation of misinformation on social media.",
    "descriptor": "",
    "authors": [
      "Filipo Sharevski",
      "Amy Devine",
      "Emma Pieroni",
      "Peter Jacnim"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.01243"
  },
  {
    "id": "arXiv:2205.01247",
    "title": "Scheduling with Speed Predictions",
    "abstract": "Algorithms with predictions is a recent framework that has been used to\novercome pessimistic worst-case bounds in incomplete information settings. In\nthe context of scheduling, very recent work has leveraged machine-learned\npredictions to design algorithms that achieve improved approximation ratios in\nsettings where the processing times of the jobs are initially unknown. In this\npaper, we study the speed-robust scheduling problem where the speeds of the\nmachines, instead of the processing times of the jobs, are unknown and augment\nthis problem with predictions.\nOur main result is an algorithm that achieves a\n$\\min\\{\\eta^2(1+\\epsilon)^2(1+\\alpha), (1+\\epsilon)(2 + 2/\\alpha)\\}$\napproximation, for any constants $\\alpha, \\epsilon \\in (0,1)$, where $\\eta \\geq\n1$ is the prediction error. When the predictions are accurate, this\napproximation improves over the previously best known approximation of $2-1/m$\nfor speed-robust scheduling, where $m$ is the number of machines, while\nsimultaneously maintaining a worst-case approximation of $(1+\\epsilon)(2 +\n2/\\alpha)$ even when the predictions are wrong. In addition, we obtain improved\napproximations for the special cases of equal and infinitesimal job sizes, and\nwe complement our algorithmic results with lower bounds. Finally, we\nempirically evaluate our algorithm against existing algorithms for speed-robust\nscheduling.",
    "descriptor": "",
    "authors": [
      "Eric Balkanski",
      "Tingting Ou",
      "Clifford Stein",
      "Hao-Ting Wei"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01247"
  },
  {
    "id": "arXiv:2205.01252",
    "title": "SIMD$^2$: A Generalized Matrix Instruction Set for Accelerating Tensor  Computation beyond GEMM",
    "abstract": "Matrix-multiplication units (MXUs) are now prevalent in every computing\nplatform. The key attribute that makes MXUs so successful is the semiring\nstructure, which allows tiling for both parallelism and data reuse.\nNonetheless, matrix-multiplication is not the only algorithm with such\nattributes. We find that many algorithms share the same structure and differ in\nonly the core operation; for example, using add-minimum instead of\nmultiply-add. Algorithms with a semiring-like structure therefore have\npotential to be accelerated by a general-purpose matrix operation architecture,\ninstead of common MXUs.\nIn this paper, we propose SIMD$^2$, a new programming paradigm to support\ngeneralized matrix operations with a semiring-like structure. SIMD$^2$\ninstructions accelerate eight more types of matrix operations, in addition to\nmatrix multiplications. Since SIMD$^2$ instructions resemble a\nmatrix-multiplication instruction, we are able to build SIMD$^2$ architecture\non top of any MXU architecture with minimal modifications. We developed a\nframework that emulates and validates SIMD$^2$ using NVIDIA GPUs with Tensor\nCores. Across 8 applications, SIMD2 provides up to 38.59$\\times$ speedup and\nmore than 10.63$\\times$ on average over optimized CUDA programs, with only 5%\nof full-chip area overhead.",
    "descriptor": "\nComments: To Appear in the 49th International Symposium on Computer Architecture (ISCA'22), June 18--22, 2022, New York, NY, USA\n",
    "authors": [
      "Yunan Zhang",
      "Po-An Tsai",
      "Hung-Wei Tseng"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2205.01252"
  },
  {
    "id": "arXiv:2205.01253",
    "title": "Storyteller: The papers co-citing Sleeping Beauty and Prince before  awakening",
    "abstract": "In the Cumulative Advantage(CA) model, which is one of the most fundamental\napproaches to understand the mechanism of citation dynamics, papers receive\ncitations depending on how much they have been already cited. On the other\nhand, a substantial effect not included in CA is that some surprising\ndiscoveries suddenly acquire citations after a long time from publishing. This\nphenomenon is known as Sleeping Beauty(SB). Since disrupting discoveries need\nlong-time discussion by the research community to accept, SBs can capture\ninnovative findings and reveal the nature of disruptive scientific knowledge\nproduction. To research SBs citation burst mechanism, bibliometricians consider\nthe existence of the Prince(PR) for each SBs, which can be the trigger of SBs\nawakeness. For example, the discovery of Green Fluorescent Protein(GFP), which\ngot Nobel prize in chemistry, had been overlooked for 30 years until Chalfie\nand Tsien, who also received the prize, developed a method to use GFP as a\nmarker protein in genetic engineering. However, how does Chalfies and Tsiens\nresearch relight the hidden knowledge in the research community? If we can\nclarify such a mechanism rediscovering from nearly nothing, it can be helpful\nin science support and policy decision-making. This study proposes a\nStoryteller that focuses on the connection between SB and PR before SB gets\ncitation burst by co-citation. PR is found to be the paper awakening SB in\nretrospect, but it is not easy to detect it as the trigger of SBs awakeness at\nthe time of PR submission. We named the papers which co-cites SB and PR before\nthe citation burst of SB as Storyteller(ST) and analyze (1) how ST contributes\nto broadening the novelty of SB&PR connections and (2) how much ST leads the\ncitation burst after awakening.",
    "descriptor": "\nComments: preprint, submitted to ASIS&T SIG-MET Workshop, extended abstract\n",
    "authors": [
      "Takahiro Miura",
      "Ichiro Sakata"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2205.01253"
  },
  {
    "id": "arXiv:2205.01254",
    "title": "Deep API Learning Revisited",
    "abstract": "Understanding the correct API usage sequences is one of the most important\ntasks for programmers when they work with unfamiliar libraries. However,\nprogrammers often encounter obstacles to finding the appropriate information\ndue to either poor quality of API documentation or ineffective query-based\nsearching strategy. To help solve this issue, researchers have proposed various\nmethods to suggest the sequence of APIs given natural language queries\nrepresenting the information needs from programmers. Among such efforts, Gu et\nal. adopted a deep learning method, in particular an RNN Encoder-Decoder\narchitecture, to perform this task and obtained promising results on common\nAPIs in Java. In this work, we aim to reproduce their results and apply the\nsame methods for APIs in Python. Additionally, we compare the performance with\na more recent Transformer-based method, i.e., CodeBERT, for the same task. Our\nexperiment reveals a clear drop in performance measures when careful data\ncleaning is performed. Owing to the pretraining from a large number of source\ncode files and effective encoding technique, CodeBERT outperforms the method by\nGu et al., to a large extent.",
    "descriptor": "\nComments: 10 pages, 6 figures. This paper is accepted at ICPC 2022 (the 30th IEEE/ACM International Conference on Program Comprehension)\n",
    "authors": [
      "James Martin",
      "Jin L.C. Guo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.01254"
  },
  {
    "id": "arXiv:2205.01256",
    "title": "Hybrid Finite Difference Schemes for Elliptic Interface Problems with  Discontinuous and High-Contrast Variable Coefficients",
    "abstract": "For elliptic interface problems with discontinuous coefficients, the maximum\naccuracy order for compact 9-point finite difference scheme in irregular points\nis three [7]. The discontinuous coefficients usually have abrupt jumps across\nthe interface curve in the porous medium of realistic problems, causing the\npollution effect of numerical methods. So, to obtain a reasonable numerical\nsolution of the above problem, the higher order scheme and its effective\nimplementation are necessary. In this paper, we propose an efficient and\nflexible way to achieve the implementation of a hybrid (9-point scheme with\nsixth order accuracy for interior regular points and 13-point scheme with fifth\norder accuracy for interior irregular points) finite difference scheme in\nuniform meshes for the elliptic interface problems with discontinuous and\nhigh-contrast piecewise smooth coefficients in a rectangle $\\Omega$. We also\nderive the $6$-point and $4$-point finite difference schemes in uniform meshes\nwith sixth order accuracy for the side points and corner points of various\nmixed boundary conditions (Dirichlet, Neumann and Robin) of elliptic equations\nin a rectangle. Our numerical experiments confirm the flexibility and the sixth\norder accuracy in $l_2$ and $l_{\\infty}$ norms of the proposed hybrid scheme.",
    "descriptor": "\nComments: 23 pages, 12 figures\n",
    "authors": [
      "Qiwei Feng",
      "Bin Han",
      "Peter Minev"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.01256"
  },
  {
    "id": "arXiv:2205.01258",
    "title": "Universal Optimality and Robust Utility Bounds for Metric Differential  Privacy",
    "abstract": "We study the privacy-utility trade-off in the context of metric differential\nprivacy. Ghosh et al. introduced the idea of universal optimality to\ncharacterise the best mechanism for a certain query that simultaneously\nsatisfies (a fixed) $\\epsilon$-differential privacy constraint whilst at the\nsame time providing better utility compared to any other\n$\\epsilon$-differentially private mechanism for the same query. They showed\nthat the Geometric mechanism is \"universally optimal\" for the class of counting\nqueries. On the other hand, Brenner and Nissim showed that outside the space of\ncounting queries, and for the Bayes risk loss function, no such universally\noptimal mechanisms exist. In this paper we use metric differential privacy and\nquantitative information flow as the fundamental principle for studying\nuniversal optimality. Metric differential privacy is a generalisation of both\nstandard (i.e., central) differential privacy and local differential privacy,\nand it is increasingly being used in various application domains, for instance\nin location privacy and in privacy preserving machine learning. Using this\nframework we are able to clarify Nissim and Brenner's negative results, showing\n(a) that in fact all privacy types contain optimal mechanisms relative to\ncertain kinds of non-trivial loss functions, and (b) extending and generalising\ntheir negative results beyond Bayes risk specifically to a wide class of\nnon-trivial loss functions. We also propose weaker universal benchmarks of\nutility called \"privacy type capacities\". We show that such capacities always\nexist and can be computed using a convex optimisation algorithm.",
    "descriptor": "",
    "authors": [
      "Natasha Fernandes",
      "Annabelle McIver",
      "Catuscia Palamidessi",
      "Ming Ding"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.01258"
  },
  {
    "id": "arXiv:2205.01263",
    "title": "How Do Captions Affect Visualization Reading?",
    "abstract": "Captions help readers better understand visualizations. However, if the\nvisualization is intended to communicate specific features, should the caption\nbe statistical, and focus on specific values, or perceptual, and focus on\ngeneral patterns? Prior work has shown that when captions mention visually\nsalient features, users tend to recall those features. Still, we lack explicit\nguidelines for how to compose the appropriate caption. Further, what if the\nauthor wishes to emphasize a less salient feature?\nIn this paper, we study how the visual salience of the feature described in a\ncaption, and the semantic level of the caption description, affect a reader's\ntakeaways from line charts. For each single- or multi-line chart, we generate 4\ncaptions that 1) describe either the primary or secondary most salient feature\nin a chart, and 2) describe the feature either at the statistical or perceptual\nlevels. We then show users random chart-caption pairs and record their\ntakeaways.\nWe find that the primary salient feature is more memorable for single-line\ncharts when the caption is expressed at the statistical level; for secondary\nsalient features in single- and multi-line charts, the perceptual level is more\nmemorable. We also find that many users will tend to rely on erroneous data in\nthe caption and not double-check its veracity against the data in the chart.",
    "descriptor": "",
    "authors": [
      "Shelly Cheng",
      "Hazel Zhu",
      "Eugene Wu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.01263"
  },
  {
    "id": "arXiv:2205.01265",
    "title": "From {Solution Synthesis} to {Student Attempt Synthesis} for Block-Based  Visual Programming Tasks",
    "abstract": "Block-based visual programming environments are increasingly used to\nintroduce computing concepts to beginners. Given that programming tasks are\nopen-ended and conceptual, novice students often struggle when learning in\nthese environments. AI-driven programming tutors hold great promise in\nautomatically assisting struggling students, and need several components to\nrealize this potential. We investigate the crucial component of student\nmodeling, in particular, the ability to automatically infer students'\nmisconceptions for predicting (synthesizing) their behavior. We introduce a\nnovel benchmark, StudentSyn, centered around the following challenge: For a\ngiven student, synthesize the student's attempt on a new target task after\nobserving the student's attempt on a fixed reference task. This challenge is\nakin to that of program synthesis; however, instead of synthesizing a\n{solution} (i.e., program an expert would write), the goal here is to\nsynthesize a {student attempt} (i.e., program that a given student would\nwrite). We first show that human experts (TutorSS) can achieve high performance\non the benchmark, whereas simple baselines perform poorly. Then, we develop two\nneuro/symbolic techniques (NeurSS and SymSS) in a quest to close this gap with\nTutorSS. We will publicly release the benchmark to facilitate future research\nin this area.",
    "descriptor": "\nComments: Longer version of EDM 2022 paper\n",
    "authors": [
      "Adish Singla",
      "Nikitas Theodoropoulos"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01265"
  },
  {
    "id": "arXiv:2205.01267",
    "title": "PropEM-L: Radio Propagation Environment Modeling and Learning for  Communication-Aware Multi-Robot Exploration",
    "abstract": "Multi-robot exploration of complex, unknown environments benefits from the\ncollaboration and cooperation offered by inter-robot communication. Accurate\nradio signal strength prediction enables communication-aware exploration.\nModels which ignore the effect of the environment on signal propagation or rely\non a priori maps suffer in unknown, communication-restricted (e.g.\nsubterranean) environments. In this work, we present Propagation Environment\nModeling and Learning (PropEM-L), a framework which leverages real-time\nsensor-derived 3D geometric representations of an environment to extract\ninformation about line of sight between radios and attenuating walls/obstacles\nin order to accurately predict received signal strength (RSS). Our data-driven\napproach combines the strengths of well-known models of signal propagation\nphenomena (e.g. shadowing, reflection, diffraction) and machine learning, and\ncan adapt online to new environments. We demonstrate the performance of\nPropEM-L on a six-robot team in a communication-restricted environment with\nsubway-like, mine-like, and cave-like characteristics, constructed for the 2021\nDARPA Subterranean Challenge. Our findings indicate that PropEM-L can improve\nsignal strength prediction accuracy by up to 44% over a log-distance path loss\nmodel.",
    "descriptor": "\nComments: Robotics: Science and Systems 2022, 8 pages\n",
    "authors": [
      "Lillian Clark",
      "Jeffrey A. Edlund",
      "Marc Sanchez Net",
      "Tiago Stegun Vaquero",
      "Ali-akbar Agha-mohammadi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.01267"
  },
  {
    "id": "arXiv:2205.01271",
    "title": "Lite Pose: Efficient Architecture Design for 2D Human Pose Estimation",
    "abstract": "Pose estimation plays a critical role in human-centered vision applications.\nHowever, it is difficult to deploy state-of-the-art HRNet-based pose estimation\nmodels on resource-constrained edge devices due to the high computational cost\n(more than 150 GMACs per frame). In this paper, we study efficient architecture\ndesign for real-time multi-person pose estimation on edge. We reveal that\nHRNet's high-resolution branches are redundant for models at the\nlow-computation region via our gradual shrinking experiments. Removing them\nimproves both efficiency and performance. Inspired by this finding, we design\nLitePose, an efficient single-branch architecture for pose estimation, and\nintroduce two simple approaches to enhance the capacity of LitePose, including\nFusion Deconv Head and Large Kernel Convs. Fusion Deconv Head removes the\nredundancy in high-resolution branches, allowing scale-aware feature fusion\nwith low overhead. Large Kernel Convs significantly improve the model's\ncapacity and receptive field while maintaining a low computational cost. With\nonly 25% computation increment, 7x7 kernels achieve +14.0 mAP better than 3x3\nkernels on the CrowdPose dataset. On mobile platforms, LitePose reduces the\nlatency by up to 5.0x without sacrificing performance, compared with prior\nstate-of-the-art efficient pose estimation models, pushing the frontier of\nreal-time multi-person pose estimation on edge. Our code and pre-trained models\nare released at https://github.com/mit-han-lab/litepose.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Yihan Wang",
      "Muyang Li",
      "Han Cai",
      "Wei-Ming Chen",
      "Song Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01271"
  },
  {
    "id": "arXiv:2205.01273",
    "title": "Few-Shot Musical Source Separation",
    "abstract": "Deep learning-based approaches to musical source separation are often limited\nto the instrument classes that the models are trained on and do not generalize\nto separate unseen instruments. To address this, we propose a few-shot musical\nsource separation paradigm. We condition a generic U-Net source separation\nmodel using few audio examples of the target instrument. We train a few-shot\nconditioning encoder jointly with the U-Net to encode the audio examples into a\nconditioning vector to configure the U-Net via feature-wise linear modulation\n(FiLM). We evaluate the trained models on real musical recordings in the\nMUSDB18 and MedleyDB datasets. We show that our proposed few-shot conditioning\nparadigm outperforms the baseline one-hot instrument-class conditioned model\nfor both seen and unseen instruments. To extend the scope of our approach to a\nwider variety of real-world scenarios, we also experiment with different\nconditioning example characteristics, including examples from different\nrecordings, with multiple sources, or negative conditioning examples.",
    "descriptor": "\nComments: ICASSP 2022\n",
    "authors": [
      "Yu Wang",
      "Daniel Stoller",
      "Rachel M. Bittner",
      "Juan Pablo Bello"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.01273"
  },
  {
    "id": "arXiv:2205.01278",
    "title": "Real-time Cooperative Vehicle Coordination at Unsignalized Road  Intersections",
    "abstract": "Cooperative coordination at unsignalized road intersections, which aims to\nimprove the driving safety and traffic throughput for connected and automated\nvehicles, has attracted increasing interests in recent years. However, most\nexisting investigations either suffer from computational complexity or cannot\nharness the full potential of the road infrastructure. To this end, we first\npresent a dedicated intersection coordination framework, where the involved\nvehicles hand over their control authorities and follow instructions from a\ncentralized coordinator. Then a unified cooperative trajectory optimization\nproblem will be formulated to maximize the traffic throughput while ensuring\nthe driving safety and long-term stability of the coordination system. To\naddress the key computational challenges in the real-world deployment, we\nreformulate this non-convex sequential decision problem into a model-free\nMarkov Decision Process (MDP) and tackle it by devising a Twin Delayed Deep\nDeterministic Policy Gradient (TD3)-based strategy in the deep reinforcement\nlearning (DRL) framework. Simulation and practical experiments show that the\nproposed strategy could achieve near-optimal performance in sub-static\ncoordination scenarios and significantly improve the traffic throughput in the\nrealistic continuous traffic flow. The most remarkable advantage is that our\nstrategy could reduce the time complexity of computation to milliseconds, and\nis shown scalable when the road lanes increase.",
    "descriptor": "",
    "authors": [
      "Jiping Luo",
      "Tingting Zhang",
      "Rui Hao",
      "Donglin Li",
      "Chunsheng Chen",
      "Zhenyu Na",
      "Qinyu Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.01278"
  },
  {
    "id": "arXiv:2205.01283",
    "title": "Extending the View Composition Algebra to Hierarchical Data",
    "abstract": "Comparison is a core task in visual analysis. Although there are numerous\nguidelines to help users design effective visualizations to aid known\ncomparison tasks, there are few formalisms that define the semantics of\ncomparison operations in a way that can serve as the basis for a grammar of\ncomparison interactions. Recent work proposed a formalism called View\nComposition Algebra (VCA) that enables ad hoc comparisons between any\ncombination of marks, trends, or charts in a visualization interface. However,\nVCA limits comparisons to visual representations of data that have an identical\nschema, or where the schemas form a strict subset relationship (e.g., comparing\nprice per state with price, but not with price per county). In contrast, the\nmajority of real-world data - temporal, geographical, organizational - are\nhierarchical.\nTo bridge this gap, this paper presents an extension to VCA (called VCAH)\nthat enables ad hoc comparisons between visualizations of hierarchical data.\nVCAH leverages known hierarchical relationships to enable ad hoc comparison of\ndata at different hierarchical granularities. We illustrate applications to\nhierarchical and Tableau visualizations.",
    "descriptor": "",
    "authors": [
      "Eugene Wu"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.01283"
  },
  {
    "id": "arXiv:2205.01284",
    "title": "Scalable Private Decision Tree Evaluation with Sublinear Communication",
    "abstract": "Private decision tree evaluation (PDTE) allows a decision tree holder to run\na secure protocol with a feature provider. By running the protocol, the feature\nprovider will learn a classification result. Nothing more is revealed to either\nparty. In most existing PDTE protocols, the required communication grows\nexponentially with the tree's depth $d$, which is highly inefficient for large\ntrees. This shortcoming motivated us to design a sublinear PDTE protocol with\n$O(d)$ communication complexity. The core of our construction is a shared\noblivious selection (SOS) functionality, allowing two parties to perform a\nsecret-shared oblivious read operation from an array. We provide two SOS\nprotocols, both of which achieve sublinear communication and propose\noptimizations to further improve their efficiency. Our sublinear PDTE protocol\nis based on the proposed SOS functionality and we prove its security under a\nsemi-honest adversary. We compare our protocol with the state-of-the-art, in\nterms of communication and computation, under various network settings. The\nperformance evaluation shows that our protocol is practical and more scalable\nover large trees than existing solutions.",
    "descriptor": "",
    "authors": [
      "Jianli Bai",
      "Xiangfu Song",
      "Shujie Cui",
      "Ee-Chien Chang",
      "Giovanni Russello"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.01284"
  },
  {
    "id": "arXiv:2205.01286",
    "title": "When Multi-Level Meets Multi-Interest: A Multi-Grained Neural Model for  Sequential Recommendation",
    "abstract": "Sequential recommendation aims at identifying the next item that is preferred\nby a user based on their behavioral history. Compared to conventional\nsequential models that leverage attention mechanisms and RNNs, recent efforts\nmainly follow two directions for improvement: multi-interest learning and graph\nconvolutional aggregation. Specifically, multi-interest methods such as ComiRec\nand MIMN, focus on extracting different interests for a user by performing\nhistorical item clustering, while graph convolution methods including TGSRec\nand SURGE elect to refine user preferences based on multi-level correlations\nbetween historical items. Unfortunately, neither of them realizes that these\ntwo types of solutions can mutually complement each other, by aggregating\nmulti-level user preference to achieve more precise multi-interest extraction\nfor a better recommendation. To this end, in this paper, we propose a unified\nmulti-grained neural model(named MGNM) via a combination of multi-interest\nlearning and graph convolutional aggregation. Concretely, MGNM first learns the\ngraph structure and information aggregation paths of the historical items for a\nuser. It then performs graph convolution to derive item representations in an\niterative fashion, in which the complex preferences at different levels can be\nwell captured. Afterwards, a novel sequential capsule network is proposed to\ninject the sequential patterns into the multi-interest extraction process,\nleading to a more precise interest learning in a multi-grained manner.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Yu Tian",
      "Jianxin Chang",
      "Yannan Niu",
      "Yang Song",
      "Chenliang Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.01286"
  },
  {
    "id": "arXiv:2205.01287",
    "title": "SemAttack: Natural Textual Attacks via Different Semantic Spaces",
    "abstract": "Recent studies show that pre-trained language models (LMs) are vulnerable to\ntextual adversarial attacks. However, existing attack methods either suffer\nfrom low attack success rates or fail to search efficiently in the\nexponentially large perturbation space. We propose an efficient and effective\nframework SemAttack to generate natural adversarial text by constructing\ndifferent semantic perturbation functions. In particular, SemAttack optimizes\nthe generated perturbations constrained on generic semantic spaces, including\ntypo space, knowledge space (e.g., WordNet), contextualized semantic space\n(e.g., the embedding space of BERT clusterings), or the combination of these\nspaces. Thus, the generated adversarial texts are more semantically close to\nthe original inputs. Extensive experiments reveal that state-of-the-art (SOTA)\nlarge-scale LMs (e.g., DeBERTa-v2) and defense strategies (e.g., FreeLB) are\nstill vulnerable to SemAttack. We further demonstrate that SemAttack is general\nand able to generate natural adversarial texts for different languages (e.g.,\nEnglish and Chinese) with high attack success rates. Human evaluations also\nconfirm that our generated adversarial texts are natural and barely affect\nhuman performance. Our code is publicly available at\nhttps://github.com/AI-secure/SemAttack.",
    "descriptor": "\nComments: Published at Findings of NAACL 2022\n",
    "authors": [
      "Boxin Wang",
      "Chejian Xu",
      "Xiangyu Liu",
      "Yu Cheng",
      "Bo Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01287"
  },
  {
    "id": "arXiv:2205.01289",
    "title": "On Ranking Consistency of Pre-ranking Stage",
    "abstract": "Industrial ranking systems, such as advertising systems, rank items by\naggregating multiple objectives into one final objective to satisfy user demand\nand commercial intent. Cascade architecture, composed of retrieval,\npre-ranking, and ranking stages, is usually adopted to reduce the computational\ncost. Each stage may employ various models for different objectives and\ncalculate the final objective by aggregating these models' outputs. The\nmulti-stage ranking strategy causes a new problem - the ranked lists of the\nranking stage and previous stages may be inconsistent. For example, items that\nshould be ranked at the top of the ranking stage may be ranked at the bottom of\nprevious stages. In this paper, we focus on the ranking consistency between the\npre-ranking and ranking stages. Specifically, we formally define the problem of\nranking consistency and propose the Ranking Consistency Score (RCS) metric for\nevaluation. We demonstrate that ranking consistency has a direct impact on\nonline performance. Compared with the traditional evaluation manner that mainly\nfocuses on the individual ranking quality of every objective, RCS considers the\nranking consistency of the fused final objective, which is more proper for\nevaluation. Finally, to improve the ranking consistency, we propose several\nmethods from the perspective of sample selection and learning algorithms.\nExperimental results on industrial datasets validate the efficacy of the\nproposed metrics and methods. The proposed consistency methods have been\ndeployed on the display advertising system of Alibaba, obtaining a 6.7%\nimprovement on CTR (Click-Through Rate) and a 5.5% increase on RPM (Revenue Per\nMille).",
    "descriptor": "\nComments: 9 pagees, 5 figures\n",
    "authors": [
      "Siyu Gu",
      "Xiang-Rong Sheng",
      "Biye Jiang",
      "Siyuan Lou",
      "Shuguang Han",
      "Hongbo Deng",
      "Bo Zheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.01289"
  },
  {
    "id": "arXiv:2205.01290",
    "title": "DrugEHRQA: A Question Answering Dataset on Structured and Unstructured  Electronic Health Records For Medicine Related Queries",
    "abstract": "This paper develops the first question answering dataset (DrugEHRQA)\ncontaining question-answer pairs from both structured tables and unstructured\nnotes from a publicly available Electronic Health Record (EHR). EHRs contain\npatient records, stored in structured tables and unstructured clinical notes.\nThe information in structured and unstructured EHRs is not strictly disjoint:\ninformation may be duplicated, contradictory, or provide additional context\nbetween these sources. Our dataset has medication-related queries, containing\nover 70,000 question-answer pairs. To provide a baseline model and help analyze\nthe dataset, we have used a simple model (MultimodalEHRQA) which uses the\npredictions of a modality selection network to choose between EHR tables and\nclinical notes to answer the questions. This is used to direct the questions to\nthe table-based or text-based state-of-the-art QA model. In order to address\nthe problem arising from complex, nested queries, this is the first time\nRelation-Aware Schema Encoding and Linking for Text-to-SQL Parsers (RAT-SQL)\nhas been used to test the structure of query templates in EHR data. Our goal is\nto provide a benchmark dataset for multi-modal QA systems, and to open up new\navenues of research in improving question answering over EHR structured data by\nusing context from unstructured clinical data.",
    "descriptor": "\nComments: 15 pages (including Appendix section), 7 figures\n",
    "authors": [
      "Jayetri Bardhan",
      "Anthony Colas",
      "Kirk Roberts",
      "Daisy Zhe Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01290"
  },
  {
    "id": "arXiv:2205.01291",
    "title": "Cross Domain Object Detection by Target-Perceived Dual Branch  Distillation",
    "abstract": "Cross domain object detection is a realistic and challenging task in the\nwild. It suffers from performance degradation due to large shift of data\ndistributions and lack of instance-level annotations in the target domain.\nExisting approaches mainly focus on either of these two difficulties, even\nthough they are closely coupled in cross domain object detection. To solve this\nproblem, we propose a novel Target-perceived Dual-branch Distillation (TDD)\nframework. By integrating detection branches of both source and target domains\nin a unified teacher-student learning scheme, it can reduce domain shift and\ngenerate reliable supervision effectively. In particular, we first introduce a\ndistinct Target Proposal Perceiver between two domains. It can adaptively\nenhance source detector to perceive objects in a target image, by leveraging\ntarget proposal contexts from iterative cross-attention. Afterwards, we design\na concise Dual Branch Self Distillation strategy for model training, which can\nprogressively integrate complementary object knowledge from different domains\nvia self-distillation in two branches. Finally, we conduct extensive\nexperiments on a number of widely-used scenarios in cross domain object\ndetection. The results show that our TDD significantly outperforms the\nstate-of-the-art methods on all the benchmarks. Our code and model will be\navailable at https://github.com/Feobi1999/TDD.",
    "descriptor": "\nComments: CVPR2022\n",
    "authors": [
      "Mengzhe He",
      "Yali Wang",
      "Jiaxi Wu",
      "Yiru Wang",
      "Hanqing Li",
      "Bo Li",
      "Weihao Gan",
      "Wei Wu",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01291"
  },
  {
    "id": "arXiv:2205.01293",
    "title": "A Survey of Deep Learning Models for Structural Code Understanding",
    "abstract": "In recent years, the rise of deep learning and automation requirements in the\nsoftware industry has elevated Intelligent Software Engineering to new heights.\nThe number of approaches and applications in code understanding is growing,\nwith deep learning techniques being used in many of them to better capture the\ninformation in code data. In this survey, we present a comprehensive overview\nof the structures formed from code data. We categorize the models for\nunderstanding code in recent years into two groups: sequence-based and\ngraph-based models, further make a summary and comparison of them. We also\nintroduce metrics, datasets and the downstream tasks. Finally, we make some\nsuggestions for future research in structural code understanding field.",
    "descriptor": "\nComments: 48 pages, 4 figures\n",
    "authors": [
      "Ruoting Wu",
      "Yuxin Zhang",
      "Qibiao Peng",
      "Liang Chen",
      "Zibin Zheng"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "General Literature (cs.GL)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2205.01293"
  },
  {
    "id": "arXiv:2205.01296",
    "title": "Visual Knowledge Discovery with Artificial Intelligence: Challenges and  Future Directions",
    "abstract": "This volume is devoted to the emerging field of Integrated Visual Knowledge\nDiscovery that combines advances in Artificial Intelligence/Machine Learning\n(AI/ML) and Visualization/Visual Analytics. Chapters included are extended\nversions of the selected AI and Visual Analytics papers and related symposia at\nthe recent International Information Visualization Conferences (IV2019 and\nIV2020). AI/ML face a long-standing challenge of explaining models to humans.\nModels explanation is fundamentally human activity, not only an algorithmic\none. In this chapter we aim to present challenges and future directions within\nthe field of Visual Analytics, Visual Knowledge Discovery and AI/ML, and to\ndiscuss the role of visualization in visual AI/ML. In addition, we describe\nprogress in emerging Full 2D ML, natural language processing, and AI/ML in\nmultidimensional data aided by visual means.",
    "descriptor": "",
    "authors": [
      "Boris Kovalerchuk",
      "R\u0103zvan Andonie",
      "Nuno Datia",
      "Kawa Nazemi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01296"
  },
  {
    "id": "arXiv:2205.01297",
    "title": "RU-Net: Regularized Unrolling Network for Scene Graph Generation",
    "abstract": "Scene graph generation (SGG) aims to detect objects and predict the\nrelationships between each pair of objects. Existing SGG methods usually suffer\nfrom several issues, including 1) ambiguous object representations, as graph\nneural network-based message passing (GMP) modules are typically sensitive to\nspurious inter-node correlations, and 2) low diversity in relationship\npredictions due to severe class imbalance and a large number of missing\nannotations. To address both problems, in this paper, we propose a regularized\nunrolling network (RU-Net). We first study the relation between GMP and graph\nLaplacian denoising (GLD) from the perspective of the unrolling technique,\ndetermining that GMP can be formulated as a solver for GLD. Based on this\nobservation, we propose an unrolled message passing module and introduce an\n$\\ell_p$-based graph regularization to suppress spurious connections between\nnodes. Second, we propose a group diversity enhancement module that promotes\nthe prediction diversity of relationships via rank maximization. Systematic\nexperiments demonstrate that RU-Net is effective under a variety of settings\nand metrics. Furthermore, RU-Net achieves new state-of-the-arts on three\npopular databases: VG, VRD, and OI. Code is available at\nhttps://github.com/siml3/RU-Net.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Xin Lin",
      "Changxing Ding",
      "Jing Zhang",
      "Yibing Zhan",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01297"
  },
  {
    "id": "arXiv:2205.01300",
    "title": "Towards an Ensemble Regressor Model for Anomalous ISP Traffic Prediction",
    "abstract": "Prediction of network traffic behavior is significant for the effective\nmanagement of modern telecommunication networks. However, the intuitive\napproach of predicting network traffic using administrative experience and\nmarket analysis data is inadequate for an efficient forecast framework. As a\nresult, many different mathematical models have been studied to capture the\ngeneral trend of the network traffic and predict accordingly. But the\ncomprehensive performance analysis of varying regression models and their\nensemble has not been studied before for analyzing real-world anomalous\ntraffic. In this paper, several regression models such as Extra Gradient Boost\n(XGBoost), Light Gradient Boosting Machine (LightGBM), Stochastic Gradient\nDescent (SGD), Gradient Boosting Regressor (GBR), and CatBoost Regressor were\nanalyzed to predict real traffic without and with outliers and show the\nsignificance of outlier detection in real-world traffic prediction. Also, we\nshowed the outperformance of the ensemble regression model over the individual\nprediction model. We compared the performance of different regression models\nbased on five different feature sets of lengths 6, 9, 12, 15, and 18. Our\nensemble regression model achieved the minimum average gap of 5.04% between\nactual and predicted traffic with nine outlier-adjusted inputs. In general, our\nexperimental results indicate that the outliers in the data can significantly\nimpact the quality of the prediction. Thus, outlier detection and mitigation\nassist the regression model in learning the general trend and making better\npredictions.",
    "descriptor": "\nComments: 7 pages, 7 figures, To appear in the proceedings on International Symposium on Networks, Computers and Communications in China, from July 19 to 22, 2022\n",
    "authors": [
      "Sajal Saha",
      "Anwar Haque",
      "Greg Sidebottom"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.01300"
  },
  {
    "id": "arXiv:2205.01302",
    "title": "Capacity Variation in the Many-to-one Stable Matching",
    "abstract": "The many-to-one stable matching problem provides the fundamental abstraction\nof several real-world matching markets such as school choice and\nhospital-resident allocation. The agents on both sides are often referred to as\nresidents and hospitals. The classical setup assumes that the agents rank the\nopposite side and that the capacities of the hospitals are fixed. It is known\nthat increasing the capacity of a single hospital improves the residents' final\nallocation. On the other hand, reducing the capacity of a single hospital\ndeteriorates the residents' allocation. In this work, we study the\ncomputational complexity of finding the optimal variation of hospitals'\ncapacities that leads to the best outcome for the residents, subject to\nstability and a capacity variation constraint. First, we show that the decision\nproblem of finding the optimal capacity expansion is NP-complete and the\ncorresponding optimization problem is inapproximable within a certain factor.\nThis result holds under strict and complete preferences, and even if we\nallocate extra capacities to disjoint sets of hospitals. Second, we obtain\nanalogous computational complexity results for the problem of capacity\nreduction. Finally, we study the variants of these problems when the goal is to\nmaximize the size of the final matching under incomplete preference lists.",
    "descriptor": "",
    "authors": [
      "Federico Bobbio",
      "Margarida Carvalho",
      "Andrea Lodi",
      "Alfredo Torrico"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2205.01302"
  },
  {
    "id": "arXiv:2205.01306",
    "title": "CANShield: Signal-based Intrusion Detection for Controller Area Networks",
    "abstract": "Modern vehicles rely on a fleet of electronic control units (ECUs) connected\nthrough controller area network (CAN) buses for critical vehicular control.\nHowever, with the expansion of advanced connectivity features in automobiles\nand the elevated risks of internal system exposure, the CAN bus is increasingly\nprone to intrusions and injection attacks. The ordinary injection attacks\ndisrupt the typical timing properties of the CAN data stream, and the\nrule-based intrusion detection systems (IDS) can easily detect them. However,\nadvanced attackers can inject false data to the time series sensory data\n(signal), while looking innocuous by the pattern/frequency of the CAN messages.\nSuch attacks can bypass the rule-based IDS or any anomaly-based IDS built on\nbinary payload data. To make the vehicles robust against such intelligent\nattacks, we propose CANShield, a signal-based intrusion detection framework for\nthe CAN bus. CANShield consists of three modules: a data preprocessing module\nthat handles the high-dimensional CAN data stream at the signal level and makes\nthem suitable for a deep learning model; a data analyzer module consisting of\nmultiple deep autoencoder (AE) networks, each analyzing the time-series data\nfrom a different temporal perspective; and finally an attack detection module\nthat uses an ensemble method to make the final decision. Evaluation results on\ntwo high-fidelity signal-based CAN attack datasets show the high accuracy and\nresponsiveness of CANShield in detecting wide-range of advanced intrusion\nattacks.",
    "descriptor": "\nComments: 15 pages, 6 figures, A version of this paper is accepted by escar USA 2022\n",
    "authors": [
      "Md Hasan Shahriar",
      "Yang Xiao",
      "Pablo Moriano",
      "Wenjing Lou",
      "Y. Thomas Hou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01306"
  },
  {
    "id": "arXiv:2205.01307",
    "title": "Embedding Hallucination for Few-Shot Language Fine-tuning",
    "abstract": "Few-shot language learners adapt knowledge from a pre-trained model to\nrecognize novel classes from a few-labeled sentences. In such settings,\nfine-tuning a pre-trained language model can cause severe over-fitting. In this\npaper, we propose an Embedding Hallucination (EmbedHalluc) method, which\ngenerates auxiliary embedding-label pairs to expand the fine-tuning dataset.\nThe hallucinator is trained by playing an adversarial game with the\ndiscriminator, such that the hallucinated embedding is indiscriminative to the\nreal ones in the fine-tuning dataset. By training with the extended dataset,\nthe language learner effectively learns from the diverse hallucinated\nembeddings to overcome the over-fitting issue. Experiments demonstrate that our\nproposed method is effective in a wide range of language tasks, outperforming\ncurrent fine-tuning methods. Further, we show that EmbedHalluc outperforms\nother methods that address this over-fitting problem, such as common data\naugmentation, semi-supervised pseudo-labeling, and regularization. The code\nwill be made available at: https://github.com/yiren-jian/EmbedHalluc.",
    "descriptor": "\nComments: accepted to NAACL 2022\n",
    "authors": [
      "Yiren Jian",
      "Chongyang Gao",
      "Soroush Vosoughi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01307"
  },
  {
    "id": "arXiv:2205.01308",
    "title": "Contrastive Learning for Prompt-Based Few-Shot Language Learners",
    "abstract": "The impressive performance of GPT-3 using natural language prompts and\nin-context learning has inspired work on better fine-tuning of moderately-sized\nmodels under this paradigm. Following this line of work, we present a\ncontrastive learning framework that clusters inputs from the same class for\nbetter generality of models trained with only limited examples. Specifically,\nwe propose a supervised contrastive framework that clusters inputs from the\nsame class under different augmented \"views\" and repel the ones from different\nclasses. We create different \"views\" of an example by appending it with\ndifferent language prompts and contextual demonstrations. Combining a\ncontrastive loss with the standard masked language modeling (MLM) loss in\nprompt-based few-shot learners, the experimental results show that our method\ncan improve over the state-of-the-art methods in a diverse set of 15 language\ntasks. Our framework makes minimal assumptions on the task or the base model,\nand can be applied to many recent methods with little modification. The code\nwill be made available at: https://github.com/yiren-jian/LM-SupCon.",
    "descriptor": "\nComments: accepted to NAACL 2022\n",
    "authors": [
      "Yiren Jian",
      "Chongyang Gao",
      "Soroush Vosoughi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01308"
  },
  {
    "id": "arXiv:2205.01310",
    "title": "FedRN: Exploiting k-Reliable Neighbors Towards Robust Federated Learning",
    "abstract": "Robustness is becoming another important challenge of federated learning in\nthat the data collection process in each client is naturally accompanied by\nnoisy labels. However, it is far more complex and challenging owing to varying\nlevels of data heterogeneity and noise over clients, which exacerbates the\nclient-to-client performance discrepancy. In this work, we propose a robust\nfederated learning method called FedRN, which exploits k-reliable neighbors\nwith high data expertise or similarity. Our method helps mitigate the gap\nbetween low- and high-performance clients by training only with a selected set\nof clean examples, identified by their ensembled mixture models. We demonstrate\nthe superiority of FedRN via extensive evaluations on three real-world or\nsynthetic benchmark datasets. Compared with existing robust training methods,\nthe results show that FedRN significantly improves the test accuracy in the\npresence of noisy labels.",
    "descriptor": "",
    "authors": [
      "SangMook Kim",
      "Wonyoung Shin",
      "Soohyuk Jang",
      "Hwanjun Song",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01310"
  },
  {
    "id": "arXiv:2205.01311",
    "title": "Automatically Debugging AutoML Pipelines Using Maro: ML Automated  Remediation Oracle (Extended Version)",
    "abstract": "Machine learning in practice often involves complex pipelines for data\ncleansing, feature engineering, preprocessing, and prediction. These pipelines\nare composed of operators, which have to be correctly connected and whose\nhyperparameters must be correctly configured. Unfortunately, it is quite common\nfor certain combinations of datasets, operators, or hyperparameters to cause\nfailures. Diagnosing and fixing those failures is tedious and error-prone and\ncan seriously derail a data scientist's workflow. This paper describes an\napproach for automatically debugging an ML pipeline, explaining the failures,\nand producing a remediation. We implemented our approach, which builds on a\ncombination of AutoML and SMT, in a tool called Maro. Maro works seamlessly\nwith the familiar data science ecosystem including Python, Jupyter notebooks,\nscikit-learn, and AutoML tools such as Hyperopt. We empirically evaluate our\ntool and find that for most cases, a single remediation automatically fixes\nerrors, produces no additional faults, and does not significantly impact\noptimal accuracy nor time to convergence.",
    "descriptor": "\nComments: Extended version of MAPS 2022 paper\n",
    "authors": [
      "Julian Dolby",
      "Jason Tsay",
      "Martin Hirzel"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.01311"
  },
  {
    "id": "arXiv:2205.01313",
    "title": "cuPSO: GPU Parallelization for Particle Swarm Optimization Algorithms",
    "abstract": "Particle Swarm Optimization (PSO) is a stochastic technique for solving the\noptimization problem. Attempts have been made to shorten the computation times\nof PSO based algorithms with massive threads on GPUs (graphic processing\nunits), where thread groups are formed to calculate the information of\nparticles and the computed outputs for the particles are aggregated and\nanalyzed to find the best solution. In particular, the reduction-based method\nis considered as a common approach to handle the data aggregation and analysis\nfor the calculated particle information. Nevertheless, based on our analysis,\nthe reduction-based method would suffer from excessive memory accesses and\nthread synchronization overheads. In this paper, we propose a novel algorithm\nto alleviate the above overheads with the atomic functions. The threads within\na thread group update the calculated results atomically to the intra-group data\nqueue conditionally, which prevents the frequent accesses to the memory as done\nby the parallel reduction operations. Furthermore, we develop an enhanced\nversion of the algorithm to alleviate the synchronization barrier among the\nthread groups, which is achieved by allowing the thread groups to run\nasynchronously and updating to the global, lock-protected variables\noccasionally if necessary. Our experimental results show that our proposed\nalgorithm running on the Nvidia GPU is about 200 times faster than the serial\nversion executed by the Intel Xeon CPU. Moreover, the novel algorithm\noutperforms the state-of-the-art method (the parallel reduction approach) by a\nfactor of 2.2.",
    "descriptor": "\nComments: Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s)\n",
    "authors": [
      "Chuan-Chi Wang",
      "Chun-Yen Ho",
      "Chia-Heng Tu",
      "Shih-Hao Hung"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2205.01313"
  },
  {
    "id": "arXiv:2205.01314",
    "title": "Distilling Governing Laws and Source Input for Dynamical Systems from  Videos",
    "abstract": "Distilling interpretable physical laws from videos has led to expanded\ninterest in the computer vision community recently thanks to the advances in\ndeep learning, but still remains a great challenge. This paper introduces an\nend-to-end unsupervised deep learning framework to uncover the explicit\ngoverning equations of dynamics presented by moving object(s), based on\nrecorded videos. Instead in the pixel (spatial) coordinate system of image\nspace, the physical law is modeled in a regressed underlying physical\ncoordinate system where the physical states follow potential explicit governing\nequations. A numerical integrator-based sparse regression module is designed\nand serves as a physical constraint to the autoencoder and coordinate system\nregression, and, in the meanwhile, uncover the parsimonious closed-form\ngoverning equations from the learned physical states. Experiments on simulated\ndynamical scenes show that the proposed method is able to distill closed-form\ngoverning equations and simultaneously identify unknown excitation input for\nseveral dynamical systems recorded by videos, which fills in the gap in\nliterature where no existing methods are available and applicable for solving\nthis type of problem.",
    "descriptor": "\nComments: 7 pages, 6 figures, IJCAI-2022. arXiv admin note: text overlap with arXiv:2106.04776\n",
    "authors": [
      "Lele Luan",
      "Yang Liu",
      "Hao Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.01314"
  },
  {
    "id": "arXiv:2205.01316",
    "title": "HL-Net: Heterophily Learning Network for Scene Graph Generatio",
    "abstract": "Scene graph generation (SGG) aims to detect objects and predict their\npairwise relationships within an image. Current SGG methods typically utilize\ngraph neural networks (GNNs) to acquire context information between\nobjects/relationships. Despite their effectiveness, however, current SGG\nmethods only assume scene graph homophily while ignoring heterophily.\nAccordingly, in this paper, we propose a novel Heterophily Learning Network\n(HL-Net) to comprehensively explore the homophily and heterophily between\nobjects/relationships in scene graphs. More specifically, HL-Net comprises the\nfollowing 1) an adaptive reweighting transformer module, which adaptively\nintegrates the information from different layers to exploit both the\nheterophily and homophily in objects; 2) a relationship feature propagation\nmodule that efficiently explores the connections between relationships by\nconsidering heterophily in order to refine the relationship representation; 3)\na heterophily-aware message-passing scheme to further distinguish the\nheterophily and homophily between objects/relationships, thereby facilitating\nimproved message passing in graphs. We conducted extensive experiments on two\npublic datasets: Visual Genome (VG) and Open Images (OI). The experimental\nresults demonstrate the superiority of our proposed HL-Net over existing\nstate-of-the-art approaches. In more detail, HL-Net outperforms the second-best\ncompetitors by 2.1$\\%$ on the VG dataset for scene graph classification and\n1.2$\\%$ on the IO dataset for the final score. Code is available at\nhttps://github.com/siml3/HL-Net.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Xin Lin",
      "Changxing Ding",
      "Yibing Zhan",
      "Zijian Li",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01316"
  },
  {
    "id": "arXiv:2205.01324",
    "title": "Learning Discrete Structured Variational Auto-Encoder using Natural  Evolution Strategies",
    "abstract": "Discrete variational auto-encoders (VAEs) are able to represent semantic\nlatent spaces in generative learning. In many real-life settings, the discrete\nlatent space consists of high-dimensional structures, and propagating gradients\nthrough the relevant structures often requires enumerating over an\nexponentially large latent space. Recently, various approaches were devised to\npropagate approximated gradients without enumerating over the space of possible\nstructures. In this work, we use Natural Evolution Strategies (NES), a class of\ngradient-free black-box optimization algorithms, to learn discrete structured\nVAEs. The NES algorithms are computationally appealing as they estimate\ngradients with forward pass evaluations only, thus they do not require to\npropagate gradients through their discrete structures. We demonstrate\nempirically that optimizing discrete structured VAEs using NES is as effective\nas gradient-based approximations. Lastly, we prove NES converges for\nnon-Lipschitz functions as appear in discrete structured VAEs.",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2022\n",
    "authors": [
      "Alon Berliner",
      "Guy Rotman",
      "Yossi Adi",
      "Roi Reichart",
      "Tamir Hazan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.01324"
  },
  {
    "id": "arXiv:2205.01331",
    "title": "GRAPHYP: A Scientific Knowledge Graph with Manifold Subnetworks of  Communities. Detection of Scholarly Disputes in Adversarial Information  Routes",
    "abstract": "The cognitive manifold of published content is currently expanding in all\nareas of science. However, Scientific Knowledge Graphs (SKGs) only provide poor\npictures of the adversarial directions and scientific controversies that feed\nthe production of knowledge. In this Article, we tackle the understanding of\nthe design of the information space of a cognitive representation of research\nactivities, and of related bottlenecks that affect search interfaces, in the\nmapping of structured objects into graphs. We propose, with SKG GRAPHYP, a\nnovel graph designed geometric architecture which optimizes both the detection\nof the knowledge manifold of \"cognitive communities\", and the representation of\nalternative paths to adversarial answers to a research question, for instance\nin the context of academic disputes. With a methodology for designing \"Manifold\nSubnetworks of Cognitive Communities\", GRAPHYP provides a classification of\ndistinct search paths in a research field. Users are detected from the variety\nof their search practices and classified in \"Cognitive communities\" from the\nanalysis of the search history of their logs of scientific documentation. The\nmanifold of practices is expressed from metrics of differentiated uses by\ntriplets of nodes shaped into symmetrical graph subnetworks, with the following\nthree parameters: Mass, Intensity, and Variety.",
    "descriptor": "",
    "authors": [
      "Renaud Fabre",
      "Otmane Azeroual",
      "Patrice Bellot",
      "Joachim Sch\u00f6pfel",
      "Daniel Egret"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01331"
  },
  {
    "id": "arXiv:2205.01333",
    "title": "Engineering Annotations: A Generic Framework For Gluing Design Artefacts  in Models of Interactive Systems",
    "abstract": "Along the design process of interactive system many intermediate artefacts\n(such as user interface prototypes, task models describing user work and\nactivities, dialog models specifying system behavior, interaction models\ndescribing user interactions {\\ldots}) are created, tested, revised and\nimproved until the development team produces a validated version of the\nfull-fledged system. Indeed, to build interactive systems there is a need to\nuse multiple artefacts/models (as they provide a complementary view). However,\nrelevant information for describing the design solution and/or supporting\ndesign decisions (such as rational about the design, decisions made,\nrecommendations, etc.) is not explicitly capturable in the models/artefacts,\nhence the need for annotations. Multi-artefacts approaches usually argue that a\ngiven information should only be present in one artefact to avoid duplication\nand increase maintainability of the artefacts. Nonetheless, annotations created\non one artefact are usually relevant to other artefacts/models. So that, there\nis a need for tools and techniques to coordinate annotations across\nartefacts/models which is the contribution of the present work. In this paper,\nwe propose a model-based approach that was conceived to handle annotations in a\nsystematic way along the development process of interactive systems. As part of\nthe solution, we propose an annotation model built upon the W3C's Web\nAnnotation Data Model. The feasibility of the approach is demonstrated by means\nof a tool suite featuring a plugin, which has been deployed and tested over the\nmulti-artefacts. The overall approach is illustrated on the design of an\ninteractive cockpit application performing two design iterations. The\ncontribution brings two main benefits for interactive systems engineering: i)\nit presents a generic pattern for integrating information in multiple usually\nheterogenous artefacts throughout the design process of interactive systems;\nand ii) it highlights the need for tools helping to rationalize and to document\nthe various artefacts and the related decisions made during interactive systems\ndesign. CCS CONCEPTS $\\bullet$ Human-centered computing $\\bullet$ Human\ncomputer interaction (HCI)",
    "descriptor": "",
    "authors": [
      "Marco Winckler",
      "Philippe Palanque",
      "Jean-Luc Hak",
      "Eric Barboni",
      "Olivier Nicolas",
      "Laurent Goncalves"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.01333"
  },
  {
    "id": "arXiv:2205.01335",
    "title": "Predicting Issue Types with seBERT",
    "abstract": "Pre-trained transformer models are the current state-of-the-art for natural\nlanguage models processing. seBERT is such a model, that was developed based on\nthe BERT architecture, but trained from scratch with software engineering data.\nWe fine-tuned this model for the NLBSE challenge for the task of issue type\nprediction. Our model dominates the baseline fastText for all three issue types\nin both recall and precisio} to achieve an overall F1-score of 85.7%, which is\nan increase of 4.1% over the baseline.",
    "descriptor": "\nComments: Accepted for Publication at the NLBSE'22 Tool Competition\n",
    "authors": [
      "Alexander Trautsch",
      "Steffen Herbold"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01335"
  },
  {
    "id": "arXiv:2205.01338",
    "title": "MMSE Signal Detection for MIMO Systems based on Ordinary Differential  Equation",
    "abstract": "Motivated by emerging technologies for energy efficient analog computing and\ncontinuous-time processing, this paper proposes continuous-time minimum mean\nsquared error estimation for multiple-input multiple-output (MIMO) systems\nbased on an ordinary differential equation. Mean squared error (MSE) is a\nprincipal detection performance measure of estimation methods for MIMO systems.\nWe derive an analytical MSE formula that indicates the MSE at any time. The MSE\nof the proposed method depends on a regularization parameter which affects the\nconvergence property of the MSE. Furthermore, we extend the proposed method by\nusing a time-dependent regularization parameter to achieve better convergence\nperformance. Numerical experiments indicated excellent agreement with the\ntheoretical values and improvement in the convergence performance owing to the\nuse of the time-dependent parameter.",
    "descriptor": "",
    "authors": [
      "Ayano Nakai-Kasai",
      "Tadashi Wadayama"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.01338"
  },
  {
    "id": "arXiv:2205.01340",
    "title": "On the Design of Locking Free Ghost Penalty Stabilization and the  Relation to CutFEM with Discrete Extension",
    "abstract": "In this note, we develop a new stabilization mechanism for cut finite element\nmethods that generalizes previous approaches of ghost penalty type in two ways:\n(1) The quantity that is stabilized and (2) The choice of elements that are\nconnected in the stabilization. In particular, we can stabilize functionals of\nthe discrete function such as finite element degrees of freedom. We\nsubsequently show that the kernel of our ghost penalty operator defines a\nfinite element space based on discrete extensions in the spirit of those\nintroduced in Burman, E.; Hansbo, P. and Larson, M. G., CutFEM Based on\nExtended Finite Element Spaces, arXiv2101.10052, 2021.",
    "descriptor": "\nComments: 31 pages, 12 figures\n",
    "authors": [
      "Erik Burman",
      "Peter Hansbo",
      "Mats G. Larson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.01340"
  },
  {
    "id": "arXiv:2205.01345",
    "title": "Reality-based UTXO Ledger",
    "abstract": "The Unspent Transaction Output (UTXO) model is commonly used in the field of\nDistributed Ledger Technology (DLT) to transfer value between participants. One\nof its advantages is that it allows parallel processing of transactions, as\nindependent transactions can be added in any order. This property of order\ninvariance and parallelisability has potential benefits in terms of\nscalability. However, since the UTXO Ledger is an append-only data structure,\nthis advantage is compromised through the presence of conflicting transactions.\nWe propose an extended UTXO Ledger model that optimistically updates the ledger\nand keeps track of the dependencies of the possible conflicts. In the presence\nof a conflict resolution mechanism, we propose a method to reduce the extended\nledger back to a consistent UTXO Ledger.",
    "descriptor": "",
    "authors": [
      "Sebastian M\u00fcller",
      "Andreas Penzkofer",
      "Nikita Polyanskii",
      "Jonas Theis",
      "William Sanders",
      "Hans Moog"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.01345"
  },
  {
    "id": "arXiv:2205.01351",
    "title": "Tooling for Time- and Space-efficient git Repository Mining",
    "abstract": "Software projects under version control grow with each commit, accumulating\nup to hundreds of thousands of commits per repository. Especially for such\nlarge projects, the traversal of a repository and data extraction for static\nsource code analysis poses a trade-off between granularity and speed. We\nshowcase the command-line tool pyrepositoryminer that combines a set of\noptimization approaches for efficient traversal and data extraction from git\nrepositories while being adaptable to third-party and custom software metrics\nand data extractions. The tool is written in Python and combines bare\nrepository access, in-memory storage, parallelization, caching, change-based\nanalysis, and optimized communication between the traversal and custom data\nextraction components. The tool allows for both metrics written in Python and\nexternal programs for data extraction. A single-thread performance evaluation\nbased on a basic mining use case shows a mean speedup of 15.6x to other freely\navailable tools across four mid-sized open source projects. A multi-threaded\nexecution allows for load distribution among cores and, thus, a mean speedup up\nto 86.9x using 12 threads.",
    "descriptor": "",
    "authors": [
      "Fabian Heseding",
      "Willy Scheibel",
      "J\u00fcrgen D\u00f6llner"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.01351"
  },
  {
    "id": "arXiv:2205.01353",
    "title": "BioTouchPass: Handwritten Passwords for Touchscreen Biometrics",
    "abstract": "This work enhances traditional authentication systems based on Personal\nIdentification Numbers (PIN) and One-Time Passwords (OTP) through the\nincorporation of biometric information as a second level of user\nauthentication. In our proposed approach, users draw each digit of the password\non the touchscreen of the device instead of typing them as usual. A complete\nanalysis of our proposed biometric system is carried out regarding the\ndiscriminative power of each handwritten digit and the robustness when\nincreasing the length of the password and the number of enrolment samples. The\nnew e-BioDigit database, which comprises on-line handwritten digits from 0 to\n9, has been acquired using the finger as input on a mobile device. This\ndatabase is used in the experiments reported in this work and it is available\ntogether with benchmark results in GitHub. Finally, we discuss specific details\nfor the deployment of our proposed approach on current PIN and OTP systems,\nachieving results with Equal Error Rates (EERs) ca. 4.0% when the attacker\nknows the password. These results encourage the deployment of our proposed\napproach in comparison to traditional PIN and OTP systems where the attack\nwould have 100% success rate under the same impostor scenario.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2001.10223\n",
    "authors": [
      "Ruben Tolosana",
      "Ruben Vera-Rodriguez",
      "Julian Fierrez"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.01353"
  },
  {
    "id": "arXiv:2205.01355",
    "title": "Predicting Loose-Fitting Garment Deformations Using Bone-Driven Motion  Networks",
    "abstract": "We present a learning algorithm that uses bone-driven motion networks to\npredict the deformation of loose-fitting garment meshes at interactive rates.\nGiven a garment, we generate a simulation database and extract virtual bones\nfrom simulated mesh sequences using skin decomposition. At runtime, we\nseparately compute low- and high-frequency deformations in a sequential manner.\nThe low-frequency deformations are predicted by transferring body motions to\nvirtual bones' motions, and the high-frequency deformations are estimated\nleveraging the global information of virtual bones' motions and local\ninformation extracted from low-frequency meshes. In addition, our method can\nestimate garment deformations caused by variations of the simulation parameters\n(e.g., fabric's bending stiffness) using an RBF kernel ensembling trained\nnetworks for different sets of simulation parameters. Through extensive\ncomparisons, we show that our method outperforms state-of-the-art methods in\nterms of prediction accuracy of mesh deformations by about 20% in RMSE and 10%\nin Hausdorff distance and STED. The code and data are available at\nhttps://github.com/non-void/VirtualBones.",
    "descriptor": "\nComments: SIGGRAPH 22 Conference Paper\n",
    "authors": [
      "Xiaoyu Pan",
      "Jiaming Mai",
      "Xinwei Jiang",
      "Dongxue Tang",
      "Jingxiang Li",
      "Tianjia Shao",
      "Kun Zhou",
      "Xiaogang Jin",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01355"
  },
  {
    "id": "arXiv:2205.01356",
    "title": "Neural Combinatorial Optimization: a New Player in the Field",
    "abstract": "Neural Combinatorial Optimization attempts to learn good heuristics for\nsolving a set of problems using Neural Network models and Reinforcement\nLearning. Recently, its good performance has encouraged many practitioners to\ndevelop neural architectures for a wide variety of combinatorial problems.\nHowever, the incorporation of such algorithms in the conventional optimization\nframework has raised many questions related to their performance and the\nexperimental comparison with other methods such as exact algorithms, heuristics\nand metaheuristics. This paper presents a critical analysis on the\nincorporation of algorithms based on neural networks into the classical\ncombinatorial optimization framework. Subsequently, a comprehensive study is\ncarried out to analyse the fundamental aspects of such algorithms, including\nperformance, transferability, computational cost and generalization to\nlarger-sized instances. To that end, we select the Linear Ordering Problem as a\ncase of study, an NP-hard problem, and develop a Neural Combinatorial\nOptimization model to optimize it. Finally, we discuss how the analysed aspects\napply to a general learning framework, and suggest new directions for future\nwork in the area of Neural Combinatorial Optimization algorithms.",
    "descriptor": "",
    "authors": [
      "Andoni I. Garmendia",
      "Josu Ceberio",
      "Alexander Mendiburu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2205.01356"
  },
  {
    "id": "arXiv:2205.01357",
    "title": "Prediction-Based Reachability Analysis for Collision Risk Assessment on  Highways",
    "abstract": "Real-time safety systems are crucial components of intelligent vehicles. This\npaper introduces a prediction-based collision risk assessment approach on\nhighways. Given a point mass vehicle dynamics system, a stochastic forward\nreachable set considering two-dimensional motion with vehicle state probability\ndistributions is firstly established. We then develop an acceleration\nprediction model, which provides multi-modal probabilistic acceleration\ndistributions to propagate vehicle states. The collision probability is\ncalculated by summing up the probabilities of the states where two vehicles\nspatially overlap. Simulation results show that the prediction model has\nsuperior performance in terms of vehicle motion position errors, and the\nproposed collision detection approach is agile and effective to identify the\ncollision in cut-in crash events.",
    "descriptor": "\nComments: Accepted by IEEE IV 2022\n",
    "authors": [
      "Xinwei Wang",
      "Zirui Li",
      "Javier Alonso-Mora",
      "Meng Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01357"
  },
  {
    "id": "arXiv:2205.01358",
    "title": "Learning Label Initialization for Time-Dependent Harmonic Extension",
    "abstract": "Node classification on graphs can be formulated as the Dirichlet problem on\ngraphs where the signal is given at the labeled nodes, and the harmonic\nextension is done on the unlabeled nodes. This paper considers a time-dependent\nversion of the Dirichlet problem on graphs and shows how to improve its\nsolution by learning the proper initialization vector on the unlabeled nodes.\nFurther, we show that the improved solution is at par with state-of-the-art\nmethods used for node classification. Finally, we conclude this paper by\ndiscussing the importance of parameter t, pros, and future directions.",
    "descriptor": "\nComments: Accepted as a conference paper at IJCAI-2022\n",
    "authors": [
      "Amitoz Azad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01358"
  },
  {
    "id": "arXiv:2205.01362",
    "title": "TracInAD: Measuring Influence for Anomaly Detection",
    "abstract": "As with many other tasks, neural networks prove very effective for anomaly\ndetection purposes. However, very few deep-learning models are suited for\ndetecting anomalies on tabular datasets. This paper proposes a novel\nmethodology to flag anomalies based on TracIn, an influence measure initially\nintroduced for explicability purposes. The proposed methods can serve to\naugment any unsupervised deep anomaly detection method. We test our approach\nusing Variational Autoencoders and show that the average influence of a\nsubsample of training points on a test point can serve as a proxy for\nabnormality. Our model proves to be competitive in comparison with\nstate-of-the-art approaches: it achieves comparable or better performance in\nterms of detection accuracy on medical and cyber-security tabular benchmark\ndata.",
    "descriptor": "",
    "authors": [
      "Hugo Thimonier",
      "Fabrice Popineau",
      "Arpad Rimmel",
      "Bich-Li\u00ean Doan",
      "Fabrice Daniel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01362"
  },
  {
    "id": "arXiv:2205.01365",
    "title": "Half-Positional Objectives Recognized by Deterministic B\u00fcchi Automata",
    "abstract": "A central question in the theory of two-player games over graphs is to\nunderstand which objectives are half-positional, that is, which are the\nobjectives for which the protagonist does not need memory to implement winning\nstrategies. Objectives for which both players do not need memory have already\nbeen characterized (both in finite and infinite graphs). However, less is known\nabout half-positional objectives. In particular, no characterization of\nhalf-positionality is known for the central class of omega-regular objectives.\nIn this paper, we characterize objectives recognizable by deterministic\nB\\\"uchi automata (a class of omega-regular objectives) that are\nhalf-positional, in both finite and infinite graphs. Our characterization\nconsists of three natural conditions linked to the language-theoretic notion of\nright congruence. Furthermore, this characterization yields a polynomial-time\nalgorithm to decide half-positionality of an objective recognized by a given\ndeterministic B\\\"uchi automaton.",
    "descriptor": "\nComments: 37 pages, 14 figures\n",
    "authors": [
      "Patricia Bouyer",
      "Antonio Casares",
      "Mickael Randour",
      "Pierre Vandenhove"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.01365"
  },
  {
    "id": "arXiv:2205.01366",
    "title": "Finding patterns in Knowledge Attribution for Transformers",
    "abstract": "We analyze the Knowledge Neurons framework for the attribution of factual and\nrelational knowledge to particular neurons in the transformer network. We use a\n12-layer multi-lingual BERT model for our experiments. Our study reveals\nvarious interesting phenomena. We observe that mostly factual knowledge can be\nattributed to middle and higher layers of the network($\\ge 6$). Further\nanalysis reveals that the middle layers($6-9$) are mostly responsible for\nrelational information, which is further refined into actual factual knowledge\nor the \"correct answer\" in the last few layers($10-12$). Our experiments also\nshow that the model handles prompts in different languages, but representing\nthe same fact, similarly, providing further evidence for effectiveness of\nmulti-lingual pre-training. Applying the attribution scheme for grammatical\nknowledge, we find that grammatical knowledge is far more dispersed among the\nneurons than factual knowledge.",
    "descriptor": "",
    "authors": [
      "Jeevesh Juneja",
      "Ritu Agarwal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01366"
  },
  {
    "id": "arXiv:2205.01367",
    "title": "A hybrid multi-object segmentation framework with model-based B-splines  for microbial single cell analysis",
    "abstract": "In this paper, we propose a hybrid approach for multi-object microbial cell\nsegmentation. The approach combines an ML-based detection with a geometry-aware\nvariational-based segmentation using B-splines that are parametrized based on a\ngeometric model of the cell shape. The detection is done first using YOLOv5. In\na second step, each detected cell is segmented individually. Thus, the\nsegmentation only needs to be done on a per-cell basis, which makes it amenable\nto a variational approach that incorporates prior knowledge on the geometry.\nHere, the contour of the segmentation is modelled as closed uniform cubic\nB-spline, whose control points are parametrized using the known cell geometry.\nCompared to purely ML-based segmentation approaches, which need accurate\nsegmentation maps as training data that are very laborious to produce, our\nmethod just needs bounding boxes as training data. Still, the proposed method\nperforms on par with ML-based segmentation approaches usually used in this\ncontext. We study the performance of the proposed method on time-lapse\nmicroscopy data of Corynebacterium glutamicum.",
    "descriptor": "",
    "authors": [
      "Karina Ruzaeva",
      "Katharina N\u00f6h",
      "Benjamin Berkels"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2205.01367"
  },
  {
    "id": "arXiv:2205.01372",
    "title": "A Global Operational Readiness Review Process: Improving Cloud  Availability",
    "abstract": "The ORR (Operational Readiness Review) is a long standing practice to help\ninsure application or system readiness and improved Availability. In this paper\nthe ORR is defined and recent examples of its use from Cloud Computing\nenvironments are compared. An emphasis on ORRs used within DevOps environments\nis also provided. A detailed presentation of a specific and custom ORR\nimplementation for a large global IT organization is shared. This includes the\nprocess development approach, key components of the ORR checklist, automation\nsupport provided, and a unique Executive dashboard solution to visualize status\non in-flight releases. Challenges and benefits from this ORR implementation are\nprovided as well as a detailed comparison with the Google Launch checklist and\nits associated PRR/ORR. Finally, suggestions for further improvements,\nautomation, and usage of the ORR in large-scale industrial settings based on\nthis real-world experience are elaborated.\nKeywords: Operational Readiness Review, ORR, IT Services, IT Operations,\nITIL, Process Engineering, Reliability, Availability, Software Architecture,\nCloud Computing, Networking, Site Reliability Engineering, DevOps, Agile\nMethods, Quality, Defect Prevention, Release Management, Risk Management, Data\nVisualization, Organizational Change Management.",
    "descriptor": "\nComments: Paper contains 8 pages, 4 figures, and 21 references\n",
    "authors": [
      "James J. Cusick"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.01372"
  },
  {
    "id": "arXiv:2205.01373",
    "title": "Copy Motion From One to Another: Fake Motion Video Generation",
    "abstract": "One compelling application of artificial intelligence is to generate a video\nof a target person performing arbitrary desired motion (from a source person).\nWhile the state-of-the-art methods are able to synthesize a video demonstrating\nsimilar broad stroke motion details, they are generally lacking in texture\ndetails. A pertinent manifestation appears as distorted face, feet, and hands,\nand such flaws are very sensitively perceived by human observers. Furthermore,\ncurrent methods typically employ GANs with a L2 loss to assess the authenticity\nof the generated videos, inherently requiring a large amount of training\nsamples to learn the texture details for adequate video generation. In this\nwork, we tackle these challenges from three aspects: 1) We disentangle each\nvideo frame into foreground (the person) and background, focusing on generating\nthe foreground to reduce the underlying dimension of the network output. 2) We\npropose a theoretically motivated Gromov-Wasserstein loss that facilitates\nlearning the mapping from a pose to a foreground image. 3) To enhance texture\ndetails, we encode facial features with geometric guidance and employ local\nGANs to refine the face, feet, and hands. Extensive experiments show that our\nmethod is able to generate realistic target person videos, faithfully copying\ncomplex motions from a source person. Our code and datasets are released at\nhttps://github.com/Sifann/FakeMotion",
    "descriptor": "\nComments: This paper is accepted to IJCAI2022 (ORAL presentation)\n",
    "authors": [
      "Zhenguang Liu",
      "Sifan Wu",
      "Chejian Xu",
      "Xiang Wang",
      "Lei Zhu",
      "Shuang Wu",
      "Fuli Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01373"
  },
  {
    "id": "arXiv:2205.01374",
    "title": "Hidden behind the obvious: misleading keywords and implicitly abusive  language on social media",
    "abstract": "While social media offers freedom of self-expression, abusive language carry\nsignificant negative social impact. Driven by the importance of the issue,\nresearch in the automated detection of abusive language has witnessed growth\nand improvement. However, these detection models display a reliance on strongly\nindicative keywords, such as slurs and profanity. This means that they can\nfalsely (1a) miss abuse without such keywords or (1b) flag non-abuse with such\nkeywords, and that (2) they perform poorly on unseen data. Despite the\nrecognition of these problems, gaps and inconsistencies remain in the\nliterature. In this study, we analyse the impact of keywords from dataset\nconstruction to model behaviour in detail, with a focus on how models make\nmistakes on (1a) and (1b), and how (1a) and (1b) interact with (2). Through the\nanalysis, we provide suggestions for future research to address all three\nproblems.",
    "descriptor": "\nComments: Accepted for publication in Online Social Networks and Media\n",
    "authors": [
      "Wenjie Yin",
      "Arkaitz Zubiaga"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.01374"
  },
  {
    "id": "arXiv:2205.01376",
    "title": "Textual Entailment for Event Argument Extraction: Zero- and Few-Shot  with Multi-Source Learning",
    "abstract": "Recent work has shown that NLP tasks such as Relation Extraction (RE) can be\nrecasted as Textual Entailment tasks using verbalizations, with strong\nperformance in zero-shot and few-shot settings thanks to pre-trained entailment\nmodels. The fact that relations in current RE datasets are easily verbalized\ncasts doubts on whether entailment would be effective in more complex tasks. In\nthis work we show that entailment is also effective in Event Argument\nExtraction (EAE), reducing the need of manual annotation to 50% and 20% in ACE\nand WikiEvents respectively, while achieving the same performance as with full\ntraining. More importantly, we show that recasting EAE as entailment alleviates\nthe dependency on schemas, which has been a road-block for transferring\nannotations between domains. Thanks to the entailment, the multi-source\ntransfer between ACE and WikiEvents further reduces annotation down to 10% and\n5% (respectively) of the full training without transfer. Our analysis shows\nthat the key to good results is the use of several entailment datasets to\npre-train the entailment model. Similar to previous approaches, our method\nrequires a small amount of effort for manual verbalization: only less than 15\nminutes per event argument type is needed, and comparable results can be\nachieved with users with different level of expertise.",
    "descriptor": "\nComments: Accepted as Findings of NAACL2022\n",
    "authors": [
      "Oscar Sainz",
      "Itziar Gonzalez-Dios",
      "Oier Lopez de Lacalle",
      "Bonan Min",
      "Eneko Agirre"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01376"
  },
  {
    "id": "arXiv:2205.01378",
    "title": "Complex-order Reset Control System",
    "abstract": "According to the well-known loop shaping method for the design of\ncontrollers, the performance of the controllers in terms of step response,\nsteady-state disturbance rejection and noise attenuation and robustness can be\nimproved by increasing the gain at lower frequencies and decreasing it at\nhigher frequencies and increasing the phase margin as much as possible.\nHowever, the inherent properties of linear controllers, the Bode's phase-gain\nrelation, create a limitation. In theory, a complex-order transfer function can\nbreak the Bode's gain-phase relation; however, such transfer function cannot be\ndirectly implemented and should be approximated. This paper proposes a reset\nelement and a tuning method to approximate a Complex-Order Controller (CLOC)\nand, through a simulation example, shows the benefits of using such a\ncontroller.",
    "descriptor": "",
    "authors": [
      "Nima Karbasizadeh",
      "S. Hassan HosseinNia"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.01378"
  },
  {
    "id": "arXiv:2205.01380",
    "title": "Deep Learning in Multimodal Remote Sensing Data Fusion: A Comprehensive  Review",
    "abstract": "With the extremely rapid advances in remote sensing (RS) technology, a great\nquantity of Earth observation (EO) data featuring considerable and complicated\nheterogeneity is readily available nowadays, which renders researchers an\nopportunity to tackle current geoscience applications in a fresh way. With the\njoint utilization of EO data, much research on multimodal RS data fusion has\nmade tremendous progress in recent years, yet these developed traditional\nalgorithms inevitably meet the performance bottleneck due to the lack of the\nability to comprehensively analyse and interpret these strongly heterogeneous\ndata. Hence, this non-negligible limitation further arouses an intense demand\nfor an alternative tool with powerful processing competence. Deep learning\n(DL), as a cutting-edge technology, has witnessed remarkable breakthroughs in\nnumerous computer vision tasks owing to its impressive ability in data\nrepresentation and reconstruction. Naturally, it has been successfully applied\nto the field of multimodal RS data fusion, yielding great improvement compared\nwith traditional methods. This survey aims to present a systematic overview in\nDL-based multimodal RS data fusion. More specifically, some essential knowledge\nabout this topic is first given. Subsequently, a literature survey is conducted\nto analyse the trends of this field. Some prevalent sub-fields in the\nmultimodal RS data fusion are then reviewed in terms of the to-be-fused data\nmodalities, i.e., spatiospectral, spatiotemporal, light detection and\nranging-optical, synthetic aperture radar-optical, and RS-Geospatial Big Data\nfusion. Furthermore, We collect and summarize some valuable resources for the\nsake of the development in multimodal RS data fusion. Finally, the remaining\nchallenges and potential future directions are highlighted.",
    "descriptor": "",
    "authors": [
      "Jiaxin Li",
      "Danfeng Hong",
      "Lianru Gao",
      "Jing Yao",
      "Ke Zheng",
      "Bing Zhang",
      "Jocelyn Chanussot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.01380"
  },
  {
    "id": "arXiv:2205.01381",
    "title": "Kompetencer: Fine-grained Skill Classification in Danish Job Postings  via Distant Supervision and Transfer Learning",
    "abstract": "Skill Classification (SC) is the task of classifying job competences from job\npostings. This work is the first in SC applied to Danish job vacancy data. We\nrelease the first Danish job posting dataset: Kompetencer (en: competences),\nannotated for nested spans of competences. To improve upon coarse-grained\nannotations, we make use of The European Skills, Competences, Qualifications\nand Occupations (ESCO; le Vrang et al., 2014) taxonomy API to obtain\nfine-grained labels via distant supervision. We study two setups: The zero-shot\nand few-shot classification setting. We fine-tune English-based models and\nRemBERT (Chung et al., 2020) and compare them to in-language Danish models. Our\nresults show RemBERT significantly outperforms all other models in both the\nzero-shot and the few-shot setting.",
    "descriptor": "\nComments: 7 pages, accepted to LREC 2022. arXiv admin note: text overlap with arXiv:2204.12811\n",
    "authors": [
      "Mike Zhang",
      "Kristian N\u00f8rgaard Jensen",
      "Barbara Plank"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01381"
  },
  {
    "id": "arXiv:2205.01382",
    "title": "A Mapping Approach to Convert MTPs into a Capability and Skill Ontology",
    "abstract": "Being able to quickly integrate new equipment and functions into an existing\nplant is a major goal for both discrete and process manufacturing. But\ncurrently, these two industry domains use different approaches to achieve this\ngoal. While the Module Type Package (MTP) is getting more and more adapted in\npractical applications of process manufacturing, so-called skill-based\nmanufacturing approaches are favored in the context of discrete manufacturing.\nThe two approaches are incompatible because their models feature different\ncontents and they use different technologies. This contribution provides a\ncomparison of the MTP with a skill-based approach as well as an automated\nmapping that can be used to transfer the contents of an MTP into a skill\nontology. Through this mapping an MTP can be semantically lifted in order to\napply functions like querying or reasoning. Furthermore, machines that were\npreviously described using two incompatible models can now be used in one\nproduction process.",
    "descriptor": "",
    "authors": [
      "Aljosha K\u00f6cher",
      "Lasse Beers",
      "Alexander Fay"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.01382"
  },
  {
    "id": "arXiv:2205.01388",
    "title": "Restarted randomized surrounding methods for solving large linear  equations",
    "abstract": "A class of restarted randomized surrounding methods are presented to\naccelerate the surrounding algorithms by restarted techniques for solving the\nlinear equations. Theoretical analysis prove that the proposed method converges\nunder the randomized row selection rule and the expectation convergence rate is\nalso addressed. Numerical experiments further demonstrate that the proposed\nalgorithms are efficient and outperform the existing method for over-determined\nand under-determined linear equation, as well as in the application of image\nprocessing.",
    "descriptor": "",
    "authors": [
      "Junfeng Yin",
      "Nan Li",
      "Ning Zheng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.01388"
  },
  {
    "id": "arXiv:2205.01389",
    "title": "Sampling-free obstacle gradients and reactive planning in Neural  Radiance Fields (NeRF)",
    "abstract": "This work investigates the use of Neural implicit representations,\nspecifically Neural Radiance Fields (NeRF), for geometrical queries and motion\nplanning. We show that by adding the capacity to infer occupancy in a radius to\na pre-trained NeRF, we are effectively learning an approximation to a Euclidean\nSigned Distance Field (ESDF). Using backward differentiation of the augmented\nnetwork, we obtain an obstacle gradient that is integrated into an obstacle\navoidance policy based on the Riemannian Motion Policies (RMP) framework. Thus,\nour findings allow for very fast sampling-free obstacle avoidance planning in\nthe implicit representation.",
    "descriptor": "\nComments: Accepted to the \"Motion Planning with Implicit Neural Representations of Geometry\" Workshop at ICRA 2022\n",
    "authors": [
      "Michael Pantic",
      "Cesar Cadena",
      "Roland Siegwart",
      "Lionel Ott"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01389"
  },
  {
    "id": "arXiv:2205.01390",
    "title": "Cost-Efficient and QoS-Aware User Association and 3D Placement of 6G  Aerial Mobile Access Points",
    "abstract": "6G networks require a flexible infrastructure to dynamically provide\nubiquitous network coverage. Mobile Access Points (MAP) deployment is a\npromising solution. In this paper, we formulate the joint 3D MAP deployment and\nuser association problem over a dynamic network under interference and mobility\nconstraints. First, we propose an iterative algorithm to optimize the\ndeployment of MAPs. Our solution efficiently and quickly determines the number,\nposition and configuration of MAPs for highly dynamic scenarios. MAPs provide\nappropriate Quality of Service (QoS) connectivity to mobile ground user in\nmmwave or sub-6GHz bands and find their optimal positions in a 3D grid. Each\nMAP also implies an energy cost (e.g. for travel) to be minimized. Once all\nMAPs deployed, a deep multiagent reinforcement learning algorithm is proposed\nto associate multiple users to multiple MAPs under interference constraint.\nEach user acts as an independent agent that operates in a fully distributed\narchitecture and maximizes the network sum-rate.",
    "descriptor": "\nComments: To be published to 2022 Joint European Conference on Networks and Communications & 6G Summit (EuCNC/6G Summit)\n",
    "authors": [
      "Esteban Catt\u00e9",
      "Mohamed Sana",
      "Mickael Maman"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.01390"
  },
  {
    "id": "arXiv:2205.01392",
    "title": "A Unified Framework for Verification of Observational Properties for  Partially-Observed Discrete-Event Systems",
    "abstract": "In this paper, we investigate property verification problems in\npartially-observed discrete-event systems (DES). Particularly, we are\ninterested in verifying observational properties that are related to the\ninformation-flow of the system. Observational properties considered here\ninclude diagnosability, predictability, detectability and opacity, which have\ndrawn considerable attentions in the literature. However, in contrast to\nexisting results, where different verification procedures are developed for\ndifferent properties case-by-case, in this work, we provide a unified framework\nfor verifying all these properties by reducing each of them as an instance of\nHyperLTL model checking. Our approach is based on the construction of a Kripke\nstructure that effectively captures the issue of unobservability as well as the\nfinite string semantics in partially-observed DES so that HyperLTL model\nchecking techniques can be suitably applied. Then for each observational\nproperty considered, we explicitly provide the HyperLTL formula to be checked\nover the Kripke structure for the purpose of verification. Our approach is\nuniform in the sense that all different properties can be verified with the\nsame model checking engine. Furthermore, our unified framework also brings new\ninsights for classifying observational properties for partially-observed DES in\nterms of their verification complexity.",
    "descriptor": "",
    "authors": [
      "Jianing Zhao",
      "Xiang Yin",
      "Shaoyuan Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.01392"
  },
  {
    "id": "arXiv:2205.01395",
    "title": "Publishing a Knowledge Organization System as Linked Data: The Case of  the Universal Decimal Classification",
    "abstract": "Linked data (LD) technology is hailed as a long-awaited solution in web-based\ninformation exchange. Linked Open Data (LOD) bring this to another level by\nenabling meaningful linking of resources and creating a global, openly\naccessible knowledge graph. Our case is the Universal Decimal Classification\n(UDC) and the challenges for a KOS service provider to maintain an LD service.\nUDC was created during the period 1896--1904 to support systematic organization\nand information retrieval of a bibliography. When discussing UDC as LD we make\na distinction between two types of UDC data or two provenances: UDC source\ndata, and UDC codes as they appear in metadata. To serve the purpose of\nsupplying semantics one has to front--end UDC LD with a service that can parse\nand interpret complex UDC strings. While the use of UDC is free the publishing\nand distributing of UDC data is protected by a licence. Publishing of UDC both\nas LD and as LOD must be provided for within a complex service that would allow\nopen access as well as access through a paywall barrier for different levels of\nlicences. The practical task of publishing the UDC as LOD was informed by the\n'10Things guidelines'. The process includes conceptual parts and technological\nparts. The transition to a new technology is never a purely mechanical act but\nis a research endeavour in its own right. The UDC case has shown the importance\nof cross-domain, inter-disciplinary collaboration which needs experts well\nsituated in multiple knowledge domains.",
    "descriptor": "",
    "authors": [
      "Aida Slavic",
      "Ronald Siebes",
      "Andrea Scharnhorst"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2205.01395"
  },
  {
    "id": "arXiv:2205.01397",
    "title": "Data Determines Distributional Robustness in Contrastive Language Image  Pre-training (CLIP)",
    "abstract": "Contrastively trained image-text models such as CLIP, ALIGN, and BASIC have\ndemonstrated unprecedented robustness to multiple challenging natural\ndistribution shifts. Since these image-text models differ from previous\ntraining approaches in several ways, an important question is what causes the\nlarge robustness gains. We answer this question via a systematic experimental\ninvestigation. Concretely, we study five different possible causes for the\nrobustness gains: (i) the training set size, (ii) the training distribution,\n(iii) language supervision at training time, (iv) language supervision at test\ntime, and (v) the contrastive loss function. Our experiments show that the more\ndiverse training distribution is the main cause for the robustness gains, with\nthe other factors contributing little to no robustness. Beyond our experimental\nresults, we also introduce ImageNet-Captions, a version of ImageNet with\noriginal text annotations from Flickr, to enable further controlled experiments\nof language-image training.",
    "descriptor": "",
    "authors": [
      "Alex Fang",
      "Gabriel Ilharco",
      "Mitchell Wortsman",
      "Yuhao Wan",
      "Vaishaal Shankar",
      "Achal Dave",
      "Ludwig Schmidt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01397"
  },
  {
    "id": "arXiv:2205.01398",
    "title": "Neural language models for network configuration: Opportunities and  reality check",
    "abstract": "Boosted by deep learning, natural language processing (NLP) techniques have\nrecently seen spectacular progress, mainly fueled by breakthroughs both in\nrepresentation learning with word embeddings (e.g. word2vec) as well as novel\narchitectures (e.g. transformers). This success quickly invited researchers to\nexplore the use of NLP techniques to other field, such as computer programming\nlanguages, with the promise to automate tasks in software programming (bug\ndetection, code synthesis, code repair, cross language translation etc.). By\nextension, NLP has potential for application to network configuration languages\nas well, for instance considering tasks such as network configuration\nverification, synthesis, and cross-vendor translation. In this paper, we survey\nrecent advances in deep learning applied to programming languages, for the\npurpose of code verification, synthesis and translation: in particularly, we\nreview their training requirements and expected performance, and qualitatively\nassess whether similar techniques can benefit corresponding use-cases in\nnetworking.",
    "descriptor": "",
    "authors": [
      "Zied Ben Houidi",
      "Dario Rossi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.01398"
  },
  {
    "id": "arXiv:2205.01399",
    "title": "Outdoor Monocular Depth Estimation: A Research Review",
    "abstract": "Depth estimation is an important task, applied in various methods and\napplications of computer vision. While the traditional methods of estimating\ndepth are based on depth cues and require specific equipment such as stereo\ncameras and configuring input according to the approach being used, the focus\nat the current time is on a single source, or monocular, depth estimation. The\nrecent developments in Convolution Neural Networks along with the integration\nof classical methods in these deep learning approaches have led to a lot of\nadvancements in the depth estimation problem. The problem of outdoor depth\nestimation, or depth estimation in wild, is a very scarcely researched field of\nstudy. In this paper, we give an overview of the available datasets, depth\nestimation methods, research work, trends, challenges, and opportunities that\nexist for open research. To our knowledge, no openly available survey work\nprovides a comprehensive collection of outdoor depth estimation techniques and\nresearch scope, making our work an essential contribution for people looking to\nenter this field of study.",
    "descriptor": "",
    "authors": [
      "Pulkit Vyas",
      "Chirag Saxena",
      "Anwesh Badapanda",
      "Anurag Goswami"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01399"
  },
  {
    "id": "arXiv:2205.01402",
    "title": "A Model of Random Multiple Access in Unlicensed Spectrum Systems",
    "abstract": "We consider a classical multiple access system with a single transmission\nchannel, finite number of users (users), and randomized transmission protocol\n(ALOHA). We assume that every user sends messages to the base station with\nvarious intensities. Due to the overlapping of messages during their sending\nthere are restrictions on the time between the messages and a mathematical\nmodel adequate to the physical one becomes quite complicated. In this work, we\npropose a simplified mathematical model that is easy to analyze and takes into\naccount the properties of real systems.",
    "descriptor": "\nComments: 4 pages, 2 figures\n",
    "authors": [
      "Dmitriy Kim",
      "Georgi Georgiev",
      "Natalya Markovskaya"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.01402"
  },
  {
    "id": "arXiv:2205.01404",
    "title": "Neural Language Taskonomy: Which NLP Tasks are the most Predictive of  fMRI Brain Activity?",
    "abstract": "Several popular Transformer based language models have been found to be\nsuccessful for text-driven brain encoding. However, existing literature\nleverages only pretrained text Transformer models and has not explored the\nefficacy of task-specific learned Transformer representations. In this work, we\nexplore transfer learning from representations learned for ten popular natural\nlanguage processing tasks (two syntactic and eight semantic) for predicting\nbrain responses from two diverse datasets: Pereira (subjects reading sentences\nfrom paragraphs) and Narratives (subjects listening to the spoken stories).\nEncoding models based on task features are used to predict activity in\ndifferent regions across the whole brain. Features from coreference resolution,\nNER, and shallow syntax parsing explain greater variance for the reading\nactivity. On the other hand, for the listening activity, tasks such as\nparaphrase generation, summarization, and natural language inference show\nbetter encoding performance. Experiments across all 10 task representations\nprovide the following cognitive insights: (i) language left hemisphere has\nhigher predictive brain activity versus language right hemisphere, (ii)\nposterior medial cortex, temporo-parieto-occipital junction, dorsal frontal\nlobe have higher correlation versus early auditory and auditory association\ncortex, (iii) syntactic and semantic tasks display a good predictive\nperformance across brain regions for reading and listening stimuli resp.",
    "descriptor": "\nComments: 18 pages, 18 figures\n",
    "authors": [
      "Subba Reddy Oota",
      "Jashn Arora",
      "Veeral Agarwal",
      "Mounika Marreddy",
      "Manish Gupta",
      "Bapi Raju Surampudi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2205.01404"
  },
  {
    "id": "arXiv:2205.01411",
    "title": "On the Utility of Prediction Sets in Human-AI Teams",
    "abstract": "Research on human-AI teams usually provides experts with a single label,\nwhich ignores the uncertainty in a model's recommendation. Conformal prediction\n(CP) is a well established line of research that focuses on building a\ntheoretically grounded, calibrated prediction set, which may contain multiple\nlabels. We explore how such prediction sets impact expert decision-making in\nhuman-AI teams. Our evaluation on human subjects finds that set valued\npredictions positively impact experts. However, we notice that the predictive\nsets provided by CP can be very large, which leads to unhelpful AI assistants.\nTo mitigate this, we introduce D-CP, a method to perform CP on some examples\nand defer to experts. We prove that D-CP can reduce the prediction set size of\nnon-deferred examples. We show how D-CP performs in quantitative and in human\nsubject experiments ($n=120$). Our results suggest that CP prediction sets\nimprove human-AI team performance over showing the top-1 prediction alone, and\nthat experts find D-CP prediction sets are more useful than CP prediction sets.",
    "descriptor": "\nComments: Accepted at IJCAI 2022\n",
    "authors": [
      "Varun Babbar",
      "Umang Bhatt",
      "Adrian Weller"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.01411"
  },
  {
    "id": "arXiv:2205.01414",
    "title": "Multimodal Detection of Unknown Objects on Roads for Autonomous Driving",
    "abstract": "Tremendous progress in deep learning over the last years has led towards a\nfuture with autonomous vehicles on our roads. Nevertheless, the performance of\ntheir perception systems is strongly dependent on the quality of the utilized\ntraining data. As these usually only cover a fraction of all object classes an\nautonomous driving system will face, such systems struggle with handling the\nunexpected. In order to safely operate on public roads, the identification of\nobjects from unknown classes remains a crucial task. In this paper, we propose\na novel pipeline to detect unknown objects. Instead of focusing on a single\nsensor modality, we make use of lidar and camera data by combining state-of-the\nart detection models in a sequential manner. We evaluate our approach on the\nWaymo Open Perception Dataset and point out current research gaps in anomaly\ndetection.",
    "descriptor": "\nComments: Daniel Bogdoll, Enrico Eisen, Maximilian Nitsche and Christin Scheib contributed equally\n",
    "authors": [
      "Daniel Bogdoll",
      "Enrico Eisen",
      "Maximilian Nitsche",
      "Christin Scheib",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.01414"
  },
  {
    "id": "arXiv:2205.01415",
    "title": "Robust Subset Selection by Greedy and Evolutionary Pareto Optimization",
    "abstract": "Subset selection, which aims to select a subset from a ground set to maximize\nsome objective function, arises in various applications such as influence\nmaximization and sensor placement. In real-world scenarios, however, one often\nneeds to find a subset which is robust against (i.e., is good over) a number of\npossible objective functions due to uncertainty, resulting in the problem of\nrobust subset selection. This paper considers robust subset selection with\nmonotone objective functions, relaxing the submodular property required by\nprevious studies. We first show that the greedy algorithm can obtain an\napproximation ratio of $1-e^{-\\beta\\opgamma}$, where $\\beta$ and $\\opgamma$ are\nthe correlation and submodularity ratios of the objective functions,\nrespectively; and then propose EPORSS, an evolutionary Pareto optimization\nalgorithm that can utilize more time to find better subsets. We prove that\nEPORSS can also be theoretically grounded, achieving a similar approximation\nguarantee to the greedy algorithm. In addition, we derive the lower bound of\n$\\beta$ for the application of robust influence maximization, and further\nconduct experiments to validate the performance of the greedy algorithm and\nEPORSS.",
    "descriptor": "",
    "authors": [
      "Chao Bian",
      "Yawen Zhou",
      "Chao Qian"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2205.01415"
  },
  {
    "id": "arXiv:2205.01416",
    "title": "Exact Paired-Permutation Testing for Structured Test Statistics",
    "abstract": "Significance testing -- especially the paired-permutation test -- has played\na vital role in developing NLP systems to provide confidence that the\ndifference in performance between two systems (i.e., the test statistic) is not\ndue to luck. However, practitioners rely on Monte Carlo approximation to\nperform this test due to a lack of a suitable exact algorithm. In this paper,\nwe provide an efficient exact algorithm for the paired-permutation test for a\nfamily of structured test statistics. Our algorithm runs in $\\mathcal{O}(GN\n(\\log GN )(\\log N ))$ time where $N$ is the dataset size and $G$ is the range\nof the test statistic. We found that our exact algorithm was $10$x faster than\nthe Monte Carlo approximation with $20000$ samples on a common dataset.",
    "descriptor": "",
    "authors": [
      "Ran Zmigrod",
      "Tim Vieira",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01416"
  },
  {
    "id": "arXiv:2205.01417",
    "title": "The Price of Hierarchical Clustering",
    "abstract": "Hierarchical Clustering is a popular tool for understanding the hereditary\nproperties of a data set. Such a clustering is actually a sequence of\nclusterings that starts with the trivial clustering in which every data point\nforms its own cluster and then successively merges two existing clusters until\nall points are in the same cluster. A hierarchical clustering achieves an\napproximation factor of $\\alpha$ if the costs of each $k$-clustering in the\nhierarchy are at most $\\alpha$ times the costs of an optimal $k$-clustering. We\nstudy as cost functions the maximum (discrete) radius of any cluster\n($k$-center problem) and the maximum diameter of any cluster ($k$-diameter\nproblem). In general, the optimal clusterings do not form a hierarchy and hence\nan approximation factor of $1$ cannot be achieved. We call the smallest\napproximation factor that can be achieved for any instance the price of\nhierarchy. For the $k$-diameter problem we improve the upper bound on the price\nof hierarchy to $3+2\\sqrt{2}\\approx 5.83$. Moreover we significantly improve\nthe lower bounds for $k$-center and $k$-diameter, proving a price of hierarchy\nof exactly $4$ and $3+2\\sqrt{2}$, respectively.",
    "descriptor": "\nComments: 32 pages, 8 figures\n",
    "authors": [
      "Anna Arutyunova",
      "Heiko R\u00f6glin"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.01417"
  },
  {
    "id": "arXiv:2205.01418",
    "title": "How Does Embodiment Affect the Human Perception of Computational  Creativity? An Experimental Study Framework",
    "abstract": "Which factors influence the human assessment of creativity exhibited by a\ncomputational system is a core question of computational creativity (CC)\nresearch. Recently, the system's embodiment has been put forward as such a\nfactor, but empirical studies of its effect are lacking. To this end, we\npropose an experimental framework which isolates the effect of embodiment on\nthe perception of creativity from its effect on creativity per se. We not only\nmanipulate the system's embodiment, but also the perceptual evidence as the\nbasis for the human creativity assessment. We motivate the core framework with\nembodiment and perceptual evidence as independent and the creative process as\ncontrolled variable, and we provide recommendations on measuring the assessment\nof creativity as dependent variable. We hope the framework will inspire others\nto study the human perception of embodied CC in a principled manner.",
    "descriptor": "\nComments: 4 pages, submitted to the workshop \"The Role of Embodiment in the Perception of Human and Artificial Creativity\" at the International Conference on Computational Creativity (ICCC) 2022. Simo Linkola and Christian Guckelsberger share first authorship\n",
    "authors": [
      "Simo Linkola",
      "Christian Guckelsberger",
      "Tomi M\u00e4nnist\u00f6",
      "Anna Kantosalo"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.01418"
  },
  {
    "id": "arXiv:2205.01419",
    "title": "An Empirical Analysis of the Use of Real-Time Reachability for the  Safety Assurance of Autonomous Vehicles",
    "abstract": "Recent advances in machine learning technologies and sensing have paved the\nway for the belief that safe, accessible, and convenient autonomous vehicles\nmay be realized in the near future. Despite tremendous advances within this\ncontext, fundamental challenges around safety and reliability are limiting\ntheir arrival and comprehensive adoption. Autonomous vehicles are often tasked\nwith operating in dynamic and uncertain environments. As a result, they often\nmake use of highly complex components, such as machine learning approaches, to\nhandle the nuances of sensing, actuation, and control. While these methods are\nhighly effective, they are notoriously difficult to assure. Moreover, within\nuncertain and dynamic environments, design time assurance analyses may not be\nsufficient to guarantee safety. Thus, it is critical to monitor the correctness\nof these systems at runtime. One approach for providing runtime assurance of\nsystems with components that may not be amenable to formal analysis is the\nsimplex architecture, where an unverified component is wrapped with a safety\ncontroller and a switching logic designed to prevent dangerous behavior. In\nthis paper, we propose using a real-time reachability algorithm for the\nimplementation of the simplex architecture to assure the safety of a 1/10 scale\nopen source autonomous vehicle platform known as F1/10. The reachability\nalgorithm that we leverage (a) provides provable guarantees of safety, and (b)\nis used to detect potentially unsafe scenarios. In our approach, the need to\nanalyze an underlying controller is abstracted away, instead focusing on the\neffects of the controller's decisions on the system's future states. We\ndemonstrate the efficacy of our architecture through a vast set of experiments\nconducted both in simulation and on an embedded hardware platform.",
    "descriptor": "\nComments: 30 pages, 12 Figures, Submitted to Artificial Intelligence's Special Issue on \"Risk-Aware Autonomous Systems: Theory and Practice.\"\n",
    "authors": [
      "Patrick Musau",
      "Nathaniel Hamilton",
      "Diego Manzanas Lopez",
      "Preston Robinette",
      "Taylor T. Johnson"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.01419"
  },
  {
    "id": "arXiv:2205.01420",
    "title": "Bridging Causal Consistent and Time Reversibility: A Stochastic Process  Algebraic Approach",
    "abstract": "Causal consistent reversibility blends causality and reversibility. For a\nconcurrent system, it says that an action can be undone provided that this has\nno consequences, thereby making it possible to bring the system back to a past\nconsistent state. Time reversibility is instead considered in the performance\nevaluation field, mostly for efficient analysis purposes. A continuous-time\nMarkov chain is time reversible if its stochastic behavior remains the same\nwhen the direction of time is reversed. We study how to bridge these two\ntheories of reversibility by showing the conditions under which both causal\nconsistent reversibility and time reversibility can be ensured by construction.\nThis is done in the setting of a stochastic process calculus, which is then\nequipped with a notion of stochastic bisimilarity accounting for both forward\nand backward directions.",
    "descriptor": "",
    "authors": [
      "Marco Bernardo",
      "Claudio Antares Mezzina"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.01420"
  },
  {
    "id": "arXiv:2205.01421",
    "title": "A Falsificationist Account of Artificial Neural Networks",
    "abstract": "Machine learning operates at the intersection of statistics and computer\nscience. This raises the question as to its underlying methodology. While much\nemphasis has been put on the close link between the process of learning from\ndata and induction, the falsificationist component of machine learning has\nreceived minor attention. In this paper, we argue that the idea of\nfalsification is central to the methodology of machine learning. It is commonly\nthought that machine learning algorithms infer general prediction rules from\npast observations. This is akin to a statistical procedure by which estimates\nare obtained from a sample of data. But machine learning algorithms can also be\ndescribed as choosing one prediction rule from an entire class of functions. In\nparticular, the algorithm that determines the weights of an artificial neural\nnetwork operates by empirical risk minimization and rejects prediction rules\nthat lack empirical adequacy. It also exhibits a behavior of implicit\nregularization that pushes hypothesis choice toward simpler prediction rules.\nWe argue that taking both aspects together gives rise to a falsificationist\naccount of artificial neural networks.",
    "descriptor": "\nComments: 27 pages, 2 figures\n",
    "authors": [
      "Oliver Buchholz",
      "Eric Raidl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.01421"
  },
  {
    "id": "arXiv:2205.01423",
    "title": "Autonomy and Intelligence in the Computing Continuum: Challenges,  Enablers, and Future Directions for Orchestration",
    "abstract": "Future AI applications require performance, reliability and privacy that the\nexisting, cloud-dependant system architectures cannot provide. In this article,\nwe study orchestration in the device-edge-cloud continuum, and focus on AI for\nedge, that is, the AI methods used in resource orchestration. We claim that to\nsupport the constantly growing requirements of intelligent applications in the\ndevice-edge-cloud computing continuum, resource orchestration needs to embrace\nedge AI and emphasize local autonomy and intelligence. To justify the claim, we\nprovide a general definition for continuum orchestration, and look at how\ncurrent and emerging orchestration paradigms are suitable for the computing\ncontinuum. We describe certain major emerging research themes that may affect\nfuture orchestration, and provide an early vision of an orchestration paradigm\nthat embraces those research themes. Finally, we survey current key edge AI\nmethods and look at how they may contribute into fulfilling the vision of\nfuture continuum orchestration.",
    "descriptor": "",
    "authors": [
      "Henna Kokkonen",
      "Lauri Lov\u00e9n",
      "Naser Hossein Motlagh",
      "Juha Partala",
      "Alfonso Gonz\u00e1lez-Gil",
      "Ester Sola",
      "I\u00f1igo Angulo",
      "Madhusanka Liyanage",
      "Teemu Lepp\u00e4nen",
      "Tri Nguyen",
      "Panos Kostakos",
      "Mehdi Bennis",
      "Sasu Tarkoma",
      "Schahram Dustdar",
      "Susanna Pirttikangas",
      "Jukka Riekki"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01423"
  },
  {
    "id": "arXiv:2205.01428",
    "title": "Filtering and Sampling Object-Centric Event Logs",
    "abstract": "The scalability of process mining techniques is one of the main challenges to\ntackling the massive amount of event data produced every day in enterprise\ninformation systems. To this purpose, filtering and sampling techniques are\nproposed to keep a subset of the behavior of the original log and make the\napplication of process mining techniques feasible. While techniques for\nfiltering/sampling traditional event logs have been already proposed,\nfiltering/sampling object-centric event logs is more challenging as the number\nof factors (events, objects, object types) to consider is significantly higher.\nThis paper provides some techniques to filter/sample object-centric event logs.",
    "descriptor": "",
    "authors": [
      "Alessandro Berti"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2205.01428"
  },
  {
    "id": "arXiv:2205.01429",
    "title": "Differentially Private Subgraph Counting in the Shuffle Model",
    "abstract": "Subgraph counting is fundamental for analyzing connection patterns or\nclustering tendencies in graph data. Recent studies have applied LDP (Local\nDifferential Privacy) to subgraph counting to protect user privacy even against\na data collector in both centralized and decentralized social networks.\nHowever, existing local algorithms suffer from extremely large estimation\nerrors or assume multi-round interaction between users and the data collector,\nwhich requires a lot of user effort and synchronization.\nIn this paper, we focus on a one-round of interaction and propose accurate\nsubgraph counting algorithms by introducing a recently studied shuffle model.\nWe first propose a basic technique called wedge shuffling to send wedge\ninformation, the main component of several subgraphs, with small noise. Then we\napply our wedge shuffling to counting triangles and 4-cycles -- basic subgraphs\nfor analyzing clustering tendencies -- with several additional techniques. We\nalso show upper bounds on the estimation error for each algorithm. We show\nthrough comprehensive experiments that our one-round shuffle algorithms\nsignificantly outperform the one-round local algorithms in terms of accuracy\nand achieve small estimation errors with a reasonable privacy budget, e.g.,\nsmaller than 1 in edge DP.",
    "descriptor": "\nComments: The first and second authors made equal contribution\n",
    "authors": [
      "Jacob Imola",
      "Takao Murakami",
      "Kamalika Chaudhuri"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2205.01429"
  },
  {
    "id": "arXiv:2205.01430",
    "title": "A Riccati-Lyapunov Approach to Nonfeedback Capacity of MIMO Gaussian  Channels Driven by Stable and Unstable Noise",
    "abstract": "In this paper it is shown that the nonfeedback capacity of multiple-input\nmultiple-output (MIMO) additive Gaussian noise (AGN) channels, when the noise\nis nonstationary and unstable, is characterized by an asymptotic optimization\nproblem that involves, a generalized matrix algebraic Riccati equation (ARE) of\nfiltering theory, and a matrix Lyapunov equation of stability theory of\nGaussian systems. Furthermore, conditions are identified such that, the\ncharacterization of nonfeedback capacity corresponds to the uniform asymptotic\nper unit time limit, over all initial distributions, of the characterization of\na finite block or transmission without feedback information (FTwFI) capacity,\nwhich involves, two generalized matrix difference Riccati equations (DREs) and\na matrix difference Lyapunov equation.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Charalambos D. Charalambous",
      "Stelios Louka"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.01430"
  },
  {
    "id": "arXiv:2205.01432",
    "title": "ARCADE: Adversarially Regularized Convolutional Autoencoder for Network  Anomaly Detection",
    "abstract": "As the number of heterogenous IP-connected devices and traffic volume\nincrease, so does the potential for security breaches. The undetected\nexploitation of these breaches can bring severe cybersecurity and privacy\nrisks. In this paper, we present a practical unsupervised anomaly-based deep\nlearning detection system called ARCADE (Adversarially Regularized\nConvolutional Autoencoder for unsupervised network anomaly DEtection). ARCADE\nexploits the property of 1D Convolutional Neural Networks (CNNs) and Generative\nAdversarial Networks (GAN) to automatically build a profile of the normal\ntraffic based on a subset of raw bytes of a few initial packets of network\nflows so that potential network anomalies and intrusions can be effectively\ndetected before they could cause any more damage to the network. A\nconvolutional Autoencoder (AE) is proposed that suits online detection in\nresource-constrained environments, and can be easily improved for environments\nwith higher computational capabilities. An adversarial training strategy is\nproposed to regularize and decrease the AE's capabilities to reconstruct\nnetwork flows that are out of the normal distribution, and thereby improve its\nanomaly detection capabilities. The proposed approach is more effective than\nexisting state-of-the-art deep learning approaches for network anomaly\ndetection and significantly reduces detection time. The evaluation results show\nthat the proposed approach is suitable for anomaly detection on\nresource-constrained hardware platforms such as Raspberry Pi.",
    "descriptor": "",
    "authors": [
      "Willian T. Lunardi",
      "Martin Andreoni Lopez",
      "Jean-Pierre Giacalone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.01432"
  },
  {
    "id": "arXiv:2205.01435",
    "title": "RLFlow: Optimising Neural Network Subgraph Transformation with World  Models",
    "abstract": "We explored the use of reinforcement learning (RL) agents that can learn to\nperform neural network subgraph transformations, without the need of expertly\ndesigned heuristics to achieve a high level of performance. Reducing compute\nrequirements of deep learning models is a focus of extensive research and many\nsystems, optimisations and just-in-time (JIT) compilers have been proposed to\ndecrease runtime.\nRecent work has aimed to apply reinforcement learning to computer systems\nwith some success, especially using model-free RL techniques. Model-based\nreinforcement learning methods have seen an increased focus in research as they\ncan be used to learn the transition dynamics of the environment; this can be\nleveraged to train an agent using the hallucinogenic environment, thereby\nincreasing sample efficiency compared to model-free approaches. Furthermore,\nwhen using a world model as a simulated environment, batch rollouts can occur\nsafely in parallel and, especially in systems environments, it overcomes the\nlatency impact of updating system environments that can take orders of\nmagnitude longer to perform an action compared to simple emulators for video\ngames.\nWe propose a design for a model-based agent which learns to optimise the\narchitecture of neural networks by performing a sequence of subgraph\ntransformations to reduce model runtime. We show our approach can match the\nperformance of state of the art on common convolutional networks and outperform\nthose by up to 5% on transformer-style architectures.",
    "descriptor": "\nComments: 12 pages, 11 figures\n",
    "authors": [
      "Sean Parker",
      "Sami Alabed",
      "Eiko Yoneki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01435"
  },
  {
    "id": "arXiv:2205.01438",
    "title": "Efficient and Convergent Federated Learning",
    "abstract": "Federated learning has shown its advances over the last few years but is\nfacing many challenges, such as how algorithms save communication resources,\nhow they reduce computational costs, and whether they converge. To address\nthese issues, this paper proposes a new federated learning algorithm (FedGiA)\nthat combines the gradient descent and the inexact alternating direction method\nof multipliers. It is shown that FedGiA is computation and\ncommunication-efficient and convergent linearly under mild conditions.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2110.15318; text overlap with arXiv:2204.10607\n",
    "authors": [
      "Shenglong Zhou",
      "Geoffrey Ye Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.01438"
  },
  {
    "id": "arXiv:2205.01440",
    "title": "How Are Communication Channels on GitHub Presented to Their Intended  Audience? -- A Thematic Analysis",
    "abstract": "Communication is essential in software development, and even more in\ndistributed settings. Communication activities need to be organized and\ncoordinated to defend against the threat of productivity losses, increases in\ncognitive load, and stress among team members. With a plethora of communication\nchannels that were identified by previous research in open-source projects,\nthere is a need to explore organizational issues in how these communication\nchannels are introduced, explained, and motivated for use among all project\nmembers. In this study, we wanted to understand which communication channels\nare used in GitHub projects and how they are presented to the GitHub project\naudience. We employed thematic analysis to analyze 151 artifacts in 90 GitHub\nprojects. Our results revealed 32 unique communications channels that can be\ndivided into nine different types. Projects mostly provide channels of\ndifferent types, but for some types (e.g., chat) it is common to provide\nseveral channels. Maintainers are aware that channels have different properties\nand help the developers to decide which channel should be used in which case.\nHowever, this is not true for all projects, and often we have not found any\nexplicit reasons why maintainers chose to provide one channel over another.\nDifferent channels can be used for different purposes and have different\naffordances, so maintainers have to decide wisely which channels they want to\nprovide and make clear which channel should be used in which case. Otherwise,\ndevelopers might feel overwhelmed of too many channels and information can get\nfragmented over multiple channels.",
    "descriptor": "\nComments: 10 pages, 5 figures. Accepted for presentation at the International Conference on Evaluation and Assessment in Software Engineering (EASE) 2022\n",
    "authors": [
      "Verena Ebert",
      "Daniel Graziotin",
      "Stefan Wagner"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.01440"
  },
  {
    "id": "arXiv:2205.01446",
    "title": "A Cross-Company Ethnographic Study on Software Teams for DevOps and  Microservices: Organization, Benefits, and Issues",
    "abstract": "Context: DevOps and microservices are acknowledged to be important new\nparadigms to tackle contemporary software demands and provide capabilities for\nrapid and reliable software development. Industrial reports show that they are\nquickly adopted together in massive software companies. However, because of the\ntechnical and organizational requirements, many difficulties against efficient\nimplementation of the both emerge in real software teams. Objectives: This\nstudy aims to discover the organization, benefits and issues of software teams\nusing DevOps & microservices from an immersive perspective. Method: An\nethnographic study was carried out in three companies with different business,\nsize, products, customers, and degree of globalization. All the three companies\nclaimed their adoption of DevOps and microservices. Seven months (cumulative)\nof participant observations and nine interviews with practitioners were\nconducted to collect the data of software teams related to DevOps and\nmicroservices. A cross-company empirical investigation using grounded theory\nwas done by analyzing the archive data. Results: The adoption of DevOps and\nmicroservices brings benefits to rapid delivery, ability improvements and\nburden reduction, whilst the high cost and lack of practical guidance were\nemerged. Moreover, our observations and interviews reflect that in software\nteams, the relationship between DevOps and microservices is not significant,\nwhich differs from the relationship described in the previous studies. Four\nlessons for practitioners and four implications for researchers were discussed\nbased on our findings. Conclusion: Our findings contribute to the understanding\nof the organization, benefits and issues of adopting DevOps and microservices\nfrom an immersive perspective of software teams.",
    "descriptor": "",
    "authors": [
      "Xin Zhou",
      "Huang Huang",
      "He Zhang",
      "Xin Huang",
      "Dong Shao",
      "Chenxing Zhong"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.01446"
  },
  {
    "id": "arXiv:2205.01447",
    "title": "Model-Free Opponent Shaping",
    "abstract": "In general-sum games, the interaction of self-interested learning agents\ncommonly leads to collectively worst-case outcomes, such as defect-defect in\nthe iterated prisoner's dilemma (IPD). To overcome this, some methods, such as\nLearning with Opponent-Learning Awareness (LOLA), shape their opponents'\nlearning process. However, these methods are myopic since only a small number\nof steps can be anticipated, are asymmetric since they treat other agents as\nnaive learners, and require the use of higher-order derivatives, which are\ncalculated through white-box access to an opponent's differentiable learning\nalgorithm. To address these issues, we propose Model-Free Opponent Shaping\n(M-FOS). M-FOS learns in a meta-game in which each meta-step is an episode of\nthe underlying (\"inner\") game. The meta-state consists of the inner policies,\nand the meta-policy produces a new inner policy to be used in the next episode.\nM-FOS then uses generic model-free optimisation methods to learn meta-policies\nthat accomplish long-horizon opponent shaping. Empirically, M-FOS\nnear-optimally exploits naive learners and other, more sophisticated algorithms\nfrom the literature. For example, to the best of our knowledge, it is the first\nmethod to learn the well-known Zero-Determinant (ZD) extortion strategy in the\nIPD. In the same settings, M-FOS leads to socially optimal outcomes under\nmeta-self-play. Finally, we show that M-FOS can be scaled to high-dimensional\nsettings.",
    "descriptor": "",
    "authors": [
      "Chris Lu",
      "Timon Willi",
      "Christian Schroeder de Witt",
      "Jakob Foerster"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2205.01447"
  },
  {
    "id": "arXiv:2205.01448",
    "title": "Approximate Selection with Unreliable Comparisons in Optimal Expected  Time",
    "abstract": "Given $n$ elements, an integer $k$ and a parameter $\\varepsilon$, we study to\nselect an element with rank in $(k-n\\varepsilon,k+n\\varepsilon]$ using\nunreliable comparisons where the outcome of each comparison is incorrect\nindependently with a constant error probability, and multiple comparisons\nbetween the same pair of elements are independent. In this fault model, the\nfundamental problems of finding the minimum, selecting the $k$-th smallest\nelement and sorting have been shown to require $\\Theta\\big(n \\log\n\\frac{1}{Q}\\big)$, $\\Theta\\big(n\\log \\frac{\\min\\{k,n-k\\}}{Q}\\big)$ and\n$\\Theta\\big(n\\log \\frac{n}{Q}\\big)$ comparisons, respectively, to achieve\nsuccess probability $1-Q$. Recently, Leucci and Liu proved that the approximate\nminimum selection problem ($k=0$) requires expected\n$\\Theta(\\varepsilon^{-1}\\log \\frac{1}{Q})$ comparisons.\nWe develop a randomized algorithm that performs expected\n$O(\\frac{k}{n}\\varepsilon^{-2} \\log \\frac{1}{Q})$ comparisons to achieve\nsuccess probability at least $1-Q$. We also prove that any randomized algorithm\nwith success probability at least $1-Q$ performs expected\n$\\Omega(\\frac{k}{n}\\varepsilon^{-2}\\log \\frac{1}{Q})$ comparisons. Our results\nindicate a clear distinction between approximating the minimum and\napproximating the $k$-th smallest element, which holds even for the high\nprobability guarantee, e.g., if $k=\\frac{n}{2}$ and $Q=\\frac{1}{n}$,\n$\\Theta(\\varepsilon^{-1}\\log n)$ versus $\\Theta(\\varepsilon^{-2}\\log n)$.\nMoreover, if $\\varepsilon=n^{-\\alpha}$ for $\\alpha \\in (0,\\frac{1}{2})$, the\nasymptotic difference is almost quadratic, i.e., $\\tilde{\\Theta}(n^{\\alpha})$\nversus $\\tilde{\\Theta}(n^{2\\alpha})$.",
    "descriptor": "",
    "authors": [
      "Shengyu Huang",
      "Chih-Hung Liu",
      "Daniel Rutschman"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.01448"
  },
  {
    "id": "arXiv:2205.01449",
    "title": "Does a Program Yield the Right Distribution? Verifying Probabilistic  Programs via Generating Functions",
    "abstract": "We study discrete probabilistic programs with potentially unbounded looping\nbehaviors over an infinite state space. We present, to the best of our\nknowledge, the first decidability result for the problem of determining whether\nsuch a program generates exactly a specified distribution over its outputs\n(provided the program terminates almost surely). The class of distributions\nthat can be specified in our formalism consists of standard distributions\n(geometric, uniform, etc.) and finite convolutions thereof. Our method relies\non representing these (possibly infinite-support) distributions as probability\ngenerating functions which admit effective arithmetic operations. We have\nautomated our techniques in a tool called prodigy, which supports automatic\ninvariance checking, compositional reasoning of nested loops, and efficient\nqueries on various quantities of to the output distribution, as demonstrated by\nexperiments.",
    "descriptor": "\nComments: Full version of CAV2022 paper including an appendix with proofs and further material; 44 pages\n",
    "authors": [
      "Mingshuai Chen",
      "Joost-Pieter Katoen",
      "Lutz Klinkenberg",
      "Tobias Winkler"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2205.01449"
  },
  {
    "id": "arXiv:2205.01453",
    "title": "Understanding the Moments of Tabulation Hashing via Chaoses",
    "abstract": "Simple tabulation hashing dates back to Zobrist in 1970 and is defined as\nfollows: Each key is viewed as $c$ characters from some alphabet $\\Sigma$, we\nhave $c$ fully random hash functions $h_0, \\ldots, h_{c - 1} \\colon \\Sigma \\to\n\\{0, \\ldots, 2^l - 1\\}$, and a key $x = (x_0, \\ldots, x_{c - 1})$ is hashed to\n$h(x) = h_0(x_0) \\oplus \\ldots \\oplus h_{c - 1}(x_{c - 1})$ where $\\oplus$ is\nthe bitwise XOR operation. The previous results on tabulation hashing by P{\\v\na}tra{\\c s}cu and Thorup~[J.ACM'11] and by Aamand et al.~[STOC'20] focused on\nproving Chernoff-style tail bounds on hash-based sums, e.g., the number keys\nhashing to a given value, for simple tabulation hashing, but their bounds do\nnot cover the entire tail.\nChaoses are random variables of the form $\\sum a_{i_0, \\ldots, i_{c - 1}}\nX_{i_0} \\cdot \\ldots \\cdot X_{i_{c - 1}}$ where $X_i$ are independent random\nvariables. Chaoses are a well-studied concept from probability theory, and\ntight analysis has been proven in several instances, e.g., when the independent\nrandom variables are standard Gaussian variables and when the independent\nrandom variables have logarithmically convex tails. We notice that hash-based\nsums of simple tabulation hashing can be seen as a sum of chaoses that are not\nindependent. This motivates us to use techniques from the theory of chaoses to\nanalyze hash-based sums of simple tabulation hashing.\nIn this paper, we obtain bounds for all the moments of hash-based sums for\nsimple tabulation hashing which are tight up to constants depending only on\n$c$. In contrast with the previous attempts, our approach will mostly be\nanalytical and does not employ intricate combinatorial arguments. The improved\nanalysis of simple tabulation hashing allows us to obtain bounds for the\nmoments of hash-based sums for the mixed tabulation hashing introduced by\nDahlgaard et al.~[FOCS'15].",
    "descriptor": "\nComments: 79 pages. Extended abstract to appear at ICALP'22\n",
    "authors": [
      "Jakob B\u00e6k Tejs Houen",
      "Mikkel Thorup"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.01453"
  },
  {
    "id": "arXiv:2205.01457",
    "title": "Efficient implementation of incremental proximal-point methods",
    "abstract": "Model training algorithms which observe a small portion of the training set\nin each computational step are ubiquitous in practical machine learning, and\ninclude both stochastic and online optimization methods. In the vast majority\nof cases, such algorithms typically observe the training samples via the\ngradients of the cost functions the samples incur. Thus, these methods exploit\nare the \\emph{slope} of the cost functions via their first-order\napproximations.\nTo address limitations of gradient-based methods, such as sensitivity to\nstep-size choice in the stochastic setting, or inability to exploit small\nfunction variability in the online setting, several streams of research attempt\nto exploit more information about the cost functions than just their gradients\nvia the well-known proximal framework of optimization. However, implementing\nsuch methods in practice poses a challenge, since each iteration step boils\ndown to computing a proximal operator, which may not be easy. In this work we\nprovide efficient algorithms and corresponding implementations of proximal\noperators in order to make experimentation with incremental proximal\noptimization algorithms accessible to a larger audience of researchers and\npractitioners, and in particular to promote additional theoretical research\ninto these methods by closing the gap between their theoretical description in\nresearch papers and their use in practice. The corresponding code is published\nat https://github.com/alexshtf/inc_prox_pt.",
    "descriptor": "\nComments: Submitted to JMLR\n",
    "authors": [
      "Alex Shtoff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.01457"
  },
  {
    "id": "arXiv:2205.01460",
    "title": "3D Semantic Scene Perception using Distributed Smart Edge Sensors",
    "abstract": "We present a system for 3D semantic scene perception consisting of a network\nof distributed smart edge sensors. The sensor nodes are based on an embedded\nCNN inference accelerator and RGB-D and thermal cameras. Efficient vision CNN\nmodels for object detection, semantic segmentation, and human pose estimation\nrun on-device in real time. 2D human keypoint estimations, augmented with the\nRGB-D depth estimate, as well as semantically annotated point clouds are\nstreamed from the sensors to a central backend, where multiple viewpoints are\nfused into an allocentric 3D semantic scene model. As the image interpretation\nis computed locally, only semantic information is sent over the network. The\nraw images remain on the sensor boards, significantly reducing the required\nbandwidth, and mitigating privacy risks for the observed persons. We evaluate\nthe proposed system in challenging real-world multi-person scenes in our lab.\nThe proposed perception system provides a complete scene view containing\nsemantically annotated 3D geometry and estimates 3D poses of multiple persons\nin real time.",
    "descriptor": "\nComments: 17th International Conference on Intelligent Autonomous Systems (IAS), Zagreb, Croatia, June 2022\n",
    "authors": [
      "Simon Bultmann",
      "Sven Behnke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.01460"
  },
  {
    "id": "arXiv:2205.01464",
    "title": "Inducing and Using Alignments for Transition-based AMR Parsing",
    "abstract": "Transition-based parsers for Abstract Meaning Representation (AMR) rely on\nnode-to-word alignments. These alignments are learned separately from parser\ntraining and require a complex pipeline of rule-based components,\npre-processing, and post-processing to satisfy domain-specific constraints.\nParsers also train on a point-estimate of the alignment pipeline, neglecting\nthe uncertainty due to the inherent ambiguity of alignment. In this work we\nexplore two avenues for overcoming these limitations. First, we propose a\nneural aligner for AMR that learns node-to-word alignments without relying on\ncomplex pipelines. We subsequently explore a tighter integration of aligner and\nparser training by considering a distribution over oracle action sequences\narising from aligner uncertainty. Empirical results show this approach leads to\nmore accurate alignments and generalization better from the AMR2.0 to AMR3.0\ncorpora. We attain a new state-of-the art for gold-only trained models,\nmatching silver-trained performance without the need for beam search on AMR3.0.",
    "descriptor": "\nComments: Accepted at NAACL 2022\n",
    "authors": [
      "Andrew Drozdov",
      "Jiawei Zhou",
      "Radu Florian",
      "Andrew McCallum",
      "Tahira Naseem",
      "Yoon Kim",
      "Ramon Fernandez Astudillo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01464"
  },
  {
    "id": "arXiv:2205.01467",
    "title": "On the Effect of Information Asymmetry in Human-AI Teams",
    "abstract": "Over the last years, the rising capabilities of artificial intelligence (AI)\nhave improved human decision-making in many application areas. Teaming between\nAI and humans may even lead to complementary team performance (CTP), i.e., a\nlevel of performance beyond the ones that can be reached by AI or humans\nindividually. Many researchers have proposed using explainable AI (XAI) to\nenable humans to rely on AI advice appropriately and thereby reach CTP.\nHowever, CTP is rarely demonstrated in previous work as often the focus is on\nthe design of explainability, while a fundamental prerequisite -- the presence\nof complementarity potential between humans and AI -- is often neglected.\nTherefore, we focus on the existence of this potential for effective human-AI\ndecision-making. Specifically, we identify information asymmetry as an\nessential source of complementarity potential, as in many real-world\nsituations, humans have access to different contextual information. By\nconducting an online experiment, we demonstrate that humans can use such\ncontextual information to adjust the AI's decision, finally resulting in CTP.",
    "descriptor": "\nComments: CHI Conference on Human Factors in Computing Systems (CHI '22), Workshop on Human-Centered Explainable AI (HCXAI)\n",
    "authors": [
      "Patrick Hemmer",
      "Max Schemmer",
      "Niklas K\u00fchl",
      "Michael V\u00f6ssing",
      "Gerhard Satzger"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01467"
  },
  {
    "id": "arXiv:2205.01469",
    "title": "On the Convergence of Fictitious Play: A Decomposition Approach",
    "abstract": "Fictitious play (FP) is one of the most fundamental game-theoretical learning\nframeworks for computing Nash equilibrium in $n$-player games, which builds the\nfoundation for modern multi-agent learning algorithms. Although FP has provable\nconvergence guarantees on zero-sum games and potential games, many real-world\nproblems are often a mixture of both and the convergence property of FP has not\nbeen fully studied yet. In this paper, we extend the convergence results of FP\nto the combinations of such games and beyond. Specifically, we derive new\nconditions for FP to converge by leveraging game decomposition techniques. We\nfurther develop a linear relationship unifying cooperation and competition in\nthe sense that these two classes of games are mutually transferable. Finally,\nwe analyze a non-convergent example of FP, the Shapley game, and develop\nsufficient conditions for FP to converge.",
    "descriptor": "",
    "authors": [
      "Yurong Chen",
      "Xiaotie Deng",
      "Chenchen Li",
      "David Mguni",
      "Jun Wang",
      "Xiang Yan",
      "Yaodong Yang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2205.01469"
  },
  {
    "id": "arXiv:2205.01470",
    "title": "Revisiting Communication-Efficient Federated Learning with Balanced  Global and Local Updates",
    "abstract": "In federated learning (FL), a number of devices train their local models and\nupload the corresponding parameters or gradients to the base station (BS) to\nupdate the global model while protecting their data privacy. However, due to\nthe limited computation and communication resources, the number of local\ntrainings (a.k.a. local update) and that of aggregations (a.k.a. global update)\nneed to be carefully chosen. In this paper, we investigate and analyze the\noptimal trade-off between the number of local trainings and that of global\naggregations to speed up the convergence and enhance the prediction accuracy\nover the existing works. Our goal is to minimize the global loss function under\nboth the delay and the energy consumption constraints. In order to make the\noptimization problem tractable, we derive a new and tight upper bound on the\nloss function, which allows us to obtain closed-form expressions for the number\nof local trainings and that of global aggregations. Simulation results show\nthat our proposed scheme can achieve a better performance in terms of the\nprediction accuracy, and converge much faster than the baseline schemes.",
    "descriptor": "",
    "authors": [
      "Zhigang Yan",
      "Dong Li",
      "Zhichao Zhang",
      "Jiguang He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.01470"
  },
  {
    "id": "arXiv:2205.01472",
    "title": "Learning Economic Indicators by Aggregating Multi-Level Geospatial  Information",
    "abstract": "High-resolution daytime satellite imagery has become a promising source to\nstudy economic activities. These images display detailed terrain over large\nareas and allow zooming into smaller neighborhoods. Existing methods, however,\nhave utilized images only in a single-level geographical unit. This research\npresents a deep learning model to predict economic indicators via aggregating\ntraits observed from multiple levels of geographical units. The model first\nmeasures hyperlocal economy over small communities via ordinal regression. The\nnext step extracts district-level features by summarizing interconnection among\nhyperlocal economies. In the final step, the model estimates economic\nindicators of districts via aggregating the hyperlocal and district\ninformation. Our new multi-level learning model substantially outperforms\nstrong baselines in predicting key indicators such as population, purchasing\npower, and energy consumption. The model is also robust against data shortage;\nthe trained features from one country can generalize to other countries when\nevaluated with data gathered from Malaysia, the Philippines, Thailand, and\nVietnam. We discuss the multi-level model's implications for measuring\ninequality, which is the essential first step in policy and social science\nresearch on inequality and poverty.",
    "descriptor": "\nComments: Accepted at AAAI2022\n",
    "authors": [
      "Sungwon Park",
      "Sungwon Han",
      "Donghyun Ahn",
      "Jaeyeon Kim",
      "Jeasurk Yang",
      "Susang Lee",
      "Seunghoon Hong",
      "Jihee Kim",
      "Sangyoon Park",
      "Hyunjoo Yang",
      "Meeyoung Cha"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.01472"
  },
  {
    "id": "arXiv:2205.01476",
    "title": "Real-Time Streaming and Event-driven Control of Scientific Experiments",
    "abstract": "Advancements in scientific instrument sensors and connected devices provide\nunprecedented insight into ongoing experiments and present new opportunities\nfor control, optimization, and steering. However, the diversity of sensors and\nheterogeneity of their data result in make it challenging to fully realize\nthese new opportunities. Organizing and synthesizing diverse data streams in\nnear-real-time requires both rich automation and Machine Learning (ML). To\nefficiently utilize ML during an experiment, the entire ML lifecycle must be\naddressed, including refining experiment configurations, retraining models, and\napplying decisions-tasks that require an equally diverse array of computational\nresources spanning centralized HPC to the accelerators at the edge. Here we\npresent the Manufacturing Data and Machine Learning platform (MDML). The MDML\nis designed to standardize the research and operational environment for\nadvanced data analytics and ML-enabled automated process optimization by\nproviding the cyberinfrastructure to integrate sensor data streams and AI in\ncyber-physical systems for in-situ analysis. To achieve this, the MDML provides\na fabric to receive and aggregate IoT data and simultaneously orchestrate\nremote computation across the computing continuum. In this paper we describe\nthe MDML and show how it is used in advanced manufacturing to act on IoT data\nand orchestrate distributed ML to guide experiments.",
    "descriptor": "",
    "authors": [
      "Jakob R. Elias",
      "Ryan Chard",
      "Maksim Levental",
      "Zhengchun Liu",
      "Ian Foster",
      "Santanu Chaudhuri"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.01476"
  },
  {
    "id": "arXiv:2205.01480",
    "title": "Residual Graph Convolutional Recurrent Networks For Multi-step Traffic  Flow Forecasting",
    "abstract": "Traffic flow forecasting is essential for traffic planning, control and\nmanagement. The main challenge of traffic forecasting tasks is accurately\ncapturing traffic networks' spatial and temporal correlation. Although there\nare many traffic forecasting methods, most of them still have limitations in\ncapturing spatial and temporal correlations. To improve traffic forecasting\naccuracy, we propose a new Spatial-temporal forecasting model, namely the\nResidual Graph Convolutional Recurrent Network (RGCRN). The model uses our\nproposed Residual Graph Convolutional Network (ResGCN) to capture the\nfine-grained spatial correlation of the traffic road network and then uses a\nBi-directional Gated Recurrent Unit (BiGRU) to model time series with spatial\ninformation and obtains the temporal correlation by analysing the change in\ninformation transfer between the forward and reverse neurons of the time series\ndata. Our comparative experimental results on two real datasets show that RGCRN\nimproves on average by 20.66% compared to the best baseline model. You can get\nour source code and data through https://github.com/zhangshqii/RGCRN.",
    "descriptor": "",
    "authors": [
      "Wei Zhao",
      "Shiqi Zhang",
      "Bing Zhou",
      "Bei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01480"
  },
  {
    "id": "arXiv:2205.01482",
    "title": "Hardness Results for Weaver's Discrepancy Problem",
    "abstract": "Marcus, Spielman and Srivastava (Annals of Mathematics 2014) solved the\nKadison--Singer Problem by proving a strong form of Weaver's conjecture: they\nshowed that for all $\\alpha > 0$ and all lists of vectors of norm at most\n$\\sqrt{\\alpha}$ whose outer products sum to the identity, there exists a signed\nsum of those outer products with operator norm at most $\\sqrt{8 \\alpha} + 2\n\\alpha.$ We prove that it is NP-hard to distinguish such a list of vectors for\nwhich there is a signed sum that equals the zero matrix from those in which\nevery signed sum has operator norm at least $\\kappa \\sqrt{\\alpha}$, for some\nabsolute constant $\\kappa > 0.$ Thus, it is NP-hard to construct a signing that\nis a constant factor better than that guaranteed to exist.\nFor $\\alpha = 1/4$, we prove that it is NP-hard to distinguish whether there\nis a signed sum that equals the zero matrix from the case in which every signed\nsum has operator norm at least $1/4$.",
    "descriptor": "",
    "authors": [
      "Daniel A. Spielman",
      "Peng Zhang"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.01482"
  },
  {
    "id": "arXiv:2205.01485",
    "title": "Optimal $(r,\u03b4)$-LRCs from zero-dimensional affine variety codes and  their subfield-subcodes",
    "abstract": "We introduce zero-dimensional affine variety codes (ZAVCs) which can be\nregarded as $(r,\\delta)$-locally recoverable codes (LRCs). These codes come\nwith a natural bound for their minimum distance and we determine those giving\nrise to $(r,\\delta)$-optimal LRCs for that distance, which are in fact\n$(r,\\delta)$-optimal. A large subfamily of ZAVCs admit subfield-subcodes with\nthe same parameters of the optimal codes but over smaller supporting fields.\nThis fact allows us to determine infinitely many sets of new\n$(r,\\delta)$-optimal LRCs and their parameters.",
    "descriptor": "",
    "authors": [
      "Fernando Hernando",
      "Carlos Galindo",
      "Helena Mart\u00edn-Cruz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.01485"
  },
  {
    "id": "arXiv:2205.01488",
    "title": "On the stability of strong-stability-preserving modified Patankar  Runge-Kutta schemes",
    "abstract": "In this paper, we perform stability analysis for a class of second and third\norder accurate strong-stability-preserving modified Patankar Runge-Kutta\n(SSPMPRK) schemes, which were introduced in [4,5] and can be used to solve\nconvection equations with stiff source terms, such as reactive Euler equations,\nwith guaranteed positivity under the standard CFL condition due to the\nconvection terms only. The analysis allows us to identify the range of free\nparameters in these SSPMPRK schemes in order to ensure stability. Numerical\nexperiments are provided to demonstrate the validity of the analysis.",
    "descriptor": "\nComments: 22 pages, 10 figures\n",
    "authors": [
      "Juntao Huang",
      "Thomas Izgin",
      "Stefan Kopecz",
      "Andreas Meister",
      "Chi-Wang Shu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.01488"
  },
  {
    "id": "arXiv:2205.01489",
    "title": "Computing the jump-term in space-time FEM for arbitrary temporal  interpolation",
    "abstract": "One approach with rising popularity in analyzing time-dependent problems in\nscience and engineering is the so-called space-time finite-element method that\nutilized finiteelements in both space and time. A common ansatz in this context\nis to divide the mesh in temporal direction into so-called space-time slabs,\nwhich are subsequently weakly connected in time with a Discontinuous Galerkin\napproach. The corresponding jumpterm, which is responsible for imposing the\nweak continuity across space-time slabs can be challenging to compute, in\nparticular in the context of deforming domains. Ensuring a conforming\ndiscretization of the space-time slab at the top and bottom in time direction\nsimplifies the handling of this term immensely. Otherwise, a computationally\nexpensive and error prone projection of the solution from one time-level to\nanother is necessary. However, when it comes to simulations with deformable\ndomains, e.g. for free-surface flows, ensuring conforming meshes is quite\nlaborious. A possible solution to this challenge is to extrude a spatial mesh\nin time at each time-step resulting in the so-called time-discontinuous\nprismatic space-time (D-PST) method. However, this procedure is restricted to\nfinite-elements of 1st order in time. We present a novel algorithmic approach\nfor arbitrarily discretized meshes by flipping the mesh in time-direction for\neach time-step. This ansatz allows for a simple evaluation of the jump-term as\nthe mesh is always conforming. The cost of flipping the mesh around its\nsymmetry plane in time scales with the number of nodes, which makes it\ncomputationally cheaper than an additional update of the mesh to enforce\nconformity or the evaluation of a projection. We validate the approach on\nvarious physical problems with and without deforming domains.",
    "descriptor": "",
    "authors": [
      "Eugen Salzmann",
      "Florian Zwicke",
      "Stefanie Elgeti"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2205.01489"
  },
  {
    "id": "arXiv:2205.01490",
    "title": "Subspace Diffusion Generative Models",
    "abstract": "Score-based models generate samples by mapping noise to data (and vice versa)\nvia a high-dimensional diffusion process. We question whether it is necessary\nto run this entire process at high dimensionality and incur all the\ninconveniences thereof. Instead, we restrict the diffusion via projections onto\nsubspaces as the data distribution evolves toward noise. When applied to\nstate-of-the-art models, our framework simultaneously improves sample quality\n-- reaching an FID of 2.17 on unconditional CIFAR-10 -- and reduces the\ncomputational cost of inference for the same number of denoising steps. Our\nframework is fully compatible with continuous-time diffusion and retains its\nflexible capabilities, including exact log-likelihoods and controllable\ngeneration. Code is available at\nhttps://github.com/bjing2016/subspace-diffusion.",
    "descriptor": "",
    "authors": [
      "Bowen Jing",
      "Gabriele Corso",
      "Renato Berlinghieri",
      "Tommi Jaakkola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01490"
  },
  {
    "id": "arXiv:2205.01491",
    "title": "A Comprehensive Survey of Image Augmentation Techniques for Deep  Learning",
    "abstract": "Deep learning has been achieving decent performance in computer vision\nrequiring a large volume of images, however, collecting images is expensive and\ndifficult in many scenarios. To alleviate this issue, many image augmentation\nalgorithms have been proposed as effective and efficient strategies.\nUnderstanding current algorithms is essential to find suitable methods or\ndevelop novel techniques for given tasks. In this paper, we perform a\ncomprehensive survey on image augmentation for deep learning with a novel\ninformative taxonomy. To get the basic idea why we need image augmentation, we\nintroduce the challenges in computer vision tasks and vicinity distribution.\nThen, the algorithms are split into three categories; model-free, model-based,\nand optimizing policy-based. The model-free category employs image processing\nmethods while the model-based method leverages trainable image generation\nmodels. In contrast, the optimizing policy-based approach aims to find the\noptimal operations or their combinations. Furthermore, we discuss the current\ntrend of common applications with two more active topics, leveraging different\nways to understand image augmentation, such as group and kernel theory, and\ndeploying image augmentation for unsupervised learning. Based on the analysis,\nwe believe that our survey gives a better understanding helpful to choose\nsuitable methods or design novel algorithms for practical applications.",
    "descriptor": "\nComments: 41 pages\n",
    "authors": [
      "Mingle Xu",
      "Sook Yoon",
      "Alvaro Fuentes",
      "Dong Sun Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01491"
  },
  {
    "id": "arXiv:2205.01492",
    "title": "A unified view on Self-Organizing Maps (SOMs) and Stochastic Neighbor  Embedding (SNE)",
    "abstract": "We propose a unified view on two widely used data visualization techniques:\nSelf-Organizing Maps (SOMs) and Stochastic Neighbor Embedding (SNE). We show\nthat they can both be derived from a common mathematical framework. Leveraging\nthis formulation, we propose to compare SOM and SNE quantitatively on two\ndatasets, and discuss possible avenues for future work to take advantage of\nboth approaches.",
    "descriptor": "",
    "authors": [
      "Thibaut Kulak",
      "Anthony Fillion",
      "Fran\u00e7ois Blayo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.01492"
  },
  {
    "id": "arXiv:2205.01493",
    "title": "On the uncertainty principle of neural networks",
    "abstract": "Despite the successes in many fields, it is found that neural networks are\nvulnerability and difficult to be both accurate and robust (robust means that\nthe prediction of the trained network stays unchanged for inputs with\nnon-random perturbations introduced by adversarial attacks). Various empirical\nand analytic studies have suggested that there is more or less a trade-off\nbetween the accuracy and robustness of neural networks. If the trade-off is\ninherent, applications based on the neural networks are vulnerable with\nuntrustworthy predictions. It is then essential to ask whether the trade-off is\nan inherent property or not. Here, we show that the accuracy-robustness\ntrade-off is an intrinsic property whose underlying mechanism is deeply related\nto the uncertainty principle in quantum mechanics. We find that for a neural\nnetwork to be both accurate and robust, it needs to resolve the features of the\ntwo conjugated parts $x$ (the inputs) and $\\Delta$ (the derivatives of the\nnormalized loss function $J$ with respect to $x$), respectively. Analogous to\nthe position-momentum conjugation in quantum mechanics, we show that the inputs\nand their conjugates cannot be resolved by a neural network simultaneously.",
    "descriptor": "\nComments: 8 pages, 8 figures\n",
    "authors": [
      "Jun-Jie Zhang",
      "Dong-Xiao Zhang",
      "Jian-Nan Chen",
      "Long-Gang Pang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.01493"
  },
  {
    "id": "arXiv:2205.01497",
    "title": "Semantic Diversity in Dialogue with Natural Language Inference",
    "abstract": "Generating diverse, interesting responses to chitchat conversations is a\nproblem for neural conversational agents. This paper makes two substantial\ncontributions to improving diversity in dialogue generation. First, we propose\na novel metric which uses Natural Language Inference (NLI) to measure the\nsemantic diversity of a set of model responses for a conversation. We evaluate\nthis metric using an established framework (Tevet and Berant, 2021) and find\nstrong evidence indicating NLI Diversity is correlated with semantic diversity.\nSpecifically, we show that the contradiction relation is more useful than the\nneutral relation for measuring this diversity and that incorporating the NLI\nmodel's confidence achieves state-of-the-art results. Second, we demonstrate\nhow to iteratively improve the semantic diversity of a sampled set of responses\nvia a new generation procedure called Diversity Threshold Generation, which\nresults in an average 137% increase in NLI Diversity compared to standard\ngeneration procedures.",
    "descriptor": "\nComments: To appear at NAACL 2022\n",
    "authors": [
      "Katherine Stasaski",
      "Marti A. Hearst"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01497"
  },
  {
    "id": "arXiv:2205.01500",
    "title": "Meta Learning for Natural Language Processing: A Survey",
    "abstract": "Deep learning has been the mainstream technique in natural language\nprocessing (NLP) area. However, the techniques require many labeled data and\nare less generalizable across domains. Meta-learning is an arising field in\nmachine learning studying approaches to learn better learning algorithms.\nApproaches aim at improving algorithms in various aspects, including data\nefficiency and generalizability. Efficacy of approaches has been shown in many\nNLP tasks, but there is no systematic survey of these approaches in NLP, which\nhinders more researchers from joining the field. Our goal with this survey\npaper is to offer researchers pointers to relevant meta-learning works in NLP\nand attract more attention from the NLP community to drive future innovation.\nThis paper first introduces the general concepts of meta-learning and the\ncommon approaches. Then we summarize task construction settings and application\nof meta-learning for various NLP problems and review the development of\nmeta-learning in NLP community.",
    "descriptor": "\nComments: Accepted by NAACL 2022\n",
    "authors": [
      "Hung-yi Lee",
      "Shang-Wen Li",
      "Ngoc Thang Vu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01500"
  },
  {
    "id": "arXiv:2205.01503",
    "title": "Uniform Vs. Non-Uniform Coarse Quantization in Mutual Information  Maximizing LDPC Decoding",
    "abstract": "Recently, low-resolution LDPC decoders have been introduced that perform\nmutual information maximizing signal processing. However, the optimal\nquantization in variable and check nodes requires expensive non-uniform\noperations. Instead, we propose to use uniform quantization with a simple\nhardware structure, which reduces the complexity of individual node operations\napproximately by half and shortens the decoding delay significantly. Our\nanalysis shows that the loss of preserved mutual information resulting from\nrestriction to uniform quantization is very small. Furthermore, the error rate\nsimulations with regular LDPC codes confirm that the uniformly quantized\ndecoders cause only minor performance degradation within 0.01 dB compared to\nthe non-uniform alternatives. Due to the complexity reduction, especially the\nproposed 3-bit decoder is a promising candidate to replace 4-bit conventional\ndecoders.",
    "descriptor": "\nComments: This work has been submitted to IEEE GLOBECOM 2022 and is currently under review\n",
    "authors": [
      "Philipp Mohr",
      "Gerhard Bauch"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.01503"
  },
  {
    "id": "arXiv:2205.01505",
    "title": "Private Matrix Multiplication From MDS-Coded Storage With Colluding  Servers",
    "abstract": "In this paper, we study the two problems of Private and Secure Matrix\nMultiplication and Fully Private Matrix Multiplication from MDS-coded storage\nwith Colluding servers, referred to as MDS-C-PSMM and MDS-C-FPMM respectively,\non a distributed computing system with a master node and multiple servers.\nSpecifically, in the MDS-C-PSMM problem, the master wants to compute the\nproduct of its owned confidential matrix $\\mathbf{A}$ with one out of a batch\nof public matrices that is stored across distributed servers according to an\nMDS code, without revealing any information about the matrix $\\mathbf{A}$ and\nthe index of another interested matrix to a certain number of colluding\nservers. In the second MDS-C-FPMM problem, the matrix $\\mathbf{A}$ is also\nselected from another batch of public matrices that is stored at the servers in\nMDS-coded form. In this case, the indices of the two interested matrices should\nbe kept private from the colluding servers. We construct computation strategies\nfor both MDS-C-PSMM and MDS-C-FPMM problems by exploiting the structure\ninspired by the encoding functions of related secure matrix multiplication\nstrategies, yielding flexible tradeoffs among recovery threshold, i.e., the\nnumber of servers required to recover desired product, computation overhead,\ni.e., the computation complexity of distributed system, and communication\noverhead, i.e., the amount of communication bits between the master and the\nservers.",
    "descriptor": "\nComments: 12 pages, 2 figures, 1 table\n",
    "authors": [
      "Jinbao Zhu",
      "Jie Li",
      "Songze Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.01505"
  },
  {
    "id": "arXiv:2205.01506",
    "title": "BasqueParl: A Bilingual Corpus of Basque Parliamentary Transcriptions",
    "abstract": "Parliamentary transcripts provide a valuable resource to understand the\nreality and know about the most important facts that occur over time in our\nsocieties. Furthermore, the political debates captured in these transcripts\nfacilitate research on political discourse from a computational social science\nperspective. In this paper we release the first version of a newly compiled\ncorpus from Basque parliamentary transcripts. The corpus is characterized by\nheavy Basque-Spanish code-switching, and represents an interesting resource to\nstudy political discourse in contrasting languages such as Basque and Spanish.\nWe enrich the corpus with metadata related to relevant attributes of the\nspeakers and speeches (language, gender, party...) and process the text to\nobtain named entities and lemmas. The obtained metadata is then used to perform\na detailed corpus analysis which provides interesting insights about the\nlanguage use of the Basque political representatives across time, parties and\ngender.",
    "descriptor": "\nComments: 9 pages, 14 figures, 4 tables. To be published in LREC 2022\n",
    "authors": [
      "Nayla Escribano",
      "Jon Ander Gonz\u00e1lez",
      "Julen Orbegozo-Terradillos",
      "Ainara Larrondo-Ureta",
      "Sim\u00f3n Pe\u00f1a-Fern\u00e1ndez",
      "Olatz Perez-de-Vi\u00f1aspre",
      "Rodrigo Agerri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01506"
  },
  {
    "id": "arXiv:2205.01508",
    "title": "Compact Neural Networks via Stacking Designed Basic Units",
    "abstract": "Unstructured pruning has the limitation of dealing with the sparse and\nirregular weights. By contrast, structured pruning can help eliminate this\ndrawback but it requires complex criterion to determine which components to be\npruned. To this end, this paper presents a new method termed TissueNet, which\ndirectly constructs compact neural networks with fewer weight parameters by\nindependently stacking designed basic units, without requiring additional\njudgement criteria anymore. Given the basic units of various architectures,\nthey are combined and stacked in a certain form to build up compact neural\nnetworks. We formulate TissueNet in diverse popular backbones for comparison\nwith the state-of-the-art pruning methods on different benchmark datasets.\nMoreover, two new metrics are proposed to evaluate compression performance.\nExperiment results show that TissueNet can achieve comparable classification\naccuracy while saving up to around 80% FLOPs and 89.7% parameters. That is,\nstacking basic units provides a new promising way for network compression.",
    "descriptor": "\nComments: 17 pages, 4 figures, 5 tables\n",
    "authors": [
      "Weichao Lan",
      "Yiu-ming Cheung",
      "Juyong Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01508"
  },
  {
    "id": "arXiv:2205.01510",
    "title": "ExSpliNet: An interpretable and expressive spline-based neural network",
    "abstract": "In this paper we present ExSpliNet, an interpretable and expressive neural\nnetwork model. The model combines ideas of Kolmogorov neural networks,\nensembles of probabilistic trees, and multivariate B-spline representations. We\ngive a probabilistic interpretation of the model and show its universal\napproximation properties. We also discuss how it can be efficiently encoded by\nexploiting B-spline properties. Finally, we test the effectiveness of the\nproposed model on synthetic approximation problems and classical machine\nlearning benchmark datasets.",
    "descriptor": "",
    "authors": [
      "Daniele Fakhoury",
      "Emanuele Fakhoury",
      "Hendrik Speleers"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.01510"
  },
  {
    "id": "arXiv:2205.01512",
    "title": "Fair Feature Subset Selection using Multiobjective Genetic Algorithm",
    "abstract": "The feature subset selection problem aims at selecting the relevant subset of\nfeatures to improve the performance of a Machine Learning (ML) algorithm on\ntraining data. Some features in data can be inherently noisy, costly to\ncompute, improperly scaled, or correlated to other features, and they can\nadversely affect the accuracy, cost, and complexity of the induced algorithm.\nThe goal of traditional feature selection approaches has been to remove such\nirrelevant features. In recent years ML is making a noticeable impact on the\ndecision-making processes of our everyday lives. We want to ensure that these\ndecisions do not reflect biased behavior towards certain groups or individuals\nbased on protected attributes such as age, sex, or race. In this paper, we\npresent a feature subset selection approach that improves both fairness and\naccuracy objectives and computes Pareto-optimal solutions using the NSGA-II\nalgorithm. We use statistical disparity as a fairness metric and F1-Score as a\nmetric for model performance. Our experiments on the most commonly used\nfairness benchmark datasets with three different machine learning algorithms\nshow that using the evolutionary algorithm we can effectively explore the\ntrade-off between fairness and accuracy.",
    "descriptor": "",
    "authors": [
      "Ayaz Ur Rehman",
      "Anas Nadeem",
      "Muhammad Zubair Malik"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01512"
  },
  {
    "id": "arXiv:2205.01513",
    "title": "Threshold Rates of Codes Ensembles: Linear is Best",
    "abstract": "In this work, we prove new results concerning the combinatorial properties of\nrandom linear codes.\nFirstly, we prove a lower bound on the list-size required for random linear\ncodes over $\\mathbb F_q$ $\\varepsilon$-close to capacity to list-recover with\nerror radius $\\rho$ and input lists of size $\\ell$. We show that the list-size\n$L$ must be at least $\\frac{\\log_q\\binom{q}{\\ell}-R}{\\varepsilon}$, where $R$\nis the rate of the random linear code. As a comparison, we also pin down the\nlist size of random codes which is $\\frac{\\log_q\\binom{q}{\\ell}}{\\varepsilon}$.\nThis leaves open the possibility (that we consider likely) that random linear\ncodes perform better than random codes for list-recoverability, which is in\ncontrast to a recent gap shown for the case of list-recovery from erasures\n(Guruswami et al., IEEE TIT 2021B).\nNext, we consider list-decoding with constant list-sizes. Specifically, we\nobtain new lower bounds on the rate required for list-of-$3$ decodability of\nrandom linear codes over $\\mathbb F_2$; and list-of-$2$ decodability of random\nlinear codes over $\\mathbb F_q$ (for any $q$). This expands upon Guruswami et\nal. (IEEE TIT 2021A) which only studied list-of-$2$ decodability of random\nlinear codes over $\\mathbb F_2$. Further, in both cases we are able to show\nthat the rate is larger than that which is possible for uniformly random codes.",
    "descriptor": "\nComments: 37 pages, 2 figures. Accepted to ICALP 2022\n",
    "authors": [
      "Nicolas Resch",
      "Chen Yuan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.01513"
  },
  {
    "id": "arXiv:2205.01515",
    "title": "Multitask Network for Joint Object Detection, Semantic Segmentation and  Human Pose Estimation in Vehicle Occupancy Monitoring",
    "abstract": "In order to ensure safe autonomous driving, precise information about the\nconditions in and around the vehicle must be available. Accordingly, the\nmonitoring of occupants and objects inside the vehicle is crucial. In the\nstate-of-the-art, single or multiple deep neural networks are used for either\nobject recognition, semantic segmentation, or human pose estimation. In\ncontrast, we propose our Multitask Detection, Segmentation and Pose Estimation\nNetwork (MDSP) -- the first multitask network solving all these three tasks\njointly in the area of occupancy monitoring. Due to the shared architecture,\nmemory and computing costs can be saved while achieving higher accuracy.\nFurthermore, our architecture allows a flexible combination of the three\nmentioned tasks during a simple end-to-end training. We perform comprehensive\nevaluations on the public datasets SVIRO and TiCaM in order to demonstrate the\nsuperior performance.",
    "descriptor": "\nComments: This paper has been accepted at IEEE Intelligent Vehicles Symposium (IV), 2022 (ORAL)\n",
    "authors": [
      "Nikolas Ebert",
      "Patrick Mangat",
      "Oliver Wasenm\u00fcller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01515"
  },
  {
    "id": "arXiv:2205.01523",
    "title": "ElitePLM: An Empirical Study on General Language Ability Evaluation of  Pretrained Language Models",
    "abstract": "Nowadays, pretrained language models (PLMs) have dominated the majority of\nNLP tasks. While, little research has been conducted on systematically\nevaluating the language abilities of PLMs. In this paper, we present a\nlarge-scale empirical study on general language ability evaluation of PLMs\n(ElitePLM). In our study, we design four evaluation dimensions, i.e. memory,\ncomprehension, reasoning, and composition, to measure ten widely-used PLMs\nwithin five categories. Our empirical results demonstrate that: (1) PLMs with\nvarying training objectives and strategies are good at different ability tests;\n(2) fine-tuning PLMs in downstream tasks is usually sensitive to the data size\nand distribution; (3) PLMs have excellent transferability between similar\ntasks. Moreover, the prediction results of PLMs in our experiments are released\nas an open resource for more deep and detailed analysis on the language\nabilities of PLMs. This paper can guide the future work to select, apply, and\ndesign PLMs for specific tasks. We have made all the details of experiments\npublicly available at https://github.com/RUCAIBox/ElitePLM.",
    "descriptor": "\nComments: Accepted by NAACL 2022 main conference (Long Paper)\n",
    "authors": [
      "Junyi Li",
      "Tianyi Tang",
      "Zheng Gong",
      "Lixin Yang",
      "Zhuohao Yu",
      "Zhipeng Chen",
      "Jingyuan Wang",
      "Wayne Xin Zhao",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01523"
  },
  {
    "id": "arXiv:2205.01527",
    "title": "Productive Parallel Programming with Parsl",
    "abstract": "Parsl is a parallel programming library for Python that aims to make it easy\nto specify parallelism in programs and to realize that parallelism on arbitrary\nparallel and distributed computing systems. Parsl relies on developers\nannotating Python functions-wrapping either Python or external applications-to\nindicate that these functions may be executed concurrently. Developers can then\nlink together functions via the exchange of data. Parsl establishes a dynamic\ndependency graph and sends tasks for execution on connected resources when\ndependencies are resolved. Parsl's runtime system enables different compute\nresources to be used, from laptops to supercomputers, without modification to\nthe Parsl program.",
    "descriptor": "",
    "authors": [
      "Kyle Chard",
      "Yadu Babuji",
      "Anna Woodard",
      "Ben Clifford",
      "Zhuozhao Li",
      "Mihael Hategan",
      "Ian Foster",
      "Mike Wilde",
      "Daniel S. Katz"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.01527"
  },
  {
    "id": "arXiv:2205.01529",
    "title": "Masked Generative Distillation",
    "abstract": "Knowledge distillation has been applied to various tasks successfully. The\ncurrent distillation algorithm usually improves students' performance by\nimitating the output of the teacher. This paper shows that teachers can also\nimprove students' representation power by guiding students' feature recovery.\nFrom this point of view, we propose Masked Generative Distillation (MGD), which\nis simple: we mask random pixels of the student's feature and force it to\ngenerate the teacher's full feature through a simple block. MGD is a truly\ngeneral feature-based distillation method, which can be utilized on various\ntasks, including image classification, object detection, semantic segmentation\nand instance segmentation. We experiment on different models with extensive\ndatasets and the results show that all the students achieve excellent\nimprovements. Notably, we boost ResNet-18 from 69.90% to 71.69% ImageNet top-1\naccuracy, RetinaNet with ResNet-50 backbone from 37.4 to 41.0 Boundingbox mAP,\nSOLO based on ResNet-50 from 33.1 to 36.2 Mask mAP and DeepLabV3 based on\nResNet-18 from 73.20 to 76.02 mIoU. Our codes are available at\nhttps://github.com/yzd-v/MGD.",
    "descriptor": "\nComments: 5 figures, 8 tables\n",
    "authors": [
      "Zhendong Yang",
      "Zhe Li",
      "Mingqi Shao",
      "Dachuan Shi",
      "Zehuan Yuan",
      "Chun Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01529"
  },
  {
    "id": "arXiv:2205.01532",
    "title": "Using Ontologies for the Formalization and Recognition of Criticality  for Automated Driving",
    "abstract": "Knowledge representation and reasoning has a long history of examining how\nknowledge can be formalized, interpreted, and semantically analyzed by\nmachines. In the area of automated vehicles, recent advances suggest the\nability to formalize and leverage relevant knowledge as a key enabler in\nhandling the inherently open and complex context of the traffic world. This\npaper demonstrates ontologies to be a powerful tool for a) modeling and\nformalization of and b) reasoning about factors associated with criticality in\nthe environment of automated vehicles. For this, we leverage the well-known\n6-Layer Model to create a formal representation of the environmental context.\nWithin this representation, an ontology models domain knowledge as logical\naxioms, enabling deduction on the presence of critical factors within traffic\nscenes and scenarios. For executing automated analyses, a joint description\nlogic and rule reasoner is used in combination with an a-priori predicate\naugmentation. We elaborate on the modular approach, present a publicly\navailable implementation, and evaluate the method by means of a large-scale\ndrone data set of urban traffic scenarios.",
    "descriptor": "",
    "authors": [
      "Lukas Westhofen",
      "Christian Neurohr",
      "Martin Butz",
      "Maike Scholtes",
      "Michael Schuldes"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.01532"
  },
  {
    "id": "arXiv:2205.01533",
    "title": "Average Age of Information Minimization in Reliable Covert Communication  on Time-Varying Channels",
    "abstract": "In this letter, we propose reliable covert communications with the aim of\nminimizing age of information (AoI) in the time-varying channels. We named the\ntime duration that channel state information (CSI) is valid as a new metric, as\nage of channel variation (AoC). To find reliable covert communication in a\nfresh manner in dynamic environments, this work considers a new constraint that\nshows a relation between AoI and AoC. With the aid of the proposed constraint,\nthis paper addresses two main challenges of reliable covert communication with\nthe aim of minimizing AoI: 1) users packets with desirable size; 2)\nguaranteeing the negligible probability of Willies detection, in time-varying\nnetworks. In the simulation results, we compare the performance of the proposed\nconstraint in reliable covert communication with the aim of minimizing AoI with\nconventional optimization of the requirement of information freshness in covert\ncommunications.",
    "descriptor": "",
    "authors": [
      "Shima Salar Hosseini",
      "Paeiz Azmi",
      "Nader Mokari"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.01533"
  },
  {
    "id": "arXiv:2205.01535",
    "title": "A review of the Separation Theorem of Chebyshev-Markov-Stieltjes for  polynomial and some rational Krylov subspaces",
    "abstract": "The accumulated quadrature weights of Gaussian quadrature formulae constitute\nbounds on the integral over the intervals between the quadrature nodes.\nClassical results in this concern date back to works of Chebyshev, Markov and\nStieltjes and are referred to as Separation Theorem of\nChebyshev-Markov-Stieltjes (CMS Theorem). Similar separation theorems hold true\nfor some classes of rational Gaussian quadrature. The Krylov subspace for a\ngiven matrix and initial vector is closely related to orthogonal polynomials\nassociated with the spectral distribution of the initial vector in the\neigenbasis of the given matrix, and Gaussian quadrature for the\nRiemann-Stielthes integral associated with this spectral distribution. Similar\nrelations hold true for rational Krylov subspaces. In the present work,\nseparation theorems are reviewed in the context of Krylov subspaces including\nrational Krylov subspaces with a single complex pole of higher multiplicity and\nsome extended Krylov subspaces. For rational Gaussian quadrature related to\nsome classes of rational Krylov subspaces with a single pole, the underlying\nseparation theorems are newly introduced here.",
    "descriptor": "",
    "authors": [
      "Tobias Jawecki"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.01535"
  },
  {
    "id": "arXiv:2205.01536",
    "title": "BiOcularGAN: Bimodal Synthesis and Annotation of Ocular Images",
    "abstract": "Current state-of-the-art segmentation techniques for ocular images are\ncritically dependent on large-scale annotated datasets, which are\nlabor-intensive to gather and often raise privacy concerns. In this paper, we\npresent a novel framework, called BiOcularGAN, capable of generating synthetic\nlarge-scale datasets of photorealistic (visible light and near infrared) ocular\nimages, together with corresponding segmentation labels to address these\nissues. At its core, the framework relies on a novel Dual-Branch StyleGAN2\n(DB-StyleGAN2) model that facilitates bimodal image generation, and a Semantic\nMask Generator (SMG) that produces semantic annotations by exploiting\nDB-StyleGAN2's feature space. We evaluate BiOcularGAN through extensive\nexperiments across five diverse ocular datasets and analyze the effects of\nbimodal data generation on image quality and the produced annotations. Our\nexperimental results show that BiOcularGAN is able to produce high-quality\nmatching bimodal images and annotations (with minimal manual intervention) that\ncan be used to train highly competitive (deep) segmentation models that perform\nwell across multiple real-world datasets. The source code will be made publicly\navailable.",
    "descriptor": "\nComments: 13 pages, 13 figures\n",
    "authors": [
      "Darian Toma\u0161evi\u0107",
      "Peter Peer",
      "Vitomir \u0160truc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01536"
  },
  {
    "id": "arXiv:2205.01538",
    "title": "SUBS: Subtree Substitution for Compositional Semantic Parsing",
    "abstract": "Although sequence-to-sequence models often achieve good performance in\nsemantic parsing for i.i.d. data, their performance is still inferior in\ncompositional generalization. Several data augmentation methods have been\nproposed to alleviate this problem. However, prior work only leveraged\nsuperficial grammar or rules for data augmentation, which resulted in limited\nimprovement. We propose to use subtree substitution for compositional data\naugmentation, where we consider subtrees with similar semantic functions as\nexchangeable. Our experiments showed that such augmented data led to\nsignificantly better performance on SCAN and GeoQuery, and reached new SOTA on\ncompositional split of GeoQuery.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Jingfeng Yang",
      "Le Zhang",
      "Diyi Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01538"
  },
  {
    "id": "arXiv:2205.01541",
    "title": "Efficient Fine-Tuning of BERT Models on the Edge",
    "abstract": "Resource-constrained devices are increasingly the deployment targets of\nmachine learning applications. Static models, however, do not always suffice\nfor dynamic environments. On-device training of models allows for quick\nadaptability to new scenarios. With the increasing size of deep neural\nnetworks, as noted with the likes of BERT and other natural language processing\nmodels, comes increased resource requirements, namely memory, computation,\nenergy, and time. Furthermore, training is far more resource intensive than\ninference. Resource-constrained on-device learning is thus doubly difficult,\nespecially with large BERT-like models. By reducing the memory usage of\nfine-tuning, pre-trained BERT models can become efficient enough to fine-tune\non resource-constrained devices. We propose Freeze And Reconfigure (FAR), a\nmemory-efficient training regime for BERT-like models that reduces the memory\nusage of activation maps during fine-tuning by avoiding unnecessary parameter\nupdates. FAR reduces fine-tuning time on the DistilBERT model and CoLA dataset\nby 30%, and time spent on memory operations by 47%. More broadly, reductions in\nmetric performance on the GLUE and SQuAD datasets are around 1% on average.",
    "descriptor": "\nComments: 4 pages, 2 figures, 3 tables. To be published in ISCAS 2022 and made available on IEEE Xplore\n",
    "authors": [
      "Danilo Vucetic",
      "Mohammadreza Tayaranian",
      "Maryam Ziaeefard",
      "James J. Clark",
      "Brett H. Meyer",
      "Warren J. Gross"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01541"
  },
  {
    "id": "arXiv:2205.01543",
    "title": "Learning to Transfer Prompts for Text Generation",
    "abstract": "Pretrained language models (PLMs) have made remarkable progress in text\ngeneration tasks via fine-tuning. While, it is challenging to fine-tune PLMs in\na data-scarce situation. Therefore, it is non-trivial to develop a general and\nlightweight model that can adapt to various text generation tasks based on\nPLMs. To fulfill this purpose, the recent prompt-based learning offers a\npotential solution. In this paper, we improve this technique and propose a\nnovel prompt-based method (PTG) for text generation in a transferable setting.\nFirst, PTG learns a set of source prompts for various source generation tasks\nand then transfers these prompts as target prompts to perform target generation\ntasks. To consider both task- and instance-level information, we design an\nadaptive attention mechanism to derive the target prompts. For each data\ninstance, PTG learns a specific target prompt by attending to highly relevant\nsource prompts. In extensive experiments, PTG yields competitive or better\nresults than fine-tuning methods. We release our source prompts as an open\nresource, where users can add or reuse them to improve new text generation\ntasks for future research. Code and data can be available at\nhttps://github.com/RUCAIBox/Transfer-Prompts-for-Text-Generation.",
    "descriptor": "\nComments: Accepted by NAACL 2022 main conference (Long Paper)\n",
    "authors": [
      "Junyi Li",
      "Tianyi Tang",
      "Jian-Yun Nie",
      "Ji-Rong Wen",
      "Wayne Xin Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01543"
  },
  {
    "id": "arXiv:2205.01546",
    "title": "Learn To Remember: Transformer with Recurrent Memory for Document-Level  Machine Translation",
    "abstract": "The Transformer architecture has led to significant gains in machine\ntranslation. However, most studies focus on only sentence-level translation\nwithout considering the context dependency within documents, leading to the\ninadequacy of document-level coherence. Some recent research tried to mitigate\nthis issue by introducing an additional context encoder or translating with\nmultiple sentences or even the entire document. Such methods may lose the\ninformation on the target side or have an increasing computational complexity\nas documents get longer. To address such problems, we introduce a recurrent\nmemory unit to the vanilla Transformer, which supports the information exchange\nbetween the sentence and previous context. The memory unit is recurrently\nupdated by acquiring information from sentences, and passing the aggregated\nknowledge back to subsequent sentence states. We follow a two-stage training\nstrategy, in which the model is first trained at the sentence level and then\nfinetuned for document-level translation. We conduct experiments on three\npopular datasets for document-level machine translation and our model has an\naverage improvement of 0.91 s-BLEU over the sentence-level baseline. We also\nachieve state-of-the-art results on TED and News, outperforming the previous\nwork by 0.36 s-BLEU and 1.49 d-BLEU on average.",
    "descriptor": "\nComments: Accepted by NAACL-2022 Findings\n",
    "authors": [
      "Yukun Feng",
      "Feng Li",
      "Ziang Song",
      "Boyuan Zheng",
      "Philipp Koehn"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01546"
  },
  {
    "id": "arXiv:2205.01547",
    "title": "Effective Security by Obscurity",
    "abstract": "\"Security by obscurity\" is a bromide which is frequently applied to undermine\nthe perceived value of a certain class of techniques in security. This usage\ninitially stemmed from applications and experience in the areas of\ncryptographic theory, and the open vs. closed source debate. Through the\nperceived absence of true security, the field of security by obscurity has not\ncoalesced into a viable or recognizable approach for security practitioners.\nThe ramifications of this has resulted in these techniques going underused and\nunderappreciated by defenders, while they continue to provide value to\nattackers, which creates an unfortunate information asymmetry. Exploring\neffective methods for employing security by obscurity, it can be seen that\nexamples are already embedded unrecognized in other viable security\ndisciplines, such as information hiding, obfuscation, diversity, and moving\ntarget defense. In showing that obscurity measures are an achievable and\ndesirable supplement to other security measures, it is apparent that the\nin-depth defense of an organization's assets can be enhanced by intentional and\neffective use of security by obscurity.",
    "descriptor": "\nComments: 28 pages, 2 figures\n",
    "authors": [
      "J. Christian Smith"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.01547"
  },
  {
    "id": "arXiv:2205.01549",
    "title": "Adaptable Adapters",
    "abstract": "State-of-the-art pretrained NLP models contain a hundred million to trillion\nparameters. Adapters provide a parameter-efficient alternative for the full\nfinetuning in which we can only finetune lightweight neural network layers on\ntop of pretrained weights. Adapter layers are initialized randomly. However,\nexisting work uses the same adapter architecture -- i.e., the same adapter\nlayer on top of each layer of the pretrained model -- for every dataset,\nregardless of the properties of the dataset or the amount of available training\ndata. In this work, we introduce adaptable adapters that contain (1) learning\ndifferent activation functions for different layers and different input data,\nand (2) a learnable switch to select and only use the beneficial adapter\nlayers. We show that adaptable adapters achieve on-par performances with the\nstandard adapter architecture while using a considerably smaller number of\nadapter layers. In addition, we show that the selected adapter architecture by\nadaptable adapters transfers well across different data settings and similar\ntasks. We propose to use adaptable adapters for designing efficient and\neffective adapter architectures. The resulting adapters (a) contain about 50%\nof the learning parameters of the standard adapter and are therefore more\nefficient at training and inference, and require less storage space, and (b)\nachieve considerably higher performances in low-data settings.",
    "descriptor": "\nComments: Accepted at NAACL-2022 main conference\n",
    "authors": [
      "Nafise Sadat Moosavi",
      "Quentin Delfosse",
      "Kristian Kersting",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01549"
  },
  {
    "id": "arXiv:2205.01550",
    "title": "Multi Scale Sparse Convolution Point Cloud Semantic Segmentation Neural  Network",
    "abstract": "Point clouds have the characteristics of disorder, unstructured and\nsparseness.Aiming at the problem of the non-structural nature of point clouds,\nthanks to the excellent performance of convolutional neural networks in image\nprocessing, one of the solutions is to extract features from point clouds based\non two-dimensional convolutional neural networks. The three-dimensional\ninformation carried in the point cloud can be converted to two-dimensional, and\nthen processed by a two-dimensional convolutional neural network, and finally\nback-projected to three-dimensional.In the process of projecting 3D information\nto 2D and back-projection, certain information loss will inevitably be caused\nto the point cloud and category inconsistency will be introduced in the\nback-projection stage;Another solution is the voxel-based point cloud\nsegmentation method, which divides the point cloud into small grids one by\none.However, the point cloud is sparse, and the direct use of 3D convolutional\nneural network inevitably wastes computing resources. In this paper, we propose\na feature extraction module based on multi-scale ultra-sparse convolution and a\nfeature selection module based on channel attention, and build a point cloud\nsegmentation network framework based on this.By introducing multi-scale sparse\nconvolution, network could capture richer feature information based on\nconvolution kernels of different sizes, improving the segmentation result of\npoint cloud segmentation.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2202.10047, arXiv:2102.04530 by other authors\n",
    "authors": [
      "Yunzheng Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.01550"
  },
  {
    "id": "arXiv:2205.01551",
    "title": "Cross-View Cross-Scene Multi-View Crowd Counting",
    "abstract": "Multi-view crowd counting has been previously proposed to utilize\nmulti-cameras to extend the field-of-view of a single camera, capturing more\npeople in the scene, and improve counting performance for occluded people or\nthose in low resolution. However, the current multi-view paradigm trains and\ntests on the same single scene and camera-views, which limits its practical\napplication. In this paper, we propose a cross-view cross-scene (CVCS)\nmulti-view crowd counting paradigm, where the training and testing occur on\ndifferent scenes with arbitrary camera layouts. To dynamically handle the\nchallenge of optimal view fusion under scene and camera layout change and\nnon-correspondence noise due to camera calibration errors or erroneous\nfeatures, we propose a CVCS model that attentively selects and fuses multiple\nviews together using camera layout geometry, and a noise view regularization\nmethod to train the model to handle non-correspondence errors. We also generate\na large synthetic multi-camera crowd counting dataset with a large number of\nscenes and camera views to capture many possible variations, which avoids the\ndifficulty of collecting and annotating such a large real dataset. We then test\nour trained CVCS model on real multi-view counting datasets, by using\nunsupervised domain transfer. The proposed CVCS model trained on synthetic data\noutperforms the same model trained only on real data, and achieves promising\nperformance compared to fully supervised methods that train and test on the\nsame single scene.",
    "descriptor": "\nComments: CVPR 2021\n",
    "authors": [
      "Qi Zhang",
      "Wei Lin",
      "Antoni B. Chan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01551"
  },
  {
    "id": "arXiv:2205.01553",
    "title": "Why The Trans Programmer?",
    "abstract": "Through online anecdotal evidence and online communities, there is an\nin-group idea of trans people (specifically trans-feminine individuals)\ndisproportionately entering computer science education & fields. Existing data\nsuggests this is a plausible trend, yet no research has been done into exactly\nwhy. As computer science education (traditional schooling or self-taught\nmethods) is integral to working in computer science fields, a simple research\nsurvey was conducted to gather data on 138 trans people's experiences with\ncomputer science & computer science education. This article's purpose is to\nshed insight on the motivations for trans individuals choosing computer science\npaths, while acting as a basis and call to action for further research.",
    "descriptor": "\nComments: IEEE Integrated STEM Education Conference 2022\n",
    "authors": [
      "Skye Kychenthal"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.01553"
  },
  {
    "id": "arXiv:2205.01554",
    "title": "Exploring Proxying QUIC and HTTP/3 for Satellite Communication",
    "abstract": "Low-Earth Orbit satellites have gained momentum to provide Internet\nconnectivity, augmenting those in the long-established geostationary orbits. At\nthe same time, QUIC has been developed as the new transport protocol for the\nweb. While QUIC traffic is fully encrypted, intermediaries such as performance\nenhancing proxies (PEPs) - in the past essential for Internet over satellite\nperformance - can no longer tamper with and optimize transport connections. In\nthis paper, we present a satellite emulation testbed and use it to compare QUIC\nand TCP as well as HTTP/3 and HTTP/1.1 with and without minimal PEP\nfunctionality. Evaluating goodput over time, we find that the slow start\nthreshold is reached up to 2s faster for QUIC PEP in comparison to QUIC\nNon-PEP. Moreover, we find that HTTP/3 and HTTP/3-PEP outperform HTTP/1.1 and\nHTTP/1.1-PEP in multiple web performance scenarios, where HTTP/3-PEP improves\nover HTTP/3 for Page Load Time by over 7s in edge cases. Hence, our findings\nhint that these performance gains may warrant exploring PEPs for QUIC.",
    "descriptor": "\nComments: To be published in IFIP Networking 2022\n",
    "authors": [
      "Mike Kosek",
      "Hendrik Cech",
      "Vaibhav Bajpai",
      "J\u00f6rg Ott"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.01554"
  },
  {
    "id": "arXiv:2205.01556",
    "title": "Privacy Amplification via Random Participation in Federated Learning",
    "abstract": "Running a randomized algorithm on a subsampled dataset instead of the entire\ndataset amplifies differential privacy guarantees. In this work, in a federated\nsetting, we consider random participation of the clients in addition to\nsubsampling their local datasets. Since such random participation of the\nclients creates correlation among the samples of the same client in their\nsubsampling, we analyze the corresponding privacy amplification via non-uniform\nsubsampling. We show that when the size of the local datasets is small, the\nprivacy guarantees via random participation is close to those of the\ncentralized setting, in which the entire dataset is located in a single host\nand subsampled. On the other hand, when the local datasets are large, observing\nthe output of the algorithm may disclose the identities of the sampled clients\nwith high confidence. Our analysis reveals that, even in this case, privacy\nguarantees via random participation outperform those via only local\nsubsampling.",
    "descriptor": "",
    "authors": [
      "Burak Hasircioglu",
      "Deniz Gunduz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.01556"
  },
  {
    "id": "arXiv:2205.01557",
    "title": "Training Mixed-Domain Translation Models via Federated Learning",
    "abstract": "Training mixed-domain translation models is a complex task that demands\ntailored architectures and costly data preparation techniques. In this work, we\nleverage federated learning (FL) in order to tackle the problem. Our\ninvestigation demonstrates that with slight modifications in the training\nprocess, neural machine translation (NMT) engines can be easily adapted when an\nFL-based aggregation is applied to fuse different domains. Experimental results\nalso show that engines built via FL are able to perform on par with\nstate-of-the-art baselines that rely on centralized training techniques. We\nevaluate our hypothesis in the presence of five datasets with different sizes,\nfrom different domains, to translate from German into English and discuss how\nFL and NMT can mutually benefit from each other. In addition to providing\nbenchmarking results on the union of FL and NMT, we also propose a novel\ntechnique to dynamically control the communication bandwidth by selecting\nimpactful parameters during FL updates. This is a significant achievement\nconsidering the large size of NMT engines that need to be exchanged between FL\nparties.",
    "descriptor": "\nComments: accepted at NAACL 2022 (main conference)\n",
    "authors": [
      "Peyman Passban",
      "Tanya Roosta",
      "Rahul Gupta",
      "Ankit Chadha",
      "Clement Chung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01557"
  },
  {
    "id": "arXiv:2205.01560",
    "title": "Optimal Thermal Management, Charging, and Eco-driving of Battery  Electric Vehicles",
    "abstract": "This paper addresses optimal battery thermal management (BTM), charging, and\neco-driving of a battery electric vehicle (BEV) with the goal of improving its\ngrid-to-meter energy efficiency. Thus, an optimisation problem is formulated,\naiming at finding the optimal trade-off between trip time and charging cost.\nThe formulated problem is then transformed into a hybrid dynamical system,\nwhere the dynamics in driving and charging modes are modeled with different\nfunctions and with different state and control vectors. Moreover, to improve\ncomputational efficiency, we propose modelling the driving dynamics in a\nspatial domain, where decisions are made along the traveled distance. Charging\ndynamics are modeled in a temporal domain, where decisions are made along a\nnormalized charging time. The actual charging time is modeled as a scalar\nvariable that is optimized simultaneously with the optimal state and control\ntrajectories, for both charging and driving modes. The performance of the\nproposed algorithm is assessed over a road with a hilly terrain, where two\ncharging possibilities are considered along the driving route. According to the\nresults, trip time including driving and charging times, is reduced by 44 %,\ncompared to a case without battery active heating/cooling.",
    "descriptor": "",
    "authors": [
      "Ahad Hamednia",
      "Nikolce Murgovski",
      "Jonas Fredriksson",
      "Jimmy Forsman",
      "Mitra Pourabdollah",
      "Viktor Larsson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.01560"
  },
  {
    "id": "arXiv:2205.01562",
    "title": "Nested Dissection Meets IPMs: Planar Min-Cost Flow in Nearly-Linear Time",
    "abstract": "We present a nearly-linear time algorithm for finding a minimum-cost flow in\nplanar graphs with polynomially bounded integer costs and capacities. The\nprevious fastest algorithm for this problem is based on interior point methods\n(IPMs) and works for general sparse graphs in $O(n^{1.5}\\text{poly}(\\log n))$\ntime [Daitch-Spielman, STOC'08]. Intuitively, $\\Omega(n^{1.5})$ is a natural\nruntime barrier for IPM-based methods, since they require $\\sqrt{n}$\niterations, each routing a possibly-dense electrical flow.\nTo break this barrier, we develop a new implicit representation for flows\nbased on generalized nested-dissection [Lipton-Rose-Tarjan, JSTOR'79] and\napproximate Schur complements [Kyng-Sachdeva, FOCS'16]. This implicit\nrepresentation permits us to design a data structure to route an electrical\nflow with sparse demands in roughly $\\sqrt{n}$ update time, resulting in a\ntotal running time of $O(n\\cdot\\text{poly}(\\log n))$.\nOur results immediately extend to all families of separable graphs.",
    "descriptor": "\nComments: 93 pages\n",
    "authors": [
      "Sally Dong",
      "Yu Gao",
      "Gramoz Goranci",
      "Yin Tat Lee",
      "Richard Peng",
      "Sushant Sachdeva",
      "Guanghao Ye"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.01562"
  },
  {
    "id": "arXiv:2205.01568",
    "title": "RAFT-MSF: Self-Supervised Monocular Scene Flow using Recurrent Optimizer",
    "abstract": "Learning scene flow from a monocular camera still remains a challenging task\ndue to its ill-posedness as well as lack of annotated data. Self-supervised\nmethods demonstrate learning scene flow estimation from unlabeled data, yet\ntheir accuracy lags behind (semi-)supervised methods. In this paper, we\nintroduce a self-supervised monocular scene flow method that substantially\nimproves the accuracy over the previous approaches. Based on RAFT, a\nstate-of-the-art optical flow model, we design a new decoder to iteratively\nupdate 3D motion fields and disparity maps simultaneously. Furthermore, we\npropose an enhanced upsampling layer and a disparity initialization technique,\nwhich overall further improves accuracy up to 7.2%. Our method achieves\nstate-of-the-art accuracy among all self-supervised monocular scene flow\nmethods, improving accuracy by 34.2%. Our fine-tuned model outperforms the best\nprevious semi-supervised method with 228 times faster runtime. Code will be\npublicly available.",
    "descriptor": "",
    "authors": [
      "Bayram Bayramli",
      "Junhwa Hur",
      "Hongtao Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.01568"
  },
  {
    "id": "arXiv:2205.01569",
    "title": "PSCNN: A 885.86 TOPS/W Programmable SRAM-based Computing-In-Memory  Processor for Keyword Spotting",
    "abstract": "Computing-in-memory (CIM) has attracted significant attentions in recent\nyears due to its massive parallelism and low power consumption. However,\ncurrent CIM designs suffer from large area overhead of small CIM macros and bad\nprogrammablity for model execution. This paper proposes a programmable CIM\nprocessor with a single large sized CIM macro instead of multiple smaller ones\nfor power efficient computation and a flexible instruction set to support\nvarious binary 1-D convolution Neural Network (CNN) models in an easy way.\nFurthermore, the proposed architecture adopts the pooling write-back method to\nsupport fused or independent convolution/pooling operations to reduce 35.9\\% of\nlatency, and the flexible ping-pong feature SRAM to fit different feature map\nsizes during layer-by-layer execution.The design fabricated in TSMC 28nm\ntechnology achieves 150.8 GOPS throughput and 885.86 TOPS/W power efficiency at\n10 MHz when executing our binary keyword spotting model, which has higher power\nefficiency and flexibility than previous designs.",
    "descriptor": "\nComments: 5 pages, 7 figures, published in IEEE ISCAS 2022\n",
    "authors": [
      "Shu-Hung Kuo",
      "Tian-Sheuan Chang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.01569"
  },
  {
    "id": "arXiv:2205.01570",
    "title": "RangeSeg: Range-Aware Real Time Segmentation of 3D LiDAR Point Clouds",
    "abstract": "Semantic outdoor scene understanding based on 3D LiDAR point clouds is a\nchallenging task for autonomous driving due to the sparse and irregular data\nstructure. This paper takes advantages of the uneven range distribution of\ndifferent LiDAR laser beams to propose a range aware instance segmentation\nnetwork, RangeSeg. RangeSeg uses a shared encoder backbone with two range\ndependent decoders. A heavy decoder only computes top of a range image where\nthe far and small objects locate to improve small object detection accuracy,\nand a light decoder computes whole range image for low computational cost. The\nresults are further clustered by the DBSCAN method with a resolution weighted\ndistance function to get instance-level segmentation results. Experiments on\nthe KITTI dataset show that RangeSeg outperforms the state-of-the-art semantic\nsegmentation methods with enormous speedup and improves the instance-level\nsegmentation performance on small and far objects. The whole RangeSeg pipeline\nmeets the real time requirement on NVIDIA\\textsuperscript{\\textregistered}\nJETSON AGX Xavier with 19 frames per second in average.",
    "descriptor": "\nComments: 10 pages, 7 figures. IEEE Transactions on Intelligent Vehicles (2021)\n",
    "authors": [
      "Tzu-Hsuan Chen",
      "Tian Sheuan Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01570"
  },
  {
    "id": "arXiv:2205.01571",
    "title": "A Real Time 1280x720 Object Detection Chip With 585MB/s Memory Traffic",
    "abstract": "Memory bandwidth has become the real-time bottleneck of current deep learning\naccelerators (DLA), particularly for high definition (HD) object detection.\nUnder resource constraints, this paper proposes a low memory traffic DLA chip\nwith joint hardware and software optimization. To maximize hardware utilization\nunder memory bandwidth, we morph and fuse the object detection model into a\ngroup fusion-ready model to reduce intermediate data access. This reduces the\nYOLOv2's feature memory traffic from 2.9 GB/s to 0.15 GB/s. To support group\nfusion, our previous DLA based hardware employes a unified buffer with\nwrite-masking for simple layer-by-layer processing in a fusion group. When\ncompared to our previous DLA with the same PE numbers, the chip implemented in\na TSMC 40nm process supports 1280x720@30FPS object detection and consumes 7.9X\nless external DRAM access energy, from 2607 mJ to 327.6 mJ.",
    "descriptor": "\nComments: 11 pages, 14 figures, to be published IEEE Transactions on Very Large Scale Integration (VLSI) Systems\n",
    "authors": [
      "Kuo-Wei Chang",
      "Hsu-Tung Shih",
      "Tian-Sheuan Chang",
      "Shang-Hong Tsai",
      "Chih-Chyau Yang",
      "Chien-Ming Wu",
      "Chun-Ming Huang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01571"
  },
  {
    "id": "arXiv:2205.01573",
    "title": "StreamingHub: Interactive Stream Analysis Workflows",
    "abstract": "Reusable data/code and reproducible analyses are foundational to quality\nresearch. This aspect, however, is often overlooked when designing interactive\nstream analysis workflows for time-series data (e.g., eye-tracking data). A\nmechanism to transmit informative metadata alongside data may allow such\nworkflows to intelligently consume data, propagate metadata to downstream\ntasks, and thereby auto-generate reusable, reproducible analytic outputs with\nzero supervision. Moreover, a visual programming interface to design, develop,\nand execute such workflows may allow rapid prototyping for interdisciplinary\nresearch. Capitalizing on these ideas, we propose StreamingHub, a framework to\nbuild metadata propagating, interactive stream analysis workflows using visual\nprogramming. We conduct two case studies to evaluate the generalizability of\nour framework. Simultaneously, we use two heuristics to evaluate their\ncomputational fluidity and data growth. Results show that our framework\ngeneralizes to multiple tasks with a minimal performance overhead.",
    "descriptor": "\nComments: Code Repository at this https URL\n",
    "authors": [
      "Yasith Jayawardana",
      "Vikas G. Ashok",
      "Sampath Jayarathna"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Digital Libraries (cs.DL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.01573"
  },
  {
    "id": "arXiv:2205.01576",
    "title": "Computing Maximal Unique Matches with the r-index",
    "abstract": "In recent years, pangenomes received increasing attention from the scientific\ncommunity for their ability to incorporate population variation information and\nalleviate reference genome bias. Maximal Exact Matches (MEMs) and Maximal\nUnique Matches (MUMs) have proven themselves to be useful in multiple\nbioinformatic contexts, for example short-read alignment and multiple-genome\nalignment. However, standard techniques using suffix trees and FM-indexes do\nnot scale to a pangenomic level. Recently, Gagie et al. [JACM 20] introduced\nthe $r$-index that is a Burrows-Wheeler Transform (BWT)-based index able to\nhandle hundreds of human genomes. Later, Rossi et al. [JCB 22] enabled the\ncomputation of MEMs using the $r$-index, and Boucher et al. [DCC 21] showed how\nto compute them in a streaming fashion. In this paper, we show how to augment\nBoucher et al.'s approach to enable the computation of MUMs on the $r$-index,\nwhile preserving the space and time bounds. We add additional $O(r)$ samples of\nthe longest common prefix (LCP) array, where $r$ is the number of equal-letter\nruns of the BWT, that permits the computation of the second longest match of\nthe pattern suffix with respect to the input text, which in turn allows the\ncomputation of candidate MUMs. We implemented a proof-of-concept of our\napproach, that we call mum-phinder, and tested on real-world datasets. We\ncompared our approach with competing methods that are able to compute MUMs. We\nobserve that our method is up to 8 times smaller, while up to 19 times slower\nwhen the dataset is not highly repetitive, while on highly repetitive data, our\nmethod is up to 6.5 times slower and uses up to 25 times less memory.",
    "descriptor": "\nComments: Our code is available at: this https URL\n",
    "authors": [
      "Sara Giuliani",
      "Giuseppe Romana",
      "Massimiliano Rossi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.01576"
  },
  {
    "id": "arXiv:2205.01578",
    "title": "A Model of Fluid-Structure and Biochemical Interactions with  Applications to Subclinical Leaflet Thrombosis",
    "abstract": "Subclinical leaflet thrombosis (SLT) is a potentially serious complication of\naortic valve replacement with a bioprosthetic valve in which blood clots form\non the replacement valve. SLT is associated with increased risk of transient\nischemic attacks and strokes and can progress to clinical leaflet thrombosis.\nSLT following aortic valve replacement also may be related to subsequent\nstructural valve deterioration, which can impair the durability of the valve\nreplacement. Because of the difficulty in clinical imaging of SLT, models are\nneeded to determine the mechanisms of SLT and could eventually predict which\npatients will develop SLT. To this end, we develop methods to simulate leaflet\nthrombosis that combine fluid-structure interaction and a simplified thrombosis\nmodel that allows for deposition along the moving leaflets. Additionally, this\nmodel can be adapted to model deposition or absorption along other moving\nboundaries. We present both convergence results and quantify the model's\nability to realize changes in stroke volume and pressures. These new approaches\nare an important advancement in thrombosis modeling in that it incorporates\nboth adhesion to the surface of the leaflets and feedback to the\nfluid-structure interaction.",
    "descriptor": "\nComments: 26 pages, 11 figures\n",
    "authors": [
      "Aaron Barrett",
      "Jordan A. Brown",
      "Margaret Anne Smith",
      "Andrew Woodward",
      "John P. Vavalle",
      "Arash Kheradvar",
      "Boyce E. Griffith",
      "Aaron L. Fogelson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2205.01578"
  },
  {
    "id": "arXiv:2205.01580",
    "title": "Better plain ViT baselines for ImageNet-1k",
    "abstract": "It is commonly accepted that the Vision Transformer model requires\nsophisticated regularization techniques to excel at ImageNet-1k scale data.\nSurprisingly, we find this is not the case and standard data augmentation is\nsufficient. This note presents a few minor modifications to the original Vision\nTransformer (ViT) vanilla training setting that dramatically improve the\nperformance of plain ViT models. Notably, 90 epochs of training surpass 76%\ntop-1 accuracy in under seven hours on a TPUv3-8, similar to the classic\nResNet50 baseline, and 300 epochs of training reach 80% in less than one day.",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Lucas Beyer",
      "Xiaohua Zhai",
      "Alexander Kolesnikov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01580"
  },
  {
    "id": "arXiv:2205.01583",
    "title": "An Explore of Virtual Reality for Awareness of the Climate Change  Crisis: A Simulation of Sea Level Rise",
    "abstract": "Virtual Reality (VR) technology has been shown to achieve remarkable results\nin multiple fields. Due to the nature of the immersive medium of Virtual\nReality it logically follows that it can be used as a high-quality educational\ntool as it offers potentially a higher bandwidth than other mediums such as\ntext, pictures and videos. This short paper illustrates the development of a\nclimate change educational awareness application for virtual reality to\nsimulate virtual scenes of local scenery and sea level rising until 2100 using\nprediction data. The paper also reports on the current in progress work of\nporting the system to Augmented Reality (AR) and future work to evaluate the\nsystem.",
    "descriptor": "\nComments: Published in 8th International Conference of the Immersive Learning Research Network (iLRN 2022)\n",
    "authors": [
      "Zixiang Xu",
      "Abraham G. Campbell",
      "Soumyabrata Dev",
      "Yuan Liang"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.01583"
  },
  {
    "id": "arXiv:2205.01586",
    "title": "Simpler is Better: off-the-shelf Continual Learning Through Pretrained  Backbones",
    "abstract": "In this short paper, we propose a baseline (off-the-shelf) for Continual\nLearning of Computer Vision problems, by leveraging the power of pretrained\nmodels. By doing so, we devise a simple approach achieving strong performance\nfor most of the common benchmarks. Our approach is fast since requires no\nparameters updates and has minimal memory requirements (order of KBytes). In\nparticular, the \"training\" phase reorders data and exploit the power of\npretrained models to compute a class prototype and fill a memory bank. At\ninference time we match the closest prototype through a knn-like approach,\nproviding us the prediction. We will see how this naive solution can act as an\noff-the-shelf continual learning system. In order to better consolidate our\nresults, we compare the devised pipeline with common CNN models and show the\nsuperiority of Vision Transformers, suggesting that such architectures have the\nability to produce features of higher quality. Moreover, this simple pipeline,\nraises the same questions raised by previous works \\cite{gdumb} on the\neffective progresses made by the CL community especially in the dataset\nconsidered and the usage of pretrained models. Code is live at\nhttps://github.com/francesco-p/off-the-shelf-cl",
    "descriptor": "",
    "authors": [
      "Francesco Pelosin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01586"
  },
  {
    "id": "arXiv:2205.01588",
    "title": "SparCAssist: A Model Risk Assessment Assistant Based on Sparse Generated  Counterfactuals",
    "abstract": "We introduce SparcAssist, a general-purpose risk assessment tool for the\nmachine learning models trained for language tasks. It evaluates models' risk\nby inspecting their behavior on counterfactuals, namely out-of-distribution\ninstances generated based on the given data instance. The counterfactuals are\ngenerated by replacing tokens in rational subsequences identified by ExPred,\nwhile the replacements are retrieved using HotFlip or\nMasked-Language-Model-based algorithms. The main purpose of our system is to\nhelp the human annotators to assess the model's risk on deployment. The\ncounterfactual instances generated during the assessment are the by-product and\ncan be used to train more robust NLP models in the future.",
    "descriptor": "\nComments: 5 pages, 2 figures, submitted and accepted as a demo paper in SIGIR2022\n",
    "authors": [
      "Zijian Zhang",
      "Vinay Setty",
      "Avishek Anand"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01588"
  },
  {
    "id": "arXiv:2205.01589",
    "title": "A dynamic mass transport method for Poisson-Nernst-Planck equations",
    "abstract": "A dynamic mass-transport method is proposed for approximately solving the\nPoisson-Nernst-Planck(PNP) equations. The semi-discrete scheme based on the JKO\ntype variational formulation naturally enforces solution positivity and the\nenergy law as for the continuous PNP system. The fully discrete scheme is\nfurther formulated as a constrained minimization problem, shown to be solvable,\nand satisfy all three solution properties (mass conservation, positivity and\nenergy dissipation) independent of time step size or the spatial mesh size.\nNumerical experiments are conducted to validate convergence of the computed\nsolutions and verify the structure preserving property of the proposed scheme.",
    "descriptor": "",
    "authors": [
      "H. Liu",
      "W. Maimaitiyiming"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.01589"
  },
  {
    "id": "arXiv:2205.01590",
    "title": "An Empirical Study on Internet Traffic Prediction Using Statistical  Rolling Model",
    "abstract": "Real-world IP network traffic is susceptible to external and internal factors\nsuch as new internet service integration, traffic migration, internet\napplication, etc. Due to these factors, the actual internet traffic is\nnon-linear and challenging to analyze using a statistical model for future\nprediction. In this paper, we investigated and evaluated the performance of\ndifferent statistical prediction models for real IP network traffic; and showed\na significant improvement in prediction using the rolling prediction technique.\nInitially, a set of best hyper-parameters for the corresponding prediction\nmodel is identified by analyzing the traffic characteristics and implementing a\ngrid search algorithm based on the minimum Akaike Information Criterion (AIC).\nThen, we performed a comparative performance analysis among AutoRegressive\nIntegrated Moving Average (ARIMA), Seasonal ARIMA (SARIMA), SARIMA with\neXogenous factors (SARIMAX), and Holt-Winter for single-step prediction. The\nseasonality of our traffic has been explicitly modeled using SARIMA, which\nreduces the rolling prediction Mean Average Percentage Error (MAPE) by more\nthan 4% compared to ARIMA (incapable of handling the seasonality). We further\nimproved traffic prediction using SARIMAX to learn different exogenous factors\nextracted from the original traffic, which yielded the best rolling prediction\nresults with a MAPE of 6.83%. Finally, we applied the exponential smoothing\ntechnique to handle the variability in traffic following the Holt-Winter model,\nwhich exhibited a better prediction than ARIMA (around 1.5% less MAPE). The\nrolling prediction technique reduced prediction error using real Internet\nService Provider (ISP) traffic data by more than 50\\% compared to the standard\nprediction method.",
    "descriptor": "\nComments: 6 pages, 2 figures, To appear in the Proceedings of the International Wireless Communications and Mobile Computing Conference in Dubrovnik, Croatia, 2022\n",
    "authors": [
      "Sajal Saha",
      "Anwar Haque",
      "Greg Sidebottom"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01590"
  },
  {
    "id": "arXiv:2205.01595",
    "title": "A Bidirectional Conversion Network for Cross-Spectral Face Recognition",
    "abstract": "Face recognition in the infrared (IR) band has become an important supplement\nto visible light face recognition due to its advantages of independent\nbackground light, strong penetration, ability of imaging under harsh\nenvironments such as nighttime, rain and fog. However, cross-spectral face\nrecognition (i.e., VIS to IR) is very challenging due to the dramatic\ndifference between the visible light and IR imageries as well as the lack of\npaired training data. This paper proposes a framework of bidirectional\ncross-spectral conversion (BCSC-GAN) between the heterogeneous face images, and\ndesigns an adaptive weighted fusion mechanism based on information fusion\ntheory. The network reduces the cross-spectral recognition problem into an\nintra-spectral problem, and improves performance by fusing bidirectional\ninformation. Specifically, a face identity retaining module (IRM) is introduced\nwith the ability to preserve identity features, and a new composite loss\nfunction is designed to overcome the modal differences caused by different\nspectral characteristics. Two datasets of TINDERS and CASIA were tested, where\nperformance metrics of FID, recognition rate, equal error rate and normalized\ndistance were compared. Results show that our proposed network is superior than\nother state-of-the-art methods. Additionally, the proposed rule of Self\nAdaptive Weighted Fusion (SAWF) is better than the recognition results of the\nunfused case and other traditional fusion rules that are commonly used, which\nfurther justifies the effectiveness and superiority of the proposed\nbidirectional conversion approach.",
    "descriptor": "",
    "authors": [
      "Zhicheng Cao",
      "Jiaxuan Zhang",
      "Liaojun Pang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01595"
  },
  {
    "id": "arXiv:2205.01598",
    "title": "Level-based Blocking for Sparse Matrices: Sparse Matrix-Power-Vector  Multiplication",
    "abstract": "The multiplication of a sparse matrix with a dense vector (SpMV) is a key\ncomponent in many numerical schemes and its performance is known to be severely\nlimited by main memory access. Several numerical schemes require the\nmultiplication of a sparse matrix polynomial with a dense vector, which is\ntypically implemented as a sequence of SpMVs. This results in low performance\nand ignores the potential to increase the arithmetic intensity by reusing the\nmatrix data from cache. In this work we use the recursive algebraic coloring\nengine (RACE) to enable blocking of sparse matrix data across the polynomial\ncomputations. In the graph representing the sparse matrix we form levels using\na breadth-first search. Locality relations of these levels are then used to\nimprove spatial and temporal locality when accessing the matrix data and to\nimplement an efficient multithreaded parallelization. Our approach is\nindependent of the matrix structure and avoids shortcomings of existing\n\"blocking\" strategies in terms of hardware efficiency and parallelization\noverhead. We quantify the quality of our implementation using performance\nmodelling and demonstrate speedups of up to 3$\\times$ and 5$\\times$ compared to\nan optimal SpMV-based baseline on a single multicore chip of recent Intel and\nAMD architectures. As a potential application, we demonstrate the benefit of\nour implementation for a Chebyshev time propagation scheme, representing the\nclass of polynomial approximations to exponential integrators. Further\nnumerical schemes which may benefit from our developments include $s$-step\nKrylov solvers and power clustering algorithms.",
    "descriptor": "\nComments: 18 pages, 19 figures, 3 tables\n",
    "authors": [
      "Christie L. Alappat",
      "Georg Hager",
      "Olaf Schenk",
      "Gerhard Wellein"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2205.01598"
  },
  {
    "id": "arXiv:2205.01600",
    "title": "A Comparison of Approaches for Imbalanced Classification Problems in the  Context of Retrieving Relevant Documents for an Analysis",
    "abstract": "One of the first steps in many text-based social science studies is to\nretrieve documents that are relevant for the analysis from large corpora of\notherwise irrelevant documents. The conventional approach in social science to\naddress this retrieval task is to apply a set of keywords and to consider those\ndocuments to be relevant that contain at least one of the keywords. But the\napplication of incomplete keyword lists risks drawing biased inferences. More\ncomplex and costly methods such as query expansion techniques, topic\nmodel-based classification rules, and active as well as passive supervised\nlearning could have the potential to more accurately separate relevant from\nirrelevant documents and thereby reduce the potential size of bias. Yet,\nwhether applying these more expensive approaches increases retrieval\nperformance compared to keyword lists at all, and if so, by how much, is\nunclear as a comparison of these approaches is lacking. This study closes this\ngap by comparing these methods across three retrieval tasks associated with a\ndata set of German tweets (Linder, 2017), the Social Bias Inference Corpus\n(SBIC) (Sap et al., 2020), and the Reuters-21578 corpus (Lewis, 1997). Results\nshow that query expansion techniques and topic model-based classification rules\nin most studied settings tend to decrease rather than increase retrieval\nperformance. Active supervised learning, however, if applied on a not too small\nset of labeled training instances (e.g. 1,000 documents), reaches a\nsubstantially higher retrieval performance than keyword lists.",
    "descriptor": "\nComments: 78 pages, 17 figures, 9 tables\n",
    "authors": [
      "Sandra Wankm\u00fcller"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.01600"
  },
  {
    "id": "arXiv:2205.01603",
    "title": "CTM -- A Model for Large-Scale Multi-View Tweet Topic Classification",
    "abstract": "Automatically associating social media posts with topics is an important\nprerequisite for effective search and recommendation on many social media\nplatforms. However, topic classification of such posts is quite challenging\nbecause of (a) a large topic space (b) short text with weak topical cues, and\n(c) multiple topic associations per post. In contrast to most prior work which\nonly focuses on post classification into a small number of topics ($10$-$20$),\nwe consider the task of large-scale topic classification in the context of\nTwitter where the topic space is $10$ times larger with potentially multiple\ntopic associations per Tweet. We address the challenges above by proposing a\nnovel neural model, CTM that (a) supports a large topic space of $300$ topics\nand (b) takes a holistic approach to tweet content modeling -- leveraging\nmulti-modal content, author context, and deeper semantic cues in the Tweet. Our\nmethod offers an effective way to classify Tweets into topics at scale by\nyielding superior performance to other approaches (a relative lift of\n$\\mathbf{20}\\%$ in median average precision score) and has been successfully\ndeployed in production at Twitter.",
    "descriptor": "\nComments: 12 pages. 1 figure. NAACL Industry Track\n",
    "authors": [
      "Vivek Kulkarni",
      "Kenny Leung",
      "Aria Haghighi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01603"
  },
  {
    "id": "arXiv:2205.01605",
    "title": "Toward Modeling Creative Processes for Algorithmic Painting",
    "abstract": "This paper proposes a framework for computational modeling of artistic\npainting algorithms, inspired by human creative practices. Based on examples\nfrom expert artists and from the author's own experience, the paper argues that\ncreative processes often involve two important components: vague, high-level\ngoals (e.g., \"make a good painting\"), and exploratory processes for discovering\nnew ideas. This paper then sketches out possible computational mechanisms for\nimitating those elements of the painting process, including underspecified loss\nfunctions and iterative painting procedures with explicit task decompositions.",
    "descriptor": "\nComments: Proc. ICCC 2022\n",
    "authors": [
      "Aaron Hertzmann"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2205.01605"
  },
  {
    "id": "arXiv:2205.01608",
    "title": "Local Stochastic Bilevel Optimization with Momentum-Based Variance  Reduction",
    "abstract": "Bilevel Optimization has witnessed notable progress recently with new\nemerging efficient algorithms and has been applied to many machine learning\ntasks such as data cleaning, few-shot learning, and neural architecture search.\nHowever, little attention has been paid to solve the bilevel problems under\ndistributed setting. Federated learning (FL) is an emerging paradigm which\nsolves machine learning tasks over distributed-located data. FL problems are\nchallenging to solve due to the heterogeneity and communication bottleneck.\nHowever, it is unclear how these challenges will affect the convergence of\nBilevel Optimization algorithms. In this paper, we study Federated Bilevel\nOptimization problems. Specifically, we first propose the FedBiO, a\ndeterministic gradient-based algorithm and we show it requires\n$O(\\epsilon^{-2})$ number of iterations to reach an $\\epsilon$-stationary\npoint. Then we propose FedBiOAcc to accelerate FedBiO with the momentum-based\nvariance-reduction technique under the stochastic scenario. We show FedBiOAcc\nhas complexity of $O(\\epsilon^{-1.5})$. Finally, we validate our proposed\nalgorithms via the important Fair Federated Learning task. More specifically,\nwe define a bilevel-based group fair FL objective. Our algorithms show superior\nperformances compared to other baselines in numerical experiments.",
    "descriptor": "",
    "authors": [
      "Junyi Li",
      "Feihu Huang",
      "Heng Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.01608"
  },
  {
    "id": "arXiv:2205.01611",
    "title": "Improved Weakly Private Information Retrieval Codes",
    "abstract": "We study the problem of weakly private information retrieval (W-PIR), where a\nuser wishes to retrieve a desired message from $N$ non-colluding servers in a\nway that the privacy leakage regarding the desired message's identity is less\nthan or equal to a threshold. We propose a new code construction which\nsignificantly improves upon the best known result in the literature, based on\nthe following critical observation. In previous constructions, for the extreme\ncase of minimum download, the retrieval pattern is to download the message\ndirectly from $N-1$ servers; however this causes leakage to all these $N-1$\nservers, and a better retrieval pattern for this extreme case is to download\nthe message directly from a single server. The proposed code construction\nallows a natural transition to such a pattern, and for both the maximal leakage\nmetric and the mutual information leakage metric, significant improvements can\nbe obtained. We provide explicit solutions, in contrast to a previous work by\nLin et al., where only numerical solutions were obtained.",
    "descriptor": "\nComments: 6 pages 1 figure, ISIT 2022 accepted\n",
    "authors": [
      "Chengyuan Qian",
      "Ruida Zhou",
      "Chao Tian",
      "Tie Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.01611"
  },
  {
    "id": "arXiv:2205.01612",
    "title": "A New Approach to Compute Information Theoretic Outer Bounds and Its  Application to Regenerating Codes",
    "abstract": "The study of the fundamental limits of information systems is a central theme\nin information theory. Both the traditional analytical approach and the\nrecently proposed computational approach have significant limitations, where\nthe former is mainly due to its reliance on human ingenuity, and the latter due\nto its exponential memory and computational complexity. In this work, we\npropose a new computational approach to tackle the problem with much lower\nmemory and computational requirements, which can naturally utilize certain\nintuitions, but also can maintain the strong computational advantage of the\nexisting computational approach. A reformulation of the underlying optimization\nproblem is first proposed, which converts the large linear program to a maximin\nproblem. This leads to an iterative solving procedure, which uses the LP dual\nto carry over learned evidence between iterations. The key in the reformulated\nproblem is the selection of good information inequalities, with which a relaxed\nLP can be formed. A particularly powerful intuition is a potentially optimal\ncode construction, and we provide a method that directly utilizes it in the new\nalgorithm. As an application, we derive a tighter outer bound for the\nstorage-repair tradeoff for the $(6,5,5)$ regenerating code problem, which\ninvolves at least 30 random variables and is impossible to compute with the\npreviously known computational approach.",
    "descriptor": "\nComments: 6 pages, 3 figures, accepted ISIT 2022\n",
    "authors": [
      "Wenjing Chen",
      "Chao Tian"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.01612"
  },
  {
    "id": "arXiv:2205.01614",
    "title": "Automatic Segmentation of Aircraft Dents in Point Clouds",
    "abstract": "Dents on the aircraft skin are frequent and may easily go undetected during\nairworthiness checks, as their inspection process is tedious and extremely\nsubject to human factors and environmental conditions. Nowadays, 3D scanning\ntechnologies are being proposed for more reliable, human-independent\nmeasurements, yet the process of inspection and reporting remains laborious and\ntime consuming because data acquisition and validation are still carried out by\nthe engineer. For full automation of dent inspection, the acquired point cloud\ndata must be analysed via a reliable segmentation algorithm, releasing humans\nfrom the search and evaluation of damage. This paper reports on two\ndevelopments towards automated dent inspection. The first is a method to\ngenerate a synthetic dataset of dented surfaces to train a fully convolutional\nneural network. The training of machine learning algorithms needs a substantial\nvolume of dent data, which is not readily available. Dents are thus simulated\nin random positions and shapes, within criteria and definitions of a Boeing 737\nstructural repair manual. The noise distribution from the scanning apparatus is\nthen added to reflect the complete process of 3D point acquisition on the\ntraining. The second proposition is a surface fitting strategy to convert 3D\npoint clouds to 2.5D. This allows higher resolution point clouds to be\nprocessed with a small amount of memory compared with state-of-the-art methods\ninvolving 3D sampling approaches. Simulations with available ground truth data\nshow that the proposed technique reaches an intersection-over-union of over\n80%. Experiments over dent samples prove an effective detection of dents with a\nspeed of over 500 000 points per second.",
    "descriptor": "",
    "authors": [
      "Pasquale Lafiosca",
      "Ip-Shing Fan",
      "Nicolas P. Avdelidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.01614"
  },
  {
    "id": "arXiv:2205.01616",
    "title": "Data assimilation with agent-based models using Markov chain sampling",
    "abstract": "Every day, weather forecasting centres around the world make use of noisy,\nincomplete observations of the atmosphere to update their weather forecasts.\nThis process is known as data assimilation, data fusion or state estimation and\nis best expressed as Bayesian inference: given a set of observations, some\nprior beliefs and a model of the target system, what is the probability\ndistribution of some set of unobserved quantities or latent variables at some\ntime, possibly in the future?\nWhile data assimilation has developed rapidly in some areas, relatively\nlittle progress has been made in performing data assimilation with agent-based\nmodels. This has hampered the use of agent-based models to make quantitative\nclaims about real-world systems.\nHere we present an algorithm that uses Markov-Chain-Monte-Carlo methods to\ngenerate samples of the parameters and trajectories of an agent-based model\nover a window of time given a set of possibly noisy, aggregated and incomplete\nobservations of the system. This can be used as-is, or as part of a data\nassimilation cycle or sequential-MCMC algorithm.\nOur algorithm is applicable to time-stepping, agent-based models whose agents\nhave a finite set of states and a finite number of ways of acting on the world.\nAs presented the algorithm is only practical for agents with a few bytes of\ninternal state although we discuss ways of removing this restriction. We\ndemonstrate the algorithm by performing data assimilation with an agent-based,\nspatial predator-prey model.",
    "descriptor": "\nComments: 22 pages, 4 figures\n",
    "authors": [
      "Daniel Tang",
      "Nick Malleson"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2205.01616"
  },
  {
    "id": "arXiv:2205.01620",
    "title": "OmniKnight: Multilingual Neural Machine Translation with  Language-Specific Self-Distillation",
    "abstract": "Although all-in-one-model multilingual neural machine translation (MNMT) has\nachieved remarkable progress in recent years, its selected best overall\ncheckpoint fails to achieve the best performance simultaneously in all language\npairs. It is because that the best checkpoints for each individual language\npair (i.e., language-specific best checkpoints) scatter in different epochs. In\nthis paper, we present a novel training strategy dubbed Language-Specific\nSelf-Distillation (LSSD) for bridging the gap between language-specific best\ncheckpoints and the overall best checkpoint. In detail, we regard each\nlanguage-specific best checkpoint as a teacher to distill the overall best\ncheckpoint. Moreover, we systematically explore three variants of our LSSD,\nwhich perform distillation statically, selectively, and adaptively.\nExperimental results on two widely-used benchmarks show that LSSD obtains\nconsistent improvements towards all language pairs and achieves the\nstate-of-the-art",
    "descriptor": "",
    "authors": [
      "Yichong Huang",
      "Xiaocheng Feng",
      "Xinwei Geng",
      "Bing Qin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01620"
  },
  {
    "id": "arXiv:2205.01624",
    "title": "Practical Saccade Prediction for Head-Mounted Displays: Towards a  Comprehensive Model",
    "abstract": "Eye-tracking technology is an integral component of new display devices such\nas virtual and augmented reality headsets. Applications of gaze information\nrange from new interaction techniques exploiting eye patterns to\ngaze-contingent digital content creation. However, system latency is still a\nsignificant issue in many of these applications because it breaks the\nsynchronization between the current and measured gaze positions. Consequently,\nit may lead to unwanted visual artifacts and degradation of user experience. In\nthis work, we focus on foveated rendering applications where the quality of an\nimage is reduced towards the periphery for computational savings. In foveated\nrendering, the presence of latency leads to delayed updates to the rendered\nframe, making the quality degradation visible to the user. To address this\nissue and to combat system latency, recent work proposes to use saccade landing\nposition prediction to extrapolate the gaze information from delayed\neye-tracking samples. While the benefits of such a strategy have already been\ndemonstrated, the solutions range from simple and efficient ones, which make\nseveral assumptions about the saccadic eye movements, to more complex and\ncostly ones, which use machine learning techniques. Yet, it is unclear to what\nextent the prediction can benefit from accounting for additional factors.\n\\revcorr{This paper presents a series of experiments investigating the\nimportance of different factors for saccades prediction in common virtual and\naugmented reality applications. In particular, we investigate the effects of\nsaccade orientation in 3D space and smooth pursuit eye-motion (SPEM) and how\ntheir influence compares to the variability across users. We also present a\nsimple yet efficient correction method that adapts the existing saccade\nprediction methods to handle these factors without performing extensive data\ncollection.",
    "descriptor": "",
    "authors": [
      "Elena Arabadzhiyska",
      "Cara Tursun",
      "Hans-Peter Seidel",
      "Piotr Didyk"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2205.01624"
  },
  {
    "id": "arXiv:2205.01625",
    "title": "Toward Robust Spiking Neural Network Against Adversarial Perturbation",
    "abstract": "As spiking neural networks (SNNs) are deployed increasingly in real-world\nefficiency critical applications, the security concerns in SNNs attract more\nattention. Currently, researchers have already demonstrated an SNN can be\nattacked with adversarial examples. How to build a robust SNN becomes an urgent\nissue. Recently, many studies apply certified training in artificial neural\nnetworks (ANNs), which can improve the robustness of an NN model promisely.\nHowever, existing certifications cannot transfer to SNNs directly because of\nthe distinct neuron behavior and input formats for SNNs. In this work, we first\ndesign S-IBP and S-CROWN that tackle the non-linear functions in SNNs' neuron\nmodeling. Then, we formalize the boundaries for both digital and spike inputs.\nFinally, we demonstrate the efficiency of our proposed robust training method\nin different datasets and model architectures. Based on our experiment, we can\nachieve a maximum $37.7\\%$ attack error reduction with $3.7\\%$ original\naccuracy loss. To the best of our knowledge, this is the first analysis on\nrobust training of SNNs.",
    "descriptor": "",
    "authors": [
      "Ling Liang",
      "Kaidi Xu",
      "Xing Hu",
      "Lei Deng",
      "Yuan Xie"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01625"
  },
  {
    "id": "arXiv:2205.01626",
    "title": "Automated Learning of Interpretable Models with Quantified Uncertainty",
    "abstract": "Interpretability and uncertainty quantification in machine learning can\nprovide justification for decisions, promote scientific discovery and lead to a\nbetter understanding of model behavior. Symbolic regression provides inherently\ninterpretable machine learning, but relatively little work has focused on the\nuse of symbolic regression on noisy data and the accompanying necessity to\nquantify uncertainty. A new Bayesian framework for genetic-programming-based\nsymbolic regression (GPSR) is introduced that uses model evidence (i.e.,\nmarginal likelihood) to formulate replacement probability during the selection\nphase of evolution. Model parameter uncertainty is automatically quantified,\nenabling probabilistic predictions with each equation produced by the GPSR\nalgorithm. Model evidence is also quantified in this process, and its use is\nshown to increase interpretability, improve robustness to noise, and reduce\noverfitting when compared to a conventional GPSR implementation on both\nnumerical and physical experiments.",
    "descriptor": "",
    "authors": [
      "G.F. Bomarito",
      "P.E. Leser",
      "N.C.M Strauss",
      "K.M. Garbrecht",
      "J.D. Hochhalter"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01626"
  },
  {
    "id": "arXiv:2205.01629",
    "title": "AutoFi: Towards Automatic WiFi Human Sensing via Geometric  Self-Supervised Learning",
    "abstract": "WiFi sensing technology has shown superiority in smart homes among various\nsensors for its cost-effective and privacy-preserving merits. It is empowered\nby Channel State Information (CSI) extracted from WiFi signals and advanced\nmachine learning models to analyze motion patterns in CSI. Many learning-based\nmodels have been proposed for kinds of applications, but they severely suffer\nfrom environmental dependency. Though domain adaptation methods have been\nproposed to tackle this issue, it is not practical to collect high-quality,\nwell-segmented and balanced CSI samples in a new environment for adaptation\nalgorithms, but randomly captured CSI samples can be easily collected. In this\npaper, we firstly explore how to learn a robust model from these low-quality\nCSI samples, and propose AutoFi, an automatic WiFi sensing model based on a\nnovel geometric self-supervised learning algorithm. The AutoFi fully utilizes\nunlabeled low-quality CSI samples that are captured randomly, and then\ntransfers the knowledge to specific tasks defined by users, which is the first\nwork to achieve cross-task transfer in WiFi sensing. The AutoFi is implemented\non a pair of Atheros WiFi APs for evaluation. The AutoFi transfers knowledge\nfrom randomly collected CSI samples into human gait recognition and achieves\nstate-of-the-art performance. Furthermore, we simulate cross-task transfer\nusing public datasets to further demonstrate its capacity for cross-task\nlearning. For the UT-HAR and Widar datasets, the AutoFi achieves satisfactory\nresults on activity recognition and gesture recognition without any prior\ntraining. We believe that the AutoFi takes a huge step toward automatic WiFi\nsensing without any developer engagement while overcoming the cross-site issue.",
    "descriptor": "",
    "authors": [
      "Jianfei Yang",
      "Xinyan Chen",
      "Han Zou",
      "Dazhuo Wang",
      "Lihua Xie"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.01629"
  },
  {
    "id": "arXiv:2205.01631",
    "title": "A general approach to deriving diagnosability results of interconnection  networks",
    "abstract": "We generalize an approach to deriving diagnosability results of various\ninterconnection networks in terms of the popular $g$-good-neighbor and\n$g$-extra fault-tolerant models, as well as mainstream diagnostic models such\nas the PMC and the MM* models.\nAs demonstrative examples, we show how to follow this constructive, and\neffective, process to derive the $g$-extra diagnosabilities of the hypercube,\nthe $(n, k)$-star, and the arrangement graph. These results agree with those\nachieved individually, without duplicating structure independent technical\ndetails. Some of them come with a larger applicable range than those already\nknown, and the result for the arrangement graph in terms of the MM* model is\nnew.",
    "descriptor": "\nComments: Preliminary versions of some results of this paper were announced (without proofs) at 2019 International Conference on Modeling, Simulation, Optimization and Algorithm (ICMSOA 2019), November 9-10, 2019, Sanya, China. J. Phys: Conf. Ser. 1409 (2019) 012024\n",
    "authors": [
      "Eddie Cheng",
      "Yaping Mao",
      "Ke Qiu",
      "Zhizhang Shen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2205.01631"
  },
  {
    "id": "arXiv:2205.01632",
    "title": "Group separation strikes back",
    "abstract": "We consider group languages, which are those recognized by a finite group, or\nequivalently by a permutation automaton (i.e., each letter induces a\npermutation on the set of states). We investigate the separation problem for\nthis class: given two regular languages as input, decide whether there exists a\ngroup language containing the first, while being disjoint from the second. We\nprove that covering, which generalizes separation, is decidable. So far, this\nresult could only be obtained as a corollary of an independent algebraic\ntheorem by Ash, whose proof relies on involved algebraic notions. In contrast,\nour algorithm and its proof rely exclusively on standard notions from automata\ntheory. Additionally, we prove that covering is also decidable for two strict\nsubclasses: languages recognized by commutative groups, and modulo languages.\nBoth algorithms rely on the construction made for group languages, but the\nproof for commutative groups builds on independent ideas.",
    "descriptor": "",
    "authors": [
      "Thomas Place",
      "Marc Zeitoun"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2205.01632"
  },
  {
    "id": "arXiv:2205.01634",
    "title": "Multi-view Geometry: Correspondences Refinement Based on Algebraic  Properties",
    "abstract": "Correspondences estimation or feature matching is a key step in the\nimage-based 3D reconstruction problem. In this paper, we propose two algebraic\nproperties for correspondences. The first is a rank deficient matrix construct\nfrom the correspondences of at least nine key-points on two images (two-view\ncorrespondences) and the second is also another rank deficient matrix built\nfrom the other correspondences of six key-points on at least five images\n(multi-view correspondences). To our knowledge, there are no theoretical\nresults for multi-view correspondences prior to this paper. To obtain accurate\ncorrespondences, multi-view correspondences seem to be more useful than\ntwo-view correspondences. From these two algebraic properties, we propose an\nrefinement algorithm for correspondences. This algorithm is a combination of\ncorrespondences refinement, outliers recognition and missing key-points\nrecovery. Real experiments from the project of reconstructing Buddha statue\nshow that the proposed refinement algorithm can reduce the average error from\n77 pixels to 55 pixels on the correspondences estimation. This drop is\nsubstantial and it validates our results.",
    "descriptor": "",
    "authors": [
      "Trung-Kien Le",
      "Ping Li"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01634"
  },
  {
    "id": "arXiv:2205.01643",
    "title": "Cross-Domain Object Detection with Mean-Teacher Transformer",
    "abstract": "Recently, DEtection TRansformer (DETR), an end-to-end object detection\npipeline, has achieved promising performance. However, it requires large-scale\nlabeled data and suffers from domain shift, especially when no labeled data is\navailable in the target domain. To solve this problem, we propose an end-to-end\ncross-domain detection transformer based on the mean teacher knowledge transfer\n(MTKT), which transfers knowledge between domains via pseudo labels. To improve\nthe quality of pseudo labels in the target domain, which is a crucial factor\nfor better domain adaptation, we design three levels of source-target feature\nalignment strategies based on the architecture of the Transformer, including\ndomain query-based feature alignment (DQFA), bi-level-graph-based prototype\nalignment (BGPA), and token-wise image feature alignment (TIFA). These three\nlevels of feature alignment match the global, local, and instance features\nbetween source and target, respectively. With these strategies, more accurate\npseudo labels can be obtained, and knowledge can be better transferred from\nsource to target, thus improving the cross-domain capability of the detection\ntransformer. Extensive experiments demonstrate that our proposed method\nachieves state-of-the-art performance on three domain adaptation scenarios,\nespecially the result of Sim10k to Cityscapes scenario is remarkably improved\nfrom 52.6 mAP to 57.9 mAP. Code will be released.",
    "descriptor": "",
    "authors": [
      "Jinze Yu",
      "Jiaming Liu",
      "Xiaobao Wei",
      "Haoyi Zhou",
      "Yohei Nakata",
      "Denis Gudovskiy",
      "Tomoyuki Okuno",
      "Jianxin Li",
      "Kurt Keutzer",
      "Shanghang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01643"
  },
  {
    "id": "arXiv:2205.01644",
    "title": "Towards URLLC with Proactive HARQ Adaptation",
    "abstract": "In this work, we propose a dynamic decision maker algorithm to improve the\nproactive HARQ protocol for beyond 5G networks. Based on Lyapunov stochastic\noptimization, our adaptation control framework dynamically selects the number\nof proactive retransmissions for intermittent URLLC traffic scenarios under\ntime-varying channel conditions without requiring any prior knowledge\nassociated with this stochastic process. It then better exploits the trade-off\nbetween Radio Access Network (RAN) latency, reliability and resource\nefficiency, which is still limited in its realization on current HARQ designs.\nWe then evaluate the performance of several HARQ strategies and show that our\nproposal further improves latency over the reactive regime without affecting\nthe resource efficiency such as fixed proactive retransmission while\nmaintaining target reliability.",
    "descriptor": "",
    "authors": [
      "Lam Ngoc Dinh",
      "Ibtissam Labriji",
      "Mickael Maman",
      "Emilio Calvanese Strinati"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.01644"
  },
  {
    "id": "arXiv:2205.01646",
    "title": "Implementation of an efficient, portable and platform-agnostic  cryptocurrency mining algorithm for Internet of Things devices",
    "abstract": "Recently, there has been a remarkable amount of research being done in both,\nthe fields of Blockchain and Internet of Things (IoT). Blockchain technology\nsynergises well with IoT, solving key problems such as privacy, concerns with\ninteroperability and security. However, the consensus mechanisms that allows\ntrustless parties to maintain an agreement, the same algorithms that underpins\ncryptocurrency mining, are usually extremely computationally expensive, making\nimplementation on low-power IoT devices difficult. More importantly, mining\nrequires downloading and synchronizing hundred of gigabytes worth of blocks\nwhich is far beyond the capabilities of most IoT devices. In this paper, we\npresent an efficient, portable and platform-agnostic cryptocurrency mining\nalgorithm using the Stratum protocol to avoid downloading the entire\nblockchain. We implement the algorithm in four different platforms- PC, ESP32,\nan emulator and an old PlayStation Portable (PSP) to demonstrate that it is\nindeed possible for any device to mine cryptocurrencies with no assumptions\nexcept the ability to connect to the internet. To make sure of ease of\nportability on any platform and for reproducibility of the reported results we\nmake the implementation publicly available with detailed instructions at:\nhttps://anonymous.4open.science/r/cryptominer.",
    "descriptor": "\nComments: 10 pages, 9 figures, 4 tables. Submitted to Array, Elsevier\n",
    "authors": [
      "Kinshuk Dua"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.01646"
  },
  {
    "id": "arXiv:2205.01647",
    "title": "Intelligent Trajectory Design for RIS-NOMA aided Multi-robot  Communications",
    "abstract": "A novel reconfigurable intelligent surface-aided multi-robot network is\nproposed, where multiple mobile robots are served by an access point (AP)\nthrough non-orthogonal multiple access (NOMA). The goal is to maximize the\nsum-rate of whole trajectories for multi-robot system by jointly optimizing\ntrajectories and NOMA decoding orders of robots, phase-shift coefficients of\nthe RIS, and the power allocation of the AP, subject to predicted initial and\nfinal positions of robots and the quality of service (QoS) of each robot. To\ntackle this problem, an integrated machine learning (ML) scheme is proposed,\nwhich combines long short-term memory (LSTM)-autoregressive integrated moving\naverage (ARIMA) model and dueling double deep Q-network (D$^{3}$QN) algorithm.\nFor initial and final position prediction for robots, the LSTM-ARIMA is able to\novercome the problem of gradient vanishment of non-stationary and non-linear\nsequences of data. For jointly determining the phase shift matrix and robots'\ntrajectories, D$^{3}$QN is invoked for solving the problem of action value\noverestimation. Based on the proposed scheme, each robot holds a global optimal\ntrajectory based on the maximum sum-rate of a whole trajectory, which reveals\nthat robots pursue long-term benefits for whole trajectory design. Numerical\nresults demonstrated that: 1) LSTM-ARIMA model provides high accuracy\npredicting model; 2) The proposed D$^{3}$QN algorithm can achieve fast average\nconvergence; 3) The RIS with higher resolution bits offers a bigger sum-rate of\ntrajectories than lower resolution bits; and 4) RIS-NOMA networks have superior\nnetwork performance compared to RIS-aided orthogonal counterparts.",
    "descriptor": "\nComments: 30 pages, 12 figures, part of this work has been presented at the IEEE International Conference on Communications, 14-23 June, 2021\n",
    "authors": [
      "Xinyu Gao",
      "Xidong Mu",
      "Wenqiang Yi",
      "Yuanwei Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.01647"
  },
  {
    "id": "arXiv:2205.01651",
    "title": "Unique Characterisability and Learnability of Temporal Instance Queries",
    "abstract": "We aim to determine which temporal instance queries can be uniquely\ncharacterised by a (polynomial-size) set of positive and negative temporal data\nexamples. We start by considering queries formulated in fragments of\npropositional linear temporal logic LTL that correspond to conjunctive queries\n(CQs) or extensions thereof induced by the until operator. Not all of these\nqueries admit polynomial characterisations but by restricting them further to\npath-shaped queries we identify natural classes that do. We then investigate\nhow far the obtained characterisations can be lifted to temporal knowledge\ngraphs queried by 2D languages combining LTL with concepts in description\nlogics EL or ELI (i.e., tree-shaped CQs). While temporal operators in the scope\nof description logic constructors can destroy polynomial characterisability, we\nobtain general transfer results for the case when description logic\nconstructors are within the scope of temporal operators. Finally, we apply our\ncharacterisations to establish (polynomial) learnability of temporal instance\nqueries using membership queries in the active learning framework.",
    "descriptor": "\nComments: accepted for KR2022\n",
    "authors": [
      "Marie Fortin",
      "Boris Konev",
      "Vladislav Ryzhikov",
      "Yury Savateev",
      "Frank Wolter",
      "Michael Zakharyaschev"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.01651"
  },
  {
    "id": "arXiv:2205.01652",
    "title": "Episodic Memory Question Answering",
    "abstract": "Egocentric augmented reality devices such as wearable glasses passively\ncapture visual data as a human wearer tours a home environment. We envision a\nscenario wherein the human communicates with an AI agent powering such a device\nby asking questions (e.g., where did you last see my keys?). In order to\nsucceed at this task, the egocentric AI assistant must (1) construct\nsemantically rich and efficient scene memories that encode spatio-temporal\ninformation about objects seen during the tour and (2) possess the ability to\nunderstand the question and ground its answer into the semantic memory\nrepresentation. Towards that end, we introduce (1) a new task - Episodic Memory\nQuestion Answering (EMQA) wherein an egocentric AI assistant is provided with a\nvideo sequence (the tour) and a question as an input and is asked to localize\nits answer to the question within the tour, (2) a dataset of grounded questions\ndesigned to probe the agent's spatio-temporal understanding of the tour, and\n(3) a model for the task that encodes the scene as an allocentric, top-down\nsemantic feature map and grounds the question into the map to localize the\nanswer. We show that our choice of episodic scene memory outperforms naive,\noff-the-shelf solutions for the task as well as a host of very competitive\nbaselines and is robust to noise in depth, pose as well as camera jitter. The\nproject page can be found at: https://samyak-268.github.io/emqa .",
    "descriptor": "\nComments: Published at CVPR 2022 (Oral presentation)\n",
    "authors": [
      "Samyak Datta",
      "Sameer Dharur",
      "Vincent Cartillier",
      "Ruta Desai",
      "Mukul Khanna",
      "Dhruv Batra",
      "Devi Parikh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01652"
  },
  {
    "id": "arXiv:2205.01656",
    "title": "GeoRefine: Self-Supervised Online Depth Refinement for Accurate Dense  Mapping",
    "abstract": "We present a robust and accurate depth refinement system, named GeoRefine,\nfor geometrically-consistent dense mapping from monocular sequences. GeoRefine\nconsists of three modules: a hybrid SLAM module using learning-based priors, an\nonline depth refinement module leveraging self-supervision, and a global\nmapping module via TSDF fusion. The proposed system is online by design and\nachieves great robustness and accuracy via: (i) a robustified hybrid SLAM that\nincorporates learning-based optical flow and/or depth; (ii) self-supervised\nlosses that leverage SLAM outputs and enforce long-term geometric consistency;\n(iii) careful system design that avoids degenerate cases in online depth\nrefinement. We extensively evaluate GeoRefine on multiple public datasets and\nreach as low as $5\\%$ absolute relative depth errors.",
    "descriptor": "",
    "authors": [
      "Pan Ji",
      "Qingan Yan",
      "Yuxin Ma",
      "Yi Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01656"
  },
  {
    "id": "arXiv:2205.01657",
    "title": "Cross-modal Representation Learning for Zero-shot Action Recognition",
    "abstract": "We present a cross-modal Transformer-based framework, which jointly encodes\nvideo data and text labels for zero-shot action recognition (ZSAR). Our model\nemploys a conceptually new pipeline by which visual representations are learned\nin conjunction with visual-semantic associations in an end-to-end manner. The\nmodel design provides a natural mechanism for visual and semantic\nrepresentations to be learned in a shared knowledge space, whereby it\nencourages the learned visual embedding to be discriminative and more\nsemantically consistent. In zero-shot inference, we devise a simple semantic\ntransfer scheme that embeds semantic relatedness information between seen and\nunseen classes to composite unseen visual prototypes. Accordingly, the\ndiscriminative features in the visual structure could be preserved and\nexploited to alleviate the typical zero-shot issues of information loss,\nsemantic gap, and the hubness problem. Under a rigorous zero-shot setting of\nnot pre-training on additional datasets, the experiment results show our model\nconsiderably improves upon the state of the arts in ZSAR, reaching encouraging\ntop-1 accuracy on UCF101, HMDB51, and ActivityNet benchmark datasets. Code will\nbe made available.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Chung-Ching Lin",
      "Kevin Lin",
      "Linjie Li",
      "Lijuan Wang",
      "Zicheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01657"
  },
  {
    "id": "arXiv:2205.01663",
    "title": "Adversarial Training for High-Stakes Reliability",
    "abstract": "In the future, powerful AI systems may be deployed in high-stakes settings,\nwhere a single failure could be catastrophic. One technique for improving AI\nsafety in high-stakes settings is adversarial training, which uses an adversary\nto generate examples to train on in order to achieve better worst-case\nperformance.\nIn this work, we used a language generation task as a testbed for achieving\nhigh reliability through adversarial training. We created a series of\nadversarial training techniques -- including a tool that assists human\nadversaries -- to find and eliminate failures in a classifier that filters text\ncompletions suggested by a generator. In our simple \"avoid injuries\" task, we\ndetermined that we can set very conservative classifier thresholds without\nsignificantly impacting the quality of the filtered outputs. With our chosen\nthresholds, filtering with our baseline classifier decreases the rate of unsafe\ncompletions from about 2.4% to 0.003% on in-distribution data, which is near\nthe limit of our ability to measure. We found that adversarial training\nsignificantly increased robustness to the adversarial attacks that we trained\non, without affecting in-distribution performance. We hope to see further work\nin the high-stakes reliability setting, including more powerful tools for\nenhancing human adversaries and better ways to measure high levels of\nreliability, until we can confidently rule out the possibility of catastrophic\ndeployment-time failures of powerful models.",
    "descriptor": "\nComments: 31 pages, 6 figures\n",
    "authors": [
      "Daniel M. Ziegler",
      "Seraphina Nix",
      "Lawrence Chan",
      "Tim Bauman",
      "Peter Schmidt-Nielsen",
      "Tao Lin",
      "Adam Scherlis",
      "Noa Nabeshima",
      "Ben Weinstein-Raun",
      "Daniel de Haas",
      "Buck Shlegeris",
      "Nate Thomas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01663"
  },
  {
    "id": "arXiv:2205.01666",
    "title": "DANBO: Disentangled Articulated Neural Body Representations via Graph  Neural Networks",
    "abstract": "Deep learning greatly improved the realism of animatable human models by\nlearning geometry and appearance from collections of 3D scans, template meshes,\nand multi-view imagery. High-resolution models enable photo-realistic avatars\nbut at the cost of requiring studio settings not available to end users. Our\ngoal is to create avatars directly from raw images without relying on expensive\nstudio setups and surface tracking. While a few such approaches exist, those\nhave limited generalization capabilities and are prone to learning spurious\n(chance) correlations between irrelevant body parts, resulting in implausible\ndeformations and missing body parts on unseen poses. We introduce a three-stage\nmethod that induces two inductive biases to better disentangled pose-dependent\ndeformation. First, we model correlations of body parts explicitly with a graph\nneural network. Second, to further reduce the effect of chance correlations, we\nintroduce localized per-bone features that use a factorized volumetric\nrepresentation and a new aggregation function. We demonstrate that our model\nproduces realistic body shapes under challenging unseen poses and shows\nhigh-quality image synthesis. Our proposed representation strikes a better\ntrade-off between model capacity, expressiveness, and robustness than competing\nmethods. Project website: https://lemonatsu.github.io/danbo.",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Shih-Yang Su",
      "Timur Bagautdinov",
      "Helge Rhodin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01666"
  },
  {
    "id": "arXiv:2205.01668",
    "title": "End-to-End Visual Editing with a Generatively Pre-Trained Artist",
    "abstract": "We consider the targeted image editing problem: blending a region in a source\nimage with a driver image that specifies the desired change. Differently from\nprior works, we solve this problem by learning a conditional probability\ndistribution of the edits, end-to-end. Training such a model requires\naddressing a fundamental technical challenge: the lack of example edits for\ntraining. To this end, we propose a self-supervised approach that simulates\nedits by augmenting off-the-shelf images in a target domain. The benefits are\nremarkable: implemented as a state-of-the-art auto-regressive transformer, our\napproach is simple, sidesteps difficulties with previous methods based on\nGAN-like priors, obtains significantly better edits, and is efficient.\nFurthermore, we show that different blending effects can be learned by an\nintuitive control of the augmentation process, with no other changes required\nto the model architecture. We demonstrate the superiority of this approach\nacross several datasets in extensive quantitative and qualitative experiments,\nincluding human studies, significantly outperforming prior work.",
    "descriptor": "",
    "authors": [
      "Andrew Brown",
      "Cheng-Yang Fu",
      "Omkar Parkhi",
      "Tamara L. Berg",
      "Andrea Vedaldi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01668"
  },
  {
    "id": "arXiv:2205.00125",
    "title": "Quantum Telecloning on NISQ Computers",
    "abstract": "Due to the no-cloning theorem, generating perfect quantum clones of an\narbitrary quantum state is not possible, however approximate quantum clones can\nbe constructed. Quantum telecloning is a protocol that originates from a\ncombination of quantum teleportation and quantum cloning. Here we present $1\n\\rightarrow 2$ and $1 \\rightarrow 3$ quantum telecloning circuits, with and\nwithout ancilla, that are theoretically optimal (meaning the clones are the\nhighest fidelity allowed by quantum mechanics), universal (meaning the clone\nfidelity is independent of the state being cloned), and symmetric (meaning the\nclones all have the same fidelity). We implement these circuits on gate model\nIBMQ and Quantinuum NISQ hardware and quantify the clone fidelities using\nparallel single qubit state tomography. Quantum telecloning using mid-circuit\nmeasurement with real time if statements is demonstrated on the Quantinuum H1-2\ndevice. Two alternative implementations of quantum telecloning (deferred\nmeasurement and post selection) are demonstrated on ibmq\\_montreal for cases\nwhere mid-circuit measurement with real time if statements are not available.\nOur results show that NISQ devices can achieve near-optimal quantum telecloning\nfidelity; for example the Quantinuum H1-2 device running the telecloning\ncircuits without ancilla achieved a mean clone fidelity of $0.824$ for two\nclone circuits and $0.765$ for three clone circuits (the theoretical fidelity\nlimits are $0.8\\bar{33}$ for two clones and $0.\\bar{77}$ for three clones).\nThis demonstrates the viability of performing experimental analysis of quantum\ninformation networks and quantum cryptography protocols on NISQ computers.",
    "descriptor": "",
    "authors": [
      "Elijah Pelofske",
      "Andreas B\u00e4rtschi",
      "Bryan Garcia",
      "Boris Kiefer",
      "Stephan Eidenbenz"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2205.00125"
  },
  {
    "id": "arXiv:2205.01141",
    "title": "Efficient quantum algorithm for nonlinear reaction-diffusion equations  and energy estimation",
    "abstract": "Nonlinear differential equations exhibit rich phenomena in many fields but\nare notoriously challenging to solve. Recently, Liu et al. [1] demonstrated the\nfirst efficient quantum algorithm for dissipative quadratic differential\nequations under the condition $R < 1$, where $R$ measures the ratio of\nnonlinearity to dissipation using the $\\ell_2$ norm. Here we develop an\nefficient quantum algorithm based on [1] for reaction-diffusion equations, a\nclass of nonlinear partial differential equations (PDEs). To achieve this, we\nimprove upon the Carleman linearization approach introduced in [1] to obtain a\nfaster convergence rate under the condition $R_D < 1$, where $R_D$ measures the\nratio of nonlinearity to dissipation using the $\\ell_{\\infty}$ norm. Since\n$R_D$ is independent of the number of spatial grid points $n$ while $R$\nincreases with $n$, the criterion $R_D<1$ is significantly milder than $R<1$\nfor high-dimensional systems and can stay convergent under grid refinement for\napproximating PDEs. As applications of our quantum algorithm we consider the\nFisher-KPP and Allen-Cahn equations, which have interpretations in classical\nphysics. In particular, we show how to estimate the mean square kinetic energy\nin the solution by postprocessing the quantum state that encodes it to extract\nderivative information.",
    "descriptor": "\nComments: 59 pages, 5 figures\n",
    "authors": [
      "Dong An",
      "Di Fang",
      "Stephen Jordan",
      "Jin-Peng Liu",
      "Guang Hao Low",
      "Jiasu Wang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Mathematical Physics (math-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.01141"
  },
  {
    "id": "arXiv:2205.01158",
    "title": "Reproducing Kernels and New Approaches in Compositional Data Analysis",
    "abstract": "Compositional data, such as human gut microbiomes, consist of non-negative\nvariables whose only the relative values to other variables are available.\nAnalyzing compositional data such as human gut microbiomes needs a careful\ntreatment of the geometry of the data. A common geometrical understanding of\ncompositional data is via a regular simplex. Majority of existing approaches\nrely on a log-ratio or power transformations to overcome the innate simplicial\ngeometry. In this work, based on the key observation that a compositional data\nare projective in nature, and on the intrinsic connection between projective\nand spherical geometry, we re-interpret the compositional domain as the\nquotient topology of a sphere modded out by a group action. This\nre-interpretation allows us to understand the function space on compositional\ndomains in terms of that on spheres and to use spherical harmonics theory along\nwith reflection group actions for constructing a compositional Reproducing\nKernel Hilbert Space (RKHS). This construction of RKHS for compositional data\nwill widely open research avenues for future methodology developments. In\nparticular, well-developed kernel embedding methods can be now introduced to\ncompositional data analysis. The polynomial nature of compositional RKHS has\nboth theoretical and computational benefits. The wide applicability of the\nproposed theoretical framework is exemplified with nonparametric density\nestimation and kernel exponential family for compositional data.",
    "descriptor": "",
    "authors": [
      "Binglin Li",
      "Jeongyoun Ahn"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2205.01158"
  },
  {
    "id": "arXiv:2205.01165",
    "title": "Classical and Quantum Solvers for Joint Network/Servers Power  Optimization",
    "abstract": "The digital transformation that Telecommunications and ICT domains are\ncrossing today, is posing several new challenges to Telecom Operators. These\nchallenges require solving complex problems such as: dimensioning and\nscheduling of virtual/real resources in data centers; automating real-time\nmanagement/control and orchestration of networks processes; optimizing energy\nconsumption; and overall, ensuring networks and services stability. These\nproblems are usually tackled with methods and algorithms that find suboptimal\nsolutions, for computational efficiency reasons. In this work, we consider a\nVirtual Data Center scenario where virtual machine consolidation must be\nperformed with joint minimization of network/servers power consumption. For\nthis scenario, we provide an ILP model, the equivalent binary model and the\nsteps towards the equivalent Quadratic Unconstrained Binary Optimization (QUBO)\nmodel that is suitable for being solved by means of quantum optimization\nalgorithms. Finally, we compare the computational complexity of classical and\nquantum solvers from a theoretical perspective.",
    "descriptor": "\nComments: 13 pages, 2 figures\n",
    "authors": [
      "Michele Amoretti",
      "Davide Ferrari",
      "Antonio Manzalini"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.01165"
  },
  {
    "id": "arXiv:2205.01191",
    "title": "Taming graphs with no large creatures and skinny ladders",
    "abstract": "We confirm a conjecture of Gartland and Lokshtanov [arXiv:2007.08761]: if for\na hereditary graph class $\\mathcal{G}$ there exists a constant $k$ such that no\nmember of $\\mathcal{G}$ contains a $k$-creature as an induced subgraph or a\n$k$-skinny-ladder as an induced minor, then there exists a polynomial $p$ such\nthat every $G \\in \\mathcal{G}$ contains at most $p(|V(G)|)$ minimal separators.\nBy a result of Fomin, Todinca, and Villanger [SIAM J. Comput. 2015] the latter\nentails the existence of polynomial-time algorithms for Maximum Weight\nIndependent Set, Feedback Vertex Set and many other problems, when restricted\nto an input graph from $\\mathcal{G}$. Furthermore, as shown by Gartland and\nLokshtanov, our result implies a full dichotomy of hereditary graph classes\ndefined by a finite set of forbidden induced subgraphs into tame (admitting a\npolynomial bound of the number of minimal separators) and feral (containing\ninfinitely many graphs with exponential number of minimal separators).",
    "descriptor": "",
    "authors": [
      "Jakub Gajarsk\u00fd",
      "Lars Jaffke",
      "Paloma T. Lima",
      "Jana Novotn\u00e1",
      "Marcin Pilipczuk",
      "Pawe\u0142 Rz\u0105\u017cewski",
      "U\u00e9verton S. Souza"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.01191"
  },
  {
    "id": "arXiv:2205.01222",
    "title": "Leveraging Stochastic Predictions of Bayesian Neural Networks for Fluid  Simulations",
    "abstract": "We investigate uncertainty estimation and multimodality via the\nnon-deterministic predictions of Bayesian neural networks (BNNs) in fluid\nsimulations. To this end, we deploy BNNs in three challenging experimental\ntest-cases of increasing complexity: We show that BNNs, when used as surrogate\nmodels for steady-state fluid flow predictions, provide accurate physical\npredictions together with sensible estimates of uncertainty. Further, we\nexperiment with perturbed temporal sequences from Navier-Stokes simulations and\nevaluate the capabilities of BNNs to capture multimodal evolutions. While our\nfindings indicate that this is problematic for large perturbations, our results\nshow that the networks learn to correctly predict high uncertainties in such\nsituations. Finally, we study BNNs in the context of solver interactions with\nturbulent plasma flows. We find that BNN-based corrector networks can stabilize\ncoarse-grained simulations and successfully create multimodal trajectories.",
    "descriptor": "",
    "authors": [
      "Maximilian Mueller",
      "Robin Greif",
      "Frank Jenko",
      "Nils Thuerey"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01222"
  },
  {
    "id": "arXiv:2205.01223",
    "title": "FINETUNA: Fine-tuning Accelerated Molecular Simulations",
    "abstract": "Machine learning approaches have the potential to approximate Density\nFunctional Theory (DFT) for atomistic simulations in a computationally\nefficient manner, which could dramatically increase the impact of computational\nsimulations on real-world problems. However, they are limited by their accuracy\nand the cost of generating labeled data. Here, we present an online active\nlearning framework for accelerating the simulation of atomic systems\nefficiently and accurately by incorporating prior physical information learned\nby large-scale pre-trained graph neural network models from the Open Catalyst\nProject. Accelerating these simulations enables useful data to be generated\nmore cheaply, allowing better models to be trained and more atomistic systems\nto be screened. We also present a method of comparing local optimization\ntechniques on the basis of both their speed and accuracy. Experiments on 30\nbenchmark adsorbate-catalyst systems show that our method of transfer learning\nto incorporate prior information from pre-trained models accelerates\nsimulations by reducing the number of DFT calculations by 91%, while meeting an\naccuracy threshold of 0.02 eV 93% of the time. Finally, we demonstrate a\ntechnique for leveraging the interactive functionality built in to VASP to\nefficiently compute single point calculations within our online active learning\nframework without the significant startup costs. This allows VASP to work in\ntandem with our framework while requiring 75% fewer self-consistent cycles than\nconventional single point calculations. The online active learning\nimplementation, and examples using the VASP interactive code, are available in\nthe open source FINETUNA package on Github.",
    "descriptor": "\nComments: Joseph Musielewicz and Xiaoxiao Wang contributed equally to this work. 14 pages, 5 figures, submitted to Machine Learning: Science & Technology journal of IOP\n",
    "authors": [
      "Joseph Musielewicz",
      "Xiaoxiao Wang",
      "Tian Tian",
      "Zachary Ulissi"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01223"
  },
  {
    "id": "arXiv:2205.01239",
    "title": "A Performance-Consistent and Computation-Efficient CNN System for  High-Quality Automated Brain Tumor Segmentation",
    "abstract": "The research on developing CNN-based fully-automated Brain-Tumor-Segmentation\nsystems has been progressed rapidly. For the systems to be applicable in\npractice, a good The research on developing CNN-based fully-automated\nBrain-Tumor-Segmentation systems has been progressed rapidly. For the systems\nto be applicable in practice, a good processing quality and reliability are the\nmust. Moreover, for wide applications of such systems, a minimization of\ncomputation complexity is desirable, which can also result in a minimization of\nrandomness in computation and, consequently, a better performance consistency.\nTo this end, the CNN in the proposed system has a unique structure with 2\ndistinguished characters. Firstly, the three paths of its feature extraction\nblock are designed to extract, from the multi-modality input, comprehensive\nfeature information of mono-modality, paired-modality and cross-modality data,\nrespectively. Also, it has a particular three-branch classification block to\nidentify the pixels of 4 classes. Each branch is trained separately so that the\nparameters are updated specifically with the corresponding ground truth data of\na target tumor areas. The convolution layers of the system are custom-designed\nwith specific purposes, resulting in a very simple config of 61,843 parameters\nin total. The proposed system is tested extensively with BraTS2018 and\nBraTS2019 datasets. The mean Dice scores, obtained from the ten experiments on\nBraTS2018 validation samples, are 0.787+0.003, 0.886+0.002, 0.801+0.007, for\nenhancing tumor, whole tumor and tumor core, respectively, and 0.751+0.007,\n0.885+0.002, 0.776+0.004 on BraTS2019. The test results demonstrate that the\nproposed system is able to perform high-quality segmentation in a consistent\nmanner. Furthermore, its extremely low computation complexity will facilitate\nits implementation/application in various environments.",
    "descriptor": "\nComments: 10 pages, 4 figures, currently under review of IEEE transactions on medical imaging\n",
    "authors": [
      "Juncheng Tong",
      "Chunyan Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01239"
  },
  {
    "id": "arXiv:2205.01257",
    "title": "Norm-Agnostic Linear Bandits",
    "abstract": "Linear bandits have a wide variety of applications including recommendation\nsystems yet they make one strong assumption: the algorithms must know an upper\nbound $S$ on the norm of the unknown parameter $\\theta^*$ that governs the\nreward generation. Such an assumption forces the practitioner to guess $S$\ninvolved in the confidence bound, leaving no choice but to wish that\n$\\|\\theta^*\\|\\le S$ is true to guarantee that the regret will be low. In this\npaper, we propose novel algorithms that do not require such knowledge for the\nfirst time. Specifically, we propose two algorithms and analyze their regret\nbounds: one for the changing arm set setting and the other for the fixed arm\nset setting. Our regret bound for the former shows that the price of not\nknowing $S$ does not affect the leading term in the regret bound and inflates\nonly the lower order term. For the latter, we do not pay any price in the\nregret for now knowing $S$. Our numerical experiments show standard algorithms\nassuming knowledge of $S$ can fail catastrophically when $\\|\\theta^*\\|\\le S$ is\nnot true whereas our algorithms enjoy low regret.",
    "descriptor": "\nComments: AISTATS'22; added acknowledgements\n",
    "authors": [
      "Spencer",
      "Gales",
      "Sunder Sethuraman",
      "Kwang-Sung Jun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01257"
  },
  {
    "id": "arXiv:2205.01269",
    "title": "Modus ponens and modus tollens for the compositional rule of inference  with aggregation functions",
    "abstract": "The compositional rule of inference (CRI) proposed by Zadeh has been widely\napplied in artificial intelligence, control, data mining, image processing,\ndecision making and so on. Recently, Li and Zeng [Li, D., Zeng, Q. Approximate\nreasoning with aggregation functions satisfying GMP rules, Artificial\nIntelligence Review (2022), https://doi.org/10.1007/s10462-022-10136-1] shown\nan A-compositional rule of inference (ACRI) method in which generalizes the\nt-norm to any aggregation function in CRI method and studied its validity using\nGMP rules. In this paper, we continue to investigate the validity of ACRI\nmethod from a logical view and an interpolative view. Specifically, to discuss\nthe modus ponens (MP) and modus tollens (MT) properties of ACRI method based on\nwell-known fuzzy implications with aggregation functions.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2112.12808\n",
    "authors": [
      "Dechao Li",
      "Qingxue Zeng"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01269"
  },
  {
    "id": "arXiv:2205.01280",
    "title": "Improving Dual-Microphone Speech Enhancement by Learning Cross-Channel  Features with Multi-Head Attention",
    "abstract": "Hand-crafted spatial features, such as inter-channel intensity difference\n(IID) and inter-channel phase difference (IPD), play a fundamental role in\nrecent deep learning based dual-microphone speech enhancement (DMSE) systems.\nHowever, learning the mutual relationship between artificially designed spatial\nand spectral features is hard in the end-to-end DMSE. In this work, a novel\narchitecture for DMSE using a multi-head cross-attention based convolutional\nrecurrent network (MHCA-CRN) is presented. The proposed MHCA-CRN model includes\na channel-wise encoding structure for preserving intra-channel features and a\nmulti-head cross-attention mechanism for fully exploiting cross-channel\nfeatures. In addition, the proposed approach specifically formulates the\ndecoder with an extra SNR estimator to estimate frame-level SNR under a\nmulti-task learning framework, which is expected to avoid speech distortion led\nby end-to-end DMSE module. Finally, a spectral gain function is adopted to\nfurther suppress the unnatural residual noise. Experiment results demonstrated\nsuperior performance of the proposed model against several state-of-the-art\nmodels.",
    "descriptor": "\nComments: Accepted by ICASSP 2022\n",
    "authors": [
      "Xinmeng Xu",
      "Rongzhi Gu",
      "Yuexian Zou"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2205.01280"
  },
  {
    "id": "arXiv:2205.01303",
    "title": "Convergence of Stochastic Approximation via Martingale and Converse  Lyapunov Methods",
    "abstract": "This paper is dedicated to Prof. Eduardo Sontag on the occasion of his\nseventieth birthday. In this paper, we build upon the ideas first proposed in\nGladyshev (1965) to develop a very general framework for proving the almost\nsure boundedness and the convergence of stochastic approximation algorithms.\nThese ideas are based on martingale methods and are in some ways simpler than\nconvergence proofs based on the ODE method, e.g., Borkar-Meyn (2000). First we\nstudy the original version of the SA algorithm introduced in Robbins-Monro\n(1951), where the objective is to determine a zero of a function, when only\nnoisy measurements of the function are available. The proof makes use of the\ngeneral framework developed here, together with a new theorem on converse\nLyapunov stability, which might be of independent interest. Next we study an\nalternate version of SA, first introduced in Kiefer-Wolfowitz (1952). The\nobjective here is to find a stationary point of a scalar-valued function, using\nfirst-order differences to approximate its gradient. This problem is analyzed\nin Blum (1954), but with a very opaque proof. We reproduce Blum's conclusions\nusing the proposed framework.",
    "descriptor": "\nComments: 18 pages; dedicated to Prof. Eduardo Sontag on the occasion of his 70th birthday\n",
    "authors": [
      "M. Vidyasagar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2205.01303"
  },
  {
    "id": "arXiv:2205.01304",
    "title": "Efficient dynamic filter for robust and low computational feature  extraction",
    "abstract": "Unseen noise signal which is not considered in a model training process is\ndifficult to anticipate and would lead to performance degradation. Various\nmethods have been investigated to mitigate unseen noise. In our previous work,\nan Instance-level Dynamic Filter (IDF) and a Pixel Dynamic Filter (PDF) were\nproposed to extract noise-robust features. However, the performance of the\ndynamic filter might be degraded since simple feature pooling is used to reduce\nthe computational resource in the IDF part. In this paper, we propose an\nefficient dynamic filter to enhance the performance of the dynamic filter.\nInstead of utilizing the simple feature mean, we separate Time-Frequency (T-F)\nfeatures as non-overlapping chunks, and separable convolutions are carried out\nfor each feature direction (inter chunks and intra chunks). Additionally, we\npropose Dynamic Attention Pooling that maps high dimensional features as low\ndimensional feature embeddings. These methods are applied to the IDF for\nkeyword spotting and speaker verification tasks. We confirm that our proposed\nmethod performs better in unseen environments (unseen noise and unseen\nspeakers) than state-of-the-art models.",
    "descriptor": "",
    "authors": [
      "Donghyeon Kim",
      "Gwantae Kim",
      "Bokyeung Lee",
      "Jeong-gi Kwak",
      "David K. Han",
      "Hanseok Ko"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2205.01304"
  },
  {
    "id": "arXiv:2205.01317",
    "title": "Open vs Closed-ended questions in attitudinal surveys -- comparing,  combining, and interpreting using natural language processing",
    "abstract": "To improve the traveling experience, researchers have been analyzing the role\nof attitudes in travel behavior modeling. Although most researchers use\nclosed-ended surveys, the appropriate method to measure attitudes is debatable.\nTopic Modeling could significantly reduce the time to extract information from\nopen-ended responses and eliminate subjective bias, thereby alleviating analyst\nconcerns. Our research uses Topic Modeling to extract information from\nopen-ended questions and compare its performance with closed-ended responses.\nFurthermore, some respondents might prefer answering questions using their\npreferred questionnaire type. So, we propose a modeling framework that allows\nrespondents to use their preferred questionnaire type to answer the survey and\nenable analysts to use the modeling frameworks of their choice to predict\nbehavior. We demonstrate this using a dataset collected from the USA that\nmeasures the intention to use Autonomous Vehicles for commute trips.\nRespondents were presented with alternative questionnaire versions (open- and\nclosed- ended). Since our objective was also to compare the performance of\nalternative questionnaire versions, the survey was designed to eliminate\ninfluences resulting from statements, behavioral framework, and the choice\nexperiment. Results indicate the suitability of using Topic Modeling to extract\ninformation from open-ended responses; however, the models estimated using the\nclosed-ended questions perform better compared to them. Besides, the proposed\nmodel performs better compared to the models used currently. Furthermore, our\nproposed framework will allow respondents to choose the questionnaire type to\nanswer, which could be particularly beneficial to them when using voice-based\nsurveys.",
    "descriptor": "",
    "authors": [
      "Vishnu Baburajan",
      "Jo\u00e3o de Abreu e Silva",
      "Francisco Camara Pereira"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01317"
  },
  {
    "id": "arXiv:2205.01325",
    "title": "Exo-SIR: An Epidemiological Model to Analyze the Impact of Exogenous  Spread of Infection",
    "abstract": "Epidemics like Covid-19 and Ebola have impacted people's lives significantly.\nThe impact of mobility of people across the countries or states in the spread\nof epidemics has been significant. The spread of disease due to factors local\nto the population under consideration is termed the endogenous spread. The\nspread due to external factors like migration, mobility, etc. is called the\nexogenous spread. In this paper, we introduce the Exo-SIR model, an extension\nof the popular SIR model and a few variants of the model. The novelty in our\nmodel is that it captures both the exogenous and endogenous spread of the\nvirus. First, we present an analytical study. Second, we simulate the Exo-SIR\nmodel with and without assuming contact network for the population. Third, we\nimplement the Exo-SIR model on real datasets regarding Covid-19 and Ebola. We\nfound that endogenous infection is influenced by exogenous infection.\nFurthermore, we found that the Exo-SIR model predicts the peak time better than\nthe SIR model. Hence, the Exo-SIR model would be helpful for governments to\nplan policy interventions at the time of a pandemic.",
    "descriptor": "\nComments: To appear in Springer Nature Journal of Data Science and Analytics. arXiv admin note: substantial text overlap with arXiv:2008.06335\n",
    "authors": [
      "Nirmal Kumar Sivaraman",
      "Manas Gaur",
      "Shivansh Baijal",
      "Sakthi Balan Muthiah",
      "Amit Sheth"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.01325"
  },
  {
    "id": "arXiv:2205.01332",
    "title": "Large-scale Virtual Clinical Trials of Closed-loop Treatments for People  with Type 1 Diabetes",
    "abstract": "We propose a virtual clinical trial for assessing the safety and efficacy of\nclosed-loop diabetes treatments prior to an actual clinical trial. Such virtual\ntrials enable rapid and risk-free pretrial testing of algorithms, and they can\nbe used to compare different treatment variations for large and diverse\npopulations. The participants are represented by multiple mathematical models,\nconsisting of stochastic differential equations, and we use Monte Carlo\nclosed-loop simulations to compute detailed statistics of the closed-loop\ntreatments. We implement the virtual clinical trial using high-performance\nsoftware and hardware, and we present an example trial with two mathematical\nmodels of one~million participants over 52~weeks (i.e., two~million\nsimulations), which can be completed in 2~h 9~min.",
    "descriptor": "\nComments: 6 pages, 2 tables, 5 figures, in submission for presentation at a conference\n",
    "authors": [
      "Tobias K. S. Ritschel",
      "Asbj\u00f8rn Thode Reenberg",
      "John Bagterp J\u00f8rgensen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.01332"
  },
  {
    "id": "arXiv:2205.01385",
    "title": "Smooth over-parameterized solvers for non-smooth structured optimization",
    "abstract": "Non-smooth optimization is a core ingredient of many imaging or machine\nlearning pipelines. Non-smoothness encodes structural constraints on the\nsolutions, such as sparsity, group sparsity, low-rank and sharp edges. It is\nalso the basis for the definition of robust loss functions and scale-free\nfunctionals such as square-root Lasso. Standard approaches to deal with\nnon-smoothness leverage either proximal splitting or coordinate descent. These\napproaches are effective but usually require parameter tuning, preconditioning\nor some sort of support pruning. In this work, we advocate and study a\ndifferent route, which operates a non-convex but smooth over-parametrization of\nthe underlying non-smooth optimization problems. This generalizes quadratic\nvariational forms that are at the heart of the popular Iterative Reweighted\nLeast Squares (IRLS). Our main theoretical contribution connects gradient\ndescent on this reformulation to a mirror descent flow with a varying Hessian\nmetric. This analysis is crucial to derive convergence bounds that are\ndimension-free. This explains the efficiency of the method when using small\ngrid sizes in imaging. Our main algorithmic contribution is to apply the\nVariable Projection (VarPro) method which defines a new formulation by\nexplicitly minimizing over part of the variables. This leads to a better\nconditioning of the minimized functional and improves the convergence of simple\nbut very efficient gradient-based methods, for instance quasi-Newton solvers.\nWe exemplify the use of this new solver for the resolution of regularized\nregression problems for inverse problems and supervised learning, including\ntotal variation prior and non-convex regularizers.",
    "descriptor": "",
    "authors": [
      "Clarice Poon",
      "Gabriel Peyr\u00e9"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.01385"
  },
  {
    "id": "arXiv:2205.01387",
    "title": "Integration of Behavioral Economic Models to Optimize ML performance and  interpretability: a sandbox example",
    "abstract": "This paper presents a sandbox example of how the integration of models\nborrowed from Behavioral Economic (specifically Protection-Motivation Theory)\ninto ML algorithms (specifically Bayesian Networks) can improve the performance\nand interpretability of ML algorithms when applied to Behavioral Data. The\nintegration of Behavioral Economics knowledge to define the architecture of the\nBayesian Network increases the accuracy of the predictions in 11 percentage\npoints. Moreover, it simplifies the training process, making unnecessary\ntraining computational efforts to identify the optimal structure of the\nBayesian Network. Finally, it improves the explicability of the algorithm,\navoiding illogical relations among variables that are not supported by previous\nbehavioral cybersecurity literature. Although preliminary and limited to 0ne\nsimple model trained with a small dataset, our results suggest that the\nintegration of behavioral economics and complex ML models may open a promising\nstrategy to improve the predictive power, training costs and explicability of\ncomplex ML models. This integration will contribute to solve the scientific\nissue of ML exhaustion problem and to create a new ML technology with relevant\nscientific, technological and market implications.",
    "descriptor": "",
    "authors": [
      "Emilio Soria-Olivas",
      "Jos\u00e9 E. Vila Gisbert",
      "Regino Barranquero Carde\u00f1osa",
      "Yolanda Gomez"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2205.01387"
  },
  {
    "id": "arXiv:2205.01443",
    "title": "Learning Coulomb Diamonds in Large Quantum Dot Arrays",
    "abstract": "We introduce an algorithm that is able to find the facets of Coulomb diamonds\nin quantum dot arrays. We simulate these arrays using the constant-interaction\nmodel, and rely only on one-dimensional raster scans (rays) to learn a model of\nthe device using regularized maximum likelihood estimation. This allows us to\ndetermine, for a given charge state of the device, which transitions exist and\nwhat the compensated gate voltages for these are. For smaller devices the\nsimulator can also be used to compute the exact boundaries of the Coulomb\ndiamonds, which we use to assess that our algorithm correctly finds the vast\nmajority of transitions with high precision.",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Oswin Krause",
      "Anasua Chatterjee",
      "Ferdinand Kuemmeth",
      "Evert van Nieuwenburg"
    ],
    "subjectives": [
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01443"
  },
  {
    "id": "arXiv:2205.01445",
    "title": "High-dimensional Asymptotics of Feature Learning: How One Gradient Step  Improves the Representation",
    "abstract": "We study the first gradient descent step on the first-layer parameters\n$\\boldsymbol{W}$ in a two-layer neural network: $f(\\boldsymbol{x}) =\n\\frac{1}{\\sqrt{N}}\\boldsymbol{a}^\\top\\sigma(\\boldsymbol{W}^\\top\\boldsymbol{x})$,\nwhere $\\boldsymbol{W}\\in\\mathbb{R}^{d\\times N},\n\\boldsymbol{a}\\in\\mathbb{R}^{N}$ are randomly initialized, and the training\nobjective is the empirical MSE loss: $\\frac{1}{n}\\sum_{i=1}^n\n(f(\\boldsymbol{x}_i)-y_i)^2$. In the proportional asymptotic limit where\n$n,d,N\\to\\infty$ at the same rate, and an idealized student-teacher setting, we\nshow that the first gradient update contains a rank-1 \"spike\", which results in\nan alignment between the first-layer weights and the linear component of the\nteacher model $f^*$. To characterize the impact of this alignment, we compute\nthe prediction risk of ridge regression on the conjugate kernel after one\ngradient step on $\\boldsymbol{W}$ with learning rate $\\eta$, when $f^*$ is a\nsingle-index model. We consider two scalings of the first step learning rate\n$\\eta$. For small $\\eta$, we establish a Gaussian equivalence property for the\ntrained feature map, and prove that the learned kernel improves upon the\ninitial random features model, but cannot defeat the best linear model on the\ninput. Whereas for sufficiently large $\\eta$, we prove that for certain $f^*$,\nthe same ridge estimator on trained features can go beyond this \"linear regime\"\nand outperform a wide range of random features and rotationally invariant\nkernels. Our results demonstrate that even one gradient step can lead to a\nconsiderable advantage over random features, and highlight the role of learning\nrate scaling in the initial phase of training.",
    "descriptor": "\nComments: 71 pages\n",
    "authors": [
      "Jimmy Ba",
      "Murat A. Erdogdu",
      "Taiji Suzuki",
      "Zhichao Wang",
      "Denny Wu",
      "Greg Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2205.01445"
  },
  {
    "id": "arXiv:2205.01458",
    "title": "Frequency-Selective Geometry Upsampling of Point Clouds",
    "abstract": "The demand for high-resolution point clouds has increased throughout the last\nyears. However, capturing high-resolution point clouds is expensive and thus,\nfrequently replaced by upsampling of low-resolution data. Most state-of-the-art\nmethods are either restricted to a rastered grid, incorporate normal vectors,\nor are trained for a single use case. We propose to use the frequency\nselectivity principle, where a frequency model is estimated locally that\napproximates the surface of the point cloud. Then, additional points are\ninserted into the approximated surface. Our novel frequency-selective geometry\nupsampling shows superior results in terms of subjective as well as objective\nquality compared to state-of-the-art methods for scaling factors of 2 and 4. On\naverage, our proposed method shows a 4.4 times smaller point-to-point error\nthan the second best state-of-the-art PU-Net for a scale factor of 4.",
    "descriptor": "\nComments: 5 pages, 3 figures, submitted to International Conference on Image Processing (ICIP) 2022\n",
    "authors": [
      "Viktoria Heimann",
      "Andreas Spruck",
      "Andr\u00e9 Kaup"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01458"
  },
  {
    "id": "arXiv:2205.01478",
    "title": "Eigenvector centrality for multilayer networks with dependent node  importance",
    "abstract": "We present an approach for computing eigenvector centrality for multilayer\nnetworks with interlayer constraints on node importance. Specifically, we\nconsider a multilayer network defined by multiple edge-weighted, potentially\ndirected, graphs over the same set of nodes with each graph representing one\nlayer of the network. In this scenario, edges between layers are not allowed.\nAs in the standard eigenvector centrality construction, the importance each\nnode in a given layer is based on the weighted sum of the importance of\nadjacent nodes in that same layer. Unlike standard eigenvector centrality, we\nassume that the adjacency relationship and the importance of adjacent nodes may\nbe based on distinct layers. This form of centrality constraint between the\nlayers leads to eigenvector centrality values defined by a system of\ninterdependent eigenvalue problems, whose solution can be efficiently realized\nusing an interleaved power iteration algorithm.",
    "descriptor": "",
    "authors": [
      "H. Robert Frost"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.01478"
  },
  {
    "id": "arXiv:2205.01486",
    "title": "Scalable Regularised Joint Mixture Models",
    "abstract": "In many applications, data can be heterogeneous in the sense of spanning\nlatent groups with different underlying distributions. When predictive models\nare applied to such data the heterogeneity can affect both predictive\nperformance and interpretability. Building on developments at the intersection\nof unsupervised learning and regularised regression, we propose an approach for\nheterogeneous data that allows joint learning of (i) explicit multivariate\nfeature distributions, (ii) high-dimensional regression models and (iii) latent\ngroup labels, with both (i) and (ii) specific to latent groups and both\nelements informing (iii). The approach is demonstrably effective in high\ndimensions, combining data reduction for computational efficiency with a\nre-weighting scheme that retains key signals even when the number of features\nis large. We discuss in detail these aspects and their impact on modelling and\ncomputation, including EM convergence. The approach is modular and allows\nincorporation of data reductions and high-dimensional estimators that are\nsuitable for specific applications. We show results from extensive simulations\nand real data experiments, including highly non-Gaussian data. Our results\nallow efficient, effective analysis of high-dimensional data in settings, such\nas biomedicine, where both interpretable prediction and explicit feature space\nmodels are needed but hidden heterogeneity may be a concern.",
    "descriptor": "\nComments: 53 pages, 31 figures\n",
    "authors": [
      "Thomas Lartigue",
      "Sach Mukherjee"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2205.01486"
  },
  {
    "id": "arXiv:2205.01509",
    "title": "MS Lesion Segmentation: Revisiting Weighting Mechanisms for Federated  Learning",
    "abstract": "Federated learning (FL) has been widely employed for medical image analysis\nto facilitate multi-client collaborative learning without sharing raw data.\nDespite great success, FL's performance is limited for multiple sclerosis (MS)\nlesion segmentation tasks, due to variance in lesion characteristics imparted\nby different scanners and acquisition parameters. In this work, we propose the\nfirst FL MS lesion segmentation framework via two effective re-weighting\nmechanisms. Specifically, a learnable weight is assigned to each local node\nduring the aggregation process, based on its segmentation performance. In\naddition, the segmentation loss function in each client is also re-weighted\naccording to the lesion volume for the data during training. Comparison\nexperiments on two FL MS segmentation scenarios using public and clinical\ndatasets have demonstrated the effectiveness of the proposed method by\noutperforming other FL methods significantly. Furthermore, the segmentation\nperformance of FL incorporating our proposed aggregation mechanism can exceed\ncentralised training with all the raw data. The extensive evaluation also\nindicated the superiority of our method when estimating brain volume\ndifferences estimation after lesion inpainting.",
    "descriptor": "\nComments: 10 pages, 3 figures, and 7 tables\n",
    "authors": [
      "Dongnan Liu",
      "Mariano Cabezas",
      "Dongang Wang",
      "Zihao Tang",
      "Lei Bai",
      "Geng Zhan",
      "Yuling Luo",
      "Kain Kyle",
      "Linda Ly",
      "James Yu",
      "Chun-Chien Shieh",
      "Aria Nguyen",
      "Ettikan Kandasamy Karuppiah",
      "Ryan Sullivan",
      "Fernando Calamante",
      "Michael Barnett",
      "Wanli Ouyang",
      "Weidong Cai",
      "Chenyu Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01509"
  },
  {
    "id": "arXiv:2205.01528",
    "title": "Attentive activation function for improving end-to-end spoofing  countermeasure systems",
    "abstract": "The main objective of the spoofing countermeasure system is to detect the\nartifacts within the input speech caused by the speech synthesis or voice\nconversion process. In order to achieve this, we propose to adopt an attentive\nactivation function, more specifically attention rectified linear unit (AReLU)\nto the end-to-end spoofing countermeasure system. Since the AReLU employs the\nattention mechanism to boost the contribution of relevant input features while\nsuppressing the irrelevant ones, introducing AReLU can help the countermeasure\nsystem to focus on the features related to the artifacts. The proposed\nframework was experimented on the logical access (LA) task of ASVSpoof2019\ndataset, and outperformed the systems using the standard non-learnable\nactivation functions.",
    "descriptor": "",
    "authors": [
      "Woo Hyun Kang",
      "Jahangir Alam",
      "Abderrahim Fathan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2205.01528"
  },
  {
    "id": "arXiv:2205.01539",
    "title": "Parameterized Vietoris-Rips Filtrations via Covers",
    "abstract": "A challenge in computational topology is to deal with large filtered\ngeometric complexes built from point cloud data such as Vietoris-Rips\nfiltrations. This has led to the development of schemes for parallel\ncomputation and compression which restrict simplices to lie in open sets in a\ncover of the data. We extend the method of acyclic carriers to the setting of\npersistent homology to give detailed bounds on the relationship between\nVietoris-Rips filtrations restricted to covers and the full construction. We\nshow how these complexes can be used to study data over a base space and use\nour results to guide the selection of covers of data. We demonstrate these\ntechniques on a variety of covers, and show the utility of this construction in\ninvestigating higher-order homology of a model of high-dimensional image\npatches.",
    "descriptor": "\nComments: 18 pages, 6 figures\n",
    "authors": [
      "Bradley J. Nelson"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2205.01539"
  },
  {
    "id": "arXiv:2205.01552",
    "title": "Physical Layer Security for 6G Systems why it is needed and how to make  it happen",
    "abstract": "Sixth generations (6G) systems will be required to meet diverse constraints\nin an integrated ground-air-space global network. In particular, meeting overly\naggressive latency constraints, operating in massive connectivity regimes, with\nlow energy footprint and low computational effort, while providing explicit\nsecurity guarantees, can be challenging. In this setting, quality of security\n(QoSec) is envisioned as a flexible security framework for future networks with\nhighly diverse non-functional requirements. Mirroring the differentiated\nservices (DiffServ) networking paradigm, different security levels could be\nconceptualized, moving away from static security controls, captured currently\nin zero-trust security architectures. In parallel, the integration of\ncommunications and sensing, along with embedded (on-device) AI, can provide the\nfoundations for building autonomous and adaptive security controls,\norchestrated by a vertical security plane in coordination with a vertical\nsemantic plane. It is in this framework, that we envision the incorporation of\nphysical layer security (PLS) schemes in 6G security protocols, introducing\nsecurity controls at all layers, for the first time.",
    "descriptor": "",
    "authors": [
      "Arsenia Chorti"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.01552"
  },
  {
    "id": "arXiv:2205.01563",
    "title": "Simulation of reversible molecular mechanical logic gates and circuits",
    "abstract": "Landauer's principle places a fundamental lower limit on the work required to\nperform a logically irreversible operation. Logically reversible gates provide\na way to avoid these work costs, and also simplify the task of making the\ncomputation as a whole thermodynamically reversible. The inherent reversibility\nof mechanical logic gates would make them good candidates for the design of\npractical logically reversible computing systems if not for the relatively\nlarge size and mass of such systems. In this paper, we outline the design and\nsimulation of reversible molecular mechanical logic gates that come close to\nthe limits of thermodynamic reversibility even under the effects of thermal\nnoise, and outline associated circuit components from which arbitrary\ncombinatorial reversible circuits can be constructed and simulated. We\ndemonstrate that isolated components can be operated in a thermodynamically\nreversible manner, and explore the complexities of combining components to\nimplement more complex computations. Finally, we demonstrate a method to\nconstruct arbitrarily large reversible combinatorial circuits using multiple\nexternal controls and signal boosters with a working half-adder circuit.",
    "descriptor": "",
    "authors": [
      "Ian Seet",
      "Thomas E. Ouldridge",
      "Jonathan P.K. Doye"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2205.01563"
  },
  {
    "id": "arXiv:2205.01592",
    "title": "Conditional $\u03b2$-VAE for De Novo Molecular Generation",
    "abstract": "Deep learning has significantly advanced and accelerated de novo molecular\ngeneration. Generative networks, namely Variational Autoencoders (VAEs) can not\nonly randomly generate new molecules, but also alter molecular structures to\noptimize specific chemical properties which are pivotal for drug-discovery.\nWhile VAEs have been proposed and researched in the past for pharmaceutical\napplications, they possess deficiencies which limit their ability to both\noptimize properties and decode syntactically valid molecules. We present a\nrecurrent, conditional $\\beta$-VAE which disentangles the latent space to\nenhance post hoc molecule optimization. We create a mutual information driven\ntraining protocol and data augmentations to both increase molecular validity\nand promote longer sequence generation. We demonstrate the efficacy of our\nframework on the ZINC-250k dataset, achieving SOTA unconstrained optimization\nresults on the penalized LogP (pLogP) and QED scores, while also matching\ncurrent SOTA results for validity, novelty and uniqueness scores for random\ngeneration. We match the current SOTA on QED for top-3 molecules at 0.948,\nwhile setting a new SOTA for pLogP optimization at 104.29, 90.12, 69.68 and\ndemonstrating improved results on the constrained optimization task.",
    "descriptor": "",
    "authors": [
      "Ryan J Richards",
      "Austen M Groener"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)",
      "Molecular Networks (q-bio.MN)"
    ],
    "url": "https://arxiv.org/abs/2205.01592"
  },
  {
    "id": "arXiv:2205.01607",
    "title": "Modeling and Correcting Bias in Sequential Evaluation",
    "abstract": "We consider the problem of sequential evaluation, in which an evaluator\nobserves candidates in a sequence and assigns scores to these candidates in an\nonline, irrevocable fashion. Motivated by the psychology literature that has\nstudied sequential bias in such settings -- namely, dependencies between the\nevaluation outcome and the order in which the candidates appear -- we propose a\nnatural model for the evaluator's rating process that captures the lack of\ncalibration inherent to such a task. We conduct crowdsourcing experiments to\ndemonstrate various facets of our model. We then proceed to study how to\ncorrect sequential bias under our model by posing this as a statistical\ninference problem. We propose a near-linear time, online algorithm for this\ntask and prove guarantees in terms of two canonical ranking metrics, matched\nwith lower bounds demonstrating optimality in a certain sense. Our algorithm\noutperforms the de facto method of using the rankings induced by the reported\nscores.",
    "descriptor": "",
    "authors": [
      "Jingyan Wang",
      "Ashwin Pananjady"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Science and Game Theory (cs.GT)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01607"
  },
  {
    "id": "arXiv:2205.01628",
    "title": "SynopSet: Multiscale Visual Abstraction Set for Explanatory Analysis of  DNA Nanotechnology Simulations",
    "abstract": "We propose a new abstraction set (SynopSet) that has a continuum of visual\nrepresentations for the explanatory analysis of molecular dynamics simulations\n(MDS) in the DNA nanotechnology domain. By re-purposing the commonly used\nprogress bar and designing novel visuals, as well as transforming the data from\nthe domain format to a format that better fits the newly designed visuals, we\ncompose this new set of representations. This set is also designed to be\ncapable of showing all spatial and temporal details, and all structural\ncomplexity, or abstracting these to various degrees, enabling both the slow\nplayback of the simulation for detailed examinations or very fast playback for\nan overview that helps to efficiently identify events of interest, as well as\nseveral intermediate levels between these two extremes. For any pair of\nsuccessive representations, we demonstrate smooth, continuous transitions,\nenabling users to keep track of relevant information from one representation to\nthe next. By providing multiple representations suited to different temporal\nresolutions and connected by smooth transitions, we enable time-efficient\nsimulation analysis, giving users the opportunity to examine and present\nimportant phases in great detail, or leverage abstract representations to go\nover uneventful phases much faster. Domain experts can thus gain actionable\ninsight about their simulations and communicate it in a much shorter time.\nFurther, the novel representations are more intuitive and also enable\nresearchers unfamiliar with MDS analysis graphs to better understand the\nsimulation results. We assessed the effectiveness of SynopSet on 12 DNA\nnanostructure simulations together with a domain expert. We have also shown\nthat our set of representations can be systematically located in a\nvisualization space, dubbed SynopSpace.",
    "descriptor": "",
    "authors": [
      "Deng Luo",
      "Alexandre Kouyoumdjian",
      "Ond\u0159ej Strnad",
      "Haichao Miao",
      "Ivan Bari\u0161i\u0107",
      "Ivan Viola"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Biological Physics (physics.bio-ph)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.01628"
  },
  {
    "id": "arXiv:2205.01639",
    "title": "Dynamic and Context-Dependent Stock Price Prediction Using Attention  Modules and News Sentiment",
    "abstract": "The growth of machine-readable data in finance, such as alternative data,\nrequires new modeling techniques that can handle non-stationary and\nnon-parametric data. Due to the underlying causal dependence and the size and\ncomplexity of the data, we propose a new modeling approach for financial time\nseries data, the $\\alpha_{t}$-RIM (recurrent independent mechanism). This\narchitecture makes use of key-value attention to integrate top-down and\nbottom-up information in a context-dependent and dynamic way. To model the data\nin such a dynamic manner, the $\\alpha_{t}$-RIM utilizes an exponentially\nsmoothed recurrent neural network, which can model non-stationary times series\ndata, combined with a modular and independent recurrent structure. We apply our\napproach to the closing prices of three selected stocks of the S\\&P 500\nuniverse as well as their news sentiment score. The results suggest that the\n$\\alpha_{t}$-RIM is capable of reflecting the causal structure between stock\nprices and news sentiment, as well as the seasonality and trends. Consequently,\nthis modeling approach markedly improves the generalization performance, that\nis, the prediction of unseen data, and outperforms state-of-the-art networks\nsuch as long short-term memory models.",
    "descriptor": "",
    "authors": [
      "Nicole Koenigstein"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01639"
  },
  {
    "id": "arXiv:2205.01640",
    "title": "Adaptive Traffic Signal Control for Developing Countries Using Fused  Parameters Derived from Crowd-Source Data",
    "abstract": "Advancement of mobile technologies has enabled economical collection,\nstorage, processing, and sharing of traffic data. These data are made\naccessible to intended users through various application program interfaces\n(API) and can be used to recognize and mitigate congestion in real time. In\nthis paper, quantitative (time of arrival) and qualitative (color-coded\ncongestion levels) data were acquired from the Google traffic APIs. New\nparameters that reflect heterogeneous traffic conditions were defined and\nutilized for real-time control of traffic signals while maintaining the\ngreen-to-red time ratio. The proposed method utilizes a congestion-avoiding\nprinciple commonly used in computer networking. Adaptive congestion levels were\nobserved on three different intersections of Delhi (India), in peak hours. It\nshowed good variation, hence sensitive for the control algorithm to act\nefficiently. Also, simulation study establishes that proposed control algorithm\ndecreases waiting time and congestion. The proposed method provides an\ninexpensive alternative for traffic sensing and tracking technologies.",
    "descriptor": "\nComments: 15 pages, 11 figures, 7 tables, Accepted by Transportation Letters: the International Journal of Transportation Research\n",
    "authors": [
      "Sumit Mishra",
      "Vishal Singh",
      "Ankit Gupta",
      "Devanjan Bhattacharya",
      "Abhisek Mudgal"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.01640"
  },
  {
    "id": "arXiv:2205.01649",
    "title": "Learning Enriched Features for Fast Image Restoration and Enhancement",
    "abstract": "Given a degraded input image, image restoration aims to recover the missing\nhigh-quality image content. Numerous applications demand effective image\nrestoration, e.g., computational photography, surveillance, autonomous\nvehicles, and remote sensing. Significant advances in image restoration have\nbeen made in recent years, dominated by convolutional neural networks (CNNs).\nThe widely-used CNN-based methods typically operate either on full-resolution\nor on progressively low-resolution representations. In the former case, spatial\ndetails are preserved but the contextual information cannot be precisely\nencoded. In the latter case, generated outputs are semantically reliable but\nspatially less accurate. This paper presents a new architecture with a holistic\ngoal of maintaining spatially-precise high-resolution representations through\nthe entire network, and receiving complementary contextual information from the\nlow-resolution representations. The core of our approach is a multi-scale\nresidual block containing the following key elements: (a) parallel\nmulti-resolution convolution streams for extracting multi-scale features, (b)\ninformation exchange across the multi-resolution streams, (c) non-local\nattention mechanism for capturing contextual information, and (d) attention\nbased multi-scale feature aggregation. Our approach learns an enriched set of\nfeatures that combines contextual information from multiple scales, while\nsimultaneously preserving the high-resolution spatial details. Extensive\nexperiments on six real image benchmark datasets demonstrate that our method,\nnamed as MIRNet-v2 , achieves state-of-the-art results for a variety of image\nprocessing tasks, including defocus deblurring, image denoising,\nsuper-resolution, and image enhancement. The source code and pre-trained models\nare available at https://github.com/swz30/MIRNetv2",
    "descriptor": "\nComments: This article supersedes arXiv:2003.06792. Accepted for publication in TPAMI\n",
    "authors": [
      "Syed Waqas Zamir",
      "Aditya Arora",
      "Salman Khan",
      "Munawar Hayat",
      "Fahad Shahbaz Khan",
      "Ming-Hsuan Yang",
      "Ling Shao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01649"
  },
  {
    "id": "arXiv:1411.4407",
    "title": "Data driven weak universal consistency",
    "abstract": "Comments: Published in JMLR 2022",
    "descriptor": "\nComments: Published in JMLR 2022\n",
    "authors": [
      "N. Santhanam",
      "V. Anantharam",
      "W. Szpankowski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1411.4407"
  },
  {
    "id": "arXiv:1809.07005",
    "title": "Tail redundancy and its characterization of compression of memoryless  sources",
    "abstract": "Tail redundancy and its characterization of compression of memoryless  sources",
    "descriptor": "",
    "authors": [
      "Maryam Hosseini",
      "Narayana Santhanam"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1809.07005"
  },
  {
    "id": "arXiv:1901.03409",
    "title": "Graph embeddings into Hamming spaces",
    "abstract": "Comments: 3 pages",
    "descriptor": "\nComments: 3 pages\n",
    "authors": [
      "Dominic van der Zypen"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/1901.03409"
  },
  {
    "id": "arXiv:1908.00882",
    "title": "Population Predictive Checks",
    "abstract": "Population Predictive Checks",
    "descriptor": "",
    "authors": [
      "Gemma E. Moran",
      "David M. Blei",
      "Rajesh Ranganath"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1908.00882"
  },
  {
    "id": "arXiv:1908.08672",
    "title": "Jointly Modeling Hierarchical and Horizontal Features for Relational  Triple Extraction",
    "abstract": "Comments: 20 pages, 5 figures",
    "descriptor": "\nComments: 20 pages, 5 figures\n",
    "authors": [
      "Zhepei Wei",
      "Yantao Jia",
      "Yuan Tian",
      "Mohammad Javad Hosseini",
      "Sujian Li",
      "Mark Steedman",
      "Yi Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/1908.08672"
  },
  {
    "id": "arXiv:1910.01099",
    "title": "Graph modification for edge-coloured and signed graph homomorphism  problems: parameterized and classical complexity",
    "abstract": "Comments: 17 pages, 9 figures, 2 tables",
    "descriptor": "\nComments: 17 pages, 9 figures, 2 tables\n",
    "authors": [
      "Florent Foucaud",
      "Herv\u00e9 Hocquard",
      "Dimitri Lajou",
      "Valia Mitsou",
      "Th\u00e9o Pierron"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/1910.01099"
  },
  {
    "id": "arXiv:1910.05261",
    "title": "Finite element approximation of Lyapunov equations related to parabolic  stochastic PDEs",
    "abstract": "Comments: 29 pages with an 8 page appendix, 5 figures; revised presentation of result and added stability comparison with a Monte Carlo method",
    "descriptor": "\nComments: 29 pages with an 8 page appendix, 5 figures; revised presentation of result and added stability comparison with a Monte Carlo method\n",
    "authors": [
      "Adam Andersson",
      "Annika Lang",
      "Andreas Petersson",
      "Leander Schroer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/1910.05261"
  },
  {
    "id": "arXiv:1912.10905",
    "title": "Acoustic Scene Analysis using Analog Spiking Neural Network",
    "abstract": "Comments: 21 pages, Journal",
    "descriptor": "\nComments: 21 pages, Journal\n",
    "authors": [
      "Anand Kumar Mukhopadhyay",
      "Naligala Moses Prabhakar",
      "Divya Lakshmi Duggisetty",
      "Indrajit Chakrabarti",
      "Mrigank Sharad"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Emerging Technologies (cs.ET)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/1912.10905"
  },
  {
    "id": "arXiv:2005.04123",
    "title": "The ghosts of forgotten things: A study on size after forgetting",
    "abstract": "The ghosts of forgotten things: A study on size after forgetting",
    "descriptor": "",
    "authors": [
      "Paolo Liberatore"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2005.04123"
  },
  {
    "id": "arXiv:2006.03869",
    "title": "Learning Mixtures of Random Utility Models with Features from Incomplete  Preferences",
    "abstract": "Comments: Full version of the paper with the same title accepted by IJCAI-22",
    "descriptor": "\nComments: Full version of the paper with the same title accepted by IJCAI-22\n",
    "authors": [
      "Zhibing Zhao",
      "Ao Liu",
      "Lirong Xia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.03869"
  },
  {
    "id": "arXiv:2006.07776",
    "title": "Domain Adaptation and Image Classification via Deep Conditional  Adaptation Network",
    "abstract": "Domain Adaptation and Image Classification via Deep Conditional  Adaptation Network",
    "descriptor": "",
    "authors": [
      "Pengfei Ge",
      "Chuan-Xian Ren",
      "Dao-Qing Dai",
      "Hong Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2006.07776"
  },
  {
    "id": "arXiv:2007.04800",
    "title": "A Bandit Model for Human-Machine Decision Making with Private  Information and Opacity",
    "abstract": "A Bandit Model for Human-Machine Decision Making with Private  Information and Opacity",
    "descriptor": "",
    "authors": [
      "Sebastian Bordt",
      "Ulrike von Luxburg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.04800"
  },
  {
    "id": "arXiv:2010.04030",
    "title": "Weakly Supervised Learning of Multi-Object 3D Scene Decompositions Using  Deep Shape Priors",
    "abstract": "Comments: Preprint accepted to Computer Vision and Image Understanding",
    "descriptor": "\nComments: Preprint accepted to Computer Vision and Image Understanding\n",
    "authors": [
      "Cathrin Elich",
      "Martin R. Oswald",
      "Marc Pollefeys",
      "Joerg Stueckler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.04030"
  },
  {
    "id": "arXiv:2010.13506",
    "title": "Driving bifurcating parametrized nonlinear PDEs by optimal control  strategies: application to Navier-Stokes equations with model order reduction",
    "abstract": "Driving bifurcating parametrized nonlinear PDEs by optimal control  strategies: application to Navier-Stokes equations with model order reduction",
    "descriptor": "",
    "authors": [
      "Federico Pichi",
      "Maria Strazzullo",
      "Francesco Ballarin",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2010.13506"
  },
  {
    "id": "arXiv:2011.14619",
    "title": "DeepCloth: Neural Garment Representation for Shape and Style Editing",
    "abstract": "DeepCloth: Neural Garment Representation for Shape and Style Editing",
    "descriptor": "",
    "authors": [
      "Zhaoqi Su",
      "Tao Yu",
      "Yangang Wang",
      "Yebin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.14619"
  },
  {
    "id": "arXiv:2012.11073",
    "title": "Regularization in network optimization via trimmed stochastic gradient  descent with noisy label",
    "abstract": "Regularization in network optimization via trimmed stochastic gradient  descent with noisy label",
    "descriptor": "",
    "authors": [
      "Kensuke Nakamura",
      "Bong-Soo Sohn",
      "Kyoung-Jae Won",
      "Byung-Woo Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.11073"
  },
  {
    "id": "arXiv:2012.11109",
    "title": "Communicating Uncertainty and Risk in Air Quality Maps",
    "abstract": "Communicating Uncertainty and Risk in Air Quality Maps",
    "descriptor": "",
    "authors": [
      "Annie Preston",
      "Kwan-Liu Ma"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2012.11109"
  },
  {
    "id": "arXiv:2012.12298",
    "title": "Zeros of Gaussian Weyl-Heisenberg functions and hyperuniformity of  charge",
    "abstract": "Comments: 43 pages",
    "descriptor": "\nComments: 43 pages\n",
    "authors": [
      "Antti Haimi",
      "G\u00fcnther Koliander",
      "Jos\u00e9 Luis Romero"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2012.12298"
  },
  {
    "id": "arXiv:2012.14287",
    "title": "Frequency extraction for BEM-matrices arising from the 3D scalar  Helmholtz equation",
    "abstract": "Frequency extraction for BEM-matrices arising from the 3D scalar  Helmholtz equation",
    "descriptor": "",
    "authors": [
      "Simon Dirckx",
      "Daan Huybrechs",
      "Karl Meerbergen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2012.14287"
  },
  {
    "id": "arXiv:2101.12081",
    "title": "Generalising via Meta-Examples for Continual Learning in the Wild",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2009.08107",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2009.08107\n",
    "authors": [
      "Alessia Bertugli",
      "Stefano Vincenzi",
      "Simone Calderara",
      "Andrea Passerini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.12081"
  },
  {
    "id": "arXiv:2102.03277",
    "title": "Minimum projective linearizations of trees in linear time",
    "abstract": "Comments: Updated with latest revision submitted to journal",
    "descriptor": "\nComments: Updated with latest revision submitted to journal\n",
    "authors": [
      "Llu\u00eds Alemany-Puig",
      "Juan Luis Esteban",
      "Ramon Ferrer-i-Cancho"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computation and Language (cs.CL)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2102.03277"
  },
  {
    "id": "arXiv:2103.02597",
    "title": "Neural 3D Video Synthesis from Multi-view Video",
    "abstract": "Comments: Accepted as an oral presentation for CVPR 2022. Project website: this https URL",
    "descriptor": "\nComments: Accepted as an oral presentation for CVPR 2022. Project website: this https URL\n",
    "authors": [
      "Tianye Li",
      "Mira Slavcheva",
      "Michael Zollhoefer",
      "Simon Green",
      "Christoph Lassner",
      "Changil Kim",
      "Tanner Schmidt",
      "Steven Lovegrove",
      "Michael Goesele",
      "Richard Newcombe",
      "Zhaoyang Lv"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2103.02597"
  },
  {
    "id": "arXiv:2104.03543",
    "title": "Extended Parallel Corpus for Amharic-English Machine Translation",
    "abstract": "Comments: Accepted to LREC 2022",
    "descriptor": "\nComments: Accepted to LREC 2022\n",
    "authors": [
      "Andargachew Mekonnen Gezmu",
      "Andreas N\u00fcrnberger",
      "Tesfaye Bayu Bati"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.03543"
  },
  {
    "id": "arXiv:2104.11172",
    "title": "Inference in Opinion Dynamics under Social Pressure",
    "abstract": "Inference in Opinion Dynamics under Social Pressure",
    "descriptor": "",
    "authors": [
      "Ali Jadbabaie",
      "Anuran Makur",
      "Elchanan Mossel",
      "Rabih Salhab"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2104.11172"
  },
  {
    "id": "arXiv:2104.12278",
    "title": "Causal Learning for Socially Responsible AI",
    "abstract": "Comments: 8 pages, 3 figures, accepted at IJCAI21 survey track",
    "descriptor": "\nComments: 8 pages, 3 figures, accepted at IJCAI21 survey track\n",
    "authors": [
      "Lu Cheng",
      "Ahmadreza Mosallanezhad",
      "Paras Sheth",
      "Huan Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.12278"
  },
  {
    "id": "arXiv:2105.01469",
    "title": "Counting vertices of integral polytopes defined by facets",
    "abstract": "Comments: 15 pages. Minor edits, including a small change to the title. This version is accepted for publication in Discrete and Computational Geometry",
    "descriptor": "\nComments: 15 pages. Minor edits, including a small change to the title. This version is accepted for publication in Discrete and Computational Geometry\n",
    "authors": [
      "Heng Guo",
      "Mark Jerrum"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2105.01469"
  },
  {
    "id": "arXiv:2105.03155",
    "title": "Diffusion Mechanism in Residual Neural Network: Theory and Applications",
    "abstract": "Diffusion Mechanism in Residual Neural Network: Theory and Applications",
    "descriptor": "",
    "authors": [
      "Tangjun Wang",
      "Zehao Dou",
      "Chenglong Bao",
      "Zuoqiang Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03155"
  },
  {
    "id": "arXiv:2105.05209",
    "title": "Restoring Hebrew Diacritics Without a Dictionary",
    "abstract": "Comments: Findings of NAACL 2022 (in press). 6 pages, 1 figure",
    "descriptor": "\nComments: Findings of NAACL 2022 (in press). 6 pages, 1 figure\n",
    "authors": [
      "Elazar Gershuni",
      "Yuval Pinter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.05209"
  },
  {
    "id": "arXiv:2105.10155",
    "title": "Should We Trust This Summary? Bayesian Abstractive Summarization to The  Rescue",
    "abstract": "Should We Trust This Summary? Bayesian Abstractive Summarization to The  Rescue",
    "descriptor": "",
    "authors": [
      "Alexios Gidiotis",
      "Grigorios Tsoumakas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.10155"
  },
  {
    "id": "arXiv:2105.11084",
    "title": "Unsupervised Speech Recognition",
    "abstract": "Unsupervised Speech Recognition",
    "descriptor": "",
    "authors": [
      "Alexei Baevski",
      "Wei-Ning Hsu",
      "Alexis Conneau",
      "Michael Auli"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.11084"
  },
  {
    "id": "arXiv:2105.12914",
    "title": "Random Simplicial Complexes: Models and Phenomena",
    "abstract": "Random Simplicial Complexes: Models and Phenomena",
    "descriptor": "",
    "authors": [
      "Omer Bobrowski",
      "Dmitri Krioukov"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Social and Information Networks (cs.SI)",
      "Algebraic Topology (math.AT)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.12914"
  },
  {
    "id": "arXiv:2106.08771",
    "title": "Reinforcement Learning for Markovian Bandits: Is Posterior Sampling more  Scalable than Optimism?",
    "abstract": "Reinforcement Learning for Markovian Bandits: Is Posterior Sampling more  Scalable than Optimism?",
    "descriptor": "",
    "authors": [
      "Nicolas Gast",
      "Bruno Gaujal",
      "Kimang Khun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08771"
  },
  {
    "id": "arXiv:2106.13086",
    "title": "Partial Maximum Correntropy Regression for Robust Trajectory Decoding  from Noisy Epidural Electrocorticographic Signals",
    "abstract": "Partial Maximum Correntropy Regression for Robust Trajectory Decoding  from Noisy Epidural Electrocorticographic Signals",
    "descriptor": "",
    "authors": [
      "Yuanhao Li",
      "Badong Chen",
      "Gang Wang",
      "Natsue Yoshimura",
      "Yasuharu Koike"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13086"
  },
  {
    "id": "arXiv:2106.15419",
    "title": "Convergent and Efficient Deep Q Network Algorithm",
    "abstract": "Convergent and Efficient Deep Q Network Algorithm",
    "descriptor": "",
    "authors": [
      "Zhikang T. Wang",
      "Masahito Ueda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.15419"
  },
  {
    "id": "arXiv:2107.05863",
    "title": "Toward Safe Integration of Legacy SCADA Systems in the Smart Grid",
    "abstract": "Comments: 22 pages, 6 figures",
    "descriptor": "\nComments: 22 pages, 6 figures\n",
    "authors": [
      "Aldar C-F. Chan",
      "Jianying Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.05863"
  },
  {
    "id": "arXiv:2107.06943",
    "title": "FetalNet: Multi-task Deep Learning Framework for Fetal Ultrasound  Biometric Measurements",
    "abstract": "Comments: Accepted to 28th International Conference on Neural Information Processing (ICONIP) 2021, Bali, Indonesia, 8-12 December, 2021",
    "descriptor": "\nComments: Accepted to 28th International Conference on Neural Information Processing (ICONIP) 2021, Bali, Indonesia, 8-12 December, 2021\n",
    "authors": [
      "Szymon P\u0142otka",
      "Tomasz W\u0142odarczyk",
      "Adam Klasa",
      "Micha\u0142 Lipa",
      "Arkadiusz Sitek",
      "Tomasz Trzci\u0144ski"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06943"
  },
  {
    "id": "arXiv:2107.11852",
    "title": "Reconfigurable Intelligent Surface Phase Hopping for Ultra-Reliable  Communications",
    "abstract": "Comments: 13 pages, 12 figures",
    "descriptor": "\nComments: 13 pages, 12 figures\n",
    "authors": [
      "Karl-Ludwig Besser",
      "Eduard A. Jorswieck"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.11852"
  },
  {
    "id": "arXiv:2108.06988",
    "title": "A diffusion-map-based algorithm for gradient computation on manifolds  and applications",
    "abstract": "Comments: New version with applications in inverse problems",
    "descriptor": "\nComments: New version with applications in inverse problems\n",
    "authors": [
      "Alvaro Almeida Gomez",
      "Ant\u00f4nio J. Silva Neto",
      "Jorge P. Zubelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.06988"
  },
  {
    "id": "arXiv:2108.07160",
    "title": "Computing and Listing Avoidable Vertices and Paths",
    "abstract": "Computing and Listing Avoidable Vertices and Paths",
    "descriptor": "",
    "authors": [
      "Charis Papadopoulos",
      "Athanasios Zisis"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2108.07160"
  },
  {
    "id": "arXiv:2109.04392",
    "title": "Fair Conformal Predictors for Applications in Medical Imaging",
    "abstract": "Comments: 7 pages, 6 figures, AAAI-22 conference",
    "descriptor": "\nComments: 7 pages, 6 figures, AAAI-22 conference\n",
    "authors": [
      "Charles Lu",
      "Andreanne Lemay",
      "Ken Chang",
      "Katharina Hoebel",
      "Jayashree Kalpathy-Cramer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04392"
  },
  {
    "id": "arXiv:2109.06980",
    "title": "Explainable Identification of Dementia from Transcripts using  Transformer Networks",
    "abstract": "Comments: IEEE Journal of Biomedical and Health Informatics (Accepted)",
    "descriptor": "\nComments: IEEE Journal of Biomedical and Health Informatics (Accepted)\n",
    "authors": [
      "Loukas Ilias",
      "Dimitris Askounis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06980"
  },
  {
    "id": "arXiv:2109.07049",
    "title": "Self-Training with Differentiable Teacher",
    "abstract": "Comments: NAACL 2022 (Findings)",
    "descriptor": "\nComments: NAACL 2022 (Findings)\n",
    "authors": [
      "Simiao Zuo",
      "Yue Yu",
      "Chen Liang",
      "Haoming Jiang",
      "Siawpeng Er",
      "Chao Zhang",
      "Tuo Zhao",
      "Hongyuan Zha"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07049"
  },
  {
    "id": "arXiv:2109.08971",
    "title": "Envy-Free and Pareto-Optimal Allocations for Agents with Asymmetric  Random Valuations",
    "abstract": "Comments: Appeared in IJCAI 22'",
    "descriptor": "\nComments: Appeared in IJCAI 22'\n",
    "authors": [
      "Yushi Bai",
      "Paul G\u00f6lz"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2109.08971"
  },
  {
    "id": "arXiv:2109.12249",
    "title": "A general alternating-direction implicit framework with Gaussian process  regression parameter prediction for large sparse linear systems",
    "abstract": "A general alternating-direction implicit framework with Gaussian process  regression parameter prediction for large sparse linear systems",
    "descriptor": "",
    "authors": [
      "Kai Jiang",
      "Xuehong Su",
      "Juan Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.12249"
  },
  {
    "id": "arXiv:2109.12813",
    "title": "An optimised deep spiking neural network architecture without gradients",
    "abstract": "Comments: 18 pages, 6 figures",
    "descriptor": "\nComments: 18 pages, 6 figures\n",
    "authors": [
      "Yeshwanth Bethi",
      "Ying Xu",
      "Gregory Cohen",
      "Andre van Schaik",
      "Saeed Afshar"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.12813"
  },
  {
    "id": "arXiv:2109.14176",
    "title": "Linear Asymptotic Convergence of Anderson Acceleration: Fixed-Point  Analysis",
    "abstract": "Linear Asymptotic Convergence of Anderson Acceleration: Fixed-Point  Analysis",
    "descriptor": "",
    "authors": [
      "Hans De Sterck",
      "Yunhui He"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.14176"
  },
  {
    "id": "arXiv:2109.14771",
    "title": "Polynomial Approximation of Symmetric Functions",
    "abstract": "Polynomial Approximation of Symmetric Functions",
    "descriptor": "",
    "authors": [
      "Markus Bachmayr",
      "Genevi\u00e8ve Dusson",
      "Christoph Ortner",
      "Jack Thomas"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.14771"
  },
  {
    "id": "arXiv:2110.06123",
    "title": "COVID-19 Diagnosis from Cough Acoustics using ConvNets and Data  Augmentation",
    "abstract": "Comments: DiCOVA, top 1st, This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: DiCOVA, top 1st, This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Saranga Kingkor Mahanta",
      "Darsh Kaushik",
      "Shubham Jain",
      "Hoang Van Truong",
      "Koushik Guha"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.06123"
  },
  {
    "id": "arXiv:2110.06635",
    "title": "ADOP: Approximate Differentiable One-Pixel Point Rendering",
    "abstract": "ADOP: Approximate Differentiable One-Pixel Point Rendering",
    "descriptor": "",
    "authors": [
      "Darius R\u00fcckert",
      "Linus Franke",
      "Marc Stamminger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.06635"
  },
  {
    "id": "arXiv:2110.08394",
    "title": "Adapt to Adaptation: Learning Personalization for Cross-Silo Federated  Learning",
    "abstract": "Comments: Accepted by IJCAI 2022",
    "descriptor": "\nComments: Accepted by IJCAI 2022\n",
    "authors": [
      "Jun Luo",
      "Shandong Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08394"
  },
  {
    "id": "arXiv:2110.11867",
    "title": "CeyMo: See More on Roads -- A Novel Benchmark Dataset for Road Marking  Detection",
    "abstract": "Comments: Accepted to 2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV 2022)",
    "descriptor": "\nComments: Accepted to 2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV 2022)\n",
    "authors": [
      "Oshada Jayasinghe",
      "Sahan Hemachandra",
      "Damith Anhettigama",
      "Shenali Kariyawasam",
      "Ranga Rodrigo",
      "Peshala Jayasekara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11867"
  },
  {
    "id": "arXiv:2110.15093",
    "title": "Finite Horizon Q-learning: Stability, Convergence, Simulations and an  application on Smart Grids",
    "abstract": "Finite Horizon Q-learning: Stability, Convergence, Simulations and an  application on Smart Grids",
    "descriptor": "",
    "authors": [
      "Vivek VP",
      "Dr.Shalabh Bhatnagar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15093"
  },
  {
    "id": "arXiv:2110.15943",
    "title": "MetaICL: Learning to Learn In Context",
    "abstract": "Comments: 19 pages, 2 figures. Published as a conference paper at NAACL 2022 (long). Code available at this https URL",
    "descriptor": "\nComments: 19 pages, 2 figures. Published as a conference paper at NAACL 2022 (long). Code available at this https URL\n",
    "authors": [
      "Sewon Min",
      "Mike Lewis",
      "Luke Zettlemoyer",
      "Hannaneh Hajishirzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15943"
  },
  {
    "id": "arXiv:2111.01221",
    "title": "Robust Federated Learning via Over-The-Air Computation",
    "abstract": "Robust Federated Learning via Over-The-Air Computation",
    "descriptor": "",
    "authors": [
      "Houssem Sifaou",
      "Geoffrey Ye Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01221"
  },
  {
    "id": "arXiv:2111.01533",
    "title": "A comparison of mixed-variables Bayesian optimization approaches",
    "abstract": "Comments: Accepted for publication in Advanced Modeling and Simulation in Engineering Sciences, march 2022",
    "descriptor": "\nComments: Accepted for publication in Advanced Modeling and Simulation in Engineering Sciences, march 2022\n",
    "authors": [
      "Jhouben Cuesta-Ramirez",
      "Rodolphe Le Riche",
      "Olivier Roustant",
      "Guillaume Perrin",
      "Cedric Durantin",
      "Alain Gliere"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.01533"
  },
  {
    "id": "arXiv:2111.04637",
    "title": "A hemispheric two-channel code accounts for binaural unmasking in humans",
    "abstract": "A hemispheric two-channel code accounts for binaural unmasking in humans",
    "descriptor": "",
    "authors": [
      "J\u00f6rg Encke",
      "Mathias Dietz"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.04637"
  },
  {
    "id": "arXiv:2111.05620",
    "title": "Tracking multiple spawning targets using Poisson multi-Bernoulli  mixtures on sets of tree trajectories",
    "abstract": "Comments: Matlab code can be found at this https URL",
    "descriptor": "\nComments: Matlab code can be found at this https URL\n",
    "authors": [
      "\u00c1ngel F. Garc\u00eda-Fern\u00e1ndez",
      "Lennart Svensson"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Systems and Control (eess.SY)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2111.05620"
  },
  {
    "id": "arXiv:2111.06921",
    "title": "Performance Analysis over Correlated/Independent Fisher-Snedecor F  Fading Multi-User Channels",
    "abstract": "Performance Analysis over Correlated/Independent Fisher-Snedecor F  Fading Multi-User Channels",
    "descriptor": "",
    "authors": [
      "Farshad Rostami Ghadi",
      "Wei-Ping Zhu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.06921"
  },
  {
    "id": "arXiv:2111.07380",
    "title": "Eluding Secure Aggregation in Federated Learning via Model Inconsistency",
    "abstract": "Comments: 17 pages",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Dario Pasquini",
      "Danilo Francati",
      "Giuseppe Ateniese"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.07380"
  },
  {
    "id": "arXiv:2111.10541",
    "title": "Retrieve-then-extract Based Knowledge Graph Querying Using Graph Neural  Networks",
    "abstract": "Retrieve-then-extract Based Knowledge Graph Querying Using Graph Neural  Networks",
    "descriptor": "",
    "authors": [
      "Hanning Gao",
      "Lingfei Wu",
      "Po Hu",
      "Zhihua Wei",
      "Fangli Xu",
      "Bo Long"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.10541"
  },
  {
    "id": "arXiv:2111.11892",
    "title": "LMGP: Lifted Multicut Meets Geometry Projections for Multi-Camera  Multi-Object Tracking",
    "abstract": "Comments: Official version for CVPR 2022",
    "descriptor": "\nComments: Official version for CVPR 2022\n",
    "authors": [
      "Duy M. H. Nguyen",
      "Roberto Henschel",
      "Bodo Rosenhahn",
      "Daniel Sonntag",
      "Paul Swoboda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.11892"
  },
  {
    "id": "arXiv:2111.15338",
    "title": "A Semi-automated Method for Domain-Specific Ontology Creation from  Medical Guidelines",
    "abstract": "Comments: Published at EMMSAD 2022",
    "descriptor": "\nComments: Published at EMMSAD 2022\n",
    "authors": [
      "Omar ElAssy",
      "Rik de Vendt",
      "Fabiano Dalpiaz",
      "Sjaak Brinkkemper"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.15338"
  },
  {
    "id": "arXiv:2112.01156",
    "title": "A Unified Framework for Adversarial Attack and Defense in Constrained  Feature Space",
    "abstract": "A Unified Framework for Adversarial Attack and Defense in Constrained  Feature Space",
    "descriptor": "",
    "authors": [
      "Thibault Simonetto",
      "Salijona Dyrmishi",
      "Salah Ghamizi",
      "Maxime Cordy",
      "Yves Le Traon"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01156"
  },
  {
    "id": "arXiv:2112.04764",
    "title": "3D-VField: Adversarial Augmentation of Point Clouds for Domain  Generalization in 3D Object Detection",
    "abstract": "Comments: CVPR 2022. Project page: this https URL",
    "descriptor": "\nComments: CVPR 2022. Project page: this https URL\n",
    "authors": [
      "Alexander Lehner",
      "Stefano Gasperini",
      "Alvaro Marcos-Ramiro",
      "Michael Schmidt",
      "Mohammad-Ali Nikouei Mahani",
      "Nassir Navab",
      "Benjamin Busam",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.04764"
  },
  {
    "id": "arXiv:2112.05536",
    "title": "Rapid manufacturing of color-based hemispherical soft tactile fingertips",
    "abstract": "Rapid manufacturing of color-based hemispherical soft tactile fingertips",
    "descriptor": "",
    "authors": [
      "Rob B.N. Scharff",
      "Dirk-Jan Boonstra",
      "Laurence Willemet",
      "Xi Lin",
      "Micha\u00ebl Wiertlewski"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.05536"
  },
  {
    "id": "arXiv:2112.05787",
    "title": "Representation Learning for Conversational Data using Discourse Mutual  Information Maximization",
    "abstract": "Comments: Preprint, 15 pages, To appear in NAACL 2022 (Main)",
    "descriptor": "\nComments: Preprint, 15 pages, To appear in NAACL 2022 (Main)\n",
    "authors": [
      "Bishal Santra",
      "Sumegh Roychowdhury",
      "Aishik Mandal",
      "Vasu Gurram",
      "Atharva Naik",
      "Manish Gupta",
      "Pawan Goyal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.05787"
  },
  {
    "id": "arXiv:2112.06833",
    "title": "Beyond Ads: Sequential Decision-Making Algorithms in Law and Public  Policy",
    "abstract": "Comments: Version 1 presented at Causal Inference Challenges in Sequential Decision Making: Bridging Theory and Practice, a NeurIPS 2021 Workshop",
    "descriptor": "\nComments: Version 1 presented at Causal Inference Challenges in Sequential Decision Making: Bridging Theory and Practice, a NeurIPS 2021 Workshop\n",
    "authors": [
      "Peter Henderson",
      "Ben Chugg",
      "Brandon Anderson",
      "Daniel E. Ho"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.06833"
  },
  {
    "id": "arXiv:2112.07660",
    "title": "Massive-scale Decoding for Text Generation using Lattices",
    "abstract": "Comments: NAACL 2022, see this https URL for code",
    "descriptor": "\nComments: NAACL 2022, see this https URL for code\n",
    "authors": [
      "Jiacheng Xu",
      "Siddhartha Reddy Jonnalagadda",
      "Greg Durrett"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07660"
  },
  {
    "id": "arXiv:2112.07790",
    "title": "Maximum Bayes Smatch Ensemble Distillation for AMR Parsing",
    "abstract": "Maximum Bayes Smatch Ensemble Distillation for AMR Parsing",
    "descriptor": "",
    "authors": [
      "Young-Suk Lee",
      "Ramon Fernandez Astudillo",
      "Thanh Lam Hoang",
      "Tahira Naseem",
      "Radu Florian",
      "Salim Roukos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07790"
  },
  {
    "id": "arXiv:2112.07916",
    "title": "LongT5: Efficient Text-To-Text Transformer for Long Sequences",
    "abstract": "Comments: Accepted in NAACL 2022",
    "descriptor": "\nComments: Accepted in NAACL 2022\n",
    "authors": [
      "Mandy Guo",
      "Joshua Ainslie",
      "David Uthus",
      "Santiago Ontanon",
      "Jianmo Ni",
      "Yun-Hsuan Sung",
      "Yinfei Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07916"
  },
  {
    "id": "arXiv:2112.08594",
    "title": "Twitter-COMMs: Detecting Climate, COVID, and Military Multimodal  Misinformation",
    "abstract": "Comments: 11 pages, 6 figures",
    "descriptor": "\nComments: 11 pages, 6 figures\n",
    "authors": [
      "Giscard Biamby",
      "Grace Luo",
      "Trevor Darrell",
      "Anna Rohrbach"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08594"
  },
  {
    "id": "arXiv:2112.08786",
    "title": "Efficient Hierarchical Domain Adaptation for Pretrained Language Models",
    "abstract": "Comments: NAACL 2022 accepted paper camera ready version",
    "descriptor": "\nComments: NAACL 2022 accepted paper camera ready version\n",
    "authors": [
      "Alexandra Chronopoulou",
      "Matthew E. Peters",
      "Jesse Dodge"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08786"
  },
  {
    "id": "arXiv:2112.08787",
    "title": "AcTune: Uncertainty-aware Active Self-Training for Semi-Supervised  Active Learning with Pretrained Language Models",
    "abstract": "Comments: NAACL 2022 Main Conference (Code: this https URL)",
    "descriptor": "\nComments: NAACL 2022 Main Conference (Code: this https URL)\n",
    "authors": [
      "Yue Yu",
      "Lingkai Kong",
      "Jieyu Zhang",
      "Rongzhi Zhang",
      "Chao Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08787"
  },
  {
    "id": "arXiv:2112.08995",
    "title": "Connecting the Dots between Audio and Text without Parallel Data through  Visual Knowledge Transfer",
    "abstract": "Comments: Accepted to NAACL 2022. Our code is available at this https URL",
    "descriptor": "\nComments: Accepted to NAACL 2022. Our code is available at this https URL\n",
    "authors": [
      "Yanpeng Zhao",
      "Jack Hessel",
      "Youngjae Yu",
      "Ximing Lu",
      "Rowan Zellers",
      "Yejin Choi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.08995"
  },
  {
    "id": "arXiv:2112.10166",
    "title": "FedNI: Federated Graph Learning with Network Inpainting for  Population-Based Disease Prediction",
    "abstract": "FedNI: Federated Graph Learning with Network Inpainting for  Population-Based Disease Prediction",
    "descriptor": "",
    "authors": [
      "Liang Peng",
      "Nan Wang",
      "Nicha Dvornek",
      "Xiaofeng Zhu",
      "Xiaoxiao Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.10166"
  },
  {
    "id": "arXiv:2201.00864",
    "title": "Secret Sharing Sharing For Highly Scalable Secure Aggregation",
    "abstract": "Comments: 12 pages, 6 figures",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Timothy Stevens",
      "Joseph Near",
      "Christian Skalka"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.00864"
  },
  {
    "id": "arXiv:2201.00989",
    "title": "DigNet: Digging Clues from Local-Global Interactive Graph for  Aspect-level Sentiment Classification",
    "abstract": "Comments: submitted to Journal of Artificial Intelligence Research (JAIR)",
    "descriptor": "\nComments: submitted to Journal of Artificial Intelligence Research (JAIR)\n",
    "authors": [
      "Bowen Xing",
      "Ivor Tsang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.00989"
  },
  {
    "id": "arXiv:2201.01666",
    "title": "Sample Efficient Deep Reinforcement Learning via Uncertainty Estimation",
    "abstract": "Comments: ICLR 2022 [Spotlight]",
    "descriptor": "\nComments: ICLR 2022 [Spotlight]\n",
    "authors": [
      "Vincent Mai",
      "Kaustubh Mani",
      "Liam Paull"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.01666"
  },
  {
    "id": "arXiv:2201.05028",
    "title": "Context binning, model clustering and adaptivity for data compression of  genetic data",
    "abstract": "Comments: 7 pages, 7 figures",
    "descriptor": "\nComments: 7 pages, 7 figures\n",
    "authors": [
      "Jarek Duda"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2201.05028"
  },
  {
    "id": "arXiv:2201.05041",
    "title": "LARD: Large-scale Artificial Disfluency Generation",
    "abstract": "Comments: Accepted at LREC 2022",
    "descriptor": "\nComments: Accepted at LREC 2022\n",
    "authors": [
      "T. Passali",
      "T. Mavropoulos",
      "G. Tsoumakas",
      "G. Meditskos",
      "S. Vrochidis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.05041"
  },
  {
    "id": "arXiv:2201.05279",
    "title": "Manifoldron: Direct Space Partition via Manifold Discovery",
    "abstract": "Manifoldron: Direct Space Partition via Manifold Discovery",
    "descriptor": "",
    "authors": [
      "Dayang Wang",
      "Feng-Lei Fan",
      "Bo-Jian Hou",
      "Hao Zhang",
      "Zhen Jia",
      "Boce Zhou",
      "Rongjie Lai",
      "Hengyong Yu",
      "Fei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.05279"
  },
  {
    "id": "arXiv:2201.06503",
    "title": "Analytic-DPM: an Analytic Estimate of the Optimal Reverse Variance in  Diffusion Probabilistic Models",
    "abstract": "Comments: ICLR 2022 (Outstanding Paper Award)",
    "descriptor": "\nComments: ICLR 2022 (Outstanding Paper Award)\n",
    "authors": [
      "Fan Bao",
      "Chongxuan Li",
      "Jun Zhu",
      "Bo Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.06503"
  },
  {
    "id": "arXiv:2201.06665",
    "title": "Text characterization based on recurrence networks",
    "abstract": "Text characterization based on recurrence networks",
    "descriptor": "",
    "authors": [
      "B\u00e1rbara C. e Souza",
      "Filipi N. Silva",
      "Henrique F. de Arruda",
      "Giovana D. da Silva",
      "Luciano da F. Costa",
      "Diego R. Amancio"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2201.06665"
  },
  {
    "id": "arXiv:2201.07765",
    "title": "Towards Situational Aware Cyber-Physical Systems: A Security-Enhancing  Use Case of Blockchain-based Digital Twins",
    "abstract": "Comments: 39 pages, 10 figures",
    "descriptor": "\nComments: 39 pages, 10 figures\n",
    "authors": [
      "Sabah Suhail",
      "Saif Ur Rehman Malik",
      "Raja Jurdak",
      "Rasheed Hussain",
      "Raimundas Matulevi\u010dius",
      "Davor Svetinovic"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.07765"
  },
  {
    "id": "arXiv:2201.08207",
    "title": "Invasion Dynamics in the Biased Voter Process",
    "abstract": "Comments: 8 pages, 3 figures. To be published in IJCAI-22",
    "descriptor": "\nComments: 8 pages, 3 figures. To be published in IJCAI-22\n",
    "authors": [
      "Loke Durocher",
      "Panagiotis Karras",
      "Andreas Pavlogiannis",
      "Josef Tkadlec"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2201.08207"
  },
  {
    "id": "arXiv:2201.08484",
    "title": "Iterated Reasoning with Mutual Information in Cooperative and Byzantine  Decentralized Teaming",
    "abstract": "Comments: The first two authors contributed equally to this work (Published in ICLR 2022)",
    "descriptor": "\nComments: The first two authors contributed equally to this work (Published in ICLR 2022)\n",
    "authors": [
      "Sachin Konan",
      "Esmaeil Seraj",
      "Matthew Gombolay"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.08484"
  },
  {
    "id": "arXiv:2201.08914",
    "title": "Numerical Analysis of a Corrected Smagorinsky Model",
    "abstract": "Comments: 26pages,4 figures, 2 table",
    "descriptor": "\nComments: 26pages,4 figures, 2 table\n",
    "authors": [
      "Farjana Siddiqua",
      "Xihui Xie"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2201.08914"
  },
  {
    "id": "arXiv:2201.12158",
    "title": "Stagnation Detection Meets Fast Mutation",
    "abstract": "Comments: 28 pages. Full version of a paper appearing at EvoCOP 2022",
    "descriptor": "\nComments: 28 pages. Full version of a paper appearing at EvoCOP 2022\n",
    "authors": [
      "Benjamin Doerr",
      "Amirhossein Rajabi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2201.12158"
  },
  {
    "id": "arXiv:2201.13402",
    "title": "Privacy Limitations Of Interest-based Advertising On The Web: A  Post-mortem Empirical Analysis Of Google's FLoC",
    "abstract": "Privacy Limitations Of Interest-based Advertising On The Web: A  Post-mortem Empirical Analysis Of Google's FLoC",
    "descriptor": "",
    "authors": [
      "Alex Berke",
      "Dan Calacci"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2201.13402"
  },
  {
    "id": "arXiv:2202.00543",
    "title": "Testability and local certification of monotone properties in  minor-closed classes",
    "abstract": "Comments: Accepted in the 49th EATCS International Colloquium on Automata, Languages and Programming (ICALP 2022)",
    "descriptor": "\nComments: Accepted in the 49th EATCS International Colloquium on Automata, Languages and Programming (ICALP 2022)\n",
    "authors": [
      "Louis Esperet",
      "Sergey Norin"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.00543"
  },
  {
    "id": "arXiv:2202.01909",
    "title": "Ad-datasets: a meta-collection of data sets for autonomous driving",
    "abstract": "Comments: Daniel Bogdoll and Felix Schreyer contributed equally. Accepted for publication at VEHITS 2022",
    "descriptor": "\nComments: Daniel Bogdoll and Felix Schreyer contributed equally. Accepted for publication at VEHITS 2022\n",
    "authors": [
      "Daniel Bogdoll",
      "Felix Schreyer",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01909"
  },
  {
    "id": "arXiv:2202.03497",
    "title": "A crawling robot driven by a folded self-sustained oscillator",
    "abstract": "Comments: 6 pages, 8 figures, has been accepted by RoboSoft 2022",
    "descriptor": "\nComments: 6 pages, 8 figures, has been accepted by RoboSoft 2022\n",
    "authors": [
      "Wenzhong Yan",
      "Ankur Mehta"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.03497"
  },
  {
    "id": "arXiv:2202.04052",
    "title": "Decision boundaries and convex hulls in the feature space that deep  learning functions learn from images",
    "abstract": "Decision boundaries and convex hulls in the feature space that deep  learning functions learn from images",
    "descriptor": "",
    "authors": [
      "Roozbeh Yousefzadeh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.04052"
  },
  {
    "id": "arXiv:2202.05628",
    "title": "Artemis: Articulated Neural Pets with Appearance and Motion synthesis",
    "abstract": "Artemis: Articulated Neural Pets with Appearance and Motion synthesis",
    "descriptor": "",
    "authors": [
      "Haimin Luo",
      "Teng Xu",
      "Yuheng Jiang",
      "Chenglin Zhou",
      "Qiwei Qiu",
      "Yingliang Zhang",
      "Wei Yang",
      "Lan Xu",
      "Jingyi Yu"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05628"
  },
  {
    "id": "arXiv:2202.06428",
    "title": "Beyond Worst-Case Analysis for Root Isolation Algorithms",
    "abstract": "Comments: 9 pages, 2 figures. 2nd version: New title, corrections",
    "descriptor": "\nComments: 9 pages, 2 figures. 2nd version: New title, corrections\n",
    "authors": [
      "Alperen A. Erg\u00fcr",
      "Josu\u00e9 Tonelli-Cueto",
      "Elias Tsigaridas"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Symbolic Computation (cs.SC)",
      "Algebraic Geometry (math.AG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2202.06428"
  },
  {
    "id": "arXiv:2202.06450",
    "title": "Towards Deployment-Efficient Reinforcement Learning: Lower Bound and  Optimality",
    "abstract": "Comments: 49 Pages; ICLR 2022",
    "descriptor": "\nComments: 49 Pages; ICLR 2022\n",
    "authors": [
      "Jiawei Huang",
      "Jinglin Chen",
      "Li Zhao",
      "Tao Qin",
      "Nan Jiang",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.06450"
  },
  {
    "id": "arXiv:2202.06830",
    "title": "Online Approval Committee Elections",
    "abstract": "Comments: To appear at IJCAI 2022",
    "descriptor": "\nComments: To appear at IJCAI 2022\n",
    "authors": [
      "Virginie Do",
      "Matthieu Hervouin",
      "J\u00e9r\u00f4me Lang",
      "Piotr Skowron"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.06830"
  },
  {
    "id": "arXiv:2202.06877",
    "title": "A Review of zk-SNARKs",
    "abstract": "A Review of zk-SNARKs",
    "descriptor": "",
    "authors": [
      "Thomas Chen",
      "Hui Lu",
      "Teeramet Kunpittaya",
      "Alan Luo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.06877"
  },
  {
    "id": "arXiv:2202.08381",
    "title": "Improving Performance Bounds for Weighted Round-Robin Schedulers under  Constrained Cross-Traffic",
    "abstract": "Improving Performance Bounds for Weighted Round-Robin Schedulers under  Constrained Cross-Traffic",
    "descriptor": "",
    "authors": [
      "Vlad-Cristian Constantin",
      "Paul Nikolaus",
      "Jens Schmitt"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.08381"
  },
  {
    "id": "arXiv:2202.08437",
    "title": "Visual attention analysis of pathologists examining whole slide images  of Prostate cancer",
    "abstract": "Comments: ISBI 2022 (Oral presentation)",
    "descriptor": "\nComments: ISBI 2022 (Oral presentation)\n",
    "authors": [
      "Souradeep Chakraborty",
      "Ke Ma",
      "Rajarsi Gupta",
      "Beatrice Knudsen",
      "Gregory J. Zelinsky",
      "Joel H. Saltz",
      "Dimitris Samaras"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08437"
  },
  {
    "id": "arXiv:2202.09338",
    "title": "Signal Decomposition Using Masked Proximal Operators",
    "abstract": "Comments: The manuscript has 57 pages, 22 figures and 2 tables. Also hosted at this https URL For code, see this https URL",
    "descriptor": "\nComments: The manuscript has 57 pages, 22 figures and 2 tables. Also hosted at this https URL For code, see this https URL\n",
    "authors": [
      "Bennet E. Meyers",
      "Stephen P. Boyd"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.09338"
  },
  {
    "id": "arXiv:2202.11205",
    "title": "Constant matters: Fine-grained Complexity of Differentially Private  Continual Observation",
    "abstract": "Comments: 29 pages (includes new graphs and applications)",
    "descriptor": "\nComments: 29 pages (includes new graphs and applications)\n",
    "authors": [
      "Hendrik Fichtenberger",
      "Monika Henzinger",
      "Jalaj Upadhyay"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11205"
  },
  {
    "id": "arXiv:2202.11257",
    "title": "ML-Aided Collision Recovery for UHF-RFID Systems",
    "abstract": "ML-Aided Collision Recovery for UHF-RFID Systems",
    "descriptor": "",
    "authors": [
      "Talha Akyildiz",
      "Raymond Ku",
      "Nicholas Harder",
      "Najme Ebrahimi",
      "Hessam Mahdavifar"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.11257"
  },
  {
    "id": "arXiv:2203.00274",
    "title": "TableFormer: Robust Transformer Modeling for Table-Text Encoding",
    "abstract": "Comments: ACL 2022, 10 pages",
    "descriptor": "\nComments: ACL 2022, 10 pages\n",
    "authors": [
      "Jingfeng Yang",
      "Aditya Gupta",
      "Shyam Upadhyay",
      "Luheng He",
      "Rahul Goel",
      "Shachi Paul"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.00274"
  },
  {
    "id": "arXiv:2203.00439",
    "title": "Active learning with binary models for real time data labelling",
    "abstract": "Active learning with binary models for real time data labelling",
    "descriptor": "",
    "authors": [
      "Ankush Deshmukh",
      "Bhargava B C",
      "A V Narasimhadhan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.00439"
  },
  {
    "id": "arXiv:2203.01322",
    "title": "Recent, rapid advancement in visual question answering architecture: a  review",
    "abstract": "Comments: 8 pages. Accepted to EIT2022 conference",
    "descriptor": "\nComments: 8 pages. Accepted to EIT2022 conference\n",
    "authors": [
      "Venkat Kodali",
      "Daniel Berleant"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2203.01322"
  },
  {
    "id": "arXiv:2203.02628",
    "title": "Target Network and Truncation Overcome The Deadly Triad in $Q$-Learning",
    "abstract": "Target Network and Truncation Overcome The Deadly Triad in $Q$-Learning",
    "descriptor": "",
    "authors": [
      "Zaiwei Chen",
      "John Paul Clarke",
      "Siva Theja Maguluri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.02628"
  },
  {
    "id": "arXiv:2203.02832",
    "title": "On the Error of Random Sampling: Uniformly Distributed Random Points on  Parametric Curves",
    "abstract": "Comments: 10 pages, 5 figures, 1 table. 2nd version: New title, major changes",
    "descriptor": "\nComments: 10 pages, 5 figures, 1 table. 2nd version: New title, major changes\n",
    "authors": [
      "Apostolos Chalkis",
      "Christina Katsamaki",
      "Josu\u00e9 Tonelli-Cueto"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computational Complexity (cs.CC)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2203.02832"
  },
  {
    "id": "arXiv:2203.03437",
    "title": "Multilevel Monte Carlo with Surrogate Models for Resource Adequacy  Assessment",
    "abstract": "Multilevel Monte Carlo with Surrogate Models for Resource Adequacy  Assessment",
    "descriptor": "",
    "authors": [
      "Ensieh Sharifnia",
      "Simon Tindemans"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.03437"
  },
  {
    "id": "arXiv:2203.04183",
    "title": "Enhancing Mechanical Metamodels with a Generative Model-Based Augmented  Training Dataset",
    "abstract": "Comments: 14 pages, 6 figures",
    "descriptor": "\nComments: 14 pages, 6 figures\n",
    "authors": [
      "Hiba Kobeissi",
      "Saeed Mohammadzadeh",
      "Emma Lejeune"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2203.04183"
  },
  {
    "id": "arXiv:2203.05642",
    "title": "Parameter-Free Attentive Scoring for Speaker Verification",
    "abstract": "Parameter-Free Attentive Scoring for Speaker Verification",
    "descriptor": "",
    "authors": [
      "Jason Pelecanos",
      "Quan Wang",
      "Yiling Huang",
      "Ignacio Lopez Moreno"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.05642"
  },
  {
    "id": "arXiv:2203.06856",
    "title": "ACID: Action-Conditional Implicit Visual Dynamics for Deformable Object  Manipulation",
    "abstract": "ACID: Action-Conditional Implicit Visual Dynamics for Deformable Object  Manipulation",
    "descriptor": "",
    "authors": [
      "Bokui Shen",
      "Zhenyu Jiang",
      "Christopher Choy",
      "Leonidas J. Guibas",
      "Silvio Savarese",
      "Anima Anandkumar",
      "Yuke Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.06856"
  },
  {
    "id": "arXiv:2203.08021",
    "title": "Interpretable machine learning in Physics",
    "abstract": "Comments: Submitted version of invited Comment Article for Nature Reviews Physics (2022)",
    "descriptor": "\nComments: Submitted version of invited Comment Article for Nature Reviews Physics (2022)\n",
    "authors": [
      "Christophe Grojean",
      "Ayan Paul",
      "Zhuoni Qian",
      "Inga Str\u00fcmke"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08021"
  },
  {
    "id": "arXiv:2203.08958",
    "title": "On the Usefulness of the Fit-on-the-Test View on Evaluating Calibration  of Classifiers",
    "abstract": "On the Usefulness of the Fit-on-the-Test View on Evaluating Calibration  of Classifiers",
    "descriptor": "",
    "authors": [
      "Markus K\u00e4ngsepp",
      "Kaspar Valk",
      "Meelis Kull"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08958"
  },
  {
    "id": "arXiv:2203.09509",
    "title": "ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and  Implicit Hate Speech Detection",
    "abstract": "ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and  Implicit Hate Speech Detection",
    "descriptor": "",
    "authors": [
      "Thomas Hartvigsen",
      "Saadia Gabriel",
      "Hamid Palangi",
      "Maarten Sap",
      "Dipankar Ray",
      "Ece Kamar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.09509"
  },
  {
    "id": "arXiv:2203.09678",
    "title": "Self-Ensemble Adversarial Training for Improved Robustness",
    "abstract": "Comments: 18 pages, 3 figures, ICLR 2022",
    "descriptor": "\nComments: 18 pages, 3 figures, ICLR 2022\n",
    "authors": [
      "Hongjun Wang",
      "Yisen Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.09678"
  },
  {
    "id": "arXiv:2203.13238",
    "title": "Open-set Recognition via Augmentation-based Similarity Learning",
    "abstract": "Open-set Recognition via Augmentation-based Similarity Learning",
    "descriptor": "",
    "authors": [
      "Sepideh Esmaeilpour",
      "Lei Shu",
      "Bing Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.13238"
  },
  {
    "id": "arXiv:2203.13602",
    "title": "ZS4IE: A toolkit for Zero-Shot Information Extraction with simple  Verbalizations",
    "abstract": "Comments: Accepted at NAACL2022 Demo track",
    "descriptor": "\nComments: Accepted at NAACL2022 Demo track\n",
    "authors": [
      "Oscar Sainz",
      "Haoling Qiu",
      "Oier Lopez de Lacalle",
      "Eneko Agirre",
      "Bonan Min"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.13602"
  },
  {
    "id": "arXiv:2204.00408",
    "title": "Structured Pruning Learns Compact and Accurate Models",
    "abstract": "Comments: Accepted to ACL 2022; The code and models are available at this https URL",
    "descriptor": "\nComments: Accepted to ACL 2022; The code and models are available at this https URL\n",
    "authors": [
      "Mengzhou Xia",
      "Zexuan Zhong",
      "Danqi Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.00408"
  },
  {
    "id": "arXiv:2204.02246",
    "title": "Continuously Discovering Novel Strategies via Reward-Switching Policy  Optimization",
    "abstract": "Comments: 30 pages, 15 figures, published as a conference paper at ICLR 2022",
    "descriptor": "\nComments: 30 pages, 15 figures, published as a conference paper at ICLR 2022\n",
    "authors": [
      "Zihan Zhou",
      "Wei Fu",
      "Bingliang Zhang",
      "Yi Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02246"
  },
  {
    "id": "arXiv:2204.04391",
    "title": "MINER: Improving Out-of-Vocabulary Named Entity Recognition from an  Information Theoretic Perspective",
    "abstract": "Comments: Accepted as a long paper at ACL 2022",
    "descriptor": "\nComments: Accepted as a long paper at ACL 2022\n",
    "authors": [
      "Xiao Wang",
      "Shihan Dou",
      "Limao Xiong",
      "Yicheng Zou",
      "Qi Zhang",
      "Tao Gui",
      "Liang Qiao",
      "Zhanzhan Cheng",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.04391"
  },
  {
    "id": "arXiv:2204.04796",
    "title": "SOS! Self-supervised Learning Over Sets Of Handled Objects In Egocentric  Action Recognition",
    "abstract": "SOS! Self-supervised Learning Over Sets Of Handled Objects In Egocentric  Action Recognition",
    "descriptor": "",
    "authors": [
      "Victor Escorcia",
      "Ricardo Guerrero",
      "Xiatian Zhu",
      "Brais Martinez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04796"
  },
  {
    "id": "arXiv:2204.04902",
    "title": "NeuS: Neutral Multi-News Summarization for Mitigating Framing Bias",
    "abstract": "Comments: NAACL2022 Long Paper",
    "descriptor": "\nComments: NAACL2022 Long Paper\n",
    "authors": [
      "Nayeon Lee",
      "Yejin Bang",
      "Tiezheng Yu",
      "Andrea Madotto",
      "Pascale Fung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04902"
  },
  {
    "id": "arXiv:2204.04991",
    "title": "TRUE: Re-evaluating Factual Consistency Evaluation",
    "abstract": "Comments: Accepted as a long paper to NAACL 2022 main conference",
    "descriptor": "\nComments: Accepted as a long paper to NAACL 2022 main conference\n",
    "authors": [
      "Or Honovich",
      "Roee Aharoni",
      "Jonathan Herzig",
      "Hagai Taitelbaum",
      "Doron Kukliansy",
      "Vered Cohen",
      "Thomas Scialom",
      "Idan Szpektor",
      "Avinatan Hassidim",
      "Yossi Matias"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04991"
  },
  {
    "id": "arXiv:2204.05011",
    "title": "FederatedScope: A Flexible Federated Learning Platform for Heterogeneity",
    "abstract": "Comments: We have released FederatedScope for users on this https URL",
    "descriptor": "\nComments: We have released FederatedScope for users on this https URL\n",
    "authors": [
      "Yuexiang Xie",
      "Zhen Wang",
      "Daoyuan Chen",
      "Dawei Gao",
      "Liuyi Yao",
      "Weirui Kuang",
      "Yaliang Li",
      "Bolin Ding",
      "Jingren Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05011"
  },
  {
    "id": "arXiv:2204.05991",
    "title": "ReCLIP: A Strong Zero-Shot Baseline for Referring Expression  Comprehension",
    "abstract": "Comments: ACL 2022",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Sanjay Subramanian",
      "William Merrill",
      "Trevor Darrell",
      "Matt Gardner",
      "Sameer Singh",
      "Anna Rohrbach"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.05991"
  },
  {
    "id": "arXiv:2204.06175",
    "title": "Efficient Cluster-Based k-Nearest-Neighbor Machine Translation",
    "abstract": "Comments: 8 pages,6 figures, Accepted by ACL 2022 main conference",
    "descriptor": "\nComments: 8 pages,6 figures, Accepted by ACL 2022 main conference\n",
    "authors": [
      "Dexin Wang",
      "Kai Fan",
      "Boxing Chen",
      "Deyi Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.06175"
  },
  {
    "id": "arXiv:2204.06367",
    "title": "Mixed-Integer Programming for Signal Temporal Logic with Fewer Binary  Variables",
    "abstract": "Comments: Accepted to L-CSS",
    "descriptor": "\nComments: Accepted to L-CSS\n",
    "authors": [
      "Vince Kurtz",
      "Hai Lin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.06367"
  },
  {
    "id": "arXiv:2204.07316",
    "title": "XDBERT: Distilling Visual Information to BERT from Cross-Modal Systems  to Improve Language Understanding",
    "abstract": "Comments: ACL 2022",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Chan-Jan Hsu",
      "Hung-yi Lee",
      "Yu Tsao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07316"
  },
  {
    "id": "arXiv:2204.07497",
    "title": "Helicity-conservative Physics-informed Neural Network Model for  Navier-Stokes Equations",
    "abstract": "Comments: 17 pages, 9 figures, 3 tables",
    "descriptor": "\nComments: 17 pages, 9 figures, 3 tables\n",
    "authors": [
      "Jiwei Jia",
      "Young Ju Lee",
      "Ziqian Li",
      "Zheng Lu",
      "Ran Zhang"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.07497"
  },
  {
    "id": "arXiv:2204.08031",
    "title": "Limit theorems of Chatterjee's rank correlation",
    "abstract": "Comments: 40 pages; more references were added and discussed",
    "descriptor": "\nComments: 40 pages; more references were added and discussed\n",
    "authors": [
      "Zhexiao Lin",
      "Fang Han"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2204.08031"
  },
  {
    "id": "arXiv:2204.08331",
    "title": "Practical KMP/BM Style Pattern-Matching on Indeterminate Strings",
    "abstract": "Practical KMP/BM Style Pattern-Matching on Indeterminate Strings",
    "descriptor": "",
    "authors": [
      "Hossein Dehghani",
      "Neerja Mhaskar",
      "W. F. Smyth"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.08331"
  },
  {
    "id": "arXiv:2204.08535",
    "title": "Imagination-Augmented Natural Language Understanding",
    "abstract": "Comments: NAACL 2022 Main Conference",
    "descriptor": "\nComments: NAACL 2022 Main Conference\n",
    "authors": [
      "Yujie Lu",
      "Wanrong Zhu",
      "Xin Eric Wang",
      "Miguel Eckstein",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.08535"
  },
  {
    "id": "arXiv:2204.09183",
    "title": "Robustness Testing of Data and Knowledge Driven Anomaly Detection in  Cyber-Physical Systems",
    "abstract": "Comments: 8 pages, 10 figures, to appear in the 5th IEEE/IFIP DSN Workshop on Dependable and Secure Machine Learning (DSN-DSML)",
    "descriptor": "\nComments: 8 pages, 10 figures, to appear in the 5th IEEE/IFIP DSN Workshop on Dependable and Secure Machine Learning (DSN-DSML)\n",
    "authors": [
      "Xugui Zhou",
      "Maxfield Kouzel",
      "Homa Alemzadeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.09183"
  },
  {
    "id": "arXiv:2204.09526",
    "title": "Modeling Review History for Reviewer Recommendation:A Hypergraph  Approach",
    "abstract": "Modeling Review History for Reviewer Recommendation:A Hypergraph  Approach",
    "descriptor": "",
    "authors": [
      "Guoping Rong",
      "Yifan Zhang",
      "Lanxin Yang",
      "Fuli Zhang",
      "Hongyu Kuang",
      "He Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.09526"
  },
  {
    "id": "arXiv:2204.10281",
    "title": "How Conservative are Language Models? Adapting to the Introduction of  Gender-Neutral Pronouns",
    "abstract": "Comments: To appear at NAACL 2022",
    "descriptor": "\nComments: To appear at NAACL 2022\n",
    "authors": [
      "Stephanie Brandl",
      "Ruixiang Cui",
      "Anders S\u00f8gaard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.10281"
  },
  {
    "id": "arXiv:2204.11249",
    "title": "The Generalized Degrees-of-Freedom of the Asymmetric Interference  Channel with Delayed CSIT",
    "abstract": "Comments: Accepted by IEEE ISIT 2022",
    "descriptor": "\nComments: Accepted by IEEE ISIT 2022\n",
    "authors": [
      "Tong Zhang",
      "Yufan Zhuang",
      "Yinfei Xu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.11249"
  },
  {
    "id": "arXiv:2204.11270",
    "title": "Optimization-Based Ramping Reserve Allocation of BESS for AGC  Enhancement",
    "abstract": "Optimization-Based Ramping Reserve Allocation of BESS for AGC  Enhancement",
    "descriptor": "",
    "authors": [
      "Yiqiao Xu",
      "Alessandra Parisio",
      "Zhongguo Li",
      "Zhen Dong",
      "Zhengtao Ding"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.11270"
  },
  {
    "id": "arXiv:2204.11830",
    "title": "Proto2Proto: Can you recognize the car, the way I do?",
    "abstract": "Comments: To appear in CVPR 2022. Code is available at this https URL",
    "descriptor": "\nComments: To appear in CVPR 2022. Code is available at this https URL\n",
    "authors": [
      "Monish Keswani",
      "Sriranjani Ramakrishnan",
      "Nishant Reddy",
      "Vineeth N Balasubramanian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.11830"
  },
  {
    "id": "arXiv:2204.12010",
    "title": "Theoretical Understanding of the Information Flow on Continual Learning  Performance",
    "abstract": "Comments: 7 figures, 16 pages",
    "descriptor": "\nComments: 7 figures, 16 pages\n",
    "authors": [
      "Josh Andle",
      "Salimeh Yasaei Sekeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.12010"
  },
  {
    "id": "arXiv:2204.12371",
    "title": "Social learning spontaneously emerges by searching optimal heuristics  with deep reinforcement learning",
    "abstract": "Comments: Main manuscript : 11 pages, 6 figures. Supplementary information : 7 pages, 7 figures",
    "descriptor": "\nComments: Main manuscript : 11 pages, 6 figures. Supplementary information : 7 pages, 7 figures\n",
    "authors": [
      "Seungwoong Ha",
      "Hawoong Jeong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2204.12371"
  },
  {
    "id": "arXiv:2204.12376",
    "title": "Structural Rules and Algebraic Properties of Intersection Types",
    "abstract": "Comments: 29 pages, submitted to MFPS 22",
    "descriptor": "\nComments: 29 pages, submitted to MFPS 22\n",
    "authors": [
      "Sandra Alves",
      "M\u00e1rio Florido"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2204.12376"
  },
  {
    "id": "arXiv:2204.12425",
    "title": "Bioblox 2.5D -- Developing an Educational Game Based on Protein Docking",
    "abstract": "Comments: 9 pages",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Frederic Fol Leymarie",
      "William Latham",
      "Guido Salimbeni",
      "Suhail A. Islam",
      "Christopher Reynolds",
      "Charlie Cook",
      "Luis Armas Suarez",
      "Richard Leinfellner",
      "Michael J. E. Sternberg"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2204.12425"
  },
  {
    "id": "arXiv:2204.12562",
    "title": "On the Verification of Belief Programs",
    "abstract": "Comments: unpublished",
    "descriptor": "\nComments: unpublished\n",
    "authors": [
      "Daxin Liu",
      "Gerhard Lakemeyer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.12562"
  },
  {
    "id": "arXiv:2204.12721",
    "title": "Regularized Box-Simplex Games and Dynamic Decremental Bipartite Matching",
    "abstract": "Comments: Accepted at ICALP'22",
    "descriptor": "\nComments: Accepted at ICALP'22\n",
    "authors": [
      "Arun Jambulapati",
      "Yujia Jin",
      "Aaron Sidford",
      "Kevin Tian"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.12721"
  },
  {
    "id": "arXiv:2204.12798",
    "title": "Affine Frequency Division Multiplexing for Next Generation Wireless  Communications",
    "abstract": "Comments: Submitted to IEEE Transactions on Wireless Communications",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Ali Bemani",
      "Nassar Ksairi",
      "Marios Kountouris"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.12798"
  },
  {
    "id": "arXiv:2204.12834",
    "title": "Power Bundle Adjustment for Large-Scale 3D Reconstruction",
    "abstract": "Power Bundle Adjustment for Large-Scale 3D Reconstruction",
    "descriptor": "",
    "authors": [
      "Simon Weber",
      "Nikolaus Demmel",
      "Tin Chon Chan",
      "Daniel Cremers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.12834"
  },
  {
    "id": "arXiv:2204.13155",
    "title": "A Soft-Bodied Aerial Robot for Collision Resilience and Contact-Reactive  Perching",
    "abstract": "Comments: Submission under review, Soft Robotics Journal - Mary Ann Liebert Inc., Manuscript Details - 20 pages, 17 Figures, 2 Tables",
    "descriptor": "\nComments: Submission under review, Soft Robotics Journal - Mary Ann Liebert Inc., Manuscript Details - 20 pages, 17 Figures, 2 Tables\n",
    "authors": [
      "Pham H. Nguyen",
      "Karishma Patnaik",
      "Shatadal Mishra",
      "Panagiotis Polygerinos",
      "Wenlong Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.13155"
  },
  {
    "id": "arXiv:2204.13653",
    "title": "GRIT: General Robust Image Task Benchmark",
    "abstract": "GRIT: General Robust Image Task Benchmark",
    "descriptor": "",
    "authors": [
      "Tanmay Gupta",
      "Ryan Marten",
      "Aniruddha Kembhavi",
      "Derek Hoiem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.13653"
  },
  {
    "id": "arXiv:2204.13807",
    "title": "A very preliminary analysis of DALL-E 2",
    "abstract": "A very preliminary analysis of DALL-E 2",
    "descriptor": "",
    "authors": [
      "Gary Marcus",
      "Ernest Davis",
      "Scott Aaronson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.13807"
  },
  {
    "id": "arXiv:2204.14154",
    "title": "Outage Performance of Uplink Rate Splitting Multiple Access with  Randomly Deployed Users",
    "abstract": "Comments: 38 pages,9 figures",
    "descriptor": "\nComments: 38 pages,9 figures\n",
    "authors": [
      "Huabing Lu",
      "Xianzhong Xie",
      "Zhaoyuan Shi",
      "Hongjian Lei",
      "Nan Zhao",
      "Jun Cai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.14154"
  },
  {
    "id": "arXiv:2204.14223",
    "title": "Dataset of Multi-aspect Integrated Migration Indicators",
    "abstract": "Comments: 23 pages, 19 figures, corrections on typos and references",
    "descriptor": "\nComments: 23 pages, 19 figures, corrections on typos and references\n",
    "authors": [
      "D. Goglia",
      "L. Pollacci",
      "A. Sirbu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.14223"
  },
  {
    "id": "arXiv:2205.00119",
    "title": "MiCS: Near-linear Scaling for Training Gigantic Model on Public Cloud",
    "abstract": "MiCS: Near-linear Scaling for Training Gigantic Model on Public Cloud",
    "descriptor": "",
    "authors": [
      "Zhen Zhang",
      "Shuai Zheng",
      "Yida Wang",
      "Justin Chiu",
      "George Karypis",
      "Trishul Chilimbi",
      "Mu Li",
      "Xin Jin"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.00119"
  },
  {
    "id": "arXiv:2205.00291",
    "title": "Learning Mixed Strategies in Trajectory Games",
    "abstract": "Learning Mixed Strategies in Trajectory Games",
    "descriptor": "",
    "authors": [
      "Lasse Peters",
      "David Fridovich-Keil",
      "Laura Ferranti",
      "Cyrill Stachniss",
      "Javier Alonso-Mora",
      "Forrest Laine"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.00291"
  },
  {
    "id": "arXiv:2205.00312",
    "title": "Source Domain Subset Sampling for Semi-Supervised Domain Adaptation in  Semantic Segmentation",
    "abstract": "Comments: 10pages, 4figures",
    "descriptor": "\nComments: 10pages, 4figures\n",
    "authors": [
      "Daehan Kim",
      "Minseok Seo",
      "Jinsun Park",
      "Dong-Geol Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.00312"
  },
  {
    "id": "arXiv:2205.00344",
    "title": "Opponent Modeling in Negotiation Dialogues by Related Data Adaptation",
    "abstract": "Comments: Appearing at Findings of NAACL 2022",
    "descriptor": "\nComments: Appearing at Findings of NAACL 2022\n",
    "authors": [
      "Kushal Chawla",
      "Gale M. Lucas",
      "Jonathan May",
      "Jonathan Gratch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.00344"
  },
  {
    "id": "arXiv:2205.00371",
    "title": "The Johnson-Lindenstrauss Lemma for Clustering and Subspace  Approximation: From Coresets to Dimension Reduction",
    "abstract": "The Johnson-Lindenstrauss Lemma for Clustering and Subspace  Approximation: From Coresets to Dimension Reduction",
    "descriptor": "",
    "authors": [
      "Moses Charikar",
      "Erik Waingarten"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.00371"
  },
  {
    "id": "arXiv:2205.00379",
    "title": "The Cross-lingual Conversation Summarization Challenge",
    "abstract": "The Cross-lingual Conversation Summarization Challenge",
    "descriptor": "",
    "authors": [
      "Yulong Chen",
      "Ming Zhong",
      "Xuefeng Bai",
      "Naihao Deng",
      "Jing Li",
      "Xianchao Zhu",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.00379"
  },
  {
    "id": "arXiv:2205.00423",
    "title": "UTC: A Unified Transformer with Inter-Task Contrastive Learning for  Visual Dialog",
    "abstract": "Comments: Accepted in CVPR 2022",
    "descriptor": "\nComments: Accepted in CVPR 2022\n",
    "authors": [
      "Cheng Chen",
      "Yudong Zhu",
      "Zhenshan Tan",
      "Qingrong Cheng",
      "Xin Jiang",
      "Qun Liu",
      "Xiaodong Gu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.00423"
  },
  {
    "id": "arXiv:2205.00451",
    "title": "The Ludii Game Description Language is Universal",
    "abstract": "The Ludii Game Description Language is Universal",
    "descriptor": "",
    "authors": [
      "Dennis J. N. J. Soemers",
      "\u00c9ric Piette",
      "Matthew Stephenson",
      "Cameron Browne"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2205.00451"
  },
  {
    "id": "arXiv:2205.00476",
    "title": "None Class Ranking Loss for Document-Level Relation Extraction",
    "abstract": "Comments: Accepted by IJCAI 2022. Code available at this https URL",
    "descriptor": "\nComments: Accepted by IJCAI 2022. Code available at this https URL\n",
    "authors": [
      "Yang Zhou",
      "Wee Sun Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.00476"
  },
  {
    "id": "arXiv:2205.00551",
    "title": "Gender Bias in Masked Language Models for Multiple Languages",
    "abstract": "Comments: NAACL 2022",
    "descriptor": "\nComments: NAACL 2022\n",
    "authors": [
      "Masahiro Kaneko",
      "Aizhan Imankulova",
      "Danushka Bollegala",
      "Naoaki Okazaki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.00551"
  },
  {
    "id": "arXiv:2205.00615",
    "title": "Quantum Key Infrastructure: A scalable quantum-proof key distribution  system",
    "abstract": "Comments: 11 pages, 6 figures",
    "descriptor": "\nComments: 11 pages, 6 figures\n",
    "authors": [
      "Hoi-Kwong Lo",
      "Mattia Montagna",
      "Manfred von Willich"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.00615"
  },
  {
    "id": "arXiv:2205.00680",
    "title": "Functions as Processes: The Case of Collapsing Non-determinism",
    "abstract": "Functions as Processes: The Case of Collapsing Non-determinism",
    "descriptor": "",
    "authors": [
      "Bas van den Heuvel",
      "Joseph W. N. Paulus",
      "Daniele Nantes-Sobrinho",
      "Jorge A. P\u00e9rez"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.00680"
  },
  {
    "id": "arXiv:2205.00692",
    "title": "Energy-efficient Caching and Task offloading for Timely Status Updates  in UAV-assisted VANETs",
    "abstract": "Energy-efficient Caching and Task offloading for Timely Status Updates  in UAV-assisted VANETs",
    "descriptor": "",
    "authors": [
      "Nan Hu",
      "Xiaoqi Qin",
      "Nan Ma",
      "Yiming Liu",
      "Yuanyuan Yao",
      "Ping Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.00692"
  },
  {
    "id": "arXiv:2205.00701",
    "title": "DeepGraviLens: a Multi-Modal Architecture for Classifying Gravitational  Lensing Data",
    "abstract": "DeepGraviLens: a Multi-Modal Architecture for Classifying Gravitational  Lensing Data",
    "descriptor": "",
    "authors": [
      "Nicol\u00f2 Oreste Pinciroli Vago",
      "Piero Fraternali"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "General Relativity and Quantum Cosmology (gr-qc)"
    ],
    "url": "https://arxiv.org/abs/2205.00701"
  },
  {
    "id": "arXiv:2205.00718",
    "title": "What a Publication Tells You -- Benefits of Narrative Information Access  in Digital Libraries",
    "abstract": "Comments: Accepted at JCDL2022, 8 pages, 1 figure",
    "descriptor": "\nComments: Accepted at JCDL2022, 8 pages, 1 figure\n",
    "authors": [
      "Hermann Kroll",
      "Florian Pl\u00f6tzky",
      "Jan Pirklbauer",
      "Wolf-Tilo Balke"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2205.00718"
  },
  {
    "id": "arXiv:2205.00755",
    "title": "How does a spontaneously speaking conversational agent affect user  behavior?",
    "abstract": "Comments: Updated: Added the ethics statement. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: Updated: Added the ethics statement. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Takahisa Iizuka",
      "Hiroki Mori"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.00755"
  },
  {
    "id": "arXiv:2205.00756",
    "title": "VICE: Variational Inference for Concept Embeddings",
    "abstract": "VICE: Variational Inference for Concept Embeddings",
    "descriptor": "",
    "authors": [
      "Lukas Muttenthaler",
      "Charles Y. Zheng",
      "Patrick McClure",
      "Robert A. Vandermeulen",
      "Martin N. Hebart",
      "Francisco Pereira"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.00756"
  },
  {
    "id": "arXiv:2205.00771",
    "title": "Local Differential Privacy Meets Computational Social Choice --  Resilience under Voter Deletion",
    "abstract": "Local Differential Privacy Meets Computational Social Choice --  Resilience under Voter Deletion",
    "descriptor": "",
    "authors": [
      "Liangde Tao",
      "Lin Chen",
      "Lei Xu",
      "Weidong Shi"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.00771"
  },
  {
    "id": "arXiv:2205.00922",
    "title": "ARK: Fully Homomorphic Encryption Accelerator with Runtime Data  Generation and Inter-Operation Key Reuse",
    "abstract": "Comments: 14 pages, 8 figures",
    "descriptor": "\nComments: 14 pages, 8 figures\n",
    "authors": [
      "Jongmin Kim",
      "Gwangho Lee",
      "Sangpyo Kim",
      "Gina Sohn",
      "John Kim",
      "Minsoo Rhu",
      "Jung Ho Ahn"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2205.00922"
  },
  {
    "id": "arXiv:2205.00931",
    "title": "Creative Uses of AI Systems and their Explanations: A Case Study from  Insurance",
    "abstract": "Comments: Accepted at the ACM CHI 2022 Workshop on Human-Centered Explainable AI (HCXAI)",
    "descriptor": "\nComments: Accepted at the ACM CHI 2022 Workshop on Human-Centered Explainable AI (HCXAI)\n",
    "authors": [
      "Michaela Benk",
      "Raphael Weibel",
      "Andrea Ferrario"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.00931"
  },
  {
    "id": "arXiv:2205.00943",
    "title": "CCLF: A Contrastive-Curiosity-Driven Learning Framework for  Sample-Efficient Reinforcement Learning",
    "abstract": "Comments: Full paper with supplementary material, accepted by IJCAI 2022. Acknowledgements and affiliations are updated",
    "descriptor": "\nComments: Full paper with supplementary material, accepted by IJCAI 2022. Acknowledgements and affiliations are updated\n",
    "authors": [
      "Chenyu Sun",
      "Hangwei Qian",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.00943"
  },
  {
    "id": "arXiv:2205.00980",
    "title": "Multi-dimensional parameter-space partitioning of spatio-temporal  simulation ensembles",
    "abstract": "Comments: 14 pages, 9 figures",
    "descriptor": "\nComments: 14 pages, 9 figures\n",
    "authors": [
      "Marina Evers",
      "Lars Linsen"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.00980"
  },
  {
    "id": "arXiv:2205.01005",
    "title": "What Factors Should Paper-Reviewer Assignments Rely On? Community  Perspectives on Issues and Ideals in Conference Peer-Review",
    "abstract": "Comments: NAACL 2022 camera-ready Replacement note: formatting mistake on pages 4-5",
    "descriptor": "\nComments: NAACL 2022 camera-ready Replacement note: formatting mistake on pages 4-5\n",
    "authors": [
      "Terne Sasha Thorn Jakobsen",
      "Anna Rogers"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01005"
  },
  {
    "id": "arXiv:2205.01041",
    "title": "The Chaotic State of UK Drone Regulation",
    "abstract": "The Chaotic State of UK Drone Regulation",
    "descriptor": "",
    "authors": [
      "Scott McLachlan",
      "Kudakwashe Dube",
      "Burkhard Schafer",
      "Norman Fenton"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.01041"
  },
  {
    "id": "arXiv:2205.01045",
    "title": "Geo-located data for better dynamic replication",
    "abstract": "Comments: 9 pages, 4 figures and 3 listings",
    "descriptor": "\nComments: 9 pages, 4 figures and 3 listings\n",
    "authors": [
      "Lu\u00eds M. Silva",
      "Frederico Aleixo",
      "Albert van der Linde",
      "Jo\u00e3o Leit\u00e3o",
      "Nuno Pregui\u00e7a"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.01045"
  },
  {
    "id": "arXiv:2205.01054",
    "title": "A Change Dynamic Model for the Online Detection of Gradual Change",
    "abstract": "A Change Dynamic Model for the Online Detection of Gradual Change",
    "descriptor": "",
    "authors": [
      "Chris Browne"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2205.01054"
  },
  {
    "id": "arXiv:2205.01066",
    "title": "Quantifying Health Inequalities Induced by Data and AI Models",
    "abstract": "Comments: Accepted by IJCAI-ECAI 2022 AI for Good track",
    "descriptor": "\nComments: Accepted by IJCAI-ECAI 2022 AI for Good track\n",
    "authors": [
      "Honghan Wu",
      "Minhong Wang",
      "Aneeta Sylolypavan",
      "Sarah Wild"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01066"
  },
  {
    "id": "arXiv:2205.01068",
    "title": "OPT: Open Pre-trained Transformer Language Models",
    "abstract": "OPT: Open Pre-trained Transformer Language Models",
    "descriptor": "",
    "authors": [
      "Susan Zhang",
      "Stephen Roller",
      "Naman Goyal",
      "Mikel Artetxe",
      "Moya Chen",
      "Shuohui Chen",
      "Christopher Dewan",
      "Mona Diab",
      "Xian Li",
      "Xi Victoria Lin",
      "Todor Mihaylov",
      "Myle Ott",
      "Sam Shleifer",
      "Kurt Shuster",
      "Daniel Simig",
      "Punit Singh Koura",
      "Anjali Sridhar",
      "Tianlu Wang",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01068"
  }
]
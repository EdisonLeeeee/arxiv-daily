[
  {
    "id": "arXiv:2205.05077",
    "title": "Unconditional Stability Of A Two-Step Fourth-Order Modified Explicit  Euler/Crank-Nicolson Approach For Solving Time-Variable Fractional  Mobile-Immobile Advection-Dispersion Equation",
    "abstract": "This paper considers a two-step fourth-order modified explicit\nEuler/Crank-Nicolson numerical method for solving the time-variable fractional\nmobile-immobile advection-dispersion model subjects to suitable initial and\nboundary conditions. Both stability and error estimates of the new approach are\ndeeply analyzed in the $L^{\\infty}(0,T;L^{2})$-norm. The theoretical studies\nshow that the proposed technique is unconditionally stable with convergence of\norder $O(k+h^{4})$, where $h$ and $k$ are space step and time step,\nrespectively. This result indicate that the two-step fourth-order formulation\nis more efficient than a broad range of numerical schemes widely studied in the\nliterature for the considered problem. Numerical experiments are performed to\nverify the unconditional stability and convergence rate of the developed\nalgorithm.",
    "descriptor": "\nComments: 28 pages, 16 figures, 4 tables\n",
    "authors": [
      "Eric Ngondiep"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.05077"
  },
  {
    "id": "arXiv:2205.05078",
    "title": "Modeling Operational Fairness of Hybrid Cloud Brokerage",
    "abstract": "Cloud service brokerage is an emerging technology that attempts to simplify\nthe consumption and operation of hybrid clouds. Today's cloud brokers attempt\nto insulate consumers from the vagaries of multiple clouds. To achieve the\ninsulation, the modern cloud broker needs to disguise itself as the\nend-provider to consumers by creating and operating a virtual data center\nconstruct that we call a meta-cloud, which is assembled on top of a set of\nparticipating supplier clouds. It is crucial for such a cloud broker to be\nconsidered a trusted partner both by cloud consumers and by the underpinning\ncloud suppliers. A fundamental tenet of brokerage trust is vendor neutrality.\nOn the one hand, cloud consumers will be comfortable if a cloud broker\nguarantees that they will not be led through a preferred path. And on the other\nhand, cloud suppliers would be more interested in partnering with a cloud\nbroker who promises a fair apportioning of client provisioning requests.\nBecause consumer and supplier trust on a meta-cloud broker stems from the\nassumption of being agnostic to supplier clouds, there is a need for a test\nstrategy that verifies the fairness of cloud brokerage. In this paper, we\npropose a calculus of fairness that defines the rules to determine the\noperational behavior of a cloud broker. The calculus uses temporal logic to\nmodel the fact that fairness is a trait that has to be ascertained over time;\nit is not a characteristic that can be judged at a per-request fulfillment\nlevel. Using our temporal calculus of fairness as the basis, we propose an\nalgorithm to determine the fairness of a broker probabilistically, based on its\nobserved request apportioning policies. Our model for the fairness of cloud\nbroker behavior also factors in inter-provider variables such as cost\ndivergence and capacity variance.",
    "descriptor": "\nComments: This paper appears in the Proceedings of the 18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID 2018)\n",
    "authors": [
      "Sreekrishnan Venkateswaran",
      "Santonu Sarkar"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.05078"
  },
  {
    "id": "arXiv:2205.05092",
    "title": "Problems with Cosine as a Measure of Embedding Similarity for High  Frequency Words",
    "abstract": "Cosine similarity of contextual embeddings is used in many NLP tasks (e.g.,\nQA, IR, MT) and metrics (e.g., BERTScore). Here, we uncover systematic ways in\nwhich word similarities estimated by cosine over BERT embeddings are\nunderstated and trace this effect to training data frequency. We find that\nrelative to human judgements, cosine similarity underestimates the similarity\nof frequent words with other instances of the same word or other words across\ncontexts, even after controlling for polysemy and other factors. We conjecture\nthat this underestimation of similarity for high frequency words is due to\ndifferences in the representational geometry of high and low frequency words\nand provide a formal argument for the two-dimensional case.",
    "descriptor": "\nComments: Camera Ready for ACL 2022 (Main Conference)\n",
    "authors": [
      "Kaitlyn Zhou",
      "Kawin Ethayarajh",
      "Dallas Card",
      "Dan Jurafsky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.05092"
  },
  {
    "id": "arXiv:2205.05093",
    "title": "Richer Countries and Richer Representations",
    "abstract": "We examine whether some countries are more richly represented in embedding\nspace than others. We find that countries whose names occur with low frequency\nin training corpora are more likely to be tokenized into subwords, are less\nsemantically distinct in embedding space, and are less likely to be correctly\npredicted: e.g., Ghana (the correct answer and in-vocabulary) is not predicted\nfor, \"The country producing the most cocoa is [MASK].\". Although these\nperformance discrepancies and representational harms are due to frequency, we\nfind that frequency is highly correlated with a country's GDP; thus\nperpetuating historic power and wealth inequalities. We analyze the\neffectiveness of mitigation strategies; recommend that researchers report\ntraining word frequencies; and recommend future work for the community to\ndefine and design representational guarantees.",
    "descriptor": "\nComments: Camera Ready for ACL 2022 (Findings)\n",
    "authors": [
      "Kaitlyn Zhou",
      "Kawin Ethayarajh",
      "Dan Jurafsky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.05093"
  },
  {
    "id": "arXiv:2205.05095",
    "title": "Design and Implementation of a Secure RISC-V Microprocessor",
    "abstract": "Secret keys can be extracted from the power consumption or electromagnetic\nemanations of unprotected devices. Traditional counter-measures have limited\nscope of protection, and impose several restrictions on how sensitive data must\nbe manipulated. We demonstrate a bit-serial RISC-V microprocessor\nimplementation with no plain-text data. All values are protected using Boolean\nmasking. Software can run with little to no counter-measures, reducing code\nsize and performance overheads. Unlike previous literature, our methodology is\nfully automated and can be applied to designs of arbitrary size or complexity.\nWe also provide details on other key components such as clock randomizer,\nmemory protection, and random number generator. The microprocessor was\nimplemented in 65 nm CMOS technology. Its implementation was evaluated using\nNIST tests as well as side channel attacks. Random numbers generated with our\nRNG pass on all NIST tests. Side-channel analysis on the baseline\nimplementation extracted the AES key using only 375 traces, while our secure\nmicroprocessor was able to withstand attacks using 20 M traces.",
    "descriptor": "\nComments: Submitted to IEEE for possible publication. Copyright may be transferred. This version may no longer be accessible\n",
    "authors": [
      "Kleber Stangherlin",
      "Manoj Sachdev"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.05095"
  },
  {
    "id": "arXiv:2205.05109",
    "title": "Data-driven Tensor Train Gradient Cross Approximation for  Hamilton-Jacobi-Bellman Equations",
    "abstract": "A gradient-enhanced functional tensor train cross approximation method for\nthe resolution of the Hamilton-Jacobi-Bellman (HJB) equations associated to\noptimal feedback control of nonlinear dynamics is presented. The procedure uses\nsamples of both the solution of the HJB equation and its gradient to obtain a\ntensor train approximation of the value function. The collection of the data\nfor the algorithm is based on two possible techniques: Pontryagin Maximum\nPrinciple and State Dependent Riccati Equations. Several numerical tests are\npresented in low and high dimension showing the effectiveness of the proposed\nmethod and its robustness with respect to inexact data evaluations, provided by\nthe gradient information. The resulting tensor train approximation paves the\nway towards fast synthesis of the control signal in real-time applications.",
    "descriptor": "",
    "authors": [
      "Sergey Dolgov",
      "Dante Kalise",
      "Luca Saluzzi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.05109"
  },
  {
    "id": "arXiv:2205.05114",
    "title": "Vibration-Based Bridge Health Monitoring using Telecommunication Cables",
    "abstract": "Bridge Health Monitoring (BHM) enables early damage detection of bridges and\nis thus critical for avoiding more severe damages that might result in major\nfinancial and human losses. However, conventional BHM systems require dedicated\nsensors on bridges, which is costly to install and maintain and hard to scale\nup. To overcome this challenge, we introduce a new system that uses existing\ntelecommunication cables for Distributed Acoustic Sensing (DAS) to collect\nbridge dynamic strain responses. In addition, we develop a two-module\nphysics-guided system identification method to extract bridge damage-sensitive\ninformation (e.g., natural frequencies and mode shapes) from noisy DAS data by\nconstraining strain and displacement mode shapes by bridge dynamics. This\napproach does not require installation and maintenance of dedicated sensors on\nbridges. We evaluate our system with field experiments on a concrete bridge\nwith fiber cable running in a conduit under the deck. Our system successfully\nidentified modal frequencies and reconstructed meter-scale mode shapes.",
    "descriptor": "",
    "authors": [
      "Jingxiao Liu",
      "Siyuan Yuan",
      "Bin Luo",
      "Biondo Biondi",
      "Hae Young Noh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.05114"
  },
  {
    "id": "arXiv:2205.05119",
    "title": "Robust Data-Driven Output Feedback Control via Bootstrapped  Multiplicative Noise",
    "abstract": "We propose a robust data-driven output feedback control algorithm that\nexplicitly incorporates inherent finite-sample model estimate uncertainties\ninto the control design. The algorithm has three components: (1) a subspace\nidentification nominal model estimator; (2) a bootstrap resampling method that\nquantifies non-asymptotic variance of the nominal model estimate; and (3) a\nnon-conventional robust control design method comprising a coupled optimal\ndynamic output feedback filter and controller with multiplicative noise. A key\nadvantage of the proposed approach is that the system identification and robust\ncontrol design procedures both use stochastic uncertainty representations, so\nthat the actual inherent statistical estimation uncertainty directly aligns\nwith the uncertainty the robust controller is being designed against. Moreover,\nthe control design method accommodates a highly structured uncertainty\nrepresentation that can capture uncertainty shape more effectively than\nexisting approaches. We show through numerical experiments that the proposed\nrobust data-driven output feedback controller can significantly outperform a\ncertainty equivalent controller on various measures of sample complexity and\nstability robustness.",
    "descriptor": "",
    "authors": [
      "Benjamin Gravell",
      "Iman Shames",
      "Tyler Summers"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.05119"
  },
  {
    "id": "arXiv:2205.05121",
    "title": "Detecting Phishing sites Without Visiting them",
    "abstract": "Now-a-days, cyberattacks are increasing at an unprecedented rate. Phishing is\na social engineering attack which has a massive global impact, destroying the\nfinancial and economic value of corporations, government sectors and\nindividuals. In phishing, attackers steal users personal information such as\nusername, passwords, debit card information and so on. In order to detect\nzero-hour attacks and protect end-users from these attacks, various\nanti-phishing techniques are developed, but the end-users have to visit the\nwebsites to know whether they are safe or not, which may lead to infecting\ntheir system. In this paper, we propose a method where end-users can detect the\ngenuineness of the sites without visiting them. The proposed method collects\nlegitimate and phishing URLs and extract features from them. The extracted\nfeatures are given as input to six different classifiers for training and\nconstructing the model. The classifiers used are Naive-Bayes, Logistic\nRegression, Random Forest,CatBoost, XGBoost and Multilayer perceptron. The\nmethod is tested by developing into an extension so that the end-users can use\nit when browsing. In the browser extension when the user takes the cursor over\nany link, a pop-up appears showing the nature of the website i.e., safe site or\ndeceptive site and then a confirm box shows up asking the user whether they\nwant to visit or not. The performance of the approach is tested using a dataset\nconsisting of 2000 phishing and legitimate website URLs and the method is able\nto detect the sites correctly in very little time. Random-Forest is chosen for\nconstructing the model as it gives the highest accuracy of 95%.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2009.11116, arXiv:2103.12739 by other authors\n",
    "authors": [
      "Kalaharsha Pagadala"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.05121"
  },
  {
    "id": "arXiv:2205.05122",
    "title": "Multichannel Optimal Tree-Decodable Codes are Not Always Optimal Prefix  Codes",
    "abstract": "The theory of multichannel prefix codes aims to generalize the classical\ntheory of prefix codes. Although single- and two-channel prefix codes always\nhave decoding trees, the same cannot be said when there are more than two\nchannels. One question is of theoretical interest: Do there exist optimal\ntree-decodable codes that are not optimal prefix codes? Existing literature,\nwhich focused on generalizing single-channel results, covered little about\nnon-tree-decodable prefix codes since they have no single-channel counterparts.\nIn this work, we study the fundamental reason behind the non-tree-decodability\nof prefix codes. By investigating the simplest non-tree-decodable structure, we\nobtain a general sufficient condition on the channel alphabets for the\nexistence of optimal tree-decodable codes that are not optimal prefix codes.",
    "descriptor": "\nComments: Full version of the conference version in ISIT'22\n",
    "authors": [
      "Hoover H. F. Yin",
      "Harry W. H. Wong",
      "Mehrdad Tahernia",
      "Russell W. F. Lai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.05122"
  },
  {
    "id": "arXiv:2205.05124",
    "title": "Extracting Latent Steering Vectors from Pretrained Language Models",
    "abstract": "Prior work on controllable text generation has focused on learning how to\ncontrol language models through trainable decoding, smart-prompt design, or\nfine-tuning based on a desired objective. We hypothesize that the information\nneeded to steer the model to generate a target sentence is already encoded\nwithin the model. Accordingly, we explore a different approach altogether:\nextracting latent vectors directly from pretrained language model decoders\nwithout fine-tuning. Experiments show that there exist steering vectors, which,\nwhen added to the hidden states of the language model, generate a target\nsentence nearly perfectly (> 99 BLEU) for English sentences from a variety of\ndomains. We show that vector arithmetic can be used for unsupervised sentiment\ntransfer on the Yelp sentiment benchmark, with performance comparable to models\ntailored to this task. We find that distances between steering vectors reflect\nsentence similarity when evaluated on a textual similarity benchmark (STS-B),\noutperforming pooled hidden states of models. Finally, we present an analysis\nof the intrinsic properties of the steering vectors. Taken together, our\nresults suggest that frozen LMs can be effectively controlled through their\nlatent steering space.",
    "descriptor": "\nComments: Accepted to ACL2022 Findings; 16 pages (9 pages plus references and appendices); Code: this https URL; Some text overlap with arXiv:2008.09049\n",
    "authors": [
      "Nishant Subramani",
      "Nivedita Suresh",
      "Matthew E. Peters"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05124"
  },
  {
    "id": "arXiv:2205.05126",
    "title": "A Meta-Analysis on the Utility of Explainable Artificial Intelligence in  Human-AI Decision-Making",
    "abstract": "Research in Artificial Intelligence (AI)-assisted decision-making is\nexperiencing tremendous growth with a constantly rising number of studies\nevaluating the effect of AI with and without techniques from the field of\nexplainable AI (XAI) on human decision-making performance. However, as tasks\nand experimental setups vary due to different objectives, some studies report\nimproved user decision-making performance through XAI, while others report only\nnegligible effects. Therefore, in this article, we present an initial synthesis\nof existing research on XAI studies using a statistical meta-analysis to derive\nimplications across existing research. We observe a statistically positive\nimpact of XAI on users' performance. Additionally, first results might indicate\nthat human-AI decision-making yields better task performance on text data.\nHowever, we find no effect of explanations on users' performance compared to\nsole AI predictions. Our initial synthesis gives rise to future research to\ninvestigate the underlying causes as well as contribute to further development\nof algorithms that effectively benefit human decision-makers in the form of\nexplanations.",
    "descriptor": "\nComments: AAI/ACM Conference on AI, Ethics, and Society (AIES) 2022\n",
    "authors": [
      "Max Schemmer",
      "Patrick Hemmer",
      "Maximilian Nitsche",
      "Niklas K\u00fchl",
      "Michael V\u00f6ssing"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.05126"
  },
  {
    "id": "arXiv:2205.05128",
    "title": "Human Language Modeling",
    "abstract": "Natural language is generated by people, yet traditional language modeling\nviews words or documents as if generated independently. Here, we propose human\nlanguage modeling (HuLM), a hierarchical extension to the language modeling\nproblem whereby a human-level exists to connect sequences of documents (e.g.\nsocial media messages) and capture the notion that human language is moderated\nby changing human states. We introduce, HaRT, a large-scale transformer model\nfor the HuLM task, pre-trained on approximately 100,000 social media users, and\ndemonstrate its effectiveness in terms of both language modeling (perplexity)\nfor social media and fine-tuning for 4 downstream tasks spanning document- and\nuser-levels: stance detection, sentiment classification, age estimation, and\npersonality assessment. Results on all tasks meet or surpass the current\nstate-of-the-art.",
    "descriptor": "",
    "authors": [
      "Nikita Soni",
      "Matthew Matero",
      "Niranjan Balasubramanian",
      "H. Andrew Schwartz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05128"
  },
  {
    "id": "arXiv:2205.05131",
    "title": "Unifying Language Learning Paradigms",
    "abstract": "Existing pre-trained models are generally geared towards a particular class\nof problems. To date, there seems to be still no consensus on what the right\narchitecture and pre-training setup should be. This paper presents a unified\nframework for pre-training models that are universally effective across\ndatasets and setups. We begin by disentangling architectural archetypes with\npre-training objectives -- two concepts that are commonly conflated. Next, we\npresent a generalized and unified perspective for self-supervision in NLP and\nshow how different pre-training objectives can be cast as one another and how\ninterpolating between different objectives can be effective. We then propose\nMixture-of-Denoisers (MoD), a pre-training objective that combines diverse\npre-training paradigms together. We furthermore introduce a notion of mode\nswitching, wherein downstream fine-tuning is associated with specific\npre-training schemes. We conduct extensive ablative experiments to compare\nmultiple pre-training objectives and find that our method pushes the\nPareto-frontier by outperforming T5 and/or GPT-like models across multiple\ndiverse setups. Finally, by scaling our model up to 20B parameters, we achieve\nSOTA performance on 50 well-established supervised NLP tasks ranging from\nlanguage generation (with automated and human evaluation), language\nunderstanding, text classification, question answering, commonsense reasoning,\nlong text reasoning, structured knowledge grounding and information retrieval.\nOur model also achieve strong results at in-context learning, outperforming\n175B GPT-3 on zero-shot SuperGLUE and tripling the performance of T5-XXL on\none-shot summarization. We release Flax-based T5X model checkpoints for the 20B\nmodel at\n\\url{https://github.com/google-research/google-research/tree/master/ul2}.",
    "descriptor": "",
    "authors": [
      "Yi Tay",
      "Mostafa Dehghani",
      "Vinh Q. Tran",
      "Xavier Garcia",
      "Dara Bahri",
      "Tal Schuster",
      "Huaixiu Steven Zheng",
      "Neil Houlsby",
      "Donald Metzler"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.05131"
  },
  {
    "id": "arXiv:2205.05136",
    "title": "A matrix-free high-order solver for the numerical solution of cardiac  electrophysiology",
    "abstract": "We propose a matrix-free solver for the numerical solution of the cardiac\nelectrophysiology model consisting of the monodomain nonlinear\nreaction-diffusion equation coupled with a system of ordinary differential\nequations for the ionic species. Our numerical approximation is based on the\nhigh-order Spectral Element Method (SEM) to achieve accurate numerical\ndiscretization while employing a much smaller number of Degrees of Freedom than\nfirst-order Finite Elements. We combine sum-factorization with vectorization,\nthus allowing for a very efficient use of high-order polynomials in a high\nperformance computing framework. We validate the effectiveness of our\nmatrix-free solver in a variety of applications and perform different\nelectrophysiological simulations ranging from a simple slab of cardiac tissue\nto a realistic four-chamber heart geometry. We compare SEM to SEM with\nNumerical Integration (SEM-NI), showing that they provide comparable results in\nterms of accuracy and efficiency. In both cases, increasing the local\npolynomial degree $p$ leads to better numerical results and smaller\ncomputational times than reducing the mesh size $h$. We also implement a\nmatrix-free Geometric Multigrid preconditioner that entails better performance\nin terms of linear solver iterations than state-of-the-art matrix-based\nAlgebraic Multigrid preconditioners. As a matter of fact, the matrix-free\nsolver here proposed yields up to 50$\\times$ speed-up with respect to a\nconventional matrix-based solver.",
    "descriptor": "",
    "authors": [
      "Pasquale Claudio Africa",
      "Matteo Salvador",
      "Paola Gervasio",
      "Luca Dede'",
      "Alfio Quarteroni"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2205.05136"
  },
  {
    "id": "arXiv:2205.05137",
    "title": "Sibylvariant Transformations for Robust Text Classification",
    "abstract": "The vast majority of text transformation techniques in NLP are inherently\nlimited in their ability to expand input space coverage due to an implicit\nconstraint to preserve the original class label. In this work, we propose the\nnotion of sibylvariance (SIB) to describe the broader set of transforms that\nrelax the label-preserving constraint, knowably vary the expected class, and\nlead to significantly more diverse input distributions. We offer a unified\nframework to organize all data transformations, including two types of SIB: (1)\nTransmutations convert one discrete kind into another, (2) Mixture Mutations\nblend two or more classes together. To explore the role of sibylvariance within\nNLP, we implemented 41 text transformations, including several novel techniques\nlike Concept2Sentence and SentMix. Sibylvariance also enables a unique form of\nadaptive training that generates new input mixtures for the most confused class\npairs, challenging the learner to differentiate with greater nuance. Our\nexperiments on six benchmark datasets strongly support the efficacy of\nsibylvariance for generalization performance, defect detection, and adversarial\nrobustness.",
    "descriptor": "\nComments: 9 pages, Findings of ACL 2022\n",
    "authors": [
      "Fabrice Harel-Canada",
      "Muhammad Ali Gulzar",
      "Nanyun Peng",
      "Miryung Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05137"
  },
  {
    "id": "arXiv:2205.05138",
    "title": "Efficient Risk-Averse Reinforcement Learning",
    "abstract": "In risk-averse reinforcement learning (RL), the goal is to optimize some risk\nmeasure of the returns. A risk measure often focuses on the worst returns out\nof the agent's experience. As a result, standard methods for risk-averse RL\noften ignore high-return strategies. We prove that under certain conditions\nthis inevitably leads to a local-optimum barrier, and propose a soft risk\nmechanism to bypass it. We also devise a novel Cross Entropy module for risk\nsampling, which (1) preserves risk aversion despite the soft risk; (2)\nindependently improves sample efficiency. By separating the risk aversion of\nthe sampler and the optimizer, we can sample episodes with poor conditions, yet\noptimize with respect to successful strategies. We combine these two concepts\nin CeSoR - Cross-entropy Soft-Risk optimization algorithm - which can be\napplied on top of any risk-averse policy gradient (PG) method. We demonstrate\nimproved risk aversion in maze navigation, autonomous driving, and resource\nallocation benchmarks, including in scenarios where standard risk-averse PG\ncompletely fails.",
    "descriptor": "",
    "authors": [
      "Ido Greenberg",
      "Yinlam Chow",
      "Mohammad Ghavamzadeh",
      "Shie Mannor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05138"
  },
  {
    "id": "arXiv:2205.05140",
    "title": "RotorTM: A Flexible Simulator for Aerial Transportation and Manipulation",
    "abstract": "Low-cost autonomous Micro Aerial Vehicles (MAVs) have the potential to help\nhumans by simplifying and speeding up complex tasks that require their\ninteraction with the environment such as construction, package delivery, and\nsearch and rescue. These systems, composed of single or multiple vehicles, can\nbe endowed with passive connection mechanisms such as rigid links or cables to\nperform transportation and manipulation tasks. However, they are inherently\ncomplex since they are often underactuated, and evolve on nonlinear manifold\nconfiguration spaces. In addition, the complexity of systems with\ncable-suspended load is further increased by the hybrid dynamics depending on\nthe cables' varying tension conditions. In this paper, we present the first\naerial transportation and manipulation simulator incorporating different\npayloads and passive connection mechanisms with full system dynamics as well as\nplanning and control algorithms. Furthermore, it includes a novel model\naccounting for the transient hybrid dynamics for aerial systems with\ncable-suspended load to closely mimic real-world systems. The availability of a\nflexible and intuitive interface further contributes to its usability and\nversatility. Comparisons between simulations and real-world experiments with\ndifferent vehicles' configurations show the fidelity of the simulator results\nwith respect to real-world settings and its benefit for rapid prototyping and\ntransitioning of aerial transportation and manipulation systems to real-world\ndeployment.",
    "descriptor": "",
    "authors": [
      "Guanrui Li",
      "Xinyang Liu",
      "Giuseppe Loianno"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.05140"
  },
  {
    "id": "arXiv:2205.05150",
    "title": "Bounds on the Coupling Strengths of Communication Channels and Their  Information Capacities",
    "abstract": "The concept of optimal communication channels shapes our understanding of\nwave-based communication. Its analysis, however, always pertains to specific\ncommunication-domain geometries, without a general theory of scaling laws or\nfundamental limits. In this article, we derive shape-independent bounds on the\ncoupling strengths and information capacities of optimal communication channels\nfor any two domains that can be separated by a spherical surface. Previous\ncomputational experiments have always observed rapid, exponential decay of\ncoupling strengths, but our bounds predict a much slower, sub-exponential\noptimal decay, and specific source/receiver distributions that can achieve such\nperformance. Our bounds show that domain sizes and configurations, and not\ndomain shapes, are the keys to maximizing the number of non-trivial\ncommunication channels and total information capacities. Applicable to general\nwireless and optical communication systems, our bounds reveal fundamental\nlimits to what is possible through engineering the communication domains of\nelectromagnetic waves.",
    "descriptor": "",
    "authors": [
      "Zeyu Kuang",
      "David A. B. Miller",
      "Owen D. Miller"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2205.05150"
  },
  {
    "id": "arXiv:2205.05155",
    "title": "Few-Shot Image Classification Benchmarks are Too Far From Reality: Build  Back Better with Semantic Task Sampling",
    "abstract": "Every day, a new method is published to tackle Few-Shot Image Classification,\nshowing better and better performances on academic benchmarks. Nevertheless, we\nobserve that these current benchmarks do not accurately represent the real\nindustrial use cases that we encountered. In this work, through both\nqualitative and quantitative studies, we expose that the widely used benchmark\ntieredImageNet is strongly biased towards tasks composed of very semantically\ndissimilar classes e.g. bathtub, cabbage, pizza, schipperke, and cardoon. This\nmakes tieredImageNet (and similar benchmarks) irrelevant to evaluate the\nability of a model to solve real-life use cases usually involving more\nfine-grained classification. We mitigate this bias using semantic information\nabout the classes of tieredImageNet and generate an improved, balanced\nbenchmark. Going further, we also introduce a new benchmark for Few-Shot Image\nClassification using the Danish Fungi 2020 dataset. This benchmark proposes a\nwide variety of evaluation tasks with various fine-graininess. Moreover, this\nbenchmark includes many-way tasks (e.g. composed of 100 classes), which is a\nchallenging setting yet very common in industrial applications. Our experiments\nbring out the correlation between the difficulty of a task and the semantic\nsimilarity between its classes, as well as a heavy performance drop of\nstate-of-the-art methods on many-way few-shot classification, raising questions\nabout the scaling abilities of these methods. We hope that our work will\nencourage the community to further question the quality of standard evaluation\nprocesses and their relevance to real-life applications.",
    "descriptor": "\nComments: CVPR 2022 Workshop on Vision Datasets Understanding\n",
    "authors": [
      "Etienne Bennequin",
      "Myriam Tami",
      "Antoine Toubhans",
      "Celine Hudelot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.05155"
  },
  {
    "id": "arXiv:2205.05160",
    "title": "Improved long time accuracy for projection methods for Navier-Stokes  equations using EMAC formulation",
    "abstract": "We consider a pressure correction temporal discretization for the\nincompressible Navier-Stokes equations in EMAC form. We prove stability and\nerror estimates for the case of mixed finite element spatial discretization,\nand in particular that the Gronwall constant's exponential dependence on the\nReynolds number is removed (for sufficiently smooth true solutions) or at least\nsignificantly reduced compared to the commonly used skew-symmetric formulation.\nWe also show the method preserves momentum and angular momentum, and while it\ndoes not preserve energy it does admit an energy inequality. Several numerical\ntests show the advantages EMAC can have over other commonly used formulations\nof the nonlinearity. Additionally, we discuss extensions of the results to the\nusual Crank-Nicolson temporal discretization.",
    "descriptor": "",
    "authors": [
      "Sean Ingimarson",
      "Monika Neda",
      "Leo Rebholz",
      "Jorge Reyes",
      "An Vu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.05160"
  },
  {
    "id": "arXiv:2205.05161",
    "title": "Numerical Solution of the Savage-Hutter Equations for Granular Avalanche  Flow using the Discontinuous Galerkin Method",
    "abstract": "The Savage-Hutter (SH) equations are a hyperbolic system of nonlinear partial\ndifferential equations describing the temporal evolution of the depth and depth\naveraged velocity for modelling the avalanche of a shallow layer of granular\nmaterials on an inclined surface. These equations admit the occurrence of shock\nwaves and vacuum fronts as in the shallow-water equations while possessing the\nspecial reposing state of granular material. In this paper, we develop a\nthird-order Runge-Kutta discontinuous Galerkin (RKDG) method for the numerical\nsolution of the one-dimensional SH equations. We adopt a TVD slope limiter to\nsuppress numerical oscillations near discontinuities. And we give numerical\ntreatments for the avalanche front and for the bed friction to achieve the\nwell-balanced reposing property of granular materials. Numerical results of the\navalanche of cohesionless dry granular materials down an inclined and smoothly\ntransitioned to horizontal plane under various internal and bed friction angles\nand slope angles are given to show the performance of the present numerical\nscheme.",
    "descriptor": "\nComments: 28 pages, 9 figures\n",
    "authors": [
      "Abdullah Shah",
      "Muhammad Naveed Zafar",
      "Yulong Du",
      "Li Yuan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.05161"
  },
  {
    "id": "arXiv:2205.05166",
    "title": "Soft Robotic Mannequin: Design and Algorithm for Deformation Control",
    "abstract": "This paper presents a novel soft robotic system for a deformable mannequin\nthat can be employed to physically realize the 3D geometry of different human\nbodies. The soft membrane on a mannequin is deformed by inflating several\ncurved chambers using pneumatic actuation. Controlling the freeform surface of\na soft membrane by adjusting the pneumatic actuation in different chambers is\nchallenging as the membrane's shape is commonly determined by interaction\nbetween all chambers. Using vision feedback provided by a structured-light\nbased 3D scanner, we developed an efficient algorithm to compute the optimized\nactuation of all chambers which could drive the soft membrane to deform into\nthe best approximation of different target shapes. Our algorithm converges\nquickly by including the step of pose estimation in the loop of optimization,\nand the time-consuming step for evaluating derivatives on the deformable\nmembrane is avoided by using the Broyden update when possible. The\neffectiveness of our soft robotic mannequin with controlled deformation has\nbeen verified in experiments.",
    "descriptor": "",
    "authors": [
      "Yingjun Tian",
      "Guoxin Fang",
      "Justas Petrulis",
      "Andrew Weightman",
      "Charlie C.L. Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.05166"
  },
  {
    "id": "arXiv:2205.05167",
    "title": "Robustness of Humans and Machines on Object Recognition with Extreme  Image Transformations",
    "abstract": "Recent neural network architectures have claimed to explain data from the\nhuman visual cortex. Their demonstrated performance is however still limited by\nthe dependence on exploiting low-level features for solving visual tasks. This\nstrategy limits their performance in case of out-of-distribution/adversarial\ndata. Humans, meanwhile learn abstract concepts and are mostly unaffected by\neven extreme image distortions. Humans and networks employ strikingly different\nstrategies to solve visual tasks. To probe this, we introduce a novel set of\nimage transforms and evaluate humans and networks on an object recognition\ntask. We found performance for a few common networks quickly decreases while\nhumans are able to recognize objects with a high accuracy.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Dakarai Crowder",
      "Girik Malik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.05167"
  },
  {
    "id": "arXiv:2205.05168",
    "title": "Deep Graph Clustering via Mutual Information Maximization and Mixture  Model",
    "abstract": "Attributed graph clustering or community detection which learns to cluster\nthe nodes of a graph is a challenging task in graph analysis. In this paper, we\nintroduce a contrastive learning framework for learning clustering-friendly\nnode embedding. Although graph contrastive learning has shown outstanding\nperformance in self-supervised graph learning, using it for graph clustering is\nnot well explored. We propose Gaussian mixture information maximization (GMIM)\nwhich utilizes a mutual information maximization approach for node embedding.\nMeanwhile, it assumes that the representation space follows a Mixture of\nGaussians (MoG) distribution. The clustering part of our objective tries to fit\na Gaussian distribution to each community. The node embedding is jointly\noptimized with the parameters of MoG in a unified framework. Experiments on\nreal-world datasets demonstrate the effectiveness of our method in community\ndetection.",
    "descriptor": "",
    "authors": [
      "Maedeh Ahmadi",
      "Mehran Safayani",
      "Abdolreza Mirzaei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05168"
  },
  {
    "id": "arXiv:2205.05173",
    "title": "Self-Supervised Anomaly Detection: A Survey and Outlook",
    "abstract": "Over the past few years, anomaly detection, a subfield of machine learning\nthat is mainly concerned with the detection of rare events, witnessed an\nimmense improvement following the unprecedented growth of deep learning models.\nRecently, the emergence of self-supervised learning has sparked the development\nof new anomaly detection algorithms that surpassed state-of-the-art accuracy by\na significant margin. This paper aims to review the current approaches in\nself-supervised anomaly detection. We present technical details of the common\napproaches and discuss their strengths and drawbacks. We also compare the\nperformance of these models against each other and other state-of-the-art\nanomaly detection models. Finally, we discuss a variety of new directions for\nimproving the existing algorithms.",
    "descriptor": "\nComments: 18 pages, 4 figures, 4 tables\n",
    "authors": [
      "Hadi Hojjati",
      "Thi Kieu Khanh Ho",
      "Narges Armanfard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05173"
  },
  {
    "id": "arXiv:2205.05177",
    "title": "ConfLab: A Rich Multimodal Multisensor Dataset of Free-Standing Social  Interactions In-the-Wild",
    "abstract": "We describe an instantiation of a new concept for multimodal multisensor data\ncollection of real life in-the-wild free standing social interactions in the\nform of a Conference Living Lab (ConfLab). ConfLab contains high fidelity data\nof 49 people during a real-life professional networking event capturing a\ndiverse mix of status, acquaintanceship, and networking motivations at an\ninternational conference. Recording such a dataset is challenging due to the\ndelicate trade-off between participant privacy and fidelity of the data, and\nthe technical and logistic challenges involved. We improve upon prior datasets\nin the fidelity of most of our modalities: 8-camera overhead setup, personal\nwearable sensors recording body motion (9-axis IMU), Bluetooth-based proximity,\nand low-frequency audio. Additionally, we use a state-of-the-art hardware\nsynchronization solution and time-efficient continuous technique for annotating\nbody keypoints and actions at high frequencies. We argue that our improvements\nare essential for a deeper study of interaction dynamics at finer time scales.\nOur research tasks showcase some of the open challenges related to in-the-wild\nprivacy-preserving social data analysis: keypoints detection from overhead\ncamera views, skeleton based no-audio speaker detection, and F-formation\ndetection. With the ConfLab dataset, we aim to bridge the gap between\ntraditional computer vision tasks and in-the-wild ecologically valid\nsocially-motivated tasks.",
    "descriptor": "",
    "authors": [
      "Chirag Raman",
      "Jose Vargas-Quiros",
      "Stephanie Tan",
      "Ekin Gedik",
      "Ashraful Islam",
      "Hayley Hung"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05177"
  },
  {
    "id": "arXiv:2205.05180",
    "title": "Massively Digitized Power Grid: Opportunities and Challenges of  Use-inspired AI",
    "abstract": "This article presents a use-inspired perspective of the opportunities and\nchallenges in a massively digitized power grid. It argues that the intricate\ninterplay of data availability, computing capability, and artificial\nintelligence (AI) algorithm development are the three key factors driving the\nadoption of digitized solutions in the power grid. The impact of these three\nfactors on critical functions of power system operation and planning practices\nare reviewed and illustrated with industrial practice case studies. Open\nchallenges and research opportunities for data, computing, and AI algorithms\nare articulated within the context of the power industry's tremendous\ndecarbonization efforts.",
    "descriptor": "",
    "authors": [
      "Le Xie",
      "Xiangtian Zheng",
      "Yannan Sun",
      "Tong Huang",
      "Tony Bruton"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.05180"
  },
  {
    "id": "arXiv:2205.05181",
    "title": "The Move Borrow Checker",
    "abstract": "The Move language provides abstractions for programming with digital assets\nvia a mix of value semantics and reference semantics. Ensuring memory safety in\nprograms with references that access a shared, mutable global ledger is\ndifficult, yet essential for the use-cases targeted by Move. The language meets\nthis challenge with a novel memory model and a modular, intraprocedural static\nreference safety analysis that leverages key properties of the memory. The\nanalysis ensures the absence of memory safety violations in all Move programs\n(including ones that link against untrusted code) by running as part of a\nload-time bytecode verification pass similar to the JVM [12] and CLR [15]. We\nformalize the static analysis and prove that it enjoys three desirable\nproperties: absence of dangling references, referential transparency for\nimmutable references, and absence of memory leaks.",
    "descriptor": "",
    "authors": [
      "Sam Blackshear",
      "John Mitchell",
      "Todd Nowacki",
      "Shaz Qadeer"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2205.05181"
  },
  {
    "id": "arXiv:2205.05182",
    "title": "A G\u00f6del Calculus for Linear Temporal Logic",
    "abstract": "We consider G\\\"odel temporal logic ($\\sf GTL$), a variant of linear temporal\nlogic based on G\\\"odel--Dummett propositional logic. In recent work, we have\nshown this logic to enjoy natural semantics both as a fuzzy logic and as a\nsuperintuitionistic logic. Using semantical methods, the logic was shown to be\n{\\sc pspace}-complete. In this paper we provide a deductive calculus for $\\sf\nGTL$, and show this calculus to be sound and complete for the above-mentioned\nsemantics.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2205.00574\n",
    "authors": [
      "Juan Pablo Aguilera",
      "Mart\u00edn Di\u00e9guez",
      "David Fern\u00e1ndez-Duque",
      "Brett McLean"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.05182"
  },
  {
    "id": "arXiv:2205.05183",
    "title": "All-to-All Encode in Synchronous Systems",
    "abstract": "We define all-to-all encode, a collective communication operation serving as\na primitive in decentralized computation and storage systems. Consider a\nscenario where every processor initially has a data packet and requires a\nlinear combination of all data packets; the linear combinations are distinct\nfrom one processor to another, and are specified by a generator matrix of an\nerror correcting code. We use a linear network model, in which processors\ntransmit linear combinations of their data and previously received packets, and\nadopt a standard synchronous system setting to analyze its communication cost.\nWe provide a universal algorithm which computes any matrix in this model by\nonly varying intermediate coefficients, and prove its optimality. When the\ngenerator matrix is of the Vandermonde or Lagrange type, we further optimize\nthe communication efficiency of the proposed algorithm.",
    "descriptor": "",
    "authors": [
      "Canran Wang",
      "Netanel Raviv"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.05183"
  },
  {
    "id": "arXiv:2205.05187",
    "title": "Multifidelity data fusion in convolutional encoder/decoder networks",
    "abstract": "We analyze the regression accuracy of convolutional neural networks assembled\nfrom encoders, decoders and skip connections and trained with multifidelity\ndata. Besides requiring significantly less trainable parameters than equivalent\nfully connected networks, encoder, decoder, encoder-decoder or decoder-encoder\narchitectures can learn the mapping between inputs to outputs of arbitrary\ndimensionality. We demonstrate their accuracy when trained on a few\nhigh-fidelity and many low-fidelity data generated from models ranging from\none-dimensional functions to Poisson equation solvers in two-dimensions. We\nfinally discuss a number of implementation choices that improve the reliability\nof the uncertainty estimates generated by Monte Carlo DropBlocks, and compare\nuncertainty estimates among low-, high- and multifidelity approaches.",
    "descriptor": "",
    "authors": [
      "Lauren Partin",
      "Gianluca Geraci",
      "Ahmad Rushdi",
      "Michael S. Eldred",
      "Daniele E. Schiavazzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05187"
  },
  {
    "id": "arXiv:2205.05188",
    "title": "On Scale Space Radon Transform, Properties and Image Reconstruction",
    "abstract": "Aware of the importance of the good behavior in the scale space that a\nmathematical transform must have, we depict, in this paper, the basic\nproperties and the inverse transform of the Scale Space Radon Transform (SSRT).\nTo reconstruct the image from SSRT sinogram, the Filtered backprojection (FBP)\ntechnique is used in two different ways: (1) Deconvolve SSRT to obtain the\nestimated Radon transform (RT) and then, reconstruct image using classical FBP\nor (2) Adapt FBP technique to SSRT so that the Radon projections spectrum used\nin classical FBP is replaced by SSRT and Wiener filtering, expressed in the\nfrequency domain. Comparison of image reconstruction techniques using SSRT and\nRT are performed on Shepp-Logan head phantom image. Using the Mean Absolute\nError (MAE) as image reconstruction quality measure, the preliminary results\npresent an outstanding performance for SSRT-based image reconstruction\ntechniques compared to the RT-based one. Furthermore, the method (2)\noutperforms the method (1) in terms of computation time and adaptability for\nhigh level of noise when fairly large Gaussian kernel is used.",
    "descriptor": "",
    "authors": [
      "Nafaa Nacereddine",
      "Djemel Ziou",
      "Aicha Baya Goumeidane"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.05188"
  },
  {
    "id": "arXiv:2205.05192",
    "title": "Social Inclusion in Curated Contexts: Insights from Museum Practices",
    "abstract": "Artificial intelligence literature suggests that minority and fragile\ncommunities in society can be negatively impacted by machine learning\nalgorithms due to inherent biases in the design process, which lead to socially\nexclusive decisions and policies. Faced with similar challenges in dealing with\nan increasingly diversified audience, the museum sector has seen changes in\ntheory and practice, particularly in the areas of representation and\nmeaning-making. While rarity and grandeur used to be at the centre stage of the\nearly museum practices, folk life and museums' relationships with the diverse\ncommunities they serve become a widely integrated part of the contemporary\npractices. These changes address issues of diversity and accessibility in order\nto offer more socially inclusive services. Drawing on these changes and\nreflecting back on the AI world, we argue that the museum experience provides\nuseful lessons for building AI with socially inclusive approaches, especially\nin situations in which both a collection and access to it will need to be\ncurated or filtered, as frequently happens in search engines, recommender\nsystems and digital libraries. We highlight three principles: (1) Instead of\nupholding the value of neutrality, practitioners are aware of the influences of\ntheir own backgrounds and those of others on their work. By not claiming to be\nneutral but practising cultural humility, the chances of addressing potential\nbiases can be increased. (2) There should be room for situational\ninterpretation beyond the stages of data collection and machine learning.\nBefore applying models and predictions, the contexts in which relevant parties\nexist should be taken into account. (3) Community participation serves the\nneeds of communities and has the added benefit of bringing practitioners and\ncommunities together.",
    "descriptor": "\nComments: in Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency (FAccT '22), June 21-24, 2022, Seoul, Republic of Korea\n",
    "authors": [
      "Han-Yin Huang",
      "Cynthia C. S. Liem"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.05192"
  },
  {
    "id": "arXiv:2205.05194",
    "title": "Student Collaboration Improves Self-Supervised Learning: Dual-Loss  Adaptive Masked Autoencoder for Brain Cell Image Analysis",
    "abstract": "Self-supervised learning leverages the underlying data structure as the\nsource of the supervisory signal without the need for human annotation effort.\nThis approach offers a practical solution to learning with a large amount of\nbiomedical data and limited annotation. Unlike other studies exploiting data\nvia multi-view (e.g., augmented images), this study presents a self-supervised\nDual-Loss Adaptive Masked Autoencoder (DAMA) algorithm established from the\nviewpoint of the information theory. Specifically, our objective function\nmaximizes the mutual information by minimizing the conditional entropy in\npixel-level reconstruction and feature-level regression. We further introduce\nan adaptive mask sampling strategy to maximize mutual information. We conduct\nextensive experiments on brain cell images to validate the proposed method.\nDAMA significantly outperforms both state-of-the-art self-supervised and\nsupervised methods on brain cells data and demonstrates competitive result on\nImageNet-1k. Code: https://github.com/hula-ai/DAMA",
    "descriptor": "\nComments: Pytorch code: this https URL\n",
    "authors": [
      "Son T. Ly",
      "Bai Lin",
      "Hung Q. Vo",
      "Dragan Maric",
      "Badri Roysam",
      "Hien V. Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.05194"
  },
  {
    "id": "arXiv:2205.05197",
    "title": "Incident duration prediction using a bi-level machine learning framework  with outlier removal and intra-extra joint optimisation",
    "abstract": "Predicting the duration of traffic incidents is a challenging task due to the\nstochastic nature of events. The ability to accurately predict how long\naccidents will last can provide significant benefits to both end-users in their\nroute choice and traffic operation managers in handling of non-recurrent\ntraffic congestion. This paper presents a novel bi-level machine learning\nframework enhanced with outlier removal and intra-extra joint optimisation for\npredicting the incident duration on three heterogeneous data sets collected for\nboth arterial roads and motorways from Sydney, Australia and San-Francisco,\nU.S.A. Firstly, we use incident data logs to develop a binary classification\nprediction approach, which allows us to classify traffic incidents as\nshort-term or long-term. We find the optimal threshold between short-term\nversus long-term traffic incident duration, targeting both class balance and\nprediction performance while also comparing the binary versus multi-class\nclassification approaches. Secondly, for more granularity of the incident\nduration prediction to the minute level, we propose a new Intra-Extra Joint\nOptimisation algorithm (IEO-ML) which extends multiple baseline ML models\ntested against several regression scenarios across the data sets. Final results\nindicate that: a) 40-45 min is the best split threshold for identifying short\nversus long-term incidents and that these incidents should be modelled\nseparately, b) our proposed IEO-ML approach significantly outperforms baseline\nML models in $66\\%$ of all cases showcasing its great potential for accurate\nincident duration prediction. Lastly, we evaluate the feature importance and\nshow that time, location, incident type, incident reporting source and weather\nat among the top 10 critical factors which influence how long incidents will\nlast.",
    "descriptor": "",
    "authors": [
      "Artur Grigorev",
      "Adriana-Simona Mihaita",
      "Seunghyeon Lee",
      "Fang Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05197"
  },
  {
    "id": "arXiv:2205.05198",
    "title": "Reducing Activation Recomputation in Large Transformer Models",
    "abstract": "Training large transformer models is one of the most important computational\nchallenges of modern AI. In this paper, we show how to significantly accelerate\ntraining of large transformer models by reducing activation recomputation.\nActivation recomputation is commonly used to work around memory capacity\nconstraints. Rather than storing activations for backpropagation, they are\ntraditionally recomputed, which saves memory but adds redundant compute. In\nthis work, we show most of this redundant compute is unnecessary because we can\nreduce memory consumption sufficiently without it. We present two novel yet\nvery simple techniques: sequence parallelism and selective activation\nrecomputation. In conjunction with tensor parallelism, these techniques almost\neliminate the need to recompute activations. We evaluate our approach on\nlanguage models up to one trillion parameters in scale and show that our method\nreduces activation memory by 5x, while reducing execution time overhead from\nactivation recomputation by over 90%. For example, when training a 530B\nparameter GPT-3 style model on 2240 NVIDIA A100 GPUs, we achieve a Model Flops\nUtilization of 54.2%, which is 29% faster than the 42.1% we achieve using\nrecomputation. Our implementation will be available in both Megatron-LM and\nNeMo-Megatron.",
    "descriptor": "",
    "authors": [
      "Vijay Korthikanti",
      "Jared Casper",
      "Sangkug Lym",
      "Lawrence McAfee",
      "Michael Andersch",
      "Mohammad Shoeybi",
      "Bryan Catanzaro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.05198"
  },
  {
    "id": "arXiv:2205.05202",
    "title": "Deep Learning-based Channel Estimation for Wideband Hybrid MmWave  Massive MIMO",
    "abstract": "Hybrid analog-digital (HAD) architecture is widely adopted in practical\nmillimeter wave (mmWave) massive multiple-input multiple-output (MIMO) systems\nto reduce hardware cost and energy consumption. However, channel estimation in\nthe context of HAD is challenging due to only limited radio frequency (RF)\nchains at transceivers. Although various compressive sensing (CS) algorithms\nhave been developed to solve this problem by exploiting inherent channel\nsparsity and sparsity structures, practical effects, such as power leakage and\nbeam squint, can still make the real channel features deviate from the assumed\nmodels and result in performance degradation. Also, the high complexity of CS\nalgorithms caused by a large number of iterations hinders their applications in\npractice. To tackle these issues, we develop a deep learning (DL)-based channel\nestimation approach where the sparse Bayesian learning (SBL) algorithm is\nunfolded into a deep neural network (DNN). In each SBL layer, Gaussian variance\nparameters of the sparse angular domain channel are updated by a tailored DNN,\nwhich is able to effectively capture complicated channel sparsity structures in\nvarious domains. Besides, the measurement matrix is jointly optimized for\nperformance improvement. Then, the proposed approach is extended to the\nmulti-block case where channel correlation in time is further exploited to\nadaptively predict the measurement matrix and facilitate the update of Gaussian\nvariance parameters. Based on simulation results, the proposed approaches\nsignificantly outperform existing approaches but with reduced complexity.",
    "descriptor": "",
    "authors": [
      "Jiabao Gao",
      "Caijun Zhong",
      "Geoffrey Ye Li",
      "Joseph B. Soriaga",
      "Arash Behboodi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.05202"
  },
  {
    "id": "arXiv:2205.05207",
    "title": "Optimal screening contests",
    "abstract": "We study the optimal design of contests as screening devices. In an\nincomplete information environment, contest results reveal information about\nthe quality of the participating agents at the cost of potentially wasteful\neffort put in by these agents. We are interested in finding contests that\nmaximize the information revealed per unit of expected effort put in by the\nagents. In a model with linear costs of effort and privately known marginal\ncosts, we find the Bayes-Nash equilibrium strategy for arbitrary prize\nstructures ($1=v_1 \\geq v_2 \\dots \\geq v_n=0$) and show that the equilibrium\nstrategy mapping marginal costs to effort is always a density function. It\nfollows then that the expected effort under the uniform prior on marginal costs\nis independent of the prize structure. Restricting attention to a simple class\nof uniform prizes contests (top $k$ agents get $1$ and others get $0$), we find\nthat the optimal screening contest under the uniform prior awards half as many\nprizes as there are agents. For the power distribution $F(\\theta)=\\theta^p$\nwith $p\\geq 1$, we conjecture that the number of prizes in the optimal\nscreening contest is decreasing in $p$. In addition, we also show that a\nuniform prize structure is generally optimal for the standard objectives of\nmaximizing expected effort of an arbitrary agent, most efficient agent and\nleast efficient agent.",
    "descriptor": "",
    "authors": [
      "Sumit Goel"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2205.05207"
  },
  {
    "id": "arXiv:2205.05209",
    "title": "Bayesian Prior Learning via Neural Networks for Next-item Recommendation",
    "abstract": "Next-item prediction is a a popular problem in the recommender systems\ndomain. As the name suggests, the task is to recommend subsequent items that a\nuser would be interested in given contextual information and historical\ninteraction data. In our paper, we model a general notion of context via a\nsequence of item interactions. We model the next item prediction problem using\nthe Bayesian framework and capture the probability of appearance of a sequence\nthrough the posterior mean of the Beta distribution. We train two neural\nnetworks to accurately predict the alpha & beta parameter values of the Beta\ndistribution. Our novel approach of combining black-box style neural networks,\nknown to be suitable for function approximation with Bayesian estimation\nmethods have resulted in an innovative method that outperforms various\nstate-of-the-art baselines. We demonstrate the effectiveness of our method in\ntwo real world datasets. Our framework is an important step towards the goal of\nbuilding privacy preserving recommender systems.",
    "descriptor": "",
    "authors": [
      "Manoj Reddy Dareddy",
      "Zijun Xue",
      "Nicholas Lin",
      "Junghoo Cho"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.05209"
  },
  {
    "id": "arXiv:2205.05211",
    "title": "Ancestral Colorings of Perfect Binary Trees With Applications in Private  Retrieval of Merkle Proofs",
    "abstract": "We introduce a novel tree coloring problem in which each node of a rooted\ntree of height $h$ is assigned one of the $h$ colors under the condition that\nany two nodes that are ancestor and descendant of each other must have\ndifferent colors and moreover, the numbers of nodes in any two distinct color\nclasses differ by at most one. We refer to such a coloring as a balanced\nancestral coloring. Our key contribution is to characterize, based on\nmajorizations, all color sequences (not only the balanced ones) for which there\nexists an ancestral coloring for perfect binary trees. We then develop an\nalmost linear time (in the number of tree nodes) divide-and-conquer algorithm\nto generate such a coloring for every perfect binary tree of height $h\\geq 1$.\nThe existence of a balanced ancestral coloring reveals an interesting fact\nabout combinatorial batch code: when the batch follows a special pattern\n(consisting of nodes along a root-to-leaf path in a tree), the total storage\ncapacity required can be reduced by a factor of $\\Theta(h)$ compared to when\nthe batch is arbitrary while keeping a balanced storage capacity across $h$\nservers. Furthermore, our result also identifies an infinite family of graphs\nfor which the equitable chromatic number can be explicitly determined. As far\nas we know, this family has not been discovered before in the literature. As a\npractical application, we show that a balanced ancestral coloring can be\nemployed to speed up the private retrieval of a Merkle proof in a Merkle tree\nby a factor of $\\Theta(h/2)$ compared to a straightforward parallel\nimplementation of SealPIR, a state-of-the-art private information retrieval\nscheme.",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Quang Cao",
      "Rinaldo Gagiano",
      "Duy Huynh",
      "Xun Yi",
      "Son Hoang Dau",
      "Phuc Lu Le",
      "Quang-Hung Luu",
      "Emanuele Viterbo",
      "Yu-Chih Huang",
      "Jingge Zhu",
      "Mohammad M. Jalalzai",
      "Chen Feng"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2205.05211"
  },
  {
    "id": "arXiv:2205.05212",
    "title": "A State-Distribution Matching Approach to Non-Episodic Reinforcement  Learning",
    "abstract": "While reinforcement learning (RL) provides a framework for learning through\ntrial and error, translating RL algorithms into the real world has remained\nchallenging. A major hurdle to real-world application arises from the\ndevelopment of algorithms in an episodic setting where the environment is reset\nafter every trial, in contrast with the continual and non-episodic nature of\nthe real-world encountered by embodied agents such as humans and robots. Prior\nworks have considered an alternating approach where a forward policy learns to\nsolve the task and the backward policy learns to reset the environment, but\nwhat initial state distribution should the backward policy reset the agent to?\nAssuming access to a few demonstrations, we propose a new method, MEDAL, that\ntrains the backward policy to match the state distribution in the provided\ndemonstrations. This keeps the agent close to the task-relevant states,\nallowing for a mix of easy and difficult starting states for the forward\npolicy. Our experiments show that MEDAL matches or outperforms prior methods on\nthree sparse-reward continuous control tasks from the EARL benchmark, with 40%\ngains on the hardest task, while making fewer assumptions than prior works.",
    "descriptor": "",
    "authors": [
      "Archit Sharma",
      "Rehaan Ahmad",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.05212"
  },
  {
    "id": "arXiv:2205.05218",
    "title": "DcnnGrasp: Towards Accurate Grasp Pattern Recognition with Adaptive  Regularizer Learning",
    "abstract": "The task of grasp pattern recognition aims to derive the applicable grasp\ntypes of an object according to the visual information. Current\nstate-of-the-art methods ignore category information of objects which is\ncrucial for grasp pattern recognition. This paper presents a novel dual-branch\nconvolutional neural network (DcnnGrasp) to achieve joint learning of object\ncategory classification and grasp pattern recognition. DcnnGrasp takes object\ncategory classification as an auxiliary task to improve the effectiveness of\ngrasp pattern recognition. Meanwhile, a new loss function called joint\ncross-entropy with an adaptive regularizer is derived through maximizing a\nposterior, which significantly improves the model performance. Besides, based\non the new loss function, a training strategy is proposed to maximize the\ncollaborative learning of the two tasks. The experiment was performed on five\nhousehold objects datasets including the RGB-D Object dataset, Hit-GPRec\ndataset, Amsterdam library of object images (ALOI), Columbia University Image\nLibrary (COIL-100), and MeganePro dataset 1. The experimental results\ndemonstrated that the proposed method can achieve competitive performance on\ngrasp pattern recognition with several state-of-the-art methods. Specifically,\nour method even outperformed the second-best one by nearly 15% in terms of\nglobal accuracy for the case of testing a novel object on the RGB-D Object\ndataset.",
    "descriptor": "",
    "authors": [
      "Xiaoqin Zhang",
      "Ziwei Huang",
      "Jingjing Zheng",
      "Shuo Wang",
      "Xianta Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.05218"
  },
  {
    "id": "arXiv:2205.05228",
    "title": "Hierarchical Constrained Stochastic Shortest Path Planning via Cost  Budget Allocation",
    "abstract": "Stochastic sequential decision making often requires hierarchical structure\nin the problem where each high-level action should be further planned with\nprimitive states and actions. In addition, many real-world applications require\na plan that satisfies constraints on the secondary costs such as risk measure\nor fuel consumption. In this paper, we propose a hierarchical constrained\nstochastic shortest path problem (HC-SSP) that meets those two crucial\nrequirements in a single framework. Although HC-SSP provides a useful framework\nto model such planning requirements in many real-world applications, the\nresulting problem has high complexity and makes it difficult to find an optimal\nsolution fast which prevents user from applying it to real-time and\nrisk-sensitive applications. To address this problem, we present an algorithm\nthat iteratively allocates cost budget to lower level planning problems based\non branch-and-bound scheme to find a feasible solution fast and incrementally\nupdate the incumbent solution. We demonstrate the proposed algorithm in an\nevacuation scenario and prove the advantage over a state-of-the-art\nmathematical programming based approach.",
    "descriptor": "",
    "authors": [
      "Sungkweon Hong",
      "Brian C. Williams"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.05228"
  },
  {
    "id": "arXiv:2205.05230",
    "title": "Developing cooperative policies for multi-stage reinforcement learning  tasks",
    "abstract": "Many hierarchical reinforcement learning algorithms utilise a series of\nindependent skills as a basis to solve tasks at a higher level of reasoning.\nThese algorithms don't consider the value of using skills that are cooperative\ninstead of independent. This paper proposes the Cooperative Consecutive\nPolicies (CCP) method of enabling consecutive agents to cooperatively solve\nlong time horizon multi-stage tasks. This method is achieved by modifying the\npolicy of each agent to maximise both the current and next agent's critic.\nCooperatively maximising critics allows each agent to take actions that are\nbeneficial for its task as well as subsequent tasks. Using this method in a\nmulti-room maze domain and a peg in hole manipulation domain, the cooperative\npolicies were able to outperform a set of naive policies, a single agent\ntrained across the entire domain, as well as another sequential HRL algorithm.",
    "descriptor": "\nComments: This paper supersedes the rejected paper \"Developing cooperative policies for multi-stage tasks\". arXiv admin note: substantial text overlap with arXiv:2007.00203\n",
    "authors": [
      "Jordan Erskine",
      "Chris Lehnert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.05230"
  },
  {
    "id": "arXiv:2205.05236",
    "title": "Reconnecting the Estranged Relationships: Optimizing the Influence  Propagation in Evolving Networks",
    "abstract": "Influence Maximization (IM), which aims to select a set of users from a\nsocial network to maximize the expected number of influenced users, has\nrecently received significant attention for mass communication and commercial\nmarketing. Existing research efforts dedicated to the IM problem depend on a\nstrong assumption: the selected seed users are willing to spread the\ninformation after receiving benefits from a company or organization. In\nreality, however, some seed users may be reluctant to spread the information,\nor need to be paid higher to be motivated. Furthermore, the existing IM works\npay little attention to capture user's influence propagation in the future\nperiod as well. In this paper, we target a new research problem, named\nReconnecting Top-l Relationships (RTlR) query, which aims to find l number of\nprevious existing relationships but being stranged later, such that\nreconnecting these relationships will maximize the expected benefit of\ninfluenced users by the given group in a future period. We prove that the RTlR\nproblem is NP-hard. An efficient greedy algorithm is proposed to answer the\nRTlR queries with the influence estimation technique and the well-chosen link\nprediction method to predict the near future network structure. We also design\na pruning method to reduce unnecessary probing from candidate edges. Further, a\ncarefully designed order-based algorithm is proposed to accelerate the RTlR\nqueries. Finally, we conduct extensive experiments on real-world datasets to\ndemonstrate the effectiveness and efficiency of our proposed methods.",
    "descriptor": "",
    "authors": [
      "Taotao Cai",
      "Qi Lei",
      "Quan Z. Sheng",
      "Shuiqiao Yang",
      "Jian Yang",
      "Wei Emma Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2205.05236"
  },
  {
    "id": "arXiv:2205.05243",
    "title": "Libra: In-network Gradient Aggregation for Speeding up Distributed  Sparse Deep Training",
    "abstract": "Distributed sparse deep learning has been widely used in many internet-scale\napplications. Network communication is one of the major hurdles for the\ntraining performance. In-network gradient aggregation on programmable switches\nis a promising solution to speed up the performance. Nevertheless,existing\nin-network aggregation solutions are designed for the distributed dense deep\ntraining, and fall short when used for the sparse deep training.To address this\ngap, we present Libra based on our key observation of the extremely biased\nupdate frequency of parameters in distributed deep sparse training.\nSpecifically, Libra offloads only the aggregation for \"hot\" parameters that are\nupdated frequently onto programmable switches. To enable this offloading and\nachieve high aggregation throughput, we propose solutions to address the\nchallenges related to hot parameter identification, parameter orchestration,\nfloating-point summation on switches as well as system reliability. We\nimplemented Libra on Intel Tofino switches and integrated it with PS-lite.\nFinally, we evaluate Libra's performance through extensive experiments and show\nthat Libra can speed up the gradient aggregation by 1.5~4 times.",
    "descriptor": "\nComments: 14 pages, 18 figures\n",
    "authors": [
      "Heng Pan",
      "Penglai Cui",
      "Zhenyu li",
      "Ru Jia",
      "Penghao Zhang",
      "Leilei Zhang",
      "Ye Yang",
      "Jiahao Wu",
      "Jianbo Dong",
      "Zheng Cao",
      "Qiang Li",
      "Hongqiang Harry Liu",
      "Mathy Laurent",
      "Gaogang Xie"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.05243"
  },
  {
    "id": "arXiv:2205.05245",
    "title": "Salient Object Detection via Bounding-box Supervision",
    "abstract": "The success of fully supervised saliency detection models depends on a large\nnumber of pixel-wise labeling. In this paper, we work on bounding-box based\nweakly-supervised saliency detection to relieve the labeling effort. Given the\nbounding box annotation, we observe that pixels inside the bounding box may\ncontain extensive labeling noise. However, as a large amount of background is\nexcluded, the foreground bounding box region contains a less complex\nbackground, making it possible to perform handcrafted features-based saliency\ndetection with only the cropped foreground region. As the conventional\nhandcrafted features are not representative enough, leading to noisy saliency\nmaps, we further introduce structure-aware self-supervised loss to regularize\nthe structure of the prediction. Further, we claim that pixels outside the\nbounding box should be background, thus partial cross-entropy loss function can\nbe used to accurately localize the accurate background region. Experimental\nresults on six benchmark RGB saliency datasets illustrate the effectiveness of\nour model.",
    "descriptor": "\nComments: 5 pages,4 figures,submitted to ICIP 2022\n",
    "authors": [
      "Mengqi He",
      "Jing Zhang",
      "Wenxin Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05245"
  },
  {
    "id": "arXiv:2205.05248",
    "title": "Efficient Distributed Framework for Collaborative Multi-Agent  Reinforcement Learning",
    "abstract": "Multi-agent reinforcement learning for incomplete information environments\nhas attracted extensive attention from researchers. However, due to the slow\nsample collection and poor sample exploration, there are still some problems in\nmulti-agent reinforcement learning, such as unstable model iteration and low\ntraining efficiency. Moreover, most of the existing distributed framework are\nproposed for single-agent reinforcement learning and not suitable for\nmulti-agent. In this paper, we design an distributed MARL framework based on\nthe actor-work-learner architecture. In this framework, multiple asynchronous\nenvironment interaction modules can be deployed simultaneously, which greatly\nimproves the sample collection speed and sample diversity. Meanwhile, to make\nfull use of computing resources, we decouple the model iteration from\nenvironment interaction, and thus accelerate the policy iteration. Finally, we\nverified the effectiveness of propose framework in MaCA military simulation\nenvironment and the SMAC 3D realtime strategy gaming environment with\nimcomplete information characteristics.",
    "descriptor": "\nComments: 9 pages, 20 figures\n",
    "authors": [
      "Shuhan Qi",
      "Shuhao Zhang",
      "Xiaohan Hou",
      "Jiajia Zhang",
      "Xuan Wang",
      "Jing Xiao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2205.05248"
  },
  {
    "id": "arXiv:2205.05249",
    "title": "Secure Federated Learning for Neuroimaging",
    "abstract": "The amount of biomedical data continues to grow rapidly. However, the ability\nto collect data from multiple sites for joint analysis remains challenging due\nto security, privacy, and regulatory concerns. We present a Secure Federated\nLearning architecture, MetisFL, which enables distributed training of neural\nnetworks over multiple data sources without sharing data. Each site trains the\nneural network over its private data for some time, then shares the neural\nnetwork parameters (i.e., weights, gradients) with a Federation Controller,\nwhich in turn aggregates the local models, sends the resulting community model\nback to each site, and the process repeats. Our architecture provides strong\nsecurity and privacy. First, sample data never leaves a site. Second, neural\nparameters are encrypted before transmission and the community model is\ncomputed under fully-homomorphic encryption. Finally, we use\ninformation-theoretic methods to limit information leakage from the neural\nmodel to prevent a curious site from performing membership attacks. We\ndemonstrate this architecture in neuroimaging. Specifically, we investigate\ntraining neural models to classify Alzheimer's disease, and estimate Brain Age,\nfrom magnetic resonance imaging datasets distributed across multiple sites,\nincluding heterogeneous environments where sites have different amounts of\ndata, statistical distributions, and computational capabilities.",
    "descriptor": "\nComments: 10 pages, 7 figures, 2 tables\n",
    "authors": [
      "Dimitris Stripelis",
      "Umang Gupta",
      "Hamza Saleem",
      "Nikhil Dhinagar",
      "Tanmay Ghai",
      "Rafael Sanchez",
      "Chrysovalantis Anastasiou",
      "Armaghan Asghar",
      "Greg Ver Steeg",
      "Srivatsan Ravi",
      "Muhammad Naveed",
      "Paul M. Thompson",
      "Jose Luis Ambite"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.05249"
  },
  {
    "id": "arXiv:2205.05250",
    "title": "Spatial-temporal associations representation and application for process  monitoring using graph convolution neural network",
    "abstract": "Industrial process data reflects the dynamic changes of operation conditions,\nwhich mainly refer to the irregular changes in the dynamic associations between\ndifferent variables in different time. And this related associations knowledge\nfor process monitoring is often implicit in these dynamic monitoring data which\nalways have richer operation condition information and have not been paid\nenough attention in current research. To this end, a new process monitoring\nmethod based on spatial-based graph convolution neural network (SGCN) is\nproposed to describe the characteristics of the dynamic associations which can\nbe used to represent the operation status over time. Spatia-temporal graphs are\nfirstly defined, which can be used to represent the characteristics of node\nattributes (dynamic edge features) dynamically changing with time. Then, the\nassociations between monitoring variables at a certain time can be considered\nas the node attributes to define a snapshot of the static graph network at the\ncertain time. Finally, the snapshot containing graph structure and node\nattributes is used as model inputs which are processed to implement graph\nclassification by spatial-based convolution graph neural network with aggregate\nand readout steps. The feasibility and applicability of this proposed method\nare demonstrated by our experimental results of benchmark and practical case\napplication.",
    "descriptor": "",
    "authors": [
      "Hao Ren",
      "Chunhua Yang",
      "Xiaojun Liang",
      "Zhiwen Chen",
      "Weihua Gui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.05250"
  },
  {
    "id": "arXiv:2205.05256",
    "title": "Evaluation Gaps in Machine Learning Practice",
    "abstract": "Forming a reliable judgement of a machine learning (ML) model's\nappropriateness for an application ecosystem is critical for its responsible\nuse, and requires considering a broad range of factors including harms,\nbenefits, and responsibilities. In practice, however, evaluations of ML models\nfrequently focus on only a narrow range of decontextualized predictive\nbehaviours. We examine the evaluation gaps between the idealized breadth of\nevaluation concerns and the observed narrow focus of actual evaluations.\nThrough an empirical study of papers from recent high-profile conferences in\nthe Computer Vision and Natural Language Processing communities, we demonstrate\na general focus on a handful of evaluation methods. By considering the metrics\nand test data distributions used in these methods, we draw attention to which\nproperties of models are centered in the field, revealing the properties that\nare frequently neglected or sidelined during evaluation. By studying these\nproperties, we demonstrate the machine learning discipline's implicit\nassumption of a range of commitments which have normative impacts; these\ninclude commitments to consequentialism, abstractability from context, the\nquantifiability of impacts, the limited role of model inputs in evaluation, and\nthe equivalence of different failure modes. Shedding light on these assumptions\nenables us to question their appropriateness for ML system contexts, pointing\nthe way towards more contextualized evaluation methodologies for robustly\nexamining the trustworthiness of ML models",
    "descriptor": "",
    "authors": [
      "Ben Hutchinson",
      "Negar Rostamzadeh",
      "Christina Greer",
      "Katherine Heller",
      "Vinodkumar Prabhakaran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05256"
  },
  {
    "id": "arXiv:2205.05264",
    "title": "Spatial-Temporal Space Hand-in-Hand: Spatial-Temporal Video  Super-Resolution via Cycle-Projected Mutual Learning",
    "abstract": "Spatial-Temporal Video Super-Resolution (ST-VSR) aims to generate\nsuper-resolved videos with higher resolution(HR) and higher frame rate (HFR).\nQuite intuitively, pioneering two-stage based methods complete ST-VSR by\ndirectly combining two sub-tasks: Spatial Video Super-Resolution (S-VSR) and\nTemporal Video Super-Resolution(T-VSR) but ignore the reciprocal relations\namong them. Specifically, 1) T-VSR to S-VSR: temporal correlations help\naccurate spatial detail representation with more clues; 2) S-VSR to T-VSR:\nabundant spatial information contributes to the refinement of temporal\nprediction. To this end, we propose a one-stage based Cycle-projected Mutual\nlearning network (CycMu-Net) for ST-VSR, which makes full use of\nspatial-temporal correlations via the mutual learning between S-VSR and T-VSR.\nSpecifically, we propose to exploit the mutual information among them via\niterative up-and-down projections, where the spatial and temporal features are\nfully fused and distilled, helping the high-quality video reconstruction.\nBesides extensive experiments on benchmark datasets, we also compare our\nproposed CycMu-Net with S-VSR and T-VSR tasks, demonstrating that our method\nsignificantly outperforms state-of-the-art methods.",
    "descriptor": "\nComments: 10 pages, 8 figures\n",
    "authors": [
      "Mengshun Hu",
      "Kui Jiang",
      "Liang Liao",
      "Jing Xiao",
      "Junjun Jiang",
      "Zheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.05264"
  },
  {
    "id": "arXiv:2205.05265",
    "title": "What is Proxy Discrimination?",
    "abstract": "The near universal condemnation of proxy discrimination hides a disagreement\nover what it is. This work surveys various notions of proxy and proxy\ndiscrimination found in prior work and represents them in a common framework.\nThese notions variously turn on statistical dependencies, causal effects, and\nintentions. It discusses the limitations and uses of each notation and of the\nconcept as a whole.",
    "descriptor": "\nComments: To appear as in the 2022 ACM Conference on Fairness, Accountability, and Transparency (FAccT '22), June 21-24, 2022, Seoul, Republic of Korea. ACM, New York, NY, USA. this https URL\n",
    "authors": [
      "Michael Carl Tschantz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.05265"
  },
  {
    "id": "arXiv:2205.05268",
    "title": "The Meta-Turing Test",
    "abstract": "We propose an alternative to the Turing test that removes the inherent\nasymmetry between humans and machines in Turing's original imitation game. In\nthis new test, both humans and machines judge each other. We argue that this\nmakes the test more robust against simple deceptions. We also propose a small\nnumber of refinements to improve further the test. These refinements could be\napplied also to Turing's original imitation game.",
    "descriptor": "\nComments: Appeared in AAAI 2017 Workshop - Technical Report, San Francisco, California USA, pp. 132 - 137, presented at AAAI 2017 conference\n",
    "authors": [
      "Toby Walsh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.05268"
  },
  {
    "id": "arXiv:2205.05270",
    "title": "Relational Triple Extraction: One Step is Enough",
    "abstract": "Extracting relational triples from unstructured text is an essential task in\nnatural language processing and knowledge graph construction. Existing\napproaches usually contain two fundamental steps: (1) finding the boundary\npositions of head and tail entities; (2) concatenating specific tokens to form\ntriples. However, nearly all previous methods suffer from the problem of error\naccumulation, i.e., the boundary recognition error of each entity in step (1)\nwill be accumulated into the final combined triples. To solve the problem, in\nthis paper, we introduce a fresh perspective to revisit the triple extraction\ntask, and propose a simple but effective model, named DirectRel. Specifically,\nthe proposed model first generates candidate entities through enumerating token\nsequences in a sentence, and then transforms the triple extraction task into a\nlinking problem on a \"head $\\rightarrow$ tail\" bipartite graph. By doing so,\nall triples can be directly extracted in only one step. Extensive experimental\nresults on two widely used datasets demonstrate that the proposed model\nperforms better than the state-of-the-art baselines.",
    "descriptor": "\nComments: Accepted by IJCAI-2022\n",
    "authors": [
      "Yu-Ming Shang",
      "Heyan Huang",
      "Xin Sun",
      "Wei Wei",
      "Xian-Ling Mao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.05270"
  },
  {
    "id": "arXiv:2205.05272",
    "title": "Hierarchical Collaborative Hyper-parameter Tuning",
    "abstract": "Hyper-parameter Tuning is among the most critical stages in building machine\nlearning solutions. This paper demonstrates how multi-agent systems can be\nutilized to develop a distributed technique for determining near-optimal values\nfor any arbitrary set of hyper-parameters in a machine learning model. The\nproposed method employs a distributedly formed hierarchical agent-based\narchitecture for the cooperative searching procedure of tuning hyper-parameter\nvalues. The presented generic model is used to develop a guided randomized\nagent-based tuning technique, and its behavior is investigated in both machine\nlearning and global function optimization applications. According the empirical\nresults, the proposed model outperformed both of its underlying randomized\ntuning strategies in terms of classification error and function evaluations,\nnotably in higher number of dimensions.",
    "descriptor": "",
    "authors": [
      "Ahmad Esmaeili",
      "Zahra Ghorrati",
      "Eric Matson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2205.05272"
  },
  {
    "id": "arXiv:2205.05275",
    "title": "Strong Sign Controllability of Diffusively-Coupled Networks",
    "abstract": "This paper presents several conditions to determine strong sign\ncontrollability for diffusively-coupled undirected networks. The strong sign\ncontrollability is determined by the sign patterns (positive, negative, zero)\nof the edges. We first provide the necessary and sufficient conditions for\nstrong sign controllability of basic components, such as path, cycle, and tree.\nNext, we propose a merging process to extend the basic componenets to a larger\ngraph based on the conditions of the strong sign controllability. Furthermore,\nwe develop an algorithm of polynomial complexity to find the minimum number of\nexternal input nodes while maintaining the strong sign controllability of a\nnetwork.",
    "descriptor": "",
    "authors": [
      "Nam-Jin Park",
      "Seong-Ho Kwon",
      "Yoo-Bin Bae",
      "Byeong-Yeon Kim",
      "Kevin L. Moore",
      "Hyo-Sung Ahn"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.05275"
  },
  {
    "id": "arXiv:2205.05277",
    "title": "AggPose: Deep Aggregation Vision Transformer for Infant Pose Estimation",
    "abstract": "Movement and pose assessment of newborns lets experienced pediatricians\npredict neurodevelopmental disorders, allowing early intervention for related\ndiseases. However, most of the newest AI approaches for human pose estimation\nmethods focus on adults, lacking publicly benchmark for infant pose estimation.\nIn this paper, we fill this gap by proposing infant pose dataset and Deep\nAggregation Vision Transformer for human pose estimation, which introduces a\nfast trained full transformer framework without using convolution operations to\nextract features in the early stages. It generalizes Transformer + MLP to\nhigh-resolution deep layer aggregation within feature maps, thus enabling\ninformation fusion between different vision levels. We pre-train AggPose on\nCOCO pose dataset and apply it on our newly released large-scale infant pose\nestimation dataset. The results show that AggPose could effectively learn the\nmulti-scale features among different resolutions and significantly improve the\nperformance of infant pose estimation. We show that AggPose outperforms hybrid\nmodel HRFormer and TokenPose in the infant pose estimation dataset. Moreover,\nour AggPose outperforms HRFormer by 0.7% AP on COCO val pose estimation on\naverage. Our code is available at github.com/SZAR-LAB/AggPose.",
    "descriptor": "\nComments: To appear in the 31th International Joint Conference on Artificial Intelligence (IJCAI 2022)\n",
    "authors": [
      "Xu Cao",
      "Xiaoye Li",
      "Liya Ma",
      "Yi Huang",
      "Xuan Feng",
      "Zening Chen",
      "Hongwu Zeng",
      "Jianguo Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.05277"
  },
  {
    "id": "arXiv:2205.05279",
    "title": "Unsupervised machine learning for physical concepts",
    "abstract": "In recent years, machine learning methods have been used to assist scientists\nin scientific research. Human scientific theories are based on a series of\nconcepts. How machine learns the concepts from experimental data will be an\nimportant first step. We propose a hybrid method to extract interpretable\nphysical concepts through unsupervised machine learning. This method consists\nof two stages. At first, we need to find the Betti numbers of experimental\ndata. Secondly, given the Betti numbers, we use a variational autoencoder\nnetwork to extract meaningful physical variables. We test our protocol on toy\nmodels and show how it works.",
    "descriptor": "",
    "authors": [
      "Ruyu Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.05279"
  },
  {
    "id": "arXiv:2205.05281",
    "title": "Poisson Integrators based on splitting method for Poisson systems",
    "abstract": "We propose Poisson integrators for the numerical integration of separable\nPoisson systems. We analyze three situations in which the Poisson systems are\nseparated in three ways and the Poisson integrators can be constructed by using\nthe splitting method. Numerical results show that the Poisson integrators\noutperform the higher order non-Poisson integrators in phase orbit tracking,\nlong-term energy conservation and efficiency.",
    "descriptor": "",
    "authors": [
      "Beibei Zhu",
      "Lun Ji",
      "Aiqing Zhu",
      "Yifa Tang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.05281"
  },
  {
    "id": "arXiv:2205.05282",
    "title": "ReFine: Re-randomization before Fine-tuning for Cross-domain Few-shot  Learning",
    "abstract": "Cross-domain few-shot learning (CD-FSL), where there are few target samples\nunder extreme differences between source and target domains, has recently\nattracted huge attention. For CD-FSL, recent studies generally have developed\ntransfer learning based approaches that pre-train a neural network on popular\nlabeled source domain datasets and then transfer it to target domain data.\nAlthough the labeled datasets may provide suitable initial parameters for the\ntarget data, the domain difference between the source and target might hinder\nthe fine-tuning on the target domain. This paper proposes a simple yet powerful\nmethod that re-randomizes the parameters fitted on the source domain before\nadapting to the target data. The re-randomization resets source-specific\nparameters of the source pre-trained model and thus facilitates fine-tuning on\nthe target domain, improving few-shot performance.",
    "descriptor": "\nComments: 8 pages, 3 figures, and 7 tables\n",
    "authors": [
      "Jaehoon Oh",
      "Sungnyun Kim",
      "Namgyu Ho",
      "Jin-Hwa Kim",
      "Hwanjun Song",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.05282"
  },
  {
    "id": "arXiv:2205.05293",
    "title": "Invisible-to-Visible: Privacy-Aware Human Segmentation using Airborne  Ultrasound via Collaborative Learning Probabilistic U-Net",
    "abstract": "Color images are easy to understand visually and can acquire a great deal of\ninformation, such as color and texture. They are highly and widely used in\ntasks such as segmentation. On the other hand, in indoor person segmentation,\nit is necessary to collect person data considering privacy. We propose a new\ntask for human segmentation from invisible information, especially airborne\nultrasound. We first convert ultrasound waves to reflected ultrasound\ndirectional images (ultrasound images) to perform segmentation from invisible\ninformation. Although ultrasound images can roughly identify a person's\nlocation, the detailed shape is ambiguous. To address this problem, we propose\na collaborative learning probabilistic U-Net that uses ultrasound and\nsegmentation images simultaneously during training, closing the probabilistic\ndistributions between ultrasound and segmentation images by comparing the\nparameters of the latent spaces. In inference, only ultrasound images can be\nused to obtain segmentation results. As a result of performance verification,\nthe proposed method could estimate human segmentations more accurately than\nconventional probabilistic U-Net and other variational autoencoder models.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2204.07280\n",
    "authors": [
      "Risako Tanigawa",
      "Yasunori Ishii",
      "Kazuki Kozuka",
      "Takayoshi Yamashita"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.05293"
  },
  {
    "id": "arXiv:2205.05296",
    "title": "Subspace Learning Machine (SLM): Methodology and Performance",
    "abstract": "Inspired by the feedforward multilayer perceptron (FF-MLP), decision tree\n(DT) and extreme learning machine (ELM), a new classification model, called the\nsubspace learning machine (SLM), is proposed in this work. SLM first identifies\na discriminant subspace, $S^0$, by examining the discriminant power of each\ninput feature. Then, it uses probabilistic projections of features in $S^0$ to\nyield 1D subspaces and finds the optimal partition for each of them. This is\nequivalent to partitioning $S^0$ with hyperplanes. A criterion is developed to\nchoose the best $q$ partitions that yield $2q$ partitioned subspaces among\nthem. We assign $S^0$ to the root node of a decision tree and the intersections\nof $2q$ subspaces to its child nodes of depth one. The partitioning process is\nrecursively applied at each child node to build an SLM tree. When the samples\nat a child node are sufficiently pure, the partitioning process stops and each\nleaf node makes a prediction. The idea can be generalized to regression,\nleading to the subspace learning regressor (SLR). Furthermore, ensembles of\nSLM/SLR trees can yield a stronger predictor. Extensive experiments are\nconducted for performance benchmarking among SLM/SLR trees, ensembles and\nclassical classifiers/regressors.",
    "descriptor": "",
    "authors": [
      "Hongyu Fu",
      "Yijing Yang",
      "Vinod K. Mishra",
      "C.-C. Jay Kuo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05296"
  },
  {
    "id": "arXiv:2205.05300",
    "title": "User Guide for KOTE: Korean Online Comments Emotions Dataset",
    "abstract": "Sentiment analysis that classifies data into positive or negative has been\ndominantly used to recognize emotional aspects of texts, despite the deficit of\nthorough examination of emotional meanings. Recently, corpora labeled with more\nthan just valence are built to exceed this limit. However, most Korean emotion\ncorpora are small in the number of instances and cover a limited range of\nemotions. We introduce KOTE dataset. KOTE contains 50k (250k cases) Korean\nonline comments, each of which is manually labeled for 43 emotion labels or one\nspecial label (NO EMOTION) by crowdsourcing (Ps = 3,048). The emotion taxonomy\nof the 43 emotions is systematically established by cluster analysis of Korean\nemotion concepts expressed on word embedding space. After explaining how KOTE\nis developed, we also discuss the results of finetuning and analysis for social\ndiscrimination in the corpus.",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Duyoung Jeon",
      "Junho Lee",
      "Cheongtag Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.05300"
  },
  {
    "id": "arXiv:2205.05302",
    "title": "Weak Supervision with Incremental Source Accuracy Estimation",
    "abstract": "Motivated by the desire to generate labels for real-time data we develop a\nmethod to estimate the dependency structure and accuracy of weak supervision\nsources incrementally. Our method first estimates the dependency structure\nassociated with the supervision sources and then uses this to iteratively\nupdate the estimated source accuracies as new data is received. Using both\noff-the-shelf classification models trained using publicly-available datasets\nand heuristic functions as supervision sources we show that our method\ngenerates probabilistic labels with an accuracy matching that of existing\noff-line methods.",
    "descriptor": "",
    "authors": [
      "Richard Gresham Correro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2205.05302"
  },
  {
    "id": "arXiv:2205.05304",
    "title": "Error Rate Analysis for Grant-free Massive Random Access with  Short-Packet Transmission",
    "abstract": "Grant-free massive random access (RA) is a promising protocol to support the\nmassive machine-type communications (mMTC) scenario in 5G and beyond networks.\nIn this paper, we focus on the error rate analysis in grant-free massive RA,\nwhich is critical for practical deployment but has not been well studied. We\nconsider a two-phase frame structure, with a pilot transmission phase for\nactivity detection and channel estimation, followed by a data transmission\nphase with coded data symbols. Considering the characteristics of short-packet\ntransmission, we analyze the block error rate (BLER) in the finite blocklength\nregime to characterize the data transmission performance. The analysis involves\ncharacterizing the activity detection and channel estimation errors as well as\napplying the random matrix theory (RMT) to analyze the distribution of the\npost-processing signal-to-noise ratio (SNR). As a case study, the derived BLER\nexpression is further simplified to optimize the pilot length. Simulation\nresults verify our analysis and demonstrate its effectiveness in pilot length\noptimization.",
    "descriptor": "",
    "authors": [
      "Xinyu Bian",
      "Yuyi Mao",
      "Jun Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.05304"
  },
  {
    "id": "arXiv:2205.05306",
    "title": "The Conflict Between Explainable and Accountable Decision-Making  Algorithms",
    "abstract": "Decision-making algorithms are being used in important decisions, such as who\nshould be enrolled in health care programs and be hired. Even though these\nsystems are currently deployed in high-stakes scenarios, many of them cannot\nexplain their decisions. This limitation has prompted the Explainable\nArtificial Intelligence (XAI) initiative, which aims to make algorithms\nexplainable to comply with legal requirements, promote trust, and maintain\naccountability. This paper questions whether and to what extent explainability\ncan help solve the responsibility issues posed by autonomous AI systems. We\nsuggest that XAI systems that provide post-hoc explanations could be seen as\nblameworthy agents, obscuring the responsibility of developers in the\ndecision-making process. Furthermore, we argue that XAI could result in\nincorrect attributions of responsibility to vulnerable stakeholders, such as\nthose who are subjected to algorithmic decisions (i.e., patients), due to a\nmisguided perception that they have control over explainable algorithms. This\nconflict between explainability and accountability can be exacerbated if\ndesigners choose to use algorithms and patients as moral and legal scapegoats.\nWe conclude with a set of recommendations for how to approach this tension in\nthe socio-technical process of algorithmic decision-making and a defense of\nhard regulation to prevent designers from escaping responsibility.",
    "descriptor": "\nComments: To appear in the FAccT 2022 proceedings\n",
    "authors": [
      "Gabriel Lima",
      "Nina Grgi\u0107-Hla\u010da",
      "Jin Keun Jeong",
      "Meeyoung Cha"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.05306"
  },
  {
    "id": "arXiv:2205.05313",
    "title": "Towards Unified Prompt Tuning for Few-shot Text Classification",
    "abstract": "Prompt-based fine-tuning has boosted the performance of Pre-trained Language\nModels (PLMs) on few-shot text classification by employing task-specific\nprompts. Yet, PLMs are unfamiliar with prompt-style expressions during\npre-training, which limits the few-shot learning performance on downstream\ntasks. It would be desirable if the models can acquire some prompting knowledge\nbefore adaptation to specific NLP tasks. We present the Unified Prompt Tuning\n(UPT) framework, leading to better few-shot text classification for BERT-style\nmodels by explicitly capturing prompting semantics from non-target NLP\ndatasets. In UPT, a novel paradigm Prompt-Options-Verbalizer is proposed for\njoint prompt learning across different NLP tasks, forcing PLMs to capture\ntask-invariant prompting knowledge. We further design a self-supervised task\nnamed Knowledge-enhanced Selective Masked Language Modeling to improve the\nPLM's generalization abilities for accurate adaptation to previously unseen\ntasks. After multi-task learning across multiple tasks, the PLM can be better\nprompt-tuned towards any dissimilar target tasks in low-resourced settings.\nExperiments over a variety of NLP tasks show that UPT consistently outperforms\nstate-of-the-arts for prompt-based fine-tuning.",
    "descriptor": "",
    "authors": [
      "Jianing Wang",
      "Chengyu Wang",
      "Fuli Luo",
      "Chuanqi Tan",
      "Minghui Qiu",
      "Fei Yang",
      "Qiuhui Shi",
      "Songfang Huang",
      "Ming Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.05313"
  },
  {
    "id": "arXiv:2205.05314",
    "title": "Statistical Characterization of Closed-Loop Latency at the Mobile Edge",
    "abstract": "The stringent timing and reliability requirements in mission-critical\napplications require a detailed statistical characterization of the latency.\nTeleoperation is a representative use case, in which a human operator (HO)\nremotely controls a robot by exchanging command and feedback signals. We\npresent a framework to analyze the latency of a closed-loop teleoperation\nsystem consisting of three entities: HO, robot located in remote environment,\nand a Base Station (BS) with Mobile edge Computing (MEC) capabilities. A model\nof each component of the system is used to analyze the closed-loop latency and\ndecide upon the optimal compression strategy. The closed-form expression of the\ndistribution of the closed-loop latency is difficult to estimate, such that\nsuitable upper and lower bounds are obtained. We formulate a non-convex\noptimization problem to minimize the closed-loop latency. Using the obtained\nupper and lower bound on the closed-loop latency, a computationally efficient\nprocedure to optimize the closed-loop latency is presented. The simulation\nresults reveal that compression of sensing data is not always beneficial, while\nsystem design based on average performance leads to under-provisioning and may\ncause performance degradation. The applicability of the proposed analysis is\nmuch wider than teleoperation, for systems whose latency budget consists of\nmany components.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Communications\n",
    "authors": [
      "Suraj Suman",
      "Federico Chiariotti",
      "Cedomir Stefanovic",
      "Strahinja Dosen",
      "Petar Popovski"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.05314"
  },
  {
    "id": "arXiv:2205.05320",
    "title": "Arbitrary Shape Text Detection via Boundary Transformer",
    "abstract": "Arbitrary shape text detection is a challenging task due to its complexity\nand variety, e.g, various scales, random rotations, and curve shapes. In this\npaper, we propose an arbitrary shape text detector with a boundary transformer,\nwhich can accurately and directly locate text boundaries without any\npost-processing. Our method mainly consists of a boundary proposal module and\nan iteratively optimized boundary transformer module. The boundary proposal\nmodule consisting of multi-layer dilated convolutions will compute important\nprior information (including classification map, distance field, and direction\nfield) for generating coarse boundary proposals meanwhile guiding the\noptimization of boundary transformer. The boundary transformer module adopts an\nencoder-decoder structure, in which the encoder is constructed by multi-layer\ntransformer blocks with residual connection while the decoder is a simple\nmulti-layer perceptron network (MLP). Under the guidance of prior information,\nthe boundary transformer module will gradually refine the coarse boundary\nproposals via boundary deformation in an iterative manner. Furthermore, we\npropose a novel boundary energy loss (BEL) which introduces an energy\nminimization constraint and an energy monotonically decreasing constraint for\nevery boundary optimization step. Extensive experiments on publicly available\nand challenging datasets demonstrate the state-of-the-art performance and\npromising efficiency of our method.",
    "descriptor": "\nComments: 13 pages, 12 figures.It is not the final version,just a preview. arXiv admin note: text overlap with arXiv:2107.12664\n",
    "authors": [
      "Shi-Xue Zhang",
      "Xiaobin Zhu",
      "Chun Yang",
      "Xu-Cheng Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.05320"
  },
  {
    "id": "arXiv:2205.05321",
    "title": "A Survey on Cache-Aided NOMA for 6G Networks",
    "abstract": "Contrary to orthogonal multiple-access (OMA), non-orthogonal multiple-access\n(NOMA) schemes can serve a pool of users without exploiting the scarce\nfrequency or time domain resources. This is useful in meeting the sixth\ngeneration (6G) network requirements, such as, low latency, massive\nconnectivity, users fairness, and high spectral efficiency. On the other hand,\ncontent caching restricts duplicate data transmission by storing popular\ncontents in advance at the network edge which reduces 6G data traffic. In this\nsurvey, we focus on cache-aided NOMA-based wireless networks which can reap the\nbenefits of both cache and NOMA; switching to NOMA from OMA enables cache-aided\nnetworks to push additional files to content servers in parallel and improve\nthe cache hit probability. Beginning with fundamentals of cache-aided NOMA\ntechnology, we summarize the performance goals of cache-aided NOMA systems,\npresent the associated design challenges, and categorize related recent\nliterature based on their application verticals. Concomitant standardization\nactivities and open research challenges are highlighted as well.",
    "descriptor": "",
    "authors": [
      "Dipen Bepari",
      "Soumen Mondal",
      "Aniruddha Chandra",
      "Rajeev Shukla",
      "Yuanwei Liu",
      "Mohsen Guizani",
      "Arumugam Nallanathan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.05321"
  },
  {
    "id": "arXiv:2205.05325",
    "title": "Open Problems in Fuzzing RESTful APIs: A Comparison of Tools",
    "abstract": "RESTful APIs are a type of web services that are widely used in industry. In\nthe last few years, a lot of effort in the research community has been spent in\ndesigning novel techniques to automatically fuzz those APIs to find faults in\nthem. Many real faults were automatically found in a large variety of RESTful\nAPIs. However, usually the analyzed fuzzers treat the APIs as black-box, and no\nanalysis of what is actually covered in these systems is done. Therefore,\nalthough these fuzzers are clearly useful for practitioners, we do not know\nwhat are their current limitations and actual effectiveness. Solving this is a\nnecessary step to be able to design better, more efficient and effective\ntechniques. To address this issue, in this paper we compare 6 state-of-the-art\nfuzzers on 10 RESTful APIs. We then analyzed the source code of which parts of\nthese APIs the fuzzers fail to generate tests for. This analysis points to\nclear limitations of these current fuzzers, listing concrete challenges for the\nresearch community to follow up on.",
    "descriptor": "",
    "authors": [
      "Man Zhang",
      "Andrea Arcuri"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.05325"
  },
  {
    "id": "arXiv:2205.05328",
    "title": "Generalized Modeling and Fundamental Limits for Multiple-Access  Integrated Sensing and Communication Systems",
    "abstract": "In this paper, we propose a generalized state-dependent channel modeling and\npresent fundamental limits for multiple-access integrated sensing and\ncommunication (ISAC) systems. The model proposed extends the latest studies by\nKobayashi et al. and Ahmadipour et al., which explicitly accounts for more\npractical scenarios with correlated sensing and channel states, and imperfect\nchannel state information at receiver (CSIR). For the model considered, we\ndevise an achievable scheme that combines message cooperation and joint\ncompression of past transmitted codeword and echo signals (a form of strictly\ncausal feedback) via distributed Wyner-Ziv coding at each user to realize\n\"simultaneously cooperative communication and sensing\". The corresponding\nachievable rate-distortion region is derived and a numerical example is\nconstructed to illustrate the potential gain of the proposed scheme. It is\nfound that the compressed information sent is not only useful for further\nenhancing communication (particularly in the case without CSIR), but also\nhelpful in improving the sensing performance of the transmitters.",
    "descriptor": "",
    "authors": [
      "Yao Liu",
      "Min Li",
      "An Liu",
      "Jianmin Lu",
      "Tony Xiao Han"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.05328"
  },
  {
    "id": "arXiv:2205.05330",
    "title": "Generalized Fast Multichannel Nonnegative Matrix Factorization Based on  Gaussian Scale Mixtures for Blind Source Separation",
    "abstract": "This paper describes heavy-tailed extensions of a state-of-the-art versatile\nblind source separation method called fast multichannel nonnegative matrix\nfactorization (FastMNMF) from a unified point of view. The common way of\nderiving such an extension is to replace the multivariate complex Gaussian\ndistribution in the likelihood function with its heavy-tailed generalization,\ne.g., the multivariate complex Student's t and leptokurtic generalized Gaussian\ndistributions, and tailor-make the corresponding parameter optimization\nalgorithm. Using a wider class of heavy-tailed distributions called a Gaussian\nscale mixture (GSM), i.e., a mixture of Gaussian distributions whose variances\nare perturbed by positive random scalars called impulse variables, we propose\nGSM-FastMNMF and develop an expectationmaximization algorithm that works even\nwhen the probability density function of the impulse variables have no\nanalytical expressions. We show that existing heavy-tailed FastMNMF extensions\nare instances of GSM-FastMNMF and derive a new instance based on the\ngeneralized hyperbolic distribution that include the normal-inverse Gaussian,\nStudent's t, and Gaussian distributions as the special cases. Our experiments\nshow that the normalinverse Gaussian FastMNMF outperforms the state-of-the-art\nFastMNMF extensions and ILRMA model in speech enhancement and separation in\nterms of the signal-to-distortion ratio.",
    "descriptor": "",
    "authors": [
      "Mathieu Fontaine",
      "Kouhei Sekiguchi",
      "Aditya Nugraha",
      "Yoshiaki Bando",
      "Kazuyoshi Yoshii"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.05330"
  },
  {
    "id": "arXiv:2205.05333",
    "title": "Implementation and Empirical Evaluation of a Quantum Machine Learning  Pipeline for Local Classification",
    "abstract": "In the current era, quantum resources are extremely limited, and this makes\ndifficult the usage of quantum machine learning (QML) models. Concerning the\nsupervised tasks, a viable approach is the introduction of a quantum locality\ntechnique, which allows the models to focus only on the neighborhood of the\nconsidered element. A well-known locality technique is the k-nearest neighbors\n(k-NN) algorithm, of which several quantum variants have been proposed.\nNevertheless, they have not been employed yet as a preliminary step of other\nQML models, whereas the classical counterpart has already proven successful. In\nthis paper, we present (i) an implementation in Python of a QML pipeline for\nlocal classification, and (ii) its extensive empirical evaluation.\nSpecifically, the quantum pipeline, developed using Qiskit, consists of a\nquantum k-NN and a quantum binary classifier. The results have shown the\nquantum pipeline's equivalence (in terms of accuracy) to its classical\ncounterpart in the ideal case, the validity of locality's application to the\nQML realm, but also the strong sensitivity of the chosen quantum k-NN to\nprobability fluctuations and the better performance of classical baseline\nmethods like the random forest.",
    "descriptor": "\nComments: 33 pages, 8 figures, 9 tables\n",
    "authors": [
      "Enrico Zardini",
      "Enrico Blanzieri",
      "Davide Pastorello"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.05333"
  },
  {
    "id": "arXiv:2205.05334",
    "title": "Collaborative Multi-Radars Tracking by Distributed Auctions",
    "abstract": "In this paper, we present an algorithm which lies in the domain of task\nallocation for a set of static autonomous radars with rotating antennas. It\nallows a set of radars to allocate in a fully decentralized way a set of active\ntracking tasks according to their location, considering that a target can be\ntracked by several radars, in order to improve accuracy with which the target\nis tracked. The allocation algorithm proceeds through a collaborative and fully\ndecentralized auction protocol, using a collaborative auction protocol\n(Consensus Based Bundle Auction algorithm). Our algorithm is based on a double\nuse of our allocation protocol among the radars. The latter begin by allocating\ntargets, then launch a second round of allocation if theyhave resources left,\nin order to improve accuracy on targets already tracked. Our algorithm is also\nable to adapt to dynamism, i.e. to take into account the fact that the targets\nare moving and that the radar(s) most suitable for Tracking them changes as the\nmission progresses. To do this, the algorithm is restarted on a regular basis,\nto ensure that a bid made by a radar can decrease when the target moves away\nfrom it. Since our algorithm is based on collaborative auctions, it does not\nplan the following rounds, assuming that the targets are not predictable enough\nfor this. Our algorithm is however based on radars capable of anticipating the\npositions of short-term targets, thanks to a Kalman filter. The algorithm will\nbe illustrated based on a multi-radar tracking scenario where the radars,\nautonomous, must follow a set of targets in order to reduce the position\nuncertainty of the targets. Standby aspects will not be considered in this\nscenario. It is assumed that the radars can pick up targets in active pursuit,\nwith an area ofuncertainty corresponding to their distance.",
    "descriptor": "",
    "authors": [
      "Pierre Larrenie",
      "C\u00e9dric Buron",
      "Fr\u00e9d\u00e9ric Barbaresco"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2205.05334"
  },
  {
    "id": "arXiv:2205.05335",
    "title": "Deep Depth Completion: A Survey",
    "abstract": "Depth completion aims at predicting dense pixel-wise depth from a sparse map\ncaptured from a depth sensor. It plays an essential role in various\napplications such as autonomous driving, 3D reconstruction, augmented reality,\nand robot navigation. Recent successes on the task have been demonstrated and\ndominated by deep learning based solutions. In this article, for the first\ntime, we provide a comprehensive literature review that helps readers better\ngrasp the research trends and clearly understand the current advances. We\ninvestigate the related studies from the design aspects of network\narchitectures, loss functions, benchmark datasets, and learning strategies with\na proposal of a novel taxonomy that categorizes existing methods. Besides, we\npresent a quantitative comparison of model performance on two widely used\nbenchmark datasets, including an indoor and an outdoor dataset. Finally, we\ndiscuss the challenges of prior works and provide readers with some insights\nfor future research directions.",
    "descriptor": "",
    "authors": [
      "Junjie Hu",
      "Chenyu Bao",
      "Mete Ozay",
      "Chenyou Fan",
      "Qing Gao",
      "Honghai Liu",
      "Tin Lun Lam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.05335"
  },
  {
    "id": "arXiv:2205.05339",
    "title": "An Efficient Summation Algorithm for the Accuracy, Convergence and  Reproducibility of Parallel Numerical Methods",
    "abstract": "Nowadays, parallel computing is ubiquitous in several application fields,\nboth in engineering and science. The computations rely on the floating-point\narithmetic specified by the IEEE754 Standard. In this context, an elementary\nbrick of computation, used everywhere, is the sum of a sequence of numbers.\nThis sum is subject to many numerical errors in floating-point arithmetic. To\nalleviate this issue, we have introduced a new parallel algorithm for summing a\nsequence of floating-point numbers. This algorithm which scales up easily with\nthe number of processors, adds numbers of the same exponents first. In this\narticle, our main contribution is an extensive analysis of its efficiency with\nrespect to several properties: accuracy, convergence and reproducibility. In\norder to show the usefulness of our algorithm, we have chosen a set of\nrepresentative numerical methods which are Simpson, Jacobi, LU factorization\nand the Iterated power method.",
    "descriptor": "",
    "authors": [
      "Farah Benmouhoub",
      "Pierre-Lo\u00efc Garoche",
      "Matthieu Martel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2205.05339"
  },
  {
    "id": "arXiv:2205.05348",
    "title": "NDGGNET-A Node Independent Gate based Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) is an architecture for structural data, and has\nbeen adopted in a mass of tasks and achieved fabulous results, such as link\nprediction, node classification, graph classification and so on. Generally, for\na certain node in a given graph, a traditional GNN layer can be regarded as an\naggregation from one-hop neighbors, thus a set of stacked layers are able to\nfetch and update node status within multi-hops. For nodes with sparse\nconnectivity, it is difficult to obtain enough information through a single GNN\nlayer as not only there are only few nodes directly connected to them but also\ncan not propagate the high-order neighbor information. However, as the number\nof layer increases, the GNN model is prone to over-smooth for nodes with the\ndense connectivity, which resulting in the decrease of accuracy. To tackle this\nissue, in this thesis, we define a novel framework that allows the normal GNN\nmodel to accommodate more layers. Specifically, a node-degree based gate is\nemployed to adjust weight of layers dynamically, that try to enhance the\ninformation aggregation ability and reduce the probability of over-smoothing.\nExperimental results show that our proposed model can effectively increase the\nmodel depth and perform well on several datasets.",
    "descriptor": "",
    "authors": [
      "Ye Tang",
      "Xuesong Yang",
      "Xinrui Liu",
      "Xiwei Zhao",
      "Zhangang Lin",
      "Changping Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.05348"
  },
  {
    "id": "arXiv:2205.05351",
    "title": "Human-Robot Interface to Operate Robotic Systems via Muscle  Synergy-Based Kinodynamic Information Transfer",
    "abstract": "When a human performs a given specific task, it has been known that the\ncentral nervous system controls modularized muscle group, which is called\nmuscle synergy. For human-robot interface design problem, therefore, the muscle\nsynergy can be utilized to reduce the dimensionality of control signal as well\nas the complexity of classifying human posture and motion. In this paper, we\npropose an approach to design a human-robot interface which enables a human\noperator to transfer a kinodynamic control command to robotic systems. A key\nfeature of the proposed approach is that the muscle synergy and corresponding\nactivation curve are employed to calculate a force generated by a tool at the\nrobot end effector. A test bed for experiments consisted of two armband type\nsurface electromyography sensors, an RGB-d camera, and a Kinova Gen2 robotic\nmanipulator to verify the proposed approach. The result showed that both force\nand position commands could be successfully transferred to the robotic\nmanipulator via our muscle synergy-based kinodynamic interface.",
    "descriptor": "\nComments: 4 pages, 8 figures, 1 table, in Proceedings of the 19th Conference on Ubiquitous Robots(UR), July 4-6, 2022, Jeju, Korea\n",
    "authors": [
      "Janghyeon Kim",
      "Dae Han Sim",
      "Ho-Jin Jung",
      "Ji-Hyeon Yoo",
      "Changjae Lee",
      "Han Ul Yoon"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.05351"
  },
  {
    "id": "arXiv:2205.05357",
    "title": "A Comprehensive Survey of Automated Audio Captioning",
    "abstract": "Automated audio captioning, a task that mimics human perception as well as\ninnovatively links audio processing and natural language processing, has\noverseen much progress over the last few years. Audio captioning requires\nrecognizing the acoustic scene, primary audio events and sometimes the spatial\nand temporal relationship between events in an audio clip. It also requires\ndescribing these elements by a fluent and vivid sentence. Deep learning-based\napproaches are widely adopted to tackle this problem. This current paper\nsituates itself as a comprehensive review covering the benchmark datasets,\nexisting deep learning techniques and the evaluation metrics in automated audio\ncaptioning.",
    "descriptor": "",
    "authors": [
      "Xuenan Xu",
      "Mengyue Wu",
      "Kai Yu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.05357"
  },
  {
    "id": "arXiv:2205.05361",
    "title": "Reducing a complex two-sided smartwatch examination for Parkinson's  Disease to an efficient one-sided examination preserving machine learning  accuracy",
    "abstract": "Sensors from smart consumer devices have demonstrated high potential to serve\nas digital biomarkers in the identification of movement disorders in recent\nyears. With the usage of broadly available smartwatches we have recorded\nparticipants performing technology-based assessments in a prospective study to\nresearch Parkinson's Disease (PD). In total, 504 participants, including PD\npatients, differential diagnoses (DD) and healthy controls (HC), were captured\nwith a comprehensive system utilizing two smartwatches and two smartphones. To\nthe best of our knowledge, this study provided the largest PD sample size of\ntwo-hand synchronous smartwatch measurements. To establish a future easy-to use\nhome-based assessment system in PD screening, we systematically evaluated the\nperformance of the system based on a significantly reduced set of assessments\nwith only one-sided measures and assessed, whether we can maintain\nclassification accuracy.",
    "descriptor": "",
    "authors": [
      "Alexander Brenner",
      "Michael Fujarski",
      "Tobias Warnecke",
      "Julian Varghese"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05361"
  },
  {
    "id": "arXiv:2205.05363",
    "title": "Improved maximin fair allocation of indivisible items to three agents",
    "abstract": "We consider the problem of approximate maximin share (MMS) allocation of\nindivisible items among three agents with additive valuation functions. For\ngoods, we show that an $\\frac{11}{12}$ - MMS allocation always exists,\nimproving over the previously known bound of $\\frac{8}{9}$ . Moreover, in our\nallocation, we can prespecify an agent that is to receive her full proportional\nshare (PS); we also present examples showing that for such allocations the\nratio of $\\frac{11}{12}$ is best possible. For chores, we show that a\n$\\frac{19}{18}$-MMS allocation always exists. Also in this case, we can\nprespecify an agent that is to receive no more than her PS, and we present\nexamples showing that for such allocations the ratio of $\\frac{19}{18}$ is best\npossible.",
    "descriptor": "",
    "authors": [
      "Uriel Feige",
      "Alexey Norkin"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2205.05363"
  },
  {
    "id": "arXiv:2205.05368",
    "title": "Pre-trained Language Models as Re-Annotators",
    "abstract": "Annotation noise is widespread in datasets, but manually revising a flawed\ncorpus is time-consuming and error-prone. Hence, given the prior knowledge in\nPre-trained Language Models and the expected uniformity across all annotations,\nwe attempt to reduce annotation noise in the corpus through two tasks\nautomatically: (1) Annotation Inconsistency Detection that indicates the\ncredibility of annotations, and (2) Annotation Error Correction that rectifies\nthe abnormal annotations.\nWe investigate how to acquire semantic sensitive annotation representations\nfrom Pre-trained Language Models, expecting to embed the examples with\nidentical annotations to the mutually adjacent positions even without\nfine-tuning. We proposed a novel credibility score to reveal the likelihood of\nannotation inconsistencies based on the neighbouring consistency. Then, we\nfine-tune the Pre-trained Language Models based classifier with\ncross-validation for annotation correction. The annotation corrector is further\nelaborated with two approaches: (1) soft labelling by Kernel Density Estimation\nand (2) a novel distant-peer contrastive loss.\nWe study the re-annotation in relation extraction and create a new manually\nrevised dataset, Re-DocRED, for evaluating document-level re-annotation. The\nproposed credibility scores show promising agreement with human revisions,\nachieving a Binary F1 of 93.4 and 72.5 in detecting inconsistencies on TACRED\nand DocRED respectively. Moreover, the neighbour-aware classifiers based on\ndistant-peer contrastive learning and uncertain labels achieve Macro F1 up to\n66.2 and 57.8 in correcting annotations on TACRED and DocRED respectively.\nThese improvements are not merely theoretical: Rather, automatically denoised\ntraining sets demonstrate up to 3.6% performance improvement for\nstate-of-the-art relation extraction models.",
    "descriptor": "\nComments: Thesis of Master of Science by Research (M.Res) in Linguistics with Distinction; University of Edinburgh, 2022; 107 pages\n",
    "authors": [
      "Chang Shu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05368"
  },
  {
    "id": "arXiv:2205.05369",
    "title": "AutoLC: Search Lightweight and Top-Performing Architecture for Remote  Sensing Image Land-Cover Classification",
    "abstract": "Land-cover classification has long been a hot and difficult challenge in\nremote sensing community. With massive High-resolution Remote Sensing (HRS)\nimages available, manually and automatically designed Convolutional Neural\nNetworks (CNNs) have already shown their great latent capacity on HRS\nland-cover classification in recent years. Especially, the former can achieve\nbetter performance while the latter is able to generate lightweight\narchitecture. Unfortunately, they both have shortcomings. On the one hand,\nbecause manual CNNs are almost proposed for natural image processing, it\nbecomes very redundant and inefficient to process HRS images. On the other\nhand, nascent Neural Architecture Search (NAS) techniques for dense prediction\ntasks are mainly based on encoder-decoder architecture, and just focus on the\nautomatic design of the encoder, which makes it still difficult to recover the\nrefined mapping when confronting complicated HRS scenes.\nTo overcome their defects and tackle the HRS land-cover classification\nproblems better, we propose AutoLC which combines the advantages of two\nmethods. First, we devise a hierarchical search space and gain the lightweight\nencoder underlying gradient-based search strategy. Second, we meticulously\ndesign a lightweight but top-performing decoder that is adaptive to the\nsearched encoder of itself. Finally, experimental results on the LoveDA\nland-cover dataset demonstrate that our AutoLC method outperforms the\nstate-of-art manual and automatic methods with much less computational\nconsumption.",
    "descriptor": "\nComments: Early accepted by ICPR 2022\n",
    "authors": [
      "Chenyu Zheng",
      "Junjue Wang",
      "Ailong Ma",
      "Yanfei Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.05369"
  },
  {
    "id": "arXiv:2205.05383",
    "title": "Automated differential equation solver based on the parametric  approximation optimization",
    "abstract": "The numerical methods for differential equation solution allow obtaining a\ndiscrete field that converges towards the solution if the method is applied to\nthe correct problem. Nevertheless, the numerical methods have the restricted\nclass of the equations, on which the convergence with a given parameter set or\nrange is proved. Only a few \"cheap and dirty\" numerical methods converge on a\nwide class of equations without parameter tuning with the lower approximation\norder price. The article presents a method that uses an optimization algorithm\nto obtain a solution using the parameterized approximation. The result may not\nbe as precise as an expert one. However, it allows solving the wide class of\nequations in an automated manner without the algorithm's parameters change.",
    "descriptor": "",
    "authors": [
      "Alexander Hvatov",
      "Tatiana Tikhonova"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05383"
  },
  {
    "id": "arXiv:2205.05387",
    "title": "A game comonadic account of Courcelle and Feferman-Vaught-Mostowski  theorems",
    "abstract": "Game comonads, introduced by Abramsky, Dawar and Wang, and developed by\nAbramsky and Shah, give a categorical semantics for model comparison games. We\npresent an axiomatic account of Feferman-Vaught-Mostowski (FVM) composition\ntheorems within the game comonad framework, parameterized by the model\ncomparison game. In a uniform way, we produce compositionality results for the\nlogic in question, and its positive existential and counting quantifier\nvariants.\nSecondly, we extend game comonads to the second order setting, specifically\nin the case of Monadic Second Order (MSO) logic. We then generalize our FVM\ntheorems to the second order case. We conclude with an abstract formulation of\nCourcelle's algorithmic meta-theorem, exploiting our earlier developments. This\nis instantiated to recover well-known bounded tree-width and bounded\nclique-width Courcelle theorems for MSO on graphs.",
    "descriptor": "",
    "authors": [
      "Tom\u00e1\u0161 Jakl",
      "Dan Marsden",
      "Nihil Shah"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.05387"
  },
  {
    "id": "arXiv:2205.05389",
    "title": "Machine Learning to Support Triage of Children at Risk for Epileptic  Seizures in the Pediatric Intensive Care Unit",
    "abstract": "Objective: Epileptic seizures are relatively common in critically-ill\nchildren admitted to the pediatric intensive care unit (PICU) and thus serve as\nan important target for identification and treatment. Most of these seizures\nhave no discernible clinical manifestation but still have a significant impact\non morbidity and mortality. Children that are deemed at risk for seizures\nwithin the PICU are monitored using continuous-electroencephalogram (cEEG).\ncEEG monitoring cost is considerable and as the number of available machines is\nalways limited, clinicians need to resort to triaging patients according to\nperceived risk in order to allocate resources. This research aims to develop a\ncomputer aided tool to improve seizures risk assessment in critically-ill\nchildren, using an ubiquitously recorded signal in the PICU, namely the\nelectrocardiogram (ECG). Approach: A novel data-driven model was developed at a\npatient-level approach, based on features extracted from the first hour of ECG\nrecording and the clinical data of the patient. Main results: The most\npredictive features were the age of the patient, the brain injury as coma\netiology and the QRS area. For patients without any prior clinical data, using\none hour of ECG recording, the classification performance of the random forest\nclassifier reached an area under the receiver operating characteristic curve\n(AUROC) score of 0.84. When combining ECG features with the patients clinical\nhistory, the AUROC reached 0.87. Significance: Taking a real clinical scenario,\nwe estimated that our clinical decision support triage tool can improve the\npositive predictive value by more than 59% over the clinical standard.",
    "descriptor": "\nComments: 8 pages, 9 figures, submitted to Physiological Measurement\n",
    "authors": [
      "Raphael Azriel",
      "Cecil D. Hahn",
      "Thomas De Cooman",
      "Sabine Van Huffel",
      "Eric T. Payne",
      "Kristin L. McBain",
      "Danny Eytan",
      "Joachim A. Behar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.05389"
  },
  {
    "id": "arXiv:2205.05390",
    "title": "AutoKE: An automatic knowledge embedding framework for scientific  machine learning",
    "abstract": "Imposing physical constraints on neural networks as a method of knowledge\nembedding has achieved great progress in solving physical problems described by\ngoverning equations. However, for many engineering problems, governing\nequations often have complex forms, including complex partial derivatives or\nstochastic physical fields, which results in significant inconveniences from\nthe perspective of implementation. In this paper, a scientific machine learning\nframework, called AutoKE, is proposed, and a reservoir flow problem is taken as\nan instance to demonstrate that this framework can effectively automate the\nprocess of embedding physical knowledge. In AutoKE, an emulator comprised of\ndeep neural networks (DNNs) is built for predicting the physical variables of\ninterest. An arbitrarily complex equation can be parsed and automatically\nconverted into a computational graph through the equation parser module, and\nthe fitness of the emulator to the governing equation is evaluated via\nautomatic differentiation. Furthermore, the fixed weights in the loss function\nare substituted with adaptive weights by incorporating the Lagrangian dual\nmethod. Neural architecture search (NAS) is also introduced into the AutoKE to\nselect an optimal network architecture of the emulator according to the\nspecific problem. Finally, we apply transfer learning to enhance the\nscalability of the emulator. In experiments, the framework is verified by a\nseries of physical problems in which it can automatically embed physical\nknowledge into an emulator without heavy hand-coding. The results demonstrate\nthat the emulator can not only make accurate predictions, but also be applied\nto similar problems with high efficiency via transfer learning.",
    "descriptor": "",
    "authors": [
      "Mengge Du",
      "Yuntian Chen",
      "Dongxiao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.05390"
  },
  {
    "id": "arXiv:2205.05391",
    "title": "Query-Based Keyphrase Extraction from Long Documents",
    "abstract": "Transformer-based architectures in natural language processing force input\nsize limits that can be problematic when long documents need to be processed.\nThis paper overcomes this issue for keyphrase extraction by chunking the long\ndocuments while keeping a global context as a query defining the topic for\nwhich relevant keyphrases should be extracted. The developed system employs a\npre-trained BERT model and adapts it to estimate the probability that a given\ntext span forms a keyphrase. We experimented using various context sizes on two\npopular datasets, Inspec and SemEval, and a large novel dataset. The presented\nresults show that a shorter context with a query overcomes a longer one without\nthe query on long documents.",
    "descriptor": "",
    "authors": [
      "Martin Docekal",
      "Pavel Smrz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.05391"
  },
  {
    "id": "arXiv:2205.05392",
    "title": "Algebraic Presentation of Semifree Monads",
    "abstract": "Monads and their composition via distributive laws have many applications in\nprogram semantics and functional programming. For many interesting monads,\ndistributive laws fail to exist, and this has motivated investigations into\nweaker notions. In this line of research, Petri\\c{s}an and Sarkis recently\nintroduced a construction called the semifree monad in order to study\nsemialgebras for a monad and weak distributive laws. In this paper, we prove\nthat an algebraic presentation of the semifree monad M^s on a monad M can be\nobtained uniformly from an algebraic presentation of M. This result was\nconjectured by Petri\\c{s}an and Sarkis. We also show that semifree monads are\nideal monads, that the semifree construction is not a monad transformer, and\nthat the semifree construction is a comonad on the category of monads.",
    "descriptor": "\nComments: In Proceedings of CMCS 2022\n",
    "authors": [
      "Alo\u00efs Rosset",
      "Helle Hvid Hansen",
      "J\u00f6rg Endrullis"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2205.05392"
  },
  {
    "id": "arXiv:2205.05393",
    "title": "CVTT: Cross-Validation Through Time",
    "abstract": "The practical aspects of evaluating recommender systems is an actively\ndiscussed topic in the research community. While many current evaluation\ntechniques bring performance down to a single-value metric as a straightforward\napproach for model comparison, it is based on a strong assumption of the\nmethods' stable performance over time. In this paper, we argue that leaving out\na method's continuous performance can lead to losing valuable insight into\njoint data-method effects. We propose the Cross-Validation Thought Time (CVTT)\ntechnique to perform more detailed evaluations, which focus on model\ncross-validation performance over time. Using the proposed technique, we\nconduct a detailed analysis of popular RecSys algorithms' performance against\nvarious metrics and datasets. We also compare several data preparation and\nevaluation strategies to analyze their impact on model performance. Our results\nshow that model performance can vary significantly over time, and both data and\nevaluation setup can have a marked effect on it.",
    "descriptor": "",
    "authors": [
      "Sergey Kolesnikov",
      "Mikhail Andronov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05393"
  },
  {
    "id": "arXiv:2205.05396",
    "title": "A Survey on Fairness for Machine Learning on Graphs",
    "abstract": "Nowadays, the analysis of complex phenomena modeled by graphs plays a crucial\nrole in many real-world application domains where decisions can have a strong\nsocietal impact. However, numerous studies and papers have recently revealed\nthat machine learning models could lead to potential disparate treatment\nbetween individuals and unfair outcomes. In that context, algorithmic\ncontributions for graph mining are not spared by the problem of fairness and\npresent some specific challenges related to the intrinsic nature of graphs: (1)\ngraph data is non-IID, and this assumption may invalidate many existing studies\nin fair machine learning, (2) suited metric definitions to assess the different\ntypes of fairness with relational data and (3) algorithmic challenge on the\ndifficulty of finding a good trade-off between model accuracy and fairness.\nThis survey is the first one dedicated to fairness for relational data. It aims\nto present a comprehensive review of state-of-the-art techniques in fairness on\ngraph mining and identify the open challenges and future trends. In particular,\nwe start by presenting several sensible application domains and the associated\ngraph mining tasks with a focus on edge prediction and node classification in\nthe sequel. We also recall the different metrics proposed to evaluate potential\nbias at different levels of the graph mining process; then we provide a\ncomprehensive overview of recent contributions in the domain of fair machine\nlearning for graphs, that we classify into pre-processing, in-processing and\npost-processing models. We also propose to describe existing graph data,\nsynthetic and real-world benchmarks. Finally, we present in detail five\npotential promising directions to advance research in studying algorithmic\nfairness on graphs.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Manvi Choudhary",
      "Charlotte Laclau",
      "Christine Largeron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05396"
  },
  {
    "id": "arXiv:2205.05398",
    "title": "Stochastic Variational Smoothed Model Checking",
    "abstract": "Model-checking for parametric stochastic models can be expressed as checking\nthe satisfaction probability of a certain property as a function of the\nparameters of the model. Smoothed model checking (smMC) leverages Gaussian\nProcesses (GP) to infer the satisfaction function over the entire parameter\nspace from a limited set of observations obtained via simulation. This approach\nprovides accurate reconstructions with statistically sound quantification of\nthe uncertainty. However, it inherits the scalability issues of GP. In this\npaper, we exploit recent advances in probabilistic machine learning to push\nthis limitation forward, making Bayesian inference of smMC scalable to larger\ndatasets, enabling its application to larger models in terms of the dimension\nof the parameter set. We propose Stochastic Variational Smoothed Model Checking\n(SV-smMC), a solution that exploits stochastic variational inference (SVI) to\napproximate the posterior distribution of the smMC problem. The strength and\nflexibility of SVI make SV-smMC applicable to two alternative probabilistic\nmodels: Gaussian Processes (GP) and Bayesian Neural Networks (BNN). Moreover,\nSVI makes inference easily parallelizable and it enables GPU acceleration. In\nthis paper, we compare the performances of smMC against those of SV-smMC by\nlooking at the scalability, the computational efficiency and at the accuracy of\nthe reconstructed satisfaction function.",
    "descriptor": "",
    "authors": [
      "Luca Bortolussi",
      "Francesca Cairoli",
      "Ginevra Carbone",
      "Paolo Pulcini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.05398"
  },
  {
    "id": "arXiv:2205.05403",
    "title": "Uptime-Optimized Cloud Architecture as a Brokered Service",
    "abstract": "Enterprise workloads usually call for an uptime service level agreement (SLA)\nat the pain of contractual penalty in the event of slippage. Often, the\nstrategy is to introduce ad-hoc HA (High Availability) mechanisms in response.\nImplemented solutions that we surveyed do not mathematically map their\navailability model to the required uptime SLA and to any expected penalty\npayout. In most client cases that we observed, this either resulted in an\nover-engineered solution that had more redundancies than was required, or in an\ninadequate solution that could potentially slip on the system uptime SLA\nstipulated in the contract. In this paper, we propose a framework backed by a\nmodel, to automatically determine the HA-enabled solution with the least TCO\n(total cost of ownership) for a given uptime SLA and slippage penalty. We\nattempt to establish that our work is best implemented as a brokered service\nthat recommends an uptime-optimized cloud architecture.",
    "descriptor": "\nComments: Published in the Proceedings of the 2017 47th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshop (DSN-W)\n",
    "authors": [
      "Sreekrishnan Venkateswaran",
      "Santonu Sarkar"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.05403"
  },
  {
    "id": "arXiv:2205.05404",
    "title": "Recurrent Encoder-Decoder Networks for Vessel Trajectory Prediction with  Uncertainty Estimation",
    "abstract": "Recent deep learning methods for vessel trajectory prediction are able to\nlearn complex maritime patterns from historical Automatic Identification System\n(AIS) data and accurately predict sequences of future vessel positions with a\nprediction horizon of several hours. However, in maritime surveillance\napplications, reliably quantifying the prediction uncertainty can be as\nimportant as obtaining high accuracy. This paper extends deep learning\nframeworks for trajectory prediction tasks by exploring how recurrent\nencoder-decoder neural networks can be tasked not only to predict but also to\nyield a corresponding prediction uncertainty via Bayesian modeling of epistemic\nand aleatoric uncertainties. We compare the prediction performance of two\ndifferent models based on labeled or unlabeled input data to highlight how\nuncertainty quantification and accuracy can be improved by using, if available,\nadditional information on the intention of the ship (e.g., its planned\ndestination).",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Samuele Capobianco",
      "Nicola Forti",
      "Leonardo M. Millefiori",
      "Paolo Braca",
      "Peter Willett"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.05404"
  },
  {
    "id": "arXiv:2205.05406",
    "title": "Knowledge-powered Explainable Artificial Intelligence (XAI) for Network  Automation Towards 6G",
    "abstract": "Communication networks are becoming increasingly complex towards 6G. Manual\nmanagement is no longer an option for network operators. Network automation has\nbeen widely discussed in the networking community, and it is a sensible means\nto manage the complex communication network. Deep learning models developed to\nenable network automation for given operation practices have the limitations of\n1) lack of explainability and 2) inapplicable across different networks and/or\nnetwork settings. To tackle the above issues, in this article we propose a new\nknowledge-powered framework that provides a human-understandable explainable\nartificial intelligence (XAI) agent for network automation. A case study of\npath selection is developed to demonstrate the feasibility of the proposed\nframework. Research on network automation is still in its infancy. Therefore,\nat the end of this article, we provide a list of challenges and open issues\nthat can guide further research in this important area.",
    "descriptor": "",
    "authors": [
      "Yulei Wu",
      "Guozhi Lin",
      "Jingguo Ge"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.05406"
  },
  {
    "id": "arXiv:2205.05412",
    "title": "An Objective Method for Pedestrian Occlusion Level Classification",
    "abstract": "Pedestrian detection is among the most safety-critical features of driver\nassistance systems for autonomous vehicles. One of the most complex detection\nchallenges is that of partial occlusion, where a target object is only\npartially available to the sensor due to obstruction by another foreground\nobject. A number of current pedestrian detection benchmarks provide annotation\nfor partial occlusion to assess algorithm performance in these scenarios,\nhowever each benchmark varies greatly in their definition of the occurrence and\nseverity of occlusion. In addition, current occlusion level annotation methods\ncontain a high degree of subjectivity by the human annotator. This can lead to\ninaccurate or inconsistent reporting of an algorithm's detection performance\nfor partially occluded pedestrians, depending on which benchmark is used. This\nresearch presents a novel, objective method for pedestrian occlusion level\nclassification for ground truth annotation. Occlusion level classification is\nachieved through the identification of visible pedestrian keypoints and through\nthe use of a novel, effective method of 2D body surface area estimation.\nExperimental results demonstrate that the proposed method reflects the\npixel-wise occlusion level of pedestrians in images and is effective for all\nforms of occlusion, including challenging edge cases such as self-occlusion,\ntruncation and inter-occluding pedestrians.",
    "descriptor": "",
    "authors": [
      "Shane Gilroy",
      "Martin Glavin",
      "Edward Jones",
      "Darragh Mullins"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.05412"
  },
  {
    "id": "arXiv:2205.05413",
    "title": "Compact and Efficient NTRU-based KEM with Scalable Ciphertext  Compression",
    "abstract": "The NTRU lattice is a promising candidate to construct practical\ncryptosystems resistant to quantum computing attacks, and particularly plays a\nleading role in the ongoing NIST post-quantum cryptography standardization. On\nthe one hand, it is benefited from a strong security guarantee since it has\nessentially not been broken over 24 years. On the other hand, all the known\npatent threats against NTRU have expired, which is deemed a critical factor for\nconsideration when deploying PQC algorithms in reality. Nevertheless, there are\nstill some obstacles to the computational efficiency and bandwidth complexity\nof NTRU-based constructions of key encapsulation mechanisms (KEM). To address\nthese issues, we propose a compact and efficient KEM based on the NTRU lattice,\ncalled CTRU, by introducing a scalable ciphertext compression technique. It\ndemonstrates a new approach to decrypting NTRU ciphertext, where the plaintext\nmessage is recovered with the aid of our decoding algorithm in the scalable\n${E}_8$ lattice. The instantiation of CTRU is over the NTT-friendly rings of\nthe form $\\mathbb{Z}_q[x]/(x^{n}-x^{n/2}+1)$. To our knowledge, our CTRU is the\nmost bandwidth efficient KEM based on the NTRU lattice up to now. In addition,\ncompared to other NTRU-based KEM schemes, CTRU has stronger security against\nknown attacks, enjoys more robust CCA security reduction (starting from IND-CPA\nrather than OW-CPA), and its encapsulation and decapsulation processes are also\namong the most efficient. When compared to the NIST Round 3 finalist NTRU-HRSS,\nour CTRU-768 has $15\\%$ smaller ciphertext size and its security is\nstrengthened by $(45,40)$ bits for classical and quantum security respectively.\nWhen compared to the NIST Round 3 finalist Kyber that is based on the\nModule-LWE assumption, CTRU has both smaller bandwidth and lower error\nprobabilities at about the same security level.",
    "descriptor": "",
    "authors": [
      "Zhichuang Liang",
      "Boyue Fang",
      "Jieyu Zheng",
      "Yunlei Zhao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.05413"
  },
  {
    "id": "arXiv:2205.05414",
    "title": "Recommending Research Papers to Chemists: A Specialized Interface for  Chemical Entity Exploration",
    "abstract": "Researchers and scientists increasingly rely on specialized information\nretrieval (IR) or recommendation systems (RS) to support them in their daily\nresearch tasks. Paper recommender systems are one such tool scientists use to\nstay on top of the ever-increasing number of academic publications in their\nfield. Improving research paper recommender systems is an active research\nfield. However, less research has focused on how the interfaces of research\npaper recommender systems can be tailored to suit the needs of different\nresearch domains. For example, in the field of biomedicine and chemistry,\nresearchers are not only interested in textual relevance but may also want to\ndiscover or compare the contained chemical entity information found in a\npaper's full text. Existing recommender systems for academic literature do not\nsupport the discovery of this non-textual, but semantically valuable, chemical\nentity data. We present the first implementation of a specialized chemistry\npaper recommender system capable of visualizing the contained chemical\nstructures, chemical formulae, and synonyms for chemical compounds within the\ndocument's full text. We review existing tools and related research in this\nfield before describing the implementation of our ChemVis system. With the help\nof chemists, we are expanding the functionality of ChemVis, and will perform an\nevaluation of recommendation performance and usability in future work.",
    "descriptor": "\nComments: Author's preprint version. Final publication to appear in Proceedings of ACM/IEEE Joint Conference on Digital Libraries (JCDL'22)\n",
    "authors": [
      "Corinna Breitinger",
      "Kay Herklotz",
      "Tim Flegelskamp",
      "Norman Meuschke"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.05414"
  },
  {
    "id": "arXiv:2205.05419",
    "title": "Multi-Label Logo Recognition and Retrieval based on Weighted Fusion of  Neural Features",
    "abstract": "Logo classification is a particular case of image classification, since these\nmay contain only text, images, or a combination of both. In this work, we\npropose a system for the multi-label classification and similarity search of\nlogo images. The method allows obtaining the most similar logos on the basis of\ntheir shape, color, business sector, semantics, general characteristics, or a\ncombination of such features established by the user. This is done by employing\na set of multi-label networks specialized in certain characteristics of logos.\nThe features extracted from these networks are combined to perform the\nsimilarity search according to the search criteria established. Since the text\nof logos is sometimes irrelevant for the classification, a preprocessing stage\nis carried out to remove it, thus improving the overall performance. The\nproposed approach is evaluated using the European Union Trademark (EUTM)\ndataset, structured with the hierarchical Vienna classification system, which\nincludes a series of metadata with which to index trademarks. We also make a\ncomparison between well known logo topologies and Vienna in order to help\ndesigners understand their correspondences. The experimentation carried out\nattained reliable performance results, both quantitatively and qualitatively,\nwhich outperformed the state-of-the-art results. In addition, since the\nsemantics and classification of brands can often be subjective, we also\nsurveyed graphic design students and professionals in order to assess the\nreliability of the proposed method.",
    "descriptor": "",
    "authors": [
      "Marisa Bernabeu",
      "Antonio Javier Gallego",
      "Antonio Pertusa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.05419"
  },
  {
    "id": "arXiv:2205.05424",
    "title": "\"If it didn't happen, why would I change my decision?\": How Judges  Respond to Counterfactual Explanations for the Public Safety Assessment",
    "abstract": "Researchers and policymakers are interested in algorithmic explanations as a\nmechanism for enabling more fair and responsible decision-making. In this\nstudy, we shed light on how judges interpret and respond to algorithmic\nexplanations in the context of pretrial risk assessment instruments (PRAI). We\nfound that, at first, all judges misinterpreted the counterfactuals in the\nexplanations as real -- rather than hypothetical -- changes to defendants'\ncriminal history profiles. Once judges understood the counterfactuals, they\nignored them, preferring to make decisions based solely on the actual details\nof the defendant in question. Our findings suggest that using (at least this\nkind of) explanations to improve human and AI collaboration is not\nstraightforward.",
    "descriptor": "\nComments: Accepted at CHI'22 Workshop on Human-Centered Perspectives in Explainable AI (HCXAI)\n",
    "authors": [
      "Yaniv Yacoby",
      "Ben Green",
      "Christopher L. Griffin",
      "Finale Doshi Velez"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.05424"
  },
  {
    "id": "arXiv:2205.05426",
    "title": "RustSEG -- Automated segmentation of corrosion using deep learning",
    "abstract": "The inspection of infrastructure for corrosion remains a task that is\ntypically performed manually by qualified engineers or inspectors. This task of\ninspection is laborious, slow, and often requires complex access. Recently,\ndeep learning based algorithms have revealed promise and performance in the\nautomatic detection of corrosion. However, to date, research regarding the\nsegmentation of images for automated corrosion detection has been limited, due\nto the lack of availability of per-pixel labelled data sets which are required\nfor model training. Herein, a novel deep learning approach (termed RustSEG) is\npresented, that can accurately segment images for automated corrosion\ndetection, without the requirement of per-pixel labelled data sets for\ntraining. The RustSEG method will first, using deep learning techniques,\ndetermine if corrosion is present in an image (i.e. a classification task), and\nthen if corrosion is present, the model will examine what pixels in the\noriginal image contributed to that classification decision. Finally, the method\ncan refine its predictions into a pixel-level segmentation mask. In ideal\ncases, the method is able to generate precise masks of corrosion in images,\ndemonstrating that the automated segmentation of corrosion without per-pixel\ntraining data is possible, addressing a significant hurdle in automated\ninfrastructure inspection.",
    "descriptor": "",
    "authors": [
      "B. Burton",
      "W.T. Nash",
      "N. Birbilis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Materials Science (cond-mat.mtrl-sci)"
    ],
    "url": "https://arxiv.org/abs/2205.05426"
  },
  {
    "id": "arXiv:2205.05429",
    "title": "Learning a Better Control Barrier Function",
    "abstract": "Control barrier functions (CBF) are widely used in safety-critical\ncontrollers. However, the construction of valid CBFs is well known to be\nchallenging, especially for nonlinear or non-convex constraints and high\nrelative degree systems. On the other hand, finding a conservative CBF that\nonly recovers a portion of the true safe set is usually possible. In this work,\nstarting from a \"conservative\" handcrafted control barrier function (HCBF), we\ndevelop a method to find a control barrier function that recovers a reasonably\nlarger portion of the safe set. Using a different approach, by incorporating\nthe hard constraints into an optimal control problem, e.g., MPC, we can safely\ngenerate solutions within the true safe set. Nevertheless, such an approach is\nusually computationally expensive and may not lend itself to real-time\nimplementations. We propose to combine the two methods. During training, we\nutilize MPC to collect safe trajectory data. Thereafter, we train a neural\nnetwork to estimate the difference between the HCBF and the CBF that recovers a\ncloser solution to the true safe set. Using the proposed approach, we can\ngenerate a safe controller that is less conservative and computationally\nefficient. We validate our approach on three systems: a second-order\nintegrator, ball-on-beam, and unicycle.",
    "descriptor": "\nComments: Submitted to IEEE Conference on Decision and Control (CDC) 2022\n",
    "authors": [
      "Bolun Dai",
      "Prashanth Krishnamurthy",
      "Farshad Khorrami"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.05429"
  },
  {
    "id": "arXiv:2205.05433",
    "title": "ALIGNMEET: A Comprehensive Tool for Meeting Annotation, Alignment, and  Evaluation",
    "abstract": "Summarization is a challenging problem, and even more challenging is to\nmanually create, correct, and evaluate the summaries. The severity of the\nproblem grows when the inputs are multi-party dialogues in a meeting setup. To\nfacilitate the research in this area, we present ALIGNMEET, a comprehensive\ntool for meeting annotation, alignment, and evaluation. The tool aims to\nprovide an efficient and clear interface for fast annotation while mitigating\nthe risk of introducing errors. Moreover, we add an evaluation mode that\nenables a comprehensive quality evaluation of meeting minutes. To the best of\nour knowledge, there is no such tool available. We release the tool as open\nsource. It is also directly installable from PyPI.",
    "descriptor": "\nComments: Accepted to LREC22\n",
    "authors": [
      "Peter Pol\u00e1k",
      "Muskaan Singh",
      "Anna Nedoluzhko",
      "Ond\u0159ej Bojar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.05433"
  },
  {
    "id": "arXiv:2205.05434",
    "title": "A polynomial time algorithm for local testability and its level",
    "abstract": "A locally testable semigroup S is a semigroup with the property that for some\nnonnegative integer k, called the order or level of local testability, two\nwords u and v in some set of generators for semigroup S are equal in the\nsemigroup if (1) the prefix and suffix of the words of length k coincide, and\n(2) the set of intermediate substrings of length k of the words coincide. The\nlocal testability problem for semigroups is, given a finite semigroup, to\ndecide, if the semigroup is locally testable or not. Recently, we introduced a\npolynomial time algorithm for the local testability problem and to find the\nlevel of local testability for semigroups based on our previous description of\nidentities of $k$-testable semigroups and the structure of locally testable\nsemigroups. The first part of the algorithm we introduce solves the local\ntestability problem. The second part of the algorithm finds the order of local\ntestability of a semigroup. The algorithm is of quadratic order where n is the\norder of the semigroup.",
    "descriptor": "\nComments: 9 pages, no figures, found linear algorithm for study class of local testability of formal languages\n",
    "authors": [
      "A.N. Trahtman"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2205.05434"
  },
  {
    "id": "arXiv:2205.05435",
    "title": "Building for Tomorrow: Assessing the Temporal Persistence of Text  Classifiers",
    "abstract": "Performance of text classification models can drop over time when new data to\nbe classified is more distant in time from the data used for training, due to\nnaturally occurring changes in the data, such as vocabulary change. A solution\nto this is to continually label new data to retrain the model, which is,\nhowever, often unaffordable to be performed regularly due to its associated\ncost. This raises important research questions on the design of text\nclassification models that are intended to persist over time: do all embedding\nmodels and classification algorithms exhibit similar performance drops over\ntime and is the performance drop more prominent in some tasks or datasets than\nothers? With the aim of answering these research questions, we perform\nlongitudinal classification experiments on three datasets spanning between 6\nand 19 years. Findings from these experiments inform the design of text\nclassification models with the aim of preserving performance over time,\ndiscussing the extent to which one can rely on classification models trained\nfrom temporally distant training data, as well as how the characteristics of\nthe dataset impact this.",
    "descriptor": "",
    "authors": [
      "Rabab Alkhalifa",
      "Elena Kochkina",
      "Arkaitz Zubiaga"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.05435"
  },
  {
    "id": "arXiv:2205.05439",
    "title": "Injection Attacks Reloaded: Tunnelling Malicious Payloads over DNS",
    "abstract": "The traditional design principle for Internet protocols indicates: \"Be strict\nwhen sending and tolerant when receiving\" [RFC1958], and DNS is no exception to\nthis. The transparency of DNS in handling the DNS records, also standardised\nspecifically for DNS [RFC3597], is one of the key features that made it such a\npopular platform facilitating a constantly increasing number of new\napplications. An application simply creates a new DNS record and can instantly\nstart distributing it over DNS without requiring any changes to the DNS servers\nand platforms. Our Internet wide study confirms that more than 1.3M (96% of\ntested) open DNS resolvers are standard compliant and treat DNS records\ntransparently.\nIn this work we show that this `transparency' introduces a severe\nvulnerability in the Internet: we demonstrate a new method to launch string\ninjection attacks by encoding malicious payloads into DNS records. We show how\nto weaponise such DNS records to attack popular applications. For instance, we\napply string injection to launch a new type of DNS cache poisoning attack,\nwhich we evaluated against a population of open resolvers and found 105K to be\nvulnerable. Such cache poisoning cannot be prevented with common setups of\nDNSSEC. Our attacks apply to internal as well as to public services, for\ninstance, we reveal that all eduroam services are vulnerable to our injection\nattacks, allowing us to launch exploits ranging from unauthorised access to\neduroam networks to resource starvation. Depending on the application, our\nattacks cause system crashes, data corruption and leakage, degradation of\nsecurity, and can introduce remote code execution and arbitrary errors.\nIn our evaluation of the attacks in the Internet we find that all the\nstandard compliant open DNS resolvers we tested allow our injection attacks\nagainst applications and users on their networks.",
    "descriptor": "",
    "authors": [
      "Philipp Jeitner",
      "Haya Shulman"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.05439"
  },
  {
    "id": "arXiv:2205.05446",
    "title": "Predictive Compliance Monitoring in Process-Aware Information Systems:  State of the Art, Functionalities, Research Directions",
    "abstract": "Business process compliance is a key area of business process management and\naims at ensuring that processes obey to compliance constraints such as\nregulatory constraints or business rules imposed on them. Process compliance\ncan be checked during process design time based on verification of process\nmodels and at runtime based on monitoring the compliance states of running\nprocess instances. For existing compliance monitoring approaches it remains\nunclear whether and how compliance violations can be predicted, although\npredictions are crucial in order to prepare and take countermeasures in time.\nThis work, hence, analyzes existing literature from compliance and SLA\nmonitoring as well as predictive process monitoring and provides an updated\nframework of compliance monitoring functionalities. For each compliance\nmonitoring functionality we elicit prediction requirements and analyze their\ncoverage by existing approaches. Based on this analysis, open challenges and\nresearch directions for predictive compliance and process monitoring are\nelaborated.",
    "descriptor": "",
    "authors": [
      "Stefanie Rinderle-Ma",
      "Karolin Winter"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.05446"
  },
  {
    "id": "arXiv:2205.05448",
    "title": "Symphony Generation with Permutation Invariant Language Model",
    "abstract": "In this work, we present a symbolic symphony music generation solution,\nSymphonyNet, based on a permutation invariant language model. To bridge the gap\nbetween text generation and symphony generation task, we propose a novel\nMulti-track Multi-instrument Repeatable (MMR) representation with particular\n3-D positional embedding and a modified Byte Pair Encoding algorithm (Music\nBPE) for music tokens. A novel linear transformer decoder architecture is\nintroduced as a backbone for modeling extra-long sequences of symphony tokens.\nMeanwhile, we train the decoder to learn automatic orchestration as a joint\ntask by masking instrument information from the input. We also introduce a\nlarge-scale symbolic symphony dataset for the advance of symphony generation\nresearch. Our empirical results show that our proposed approach can generate\ncoherent, novel, complex and harmonious symphony compared to human composition,\nwhich is the pioneer solution for multi-track multi-instrument symbolic music\ngeneration.",
    "descriptor": "",
    "authors": [
      "Jiafeng Liu",
      "Yuanliang Dong",
      "Zehua Cheng",
      "Xinran Zhang",
      "Xiaobing Li",
      "Feng Yu",
      "Maosong Sun"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.05448"
  },
  {
    "id": "arXiv:2205.05449",
    "title": "Detecting Emerging Technologies and their Evolution using Deep Learning  and Weak Signal Analysis",
    "abstract": "Emerging technologies can have major economic impacts and affect strategic\nstability. Yet, early identification of emerging technologies remains\nchallenging. In order to identify emerging technologies in a timely and\nreliable manner, a comprehensive examination of relevant scientific and\ntechnological (S&T) trends and their related references is required. This\nexamination is generally done by domain experts and requires significant\namounts of time and effort to gain insights. The use of domain experts to\nidentify emerging technologies from S&T trends may limit the capacity to\nanalyse large volumes of information and introduce subjectivity in the\nassessments. Decision support systems are required to provide accurate and\nreliable evidence-based indicators through constant and continuous monitoring\nof the environment and help identify signals of emerging technologies that\ncould alter security and economic prosperity. For example, the research field\nof hypersonics has recently witnessed several advancements having profound\ntechnological, commercial, and national security implications. In this work, we\npresent a multi-layer quantitative approach able to identify future signs from\nscientific publications on hypersonics by leveraging deep learning and weak\nsignal analysis. The proposed framework can help strategic planners and domain\nexperts better identify and monitor emerging technology trends.",
    "descriptor": "\nComments: 17 pages, 8 figures, 2 tables (preprint version)\n",
    "authors": [
      "Ashkan Ebadi",
      "Alain Auger",
      "Yvan Gauthier"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05449"
  },
  {
    "id": "arXiv:2205.05453",
    "title": "Experiments on Bipolar Transmission with Direct Detection",
    "abstract": "Achievable information rates of bipolar 4- and 8-ary constellations are\nexperimentally compared to those of intensity modulation (IM) when using an\noversampled direct detection receiver. The bipolar constellations gain up to\n1.8 dB over their IM counterparts.",
    "descriptor": "\nComments: submitted to ECOC 2022\n",
    "authors": [
      "Thomas Wiegart",
      "Daniel Plabst",
      "Tobias Prinz",
      "Talha Rahman",
      "Maximilian Sch\u00e4dler",
      "Neboj\u0161a Stojanovi\u0107",
      "Stefano Calabr\u00f2",
      "Norbert Hanik",
      "Gerhard Kramer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.05453"
  },
  {
    "id": "arXiv:2205.05455",
    "title": "Finite-Time Analysis of Constant Step-Size Q-Learning : Switching System  Approach Revisited",
    "abstract": "This technical note revisits the novel switching system framework in [1] for\nanalyzing the finite-time convergence of Q-learning, where the dynamics of\nasynchronous Q-learning with a constant step-size is formulated as a\ndiscrete-time stochastic switching system model, and a bound on the average\niteration is established based on Lyapunov functions. We improve the analysis\nin the previous paper by replacing the average iteration with the final\niteration, which is simpler and more common in the literature. The proposed\nanalysis relies on propagations of the autocorrelation matrix of the state\ninstead of the Lyapunov function analysis. Moreover, we provide comparative\nanalysis of the proposed method and existing approaches, and prove that the\nproposed approach improves the previous sample complexities in terms of the\neffective horizon. Besides, the proposed analysis offers additional insights on\nanalysis of Q-learning and reinforcement learning, and complements existing\napproaches.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2102.08583\n",
    "authors": [
      "Donghwna Lee"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.05455"
  },
  {
    "id": "arXiv:2205.05460",
    "title": "Comparison of PAM-6 Modulations for Short-Reach Fiber-Optic Links with  Intensity Modulation and Direct Detection",
    "abstract": "PAM-6 transmission is considered for short-reach fiber-optic links with\nintensity modulation and direct detection. Experiments show that\nprobabilistically-shaped PAM-6 and a framed-cross QAM-32 constellation\noutperform conventional cross QAM-32 under a peak power constraint.",
    "descriptor": "\nComments: submitted to European Conference on Optical Communication (ECOC) 2022\n",
    "authors": [
      "Tobias Prinz",
      "Thomas Wiegart",
      "Daniel Plabst",
      "Talha Rahman",
      "Md Sabbir-Bin Hossain",
      "Neboj\u0161a Stojanovi\u0107",
      "Stefano Calabr\u00f2",
      "Norbert Hanik",
      "Gerhard Kramer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.05460"
  },
  {
    "id": "arXiv:2205.05461",
    "title": "Making Pre-trained Language Models Good Long-tailed Learners",
    "abstract": "Prompt-tuning has shown appealing performance in few-shot classification by\nvirtue of its capability in effectively exploiting pre-trained knowledge. This\nmotivates us to check the hypothesis that prompt-tuning is also a promising\nchoice for long-tailed classification, since the tail classes are intuitively\nfew-shot ones. To achieve this aim, we conduct empirical studies to examine the\nhypothesis. The results demonstrate that prompt-tuning exactly makes\npre-trained language models at least good long-tailed learners. For intuitions\non why prompt-tuning can achieve good performance in long-tailed\nclassification, we carry out an in-depth analysis by progressively bridging the\ngap between prompt-tuning and commonly used fine-tuning. The summary is that\nthe classifier structure and parameterization form the key to making good\nlong-tailed learners, in comparison with the less important input structure.\nFinally, we verify the applicability of our finding to few-shot classification.",
    "descriptor": "\nComments: Work in progress. The code will be available soon\n",
    "authors": [
      "Chen Zhang",
      "Lei Ren",
      "Jingang Wang",
      "Wei Wu",
      "Dawei Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05461"
  },
  {
    "id": "arXiv:2205.05464",
    "title": "Raw Filtering of JSON Data on FPGAs",
    "abstract": "Many Big Data applications include the processing of data streams on\nsemi-structured data formats such as JSON. A disadvantage of such formats is\nthat an application may spend a significant amount of processing time just on\nunselectively parsing all data. To relax this issue, the concept of raw\nfiltering is proposed with the idea to remove data from a stream prior to the\ncostly parsing stage. However, as accurate filtering of raw data is often only\npossible after the data has been parsed, raw filters are designed to be\napproximate in the sense of allowing false-positives in order to be implemented\nefficiently.\nContrary to previously proposed CPU-based raw filtering techniques that are\nrestricted to string matching, we present FPGA-based primitives for filtering\nstrings, numbers and also number ranges. In addition, a primitive respecting\nthe basic structure of JSON data is proposed that can be used to further\nincrease the accuracy of introduced raw filters.\nThe proposed raw filter primitives are designed to allow for their\ncomposition according to a given filter expression of a query. Thus, complex\nraw filters can be created for FPGAs which enable a drastical decrease in the\namount of generated false-positives, particularly for IoT workload.\nAs there exists a trade-off between accuracy and resource consumption, we\nevaluate primitives as well as composed raw filters using different queries\nfrom the RiotBench benchmark. Our results show that up to 94.3% of the raw data\ncan be filtered without producing any observed false-positives using only a few\nhundred LUTs.",
    "descriptor": "",
    "authors": [
      "Tobias Hahn",
      "Andreas Becher",
      "Stefan Wildermann",
      "J\u00fcrgen Teich"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2205.05464"
  },
  {
    "id": "arXiv:2205.05467",
    "title": "A Continual Deepfake Detection Benchmark: Dataset, Methods, and  Essentials",
    "abstract": "There have been emerging a number of benchmarks and techniques for the\ndetection of deepfakes. However, very few works study the detection of\nincrementally appearing deepfakes in the real-world scenarios. To simulate the\nwild scenes, this paper suggests a continual deepfake detection benchmark\n(CDDB) over a new collection of deepfakes from both known and unknown\ngenerative models. The suggested CDDB designs multiple evaluations on the\ndetection over easy, hard, and long sequence of deepfake tasks, with a set of\nappropriate measures. In addition, we exploit multiple approaches to adapt\nmulticlass incremental learning methods, commonly used in the continual visual\nrecognition, to the continual deepfake detection problem. We evaluate several\nmethods, including the adapted ones, on the proposed CDDB. Within the proposed\nbenchmark, we explore some commonly known essentials of standard continual\nlearning. Our study provides new insights on these essentials in the context of\ncontinual deepfake detection. The suggested CDDB is clearly more challenging\nthan the existing benchmarks, which thus offers a suitable evaluation avenue to\nthe future research. Our benchmark dataset and the source code will be made\npublicly available.",
    "descriptor": "",
    "authors": [
      "Chuqiao Li",
      "Zhiwu Huang",
      "Danda Pani Paudel",
      "Yabin Wang",
      "Mohamad Shahbazi",
      "Xiaopeng Hong",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05467"
  },
  {
    "id": "arXiv:2205.05468",
    "title": "Utilizing coarse-grained data in low-data settings for event extraction",
    "abstract": "Annotating text data for event information extraction systems is hard,\nexpensive, and error-prone. We investigate the feasibility of integrating\ncoarse-grained data (document or sentence labels), which is far more feasible\nto obtain, instead of annotating more documents. We utilize a multi-task model\nwith two auxiliary tasks, document and sentence binary classification, in\naddition to the main task of token classification. We perform a series of\nexperiments with varying data regimes for the aforementioned integration.\nResults show that while introducing extra coarse-grained data offers greater\nimprovement and robustness, a gain is still possible with only the addition of\nnegative documents that have no information on any event.",
    "descriptor": "\nComments: A Dissertation Submitted to the Graduate School of Sciences and Engineering in Partial Fulfillment of the Requirements for the Degree of Master of Science in Computer Science and Engineering\n",
    "authors": [
      "Osman Mutlu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05468"
  },
  {
    "id": "arXiv:2205.05469",
    "title": "Generation of non-stationary stochastic fields using Generative  Adversarial Networks with limited training data",
    "abstract": "In the context of generating geological facies conditioned on observed data,\nsamples corresponding to all possible conditions are not generally available in\nthe training set and hence the generation of these realizations depends primary\non the generalization capability of the trained generative model. The problem\nbecomes more complex when applied on non-stationary fields. In this work, we\ninvestigate the problem of training Generative Adversarial Networks (GANs)\nmodels against a dataset of geological channelized patterns that has a few\nnon-stationary spatial modes and examine the training and self-conditioning\nsettings that improve the generalization capability at new spatial modes that\nwere never seen in the given training set. The developed training method\nallowed for effective learning of the correlation between the spatial\nconditions (i.e. non-stationary maps) and the realizations implicitly without\nusing additional loss terms or solving a costly optimization problem at the\nrealization generation phase. Our models, trained on real and artificial\ndatasets were able to generate geologically-plausible realizations beyond the\ntraining samples with a strong correlation with the target maps.",
    "descriptor": "",
    "authors": [
      "Alhasan Abdellatif",
      "Ahmed H. Elsheikh",
      "Daniel Busby",
      "Philippe Berthet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05469"
  },
  {
    "id": "arXiv:2205.05473",
    "title": "The Hijackers Guide To The Galaxy: Off-Path Taking Over Internet  Resources",
    "abstract": "Internet resources form the basic fabric of the digital society. They provide\nthe fundamental platform for digital services and assets, e.g., for critical\ninfrastructures, financial services, government. Whoever controls that fabric\neffectively controls the digital society.\nIn this work we demonstrate that the current practices of Internet resources\nmanagement, of IP addresses, domains, certificates and virtual platforms are\ninsecure. Over long periods of time adversaries can maintain control over\nInternet resources which they do not own and perform stealthy manipulations,\nleading to devastating attacks. We show that network adversaries can take over\nand manipulate at least 68% of the assigned IPv4 address space as well as 31%\nof the top Alexa domains. We demonstrate such attacks by hijacking the accounts\nassociated with the digital resources.\nFor hijacking the accounts we launch off-path DNS cache poisoning attacks, to\nredirect the password recovery link to the adversarial hosts. We then\ndemonstrate that the adversaries can manipulate the resources associated with\nthese accounts. We find all the tested providers vulnerable to our attacks.\nWe recommend mitigations for blocking the attacks that we present in this\nwork. Nevertheless, the countermeasures cannot solve the fundamental problem -\nthe management of the Internet resources should be revised to ensure that\napplying transactions cannot be done so easily and stealthily as is currently\npossible.",
    "descriptor": "",
    "authors": [
      "Tianxiang Dai",
      "Philipp Jeitner",
      "Haya Shulman",
      "Michael Waidner"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.05473"
  },
  {
    "id": "arXiv:2205.05476",
    "title": "Contrastive Supervised Distillation for Continual Representation  Learning",
    "abstract": "In this paper, we propose a novel training procedure for the continual\nrepresentation learning problem in which a neural network model is sequentially\nlearned to alleviate catastrophic forgetting in visual search tasks. Our\nmethod, called Contrastive Supervised Distillation (CSD), reduces feature\nforgetting while learning discriminative features. This is achieved by\nleveraging labels information in a distillation setting in which the student\nmodel is contrastively learned from the teacher model. Extensive experiments\nshow that CSD performs favorably in mitigating catastrophic forgetting by\noutperforming current state-of-the-art methods. Our results also provide\nfurther evidence that feature forgetting evaluated in visual retrieval tasks is\nnot as catastrophic as in classification tasks. Code at:\nhttps://github.com/NiccoBiondi/ContrastiveSupervisedDistillation.",
    "descriptor": "\nComments: Paper published as Oral at ICIAP21\n",
    "authors": [
      "Tommaso Barletti",
      "Niccolo' Biondi",
      "Federico Pernici",
      "Matteo Bruni",
      "Alberto Del Bimbo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05476"
  },
  {
    "id": "arXiv:2205.05477",
    "title": "Marsupial Walking-and-Flying Robotic Deployment for Collaborative  Exploration of Unknown Environments",
    "abstract": "This work contributes a marsupial robotic system-of-systems involving a\nlegged and an aerial robot capable of collaborative mapping and exploration\npath planning that exploits the heterogeneous properties of the two systems and\nthe ability to selectively deploy the aerial system from the ground robot.\nExploiting the dexterous locomotion capabilities and long endurance of\nquadruped robots, the marsupial combination can explore within large-scale and\nconfined environments involving rough terrain. However, as certain types of\nterrain or vertical geometries can render any ground system unable to continue\nits exploration, the marsupial system can - when needed - deploy the flying\nrobot which, by exploiting its 3D navigation capabilities, can undertake a\nfocused exploration task within its endurance limitations. Focusing on\nautonomy, the two systems can co-localize and map together by sharing\nLiDAR-based maps and plan exploration paths individually, while a tailored\ngraph search onboard the legged robot allows it to identify where and when the\nferried aerial platform should be deployed. The system is verified within\nmultiple experimental studies demonstrating the expanded exploration\ncapabilities of the marsupial system-of-systems and facilitating the\nexploration of otherwise individually unreachable areas.",
    "descriptor": "\nComments: 6 pages, 6 figures, Submitted to the IEEE/RSJ International Conference on Intelligent Robots and Systems, 2022\n",
    "authors": [
      "Paolo De Petris",
      "Shehryar Khattak",
      "Mihir Dharmadhikari",
      "Gabriel Waibel",
      "Huan Nguyen",
      "Markus Montenegro",
      "Nikhil Khedekar",
      "Kostas Alexis",
      "Marco Hutter"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.05477"
  },
  {
    "id": "arXiv:2205.05480",
    "title": "Automatic Tuberculosis and COVID-19 cough classification using deep  learning",
    "abstract": "We present a deep learning based automatic cough classifier which can\ndiscriminate tuberculosis (TB) coughs from COVID-19 coughs and healthy coughs.\nBoth TB and COVID-19 are respiratory disease, have cough as a predominant\nsymptom and claim thousands of lives each year. The cough audio recordings were\ncollected at both indoor and outdoor settings and also uploaded using\nsmartphones from subjects around the globe, thus contain various levels of\nnoise. This cough data include 1.68 hours of TB coughs, 18.54 minutes of\nCOVID-19 coughs and 1.69 hours of healthy coughs from 47 TB patients, 229\nCOVID-19 patients and 1498 healthy patients and were used to train and evaluate\na CNN, LSTM and Resnet50. These three deep architectures were also pre-trained\non 2.14 hours of sneeze, 2.91 hours of speech and 2.79 hours of noise for\nimproved performance. The class-imbalance in our dataset was addressed by using\nSMOTE data balancing technique and using performance metrics such as F1-score\nand AUC. Our study shows that the highest F1-scores of 0.9259 and 0.8631 have\nbeen achieved from a pre-trained Resnet50 for two-class (TB vs COVID-19) and\nthree-class (TB vs COVID-19 vs healthy) cough classification tasks,\nrespectively. The application of deep transfer learning has improved the\nclassifiers' performance and makes them more robust as they generalise better\nover the cross-validation folds. Their performances exceed the TB triage test\nrequirements set by the world health organisation (WHO). The features producing\nthe best performance contain higher order of MFCCs suggesting that the\ndifferences between TB and COVID-19 coughs are not perceivable by the human\near. This type of cough audio classification is non-contact, cost-effective and\ncan easily be deployed on a smartphone, thus it can be an excellent tool for\nboth TB and COVID-19 screening.",
    "descriptor": "",
    "authors": [
      "Madhurananda Pahar",
      "Marisa Klopper",
      "Byron Reeve",
      "Rob Warren",
      "Grant Theron",
      "Andreas Diacon",
      "Thomas Niesler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2205.05480"
  },
  {
    "id": "arXiv:2205.05482",
    "title": "Who won? Winner Determination and Robustness in Liquid Democracy",
    "abstract": "Liquid democracy is a decision-making paradigm in which each agent can either\nvote directly for some alternative or (transitively) delegate its vote to\nanother agent. To mitigate the issue of delegation cycles or the concentration\nof power, delegating agents might be allowed to specify multiple delegation\noptions. Then, a (cycle-free) delegation is selected in which each delegating\nagent has exactly one representative. We study the winner determination problem\nfor this setting, i.e., whether we can select a delegation such that a given\nalternative wins (or does not win). Moreover, we study the robustness of\nwinning alternatives in two ways: First, we consider whether we can make a\nlimited number of changes to the preferences cast by the delegating or directly\nvoting agents such that a given alternative becomes a winner in one/in all\ndelegations, and second, whether we can make a limited number of changes to a\nselected delegation to make a given alternative a winner.",
    "descriptor": "",
    "authors": [
      "Matthias Bentert",
      "Niclas Boehmer",
      "Maciej Rymar",
      "Henri Tannenberg"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2205.05482"
  },
  {
    "id": "arXiv:2205.05487",
    "title": "Scene Consistency Representation Learning for Video Scene Segmentation",
    "abstract": "A long-term video, such as a movie or TV show, is composed of various scenes,\neach of which represents a series of shots sharing the same semantic story.\nSpotting the correct scene boundary from the long-term video is a challenging\ntask, since a model must understand the storyline of the video to figure out\nwhere a scene starts and ends. To this end, we propose an effective\nSelf-Supervised Learning (SSL) framework to learn better shot representations\nfrom unlabeled long-term videos. More specifically, we present an SSL scheme to\nachieve scene consistency, while exploring considerable data augmentation and\nshuffling methods to boost the model generalizability. Instead of explicitly\nlearning the scene boundary features as in the previous methods, we introduce a\nvanilla temporal model with less inductive bias to verify the quality of the\nshot features. Our method achieves the state-of-the-art performance on the task\nof Video Scene Segmentation. Additionally, we suggest a more fair and\nreasonable benchmark to evaluate the performance of Video Scene Segmentation\nmethods. The code is made available.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Haoqian Wu",
      "Keyu Chen",
      "Yanan Luo",
      "Ruizhi Qiao",
      "Bo Ren",
      "Haozhe Liu",
      "Weicheng Xie",
      "Linlin Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.05487"
  },
  {
    "id": "arXiv:2205.05488",
    "title": "DNA data storage, sequencing data-carrying DNA",
    "abstract": "DNA is a leading candidate as the next archival storage media due to its\ndensity, durability and sustainability. To read (and write) data DNA storage\nexploits technology that has been developed over decades to sequence naturally\noccurring DNA in the life sciences. To achieve higher accuracy for previously\nunseen, biological DNA, sequencing relies on extending and training deep\nmachine learning models known as basecallers. This growth in model complexity\nrequires substantial resources, both computational and data sets. It also\neliminates the possibility of a compact read head for DNA as a storage medium.\nWe argue that we need to depart from blindly using sequencing models from the\nlife sciences for DNA data storage. The difference is striking: for life\nscience applications we have no control over the DNA, however, in the case of\nDNA data storage, we control how it is written, as well as the particular write\nhead. More specifically, data-carrying DNA can be modulated and embedded with\nalignment markers and error correcting codes to guarantee higher fidelity and\nto carry out some of the work that the machine learning models perform.\nIn this paper, we study accuracy trade-offs between deep model size and error\ncorrecting codes. We show that, starting with a model size of 107MB, the\nreduced accuracy from model compression can be compensated by using simple\nerror correcting codes in the DNA sequences. In our experiments, we show that a\nsubstantial reduction in the size of the model does not incur an undue penalty\nfor the error correcting codes used, therefore paving the way for portable\ndata-carrying DNA read head. Crucially, we show that through the joint use of\nmodel compression and error correcting codes, we achieve a higher read accuracy\nthan without compression and error correction codes.",
    "descriptor": "",
    "authors": [
      "Jasmine Quah",
      "Omer Sella",
      "Thomas Heinis"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05488"
  },
  {
    "id": "arXiv:2205.05492",
    "title": "Two ways to make your robot proactive: reasoning about human intentions,  or reasoning about possible futures",
    "abstract": "Robots sharing their space with humans need to be proactive in order to be\nhelpful. Proactive robots are able to act on their own initiative in an\nanticipatory way to benefit humans. In this work, we investigate two ways to\nmake robots proactive. One way is to recognize humans' intentions and to act to\nfulfill them, like opening the door that you are about to cross. The other way\nis to reason about possible future threats or opportunities and to act to\nprevent or to foster them, like recommending you to take an umbrella since rain\nhas been forecasted. In this paper, we present approaches to realize these two\ntypes of proactive behavior. We then present an integrated system that can\ngenerate proactive robot behavior by reasoning on both factors: intentions and\npredictions. We illustrate our system on a sample use case including a domestic\nrobot and a human. We first run this use case with the two separate proactive\nsystems, intention-based and prediction-based, and then run it with our\nintegrated system. The results show that the integrated system is able to take\ninto account a broader variety of aspects that are needed for proactivity.",
    "descriptor": "\nComments: 20 pages, 1-column, 4 figures\n",
    "authors": [
      "Sera Buyukgoz",
      "Jasmin Grosinger",
      "Mohamed Chetouani",
      "Alessandro Saffiotti"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.05492"
  },
  {
    "id": "arXiv:2205.05493",
    "title": "Deep Learning and Computer Vision Techniques for Microcirculation  Analysis: A Review",
    "abstract": "The analysis of microcirculation images has the potential to reveal early\nsigns of life-threatening diseases like sepsis. Quantifying the capillary\ndensity and the capillary distribution in microcirculation images can be used\nas a biological marker to assist critically ill patients. The quantification of\nthese biological markers is labor-intensive, time-consuming, and subject to\ninterobserver variability. Several computer vision techniques with varying\nperformance can be used to automate the analysis of these microcirculation\nimages in light of the stated challenges. In this paper, we present a survey of\nover 50 research papers and present the most relevant and promising computer\nvision algorithms to automate the analysis of microcirculation images.\nFurthermore, we present a survey of the methods currently used by other\nresearchers to automate the analysis of microcirculation images. This survey is\nof high clinical relevance because it acts as a guidebook of techniques for\nother researchers to develop their microcirculation analysis systems and\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Maged Abdalla Helmy Mohamed Abdou",
      "Trung Tuyen Truong",
      "Eric Jul",
      "Paulo Ferreira"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.05493"
  },
  {
    "id": "arXiv:2205.05498",
    "title": "Towards Self-Adaptive Game Logic",
    "abstract": "Self-adaptive systems (SAS) can reconfigure at run time in response to\nchanging situations to express acceptable behaviors in the face of uncertainty.\nWith respect to game design, such situations may include user input, emergent\nbehaviors, performance concerns, and combinations thereof. Typically an SAS is\nmodeled as a feedback loop that functions within an existing system, with\noperations including monitoring, analyzing, planning, and executing (i.e.,\nMAPE-K) to enable online reconfiguration. This paper presents a conceptual\napproach for extending software engineering artifacts to be self-adaptive\nwithin the context of game design. We have modified a game developed for\ncreative coding education to include a MAPE-K self-adaptive feedback loop,\ncomprising run-time adaptation capabilities and the software artifacts required\nto support adaptation.",
    "descriptor": "",
    "authors": [
      "Erik M. Fredericks",
      "Byron DeVries",
      "Jared M. Moore"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.05498"
  },
  {
    "id": "arXiv:2205.05502",
    "title": "Towards Run-Time Search for Real-World Multi-Agent Systems",
    "abstract": "Multi-agent systems (MAS) may encounter uncertainties in the form of\nunexpected environmental conditions, sub-optimal system configurations, and\nunplanned interactions between autonomous agents. The number of combinations of\nsuch uncertainties may be innumerable, however run-time testing may reduce the\nissues impacting such a system. We posit that search heuristics can augment a\nrun-time testing process, in-situ, for a MAS. To support our position we\ndiscuss our in-progress experimental testbed to realize this goal and highlight\nchallenges we anticipate for this domain.",
    "descriptor": "",
    "authors": [
      "Abigail C. Diller",
      "Erik M. Fredericks"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.05502"
  },
  {
    "id": "arXiv:2205.05505",
    "title": "Probability Distribution of Hypervolume Improvement in Bi-objective  Bayesian Optimization",
    "abstract": "This work provides the exact expression of the probability distribution of\nthe hypervolume improvement (HVI) for bi-objective generalization of Bayesian\noptimization. Here, instead of a single-objective improvement, we consider the\nimprovement of the hypervolume indicator concerning the current best\napproximation of the Pareto front. Gaussian process regression models are\ntrained independently on both objective functions, resulting in a bi-variate\nseparated Gaussian distribution serving as a predictive model for the\nvector-valued objective function. Some commonly HVI-based acquisition functions\n(probability of improvement and upper confidence bound) are also leveraged with\nthe help of the exact distribution of HVI. In addition, we show the superior\nnumerical accuracy and efficiency of the exact distribution compared to the\ncommonly used approximation by Monte-Carlo sampling. Finally, we benchmark\ndistribution-leveraged acquisition functions on the widely applied ZDT problem\nset, demonstrating a significant advantage of using the exact distribution of\nHVI in multi-objective Bayesian optimization.",
    "descriptor": "",
    "authors": [
      "Hao Wang",
      "Kaifeng Yang",
      "Michael Affenzeller",
      "Michael Emmerich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.05505"
  },
  {
    "id": "arXiv:2205.05507",
    "title": "TextMatcher: Cross-Attentional Neural Network to Compare Image and Text",
    "abstract": "We study a novel multimodal-learning problem, which we call text matching:\ngiven an image containing a single-line text and a candidate text\ntranscription, the goal is to assess whether the text represented in the image\ncorresponds to the candidate text. We devise the first machine-learning model\nspecifically designed for this problem. The proposed model, termed TextMatcher,\ncompares the two inputs by applying a cross-attention mechanism over the\nembedding representations of image and text, and it is trained in an end-to-end\nfashion. We extensively evaluate the empirical performance of TextMatcher on\nthe popular IAM dataset. Results attest that, compared to a baseline and\nexisting models designed for related problems, TextMatcher achieves higher\nperformance on a variety of configurations, while at the same time running\nfaster at inference time. We also showcase TextMatcher in a real-world\napplication scenario concerning the automatic processing of bank cheques.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Valentina Arrigoni",
      "Luisa Repele",
      "Dario Marino Saccavino"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.05507"
  },
  {
    "id": "arXiv:2205.05508",
    "title": "Self-Supervised Antipodal Grasp Learning with Fine-Grained Grasp Quality  Feedback in Clutter",
    "abstract": "It is a challenging goal in robotics to make a robot grasp like a human being\nin a cluttered environment. Self-supervised grasp learning is one of the most\npromising approaches to human-like robotic grasp. However, due to inadequate\nfeedback on grasp quality, almost the existing self-supervised grasp learning\nmethods are coarse-grained. This paper proposes a fine-grained antipodal grasp\nlearning (FAGL) method with augmented learning feedback. First, an indicator\ncalled antipodal degree of a grasp (ADG) is defined by a non-increasing\nmonotonous function. ADG reflecting fine-grained grasp quality is evaluated\nindirectly by the destructive effect of a grasp on the environment via scene\nimages. Next, we design a restorative sampling strategy to collect the samples\nof fine-grained antipodal grasps and propose a refined affordance network to\ngenerate grasp affordance maps for FAGL to decide grasp policies. Finally, in\ngrasping actual metal workpieces, FAGL outperforms its peers in terms of grasp\nsuccess rate and ADG in cluttered and adversarial scenarios by reducing the\ngrasp effects on the surroundings. The results of extensive experiments show\nthat our method has great potential for industrial application.",
    "descriptor": "\nComments: 11 pages, 9 figures\n",
    "authors": [
      "Yanxu Hou",
      "Jun Li",
      "I-Ming Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.05508"
  },
  {
    "id": "arXiv:2205.05509",
    "title": "READ: Large-Scale Neural Scene Rendering for Autonomous Driving",
    "abstract": "Synthesizing free-view photo-realistic images is an important task in\nmultimedia. With the development of advanced driver assistance systems~(ADAS)\nand their applications in autonomous vehicles, experimenting with different\nscenarios becomes a challenge. Although the photo-realistic street scenes can\nbe synthesized by image-to-image translation methods, which cannot produce\ncoherent scenes due to the lack of 3D information. In this paper, a large-scale\nneural rendering method is proposed to synthesize the autonomous driving\nscene~(READ), which makes it possible to synthesize large-scale driving\nscenarios on a PC through a variety of sampling schemes. In order to represent\ndriving scenarios, we propose an {\\omega} rendering network to learn neural\ndescriptors from sparse point clouds. Our model can not only synthesize\nrealistic driving scenes but also stitch and edit driving scenes. Experiments\nshow that our model performs well in large-scale driving scenarios.",
    "descriptor": "",
    "authors": [
      "Zhuopeng Li",
      "Lu Li",
      "Zeyu Ma",
      "Ping Zhang",
      "Junbo Chen",
      "Jianke Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.05509"
  },
  {
    "id": "arXiv:2205.05511",
    "title": "Efficient Automated Deep Learning for Time Series Forecasting",
    "abstract": "Recent years have witnessed tremendously improved efficiency of Automated\nMachine Learning (AutoML), especially Automated Deep Learning (AutoDL) systems,\nbut recent work focuses on tabular, image, or NLP tasks. So far, little\nattention has been paid to general AutoDL frameworks for time series\nforecasting, despite the enormous success in applying different novel\narchitectures to such tasks. In this paper, we propose an efficient approach\nfor the joint optimization of neural architecture and hyperparameters of the\nentire data processing pipeline for time series forecasting. In contrast to\ncommon NAS search spaces, we designed a novel neural architecture search space\ncovering various state-of-the-art architectures, allowing for an efficient\nmacro-search over different DL approaches. To efficiently search in such a\nlarge configuration space, we use Bayesian optimization with multi-fidelity\noptimization. We empirically study several different budget types enabling\nefficient multi-fidelity optimization on different forecasting datasets.\nFurthermore, we compared our resulting system, dubbed Auto-PyTorch-TS, against\nseveral established baselines and show that it significantly outperforms all of\nthem across several datasets.",
    "descriptor": "",
    "authors": [
      "Difan Deng",
      "Florian Karl",
      "Frank Hutter",
      "Bernd Bischl",
      "Marius Lindauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05511"
  },
  {
    "id": "arXiv:2205.05512",
    "title": "Is calibration a fairness requirement? An argument from the point of  view of moral philosophy and decision theory",
    "abstract": "In this paper, we provide a moral analysis of two criteria of statistical\nfairness debated in the machine learning literature: 1) calibration between\ngroups and 2) equality of false positive and false negative rates between\ngroups. In our paper, we focus on moral arguments in support of either measure.\nThe conflict between group calibration vs. false positive and false negative\nrate equality is one of the core issues in the debate about group fairness\ndefinitions among practitioners. For any thorough moral analysis, the meaning\nof the term fairness has to be made explicit and defined properly. For our\npaper, we equate fairness with (non-)discrimination, which is a legitimate\nunderstanding in the discussion about group fairness. More specifically, we\nequate it with prima facie wrongful discrimination in the sense this is used in\nProf. Lippert-Rasmussen's treatment of this definition. In this paper, we argue\nthat a violation of group calibration may be unfair in some cases, but not\nunfair in others. This is in line with claims already advanced in the\nliterature, that algorithmic fairness should be defined in a way that is\nsensitive to context. The most important practical implication is that\narguments based on examples in which fairness requires between-group\ncalibration, or equality in the false-positive/false-negative rates, do no\ngeneralize. For it may be that group calibration is a fairness requirement in\none case, but not in another.",
    "descriptor": "",
    "authors": [
      "Michele Loi",
      "Christoph Heitz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.05512"
  },
  {
    "id": "arXiv:2205.05515",
    "title": "Keep Your Friends Close and Your Counterfactuals Closer: Improved  Learning From Closest Rather Than Plausible Counterfactual Explanations in an  Abstract Setting",
    "abstract": "Counterfactual explanations (CFEs) highlight what changes to a model's input\nwould have changed its prediction in a particular way. CFEs have gained\nconsiderable traction as a psychologically grounded solution for explainable\nartificial intelligence (XAI). Recent innovations introduce the notion of\ncomputational plausibility for automatically generated CFEs, enhancing their\nrobustness by exclusively creating plausible explanations. However, practical\nbenefits of such a constraint on user experience and behavior is yet unclear.\nIn this study, we evaluate objective and subjective usability of\ncomputationally plausible CFEs in an iterative learning design targeting novice\nusers. We rely on a novel, game-like experimental design, revolving around an\nabstract scenario. Our results show that novice users actually benefit less\nfrom receiving computationally plausible rather than closest CFEs that produce\nminimal changes leading to the desired outcome. Responses in a post-game survey\nreveal no differences in terms of subjective user experience between both\ngroups. Following the view of psychological plausibility as comparative\nsimilarity, this may be explained by the fact that users in the closest\ncondition experience their CFEs as more psychologically plausible than the\ncomputationally plausible counterpart. In sum, our work highlights a\nlittle-considered divergence of definitions of computational plausibility and\npsychological plausibility, critically confirming the need to incorporate human\nbehavior, preferences and mental models already at the design stages of XAI\napproaches. In the interest of reproducible research, all source code, acquired\nuser data, and evaluation scripts of the current study are available:\nhttps://github.com/ukuhl/PlausibleAlienZoo",
    "descriptor": "\nComments: 17 pages, 4 figures, 1 table; accepted at 2022 ACM Conference on Fairness, Accountability, and Transparency (FAccT '22), June 21-24, 2022, Seoul, Republic of Korea. this https URL\n",
    "authors": [
      "Ulrike Kuhl",
      "Andr\u00e9 Artelt",
      "Barbara Hammer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05515"
  },
  {
    "id": "arXiv:2205.05518",
    "title": "Building Automation System Data Integration with BIM: Data Structure and  Supporting Case Study",
    "abstract": "Buildings Automation Systems (BAS) are ubiquitous in contemporary buildings,\nboth monitoring building conditions and managing the building system control\npoints. At present, these controls are prescriptive and pre-determined by the\ndesign team, rather than responsive to actual building performance. These are\nfurther limited by prescribed logic, possess only rudimentary visualizations,\nand lack broader system integration capabilities. Advances in machine learning,\nedge analytics, data management systems, and Facility Management-enabled\nBuilding Information Models (FM-BIMs) permit a novel approach: cloud-hosted\nbuilding management. This paper presents an integration technique for mapping\nthe data from a building Internet of Things (IoT) sensor network to an FM-BIM.\nThe sensor data naming convention and timeseries analysis strategies integrated\ninto the data structure are discussed and presented, including the use of a 3D\nnested list to permit timeseries data to be mapped to the FM-BIM and readily\nvisualized. The developed approach is presented through a case study of an\noffice living lab consisting of a local sensor network mimicking a BAS, which\nstreams to a cloud server via a virtual private network connection. The\nresultant data structure and key visualizations are presented to demonstrate\nthe value of this approach, which permits the end-user to select the desired\ntimeframe for visualization and readily step through the spatio-temporal\nbuilding performance data.",
    "descriptor": "\nComments: 26 pages, 6580 words; invited to special issue of Automation in Construction for CIB W78 2019 conference\n",
    "authors": [
      "Caroline Quinn",
      "Ali Zargar Shabestari",
      "Marin Litoiu",
      "J.J. McArthur"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.05518"
  },
  {
    "id": "arXiv:2205.05519",
    "title": "Query Efficient Prophet Inequality with Unknown I.I.D. Distributions",
    "abstract": "We study the single-choice prophet inequality problem, where a gambler faces\na sequence of $n$ online i.i.d. random variables drawn from an unknown\ndistribution. When a variable reveals its value, the gambler needs to decide\nirrevocably whether or not to accept it. The goal is to maximize the\ncompetitive ratio between the expected gain of the gambler and that of the\nmaximum variable. It is shown by Correa et al. that when the distribution is\nunknown or only $o(n)$ uniform samples from the distribution are given, the\nbest an algorithm can do is $1/e$-competitive. In contrast, when the\ndistribution is known or $\\Omega(n)$ uniform samples are given, the optimal\ncompetitive ratio 0.7451 can be achieved. In this paper, we propose a new model\nin which the algorithm has access to an oracle that answers quantile queries\nabout the distribution, and study the extent to which we can use a small number\nof queries to achieve good competitive ratios. Naturally, by making queries to\nthe oracle, one can implement the threshold-based blind strategies that use the\nanswers from the queries as thresholds to accept variables. Our first\ncontribution is to prove that the competitive ratio improves gracefully with\nthe number of thresholds. Particularly with two thresholds our algorithm\nachieves a competitive ratio of 0.6786. Our second contribution, surprisingly,\nshows that with a single query, we can do strictly better than with a single\nthreshold. The algorithm sets a threshold in the first phase by making a single\nquery and uses the maximum realization from the first phase as the threshold\nfor the second phase. It can be viewed as a natural combination of the\nsingle-threshold algorithm and the algorithm for the secretary problem. By\nproperly choosing the quantile to query and the break-point between the two\nphases, we achieve a competitive ratio of 0.6718.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Bo Li",
      "Xiaowei Wu",
      "Yutong Wu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2205.05519"
  },
  {
    "id": "arXiv:2205.05521",
    "title": "Comparison of Brick and Project Haystack to Support Smart Building  Applications",
    "abstract": "Enabling buildings with Smart Building applications will help to achieve the\nongoing efficient commissioning of buildings, ultimately attaining peak\nperformance in energy use and improved occupant health and comfort, at minimum\ncost. For these technologies to be scalable data ontology must be adopted to\nsemantically represent data generated by building mechanical systems, acting as\nconduit for connection to Smart Building applications. The viability of Brick\nand Project Haystack ontologies, as found by industry and academia, prompted a\nquantitative comparison of completeness and expressiveness using a case study\nwith an industry ontology as the baseline. Additionally, a qualitative\ncomparison was completed using key ontology qualities outlined in literature. A\nrecommendation of Brick is made based on results. Brick achieved higher\nassessment values in completeness and expressiveness achieving 59% and 100%\nrespectively, as compared to Haystacks 43% and 96%. Additionally, Brick\nexhibited five of six desirable qualities, where Haystack exhibited only three.\nThe recommendation of the appropriate ontology forms the basis for longer-term\nSmart Building application development, which will support innovative\napproaches to sustainability in building operations across scale, as well as\nnext-generation building controls and automation strategies.",
    "descriptor": "\nComments: 21 pages; 8663 words\n",
    "authors": [
      "Caroline Quinn",
      "J.J. McArthur"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.05521"
  },
  {
    "id": "arXiv:2205.05533",
    "title": "Design, Modeling and Control for a Tilt-rotor VTOL UAV in the Presence  of Actuator Failure",
    "abstract": "Providing both the vertical take-off and landing capabilities and the ability\nto fly long distances to aircraft opens the door to a wide range of new\nreal-world aircraft applications while improving many existing applications.\nTiltrotor vertical take-off and landing (VTOL) unmanned aerial vehicles (UAVs)\nare a better choice than fixed-wing and multirotor aircraft for such\napplications. Prior work on these aircraft has addressed the aerodynamic\nperformance, design, modeling, and control. However, a less explored area is\nthe study of their potential fault tolerance due to their inherent redundancy,\nwhich allows them to sustain some degree of actuator failure. This work\nintroduces tolerance to several types of actuator failures in a tiltrotor VTOL\naircraft. We discuss the design and model of a custom tiltrotor VTOL UAV, which\nis a combination of a fixed-wing aircraft and a quadrotor with tilting rotors,\nwhere the four propellers can be rotated individually. Then, we analyze the\nfeasible wrench space the vehicle can generate and design the dynamic control\nallocation so that the system can adapt to actuator failure, benefiting from\nthe configuration redundancy. The proposed approach is lightweight and is\nimplemented as an extension to an already existing flight control stack.\nExtensive experiments are performed to validate that the system can maintain\nthe controlled flight under different actuator failures. To the best of our\nknowledge, this work is the first study of the tiltrotor VTOL's fault-tolerance\nthat exploits the configuration redundancy.",
    "descriptor": "",
    "authors": [
      "Mohammadreza Mousaei",
      "Junyi Geng",
      "Azarakhsh Keipour",
      "Dongwei Bai",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.05533"
  },
  {
    "id": "arXiv:2205.05535",
    "title": "Clinical Prompt Learning with Frozen Language Models",
    "abstract": "Prompt learning is a new paradigm in the Natural Language Processing (NLP)\nfield which has shown impressive performance on a number of natural language\ntasks with common benchmarking text datasets in full, few-shot, and zero-shot\ntrain-evaluation setups. Recently, it has even been observed that large but\nfrozen pre-trained language models (PLMs) with prompt learning outperform\nsmaller but fine-tuned models. However, as with many recent NLP trends, the\nperformance of even the largest PLMs such as GPT-3 do not perform well on\nspecialized domains (e.g. medical text), and the common practice to achieve\nState of the Art (SoTA) results still consists of pre-training and fine-tuning\nthe PLMs on downstream tasks. The reliance on fine-tuning large PLMs is\nproblematic in clinical settings where data is often held in non-GPU\nenvironments, and more resource efficient methods of training specialized\ndomain models is crucial. We investigated the viability of prompt learning on\nclinically meaningful decision tasks and directly compared with more\ntraditional fine-tuning methods. Results are partially in line with the prompt\nlearning literature, with prompt learning able to match or improve on\ntraditional fine-tuning with substantially fewer trainable parameters and\nrequiring less training data. We argue that prompt learning therefore provides\nlower computational resource costs applicable to clinical settings, that can\nserve as an alternative to fine-tuning ever increasing in size PLMs.\nComplementary code to reproduce experiments presented in this work can be found\nat: https://github.com/NtaylorOX/Public_Clinical_Prompt.",
    "descriptor": "\nComments: 18 pages, 6 figures, 6 tables\n",
    "authors": [
      "Niall Taylor",
      "Yi Zhang",
      "Dan Joyce",
      "Alejo Nevado-Holgado",
      "Andrey Kormilitzin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.05535"
  },
  {
    "id": "arXiv:2205.05543",
    "title": "An Empirical Study Of Self-supervised Learning Approaches For Object  Detection With Transformers",
    "abstract": "Self-supervised learning (SSL) methods such as masked language modeling have\nshown massive performance gains by pretraining transformer models for a variety\nof natural language processing tasks. The follow-up research adapted similar\nmethods like masked image modeling in vision transformer and demonstrated\nimprovements in the image classification task. Such simple self-supervised\nmethods are not exhaustively studied for object detection transformers (DETR,\nDeformable DETR) as their transformer encoder modules take input in the\nconvolutional neural network (CNN) extracted feature space rather than the\nimage space as in general vision transformers. However, the CNN feature maps\nstill maintain the spatial relationship and we utilize this property to design\nself-supervised learning approaches to train the encoder of object detection\ntransformers in pretraining and multi-task learning settings. We explore common\nself-supervised methods based on image reconstruction, masked image modeling\nand jigsaw. Preliminary experiments in the iSAID dataset demonstrate faster\nconvergence of DETR in the initial epochs in both pretraining and multi-task\nlearning settings; nonetheless, similar improvement is not observed in the case\nof multi-task learning with Deformable DETR. The code for our experiments with\nDETR and Deformable DETR are available at https://github.com/gokulkarthik/detr\nand https://github.com/gokulkarthik/Deformable-DETR respectively.",
    "descriptor": "\nComments: Final Project for the course \"Visual Object Detection And Recognition\" (CV703) at MBZUAI\n",
    "authors": [
      "Gokul Karthik Kumar",
      "Sahal Shaji Mullappilly",
      "Abhishek Singh Gehlot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05543"
  },
  {
    "id": "arXiv:2205.05551",
    "title": "NMR: Neural Manifold Representation for Autonomous Driving",
    "abstract": "Autonomous driving requires efficient reasoning about the Spatio-temporal\nnature of the semantics of the scene. Recent approaches have successfully\namalgamated the traditional modular architecture of an autonomous driving stack\ncomprising perception, prediction, and planning in an end-to-end trainable\nsystem. Such a system calls for a shared latent space embedding with\ninterpretable intermediate trainable projected representation. One such\nsuccessfully deployed representation is the Bird's-Eye View(BEV) representation\nof the scene in ego-frame. However, a fundamental assumption for an undistorted\nBEV is the local coplanarity of the world around the ego-vehicle. This\nassumption is highly restrictive, as roads, in general, do have gradients. The\nresulting distortions make path planning inefficient and incorrect. To overcome\nthis limitation, we propose Neural Manifold Representation (NMR), a\nrepresentation for the task of autonomous driving that learns to infer\nsemantics and predict way-points on a manifold over a finite horizon, centered\non the ego-vehicle. We do this using an iterative attention mechanism applied\non a latent high dimensional embedding of surround monocular images and partial\nego-vehicle state. This representation helps generate motion and behavior plans\nconsistent with and cognizant of the surface geometry. We propose a sampling\nalgorithm based on edge-adaptive coverage loss of BEV occupancy grid and\nassociated guidance flow field to generate the surface manifold while incurring\nminimal computational overhead. We aim to test the efficacy of our approach on\nCARLA and SYNTHIA-SF.",
    "descriptor": "",
    "authors": [
      "Unnikrishnan R. Nair",
      "Sarthak Sharma",
      "Midhun S. Menon",
      "Srikanth Vidapanakal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.05551"
  },
  {
    "id": "arXiv:2205.05563",
    "title": "Access Trends of In-network Cache for Scientific Data",
    "abstract": "Scientific collaborations are increasingly relying on large volumes of data\nfor their work and many of them employ tiered systems to replicate the data to\ntheir worldwide user communities. Each user in the community often selects a\ndifferent subset of data for their analysis tasks; however, members of a\nresearch group often are working on related research topics that require\nsimilar data objects. Thus, there is a significant amount of data sharing\npossible. In this work, we study the access traces of a federated storage cache\nknown as the Southern California Petabyte Scale Cache. By studying the access\npatterns and potential for network traffic reduction by this caching system, we\naim to explore the predictability of the cache uses and the potential for a\nmore general in-network data caching. Our study shows that this distributed\nstorage cache is able to reduce the network traffic volume by a factor of 2.35\nduring a part of the study period. We further show that machine learning models\ncould predict cache utilization with an accuracy of 0.88. This demonstrates\nthat such cache usage is predictable, which could be useful for managing\ncomplex networking resources such as in-network caching.",
    "descriptor": "",
    "authors": [
      "Ruize Han",
      "Alex Sim",
      "Kesheng Wu",
      "Inder Monga",
      "Chin Guok",
      "Frank W\u00fcrthwein",
      "Diego Davila",
      "Justas Balcas",
      "Harvey Newman"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2205.05563"
  },
  {
    "id": "arXiv:2205.05569",
    "title": "Delayed Reinforcement Learning by Imitation",
    "abstract": "When the agent's observations or interactions are delayed, classic\nreinforcement learning tools usually fail. In this paper, we propose a simple\nyet new and efficient solution to this problem. We assume that, in the\nundelayed environment, an efficient policy is known or can be easily learned,\nbut the task may suffer from delays in practice and we thus want to take them\ninto account. We present a novel algorithm, Delayed Imitation with Dataset\nAggregation (DIDA), which builds upon imitation learning methods to learn how\nto act in a delayed environment from undelayed demonstrations. We provide a\ntheoretical analysis of the approach that will guide the practical design of\nDIDA. These results are also of general interest in the delayed reinforcement\nlearning literature by providing bounds on the performance between delayed and\nundelayed tasks, under smoothness conditions. We show empirically that DIDA\nobtains high performances with a remarkable sample efficiency on a variety of\ntasks, including robotic locomotion, classic control, and trading.",
    "descriptor": "",
    "authors": [
      "Pierre Liotet",
      "Davide Maran",
      "Lorenzo Bisi",
      "Marcello Restelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05569"
  },
  {
    "id": "arXiv:2205.05570",
    "title": "Review on Panoramic Imaging and Its Applications in Scene Understanding",
    "abstract": "With the rapid development of high-speed communication and artificial\nintelligence technologies, human perception of real-world scenes is no longer\nlimited to the use of small Field of View (FoV) and low-dimensional scene\ndetection devices. Panoramic imaging emerges as the next generation of\ninnovative intelligent instruments for environmental perception and\nmeasurement. However, while satisfying the need for large-FoV photographic\nimaging, panoramic imaging instruments are expected to have high resolution, no\nblind area, miniaturization, and multi-dimensional intelligent perception, and\ncan be combined with artificial intelligence methods towards the next\ngeneration of intelligent instruments, enabling deeper understanding and more\nholistic perception of 360-degree real-world surrounding environments.\nFortunately, recent advances in freeform surfaces, thin-plate optics, and\nmetasurfaces provide innovative approaches to address human perception of the\nenvironment, offering promising ideas beyond conventional optical imaging. In\nthis review, we begin with introducing the basic principles of panoramic\nimaging systems, and then describe the architectures, features, and functions\nof various panoramic imaging systems. Afterwards, we discuss in detail the\nbroad application prospects and great design potential of freeform surfaces,\nthin-plate optics, and metasurfaces in panoramic imaging. We then provide a\ndetailed analysis on how these techniques can help enhance the performance of\npanoramic imaging systems. We further offer a detailed analysis of applications\nof panoramic imaging in scene understanding for autonomous driving and\nrobotics, spanning panoramic semantic image segmentation, panoramic depth\nestimation, panoramic visual localization, and so on. Finally, we cast a\nperspective on future potential and research directions for panoramic imaging\ninstruments.",
    "descriptor": "\nComments: 29 pages, 14 figures, 348 references\n",
    "authors": [
      "Shaohua Gao",
      "Kailun Yang",
      "Hao Shi",
      "Kaiwei Wang",
      "Jian Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2205.05570"
  },
  {
    "id": "arXiv:2205.05572",
    "title": "Face Detection on Mobile: Five Implementations and Analysis",
    "abstract": "In many practical cases face detection on smartphones or other highly\nportable devices is a necessity. Applications include mobile face access\ncontrol systems, driver status tracking, emotion recognition, etc. Mobile\ndevices have limited processing power and should have long-enough battery life\neven with face detection application running. Thus, striking the right balance\nbetween algorithm quality and complexity is crucial. In this work we adapt 5\nalgorithms to mobile. These algorithms are based on handcrafted or\nneural-network-based features and include: Viola-Jones (Haar cascade), LBP,\nHOG, MTCNN, BlazeFace. We analyze inference time of these algorithms on\ndifferent devices with different input image resolutions. We provide guidance,\nwhich algorithms are the best fit for mobile face access control systems and\npotentially other mobile applications. Interestingly, we note that cascaded\nalgorithms perform faster on scenes without faces, while BlazeFace is slower on\nempty scenes. Exploiting this behavior might be useful in practice.",
    "descriptor": "",
    "authors": [
      "Kostiantyn Khabarlak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.05572"
  },
  {
    "id": "arXiv:2205.05573",
    "title": "A Longitudal Study of Cryptographic API -- a Decade of Android Malware",
    "abstract": "Cryptography has been extensively used in Android applications to guarantee\nsecure communications, conceal critical data from reverse engineering, or\nensure mobile users' privacy. Various system-based and third-party libraries\nfor Android provide cryptographic functionalities, and previous works mainly\nexplored the misuse of cryptographic API in benign applications. However, the\nrole of cryptographic API has not yet been explored in Android malware. This\npaper performs a comprehensive, longitudinal analysis of cryptographic API in\nAndroid malware. In particular, we analyzed $603\\,937$ Android applications\n(half of them malicious, half benign) released between $2012$ and $2020$,\ngathering more than 1 million cryptographic API expressions. Our results reveal\nintriguing trends and insights on how and why cryptography is employed in\nAndroid malware. For instance, we point out the widespread use of weak hash\nfunctions and the late transition from insecure DES to AES. Additionally, we\nshow that cryptography-related characteristics can help to improve the\nperformance of learning-based systems in detecting malicious applications.",
    "descriptor": "",
    "authors": [
      "Adam Janovsky",
      "Davide Maiorca",
      "Dominik Macko",
      "Vashek Matyas",
      "Giorgio Giacinto"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.05573"
  },
  {
    "id": "arXiv:2205.05575",
    "title": "DoubleMatch: Improving Semi-Supervised Learning with Self-Supervision",
    "abstract": "Following the success of supervised learning, semi-supervised learning (SSL)\nis now becoming increasingly popular. SSL is a family of methods, which in\naddition to a labeled training set, also use a sizable collection of unlabeled\ndata for fitting a model. Most of the recent successful SSL methods are based\non pseudo-labeling approaches: letting confident model predictions act as\ntraining labels. While these methods have shown impressive results on many\nbenchmark datasets, a drawback of this approach is that not all unlabeled data\nare used during training. We propose a new SSL algorithm, DoubleMatch, which\ncombines the pseudo-labeling technique with a self-supervised loss, enabling\nthe model to utilize all unlabeled data in the training process. We show that\nthis method achieves state-of-the-art accuracies on multiple benchmark datasets\nwhile also reducing training times compared to existing SSL methods. Code is\navailable at https://github.com/walline/doublematch.",
    "descriptor": "\nComments: ICPR2022\n",
    "authors": [
      "Erik Wallin",
      "Lennart Svensson",
      "Fredrik Kahl",
      "Lars Hammarstrand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.05575"
  },
  {
    "id": "arXiv:2205.05577",
    "title": "Channel Estimation in RIS-assisted Downlink Massive MIMO: A  Learning-Based Approach",
    "abstract": "For downlink massive multiple-input multiple-output (MIMO) operating in\ntime-division duplex protocol, users can decode the signals effectively by only\nutilizing the channel statistics as long as channel hardening holds. However,\nin a reconfigurable intelligent surface (RIS)-assisted massive MIMO system, the\npropagation channels may be less hardened due to the extra random fluctuations\nof the effective channel gains. To address this issue, we propose a\nlearning-based method that trains a neural network to learn a mapping between\nthe received downlink signal and the effective channel gains. The proposed\nmethod does not require any downlink pilots and statistical information of\ninterfering users. Numerical results show that, in terms of mean-square error\nof the channel estimation, our proposed learning-based method outperforms the\nstate-of-the-art methods, especially when the light-of-sight (LoS) paths are\ndominated by non-LoS paths with a low level of channel hardening, e.g., in the\ncases of small numbers of RIS elements and/or base station antennas.",
    "descriptor": "\nComments: accepted to appear in IEEE SPAWC'22, Oulu, Finland\n",
    "authors": [
      "Tung T. Vu",
      "Trinh Van Chien",
      "Canh T. Dinh",
      "Hien Quoc Ngo",
      "Michail Matthaiou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.05577"
  },
  {
    "id": "arXiv:2205.05580",
    "title": "Scream Detection in Heavy Metal Music",
    "abstract": "Harsh vocal effects such as screams or growls are far more common in heavy\nmetal vocals than the traditionally sung vocal. This paper explores the problem\nof detection and classification of extreme vocal techniques in heavy metal\nmusic, specifically the identification of different scream techniques. We\ninvestigate the suitability of various feature representations, including\ncepstral, spectral, and temporal features as input representations for\nclassification. The main contributions of this work are (i) a manually\nannotated dataset comprised of over 280 minutes of heavy metal songs of various\ngenres with a statistical analysis of occurrences of different extreme vocal\ntechniques in heavy metal music, and (ii) a systematic study of different input\nfeature representations for the classification of heavy metal vocals",
    "descriptor": "",
    "authors": [
      "Vedant Kalbag",
      "Alexander Lerch"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.05580"
  },
  {
    "id": "arXiv:2205.05583",
    "title": "TDT: Teaching Detectors to Track without Fully Annotated Videos",
    "abstract": "Recently, one-stage trackers that use a joint model to predict both\ndetections and appearance embeddings in one forward pass received much\nattention and achieved state-of-the-art results on the Multi-Object Tracking\n(MOT) benchmarks. However, their success depends on the availability of videos\nthat are fully annotated with tracking data, which is expensive and hard to\nobtain. This can limit the model generalization. In comparison, the two-stage\napproach, which performs detection and embedding separately, is slower but\neasier to train as their data are easier to annotate. We propose to combine the\nbest of the two worlds through a data distillation approach. Specifically, we\nuse a teacher embedder, trained on Re-ID datasets, to generate pseudo\nappearance embedding labels for the detection datasets. Then, we use the\naugmented dataset to train a detector that is also capable of regressing these\npseudo-embeddings in a fully-convolutional fashion. Our proposed one-stage\nsolution matches the two-stage counterpart in quality but is 3 times faster.\nEven though the teacher embedder has not seen any tracking data during\ntraining, our proposed tracker achieves competitive performance with some\npopular trackers (e.g. JDE) trained with fully labeled tracking data.",
    "descriptor": "\nComments: Workshop on Learning with Limited Labelled Data for Image and Video Understanding (L3D-IVU), CVPR2022 Workshop\n",
    "authors": [
      "Shuzhi Yu",
      "Guanhang Wu",
      "Chunhui Gu",
      "Mohammed E. Fathy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.05583"
  },
  {
    "id": "arXiv:2205.05588",
    "title": "Characterizing the Action-Generalization Gap in Deep Q-Learning",
    "abstract": "We study the action generalization ability of deep Q-learning in discrete\naction spaces. Generalization is crucial for efficient reinforcement learning\n(RL) because it allows agents to use knowledge learned from past experiences on\nnew tasks. But while function approximation provides deep RL agents with a\nnatural way to generalize over state inputs, the same generalization mechanism\ndoes not apply to discrete action outputs. And yet, surprisingly, our\nexperiments indicate that Deep Q-Networks (DQN), which use exactly this type of\nfunction approximator, are still able to achieve modest action generalization.\nOur main contribution is twofold: first, we propose a method of evaluating\naction generalization using expert knowledge of action similarity, and\nempirically confirm that action generalization leads to faster learning;\nsecond, we characterize the action-generalization gap (the difference in\nlearning performance between DQN and the expert) in different domains. We find\nthat DQN can indeed generalize over actions in several simple domains, but that\nits ability to do so decreases as the action space grows larger.",
    "descriptor": "\nComments: To appear at the 5th Multidisciplinary Conference on Reinforcement Learning and Decision Making (RLDM2022)\n",
    "authors": [
      "Zhiyuan Zhou",
      "Cameron Allen",
      "Kavosh Asadi",
      "George Konidaris"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05588"
  },
  {
    "id": "arXiv:2205.05589",
    "title": "KETOD: Knowledge-Enriched Task-Oriented Dialogue",
    "abstract": "Existing studies in dialogue system research mostly treat task-oriented\ndialogue and chit-chat as separate domains. Towards building a human-like\nassistant that can converse naturally and seamlessly with users, it is\nimportant to build a dialogue system that conducts both types of conversations\neffectively. In this work, we investigate how task-oriented dialogue and\nknowledge-grounded chit-chat can be effectively integrated into a single model.\nTo this end, we create a new dataset, KETOD (Knowledge-Enriched Task-Oriented\nDialogue), where we naturally enrich task-oriented dialogues with chit-chat\nbased on relevant entity knowledge. We also propose two new models,\nSimpleToDPlus and Combiner, for the proposed task. Experimental results on both\nautomatic and human evaluations show that the proposed methods can\nsignificantly improve the performance in knowledge-enriched response generation\nwhile maintaining a competitive task-oriented dialog performance. We believe\nour new dataset will be a valuable resource for future studies. Our dataset and\ncode are publicly available at \\url{https://github.com/facebookresearch/ketod}.",
    "descriptor": "\nComments: NAACL 2022 Findings\n",
    "authors": [
      "Zhiyu Chen",
      "Bing Liu",
      "Seungwhan Moon",
      "Chinnadhurai Sankar",
      "Paul Crook",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.05589"
  },
  {
    "id": "arXiv:2205.05590",
    "title": "A neural prosody encoder for end-ro-end dialogue act classification",
    "abstract": "Dialogue act classification (DAC) is a critical task for spoken language\nunderstanding in dialogue systems. Prosodic features such as energy and pitch\nhave been shown to be useful for DAC. Despite their importance, little research\nhas explored neural approaches to integrate prosodic features into end-to-end\n(E2E) DAC models which infer dialogue acts directly from audio signals. In this\nwork, we propose an E2E neural architecture that takes into account the need\nfor characterizing prosodic phenomena co-occurring at different levels inside\nan utterance. A novel part of this architecture is a learnable gating mechanism\nthat assesses the importance of prosodic features and selectively retains core\ninformation necessary for E2E DAC. Our proposed model improves DAC accuracy by\n1.07% absolute across three publicly available benchmark datasets.",
    "descriptor": "",
    "authors": [
      "Kai Wei",
      "Dillon Knox",
      "Martin Radfar",
      "Thanh Tran",
      "Markus Muller",
      "Grant P. Strimel",
      "Nathan Susanj",
      "Athanasios Mouchtaris",
      "Maurizio Omologo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.05590"
  },
  {
    "id": "arXiv:2205.05593",
    "title": "Identifying Moments of Change from Longitudinal User Text",
    "abstract": "Identifying changes in individuals' behaviour and mood, as observed via\ncontent shared on online platforms, is increasingly gaining importance. Most\nresearch to-date on this topic focuses on either: (a) identifying individuals\nat risk or with a certain mental health condition given a batch of posts or (b)\nproviding equivalent labels at the post level. A disadvantage of such work is\nthe lack of a strong temporal component and the inability to make longitudinal\nassessments following an individual's trajectory and allowing timely\ninterventions. Here we define a new task, that of identifying moments of change\nin individuals on the basis of their shared content online. The changes we\nconsider are sudden shifts in mood (switches) or gradual mood progression\n(escalations). We have created detailed guidelines for capturing moments of\nchange and a corpus of 500 manually annotated user timelines (18.7K posts). We\nhave developed a variety of baseline models drawing inspiration from related\ntasks and show that the best performance is obtained through context aware\nsequential modelling. We also introduce new metrics for capturing rare events\nin temporal windows.",
    "descriptor": "\nComments: Preprint accepted for publication in ACL 2022\n",
    "authors": [
      "Adam Tsakalidis",
      "Federico Nanni",
      "Anthony Hills",
      "Jenny Chim",
      "Jiayu Song",
      "Maria Liakata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.05593"
  },
  {
    "id": "arXiv:2205.05594",
    "title": "Delay Encryption by Cubing",
    "abstract": "Delay Encryption (often called Timed-Release Encryption) is a scheme in which\na message is sent into the future by ensuring its confidentiality only for a\ngiven amount of time. We propose a new scheme based on a novel time-lock\npuzzle. This puzzle relies on the assumption that repeated squaring is an\ninherently sequential process. We perform an extensive and practical analysis\nof many classical and quantum attacks on our scheme and conclude that it is\nsecure given some precautions.",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Ivo Maffei",
      "A. W. Roscoe"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.05594"
  },
  {
    "id": "arXiv:2205.05598",
    "title": "Studying Scientific Data Lifecycle in On-demand Distributed Storage  Caches",
    "abstract": "The XRootD system is used to transfer, store, and cache large datasets from\nhigh-energy physics (HEP). In this study we focus on its capability as\ndistributed on-demand storage cache. Through exploring a large set of daily log\nfiles between 2020 and 2021, we seek to understand the data access patterns\nthat might inform future cache design. Our study begins with a set of summary\nstatistics regarding file read operations, file lifetimes, and file transfers.\nWe observe that the number of read operations on each file remains nearly\nconstant, while the average size of a read operation grows over time.\nFurthermore, files tend to have a consistent length of time during which they\nremain open and are in use. Based on this comprehensive study of the cache\naccess statistics, we developed a cache simulator to explore the behavior of\ncaches of different sizes. Within a certain size range, we find that increasing\nthe XRootD cache size improves the cache hit rate, yielding faster overall file\naccess. In particular, we find that increase the cache size from 40TB to 56TB\ncould increase the hit rate from 0.62 to 0.89, which is a significant increase\nin cache effectiveness for modest cost.",
    "descriptor": "",
    "authors": [
      "Julian Bellavita",
      "Alex Sim",
      "Kesheng Wu",
      "Inder Monga",
      "Chin Guok",
      "Frank W\u00fcrthwein",
      "Diego Davila"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.05598"
  },
  {
    "id": "arXiv:2205.05604",
    "title": "The Fluctuating Two-Ray Fading Model with Independent Specular  Components",
    "abstract": "We introduce and characterize the independent fluctuating two-ray (IFTR)\nfading model, a class of fading models consisting of two specular components\nwhich fluctuate independently, plus a diffuse component modeled as a complex\nGaussian random variable. The IFTR model complements the popular fluctuating\ntwo-ray (FTR) model, on which the specular components are fully correlated and\nfluctuate jointly. The chief probability functions of the received SNR in IFTR\nfading, including the PDF, CDF and MGF, are expressed in closed-form, having a\nfunctional form similar to other state-of-the-art fading models. Then, the IFTR\nmodel is empirically validated using multiple channels measured in rather\ndiverse scenarios, including line of sight (LOS) millimeter-wave, land mobile\nsatellite (LMS) and underwater acoustic communication (UAC), showing a better\nfit than the original FTR model and other models previously used in these\nenvironments. Additionally, the performance of wireless communication systems\noperating under IFTR fading is evaluated in closed-form in two scenarios: (i)\nexact and asymptotic bit error rate for a family of coherent modulations; and\n(ii) exact and asymptotic outage probability.",
    "descriptor": "\nComments: 11 pages, 8 figures. arXiv admin note: text overlap with arXiv:1611.05063\n",
    "authors": [
      "Maryam Olyaee",
      "Jos\u00e9 A. Cort\u00e9s",
      "F. Javier Lopez-Martinez",
      "Jos\u00e9 F. Paris",
      "Juan M. Romero-Jerez"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.05604"
  },
  {
    "id": "arXiv:2205.05609",
    "title": "Video-ReTime: Learning Temporally Varying Speediness for Time Remapping",
    "abstract": "We propose a method for generating a temporally remapped video that matches\nthe desired target duration while maximally preserving natural video dynamics.\nOur approach trains a neural network through self-supervision to recognize and\naccurately localize temporally varying changes in the video playback speed. To\nre-time videos, we 1. use the model to infer the slowness of individual video\nframes, and 2. optimize the temporal frame sub-sampling to be consistent with\nthe model's slowness predictions. We demonstrate that this model can detect\nplayback speed variations more accurately while also being orders of magnitude\nmore efficient than prior approaches. Furthermore, we propose an optimization\nfor video re-timing that enables precise control over the target duration and\nperforms more robustly on longer videos than prior methods. We evaluate the\nmodel quantitatively on artificially speed-up videos, through transfer to\naction recognition, and qualitatively through user studies.",
    "descriptor": "\nComments: Accepted at the AI for Content Creation (AICC) workshop at CVPR 2022\n",
    "authors": [
      "Simon Jenni",
      "Markus Woodson",
      "Fabian Caba Heilbron"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.05609"
  },
  {
    "id": "arXiv:2205.05611",
    "title": "Blockchain-based Secure Client Selection in Federated Learning",
    "abstract": "Despite the great potential of Federated Learning (FL) in large-scale\ndistributed learning, the current system is still subject to several privacy\nissues due to the fact that local models trained by clients are exposed to the\ncentral server. Consequently, secure aggregation protocols for FL have been\ndeveloped to conceal the local models from the server. However, we show that,\nby manipulating the client selection process, the server can circumvent the\nsecure aggregation to learn the local models of a victim client, indicating\nthat secure aggregation alone is inadequate for privacy protection. To tackle\nthis issue, we leverage blockchain technology to propose a verifiable client\nselection protocol. Owing to the immutability and transparency of blockchain,\nour proposed protocol enforces a random selection of clients, making the server\nunable to control the selection process at its discretion. We present security\nproofs showing that our protocol is secure against this attack. Additionally,\nwe conduct several experiments on an Ethereum-like blockchain to demonstrate\nthe feasibility and practicality of our solution.",
    "descriptor": "\nComments: IEEE ICBC 2022\n",
    "authors": [
      "Truc Nguyen",
      "Phuc Thai",
      "Tre' R. Jeter",
      "Thang N. Dinh",
      "My T. Thai"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05611"
  },
  {
    "id": "arXiv:2205.05622",
    "title": "Computing control invariant sets of nonlinear systems: decomposition and  distributed computing",
    "abstract": "In this work, we present a distributed framework based on the graph algorithm\nfor computing control invariant set for nonlinear cascade systems. The proposed\nalgorithm exploits the structure of the interconnections within a process\nnetwork. First, the overall system is decomposed into several subsystems with\noverlapping states. Second, the control invariant set for the subsystems are\ncomputed in a distributed manner. Finally, an approximation of the control\ninvariant set for the overall system is reconstructed from the subsystem\nsolutions and validated. We demonstrate the efficacy and convergence of the\nproposed method to the centralized graph-based algorithm using several\nnumerical examples including a six dimensional continuous stirred tank reactor\nsystem.",
    "descriptor": "",
    "authors": [
      "Benjamin Decardi-Nelson",
      "Jinfeng Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.05622"
  },
  {
    "id": "arXiv:2205.05626",
    "title": "High-Speed Imaging Receiver Design for 6G Optical Wireless  Communications: A Rate-FOV Trade-Off",
    "abstract": "The design of a compact high-speed and wide field of view (FOV) receiver is\nchallenging due to the presence of two well-known trade-offs. The first one is\nthe area-bandwidth trade-off of photodetectors (PDs) and the second one is the\ngain-FOV trade-off due to the use of optics. The combined effects of these two\ntrade-offs imply that the achievable data rate of an imaging optical receiver\nis limited by its FOV, i.e., a rate-FOV trade-off. To control the\narea-bandwidth trade-off, an array of small PDs can be used instead of a single\nPD. Moreover, in practice, a large-area lens is required to ensure sufficient\npower collection, which in turn limits the receiver FOV (i.e., gain-FOV\ntrade-off). We propose an imaging receiver design in the form of an array of\narrays. To achieve a reasonable receiver FOV, we use individual focusing lens\nfor each PD array rather than a single collection lens for the whole receiver.\nThe proposed array of arrays structure provides an effective method to control\nboth gain-FOV trade-off (via an array of lenses) and area-bandwidth trade-off\n(via arrays of PDs). We first derive a tractable analytical model for the SNR\nof an array of PDs where the maximum ratio combining has been employed. Then,\nwe extend the model for the proposed array of arrays structure and the accuracy\nof the analytical model is verified based on several Optic Studio-based\nsimulations. Next, we formulate an optimization problem to maximize the\nachievable data rate of the imaging receiver subject to a minimum required FOV.\nThe optimization problem is solved for two commonly used modulation techniques,\nnamely, OOK and direct current biased optical orthogonal frequency division\nmultiplexing with variable rate quadrature amplitude modulation. It is\ndemonstrated that a data rate of ~ 24 Gbps with a FOV of 15 is achievable using\nOOK with a total receiver size of 2 cm by 2 cm.",
    "descriptor": "\nComments: 30 pages, 15 Figures and 6 Tables\n",
    "authors": [
      "Mohammad Dehghani Soltani",
      "Hossein Kazemi",
      "Elham Sarbazi",
      "Taisir E. H. El-Gorashi",
      "Jaafar M. H. Elmirghani",
      "Richard V. Penty",
      "Ian H. White",
      "Harald Haas",
      "Majid Safari"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.05626"
  },
  {
    "id": "arXiv:2205.05627",
    "title": "On Upward-Planar L-Drawings of Graphs",
    "abstract": "In an upward-planar L-drawing of a directed acyclic graph (DAG) each edge $e$\nis represented as a polyline composed of a vertical segment with its lowest\nendpoint at the tail of $e$ and of a horizontal segment ending at the head of\n$e$. Distinct edges may overlap, but not cross. Recently, upward-planar\nL-drawings have been studied for $st$-graphs, i.e., planar DAGs with a single\nsource $s$ and a single sink $t$ containing an edge directed from $s$ to $t$.\nIt is known that a plane $st$-graph, i.e., an embedded $st$-graph in which the\nedge $(s,t)$ is incident to the outer face, admits an upward-planar L-drawing\nif and only if it admits a bitonic $st$-ordering, which can be tested in linear\ntime.\nWe study upward-planar L-drawings of DAGs that are not necessarily\n$st$-graphs. On the combinatorial side, we show that a plane DAG admits an\nupward-planar L-drawing if and only if it is a subgraph of a plane $st$-graph\nadmitting a bitonic $st$-ordering. This allows us to show that not every tree\nwith a fixed bimodal embedding admits an upward-planar L-drawing. Moreover, we\nprove that any acyclic cactus with a single source (or a single sink) admits an\nupward-planar L-drawing, which respects a given outerplanar embedding if there\nare no transitive edges. On the algorithmic side, we consider DAGs with a\nsingle source (or a single sink). We give linear-time testing algorithms for\nthese DAGs in two cases: (i) when the drawing must respect a prescribed\nembedding and (ii) when no restriction is given on the embedding, but each\nbiconnected component is series-parallel.",
    "descriptor": "\nComments: 27 pages, 8 figures\n",
    "authors": [
      "Patrizio Angelini",
      "Steven Chaplick",
      "Sabine Cornelsen",
      "Giordano Da Lozzo"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.05627"
  },
  {
    "id": "arXiv:2205.05628",
    "title": "Extensible Machine Learning for Encrypted Network Traffic Application  Labeling via Uncertainty Quantification",
    "abstract": "With the increasing prevalence of encrypted network traffic, cyber security\nanalysts have been turning to machine learning (ML) techniques to elucidate the\ntraffic on their networks. However, ML models can become stale as known traffic\nfeatures can shift between networks and as new traffic emerges that is outside\nof the distribution of the training set. In order to reliably adapt in this\ndynamic environment, ML models must additionally provide contextualized\nuncertainty quantification to their predictions, which has received little\nattention in the cyber security domain. Uncertainty quantification is necessary\nboth to signal when the model is uncertain about which class to choose in its\nlabel assignment and when the traffic is not likely to belong to any\npre-trained classes.\nWe present a new, public dataset of network traffic that includes labeled,\nVirtual Private Network (VPN)-encrypted network traffic generated by 10\napplications and corresponding to 5 application categories. We also present an\nML framework that is designed to rapidly train with modest data requirements\nand provide both calibrated, predictive probabilities as well as an\ninterpretable ``out-of-distribution'' (OOD) score to flag novel traffic\nsamples. We describe how to compute a calibrated OOD score from p-values of the\nso-called relative Mahalanobis distance.\nWe demonstrate that our framework achieves an F1 score of 0.98 on our dataset\nand that it can extend to an enterprise network by testing the model: (1) on\ndata from similar applications, (2) on dissimilar application traffic from an\nexisting category, and (3) on application traffic from a new category. The\nmodel correctly flags uncertain traffic and, upon retraining, accurately\nincorporates the new data. We additionally demonstrate good performance (F1\nscore of 0.97) when packet sizes are made to be uniform, as occurs for certain\nencryption protocols.",
    "descriptor": "\nComments: Paper is 13 pages and has 9 figures. For associated dataset, see this https URL\n",
    "authors": [
      "Steven Jorgensen",
      "John Holodnak",
      "Jensen Dempsey",
      "Karla de Souza",
      "Ananditha Raghunath",
      "Vernon Rivet",
      "Noah DeMoes",
      "Andr\u00e9s Alejos",
      "Allan Wollaber"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05628"
  },
  {
    "id": "arXiv:2205.05630",
    "title": "Benefits of Feedforward for Model Predictive Airpath Control of Diesel  Engines",
    "abstract": "This paper investigates options to complement a diesel engine airpath\nfeedback controller with a feedforward. The control objective is to track the\nintake manifold pressure and exhaust gas recirculation (EGR) rate targets by\nmanipulating the EGR valve and variable geometry turbine (VGT) while satisfying\nstate and input constraints. The feedback controller is based on rate-based\nModel Predictive Control (MPC) that provides integral action for tracking. Two\noptions for the feedforward are considered one based on a look-up table that\nspecifies the feedforward as a function of engine speed and fuel injection\nrate, and another one based on a (non-rate-based) MPC that generates dynamic\nfeedforward trajectories. The controllers are designed and verified using a\nhigh-fidelity engine model in GT-Power and exploit a low-order rate-based\nlinear parameter-varying (LPV) model for prediction which is identified from\ntransient response data generated by the GT-Power model. It is shown that the\ncombination of feedforward and feedback MPC has the potential to improve the\nperformance and robustness of the control design. In particular, the feedback\nMPC without feedforward can lose stability at low engine speeds, while\nMPC-based feedforward results in the best transient response. Mechanisms by\nwhich feedforward is able to assist in stabilization and improve performance\nare discussed.",
    "descriptor": "\nComments: 10th IFAC Symposium on Robust Control Design (ROCOND), August 30-September 2, 2022, Kyoto, Japan\n",
    "authors": [
      "Jiadi Zhang",
      "Mohammad Reza Amini",
      "Ilya Kolmanovsky",
      "Munechika Tsutsumi",
      "Hayato Nakada"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.05630"
  },
  {
    "id": "arXiv:2205.05631",
    "title": "Second-Order Asymptotics of Hoeffding-Like Hypothesis Tests",
    "abstract": "We consider a binary statistical hypothesis testing problem, where $n$\nindependent and identically distributed random variables $Z^n$ are either\ndistributed according to the null hypothesis $P$ or the alternate hypothesis\n$Q$, and only $P$ is known. For this problem, a well-known test is the\nHoeffding test, which accepts $P$ if the Kullback-Leibler (KL) divergence\nbetween the empirical distribution of $Z^n$ and $P$ is below some threshold. In\nthis paper, we consider Hoeffding-like tests, where the KL divergence is\nreplaced by other divergences, and characterize, for a large class of\ndivergences, the first and second-order terms of the type-II error for a fixed\ntype-I error. Since the considered class includes the KL divergence, we obtain\nthe second-order term of the Hoeffiding test as a special case.",
    "descriptor": "\nComments: 26 pages. Submitted to the 2022 IEEE Information Theory Workshop\n",
    "authors": [
      "K. V. Harsha",
      "Jithin Ravi",
      "Tobias Koch"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.05631"
  },
  {
    "id": "arXiv:2205.05638",
    "title": "Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than  In-Context Learning",
    "abstract": "Few-shot in-context learning (ICL) enables pre-trained language models to\nperform a previously-unseen task without any gradient-based training by feeding\na small number of training examples as part of the input. ICL incurs\nsubstantial computational, memory, and storage costs because it involves\nprocessing all of the training examples every time a prediction is made.\nParameter-efficient fine-tuning (e.g. adapter modules, prompt tuning, sparse\nupdate methods, etc.) offers an alternative paradigm where a small set of\nparameters are trained to enable a model to perform the new task. In this\npaper, we rigorously compare few-shot ICL and parameter-efficient fine-tuning\nand demonstrate that the latter offers better accuracy as well as dramatically\nlower computational costs. Along the way, we introduce a new\nparameter-efficient fine-tuning method called (IA)$^3$ that scales activations\nby learned vectors, attaining stronger performance while only introducing a\nrelatively tiny amount of new parameters. We also propose a simple recipe based\non the T0 model called T-Few that can be applied to new tasks without\ntask-specific tuning or modifications. We validate the effectiveness of T-Few\non completely unseen tasks by applying it to the RAFT benchmark, attaining\nsuper-human performance for the first time and outperforming the\nstate-of-the-art by 6% absolute. All of the code used in our experiments is\npublicly available.",
    "descriptor": "",
    "authors": [
      "Haokun Liu",
      "Derek Tam",
      "Mohammed Muqeeth",
      "Jay Mohta",
      "Tenghao Huang",
      "Mohit Bansal",
      "Colin Raffel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.05638"
  },
  {
    "id": "arXiv:2205.05643",
    "title": "A New Class of String Transformations for Compressed Text Indexing",
    "abstract": "Introduced about thirty years ago in the field of Data Compression, the\nBurrows-Wheeler Transform (BWT) is a string transformation that, besides being\na booster of the performance of memoryless compressors, plays a fundamental\nrole in the design of efficient self-indexing compressed data structures.\nFinding other string transformations with the same remarkable properties of BWT\nhas been a challenge for many researchers for a long time. Among the known BWT\nvariants, the only one that has been recently shown to be a valid alternative\nto BWT is the Alternating BWT (ABWT), another invertible string transformation\nintroduced about ten years ago in connection with a generalization of Lyndon\nwords. In this paper, we introduce a whole class of new string transformations,\ncalled local orderings-based transformations, which have all the myriad virtues\nof BWT. We show that this new family is a special case of a much larger class\nof transformations, based on context adaptive alphabet orderings, that includes\nBWT and ABWT. Although all transformations support pattern search, we show\nthat, in the general case, the transformations within our larger class may take\nquadratic time for inversion and pattern search. As a further result, we show\nthat the local orderings-based transformations can be used for the construction\nof the recently introduced r-index, which makes them suitable also for highly\nrepetitive collections. In this context, we consider the problem of finding,\nfor a given string, the BWT variant that minimizes the number of runs in the\ntransformed string, and we provide an algorithm solving this problem in linear\ntime.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1902.01280\n",
    "authors": [
      "Raffaele Giancarlo",
      "Giovanni Manzini",
      "Antonio Restivo",
      "Giovanna Rosone",
      "Marinella Sciortino"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.05643"
  },
  {
    "id": "arXiv:2205.05646",
    "title": "Aggregating Pairwise Semantic Differences for Few-Shot Claim Veracity  Classification",
    "abstract": "As part of an automated fact-checking pipeline, the claim veracity\nclassification task consists in determining if a claim is supported by an\nassociated piece of evidence. The complexity of gathering labelled\nclaim-evidence pairs leads to a scarcity of datasets, particularly when dealing\nwith new domains. In this paper, we introduce SEED, a novel vector-based method\nto few-shot claim veracity classification that aggregates pairwise semantic\ndifferences for claim-evidence pairs. We build on the hypothesis that we can\nsimulate class representative vectors that capture average semantic differences\nfor claim-evidence pairs in a class, which can then be used for classification\nof new instances. We compare the performance of our method with competitive\nbaselines including fine-tuned BERT/RoBERTa models, as well as the\nstate-of-the-art few-shot veracity classification method that leverages\nlanguage model perplexity. Experiments conducted on the FEVER and SCIFACT\ndatasets show consistent improvements over competitive baselines in few-shot\nsettings. Our code is available.",
    "descriptor": "",
    "authors": [
      "Xia Zeng",
      "Arkaitz Zubiaga"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05646"
  },
  {
    "id": "arXiv:2205.05649",
    "title": "Any-k Algorithms for Enumerating Ranked Answers to Conjunctive Queries",
    "abstract": "We study ranked enumeration for Conjunctive Queries (CQs) where the answers\nare ordered by a given ranking function (e.g., an ORDER BY clause in SQL). We\ndevelop \"any-k\" algorithms which, without knowing the number k of desired\nanswers, push the ranking into joins and avoid materializing the join output\nearlier than necessary. For this to be possible, the ranking function needs to\nobey a certain kind of monotonicity; the supported ranking functions include\nthe common sum-of-weights case where query answers are compared by sums of\ninput weights, as well as any commutative selective dioid. One core insight of\nour work is that the problem is closely related to the fundamental task of path\nenumeration in a weighted DAG. We generalize and improve upon classic research\non finding the k'th shortest path and unify into the same framework several\nsolutions from different areas that had been studied in isolation. For the time\nto the k'th ranked CQ answer (for every value of k), our approach is optimal in\ndata complexity precisely for the same class of queries where unranked\nenumeration is optimal -- and only slower by a logarithmic factor. In a more\ncareful analysis of combined complexity, we uncover a previously unknown\ntradeoff between two different any-k algorithms: one has lower complexity when\nthe number of returned results is small, the other when the number is very\nlarge. This tradeoff is eliminated under a stricter monotonicity property that\nwe exploit to design a novel algorithm that asymptotically dominates all\npreviously known alternatives, including the well-known algorithm of Eppstein\nfor sum-of-weights path enumeration. We empirically demonstrate the findings of\nour theoretical analysis in an experimental study that highlights the\nsuperiority of our approach over the join-then-rank approach that existing\ndatabase systems typically follow.",
    "descriptor": "",
    "authors": [
      "Nikolaos Tziavelis",
      "Wolfgang Gatterbauer",
      "Mirek Riedewald"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Data Structures and Algorithms (cs.DS)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.05649"
  },
  {
    "id": "arXiv:2205.05656",
    "title": "Ontology-Based and Weakly Supervised Rare Disease Phenotyping from  Clinical Notes",
    "abstract": "Computational text phenotyping is the practice of identifying patients with\ncertain disorders and traits from clinical notes. Rare diseases are challenging\nto be identified due to few cases available for machine learning and the need\nfor data annotation from domain experts. We propose a method using ontologies\nand weak supervision, with recent pre-trained contextual representations from\nBi-directional Transformers (e.g. BERT). The ontology-based framework includes\ntwo steps: (i) Text-to-UMLS, extracting phenotypes by contextually linking\nmentions to concepts in Unified Medical Language System (UMLS), with a Named\nEntity Recognition and Linking (NER+L) tool, SemEHR, and weak supervision with\ncustomised rules and contextual mention representation; (ii) UMLS-to-ORDO,\nmatching UMLS concepts to rare diseases in Orphanet Rare Disease Ontology\n(ORDO). The weakly supervised approach is proposed to learn a phenotype\nconfirmation model to improve Text-to-UMLS linking, without annotated data from\ndomain experts. We evaluated the approach on three clinical datasets of\ndischarge summaries and radiology reports from two institutions in the US and\nthe UK. Our best weakly supervised method achieved 81.4% precision and 91.4%\nrecall on extracting rare disease UMLS phenotypes from MIMIC-III discharge\nsummaries. The overall pipeline processing clinical notes can surface rare\ndisease cases, mostly uncaptured in structured data (manually assigned ICD\ncodes). Results on radiology reports from MIMIC-III and NHS Tayside were\nconsistent with the discharge summaries. We discuss the usefulness of the weak\nsupervision approach and propose directions for future studies.",
    "descriptor": "\nComments: 12 pages, 4 figures, submitted to IEEE Journal of Biomedical and Health Informatics, with supplementary materials (4 extra pages, 1 extra figure)\n",
    "authors": [
      "Hang Dong",
      "V\u00edctor Su\u00e1rez-Paniagua",
      "Huayu Zhang",
      "Minhong Wang",
      "Arlene Casey",
      "Emma Davidson",
      "Jiaoyan Chen",
      "Beatrice Alex",
      "William Whiteley",
      "Honghan Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.05656"
  },
  {
    "id": "arXiv:2205.05659",
    "title": "Ranked Prioritization of Groups in Combinatorial Bandit Allocation",
    "abstract": "Preventing poaching through ranger patrols protects endangered wildlife,\ndirectly contributing to the UN Sustainable Development Goal 15 of life on\nland. Combinatorial bandits have been used to allocate limited patrol\nresources, but existing approaches overlook the fact that each location is home\nto multiple species in varying proportions, so a patrol benefits each species\nto differing degrees. When some species are more vulnerable, we ought to offer\nmore protection to these animals; unfortunately, existing combinatorial bandit\napproaches do not offer a way to prioritize important species. To bridge this\ngap, (1) We propose a novel combinatorial bandit objective that trades off\nbetween reward maximization and also accounts for prioritization over species,\nwhich we call ranked prioritization. We show this objective can be expressed as\na weighted linear sum of Lipschitz-continuous reward functions. (2) We provide\nRankedCUCB, an algorithm to select combinatorial actions that optimize our\nprioritization-based objective, and prove that it achieves asymptotic\nno-regret. (3) We demonstrate empirically that RankedCUCB leads to up to 38%\nimprovement in outcomes for endangered species using real-world wildlife\nconservation data. Along with adapting to other challenges such as preventing\nillegal logging and overfishing, our no-regret algorithm addresses the general\ncombinatorial bandit problem with a weighted linear objective.",
    "descriptor": "\nComments: Accepted at IJCAI 2022, AI for Good track. 7 pages + 2 pages appendix. Code is available at this https URL\n",
    "authors": [
      "Lily Xu",
      "Arpita Biswas",
      "Fei Fang",
      "Milind Tambe"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05659"
  },
  {
    "id": "arXiv:2205.05661",
    "title": "How Platform-User Power Relations Shape Algorithmic Accountability: A  Case Study of Instant Loan Platforms and Financially Stressed Users in India",
    "abstract": "Accountability, a requisite for responsible AI, can be facilitated through\ntransparency mechanisms such as audits and explainability. However, prior work\nsuggests that the success of these mechanisms may be limited to Global North\ncontexts; understanding the limitations of current interventions in varied\nsocio-political conditions is crucial to help policymakers facilitate wider\naccountability. To do so, we examined the mediation of accountability in the\nexisting interactions between vulnerable users and a 'high-risk' AI system in a\nGlobal South setting. We report on a qualitative study with 29\nfinancially-stressed users of instant loan platforms in India. We found that\nusers experienced intense feelings of indebtedness for the 'boon' of instant\nloans, and perceived huge obligations towards loan platforms. Users fulfilled\nobligations by accepting harsh terms and conditions, over-sharing sensitive\ndata, and paying high fees to unknown and unverified lenders. Users\ndemonstrated a dependence on loan platforms by persisting with such behaviors\ndespite risks of harms such as abuse, recurring debts, discrimination, privacy\nharms, and self-harm to them. Instead of being enraged with loan platforms,\nusers assumed responsibility for their negative experiences, thus releasing the\nhigh-powered loan platforms from accountability obligations. We argue that\naccountability is shaped by platform-user power relations, and urge caution to\npolicymakers in adopting a purely technical approach to fostering algorithmic\naccountability. Instead, we call for situated interventions that enhance agency\nof users, enable meaningful transparency, reconfigure designer-user relations,\nand prompt a critical reflection in practitioners towards wider accountability.\nWe conclude with implications for responsibly deploying AI in FinTech\napplications in India and beyond.",
    "descriptor": "\nComments: To appear at FAccT 2022\n",
    "authors": [
      "Divya Ramesh",
      "Vaishnav Kameswaran",
      "Ding Wang",
      "Nithya Sambasivan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05661"
  },
  {
    "id": "arXiv:2205.05662",
    "title": "Deep Architecture Connectivity Matters for Its Convergence: A  Fine-Grained Analysis",
    "abstract": "Advanced deep neural networks (DNNs), designed by either human or AutoML\nalgorithms, are growing increasingly complex. Diverse operations are connected\nby complicated connectivity patterns, e.g., various types of skip connections.\nThose topological compositions are empirically effective and observed to smooth\nthe loss landscape and facilitate the gradient flow in general. However, it\nremains elusive to derive any principled understanding of their effects on the\nDNN capacity or trainability, and to understand why or in which aspect one\nspecific connectivity pattern is better than another. In this work, we\ntheoretically characterize the impact of connectivity patterns on the\nconvergence of DNNs under gradient descent training in fine granularity. By\nanalyzing a wide network's Neural Network Gaussian Process (NNGP), we are able\nto depict how the spectrum of an NNGP kernel propagates through a particular\nconnectivity pattern, and how that affects the bound of convergence rates. As\none practical implication of our results, we show that by a simple filtration\non \"unpromising\" connectivity patterns, we can trim down the number of models\nto evaluate, and significantly accelerate the large-scale neural architecture\nsearch without any overhead. Codes will be released at\nhttps://github.com/chenwydj/architecture_convergence.",
    "descriptor": "",
    "authors": [
      "Wuyang Chen",
      "Wei Huang",
      "Xinyu Gong",
      "Boris Hanin",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05662"
  },
  {
    "id": "arXiv:2205.05664",
    "title": "Theory and Implementation of Process and Temperature Scalable  Shape-based CMOS Analog Circuits",
    "abstract": "Analog computing is attractive to its digital counterparts due to its\npotential for achieving high compute density and energy efficiency. However,\nthe device-to-device variability and challenges in porting existing designs to\nadvance process nodes have posed a major hindrance in harnessing the full\npotential of analog computations for Machine Learning (ML) applications. This\nwork proposes a novel analog computing framework for designing an analog ML\nprocessor similar to that of a digital design - where the designs can be scaled\nand ported to advanced process nodes without architectural changes. At the core\nof our work lies shape-based analog computing (S-AC). It utilizes device\nprimitives to yield a robust proto-function through which other non-linear\nshapes can be derived. S-AC paradigm also allows the user to trade off\ncomputational precision with silicon circuit area and power. Thus allowing\nusers to build a truly power-efficient and scalable analog architecture where\nthe same synthesized analog circuit can operate across different biasing\nregimes of transistors and simultaneously scale across process nodes. As a\nproof of concept, we show the implementation of commonly used mathematical\nfunctions for carrying standard ML tasks in both planar CMOS 180nm and FinFET\n7nm process nodes. The synthesized Shape-based ML architecture has been\ndemonstrated for its classification accuracy on standard data sets at different\nprocess nodes.",
    "descriptor": "\nComments: 13 Pages, 14 Figures, 3 Tables. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Pratik Kumar",
      "Ankita Nandi",
      "Shantanu Chakrabartty",
      "Chetan Singh Thakur"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05664"
  },
  {
    "id": "arXiv:2205.05666",
    "title": "Identifying concept libraries from language about object structure",
    "abstract": "Our understanding of the visual world goes beyond naming objects,\nencompassing our ability to parse objects into meaningful parts, attributes,\nand relations. In this work, we leverage natural language descriptions for a\ndiverse set of 2K procedurally generated objects to identify the parts people\nuse and the principles leading these parts to be favored over others. We\nformalize our problem as search over a space of program libraries that contain\ndifferent part concepts, using tools from machine translation to evaluate how\nwell programs expressed in each library align to human language. By combining\nnaturalistic language at scale with structured program representations, we\ndiscover a fundamental information-theoretic tradeoff governing the part\nconcepts people name: people favor a lexicon that allows concise descriptions\nof each object, while also minimizing the size of the lexicon itself.",
    "descriptor": "\nComments: Appears in the conference proceedings of CogSci 2022\n",
    "authors": [
      "Catherine Wong",
      "William P. McCarthy",
      "Gabriel Grand",
      "Yoni Friedman",
      "Joshua B. Tenenbaum",
      "Jacob Andreas",
      "Robert D. Hawkins",
      "Judith E. Fan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.05666"
  },
  {
    "id": "arXiv:2205.05671",
    "title": "RepSR: Training Efficient VGG-style Super-Resolution Networks with  Structural Re-Parameterization and Batch Normalization",
    "abstract": "This paper explores training efficient VGG-style super-resolution (SR)\nnetworks with the structural re-parameterization technique. The general\npipeline of re-parameterization is to train networks with multi-branch topology\nfirst, and then merge them into standard 3x3 convolutions for efficient\ninference. In this work, we revisit those primary designs and investigate\nessential components for re-parameterizing SR networks. First of all, we find\nthat batch normalization (BN) is important to bring training non-linearity and\nimprove the final performance. However, BN is typically ignored in SR, as it\nusually degrades the performance and introduces unpleasant artifacts. We\ncarefully analyze the cause of BN issue and then propose a straightforward yet\neffective solution. In particular, we first train SR networks with mini-batch\nstatistics as usual, and then switch to using population statistics at the\nlater training period. While we have successfully re-introduced BN into SR, we\nfurther design a new re-parameterizable block tailored for SR, namely RepSR. It\nconsists of a clean residual path and two expand-and-squeeze convolution paths\nwith the modified BN. Extensive experiments demonstrate that our simple RepSR\nis capable of achieving superior performance to previous SR re-parameterization\nmethods among different model sizes. In addition, our RepSR can achieve a\nbetter trade-off between performance and actual running time (throughput) than\nprevious SR methods. Codes will be available at\nhttps://github.com/TencentARC/RepSR.",
    "descriptor": "\nComments: Technical Report. Codes will be available at this https URL\n",
    "authors": [
      "Xintao Wang",
      "Chao Dong",
      "Ying Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.05671"
  },
  {
    "id": "arXiv:2205.05675",
    "title": "NTIRE 2022 Challenge on Efficient Super-Resolution: Methods and Results",
    "abstract": "This paper reviews the NTIRE 2022 challenge on efficient single image\nsuper-resolution with focus on the proposed solutions and results. The task of\nthe challenge was to super-resolve an input image with a magnification factor\nof $\\times$4 based on pairs of low and corresponding high resolution images.\nThe aim was to design a network for single image super-resolution that achieved\nimprovement of efficiency measured according to several metrics including\nruntime, parameters, FLOPs, activations, and memory consumption while at least\nmaintaining the PSNR of 29.00dB on DIV2K validation set. IMDN is set as the\nbaseline for efficiency measurement. The challenge had 3 tracks including the\nmain track (runtime), sub-track one (model complexity), and sub-track two\n(overall performance). In the main track, the practical runtime performance of\nthe submissions was evaluated. The rank of the teams were determined directly\nby the absolute value of the average runtime on the validation set and test\nset. In sub-track one, the number of parameters and FLOPs were considered. And\nthe individual rankings of the two metrics were summed up to determine a final\nranking in this track. In sub-track two, all of the five metrics mentioned in\nthe description of the challenge including runtime, parameter count, FLOPs,\nactivations, and memory consumption were considered. Similar to sub-track one,\nthe rankings of five metrics were summed up to determine a final ranking. The\nchallenge had 303 registered participants, and 43 teams made valid submissions.\nThey gauge the state-of-the-art in efficient single image super-resolution.",
    "descriptor": "\nComments: Validation code of the baseline model is available at this https URL Validation of all submitted models is available at this https URL\n",
    "authors": [
      "Yawei Li",
      "Kai Zhang",
      "Radu Timofte",
      "Luc Van Gool",
      "Fangyuan Kong",
      "Mingxi Li",
      "Songwei Liu",
      "Zongcai Du",
      "Ding Liu",
      "Chenhui Zhou",
      "Jingyi Chen",
      "Qingrui Han",
      "Zheyuan Li",
      "Yingqi Liu",
      "Xiangyu Chen",
      "Haoming Cai",
      "Yu Qiao",
      "Chao Dong",
      "Long Sun",
      "Jinshan Pan",
      "Yi Zhu",
      "Zhikai Zong",
      "Xiaoxiao Liu",
      "Zheng Hui",
      "Tao Yang",
      "Peiran Ren",
      "Xuansong Xie",
      "Xian-Sheng Hua",
      "Yanbo Wang",
      "Xiaozhong Ji",
      "Chuming Lin",
      "Donghao Luo",
      "Ying Tai",
      "Chengjie Wang",
      "Zhizhong Zhang",
      "Yuan Xie",
      "Shen Cheng",
      "Ziwei Luo",
      "Lei Yu",
      "Zhihong Wen",
      "Qi Wu1",
      "Youwei Li",
      "Haoqiang Fan",
      "Jian Sun",
      "Shuaicheng Liu",
      "Yuanfei Huang",
      "Meiguang Jin",
      "Hua Huang",
      "Jing Liu",
      "Xinjian Zhang",
      "Yan Wang",
      "Lingshun Long",
      "Gen Li",
      "Yuanfan Zhang",
      "Zuowei Cao",
      "Lei Sun",
      "Panaetov Alexander",
      "Yucong Wang",
      "Minjie Cai",
      "Li Wang",
      "Lu Tian",
      "Zheyuan Wang",
      "Hongbing Ma",
      "Jie Liu",
      "Chao Chen",
      "Yidong Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.05675"
  },
  {
    "id": "arXiv:2205.05676",
    "title": "Revisiting Random Channel Pruning for Neural Network Compression",
    "abstract": "Channel (or 3D filter) pruning serves as an effective way to accelerate the\ninference of neural networks. There has been a flurry of algorithms that try to\nsolve this practical problem, each being claimed effective in some ways. Yet, a\nbenchmark to compare those algorithms directly is lacking, mainly due to the\ncomplexity of the algorithms and some custom settings such as the particular\nnetwork configuration or training procedure. A fair benchmark is important for\nthe further development of channel pruning.\nMeanwhile, recent investigations reveal that the channel configurations\ndiscovered by pruning algorithms are at least as important as the pre-trained\nweights. This gives channel pruning a new role, namely searching the optimal\nchannel configuration. In this paper, we try to determine the channel\nconfiguration of the pruned models by random search. The proposed approach\nprovides a new way to compare different methods, namely how well they behave\ncompared with random pruning. We show that this simple strategy works quite\nwell compared with other channel pruning methods. We also show that under this\nsetting, there are surprisingly no clear winners among different channel\nimportance evaluation methods, which then may tilt the research efforts into\nadvanced channel configuration searching methods.",
    "descriptor": "\nComments: Accepted to CVPR2022. Code will be released at \\url{this https URL}\n",
    "authors": [
      "Yawei Li",
      "Kamil Adamczewski",
      "Wen Li",
      "Shuhang Gu",
      "Radu Timofte",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.05676"
  },
  {
    "id": "arXiv:2205.05677",
    "title": "HULC: 3D Human Motion Capture with Pose Manifold Sampling and Dense  Contact Guidance",
    "abstract": "Marker-less monocular 3D human motion capture (MoCap) with scene interactions\nis a challenging research topic relevant for extended reality, robotics and\nvirtual avatar generation. Due to the inherent depth ambiguity of monocular\nsettings, 3D motions captured with existing methods often contain severe\nartefacts such as incorrect body-scene inter-penetrations, jitter and body\nfloating. To tackle these issues, we propose HULC, a new approach for 3D human\nMoCap which is aware of the scene geometry. HULC estimates 3D poses and dense\nbody-environment surface contacts for improved 3D localisations, as well as the\nabsolute scale of the subject. Furthermore, we introduce a 3D pose trajectory\noptimisation based on a novel pose manifold sampling that resolves erroneous\nbody-environment inter-penetrations. Although the proposed method requires less\nstructured inputs compared to existing scene-aware monocular MoCap algorithms,\nit produces more physically-plausible poses: HULC significantly and\nconsistently outperforms the existing approaches in various experiments and on\ndifferent metrics.",
    "descriptor": "",
    "authors": [
      "Soshi Shimada",
      "Vladislav Golyanik",
      "Patrick P\u00e9rez",
      "Weipeng Xu",
      "Christian Theobalt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.05677"
  },
  {
    "id": "arXiv:2205.05678",
    "title": "RISP: Rendering-Invariant State Predictor with Differentiable Simulation  and Rendering for Cross-Domain Parameter Estimation",
    "abstract": "This work considers identifying parameters characterizing a physical system's\ndynamic motion directly from a video whose rendering configurations are\ninaccessible. Existing solutions require massive training data or lack\ngeneralizability to unknown rendering configurations. We propose a novel\napproach that marries domain randomization and differentiable rendering\ngradients to address this problem. Our core idea is to train a\nrendering-invariant state-prediction (RISP) network that transforms image\ndifferences into state differences independent of rendering configurations,\ne.g., lighting, shadows, or material reflectance. To train this predictor, we\nformulate a new loss on rendering variances using gradients from differentiable\nrendering. Moreover, we present an efficient, second-order method to compute\nthe gradients of this loss, allowing it to be integrated seamlessly into modern\ndeep learning frameworks. We evaluate our method in rigid-body and\ndeformable-body simulation environments using four tasks: state estimation,\nsystem identification, imitation learning, and visuomotor control. We further\ndemonstrate the efficacy of our approach on a real-world example: inferring the\nstate and action sequences of a quadrotor from a video of its motion sequences.\nCompared with existing methods, our approach achieves significantly lower\nreconstruction errors and has better generalizability among unknown rendering\nconfigurations.",
    "descriptor": "\nComments: ICLR Oral. Project page: this http URL\n",
    "authors": [
      "Pingchuan Ma",
      "Tao Du",
      "Joshua B. Tenenbaum",
      "Wojciech Matusik",
      "Chuang Gan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.05678"
  },
  {
    "id": "arXiv:2107.05227",
    "title": "A Sublinear Bound on the Page Number of Upward Planar Graphs",
    "abstract": "The page number of a directed acyclic graph $G$ is the minimum $k$ for which\nthere is a topological ordering of $G$ and a $k$-coloring of the edges such\nthat no two edges of the same color cross, i.e., have alternating endpoints\nalong the topological ordering. We address the long-standing open problem\nasking for the largest page number among all upward planar graphs. We improve\nthe best known lower bound to $5$ and present the first asymptotic improvement\nover the trivial $O(n)$ upper bound, where $n$ denotes the number of vertices\nin $G$. Specifically, we first prove that the page number of every upward\nplanar graph is bounded in terms of its width, as well as its height. We then\ncombine both approaches to show that every $n$-vertex upward planar graph has\npage number $O(n^{2/3} \\log(n)^{2/3})$.",
    "descriptor": "",
    "authors": [
      "Paul Jungeblut",
      "Laura Merker",
      "Torsten Ueckerdt"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2107.05227"
  },
  {
    "id": "arXiv:2110.01360",
    "title": "Posterior predictive model checking using formal methods in a  spatio-temporal model",
    "abstract": "We propose an interdisciplinary framework, Bayesian formal predictive model\nchecking (Bayes FPMC), which combines Bayesian predictive inference, a well\nestablished tool in statistics, with formal verification methods rooting in the\ncomputer science community.\nBayesian predictive inference allows for coherently incorporating uncertainty\nabout unknown quantities by making use of methods or models that produce\npredictive distributions which in turn inform decision problems. By formalizing\nthese problems and the corresponding properties, we can use spatio-temporal\nreach and escape logic to probabilistically assess their satisfaction. This\nway, competing models can directly be ranked according to how well they solve\nthe actual problem at hand.\nThe approach is illustrated on an urban mobility application, where the\ncrowdedness in the center of Milan is proxied by aggregated mobile phone\ntraffic data. We specify several desirable spatio-temporal properties related\nto city crowdedness such as a fault tolerant network or the reachability of\nhospitals. After verifying these properties on draws from the posterior\npredictive distributions, we compare several spatio-temporal Bayesian models\nbased on their overall and property-based predictive performance.",
    "descriptor": "",
    "authors": [
      "Laura Vana",
      "Ennio Visconti",
      "Laura Nenzi",
      "Annalisa Cadonna",
      "Gregor Kastner"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.01360"
  },
  {
    "id": "arXiv:2205.05100",
    "title": "On equipathenergetic graphs and new bounds on path energy",
    "abstract": "The path energy of a simple connected graph G is equal to the sum of the\nabsolute values of the path eigenvalues of the graph G . (S. Shikare et. al,\n2018), where the path eigenvalues of a graph G is the path eigenvalues of its\npath matrix. In this paper we define equipathenergetic and n -equipathenergetic\ngraphs, their properties and several ways to construct the equipathenergetic\nand n -equipathenergetic graphs. We have found new upper bounds for path energy\nin terms of the maximum degree of a graph. A relation between energy of a graph\nand path energy of a graph is also provided.",
    "descriptor": "",
    "authors": [
      "Amol P. Narke",
      "Prashant P. Malavadkar"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2205.05100"
  },
  {
    "id": "arXiv:2205.05113",
    "title": "An Efficient Calculation of Quaternion Correlation of Signals and Color  Images",
    "abstract": "Over the past century, a correlation has been an essential mathematical\ntechnique utilized in engineering sciences, including practically every\nsignal/image processing field. This paper describes an effective method of\ncalculating the correlation function of signals and color images in quaternion\nalgebra. We propose using the quaternions with a commutative multiplication\noperation and defining the corresponding correlation function in this\narithmetic. The correlation between quaternion signals and images can be\ncalculated by multiplying two quaternion DFTs of signals and images. The\ncomplexity of the correlation of color images is three times higher than in\ncomplex algebra.",
    "descriptor": "\nComments: 14 pages, 7 figures, 1 table\n",
    "authors": [
      "Artyom M. Grigoryan",
      "Sos S. Agaian"
    ],
    "subjectives": [
      "Commutative Algebra (math.AC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.05113"
  },
  {
    "id": "arXiv:2205.05123",
    "title": "Deep fusion of gray level co-occurrence matrices for lung nodule  classification",
    "abstract": "Lung cancer is a severe menace to human health, due to which millions of\npeople die because of late diagnoses of cancer; thus, it is vital to detect the\ndisease as early as possible. The Computerized chest analysis Tomography of\nscan is assumed to be one of the efficient solutions for detecting and\nclassifying lung nodules. The necessity of high accuracy of analyzing C.T. scan\nimages of the lung is considered as one of the crucial challenges in detecting\nand classifying lung cancer. A new long-short-term-memory (LSTM) based deep\nfusion structure, is introduced, where, the texture features computed from lung\nnodules through new volumetric grey-level-co-occurrence-matrices (GLCM)\ncomputations are applied to classify the nodules into: benign, malignant and\nambiguous. An improved Otsu segmentation method combined with the water strider\noptimization algorithm (WSA) is proposed to detect the lung nodules. Otsu-WSA\nthresholding can overcome the restrictions present in previous thresholding\nmethods. Extended experiments are run to assess this fusion structure by\nconsidering 2D-GLCM computations based 2D-slices fusion, and an approximation\nof this 3D-GLCM with volumetric 2.5D-GLCM computations-based LSTM fusion\nstructure. The proposed methods are trained and assessed through the LIDC-IDRI\ndataset, where 94.4%, 91.6%, and 95.8% Accuracy, sensitivity, and specificity\nare obtained, respectively for 2D-GLCM fusion and 97.33%, 96%, and 98%,\naccuracy, sensitivity, and specificity, respectively, for 2.5D-GLCM fusion. The\nyield of the same are 98.7%, 98%, and 99%, for the 3D-GLCM fusion. The obtained\nresults and analysis indicate that the WSA-Otsu method requires less execution\ntime and yields a more accurate thresholding process. It is found that 3D-GLCM\nbased LSTM outperforms its counterparts.",
    "descriptor": "\nComments: 24 pages, 6 figures, 80 references\n",
    "authors": [
      "Ahmed Saihood",
      "Hossein Karshenas",
      "AhmadReza Naghsh Nilchi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05123"
  },
  {
    "id": "arXiv:2205.05152",
    "title": "Sparsity Based Non-Contact Vital Signs Monitoring of Multiple People Via  FMCW Radar",
    "abstract": "Non-contact technology for monitoring multiple people's vital signs, such as\nrespiration and heartbeat, has been investigated in recent years due to the\nrising cardiopulmonary morbidity, the risk of transmitting diseases, and the\nheavy burden on the medical staff. Frequency modulated continuous wave (FMCW)\nradars have shown great promise in meeting these needs. However, contemporary\ntechniques for non-contact vital signs monitoring (NCVSM) via FMCW radars, are\nbased on simplistic models, and present difficulties coping with noisy\nenvironments containing multiple objects. In this work, we develop an extended\nmodel of FMCW radar signals in a noisy setting containing multiple people and\nclutter. By utilizing the sparse nature of the modeled signals in conjunction\nwith human-typical cardiopulmonary features, we can accurately localize humans\nand reliably monitor their vital signs, using only a single channel and a\nsingle-input-single-output setup. To this end, we first show that spatial\nsparsity allows for both accurate detection of multiple people and\ncomputationally efficient extraction of their Doppler samples, using a joint\nsparse recovery approach. Given the extracted samples, we develop a method\nnamed Vital Signs based Dictionary Recovery (VSDR), which uses a\ndictionary-based approach to search for the desired rates of respiration and\nheartbeat over high-resolution grids corresponding to normal cardiopulmonary\nactivity. The advantages of the proposed method are illustrated through\nexamples that combine the proposed model with real data of $30$ monitored\nindividuals. We demonstrate accurate human localization in a clutter-rich\nscenario that includes both static and vibrating objects, and show that our\nVSDR approach outperforms existing techniques, based on several statistical\nmetrics. The findings support the widespread use of FMCW radars with the\nproposed algorithms in healthcare.",
    "descriptor": "",
    "authors": [
      "Yonathan Eder",
      "Yonina C. Eldar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.05152"
  },
  {
    "id": "arXiv:2205.05162",
    "title": "Simplifying the axiomatization for the order affine geometry",
    "abstract": "Based on an ordering with directed lines and using constructions instead of\nexistential axioms, von Plato proposed a constructive axiomatization of ordered\naffine geometry. There are 22 axioms for the ordered affine geometry, of which\nthe axiom I.7 is about the convergence of three lines (ignoring their\ndirections). In this paper, we indicate that the axiom I.7 includes much\nredundancy, and demonstrate that the complicated axiom I.7 can be replaced with\na simpler and more intuitive new axiom (called ODO) which describes the\nproperties of oppositely and equally directed lines. We also investigate a\npossibility to replace the axiom I.6 with ODO.",
    "descriptor": "\nComments: 14 pages, no figure\n",
    "authors": [
      "Dafa Li"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.05162"
  },
  {
    "id": "arXiv:2205.05178",
    "title": "Magnitude and topological entropy of digraphs",
    "abstract": "Magnitude and (co)weightings are quite general constructions in enriched\ncategories, yet they have been developed almost exclusively in the context of\nLawvere metric spaces. We construct a meaningful notion of magnitude for flow\ngraphs based on the observation that topological entropy provides a suitable\nmap into the max-plus semiring, and we outline its utility. Subsequently, we\nidentify a separate point of contact between magnitude and topological entropy\nin digraphs that yields an analogue of volume entropy for geodesic flows.\nFinally, we sketch the utility of this construction for feature engineering in\ndownstream applications with generic digraphs.",
    "descriptor": "",
    "authors": [
      "Steve Huntsman"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2205.05178"
  },
  {
    "id": "arXiv:2205.05199",
    "title": "Separator-Transducer-Segmenter: Streaming Recognition and Segmentation  of Multi-party Speech",
    "abstract": "Streaming recognition and segmentation of multi-party conversations with\noverlapping speech is crucial for the next generation of voice assistant\napplications. In this work we address its challenges discovered in the previous\nwork on multi-turn recurrent neural network transducer (MT-RNN-T) with a novel\napproach, separator-transducer-segmenter (STS), that enables tighter\nintegration of speech separation, recognition and segmentation in a single\nmodel. First, we propose a new segmentation modeling strategy through\nstart-of-turn and end-of-turn tokens that improves segmentation without\nrecognition accuracy degradation. Second, we further improve both speech\nrecognition and segmentation accuracy through an emission regularization\nmethod, FastEmit, and multi-task training with speech activity information as\nan additional training signal. Third, we experiment with end-of-turn emission\nlatency penalty to improve end-point detection for each speaker turn. Finally,\nwe establish a novel framework for segmentation analysis of multi-party\nconversations through emission latency metrics. With our best model, we report\n4.6% abs. turn counting accuracy improvement and 17% rel. word error rate (WER)\nimprovement on LibriCSS dataset compared to the previously published work.",
    "descriptor": "\nComments: Submitted to InterSpeech 2022\n",
    "authors": [
      "Ilya Sklyar",
      "Anna Piunova",
      "Christian Osendorfer"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2205.05199"
  },
  {
    "id": "arXiv:2205.05206",
    "title": "Best of Both Worlds: Multi-task Audio-Visual Automatic Speech  Recognition and Active Speaker Detection",
    "abstract": "Under noisy conditions, automatic speech recognition (ASR) can greatly\nbenefit from the addition of visual signals coming from a video of the\nspeaker's face. However, when multiple candidate speakers are visible this\ntraditionally requires solving a separate problem, namely active speaker\ndetection (ASD), which entails selecting at each moment in time which of the\nvisible faces corresponds to the audio. Recent work has shown that we can solve\nboth problems simultaneously by employing an attention mechanism over the\ncompeting video tracks of the speakers' faces, at the cost of sacrificing some\naccuracy on active speaker detection. This work closes this gap in active\nspeaker detection accuracy by presenting a single model that can be jointly\ntrained with a multi-task loss. By combining the two tasks during training we\nreduce the ASD classification accuracy by approximately 25%, while\nsimultaneously improving the ASR performance when compared to the multi-person\nbaseline trained exclusively for ASR.",
    "descriptor": "",
    "authors": [
      "Otavio Braga",
      "Olivier Siohan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2205.05206"
  },
  {
    "id": "arXiv:2205.05214",
    "title": "A Unified f-divergence Framework Generalizing VAE and GAN",
    "abstract": "Developing deep generative models that flexibly incorporate diverse measures\nof probability distance is an important area of research. Here we develop an\nunified mathematical framework of f-divergence generative model, f-GM, that\nincorporates both VAE and f-GAN, and enables tractable learning with general\nf-divergences. f-GM allows the experimenter to flexibly design the f-divergence\nfunction without changing the structure of the networks or the learning\nprocedure. f-GM jointly models three components: a generator, a inference\nnetwork and a density estimator. Therefore it simultaneously enables sampling,\nposterior inference of the latent variable as well as evaluation of the\nlikelihood of an arbitrary datum. f-GM belongs to the class of encoder-decoder\nGANs: our density estimator can be interpreted as playing the role of a\ndiscriminator between samples in the joint space of latent code and observed\nspace. We prove that f-GM naturally simplifies to the standard VAE and to f-GAN\nas special cases, and illustrates the connections between different\nencoder-decoder GAN architectures. f-GM is compatible with general network\narchitecture and optimizer. We leverage it to experimentally explore the\neffects -- e.g. mode collapse and image sharpness -- of different choices of\nf-divergence.",
    "descriptor": "",
    "authors": [
      "Jaime Roquero Gimenez",
      "James Zou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05214"
  },
  {
    "id": "arXiv:2205.05227",
    "title": "Towards Improved Zero-shot Voice Conversion with Conditional DSVAE",
    "abstract": "Disentangling content and speaking style information is essential for\nzero-shot non-parallel voice conversion (VC). Our previous study investigated a\nnovel framework with disentangled sequential variational autoencoder (DSVAE) as\nthe backbone for information decomposition. We have demonstrated that\nsimultaneous disentangling content embedding and speaker embedding from one\nutterance is feasible for zero-shot VC. In this study, we continue the\ndirection by raising one concern about the prior distribution of content branch\nin the DSVAE baseline. We find the random initialized prior distribution will\nforce the content embedding to reduce the phonetic-structure information during\nthe learning process, which is not a desired property. Here, we seek to achieve\na better content embedding with more phonetic information preserved. We propose\nconditional DSVAE, a new model that enables content bias as a condition to the\nprior modeling and reshapes the content embedding sampled from the posterior\ndistribution. In our experiment on the VCTK dataset, we demonstrate that\ncontent embeddings derived from the conditional DSVAE overcome the randomness\nand achieve a much better phoneme classification accuracy, a stabilized\nvocalization and a better zero-shot VC performance compared with the\ncompetitive DSVAE baseline.",
    "descriptor": "\nComments: Submitted to 2022 Interspeech\n",
    "authors": [
      "Jiachen Lian",
      "Chunlei Zhang",
      "Gopala Krishna Anumanchipalli",
      "Dong Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2205.05227"
  },
  {
    "id": "arXiv:2205.05229",
    "title": "A new approach for the fractional Laplacian via deep neural networks",
    "abstract": "The fractional Laplacian has been strongly studied during past decades. In\nthis paper we present a different approach for the associated Dirichlet\nproblem, using recent deep learning techniques. In fact, recently certain\nparabolic PDEs with a stochastic representation have been understood via neural\nnetworks, overcoming the so-called curse of dimensionality. Among these\nequations one can find parabolic ones in $\\mathbb{R}^d$ and elliptic in a\nbounded domain $D \\subset \\mathbb{R}^d$. In this paper we consider the\nDirichlet problem for the fractional Laplacian with exponent $\\alpha \\in\n(1,2)$. We show that its solution, represented in a stochastic fashion can be\napproximated using deep neural networks. We also check that this approximation\ndoes not suffer from the curse of dimensionality.",
    "descriptor": "\nComments: 55 pages, 1 figure\n",
    "authors": [
      "Nicol\u00e1s Valenzuela"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2205.05229"
  },
  {
    "id": "arXiv:2205.05232",
    "title": "Linear average-case complexity of algorithmic problems in groups",
    "abstract": "The worst-case complexity of group-theoretic algorithms has been studied for\na long time. Generic-case complexity, or complexity on random inputs, was\nintroduced and studied relatively recently. In this paper, we address the\naverage-case time complexity of the word problem in several classes of groups\nand show that it is often the case that the average-case complexity is linear\nwith respect to the length of an input word. The classes of groups that we\nconsider include groups of matrices over rationals (in particular, polycyclic\ngroups), some classes of solvable groups, as well as free products. For free\nproducts, we also address the average-case complexity of the subgroup\nmembership problem and show that it is often linear, too. Finally, we discuss\nthe identity problem that has not been considered before.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Alexander Olshanskii",
      "Vladimir Shpilrain"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2205.05232"
  },
  {
    "id": "arXiv:2205.05262",
    "title": "A globally convergent fast iterative shrinkage-thresholding algorithm  with a new momentum factor for single and multi-objective convex optimization",
    "abstract": "Convex-composite optimization, which minimizes an objective function\nrepresented by the sum of a differentiable function and a convex one, is widely\nused in machine learning and signal/image processing. Fast Iterative Shrinkage\nThresholding Algorithm (FISTA) is a typical method for solving this problem and\nhas a global convergence rate of $O(1 / k^2)$. Recently, this has been extended\nto multi-objective optimization, together with the proof of the $O(1 / k^2)$\nglobal convergence rate. However, its momentum factor is classical, and the\nconvergence of its iterates has not been proven. In this work, introducing some\nadditional hyperparameters $(a, b)$, we propose another accelerated proximal\ngradient method with a general momentum factor, which is new even for the\nsingle-objective cases. We show that our proposed method also has a global\nconvergence rate of $O(1/k^2)$ for any $(a,b)$, and further that the generated\nsequence of iterates converges to a weak Pareto solution when $a$ is positive,\nan essential property for the finite-time manifold identification. Moreover, we\nreport numerical results with various $(a,b)$, showing that some of these\nchoices give better results than the classical momentum factors.",
    "descriptor": "",
    "authors": [
      "Hiroki Tanabe",
      "Ellen H. Fukuda",
      "Nobuo Yamashita"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05262"
  },
  {
    "id": "arXiv:2205.05315",
    "title": "Numerical method for approximately optimal solutions of two-stage  distributionally robust optimization with marginal constraints",
    "abstract": "In this paper, we consider a general class of two-stage distributionally\nrobust optimization (DRO) problems which includes prominent problem instances\nsuch as task scheduling, the assemble-to-order system, and supply chain network\ndesign. The ambiguity set is constrained by fixed marginal distributions that\nare not necessarily discrete. We develop a numerical algorithm for computing\napproximately optimal solutions of such problems. Through replacing the\nmarginal constraints by a finite collection of linear constraints, we derive a\nrelaxed-version of the two-stage DRO problem which serves as its upper bound.\nWe can control the error incurred by the relaxation to be arbitrarily close to\n0. Subsequently, we develop duality results tailored to this setting and\ntransform the inf-sup problem into an inf-inf problem. This leads to a\nnumerical algorithm for two-stage DRO problems with marginal constraints which\nsolves a linear semi-infinite optimization problem via a cutting-plane method.\nBesides an approximately optimal solution, the proposed algorithm computes both\nan upper bound and a lower bound for the optimal value of the problem. The\ndifference between the computed bounds provides us with a direct estimate of\nthe sub-optimality of the computed solution. Most importantly, one is able to\nchoose the inputs of the algorithm such that the sub-optimality is controlled\nto be arbitrarily small. In our numerical examples, we apply the proposed\nalgorithm to task scheduling, the assemble-to-order system, and supply chain\nnetwork design. The ambiguity sets in these problems involve a large number of\nmarginals, which include both discrete and continuous distributions. The\nnumerical results showcase that the proposed algorithm computes high-quality\nrobust decisions along with their corresponding sub-optimality estimates with\npractically reasonable magnitudes that are not over-conservative.",
    "descriptor": "",
    "authors": [
      "Ariel Neufeld",
      "Qikun Xiang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2205.05315"
  },
  {
    "id": "arXiv:2205.05343",
    "title": "Learning Multitask Gaussian Bayesian Networks",
    "abstract": "Major depressive disorder (MDD) requires study of brain functional\nconnectivity alterations for patients, which can be uncovered by resting-state\nfunctional magnetic resonance imaging (rs-fMRI) data. We consider the problem\nof identifying alterations of brain functional connectivity for a single MDD\npatient. This is particularly difficult since the amount of data collected\nduring an fMRI scan is too limited to provide sufficient information for\nindividual analysis. Additionally, rs-fMRI data usually has the characteristics\nof incompleteness, sparsity, variability, high dimensionality and high noise.\nTo address these problems, we proposed a multitask Gaussian Bayesian network\n(MTGBN) framework capable for identifying individual disease-induced\nalterations for MDD patients. We assume that such disease-induced alterations\nshow some degrees of similarity with the tool to learn such network structures\nfrom observations to understanding of how system are structured jointly from\nrelated tasks. First, we treat each patient in a class of observation as a task\nand then learn the Gaussian Bayesian networks (GBNs) of this data class by\nlearning from all tasks that share a default covariance matrix that encodes\nprior knowledge. This setting can help us to learn more information from\nlimited data. Next, we derive a closed-form formula of the complete likelihood\nfunction and use the Monte-Carlo Expectation-Maximization(MCEM) algorithm to\nsearch for the approximately best Bayesian network structures efficiently.\nFinally, we assess the performance of our methods with simulated and real-world\nrs-fMRI data.",
    "descriptor": "",
    "authors": [
      "Shuai Liu",
      "Yixuan Qiu",
      "Baojuan Li",
      "Huaning Wang",
      "Xiangyu Chang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05343"
  },
  {
    "id": "arXiv:2205.05359",
    "title": "Exploring Local Explanations of Nonlinear Models Using Animated Linear  Projections",
    "abstract": "The increased predictive power of nonlinear models comes at the cost of\ninterpretability of its terms. This trade-off has led to the emergence of\neXplainable AI (XAI). XAI attempts to shed light on how models use predictors\nto arrive at a prediction with local explanations, a point estimate of the\nlinear feature importance in the vicinity of one instance. These can be\nconsidered linear projections and can be further explored to understand better\nthe interactions between features used to make predictions across the\npredictive model surface. Here we describe interactive linear interpolation\nused for exploration at any instance and illustrate with examples with\ncategorical (penguin species, chocolate types) and quantitative\n(soccer/football salaries, house prices) output. The methods are implemented in\nthe R package cheem, available on CRAN.",
    "descriptor": "\nComments: 24 pages, 9 figures, 0 tables\n",
    "authors": [
      "Nicholas Spyrison",
      "Dianne Cook"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05359"
  },
  {
    "id": "arXiv:2205.05428",
    "title": "An Inexact Augmented Lagrangian Algorithm for Training Leaky ReLU Neural  Network with Group Sparsity",
    "abstract": "The leaky ReLU network with a group sparse regularization term has been\nwidely used in the recent years. However, training such a network yields a\nnonsmooth nonconvex optimization problem and there exists a lack of approaches\nto compute a stationary point deterministically. In this paper, we first\nresolve the multi-layer composite term in the original optimization problem by\nintroducing auxiliary variables and additional constraints. We show the new\nmodel has a nonempty and bounded solution set and its feasible set satisfies\nthe Mangasarian-Fromovitz constraint qualification. Moreover, we show the\nrelationship between the new model and the original problem. Remarkably, we\npropose an inexact augmented Lagrangian algorithm for solving the new model and\nshow the convergence of the algorithm to a KKT point. Numerical experiments\ndemonstrate that our algorithm is more efficient for training sparse leaky ReLU\nneural networks than some well-known algorithms.",
    "descriptor": "\nComments: Submitted to Journal of Machine Learning Research\n",
    "authors": [
      "Wei Liu",
      "Xin Liu",
      "Xiaojun Chen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05428"
  },
  {
    "id": "arXiv:2205.05472",
    "title": "Effective submodularity of influence maximization on temporal networks",
    "abstract": "We study influence maximization on temporal networks. This is a special\nsetting where the influence function is not submodular, and there is no\noptimality guarantee for solutions achieved via greedy optimization. We perform\nan exhaustive analysis on both real and synthetic networks. We show that the\ninfluence function of randomly sampled sets of seeds often violates the\nnecessary conditions for submodularity. However, when sets of seeds are\nselected according to the greedy optimization strategy, the influence function\nbehaves effectively as a submodular function. Specifically, violations of the\nnecessary conditions for submodularity are never observed in real networks, and\nonly rarely in synthetic ones. The direct comparison with exact solutions\nobtained via brute-force search indicate that the greedy strategy provides\napproximate solutions that are well within the optimality gap guaranteed for\nstrictly submodular functions. Greedy optimization appears therefore an\neffective strategy for the maximization of influence on temporal networks.",
    "descriptor": "\nComments: 12 pages, 9 figures, 3 tables\n",
    "authors": [
      "Sirag Erkol",
      "Dario Mazzilli",
      "Filippo Radicchi"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.05472"
  },
  {
    "id": "arXiv:2205.05474",
    "title": "DeepFilterNet2: Towards Real-Time Speech Enhancement on Embedded Devices  for Full-Band Audio",
    "abstract": "Deep learning-based speech enhancement has seen huge improvements and\nrecently also expanded to full band audio (48 kHz). However, many approaches\nhave a rather high computational complexity and require big temporal buffers\nfor real time usage e.g. due to temporal convolutions or attention. Both make\nthose approaches not feasible on embedded devices. This work further extends\nDeepFilterNet, which exploits harmonic structure of speech allowing for\nefficient speech enhancement (SE). Several optimizations in the training\nprocedure, data augmentation, and network structure result in state-of-the-art\nSE performance while reducing the real-time factor to 0.04 on a notebook\nCore-i5 CPU. This makes the algorithm applicable to run on embedded devices in\nreal-time. The DeepFilterNet framework can be obtained under an open source\nlicense.",
    "descriptor": "\nComments: Submitted to IWAENC 2022\n",
    "authors": [
      "Hendrik Schr\u00f6ter",
      "Alberto N. Escalante-B.",
      "Tobias Rosenkranz",
      "Andreas Maier"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.05474"
  },
  {
    "id": "arXiv:2205.05496",
    "title": "Beyond Griffin-Lim: Improved Iterative Phase Retrieval for Speech",
    "abstract": "Phase retrieval is a problem encountered not only in speech and audio\nprocessing, but in many other fields such as optics. Iterative algorithms based\non non-convex set projections are effective and frequently used for retrieving\nthe phase when only STFT magnitudes are available. While the basic Griffin-Lim\nalgorithm and its variants have been the prevalent method for decades, more\nrecent advances, e.g. in optics, raise the question: Can we do better than\nGriffin-Lim for speech signals, using the same principle of iterative\nprojection?\nIn this paper we compare the classical algorithms in the speech domain with\ntwo modern methods from optics with respect to reconstruction quality and\nconvergence rate. Based on this study, we propose to combine Griffin-Lim with\nthe Difference Map algorithm in a hybrid approach which shows superior results,\nin terms of both convergence and quality of the final reconstruction.",
    "descriptor": "\nComments: Submitted to IWAENC 2022\n",
    "authors": [
      "Tal Peer",
      "Simon Welker",
      "Timo Gerkmann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.05496"
  },
  {
    "id": "arXiv:2205.05500",
    "title": "Analysis of convolutional neural network image classifiers in a  rotationally symmetric model",
    "abstract": "Convolutional neural network image classifiers are defined and the rate of\nconvergence of the misclassification risk of the estimates towards the optimal\nmisclassification risk is analyzed. Here we consider images as random variables\nwith values in some functional space, where we only observe discrete samples as\nfunction values on some finite grid. Under suitable structural and smoothness\nassumptions on the functional a posteriori probability, which includes some\nkind of symmetry against rotation of subparts of the input image, it is shown\nthat least squares plug-in classifiers based on convolutional neural networks\nare able to circumvent the curse of dimensionality in binary image\nclassification if we neglect a resolution-dependent error term. The finite\nsample size behavior of the classifier is analyzed by applying it to simulated\nand real data.",
    "descriptor": "",
    "authors": [
      "Michael Kohler",
      "Benjamin Walter"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05500"
  },
  {
    "id": "arXiv:2205.05522",
    "title": "Private Hypothesis Testing for Social Sciences",
    "abstract": "While running any experiment, we often have to consider the statistical power\nto ensure an effective study. Statistical power or power ensures that we can\nobserve an effect with high probability if such a true effect exists. However,\nseveral studies lack the appropriate planning for determining the optimal\nsample size to ensure adequate power. Thus, careful planning ensures that the\npower remains high even under high measurement errors while keeping the type 1\nerror constrained. We study the impact of differential privacy on experiments\nand theoretically analyze the change in sample size required due to the\nGaussian mechanisms. Further, we provide an empirical method to improve the\naccuracy of private statistics with simple bootstrapping.",
    "descriptor": "\nComments: Under review at Theory and Practice of Differential Privacy (TPDP) 2022\n",
    "authors": [
      "Ajinkya K Mulay",
      "Sean Lane",
      "Erin Hennes"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.05522"
  },
  {
    "id": "arXiv:2205.05545",
    "title": "CNN-LSTM Based Multimodal MRI and Clinical Data Fusion for Predicting  Functional Outcome in Stroke Patients",
    "abstract": "Clinical outcome prediction plays an important role in stroke patient\nmanagement. From a machine learning point-of-view, one of the main challenges\nis dealing with heterogeneous data at patient admission, i.e. the image data\nwhich are multidimensional and the clinical data which are scalars. In this\npaper, a multimodal convolutional neural network - long short-term memory\n(CNN-LSTM) based ensemble model is proposed. For each MR image module, a\ndedicated network provides preliminary prediction of the clinical outcome using\nthe modified Rankin scale (mRS). The final mRS score is obtained by merging the\npreliminary probabilities of each module dedicated to a specific type of MR\nimage weighted by the clinical metadata, here age or the National Institutes of\nHealth Stroke Scale (NIHSS). The experimental results demonstrate that the\nproposed model surpasses the baselines and offers an original way to\nautomatically encode the spatio-temporal context of MR images in a deep\nlearning architecture. The highest AUC (0.77) was achieved for the proposed\nmodel with NIHSS.",
    "descriptor": "\nComments: 44th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC 2022)\n",
    "authors": [
      "Nima Hatami",
      "Tae-Hee Cho",
      "Laura Mechtouff",
      "Omer Faruk Eker",
      "David Rousseau",
      "Carole Frindel"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05545"
  },
  {
    "id": "arXiv:2205.05554",
    "title": "Performance of a deep learning system for detection of referable  diabetic retinopathy in real clinical settings",
    "abstract": "Background: To determine the ability of a commercially available deep\nlearning system, RetCAD v.1.3.1 (Thirona, Nijmegen, The Netherlands) for the\nautomatic detection of referable diabetic retinopathy (DR) on a dataset of\ncolour fundus images acquired during routine clinical practice in a tertiary\nhospital screening program, analyzing the reduction of workload that can be\nreleased incorporating this artificial intelligence-based technology. Methods:\nEvaluation of the software was performed on a dataset of 7195 nonmydriatic\nfundus images from 6325 eyes of 3189 diabetic patients attending our screening\nprogram between February to December of 2019. The software generated a DR\nseverity score for each colour fundus image which was combined into an\neye-level score. This score was then compared with a reference standard as set\nby a human expert using receiver operating characteristic (ROC) curve analysis.\nResults: The artificial intelligence (AI) software achieved an area under the\nROC curve (AUC) value of 0.988 [0.981:0.993] for the detection of referable DR.\nAt the proposed operating point, the sensitivity of the RetCAD software for DR\nis 90.53% and specificity is 97.13%. A workload reduction of 96% could be\nachieved at the cost of only 6 false negatives. Conclusions: The AI software\ncorrectly identified the vast majority of referable DR cases, with a workload\nreduction of 96% of the cases that would need to be checked, while missing\nalmost no true cases, so it may therefore be used as an instrument for triage.",
    "descriptor": "\nComments: 15 pages, 3 figures, 2 tables\n",
    "authors": [
      "Ver\u00f3nica S\u00e1nchez-Guti\u00e9rrez",
      "Paula Hern\u00e1ndez-Mart\u00ednez",
      "Francisco J. Mu\u00f1oz-Negrete",
      "Jonne Engelberts",
      "Allison M. Luger",
      "Mark J.J.P. van Grinsven"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05554"
  },
  {
    "id": "arXiv:2205.05579",
    "title": "Components and Cycles of Random Mappings",
    "abstract": "Each connected component of a mapping $\\{1,2,...,n\\}\\rightarrow\\{1,2,...,n\\}$\ncontains a unique cycle. The largest such component can be studied\nprobabilistically via either a delay differential equation or an inverse\nLaplace transform. The longest such cycle likewise admits two approaches: we\nfind an (apparently new) density formula for its length. Implications of a\nconstraint -- that exactly one component exists -- are also examined. For\ninstance, the mean length of the longest cycle is $(0.7824...)\\sqrt n$ in\ngeneral, but for the special case, it is $(0.7978...)\\sqrt n$, a difference of\nless than $2\\%$.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Steven Finch"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2205.05579"
  },
  {
    "id": "arXiv:2205.05581",
    "title": "A deep representation learning speech enhancement method using  $\u03b2$-VAE",
    "abstract": "In previous work, we proposed a variational autoencoder-based (VAE) Bayesian\npermutation training speech enhancement (SE) method (PVAE) which indicated that\nthe SE performance of the traditional deep neural network-based (DNN) method\ncould be improved by deep representation learning (DRL). Based on our previous\nwork, we in this paper propose to use $\\beta$-VAE to further improve PVAE's\nability of representation learning. More specifically, our $\\beta$-VAE can\nimprove PVAE's capacity of disentangling different latent variables from the\nobserved signal without the trade-off problem between disentanglement and\nsignal reconstruction. This trade-off problem widely exists in previous\n$\\beta$-VAE algorithms. Unlike the previous $\\beta$-VAE algorithms, the\nproposed $\\beta$-VAE strategy can also be used to optimize the DNN's structure.\nThis means that the proposed method can not only improve PVAE's SE performance\nbut also reduce the number of PVAE training parameters. The experimental\nresults show that the proposed method can acquire better speech and noise\nlatent representation than PVAE. Meanwhile, it also obtains a higher\nscale-invariant signal-to-distortion ratio, speech quality, and speech\nintelligibility.",
    "descriptor": "\nComments: Submitted to Eurosipco\n",
    "authors": [
      "Yang Xiang",
      "Jesper Lisby H\u00f8jvang",
      "Morten H\u00f8jfeldt Rasmussen",
      "Mads Gr\u00e6sb\u00f8ll Christensen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2205.05581"
  },
  {
    "id": "arXiv:2205.05586",
    "title": "End-to-End Multi-Person Audio/Visual Automatic Speech Recognition",
    "abstract": "Traditionally, audio-visual automatic speech recognition has been studied\nunder the assumption that the speaking face on the visual signal is the face\nmatching the audio. However, in a more realistic setting, when multiple faces\nare potentially on screen one needs to decide which face to feed to the A/V ASR\nsystem. The present work takes the recent progress of A/V ASR one step further\nand considers the scenario where multiple people are simultaneously on screen\n(multi-person A/V ASR). We propose a fully differentiable A/V ASR model that is\nable to handle multiple face tracks in a video. Instead of relying on two\nseparate models for speaker face selection and audio-visual ASR on a single\nface track, we introduce an attention layer to the ASR encoder that is able to\nsoft-select the appropriate face video track. Experiments carried out on an A/V\nsystem trained on over 30k hours of YouTube videos illustrate that the proposed\napproach can automatically select the proper face tracks with minor WER\ndegradation compared to an oracle selection of the speaking face while still\nshowing benefits of employing the visual signal instead of the audio alone.",
    "descriptor": "",
    "authors": [
      "Otavio Braga",
      "Takaki Makino",
      "Olivier Siohan",
      "Hank Liao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2205.05586"
  },
  {
    "id": "arXiv:2205.05587",
    "title": "Choice of training label matters: how to best use deep learning for  quantitative MRI parameter estimation",
    "abstract": "Deep learning (DL) is gaining popularity as a parameter estimation method for\nquantitative MRI. A range of competing implementations have been proposed,\nrelying on either supervised or self-supervised learning. Self-supervised\napproaches, sometimes referred to as unsupervised, have been loosely based on\nauto-encoders, whereas supervised methods have, to date, been trained on\ngroundtruth labels. These two learning paradigms have been shown to have\ndistinct strengths. Notably, self-supervised approaches have offered lower-bias\nparameter estimates than their supervised alternatives. This result is\ncounterintuitive - incorporating prior knowledge with supervised labels should,\nin theory, lead to improved accuracy. In this work, we show that this apparent\nlimitation of supervised approaches stems from the naive choice of groundtruth\ntraining labels. By training on labels which are deliberately not groundtruth,\nwe show that the low-bias parameter estimation previously associated with\nself-supervised methods can be replicated - and improved on - within a\nsupervised learning framework. This approach sets the stage for a single,\nunifying, deep learning parameter estimation framework, based on supervised\nlearning, where trade-offs between bias and variance are made by careful\nadjustment of training label.",
    "descriptor": "\nComments: 20 pages, 10 figures\n",
    "authors": [
      "Sean C. Epstein",
      "Timothy J. P. Bray",
      "Margaret Hall-Craggs",
      "Hui Zhang"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.05587"
  },
  {
    "id": "arXiv:2205.05591",
    "title": "Predicting hot electrons free energies from ground-state data",
    "abstract": "Machine-learning potentials are usually trained on the ground-state,\nBorn-Oppenheimer energy surface, which depends exclusively on the atomic\npositions and not on the simulation temperature. This disregards the effect of\nthermally-excited electrons, that is important in metals, and essential to the\ndescription of warm dense matter. An accurate physical description of these\neffects requires that the nuclei move on a temperature-dependent electronic\nfree energy. We propose a method to obtain machine-learning predictions of this\nfree energy at an arbitrary electron temperature using exclusively training\ndata from ground-state calculations, avoiding the need to train\ntemperature-dependent potentials. We benchmark our method on metallic liquid\nhydrogen at the conditions of the core of gas giants and brown dwarfs.",
    "descriptor": "",
    "authors": [
      "Chiheb Ben Mahmoud",
      "Federico Grasselli",
      "Michele Ceriotti"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05591"
  },
  {
    "id": "arXiv:2205.05600",
    "title": "RLOP: RL Methods in Option Pricing from a Mathematical Perspective",
    "abstract": "Abstract In this work, we build two environments, namely the modified QLBS\nand RLOP models, from a mathematics perspective which enables RL methods in\noption pricing through replicating by portfolio. We implement the environment\nspecifications (the source code can be found at\nhttps://github.com/owen8877/RLOP), the learning algorithm, and agent\nparametrization by a neural network. The learned optimal hedging strategy is\ncompared against the BS prediction. The effect of various factors is considered\nand studied based on how they affect the optimal price and position.",
    "descriptor": "",
    "authors": [
      "Ziheng Chen"
    ],
    "subjectives": [
      "Pricing of Securities (q-fin.PR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05600"
  },
  {
    "id": "arXiv:2205.05607",
    "title": "A simple framework for contrastive learning phases of matter",
    "abstract": "A main task in condensed-matter physics is to recognize, classify, and\ncharacterize phases of matter and the corresponding phase transitions, for\nwhich machine learning provides a new class of research tools due to the\nremarkable development in computing power and algorithms. Despite much\nexploration in this new field, usually different methods and techniques are\nneeded for different scenarios. Here, we present SimCLP: a simple framework for\ncontrastive learning phases of matter, which is inspired by the recent\ndevelopment in contrastive learning of visual representations. We demonstrate\nthe success of this framework on several representative systems, including\nclassical and quantum, single-particle and many-body, conventional and\ntopological. SimCLP is flexible and free of usual burdens such as manual\nfeature engineering and prior knowledge. The only prerequisite is to prepare\nenough state configurations. Furthermore, it can generate representation\nvectors and labels and hence help tackle other problems. SimCLP therefore paves\nan alternative way to the development of a generic tool for identifying\nunexplored phase transitions.",
    "descriptor": "\nComments: 7 pages, 6 figures\n",
    "authors": [
      "Xiao-Qi Han",
      "Sheng-Song Xu",
      "Zhen Feng",
      "Rong-Qiang He",
      "Zhong-Yi Lu"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.05607"
  },
  {
    "id": "arXiv:2205.05614",
    "title": "Gamma and Vega Hedging Using Deep Distributional Reinforcement Learning",
    "abstract": "We use deep distributional reinforcement learning (RL) to develop hedging\nstrategies for a trader responsible for derivatives dependent on a particular\nunderlying asset. The transaction costs associated with trading the underlying\nasset are usually quite small. Traders therefore tend to carry out delta\nhedging daily, or even more frequently, to ensure that the portfolio is almost\ncompletely insensitive to small movements in the asset's price. Hedging the\nportfolio's exposure to large asset price movements and volatility changes\n(gamma and vega hedging) is more expensive because this requires trades in\nderivatives, for which transaction costs are quite large. Our analysis takes\naccount of these transaction cost differences. It shows how RL can be used to\ndevelop a strategy for using options to manage gamma and vega risk with three\ndifferent objective functions. These objective functions involve a\nmean-variance trade-off, value at risk, and conditional value at risk. We\nillustrate how the optimal hedging strategy depends on the asset price process,\nthe trader's objective function, the level of transaction costs when options\nare traded, and the maturity of the options used for hedging.",
    "descriptor": "",
    "authors": [
      "Jay Cao",
      "Jacky Chen",
      "Soroush Farghadani",
      "John Hull",
      "Zissis Poulos",
      "Zeyu Wang",
      "Jun Yuan"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2205.05614"
  },
  {
    "id": "arXiv:2205.05621",
    "title": "Rational sets in virtually abelian groups: languages and growth",
    "abstract": "In this paper we generalise and unify the results and methods used by Benson,\nLiardet, Evetts, and Evetts & Levine, to show that rational sets in a virtually\nabelian group G have rational (relative) growth series with respect to any\ngenerating set for G. We prove equivalences between the structures used in the\nliterature, and establish the rationality of important classes of sets in G:\ndefinable sets, algebraic sets, conjugacy representatives and coset\nrepresentatives (of any fixed subgroup), among others. Furthermore, we show\nthat any rational set, when written as words over the generating set of G, has\nseveral EDT0L representations.",
    "descriptor": "\nComments: 19 pages, 3 figures. Comments welcome\n",
    "authors": [
      "Laura Ciobanu",
      "Alex Evetts"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2205.05621"
  },
  {
    "id": "arXiv:2205.05625",
    "title": "Quantum Self-Attention Neural Networks for Text Classification",
    "abstract": "An emerging direction of quantum computing is to establish meaningful quantum\napplications in various fields of artificial intelligence, including natural\nlanguage processing (NLP). Although some efforts based on syntactic analysis\nhave opened the door to research in Quantum NLP (QNLP), limitations such as\nheavy syntactic preprocessing and syntax-dependent network architecture make\nthem impracticable on larger and real-world data sets. In this paper, we\npropose a new simple network architecture, called the quantum self-attention\nneural network (QSANN), which can make up for these limitations. Specifically,\nwe introduce the self-attention mechanism into quantum neural networks and then\nutilize a Gaussian projected quantum self-attention serving as a sensible\nquantum version of self-attention. As a result, QSANN is effective and scalable\non larger data sets and has the desirable property of being implementable on\nnear-term quantum devices. In particular, our QSANN outperforms the best\nexisting QNLP model based on syntactic analysis as well as a simple classical\nself-attention neural network in numerical experiments of text classification\ntasks on public data sets. We further show that our method exhibits robustness\nto low-level quantum noises.",
    "descriptor": "\nComments: 18 pages including appendix\n",
    "authors": [
      "Guangxi Li",
      "Xuanqiang Zhao",
      "Xin Wang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05625"
  },
  {
    "id": "arXiv:2205.05632",
    "title": "On Distributed Adaptive Optimization with Gradient Compression",
    "abstract": "We study COMP-AMS, a distributed optimization framework based on gradient\naveraging and adaptive AMSGrad algorithm. Gradient compression with error\nfeedback is applied to reduce the communication cost in the gradient\ntransmission process. Our convergence analysis of COMP-AMS shows that such\ncompressed gradient averaging strategy yields same convergence rate as standard\nAMSGrad, and also exhibits the linear speedup effect w.r.t. the number of local\nworkers. Compared with recently proposed protocols on distributed adaptive\nmethods, COMP-AMS is simple and convenient. Numerical experiments are conducted\nto justify the theoretical findings, and demonstrate that the proposed method\ncan achieve same test accuracy as the full-gradient AMSGrad with substantial\ncommunication savings. With its simplicity and efficiency, COMP-AMS can serve\nas a useful distributed training framework for adaptive gradient methods.",
    "descriptor": "",
    "authors": [
      "Xiaoyun Li",
      "Belhal Karimi",
      "Ping Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05632"
  },
  {
    "id": "arXiv:2205.05653",
    "title": "The First Optimal Algorithm for Smooth and  Strongly-Convex-Strongly-Concave Minimax Optimization",
    "abstract": "In this paper, we revisit the smooth and strongly-convex-strongly-concave\nminimax optimization problem. Zhang et al. (2021) and Ibrahim et al. (2020)\nestablished the lower bound $\\Omega\\left(\\sqrt{\\kappa_x\\kappa_y} \\log\n\\frac{1}{\\epsilon}\\right)$ on the number of gradient evaluations required to\nfind an $\\epsilon$-accurate solution, where $\\kappa_x$ and $\\kappa_y$ are\ncondition numbers for the strong convexity and strong concavity assumptions.\nHowever, the existing state-of-the-art methods do not match this lower bound:\nalgorithms of Lin et al. (2020) and Wang and Li (2020) have gradient evaluation\ncomplexity $\\mathcal{O}\\left(\n\\sqrt{\\kappa_x\\kappa_y}\\log^3\\frac{1}{\\epsilon}\\right)$ and $\\mathcal{O}\\left(\n\\sqrt{\\kappa_x\\kappa_y}\\log^3 (\\kappa_x\\kappa_y)\\log\\frac{1}{\\epsilon}\\right)$,\nrespectively. We fix this fundamental issue by providing the first algorithm\nwith $\\mathcal{O}\\left(\\sqrt{\\kappa_x\\kappa_y}\\log\\frac{1}{\\epsilon}\\right)$\ngradient evaluation complexity. We design our algorithm in three steps: (i) we\nreformulate the original problem as a minimization problem via the pointwise\nconjugate function; (ii) we apply a specific variant of the proximal point\nalgorithm to the reformulated problem; (iii) we compute the proximal operator\ninexactly using the optimal algorithm for operator norm reduction in monotone\ninclusions.",
    "descriptor": "",
    "authors": [
      "Dmitry Kovalev",
      "Alexander Gasnikov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05653"
  },
  {
    "id": "arXiv:1711.07285",
    "title": "Quantum Query Algorithms are Completely Bounded Forms",
    "abstract": "Comments: 24 pages, 3 figures. v2: 27 pages, minor changes in response to referee comments. v3: addresses an error in a proof and gives a reference for a corrected proof",
    "descriptor": "\nComments: 24 pages, 3 figures. v2: 27 pages, minor changes in response to referee comments. v3: addresses an error in a proof and gives a reference for a corrected proof\n",
    "authors": [
      "Srinivasan Arunachalam",
      "Jop Bri\u00ebt",
      "Carlos Palazuelos"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Functional Analysis (math.FA)",
      "Operator Algebras (math.OA)"
    ],
    "url": "https://arxiv.org/abs/1711.07285"
  },
  {
    "id": "arXiv:1904.05040",
    "title": "Optimising capacity allocation in networks of stochastic loss systems: A  functional-form approach",
    "abstract": "Optimising capacity allocation in networks of stochastic loss systems: A  functional-form approach",
    "descriptor": "",
    "authors": [
      "Brendan Patch",
      "Mark S. Squillante",
      "Peter M. Van de Ven"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/1904.05040"
  },
  {
    "id": "arXiv:1911.11582",
    "title": "DDNet: Dual-path Decoder Network for Occlusion Relationship Reasoning",
    "abstract": "Comments: The new one has been republished as arXiv:2108.05722",
    "descriptor": "\nComments: The new one has been republished as arXiv:2108.05722\n",
    "authors": [
      "Panhe Feng",
      "Xuejing Kang",
      "Lizhu Ye",
      "Lei Zhu",
      "Chunpeng Li",
      "Anlong Ming"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1911.11582"
  },
  {
    "id": "arXiv:2002.11650",
    "title": "Contextual Search in the Presence of Adversarial Corruptions",
    "abstract": "Comments: The first version was titled \"Corrupted multidimensional binary search: Learning in the presence of irrational agents\". An 8-page extended abstract titled \"Contextual search in the presence of irrational agents\" appeared at the 53rd ACM Symposium on the Theory of Computing (STOC '21)",
    "descriptor": "\nComments: The first version was titled \"Corrupted multidimensional binary search: Learning in the presence of irrational agents\". An 8-page extended abstract titled \"Contextual search in the presence of irrational agents\" appeared at the 53rd ACM Symposium on the Theory of Computing (STOC '21)\n",
    "authors": [
      "Akshay Krishnamurthy",
      "Thodoris Lykouris",
      "Chara Podimata",
      "Robert Schapire"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)",
      "General Economics (econ.GN)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.11650"
  },
  {
    "id": "arXiv:2003.00982",
    "title": "Benchmarking Graph Neural Networks",
    "abstract": "Comments: Benchmarking framework on GitHub at this https URL",
    "descriptor": "\nComments: Benchmarking framework on GitHub at this https URL\n",
    "authors": [
      "Vijay Prakash Dwivedi",
      "Chaitanya K. Joshi",
      "Anh Tuan Luu",
      "Thomas Laurent",
      "Yoshua Bengio",
      "Xavier Bresson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.00982"
  },
  {
    "id": "arXiv:2003.10976",
    "title": "A Model-Free Sampling Method for Estimating Basins of Attraction Using  Hybrid Active Learning (HAL)",
    "abstract": "Comments: Update: 1) add time trajectory of additional sampling",
    "descriptor": "\nComments: Update: 1) add time trajectory of additional sampling\n",
    "authors": [
      "Xue-She Wang",
      "Samuel A. Moore",
      "James D. Turner",
      "Brian P. Mann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.10976"
  },
  {
    "id": "arXiv:2004.08514",
    "title": "DMT: Dynamic Mutual Training for Semi-Supervised Learning",
    "abstract": "Comments: Published at Pattern Recognition, see this https URL",
    "descriptor": "\nComments: Published at Pattern Recognition, see this https URL\n",
    "authors": [
      "Zhengyang Feng",
      "Qianyu Zhou",
      "Qiqi Gu",
      "Xin Tan",
      "Guangliang Cheng",
      "Xuequan Lu",
      "Jianping Shi",
      "Lizhuang Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2004.08514"
  },
  {
    "id": "arXiv:2007.15705",
    "title": "A note on the class of languages generated by F-systems over regular  languages",
    "abstract": "Comments: Nine pages. This is the accepted version of a manuscript submitted for publication in Information Processing Letters",
    "descriptor": "\nComments: Nine pages. This is the accepted version of a manuscript submitted for publication in Information Processing Letters\n",
    "authors": [
      "Jorge C. Lucero",
      "S\u0142awek Staworko"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2007.15705"
  },
  {
    "id": "arXiv:2010.12060",
    "title": "Analysis of three dimensional potential problems in non-homogeneous  media with physics-informed deep collocation method using material transfer  learning and sensitivity analysis",
    "abstract": "Analysis of three dimensional potential problems in non-homogeneous  media with physics-informed deep collocation method using material transfer  learning and sensitivity analysis",
    "descriptor": "",
    "authors": [
      "Hongwei Guo",
      "Xiaoying Zhuang",
      "Pengwan Chen",
      "Naif Alajlan",
      "Timon Rabczuk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2010.12060"
  },
  {
    "id": "arXiv:2012.05590",
    "title": "An Asynchronous Kalman Filter for Hybrid Event Cameras",
    "abstract": "Comments: 12 pages, 6 figures, published in International Conference on Computer Vision (ICCV) 2021",
    "descriptor": "\nComments: 12 pages, 6 figures, published in International Conference on Computer Vision (ICCV) 2021\n",
    "authors": [
      "Ziwei Wang",
      "Yonhon Ng",
      "Cedric Scheerlinck",
      "Robert Mahony"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2012.05590"
  },
  {
    "id": "arXiv:2012.07381",
    "title": "Influence-Driven Data Poisoning in Graph-Based Semi-Supervised  Classifiers",
    "abstract": "Influence-Driven Data Poisoning in Graph-Based Semi-Supervised  Classifiers",
    "descriptor": "",
    "authors": [
      "Adriano Franci",
      "Maxime Cordy",
      "Martin Gubri",
      "Mike Papadakis",
      "Yves Le Traon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2012.07381"
  },
  {
    "id": "arXiv:2102.04297",
    "title": "Eliminating Sharp Minima from SGD with Truncated Heavy-tailed Noise",
    "abstract": "Comments: Proceedings of 2022 International Conference on Learning Representations. 157 pages (12 pages for the main paper and 145 pages for the supplementary materials)",
    "descriptor": "\nComments: Proceedings of 2022 International Conference on Learning Representations. 157 pages (12 pages for the main paper and 145 pages for the supplementary materials)\n",
    "authors": [
      "Xingyu Wang",
      "Sewoong Oh",
      "Chang-Han Rhee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.04297"
  },
  {
    "id": "arXiv:2102.05566",
    "title": "Layer VQE: A Variational Approach for Combinatorial Optimization on  Noisy Quantum Computers",
    "abstract": "Layer VQE: A Variational Approach for Combinatorial Optimization on  Noisy Quantum Computers",
    "descriptor": "",
    "authors": [
      "Xiaoyuan Liu",
      "Anthony Angone",
      "Ruslan Shaydulin",
      "Ilya Safro",
      "Yuri Alexeev",
      "Lukasz Cincio"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2102.05566"
  },
  {
    "id": "arXiv:2102.08307",
    "title": "Dynamic neighbourhood optimisation for task allocation using multi-agent",
    "abstract": "Comments: 28 pages",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Niall Creech",
      "Natalia Criado Pacheco",
      "Simon Miles"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.08307"
  },
  {
    "id": "arXiv:2102.10476",
    "title": "Contextual Standard Auctions with Budgets: Revenue Equivalence and  Efficiency Guarantees",
    "abstract": "Contextual Standard Auctions with Budgets: Revenue Equivalence and  Efficiency Guarantees",
    "descriptor": "",
    "authors": [
      "Santiago Balseiro",
      "Christian Kroer",
      "Rachitesh Kumar"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2102.10476"
  },
  {
    "id": "arXiv:2103.03954",
    "title": "ODAS: Open embeddeD Audition System",
    "abstract": "Comments: This paper was published in Frontiers Robotics and AI",
    "descriptor": "\nComments: This paper was published in Frontiers Robotics and AI\n",
    "authors": [
      "Fran\u00e7ois Grondin",
      "Dominic L\u00e9tourneau",
      "C\u00e9dric Godin",
      "Jean-Samuel Lauzon",
      "Jonathan Vincent",
      "Simon Michaud",
      "Samuel Faucher",
      "Fran\u00e7ois Michaud"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Robotics (cs.RO)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2103.03954"
  },
  {
    "id": "arXiv:2103.07584",
    "title": "Free-form Design of Discrete Architectural Surfaces by use of Circle  Packing",
    "abstract": "Free-form Design of Discrete Architectural Surfaces by use of Circle  Packing",
    "descriptor": "",
    "authors": [
      "Shizuo Kaji",
      "Jingyao Zhang"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2103.07584"
  },
  {
    "id": "arXiv:2103.09696",
    "title": "Generating Annotated Training Data for 6D Object Pose Estimation in  Operational Environments with Minimal User Interaction",
    "abstract": "Comments: Paper was not accepted",
    "descriptor": "\nComments: Paper was not accepted\n",
    "authors": [
      "Paul Koch",
      "Marian Schl\u00fcter",
      "Serge Thill"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.09696"
  },
  {
    "id": "arXiv:2103.13881",
    "title": "Plasma Spray Process Parameters Configuration using Sample-efficient  Batch Bayesian Optimization",
    "abstract": "Comments: Accepted for IEEE CASE 2021",
    "descriptor": "\nComments: Accepted for IEEE CASE 2021\n",
    "authors": [
      "Xavier Guidetti",
      "Alisa Rupenyan",
      "Lutz Fassl",
      "Majid Nabavi",
      "John Lygeros"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.13881"
  },
  {
    "id": "arXiv:2103.17205",
    "title": "Augmenting Poetry Composition with Verse by Verse",
    "abstract": "Comments: NAACL 2022 Industry Track",
    "descriptor": "\nComments: NAACL 2022 Industry Track\n",
    "authors": [
      "David Uthus",
      "Maria Voitovich",
      "R.J. Mical"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.17205"
  },
  {
    "id": "arXiv:2104.10338",
    "title": "Shadow Generation for Composite Image in Real-world Scenes",
    "abstract": "Comments: This paper is accepted by AAAI 2022",
    "descriptor": "\nComments: This paper is accepted by AAAI 2022\n",
    "authors": [
      "Yan Hong",
      "Li Niu",
      "Jianfu Zhang",
      "Liqing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2104.10338"
  },
  {
    "id": "arXiv:2104.12250",
    "title": "XLM-T: Multilingual Language Models in Twitter for Sentiment Analysis  and Beyond",
    "abstract": "Comments: LREC 2022. Code and data available at this https URL",
    "descriptor": "\nComments: LREC 2022. Code and data available at this https URL\n",
    "authors": [
      "Francesco Barbieri",
      "Luis Espinosa Anke",
      "Jose Camacho-Collados"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.12250"
  },
  {
    "id": "arXiv:2105.14403",
    "title": "Re-evaluating Word Mover's Distance",
    "abstract": "Re-evaluating Word Mover's Distance",
    "descriptor": "",
    "authors": [
      "Ryoma Sato",
      "Makoto Yamada",
      "Hisashi Kashima"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.14403"
  },
  {
    "id": "arXiv:2105.15124",
    "title": "Screening of the Characteristics of Hate Crimes against Asian American  and Comparison to African Americans in Bay Area",
    "abstract": "Comments: The article is already retracted and it no longer exists in the journal",
    "descriptor": "\nComments: The article is already retracted and it no longer exists in the journal\n",
    "authors": [
      "Myung Suh Choi",
      "Yuli Choi",
      "Kevin Kang",
      "Katherine Lee",
      "Jacquelyn Ryu",
      "Nayeon Yu",
      "Sihyeon Yoon"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2105.15124"
  },
  {
    "id": "arXiv:2106.00058",
    "title": "Stable and Interpretable Unrolled Dictionary Learning",
    "abstract": "Stable and Interpretable Unrolled Dictionary Learning",
    "descriptor": "",
    "authors": [
      "Bahareh Tolooshams",
      "Demba Ba"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00058"
  },
  {
    "id": "arXiv:2106.01926",
    "title": "A new framework for polynomial approximation to differential equations",
    "abstract": "Comments: 35 pages, 4 figures, 2 tables",
    "descriptor": "\nComments: 35 pages, 4 figures, 2 tables\n",
    "authors": [
      "Luigi Brugnano",
      "Gianluca Frasca-Caccia",
      "Felice Iavernaro",
      "Vincenzo Vespri"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.01926"
  },
  {
    "id": "arXiv:2106.05146",
    "title": "An arbitrary order and pointwise divergence-free finite element scheme  for the incompressible 3D Navier-Stokes equations",
    "abstract": "Comments: 25 pages, 7 figures Improved readability of the introduction. Corrected typos",
    "descriptor": "\nComments: 25 pages, 7 figures Improved readability of the introduction. Corrected typos\n",
    "authors": [
      "M. Hanot"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.05146"
  },
  {
    "id": "arXiv:2106.09399",
    "title": "Using current research information systems to investigate data  acquisition and data sharing practices of computer scientists",
    "abstract": "Comments: e-pub ahead of print version",
    "descriptor": "\nComments: e-pub ahead of print version\n",
    "authors": [
      "Antti Mikael Rousi"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2106.09399"
  },
  {
    "id": "arXiv:2106.14248",
    "title": "Multi-Modal Transformer for Accelerated MR Imaging",
    "abstract": "Comments: this https URL",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Chun-Mei Feng",
      "Yunlu Yan",
      "Geng Chen",
      "Yong Xu",
      "Ling Shao",
      "Huazhu Fu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.14248"
  },
  {
    "id": "arXiv:2107.06658",
    "title": "A Framework for Machine Learning of Model Error in Dynamical Systems",
    "abstract": "A Framework for Machine Learning of Model Error in Dynamical Systems",
    "descriptor": "",
    "authors": [
      "Matthew E. Levine",
      "Andrew M. Stuart"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.06658"
  },
  {
    "id": "arXiv:2107.08995",
    "title": "Causal Inference Struggles with Agency on Online Platforms",
    "abstract": "Comments: Accepted to FaccT'22",
    "descriptor": "\nComments: Accepted to FaccT'22\n",
    "authors": [
      "Smitha Milli",
      "Luca Belli",
      "Moritz Hardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2107.08995"
  },
  {
    "id": "arXiv:2107.13193",
    "title": "Assessment of Deep Learning-based Heart Rate Estimation using Remote  Photoplethysmography under Different Illuminations",
    "abstract": "Assessment of Deep Learning-based Heart Rate Estimation using Remote  Photoplethysmography under Different Illuminations",
    "descriptor": "",
    "authors": [
      "Ze Yang",
      "Haofei Wang",
      "Feng Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.13193"
  },
  {
    "id": "arXiv:2107.13435",
    "title": "MWP-BERT: Numeracy-Augmented Pre-training for Math Word Problem Solving",
    "abstract": "Comments: Accepted by the Findings of NAACL 2022",
    "descriptor": "\nComments: Accepted by the Findings of NAACL 2022\n",
    "authors": [
      "Zhenwen Liang",
      "Jipeng Zhang",
      "Lei Wang",
      "Wei Qin",
      "Yunshi Lan",
      "Jie Shao",
      "Xiangliang Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.13435"
  },
  {
    "id": "arXiv:2108.02605",
    "title": "EENLP: Cross-lingual Eastern European NLP Index",
    "abstract": "Comments: Accepted for LREC 2022. 5 pages, 1 figure. Originally EEML 2021 project",
    "descriptor": "\nComments: Accepted for LREC 2022. 5 pages, 1 figure. Originally EEML 2021 project\n",
    "authors": [
      "Alexey Tikhonov",
      "Alex Malkhasov",
      "Andrey Manoshin",
      "George Dima",
      "R\u00e9ka Cserh\u00e1ti",
      "Md.Sadek Hossain Asif",
      "Matt S\u00e1rdi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2108.02605"
  },
  {
    "id": "arXiv:2108.05338",
    "title": "Truncated Emphatic Temporal Difference Methods for Prediction and  Control",
    "abstract": "Comments: Journal of Machine Learning Research 2022",
    "descriptor": "\nComments: Journal of Machine Learning Research 2022\n",
    "authors": [
      "Shangtong Zhang",
      "Shimon Whiteson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.05338"
  },
  {
    "id": "arXiv:2109.00388",
    "title": "Boolean proportions",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2006.02854",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2006.02854\n",
    "authors": [
      "Christian Anti\u0107"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2109.00388"
  },
  {
    "id": "arXiv:2109.06009",
    "title": "Entropy inequalities for random walks and permutations",
    "abstract": "Comments: 31 pages; 3 figures",
    "descriptor": "\nComments: 31 pages; 3 figures\n",
    "authors": [
      "Alexandre Bristiel",
      "Pietro Caputo"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2109.06009"
  },
  {
    "id": "arXiv:2109.07239",
    "title": "Internet of Behavior (IoB) and Explainable AI Systems for Influencing  IoT Behavior",
    "abstract": "Comments: Major Revision in IEEE Network",
    "descriptor": "\nComments: Major Revision in IEEE Network\n",
    "authors": [
      "Haya Elayan",
      "Moayad Aloqaily",
      "Fakhri Karray",
      "Mohsen Guizani"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07239"
  },
  {
    "id": "arXiv:2109.13627",
    "title": "Generalising the achromatic number to Zaslavsky's colourings of signed  graphs",
    "abstract": "Generalising the achromatic number to Zaslavsky's colourings of signed  graphs",
    "descriptor": "",
    "authors": [
      "Julien Bensmail",
      "Fran\u00e7ois Dross",
      "Nacim Oijid",
      "\u00c9ric Sopena"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2109.13627"
  },
  {
    "id": "arXiv:2110.00300",
    "title": "A cost-effective nonlinear extremum-preserving finite volume scheme for  highly anisotropic diffusion on Cartesian grids, with application to  radiation belt dynamics",
    "abstract": "A cost-effective nonlinear extremum-preserving finite volume scheme for  highly anisotropic diffusion on Cartesian grids, with application to  radiation belt dynamics",
    "descriptor": "",
    "authors": [
      "Nour Dahmen",
      "Jerome Droniou",
      "Francois Rogier"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.00300"
  },
  {
    "id": "arXiv:2110.01536",
    "title": "Universal approximation properties of shallow quadratic neural networks",
    "abstract": "Universal approximation properties of shallow quadratic neural networks",
    "descriptor": "",
    "authors": [
      "Leon Frischauf",
      "Otmar Scherzer",
      "Cong Shi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.01536"
  },
  {
    "id": "arXiv:2110.03045",
    "title": "Iterate Averaging, the Kalman Filter, and 3DVAR for Linear Inverse  Problem",
    "abstract": "Comments: revision 1, 20 pages, 3 figures",
    "descriptor": "\nComments: revision 1, 20 pages, 3 figures\n",
    "authors": [
      "Felix G. Jones",
      "Gideon Simpson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.03045"
  },
  {
    "id": "arXiv:2110.03630",
    "title": "Towards Faster Continuous Multi-Channel HRTF Measurements Based on  Learning System Models",
    "abstract": "Comments: 5 pages, 4 figures, minor changes compared to v1 after reviewers' feedbacks, accepted at ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
    "descriptor": "\nComments: 5 pages, 4 figures, minor changes compared to v1 after reviewers' feedbacks, accepted at ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\n",
    "authors": [
      "Tobias Kabzinski",
      "Peter Jax"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.03630"
  },
  {
    "id": "arXiv:2110.04988",
    "title": "Stereo Hybrid Event-Frame (SHEF) Cameras for 3D Perception",
    "abstract": "Comments: 10 pages, 6 figures, accepted for presentation at International Conference on Intelligent Robots and Systems (IROS), 2021",
    "descriptor": "\nComments: 10 pages, 6 figures, accepted for presentation at International Conference on Intelligent Robots and Systems (IROS), 2021\n",
    "authors": [
      "Ziwei Wang",
      "Liyuan Pan",
      "Yonhon Ng",
      "Zheyu Zhuang",
      "Robert Mahony"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04988"
  },
  {
    "id": "arXiv:2110.05128",
    "title": "REIN-2: Giving Birth to Prepared Reinforcement Learning Agents Using  Reinforcement Learning Agents",
    "abstract": "REIN-2: Giving Birth to Prepared Reinforcement Learning Agents Using  Reinforcement Learning Agents",
    "descriptor": "",
    "authors": [
      "Aristotelis Lazaridis",
      "Ioannis Vlahavas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05128"
  },
  {
    "id": "arXiv:2110.12594",
    "title": "Developing a Meta-suggestion Engine for Search Queries",
    "abstract": "Developing a Meta-suggestion Engine for Search Queries",
    "descriptor": "",
    "authors": [
      "Seungmin Kim",
      "EunChan Na",
      "Seong Baeg Kim"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.12594"
  },
  {
    "id": "arXiv:2110.15210",
    "title": "Towards Model Agnostic Federated Learning Using Knowledge Distillation",
    "abstract": "Comments: Published at ICLR 2022",
    "descriptor": "\nComments: Published at ICLR 2022\n",
    "authors": [
      "Andrei Afonin",
      "Sai Praneeth Karimireddy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.15210"
  },
  {
    "id": "arXiv:2111.01827",
    "title": "Equivalent Versions of Total Flow Analysis",
    "abstract": "Equivalent Versions of Total Flow Analysis",
    "descriptor": "",
    "authors": [
      "St\u00e9phan Plassart",
      "Jean-Yves Le Boudec"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.01827"
  },
  {
    "id": "arXiv:2111.03217",
    "title": "Boundary Estimation from Point Clouds: Algorithms, Guarantees and  Applications",
    "abstract": "Comments: 53 pages, 14 figures",
    "descriptor": "\nComments: 53 pages, 14 figures\n",
    "authors": [
      "Jeff Calder",
      "Sangmin Park",
      "Dejan Slep\u010dev"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.03217"
  },
  {
    "id": "arXiv:2111.13696",
    "title": "A Ubiquitous Unifying Degeneracy in Two-Body Microlensing Systems",
    "abstract": "Comments: 21 pages, 8 figures, submitted",
    "descriptor": "\nComments: 21 pages, 8 figures, submitted\n",
    "authors": [
      "Keming Zhang",
      "B. Scott Gaudi",
      "Joshua S. Bloom"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.13696"
  },
  {
    "id": "arXiv:2111.15186",
    "title": "Automatic Synthesis of Diverse Weak Supervision Sources for Behavior  Analysis",
    "abstract": "Comments: 8 pages, to appear at CVPR 2022",
    "descriptor": "\nComments: 8 pages, to appear at CVPR 2022\n",
    "authors": [
      "Albert Tseng",
      "Jennifer J. Sun",
      "Yisong Yue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15186"
  },
  {
    "id": "arXiv:2112.00029",
    "title": "Pixelated Butterfly: Simple and Efficient Sparse training for Neural  Network Models",
    "abstract": "Comments: International Conference on Learning Representations (ICLR) 2022 spotlight",
    "descriptor": "\nComments: International Conference on Learning Representations (ICLR) 2022 spotlight\n",
    "authors": [
      "Tri Dao",
      "Beidi Chen",
      "Kaizhao Liang",
      "Jiaming Yang",
      "Zhao Song",
      "Atri Rudra",
      "Christopher R\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00029"
  },
  {
    "id": "arXiv:2112.00227",
    "title": "A Machine Learning Analysis of COVID-19 Mental Health Data",
    "abstract": "Comments: 29 pages",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Mostafa Rezapour",
      "Lucas Hansen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.00227"
  },
  {
    "id": "arXiv:2112.03125",
    "title": "An arbitrary-order fully discrete Stokes complex on general polygonal  meshes",
    "abstract": "Comments: 33 pages, 3 figures Improved overall readability",
    "descriptor": "\nComments: 33 pages, 3 figures Improved overall readability\n",
    "authors": [
      "Marien-Lorenzo Hanot"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.03125"
  },
  {
    "id": "arXiv:2112.06423",
    "title": "Stochastic differential equations for limiting description of UCB rule  for Gaussian multi-armed bandits",
    "abstract": "Comments: 9 pages, 2 figures",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Sergey Garbar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2112.06423"
  },
  {
    "id": "arXiv:2112.07874",
    "title": "Linguistic Frameworks Go Toe-to-Toe at Neuro-Symbolic Language Modeling",
    "abstract": "Comments: Accepted to NAACL 2022 (slight typesetting divergences to NAACL camera-ready due to TexLive 2020/2021 mismatches)",
    "descriptor": "\nComments: Accepted to NAACL 2022 (slight typesetting divergences to NAACL camera-ready due to TexLive 2020/2021 mismatches)\n",
    "authors": [
      "Jakob Prange",
      "Nathan Schneider",
      "Lingpeng Kong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07874"
  },
  {
    "id": "arXiv:2112.08608",
    "title": "QuALITY: Question Answering with Long Input Texts, Yes!",
    "abstract": "Comments: NAACL 2022",
    "descriptor": "\nComments: NAACL 2022\n",
    "authors": [
      "Richard Yuanzhe Pang",
      "Alicia Parrish",
      "Nitish Joshi",
      "Nikita Nangia",
      "Jason Phang",
      "Angelica Chen",
      "Vishakh Padmakumar",
      "Johnny Ma",
      "Jana Thompson",
      "He He",
      "Samuel R. Bowman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08608"
  },
  {
    "id": "arXiv:2112.09062",
    "title": "Models in the Loop: Aiding Crowdworkers with Generative Annotation  Assistants",
    "abstract": "Models in the Loop: Aiding Crowdworkers with Generative Annotation  Assistants",
    "descriptor": "",
    "authors": [
      "Max Bartolo",
      "Tristan Thrush",
      "Sebastian Riedel",
      "Pontus Stenetorp",
      "Robin Jia",
      "Douwe Kiela"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.09062"
  },
  {
    "id": "arXiv:2112.09796",
    "title": "AutoTransfer: Subject Transfer Learning with Censored Representations on  Biosignals Data",
    "abstract": "Comments: 17 page extended version of International Engineering in Medicine and Biology Conference 2022 paper",
    "descriptor": "\nComments: 17 page extended version of International Engineering in Medicine and Biology Conference 2022 paper\n",
    "authors": [
      "Niklas Smedemark-Margulies",
      "Ye Wang",
      "Toshiaki Koike-Akino",
      "Deniz Erdogmus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.09796"
  },
  {
    "id": "arXiv:2112.10287",
    "title": "Marginal Independence Models",
    "abstract": "Comments: Revised to include more details in proof. Prepared for ISSAC '22",
    "descriptor": "\nComments: Revised to include more details in proof. Prepared for ISSAC '22\n",
    "authors": [
      "Tobias Boege",
      "Sonja Petrovi\u0107",
      "Bernd Sturmfels"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Symbolic Computation (cs.SC)",
      "Algebraic Geometry (math.AG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.10287"
  },
  {
    "id": "arXiv:2112.10751",
    "title": "RvS: What is Essential for Offline RL via Supervised Learning?",
    "abstract": "RvS: What is Essential for Offline RL via Supervised Learning?",
    "descriptor": "",
    "authors": [
      "Scott Emmons",
      "Benjamin Eysenbach",
      "Ilya Kostrikov",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.10751"
  },
  {
    "id": "arXiv:2112.15034",
    "title": "Self Reward Design with Fine-grained Interpretability",
    "abstract": "Self Reward Design with Fine-grained Interpretability",
    "descriptor": "",
    "authors": [
      "Erico Tjoa",
      "Guan Cuntai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.15034"
  },
  {
    "id": "arXiv:2112.15198",
    "title": "Massively Parallelized Interpolated Factored Green Function Method",
    "abstract": "Comments: 25 pages, 6 figures, 1 table, 14 algorithms, 8 pages supplementary materials with 5 tables",
    "descriptor": "\nComments: 25 pages, 6 figures, 1 table, 14 algorithms, 8 pages supplementary materials with 5 tables\n",
    "authors": [
      "Christoph Bauinger",
      "Oscar P. Bruno"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.15198"
  },
  {
    "id": "arXiv:2201.08528",
    "title": "To SMOTE, or not to SMOTE?",
    "abstract": "To SMOTE, or not to SMOTE?",
    "descriptor": "",
    "authors": [
      "Yotam Elor",
      "Hadar Averbuch-Elor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08528"
  },
  {
    "id": "arXiv:2201.10295",
    "title": "Post-Hoc Explanations Fail to Achieve their Purpose in Adversarial  Contexts",
    "abstract": "Comments: FAccT 2022",
    "descriptor": "\nComments: FAccT 2022\n",
    "authors": [
      "Sebastian Bordt",
      "Mich\u00e8le Finck",
      "Eric Raidl",
      "Ulrike von Luxburg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.10295"
  },
  {
    "id": "arXiv:2201.10574",
    "title": "Basic Quantum Algorithms",
    "abstract": "Comments: 107 pages",
    "descriptor": "\nComments: 107 pages\n",
    "authors": [
      "Renato Portugal"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2201.10574"
  },
  {
    "id": "arXiv:2201.11884",
    "title": "Making the Unaccountable Internet: The Changing Meaning of Accounting in  the Early ARPANET",
    "abstract": "Making the Unaccountable Internet: The Changing Meaning of Accounting in  the Early ARPANET",
    "descriptor": "",
    "authors": [
      "A. Feder Cooper",
      "Gili Vidan"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2201.11884"
  },
  {
    "id": "arXiv:2201.13106",
    "title": "Computational Complexity of Segmentation",
    "abstract": "Computational Complexity of Segmentation",
    "descriptor": "",
    "authors": [
      "Federico Adolfi",
      "Todd Wareham",
      "Iris van Rooij"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2201.13106"
  },
  {
    "id": "arXiv:2202.00643",
    "title": "Topological invariants for words of linear factor complexity",
    "abstract": "Comments: 14 pages",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Jason Bell"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2202.00643"
  },
  {
    "id": "arXiv:2202.04613",
    "title": "Automated Distance Estimation for Wildlife Camera Trapping",
    "abstract": "Automated Distance Estimation for Wildlife Camera Trapping",
    "descriptor": "",
    "authors": [
      "Peter Johanns",
      "Timm Haucke",
      "Volker Steinhage"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04613"
  },
  {
    "id": "arXiv:2202.05143",
    "title": "On the Acquisition of Stationary Signals Using Uniform ADCs",
    "abstract": "Comments: Accepted for presentation at the 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Singapore. Extended version including proofs. Includes corrections",
    "descriptor": "\nComments: Accepted for presentation at the 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Singapore. Extended version including proofs. Includes corrections\n",
    "authors": [
      "Peter Neuhaus",
      "Nir Shlezinger",
      "Meik D\u00f6rpinghaus",
      "Yonina C. Eldar",
      "Gerhard Fettweis"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.05143"
  },
  {
    "id": "arXiv:2202.05158",
    "title": "Advanced sleep spindle identification with neural networks",
    "abstract": "Comments: 11 pages, 4 figures",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Lars Kaulen",
      "Justus T. C. Schwabedal",
      "Jules Schneider",
      "Philipp Ritter",
      "Stephan Bialonski"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2202.05158"
  },
  {
    "id": "arXiv:2202.06709",
    "title": "How Do Vision Transformers Work?",
    "abstract": "Comments: ICLR 2022 (Spotlight)",
    "descriptor": "\nComments: ICLR 2022 (Spotlight)\n",
    "authors": [
      "Namuk Park",
      "Songkuk Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06709"
  },
  {
    "id": "arXiv:2202.08816",
    "title": "Learning and Evaluating Graph Neural Network Explanations based on  Counterfactual and Factual Reasoning",
    "abstract": "Comments: Published at the Web Conference 2022 (WWW 2022)",
    "descriptor": "\nComments: Published at the Web Conference 2022 (WWW 2022)\n",
    "authors": [
      "Juntao Tan",
      "Shijie Geng",
      "Zuohui Fu",
      "Yingqiang Ge",
      "Shuyuan Xu",
      "Yunqi Li",
      "Yongfeng Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08816"
  },
  {
    "id": "arXiv:2202.08892",
    "title": "Developing Imperceptible Adversarial Patches to Camouflage Military  Assets From Computer Vision Enabled Technologies",
    "abstract": "Comments: 8 pages, 4 figures, 4 tables, submitted to WCCI 2022",
    "descriptor": "\nComments: 8 pages, 4 figures, 4 tables, submitted to WCCI 2022\n",
    "authors": [
      "Chris Wise",
      "Jo Plested"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08892"
  },
  {
    "id": "arXiv:2202.09269",
    "title": "Quantification of Actual Road User Behavior on the Basis of Given  Traffic Rules",
    "abstract": "Comments: Daniel Bogdoll and Moritz Nekolla contributed equally. Accepted for publication at IV 2022",
    "descriptor": "\nComments: Daniel Bogdoll and Moritz Nekolla contributed equally. Accepted for publication at IV 2022\n",
    "authors": [
      "Daniel Bogdoll",
      "Moritz Nekolla",
      "Tim Joseph",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09269"
  },
  {
    "id": "arXiv:2202.10866",
    "title": "Stateful Structural Operational Semantics",
    "abstract": "Stateful Structural Operational Semantics",
    "descriptor": "",
    "authors": [
      "Sergey Goncharov",
      "Stefan Milius",
      "Lutz Schr\u00f6der",
      "Stelios Tsampas",
      "Henning Urbat"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2202.10866"
  },
  {
    "id": "arXiv:2202.12796",
    "title": "Hybrid Robotic Grasping with a Soft Multimodal Gripper and a Deep  Multistage Learning Scheme",
    "abstract": "Hybrid Robotic Grasping with a Soft Multimodal Gripper and a Deep  Multistage Learning Scheme",
    "descriptor": "",
    "authors": [
      "Fukang Liu",
      "Fuchun Sun",
      "Bin Fang",
      "Xiang Li",
      "Songyu Sun",
      "Huaping Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.12796"
  },
  {
    "id": "arXiv:2202.13403",
    "title": "A Multimodal German Dataset for Automatic Lip Reading Systems and  Transfer Learning",
    "abstract": "Comments: Accepted to LREC 2022",
    "descriptor": "\nComments: Accepted to LREC 2022\n",
    "authors": [
      "Gerald Schwiebert",
      "Cornelius Weber",
      "Leyuan Qu",
      "Henrique Siqueira",
      "Stefan Wermter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.13403"
  },
  {
    "id": "arXiv:2203.01171",
    "title": "Imitation of Manipulation Skills Using Multiple Geometries",
    "abstract": "Imitation of Manipulation Skills Using Multiple Geometries",
    "descriptor": "",
    "authors": [
      "Boyang Ti",
      "Yongsheng Gao",
      "Jie Zhao",
      "Sylvain Calinon"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.01171"
  },
  {
    "id": "arXiv:2203.01633",
    "title": "Numerical method for feasible and approximately optimal solutions of  multi-marginal optimal transport beyond discrete measures",
    "abstract": "Numerical method for feasible and approximately optimal solutions of  multi-marginal optimal transport beyond discrete measures",
    "descriptor": "",
    "authors": [
      "Ariel Neufeld",
      "Qikun Xiang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2203.01633"
  },
  {
    "id": "arXiv:2203.04862",
    "title": "Information recoverability of noisy quantum states",
    "abstract": "Comments: 18 pages including appendix",
    "descriptor": "\nComments: 18 pages including appendix\n",
    "authors": [
      "Xuanqiang Zhao",
      "Benchi Zhao",
      "Zihan Xia",
      "Xin Wang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "High Energy Physics - Theory (hep-th)"
    ],
    "url": "https://arxiv.org/abs/2203.04862"
  },
  {
    "id": "arXiv:2203.06385",
    "title": "Stateless or stateful FaaS? I'll take both!",
    "abstract": "Comments: Accepted at IEEE SMARTCOMP 2022",
    "descriptor": "\nComments: Accepted at IEEE SMARTCOMP 2022\n",
    "authors": [
      "Carlo Puliafito",
      "Claudio Cicconetti",
      "Marco Conti",
      "Enzo Mingozzi",
      "Andrea Passarella"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.06385"
  },
  {
    "id": "arXiv:2203.09993",
    "title": "WebRobot: Web Robotic Process Automation using Interactive  Programming-by-Demonstration",
    "abstract": "Comments: Published at PLDI 2022",
    "descriptor": "\nComments: Published at PLDI 2022\n",
    "authors": [
      "Rui Dong",
      "Zhicheng Huang",
      "Ian Iong Lam",
      "Yan Chen",
      "Xinyu Wang"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2203.09993"
  },
  {
    "id": "arXiv:2203.10810",
    "title": "Information-theoretic analyses of neural data to minimize the effect of  researchers' assumptions in predictive coding studies",
    "abstract": "Comments: 36 pages, 9 figures, 3 tables",
    "descriptor": "\nComments: 36 pages, 9 figures, 3 tables\n",
    "authors": [
      "Patricia Wollstadt",
      "Daniel L. Rathbun",
      "W. Martin Usrey and",
      "Andr\u00e9 Moraes Bastos",
      "Michael Lindner",
      "Viola Priesemann",
      "Michael Wibral"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.10810"
  },
  {
    "id": "arXiv:2203.10918",
    "title": "A robotic leg inspired from an insect leg",
    "abstract": "Comments: 17 pages, 10 figures",
    "descriptor": "\nComments: 17 pages, 10 figures\n",
    "authors": [
      "P.Thanh Tran-Ngoc",
      "Leslie Ziqi Lim",
      "Jia Hui Gan",
      "Hong Wang",
      "T.Thang Vo-Doan",
      "Hirotaka Sato"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.10918"
  },
  {
    "id": "arXiv:2203.10965",
    "title": "PTM4Tag: Sharpening Tag Recommendation of Stack Overflow Posts with  Pre-trained Models",
    "abstract": "Comments: Accepted for Research Track ICPC 2022",
    "descriptor": "\nComments: Accepted for Research Track ICPC 2022\n",
    "authors": [
      "Junda He",
      "Bowen Xu",
      "Zhou Yang",
      "DongGyun Han",
      "Chengran Yang",
      "David Lo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.10965"
  },
  {
    "id": "arXiv:2203.11016",
    "title": "Linking Theories and Methods in Cognitive Sciences via Joint Embedding  of the Scientific Literature: The Example of Cognitive Control",
    "abstract": "Comments: 7 pages, 4 figures,CogSci2022 camera ready",
    "descriptor": "\nComments: 7 pages, 4 figures,CogSci2022 camera ready\n",
    "authors": [
      "Morteza Ansarinia",
      "Paul Schrater",
      "Pedro Cardoso-Leite"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2203.11016"
  },
  {
    "id": "arXiv:2203.13294",
    "title": "Learning Spatiotemporal Chaos Using Next-Generation Reservoir Computing",
    "abstract": "Comments: 8 pages, 9 figures",
    "descriptor": "\nComments: 8 pages, 9 figures\n",
    "authors": [
      "Wendson A. S. Barbosa",
      "Daniel J. Gauthier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2203.13294"
  },
  {
    "id": "arXiv:2204.00382",
    "title": "Autoencoder Attractors for Uncertainty Estimation",
    "abstract": "Comments: This paper is accepted at IEEE International Conference on Pattern Recognition (ICPR), 2022",
    "descriptor": "\nComments: This paper is accepted at IEEE International Conference on Pattern Recognition (ICPR), 2022\n",
    "authors": [
      "Steve Dias Da Cruz",
      "Bertram Taetz",
      "Thomas Stifter",
      "Didier Stricker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.00382"
  },
  {
    "id": "arXiv:2204.00768",
    "title": "VQTTS: High-Fidelity Text-to-Speech Synthesis with Self-Supervised VQ  Acoustic Feature",
    "abstract": "Comments: Submitted to Interspeech 2022",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Chenpeng Du",
      "Yiwei Guo",
      "Xie Chen",
      "Kai Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.00768"
  },
  {
    "id": "arXiv:2204.01638",
    "title": "Reliable Editions from Unreliable Components: Estimating Ebooks from  Print Editions Using Profile Hidden Markov Models",
    "abstract": "Reliable Editions from Unreliable Components: Estimating Ebooks from  Print Editions Using Profile Hidden Markov Models",
    "descriptor": "",
    "authors": [
      "A. B. Riddell"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2204.01638"
  },
  {
    "id": "arXiv:2204.02567",
    "title": "FairNeuron: Improving Deep Neural Network Fairness with Adversary Games  on Selective Neurons",
    "abstract": "FairNeuron: Improving Deep Neural Network Fairness with Adversary Games  on Selective Neurons",
    "descriptor": "",
    "authors": [
      "Xuanqi Gao",
      "Juan Zhai",
      "Shiqing Ma",
      "Chao Shen",
      "Yufei Chen",
      "Qian Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.02567"
  },
  {
    "id": "arXiv:2204.02883",
    "title": "A Convex Optimization Approach for Control of Linear Quadratic Systems  with Multiplicative Noise via System Level Synthesis",
    "abstract": "A Convex Optimization Approach for Control of Linear Quadratic Systems  with Multiplicative Noise via System Level Synthesis",
    "descriptor": "",
    "authors": [
      "Majid Mazouchi",
      "Farzaneh Tatari",
      "Hamidreza Modares"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.02883"
  },
  {
    "id": "arXiv:2204.03304",
    "title": "Federated Learning from Only Unlabeled Data with  Class-Conditional-Sharing Clients",
    "abstract": "Comments: ICLR 2022 camera-ready version",
    "descriptor": "\nComments: ICLR 2022 camera-ready version\n",
    "authors": [
      "Nan Lu",
      "Zhao Wang",
      "Xiaoxiao Li",
      "Gang Niu",
      "Qi Dou",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03304"
  },
  {
    "id": "arXiv:2204.06028",
    "title": "CUNI-KIT System for Simultaneous Speech Translation Task at IWSLT 2022",
    "abstract": "Comments: Accepted to IWSLT22",
    "descriptor": "\nComments: Accepted to IWSLT22\n",
    "authors": [
      "Peter Pol\u00e1k",
      "Ngoc-Quan Ngoc",
      "Tuan-Nam Nguyen",
      "Danni Liu",
      "Carlos Mullov",
      "Jan Niehues",
      "Ond\u0159ej Bojar",
      "Alexander Waibel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.06028"
  },
  {
    "id": "arXiv:2204.06638",
    "title": "Clifford Circuits can be Properly PAC Learned if and only if  $\\textsf{RP}=\\textsf{NP}$",
    "abstract": "Comments: 25 pages, 2 figures",
    "descriptor": "\nComments: 25 pages, 2 figures\n",
    "authors": [
      "Daniel Liang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.06638"
  },
  {
    "id": "arXiv:2204.07208",
    "title": "Alternating Mahalanobis Distance Minimization for Stable and Accurate CP  Decomposition",
    "abstract": "Alternating Mahalanobis Distance Minimization for Stable and Accurate CP  Decomposition",
    "descriptor": "",
    "authors": [
      "Navjot Singh",
      "Edgar Solomonik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.07208"
  },
  {
    "id": "arXiv:2204.07661",
    "title": "Fairly Accurate: Learning Optimal Accuracy vs. Fairness Tradeoffs for  Hate Speech Detection",
    "abstract": "Fairly Accurate: Learning Optimal Accuracy vs. Fairness Tradeoffs for  Hate Speech Detection",
    "descriptor": "",
    "authors": [
      "Venelin Kovatchev",
      "Soumyajit Gupta",
      "Anubrata Das",
      "Matthew Lease"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07661"
  },
  {
    "id": "arXiv:2204.08189",
    "title": "Sardino: Ultra-Fast Dynamic Ensemble for Secure Visual Sensing at Mobile  Edge",
    "abstract": "Sardino: Ultra-Fast Dynamic Ensemble for Secure Visual Sensing at Mobile  Edge",
    "descriptor": "",
    "authors": [
      "Qun Song",
      "Zhenyu Yan",
      "Wenjie Luo",
      "Rui Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08189"
  },
  {
    "id": "arXiv:2204.08996",
    "title": "Time Difference on Arrival Extraction from Two-Way Ranging",
    "abstract": "Time Difference on Arrival Extraction from Two-Way Ranging",
    "descriptor": "",
    "authors": [
      "Patrick Rathje",
      "Olaf Landsiedel"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.08996"
  },
  {
    "id": "arXiv:2204.09311",
    "title": "Wireless Crowd Charging with Battery Aging Mitigation",
    "abstract": "Comments: Accepted for publication in IEEE SMARTCOMP 2022. This work was carried out during the tenure of an ERCIM 'Alain Bensoussan' Fellowship Programme of the first author. This work was partially funded by the European Union's Horizon 2020 Research and Innovation Programme under grant agreement No. 951972 (StandICT.eu 2023) through its 4th open call",
    "descriptor": "\nComments: Accepted for publication in IEEE SMARTCOMP 2022. This work was carried out during the tenure of an ERCIM 'Alain Bensoussan' Fellowship Programme of the first author. This work was partially funded by the European Union's Horizon 2020 Research and Innovation Programme under grant agreement No. 951972 (StandICT.eu 2023) through its 4th open call\n",
    "authors": [
      "Tamoghna Ojha",
      "Theofanis P. Raptis",
      "Marco Conti",
      "Andrea Passarella"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.09311"
  },
  {
    "id": "arXiv:2204.10380",
    "title": "The 6th AI City Challenge",
    "abstract": "Comments: Summary of the 6th AI City Challenge Workshop in conjunction with CVPR 2022. arXiv admin note: text overlap with arXiv:2104.12233",
    "descriptor": "\nComments: Summary of the 6th AI City Challenge Workshop in conjunction with CVPR 2022. arXiv admin note: text overlap with arXiv:2104.12233\n",
    "authors": [
      "Milind Naphade",
      "Shuo Wang",
      "David C. Anastasiu",
      "Zheng Tang",
      "Ming-Ching Chang",
      "Yue Yao",
      "Liang Zheng",
      "Mohammed Shaiqur Rahman",
      "Archana Venkatachalapathy",
      "Anuj Sharma",
      "Qi Feng",
      "Vitaly Ablavsky",
      "Stan Sclaroff",
      "Pranamesh Chakraborty",
      "Alice Li",
      "Shangru Li",
      "Rama Chellappa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.10380"
  },
  {
    "id": "arXiv:2204.10796",
    "title": "DACSR: Decoupled-Aggregated End-to-End Calibrated Sequential  Recommendation",
    "abstract": "DACSR: Decoupled-Aggregated End-to-End Calibrated Sequential  Recommendation",
    "descriptor": "",
    "authors": [
      "Jiayi Chen",
      "Wen Wu",
      "Liye Shi",
      "Wei Zheng",
      "Liang He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.10796"
  },
  {
    "id": "arXiv:2204.10920",
    "title": "Your Echos are Heard: Tracking, Profiling, and Ad Targeting in the  Amazon Smart Speaker Ecosystem",
    "abstract": "Comments: We answer frequently asked questions about the paper on this https URL",
    "descriptor": "\nComments: We answer frequently asked questions about the paper on this https URL\n",
    "authors": [
      "Umar Iqbal",
      "Pouneh Nikkhah Bahrami",
      "Rahmadi Trimananda",
      "Hao Cui",
      "Alexander Gamero-Garrido",
      "Daniel Dubois",
      "David Choffnes",
      "Athina Markopoulou",
      "Franziska Roesner",
      "Zubair Shafiq"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.10920"
  },
  {
    "id": "arXiv:2204.10989",
    "title": "Dialogue Meaning Representation for Task-Oriented Dialogue Systems",
    "abstract": "Dialogue Meaning Representation for Task-Oriented Dialogue Systems",
    "descriptor": "",
    "authors": [
      "Xiangkun Hu",
      "Junqi Dai",
      "Hang Yan",
      "Yi Zhang",
      "Qipeng Guo",
      "Xipeng Qiu",
      "Zheng Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.10989"
  },
  {
    "id": "arXiv:2204.11326",
    "title": "The Multiscale Structure of Neural Network Loss Functions: The Effect on  Optimization and Origin",
    "abstract": "The Multiscale Structure of Neural Network Loss Functions: The Effect on  Optimization and Origin",
    "descriptor": "",
    "authors": [
      "Chao Ma",
      "Daniel Kunin",
      "Lei Wu",
      "Lexing Ying"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.11326"
  },
  {
    "id": "arXiv:2204.12511",
    "title": "PolyLoss: A Polynomial Expansion Perspective of Classification Loss  Functions",
    "abstract": "Comments: Add ablation studies on COCO detection using RetinaNet (Section 8)",
    "descriptor": "\nComments: Add ablation studies on COCO detection using RetinaNet (Section 8)\n",
    "authors": [
      "Zhaoqi Leng",
      "Mingxing Tan",
      "Chenxi Liu",
      "Ekin Dogus Cubuk",
      "Xiaojie Shi",
      "Shuyang Cheng",
      "Dragomir Anguelov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.12511"
  },
  {
    "id": "arXiv:2204.12914",
    "title": "Forecasting foreign exchange rates with regression networks tuned by  Bayesian optimization",
    "abstract": "Forecasting foreign exchange rates with regression networks tuned by  Bayesian optimization",
    "descriptor": "",
    "authors": [
      "Linwei Li",
      "Paul-Amaury Matt",
      "Christian Heumann"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.12914"
  },
  {
    "id": "arXiv:2205.00918",
    "title": "Decay estimate of bivariate Chebyshev coefficients for functions with  limited smoothness",
    "abstract": "Comments: 6 pages",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Akansha"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.00918"
  },
  {
    "id": "arXiv:2205.01094",
    "title": "A Word is Worth A Thousand Dollars: Adversarial Attack on Tweets Fools  Stock Prediction",
    "abstract": "Comments: NAACL short paper, github: this https URL",
    "descriptor": "\nComments: NAACL short paper, github: this https URL\n",
    "authors": [
      "Yong Xie",
      "Dakuo Wang",
      "Pin-Yu Chen",
      "Jinjun Xiong",
      "Sijia Liu",
      "Sanmi Koyejo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Statistical Finance (q-fin.ST)"
    ],
    "url": "https://arxiv.org/abs/2205.01094"
  },
  {
    "id": "arXiv:2205.01289",
    "title": "On Ranking Consistency of Pre-ranking Stage",
    "abstract": "Comments: 9 pagees, 5 figures",
    "descriptor": "\nComments: 9 pagees, 5 figures\n",
    "authors": [
      "Siyu Gu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.01289"
  },
  {
    "id": "arXiv:2205.01478",
    "title": "Eigenvector centrality for multilayer networks with dependent node  importance",
    "abstract": "Eigenvector centrality for multilayer networks with dependent node  importance",
    "descriptor": "",
    "authors": [
      "H. Robert Frost"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.01478"
  },
  {
    "id": "arXiv:2205.01902",
    "title": "Pik-Fix: Restoring and Colorizing Old Photos",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2202.02606",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2202.02606\n",
    "authors": [
      "Runsheng Xu",
      "Zhengzhong Tu",
      "Yuanqi Du",
      "Xiaoyu Dong",
      "Jinlong Li",
      "Zibo Meng",
      "Jiaqi Ma",
      "Alan Bovik",
      "Hongkai Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01902"
  },
  {
    "id": "arXiv:2205.01929",
    "title": "Explain to Not Forget: Defending Against Catastrophic Forgetting with  XAI",
    "abstract": "Comments: 14 pages including appendix, 5 figures, 2 tables, 1 algorithm listing. v2 update increases figure readability, updates Fig 5 caption, adds our collaborators Dario and An as co-authors",
    "descriptor": "\nComments: 14 pages including appendix, 5 figures, 2 tables, 1 algorithm listing. v2 update increases figure readability, updates Fig 5 caption, adds our collaborators Dario and An as co-authors\n",
    "authors": [
      "Sami Ede",
      "Serop Baghdadlian",
      "Leander Weber",
      "An Nguyen",
      "Dario Zanca",
      "Wojciech Samek",
      "Sebastian Lapuschkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01929"
  },
  {
    "id": "arXiv:2205.02293",
    "title": "Original or Translated? A Causal Analysis of the Impact of  Translationese on Machine Translation Performance",
    "abstract": "Comments: NAACL 2022",
    "descriptor": "\nComments: NAACL 2022\n",
    "authors": [
      "Jingwei Ni",
      "Zhijing Jin",
      "Markus Freitag",
      "Mrinmaya Sachan",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02293"
  },
  {
    "id": "arXiv:2205.02302",
    "title": "Machine Learning Operations (MLOps): Overview, Definition, and  Architecture",
    "abstract": "Machine Learning Operations (MLOps): Overview, Definition, and  Architecture",
    "descriptor": "",
    "authors": [
      "Dominik Kreuzberger",
      "Niklas K\u00fchl",
      "Sebastian Hirschl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02302"
  },
  {
    "id": "arXiv:2205.02654",
    "title": "Polynomial-Time Algorithms for Counting and Sampling Markov Equivalent  DAGs with Applications",
    "abstract": "Comments: Preliminary results of this work have been presented at the AAAI Conference on Artificial Intelligence (AAAI 2021), see arXiv:2012.09679",
    "descriptor": "\nComments: Preliminary results of this work have been presented at the AAAI Conference on Artificial Intelligence (AAAI 2021), see arXiv:2012.09679\n",
    "authors": [
      "Marcel Wien\u00f6bst",
      "Max Bannach",
      "Maciej Li\u015bkiewicz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.02654"
  },
  {
    "id": "arXiv:2205.02921",
    "title": "Conversational Analysis of Daily Dialog Data using Polite Emotional  Dialogue Acts",
    "abstract": "Comments: Accepted at LREC 2022 (pre-print). arXiv admin note: substantial text overlap with arXiv:2112.13572",
    "descriptor": "\nComments: Accepted at LREC 2022 (pre-print). arXiv admin note: substantial text overlap with arXiv:2112.13572\n",
    "authors": [
      "Chandrakant Bothe",
      "Stefan Wermter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.02921"
  },
  {
    "id": "arXiv:2205.02959",
    "title": "Semi-Supervised Imitation Learning of Team Policies from Suboptimal  Demonstrations",
    "abstract": "Comments: Extended version of an identically-titled paper accepted at IJCAI 2022",
    "descriptor": "\nComments: Extended version of an identically-titled paper accepted at IJCAI 2022\n",
    "authors": [
      "Sangwon Seo",
      "Vaibhav V. Unhelkar"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2205.02959"
  },
  {
    "id": "arXiv:2205.03476",
    "title": "Hitting time for Markov decision process",
    "abstract": "Comments: The first version of this paper pointed out some issues in the old version of \"Cross-Domain Imitation Learning via Optimal Transport\". The authors have then addressed these issues according to our suggestions in a new version. We therefore updated our paper, in which we removed contents related to these issues",
    "descriptor": "\nComments: The first version of this paper pointed out some issues in the old version of \"Cross-Domain Imitation Learning via Optimal Transport\". The authors have then addressed these issues according to our suggestions in a new version. We therefore updated our paper, in which we removed contents related to these issues\n",
    "authors": [
      "Ruichao Jiang",
      "Javad Tavakoli",
      "Yiqinag Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.03476"
  },
  {
    "id": "arXiv:2205.03692",
    "title": "Towards a Progression-Aware Autonomous Dialogue Agent",
    "abstract": "Comments: Accepted at NAACL 2022",
    "descriptor": "\nComments: Accepted at NAACL 2022\n",
    "authors": [
      "Abraham Sanders",
      "Tomek Strzalkowski",
      "Mei Si",
      "Albert Chang",
      "Deepanshu Dey",
      "Jonas Braasch",
      "Dakuo Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.03692"
  },
  {
    "id": "arXiv:2205.03767",
    "title": "Context-Aware Abbreviation Expansion Using Large Language Models",
    "abstract": "Comments: 15 pages, 7 figures, 8 tables. Accepted as a long paper at NAACL 2022",
    "descriptor": "\nComments: 15 pages, 7 figures, 8 tables. Accepted as a long paper at NAACL 2022\n",
    "authors": [
      "Shanqing Cai",
      "Subhashini Venugopalan",
      "Katrin Tomanek",
      "Ajit Narayanan",
      "Meredith Ringel Morris",
      "Michael P. Brenner"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.03767"
  },
  {
    "id": "arXiv:2205.03825",
    "title": "Iterative Geometry-Aware Cross Guidance Network for Stereo Image  Inpainting",
    "abstract": "Comments: Accepted by IJCAI 2022",
    "descriptor": "\nComments: Accepted by IJCAI 2022\n",
    "authors": [
      "Ang Li",
      "Shanshan Zhao",
      "Qingjie Zhang",
      "Qiuhong Ke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.03825"
  },
  {
    "id": "arXiv:2205.04017",
    "title": "What Do You Get from Turning on Your Video? Effects of Videoconferencing  Affordances on Remote Class Experience During COVID-19",
    "abstract": "Comments: The paper has been accepted by CSCW 2022 and to be published in PACM HCI (this https URL)",
    "descriptor": "\nComments: The paper has been accepted by CSCW 2022 and to be published in PACM HCI (this https URL)\n",
    "authors": [
      "Yanting Wu",
      "Yuan Sun",
      "S. Shyam Sundar"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.04017"
  },
  {
    "id": "arXiv:2205.04179",
    "title": "High Performance Consensus without Duplication: Multi-pipeline Hotstuff",
    "abstract": "High Performance Consensus without Duplication: Multi-pipeline Hotstuff",
    "descriptor": "",
    "authors": [
      "Taining Cheng"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.04179"
  },
  {
    "id": "arXiv:2205.04255",
    "title": "Improved Evaluation and Generation of Grid Layouts using Distance  Preservation Quality and Linear Assignment Sorting",
    "abstract": "Improved Evaluation and Generation of Grid Layouts using Distance  Preservation Quality and Linear Assignment Sorting",
    "descriptor": "",
    "authors": [
      "Kai Uwe Barthel",
      "Nico Hezel",
      "Klaus Jung",
      "Konstantin Schall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.04255"
  },
  {
    "id": "arXiv:2205.04262",
    "title": "Discontinuous Galerkin approximation of the fully-coupled  thermo-poroelastic problem",
    "abstract": "Discontinuous Galerkin approximation of the fully-coupled  thermo-poroelastic problem",
    "descriptor": "",
    "authors": [
      "Stefano Bonetti",
      "Michele Botti",
      "Paola F. Antonietti"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.04262"
  },
  {
    "id": "arXiv:2205.04369",
    "title": "Data Size-Aware Downlink Massive MIMO: A Session-Based Approach",
    "abstract": "Comments: accepted to appear in IEEE Wireless Communications Letter, 2022",
    "descriptor": "\nComments: accepted to appear in IEEE Wireless Communications Letter, 2022\n",
    "authors": [
      "Tung T. Vu",
      "Hien Quoc Ngo",
      "Minh N. Dao",
      "Michail Matthaiou",
      "Erik G. Larsson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.04369"
  },
  {
    "id": "arXiv:2205.04417",
    "title": "Efficient algorithms for Bayesian Inverse Problems with  Whittle--Mat\u00e9rn Priors",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Harbir Antil",
      "Arvind K. Saibaba"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.04417"
  },
  {
    "id": "arXiv:2205.04424",
    "title": "Accelerated Reinforcement Learning for Temporal Logic Control Objectives",
    "abstract": "Accelerated Reinforcement Learning for Temporal Logic Control Objectives",
    "descriptor": "",
    "authors": [
      "Yiannis Kantaros"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.04424"
  },
  {
    "id": "arXiv:2205.04550",
    "title": "Casting the inverse problem as a database query. The case of  personalized tumor growth modeling",
    "abstract": "Casting the inverse problem as a database query. The case of  personalized tumor growth modeling",
    "descriptor": "",
    "authors": [
      "Ivan Ezhov",
      "Marcel Rosier",
      "Lucas Zimmer",
      "Florian Kofler",
      "Suprosanna Shit",
      "Johannes Paetzold",
      "Kevin Scibilia",
      "Leon Maechler",
      "Katharina Franitza",
      "Tamaz Amiranashvili",
      "Marie Metz",
      "Sailesh Conjeti",
      "Benedikt Wiestler",
      "Bjoern Menze"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2205.04550"
  },
  {
    "id": "arXiv:2205.04638",
    "title": "Using Frequency Attention to Make Adversarial Patch Powerful Against  Person Detector",
    "abstract": "Comments: 10pages, 4 figures",
    "descriptor": "\nComments: 10pages, 4 figures\n",
    "authors": [
      "Xiaochun Lei",
      "Chang Lu",
      "Zetao Jiang",
      "Zhaoting Gong",
      "Xiang Cai",
      "Linjun Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.04638"
  },
  {
    "id": "arXiv:2205.04639",
    "title": "STDC-MA Network for Semantic Segmentation",
    "abstract": "Comments: 10 pages, 5 figures",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Xiaochun Lei",
      "Linjun Lu",
      "Zetao Jiang",
      "Zhaoting Gong",
      "Chang Lu",
      "Jiaming Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.04639"
  },
  {
    "id": "arXiv:2205.04684",
    "title": "OTFPF: Optimal Transport-Based Feature Pyramid Fusion Network for Brain  Age Estimation with 3D Overlapped ConvNeXt",
    "abstract": "OTFPF: Optimal Transport-Based Feature Pyramid Fusion Network for Brain  Age Estimation with 3D Overlapped ConvNeXt",
    "descriptor": "",
    "authors": [
      "Yu Fu",
      "Yanyan Huang",
      "Yalin Wang",
      "Shunjie Dong",
      "Le Xue",
      "Xunzhao Yin",
      "Qianqian Yang",
      "Yiyu Shi",
      "Cheng Zhuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.04684"
  },
  {
    "id": "arXiv:2205.04790",
    "title": "Don't Throw it Away! The Utility of Unlabeled Data in Fair Decision  Making",
    "abstract": "Don't Throw it Away! The Utility of Unlabeled Data in Fair Decision  Making",
    "descriptor": "",
    "authors": [
      "Miriam Rateike",
      "Ayan Majumdar",
      "Olga Mineeva",
      "Krishna P. Gummadi",
      "Isabel Valera"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.04790"
  },
  {
    "id": "arXiv:2205.04797",
    "title": "State Encoders in Reinforcement Learning for Recommendation: A  Reproducibility Study",
    "abstract": "Comments: SIGIR 2022",
    "descriptor": "\nComments: SIGIR 2022\n",
    "authors": [
      "Jin Huang",
      "Harrie Oosterhuis",
      "Bunyamin Cetinkaya",
      "Thijs Rood",
      "Maarten de Rijke"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.04797"
  },
  {
    "id": "arXiv:2205.04812",
    "title": "The Impact of Partial Occlusion on Pedestrian Detectability",
    "abstract": "The Impact of Partial Occlusion on Pedestrian Detectability",
    "descriptor": "",
    "authors": [
      "Shane Gilroy",
      "Darragh Mullins",
      "Edward Jones",
      "Ashkan Parsi",
      "Martin Glavin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.04812"
  },
  {
    "id": "arXiv:2205.04827",
    "title": "Probabilistic and Non-Deterministic Event Data in Process Mining:  Embedding Uncertainty in Process Analysis Techniques",
    "abstract": "Comments: 12 pages, 4 figures, 4 tables, 16 references. arXiv admin note: text overlap with arXiv:2010.00334",
    "descriptor": "\nComments: 12 pages, 4 figures, 4 tables, 16 references. arXiv admin note: text overlap with arXiv:2010.00334\n",
    "authors": [
      "Marco Pegoraro"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.04827"
  },
  {
    "id": "arXiv:2205.04899",
    "title": "From Trade-only to Zero-Value NFTs: The Asset Proxy NFT Paradigm in Web3",
    "abstract": "Comments: 15 pages, 2 figures",
    "descriptor": "\nComments: 15 pages, 2 figures\n",
    "authors": [
      "Denis Avrilionis",
      "Thomas Hardjono"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.04899"
  },
  {
    "id": "arXiv:2205.04943",
    "title": "Fast Performance Evaluation of Linear Block Codes over Memoryless  Continuous Channels",
    "abstract": "Comments: 35 pages, 11 figures",
    "descriptor": "\nComments: 35 pages, 11 figures\n",
    "authors": [
      "Jinzhe Pan",
      "Wai Ho Mow"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.04943"
  },
  {
    "id": "arXiv:2205.04966",
    "title": "How Game Jams and Hackathons Accelerate Design Processes",
    "abstract": "Comments: PhD thesis, handed in 12th November 2020, defended 8th March 2021 at Aarhus University, Denmark. Please cite as: Falk, Jeanette (2021). How Game Jams and Hackathons Accelerate Design Processes. PhD thesis. Aarhus University. doi: this https URL",
    "descriptor": "\nComments: PhD thesis, handed in 12th November 2020, defended 8th March 2021 at Aarhus University, Denmark. Please cite as: Falk, Jeanette (2021). How Game Jams and Hackathons Accelerate Design Processes. PhD thesis. Aarhus University. doi: this https URL\n",
    "authors": [
      "Jeanette Falk"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.04966"
  },
  {
    "id": "arXiv:2205.05019",
    "title": "Learning to Answer Visual Questions from Web Videos",
    "abstract": "Comments: Accepted at the TPAMI Special Issue on the Best Papers of ICCV 2021. Journal extension of the conference paper arXiv:2012.00451. 16 pages, 13 figures",
    "descriptor": "\nComments: Accepted at the TPAMI Special Issue on the Best Papers of ICCV 2021. Journal extension of the conference paper arXiv:2012.00451. 16 pages, 13 figures\n",
    "authors": [
      "Antoine Yang",
      "Antoine Miech",
      "Josef Sivic",
      "Ivan Laptev",
      "Cordelia Schmid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05019"
  }
]
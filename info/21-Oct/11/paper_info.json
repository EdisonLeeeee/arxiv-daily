[
  {
    "id": "arXiv:2110.03685",
    "title": "Adjustment of force-gradient operator in symplectic methods",
    "abstract": "Many force-gradient explicit symplectic integration algorithms have been\ndesigned for the Hamiltonian $H=T (\\mathbf{p})+V(\\mathbf{q})$ with a kinetic\nenergy $T(\\mathbf{p})=\\mathbf{p}^2/2$ in the existing references. When the\nforce-gradient operator is appropriately adjusted as a new operator, they are\nstill suitable for a class of Hamiltonian problems\n$H=K(\\mathbf{p},\\mathbf{q})+V(\\mathbf{q})$ with \\emph{integrable} part\n$K(\\mathbf{p},\\mathbf{q}) = \\sum_{i=1}^{n}\n\\sum_{j=1}^{n}a_{ij}p_ip_j+\\sum_{i=1}^{n} b_ip_i$, where\n$a_{ij}=a_{ij}(\\textbf{q})$ and $b_i=b_i(\\textbf{q})$ are functions of\ncoordinates $\\textbf{q}$. The newly adjusted operator is not a force-gradient\noperator but is similar to the momentum-version operator associated to the\npotential $V$. The newly extended (or adjusted) algorithms are no longer\nsolvers of the original Hamiltonian, but are solvers of slightly modified\nHamiltonians. They are explicit symplectic integrators with time reversibility\nand time symmetry. Numerical tests show that the standard symplectic\nintegrators without the new operator are generally poorer than the\ncorresponding extended methods with the new operator in computational\naccuracies and efficiencies. The optimized methods have better accuracies than\nthe corresponding non-optimized methods. Among the tested symplectic methods,\nthe two extended optimized seven-stage fourth-order methods of Omelyan, Mryglod\nand Folk exhibit the best numerical performance. As a result, one of the two\noptimized algorithms is used to study the orbital dynamical features of a\nmodified H\\'{e}non-Heiles system and a spring pendulum. These extended\nintegrators allow for integrations in Hamiltonian problems, such as the spiral\nstructure in self-consistent models of rotating galaxies and the spiral arms in\ngalaxies.",
    "descriptor": "\nComments: 14 pages, 9 figures\n",
    "authors": [
      "Lina Zhang",
      "Xin Wu",
      "Enwei Liang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Astrophysics of Galaxies (astro-ph.GA)"
    ],
    "url": "https://arxiv.org/abs/2110.03685"
  },
  {
    "id": "arXiv:2110.03706",
    "title": "SVG-Net: An SVG-based Trajectory Prediction Model",
    "abstract": "Anticipating motions of vehicles in a scene is an essential problem for safe\nautonomous driving systems. To this end, the comprehension of the scene's\ninfrastructure is often the main clue for predicting future trajectories. Most\nof the proposed approaches represent the scene with a rasterized format and\nsome of the more recent approaches leverage custom vectorized formats. In\ncontrast, we propose representing the scene's information by employing Scalable\nVector Graphics (SVG). SVG is a well-established format that matches the\nproblem of trajectory prediction better than rasterized formats while being\nmore general than arbitrary vectorized formats. SVG has the potential to\nprovide the convenience and generality of raster-based solutions if coupled\nwith a powerful tool such as CNNs, for which we introduce SVG-Net. SVG-Net is a\nTransformer-based Neural Network that can effectively capture the scene's\ninformation from SVG inputs. Thanks to the self-attention mechanism in its\nTransformers, SVG-Net can also adequately apprehend relations amongst the scene\nand the agents. We demonstrate SVG-Net's effectiveness by evaluating its\nperformance on the publicly available Argoverse forecasting dataset. Finally,\nwe illustrate how, by using SVG, one can benefit from datasets and advancements\nin other research fronts that also utilize the same input format. Our code is\navailable at https://vita-epfl.github.io/SVGNet/.",
    "descriptor": "",
    "authors": [
      "Mohammadhossein Bahari",
      "Vahid Zehtab",
      "Sadegh Khorasani",
      "Sana Ayramlou",
      "Saeed Saadatnejad",
      "Alexandre Alahi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03706"
  },
  {
    "id": "arXiv:2110.03722",
    "title": "A Meta-learning Approach to Reservoir Computing: Time Series Prediction  with Limited Data",
    "abstract": "Recent research has established the effectiveness of machine learning for\ndata-driven prediction of the future evolution of unknown dynamical systems,\nincluding chaotic systems. However, these approaches require large amounts of\nmeasured time series data from the process to be predicted. When only limited\ndata is available, forecasters are forced to impose significant model structure\nthat may or may not accurately represent the process of interest. In this work,\nwe present a Meta-learning Approach to Reservoir Computing (MARC), a\ndata-driven approach to automatically extract an appropriate model structure\nfrom experimentally observed \"related\" processes that can be used to vastly\nreduce the amount of data required to successfully train a predictive model. We\ndemonstrate our approach on a simple benchmark problem, where it beats the\nstate of the art meta-learning techniques, as well as a challenging chaotic\nproblem.",
    "descriptor": "",
    "authors": [
      "Daniel Canaday",
      "Andrew Pomerance",
      "Michelle Girvan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03722"
  },
  {
    "id": "arXiv:2110.03726",
    "title": "Bisimulations for Neural Network Reduction",
    "abstract": "We present a notion of bisimulation that induces a reduced network which is\nsemantically equivalent to the given neural network. We provide a minimization\nalgorithm to construct the smallest bisimulation equivalent network. Reductions\nthat construct bisimulation equivalent neural networks are limited in the scale\nof reduction. We present an approximate notion of bisimulation that provides\nsemantic closeness, rather than, semantic equivalence, and quantify semantic\ndeviation between the neural networks that are approximately bisimilar. The\nlatter provides a trade-off between the amount of reduction and deviations in\nthe semantics.",
    "descriptor": "",
    "authors": [
      "Pavithra Prabhakar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.03726"
  },
  {
    "id": "arXiv:2110.03727",
    "title": "Contextual Sentence Classification: Detecting Sustainability Initiatives  in Company Reports",
    "abstract": "We introduce the novel task of detecting sustainability initiatives in\ncompany reports. Given a full report, the aim is to automatically identify\nmentions of practical activities that a company has performed in order to\ntackle specific societal issues. As a single initiative can often be described\nover multiples sentences, new methods for identifying continuous sentence spans\nneeds to be developed. We release a new dataset of company reports in which the\ntext has been manually annotated with sustainability initiatives. We also\nevaluate different models for initiative detection, introducing a novel\naggregation and evaluation methodology. Our proposed architecture uses\nsequences of five consecutive sentences to account for contextual information\nwhen making classification decisions at the individual sentence level.",
    "descriptor": "\nComments: 10 pages, 2 figures, 8 tables\n",
    "authors": [
      "Dan Hirlea",
      "Christopher Bryant",
      "Marek Rei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.03727"
  },
  {
    "id": "arXiv:2110.03728",
    "title": "HABCSm: A Hamming Based t-way Strategy Based on Hybrid Artificial Bee  Colony for Variable Strength Test Sets Generation",
    "abstract": "Search-based software engineering that involves the deployment of\nmeta-heuristics in applicable software processes has been gaining wide\nattention. Recently, researchers have been advocating the adoption of\nmeta-heuristic algorithms for t-way testing strategies (where t points the\ninteraction strength among parameters). Although helpful, no single\nmeta-heuristic based t-way strategy can claim dominance over its counterparts.\nFor this reason, the hybridization of meta-heuristic algorithms can help to\nascertain the search capabilities of each by compensating for the limitations\nof one algorithm with the strength of others. Consequently, a new\nmeta-heuristic based t-way strategy called Hybrid Artificial Bee Colony\n(HABCSm) strategy, based on merging the advantages of the Artificial Bee Colony\n(ABC) algorithm with the advantages of a Particle Swarm Optimization (PSO)\nalgorithm is proposed in this paper. HABCSm is the first t-way strategy to\nadopt Hybrid Artificial Bee Colony (HABC) algorithm with Hamming distance as\nits core method for generating a final test set and the first to adopt the\nHamming distance as the final selection criterion for enhancing the exploration\nof new solutions. The experimental results demonstrate that HABCSm provides\nsuperior competitive performance over its counterparts. Therefore, this finding\ncontributes to the field of software testing by minimizing the number of test\ncases required for test execution.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Ammar K Alazzawi",
      "Helmi Md Rais",
      "Shuib Basri",
      "Yazan A Alsariera",
      "Luiz Fernando Capretz",
      "Abdullateef Oluwagbemiga Balogun",
      "Abdullahi Abubakar Imam"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.03728"
  },
  {
    "id": "arXiv:2110.03730",
    "title": "UoB at SemEval-2021 Task 5: Extending Pre-Trained Language Models to  Include Task and Domain-Specific Information for Toxic Span Prediction",
    "abstract": "Toxicity is pervasive in social media and poses a major threat to the health\nof online communities. The recent introduction of pre-trained language models,\nwhich have achieved state-of-the-art results in many NLP tasks, has transformed\nthe way in which we approach natural language processing. However, the inherent\nnature of pre-training means that they are unlikely to capture task-specific\nstatistical information or learn domain-specific knowledge. Additionally, most\nimplementations of these models typically do not employ conditional random\nfields, a method for simultaneous token classification. We show that these\nmodifications can improve model performance on the Toxic Spans Detection task\nat SemEval-2021 to achieve a score within 4 percentage points of the top\nperforming team.",
    "descriptor": "\nComments: Published in Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021); Code available at: this https URL\n",
    "authors": [
      "Erik Yan",
      "Harish Tayyar Madabushi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.03730"
  },
  {
    "id": "arXiv:2110.03735",
    "title": "Adversarial Unlearning of Backdoors via Implicit Hypergradient",
    "abstract": "We propose a minimax formulation for removing backdoors from a given poisoned\nmodel based on a small set of clean data. This formulation encompasses much of\nprior work on backdoor removal. We propose the Implicit Bacdoor Adversarial\nUnlearning (I-BAU) algorithm to solve the minimax. Unlike previous work, which\nbreaks down the minimax into separate inner and outer problems, our algorithm\nutilizes the implicit hypergradient to account for the interdependence between\ninner and outer optimization. We theoretically analyze its convergence and the\ngeneralizability of the robustness gained by solving minimax on clean data to\nunseen test data. In our evaluation, we compare I-BAU with six state-of-art\nbackdoor defenses on seven backdoor attacks over two datasets and various\nattack settings, including the common setting where the attacker targets one\nclass as well as important but underexplored settings where multiple classes\nare targeted. I-BAU's performance is comparable to and most often significantly\nbetter than the best baseline. Particularly, its performance is more robust to\nthe variation on triggers, attack settings, poison ratio, and clean data size.\nMoreover, I-BAU requires less computation to take effect; particularly, it is\nmore than $13\\times$ faster than the most efficient baseline in the\nsingle-target attack setting. Furthermore, it can remain effective in the\nextreme case where the defender can only access 100 clean samples -- a setting\nwhere all the baselines fail to produce acceptable results.",
    "descriptor": "\nComments: 9 pages main text, 3 pages references, 12 pages appendix, 5 figures\n",
    "authors": [
      "Yi Zeng",
      "Si Chen",
      "Won Park",
      "Z. Morley Mao",
      "Jin Ming",
      "Ruoxi Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03735"
  },
  {
    "id": "arXiv:2110.03740",
    "title": "Adaptive Early-Learning Correction for Segmentation from Noisy  Annotations",
    "abstract": "Deep learning in the presence of noisy annotations has been studied\nextensively in classification, but much less in segmentation tasks. In this\nwork, we study the learning dynamics of deep segmentation networks trained on\ninaccurately-annotated data. We discover a phenomenon that has been previously\nreported in the context of classification: the networks tend to first fit the\nclean pixel-level labels during an \"early-learning\" phase, before eventually\nmemorizing the false annotations. However, in contrast to classification,\nmemorization in segmentation does not arise simultaneously for all semantic\ncategories. Inspired by these findings, we propose a new method for\nsegmentation from noisy annotations with two key elements. First, we detect the\nbeginning of the memorization phase separately for each category during\ntraining. This allows us to adaptively correct the noisy annotations in order\nto exploit early learning. Second, we incorporate a regularization term that\nenforces consistency across scales to boost robustness against annotation\nnoise. Our method outperforms standard approaches on a medical-imaging\nsegmentation task where noises are synthesized to mimic human annotation\nerrors. It also provides robustness to realistic noisy annotations present in\nweakly-supervised semantic segmentation, achieving state-of-the-art results on\nPASCAL VOC 2012.",
    "descriptor": "\nComments: The first two authors contribute equally, order decided by coin flipping\n",
    "authors": [
      "Sheng Liu",
      "Kangning Liu",
      "Weicheng Zhu",
      "Yiqiu Shen",
      "Carlos Fernandez-Granda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03740"
  },
  {
    "id": "arXiv:2110.03742",
    "title": "Beyond Distillation: Task-level Mixture-of-Experts for Efficient  Inference",
    "abstract": "Sparse Mixture-of-Experts (MoE) has been a successful approach for scaling\nmultilingual translation models to billions of parameters without a\nproportional increase in training computation. However, MoE models are\nprohibitively large and practitioners often resort to methods such as\ndistillation for serving. In this work, we investigate routing strategies at\ndifferent granularity (token, sentence, task) in MoE models to bypass\ndistillation. Experiments on WMT and a web-scale dataset suggest that\ntask-level routing (task-MoE) enables us to extract smaller, ready-to-deploy\nsub-networks from large sparse models. On WMT, our task-MoE with 32 experts\n(533M parameters) outperforms the best performing token-level MoE model\n(token-MoE) by +1.0 BLEU on average across 30 language pairs. The peak\ninference throughput is also improved by a factor of 1.9x when we route by\ntasks instead of tokens. While distilling a token-MoE to a smaller dense model\npreserves only 32% of the BLEU gains, our sub-network task-MoE, by design,\npreserves all the gains with the same inference cost as the distilled student\nmodel. Finally, when scaling up to 200 language pairs, our 128-expert task-MoE\n(13B parameters) performs competitively with a token-level counterpart, while\nimproving the peak inference throughput by a factor of 2.6x.",
    "descriptor": "\nComments: EMNLP Findings 2021\n",
    "authors": [
      "Sneha Kudugunta",
      "Yanping Huang",
      "Ankur Bapna",
      "Maxim Krikun",
      "Dmitry Lepikhin",
      "Minh-Thang Luong",
      "Orhan Firat"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03742"
  },
  {
    "id": "arXiv:2110.03743",
    "title": "Reinforcement Learning in Reward-Mixing MDPs",
    "abstract": "Learning a near optimal policy in a partially observable system remains an\nelusive challenge in contemporary reinforcement learning. In this work, we\nconsider episodic reinforcement learning in a reward-mixing Markov decision\nprocess (MDP). There, a reward function is drawn from one of multiple possible\nreward models at the beginning of every episode, but the identity of the chosen\nreward model is not revealed to the agent. Hence, the latent state space, for\nwhich the dynamics are Markovian, is not given to the agent. We study the\nproblem of learning a near optimal policy for two reward-mixing MDPs. Unlike\nexisting approaches that rely on strong assumptions on the dynamics, we make no\nassumptions and study the problem in full generality. Indeed, with no further\nassumptions, even for two switching reward-models, the problem requires several\nnew ideas beyond existing algorithmic and analysis techniques for efficient\nexploration. We provide the first polynomial-time algorithm that finds an\n$\\epsilon$-optimal policy after exploring $\\tilde{O}(poly(H,\\epsilon^{-1})\n\\cdot S^2 A^2)$ episodes, where $H$ is time-horizon and $S, A$ are the number\nof states and actions respectively. This is the first efficient algorithm that\ndoes not require any assumptions in partially observed environments where the\nobservation space is smaller than the latent state space.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Jeongyeol Kwon",
      "Yonathan Efroni",
      "Constantine Caramanis",
      "Shie Mannor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.03743"
  },
  {
    "id": "arXiv:2110.03744",
    "title": "Sequence-To-Sequence Voice Conversion using F0 and Time Conditioning and  Adversarial Learning",
    "abstract": "This paper presents a sequence-to-sequence voice conversion (S2S-VC)\nalgorithm which allows to preserve some aspects of the source speaker during\nconversion, typically its prosody, which is useful in many real-life\napplication of voice conversion. In S2S-VC, the decoder is usually conditioned\non linguistic and speaker embeddings only, with the consequence that only the\nlinguistic content is actually preserved during conversion. In the proposed\nS2S-VC architecture, the decoder is conditioned explicitly on the desired F0\nsequence so that the converted speech has the same F0 as the one of the source\nspeaker, or any F0 defined arbitrarily. Moreover, an adversarial module is\nfurther employed so that the S2S-VC is not only optimized on the available true\nspeech samples, but can also take efficiently advantage of the converted speech\nsamples that can be produced by using various conditioning such as speaker\nidentity, F0, or timing.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2107.12346\n",
    "authors": [
      "Frederik Bous",
      "Laurent Benaroya",
      "Nicolas Obin",
      "Axel Roebel"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.03744"
  },
  {
    "id": "arXiv:2110.03745",
    "title": "Adversarial Attack by Limited Point Cloud Surface Modifications",
    "abstract": "Recent research has revealed that the security of deep neural networks that\ndirectly process 3D point clouds to classify objects can be threatened by\nadversarial samples. Although existing adversarial attack methods achieve high\nsuccess rates, they do not restrict the point modifications enough to preserve\nthe point cloud appearance. To overcome this shortcoming, two constraints are\nproposed. These include applying hard boundary constraints on the number of\nmodified points and on the point perturbation norms. Due to the restrictive\nnature of the problem, the search space contains many local maxima. The\nproposed method addresses this issue by using a high step-size at the beginning\nof the algorithm to search the main surface of the point cloud fast and\neffectively. Then, in order to converge to the desired output, the step-size is\ngradually decreased. To evaluate the performance of the proposed method, it is\nrun on the ModelNet40 and ScanObjectNN datasets by employing the\nstate-of-the-art point cloud classification models; including PointNet,\nPointNet++, and DGCNN. The obtained results show that it can perform successful\nattacks and achieve state-of-the-art results by only a limited number of point\nmodifications while preserving the appearance of the point cloud. Moreover, due\nto the effective search algorithm, it can perform successful attacks in just a\nfew steps. Additionally, the proposed step-size scheduling algorithm shows an\nimprovement of up to $14.5\\%$ when adopted by other methods as well. The\nproposed method also performs effectively against popular defense methods.",
    "descriptor": "",
    "authors": [
      "Atrin Arya",
      "Hanieh Naderi",
      "Shohreh Kasaei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03745"
  },
  {
    "id": "arXiv:2110.03748",
    "title": "Optimizing Oil and Gas Acquisitions Using Recommender Systems",
    "abstract": "Well acquisition in the oil and gas industry can often be a hit or miss\nprocess, with a poor purchase resulting in substantial loss. Recommender\nsystems suggest items (wells) that users (companies) are likely to buy based on\npast activity, and applying this system to well acquisition can increase\ncompany profits. While traditional recommender systems are impactful enough on\ntheir own, they are not optimized. This is because they ignore many of the\ncomplexities involved in human decision-making, and frequently make subpar\nrecommendations. Using a preexisting Python implementation of a Factorization\nMachine results in more accurate recommendations based on a user-level ranking\nsystem. We train a Factorization Machine model on oil and gas well data that\nincludes features such as elevation, total depth, and location. The model\nproduces recommendations by using similarities between companies and wells, as\nwell as their interactions. Our model has a hit rate of 0.680, reciprocal rank\nof 0.469, precision of 0.229, and recall of 0.463. These metrics imply that\nwhile our model is able to recommend the correct wells in a general sense, it\ndoes not match exact wells to companies via relevance. To improve the model's\naccuracy, future models should incorporate additional features such as the\nwell's production data and ownership duration as these features will produce\nmore accurate recommendations.",
    "descriptor": "\nComments: 10 pages, 3 figures\n",
    "authors": [
      "Harsh Kumar",
      "Geneva Allison",
      "Jehil Mehta",
      "Jesse Pisel",
      "Michael Pyrcz"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.03748"
  },
  {
    "id": "arXiv:2110.03751",
    "title": "Discomfort Monitoring System for Residential Electrical Water Heater",
    "abstract": "An approach is described in this work for detecting discomfort moments during\nelectrical water heater daily usage. The approach employs chromatic analyzing\nsensors signals of electrical water heater systems for producing\ndistinguishable mapping to characterize and identify selected discomfort\nmoments. The preliminary results obtained indicate that it is possible to\ndistinguish such events in a non-intrusive approach. Hot water comfort\ndetection and classification intelligently through human behavior monitoring\nand analyses plays an important role in both, energy saving and energy\nmanagement. The focus is on recording the discomfort situations followed by\nmerging system outcomes with efficiency evaluation will be used to provide\nhelpful recommendations for selecting appropriate operating strategy.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Ziyad Almajali"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.03751"
  },
  {
    "id": "arXiv:2110.03753",
    "title": "From Stars to Subgraphs: Uplifting Any GNN with Local Structure  Awareness",
    "abstract": "Message Passing Neural Networks (MPNNs) are a common type of Graph Neural\nNetwork (GNN), in which each node's representation is computed recursively by\naggregating representations (messages) from its immediate neighbors akin to a\nstar-shaped pattern. MPNNs are appealing for being efficient and scalable,\nhow-ever their expressiveness is upper-bounded by the 1st-order\nWeisfeiler-Lehman isomorphism test (1-WL). In response, prior works propose\nhighly expressive models at the cost of scalability and sometimes\ngeneralization performance. Our work stands between these two regimes: we\nintroduce a general framework to uplift any MPNN to be more expressive, with\nlimited scalability overhead and greatly improved practical performance. We\nachieve this by extending local aggregation in MPNNs from star patterns to\ngeneral subgraph patterns (e.g.,k-egonets):in our framework, each node\nrepresentation is computed as the encoding of a surrounding induced subgraph\nrather than encoding of immediate neighbors only (i.e. a star). We choose the\nsubgraph encoder to be a GNN (mainly MPNNs, considering scalability) to design\na general framework that serves as a wrapper to up-lift any GNN. We call our\nproposed method GNN-AK(GNN As Kernel), as the framework resembles a\nconvolutional neural network by replacing the kernel with GNNs. Theoretically,\nwe show that our framework is strictly more powerful than 1&2-WL, and is not\nless powerful than 3-WL. We also design subgraph sampling strategies which\ngreatly reduce memory footprint and improve speed while maintaining\nperformance. Our method sets new state-of-the-art performance by large margins\nfor several well-known graph ML tasks; specifically, 0.08 MAE on ZINC,74.79%\nand 86.887% accuracy on CIFAR10 and PATTERN respectively.",
    "descriptor": "\nComments: Expressive GNN framework\n",
    "authors": [
      "Lingxiao Zhao",
      "Wei Jin",
      "Leman Akoglu",
      "Neil Shah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.03753"
  },
  {
    "id": "arXiv:2110.03754",
    "title": "Process Extraction from Text: state of the art and challenges for the  future",
    "abstract": "Automatic Process Discovery aims at developing algorithmic methodologies for\nthe extraction and elicitation of process models as described in data. While\nProcess Discovery from event-log data is a well established area, that has\nalready moved from research to concrete adoption in a mature manner, Process\nDiscovery from text is still a research area at an early stage of development,\nwhich rarely scales to real world documents. In this paper we analyze, in a\ncomparative manner, reference state-of-the-art literature, especially for what\nconcerns the techniques used, the process elements extracted and the\nevaluations performed. As a result of the analysis we discuss important\nlimitations that hamper the exploitation of recent Natural Language Processing\ntechniques in this field and we discuss fundamental limitations and challenges\nfor the future concerning the datasets, the techniques, the experimental\nevaluations, and the pipelines currently adopted and to be developed in the\nfuture.",
    "descriptor": "",
    "authors": [
      "Patrizio Bellan",
      "Mauro Dragoni",
      "Chiara Ghidini"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.03754"
  },
  {
    "id": "arXiv:2110.03755",
    "title": "On the possibility of fast stable approximation of analytic functions  from equispaced samples via polynomial frames",
    "abstract": "We consider approximating analytic functions on the interval $[-1,1]$ from\ntheir values at a set of $m+1$ equispaced nodes. A result of Platte, Trefethen\n& Kuijlaars states that fast and stable approximation from equispaced samples\nis generally impossible. In particular, any method that converges exponentially\nfast must also be exponentially ill-conditioned. We prove a positive\ncounterpart to this `impossibility' theorem. Our `possibility' theorem shows\nthat there is a well-conditioned method that provides exponential decay of the\nerror down to a finite, but user-controlled tolerance $\\epsilon > 0$, which in\npractice can be chosen close to machine epsilon. The method is known as\n\\textit{polynomial frame} approximation or \\textit{polynomial extensions}. It\nuses algebraic polynomials of degree $n$ on an extended interval\n$[-\\gamma,\\gamma]$, $\\gamma > 1$, to construct an approximation on $[-1,1]$ via\na SVD-regularized least-squares fit. A key step in the proof of our possibility\ntheorem is a new result on the maximal behaviour of a polynomial of degree $n$\non $[-1,1]$ that is simultaneously bounded by one at a set of $m+1$ equispaced\nnodes in $[-1,1]$ and $1/\\epsilon$ on the extended interval $[-\\gamma,\\gamma]$.\nWe show that linear oversampling, i.e., $m = c n \\log(1/\\epsilon) /\n\\sqrt{\\gamma^2-1}$, is sufficient for uniform boundedness of any such\npolynomial on $[-1,1]$. This result aside, we also prove an extended\nimpossibility theorem, which shows that the possibility theorem (and\nconsequently the method of polynomial frame approximation) is essentially\noptimal.",
    "descriptor": "",
    "authors": [
      "Ben Adcock",
      "Alexei Shadrin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.03755"
  },
  {
    "id": "arXiv:2110.03756",
    "title": "Sonorant spectra and coarticulation distinguish speakers with different  dialects",
    "abstract": "The aim of this study is to determine the effect of language varieties on the\nspectral distribution of stressed and unstressed sonorants (nasals /m, n/,\nlateral approximants /l/, and rhotics /r/) and on their coarticulatory effects\non adjacent sounds. To quantify the shape of the spectral distribution, we\ncalculated the spectral moments from the sonorant spectra of nasals /m, n/,\nlateral approximants /l/, and rhotics /r/ produced by Athenian Greek and\nCypriot Greek speakers. To estimate the co-articulatory effects of sonorants on\nthe adjacent vowels' F1 - F4 formant frequencies, we developed polynomial\nmodels of the adjacent vowel's formant contours. We found significant effects\nof language variety (sociolinguistic information) on the spectral moments of\neach sonorant /m/, /n/, /l/, /r/ (except between /m/ and /n/) and on the\nformant contours of the adjacent vowel. All sonorants (including /m/ and /n/)\nhad distinct effects on adjacent vowel's formant contours, especially for F3\nand F4. The study highlights that the combination of spectral moments and\ncoarticulatory effects of sonorants determines linguistic (stress and phonemic\ncategory) and sociolinguistic (language variety) characteristics of sonorants.\nIt also provides the first comparative acoustic analysis of Athenian Greek and\nCypriot Greek sonorants.",
    "descriptor": "",
    "authors": [
      "Charalambos Themistocleous",
      "Valantis Fyndanis",
      "Kyrana Tsapkini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.03756"
  },
  {
    "id": "arXiv:2110.03757",
    "title": "Predictive Maintenance for General Aviation Using Convolutional  Transformers",
    "abstract": "Predictive maintenance systems have the potential to significantly reduce\ncosts for maintaining aircraft fleets as well as provide improved safety by\ndetecting maintenance issues before they come severe. However, the development\nof such systems has been limited due to a lack of publicly labeled multivariate\ntime series (MTS) sensor data. MTS classification has advanced greatly over the\npast decade, but there is a lack of sufficiently challenging benchmarks for new\nmethods. This work introduces the NGAFID Maintenance Classification (NGAFID-MC)\ndataset as a novel benchmark in terms of difficulty, number of samples, and\nsequence length. NGAFID-MC consists of over 7,500 labeled flights, representing\nover 11,500 hours of per second flight data recorder readings of 23 sensor\nparameters. Using this benchmark, we demonstrate that Recurrent Neural Network\n(RNN) methods are not well suited for capturing temporally distant\nrelationships and propose a new architecture called Convolutional Multiheaded\nSelf Attention (Conv-MHSA) that achieves greater classification performance at\ngreater computational efficiency. We also demonstrate that image inspired\naugmentations of cutout, mixup, and cutmix, can be used to reduce overfitting\nand improve generalization in MTS classification. Our best trained models have\nbeen incorporated back into the NGAFID to allow users to potentially detect\nflights that require maintenance as well as provide feedback to further expand\nand refine the NGAFID-MC dataset.",
    "descriptor": "",
    "authors": [
      "Hong Yang",
      "Aidan LaBella",
      "Travis Desell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03757"
  },
  {
    "id": "arXiv:2110.03759",
    "title": "Explanation as a process: user-centric construction of multi-level and  multi-modal explanations",
    "abstract": "In the last years, XAI research has mainly been concerned with developing new\ntechnical approaches to explain deep learning models. Just recent research has\nstarted to acknowledge the need to tailor explanations to different contexts\nand requirements of stakeholders. Explanations must not only suit developers of\nmodels, but also domain experts as well as end users. Thus, in order to satisfy\ndifferent stakeholders, explanation methods need to be combined. While\nmulti-modal explanations have been used to make model predictions more\ntransparent, less research has focused on treating explanation as a process,\nwhere users can ask for information according to the level of understanding\ngained at a certain point in time. Consequently, an opportunity to explore\nexplanations on different levels of abstraction should be provided besides\nmulti-modal explanations. We present a process-based approach that combines\nmulti-level and multi-modal explanations. The user can ask for textual\nexplanations or visualizations through conversational interaction in a\ndrill-down manner. We use Inductive Logic Programming, an interpretable machine\nlearning approach, to learn a comprehensible model. Further, we present an\nalgorithm that creates an explanatory tree for each example for which a\nclassifier decision is to be explained. The explanatory tree can be navigated\nby the user to get answers of different levels of detail. We provide a\nproof-of-concept implementation for concepts induced from a semantic net about\nliving beings.",
    "descriptor": "\nComments: 14 pages, 5 figures; Camera-ready submission to KI2021; The final authenticated publication is available online at this https URL ; code is available at this https URL\n",
    "authors": [
      "Bettina Finzel",
      "David E. Tafler",
      "Stephan Scheele",
      "Ute Schmid"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03759"
  },
  {
    "id": "arXiv:2110.03760",
    "title": "Design Strategy Network: A deep hierarchical framework to represent  generative design strategies in complex action spaces",
    "abstract": "Generative design problems often encompass complex action spaces that may be\ndivergent over time, contain state-dependent constraints, or involve hybrid\n(discrete and continuous) domains. To address those challenges, this work\nintroduces Design Strategy Network (DSN), a data-driven deep hierarchical\nframework that can learn strategies over these arbitrary complex action spaces.\nThe hierarchical architecture decomposes every action decision into first\npredicting a preferred spatial region in the design space and then outputting a\nprobability distribution over a set of possible actions from that region. This\nframework comprises a convolutional encoder to work with image-based design\nstate representations, a multi-layer perceptron to predict a spatial region,\nand a weight-sharing network to generate a probability distribution over\nunordered set-based inputs of feasible actions. Applied to a truss design\nstudy, the framework learns to predict the actions of human designers in the\nstudy, capturing their truss generation strategies in the process. Results show\nthat DSNs significantly outperform non-hierarchical methods of policy\nrepresentation, demonstrating their superiority in complex action space\nproblems.",
    "descriptor": "\nComments: Published in Journal of Mechanical Design\n",
    "authors": [
      "Ayush Raina",
      "Jonathan Cagan",
      "Christopher McComb"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.03760"
  },
  {
    "id": "arXiv:2110.03761",
    "title": "A simple equivariant machine learning method for dynamics based on  scalars",
    "abstract": "Physical systems obey strict symmetry principles. We expect that machine\nlearning methods that intrinsically respect these symmetries should perform\nbetter than those that do not. In this work we implement a principled model\nbased on invariant scalars, and release open-source code. We apply this\n\\textsl{Scalars} method to a simple chaotic dynamical system, the springy\ndouble pendulum. We show that the Scalars method outperforms state-of-the-art\napproaches for learning the properties of physical systems with symmetries,\nboth in terms of accuracy and speed. Because the method incorporates the\nfundamental symmetries, we expect it to generalize to different settings, such\nas changes in the force laws in the system.",
    "descriptor": "",
    "authors": [
      "Weichi Yao",
      "Kate Storey-Fisher",
      "David W. Hogg",
      "Soledad Villar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03761"
  },
  {
    "id": "arXiv:2110.03762",
    "title": "Group-based Delivery of Critical Traffic in Cellular IoT Networks",
    "abstract": "Fifth generation (5G) networks are expected to connect a huge number of\nInternet of Things (IoT) devices in many usage scenarios. The challenges of\ntypical massive IoT applications with sporadic and short packet uplink\ntransmissions are well studied, while not enough attention is given to the\ndelivery of content of common interest, such as software/firmware updates and\nremote control, towards IoT devices in emerging point-to-multipoint scenarios.\nMoreover, the delivery of delay-sensitive IoT traffic is not sufficiently\naddressed in the literature. In this work we (i) identify the drawbacks of the\ncurrent Single-Cell Point-to-Multipoint (SC-PTM) solution for unplanned\ncritical traffic delivery in cellular IoT (cIoT) networks, and (ii) propose\npaging and multicast schemes for a fast distribution of critical updates after,\ne.g., bug fixes or system failures. We benchmark the performance of the\nproposed paging scheme against similar solutions available in the literature.\nOur extended SC-PTM framework is energy efficient and guarantees low service\nlatency, as demonstrated both analytically and by simulations.",
    "descriptor": "",
    "authors": [
      "F. Rinaldi",
      "S. Pizzi",
      "A. Orsino",
      "A. Iera",
      "A. Molinaro",
      "G. Araniti"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.03762"
  },
  {
    "id": "arXiv:2110.03763",
    "title": "Label Propagation across Graphs: Node Classification using Graph Neural  Tangent Kernels",
    "abstract": "Graph neural networks (GNNs) have achieved superior performance on node\nclassification tasks in the last few years. Commonly, this is framed in a\ntransductive semi-supervised learning setup wherein the entire graph, including\nthe target nodes to be labeled, is available for training. Driven in part by\nscalability, recent works have focused on the inductive case where only the\nlabeled portion of a graph is available for training. In this context, our\ncurrent work considers a challenging inductive setting where a set of labeled\ngraphs are available for training while the unlabeled target graph is\ncompletely separate, i.e., there are no connections between labeled and\nunlabeled nodes. Under the implicit assumption that the testing and training\ngraphs come from similar distributions, our goal is to develop a labeling\nfunction that generalizes to unobserved connectivity structures. To that end,\nwe employ a graph neural tangent kernel (GNTK) that corresponds to infinitely\nwide GNNs to find correspondences between nodes in different graphs based on\nboth the topology and the node features. We augment the capabilities of the\nGNTK with residual connections and empirically illustrate its performance gains\non standard benchmarks.",
    "descriptor": "\nComments: Under review at IEEE ICASSP 2022\n",
    "authors": [
      "Artun Bayer",
      "Arindam Chowdhury",
      "Santiago Segarra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.03763"
  },
  {
    "id": "arXiv:2110.03764",
    "title": "User Requirements for Software Game Process; An Empirical Investigation",
    "abstract": "This study attempts to provide a better understanding of the user dimension\nas a factor in software game success. It focuses mainly on an empirical\ninvestigation of the effect of user factors on the software game development\nprocess and finally on the quality of the resulting game. A quantitative survey\nwas developed and conducted to identify key user dimensions. For this study, a\nsurvey was used to test the research model and hypotheses. The main\ncontribution of this paper is to investigate empirically the influence of user\nkey factors on software game development process that ultimately results in a\nhigher quality final product. The results provide evidence that game\ndevelopment organizations must deal with multiple user key factors to remain\ncompetitive and handle high pressure in the soft-ware game industry.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1801.04293\n",
    "authors": [
      "Saiqa Aleem",
      "Luiz Fernando Capretz",
      "Faheem Ahmed",
      "Shuib Basri"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.03764"
  },
  {
    "id": "arXiv:2110.03765",
    "title": "Food Science Spectroscopy Model Training: Improving Data Efficiency  Using Active Learning and Semi-Supervised Learning",
    "abstract": "The past decade witnesses a rapid development in the measurement and\nmonitoring technologies for food science. Among these technologies,\nspectroscopy has been widely used for the analysis of food quality, safety, and\nnutritional properties. Due to the complexity of food systems and the lack of\ncomprehensive predictive models, rapid and simple measurements to predict\ncomplex properties in food systems are largely missing. Machine Learning (ML)\nhas shown great potential to improve classification and prediction of these\nproperties. However, the barriers to collect large datasets for ML applications\nstill persists. In this paper, we explore different approaches of data\nannotation and model training to improve data efficiency for ML applications.\nSpecifically, we leverage Active Learning (AL) and Semi-Supervised Learning\n(SSL) and investigate four approaches: baseline passive learning, AL, SSL, and\na hybrid of AL and SSL. To evaluate these approaches, we collect two\nspectroscopy datasets: predicting plasma dosage and detecting foodborne\npathogen. Our experimental results show that, compared to the de facto passive\nlearning approach, AL and SSL methods reduce the number of labeled samples by\n50% and 25% for each ML application, respectively.",
    "descriptor": "",
    "authors": [
      "Huanle Zhang",
      "Nicharee Wisuthiphaet",
      "Hemiao Cui",
      "Nitin Nitin",
      "Xin Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03765"
  },
  {
    "id": "arXiv:2110.03766",
    "title": "Trusted and Secured D2D-Aided Communications in 5G Networks",
    "abstract": "The design of the forthcoming fifth generation (5G) system shall meet the\nsevere requirement of managing an always increasing amount of traffic generated\nby both humans and machines, while guaranteeing data security. Among the\nenabling technologies that will turn 5G into a reality, Device-to-Device (D2D)\nand Multicasting will certainly play a key role because of their capability to\nlargely improve network resources utilization and to address emerging use cases\nrequiring the delivery of the same content to a large number of devices. D2D\ncommunications can help to improve traditional point-to-multipoint\ntransmissions by reducing the multicast coverage area and exploiting properly\nselected relay nodes as data forwarders towards users with worse channel\nconditions. However, security issues are even more challenging for D2D\nconnections, as data exchange happens directly between nodes in proximity. To\nenhance performance and security of delivered traffic in 5G-oriented networks,\nin this paper we design SeT-D2D (Secure and Trust D2D), according to which\ntrustworthiness inferred from both direct interactions and social-awareness\nparameters is exploited to properly select relay nodes. Main contributions of\nour research consist in the introduction of a model for the assessment of\nnetwork nodes' trustworthiness and the implementation of security mechanisms to\nprotect the data transmitted in D2D communications and the privacy of the\ninvolved users. The conducted simulation campaign testifies to the ability of\nthe proposed solution to effectively select relay nodes, which leads to an\nimproved network performance.",
    "descriptor": "",
    "authors": [
      "C. Suraci",
      "S. Pizzi",
      "D. Garompolo",
      "G. Araniti",
      "A. Molinaro",
      "A. Iera"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.03766"
  },
  {
    "id": "arXiv:2110.03771",
    "title": "Wake-Cough: cough spotting and cougher identification for personalised  long-term cough monitoring",
    "abstract": "We present 'wake-cough', an application of wake-word spotting to coughs using\nResnet50 and identifying coughers using i-vectors, for the purpose of a\nlong-term, personalised cough monitoring system. Coughs, recorded in a quiet\n(73$\\pm$5 dB) and noisy (34$\\pm$17 dB) environment, were used to extract\ni-vectors, x-vectors and d-vectors, used as features to the classifiers. The\nsystem achieves 90.02\\% accuracy from an MLP to discriminate 51 coughers using\n2-sec long cough segments in the noisy environment. When discriminating between\n5 and 14 coughers using longer (100 sec) segments in the quiet environment,\nthis accuracy rises to 99.78\\% and 98.39\\% respectively. Unlike speech,\ni-vectors outperform x-vectors and d-vectors in identifying coughers. These\ncoughs were added as an extra class in the Google Speech Commands dataset and\nfeatures were extracted by preserving the end-to-end time-domain information in\nan event. The highest accuracy of 88.58\\% is achieved in spotting coughs among\n35 other trigger phrases using a Resnet50. Wake-cough represents a\npersonalised, non-intrusive, cough monitoring system, which is power efficient\nas using wake-word detection method can keep a smartphone-based monitoring\ndevice mostly dormant. This makes wake-cough extremely attractive in multi-bed\nward environments to monitor patient's long-term recovery from lung ailments\nsuch as tuberculosis and COVID-19.",
    "descriptor": "",
    "authors": [
      "Madhurananda Pahar",
      "Marisa Klopper",
      "Byron Reeve",
      "Rob Warren",
      "Grant Theron",
      "Andreas Diacon",
      "Thomas Niesler"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.03771"
  },
  {
    "id": "arXiv:2110.03774",
    "title": "Automatically Polyconvex Strain Energy Functions using Neural Ordinary  Differential Equations",
    "abstract": "Data-driven methods are becoming an essential part of computational mechanics\ndue to their unique advantages over traditional material modeling. Deep neural\nnetworks are able to learn complex material response without the constraints of\nclosed-form approximations. However, imposing the physics-based mathematical\nrequirements that any material model must comply with is not straightforward\nfor data-driven approaches. In this study, we use a novel class of neural\nnetworks, known as neural ordinary differential equations (N-ODEs), to develop\ndata-driven material models that automatically satisfy polyconvexity of the\nstrain energy function with respect to the deformation gradient, a condition\nneeded for the existence of minimizers for boundary value problems in\nelasticity. We take advantage of the properties of ordinary differential\nequations to create monotonic functions that approximate the derivatives of the\nstrain energy function with respect to the invariants of the right Cauchy-Green\ndeformation tensor. The monotonicity of the derivatives guarantees the\nconvexity of the energy. The N-ODE material model is able to capture synthetic\ndata generated from closed-form material models, and it outperforms\nconventional models when tested against experimental data on skin, a highly\nnonlinear and anisotropic material. We also showcase the use of the N-ODE\nmaterial model in finite element simulations. The framework is general and can\nbe used to model a large class of materials. Here we focus on hyperelasticity,\nbut polyconvex strain energies are a core building block for other problems in\nelasticity such as viscous and plastic deformations. We therefore expect our\nmethodology to further enable data-driven methods in computational mechanics",
    "descriptor": "\nComments: 17 pages (including references and appendix), 8 figures. Code available at this https URL\n",
    "authors": [
      "Vahidullah Tac",
      "Francisco S. Costabal",
      "Adrian Buganza Tepole"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03774"
  },
  {
    "id": "arXiv:2110.03780",
    "title": "A composable autoencoder-based iterative algorithm for accelerating  numerical simulations",
    "abstract": "Numerical simulations for engineering applications solve partial differential\nequations (PDE) to model various physical processes. Traditional PDE solvers\nare very accurate but computationally costly. On the other hand, Machine\nLearning (ML) methods offer a significant computational speedup but face\nchallenges with accuracy and generalization to different PDE conditions, such\nas geometry, boundary conditions, initial conditions and PDE source terms. In\nthis work, we propose a novel ML-based approach, CoAE-MLSim (Composable\nAutoEncoder Machine Learning Simulation), which is an unsupervised,\nlower-dimensional, local method, that is motivated from key ideas used in\ncommercial PDE solvers. This allows our approach to learn better with\nrelatively fewer samples of PDE solutions. The proposed ML-approach is compared\nagainst commercial solvers for better benchmarks as well as latest\nML-approaches for solving PDEs. It is tested for a variety of complex\nengineering cases to demonstrate its computational speed, accuracy,\nscalability, and generalization across different PDE conditions. The results\nshow that our approach captures physics accurately across all metrics of\ncomparison (including measures such as results on section cuts and lines).",
    "descriptor": "",
    "authors": [
      "Rishikesh Ranade",
      "Chris Hill",
      "Haiyang He",
      "Amir Maleki",
      "Norman Chang",
      "Jay Pathak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2110.03780"
  },
  {
    "id": "arXiv:2110.03781",
    "title": "5G Traffic Prediction with Time Series Analysis",
    "abstract": "In todays day and age, a mobile phone has become a basic requirement needed\nfor anyone to thrive. With the cellular traffic demand increasing so\ndramatically, it is now necessary to accurately predict the user traffic in\ncellular networks, so as to improve the performance in terms of resource\nallocation and utilisation. By leveraging the power of machine learning and\nidentifying its usefulness in the field of cellular networks we try to achieve\nthree main objectives classification of the application generating the traffic,\nprediction of packet arrival intensity and burst occurrence. The design of the\nprediction and classification system is done using Long Short Term Memory\nmodel. The LSTM predictor developed in this experiment would return the number\nof uplink packets and also estimate the probability of burst occurrence in the\nspecified future time interval. For the purpose of classification, the\nregression layer in our LSTM prediction model is replaced by a softmax\nclassifier which is used to classify the application generating the cellular\ntraffic into one of the four applications including surfing, video calling,\nvoice calling, and video streaming.",
    "descriptor": "",
    "authors": [
      "Nikhil Nayak",
      "Rujula Singh R"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.03781"
  },
  {
    "id": "arXiv:2110.03783",
    "title": "Machine Learning approaches to do size based reasoning on Retail Shelf  objects to classify product variants",
    "abstract": "There has been a surge in the number of Machine Learning methods to analyze\nproducts kept on retail shelves images. Deep learning based computer vision\nmethods can be used to detect products on retail shelves and then classify\nthem. However, there are different sized variants of products which look\nexactly the same visually and the method to differentiate them is to look at\ntheir relative sizes with other products on shelves. This makes the process of\ndeciphering the sized based variants from each other using computer vision\nalgorithms alone impractical. In this work, we propose methods to ascertain the\nsize variant of the product as a downstream task to an object detector which\nextracts products from shelf and a classifier which determines product brand.\nProduct variant determination is the task which assigns a product variant to\nproducts of a brand based on the size of bounding boxes and brands predicted by\nclassifier. While gradient boosting based methods work well for products whose\nfacings are clear and distinct, a noise accommodating Neural Network method is\nproposed for cases where the products are stacked irregularly.",
    "descriptor": "",
    "authors": [
      "Muktabh Mayank Srivastava",
      "Pratyush Kumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03783"
  },
  {
    "id": "arXiv:2110.03785",
    "title": "Addressing practical challenges in Active Learning via a hybrid query  strategy",
    "abstract": "Active Learning (AL) is a powerful tool to address modern machine learning\nproblems with significantly fewer labeled training instances. However,\nimplementation of traditional AL methodologies in practical scenarios is\naccompanied by multiple challenges due to the inherent assumptions. There are\nseveral hindrances, such as unavailability of labels for the AL algorithm at\nthe beginning; unreliable external source of labels during the querying\nprocess; or incompatible mechanisms to evaluate the performance of Active\nLearner. Inspired by these practical challenges, we present a hybrid query\nstrategy-based AL framework that addresses three practical challenges\nsimultaneously: cold-start, oracle uncertainty and performance evaluation of\nActive Learner in the absence of ground truth. While a pre-clustering approach\nis employed to address the cold-start problem, the uncertainty surrounding the\nexpertise of labeler and confidence in the given labels is incorporated to\nhandle oracle uncertainty. The heuristics obtained during the querying process\nserve as the fundamental premise for accessing the performance of Active\nLearner. The robustness of the proposed AL framework is evaluated across three\ndifferent environments and industrial settings. The results demonstrate the\ncapability of the proposed framework to tackle practical challenges during AL\nimplementation in real-world scenarios.",
    "descriptor": "\nComments: 15 pages, 4 figures, 6 tables\n",
    "authors": [
      "Deepesh Agarwal",
      "Pravesh Srivastava",
      "Sergio Martin-del-Campo",
      "Balasubramaniam Natarajan",
      "Babji Srinivasan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03785"
  },
  {
    "id": "arXiv:2110.03786",
    "title": "Efficient large-scale image retrieval with deep feature orthogonality  and Hybrid-Swin-Transformers",
    "abstract": "We present an efficient end-to-end pipeline for largescale landmark\nrecognition and retrieval. We show how to combine and enhance concepts from\nrecent research in image retrieval and introduce two architectures especially\nsuited for large-scale landmark identification. A model with deep orthogonal\nfusion of local and global features (DOLG) using an EfficientNet backbone as\nwell as a novel Hybrid-Swin-Transformer is discussed and details how to train\nboth architectures efficiently using a step-wise approach and a sub-center\narcface loss with dynamic margins are provided. Furthermore, we elaborate a\nnovel discriminative re-ranking methodology for image retrieval. The\nsuperiority of our approach was demonstrated by winning the recognition and\nretrieval track of the Google Landmark Competition 2021.",
    "descriptor": "",
    "authors": [
      "Christof Henkel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03786"
  },
  {
    "id": "arXiv:2110.03789",
    "title": "Knowledge Sheaves: A Sheaf-Theoretic Framework for Knowledge Graph  Embedding",
    "abstract": "Knowledge graph embedding involves learning representations of entities --\nthe vertices of the graph -- and relations -- the edges of the graph -- such\nthat the resulting representations encode the known factual information\nrepresented by the knowledge graph are internally consistent and can be used in\nthe inference of new relations. We show that knowledge graph embedding is\nnaturally expressed in the topological and categorical language of\n\\textit{cellular sheaves}: learning a knowledge graph embedding corresponds to\nlearning a \\textit{knowledge sheaf} over the graph, subject to certain\nconstraints. In addition to providing a generalized framework for reasoning\nabout knowledge graph embedding models, this sheaf-theoretic perspective admits\nthe expression of a broad class of prior constraints on embeddings and offers\nnovel inferential capabilities. We leverage the recently developed spectral\ntheory of sheaf Laplacians to understand the local and global consistency of\nembeddings and develop new methods for reasoning over composite relations\nthrough harmonic extension with respect to the sheaf Laplacian. We then\nimplement these ideas to highlight the benefits of the extensions inspired by\nthis new perspective.",
    "descriptor": "",
    "authors": [
      "Thomas Gebhart",
      "Jakob Hansen",
      "Paul Schrater"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.03789"
  },
  {
    "id": "arXiv:2110.03790",
    "title": "Scaling Bayesian Optimization With Game Theory",
    "abstract": "We introduce the algorithm Bayesian Optimization (BO) with Fictitious Play\n(BOFiP) for the optimization of high dimensional black box functions. BOFiP\ndecomposes the original, high dimensional, space into several sub-spaces\ndefined by non-overlapping sets of dimensions. These sets are randomly\ngenerated at the start of the algorithm, and they form a partition of the\ndimensions of the original space. BOFiP searches the original space with\nalternating BO, within sub-spaces, and information exchange among sub-spaces,\nto update the sub-space function evaluation. The basic idea is to distribute\nthe high dimensional optimization across low dimensional sub-spaces, where each\nsub-space is a player in an equal interest game. At each iteration, BO produces\napproximate best replies that update the players belief distribution. The\nbelief update and BO alternate until a stopping condition is met.\nHigh dimensional problems are common in real applications, and several\ncontributions in the BO literature have highlighted the difficulty in scaling\nto high dimensions due to the computational complexity associated to the\nestimation of the model hyperparameters. Such complexity is exponential in the\nproblem dimension, resulting in substantial loss of performance for most\ntechniques with the increase of the input dimensionality.\nWe compare BOFiP to several state-of-the-art approaches in the field of high\ndimensional black box optimization. The numerical experiments show the\nperformance over three benchmark objective functions from 20 up to 1000\ndimensions. A neural network architecture design problem is tested with 42 up\nto 911 nodes in 6 up to 92 layers, respectively, resulting into networks with\n500 up to 10,000 weights. These sets of experiments empirically show that BOFiP\noutperforms its competitors, showing consistent performance across different\nproblems and increasing problem dimensionality.",
    "descriptor": "\nComments: 17 pages, 6 Figures, 4 Tables. Submitted for Journal Publication, Under review\n",
    "authors": [
      "L. Mathesen",
      "G. Pedrielli",
      "R.L. Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.03790"
  },
  {
    "id": "arXiv:2110.03792",
    "title": "A Probabilistic Graphical Model Approach to the Structure-and-Motion  Problem",
    "abstract": "We present a means of formulating and solving the well known\nstructure-and-motion problem in computer vision with probabilistic graphical\nmodels. We model the unknown camera poses and 3D feature coordinates as well as\nthe observed 2D projections as Gaussian random variables, using sigma point\nparameterizations to effectively linearize the nonlinear relationships between\nthese variables. Those variables involved in every projection are grouped into\na cluster, and we connect the clusters in a cluster graph. Loopy belief\npropagation is performed over this graph, in an iterative re-initialization and\nestimation procedure, and we find that our approach shows promise in both\nsimulation and on real-world data. The PGM is easily extendable to include\nadditional parameters or constraints.",
    "descriptor": "",
    "authors": [
      "Simon Streicher",
      "Willie Brink",
      "Johan du Preez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.03792"
  },
  {
    "id": "arXiv:2110.03794",
    "title": "Optimal Deployment and Operation of Robotic Aerial 6G Small Cells with  Grasping End Effectors",
    "abstract": "Although airborne base stations (ABSs) mounted on drones show a significant\npotential to enhance network capacity and coverage due to their flexible\ndeployment, the system performance is limited by the endurance of the on-board\nbattery. To overcome this key shortcoming, we are exploring robotic airborne\nbase station (RABS) with energy neutral grasping end-effectors able to\nautonomously perch at tall urban landforms. To this end, we propose novel\ninteger linear programming (ILP) optimization models and computational\nefficient reformulation by proving total unimodularity problem structure to\nallow optimal deployment and operation of robotic small cells based on the\nspatio-temporal characteristics of underlying traffic demand from end-users. A\nwide set of numerical investigations reveal that a single robotic aerial small\ncell is able to outperform five (5) fixed small cells in terms of served user\ngenerated traffic within a 16 to 41 hours period. This is because robotic\naerial small cell is able to alter its location based on actual traffic demand\nrather than on average values used for fixed small cell network deployment.",
    "descriptor": "",
    "authors": [
      "Yuan Liao",
      "Vasilis Friderikos"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.03794"
  },
  {
    "id": "arXiv:2110.03798",
    "title": "MPD: Moving Target Defense through Communication Protocol Dialects",
    "abstract": "Communication protocol security is among the most significant challenges of\nthe Internet of Things (IoT) due to the wide variety of hardware and software\ntechnologies involved. Moving target defense (MTD) has been adopted as an\ninnovative strategy to solve this problem by dynamically changing target system\nproperties and configurations to obfuscate the attack surface. Nevertheless,\nthe existing work of MTD primarily focuses on lower-level properties (e.g., IP\naddresses or port numbers), and only a limited number of variations can be\ngenerated based on these properties. In this paper, we propose a new approach\nof MTD through communication protocol dialects (MPD) - which dynamically\ncustomizes a communication protocol into various protocol dialects and\nleverages them to create a moving target defense. Specifically, MPD harnesses a\ndialect generating function to create protocol dialects and then a mapping\nfunction to select one specific dialect for each packet during communication.\nTo keep different network entities in synchronization, we also design a\nself-synchronization mechanism utilizing a pseudo-random number generator with\nthe input of a pre-shared secret key and previously sent packets. We implement\na prototype of MPD and evaluate its feasibility on standard network protocol\n(i.e., File Transfer Protocol) and internet of things protocol (i.e., Message\nQueuing Telemetry Transport). The results indicate that MPD can create a moving\ntarget defense with protocol dialects to effectively address various attacks -\nincluding the denial of service attack and malicious packet modifications -\nwith negligible overhead.",
    "descriptor": "\nComments: 2021 EAI SecureComm\n",
    "authors": [
      "Yongsheng Mei",
      "Kailash Gogineni",
      "Tian Lan",
      "Guru Venkataramani"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.03798"
  },
  {
    "id": "arXiv:2110.03800",
    "title": "CCGG: A Deep Autoregressive Model for Class-Conditional Graph Generation",
    "abstract": "Graph data structures are fundamental for studying connected entities. With\nan increase in the number of applications where data is represented as graphs,\nthe problem of graph generation has recently become a hot topic in many signal\nprocessing areas. However, despite its significance, conditional graph\ngeneration that creates graphs with desired features is relatively less\nexplored in previous studies. This paper addresses the problem of\nclass-conditional graph generation that uses class labels as generation\nconstraints by introducing the Class Conditioned Graph Generator (CCGG). We\nbuilt CCGG by adding the class information as an additional input to a graph\ngenerator model and including a classification loss in its total loss along\nwith a gradient passing trick. Our experiments show that CCGG outperforms\nexisting conditional graph generation methods on various datasets. It also\nmanages to maintain the quality of the generated graphs in terms of\ndistribution-based evaluation metrics.",
    "descriptor": "",
    "authors": [
      "Matin Yousefabadi",
      "Yassaman Ommi",
      "Faezeh Faez",
      "Amirmojtaba Sabour",
      "Mahdieh Soleymani Baghshah",
      "Hamid R. Rabiee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.03800"
  },
  {
    "id": "arXiv:2110.03801",
    "title": "Optimal SNR Analysis for Single-user RIS Systems in Ricean and Rayleigh  Environments",
    "abstract": "We present an analysis of the optimal uplink (UL) SNR of a SIMO\nReconfigurable Intelligent Surface (RIS)-aided wireless link. We assume that\nthe channel between base station (BS) and RIS is a rank-1 LOS channel while the\nuser (UE)-RIS and UE-BS channels are correlated Ricean. For the optimal RIS\nmatrix, we derive an exact closed form expression for the mean SNR and an\napproximation for the SNR variance leading to an accurate gamma approximation\nto the distribution of the UL SNR. Furthermore, we analytically characterise\nthe effects of correlation and the Ricean K-factor on SNR, showing that\nincreasing the K-factor and correlation in the UE-BS channel can have negative\neffects on the mean SNR, while increasing the K-factor and correlation in the\nUE-RIS channel improves system performance. We also present favourable and\nunfavourable channel scenarios which provide insight into the sort of\nenvironments that improve or degrade the mean SNR. We also show that the\nrelative gain in the mean SNR when transitioning from an unfavourable to a\nfavourable environment saturates to $(4-\\pi)/\\pi$ as $N \\rightarrow \\infty $",
    "descriptor": "\nComments: reconfigurable intelligent surface, intelligent reflecting surface, optimal RIS SNR analysis. arXiv admin note: text overlap with arXiv:2008.09376\n",
    "authors": [
      "Ikram Singh",
      "Peter J. Smith",
      "Pawel A. Dmochowski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.03801"
  },
  {
    "id": "arXiv:2110.03802",
    "title": "Hitting the Target: Stopping Active Learning at the Cost-Based Optimum",
    "abstract": "Active learning allows machine learning models to be trained using fewer\nlabels while retaining similar performance to traditional fully supervised\nlearning. An active learner selects the most informative data points, requests\ntheir labels, and retrains itself. While this approach is promising, it leaves\nan open problem of how to determine when the model is `good enough' without the\nadditional labels required for traditional evaluation. In the past, different\nstopping criteria have been proposed aiming to identify the optimal stopping\npoint. However, optimality can only be expressed as a domain-dependent\ntrade-off between accuracy and the number of labels, and no criterion is\nsuperior in all applications. This paper is the first to give actionable advice\nto practitioners on what stopping criteria they should use in a given\nreal-world scenario. We contribute the first large-scale comparison of stopping\ncriteria, using a cost measure to quantify the accuracy/label trade-off, public\nimplementations of all stopping criteria we evaluate, and an open-source\nframework for evaluating stopping criteria. Our research enables practitioners\nto substantially reduce labelling costs by utilizing the stopping criterion\nwhich best suits their domain.",
    "descriptor": "\nComments: 39 pages, 26 figures\n",
    "authors": [
      "Zac Pullar-Strecker",
      "Katharina Dost",
      "Eibe Frank",
      "J\u00f6rg Wicker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03802"
  },
  {
    "id": "arXiv:2110.03804",
    "title": "FOCUS: Familiar Objects in Common and Uncommon Settings",
    "abstract": "Standard training datasets for deep learning often contain objects in common\nsettings (e.g., \"a horse on grass\" or \"a ship in water\") since they are usually\ncollected by randomly scraping the web. Uncommon and rare settings (e.g., \"a\nplane on water\", \"a car in snowy weather\") are thus severely under-represented\nin the training data. This can lead to an undesirable bias in model predictions\ntowards common settings and create a false sense of accuracy. In this paper, we\nintroduce FOCUS (Familiar Objects in Common and Uncommon Settings), a dataset\nfor stress-testing the generalization power of deep image classifiers. By\nleveraging the power of modern search engines, we deliberately gather data\ncontaining objects in common and uncommon settings in a wide range of\nlocations, weather conditions, and time of day. We present a detailed analysis\nof the performance of various popular image classifiers on our dataset and\ndemonstrate a clear drop in performance when classifying images in uncommon\nsettings. By analyzing deep features of these models, we show that such errors\ncan be due to the use of spurious features in model predictions. We believe\nthat our dataset will aid researchers in understanding the inability of deep\nmodels to generalize well to uncommon settings and drive future work on\nimproving their distributional robustness.",
    "descriptor": "\nComments: 21 pages, 15 figures, 7 tables\n",
    "authors": [
      "Priyatham Kattakinda",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03804"
  },
  {
    "id": "arXiv:2110.03806",
    "title": "Toward a Theory of Programming Language and Reasoning Assistant Design:  Minimizing Cognitive Load",
    "abstract": "Current approaches to making programming languages and reasoning assistants\nmore effective for people focus on leveraging feedback from users and on\nevaluating the success of particular techniques. These approaches, although\nhelpful, may not result in systems that are as usable as possible, and may not\nlead to general design principles. This paper advocates for leveraging theories\nfrom cognitive science, using cognitive load theory as an example, to design\nmore effective programming languages and reasoning assistants. Development of\nthese theories may enable designers to create more effective programming\nlanguages and reasoning assistants at lower cost.",
    "descriptor": "\nComments: 7 pages. In HATRA 2021\n",
    "authors": [
      "Michael Coblenz"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.03806"
  },
  {
    "id": "arXiv:2110.03814",
    "title": "StyleGAN-induced data-driven regularization for inverse problems",
    "abstract": "Recent advances in generative adversarial networks (GANs) have opened up the\npossibility of generating high-resolution photo-realistic images that were\nimpossible to produce previously. The ability of GANs to sample from\nhigh-dimensional distributions has naturally motivated researchers to leverage\ntheir power for modeling the image prior in inverse problems. We extend this\nline of research by developing a Bayesian image reconstruction framework that\nutilizes the full potential of a pre-trained StyleGAN2 generator, which is the\ncurrently dominant GAN architecture, for constructing the prior distribution on\nthe underlying image. Our proposed approach, which we refer to as learned\nBayesian reconstruction with generative models (L-BRGM), entails joint\noptimization over the style-code and the input latent code, and enhances the\nexpressive power of a pre-trained StyleGAN2 generator by allowing the\nstyle-codes to be different for different generator layers. Considering the\ninverse problems of image inpainting and super-resolution, we demonstrate that\nthe proposed approach is competitive with, and sometimes superior to,\nstate-of-the-art GAN-based image reconstruction methods.",
    "descriptor": "\nComments: Submitted to IEEE ICASSP 2022. Under review\n",
    "authors": [
      "Arthur Conmy",
      "Subhadip Mukherjee",
      "Carola-Bibiane Sch\u00f6nlieb"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.03814"
  },
  {
    "id": "arXiv:2110.03816",
    "title": "AS-Level BGP Community Usage Classification",
    "abstract": "BGP communities are a popular mechanism used by network operators for traffic\nengineering, blackholing, and to realize network policies and business\nstrategies. In recent years, many research works have contributed to our\nunderstanding of how BGP communities are utilized, as well as how they can\nreveal secondary insights into real-world events such as outages and security\nattacks. However, one fundamental question remains unanswered: \"Which ASes tag\nannouncements with BGP communities and which remove communities in the\nannouncements they receive?\" A grounded understanding of where BGP communities\nare added or removed can help better model and predict BGP-based actions in the\nInternet and characterize the strategies of network operators.\nIn this paper we develop, validate, and share data from the first algorithm\nthat can infer BGP community tagging and cleaning behavior at the AS-level. The\nalgorithm is entirely passive and uses BGP update messages and snapshots, e.g.\nfrom public route collectors, as input. First, we quantify the correctness and\naccuracy of the algorithm in controlled experiments with simulated topologies.\nTo validate in the wild, we announce prefixes with communities and confirm that\nmore than 90% of the ASes that we classify behave as our algorithm predicts.\nFinally, we apply the algorithm to data from four sets of BGP collectors: RIPE,\nRouteViews, Isolario, and PCH. Tuned conservatively, our algorithm ascribes\ncommunity tagging and cleaning behaviors to more than 13k ASes, the majority of\nwhich are large networks and providers. We make our algorithm and inferences\navailable as a public resource to the BGP research community.",
    "descriptor": "",
    "authors": [
      "Thomas Krenc",
      "Robert Beverly",
      "Georgios Smaragdakis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.03816"
  },
  {
    "id": "arXiv:2110.03818",
    "title": "Social Groups Based Content Caching in Wireless Networks",
    "abstract": "The unprecedented growth of wireless mobile traffic, mainly due to multimedia\ntraffic over online social platforms has strained the resources in the mobile\nbackhaul network. A promising approach to reduce the backhaul load is to\nproactively cache content at the network edge, taking into account the overlaid\nsocial network. Known caching schemes require complete knowledge of the social\ngraph and mainly focus on one-to-one interactions forgoing the prevalent mode\nof content sharing among circles of 'friends'. We propose Bingo, a proactive\ncontent caching scheme that leverages the presence of interest groups in online\nsocial networks. The mobile network operator (MNO) can choose to incrementally\ndeploy Bingo at select network nodes (base stations, packet core, data center)\nbased on user profiles and revenue numbers. We approximate the group\nmemberships of users using the available user-content request logs without any\nprior knowledge of the overlaid social graph. Bingo can cater to the evolving\nnature of online social groups and file popularity distribution for making\ncaching decisions. We use synthetically generated group structures and simulate\nuser requests at the base station for empirical evaluation against traditional\nand recent caching schemes. Bingo achieves up to 30%-34% gain over the best\nbaseline.",
    "descriptor": "\nComments: To appear in Proceedings of the 19th ACM International Symposium on Mobility Management (MobiWac '21)\n",
    "authors": [
      "Nimrah Mustafa",
      "Imdadullah Khan",
      "Muhammad Asad Khan",
      "Zartash Afzal Uzmi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.03818"
  },
  {
    "id": "arXiv:2110.03820",
    "title": "How Tertiary Studies perform Quality Assessment of Secondary Studies in  Software Engineering",
    "abstract": "Context: Tertiary studies are becoming increasingly popular in software\nengineering as an instrument to synthesise evidence on a research topic in a\nsystematic way. In order to understand and contextualize their findings, it is\nimportant to assess the quality of the selected secondary studies. Objective:\nThis paper aims to provide a state of the art on the assessment of secondary\nstudies' quality as conducted in tertiary studies in the area of software\nengineering, reporting the frameworks used as instruments, the facets examined\nin these frameworks, and the purposes of the quality assessment. Method: We\ndesigned this study as a systematic mapping responding to four research\nquestions derived from the objective above. We applied a rigorous search\nprotocol over the Scopus digital library, resulting in 47 papers after\napplication of inclusion and exclusion criteria. The extracted data was\nsynthesised using content analysis. Results: A majority of tertiary studies\nperform quality assessment. It is not often used for excluding studies, but to\nsupport some kind of investigation. The DARE quality assessment framework is\nthe most frequently used, with customizations in some cases to cover missing\nfacets. We outline the first steps towards building a new framework to address\nthe shortcomings identified. Conclusion: This paper is a step forward\nestablishing a foundation for researchers in two different ways. As authors of\ntertiary studies, understanding the different possibilities in which they can\nperform quality assessment of secondary studies. As readers, having an\ninstrument to understand the methodological rigor upon which tertiary studies\nmay claim their findings.",
    "descriptor": "\nComments: Preprint of the paper presented at the XXIV Iberoamerican Conference on Software Engineering (ESELAW@CIbSE). Best paper award. If interested in the topic, check also arXiv:2109.08226 (postprint of a paper accepted at ESEM'21)\n",
    "authors": [
      "Dolors Costal",
      "Carles Farr\u00e9",
      "Xavier Franch",
      "Carme Quer"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.03820"
  },
  {
    "id": "arXiv:2110.03821",
    "title": "Uniform Guarded Fragments",
    "abstract": "In this paper we prove that the uniform one-dimensional guarded fragment,\nwhich is a natural polyadic generalization of the guarded two-variable logic,\nhas the Craig interpolation property. We will also prove that the\nsatisfiability problem of uniform guarded fragment is NEXPTIME-complete.",
    "descriptor": "",
    "authors": [
      "Reijo Jaakkola"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.03821"
  },
  {
    "id": "arXiv:2110.03825",
    "title": "Exploring Architectural Ingredients of Adversarially Robust Deep Neural  Networks",
    "abstract": "Deep neural networks (DNNs) are known to be vulnerable to adversarial\nattacks. A range of defense methods have been proposed to train adversarially\nrobust DNNs, among which adversarial training has demonstrated promising\nresults. However, despite preliminary understandings developed for adversarial\ntraining, it is still not clear, from the architectural perspective, what\nconfigurations can lead to more robust DNNs. In this paper, we address this gap\nvia a comprehensive investigation on the impact of network width and depth on\nthe robustness of adversarially trained DNNs. Specifically, we make the\nfollowing key observations: 1) more parameters (higher model capacity) does not\nnecessarily help adversarial robustness; 2) reducing capacity at the last stage\n(the last group of blocks) of the network can actually improve adversarial\nrobustness; and 3) under the same parameter budget, there exists an optimal\narchitectural configuration for adversarial robustness. We also provide a\ntheoretical analysis explaning why such network configuration can help\nrobustness. These architectural insights can help design adversarially robust\nDNNs. Code is available at \\url{https://github.com/HanxunH/RobustWRN}.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Hanxun Huang",
      "Yisen Wang",
      "Sarah Monazam Erfani",
      "Quanquan Gu",
      "James Bailey",
      "Xingjun Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.03825"
  },
  {
    "id": "arXiv:2110.03836",
    "title": "Bipartite Independent Set Oracles and Beyond: Can it Even Count  Triangles in Polylogarithmic Queries?",
    "abstract": "{Beame et al.\\ [ITCS 2018] introduced and used the {\\sc Bipartite Independent\nSet} ({\\sc BIS}) and {\\sc Independent Set} ({\\sc IS}) oracle access to an\nunknown, simple, unweighted and undirected graph and solved the edge estimation\nproblem. The introduction of this oracle set forth a series of works in a short\nspan of time that either solved open questions mentioned by Beame et al.\\ or\nwere generalizations of their work as in Dell and Lapinskas [STOC 2018], Dell,\nLapinskas and Meeks [SODA 2020], Bhattacharya et al.\\ [ISAAC 2019 and arXiv\n2019], Chen et al.\\ [SODA 2020]. Edge estimation using {\\sc BIS} can be done\nusing polylogarithmic queries, while {\\sc IS} queries need sub-linear but more\nthan polylogarithmic queries. Chen et al.\\ improved Beame et al.'s upper bound\nresult for edge estimation using {\\sc IS} and also showed an almost matching\nlower bound. This result was significant because this lower bound result on \\is\nwas the first lower bound result for independent set based oracles; till date\nno lower bound results exist for {\\sc BIS}. On the other hand, Beame et al.\\ in\ntheir introductory work asked a few open questions out of which one was if\nstructures of higher order than edges can be estimated using polylogarithmic\nnumber of {\\sc BIS} queries. Motivated by this question, we resolve in the\nnegative by showing a lower bound (greater than polylogarithmic) for estimating\nthe number of triangles using {\\sc BIS}. While doing so, we prove the first\nlower bound result involving {\\sc BIS}. We also provide a matching upper bound.\nTill now, query oracles were used for commensurate jobs -- \\bis and \\is for\nedge estimation, \\tislong for triangle estimation, \\gpislong for hyperedge\nestimation. Ours is a work that uses a lower order oracle access, like \\bis to\nestimate a higher order structure like triangle. }",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Arijit Bishnu",
      "Arijit Ghosh",
      "Gopinath Mishra"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.03836"
  },
  {
    "id": "arXiv:2110.03838",
    "title": "High-order Corrected Trapezoidal Rules for Functions with Fractional  Singularities",
    "abstract": "In this paper, we introduce and analyze a high-order quadrature rule for\nevaluating the two-dimensional singular integrals of the forms \\[\nI = \\int_{R^2}\\phi(x)\\frac{x_1^2}{|x|^{2+\\alpha}} dx, \\quad 0< \\alpha < 2\n\\] where $\\phi\\in C_c^N$ for $N\\geq 2$. This type of singular integrals and\nits quadrature rule appear in the numerical discretization of Fractional\nLaplacian in the non-local Fokker-Planck Equations in 2D by Ha \\cite{HansenHa}.\nThe quadrature rule is adapted from \\cite{MarinTornberg2014}, they are\ntrapezoidal rules equipped with correction weights for points around\nsingularity. We prove the order of convergence is $2p+4-\\alpha$, where\n$p\\in\\mathbb{N}_{0}$ is associated with total number of correction weights.\nAlthough we work in 2D setting, we mainly formulate definitions and theorems in\n$n\\in\\mathbb{N}$ dimensions for the sake of clarity and generality.",
    "descriptor": "",
    "authors": [
      "Senbao Jiang",
      "Xiaofan Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.03838"
  },
  {
    "id": "arXiv:2110.03840",
    "title": "Toward a Wearable Biosensor Ecosystem on ROS 2 for Real-time Human-Robot  Interaction Systems",
    "abstract": "Wearable biosensors can enable continuous human data capture, facilitating\ndevelopment of real-world Human-Robot Interaction (HRI) systems. However, a\nlack of standardized libraries and implementations adds extraneous complexity\nto HRI system designs, and precludes collaboration across disciplines and\ninstitutions. Here, we introduce a novel wearable biosensor package for the\nRobot Operating System 2 (ROS 2) system. The ROS2 officially supports real-time\ncomputing and multi-robot systems, and thus provides easy-to-use and reliable\nstreaming data from multiple nodes. The package standardizes biosensor HRI\nintegration, lowers the technical barrier of entry, and expands the biosensor\necosystem into the robotics field. Each biosensor package node follows a\ngeneralized node and topic structure concentrated on ease of use. Current\npackage capabilities, listed by biosensor, highlight package standardization.\nCollected example data demonstrate a full integration of each biosensor into\nROS2. We expect that standardization of this biosensors package for ROS2 will\ngreatly simplify use and cross-collaboration across many disciplines. The\nwearable biosensor package is made publicly available on GitHub at\n\\https://github.com/SMARTlab-Purdue/ros2-foxy-wearable-biosensors.",
    "descriptor": "\nComments: This paper was accepted to the IROS 2021: Workshop on Cognitive and Social Aspects of Human Multi-Robot Interaction (HMRS 2021). The proposed ROS2 package is available to download from this https URL\n",
    "authors": [
      "Wonse Jo",
      "Robert Wilson",
      "Jaeeun Kim",
      "Steve McGuire",
      "Byung-Cheol Min"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.03840"
  },
  {
    "id": "arXiv:2110.03845",
    "title": "A New Data Integration Framework for Covid-19 Social Media Information",
    "abstract": "The Covid-19 pandemic presents a serious threat to people's health, resulting\nin over 250 million confirmed cases and over 5 million deaths globally. In\norder to reduce the burden on national health care systems and to mitigate the\neffects of the outbreak, accurate modelling and forecasting methods for short-\nand long-term health demand are needed to inform government interventions\naiming at curbing the pandemic. Current research on Covid-19 is typically based\non a single source of information, specifically on structured historical\npandemic data. Other studies are exclusively focused on unstructured online\nretrieved insights, such as data available from social media. However, the\ncombined use of structured and unstructured information is still uncharted.\nThis paper aims at filling this gap, by leveraging historical as well as social\nmedia information with a novel data integration methodology. The proposed\napproach is based on vine copulas, which allow us to improve predictions by\nexploiting the dependencies between different sources of information. We apply\nthe methodology to combine structured datasets retrieved from official sources\nand to a big unstructured dataset of information collected from social media.\nThe results show that the proposed approach, compared to traditional\napproaches, yields more accurate estimations and predictions of the evolution\nof the Covid-19 pandemic.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2104.01869\n",
    "authors": [
      "Lauren Ansell",
      "Luciana Dalla Valle"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.03845"
  },
  {
    "id": "arXiv:2110.03847",
    "title": "Machine Translation Verbosity Control for Automatic Dubbing",
    "abstract": "Automatic dubbing aims at seamlessly replacing the speech in a video document\nwith synthetic speech in a different language. The task implies many\nchallenges, one of which is generating translations that not only convey the\noriginal content, but also match the duration of the corresponding utterances.\nIn this paper, we focus on the problem of controlling the verbosity of machine\ntranslation output, so that subsequent steps of our automatic dubbing pipeline\ncan generate dubs of better quality. We propose new methods to control the\nverbosity of MT output and compare them against the state of the art with both\nintrinsic and extrinsic evaluations. For our experiments we use a public data\nset to dub English speeches into French, Italian, German and Spanish. Finally,\nwe report extensive subjective tests that measure the impact of MT verbosity\ncontrol on the final quality of dubbed video clips.",
    "descriptor": "\nComments: Accepted at IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2021\n",
    "authors": [
      "Surafel M. Lakew",
      "Marcello Federico",
      "Yue Wang",
      "Cuong Hoang",
      "Yogesh Virkar",
      "Roberto Barra-Chicote",
      "Robert Enyedi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.03847"
  },
  {
    "id": "arXiv:2110.03848",
    "title": "Speeding up Deep Model Training by Sharing Weights and Then Unsharing",
    "abstract": "We propose a simple and efficient approach for training the BERT model. Our\napproach exploits the special structure of BERT that contains a stack of\nrepeated modules (i.e., transformer encoders). Our proposed approach first\ntrains BERT with the weights shared across all the repeated modules till some\npoint. This is for learning the commonly shared component of weights across all\nrepeated layers. We then stop weight sharing and continue training until\nconvergence. We present theoretic insights for training by sharing weights then\nunsharing with analysis for simplified models. Empirical experiments on the\nBERT model show that our method yields better performance of trained models,\nand significantly reduces the number of training iterations.",
    "descriptor": "",
    "authors": [
      "Shuo Yang",
      "Le Hou",
      "Xiaodan Song",
      "Qiang Liu",
      "Denny Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.03848"
  },
  {
    "id": "arXiv:2110.03851",
    "title": "Automatic annotation of visual deep neural networks",
    "abstract": "Computer vision is widely used in the fields of driverless, face recognition\nand 3D reconstruction as a technology to help or replace human eye perception\nimages or multidimensional data through computers. Nowadays, with the\ndevelopment and application of deep neural networks, the models of deep neural\nnetworks proposed for computer vision are becoming more and more abundant, and\ndevelopers will use the already trained models on the way to solve problems,\nand need to consult the relevant documents to understand the use of the model.\nThe class model, which creates the need to quickly and accurately find the\nrelevant models that you need. The automatic annotation method of visual depth\nneural network proposed in this paper is based on natural language processing\ntechnology such as semantic analysis, which realizes automatic labeling of\nmodel application fields. In the three top international conferences on\ncomputer vision: ICCV, CVPR and ECCV, the average correct rate of application\nof the papers of 72 papers reached 90%, indicating the effectiveness of the\nautomatic labeling system.",
    "descriptor": "",
    "authors": [
      "Ming Li",
      "ChenHao Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03851"
  },
  {
    "id": "arXiv:2110.03854",
    "title": "Meta-Learning 3D Shape Segmentation Functions",
    "abstract": "Learning robust 3D shape segmentation functions with deep neural networks has\nemerged as a powerful paradigm, offering promising performance in producing a\nconsistent part segmentation of each 3D shape. Generalizing across 3D shape\nsegmentation functions requires robust learning of priors over the respective\nfunction space and enables consistent part segmentation of shapes in presence\nof significant 3D structure variations. Existing generalization methods rely on\nextensive training of 3D shape segmentation functions on large-scale labeled\ndatasets. In this paper, we proposed to formalize the learning of a 3D shape\nsegmentation function space as a meta-learning problem, aiming to predict a 3D\nsegmentation model that can be quickly adapted to new shapes with no or limited\ntraining data. More specifically, we define each task as unsupervised learning\nof shape-conditioned 3D segmentation function which takes as input points in 3D\nspace and predicts the part-segment labels. The 3D segmentation function is\ntrained by a self-supervised 3D shape reconstruction loss without the need for\npart labels. Also, we introduce an auxiliary deep neural network as a\nmeta-learner which takes as input a 3D shape and predicts the prior over the\nrespective 3D segmentation function space. We show in experiments that our\nmeta-learning approach, denoted as Meta-3DSeg, leads to improvements on\nunsupervised 3D shape segmentation over the conventional designs of deep neural\nnetworks for 3D shape segmentation functions.",
    "descriptor": "",
    "authors": [
      "Yu Hao",
      "Yi Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03854"
  },
  {
    "id": "arXiv:2110.03855",
    "title": "Hardware Functional Obfuscation With Ferroelectric Active Interconnects",
    "abstract": "Camouflaging gate techniques are typically used in hardware security to\nprevent reverse engineering. Layout level camouflaging by adding dummy contacts\nensures some level of protection against extracting the correct netlist.\nThreshold voltage manipulation for multi-functional logic with identical\nlayouts has also been introduced for functional obfuscation. All these\ntechniques are implemented at the expense of circuit-complexity and with\nsignificant area, energy, and delay penalty. In this paper, we propose an\nefficient hardware encryption technique with minimal complexity and overheads\nbased on ferroelectric field-effect transistor (FeFET) active interconnects.\nThe active interconnect provides run-time reconfigurable inverter-buffer logic\nby utilizing the threshold voltage programmability of the FeFETs. Our method\nutilizes only two FeFETs and an inverter to realize the masking function\ncompared to recent reconfigurable logic gate implementations using several\nFeFETs and complex differential logic. We fabricate the proposed circuit and\ndemonstrate the functionality. Judicious placement of the proposed logic in the\nIC makes it acts as a hardware encryption key and enables encoding and decoding\nof the functional output without affecting the critical path timing delay.\nAlso, we achieve comparable encryption probability with a limited number of\nencryption units. In addition, we show a peripheral programming scheme for\nreconfigurable logic by reusing the existing scan chain logic, hence obviating\nthe need for specialized programming logic and circuitry for keybit\ndistribution. Our analysis shows an average encryption probability of 97.43\\%\nwith an increase of 2.24\\%/ 3.67\\% delay for the most critical path/ sum of 100\ncritical paths delay for ISCAS85 benchmarks.",
    "descriptor": "",
    "authors": [
      "Tonggunag Yu",
      "Yixin Xu",
      "Shan Deng",
      "Zijian Zhao",
      "Nicolas Jao",
      "You Sung Kim",
      "Stefan Duenkel",
      "Sven Beyer",
      "Kai Ni",
      "Sumitha George",
      "Vijaykrishnan Narayanan"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2110.03855"
  },
  {
    "id": "arXiv:2110.03858",
    "title": "ABCP: Automatic Block-wise and Channel-wise Network Pruning via Joint  Search",
    "abstract": "Currently, an increasing number of model pruning methods are proposed to\nresolve the contradictions between the computer powers required by the deep\nlearning models and the resource-constrained devices. However, most of the\ntraditional rule-based network pruning methods can not reach a sufficient\ncompression ratio with low accuracy loss and are time-consuming as well as\nlaborious. In this paper, we propose Automatic Block-wise and Channel-wise\nNetwork Pruning (ABCP) to jointly search the block-wise and channel-wise\npruning action with deep reinforcement learning. A joint sample algorithm is\nproposed to simultaneously generate the pruning choice of each residual block\nand the channel pruning ratio of each convolutional layer from the discrete and\ncontinuous search space respectively. The best pruning action taking both the\naccuracy and the complexity of the model into account is obtained finally.\nCompared with the traditional rule-based pruning method, this pipeline saves\nhuman labor and achieves a higher compression ratio with lower accuracy loss.\nTested on the mobile robot detection dataset, the pruned YOLOv3 model saves\n99.5% FLOPs, reduces 99.5% parameters, and achieves 37.3 times speed up with\nonly 2.8% mAP loss. The results of the transfer task on the sim2real detection\ndataset also show that our pruned model has much better robustness performance.",
    "descriptor": "\nComments: 12 pages, 9 figures, submitted to Journal of IEEE Transactions on Cybernetics\n",
    "authors": [
      "Jiaqi Li",
      "Haoran Li",
      "Yaran Chen",
      "Zixiang Ding",
      "Nannan Li",
      "Mingjun Ma",
      "Zicheng Duan",
      "Dongbing Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.03858"
  },
  {
    "id": "arXiv:2110.03860",
    "title": "Token Pooling in Visual Transformers",
    "abstract": "Despite the recent success in many applications, the high computational\nrequirements of vision transformers limit their use in resource-constrained\nsettings. While many existing methods improve the quadratic complexity of\nattention, in most vision transformers, self-attention is not the major\ncomputation bottleneck, e.g., more than 80% of the computation is spent on\nfully-connected layers. To improve the computational complexity of all layers,\nwe propose a novel token downsampling method, called Token Pooling, efficiently\nexploiting redundancies in the images and intermediate token representations.\nWe show that, under mild assumptions, softmax-attention acts as a\nhigh-dimensional low-pass (smoothing) filter. Thus, its output contains\nredundancy that can be pruned to achieve a better trade-off between the\ncomputational cost and accuracy. Our new technique accurately approximates a\nset of tokens by minimizing the reconstruction error caused by downsampling. We\nsolve this optimization problem via cost-efficient clustering. We rigorously\nanalyze and compare to prior downsampling methods. Our experiments show that\nToken Pooling significantly improves the cost-accuracy trade-off over the\nstate-of-the-art downsampling. Token Pooling is a simple and effective operator\nthat can benefit many architectures. Applied to DeiT, it achieves the same\nImageNet top-1 accuracy using 42% fewer computations.",
    "descriptor": "",
    "authors": [
      "Dmitrii Marin",
      "Jen-Hao Rick Chang",
      "Anurag Ranjan",
      "Anish Prabhu",
      "Mohammad Rastegari",
      "Oncel Tuzel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03860"
  },
  {
    "id": "arXiv:2110.03865",
    "title": "Stable Prediction on Graphs with Agnostic Distribution Shift",
    "abstract": "Graph is a flexible and effective tool to represent complex structures in\npractice and graph neural networks (GNNs) have been shown to be effective on\nvarious graph tasks with randomly separated training and testing data. In real\napplications, however, the distribution of training graph might be different\nfrom that of the test one (e.g., users' interactions on the user-item training\ngraph and their actual preference on items, i.e., testing environment, are\nknown to have inconsistencies in recommender systems). Moreover, the\ndistribution of test data is always agnostic when GNNs are trained. Hence, we\nare facing the agnostic distribution shift between training and testing on\ngraph learning, which would lead to unstable inference of traditional GNNs\nacross different test environments. To address this problem, we propose a novel\nstable prediction framework for GNNs, which permits both locally and globally\nstable learning and prediction on graphs. In particular, since each node is\npartially represented by its neighbors in GNNs, we propose to capture the\nstable properties for each node (locally stable) by re-weighting the\ninformation propagation/aggregation processes. For global stability, we propose\na stable regularizer that reduces the training losses on heterogeneous\nenvironments and thus warping the GNNs to generalize well. We conduct extensive\nexperiments on several graph benchmarks and a noisy industrial recommendation\ndataset that is collected from 5 consecutive days during a product promotion\nfestival. The results demonstrate that our method outperforms various SOTA GNNs\nfor stable prediction on graphs with agnostic distribution shift, including\nshift caused by node labels and attributes.",
    "descriptor": "\nComments: 11 pages, 6 figures\n",
    "authors": [
      "Shengyu Zhang",
      "Kun Kuang",
      "Jiezhong Qiu",
      "Jin Yu",
      "Zhou Zhao",
      "Hongxia Yang",
      "Zhongfei Zhang",
      "Fei Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.03865"
  },
  {
    "id": "arXiv:2110.03866",
    "title": "Unsupervised Cross-Lingual Transfer of Structured Predictors without  Source Data",
    "abstract": "Providing technologies to communities or domains where training data is\nscarce or protected e.g., for privacy reasons, is becoming increasingly\nimportant. To that end, we generalise methods for unsupervised transfer from\nmultiple input models for structured prediction. We show that the means of\naggregating over the input models is critical, and that multiplying marginal\nprobabilities of substructures to obtain high-probability structures for\ndistant supervision is substantially better than taking the union of such\nstructures over the input models, as done in prior work. Testing on 18\nlanguages, we demonstrate that the method works in a cross-lingual setting,\nconsidering both dependency parsing and part-of-speech structured prediction\nproblems. Our analyses show that the proposed method produces less noisy labels\nfor the distant supervision.",
    "descriptor": "",
    "authors": [
      "Kemal Kurniawan",
      "Lea Frermann",
      "Philip Schulz",
      "Trevor Cohn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.03866"
  },
  {
    "id": "arXiv:2110.03868",
    "title": "Contrastive Learning for Source Code with Structural and Functional  Properties",
    "abstract": "Pre-trained transformer models have recently shown promises for understanding\nthe source code. Most existing works expect to understand code from the textual\nfeatures and limited structural knowledge of code. However, the program\nfunctionalities sometimes cannot be fully revealed by the code sequence, even\nwith structure information. Programs can contain very different tokens and\nstructures while sharing the same functionality, but changing only one or a few\ncode tokens can introduce unexpected or malicious program behaviors while\npreserving the syntax and most tokens. In this work, we present BOOST, a novel\nself-supervised model to focus pre-training based on the characteristics of\nsource code. We first employ automated, structure-guided code transformation\nalgorithms that generate (i.) functionally equivalent code that looks\ndrastically different from the original one, and (ii.) textually and\nsyntactically very similar code that is functionally distinct from the\noriginal. We train our model in a way that brings the functionally equivalent\ncode closer and distinct code further through a contrastive learning objective.\nTo encode the structure information, we introduce a new node-type masked\nlanguage model objective that helps the model learn about structural context.\nWe pre-train BOOST with a much smaller dataset than the state-of-the-art\nmodels, but our small models can still match or outperform these large models\nin code understanding and generation tasks.",
    "descriptor": "",
    "authors": [
      "Yangruibo Ding",
      "Luca Buratti",
      "Saurabh Pujar",
      "Alessandro Morari",
      "Baishakhi Ray",
      "Saikat Chakraborty"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.03868"
  },
  {
    "id": "arXiv:2110.03872",
    "title": "The similarity index of mathematical and other scientific publications  with equations and formulas and the problem of self-plagiarism identification",
    "abstract": "The problems of estimating the similarity index of inhomogeneous scientific\npublications containing equations and formulas are discussed for the first\ntime. It is shown that the presence of equations and formulas (as well as\nfigures, drawings, and tables) is a complicating factor that significantly\ncomplicates the study of such texts. It has been proved that the method for\ndetermining the similarity index of publications, based on taking into account\nindividual mathematical symbols and parts of equations and formulas, is\nineffective and can lead to erroneous and even completely absurd conclusions.\nPossibilities of the most popular software systems Antiplagiat and iThenticate,\ncurrently used in scientific journals, are investigated for detecting\nplagiarism and self-plagiarism. The results of processing by the iThenticate\nsystem of specific examples and specific test problems containing equations and\nformulas are presented. It has been established that this software system, when\nanalyzing heterogeneous texts, is often unable to distinguish self-plagiarism\nfrom pseudo-self-plagiarism, seeming real (but false and imaginary)\nself-plagiarism. A model complex situation is considered, in which the\nidentification of self-plagiarism requires the involvement of highly qualified\nspecialists of a narrow profile. Various ways to improve the work of software\nsystems for comparing inhomogeneous texts are proposed. This article will be\nuseful to researchers and university teachers in physics, mathematics, and\nengineering, programmers dealing with problems in image recognition and\nresearch topics of digital image processing, as well as a wide range of readers\nwho are interested in issues of plagiarism and self-plagiarism.",
    "descriptor": "\nComments: 20 pages, 4 figures, 2 photos, Russian language\n",
    "authors": [
      "A.D. Polyanin",
      "I.K. Shingareva"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2110.03872"
  },
  {
    "id": "arXiv:2110.03873",
    "title": "Representation of professions in entertainment media: Insights into  frequency and sentiment trends through computational text analysis",
    "abstract": "Societal ideas and trends dictate media narratives and cinematic depictions\nwhich in turn influences people's beliefs and perceptions of the real world.\nMedia portrayal of culture, education, government, religion, and family affect\ntheir function and evolution over time as people interpret and perceive these\nrepresentations and incorporate them into their beliefs and actions. It is\nimportant to study media depictions of these social structures so that they do\nnot propagate or reinforce negative stereotypes, or discriminate against any\ndemographic section. In this work, we examine media representation of\nprofessions and provide computational insights into their incidence, and\nsentiment expressed, in entertainment media content. We create a searchable\ntaxonomy of professional groups and titles to facilitate their retrieval from\nspeaker-agnostic text passages like movie and television (TV) show subtitles.\nWe leverage this taxonomy and relevant natural language processing (NLP) models\nto create a corpus of professional mentions in media content, spanning more\nthan 136,000 IMDb titles over seven decades (1950-2017). We analyze the\nfrequency and sentiment trends of different occupations, study the effect of\nmedia attributes like genre, country of production, and title type on these\ntrends, and investigate if the incidence of professions in media subtitles\ncorrelate with their real-world employment statistics. We observe increased\nmedia mentions of STEM, arts, sports, and entertainment occupations in the\nanalyzed subtitles, and a decreased frequency of manual labor jobs and military\noccupations. The sentiment expressed toward lawyers, police, and doctors is\nbecoming negative over time, whereas astronauts, musicians, singers, and\nengineers are mentioned favorably. Professions that employ more people have\nincreased media frequency, supporting our hypothesis that media acts as a\nmirror to society.",
    "descriptor": "\nComments: 28 pages, 15 figures\n",
    "authors": [
      "Sabyasachee Baruah",
      "Krishna Somandepalli",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03873"
  },
  {
    "id": "arXiv:2110.03875",
    "title": "Dyn-Backdoor: Backdoor Attack on Dynamic Link Prediction",
    "abstract": "Dynamic link prediction (DLP) makes graph prediction based on historical\ninformation. Since most DLP methods are highly dependent on the training data\nto achieve satisfying prediction performance, the quality of the training data\nis crucial. Backdoor attacks induce the DLP methods to make wrong prediction by\nthe malicious training data, i.e., generating a subgraph sequence as the\ntrigger and embedding it to the training data. However, the vulnerability of\nDLP toward backdoor attacks has not been studied yet. To address the issue, we\npropose a novel backdoor attack framework on DLP, denoted as Dyn-Backdoor.\nSpecifically, Dyn-Backdoor generates diverse initial-triggers by a generative\nadversarial network (GAN). Then partial links of the initial-triggers are\nselected to form a trigger set, according to the gradient information of the\nattack discriminator in the GAN, so as to reduce the size of triggers and\nimprove the concealment of the attack. Experimental results show that\nDyn-Backdoor launches successful backdoor attacks on the state-of-the-art DLP\nmodels with success rate more than 90%. Additionally, we conduct a possible\ndefense against Dyn-Backdoor to testify its resistance in defensive settings,\nhighlighting the needs of defenses for backdoor attacks on DLP.",
    "descriptor": "\nComments: 11 pages,6 figures\n",
    "authors": [
      "Jinyin Chen",
      "Haiyang Xiong",
      "Haibin Zheng",
      "Jian Zhang",
      "Guodong Jiang",
      "Yi Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.03875"
  },
  {
    "id": "arXiv:2110.03876",
    "title": "Phone-to-audio alignment without text: A Semi-supervised Approach",
    "abstract": "The task of phone-to-audio alignment has many applications in speech\nresearch. Here we introduce two Wav2Vec2-based models for both text-dependent\nand text-independent phone-to-audio alignment. The proposed Wav2Vec2-FS, a\nsemi-supervised model, directly learns phone-to-audio alignment through\ncontrastive learning and a forward sum loss, and can be coupled with a\npretrained phone recognizer to achieve text-independent alignment. The other\nmodel, Wav2Vec2-FC, is a frame classification model trained on forced aligned\nlabels that can both perform forced alignment and text-independent\nsegmentation. Evaluation results suggest that both proposed methods, even when\ntranscriptions are not available, generate highly close results to existing\nforced alignment tools. Our work presents a neural pipeline of fully automated\nphone-to-audio alignment. Code and pretrained models are available at\nhttps://github.com/lingjzhu/charsiu.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Jian Zhu",
      "Cong Zhang",
      "David Jurgens"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.03876"
  },
  {
    "id": "arXiv:2110.03878",
    "title": "GEO satellites on-orbit repairing mission planning with mission deadline  constraint using a large neighborhood search-genetic algorithm",
    "abstract": "This paper proposed a novel large neighborhood search-adaptive genetic\nalgorithm (LNS-AGA) for many-to-many on-orbit repairing mission planning of\ngeosynchronous orbit (GEO) satellites with mission deadline constraint. In the\nmany-to-many on-orbit repairing scenario, several servicing spacecrafts and\ntarget satellites are located in GEO orbits which have different inclination,\nRAAN and true anomaly. Each servicing spacecraft need to rendezvous with target\nsatellites to perform repairing missions under limited fuel. The mission\nobjective is to find the optimal servicing sequence and orbit rendezvous time\nof every servicing spacecraft to minimize total cost of all servicing\nspacecrafts with all target satellites repaired. Firstly, a time-dependent\norbital rendezvous strategy is proposed, which can handle the mission deadline\nconstraint. Besides, it is also cost-effective compared with the existing\nstrategy. Based on this strategy, the many-to-many on-orbit repairing mission\nplanning model can be simplified to an integer programming problem, which is\nestablished based on the vehicle routing problem with time windows (VRPTW)\nmodel. In order to efficiently find a feasible optimal solution under\ncomplicated constraints, a hybrid adaptive genetic algorithm combining the\nlarge neighborhood search procedure is designed. The operations of \"destroy\"\nand \"repair\" are used on the elite individuals in each generation of the\ngenetic algorithm to enhance local search capabilities. Finally, the\nsimulations under different scenarios are carried out to verify the\neffectiveness of the presented algorithm and orbital rendezvous strategy, which\nperforms better than the traditional genetic algorithm.",
    "descriptor": "",
    "authors": [
      "Peng Han",
      "Yanning Guo",
      "Chuanjiang Li",
      "Hui Zhi",
      "Yueyong Lv"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.03878"
  },
  {
    "id": "arXiv:2110.03879",
    "title": "Explaining the Attention Mechanism of End-to-End Speech Recognition  Using Decision Trees",
    "abstract": "The attention mechanism has largely improved the performance of end-to-end\nspeech recognition systems. However, the underlying behaviours of attention is\nnot yet clearer. In this study, we use decision trees to explain how the\nattention mechanism impact itself in speech recognition. The results indicate\nthat attention levels are largely impacted by their previous states rather than\nthe encoder and decoder patterns. Additionally, the default attention mechanism\nseems to put more weights on closer states, but behaves poorly on modelling\nlong-term dependencies of attention states.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Yuanchao Wang",
      "Wenji Du",
      "Chenghao Cai",
      "Yanyan Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.03879"
  },
  {
    "id": "arXiv:2110.03880",
    "title": "Joint Scatterer Localization and Material Identification Using Radio  Access Technology",
    "abstract": "Cellular network technologies and radar sensing technologies have been\ndeveloping in parallel for decades. Instead of developing two individual\ntechnologies, the 6G cellular network is expected to naturally support both\ncommunication and radar functionalities with shared hardware and carrier\nfrequencies. In this regard, radio access technology (RAT)-based scatterer\nlocalization system is one of the important aspects of joint communication and\nsensing system (JCAS) that uses communication signals between transceivers to\ndetermine the location of scatterers in and around the propagation paths. In\nthis article, we first identify the challenges of RAT-based scatterer\nlocalization system, then present single- and multiple-bounce reflection loss\n(RL) simulation results for three common building materials in indoor\nenvironments. We also propose two novel methods to jointly localize and\nidentify the type of the scatterers in a rich scattering environment.",
    "descriptor": "\nComments: 11 pages, submitted to Special Issue \"Wireless Technologies towards 6G\" of the EURASIP Journal on Wireless Communications and Networking\n",
    "authors": [
      "Yi Geng",
      "Deep Shrestha",
      "Vijaya Yajnanarayana",
      "Erik Dahlman",
      "Ali Behravan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.03880"
  },
  {
    "id": "arXiv:2110.03881",
    "title": "An infinite family of antiprimitive cyclic codes supporting Steiner  systems $S(3,8, 7^m+1)$",
    "abstract": "Coding theory and combinatorial $t$-designs have close connections and\ninteresting interplay. One of the major approaches to the construction of\ncombinatorial t-designs is the employment of error-correcting codes. As we all\nknown, some $t$-designs have been constructed with this approach by using\ncertain linear codes in recent years. However, only a few infinite families of\ncyclic codes holding an infinite family of $3$-designs are reported in the\nliterature. The objective of this paper is to study an infinite family of\ncyclic codes and determine their parameters. By the parameters of these codes\nand their dual, some infinite family of $3$-designs are presented and their\nparameters are also explicitly determined. In particular, the complements of\nthe supports of the minimum weight codewords in the studied cyclic code form a\nSteiner system. Furthermore, we show that the infinite family of cyclic codes\nadmit $3$-transitive automorphism groups.",
    "descriptor": "",
    "authors": [
      "Can Xiang",
      "Chunming Tang",
      "Qi Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.03881"
  },
  {
    "id": "arXiv:2110.03882",
    "title": "ModeRNN: Harnessing Spatiotemporal Mode Collapse in Unsupervised  Predictive Learning",
    "abstract": "Learning predictive models for unlabeled spatiotemporal data is challenging\nin part because visual dynamics can be highly entangled in real scenes, making\nexisting approaches prone to overfit partial modes of physical processes while\nneglecting to reason about others. We name this phenomenon spatiotemporal mode\ncollapse and explore it for the first time in predictive learning. The key is\nto provide the model with a strong inductive bias to discover the compositional\nstructures of latent modes. To this end, we propose ModeRNN, which introduces a\nnovel method to learn structured hidden representations between recurrent\nstates. The core idea of this framework is to first extract various components\nof visual dynamics using a set of spatiotemporal slots with independent\nparameters. Considering that multiple space-time patterns may co-exist in a\nsequence, we leverage learnable importance weights to adaptively aggregate slot\nfeatures into a unified hidden representation, which is then used to update the\nrecurrent states. Across the entire dataset, different modes result in\ndifferent responses on the mixtures of slots, which enhances the ability of\nModeRNN to build structured representations and thus prevents the so-called\nmode collapse. Unlike existing models, ModeRNN is shown to prevent\nspatiotemporal mode collapse and further benefit from learning mixed visual\ndynamics.",
    "descriptor": "",
    "authors": [
      "Zhiyu Yao",
      "Yunbo Wang",
      "Haixu Wu",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03882"
  },
  {
    "id": "arXiv:2110.03883",
    "title": "Charge capacity characteristics of a Lithium Nickel-Cobalt-Aluminium  Oxide battery show fractional-derivative behavior",
    "abstract": "Batteries experience capacity offset where available charge depends on the\nrate at which this charge is drawn. In this work we analyze the capacity offset\nof a 4.8 A h lithium nickel-cobalt-aluminium oxide battery using an equivalent\ncircuit model of a fractional capacitor in series with a resistor. In this\ncase, the available charge, in theory, becomes infinite in the limit of\ninfinitesimal rate. We show that the fractional properties of the capacitor can\nbe extracted from the charge against rate plot. We then use a network of RC\nelements to represent the fractional capacitor in order to simulate the data\nwith Matlab. We find that the fractional exponent alpha obtained in this way,\n0.971, agrees with that obtained in a more traditional manner from an impedance\nversus frequency plot, although the fractional capacity does not. Such an\napproach demonstrates the importance of a fractional description for capacity\noffset even when an element is nearly a pure capacitor and is valuable for\npredictions of state-of-charge when low currents are drawn.",
    "descriptor": "\nComments: 15 pages, 5 figures\n",
    "authors": [
      "Marcus T. Wilson",
      "Vance Farrow",
      "Caleb Pyne",
      "Jonathan Scott"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.03883"
  },
  {
    "id": "arXiv:2110.03888",
    "title": "M6-10T: A Sharing-Delinking Paradigm for Efficient Multi-Trillion  Parameter Pretraining",
    "abstract": "Recent expeditious developments in deep learning algorithms, distributed\ntraining, and even hardware design for large models have enabled training\nextreme-scale models, say GPT-3 and Switch Transformer possessing hundreds of\nbillions or even trillions of parameters. However, under limited resources,\nextreme-scale model training that requires enormous amounts of computes and\nmemory footprint suffers from frustratingly low efficiency in model\nconvergence. In this paper, we propose a simple training strategy called\n\"Pseudo-to-Real\" for high-memory-footprint-required large models.\nPseudo-to-Real is compatible with large models with architecture of sequential\nlayers. We demonstrate a practice of pretraining unprecedented\n10-trillion-parameter model, an order of magnitude larger than the\nstate-of-the-art, on solely 512 GPUs within 10 days. Besides demonstrating the\napplication of Pseudo-to-Real, we also provide a technique, Granular CPU\noffloading, to manage CPU memory for training large model and maintain high GPU\nutilities. Fast training of extreme-scale models on a decent amount of\nresources can bring much smaller carbon footprint and contribute to greener AI.",
    "descriptor": "\nComments: 14 pages, 4 figures\n",
    "authors": [
      "Junyang Lin",
      "An Yang",
      "Jinze Bai",
      "Chang Zhou",
      "Le Jiang",
      "Xianyan Jia",
      "Ang Wang",
      "Jie Zhang",
      "Yong Li",
      "Wei Lin",
      "Jingren Zhou",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.03888"
  },
  {
    "id": "arXiv:2110.03889",
    "title": "A Decision Model for Selecting Patterns and Strategies to Decompose  Applications into Microservices",
    "abstract": "Microservices Architecture (MSA) style is a promising design approach to\ndevelop software applications consisting of multiple small and independently\ndeployable services. Over the past few years, researchers and practitioners\nhave proposed many MSA patterns and strategies covering various aspects of\nmicroservices design, such as application decomposition. However, selecting\nappropriate patterns and strategies can entail various challenges for\npractitioners. To this end, this study proposes a decision model for selecting\npatterns and strategies to decompose applications into microservices. We used\npeer-reviewed and grey literature to collect the patterns, strategies, and\nquality attributes for creating this decision model.",
    "descriptor": "\nComments: The 19th International Conference on Service Oriented Computing (ICSOC)\n",
    "authors": [
      "Muhammad Waseem",
      "Peng Liang",
      "Gast\u00f3n M\u00e1rquez",
      "Mojtaba Shahin",
      "Arif Ali Khan",
      "Aakash Ahmad"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.03889"
  },
  {
    "id": "arXiv:2110.03891",
    "title": "Momentum Doesn't Change the Implicit Bias",
    "abstract": "The momentum acceleration technique is widely adopted in many optimization\nalgorithms. However, the theoretical understanding of how the momentum affects\nthe generalization performance of the optimization algorithms is still unknown.\nIn this paper, we answer this question through analyzing the implicit bias of\nmomentum-based optimization. We prove that both SGD with momentum and Adam\nconverge to the $L_2$ max-margin solution for exponential-tailed loss, which is\nthe same as vanilla gradient descent. That means, these optimizers with\nmomentum acceleration still converge to a model with low complexity, which\nprovides guarantees on their generalization. Technically, to overcome the\ndifficulty brought by the error accumulation in analyzing the momentum, we\nconstruct new Lyapunov functions as a tool to analyze the gap between the model\nparameter and the max-margin solution.",
    "descriptor": "",
    "authors": [
      "Bohan Wang",
      "Qi Meng",
      "Huishuai Zhang",
      "Ruoyu Sun",
      "Wei Chen",
      "Zhi-Ming Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.03891"
  },
  {
    "id": "arXiv:2110.03892",
    "title": "BDC: Bounding-Box Deep Calibration for High Performance Face Detection",
    "abstract": "Modern CNN-based face detectors have achieved tremendous strides due to large\nannotated datasets. However, misaligned results with high detection confidence\nbut low localization accuracy restrict the further improvement of detection\nperformance. In this paper, we first generate detection results on training set\nitself. Surprisingly, a considerable part of them exist the same misalignment\nproblem. Then, we carefully examine these misaligned cases and point out\nannotation inconsistency is the main reason. Finally, we propose a novel\nBounding-Box Deep Calibration (BDC) method to reasonably replace inconsistent\nannotations with model predicted bounding-boxes and create a new annotation\nfile for training set. Extensive experiments on WIDER FACE dataset show the\neffectiveness of BDC on improving models' precision and recall rate. Our simple\nand effective method provides a new direction for improving face detection.\nSource code is available at https://github.com/shiluo1990/BDC.",
    "descriptor": "\nComments: 8 pages, 4 figures, 2 tables, 1 algorithm, 2 equation, 1 definition\n",
    "authors": [
      "Shi Luo",
      "Xiongfei Li",
      "Xiaoli Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03892"
  },
  {
    "id": "arXiv:2110.03895",
    "title": "ALL-IN-ONE: Multi-Task Learning BERT models for Evaluating Peer  Assessments",
    "abstract": "Peer assessment has been widely applied across diverse academic fields over\nthe last few decades and has demonstrated its effectiveness. However, the\nadvantages of peer assessment can only be achieved with high-quality peer\nreviews. Previous studies have found that high-quality review comments usually\ncomprise several features (e.g., contain suggestions, mention problems, use a\npositive tone). Thus, researchers have attempted to evaluate peer-review\ncomments by detecting different features using various machine learning and\ndeep learning models. However, there is no single study that investigates using\na multi-task learning (MTL) model to detect multiple features simultaneously.\nThis paper presents two MTL models for evaluating peer-review comments by\nleveraging the state-of-the-art pre-trained language representation models BERT\nand DistilBERT. Our results demonstrate that BERT-based models significantly\noutperform previous GloVe-based methods by around 6% in F1-score on tasks of\ndetecting a single feature, and MTL further improves performance while reducing\nmodel size.",
    "descriptor": "",
    "authors": [
      "Qinjin Jia",
      "Jialin Cui",
      "Yunkai Xiao",
      "Chengyuan Liu",
      "Parvez Rashid",
      "Edward F. Gehringer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.03895"
  },
  {
    "id": "arXiv:2110.03900",
    "title": "Neural Strokes: Stylized Line Drawing of 3D Shapes",
    "abstract": "This paper introduces a model for producing stylized line drawings from 3D\nshapes. The model takes a 3D shape and a viewpoint as input, and outputs a\ndrawing with textured strokes, with variations in stroke thickness,\ndeformation, and color learned from an artist's style. The model is fully\ndifferentiable. We train its parameters from a single training drawing of\nanother 3D shape. We show that, in contrast to previous image-based methods,\nthe use of a geometric representation of 3D shape and 2D strokes allows the\nmodel to transfer important aspects of shape and texture style while preserving\ncontours. Our method outputs the resulting drawing in a vector representation,\nenabling richer downstream analysis or editing in interactive applications.",
    "descriptor": "\nComments: Accepted to ICCV 2021\n",
    "authors": [
      "Difan Liu",
      "Matthew Fisher",
      "Aaron Hertzmann",
      "Evangelos Kalogerakis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.03900"
  },
  {
    "id": "arXiv:2110.03901",
    "title": "Characterizing and Demystifying the Implicit Convolution Algorithm on  Commercial Matrix-Multiplication Accelerators",
    "abstract": "Many of today's deep neural network accelerators, e.g., Google's TPU and\nNVIDIA's tensor core, are built around accelerating the general matrix\nmultiplication (i.e., GEMM). However, supporting convolution on GEMM-based\naccelerators is not trivial. The naive method explicitly lowers the convolution\nto GEMM, commonly known as im2col, which introduces significant performance and\nmemory overhead. Existing implicit im2col algorithms require unscalable\nhardware and are inefficient in supporting important convolution variants such\nas strided convolution. In this paper, we propose a memory-efficient and\nhardware-friendly implicit im2col algorithm used by Google's TPU, which\ndynamically converts a convolution into a GEMM with practically zero\nperformance and memory overhead, fully unleashing the power of GEMM engines.\nThrough comprehensive experimental results, we quantitatively argue that this\nalgorithm has been adopted in commercial closed-source platforms, and we are\nthe first to describe its high-level idea and implementation details. Finally,\nwe show that our algorithm can also be generally applied to Nvidia's Tensor\nCores (TC), matching and out-performing the measured performance on TCs.",
    "descriptor": "",
    "authors": [
      "Yangjie Zhou",
      "Mengtian Yang",
      "Cong Guo",
      "Jingwen Leng",
      "Yun Liang",
      "Quan Chen",
      "Minyi Guo",
      "Yuhao Zhu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.03901"
  },
  {
    "id": "arXiv:2110.03902",
    "title": "Multi-trends Enhanced Dynamic Micro-video Recommendation",
    "abstract": "The explosively generated micro-videos on content sharing platforms call for\nrecommender systems to permit personalized micro-video discovery with ease.\nRecent advances in micro-video recommendation have achieved remarkable\nperformance in mining users' current preference based on historical behaviors.\nHowever, most of them neglect the dynamic and time-evolving nature of users'\npreference, and the prediction on future micro-videos with historically mined\npreference may deteriorate the effectiveness of recommender systems. In this\npaper, we propose the DMR framework to explicitly model dynamic multi-trends of\nusers' current preference and make predictions based on both the history and\nfuture potential trends. We devise the DMR framework, which comprises: 1) the\nimplicit user network module which identifies sequence fragments from other\nusers with similar interests and extracts the sequence fragments that are\nchronologically behind the identified fragments; 2) the multi-trend routing\nmodule which assigns each extracted sequence fragment into a trend group and\nupdate the corresponding trend vector; 3) the history-future trend prediction\nmodule jointly uses the history preference vectors and future trend vectors to\nyield the final click-through-rate. We validate the effectiveness of DMR over\nmultiple state-of-the-art micro-video recommenders on two publicly available\nreal-world datasets. Relatively extensive analysis further demonstrate the\nsuperiority of modeling dynamic multi-trend for micro-video recommendation.",
    "descriptor": "\nComments: 11 pages, 2 figures\n",
    "authors": [
      "Yujie Lu",
      "Yingxuan Huang",
      "Shengyu Zhang",
      "Wei Han",
      "Hui Chen",
      "Zhou Zhao",
      "Fei Wu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.03902"
  },
  {
    "id": "arXiv:2110.03903",
    "title": "Kinematically consistent recurrent neural networks for learning inverse  problems in wave propagation",
    "abstract": "Although machine learning (ML) is increasingly employed recently for\nmechanistic problems, the black-box nature of conventional ML architectures\nlacks the physical knowledge to infer unforeseen input conditions. This implies\nboth severe overfitting during a dearth of training data and inadequate\nphysical interpretability, which motivates us to propose a new kinematically\nconsistent, physics-based ML model. In particular, we attempt to perform\nphysically interpretable learning of inverse problems in wave propagation\nwithout suffering overfitting restrictions. Towards this goal, we employ long\nshort-term memory (LSTM) networks endowed with a physical,\nhyperparameter-driven regularizer, performing penalty-based enforcement of the\ncharacteristic geometries. Since these characteristics are the kinematical\ninvariances of wave propagation phenomena, maintaining their structure provides\nkinematical consistency to the network. Even with modest training data, the\nkinematically consistent network can reduce the $L_1$ and $L_\\infty$ error\nnorms of the plain LSTM predictions by about 45% and 55%, respectively. It can\nalso increase the horizon of the plain LSTM's forecasting by almost two times.\nTo achieve this, an optimal range of the physical hyperparameter, analogous to\nan artificial bulk modulus, has been established through numerical experiments.\nThe efficacy of the proposed method in alleviating overfitting, and the\nphysical interpretability of the learning mechanism, are also discussed. Such\nan application of kinematically consistent LSTM networks for wave propagation\nlearning is presented here for the first time.",
    "descriptor": "",
    "authors": [
      "Wrik Mallik",
      "Rajeev K. Jaiman",
      "Jasmin Jelovica"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2110.03903"
  },
  {
    "id": "arXiv:2110.03904",
    "title": "E-learning model for art education: Case study in Iran",
    "abstract": "According to the characteristics of art, art education according to Bloom's\nclassification, should take place at high and close to the level of creativity.\nE-learning related to the subject of art is different from ordinary E-learning.\nIn this paper, a general circular model for E-learning for art education is\npresented, a case study which has been done in Iran among students and artists.\nArt in the general sense, in addition to the same and Comprehensive features,\nhas characteristics specific to different countries and cultures, and\nconsequently there are differences in art education.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Bahram Sadeghi Bigham",
      "Mahboubeh Fannakhosrow",
      "Aliakbar Safipour",
      "Mostafa Jafari",
      "Khadijeh Chenari"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.03904"
  },
  {
    "id": "arXiv:2110.03905",
    "title": "COVID-19 Monitoring System using Social Distancing and Face Mask  Detection on Surveillance video datasets",
    "abstract": "In the current times, the fear and danger of COVID-19 virus still stands\nlarge. Manual monitoring of social distancing norms is impractical with a large\npopulation moving about and with insufficient task force and resources to\nadminister them. There is a need for a lightweight, robust and 24X7\nvideo-monitoring system that automates this process. This paper proposes a\ncomprehensive and effective solution to perform person detection, social\ndistancing violation detection, face detection and face mask classification\nusing object detection, clustering and Convolution Neural Network (CNN) based\nbinary classifier. For this, YOLOv3, Density-based spatial clustering of\napplications with noise (DBSCAN), Dual Shot Face Detector (DSFD) and\nMobileNetV2 based binary classifier have been employed on surveillance video\ndatasets. This paper also provides a comparative study of different face\ndetection and face mask classification models. Finally, a video dataset\nlabelling method is proposed along with the labelled video dataset to\ncompensate for the lack of dataset in the community and is used for evaluation\nof the system. The system performance is evaluated in terms of accuracy, F1\nscore as well as the prediction time, which has to be low for practical\napplicability. The system performs with an accuracy of 91.2% and F1 score of\n90.79% on the labelled video dataset and has an average prediction time of 7.12\nseconds for 78 frames of a video.",
    "descriptor": "",
    "authors": [
      "Rujula Singh R",
      "Nikhil Nayak",
      "Sahana Srinivasan",
      "Ruchita Biradar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03905"
  },
  {
    "id": "arXiv:2110.03906",
    "title": "Nash Convergence of Mean-Based Learning Algorithms in First Price  Auctions",
    "abstract": "We consider repeated first price auctions where each bidder, having a\ndeterministic type, learns to bid using a mean-based learning algorithm. We\ncompletely characterize the Nash convergence property of the bidding dynamics\nin two senses: (1) time-average: the fraction of rounds where bidders play a\nNash equilibrium approaches to 1 in the limit; (2) last-iterate: the mixed\nstrategy profile of bidders approaches to a Nash equilibrium in the limit.\nSpecifically, the results depend on the number of bidders with the highest\nvalue: - If the number is at least three, the bidding dynamics almost surely\nconverges to a Nash equilibrium of the auction, both in time-average and in\nlast-iterate. - If the number is two, the bidding dynamics almost surely\nconverges to a Nash equilibrium in time-average but not necessarily in\nlast-iterate. - If the number is one, the bidding dynamics may not converge to\na Nash equilibrium in time-average nor in last-iterate. Our discovery opens up\nnew possibilities in the study of convergence dynamics of learning algorithms.",
    "descriptor": "\nComments: 36 pages, 4 figures\n",
    "authors": [
      "Xiaotie Deng",
      "Xinyan Hu",
      "Tao Lin",
      "Weiqiang Zheng"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2110.03906"
  },
  {
    "id": "arXiv:2110.03909",
    "title": "Meta-Learning with Task-Adaptive Loss Function for Few-Shot Learning",
    "abstract": "In few-shot learning scenarios, the challenge is to generalize and perform\nwell on new unseen examples when only very few labeled examples are available\nfor each task. Model-agnostic meta-learning (MAML) has gained the popularity as\none of the representative few-shot learning methods for its flexibility and\napplicability to diverse problems. However, MAML and its variants often resort\nto a simple loss function without any auxiliary loss function or regularization\nterms that can help achieve better generalization. The problem lies in that\neach application and task may require different auxiliary loss function,\nespecially when tasks are diverse and distinct. Instead of attempting to\nhand-design an auxiliary loss function for each application and task, we\nintroduce a new meta-learning framework with a loss function that adapts to\neach task. Our proposed framework, named Meta-Learning with Task-Adaptive Loss\nFunction (MeTAL), demonstrates the effectiveness and the flexibility across\nvarious domains, such as few-shot classification and few-shot regression.",
    "descriptor": "\nComments: ICCV 2021 (Oral). Code at this https URL\n",
    "authors": [
      "Sungyong Baik",
      "Janghoon Choi",
      "Heewon Kim",
      "Dohee Cho",
      "Jaesik Min",
      "Kyoung Mu Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03909"
  },
  {
    "id": "arXiv:2110.03910",
    "title": "Inertial Modified S-Iteration Process for Split Monotone Inclusion and  Fixed Point Problem In Real Hilbert Space",
    "abstract": "In this article we present a modified S-iteration process that we combine\nwith inertial extrapolation to find a common solution to the split monotone\ninclusion problem and the fixed point problem in real Hilbert space.Our goal is\nto establish a strong convergence theorem for approximating a common\nsolution.Under some mild conditions,the problem can be solved. We also provide\na numerical example to show that our algorithms acceleration works well.",
    "descriptor": "\nComments: 13 pages,1 figure ,1 table\n",
    "authors": [
      "Shamshad Husain",
      "Uqba Rafat"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2110.03910"
  },
  {
    "id": "arXiv:2110.03912",
    "title": "Stereo Dense Scene Reconstruction and Accurate Laparoscope Localization  for Learning-Based Navigation in Robot-Assisted Surgery",
    "abstract": "The computation of anatomical information and laparoscope position is a\nfundamental block of robot-assisted surgical navigation in Minimally Invasive\nSurgery (MIS). Recovering a dense 3D structure of surgical scene using visual\ncues remains a challenge, and the online laparoscopic tracking mostly relies on\nexternal sensors, which increases system complexity. In this paper, we propose\na learning-driven framework, in which an image-guided laparoscopic localization\nwith 3D reconstructions of complex anatomical structures is hereby achieved. To\nreconstruct the 3D structure of the whole surgical environment, we first\nfine-tune a learning-based stereoscopic depth perception method, which is\nrobust to the texture-less and variant soft tissues, for depth estimation.\nThen, we develop a dense visual reconstruction algorithm to represent the scene\nby surfels, estimate the laparoscope pose and fuse the depth data into a\nunified reference coordinate for tissue reconstruction. To estimate poses of\nnew laparoscope views, we realize a coarse-to-fine localization method, which\nincorporates our reconstructed 3D model. We evaluate the reconstruction method\nand the localization module on three datasets, namely, the stereo\ncorrespondence and reconstruction of endoscopic data (SCARED), the ex-vivo\nphantom and tissue data collected with Universal Robot (UR) and Karl Storz\nLaparoscope, and the in-vivo DaVinci robotic surgery dataset. Extensive\nexperiments have been conducted to prove the superior performance of our method\nin 3D anatomy reconstruction and laparoscopic localization, which demonstrates\nits potential implementation to surgical navigation system.",
    "descriptor": "",
    "authors": [
      "Ruofeng Wei",
      "Bin Li",
      "Hangjie Mo",
      "Bo Lu",
      "Yonghao Long",
      "Bohan Yang",
      "Qi Dou",
      "Yunhui Liu",
      "Dong Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.03912"
  },
  {
    "id": "arXiv:2110.03915",
    "title": "Optimal QoS-Aware Network slicing for Service-oriented Networks with  Flexible Routing",
    "abstract": "In this paper, we consider the network slicing problem which attempts to map\nmultiple customized virtual network requests (also called services) to a common\nshared network infrastructure and allocate network resources to meet diverse\nquality of service (QoS) requirements. We first propose a mixed integer\nnonlinear program (MINLP) formulation for this problem that optimizes the\nnetwork resource consumption while jointly considers QoS requirements, flow\nrouting, and resource budget constraints. In particular, the proposed\nformulation is able to flexibly route the traffic flow of the services on\nmultiple paths and provide end-to-end (E2E) delay and reliability guarantees\nfor all services. Due to the intrinsic nonlinearity, the MINLP formulation is\ncomputationally difficult to solve. To overcome this difficulty, we then\npropose a mixed integer linear program (MILP) formulation and show that the two\nformulations and their continuous relaxations are equivalent. Different from\nthe continuous relaxation of the MINLP formulation which is a nonconvex\nnonlinear programming problem, the continuous relaxation of the MILP\nformulation is a polynomial time solvable linear programming problem, which\nmakes the MILP formulation much more computationally solvable. Numerical\nresults demonstrate the effectiveness and efficiency of the proposed\nformulations over existing ones.",
    "descriptor": "\nComments: 5 pages, 2 figures, submitted for possible publication\n",
    "authors": [
      "Wei-Kun Chen",
      "Ya-Feng Liu",
      "Yu-Hong Dai",
      "Zhi-Quan Luo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.03915"
  },
  {
    "id": "arXiv:2110.03916",
    "title": "SCFlow: Optical Flow Estimation for Spiking Camera",
    "abstract": "As a bio-inspired sensor with high temporal resolution, Spiking camera has an\nenormous potential in real applications, especially for motion estimation in\nhigh-speed scenes. Optical flow estimation has achieved remarkable success in\nimage-based and event-based vision, but % existing methods cannot be directly\napplied in spike stream from spiking camera. conventional optical flow\nalgorithms are not well matched to the spike stream data. This paper presents,\nSCFlow, a novel deep learning pipeline for optical flow estimation for spiking\ncamera. Importantly, we introduce an proper input representation of a given\nspike stream, which is fed into SCFlow as the sole input. We introduce the\n\\textit{first} spiking camera simulator (SPCS). Furthermore, based on SPCS, we\nfirst propose two optical flow datasets for spiking camera (SPIkingly Flying\nThings and Photo-realistic High-speed Motion, denoted as SPIFT and PHM\nrespectively) corresponding to random high-speed and well-designed scenes.\nEmpirically, we show that the SCFlow can predict optical flow from spike stream\nin different high-speed scenes, and express superiority to existing methods on\nthe datasets. \\textit{All codes and constructed datasets will be released after\npublication}.",
    "descriptor": "\nComments: The first two authors contributed equally\n",
    "authors": [
      "Liwen Hu",
      "Rui Zhao",
      "Ziluo Ding",
      "Ruiqin Xiong",
      "Lei Ma",
      "Tiejun Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03916"
  },
  {
    "id": "arXiv:2110.03921",
    "title": "ViDT: An Efficient and Effective Fully Transformer-based Object Detector",
    "abstract": "Transformers are transforming the landscape of computer vision, especially\nfor recognition tasks. Detection transformers are the first fully end-to-end\nlearning systems for object detection, while vision transformers are the first\nfully transformer-based architecture for image classification. In this paper,\nwe integrate Vision and Detection Transformers (ViDT) to build an effective and\nefficient object detector. ViDT introduces a reconfigured attention module to\nextend the recent Swin Transformer to be a standalone object detector, followed\nby a computationally efficient transformer decoder that exploits multi-scale\nfeatures and auxiliary techniques essential to boost the detection performance\nwithout much increase in computational load. Extensive evaluation results on\nthe Microsoft COCO benchmark dataset demonstrate that ViDT obtains the best AP\nand latency trade-off among existing fully transformer-based object detectors,\nand achieves 49.2AP owing to its high scalability for large models. We will\nrelease the code and trained models athttps://github.com/naver-ai/vidt",
    "descriptor": "",
    "authors": [
      "Hwanjun Song",
      "Deqing Sun",
      "Sanghyuk Chun",
      "Varun Jampani",
      "Dongyoon Han",
      "Byeongho Heo",
      "Wonjae Kim",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03921"
  },
  {
    "id": "arXiv:2110.03922",
    "title": "Neural Tangent Kernel Eigenvalues Accurately Predict Generalization",
    "abstract": "Finding a quantitative theory of neural network generalization has long been\na central goal of deep learning research. We extend recent results to\ndemonstrate that, by examining the eigensystem of a neural network's \"neural\ntangent kernel\", one can predict its generalization performance when learning\narbitrary functions. Our theory accurately predicts not only test\nmean-squared-error but all first- and second-order statistics of the network's\nlearned function. Furthermore, using a measure quantifying the \"learnability\"\nof a given target function, we prove a new \"no-free-lunch\" theorem\ncharacterizing a fundamental tradeoff in the inductive bias of wide neural\nnetworks: improving a network's generalization for a given target function must\nworsen its generalization for orthogonal functions. We further demonstrate the\nutility of our theory by analytically predicting two surprising phenomena -\nworse-than-chance generalization on hard-to-learn functions and nonmonotonic\nerror curves in the small data regime - which we subsequently observe in\nexperiments. Though our theory is derived for infinite-width architectures, we\nfind it agrees with networks as narrow as width 20, suggesting it is predictive\nof generalization in practical neural networks. Code replicating our results is\navailable at https://github.com/james-simon/eigenlearning .",
    "descriptor": "\nComments: 9 pages (main text), 23 pages (total), 10 figures\n",
    "authors": [
      "James B. Simon",
      "Madeline Dickens",
      "Michael R. DeWeese"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.03922"
  },
  {
    "id": "arXiv:2110.03924",
    "title": "Directionally Decomposing Structured Light for Projector Calibration",
    "abstract": "Intrinsic projector calibration is essential in projection mapping (PM)\napplications, especially in dynamic PM. However, due to the shallow\ndepth-of-field (DOF) of a projector, more work is needed to ensure accurate\ncalibration. We aim to estimate the intrinsic parameters of a projector while\navoiding the limitation of shallow DOF. As the core of our technique, we\npresent a practical calibration device that requires a minimal working volume\ndirectly in front of the projector lens regardless of the projector's focusing\ndistance and aperture size. The device consists of a flat-bed scanner and\npinhole-array masks. For calibration, a projector projects a series of\nstructured light patterns in the device. The pinholes directionally decompose\nthe structured light, and only the projected rays that pass through the\npinholes hit the scanner plane. For each pinhole, we extract a ray passing\nthrough the optical center of the projector. Consequently, we regard the\nprojector as a pinhole projector that projects the extracted rays only, and we\ncalibrate the projector by applying the standard camera calibration technique,\nwhich assumes a pinhole camera model. Using a proof-of-concept prototype, we\ndemonstrate that our technique can calibrate projectors with different focusing\ndistances and aperture sizes at the same accuracy as a conventional method.\nFinally, we confirm that our technique can provide intrinsic parameters\naccurate enough for a dynamic PM application, even when a projector is placed\ntoo far from a projection target for a conventional method to calibrate the\nprojector using a fiducial object of reasonable size.",
    "descriptor": "",
    "authors": [
      "Masatoki Sugimoto",
      "Daisuke Iwai",
      "Koki Ishida",
      "Parinya Punpongsanon",
      "Kosuke Sato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.03924"
  },
  {
    "id": "arXiv:2110.03933",
    "title": "Towards Creating a Standardized Collection of Simple and Targeted  Experiments to Analyze Core Aspects of the Recommender Systems Problem",
    "abstract": "Imagine you are a teacher attempting to assess a student's level in a\nparticular subject. If you design a test with only hard questions, and the\nstudent fails, this mostly proves that the student does not understand the more\nadvanced material. A more insightful exam would include different types of\nquestions varying in difficulty to truly understand the student's weaknesses\nand strengths from different perspectives. In the field of Recommender Systems\n(RS), more often than not, we design evaluations to measure an algorithm's\nability to optimize goals in complex scenarios, representative of the\nreal-world challenges the system would most probably face. Nevertheless, this\npaper posits that testing an algorithm's ability to address both simple and\ncomplex tasks/problems would offer a more detailed view of performance to help\nidentify, at a more granular level, the weaknesses and strengths of solutions\nwhen facing different scenarios/domains. We believe the RS community would\ngreatly benefit from creating a collection of standardized, simple, and\ntargeted experiments, which, much like a suite of \"unit tests\", would\nindividually assess an algorithm's ability to tackle core challenges that make\nup complex RS tasks. What's more, these experiments go beyond traditional\npass/fail \"unit tests\". Running an algorithm against the collection of\nexperiments allows a researcher to empirically analyze in which type of\nsettings an algorithm performs best and to what degree under different metrics.\nNot only do we defend this position, in this paper, we also offer a proposal of\nhow these simple and targeted experiments could be defined and shared and\nsuggest potential next steps to make this project a reality.",
    "descriptor": "\nComments: Accepted to SimuRec'21: Workshop on Simulation Methods for Recommender Systems at ACM RecSys'21, October 2nd, 2021\n",
    "authors": [
      "Andrea Barraza-Urbina"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.03933"
  },
  {
    "id": "arXiv:2110.03937",
    "title": "Proposal of Analog In-Memory Computing with Magnified Tunnel  Magnetoresistance Ratio and Universal STT-MRAM Cell",
    "abstract": "In-memory computing (IMC) is an effectual solution for energy-efficient\nartificial intelligence applications. Analog IMC amortizes the power\nconsumption of multiple sensing amplifiers with analog-to-digital converter\n(ADC), and simultaneously completes the calculation of multi-line data with\nhigh parallelism degree. Based on a universal one-transistor one-magnetic\ntunnel junction (MTJ) spin transfer torque magnetic RAM (STT-MRAM) cell, this\npaper demonstrates a novel tunneling magnetoresistance (TMR) ratio magnifying\nmethod to realize analog IMC. Previous concerns include low TMR ratio and\nanalog calculation nonlinearity are addressed using device-circuit interaction.\nPeripheral circuits are minimally modified to enable in-memory matrix-vector\nmultiplication. A current mirror with feedback structure is implemented to\nenhance analog computing linearity and calculation accuracy. The proposed\ndesign maximumly supports 1024 2-bit input and 1-bit weight\nmultiply-and-accumulate (MAC) computations simultaneously. The 2-bit input is\nrepresented by the width of the input (IN) pulses, while the 1-bit weight is\nstored in STT-MRAM and the x7500 magnified TMR (m-TMR) ratio is obtained by\nlatching. The proposal is simulated using 28-nm CMOS process and MTJ compact\nmodel. The integral nonlinearity is reduced by 57.6% compared with the\nconventional structure. 9.47-25.4 TOPS/W is realized with 2-bit input, 1-bit\nweight and 4-bit output convolution neural network (CNN).",
    "descriptor": "\nComments: 2021 submitted to IEEE Transactions on Circuits and Systems-I, regular papers\n",
    "authors": [
      "Hao Cai",
      "Yanan Guo",
      "Bo Liu",
      "Mingyang Zhou",
      "Juntong Chen",
      "Xinning Liu",
      "Jun Yang"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2110.03937"
  },
  {
    "id": "arXiv:2110.03939",
    "title": "Ranking Cost: Building An Efficient and Scalable Circuit Routing Planner  with Evolution-Based Optimization",
    "abstract": "Circuit routing has been a historically challenging problem in designing\nelectronic systems such as very large-scale integration (VLSI) and printed\ncircuit boards (PCBs). The main challenge is that connecting a large number of\nelectronic components under specific design rules involves a very large search\nspace. Early solutions are typically designed with hard-coded heuristics, which\nsuffer from problems of non-optimal solutions and lack of flexibility for new\ndesign needs. Although a few learning-based methods have been proposed\nrecently, they are typically cumbersome and hard to extend to large-scale\napplications. In this work, we propose a new algorithm for circuit routing,\nnamed Ranking Cost, which innovatively combines search-based methods (i.e., A*\nalgorithm) and learning-based methods (i.e., Evolution Strategies) to form an\nefficient and trainable router. In our method, we introduce a new set of\nvariables called cost maps, which can help the A* router to find out proper\npaths to achieve the global objective. We also train a ranking parameter, which\ncan produce the ranking order and further improve the performance of our\nmethod. Our algorithm is trained in an end-to-end manner and does not use any\nartificial data or human demonstration. In the experiments, we compare with the\nsequential A* algorithm and a canonical reinforcement learning approach, and\nresults show that our method outperforms these baselines with higher\nconnectivity rates and better scalability.",
    "descriptor": "",
    "authors": [
      "Shiyu Huang",
      "Bin Wang",
      "Dong Li",
      "Jianye Hao",
      "Ting Chen",
      "Jun Zhu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.03939"
  },
  {
    "id": "arXiv:2110.03940",
    "title": "Pose Refinement with Joint Optimization of Visual Points and Lines",
    "abstract": "High-precision camera re-localization technology in a pre-established 3D\nenvironment map is the basis for many tasks, such as Augmented Reality,\nRobotics and Autonomous Driving. The point-based visual re-localization\napproaches are well-developed in recent decades, but are insufficient in some\nfeature-less cases. In this paper, we propose a point-line joint optimization\nmethod for pose refinement with the help of the innovatively designed line\nextracting CNN named VLSE, and the line matching and pose optimization\napproach. We adopt a novel line representation and customize a hybrid\nconvolutional block based on the Stacked Hourglass network, to detect accurate\nand stable line features on images. Then we apply a coarse-to-fine strategy to\nobtain precise 2D-3D line correspondences based on the geometric constraint. A\nfollowing point-line joint cost function is constructed to optimize the camera\npose with the initial coarse pose. Sufficient experiments are conducted on open\ndatasets, i.e, line extractor on Wireframe and YorkUrban, localization\nperformance on Aachen Day-Night v1.1 and InLoc, to confirm the effectiveness of\nour point-line joint pose optimization method.",
    "descriptor": "\nComments: Submitted to ICRA 2022\n",
    "authors": [
      "Shuang Gao",
      "Jixiang Wan",
      "Yishan Ping",
      "Xudong Zhang",
      "Shuzhou Dong",
      "Jijunnan Li",
      "Yandong Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.03940"
  },
  {
    "id": "arXiv:2110.03945",
    "title": "Anomaly Detection in Beehives: An Algorithm Comparison",
    "abstract": "Sensor-equipped beehives allow monitoring the living conditions of bees.\nMachine learning models can use the data of such hives to learn behavioral\npatterns and find anomalous events. One type of event that is of particular\ninterest to apiarists for economical reasons is bee swarming. Other events of\ninterest are behavioral anomalies from illness and technical anomalies, e.g.\nsensor failure. Beekeepers can be supported by suitable machine learning models\nwhich can detect these events. In this paper we compare multiple machine\nlearning models for anomaly detection and evaluate them for their applicability\nin the context of beehives. Namely we employed Deep Recurrent Autoencoder,\nElliptic Envelope, Isolation Forest, Local Outlier Factor and One-Class SVM.\nThrough evaluation with real world datasets of different hives and with\ndifferent sensor setups we find that the autoencoder is the best multi-purpose\nanomaly detector in comparison.",
    "descriptor": "",
    "authors": [
      "Padraig Davidson",
      "Michael Steininger",
      "Florian Lautenschlager",
      "Anna Krause",
      "Andreas Hotho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03945"
  },
  {
    "id": "arXiv:2110.03949",
    "title": "CheerBots: Chatbots toward Empathy and Emotionusing Reinforcement  Learning",
    "abstract": "Apart from the coherence and fluency of responses, an empathetic chatbot\nemphasizes more on people's feelings. By considering altruistic behaviors\nbetween human interaction, empathetic chatbots enable people to get a better\ninteractive and supportive experience. This study presents a framework whereby\nseveral empathetic chatbots are based on understanding users' implied feelings\nand replying empathetically for multiple dialogue turns. We call these chatbots\nCheerBots. CheerBots can be retrieval-based or generative-based and were\nfinetuned by deep reinforcement learning. To respond in an empathetic way, we\ndevelop a simulating agent, a Conceptual Human Model, as aids for CheerBots in\ntraining with considerations on changes in user's emotional states in the\nfuture to arouse sympathy. Finally, automatic metrics and human rating results\ndemonstrate that CheerBots outperform other baseline chatbots and achieves\nreciprocal altruism. The code and the pre-trained models will be made\navailable.",
    "descriptor": "",
    "authors": [
      "Jiun-Hao Jhan",
      "Chao-Peng Liu",
      "Shyh-Kang Jeng",
      "Hung-Yi Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.03949"
  },
  {
    "id": "arXiv:2110.03952",
    "title": "A Framework for Aspectual Requirements Validation: An Experimental Study",
    "abstract": "Requirements engineering is a discipline of software engineering that is\nconcerned with the identification and handling of user and system requirements.\nAspect-Oriented Requirements Engineering (AORE) extends the existing\nrequirements engineering approaches to cope with the issue of tangling and\nscattering resulted from crosscutting concerns. Crosscutting concerns are\nconsidered as potential aspects and can lead to the phenomena tyranny of the\ndominant decomposition. Requirements-level aspects are responsible for\nproducing scattered and tangled descriptions of requirements in the\nrequirements document. Validation of requirements artefacts is an essential\ntask in software development. This task ensures that requirements are correct\nand valid in terms of completeness and consistency, hence, reducing the\ndevelopment cost, maintenance and establish an approximately correct estimate\nof effort and completion time of the project. In this paper, we present a\nvalidation framework to validate the aspectual requirements and the\ncrosscutting relationship of concerns that are resulted from the requirements\nengineering phase. The proposed framework comprises a high-level and low-level\nvalidation to implement on software requirements specification (SRS). The\nhigh-level validation validates the concerns with stakeholders, whereas the\nlow-level validation validates the aspectual requirement by requirements\nengineers and analysts using a checklist. The approach has been evaluated using\nan experimental study on two AORE approaches. The approaches are\nviewpoint-based called AORE with ArCaDe and lexical analysis based on Theme/Doc\napproach. The results obtained from the study demonstrate that the proposed\nframework is an effective validation model for AORE artefacts.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Abdelsalam M. Maatuk",
      "Sohil F. Alshareef",
      "Tawfig M. Abdelaziz"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.03952"
  },
  {
    "id": "arXiv:2110.03958",
    "title": "Social Recommendation with Self-Supervised Metagraph Informax Network",
    "abstract": "In recent years, researchers attempt to utilize online social information to\nalleviate data sparsity for collaborative filtering, based on the rationale\nthat social networks offers the insights to understand the behavioral patterns.\nHowever, due to the overlook of inter-dependent knowledge across items (e.g.,\ncategories of products), existing social recommender systems are insufficient\nto distill the heterogeneous collaborative signals from both user and item\nsides. In this work, we propose a Self-Supervised Metagraph Infor-max Network\n(SMIN) which investigates the potential of jointly incorporating social- and\nknowledge-aware relational structures into the user preference representation\nfor recommendation. To model relation heterogeneity, we design a\nmetapath-guided heterogeneous graph neural network to aggregate feature\nembeddings from different types of meta-relations across users and items,\nem-powering SMIN to maintain dedicated representations for multi-faceted user-\nand item-wise dependencies. Additionally, to inject high-order collaborative\nsignals, we generalize the mutual information learning paradigm under the\nself-supervised graph-based collaborative filtering. This endows the expressive\nmodeling of user-item interactive patterns, by exploring global-level\ncollaborative relations and underlying isomorphic transformation property of\ngraph topology. Experimental results on several real-world datasets demonstrate\nthe effectiveness of our SMIN model over various state-of-the-art\nrecommendation methods. We release our source code at\nhttps://github.com/SocialRecsys/SMIN.",
    "descriptor": "\nComments: Published as a full paper in CIKM 2021\n",
    "authors": [
      "Xiaoling Long",
      "Chao Huang",
      "Yong Xu",
      "Huance Xu",
      "Peng Dai",
      "Lianghao Xia",
      "Liefeng Bo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.03958"
  },
  {
    "id": "arXiv:2110.03960",
    "title": "Mixability made efficient: Fast online multiclass logistic regression",
    "abstract": "Mixability has been shown to be a powerful tool to obtain algorithms with\noptimal regret. However, the resulting methods often suffer from high\ncomputational complexity which has reduced their practical applicability. For\nexample, in the case of multiclass logistic regression, the aggregating\nforecaster (Foster et al. (2018)) achieves a regret of $O(\\log(Bn))$ whereas\nOnline Newton Step achieves $O(e^B\\log(n))$ obtaining a double exponential gain\nin $B$ (a bound on the norm of comparative functions). However, this high\nstatistical performance is at the price of a prohibitive computational\ncomplexity $O(n^{37})$.",
    "descriptor": "",
    "authors": [
      "R\u00e9mi J\u00e9z\u00e9quel",
      "Pierre Gaillard",
      "Alessandro Rudi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.03960"
  },
  {
    "id": "arXiv:2110.03964",
    "title": "A subexponential view of domains in session types",
    "abstract": "Linear logic (LL) has inspired the design of many computational systems,\noffering reasoning techniques built on top of its meta-theory. Since its\ninception, several connections between concurrent systems and LL have emerged\nfrom different perspectives. In the last decade, the seminal work of Caires and\nPfenning showed that formulas in LL can be interpreted as session types and\nprocesses in the $\\pi$-calculus as proof terms. This leads to a Curry-Howard\ninterpretation where proof reductions in the cut-elimination procedure\ncorrespond to process reductions/interactions. The subexponentials in LL have\nalso played an important role in concurrent systems since they can be\ninterpreted in different ways, including timed, spatial and even epistemic\nmodalities in distributed systems. In this paper we address the question: What\nis the meaning of the subexponentials from the point of view of a session type\ninterpretation? Our answer is a $\\pi$-like process calculus where agents reside\nin locations/sites and they make it explicit how the communication among the\ndifferent sites should happen. The design of this language relies completely on\nthe proof theory of the subexponentials in LL, thus extending the\nCaires-Pfenning interpretation in an elegant way.",
    "descriptor": "",
    "authors": [
      "Daniele Nantes",
      "Carlos Olarte",
      "Daniel Ventura"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.03964"
  },
  {
    "id": "arXiv:2110.03967",
    "title": "GaitPrivacyON: Privacy-Preserving Mobile Gait Biometrics using  Unsupervised Learning",
    "abstract": "Numerous studies in the literature have already shown the potential of\nbiometrics on mobile devices for authentication purposes. However, it has been\nshown that, the learning processes associated to biometric systems might expose\nsensitive personal information about the subjects. This study proposes\nGaitPrivacyON, a novel mobile gait biometrics verification approach that\nprovides accurate authentication results while preserving the sensitive\ninformation of the subject. It comprises two modules: i) a convolutional\nAutoencoder that transforms attributes of the biometric raw data, such as the\ngender or the activity being performed, into a new privacy-preserving\nrepresentation; and ii) a mobile gait verification system based on the\ncombination of Convolutional Neural Networks (CNNs) and Recurrent Neural\nNetworks (RNNs) with a Siamese architecture. The main advantage of\nGaitPrivacyON is that the first module (convolutional Autoencoder) is trained\nin an unsupervised way, without specifying the sensitive attributes of the\nsubject to protect. The experimental results achieved using two popular\ndatabases (MotionSense and MobiAct) suggest the potential of GaitPrivacyON to\nsignificantly improve the privacy of the subject while keeping user\nauthentication results higher than 99% Area Under the Curve (AUC). To the best\nof our knowledge, this is the first mobile gait verification approach that\nconsiders privacy-preserving methods trained in an unsupervised way.",
    "descriptor": "",
    "authors": [
      "Paula Delgado-Santos",
      "Ruben Tolosana",
      "Richard Guest",
      "Ruben Vera",
      "Farzin Deravi",
      "Aythami Morales"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.03967"
  },
  {
    "id": "arXiv:2110.03968",
    "title": "How to Build a Curb Dataset with LiDAR Data for Autonomous Driving",
    "abstract": "Curbs are one of the essential elements of urban and highway traffic\nenvironments. Robust curb detection provides road structure information for\nmotion planning in an autonomous driving system. Commonly, video cameras and 3D\nLiDARs are mounted on autonomous vehicles for curb detection. However,\ncamera-based methods suffer from challenging illumination conditions. During\nthe long period of time before wide application of Deep Neural Network (DNN)\nwith point clouds, LiDAR-based curb detection methods are based on hand-crafted\nfeatures, which suffer from poor detection in some complex scenes. Recently,\nDNN-based dynamic object detection using LiDAR data has become prevalent, while\nfew works pay attention to curb detection with a DNN approach due to lack of\nlabeled data. A dataset with curb annotations or an efficient curb labeling\napproach, hence, is of high demand...",
    "descriptor": "\nComments: 7 pages with 10 figures, submitted to 2022 IEEE International Conference on Robotics and Automation (ICRA)\n",
    "authors": [
      "Dongfeng Bai",
      "Tongtong Cao",
      "Jingming Guo",
      "Bingbing Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03968"
  },
  {
    "id": "arXiv:2110.03969",
    "title": "Graph Meta Network for Multi-Behavior Recommendation",
    "abstract": "Modern recommender systems often embed users and items into low-dimensional\nlatent representations, based on their observed interactions. In practical\nrecommendation scenarios, users often exhibit various intents which drive them\nto interact with items with multiple behavior types (e.g., click,\ntag-as-favorite, purchase). However, the diversity of user behaviors is ignored\nin most of the existing approaches, which makes them difficult to capture\nheterogeneous relational structures across different types of interactive\nbehaviors. Exploring multi-typed behavior patterns is of great importance to\nrecommendation systems, yet is very challenging because of two aspects: i) The\ncomplex dependencies across different types of user-item interactions; ii)\nDiversity of such multi-behavior patterns may vary by users due to their\npersonalized preference. To tackle the above challenges, we propose a\nMulti-Behavior recommendation framework with Graph Meta Network to incorporate\nthe multi-behavior pattern modeling into a meta-learning paradigm. Our\ndeveloped MB-GMN empowers the user-item interaction learning with the\ncapability of uncovering type-dependent behavior representations, which\nautomatically distills the behavior heterogeneity and interaction diversity for\nrecommendations. Extensive experiments on three real-world datasets show the\neffectiveness of MB-GMN by significantly boosting the recommendation\nperformance as compared to various state-of-the-art baselines. The source code\nis available athttps://github.com/akaxlh/MB-GMN.",
    "descriptor": "\nComments: Published as a full paper at SIGIR 2021\n",
    "authors": [
      "Lianghao Xia",
      "Yong Xu",
      "Chao Huang",
      "Peng Dai",
      "Liefeng Bo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.03969"
  },
  {
    "id": "arXiv:2110.03975",
    "title": "Tensor train completion: local recovery guarantees via Riemannian  optimization",
    "abstract": "In this work we estimate the number of randomly selected elements of a tensor\nthat with high probability guarantees local convergence of Riemannian gradient\ndescent for tensor train completion. We derive a new bound for the orthogonal\nprojections onto the tangent spaces based on the harmonic mean of the\nunfoldings' singular values and introduce a notion of core coherence for tensor\ntrains. We also extend the results to tensor train completion with side\ninformation and obtain the corresponding local convergence guarantees.",
    "descriptor": "",
    "authors": [
      "Stanislav Budzinskiy",
      "Nikolai Zamarashkin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03975"
  },
  {
    "id": "arXiv:2110.03982",
    "title": "Maximize the Exploration of Congeneric Semantics for Weakly Supervised  Semantic Segmentation",
    "abstract": "With the increase in the number of image data and the lack of corresponding\nlabels, weakly supervised learning has drawn a lot of attention recently in\ncomputer vision tasks, especially in the fine-grained semantic segmentation\nproblem. To alleviate human efforts from expensive pixel-by-pixel annotations,\nour method focuses on weakly supervised semantic segmentation (WSSS) with\nimage-level tags, which are much easier to obtain. As a huge gap exists between\npixel-level segmentation and image-level labels, how to reflect the image-level\nsemantic information on each pixel is an important question. To explore the\ncongeneric semantic regions from the same class to the maximum, we construct\nthe patch-level graph neural network (P-GNN) based on the self-detected patches\nfrom different images that contain the same class labels. Patches can frame the\nobjects as much as possible and include as little background as possible. The\ngraph network that is established with patches as the nodes can maximize the\nmutual learning of similar objects. We regard the embedding vectors of patches\nas nodes, and use transformer-based complementary learning module to construct\nweighted edges according to the embedding similarity between different nodes.\nMoreover, to better supplement semantic information, we propose\nsoft-complementary loss functions matched with the whole network structure. We\nconduct experiments on the popular PASCAL VOC 2012 benchmarks, and our model\nyields state-of-the-art performance.",
    "descriptor": "",
    "authors": [
      "Ke Zhang",
      "Sihong Chen",
      "Qi Ju",
      "Yong Jiang",
      "Yucong Li",
      "Xin He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.03982"
  },
  {
    "id": "arXiv:2110.03987",
    "title": "Knowledge-aware Coupled Graph Neural Network for Social Recommendation",
    "abstract": "Social recommendation task aims to predict users' preferences over items with\nthe incorporation of social connections among users, so as to alleviate the\nsparse issue of collaborative filtering. While many recent efforts show the\neffectiveness of neural network-based social recommender systems, several\nimportant challenges have not been well addressed yet: (i) The majority of\nmodels only consider users' social connections, while ignoring the\ninter-dependent knowledge across items; (ii) Most of existing solutions are\ndesigned for singular type of user-item interactions, making them infeasible to\ncapture the interaction heterogeneity; (iii) The dynamic nature of user-item\ninteractions has been less explored in many social-aware recommendation\ntechniques. To tackle the above challenges, this work proposes a\nKnowledge-aware Coupled Graph Neural Network (KCGN) that jointly injects the\ninter-dependent knowledge across items and users into the recommendation\nframework. KCGN enables the high-order user- and item-wise relation encoding by\nexploiting the mutual information for global graph structure awareness.\nAdditionally, we further augment KCGN with the capability of capturing dynamic\nmulti-typed user-item interactive patterns. Experimental studies on real-world\ndatasets show the effectiveness of our method against many strong baselines in\na variety of settings. Source codes are available at:\nhttps://github.com/xhcdream/KCGN.",
    "descriptor": "\nComments: Published as a paper at AAAI 2021\n",
    "authors": [
      "Chao Huang",
      "Huance Xu",
      "Yong Xu",
      "Peng Dai",
      "Lianghao Xia",
      "Mengyin Lu",
      "Liefeng Bo",
      "Hao Xing",
      "Xiaoping Lai",
      "Yanfang Ye"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.03987"
  },
  {
    "id": "arXiv:2110.03991",
    "title": "Combining Differential Privacy and Byzantine Resilience in Distributed  SGD",
    "abstract": "Privacy and Byzantine resilience (BR) are two crucial requirements of\nmodern-day distributed machine learning. The two concepts have been extensively\nstudied individually but the question of how to combine them effectively\nremains unanswered. This paper contributes to addressing this question by\nstudying the extent to which the distributed SGD algorithm, in the standard\nparameter-server architecture, can learn an accurate model despite (a) a\nfraction of the workers being malicious (Byzantine), and (b) the other\nfraction, whilst being honest, providing noisy information to the server to\nensure differential privacy (DP). We first observe that the integration of\nstandard practices in DP and BR is not straightforward. In fact, we show that\nmany existing results on the convergence of distributed SGD under Byzantine\nfaults, especially those relying on $(\\alpha,f)$-Byzantine resilience, are\nrendered invalid when honest workers enforce DP. To circumvent this\nshortcoming, we revisit the theory of $(\\alpha,f)$-BR to obtain an approximate\nconvergence guarantee. Our analysis provides key insights on how to improve\nthis guarantee through hyperparameter optimization. Essentially, our\ntheoretical and empirical results show that (1) an imprudent combination of\nstandard approaches to DP and BR might be fruitless, but (2) by carefully\nre-tuning the learning algorithm, we can obtain reasonable learning accuracy\nwhile simultaneously guaranteeing DP and BR.",
    "descriptor": "",
    "authors": [
      "Rachid Guerraoui",
      "Nirupam Gupta",
      "Rafael Pinot",
      "Sebastien Rouault",
      "John Stephan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.03991"
  },
  {
    "id": "arXiv:2110.03994",
    "title": "Automated Feature-Specific Tree Species Identification from Natural  Images using Deep Semi-Supervised Learning",
    "abstract": "Prior work on plant species classification predominantly focuses on building\nmodels from isolated plant attributes. Hence, there is a need for tools that\ncan assist in species identification in the natural world. We present a novel\nand robust two-fold approach capable of identifying trees in a real-world\nnatural setting. Further, we leverage unlabelled data through deep\nsemi-supervised learning and demonstrate superior performance to supervised\nlearning. Our single-GPU implementation for feature recognition uses minimal\nannotated data and achieves accuracies of 93.96% and 93.11% for leaves and\nbark, respectively. Further, we extract feature-specific datasets of 50 species\nby employing this technique. Finally, our semi-supervised species\nclassification method attains 94.04% top-5 accuracy for leaves and 83.04% top-5\naccuracy for bark.",
    "descriptor": "\nComments: 21 pages, 7 figures, submitted to Ecological Informatics\n",
    "authors": [
      "Dewald Homan",
      "Johan A. du Preez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.03994"
  },
  {
    "id": "arXiv:2110.03996",
    "title": "Graph-Enhanced Multi-Task Learning of Multi-Level Transition Dynamics  for Session-based Recommendation",
    "abstract": "Session-based recommendation plays a central role in a wide spectrum of\nonline applications, ranging from e-commerce to online advertising services.\nHowever, the majority of existing session-based recommendation techniques\n(e.g., attention-based recurrent network or graph neural network) are not\nwell-designed for capturing the complex transition dynamics exhibited with\ntemporally-ordered and multi-level inter-dependent relation structures. These\nmethods largely overlook the relation hierarchy of item transitional patterns.\nIn this paper, we propose a multi-task learning framework with Multi-level\nTransition Dynamics (MTD), which enables the jointly learning of intra- and\ninter-session item transition dynamics in automatic and hierarchical manner.\nTowards this end, we first develop a position-aware attention mechanism to\nlearn item transitional regularities within individual session. Then, a\ngraph-structured hierarchical relation encoder is proposed to explicitly\ncapture the cross-session item transitions in the form of high-order\nconnectivities by performing embedding propagation with the global graph\ncontext. The learning process of intra- and inter-session transition dynamics\nare integrated, to preserve the underlying low- and high-level item\nrelationships in a common latent space. Extensive experiments on three\nreal-world datasets demonstrate the superiority of MTD as compared to\nstate-of-the-art baselines.",
    "descriptor": "\nComments: Published as a paper at AAAI 2021\n",
    "authors": [
      "Chao Huang",
      "Jiahui Chen",
      "Lianghao Xia",
      "Yong Xu",
      "Peng Dai",
      "Yanqing Chen",
      "Liefeng Bo",
      "Jiashu Zhao",
      "Jimmy Xiangji Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.03996"
  },
  {
    "id": "arXiv:2110.03997",
    "title": "Multi Proxy Anchor Loss and Effectiveness of Deep Metric Learning  Performance Metrics",
    "abstract": "Deep metric learning (DML) learns the mapping, which maps into embedding\nspace in which similar data is near and dissimilar data is far. Most DML\nframeworks apply L2 normalization to feature vectors, and these feature vectors\nare non-sparse. In this paper, we propose to apply L1 regularization loss to\nfeature vectors. Proposed regularization emphasizes important features and\nrestraints unimportant features on L2 normalized features. L1 regularization\ncan combine with general DML losses because L1 regularization only regularizes\nfeature vectors. In this paper, we finally propose SparseSoftTriple loss, which\nis a combination of SoftTriple loss and L1 regularization. We demonstrate the\neffectiveness of the proposed SparseSoftTriple loss on some data sets for image\nretrieval tasks and fine-grained images.",
    "descriptor": "",
    "authors": [
      "Shozo Saeki",
      "Minoru Kawahara",
      "Hirohisa Aman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03997"
  },
  {
    "id": "arXiv:2110.03999",
    "title": "Graphs as Tools to Improve Deep Learning Methods",
    "abstract": "In recent years, deep neural networks (DNNs) have known an important rise in\npopularity. However, although they are state-of-the-art in many machine\nlearning challenges, they still suffer from several limitations. For example,\nDNNs require a lot of training data, which might not be available in some\npractical applications. In addition, when small perturbations are added to the\ninputs, DNNs are prone to misclassification errors. DNNs are also viewed as\nblack-boxes and as such their decisions are often criticized for their lack of\ninterpretability.\nIn this chapter, we review recent works that aim at using graphs as tools to\nimprove deep learning methods. These graphs are defined considering a specific\nlayer in a deep learning architecture. Their vertices represent distinct\nsamples, and their edges depend on the similarity of the corresponding\nintermediate representations. These graphs can then be leveraged using various\nmethodologies, many of which built on top of graph signal processing.\nThis chapter is composed of four main parts: tools for visualizing\nintermediate layers in a DNN, denoising data representations, optimizing graph\nobjective functions and regularizing the learning process.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2012.07439\n",
    "authors": [
      "Carlos Lassance",
      "Myriam Bontonou",
      "Mounia Hamidouche",
      "Bastien Pasdeloup",
      "Lucas Drumetz",
      "Vincent Gripon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.03999"
  },
  {
    "id": "arXiv:2110.04000",
    "title": "Knowledge-Enhanced Hierarchical Graph Transformer Network for  Multi-Behavior Recommendation",
    "abstract": "Accurate user and item embedding learning is crucial for modern recommender\nsystems. However, most existing recommendation techniques have thus far focused\non modeling users' preferences over singular type of user-item interactions.\nMany practical recommendation scenarios involve multi-typed user interactive\nbehaviors (e.g., page view, add-to-favorite and purchase), which presents\nunique challenges that cannot be handled by current recommendation solutions.\nIn particular: i) complex inter-dependencies across different types of user\nbehaviors; ii) the incorporation of knowledge-aware item relations into the\nmulti-behavior recommendation framework; iii) dynamic characteristics of\nmulti-typed user-item interactions. To tackle these challenges, this work\nproposes a Knowledge-Enhanced Hierarchical Graph Transformer Network (KHGT), to\ninvestigate multi-typed interactive patterns between users and items in\nrecommender systems. Specifically, KHGT is built upon a graph-structured neural\narchitecture to i) capture type-specific behavior characteristics; ii)\nexplicitly discriminate which types of user-item interactions are more\nimportant in assisting the forecasting task on the target behavior.\nAdditionally, we further integrate the graph attention layer with the temporal\nencoding strategy, to empower the learned embeddings be reflective of both\ndedicated multiplex user-item and item-item relations, as well as the\nunderlying interaction dynamics. Extensive experiments conducted on three\nreal-world datasets show that KHGT consistently outperforms many\nstate-of-the-art recommendation methods across various evaluation settings. Our\nimplementation code is available at https://github.com/akaxlh/KHGT.",
    "descriptor": "",
    "authors": [
      "Lianghao Xia",
      "Chao Huang",
      "Yong Xu",
      "Peng Dai",
      "Xiyue Zhang",
      "Hongsheng Yang",
      "Jian Pei",
      "Liefeng Bo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04000"
  },
  {
    "id": "arXiv:2110.04001",
    "title": "Perceived and Intended Sarcasm Detection with Graph Attention Networks",
    "abstract": "Existing sarcasm detection systems focus on exploiting linguistic markers,\ncontext, or user-level priors. However, social studies suggest that the\nrelationship between the author and the audience can be equally relevant for\nthe sarcasm usage and interpretation. In this work, we propose a framework\njointly leveraging (1) a user context from their historical tweets together\nwith (2) the social information from a user's conversational neighborhood in an\ninteraction graph, to contextualize the interpretation of the post. We use\ngraph attention networks (GAT) over users and tweets in a conversation thread,\ncombined with dense user history representations. Apart from achieving\nstate-of-the-art results on the recently published dataset of 19k Twitter users\nwith 30K labeled tweets, adding 10M unlabeled tweets as context, our results\nindicate that the model contributes to interpreting the sarcastic intentions of\nan author more than to predicting the sarcasm perception by others.",
    "descriptor": "",
    "authors": [
      "Joan Plepi",
      "Lucie Flek"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04001"
  },
  {
    "id": "arXiv:2110.04002",
    "title": "Multiplex Behavioral Relation Learning for Recommendation via Memory  Augmented Transformer Network",
    "abstract": "Capturing users' precise preferences is of great importance in various\nrecommender systems (eg., e-commerce platforms), which is the basis of how to\npresent personalized interesting product lists to individual users. In spite of\nsignificant progress has been made to consider relations between users and\nitems, most of the existing recommendation techniques solely focus on singular\ntype of user-item interactions. However, user-item interactive behavior is\noften exhibited with multi-type (e.g., page view, add-to-favorite and purchase)\nand inter-dependent in nature. The overlook of multiplex behavior relations can\nhardly recognize the multi-modal contextual signals across different types of\ninteractions, which limit the feasibility of current recommendation methods. To\ntackle the above challenge, this work proposes a Memory-Augmented Transformer\nNetworks (MATN), to enable the recommendation with multiplex behavioral\nrelational information, and joint modeling of type-specific behavioral context\nand type-wise behavior inter-dependencies, in a fully automatic manner. In our\nMATN framework, we first develop a transformer-based multi-behavior relation\nencoder, to make the learned interaction representations be reflective of the\ncross-type behavior relations. Furthermore, a memory attention network is\nproposed to supercharge MATN capturing the contextual signals of different\ntypes of behavior into the category-specific latent embedding space. Finally, a\ncross-behavior aggregation component is introduced to promote the comprehensive\ncollaboration across type-aware interaction behavior representations, and\ndiscriminate their inherent contributions in assisting recommendations.\nExtensive experiments on two benchmark datasets and a real-world e-commence\nuser behavior data demonstrate significant improvements obtained by MATN over\nbaselines. Codes are available at: https://github.com/akaxlh/MATN.",
    "descriptor": "\nComments: Published as a full paper at SIGIR 2020\n",
    "authors": [
      "Lianghao Xia",
      "Chao Huang",
      "Yong Xu",
      "Peng Dai",
      "Bo Zhang",
      "Liefeng Bo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04002"
  },
  {
    "id": "arXiv:2110.04003",
    "title": "Learning to Centralize Dual-Arm Assembly",
    "abstract": "Even though industrial manipulators are widely used in modern manufacturing\nprocesses, deployment in unstructured environments remains an open problem. To\ndeal with variety, complexity and uncertainty of real world manipulation tasks\na general framework is essential. In this work we want to focus on assembly\nwith humanoid robots by providing a framework for dual-arm peg-in-hole\nmanipulation. As we aim to contribute towards an approach which is not limited\nto dual-arm peg-in-hole, but dual-arm manipulation in general, we keep modeling\neffort at a minimum. While reinforcement learning has shown great results for\nsingle-arm robotic manipulation in recent years, research focusing on dual-arm\nmanipulation is still rare. Solving such tasks often involves complex modeling\nof interaction between two manipulators and their coupling at a control level.\nIn this paper, we explore the applicability of model-free reinforcement\nlearning to dual-arm manipulation based on a modular approach with two\ndecentralized single-arm controllers and a single centralized policy. We reduce\nmodeling effort to a minimum by using sparse rewards only. We demonstrate the\neffectiveness of the framework on dual-arm peg-in-hole and analyze sample\nefficiency and success rates for different action spaces. Moreover, we compare\nresults on different clearances and showcase disturbance recovery and\nrobustness, when dealing with position uncertainties. Finally we zero-shot\ntransfer policies trained in simulation to the real-world and evaluate their\nperformance.",
    "descriptor": "",
    "authors": [
      "Marvin Alles",
      "Elie Aljalbout"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.04003"
  },
  {
    "id": "arXiv:2110.04004",
    "title": "Trident Pyramid Networks: The importance of processing at the feature  pyramid level for better object detection",
    "abstract": "Feature pyramids have become ubiquitous in multi-scale computer vision tasks\nsuch as object detection. Based on their importance, we divide a computer\nvision network into three parts: a backbone (generating a feature pyramid), a\ncore (refining the feature pyramid) and a head (generating the final output).\nMost existing networks operating on feature pyramids, named cores, are shallow\nand mostly focus on communication-based processing in the form of top-down and\nbottom-up operations. We present a new core architecture called Trident Pyramid\nNetwork (TPN), that allows for a deeper design and for a better balance between\ncommunication-based processing and self-processing. We show consistent\nimprovements when using our TPN core on the COCO object detection benchmark,\noutperforming the popular BiFPN baseline by 1.5 AP. Additionally, we\nempirically show that it is more beneficial to put additional computation into\nthe TPN core, rather than into the backbone, by outperforming a ResNet-101+FPN\nbaseline with our ResNet-50+TPN network by 1.7 AP, while operating under\nsimilar computation budgets. This emphasizes the importance of performing\ncomputation at the feature pyramid level in modern-day object detection\nsystems. Code will be released.",
    "descriptor": "",
    "authors": [
      "C\u00e9dric Picron",
      "Tinne Tuytelaars"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04004"
  },
  {
    "id": "arXiv:2110.04009",
    "title": "An End-to-End Trainable Video Panoptic Segmentation Method  usingTransformers",
    "abstract": "In this paper, we present an algorithm to tackle a video panoptic\nsegmentation problem, a newly emerging area of research. The video panoptic\nsegmentation is a task that unifies the typical task of panoptic segmentation\nand multi-object tracking. In other words, it requires generating the instance\ntracking IDs along with panoptic segmentation results across video sequences.\nOur proposed video panoptic segmentation algorithm uses the transformer and it\ncan be trained in end-to-end with an input of multiple video frames. We test\nour method on the STEP dataset and report its performance with recently\nproposed STQ metric. The method archived 57.81\\% on the KITTI-STEP dataset and\n31.8\\% on the MOTChallenge-STEP dataset.",
    "descriptor": "\nComments: This contains a brief abstract\n",
    "authors": [
      "Jeongwon Ryu",
      "Kwangjin Yoon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04009"
  },
  {
    "id": "arXiv:2110.04015",
    "title": "Multidirectional Conjugate Gradients for Scalable Bundle Adjustment",
    "abstract": "We revisit the problem of large-scale bundle adjustment and propose a\ntechnique called Multidirectional Conjugate Gradients that accelerates the\nsolution of the normal equation by up to 61%. The key idea is that we enlarge\nthe search space of classical preconditioned conjugate gradients to include\nmultiple search directions. As a consequence, the resulting algorithm requires\nfewer iterations, leading to a significant speedup of large-scale\nreconstruction, in particular for denser problems where traditional approaches\nnotoriously struggle. We provide a number of experimental ablation studies\nrevealing the robustness to variations in the hyper-parameters and the speedup\nas a function of problem density.",
    "descriptor": "",
    "authors": [
      "Simon Weber",
      "Nikolaus Demmel",
      "Daniel Cremers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04015"
  },
  {
    "id": "arXiv:2110.04017",
    "title": "GMRES algorithms over 35 years",
    "abstract": "This paper is about GMRES algorithms for the solution of nonsingular linear\nsystems. We first consider basic algorithms and study their convergence. We\nthen focus on acceleration strategies and parallel algorithms that are useful\nfor solving challenging systems. We also briefly discuss other problems, such\nas systems with multiple right-hand sides, shifted systems, and singular\nsystems.",
    "descriptor": "",
    "authors": [
      "Qinmeng Zou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.04017"
  },
  {
    "id": "arXiv:2110.04020",
    "title": "Pathologies in priors and inference for Bayesian transformers",
    "abstract": "In recent years, the transformer has established itself as a workhorse in\nmany applications ranging from natural language processing to reinforcement\nlearning. Similarly, Bayesian deep learning has become the gold-standard for\nuncertainty estimation in safety-critical applications, where robustness and\ncalibration are crucial. Surprisingly, no successful attempts to improve\ntransformer models in terms of predictive uncertainty using Bayesian inference\nexist. In this work, we study this curiously underpopulated area of Bayesian\ntransformers. We find that weight-space inference in transformers does not work\nwell, regardless of the approximate posterior. We also find that the prior is\nat least partially at fault, but that it is very hard to find well-specified\nweight priors for these models. We hypothesize that these problems stem from\nthe complexity of obtaining a meaningful mapping from weight-space to\nfunction-space distributions in the transformer. Therefore, moving closer to\nfunction-space, we propose a novel method based on the implicit\nreparameterization of the Dirichlet distribution to apply variational inference\ndirectly to the attention weights. We find that this proposed method performs\ncompetitively with our baselines.",
    "descriptor": "",
    "authors": [
      "Tristan Cinquin",
      "Alexander Immer",
      "Max Horn",
      "Vincent Fortuin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04020"
  },
  {
    "id": "arXiv:2110.04022",
    "title": "Learning Sparse Graphs with a Core-periphery Structure",
    "abstract": "In this paper, we focus on learning sparse graphs with a core-periphery\nstructure. We propose a generative model for data associated with\ncore-periphery structured networks to model the dependence of node attributes\non core scores of the nodes of a graph through a latent graph structure. Using\nthe proposed model, we jointly infer a sparse graph and nodal core scores that\ninduce dense (sparse) connections in core (respectively, peripheral) parts of\nthe network. Numerical experiments on a variety of real-world data indicate\nthat the proposed method learns a core-periphery structured graph from node\nattributes alone, while simultaneously learning core score assignments that\nagree well with existing works that estimate core scores using graph as input\nand ignoring commonly available node attributes.",
    "descriptor": "",
    "authors": [
      "Sravanthi Gurugubelli",
      "Sundeep Prabhakar Chepuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04022"
  },
  {
    "id": "arXiv:2110.04030",
    "title": "Chromatic Aberration Recovery on Arbitrary Images",
    "abstract": "Digital imaging sensor technology has continued to outpace development in\noptical technology in modern imaging systems. The resulting quality loss\nattributable to lateral chromatic aberration is becoming increasingly\nsignificant as sensor resolution increases; other classes of aberration are\nless significant with classical image enhancement (e.g. sharpening), whereas\nlateral chromatic aberration becomes more significant. The goals of\nhigher-performance and lighter lens systems drive a recent need to find new\nways to overcome resulting image quality limitations.\nThis work demonstrates the robust and automatic minimisation of lateral\nchromatic aberration, recovering the loss of image quality using both\nartificial and real-world images. A series of test images are used to validate\nthe functioning of the algorithm, and changes across a series of real-world\nimages are used to evaluate the performance of the approach.",
    "descriptor": "",
    "authors": [
      "Daniel J. Blueman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.04030"
  },
  {
    "id": "arXiv:2110.04032",
    "title": "Symbolic Register Automata for Complex Event Recognition and Forecasting",
    "abstract": "We propose an automaton model which is a combination of symbolic and register\nautomata, i.e., we enrich symbolic automata with memory. We call such automata\nSymbolic Register Automata (SRA). SRA extend the expressive power of symbolic\nautomata, by allowing Boolean formulas to be applied not only to the last\nelement read from the input string, but to multiple elements, stored in their\nregisters. SRA also extend register automata, by allowing arbitrary Boolean\nformulas, besides equality predicates. We study the closure properties of SRA\nunder union, intersection, concatenation, Kleene closure, complement and\ndeterminization and show that SRA, contrary to symbolic automata, are not in\ngeneral closed under complement and they are not determinizable. However, they\nare closed under these operations when a window operator, quintessential in\nComplex Event Recognition, is used. We show how SRA can be used in Complex\nEvent Recognition in order to detect patterns upon streams of events, using our\nframework that provides declarative and compositional semantics, and that\nallows for a systematic treatment of such automata. We also show how the\nbehavior of SRA, as they consume streams of events, can be given a\nprobabilistic description with the help of prediction suffix trees. This allows\nus to go one step beyond Complex Event Recognition to Complex Event\nForecasting, where, besides detecting complex patterns, we can also efficiently\nforecast their occurrence.",
    "descriptor": "",
    "authors": [
      "Elias Alevizos",
      "Alexander Artikis",
      "Georgios Paliouras"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.04032"
  },
  {
    "id": "arXiv:2110.04035",
    "title": "UniNet: Unified Architecture Search with Convolution, Transformer, and  MLP",
    "abstract": "Recently, transformer and multi-layer perceptron (MLP) architectures have\nachieved impressive results on various vision tasks. A few works investigated\nmanually combining those operators to design visual network architectures, and\ncan achieve satisfactory performances to some extent. In this paper, we propose\nto jointly search the optimal combination of convolution, transformer, and MLP\nfor building a series of all-operator network architectures with high\nperformances on visual tasks. We empirically identify that the widely-used\nstrided convolution or pooling based down-sampling modules become the\nperformance bottlenecks when the operators are combined to form a network. To\nbetter tackle the global context captured by the transformer and MLP operators,\nwe propose two novel context-aware down-sampling modules, which can better\nadapt to the global information encoded by transformer and MLP operators. To\nthis end, we jointly search all operators and down-sampling modules in a\nunified search space. Notably, Our searched network UniNet (Unified Network)\noutperforms state-of-the-art pure convolution-based architecture, EfficientNet,\nand pure transformer-based architecture, Swin-Transformer, on multiple public\nvisual benchmarks, ImageNet classification, COCO object detection, and ADE20K\nsemantic segmentation.",
    "descriptor": "\nComments: technich report\n",
    "authors": [
      "Jihao Liu",
      "Hongsheng Li",
      "Guanglu Song",
      "Xin Huang",
      "Yu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04035"
  },
  {
    "id": "arXiv:2110.04037",
    "title": "Simulations for novel problems in recommendation: analyzing  misinformation and data characteristics",
    "abstract": "In this position paper, we discuss recent applications of simulation\napproaches for recommender systems tasks. In particular, we describe how they\nwere used to analyze the problem of misinformation spreading and understand\nwhich data characteristics affect the performance of recommendation algorithms\nmore significantly. We also present potential lines of future work where\nsimulation methods could advance the work in the recommendation community.",
    "descriptor": "",
    "authors": [
      "Alejandro Bellog\u00edn",
      "Yashar Deldjoo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.04037"
  },
  {
    "id": "arXiv:2110.04038",
    "title": "Traffic Flow Forecasting with Spatial-Temporal Graph Diffusion Network",
    "abstract": "Accurate forecasting of citywide traffic flow has been playing critical role\nin a variety of spatial-temporal mining applications, such as intelligent\ntraffic control and public risk assessment. While previous work has made\nsignificant efforts to learn traffic temporal dynamics and spatial\ndependencies, two key limitations exist in current models. First, only the\nneighboring spatial correlations among adjacent regions are considered in most\nexisting methods, and the global inter-region dependency is ignored.\nAdditionally, these methods fail to encode the complex traffic transition\nregularities exhibited with time-dependent and multi-resolution in nature. To\ntackle these challenges, we develop a new traffic prediction\nframework-Spatial-Temporal Graph Diffusion Network (ST-GDN). In particular,\nST-GDN is a hierarchically structured graph neural architecture which learns\nnot only the local region-wise geographical dependencies, but also the spatial\nsemantics from a global perspective. Furthermore, a multi-scale attention\nnetwork is developed to empower ST-GDN with the capability of capturing\nmulti-level temporal dynamics. Experiments on several real-life traffic\ndatasets demonstrate that ST-GDN outperforms different types of\nstate-of-the-art baselines. Source codes of implementations are available at\nhttps://github.com/jill001/ST-GDN.",
    "descriptor": "\nComments: Published as a paper at AAAI 2021\n",
    "authors": [
      "Xiyue Zhang",
      "Chao Huang",
      "Yong Xu",
      "Lianghao Xia",
      "Peng Dai",
      "Liefeng Bo",
      "Junbo Zhang",
      "Yu Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04038"
  },
  {
    "id": "arXiv:2110.04039",
    "title": "Global Context Enhanced Social Recommendation with Hierarchical Graph  Neural Networks",
    "abstract": "Social recommendation which aims to leverage social connections among users\nto enhance the recommendation performance. With the revival of deep learning\ntechniques, many efforts have been devoted to developing various neural\nnetwork-based social recommender systems, such as attention mechanisms and\ngraph-based message passing frameworks. However, two important challenges have\nnot been well addressed yet: (i) Most of existing social recommendation models\nfail to fully explore the multi-type user-item interactive behavior as well as\nthe underlying cross-relational inter-dependencies. (ii) While the learned\nsocial state vector is able to model pair-wise user dependencies, it still has\nlimited representation capacity in capturing the global social context across\nusers. To tackle these limitations, we propose a new Social Recommendation\nframework with Hierarchical Graph Neural Networks (SR-HGNN). In particular, we\nfirst design a relation-aware reconstructed graph neural network to inject the\ncross-type collaborative semantics into the recommendation framework. In\naddition, we further augment SR-HGNN with a social relation encoder based on\nthe mutual information learning paradigm between low-level user embeddings and\nhigh-level global representation, which endows SR-HGNN with the capability of\ncapturing the global social contextual signals. Empirical results on three\npublic benchmarks demonstrate that SR-HGNN significantly outperforms\nstate-of-the-art recommendation methods. Source codes are available at:\nhttps://github.com/xhcdream/SR-HGNN.",
    "descriptor": "\nComments: Published as a full paper at ICDM 2020\n",
    "authors": [
      "Huance Xu",
      "Chao Huang",
      "Yong Xu",
      "Lianghao Xia",
      "Hao Xing",
      "Dawei Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04039"
  },
  {
    "id": "arXiv:2110.04040",
    "title": "Towards Math-Aware Automated Classification and Similarity Search of  Scientific Publications: Methods of Mathematical Content Representations",
    "abstract": "In this paper, we investigate mathematical content representations suitable\nfor the automated classification of and the similarity search in STEM documents\nusing standard machine learning algorithms: the Latent Dirichlet Allocation\n(LDA) and the Latent Semantic Indexing (LSI). The methods are evaluated on a\nsubset of arXiv.org papers with the Mathematics Subject Classification (MSC) as\na reference classification and using the standard precision/recall/F1-measure\nmetrics. The results give insight into how different math representations may\ninfluence the performance of the classification and similarity search tasks in\nSTEM repositories. Non-surprisingly, machine learning methods are able to grab\ndistributional semantics from textual tokens. A proper selection of weighted\ntokens representing math may improve the quality of the results slightly. A\nstructured math representation that imitates successful text-processing\ntechniques with math is shown to yield better results than flat TeX tokens.",
    "descriptor": "",
    "authors": [
      "Michal R\u016f\u017ei\u010dka",
      "Petr Sojka"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04040"
  },
  {
    "id": "arXiv:2110.04041",
    "title": "Pick Your Battles: Interaction Graphs as Population-Level Objectives for  Strategic Diversity",
    "abstract": "Strategic diversity is often essential in games: in multi-player games, for\nexample, evaluating a player against a diverse set of strategies will yield a\nmore accurate estimate of its performance. Furthermore, in games with\nnon-transitivities diversity allows a player to cover several winning\nstrategies. However, despite the significance of strategic diversity, training\nagents that exhibit diverse behaviour remains a challenge. In this paper we\nstudy how to construct diverse populations of agents by carefully structuring\nhow individuals within a population interact. Our approach is based on\ninteraction graphs, which control the flow of information between agents during\ntraining and can encourage agents to specialise on different strategies,\nleading to improved overall performance. We provide evidence for the importance\nof diversity in multi-agent training and analyse the effect of applying\ndifferent interaction graphs on the training trajectories, diversity and\nperformance of populations in a range of games. This is an extended version of\nthe long abstract published at AAMAS.",
    "descriptor": "",
    "authors": [
      "Marta Garnelo",
      "Wojciech Marian Czarnecki",
      "Siqi Liu",
      "Dhruva Tirumala",
      "Junhyuk Oh",
      "Gauthier Gidel",
      "Hado van Hasselt",
      "David Balduzzi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04041"
  },
  {
    "id": "arXiv:2110.04042",
    "title": "Context-LGM: Leveraging Object-Context Relation for Context-Aware Object  Recognition",
    "abstract": "Context, as referred to situational factors related to the object of\ninterest, can help infer the object's states or properties in visual\nrecognition. As such contextual features are too diverse (across instances) to\nbe annotated, existing attempts simply exploit image labels as supervision to\nlearn them, resulting in various contextual tricks, such as features pyramid,\ncontext attention, etc. However, without carefully modeling the context's\nproperties, especially its relation to the object, their estimated context can\nsuffer from large inaccuracy. To amend this problem, we propose a novel\nContextual Latent Generative Model (Context-LGM), which considers the\nobject-context relation and models it in a hierarchical manner. Specifically,\nwe firstly introduce a latent generative model with a pair of correlated latent\nvariables to respectively model the object and context, and embed their\ncorrelation via the generative process. Then, to infer contextual features, we\nreformulate the objective function of Variational Auto-Encoder (VAE), where\ncontextual features are learned as a posterior distribution conditioned on the\nobject. Finally, to implement this contextual posterior, we introduce a\nTransformer that takes the object's information as a reference and locates\ncorrelated contextual factors. The effectiveness of our method is verified by\nstate-of-the-art performance on two context-aware object recognition tasks,\ni.e. lung cancer prediction and emotion recognition.",
    "descriptor": "\nComments: 13 pages, currently under review\n",
    "authors": [
      "Mingzhou Liu",
      "Xinwei Sun",
      "Fandong Zhang",
      "Yizhou Yu",
      "Yizhou Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04042"
  },
  {
    "id": "arXiv:2110.04043",
    "title": "Polygon Area Decomposition Using a Compactness Metric",
    "abstract": "In this paper, we consider the problem of partitioning a polygon into a set\nof connected disjoint sub-polygons, each of which covers an area of a specific\nsize. The work is motivated by terrain covering applications in robotics, where\nthe goal is to find a set of efficient plans for a team of heterogeneous robots\nto cover a given area. Within this application, solving a polygon partitioning\nproblem is an essential stepping stone. Unlike previous work, the problem\nformulation proposed in this paper also considers a compactness metric of the\ngenerated sub-polygons, in addition to the area size constraints. Maximizing\nthe compactness of sub-polygons directly influences the optimality of any\ngenerated motion plans. Consequently, this increases the efficiency with which\nrobotic tasks can be performed within each sub-region. The proposed problem\nrepresentation is based on grid cell decomposition and a potential field model\nthat allows for the use of standard optimization techniques. A new algorithm,\nthe AreaDecompose algorithm, is proposed to solve this problem. The algorithm\nincludes a number of existing and new optimization techniques combined with two\npost-processing methods. The approach has been evaluated on a set of randomly\ngenerated polygons which are then divided using different criteria and the\nresults have been compared with a state-of-the-art algorithm. Results show that\nthe proposed algorithm can efficiently divide polygon regions maximizing\ncompactness of the resulting partitions, where the sub-polygon regions are on\naverage up to 73% more compact in comparison to existing techniques.",
    "descriptor": "\nComments: 14 pages, 12 figures\n",
    "authors": [
      "Mariusz Wzorek",
      "Cyrille Berger",
      "Patrick Doherty"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.04043"
  },
  {
    "id": "arXiv:2110.04045",
    "title": "Effect of Visual Cues on Pointing Tasks in Co-located Augmented Reality  Collaboration",
    "abstract": "Visual cues are essential in computer-mediated communication. It is\nespecially important when communication happens in a collaboration scenario\nthat requires focusing several users' attention on aspecific object among other\nsimilar ones. This paper explores the effect of visual cues on pointing tasks\nin co-located Augmented Reality (AR) collaboration. A user study (N = 32, 16\npairs) was conducted to compare two types of visual cues: Pointing Line (PL)and\nMoving Track (MT). Both are head-based visual techniques.Through a series of\ncollaborative pointing tasks on objects with different states (static and\ndynamic) and density levels (low, mediumand high), the results showed that PL\nwas better on task performance and usability, but MT was rated higher on social\npresenceand user preference. Based on our results, some design implicationsare\nprovided for pointing tasks in co-located AR collaboration.",
    "descriptor": "",
    "authors": [
      "Lei Chen",
      "Yilin Liu",
      "Yue Li",
      "Lingyun Yu",
      "BoYu Gao",
      "Maurizio Caon",
      "Yong Yue",
      "Hai-Ning Liang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.04045"
  },
  {
    "id": "arXiv:2110.04049",
    "title": "Minimal-Configuration Anomaly Detection for IIoT Sensors",
    "abstract": "The increasing deployment of low-cost IoT sensor platforms in industry boosts\nthe demand for anomaly detection solutions that fulfill two key requirements:\nminimal configuration effort and easy transferability across equipment. Recent\nadvances in deep learning, especially long-short-term memory (LSTM) and\nautoencoders, offer promising methods for detecting anomalies in sensor data\nrecordings. We compared autoencoders with various architectures such as deep\nneural networks (DNN), LSTMs and convolutional neural networks (CNN) using a\nsimple benchmark dataset, which we generated by operating a peristaltic pump\nunder various operating conditions and inducing anomalies manually. Our\npreliminary results indicate that a single model can detect anomalies under\nvarious operating conditions on a four-dimensional data set without any\nspecific feature engineering for each operating condition. We consider this\nwork as being the first step towards a generic anomaly detection method, which\nis applicable for a wide range of industrial equipment.",
    "descriptor": "\nComments: This paper is accepted at the Industrial Track IDSC this https URL The link to the publication and final version will follow as so the paper is published by Springer\n",
    "authors": [
      "Clemens Heistracher",
      "Anahid Jalali",
      "Axel Suendermann",
      "Sebastian Meixner",
      "Daniel Schall",
      "Bernhard Haslhofer",
      "Jana Kemnitz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.04049"
  },
  {
    "id": "arXiv:2110.04052",
    "title": "Safe Imitation Learning on Real-Life Highway Data for Human-like  Autonomous Driving",
    "abstract": "This paper presents a safe imitation learning approach for autonomous vehicle\ndriving, with attention on real-life human driving data and experimental\nvalidation. In order to increase occupant's acceptance and gain drivers' trust,\nthe autonomous driving function needs to provide a both safe and comfortable\nbehavior such as risk-free and naturalistic driving. Our goal is to obtain such\nbehavior via imitation learning of a planning policy from human driving data.\nIn particular, we propose to incorporate barrier functions and smooth\nspline-based motion parametrization in the training loss function. The\nadvantage is twofold: improving safety of the learning algorithm, while\nreducing the amount of needed training data. Moreover, the behavior is learned\nfrom highway driving data, which is collected consistently by a human driver\nand then processed towards a specific driving scenario. For development\nvalidation, a digital twin of the real test vehicle, sensors, and traffic\nscenarios are reconstructed toward high-fidelity and physics-based modeling\ntechnologies. These models are imported to simulation tools and co-simulated\nwith the proposed algorithm for validation and further testing. Finally, we\npresent experimental results and analyses, and compare with the conventional\nimitation learning technique (behavioral cloning) to justify the proposed\ndevelopment.",
    "descriptor": "\nComments: Published in the proceedings of the 24th IEEE International Conference on Intelligent Transportation Systems - ITSC2021 September 19-22, 2021 (Indianapolis, IN, United States)\n",
    "authors": [
      "Flavia Sofia Acerbo",
      "Mohsen Alirezaei",
      "Herman Van der Auweraer",
      "Tong Duy Son"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.04052"
  },
  {
    "id": "arXiv:2110.04054",
    "title": "Core Elements of Social Interaction for Constructive Human-Robot  Interaction",
    "abstract": "We present a discovery-based, first version, explicit model of social\ninteraction that provides a basis for measuring the quality of interaction of a\nhuman user with a social robot. The two core elements of the social interaction\nmodel are engagement and co-regulation. Engagement emphasizes the\n\\textit{qualitative nature} of social interaction and the fact that a user\nneeds to be drawn into the interaction with the robot. Co-regulation emphasizes\nthe interaction process and the fact that a user and a robot need to be acting\ntogether. We argue that the quality of social interaction with a robot can be\nmeasured in terms of how efficiently engagement and co-regulation are\nestablished and maintained during the interaction and how satisfied the user is\nwith the interaction.",
    "descriptor": "\nComments: Quality of Interaction in Socially Assistive Robots (QISAR) Workshop at International Conference on Social Robotics (ICSR19) - Madrid, Spain, November 26-29, 2019\n",
    "authors": [
      "Mike E.U. Ligthart",
      "Mark A. Neerincx",
      "Koen V. Hindriks"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.04054"
  },
  {
    "id": "arXiv:2110.04055",
    "title": "Curating Subject ID Labels using Keypoint Signatures",
    "abstract": "Subject ID labels are unique, anonymized codes that can be used to group all\nimages of a subject while maintaining anonymity. ID errors may be inadvertently\nintroduced manually error during enrollment and may lead to systematic error\ninto machine learning evaluation (e.g. due to double-dipping) or potential\npatient misdiagnosis in clinical contexts. Here we describe a highly efficient\nsystem for curating subject ID labels in large generic medical image datasets,\nbased on the 3D image keypoint representation, which recently led to the\ndiscovery of previously unknown labeling errors in widely-used public brain MRI\ndatasets",
    "descriptor": "",
    "authors": [
      "Laurent Chauvin",
      "Matthew Toews"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04055"
  },
  {
    "id": "arXiv:2110.04057",
    "title": "FAST-RIR: Fast neural diffuse room impulse response generator",
    "abstract": "We present a neural-network-based fast diffuse room impulse response\ngenerator (FAST-RIR) for generating room impulse responses (RIRs) for a given\nacoustic environment. Our FAST-RIR takes rectangular room dimensions, listener\nand speaker positions, and reverberation time as inputs and generates specular\nand diffuse reflections for a given acoustic environment. Our FAST-RIR is\ncapable of generating RIRs for a given input reverberation time with an average\nerror of 0.02s. We evaluate our generated RIRs in automatic speech recognition\n(ASR) applications using Google Speech API, Microsoft Speech API, and Kaldi\ntools. We show that our proposed FAST-RIR with batch size 1 is 400 times faster\nthan a state-of-the-art diffuse acoustic simulator (DAS) on a CPU and gives\nsimilar performance to DAS in ASR experiments. Our FAST-RIR is 12 times faster\nthan an existing GPU-based RIR generator (gpuRIR). We show that our FAST-RIR\noutperforms gpuRIR by 2.5% in an AMI far-field ASR benchmark.",
    "descriptor": "\nComments: More results and source code is available at this https URL\n",
    "authors": [
      "Anton Ratnarajah",
      "Shi-Xiong Zhang",
      "Meng Yu",
      "Zhenyu Tang",
      "Dinesh Manocha",
      "Dong Yu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.04057"
  },
  {
    "id": "arXiv:2110.04060",
    "title": "New Insights into Graph Convolutional Networks using Neural Tangent  Kernels",
    "abstract": "Graph Convolutional Networks (GCNs) have emerged as powerful tools for\nlearning on network structured data. Although empirically successful, GCNs\nexhibit certain behaviour that has no rigorous explanation -- for instance, the\nperformance of GCNs significantly degrades with increasing network depth,\nwhereas it improves marginally with depth using skip connections. This paper\nfocuses on semi-supervised learning on graphs, and explains the above\nobservations through the lens of Neural Tangent Kernels (NTKs). We derive NTKs\ncorresponding to infinitely wide GCNs (with and without skip connections).\nSubsequently, we use the derived NTKs to identify that, with suitable\nnormalisation, network depth does not always drastically reduce the performance\nof GCNs -- a fact that we also validate through extensive simulation.\nFurthermore, we propose NTK as an efficient `surrogate model' for GCNs that\ndoes not suffer from performance fluctuations due to hyper-parameter tuning\nsince it is a hyper-parameter free deterministic kernel. The efficacy of this\nidea is demonstrated through a comparison of different skip connections for\nGCNs using the surrogate NTKs.",
    "descriptor": "",
    "authors": [
      "Mahalakshmi Sabanayagam",
      "Pascal Esser",
      "Debarghya Ghoshdastidar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04060"
  },
  {
    "id": "arXiv:2110.04061",
    "title": "Enhancing business process execution with a context engine",
    "abstract": "Changes in workflow relevant data of business processes at run-time can\nhinder their completion or impact their profitability as they have been\ninstantiated under different circumstances. The purpose of this paper is to\npropose a context engine to enhance a business process management (BPM)\nsystem's context-awareness. The generic architecture provides the flexibility\nto configure processes during initialization as well as to adapt running\ninstances at decision gates or during execution due to significant context\nchange. The paper discusses context-awareness as the conceptual background. The\ntechnological capabilities of business rules and complex event processing (CEP)\nare outlined in an architecture design. A reference process is proposed and\ndiscussed in an exemplary application. The results provide an improvement over\nthe current situation of static variable instantiation of business processes\nwith local information. The proposed architecture extends the well-known\ncombination of business rules and BPM systems with a context engine based on\nCEP. The resulting architecture for a BPM system using a context engine is\ngeneric in nature and, hence, requires to be contextualized for situated\nimplementations. Implementation success is dependent on the availability of\ncontext information and process compensation options. Practitioners receive\nadvice on a reference architecture and technology choices for implementing\nsystems, which can provide and monitor context information for business\nprocesses as well as intervene and adapt the execution. Currently, there is no\nmulti-purpose non-proprietary context engine based on CEP or any other\ntechnology available for BPM, which facilitates the adaptation of processes at\nrun-time due to changes in context variables. This paper will stimulate a\ndebate between research and practice on suitable design and technology.",
    "descriptor": "\nComments: This research and development project is funded by the German Federal Ministry of Education and Research (BMBF) within the framework concept \"Innovations for Tomorrow's Production, Services, and Work\" (Funding No. 02P17D160) and managed by the Project Management Agency Karlsruhe (PTKA). The author is responsible for the contents of this publication\n",
    "authors": [
      "Christian Janiesch J\u00f6rn Kuhlenkamp"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.04061"
  },
  {
    "id": "arXiv:2110.04062",
    "title": "A fast co-simulation approach to vehicle/track interaction with finite  element models of S&C",
    "abstract": "Simulations of vehicle/track interaction (VTI) in switches and crossings\n(S\\&C) require taking into account the complexity of their geometry. The VTI\ncan be handled via a co-simulation process between a finite element (FE) model\nof the track and a multibody system (MBS) software. The objective of this paper\nis to reduce the computing effort in the co-simulation process. In the proposed\napproach, the VTI problem is solved inside the MBS software to reduce the\ncomputational effort in the track model as well as the flow of input/output\nbetween both modules. The FE code is used to supply the matrices of stiffness,\ndamping and mass at the beginning of the simulation. An explicit time scheme is\nused with mass scaling. A good agreement is found between both approaches with\na reduction of the computing time by a factor of 10. This new approach allows\nthe optimisation of the design of S\\&C in further studies.",
    "descriptor": "\nComments: IAVSD 2021 -- the 27th IAVSD Symposium on Dynamics of Vehicles on Roads and Tracks, Aug 2021, Saint Petersburg, Russia\n",
    "authors": [
      "Demeng Fan",
      "Michel Seb\u00e8s",
      "Emmanuel Bourgeois",
      "Hugues Chollet",
      "C\u00e9dric Pozzolini"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.04062"
  },
  {
    "id": "arXiv:2110.04063",
    "title": "A New Weakly Supervised Learning Approach for Real-time Iron Ore Feed  Load Estimation",
    "abstract": "Iron ore feed load control is one of the most critical settings in a mineral\ngrinding process, directly impacting the quality of final products. The setting\nof the feed load is mainly determined by the characteristics of the ore\npellets. However, the characterisation of ore is challenging to acquire in many\nproduction environments, leading to poor feed load settings and inefficient\nproduction processes. This paper presents our work using deep learning models\nfor direct ore feed load estimation from ore pellet images. To address the\nchallenges caused by the large size of a full ore pellets image and the\nshortage of accurately annotated data, we treat the whole modelling process as\na weakly supervised learning problem. A two-stage model training algorithm and\ntwo neural network architectures are proposed. The experiment results show\ncompetitive model performance, and the trained models can be used for real-time\nfeed load estimation for grind process optimisation.",
    "descriptor": "\nComments: 11 pages, 15 figures This paper has been submitted to the Journal of Minerals Engineering (this https URL)\n",
    "authors": [
      "Li Guo",
      "Yonghong Peng",
      "Rui Qin",
      "Bingyu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.04063"
  },
  {
    "id": "arXiv:2110.04064",
    "title": "A Neural Anthropometer Learning from Body Dimensions Computed on Human  3D Meshes",
    "abstract": "Human shape estimation has become increasingly important both theoretically\nand practically, for instance, in 3D mesh estimation, distance garment\nproduction and computational forensics, to mention just a few examples. As a\nfurther specialization, \\emph{Human Body Dimensions Estimation} (HBDE) focuses\non estimating human body measurements like shoulder width or chest\ncircumference from images or 3D meshes usually using supervised learning\napproaches. The main obstacle in this context is the data scarcity problem, as\ncollecting this ground truth requires expensive and difficult procedures. This\nobstacle can be overcome by obtaining realistic human measurements from 3D\nhuman meshes. However, a) there are no well established methods to calculate\nHBDs from 3D meshes and b) there are no benchmarks to fairly compare results on\nthe HBDE task. Our contribution is twofold. On the one hand, we present a\nmethod to calculate right and left arm length, shoulder width, and inseam\n(crotch height) from 3D meshes with focus on potential medical, virtual try-on\nand distance tailoring applications. On the other hand, we use four additional\nbody dimensions calculated using recently published methods to assemble a set\nof eight body dimensions which we use as a supervision signal to our Neural\nAnthropometer: a convolutional neural network capable of estimating these\ndimensions. To assess the estimation, we train the Neural Anthropometer with\nsynthetic images of 3D meshes, from which we calculated the HBDs and observed\nthat the network's overall mean estimate error is $20.89$ mm (relative error of\n2.84\\%). The results we present are fully reproducible and establish a fair\nbaseline for research on the task of HBDE, therefore enabling the community\nwith a valuable method.",
    "descriptor": "\nComments: Accepted to the IEEE Symposium Series on Computational Intelligence (IEEE SSCI 2021)\n",
    "authors": [
      "Yansel Gonz\u00e1lez Tejeda",
      "Helmut A. Mayer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04064"
  },
  {
    "id": "arXiv:2110.04065",
    "title": "Test-time Batch Statistics Calibration for Covariate Shift",
    "abstract": "Deep neural networks have a clear degradation when applying to the unseen\nenvironment due to the covariate shift. Conventional approaches like domain\nadaptation requires the pre-collected target data for iterative training, which\nis impractical in real-world applications. In this paper, we propose to adapt\nthe deep models to the novel environment during inference. An previous solution\nis test time normalization, which substitutes the source statistics in BN\nlayers with the target batch statistics. However, we show that test time\nnormalization may potentially deteriorate the discriminative structures due to\nthe mismatch between target batch statistics and source parameters. To this\nend, we present a general formulation $\\alpha$-BN to calibrate the batch\nstatistics by mixing up the source and target statistics for both alleviating\nthe domain shift and preserving the discriminative structures. Based on\n$\\alpha$-BN, we further present a novel loss function to form a unified test\ntime adaptation framework Core, which performs the pairwise class correlation\nonline optimization. Extensive experiments show that our approaches achieve the\nstate-of-the-art performance on total twelve datasets from three topics,\nincluding model robustness to corruptions, domain generalization on image\nclassification and semantic segmentation. Particularly, our $\\alpha$-BN\nimproves 28.4\\% to 43.9\\% on GTA5 $\\rightarrow$ Cityscapes without any\ntraining, even outperforms the latest source-free domain adaptation method.",
    "descriptor": "",
    "authors": [
      "Fuming You",
      "Jingjing Li",
      "Zhou Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04065"
  },
  {
    "id": "arXiv:2110.04066",
    "title": "MToFNet: Object Anti-Spoofing with Mobile Time-of-Flight Data",
    "abstract": "In online markets, sellers can maliciously recapture others' images on\ndisplay screens to utilize as spoof images, which can be challenging to\ndistinguish in human eyes. To prevent such harm, we propose an anti-spoofing\nmethod using the paired rgb images and depth maps provided by the mobile camera\nwith a Time-of-Fight sensor. When images are recaptured on display screens,\nvarious patterns differing by the screens as known as the moir\\'e patterns can\nbe also captured in spoof images. These patterns lead the anti-spoofing model\nto be overfitted and unable to detect spoof images recaptured on unseen media.\nTo avoid the issue, we build a novel representation model composed of two\nembedding models, which can be trained without considering the recaptured\nimages. Also, we newly introduce mToF dataset, the largest and most diverse\nobject anti-spoofing dataset, and the first to utilize ToF data. Experimental\nresults confirm that our model achieves robust generalization even across\nunseen domains.",
    "descriptor": "",
    "authors": [
      "Yonghyun Jeong",
      "Doyeon Kim",
      "Jaehyeon Lee",
      "Minki Hong",
      "Solbi Hwang",
      "Jongwon Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04066"
  },
  {
    "id": "arXiv:2110.04067",
    "title": "Deep Slap Fingerprint Segmentation for Juveniles and Adults",
    "abstract": "Many fingerprint recognition systems capture four fingerprints in one image.\nIn such systems, the fingerprint processing pipeline must first segment each\nfour-fingerprint slap into individual fingerprints. Note that most of the\ncurrent fingerprint segmentation algorithms have been designed and evaluated\nusing only adult fingerprint datasets. In this work, we have developed a\nhuman-annotated in-house dataset of 15790 slaps of which 9084 are adult samples\nand 6706 are samples drawn from children from ages 4 to 12. Subsequently, the\ndataset is used to evaluate the matching performance of the NFSEG, a slap\nfingerprint segmentation system developed by NIST, on slaps from adults and\njuvenile subjects. Our results reveal the lower performance of NFSEG on slaps\nfrom juvenile subjects. Finally, we utilized our novel dataset to develop the\nMask-RCNN based Clarkson Fingerprint Segmentation (CFSEG). Our matching results\nusing the Verifinger fingerprint matcher indicate that CFSEG outperforms NFSEG\nfor both adults and juvenile slaps. The CFSEG model is publicly available at\n\\url{https://github.com/keivanB/Clarkson_Finger_Segment}",
    "descriptor": "",
    "authors": [
      "M. G. Sarwar Murshed",
      "Robert Kline",
      "Keivan Bahmani",
      "Faraz Hussain",
      "Stephanie Schuckers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.04067"
  },
  {
    "id": "arXiv:2110.04068",
    "title": "Measurement of In-Circuit Common-Mode Impedance at the AC Input of a  Motor Drive System",
    "abstract": "The in-circuit common-mode (CM) impedance at the AC input of a motor drive\nsystem (MDS) provides valuable inputs for evaluating and estimating the CM\nelectromagnetic interference (EMI) noise generated by the switching of power\nsemiconductor devices in the MDS. This paper introduces a single-probe setup\n(SPS) with frequency-domain measurement to extract the in-circuit CM impedance\nof a MDS under its different operating modes. The SPS has the merits of\nnon-contact measurement and simple structure.",
    "descriptor": "\nComments: This conference paper has been accepted to be published in IEEE Xplore. arXiv admin note: substantial text overlap with arXiv:2110.00208\n",
    "authors": [
      "Zhenyu Zhao",
      "Fei Fan",
      "Arjuna Weerasinghe",
      "Pengfei Tu",
      "Kye Yak See"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)",
      "Classical Physics (physics.class-ph)",
      "Instrumentation and Detectors (physics.ins-det)"
    ],
    "url": "https://arxiv.org/abs/2110.04068"
  },
  {
    "id": "arXiv:2110.04069",
    "title": "BI-RADS-Net: An Explainable Multitask Learning Approach for Cancer  Diagnosis in Breast Ultrasound Images",
    "abstract": "In healthcare, it is essential to explain the decision-making process of\nmachine learning models to establish the trustworthiness of clinicians. This\npaper introduces BI-RADS-Net, a novel explainable deep learning approach for\ncancer detection in breast ultrasound images. The proposed approach\nincorporates tasks for explaining and classifying breast tumors, by learning\nfeature representations relevant to clinical diagnosis. Explanations of the\npredictions (benign or malignant) are provided in terms of morphological\nfeatures that are used by clinicians for diagnosis and reporting in medical\npractice. The employed features include the BI-RADS descriptors of shape,\norientation, margin, echo pattern, and posterior features. Additionally, our\napproach predicts the likelihood of malignancy of the findings, which relates\nto the BI-RADS assessment category reported by clinicians. Experimental\nvalidation on a dataset consisting of 1,192 images indicates improved model\naccuracy, supported by explanations in clinical terms using the BI-RADS\nlexicon.",
    "descriptor": "",
    "authors": [
      "Boyu Zhang",
      "Aleksandar Vakanski",
      "Min Xian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04069"
  },
  {
    "id": "arXiv:2110.04070",
    "title": "Dataset Structural Index: Understanding a machine's perspective towards  visual data",
    "abstract": "With advances in vision and perception architectures, we have realized that\nworking with data is equally crucial, if not more, than the algorithms. Till\ntoday, we have trained machines based on our knowledge and perspective of the\nworld. The entire concept of Dataset Structural Index(DSI) revolves around\nunderstanding a machine`s perspective of the dataset. With DSI, I show two meta\nvalues with which we can get more information over a visual dataset and use it\nto optimize data, create better architectures, and have an ability to guess\nwhich model would work best. These two values are the Variety contribution\nratio and Similarity matrix. In the paper, I show many applications of DSI, one\nof which is how the same level of accuracy can be achieved with the same model\narchitectures trained over less amount of data.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2011.04728\n",
    "authors": [
      "Dishant Parikh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04070"
  },
  {
    "id": "arXiv:2110.04075",
    "title": "KOHTD: Kazakh Offline Handwritten Text Dataset",
    "abstract": "Despite the transition to digital information exchange, many documents, such\nas invoices, taxes, memos and questionnaires, historical data, and answers to\nexam questions, still require handwritten inputs. In this regard, there is a\nneed to implement Handwritten Text Recognition (HTR) which is an automatic way\nto decrypt records using a computer. Handwriting recognition is challenging\nbecause of the virtually infinite number of ways a person can write the same\nmessage. For this proposal we introduce Kazakh handwritten text recognition\nresearch, a comprehensive dataset of Kazakh handwritten texts is necessary.\nThis is particularly true given the lack of a dataset for handwritten Kazakh\ntext. In this paper, we proposed our extensive Kazakh offline Handwritten Text\ndataset (KOHTD), which has 3000 handwritten exam papers and more than 140335\nsegmented images and there are approximately 922010 symbols. It can serve\nresearchers in the field of handwriting recognition tasks by using deep and\nmachine learning. We used a variety of popular text recognition methods for\nword and line recognition in our studies, including CTC-based and\nattention-based methods. The findings demonstrate KOHTD's diversity. Also, we\nproposed a Genetic Algorithm (GA) for line and word segmentation based on\nrandom enumeration of a parameter. The dataset and GA code are available at\nhttps://github.com/abdoelsayed2016/KOHTD.",
    "descriptor": "",
    "authors": [
      "Nazgul Toiganbayeva",
      "Mahmoud Kasem",
      "Galymzhan Abdimanap",
      "Kairat Bostanbekov",
      "Abdelrahman Abdallah",
      "Anel Alimova",
      "Daniyar Nurseitov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04075"
  },
  {
    "id": "arXiv:2110.04076",
    "title": "Self-supervised Point Cloud Prediction Using 3D Spatio-temporal  Convolutional Networks",
    "abstract": "Exploiting past 3D LiDAR scans to predict future point clouds is a promising\nmethod for autonomous mobile systems to realize foresighted state estimation,\ncollision avoidance, and planning. In this paper, we address the problem of\npredicting future 3D LiDAR point clouds given a sequence of past LiDAR scans.\nEstimating the future scene on the sensor level does not require any preceding\nsteps as in localization or tracking systems and can be trained\nself-supervised. We propose an end-to-end approach that exploits a 2D range\nimage representation of each 3D LiDAR scan and concatenates a sequence of range\nimages to obtain a 3D tensor. Based on such tensors, we develop an\nencoder-decoder architecture using 3D convolutions to jointly aggregate spatial\nand temporal information of the scene and to predict the future 3D point\nclouds. We evaluate our method on multiple datasets and the experimental\nresults suggest that our method outperforms existing point cloud prediction\narchitectures and generalizes well to new, unseen environments without\nadditional fine-tuning. Our method operates online and is faster than the\ncommon LiDAR frame rate of 10 Hz.",
    "descriptor": "\nComments: Accepted for CoRL 2021\n",
    "authors": [
      "Benedikt Mersch",
      "Xieyuanli Chen",
      "Jens Behley",
      "Cyrill Stachniss"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.04076"
  },
  {
    "id": "arXiv:2110.04077",
    "title": "Physical Context and Timing Aware Sequence Generating GANs",
    "abstract": "Generative Adversarial Networks (GANs) have shown remarkable successes in\ngenerating realistic images and interpolating changes between images. Existing\nmodels, however, do not take into account physical contexts behind images in\ngenerating the images, which may cause unrealistic changes. Furthermore, it is\ndifficult to generate the changes at a specific timing and they often do not\nmatch with actual changes. This paper proposes a novel GAN, named Physical\nContext and Timing aware sequence generating GANs (PCTGAN), that generates an\nimage in a sequence at a specific timing between two images with considering\nphysical contexts behind them. Our method consists of three components: an\nencoder, a generator, and a discriminator. The encoder estimates latent vectors\nfrom the beginning and ending images, their timings, and a target timing. The\ngenerator generates images and the physical contexts at the beginning, ending,\nand target timing from the corresponding latent vectors. The discriminator\ndiscriminates whether the generated images and contexts are real or not. In the\nexperiments, PCTGAN is applied to a data set of sequential changes of shapes in\ndie forging processes. We show that both timing and physical contexts are\neffective in generating sequential images.",
    "descriptor": "",
    "authors": [
      "Hayato Futase",
      "Tomoki Tsujimura",
      "Tetsuya Kajimoto",
      "Hajime Kawarazaki",
      "Toshiyuki Suzuki",
      "Makoto Miwa",
      "Yutaka Sasaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.04077"
  },
  {
    "id": "arXiv:2110.04079",
    "title": "A Hybrid Spatial-temporal Sequence-to-one Neural Network Model for Lane  Detection",
    "abstract": "Reliable and accurate lane detection is of vital importance for the safe\nperformance of Lane Keeping Assistance and Lane Departure Warning systems.\nHowever, under certain challenging peculiar circumstances (e.g., marking\ndegradation, serious vehicle occlusion), it is difficult to get satisfactory\nperformance in accurately detecting the lane markings from one single image\nwhich is often the case in current literature. Since road markings are\ncontinuous lines on the road, the lanes that are difficult to be accurately\ndetected in the current image frame might potentially be better inferred out if\ninformation from previous frames is incorporated. For this, we propose a novel\nhybrid spatial-temporal sequence-to-one deep learning architecture making full\nuse of the spatial-temporal information in multiple frames of a continuous\nsequence of images to detect lane markings in the very last current image\nframe. Specifically, the hybrid model integrates the spatial convolutional\nneural network (SCNN), which is powerful in extracting spatial features and\nrelationships in one single image, with convolutional long-short term memory\n(ConvLSTM) neural network, which can capture the spatial-temporal correlations\nand time dependencies among the image sequences. With the proposed model\narchitecture, the advantages of both SCNN and ConvLSTM are fully combined and\nthe spatial-temporal information is fully exploited. Treating lane detection as\nthe image segmentation problem, we applied encoder-decoder structures to make\nit work in an end-to-end way. Extensive experiments on two large-scale datasets\nreveal that our proposed model can effectively handle challenging driving\nscenes and outperforms previous state-of-the-art methods.",
    "descriptor": "\nComments: 33 pages, 7 figures, under review by Transportation Research Part C: Emerging Technologies\n",
    "authors": [
      "Yongqi Dong",
      "Sandeep Patil",
      "Bart van Arem",
      "Haneen Farah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.04079"
  },
  {
    "id": "arXiv:2110.04080",
    "title": "Landslide Detection in Real-Time Social Media Image Streams",
    "abstract": "Lack of global data inventories obstructs scientific modeling of and response\nto landslide hazards which are oftentimes deadly and costly. To remedy this\nlimitation, new approaches suggest solutions based on citizen science that\nrequires active participation. However, as a non-traditional data source,\nsocial media has been increasingly used in many disaster response and\nmanagement studies in recent years. Inspired by this trend, we propose to\ncapitalize on social media data to mine landslide-related information\nautomatically with the help of artificial intelligence (AI) techniques.\nSpecifically, we develop a state-of-the-art computer vision model to detect\nlandslides in social media image streams in real time. To that end, we create a\nlarge landslide image dataset labeled by experts and conduct extensive model\ntraining experiments. The experimental results indicate that the proposed model\ncan be deployed in an online fashion to support global landslide susceptibility\nmaps and emergency response.",
    "descriptor": "",
    "authors": [
      "Ferda Ofli",
      "Muhammad Imran",
      "Umair Qazi",
      "Julien Roch",
      "Catherine Pennington",
      "Vanessa J. Banks",
      "Remy Bossu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04080"
  },
  {
    "id": "arXiv:2110.04081",
    "title": "Flow Plugin Network for conditional generation",
    "abstract": "Generative models have gained many researchers' attention in the last years\nresulting in models such as StyleGAN for human face generation or PointFlow for\nthe 3D point cloud generation. However, by default, we cannot control its\nsampling process, i.e., we cannot generate a sample with a specific set of\nattributes. The current approach is model retraining with additional inputs and\ndifferent architecture, which requires time and computational resources. We\npropose a novel approach that enables to a generation of objects with a given\nset of attributes without retraining the base model. For this purpose, we\nutilize the normalizing flow models - Conditional Masked Autoregressive Flow\nand Conditional Real NVP, as a Flow Plugin Network (FPN).",
    "descriptor": "",
    "authors": [
      "Patryk Wielopolski",
      "Micha\u0142 Koperski",
      "Maciej Zi\u0119ba"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04081"
  },
  {
    "id": "arXiv:2110.04083",
    "title": "Appearance",
    "abstract": "Socially interactive agents (SIAs) are no longer mere visions for future user\ninterfaces, as 20 years of research and technology development has enabled the\nuse of virtual and physical agents in day-to-day interfaces and environments.\nThis chapter of the ACM \"The Handbook on Socially Interactive Agents\" reviews\nresearch on and technologies involving socially interactive agents, including\nvirtually embodied agents and physically embodied robots, focusing particularly\non the appearance of socially interactive agents. It covers the history of the\ndevelopment of these technologies; outlines the design space for the appearance\nof agents, including what appearance comprises, modalities in which agents are\npresented, and how agents are constructed; and the features that agents use to\nsupport social interaction, including facial and bodily features, those that\nexpress demographic characteristics, and issues surrounding realism, appeal,\nand the uncanny valley. The chapter concludes with a brief discussion of open\nquestions surrounding the appearance of socially interactive agents.",
    "descriptor": "\nComments: 38 pages, 16 figures, appears in the \"The Handbook on Socially Interactive Agents: 20 Years of Research on Embodied Conversational Agents, Intelligent Virtual Agents, and Social Robotics Volume 1: Methods, Behavior, Cognition,\" published by the ACM\n",
    "authors": [
      "Rachel McDonnell",
      "Bilge Mutlu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.04083"
  },
  {
    "id": "arXiv:2110.04089",
    "title": "Task Allocation for Multi-Robot Task and Motion Planning: a case for  Object Picking in Cluttered Workspaces",
    "abstract": "We present an AND/OR graph-based, integrated multi-robot task and motion\nplanning approach which (i) performs task allocation coordinating the activity\nof a given number of robots, and (ii) is capable of handling tasks which\ninvolve an a priori unknown number of object re-arrangements, such as those\ninvolved in retrieving objects from cluttered workspaces. Such situations may\narise, for example, in search and rescue scenarios, while locating/picking a\ncluttered object of interest. The corresponding problem falls under the\ncategory of planning in clutter. One of the challenges while planning in\nclutter is that the number of object re-arrangements required to pick the\ntarget object is not known beforehand, in general. Moreover, such tasks can be\ndecomposed in a variety of ways, since different cluttering object\nre-arrangements are possible to reach the target object. In our approach, task\nallocation and decomposition is achieved by maximizing a combined utility\nfunction. The allocated tasks are performed by an integrated task and motion\nplanner, which is robust to the requirement of an unknown number of\nre-arrangement tasks. We demonstrate our results with experiments in simulation\non two Franka Emika manipulators.",
    "descriptor": "\nComments: Accepted for presentation at 20th International Conference of the Italian Association for Artificial Intelligence, Milano (IT), December 1st-3rd, 2021\n",
    "authors": [
      "Hossein Karami",
      "Antony Thomas",
      "Fulvio Mastrogiovanni"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04089"
  },
  {
    "id": "arXiv:2110.04091",
    "title": "Affective Burst Detection from Speech using Kernel-fusion Dilated  Convolutional Neural Networks",
    "abstract": "As speech-interfaces are getting richer and widespread, speech emotion\nrecognition promises more attractive applications. In the continuous emotion\nrecognition (CER) problem, tracking changes across affective states is an\nimportant and desired capability. Although CER studies widely use correlation\nmetrics in evaluations, these metrics do not always capture all the\nhigh-intensity changes in the affective domain. In this paper, we define a\nnovel affective burst detection problem to accurately capture high-intensity\nchanges of the affective attributes. For this problem, we formulate a two-class\nclassification approach to isolate affective burst regions over the affective\nstate contour. The proposed classifier is a kernel-fusion dilated convolutional\nneural network (KFDCNN) architecture driven by speech spectral features to\nsegment the affective attribute contour into idle and burst sections.\nExperimental evaluations are performed on the RECOLA and CreativeIT datasets.\nThe proposed KFDCNN is observed to outperform baseline feedforward neural\nnetworks on both datasets.",
    "descriptor": "",
    "authors": [
      "Berkay Kopru",
      "Engin Erzin"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Human-Computer Interaction (cs.HC)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.04091"
  },
  {
    "id": "arXiv:2110.04092",
    "title": "Efficient energy-preserving exponential integrators for multi-components  Hamiltonian systems",
    "abstract": "In this paper, we develop a framework to construct energy-preserving methods\nfor multi-components Hamiltonian systems, combining the exponential integrator\nand the partitioned averaged vector field method. This leads to numerical\nschemes with both advantages of long-time stability and excellent behavior for\nhighly oscillatory or stiff problems. Compared to the existing\nenergy-preserving exponential integrators (EP-EI) in practical implementation,\nour proposed methods are much efficient which can at least be computed by\nsubsystem instead of handling a nonlinear coupling system at a time. Moreover,\nfor most cases, such as the Klein-Gordon-Schr\\\"{o}dinger equations and the\nKlein-Gordon-Zakharov equations considered in this paper, the computational\ncost can be further reduced. Specifically, one part of the derived schemes is\ntotally explicit, and the other is linearly implicit. In addition, we present\nrigorous proof of conserving the original energy of Hamiltonian systems, in\nwhich an alternative technique is utilized so that no additional assumptions\nare required, in contrast to the proof strategies used for the existing EP-EI.\nNumerical experiments are provided to demonstrate the significant advantages in\naccuracy, computational efficiency, and the ability to capture highly\noscillatory solutions.",
    "descriptor": "\nComments: 29 pages, 68 figures\n",
    "authors": [
      "X. Gu",
      "C. Jiang",
      "Y. Wang",
      "W. Cai"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.04092"
  },
  {
    "id": "arXiv:2110.04093",
    "title": "How to Do Things without Words: Modeling Semantic Drift of Emoji",
    "abstract": "Emoji have become a significant part of our informal textual communication.\nPrevious work addressing the societal and linguistic functions of emoji\noverlook the evolving meaning of the symbol. This evolution could be addressed\nthrough the framework of semantic drifts. In this paper we model and analyze\nthe semantic drift of emoji and discuss the features that may be contributing\nto the drift, some are unique to emoji and some are more general.",
    "descriptor": "",
    "authors": [
      "Eyal Arviv",
      "Oren Tsur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04093"
  },
  {
    "id": "arXiv:2110.04094",
    "title": "Privacy-Aware Communication Over the Wiretap Channel with Generative  Networks",
    "abstract": "We study privacy-aware communication over a wiretap channel using end-to-end\nlearning. Alice wants to transmit a source signal to Bob over a binary\nsymmetric channel, while passive eavesdropper Eve tries to infer some sensitive\nattribute of Alice's source based on its overheard signal. Since we usually do\nnot have access to true distributions, we propose a data-driven approach using\nvariational autoencoder (VAE)-based joint source channel coding (JSCC). We show\nthrough simulations with the colored MNIST dataset that our approach provides\nhigh reconstruction quality at the receiver while confusing the eavesdropper\nabout the latent sensitive attribute, which consists of the color and thickness\nof the digits. Finally, we consider a parallel-channel scenario, and show that\nour approach arranges the information transmission such that the channels with\nhigher noise levels at the eavesdropper carry the sensitive information, while\nthe non-sensitive information is transmitted over more vulnerable channels.",
    "descriptor": "",
    "authors": [
      "Ecenaz Erdemir",
      "Pier Luigi Dragotti",
      "Deniz Gunduz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04094"
  },
  {
    "id": "arXiv:2110.04095",
    "title": "A Mining Software Repository Extended Cookbook: Lessons learned from a  literature review",
    "abstract": "The main purpose of Mining Software Repositories (MSR) is to discover the\nlatest enhancements and provide an insight into how to make improvements in a\nsoftware project. In light of it, this paper updates the MSR findings of the\noriginal MSR Cookbook, by first conducting a systematic mapping study to elicit\nand analyze the state-of-the-art, and then proposing an extended version of the\nCookbook. This extended Cookbook was built on four high-level themes, which\nwere derived from the analysis of a list of 112 selected studies. Hence, it was\nused to consolidate the extended Cookbook as a contribution to practice and\nresearch in the following areas by: 1) including studies published in all\navailable and relevant publication venues; 2) including and updating\nrecommendations in all four high-level themes, with an increase of 84% in\ncomments in this study when compared with the original MSR Cookbook; 3)\nsummarizing the tools employed for each high-level theme; and 4) providing\nlessons learned for future studies. Thus, the extended Cookbook examined in\nthis work can support new research projects, as upgraded recommendations and\nthe lessons learned are available with the aid of samples and tools.",
    "descriptor": "",
    "authors": [
      "Daniel Barros",
      "Flavio Horita",
      "Igor Wiese",
      "Kanan Silva"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04095"
  },
  {
    "id": "arXiv:2110.04099",
    "title": "Topology-Imbalance Learning for Semi-Supervised Node Classification",
    "abstract": "The class imbalance problem, as an important issue in learning node\nrepresentations, has drawn increasing attention from the community. Although\nthe imbalance considered by existing studies roots from the unequal quantity of\nlabeled examples in different classes (quantity imbalance), we argue that graph\ndata expose a unique source of imbalance from the asymmetric topological\nproperties of the labeled nodes, i.e., labeled nodes are not equal in terms of\ntheir structural role in the graph (topology imbalance). In this work, we first\nprobe the previously unknown topology-imbalance issue, including its\ncharacteristics, causes, and threats to semi-supervised node classification\nlearning. We then provide a unified view to jointly analyzing the quantity- and\ntopology- imbalance issues by considering the node influence shift phenomenon\nwith the Label Propagation algorithm. In light of our analysis, we devise an\ninfluence conflict detection -- based metric Totoro to measure the degree of\ngraph topology imbalance and propose a model-agnostic method ReNode to address\nthe topology-imbalance issue by re-weighting the influence of labeled nodes\nadaptively based on their relative positions to class boundaries. Systematic\nexperiments demonstrate the effectiveness and generalizability of our method in\nrelieving topology-imbalance issue and promoting semi-supervised node\nclassification. The further analysis unveils varied sensitivity of different\ngraph neural networks (GNNs) to topology imbalance, which may serve as a new\nperspective in evaluating GNN architectures.",
    "descriptor": "\nComments: Accepted By NeurIPS 2021\n",
    "authors": [
      "Deli Chen",
      "Yankai Lin",
      "Guangxiang Zhao",
      "Xuancheng Ren",
      "Peng Li",
      "Jie Zhou",
      "Xu Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04099"
  },
  {
    "id": "arXiv:2110.04101",
    "title": "TFix+: Self-configuring Hybrid Timeout Bug Fixing for Cloud Systems",
    "abstract": "Timeout bugs can cause serious availability and performance issues which are\noften difficult to fix due to the lack of diagnostic information. Previous work\nproposed solutions for fixing specific type of timeout-related performance\nbugs. In this paper, we present TFix+, a self-configuring timeout bug fixing\nframework for automatically correcting two major kinds of timeout bugs (i.e.,\nmisused timeout bugs and missing timeout bugs) with dynamic timeout value\npredictions. TFix+ provides two new hybrid schemes for fixing misused and\nmissing timeout bugs, respectively. TFix+ further provides prediction-driven\ntimeout variable configuration based on runtime function tracing. We have\nimplemented a prototype of TFix+ and conducted experiments on 16 real world\ntimeout bugs. Our experimental results show that TFix+ can effectively fix 15\nout of tested 16 timeout bugs.",
    "descriptor": "",
    "authors": [
      "Jingzhu He",
      "Ting Dai",
      "Xiaohui Gu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2110.04101"
  },
  {
    "id": "arXiv:2110.04102",
    "title": "Emulating homoeostatic effects with metal-oxide memristors T-dependence",
    "abstract": "Memristor technologies have been rapidly maturing for the past decade to\nsupport the needs of emerging memory, artificial synapses, logic gates and\nbio-signal processing applications. So far, however, most concepts are\ndeveloped by exploiting the tuneable resistive state of memristors with other\nphysical characteristics being ignored. Here, we report on the thermal\nproperties of metal-oxide memristors and demonstrate how these can be used to\nemulate a fundamental function of biological neurons: homeostasis. We show that\nthermal control mechanisms, frequently dismissed for their generally slow and\nbroad-brush granularity, may in fact be an appropriate approach to emulating\nsimilarly slow and broad-brush biological mechanisms due to their extreme\nsimplicity of implementation. We further demonstrate that metal-oxide\nmemristors can be utilised as thermometers and exhibit a programmable\ntemperature sensitivity. This work paves the way towards future systems that\nemploy the rich physical properties of memristors, beyond their electrical\nstate-tuneability, to power a new generation of advanced electronic devices.",
    "descriptor": "\nComments: 5 Pages main, 7 pages supplemental, 3 figures\n",
    "authors": [
      "Thomas Abbey",
      "Alexantrou Serb",
      "Spyros Stathopoulos",
      "Loukas Michalas",
      "Themis Prodromakis"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2110.04102"
  },
  {
    "id": "arXiv:2110.04111",
    "title": "Discover, Hallucinate, and Adapt: Open Compound Domain Adaptation for  Semantic Segmentation",
    "abstract": "Unsupervised domain adaptation (UDA) for semantic segmentation has been\nattracting attention recently, as it could be beneficial for various\nlabel-scarce real-world scenarios (e.g., robot control, autonomous driving,\nmedical imaging, etc.). Despite the significant progress in this field, current\nworks mainly focus on a single-source single-target setting, which cannot\nhandle more practical settings of multiple targets or even unseen targets. In\nthis paper, we investigate open compound domain adaptation (OCDA), which deals\nwith mixed and novel situations at the same time, for semantic segmentation. We\npresent a novel framework based on three main design principles: discover,\nhallucinate, and adapt. The scheme first clusters compound target data based on\nstyle, discovering multiple latent domains (discover). Then, it hallucinates\nmultiple latent target domains in source by using image-translation\n(hallucinate). This step ensures the latent domains in the source and the\ntarget to be paired. Finally, target-to-source alignment is learned separately\nbetween domains (adapt). In high-level, our solution replaces a hard OCDA\nproblem with much easier multiple UDA problems. We evaluate our solution on\nstandard benchmark GTA to C-driving, and achieved new state-of-the-art results.",
    "descriptor": "\nComments: NeurIPS 2020\n",
    "authors": [
      "KwanYong Park",
      "Sanghyun Woo",
      "Inkyu Shin",
      "In So Kweon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04111"
  },
  {
    "id": "arXiv:2110.04117",
    "title": "Detecting adversaries in Crowdsourcing",
    "abstract": "Despite its successes in various machine learning and data science tasks,\ncrowdsourcing can be susceptible to attacks from dedicated adversaries. This\nwork investigates the effects of adversaries on crowdsourced classification,\nunder the popular Dawid and Skene model. The adversaries are allowed to deviate\narbitrarily from the considered crowdsourcing model, and may potentially\ncooperate. To address this scenario, we develop an approach that leverages the\nstructure of second-order moments of annotator responses, to identify large\nnumbers of adversaries, and mitigate their impact on the crowdsourcing task.\nThe potential of the proposed approach is empirically demonstrated on synthetic\nand real crowdsourcing datasets.",
    "descriptor": "\nComments: Full version of ICDM 2021 short paper\n",
    "authors": [
      "Panagiotis A. Traganitis",
      "Georgios B. Giannakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04117"
  },
  {
    "id": "arXiv:2110.04119",
    "title": "A Multi-viewpoint Outdoor Dataset for Human Action Recognition",
    "abstract": "Advancements in deep neural networks have contributed to near perfect results\nfor many computer vision problems such as object recognition, face recognition\nand pose estimation. However, human action recognition is still far from\nhuman-level performance. Owing to the articulated nature of the human body, it\nis challenging to detect an action from multiple viewpoints, particularly from\nan aerial viewpoint. This is further compounded by a scarcity of datasets that\ncover multiple viewpoints of actions. To fill this gap and enable research in\nwider application areas, we present a multi-viewpoint outdoor action\nrecognition dataset collected from YouTube and our own drone. The dataset\nconsists of 20 dynamic human action classes, 2324 video clips and 503086\nframes. All videos are cropped and resized to 720x720 without distorting the\noriginal aspect ratio of the human subjects in videos. This dataset should be\nuseful to many research areas including action recognition, surveillance and\nsituational awareness. We evaluated the dataset with a two-stream CNN\narchitecture coupled with a recently proposed temporal pooling scheme called\nkernelized rank pooling that produces nonlinear feature subspace\nrepresentations. The overall baseline action recognition accuracy is 74.0%.",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Asanka G. Perera",
      "Yee Wei Law",
      "Titilayo T. Ogunwa",
      "Javaan Chahl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04119"
  },
  {
    "id": "arXiv:2110.04121",
    "title": "On the Limitations of Multimodal VAEs",
    "abstract": "Multimodal variational autoencoders (VAEs) have shown promise as efficient\ngenerative models for weakly-supervised data. Yet, despite their advantage of\nweak supervision, they exhibit a gap in generative quality compared to unimodal\nVAEs, which are completely unsupervised. In an attempt to explain this gap, we\nuncover a fundamental limitation that applies to a large family of\nmixture-based multimodal VAEs. We prove that the sub-sampling of modalities\nenforces an undesirable upper bound on the multimodal ELBO and thereby limits\nthe generative quality of the respective models. Empirically, we showcase the\ngenerative quality gap on both synthetic and real data and present the\ntradeoffs between different variants of multimodal VAEs. We find that none of\nthe existing approaches fulfills all desired criteria of an effective\nmultimodal generative model when applied on more complex datasets than those\nused in previous benchmarks. In summary, we identify, formalize, and validate\nfundamental limitations of VAE-based approaches for modeling weakly-supervised\ndata and discuss implications for real-world applications.",
    "descriptor": "",
    "authors": [
      "Imant Daunhawer",
      "Thomas M. Sutter",
      "Kieran Chin-Cheong",
      "Emanuele Palumbo",
      "Julia E. Vogt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04121"
  },
  {
    "id": "arXiv:2110.04123",
    "title": "I Do Not Understand What I Cannot Define: Automatic Question Generation  With Pedagogically-Driven Content Selection",
    "abstract": "Most learners fail to develop deep text comprehension when reading textbooks\npassively. Posing questions about what learners have read is a well-established\nway of fostering their text comprehension. However, many textbooks lack\nself-assessment questions because authoring them is timeconsuming and\nexpensive. Automatic question generators may alleviate this scarcity by\ngenerating sound pedagogical questions. However, generating questions\nautomatically poses linguistic and pedagogical challenges. What should we ask?\nAnd, how do we phrase the question automatically? We address those challenges\nwith an automatic question generator grounded in learning theory. The paper\nintroduces a novel pedagogically meaningful content selection mechanism to find\nquestion-worthy sentences and answers in arbitrary textbook contents. We\nconducted an empirical evaluation study with educational experts, annotating\n150 generated questions in six different domains. Results indicate a high\nlinguistic quality of the generated questions. Furthermore, the evaluation\nresults imply that the majority of the generated questions inquire central\ninformation related to the given text and may foster text comprehension in\nspecific learning scenarios.",
    "descriptor": "",
    "authors": [
      "Tim Steuer",
      "Anna Filighera",
      "Tobias Meuser",
      "Christoph Rensing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04123"
  },
  {
    "id": "arXiv:2110.04124",
    "title": "Ensemble Neural Representation Networks",
    "abstract": "Implicit Neural Representation (INR) has recently attracted considerable\nattention for storing various types of signals in continuous forms. The\nexisting INR networks require lengthy training processes and high-performance\ncomputational resources. In this paper, we propose a novel sub-optimal ensemble\narchitecture for INR that resolves the aforementioned problems. In this\narchitecture, the representation task is divided into several sub-tasks done by\nindependent sub-networks. We show that the performance of the proposed ensemble\nINR architecture may decrease if the dimensions of sub-networks increase.\nHence, it is vital to suggest an optimization algorithm to find the sub-optimal\nstructure of the ensemble network, which is done in this paper. According to\nthe simulation results, the proposed architecture not only has significantly\nfewer floating-point operations (FLOPs) and less training time, but it also has\nbetter performance in terms of Peak Signal to Noise Ratio (PSNR) compared to\nthose of its counterparts.",
    "descriptor": "\nComments: ICASSP 2022 submitted, 5 pages, 5 figures, 1 table\n",
    "authors": [
      "Milad Soltany Kadarvish",
      "Hesam Mojtahedi",
      "Hossein Entezari Zarch",
      "Amirhossein Kazerouni",
      "Alireza Morsali",
      "Azra Abtahi",
      "Farokh Marvasti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.04124"
  },
  {
    "id": "arXiv:2110.04126",
    "title": "3D Infomax improves GNNs for Molecular Property Prediction",
    "abstract": "Molecular property prediction is one of the fastest-growing applications of\ndeep learning with critical real-world impacts. Including 3D molecular\nstructure as input to learned models their performance for many molecular\ntasks. However, this information is infeasible to compute at the scale required\nby several real-world applications. We propose pre-training a model to reason\nabout the geometry of molecules given only their 2D molecular graphs. Using\nmethods from self-supervised learning, we maximize the mutual information\nbetween 3D summary vectors and the representations of a Graph Neural Network\n(GNN) such that they contain latent 3D information. During fine-tuning on\nmolecules with unknown geometry, the GNN still generates implicit 3D\ninformation and can use it to improve downstream tasks. We show that 3D\npre-training provides significant improvements for a wide range of properties,\nsuch as a 22% average MAE reduction on eight quantum mechanical properties.\nMoreover, the learned representations can be effectively transferred between\ndatasets in different molecular spaces.",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Hannes St\u00e4rk",
      "Dominique Beaini",
      "Gabriele Corso",
      "Prudencio Tossou",
      "Christian Dallago",
      "Stephan G\u00fcnnemann",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2110.04126"
  },
  {
    "id": "arXiv:2110.04127",
    "title": "Deep Upper Confidence Bound Algorithm for Contextual Bandit Ranking of  Information Selection",
    "abstract": "Contextual multi-armed bandits (CMAB) have been widely used for learning to\nfilter and prioritize information according to a user's interest. In this work,\nwe analyze top-K ranking under the CMAB framework where the top-K arms are\nchosen iteratively to maximize a reward. The context, which represents a set of\nobservable factors related to the user, is used to increase prediction accuracy\ncompared to a standard multi-armed bandit. Contextual bandit methods have\nmostly been studied under strict linearity assumptions, but we drop that\nassumption and learn non-linear stochastic reward functions with deep neural\nnetworks. We introduce a novel algorithm called the Deep Upper Confidence Bound\n(UCB) algorithm. Deep UCB balances exploration and exploitation with a separate\nneural network to model the learning convergence. We compare the performance of\nmany bandit algorithms varying K over real-world data sets with\nhigh-dimensional data and non-linear reward functions. Empirical results show\nthat the performance of Deep UCB often outperforms though it is sensitive to\nthe problem and reward setup. Additionally, we prove theoretical regret bounds\non Deep UCB giving convergence to optimality for the weak class of CMAB\nproblems.",
    "descriptor": "",
    "authors": [
      "Michael Rawson",
      "Jade Freeman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.04127"
  },
  {
    "id": "arXiv:2110.04129",
    "title": "Morphological Matrices as a Tool for Crowdsourced Ideation",
    "abstract": "Designing a novel product is a difficult task not well suited for non-expert\ncrowd workers. In this work-in-progress paper, we first motivate why the design\nof persuasive products is an interesting context for studying creativity and\nthe creative leap. We then present a pilot study on the crowdsourced design of\npersuasive products. The pilot study motivated our subsequent feasibility study\non the use of morphological matrices as a tool for crowdsourced ideation and\nproduct design. Given the morphological matrix, workers were able to come up\nwith valid and significantly more relevant ideas for novel persuasive products.",
    "descriptor": "",
    "authors": [
      "Jonas Oppenlaender"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.04129"
  },
  {
    "id": "arXiv:2110.04133",
    "title": "Quantifying Inequality in Underreported Medical Conditions",
    "abstract": "Estimating the prevalence of a medical condition, or the proportion of the\npopulation in which it occurs, is a fundamental problem in healthcare and\npublic health. Accurate estimates of the relative prevalence across groups --\ncapturing, for example, that a condition affects women more frequently than men\n-- facilitate effective and equitable health policy which prioritizes groups\nwho are disproportionately affected by a condition. However, it is difficult to\nestimate relative prevalence when a medical condition is underreported. In this\nwork, we provide a method for accurately estimating the relative prevalence of\nunderreported medical conditions, building upon the positive unlabeled learning\nframework. We show that under the commonly made covariate shift assumption --\ni.e., that the probability of having a disease conditional on symptoms remains\nconstant across groups -- we can recover the relative prevalence, even without\nrestrictive assumptions commonly made in positive unlabeled learning and even\nif it is impossible to recover the absolute prevalence. We provide a suite of\nexperiments on synthetic and real health data that demonstrate our method's\nability to recover the relative prevalence more accurately than do baselines,\nand the method's robustness to plausible violations of the covariate shift\nassumption.",
    "descriptor": "",
    "authors": [
      "Divya Shanmugam",
      "Emma Pierson"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04133"
  },
  {
    "id": "arXiv:2110.04135",
    "title": "Revisiting Design Choices in Model-Based Offline Reinforcement Learning",
    "abstract": "Offline reinforcement learning enables agents to leverage large pre-collected\ndatasets of environment transitions to learn control policies, circumventing\nthe need for potentially expensive or unsafe online data collection.\nSignificant progress has been made recently in offline model-based\nreinforcement learning, approaches which leverage a learned dynamics model.\nThis typically involves constructing a probabilistic model, and using the model\nuncertainty to penalize rewards where there is insufficient data, solving for a\npessimistic MDP that lower bounds the true MDP. Existing methods, however,\nexhibit a breakdown between theory and practice, whereby pessimistic return\nought to be bounded by the total variation distance of the model from the true\ndynamics, but is instead implemented through a penalty based on estimated model\nuncertainty. This has spawned a variety of uncertainty heuristics, with little\nto no comparison between differing approaches. In this paper, we compare these\nheuristics, and design novel protocols to investigate their interaction with\nother hyperparameters, such as the number of models, or imaginary rollout\nhorizon. Using these insights, we show that selecting these key hyperparameters\nusing Bayesian Optimization produces superior configurations that are vastly\ndifferent to those currently used in existing hand-tuned state-of-the-art\nmethods, and result in drastically stronger performance.",
    "descriptor": "\nComments: Spotlight @ RL4RealLife Workshop ICML2021\n",
    "authors": [
      "Cong Lu",
      "Philip J. Ball",
      "Jack Parker-Holder",
      "Michael A. Osborne",
      "Stephen J. Roberts"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04135"
  },
  {
    "id": "arXiv:2110.04136",
    "title": "Adaptive Sampling for Heterogeneous Rank Aggregation from Noisy Pairwise  Comparisons",
    "abstract": "In heterogeneous rank aggregation problems, users often exhibit various\naccuracy levels when comparing pairs of items. Thus a uniform querying strategy\nover users may not be optimal. To address this issue, we propose an\nelimination-based active sampling strategy, which estimates the ranking of\nitems via noisy pairwise comparisons from users and improves the users' average\naccuracy by maintaining an active set of users. We prove that our algorithm can\nreturn the true ranking of items with high probability. We also provide a\nsample complexity bound for the proposed algorithm which is better than that of\nnon-active strategies in the literature. Experiments are provided to show the\nempirical advantage of the proposed methods over the state-of-the-art\nbaselines.",
    "descriptor": "",
    "authors": [
      "Yue Wu",
      "Tao Jin",
      "Hao Lou",
      "Pan Xu",
      "Farzad Farnoud",
      "Quanquan Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04136"
  },
  {
    "id": "arXiv:2110.04140",
    "title": "Rapid head-pose detection for automated slice prescription of  fetal-brain MRI",
    "abstract": "In fetal-brain MRI, head-pose changes between prescription and acquisition\npresent a challenge to obtaining the standard sagittal, coronal and axial views\nessential to clinical assessment. As motion limits acquisitions to thick slices\nthat preclude retrospective resampling, technologists repeat ~55-second\nstack-of-slices scans (HASTE) with incrementally reoriented field of view\nnumerous times, deducing the head pose from previous stacks. To address this\ninefficient workflow, we propose a robust head-pose detection algorithm using\nfull-uterus scout scans (EPI) which take ~5 seconds to acquire. Our ~2-second\nprocedure automatically locates the fetal brain and eyes, which we derive from\nmaximally stable extremal regions (MSERs). The success rate of the method\nexceeds 94% in the third trimester, outperforming a trained technologist by up\nto 20%. The pipeline may be used to automatically orient the anatomical\nsequence, removing the need to estimate the head pose from 2D views and\nreducing delays during which motion can occur.",
    "descriptor": "\nComments: 19 pages, 10 figures, 2 tables, fetal MRI, head-pose detection, MSER, scan automation, scan prescription, slice positioning, final published version\n",
    "authors": [
      "Malte Hoffmann",
      "Esra Abaci Turk",
      "Borjan Gagoski",
      "Leah Morgan",
      "Paul Wighton",
      "M. Dylan Tisdall",
      "Martin Reuter",
      "Elfar Adalsteinsson",
      "P. Ellen Grant",
      "Lawrence L. Wald",
      "Andr\u00e9 J. W. van der Kouwe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Medical Physics (physics.med-ph)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2110.04140"
  },
  {
    "id": "arXiv:2110.04146",
    "title": "Arachnophobia Exposure Therapy using Experience-driven Procedural  Content Generation via Reinforcement Learning (EDPCGRL)",
    "abstract": "Personalized therapy, in which a therapeutic practice is adapted to an\nindividual patient, leads to better health outcomes. Typically, this is\naccomplished by relying on a therapist's training and intuition along with\nfeedback from a patient. While there exist approaches to automatically adapt\ntherapeutic content to a patient, they rely on hand-authored, pre-defined\nrules, which may not generalize to all individuals. In this paper, we propose\nan approach to automatically adapt therapeutic content to patients based on\nphysiological measures. We implement our approach in the context of\narachnophobia exposure therapy, and rely on experience-driven procedural\ncontent generation via reinforcement learning (EDPCGRL) to generate virtual\nspiders to match an individual patient. In this initial implementation, and due\nto the ongoing pandemic, we make use of virtual or artificial humans\nimplemented based on prior arachnophobia psychology research. Our EDPCGRL\nmethod is able to more quickly adapt to these virtual humans with high accuracy\nin comparison to existing, search-based EDPCG approaches.",
    "descriptor": "\nComments: 8 pages, 3 figures, AIIDE 2021 Poster\n",
    "authors": [
      "Athar Mahmoudi-Nejad",
      "Matthew Guzdial",
      "Pierre Boulanger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.04146"
  },
  {
    "id": "arXiv:2110.04147",
    "title": "The Impact of Visualizing Design Gradients for Human Designers",
    "abstract": "Mixed-initiative Procedural Content Generation (PCG) refers to tools or\nsystems in which a human designer works with an algorithm to produce game\ncontent. This area of research remains relatively under-explored, with the\nmajority of mixed-initiative PCG level design systems using a common set of\nsearch-based PCG algorithms. In this paper, we introduce a mixed-initiative\ntool employing Exhaustive PCG (EPCG) for puzzle level design to further explore\nmixed-initiative PCG. We run an online human subject study in which individuals\nuse the tool with an EPCG component turned on or off. Our analysis of the\nresults demonstrates that, although a majority of users did not prefer the\ntool, it made the level design process significantly easier, and that the tool\nimpacted the subjects' design process. This paper describes the study results\nand draws lessons for mixed-initiative PCG tool design.",
    "descriptor": "\nComments: 8 pages, 1 figure, AIIDE 2021\n",
    "authors": [
      "Matthew Guzdial",
      "Nathan Sturtevant",
      "Carolyn Yang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04147"
  },
  {
    "id": "arXiv:2110.04148",
    "title": "The Definition-Context-Purpose Paradigm and Other Insights from Industry  Professionals About the Definition of a Quest",
    "abstract": "Among academic communities there is no single agreed upon definition of a\nquest. The industry perspective on this topic is also largely unknown. Thus,\nthee purpose of this paper is to gain an understanding of the definition of a\nquest from industry professionals to better inform the academic community. We\ninterviewed fifteen game developers with experience designing or implementing\nquests or narratives, and process the interviews using thematic analysis to\nidentify trends. We identified a variety of personal developer definitions.\nHowever, we also discovered several themes that may inform future academic\nwork. We introduce the definition-context-purpose paradigm as a synthesis of\nthese trends: elements of a quest, purpose of a quest, and context of a quest.\nFinally, we discuss the developer's reaction to a recently proposed quest\ndefinition as part of a push towards a general quest definition.",
    "descriptor": "\nComments: 8 pages, 2 figures, AIIDE 2021\n",
    "authors": [
      "Kristen K. Yu",
      "Matthew Guzdial",
      "Nathan R. Sturtevant"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.04148"
  },
  {
    "id": "arXiv:2110.04149",
    "title": "KPop Fandoms drive COVID-19 Public Health Messaging on Social Media",
    "abstract": "This report examines an unexpected but significant source of positive public\nhealth messaging during the COVID-19 pandemic -- K-pop fandoms. Leveraging more\nthan 7 million tweets related to mask wearing and K-pop between March 2020 and\nMarch 2021, we analyzed the online spread of the hashtag \\#WearAMask amid\nanti-mask sentiments and public health misinformation. Analyses reveal the\nSouth Korean boyband BTS as the most significant driver of health discourse.\nTweets from health agencies and prominent figures that mentioned K-pop generate\n111 times more of online response compared to tweets that did not. These tweets\nalso elicited a strong responses from South America, Southeast Asia, and rural\nStates -- areas often neglected in Twitter-based messaging by mainstream social\nmedia campaigns. Our results suggest that public health institutions may\nleverage pre-existing audience markets to synergistically diffuse and target\nunder-served communities both domestically and globally, especially during\nhealth crises such as COVID-19.",
    "descriptor": "\nComments: 12 pages, 2 figures, 2 tables\n",
    "authors": [
      "Ho-Chun Herbert Chang",
      "Becky Pham",
      "Emilio Ferrara"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.04149"
  },
  {
    "id": "arXiv:2110.04150",
    "title": "The Johnson-N\u00e9d\u00e9lec FEM-BEM Coupling for magnetostatic problems in  the isogeometric framework",
    "abstract": "We consider a Johnson-N\\'ed\\'elec FEM-BEM coupling, which is a direct and\nnon-symmetric coupling of finite and boundary element methods, in order to\nsolve interface problems for the magnetostatic Maxwell's equations with the\nmagnetic vector potential ansatz. In the FEM-domain, equations may be\nnon-linear, whereas they are exclusively linear in the BEM-part to guarantee\nthe existence of a fundamental solution. First, the weak problem is formulated\nin quotient spaces to avoid resolving to a saddle point problem. Second, we\nestablish in this setting well-posedness of the arising problem using the\nframework of Lipschitz and strongly monotone operators as well as a stability\nresult for a special type of non-linearity, which is typically considered in\nmagnetostatic applications. Then, the discretization is performed in the\nisogeometric context, i.e., the same type of basis functions that are used for\ngeometry design are considered as ansatz functions for the discrete setting. In\nparticular, NURBS are employed for geometry considerations, and B-Splines,\nwhich can be understood as a special type of NURBS, for analysis purposes. In\nthis context, we derive a priori estimates w.r.t. h-refinement, and point out\nto an interesting behavior of BEM, which consists in an amelioration of the\nconvergence rates, when a functional of the solution is evaluated in the\nexterior BEM-domain. This improvement may lead to a doubling of the convergence\nrate under certain assumptions. Finally, we end the paper with a numerical\nexample to illustrate the theoretical results, along with a conclusion and an\noutlook.",
    "descriptor": "",
    "authors": [
      "Mehdi Elasmi",
      "Christoph Erath",
      "Stefan Kurz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.04150"
  },
  {
    "id": "arXiv:2110.04151",
    "title": "Text analysis and deep learning: A network approach",
    "abstract": "Much information available to applied researchers is contained within written\nlanguage or spoken text. Deep language models such as BERT have achieved\nunprecedented success in many applications of computational linguistics.\nHowever, much less is known about how these models can be used to analyze\nexisting text. We propose a novel method that combines transformer models with\nnetwork analysis to form a self-referential representation of language use\nwithin a corpus of interest. Our approach produces linguistic relations\nstrongly consistent with the underlying model as well as mathematically\nwell-defined operations on them, while reducing the amount of discretionary\nchoices of representation and distance measures. It represents, to the best of\nour knowledge, the first unsupervised method to extract semantic networks\ndirectly from deep language models. We illustrate our approach in a semantic\nanalysis of the term \"founder\". Using the entire corpus of Harvard Business\nReview from 1980 to 2020, we find that ties in our network track the semantics\nof discourse over time, and across contexts, identifying and relating clusters\nof semantic and syntactic relations. Finally, we discuss how this method can\nalso complement and inform analyses of the behavior of deep learning models.",
    "descriptor": "",
    "authors": [
      "Ingo Marquart"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.04151"
  },
  {
    "id": "arXiv:2110.04156",
    "title": "Showing Your Offline Reinforcement Learning Work: Online Evaluation  Budget Matters",
    "abstract": "Over the recent years, vast progress has been made in Offline Reinforcement\nLearning (Offline-RL) for various decision-making domains: from finance to\nrobotics. However, comparing and reporting new Offline-RL algorithms has been\nnoted as underdeveloped: (1) use of unlimited online evaluation budget for\nhyperparameter search (2) sidestepping offline policy selection (3) ad-hoc\nperformance statistics reporting. In this work, we propose an evaluation\ntechnique addressing these issues, Expected Online Performance, that provides a\nperformance estimate for a best-found policy given a fixed online evaluation\nbudget. Using our approach, we can estimate the number of online evaluations\nrequired to surpass a given behavioral policy performance. Applying it to\nseveral Offline-RL baselines, we find that with a limited online evaluation\nbudget, (1) Behavioral Cloning constitutes a strong baseline over various\nexpert levels and data regimes, and (2) offline uniform policy selection is\ncompetitive with value-based approaches. We hope the proposed technique will\nmake it into the toolsets of Offline-RL practitioners to help them arrive at\ninformed conclusions when deploying RL in real-world systems.",
    "descriptor": "",
    "authors": [
      "Vladislav Kurenkov",
      "Sergey Kolesnikov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04156"
  },
  {
    "id": "arXiv:2110.04157",
    "title": "Discrete Approximation of Pressure Field Contact Patches",
    "abstract": "Rich interaction with the world requires extensive contact between robots and\nthe objects in their environment. Most such contacts involve significant\ncompliance between the contacting surfaces due to rubber pads or inflated\ngrippers, soft objects to be manipulated, and soft surfaces for safe\nhuman-robot interaction. Accurate simulation of these contacts is critical for\nmeaningful sim-to-real transfer. Compliant contact interactions generate\ncontact surfaces of considerable extent, over which contact forces are\ndistributed with varying pressure. Finite element methods can capture these\neffects but are too slow for most robotics applications. Consequently, in order\nto enable real-time simulation rates, most current simulation tools model\ncontact as occurring between rigid bodies at a point or set of points using ad\nhoc methods to incorporate localized compliance. However, point contact is\nnon-smooth, hard to extend to arbitrary geometry, and often introduces\nnon-physical artifacts. Moreover, point contact misses important area-dependent\nphenomena critical for robust manipulation, such as net contact moment and slip\ncontrol. Pressure Field Contact (PFC) was recently introduced as a method for\ndetailed modeling of contact interface regions at rates much faster than\nelasticity-theory models, while at the same time predicting essential trends\nand capturing rich contact behavior. PFC was designed to work with\ncoarsely-meshed objects while preserving continuity to permit use with\nerror-controlled integrators. Here we introduce a discrete approximation of PFC\nsuitable for use with velocity-level time steppers that enables execution at\nreal-time rates. We evaluate the accuracy and performance gains of our approach\nand demonstrate its effectiveness in simulation of relevant manipulation tasks.\nThe method is available in open source as part of Drake's Hydroelastic Contact\nmodel.",
    "descriptor": "\nComments: Submitted to ICRA 2022. 7 pages, 10 figures. Supplementary video can be found at this https URL\n",
    "authors": [
      "Joseph Masterjohn",
      "Damrong Guoy",
      "John Shepherd",
      "Alejandro Castro"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2110.04157"
  },
  {
    "id": "arXiv:2110.04158",
    "title": "Explainability-Aware One Point Attack for Point Cloud Neural Networks",
    "abstract": "With the proposition of neural networks for point clouds, deep learning has\nstarted to shine in the field of 3D object recognition while researchers have\nshown an increased interest to investigate the reliability of point cloud\nnetworks by fooling them with perturbed instances. However, most studies focus\non the imperceptibility or surface consistency, with humans perceiving no\nperturbations on the adversarial examples. This work proposes two new attack\nmethods: opa and cta, which go in the opposite direction: we restrict the\nperturbation dimensions to a human cognizable range with the help of\nexplainability methods, which enables the working principle or decision\nboundary of the models to be comprehensible through the observable perturbation\nmagnitude. Our results show that the popular point cloud networks can be\ndeceived with almost 100% success rate by shifting only one point from the\ninput instance. In addition, we attempt to provide a more persuasive viewpoint\nof comparing the robustness of point cloud models against adversarial attacks.\nWe also show the interesting impact of different point attribution\ndistributions on the adversarial robustness of point cloud networks. Finally,\nwe discuss how our approaches facilitate the explainability study for point\ncloud networks. To the best of our knowledge, this is the first\npoint-cloud-based adversarial approach concerning explainability. Our code is\navailable at https://github.com/Explain3D/Exp-One-Point-Atk-PC.",
    "descriptor": "",
    "authors": [
      "Hanxiao Tan",
      "Helena Kotthaus"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04158"
  },
  {
    "id": "arXiv:2110.04160",
    "title": "Federated Learning for Big Data: A Survey on Opportunities,  Applications, and Future Directions",
    "abstract": "Big data has remarkably evolved over the last few years to realize an\nenormous volume of data generated from newly emerging services and applications\nand a massive number of Internet-of-Things (IoT) devices. The potential of big\ndata can be realized via analytic and learning techniques, in which the data\nfrom various sources is transferred to a central cloud for central storage,\nprocessing, and training. However, this conventional approach faces critical\nissues in terms of data privacy as the data may include sensitive data such as\npersonal information, governments, banking accounts. To overcome this\nchallenge, federated learning (FL) appeared to be a promising learning\ntechnique. However, a gap exists in the literature that a comprehensive survey\non FL for big data services and applications is yet to be conducted. In this\narticle, we present a survey on the use of FL for big data services and\napplications, aiming to provide general readers with an overview of FL, big\ndata, and the motivations behind the use of FL for big data. In particular, we\nextensively review the use of FL for key big data services, including big data\nacquisition, big data storage, big data analytics, and big data privacy\npreservation. Subsequently, we review the potential of FL for big data\napplications, such as smart city, smart healthcare, smart transportation, smart\ngrid, and social media. Further, we summarize a number of important projects on\nFL-big data and discuss key challenges of this interesting topic along with\nseveral promising solutions and directions.",
    "descriptor": "\nComments: Submitted to ACM Computing Surveys\n",
    "authors": [
      "Thippa Reddy Gadekallu",
      "Quoc-Viet Pham",
      "Thien Huynh-The",
      "Sweta Bhattacharya",
      "Praveen Kumar Reddy Maddikunta",
      "Madhusanka Liyanage"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.04160"
  },
  {
    "id": "arXiv:2110.04162",
    "title": "Semantic Image Alignment for Vehicle Localization",
    "abstract": "Accurate and reliable localization is a fundamental requirement for\nautonomous vehicles to use map information in higher-level tasks such as\nnavigation or planning. In this paper, we present a novel approach to vehicle\nlocalization in dense semantic maps, including vectorized high-definition maps\nor 3D meshes, using semantic segmentation from a monocular camera. We formulate\nthe localization task as a direct image alignment problem on semantic images,\nwhich allows our approach to robustly track the vehicle pose in semantically\nlabeled maps by aligning virtual camera views rendered from the map to\nsequences of semantically segmented camera images. In contrast to existing\nvisual localization approaches, the system does not require additional keypoint\nfeatures, handcrafted localization landmark extractors or expensive LiDAR\nsensors. We demonstrate the wide applicability of our method on a diverse set\nof semantic mesh maps generated from stereo or LiDAR as well as manually\nannotated HD maps and show that it achieves reliable and accurate localization\nin real-time.",
    "descriptor": "\nComments: Accepted at 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2021)\n",
    "authors": [
      "Markus Herb",
      "Matthias Lemberger",
      "Marcel M. Schmitt",
      "Alexander Kurz",
      "Tobias Weiherer",
      "Nassir Navab",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.04162"
  },
  {
    "id": "arXiv:2110.04169",
    "title": "Iterative Decoding for Compositional Generalization in Transformers",
    "abstract": "Deep learning models do well at generalizing to in-distribution data but\nstruggle to generalize compositionally, i.e., to combine a set of learned\nprimitives to solve more complex tasks. In particular, in sequence-to-sequence\n(seq2seq) learning, transformers are often unable to predict correct outputs\nfor even marginally longer examples than those seen during training. This paper\nintroduces iterative decoding, an alternative to seq2seq learning that (i)\nimproves transformer compositional generalization and (ii) evidences that, in\ngeneral, seq2seq transformers do not learn iterations that are not unrolled.\nInspired by the idea of compositionality -- that complex tasks can be solved by\ncomposing basic primitives -- training examples are broken down into a sequence\nof intermediate steps that the transformer then learns iteratively. At\ninference time, the intermediate outputs are fed back to the transformer as\nintermediate inputs until an end-of-iteration token is predicted. Through\nnumerical experiments, we show that transfomers trained via iterative decoding\noutperform their seq2seq counterparts on the PCFG dataset, and solve the\nproblem of calculating Cartesian products between vectors longer than those\nseen during training with 100% accuracy, a task at which seq2seq models have\nbeen shown to fail. We also illustrate a limitation of iterative decoding,\nspecifically, that it can make sorting harder to learn on the CFQ dataset.",
    "descriptor": "",
    "authors": [
      "Luana Ruiz",
      "Joshua Ainslie",
      "Santiago Onta\u00f1\u00f3n"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04169"
  },
  {
    "id": "arXiv:2110.04172",
    "title": "Three decompositions of symmetric tensors have similar condition numbers",
    "abstract": "We relate the condition numbers of computing three decompositions of\nsymmetric tensors: the canonical polyadic decomposition, the Waring\ndecomposition, and a Tucker-compressed Waring decomposition. Based on this\nrelation we can speed up the computation of these condition numbers by orders\nof magnitude",
    "descriptor": "",
    "authors": [
      "Nick Dewaele",
      "Paul Breiding",
      "Nick Vannieuwenhoven"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.04172"
  },
  {
    "id": "arXiv:2110.04173",
    "title": "TopoDetect: Framework for Topological Features Detection in Graph  Embeddings",
    "abstract": "TopoDetect is a Python package that allows the user to investigate if\nimportant topological features, such as the Degree of the nodes, their Triangle\nCount, or their Local Clustering Score, are preserved in the embeddings of\ngraph representation models. Additionally, the framework enables the\nvisualization of the embeddings according to the distribution of the\ntopological features among the nodes. Moreover, TopoDetect enables us to study\nthe effect of the preservation of these features by evaluating the performance\nof the embeddings on downstream learning tasks such as clustering and\nclassification.",
    "descriptor": "",
    "authors": [
      "Maroun Haddad",
      "Mohamed Bouguessa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04173"
  },
  {
    "id": "arXiv:2110.04174",
    "title": "Uncertainty Quantification in LV State Estimation Under High Shares of  Flexible Resources",
    "abstract": "The ongoing electrification introduces new challenges to distribution system\noperators (DSOs). Controllable resources may simultaneously react to price\nsignals, potentially leading to network violations. DSOs require reliable and\naccurate low-voltage state estimation (LVSE) to improve awareness and mitigate\nsuch events. However, the influence of flexibility activations on LVSE has not\nbeen addressed yet. It remains unclear if flexibility-induced uncertainty can\nbe reliably quantified to enable robust DSO decision-making. In this work,\nuncertainty quantification in LVSE is systematically investigated for multiple\nscenarios of input availability and flexibility utilization, using real data.\nFor that purpose, a Bayesian neural network (BNN) is compared to quantile\nregression. Results show that frequent flexibility activations can\nsignificantly deteriorate LVSE performance, unless secondary substation\nmeasurements are available. Moreover, it is demonstrated that the BNN captures\nflexibility-induced voltage drops by dynamically extending the prediction\ninterval during activation periods, and that it improves interpretability\nregarding the cause of uncertainty.",
    "descriptor": "\nComments: Submitted to the 22nd Power Systems Computation Conference (PSCC 2022)\n",
    "authors": [
      "Nils M\u00fcller",
      "Samuel Chevalier",
      "Carsten Heinrich",
      "Kai Heussen",
      "Charalampos Ziras"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.04174"
  },
  {
    "id": "arXiv:2110.04175",
    "title": "RelaySum for Decentralized Deep Learning on Heterogeneous Data",
    "abstract": "In decentralized machine learning, workers compute model updates on their\nlocal data. Because the workers only communicate with few neighbors without\ncentral coordination, these updates propagate progressively over the network.\nThis paradigm enables distributed training on networks without all-to-all\nconnectivity, helping to protect data privacy as well as to reduce the\ncommunication cost of distributed training in data centers. A key challenge,\nprimarily in decentralized deep learning, remains the handling of differences\nbetween the workers' local data distributions. To tackle this challenge, we\nintroduce the RelaySum mechanism for information propagation in decentralized\nlearning. RelaySum uses spanning trees to distribute information exactly\nuniformly across all workers with finite delays depending on the distance\nbetween nodes. In contrast, the typical gossip averaging mechanism only\ndistributes data uniformly asymptotically while using the same communication\nvolume per step as RelaySum. We prove that RelaySGD, based on this mechanism,\nis independent of data heterogeneity and scales to many workers, enabling\nhighly accurate decentralized deep learning on heterogeneous data. Our code is\navailable at this http URL",
    "descriptor": "\nComments: To appear in NeurIPS 2021\n",
    "authors": [
      "Thijs Vogels",
      "Lie He",
      "Anastasia Koloskova",
      "Tao Lin",
      "Sai Praneeth Karimireddy",
      "Sebastian U. Stich",
      "Martin Jaggi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04175"
  },
  {
    "id": "arXiv:2110.04176",
    "title": "Lightweight Convolutional Neural Networks By Hypercomplex  Parameterization",
    "abstract": "Hypercomplex neural networks have proved to reduce the overall number of\nparameters while ensuring valuable performances by leveraging the properties of\nClifford algebras. Recently, hypercomplex linear layers have been further\nimproved by involving efficient parameterized Kronecker products. In this\npaper, we define the parameterization of hypercomplex convolutional layers to\ndevelop lightweight and efficient large-scale convolutional models. Our method\ngrasps the convolution rules and the filters organization directly from data\nwithout requiring a rigidly predefined domain structure to follow. The proposed\napproach is flexible to operate in any user-defined or tuned domain, from 1D to\n$n$D regardless of whether the algebra rules are preset. Such a malleability\nallows processing multidimensional inputs in their natural domain without\nannexing further dimensions, as done, instead, in quaternion neural networks\nfor 3D inputs like color images. As a result, the proposed method operates with\n$1/n$ free parameters as regards its analog in the real domain. We demonstrate\nthe versatility of this approach to multiple domains of application by\nperforming experiments on various image datasets as well as audio datasets in\nwhich our method outperforms real and quaternion-valued counterparts.",
    "descriptor": "\nComments: Under review as a conference paper at ICLR 2022\n",
    "authors": [
      "Eleonora Grassucci",
      "Aston Zhang",
      "Danilo Comminiello"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04176"
  },
  {
    "id": "arXiv:2110.04180",
    "title": "IHOP: Improved Statistical Query Recovery against Searchable Symmetric  Encryption through Quadratic Optimization",
    "abstract": "Searchable Symmetric Encryption (SSE) schemes allow a client to perform\nsecure searches over encrypted databases on a remote server. These schemes leak\ncertain information that an honest-but-curious service provider can use to\nrecover the keywords of the client's queries. Effective query recovery attacks\ntypically rely on auxiliary ground-truth information about the queries or\ndataset. Query recovery is also possible under the weaker statistical auxiliary\ninformation assumption, although statistical-based attacks achieve lower\naccuracy and are not considered a serious threat. In this work we present IHOP,\na statistical-based query recovery attack that formulates query recovery as a\nquadratic optimization problem and reaches a solution by iterating over linear\nassignment problems. We show that IHOP outperforms all other statistical-based\nquery recovery attacks on SSE schemes with typical access and search pattern\nleakage, reaching query recovery accuracies around 80% and 90%. We adapt IHOP\nagainst access-pattern obfuscation defenses and show that it still achieves\nreasonable recovery rates, outperforming existing attacks in this scenario.\nFinally, we use IHOP in a frequency-only leakage setting where the client's\nqueries are correlated, and show that our attack can exploit query dependencies\neven when PANCAKE, a recent frequency-hiding defense by Grubbs et al., is\napplied. Our findings indicate that statistical query recovery attacks pose a\nsevere threat to privacy-preserving SSE schemes.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Simon Oya",
      "Florian Kerschbaum"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.04180"
  },
  {
    "id": "arXiv:2110.04181",
    "title": "Dataset Condensation with Distribution Matching",
    "abstract": "Computational cost to train state-of-the-art deep models in many learning\nproblems is rapidly increasing due to more sophisticated models and larger\ndatasets. A recent promising direction to reduce training time is dataset\ncondensation that aims to replace the original large training set with a\nsignificantly smaller learned synthetic set while preserving its information.\nWhile training deep models on the small set of condensed images can be\nextremely fast, their synthesis remains computationally expensive due to the\ncomplex bi-level optimization and second-order derivative computation. In this\nwork, we propose a simple yet effective dataset condensation technique that\nrequires significantly lower training cost with comparable performance by\nmatching feature distributions of the synthetic and original training images in\nsampled embedding spaces. Thanks to its efficiency, we apply our method to more\nrealistic and larger datasets with sophisticated neural architectures and\nachieve a significant performance boost while using larger synthetic training\nset. We also show various practical benefits of our method in continual\nlearning and neural architecture search.",
    "descriptor": "",
    "authors": [
      "Bo Zhao",
      "Hakan Bilen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04181"
  },
  {
    "id": "arXiv:2110.04182",
    "title": "Temporal Convolutions for Multi-Step Quadrotor Motion Prediction",
    "abstract": "Model-based control methods for robotic systems such as quadrotors,\nautonomous driving vehicles and flexible manipulators require motion models\nthat generate accurate predictions of complex nonlinear system dynamics over\nlong periods of time. Temporal Convolutional Networks (TCNs) can be adapted to\nthis challenge by formulating multi-step prediction as a sequence-to-sequence\nmodeling problem. We present End2End-TCN: a fully convolutional architecture\nthat integrates future control inputs to compute multi-step motion predictions\nin one forward pass. We demonstrate the approach with a thorough analysis of\nTCN performance for the quadrotor modeling task, which includes an\ninvestigation of scaling effects and ablation studies. Ultimately, End2End-TCN\nprovides 55% error reduction over the state of the art in multi-step prediction\non an aggressive indoor quadrotor flight dataset. The model yields accurate\npredictions across 90 timestep horizons over a 900 ms interval.",
    "descriptor": "",
    "authors": [
      "Samuel Looper",
      "Steven L. Waslander"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04182"
  },
  {
    "id": "arXiv:2110.04184",
    "title": "When Can We Learn General-Sum Markov Games with a Large Number of  Players Sample-Efficiently?",
    "abstract": "Multi-agent reinforcement learning has made substantial empirical progresses\nin solving games with a large number of players. However, theoretically, the\nbest known sample complexity for finding a Nash equilibrium in general-sum\ngames scales exponentially in the number of players due to the size of the\njoint action space, and there is a matching exponential lower bound. This paper\ninvestigates what learning goals admit better sample complexities in the\nsetting of $m$-player general-sum Markov games with $H$ steps, $S$ states, and\n$A_i$ actions per player. First, we design algorithms for learning an\n$\\epsilon$-Coarse Correlated Equilibrium (CCE) in\n$\\widetilde{\\mathcal{O}}(H^5S\\max_{i\\le m} A_i / \\epsilon^2)$ episodes, and an\n$\\epsilon$-Correlated Equilibrium (CE) in\n$\\widetilde{\\mathcal{O}}(H^6S\\max_{i\\le m} A_i^2 / \\epsilon^2)$ episodes. This\nis the first line of results for learning CCE and CE with sample complexities\npolynomial in $\\max_{i\\le m} A_i$. Our algorithm for learning CE integrates an\nadversarial bandit subroutine which minimizes a weighted swap regret, along\nwith several novel designs in the outer loop. Second, we consider the important\nspecial case of Markov Potential Games, and design an algorithm that learns an\n$\\epsilon$-approximate Nash equilibrium within\n$\\widetilde{\\mathcal{O}}(S\\sum_{i\\le m} A_i / \\epsilon^3)$ episodes (when only\nhighlighting the dependence on $S$, $A_i$, and $\\epsilon$), which only depends\nlinearly in $\\sum_{i\\le m} A_i$ and significantly improves over the best known\nalgorithm in the $\\epsilon$ dependence. Overall, our results shed light on what\nequilibria or structural assumptions on the game may enable sample-efficient\nlearning with many players.",
    "descriptor": "",
    "authors": [
      "Ziang Song",
      "Song Mei",
      "Yu Bai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04184"
  },
  {
    "id": "arXiv:2110.04186",
    "title": "Medical Dead-ends and Learning to Identify High-risk States and  Treatments",
    "abstract": "Machine learning has successfully framed many sequential decision making\nproblems as either supervised prediction, or optimal decision-making policy\nidentification via reinforcement learning. In data-constrained offline\nsettings, both approaches may fail as they assume fully optimal behavior or\nrely on exploring alternatives that may not exist. We introduce an inherently\ndifferent approach that identifies possible ``dead-ends'' of a state space. We\nfocus on the condition of patients in the intensive care unit, where a\n``medical dead-end'' indicates that a patient will expire, regardless of all\npotential future treatment sequences. We postulate ``treatment security'' as\navoiding treatments with probability proportional to their chance of leading to\ndead-ends, present a formal proof, and frame discovery as an RL problem. We\nthen train three independent deep neural models for automated state\nconstruction, dead-end discovery and confirmation. Our empirical results\ndiscover that dead-ends exist in real clinical data among septic patients, and\nfurther reveal gaps between secure treatments and those that were administered.",
    "descriptor": "",
    "authors": [
      "Mehdi Fatemi",
      "Taylor W. Killian",
      "Jayakumar Subramanian",
      "Marzyeh Ghassemi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04186"
  },
  {
    "id": "arXiv:2110.04190",
    "title": "On Explicit Constructions of Extremely Depth Robust Graphs",
    "abstract": "A directed acyclic graph $G=(V,E)$ is said to be $(e,d)$-depth robust if for\nevery subset $S \\subseteq V$ of $|S| \\leq e$ nodes the graph $G-S$ still\ncontains a directed path of length $d$. If the graph is $(e,d)$-depth-robust\nfor any $e,d$ such that $e+d \\leq (1-\\epsilon)|V|$ then the graph is said to be\n$\\epsilon$-extreme depth-robust. In the field of cryptography, (extremely)\ndepth-robust graphs with low indegree have found numerous applications\nincluding the design of side-channel resistant Memory-Hard Functions, Proofs of\nSpace and Replication, and in the design of Computationally Relaxed Locally\nCorrectable Codes. In these applications, it is desirable to ensure the graphs\nare locally navigable, i.e., there is an efficient algorithm\n$\\mathsf{GetParents}$ running in time $\\mathrm{polylog} |V|$ which takes as\ninput a node $v \\in V$ and returns the set of $v$'s parents. We give the first\nexplicit construction of locally navigable $\\epsilon$-extreme depth-robust\ngraphs with indegree $O(\\log |V|)$. Previous constructions of\n$\\epsilon$-extreme depth-robust graphs either had indegree\n$\\tilde{\\omega}(\\log^2 |V|)$ or were not explicit.",
    "descriptor": "\nComments: 12 pages, 1 figure\n",
    "authors": [
      "Jeremiah Blocki",
      "Mike Cinkoske",
      "Seunghoon Lee",
      "Jin Young Son"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.04190"
  },
  {
    "id": "arXiv:2110.04192",
    "title": "Explaining Reward Functions to Humans for Better Human-Robot  Collaboration",
    "abstract": "Explainable AI techniques that describe agent reward functions can enhance\nhuman-robot collaboration in a variety of settings. One context where human\nunderstanding of agent reward functions is particularly beneficial is in the\nvalue alignment setting. In the value alignment context, an agent aims to infer\na human's reward function through interaction so that it can assist the human\nwith their tasks. If the human can understand where gaps exist in the agent's\nreward understanding, they will be able to teach more efficiently and\neffectively, leading to quicker human-agent team performance improvements. In\norder to support human collaborators in the value alignment setting and similar\ncontexts, it is first important to understand the effectiveness of different\nreward explanation techniques in a variety of domains. In this paper, we\nintroduce a categorization of information modalities for reward explanation\ntechniques, suggest a suite of assessment techniques for human reward\nunderstanding, and introduce four axes of domain complexity. We then propose an\nexperiment to study the relative efficacy of a broad set of reward explanation\ntechniques covering multiple modalities of information in a set of domains of\nvarying complexity.",
    "descriptor": "\nComments: Presented at AI-HRI symposium as part of AAAI-FSS 2021 (arXiv:2109.10836)\n",
    "authors": [
      "Lindsay Sanneman",
      "Julie Shah"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.04192"
  },
  {
    "id": "arXiv:2110.04193",
    "title": "On Fast Johnson-Lindernstrauss Embeddings of Compact Submanifolds of  $\\mathbb{R}^N$ with Boundary",
    "abstract": "Let $\\mathcal{M}$ be a smooth $d$-dimensional submanifold of $\\mathbb{R}^N$\nwith boundary that's equipped with the Euclidean (chordal) metric, and choose\n$m \\leq N$. In this paper we consider the probability that a random matrix $A\n\\in \\mathbb{R}^{m \\times N}$ will serve as a bi-Lipschitz function $A:\n\\mathcal{M} \\rightarrow \\mathbb{R}^m$ with bi-Lipschitz constants close to one\nfor three different types of distributions on the $m \\times N$ matrices $A$,\nincluding two whose realizations are guaranteed to have fast matrix-vector\nmultiplies. In doing so we generalize prior randomized metric space embedding\nresults of this type for submanifolds of $\\mathbb{R}^N$ by allowing for the\npresence of boundary while also retaining, and in some cases improving, prior\nlower bounds on the achievable embedding dimensions $m$ for which one can\nexpect small distortion with high probability. In particular, motivated by\nrecent modewise embedding constructions for tensor data, herein we present a\nnew class of highly structured distributions on matrices which outperform prior\nstructured matrix distributions for embedding sufficiently low-dimensional\nsubmanifolds of $\\mathbb{R}^N$ (with $d \\lesssim \\sqrt{N}$) with respect to\nboth achievable embedding dimension, and computationally efficient\nrealizations. As a consequence we are able to present, for example, a general\nnew class of Johnson-Lindenstrauss embedding matrices for $\\mathcal{O}(\\log^c\nN)$-dimensional submanifolds of $\\mathbb{R}^N$ which enjoy $\\mathcal{O}(N \\log\n\\log N))$-time matrix vector multiplications.",
    "descriptor": "",
    "authors": [
      "Mark A. Iwen",
      "Benjamin Schmidt",
      "Arman Tavakoli"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.04193"
  },
  {
    "id": "arXiv:2110.04196",
    "title": "Insidious Nonetheless: How Small Effects and Hierarchical Norms Create  and Maintain Gender Disparities in Organizations",
    "abstract": "The term glass ceiling is applied to the well-established phenomenon in which\nwomen and people of color are consistently blocked from reaching the upper-most\nlevels of the corporate hierarchy. Focusing on gender, we present an\nagent-based model that explores how empirically established mechanisms of\ninterpersonal discrimination coevolve with social norms at both the\norganizational (meso) and societal (macro) levels to produce this glass ceiling\neffect for women. Our model extends our understanding of how the glass ceiling\narises, and why it can be resistant to change. We do so by synthesizing\nexisting psychological and structural theories of discrimination into a\nmathematical model that quantifies explicitly how complex organizational\nsystems can produce and maintain inequality. We discuss implications of our\nfindings for both intervention and future empirical analyses, and provide\nopen-source code for those wishing to adapt or extend our work.",
    "descriptor": "",
    "authors": [
      "Yuhao Du",
      "Jessica Nordell",
      "Kenneth Joseph"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.04196"
  },
  {
    "id": "arXiv:2110.04200",
    "title": "On tolerance of discrete systems with respect to transition  perturbations",
    "abstract": "Control systems should enforce a desired property for both expected modeled\nsituations as well as unexpected unmodeled environmental situations. Existing\nmethods focus on designing controllers to enforce the desired property only\nwhen the environment behaves as expected. However, these methods lack\ndiscussion on how the system behaves when the environment is perturbed. In this\npaper, we propose an approach for analyzing control systems with respect to\ntheir tolerance against environmental perturbations. A control system tolerates\ncertain environmental perturbations when it remains capable of guaranteeing the\ndesired property despite the perturbations. Each controller inherently has a\nlevel of tolerance against environmental perturbations. We formally define this\nnotion of tolerance and describe a general technique to compute it, for any\ngiven regular property. We also present a more efficient method to compute\ntolerance with respect to invariance properties. Moreover, we introduce a new\ncontroller synthesis problem based on our notion of tolerance. We demonstrate\nthe application of our framework on an autonomous surveillance example.",
    "descriptor": "\nComments: Full version of TACAS'22 submission\n",
    "authors": [
      "R\u00f4mulo Meira-G\u00f3es",
      "Eunsuk Kang",
      "St\u00e9phane Lafortune",
      "Stavros Tripakis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.04200"
  },
  {
    "id": "arXiv:2110.04202",
    "title": "Exploiting the Intrinsic Neighborhood Structure for Source-free Domain  Adaptation",
    "abstract": "Domain adaptation (DA) aims to alleviate the domain shift between source\ndomain and target domain. Most DA methods require access to the source data,\nbut often that is not possible (e.g. due to data privacy or intellectual\nproperty). In this paper, we address the challenging source-free domain\nadaptation (SFDA) problem, where the source pretrained model is adapted to the\ntarget domain in the absence of source data. Our method is based on the\nobservation that target data, which might no longer align with the source\ndomain classifier, still forms clear clusters. We capture this intrinsic\nstructure by defining local affinity of the target data, and encourage label\nconsistency among data with high local affinity. We observe that higher\naffinity should be assigned to reciprocal neighbors, and propose a self\nregularization loss to decrease the negative impact of noisy neighbors.\nFurthermore, to aggregate information with more context, we consider expanded\nneighborhoods with small affinity values. In the experimental results we verify\nthat the inherent structure of the target features is an important source of\ninformation for domain adaptation. We demonstrate that this local structure can\nbe efficiently captured by considering the local neighbors, the reciprocal\nneighbors, and the expanded neighborhood. Finally, we achieve state-of-the-art\nperformance on several 2D image and 3D point cloud recognition datasets. Code\nis available in https://github.com/Albert0147/SFDA_neighbors.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Shiqi Yang",
      "Yaxing Wang",
      "Joost van de Weijer",
      "Luis Herranz",
      "Shangling Jui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04202"
  },
  {
    "id": "arXiv:2110.04203",
    "title": "Toward a Human-Level Video Understanding Intelligence",
    "abstract": "We aim to develop an AI agent that can watch video clips and have a\nconversation with human about the video story. Developing video understanding\nintelligence is a significantly challenging task, and evaluation methods for\nadequately measuring and analyzing the progress of AI agent are lacking as\nwell. In this paper, we propose the Video Turing Test to provide effective and\npractical assessments of video understanding intelligence as well as\nhuman-likeness evaluation of AI agents. We define a general format and\nprocedure of the Video Turing Test and present a case study to confirm the\neffectiveness and usefulness of the proposed test.",
    "descriptor": "\nComments: Presented at AI-HRI symposium as part of AAAI-FSS 2021 (arXiv:2109.10836). The first two authors have equal contribution\n",
    "authors": [
      "Yu-Jung Heo",
      "Minsu Lee",
      "Seongho Choi",
      "Woo Suk Choi",
      "Minjung Shin",
      "Minjoon Jung",
      "Jeh-Kwang Ryu",
      "Byoung-Tak Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.04203"
  },
  {
    "id": "arXiv:2110.04204",
    "title": "Development of an Extractive Title Generation System Using Titles of  Papers of Top Conferences for Intermediate English Students",
    "abstract": "The formulation of good academic paper titles in English is challenging for\nintermediate English authors (particularly students). This is because such\nauthors are not aware of the type of titles that are generally in use. We aim\nto realize a support system for formulating more effective English titles for\nintermediate English and beginner authors. This study develops an extractive\ntitle generation system that formulates titles from keywords extracted from an\nabstract. Moreover, we realize a title evaluation model that can evaluate the\nappropriateness of paper titles. We train the model with titles of\ntop-conference papers by using BERT. This paper describes the training data,\nimplementation, and experimental results. The results show that our evaluation\nmodel can identify top-conference titles more effectively than intermediate\nEnglish and beginner students.",
    "descriptor": "\nComments: 6 pages, 3 figures, 4 tables, 2 algorithms\n",
    "authors": [
      "Kento Kaku",
      "Masato Kikuchi",
      "Tadachika Ozono",
      "Toramatsu Shintani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04204"
  },
  {
    "id": "arXiv:2110.04217",
    "title": "Contrastive String Representation Learning using Synthetic Data",
    "abstract": "String representation Learning (SRL) is an important task in the field of\nNatural Language Processing, but it remains under-explored. The goal of SRL is\nto learn dense and low-dimensional vectors (or embeddings) for encoding\ncharacter sequences. The learned representation from this task can be used in\nmany downstream application tasks such as string similarity matching or lexical\nnormalization. In this paper, we propose a new method for to train a SRL model\nby only using synthetic data. Our approach makes use of Contrastive Learning in\norder to maximize similarity between related strings while minimizing it for\nunrelated strings. We demonstrate the effectiveness of our approach by\nevaluating the learned representation on the task of string similarity\nmatching. Codes, data and pretrained models will be made publicly available.",
    "descriptor": "",
    "authors": [
      "Urchade Zaratiana"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.04217"
  },
  {
    "id": "arXiv:2110.04222",
    "title": "Inferring Offensiveness In Images From Natural Language Supervision",
    "abstract": "Probing or fine-tuning (large-scale) pre-trained models results in\nstate-of-the-art performance for many NLP tasks and, more recently, even for\ncomputer vision tasks when combined with image data. Unfortunately, these\napproaches also entail severe risks. In particular, large image datasets\nautomatically scraped from the web may contain derogatory terms as categories\nand offensive images, and may also underrepresent specific classes.\nConsequently, there is an urgent need to carefully document datasets and curate\ntheir content. Unfortunately, this process is tedious and error-prone. We show\nthat pre-trained transformers themselves provide a methodology for the\nautomated curation of large-scale vision datasets. Based on human-annotated\nexamples and the implicit knowledge of a CLIP based model, we demonstrate that\none can select relevant prompts for rating the offensiveness of an image. In\naddition to e.g. privacy violation and pornographic content previously\nidentified in ImageNet, we demonstrate that our approach identifies further\ninappropriate and potentially offensive content.",
    "descriptor": "",
    "authors": [
      "Patrick Schramowski",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04222"
  },
  {
    "id": "arXiv:2110.04227",
    "title": "Universal Joint Approximation of Manifolds and Densities by Simple  Injective Flows",
    "abstract": "We analyze neural networks composed of bijective flows and injective\nexpansive elements. We find that such networks universally approximate a large\nclass of manifolds simultaneously with densities supported on them. Among\nothers, our results apply to the well-known coupling and autoregressive flows.\nWe build on the work of Teshima et al. 2020 on bijective flows and study\ninjective architectures proposed in Brehmer et al. 2020 and Kothari et al.\n2021. Our results leverage a new theoretical device called the embedding gap,\nwhich measures how far one continuous manifold is from embedding another. We\nrelate the embedding gap to a relaxation of universally we call the manifold\nembedding property, capturing the geometric part of universality. Our proof\nalso establishes that optimality of a network can be established in reverse,\nresolving a conjecture made in Brehmer et al. 2020 and opening the door for\nsimple layer-wise training schemes. Finally, we show that the studied networks\nadmit an exact layer-wise projection result, Bayesian uncertainty\nquantification, and black-box recovery of network weights.",
    "descriptor": "\nComments: 19 pages, 7 figures\n",
    "authors": [
      "Michael Puthawala",
      "Matti Lassas",
      "Ivan Dokmani\u0107",
      "Maarten de Hoop"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04227"
  },
  {
    "id": "arXiv:2110.04228",
    "title": "Hybrid Graph Embedding Techniques in Estimated Time of Arrival Task",
    "abstract": "Recently, deep learning has achieved promising results in the calculation of\nEstimated Time of Arrival (ETA), which is considered as predicting the travel\ntime from the start point to a certain place along a given path. ETA plays an\nessential role in intelligent taxi services or automotive navigation systems. A\ncommon practice is to use embedding vectors to represent the elements of a road\nnetwork, such as road segments and crossroads. Road elements have their own\nattributes like length, presence of crosswalks, lanes number, etc. However,\nmany links in the road network are traversed by too few floating cars even in\nlarge ride-hailing platforms and affected by the wide range of temporal events.\nAs the primary goal of the research, we explore the generalization ability of\ndifferent spatial embedding strategies and propose a two-stage approach to deal\nwith such problems.",
    "descriptor": "\nComments: Accepted in ICCNA 2021\n",
    "authors": [
      "Vadim Porvatov",
      "Natalia Semenova",
      "Andrey Chertok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04228"
  },
  {
    "id": "arXiv:2110.04231",
    "title": "Next Generation Mega Satellite Networks: Opportunities, Challenges, and  Performance",
    "abstract": "Digital connectivity has become the foundation of prosperity and an essential\nneed for functioning societies. Despite this dependence, limitation on Internet\naccess remains a prevalent issue, largely hinged on socioeconomic and\ngeographic factors. A promising solution to attain global access equality is\nbased on integrated terrestrial-satellite networks that rely on low Earth orbit\n(LEO) mega constellations. While the benefits of LEO constellations complement\nthe shortcomings of terrestrial networks, their incorporation impacts the\nnetwork design, adding complexity and challenges. This article presents a\nsystematic analysis of next generation LEO mega satellite constellations and\noutlines opportunities by virtue of the many benefits these constellations can\nprovide and highlights the major challenges. Furthermore, it provides a\nsynopsis of analytic models and underscores modern simulation approaches for\nnext generation mega satellite constellations. This provides network designers\nwith the necessary insights into satellite network performance.",
    "descriptor": "",
    "authors": [
      "Bassel Al Homssi",
      "Akram Al-Hourani",
      "Ke Wang",
      "Phillip Conder",
      "Sithamparanathan Kandeepan",
      "Jinho Choi",
      "Ben Allen",
      "Ben Moores"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.04231"
  },
  {
    "id": "arXiv:2110.04236",
    "title": "lambeq: An Efficient High-Level Python Library for Quantum NLP",
    "abstract": "We present lambeq, the first high-level Python library for Quantum Natural\nLanguage Processing (QNLP). The open-source toolkit offers a detailed hierarchy\nof modules and classes implementing all stages of a pipeline for converting\nsentences to string diagrams, tensor networks, and quantum circuits ready to be\nused on a quantum computer. lambeq supports syntactic parsing, rewriting and\nsimplification of string diagrams, ansatz creation and manipulation, as well as\na number of compositional models for preparing quantum-friendly representations\nof sentences, employing various degrees of syntax sensitivity. We present the\ngeneric architecture and describe the most important modules in detail,\ndemonstrating the usage with illustrative examples. Further, we test the\ntoolkit in practice by using it to perform a number of experiments on simple\nNLP tasks, implementing both classical and quantum pipelines.",
    "descriptor": "",
    "authors": [
      "Dimitri Kartsaklis",
      "Ian Fan",
      "Richie Yeung",
      "Anna Pearson",
      "Robin Lorenz",
      "Alexis Toumi",
      "Giovanni de Felice",
      "Konstantinos Meichanetzidis",
      "Stephen Clark",
      "Bob Coecke"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.04236"
  },
  {
    "id": "arXiv:2110.04238",
    "title": "Improving Kinodynamic Planners for Vehicular Navigation with Learned  Goal-Reaching Controllers",
    "abstract": "This paper aims to improve the path quality and computational efficiency of\nsampling-based kinodynamic planners for vehicular navigation. It proposes a\nlearning framework for identifying promising controls during the expansion\nprocess of sampling-based planners. Given a dynamics model, a reinforcement\nlearning process is trained offline to return a low-cost control that reaches a\nlocal goal state (i.e., a waypoint) in the absence of obstacles. By focusing on\nthe system's dynamics and not knowing the environment, this process is\ndata-efficient and takes place once for a robotic system. In this way, it can\nbe reused in different environments. The planner generates online local goal\nstates for the learned controller in an informed manner to bias towards the\ngoal and consecutively in an exploratory, random manner. For the informed\nexpansion, local goal states are generated either via (a) medial axis\ninformation in environments with obstacles, or (b) wavefront information for\nsetups with traversability costs. The learning process and the resulting\nplanning framework are evaluated for a first and second-order differential\ndrive system, as well as a physically simulated Segway robot. The results show\nthat the proposed integration of learning and planning can produce higher\nquality paths than sampling-based kinodynamic planning with random controls in\nfewer iterations and computation time.",
    "descriptor": "",
    "authors": [
      "Aravind Sivaramakrishnan",
      "Edgar Granados",
      "Seth Karten",
      "Troy McMahon",
      "Kostas E. Bekris"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.04238"
  },
  {
    "id": "arXiv:2110.04248",
    "title": "Observations on K-image Expansion of Image-Mixing Augmentation for  Classification",
    "abstract": "Image-mixing augmentations (e.g., Mixup or CutMix), which typically mix two\nimages, have become de-facto training tricks for image classification. Despite\ntheir huge success on image classification, the number of images to mix has not\nbeen profoundly investigated by the previous works, only showing the naive\nK-image expansion leads to poor performance degradation. This paper derives a\nnew K-image mixing augmentation based on the stick-breaking process under\nDirichlet prior. We show that our method can train more robust and generalized\nclassifiers through extensive experiments and analysis on classification\naccuracy, a shape of a loss landscape and adversarial robustness, than the\nusual two-image methods. Furthermore, we show that our probabilistic model can\nmeasure the sample-wise uncertainty and can boost the efficiency for Network\nArchitecture Search (NAS) with 7x reduced search time.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Joonhyun Jeong",
      "Sungmin Cha",
      "Youngjoon Yoo",
      "Sangdoo Yun",
      "Taesup Moon",
      "Jongwon Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04248"
  },
  {
    "id": "arXiv:2110.04249",
    "title": "How Can AI Recognize Pain and Express Empathy",
    "abstract": "Sensory and emotional experiences such as pain and empathy are relevant to\nmental and physical health. The current drive for automated pain recognition is\nmotivated by a growing number of healthcare requirements and demands for social\ninteraction make it increasingly essential. Despite being a trending area, they\nhave not been explored in great detail. Over the past decades, behavioral\nscience and neuroscience have uncovered mechanisms that explain the\nmanifestations of pain. Recently, also artificial intelligence research has\nallowed empathic machine learning methods to be approachable. Generally, the\npurpose of this paper is to review the current developments for computational\npain recognition and artificial empathy implementation. Our discussion covers\nthe following topics: How can AI recognize pain from unimodality and\nmultimodality? Is it necessary for AI to be empathic? How can we create an AI\nagent with proactive and reactive empathy? This article explores the challenges\nand opportunities of real-world multimodal pain recognition from a\npsychological, neuroscientific, and artificial intelligence perspective.\nFinally, we identify possible future implementations of artificial empathy and\nanalyze how humans might benefit from an AI agent equipped with empathy.",
    "descriptor": "",
    "authors": [
      "Siqi Cao",
      "Di Fu",
      "Xu Yang",
      "Pablo Barros",
      "Stefan Wermter",
      "Xun Liu",
      "Haiyan Wu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.04249"
  },
  {
    "id": "arXiv:2110.04250",
    "title": "Active learning for interactive satellite image change detection",
    "abstract": "We introduce in this paper a novel active learning algorithm for satellite\nimage change detection. The proposed solution is interactive and based on a\nquestion and answer model, which asks an oracle (annotator) the most\ninformative questions about the relevance of sampled satellite image pairs, and\naccording to the oracle's responses, updates a decision function iteratively.\nWe investigate a novel framework which models the probability that samples are\nrelevant; this probability is obtained by minimizing an objective function\ncapturing representativity, diversity and ambiguity. Only data with a high\nprobability according to these criteria are selected and displayed to the\noracle for further annotation. Extensive experiments on the task of satellite\nimage change detection after natural hazards (namely tornadoes) show the\nrelevance of the proposed method against the related work.",
    "descriptor": "",
    "authors": [
      "Hichem Sahbi",
      "Sebastien Deschamps",
      "Andrei Stoian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04250"
  },
  {
    "id": "arXiv:2110.04251",
    "title": "Co-link analysis as a monitoring tool: A webometric use case to map the  web relationships of research projects",
    "abstract": "This study explores the societal embeddedness of the websites of research\nprojects. It combines two aims: characterizing research projects based on their\nweblink relationships, and discovering external societal actors that relate to\nthe projects via weblinks. The study was based on a set of 121 EU-funded\nresearch projects and their websites. Domains referring to the websites of the\nresearch projects were collected and used in visualizations of co-link\nrelationships. These analyses revealed clusters of topical similarity among the\nresearch projects as well as among referring entities. Furthermore, a first\nstep into unveiling potentially relevant stakeholders around research projects\nwas made. Weblink analysis is discussed as an insightful tool for monitoring\nthe internal and external linkages of research projects, representing a\nrelevant application of webometric methods.",
    "descriptor": "\nComments: Research in progress paper accepted for oral presentation at the 18th International Conference on Scientometrics & Informetrics (2021)\n",
    "authors": [
      "Jonathan Dudek",
      "David G. Pina",
      "Rodrigo Costas"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2110.04251"
  },
  {
    "id": "arXiv:2110.04252",
    "title": "LCS: Learning Compressible Subspaces for Adaptive Network Compression at  Inference Time",
    "abstract": "When deploying deep learning models to a device, it is traditionally assumed\nthat available computational resources (compute, memory, and power) remain\nstatic. However, real-world computing systems do not always provide stable\nresource guarantees. Computational resources need to be conserved when load\nfrom other processes is high or battery power is low. Inspired by recent works\non neural network subspaces, we propose a method for training a \"compressible\nsubspace\" of neural networks that contains a fine-grained spectrum of models\nthat range from highly efficient to highly accurate. Our models require no\nretraining, thus our subspace of models can be deployed entirely on-device to\nallow adaptive network compression at inference time. We present results for\nachieving arbitrarily fine-grained accuracy-efficiency trade-offs at inference\ntime for structured and unstructured sparsity. We achieve accuracies on-par\nwith standard models when testing our uncompressed models, and maintain high\naccuracy for sparsity rates above 90% when testing our compressed models. We\nalso demonstrate that our algorithm extends to quantization at variable bit\nwidths, achieving accuracy on par with individually trained networks.",
    "descriptor": "",
    "authors": [
      "Elvis Nunez",
      "Maxwell Horton",
      "Anish Prabhu",
      "Anurag Ranjan",
      "Ali Farhadi",
      "Mohammad Rastegari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04252"
  },
  {
    "id": "arXiv:2110.04254",
    "title": "Assessment of Neural Networks for Stream-Water-Temperature Prediction",
    "abstract": "Climate change results in altered air and water temperatures. Increases\naffect physicochemical properties, such as oxygen concentration, and can shift\nspecies distribution and survival, with consequences for ecosystem functioning\nand services. These ecosystem services have integral value for humankind and\nare forecasted to alter under climate warming. A mechanistic understanding of\nthe drivers and magnitude of expected changes is essential in identifying\nsystem resilience and mitigation measures. In this work, we present a selection\nof state-of-the-art Neural Networks (NN) for the prediction of water\ntemperatures in six streams in Germany. We show that the use of methods that\ncompare observed and predicted values, exemplified with the Root Mean Square\nError (RMSE), is not sufficient for their assessment. Hence we introduce\nadditional analysis methods for our models to complement the state-of-the-art\nmetrics. These analyses evaluate the NN's robustness, possible maximal and\nminimal values, and the impact of single input parameters on the output. We\nthus contribute to understanding the processes within the NN and help\napplicants choose architectures and input parameters for reliable water\ntemperature prediction models.",
    "descriptor": "\nComments: ICMLA2021\n",
    "authors": [
      "Stefanie Mohr",
      "Konstantina Drainas",
      "Juergen Geist"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.04254"
  },
  {
    "id": "arXiv:2110.04257",
    "title": "VieSum: How Robust Are Transformer-based Models on Vietnamese  Summarization?",
    "abstract": "Text summarization is a challenging task within natural language processing\nthat involves text generation from lengthy input sequences. While this task has\nbeen widely studied in English, there is very limited research on summarization\nfor Vietnamese text. In this paper, we investigate the robustness of\ntransformer-based encoder-decoder architectures for Vietnamese abstractive\nsummarization. Leveraging transfer learning and self-supervised learning, we\nvalidate the performance of the methods on two Vietnamese datasets.",
    "descriptor": "",
    "authors": [
      "Hieu Nguyen",
      "Long Phan",
      "James Anibal",
      "Alec Peltekian",
      "Hieu Tran"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04257"
  },
  {
    "id": "arXiv:2110.04259",
    "title": "A Wireless Intrusion Detection System for 802.11 WPA3 Networks",
    "abstract": "Wi-Fi (802.11) networks have become an essential part of our daily lives;\nhence, their security is of utmost importance. However, Wi-Fi Protected Access\n3 (WPA3), the latest security certification for 802.11 standards, has recently\nbeen shown to be vulnerable to several attacks. In this paper, we first\ndescribe the attacks on WPA3 networks that have been reported in prior work;\nadditionally, we show that a deauthentication attack and a beacon flood attack,\nknown to be possible on a WPA2 network, are still possible with WPA3. We launch\nand test all the above (a total of nine) attacks using a testbed that contains\nan enterprise Access Point (AP) and Intrusion Detection System (IDS). Our\nexperimental results show that the AP is vulnerable to eight out of the nine\nattacks and the IDS is unable to detect any of them. We propose a design for a\nsignature-based IDS, which incorporates techniques to detect all the above\nattacks. Also, we implement these techniques on our testbed and verify that our\nIDS is able to successfully detect all the above attacks. We provide schemes\nfor mitigating the impact of the above attacks once they are detected. We make\nthe code to perform the above attacks as well as that of our IDS publicly\navailable, so that it can be used for future work by the research community at\nlarge.",
    "descriptor": "\nComments: Nine pages including one page of references\n",
    "authors": [
      "Neil Dalal",
      "Nadeem Akhtar",
      "Anubhav Gupta",
      "Nikhil Karamchandani",
      "Gaurav S. Kasbekar",
      "Jatin Parekh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.04259"
  },
  {
    "id": "arXiv:2110.04260",
    "title": "Taming Sparsely Activated Transformer with Stochastic Experts",
    "abstract": "Sparsely activated models (SAMs), such as Mixture-of-Experts (MoE), can\neasily scale to have outrageously large amounts of parameters without\nsignificant increase in computational cost. However, SAMs are reported to be\nparameter inefficient such that larger models do not always lead to better\nperformance. While most on-going research focuses on improving SAMs models by\nexploring methods of routing inputs to experts, our analysis reveals that such\nresearch might not lead to the solution we expect, i.e., the commonly-used\nrouting methods based on gating mechanisms do not work better than randomly\nrouting inputs to experts. In this paper, we propose a new expert-based model,\nTHOR (Transformer witH StOchastic ExpeRts). Unlike classic expert-based models,\nsuch as the Switch Transformer, experts in THOR are randomly activated for each\ninput during training and inference. THOR models are trained using a\nconsistency regularized loss, where experts learn not only from training data\nbut also from other experts as teachers, such that all the experts make\nconsistent predictions. We validate the effectiveness of THOR on machine\ntranslation tasks. Results show that THOR models are more parameter efficient\nin that they significantly outperform the Transformer and MoE models across\nvarious settings. For example, in multilingual translation, THOR outperforms\nthe Switch Transformer by 2 BLEU scores, and obtains the same BLEU score as\nthat of a state-of-the-art MoE model that is 18 times larger. Our code is\npublicly available at: github.com/microsoft/Stochastic-Mixture-of-Experts.",
    "descriptor": "",
    "authors": [
      "Simiao Zuo",
      "Xiaodong Liu",
      "Jian Jiao",
      "Young Jin Kim",
      "Hany Hassan",
      "Ruofei Zhang",
      "Tuo Zhao",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04260"
  },
  {
    "id": "arXiv:2110.04267",
    "title": "Exploring Heterogeneous Characteristics of Layers in ASR Models for More  Efficient Training",
    "abstract": "Transformer-based architectures have been the subject of research aimed at\nunderstanding their overparameterization and the non-uniform importance of\ntheir layers. Applying these approaches to Automatic Speech Recognition, we\ndemonstrate that the state-of-the-art Conformer models generally have multiple\nambient layers. We study the stability of these layers across runs and model\nsizes, propose that group normalization may be used without disrupting their\nformation, and examine their correlation with model weight updates in each\nlayer. Finally, we apply these findings to Federated Learning in order to\nimprove the training procedure, by targeting Federated Dropout to layers by\nimportance. This allows us to reduce the model size optimized by clients\nwithout quality degradation, and shows potential for future exploration.",
    "descriptor": "\nComments: \\c{opyright} 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Lillian Zhou",
      "Dhruv Guliani",
      "Andreas Kabel",
      "Giovanni Motta",
      "Fran\u00e7oise Beaufays"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.04267"
  },
  {
    "id": "arXiv:2110.04274",
    "title": "On the Implicit Biases of Architecture & Gradient Descent",
    "abstract": "Do neural networks generalise because of bias in the functions returned by\ngradient descent, or bias already present in the network architecture? Por\nqu\\'e no los dos?\nThis paper finds that while typical networks that fit the training data\nalready generalise fairly well, gradient descent can further improve\ngeneralisation by selecting networks with a large margin. This conclusion is\nbased on a careful study of the behaviour of infinite width networks trained by\nBayesian inference and finite width networks trained by gradient descent. To\nmeasure the implicit bias of architecture, new technical tools are developed to\nboth analytically bound and consistently estimate the average test error of the\nneural network--Gaussian process (NNGP) posterior. This error is found to be\nalready better than chance, corroborating the findings of Valle-P\\'erez et al.\n(2019) and underscoring the importance of architecture. Going beyond this\nresult, this paper finds that test performance can be substantially improved by\nselecting a function with much larger margin than is typical under the NNGP\nposterior. This highlights a curious fact: minimum a posteriori functions can\ngeneralise best, and gradient descent can select for those functions. In\nsummary, new technical tools suggest a nuanced portrait of generalisation\ninvolving both the implicit biases of architecture and gradient descent.\nCode for this paper is available at: https://github.com/jxbz/implicit-bias/.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2103.01045\n",
    "authors": [
      "Jeremy Bernstein",
      "Yisong Yue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04274"
  },
  {
    "id": "arXiv:2110.04276",
    "title": "Offline Meta-Reinforcement Learning for Industrial Insertion",
    "abstract": "Reinforcement learning (RL) can in principle make it possible for robots to\nautomatically adapt to new tasks, but in practice current RL methods require a\nvery large number of trials to accomplish this. In this paper, we tackle rapid\nadaptation to new tasks through the framework of meta-learning, which utilizes\npast tasks to learn to adapt, with a specific focus on industrial insertion\ntasks. We address two specific challenges by applying meta-learning in this\nsetting. First, conventional meta-RL algorithms require lengthy online\nmeta-training phases. We show that this can be replaced with appropriately\nchosen offline data, resulting in an offline meta-RL method that only requires\ndemonstrations and trials from each of the prior tasks, without the need to run\ncostly meta-RL procedures online. Second, meta-RL methods can fail to\ngeneralize to new tasks that are too different from those seen at meta-training\ntime, which poses a particular challenge in industrial applications, where high\nsuccess rates are critical. We address this by combining contextual\nmeta-learning with direct online finetuning: if the new task is similar to\nthose seen in the prior data, then the contextual meta-learner adapts\nimmediately, and if it is too different, it gradually adapts through\nfinetuning. We show that our approach is able to quickly adapt to a variety of\ndifferent insertion tasks, learning how to perform them with a success rate of\n100\\% using only a fraction of the samples needed for learning the tasks from\nscratch. Experiment videos and details are available at\nhttps://sites.google.com/view/offline-metarl-insertion.",
    "descriptor": "",
    "authors": [
      "Tony Z. Zhao",
      "Jianlan Luo",
      "Oleg Sushkov",
      "Rugile Pevceviciute",
      "Nicolas Heess",
      "Jon Scholz",
      "Stefan Schaal",
      "Sergey Levine"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.04276"
  },
  {
    "id": "arXiv:2110.04280",
    "title": "Pyxis: An Open-Source Performance Dataset of Sparse Accelerators",
    "abstract": "Specialized accelerators provide gains of performance and efficiency in\nspecific domains of applications. Sparse data structures or/and representations\nexist in a wide range of applications. However, it is challenging to design\naccelerators for sparse applications because no analytic architecture or\nperformance-level models are able to fully capture the spectrum of the sparse\ndata. Accelerator researchers rely on real execution to get precise feedback\nfor their designs. In this work, we present PYXIS, a performance dataset for\nspecialized accelerators on sparse data. PYXIS collects accelerator designs and\nreal execution performance statistics. Currently, there are 73.8 K instances in\nPYXIS. PYXIS is open-source, and we are constantly growing PYXIS with new\naccelerator designs and performance statistics. PYXIS can benefit researchers\nin the fields of accelerator, architecture, performance, algorithm, and many\nrelated topics.",
    "descriptor": "",
    "authors": [
      "Linghao Song",
      "Yuze Chi",
      "Jason Cong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2110.04280"
  },
  {
    "id": "arXiv:2110.04281",
    "title": "Collaging Class-specific GANs for Semantic Image Synthesis",
    "abstract": "We propose a new approach for high resolution semantic image synthesis. It\nconsists of one base image generator and multiple class-specific generators.\nThe base generator generates high quality images based on a segmentation map.\nTo further improve the quality of different objects, we create a bank of\nGenerative Adversarial Networks (GANs) by separately training class-specific\nmodels. This has several benefits including -- dedicated weights for each\nclass; centrally aligned data for each model; additional training data from\nother sources, potential of higher resolution and quality; and easy\nmanipulation of a specific object in the scene. Experiments show that our\napproach can generate high quality images in high resolution while having\nflexibility of object-level control by using class-specific generators.",
    "descriptor": "\nComments: ICCV 2021\n",
    "authors": [
      "Yuheng Li",
      "Yijun Li",
      "Jingwan Lu",
      "Eli Shechtman",
      "Yong Jae Lee",
      "Krishna Kumar Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04281"
  },
  {
    "id": "arXiv:2110.04282",
    "title": "Field Extraction from Forms with Unlabeled Data",
    "abstract": "We propose a novel framework to conduct field extraction from forms with\nunlabeled data. To bootstrap the training process, we develop a rule-based\nmethod for mining noisy pseudo-labels from unlabeled forms. Using the\nsupervisory signal from the pseudo-labels, we extract a discriminative token\nrepresentation from a transformer-based model by modeling the interaction\nbetween text in the form. To prevent the model from overfitting to label noise,\nwe introduce a refinement module based on a progressive pseudo-label ensemble.\nExperimental results demonstrate the effectiveness of our framework.",
    "descriptor": "",
    "authors": [
      "Mingfei Gao",
      "Zeyuan Chen",
      "Nikhil Naik",
      "Kazuma Hashimoto",
      "Caiming Xiong",
      "Ran Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04282"
  },
  {
    "id": "arXiv:2110.04284",
    "title": "Auto-DSP: Learning to Optimize Acoustic Echo Cancellers",
    "abstract": "Adaptive filtering algorithms are commonplace in signal processing and have\nwide-ranging applications from single-channel denoising to multi-channel\nacoustic echo cancellation and adaptive beamforming. Such algorithms typically\noperate via specialized online, iterative optimization methods and have\nachieved tremendous success, but require expert knowledge, are slow to develop,\nand are difficult to customize. In our work, we present a new method to\nautomatically learn adaptive filtering update rules directly from data. To do\nso, we frame adaptive filtering as a differentiable operator and train a\nlearned optimizer to output a gradient descent-based update rule from data via\nbackpropagation through time. We demonstrate our general approach on an\nacoustic echo cancellation task (single-talk with noise) and show that we can\nlearn high-performing adaptive filters for a variety of common linear and\nnon-linear multidelayed block frequency domain filter architectures. We also\nfind that our learned update rules exhibit fast convergence, can optimize in\nthe presence of nonlinearities, and are robust to acoustic scene changes\ndespite never encountering any during training.",
    "descriptor": "\nComments: Accepted to the 2021 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA). Source code and audio examples: this https URL\n",
    "authors": [
      "Jonah Casebeer",
      "Nicholas J. Bryan",
      "Paris Smaragdis"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.04284"
  },
  {
    "id": "arXiv:2110.04286",
    "title": "Is MC Dropout Bayesian?",
    "abstract": "MC Dropout is a mainstream \"free lunch\" method in medical imaging for\napproximate Bayesian computations (ABC). Its appeal is to solve out-of-the-box\nthe daunting task of ABC and uncertainty quantification in Neural Networks\n(NNs); to fall within the variational inference (VI) framework; and to propose\na highly multimodal, faithful predictive posterior. We question the properties\nof MC Dropout for approximate inference, as in fact MC Dropout changes the\nBayesian model; its predictive posterior assigns $0$ probability to the true\nmodel on closed-form benchmarks; the multimodality of its predictive posterior\nis not a property of the true predictive posterior but a design artefact. To\naddress the need for VI on arbitrary models, we share a generic VI engine\nwithin the pytorch framework. The code includes a carefully designed\nimplementation of structured (diagonal plus low-rank) multivariate normal\nvariational families, and mixtures thereof. It is intended as a go-to\nno-free-lunch approach, addressing shortcomings of mean-field VI with an\nadjustable trade-off between expressivity and computational complexity.",
    "descriptor": "",
    "authors": [
      "Loic Le Folgoc",
      "Vasileios Baltatzis",
      "Sujal Desai",
      "Anand Devaraj",
      "Sam Ellis",
      "Octavio E. Martinez Manzanera",
      "Arjun Nair",
      "Huaqi Qiu",
      "Julia Schnabel",
      "Ben Glocker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04286"
  },
  {
    "id": "arXiv:2110.04291",
    "title": "Local and Global Context-Based Pairwise Models for Sentence Ordering",
    "abstract": "Sentence Ordering refers to the task of rearranging a set of sentences into\nthe appropriate coherent order. For this task, most previous approaches have\nexplored global context-based end-to-end methods using Sequence Generation\ntechniques. In this paper, we put forward a set of robust local and global\ncontext-based pairwise ordering strategies, leveraging which our prediction\nstrategies outperform all previous works in this domain. Our proposed encoding\nmethod utilizes the paragraph's rich global contextual information to predict\nthe pairwise order using novel transformer architectures. Analysis of the two\nproposed decoding strategies helps better explain error propagation in pairwise\nmodels. This approach is the most accurate pure pairwise model and our encoding\nstrategy also significantly improves the performance of other recent approaches\nthat use pairwise models, including the previous state-of-the-art,\ndemonstrating the research novelty and generalizability of this work.\nAdditionally, we show how the pre-training task for ALBERT helps it to\nsignificantly outperform BERT, despite having considerably lesser parameters.\nThe extensive experimental results, architectural analysis and ablation studies\ndemonstrate the effectiveness and superiority of the proposed models compared\nto the previous state-of-the-art, besides providing a much better understanding\nof the functioning of pairwise models.",
    "descriptor": "\nComments: Under review by Knowledge-Based Systems\n",
    "authors": [
      "Ruskin Raj Manku",
      "Aditya Jyoti Paul"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.04291"
  },
  {
    "id": "arXiv:2110.04292",
    "title": "Toward a Visual Concept Vocabulary for GAN Latent Space",
    "abstract": "A large body of recent work has identified transformations in the latent\nspaces of generative adversarial networks (GANs) that consistently and\ninterpretably transform generated images. But existing techniques for\nidentifying these transformations rely on either a fixed vocabulary of\npre-specified visual concepts, or on unsupervised disentanglement techniques\nwhose alignment with human judgments about perceptual salience is unknown. This\npaper introduces a new method for building open-ended vocabularies of primitive\nvisual concepts represented in a GAN's latent space. Our approach is built from\nthree components: (1) automatic identification of perceptually salient\ndirections based on their layer selectivity; (2) human annotation of these\ndirections with free-form, compositional natural language descriptions; and (3)\ndecomposition of these annotations into a visual concept vocabulary, consisting\nof distilled directions labeled with single words. Experiments show that\nconcepts learned with our approach are reliable and composable -- generalizing\nacross classes, contexts, and observers, and enabling fine-grained manipulation\nof image style and content.",
    "descriptor": "\nComments: 15 pages, 13 figures. Accepted to ICCV 2021. Project page: this https URL\n",
    "authors": [
      "Sarah Schwettmann",
      "Evan Hernandez",
      "David Bau",
      "Samuel Klein",
      "Jacob Andreas",
      "Antonio Torralba"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04292"
  },
  {
    "id": "arXiv:2110.04293",
    "title": "Function-private Conditional Disclosure of Secrets and Multi-evaluation  Threshold Distributed Point Functions",
    "abstract": "Conditional disclosure of secrets (CDS) allows multiple parties to reveal a\nsecret to a third party if and only if some pre-decided condition is satisfied.\nIn this work, we bolster the privacy guarantees of CDS by introducing\nfunction-private CDS wherein the pre-decided condition is never revealed to the\nthird party. We also derive a function secret sharing scheme from our\nfunction-private CDS solution. The second problem that we consider concerns\nthreshold distributed point functions, which allow one to split a point\nfunction such that at least a threshold number of shares are required to\nevaluate it at any given input. We consider a setting wherein a point function\nis split among a set of parties such that multiple evaluations do not leak\nnon-negligible information about it. Finally, we present a provably optimal\nprocedure to perform threshold function secret sharing of any polynomial in a\nfinite field.",
    "descriptor": "\nComments: The is the full version of the paper that will appear in Cryptology and Network Security (CANS), 2021\n",
    "authors": [
      "Nolan Miranda",
      "Foo Yee Yeo",
      "Vipin Singh Sehrawat"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.04293"
  },
  {
    "id": "arXiv:2110.04294",
    "title": "2nd Place Solution to Google Landmark Retrieval 2021",
    "abstract": "This paper presents the 2nd place solution to the Google Landmark Retrieval\n2021 Competition on Kaggle. The solution is based on a baseline with training\ntricks from person re-identification, a continent-aware sampling strategy is\npresented to select training images according to their country tags and a\nLandmark-Country aware reranking is proposed for the retrieval task. With these\ncontributions, we achieve 0.52995 mAP@100 on private leaderboard. Code\navailable at\nhttps://github.com/WesleyZhang1991/Google_Landmark_Retrieval_2021_2nd_Place_Solution",
    "descriptor": "\nComments: Kaggle Competition, ICCV workshop\n",
    "authors": [
      "Zhang Yuqi",
      "Xu Xianzhe",
      "Chen Weihua",
      "Wang Yaohua",
      "Zhang Fangyi",
      "Wang Fan",
      "Li Hao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04294"
  },
  {
    "id": "arXiv:2110.03361",
    "title": "Multi-scale speaker embedding-based graph attention networks for speaker  diarisation",
    "abstract": "The objective of this work is effective speaker diarisation using multi-scale\nspeaker embeddings. Typically, there is a trade-off between the ability to\nrecognise short speaker segments and the discriminative power of the embedding,\naccording to the segment length used for embedding extraction. To this end,\nrecent works have proposed the use of multi-scale embeddings where segments\nwith varying lengths are used. However, the scores are combined using a\nweighted summation scheme where the weights are fixed after the training phase,\nwhereas the importance of segment lengths can differ with in a single session.\nTo address this issue, we present three key contributions in this paper: (1) we\npropose graph attention networks for multi-scale speaker diarisation; (2) we\ndesign scale indicators to utilise scale information of each embedding; (3) we\nadapt the attention-based aggregation to utilise a pre-computed affinity matrix\nfrom multi-scale embeddings. We demonstrate the effectiveness of our method in\nvarious datasets where the speaker confusion which constitutes the primary\nmetric drops over 10% in average relative compared to the baseline.",
    "descriptor": "\nComments: 5 pages, 2 figures, submitted to ICASSP as a conference paper\n",
    "authors": [
      "Youngki Kwon",
      "Hee-Soo Heo",
      "Jee-weon Jung",
      "You Jin Kim",
      "Bong-Jin Lee",
      "Joon Son Chung"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.03361"
  },
  {
    "id": "arXiv:2110.03687",
    "title": "Protecting Retail Investors from Order Book Spoofing using a GRU-based  Detection Model",
    "abstract": "Market manipulation is tackled through regulation in traditional markets\nbecause of its detrimental effect on market efficiency and many participating\nfinancial actors. The recent increase of private retail investors due to new\nlow-fee platforms and new asset classes such as decentralised digital\ncurrencies has increased the number of vulnerable actors due to lack of\ninstitutional sophistication and strong regulation. This paper proposes a\nmethod to detect illicit activity and inform investors on spoofing attempts, a\nwell-known market manipulation technique. Our framework is based on a highly\nextendable Gated Recurrent Unit (GRU) model and allows the inclusion of market\nvariables that can explain spoofing and potentially other illicit activities.\nThe model is tested on granular order book data, in one of the most unregulated\nmarkets prone to spoofing with a large number of non-institutional traders. The\nresults show that the model is performing well in an early detection context,\nallowing the identification of spoofing attempts soon enough to allow investors\nto react. This is the first step to a fully comprehensive model that will\nprotect investors in various unregulated trading environments and regulators to\nidentify illicit activity.",
    "descriptor": "",
    "authors": [
      "Jean-No\u00ebl Tuccella",
      "Philip Nadler",
      "Ovidiu \u015eerban"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03687"
  },
  {
    "id": "arXiv:2110.03688",
    "title": "Predicting Chemical Hazard across Taxa through Machine Learning",
    "abstract": "We apply machine learning methods to predict chemical hazards focusing on\nfish acute toxicity across taxa. We analyze the relevance of taxonomy and\nexperimental setup, and show that taking them into account can lead to\nconsiderable improvements in the classification performance. We quantify the\ngain obtained by introducing the taxonomic and experimental information,\ncompared to classifying based on chemical information alone. We use our\napproach with standard machine learning models (K-nearest neighbors, random\nforests and deep neural networks), as well as the recently proposed Read-Across\nStructure Activity Relationship (RASAR) models, which were very successful in\npredicting chemical hazards to mammals based on chemical similarity. We are\nable to obtain accuracies of over 0.93 on datasets where, due to noise in the\ndata, the maximum achievable accuracy is expected to be below 0.95, which\nresults in an effective accuracy of 0.98. The best performances are obtained by\nrandom forests and RASAR models. We analyze metrics to compare our results with\nanimal test reproducibility, and despite most of our models 'outperform animal\ntest reproducibility' as measured through recently proposed metrics, we show\nthat the comparison between machine learning performance and animal test\nreproducibility should be addressed with particular care. While we focus on\nfish mortality, our approach, provided that the right data is available, is\nvalid for any combination of chemicals, effects and taxa.",
    "descriptor": "",
    "authors": [
      "Jimeng Wu",
      "Simone D'Ambrosi",
      "Lorenz Ammann",
      "Julita Stadnicka-Michalak",
      "Kristin Schirmer",
      "Marco Baity-Jesi"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03688"
  },
  {
    "id": "arXiv:2110.03689",
    "title": "DeepECMP: Predicting Extracellular Matrix Proteins using Deep Learning",
    "abstract": "Introduction: The extracellular matrix (ECM) is a networkof proteins and\ncarbohydrates that has a structural and bio-chemical function. The ECM plays an\nimportant role in dif-ferentiation, migration and signaling. Several studies\nhavepredicted ECM proteins using machine learning algorithmssuch as Random\nForests, K-nearest neighbours and supportvector machines but is yet to be\nexplored using deep learn-ing. Method: DeepECMP was developed using several\nprevi-ously used ECM datasets, asymmetric undersampling andan ensemble of 11\nfeed-forward neural networks. Results: The performance of DeepECMP was 83.6%\nbal-anced accuracy which outperformed several algorithms. Inaddition, the\npipeline of DeepECMP has been shown to behighly efficient. Conclusion: This\npaper is the first to focus on utilizingdeep learning for ECM prediction.\nSeveral limitations areovercome by DeepECMP such as computational\nexpense,availability to the public and usability outside of the humanspecies",
    "descriptor": "",
    "authors": [
      "Mohamed Ghafoor",
      "Anh Nguyen"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03689"
  },
  {
    "id": "arXiv:2110.03690",
    "title": "Learning Higher-Order Dynamics in Video-Based Cardiac Measurement",
    "abstract": "Computer vision methods typically optimize for first-order dynamics (e.g.,\noptical flow). However, in many cases the properties of interest are subtle\nvariations in higher-order changes, such as acceleration. This is true in the\ncardiac pulse, where the second derivative can be used as an indicator of blood\npressure and arterial disease. Recent developments in camera-based vital sign\nmeasurement have shown that cardiac measurements can be recovered with\nimpressive accuracy from videos; however, the majority of research has focused\non extracting summary statistics such as heart rate. Less emphasis has been put\non the accuracy of waveform morphology that is necessary for many clinically\nimpactful scenarios. In this work, we provide evidence that higher-order\ndynamics are better estimated by neural models when explicitly optimized for in\nthe loss function. Furthermore, adding second-derivative inputs also improves\nperformance when estimating second-order dynamics. By incorporating the second\nderivative of both the input frames and the target vital sign signals into the\ntraining procedure, our model is better able to estimate left ventricle\nejection time (LVET) intervals.",
    "descriptor": "",
    "authors": [
      "Brian L. Hill",
      "Xin Liu",
      "Daniel McDuff"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03690"
  },
  {
    "id": "arXiv:2110.03691",
    "title": "Direct design of biquad filter cascades with deep learning by sampling  random polynomials",
    "abstract": "Designing infinite impulse response filters to match an arbitrary magnitude\nresponse requires specialized techniques. Methods like modified Yule-Walker are\nrelatively efficient, but may not be sufficiently accurate in matching high\norder responses. On the other hand, iterative optimization techniques often\nenable superior performance, but come at the cost of longer run-times and are\nsensitive to initial conditions, requiring manual tuning. In this work, we\naddress some of these limitations by learning a direct mapping from the target\nmagnitude response to the filter coefficient space with a neural network\ntrained on millions of random filters. We demonstrate our approach enables both\nfast and accurate estimation of filter coefficients given a desired response.\nWe investigate training with different families of random filters, and find\ntraining with a variety of filter families enables better generalization when\nestimating real-world filters, using head-related transfer functions and guitar\ncabinets as case studies. We compare our method against existing methods\nincluding modified Yule-Walker and gradient descent and show IIRNet is, on\naverage, both faster and more accurate.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Joseph T. Colonel",
      "Christian J. Steinmetz",
      "Marcus Michelen",
      "Joshua D. Reiss"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.03691"
  },
  {
    "id": "arXiv:2110.03712",
    "title": "Gaussian Process for Trajectories",
    "abstract": "The Gaussian process is a powerful and flexible technique for interpolating\nspatiotemporal data, especially with its ability to capture complex trends and\nuncertainty from the input signal. This chapter describes Gaussian processes as\nan interpolation technique for geospatial trajectories. A Gaussian process\nmodels measurements of a trajectory as coming from a multidimensional Gaussian,\nand it produces for each timestamp a Gaussian distribution as a prediction. We\ndiscuss elements that need to be considered when applying Gaussian process to\ntrajectories, common choices for those elements, and provide a concrete example\nof implementing a Gaussian process.",
    "descriptor": "\nComments: SpatialGems workshop 2021, 7 pages\n",
    "authors": [
      "Kien Nguyen",
      "John Krumm",
      "Cyrus Shahabi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03712"
  },
  {
    "id": "arXiv:2110.03715",
    "title": "Power efficient analog features for audio recognition",
    "abstract": "The digital signal processing-based representations like the Mel-Frequency\nCepstral Coefficient are well known to be a solid basis for various audio\nprocessing tasks. Alternatively, analog feature representations, relying on\nanalog-electronics-feasible bandpass filtering, allow much lower system power\nconsumption compared with the digital counterpart, while parity performance on\ntraditional tasks like voice activity detection can be achieved. This work\nexplores the possibility of using analog features on multiple speech processing\ntasks that vary in time dependencies: wake word detection, keyword spotting,\nand speaker identification. The results of this evaluation show that the analog\nfeatures are still more power-efficient and competitive on simpler tasks than\ndigital features but yield an increasing performance drop on more complex tasks\nwhen long-time correlations are present. We also introduce a novel theoretical\nframework based on information theory to understand this performance drop by\nquantifying information flow in feature calculation which helps identify the\nperformance bottlenecks. The theoretical claims are experimentally validated,\nleading to a maximum of 6% increase of keyword spotting accuracy, even\nsurpassing the digital baseline features. The proposed analog-feature-based\nsystems could pave the way to achieving best-in-class accuracy and power\nconsumption simultaneously.",
    "descriptor": "\nComments: Analog systems, audio classification, power efficiency, information theory\n",
    "authors": [
      "Boris Bergsma",
      "Minhao Yang",
      "Milos Cernak"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.03715"
  },
  {
    "id": "arXiv:2110.03720",
    "title": "Robustness to Incorrect Priors and Controlled Filter Stability in  Partially Observed Stochastic Control",
    "abstract": "We study controlled filter stability and its effects on the robustness\nproperties of optimal control policies designed for systems with incorrect\npriors applied to a true system. Filter stability refers to the correction of\nan incorrectly initialized filter for a partially observed stochastic dynamical\nsystem (controlled or control-free) with increasing measurements. This problem\nhas been studied extensively in the control-free context, and except for the\nstandard machinery for linear Gaussian systems involving the Kalman Filter, few\nstudies exist for the controlled setup. One of the main differences between\ncontrol-free and controlled partially observed Markov chains is that the filter\nis always Markovian under the former, whereas under a controlled model the\nfilter process may not be Markovian since the control policy may depend on past\nmeasurements in an arbitrary (measurable) fashion. This complicates the\ndependency structure and therefore results from the control-free literature do\nnot directly apply to the controlled setup. In this paper, we study the filter\nstability problem for controlled stochastic dynamical systems, and provide\nsufficient conditions for when a falsely initialized filter merges with the\ncorrectly initialized filter over time. These stability results are applied to\nrobust stochastic control problems: under filter stability, we bound the\ndifference in the expected cost incurred for implementing an incorrectly\ndesigned control policy compared to an optimal policy. A conclusion is that\nfilter stability leads to stronger robustness results to incorrect priors\n(compared with setups without controlled filter stability). Furthermore, if the\noptimum cost is that same for each prior, the cost of mismatch between the true\nprior and the assumed prior is zero.",
    "descriptor": "",
    "authors": [
      "Curtis McDonald",
      "Serdar Y\u00fcksel"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2110.03720"
  },
  {
    "id": "arXiv:2110.03747",
    "title": "Fixed-Order H2-Conic Control",
    "abstract": "H2-conic controller design seeks to minimize the closed-loop H2-norm for a\nnominal linear system while satisfying the Conic Sector Theorem for nonlinear\nstability. This problem has only been posed with limited design freedom, as\nopposed to fixed-order design where all controller parameters except the number\nof state estimates are free variables. Here, the fixed-order H2-conic design\nproblem is reformulated as a convergent series of convex approximations using\niterative convex overbounding. A synthesis algorithm and various\ninitializations are proposed. The synthesis is applied to a passivity-violated\nsystem with uncertain parameters and compared to benchmark controller designs.",
    "descriptor": "\nComments: To be presented at 60th IEEE Conference on Decision and Control in December 2021\n",
    "authors": [
      "Ethan J. LoCicero",
      "Leila Bridgeman"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.03747"
  },
  {
    "id": "arXiv:2110.03749",
    "title": "Global sensitivity analysis in probabilistic graphical models",
    "abstract": "We show how to apply Sobol's method of global sensitivity analysis to measure\nthe influence exerted by a set of nodes' evidence on a quantity of interest\nexpressed by a Bayesian network. Our method exploits the network structure so\nas to transform the problem of Sobol index estimation into that of\nmarginalization inference. This way, we can efficiently compute indices for\nnetworks where brute-force or Monte Carlo based estimators for variance-based\nsensitivity analysis would require millions of costly samples. Moreover, our\nmethod gives exact results when exact inference is used, and also supports the\ncase of correlated inputs. The proposed algorithm is inspired by the field of\ntensor networks, and generalizes earlier tensor sensitivity techniques from the\nacyclic to the cyclic case. We demonstrate the method on three medium to large\nBayesian networks that cover the areas of project risk management and\nreliability engineering.",
    "descriptor": "",
    "authors": [
      "Rafael Ballester-Ripoll",
      "Manuele Leonelli"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03749"
  },
  {
    "id": "arXiv:2110.03768",
    "title": "De-randomizing MCMC dynamics with the diffusion Stein operator",
    "abstract": "Approximate Bayesian inference estimates descriptors of an intractable target\ndistribution - in essence, an optimization problem within a family of\ndistributions. For example, Langevin dynamics (LD) extracts asymptotically\nexact samples from a diffusion process because the time evolution of its\nmarginal distributions constitutes a curve that minimizes the KL-divergence via\nsteepest descent in the Wasserstein space. Parallel to LD, Stein variational\ngradient descent (SVGD) similarly minimizes the KL, albeit endowed with a novel\nStein-Wasserstein distance, by deterministically transporting a set of particle\nsamples, thus de-randomizes the stochastic diffusion process. We propose\nde-randomized kernel-based particle samplers to all diffusion-based samplers\nknown as MCMC dynamics. Following previous work in interpreting MCMC dynamics,\nwe equip the Stein-Wasserstein space with a fiber-Riemannian Poisson structure,\nwith the capacity of characterizing a fiber-gradient Hamiltonian flow that\nsimulates MCMC dynamics. Such dynamics discretizes into generalized SVGD\n(GSVGD), a Stein-type deterministic particle sampler, with particle updates\ncoinciding with applying the diffusion Stein operator to a kernel function. We\ndemonstrate empirically that GSVGD can de-randomize complex MCMC dynamics,\nwhich combine the advantages of auxiliary momentum variables and Riemannian\nstructure, while maintaining the high sample quality from an interacting\nparticle system.",
    "descriptor": "\nComments: 22 pages, 6 figures. NeurIPS 2021\n",
    "authors": [
      "Zheyang Shen",
      "Markus Heinonen",
      "Samuel Kaski"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03768"
  },
  {
    "id": "arXiv:2110.03773",
    "title": "Isolation of connected graphs",
    "abstract": "For a connected $n$-vertex graph $G$ and a set $\\mathcal{F}$ of graphs, let\n$\\iota(G,\\mathcal{F})$ denote the size of a smallest set $D$ of vertices of $G$\nsuch that the graph obtained from $G$ by deleting the closed neighbourhood of\n$D$ contains no graph in $\\mathcal{F}$. Let $\\mathcal{E}_k$ denote the set of\nconnected graphs that have at least $k$ edges. By a result of Caro and\nHansberg, $\\iota(G,\\mathcal{E}_1) \\leq n/3$ if $n \\neq 2$ and $G$ is not a\n$5$-cycle. The author recently showed that if $G$ is not a triangle and\n$\\mathcal{C}$ is the set of cycles, then $\\iota(G,\\mathcal{C}) \\leq n/4$. We\nimprove this result by showing that $\\iota(G,\\mathcal{E}_3) \\leq n/4$ if $G$ is\nneither a triangle nor a $7$-cycle. Let $r$ be the number of vertices of $G$\nthat have only one neighbour. We determine a set $\\mathcal{S}$ of six graphs\nsuch that $\\iota(G,\\mathcal{E}_2) \\leq (4n - r)/14$ if $G$ is not a copy of a\nmember of $\\mathcal{S}$. The bounds are sharp.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Peter Borg"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.03773"
  },
  {
    "id": "arXiv:2110.03775",
    "title": "Proposing a System Level Machine Learning Hybrid Architecture and  Approach for a Comprehensive Autism Spectrum Disorder Diagnosis",
    "abstract": "Autism Spectrum Disorder (ASD) is a severe neuropsychiatric disorder that\naffects intellectual development, social behavior, and facial features, and the\nnumber of cases is still significantly increasing. Due to the variety of\nsymptoms ASD displays, the diagnosis process remains challenging, with numerous\nmisdiagnoses as well as lengthy and expensive diagnoses. Fortunately, if ASD is\ndiagnosed and treated early, then the patient will have a much higher chance of\ndeveloping normally. For an ASD diagnosis, machine learning algorithms can\nanalyze both social behavior and facial features accurately and efficiently,\nproviding an ASD diagnosis in a drastically shorter amount of time than through\ncurrent clinical diagnosis processes. Therefore, we propose to develop a hybrid\narchitecture fully utilizing both social behavior and facial feature data to\nimprove the accuracy of diagnosing ASD. We first developed a Linear Support\nVector Machine for the social behavior based module, which analyzes Autism\nDiagnostic Observation Schedule (ADOS) social behavior data. For the facial\nfeature based module, a DenseNet model was utilized to analyze facial feature\nimage data. Finally, we implemented our hybrid model by incorporating different\nfeatures of the Support Vector Machine and the DenseNet into one model. Our\nresults show that the highest accuracy of 87% for ASD diagnosis has been\nachieved by our proposed hybrid model. The pros and cons of each module will be\ndiscussed in this paper.",
    "descriptor": "",
    "authors": [
      "Ryan Liu",
      "Spencer He"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.03775"
  },
  {
    "id": "arXiv:2110.03828",
    "title": "SkullEngine: A Multi-stage CNN Framework for Collaborative CBCT Image  Segmentation and Landmark Detection",
    "abstract": "We propose a multi-stage coarse-to-fine CNN-based framework, called\nSkullEngine, for high-resolution segmentation and large-scale landmark\ndetection through a collaborative, integrated, and scalable JSD model and three\nsegmentation and landmark detection refinement models. We evaluated our\nframework on a clinical dataset consisting of 170 CBCT/CT images for the task\nof segmenting 2 bones (midface and mandible) and detecting 175 clinically\ncommon landmarks on bones, teeth, and soft tissues.",
    "descriptor": "\nComments: 10 pages, 5 figures, accepted by MLMI 2021\n",
    "authors": [
      "Qin Liu",
      "Han Deng",
      "Chunfeng Lian",
      "Xiaoyang Chen",
      "Deqiang Xiao",
      "Lei Ma",
      "Xu Chen",
      "Tianshu Kuang",
      "Jaime Gateno",
      "Pew-Thian Yap",
      "James J. Xia"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03828"
  },
  {
    "id": "arXiv:2110.03841",
    "title": "Input Length Matters: An Empirical Study Of RNN-T And MWER Training For  Long-form Telephony Speech Recognition",
    "abstract": "End-to-end models have achieved state-of-the-art results on several automatic\nspeech recognition tasks. However, they perform poorly when evaluated on\nlong-form data, e.g., minutes long conversational telephony audio. One reason\nthe model fails on long-form speech is that it has only seen short utterances\nduring training. This paper presents an empirical study on the effect of\ntraining utterance length on the word error rate (WER) for RNN-transducer\n(RNN-T) model. We compare two widely used training objectives, log loss (or\nRNN-T loss) and minimum word error rate (MWER) loss. We conduct experiments on\ntelephony datasets in four languages. Our experiments show that for both\nlosses, the WER on long-form speech reduces substantially as the training\nutterance length increases. The average relative WER gain is 15.7% for log loss\nand 8.8% for MWER loss. When training on short utterances, MWER loss leads to a\nlower WER than the log loss. Such difference between the two losses diminishes\nwhen the input length increases.",
    "descriptor": "",
    "authors": [
      "Zhiyun Lu",
      "Yanwei Pan",
      "Thibault Doutre",
      "Liangliang Cao",
      "Rohit Prabhavalkar",
      "Chao Zhang",
      "Trevor Strohman"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.03841"
  },
  {
    "id": "arXiv:2110.03857",
    "title": "A study on the efficacy of model pre-training in developing neural  text-to-speech system",
    "abstract": "In the development of neural text-to-speech systems, model pre-training with\na large amount of non-target speakers' data is a common approach. However, in\nterms of ultimately achieved system performance for target speaker(s), the\nactual benefits of model pre-training are uncertain and unstable, depending\nvery much on the quantity and text content of training data. This study aims to\nunderstand better why and how model pre-training can positively contribute to\nTTS system performance. It is postulated that the pre-training process plays a\ncritical role in learning text-related variation in speech, while further\ntraining with the target speaker's data aims to capture the speaker-related\nvariation. Different test sets are created with varying degrees of similarity\nto target speaker data in terms of text content. Experiments show that\nleveraging a speaker-independent TTS trained on speech data with diverse text\ncontent can improve the target speaker TTS on domain-mismatched text. We also\nattempt to reduce the amount of pre-training data for a new text domain and\nimprove the data and computational efficiency. It is found that the TTS system\ncould achieve comparable performance when the pre-training data is reduced to\n1/8 of its original size.",
    "descriptor": "",
    "authors": [
      "Guangyan Zhang",
      "Yichong Leng",
      "Daxin Tan",
      "Ying Qin",
      "Kaitao Song",
      "Xu Tan",
      "Sheng Zhao",
      "Tan Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.03857"
  },
  {
    "id": "arXiv:2110.03861",
    "title": "QTN-VQC: An End-to-End Learning framework for Quantum Neural Networks",
    "abstract": "The advent of noisy intermediate-scale quantum (NISQ) computers raises a\ncrucial challenge to design quantum neural networks for fully quantum learning\ntasks. To bridge the gap, this work proposes an end-to-end learning framework\nnamed QTN-VQC, by introducing a trainable quantum tensor network (QTN) for\nquantum embedding on a variational quantum circuit (VQC). The architecture of\nQTN is composed of a parametric tensor-train network for feature extraction and\na tensor product encoding for quantum encoding. We highlight the QTN for\nquantum embedding in terms of two perspectives: (1) we theoretically\ncharacterize QTN by analyzing its representation power of input features; (2)\nQTN enables an end-to-end parametric model pipeline, namely QTN-VQC, from the\ngeneration of quantum embedding to the output measurement. Our experiments on\nthe MNIST dataset demonstrate the advantages of QTN for quantum embedding over\nother quantum embedding approaches.",
    "descriptor": "",
    "authors": [
      "Jun Qi",
      "Chao-Han Huck Yang",
      "Pin-Yu Chen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.03861"
  },
  {
    "id": "arXiv:2110.03864",
    "title": "Boundary-aware Transformers for Skin Lesion Segmentation",
    "abstract": "Skin lesion segmentation from dermoscopy images is of great importance for\nimproving the quantitative analysis of skin cancer. However, the automatic\nsegmentation of melanoma is a very challenging task owing to the large\nvariation of melanoma and ambiguous boundaries of lesion areas. While\nconvolutional neutral networks (CNNs) have achieved remarkable progress in this\ntask, most of existing solutions are still incapable of effectively capturing\nglobal dependencies to counteract the inductive bias caused by limited\nreceptive fields. Recently, transformers have been proposed as a promising tool\nfor global context modeling by employing a powerful global attention mechanism,\nbut one of their main shortcomings when applied to segmentation tasks is that\nthey cannot effectively extract sufficient local details to tackle ambiguous\nboundaries. We propose a novel boundary-aware transformer (BAT) to\ncomprehensively address the challenges of automatic skin lesion segmentation.\nSpecifically, we integrate a new boundary-wise attention gate (BAG) into\ntransformers to enable the whole network to not only effectively model global\nlong-range dependencies via transformers but also, simultaneously, capture more\nlocal details by making full use of boundary-wise prior knowledge.\nParticularly, the auxiliary supervision of BAG is capable of assisting\ntransformers to learn position embedding as it provides much spatial\ninformation. We conducted extensive experiments to evaluate the proposed BAT\nand experiments corroborate its effectiveness, consistently outperforming\nstate-of-the-art methods in two famous datasets.",
    "descriptor": "",
    "authors": [
      "Jiacheng Wang",
      "Lan Wei",
      "Liansheng Wang",
      "Qichao Zhou",
      "Lei Zhu",
      "Jing Qin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03864"
  },
  {
    "id": "arXiv:2110.03877",
    "title": "Diabetic Retinopathy Screening Using Custom-Designed Convolutional  Neural Network",
    "abstract": "The prevalence of diabetic retinopathy (DR) has reached 34.6% worldwide and\nis a major cause of blindness among middle-aged diabetic patients. Regular DR\nscreening using fundus photography helps detect its complications and prevent\nits progression to advanced levels. As manual screening is time-consuming and\nsubjective, machine learning (ML) and deep learning (DL) have been employed to\naid graders. However, the existing CNN-based methods use either pre-trained CNN\nmodels or a brute force approach to design new CNN models, which are not\ncustomized to the complexity of fundus images. To overcome this issue, we\nintroduce an approach for custom-design of CNN models, whose architectures are\nadapted to the structural patterns of fundus images and better represent the\nDR-relevant features. It takes the leverage of k-medoid clustering, principal\ncomponent analysis (PCA), and inter-class and intra-class variations to\nautomatically determine the depth and width of a CNN model. The designed models\nare lightweight, adapted to the internal structures of fundus images, and\nencode the discriminative patterns of DR lesions. The technique is validated on\na local dataset from King Saud University Medical City, Saudi Arabia, and two\nchallenging benchmark datasets from Kaggle: EyePACS and APTOS2019. The\ncustom-designed models outperform the famous pre-trained CNN models like\nResNet152, Densnet121, and ResNeSt50 with a significant decrease in the number\nof parameters and compete well with the state-of-the-art CNN-based DR screening\nmethods. The proposed approach is helpful for DR screening under diverse\nclinical settings and referring the patients who may need further assessment\nand treatment to expert ophthalmologists.",
    "descriptor": "\nComments: 11 pages, 6 figures\n",
    "authors": [
      "Fahman Saeed",
      "Muhammad Hussain",
      "Senior Member",
      "IEEE",
      "Hatim A Aboalsamh",
      "Senior Member",
      "IEEE",
      "Fadwa Al Adel",
      "Adi Mohammed Al Owaifeer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03877"
  },
  {
    "id": "arXiv:2110.03887",
    "title": "Environment Aware Text-to-Speech Synthesis",
    "abstract": "This study aims at designing an environment-aware text-to-speech (TTS) system\nthat can generate speech to suit specific acoustic environments. It is also\nmotivated by the desire to leverage massive data of speech audio from\nheterogeneous sources in TTS system development. The key idea is to model the\nacoustic environment in speech audio as a factor of data variability and\nincorporate it as a condition in the process of neural network based speech\nsynthesis. Two embedding extractors are trained with two purposely constructed\ndatasets for characterization and disentanglement of speaker and environment\nfactors in speech. A neural network model is trained to generate speech from\nextracted speaker and environment embeddings. Objective and subjective\nevaluation results demonstrate that the proposed TTS system is able to\neffectively disentangle speaker and environment factors and synthesize speech\naudio that carries designated speaker characteristics and environment\nattribute. Audio samples are available online for demonstration\nhttps://daxintan-cuhk.github.io/Environment-Aware-TTS/ .",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Daxin Tan",
      "Guangyan Zhang",
      "Tan Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.03887"
  },
  {
    "id": "arXiv:2110.03894",
    "title": "A Study of Low-Resource Speech Commands Recognition based on Adversarial  Reprogramming",
    "abstract": "In this study, we propose a novel adversarial reprogramming (AR) approach for\nlow-resource spoken command recognition (SCR), and build an AR-SCR system. The\nAR procedure aims to modify the acoustic signals (from the target domain) to\nrepurpose a pretrained SCR model (from the source domain). To solve the label\nmismatches between source and target domains, and further improve the stability\nof AR, we propose a novel similarity-based label mapping technique to align\nclasses. In addition, the transfer learning (TL) technique is combined with the\noriginal AR process to improve the model adaptation capability. We evaluate the\nproposed AR-SCR system on three low-resource SCR datasets, including Arabic,\nLithuanian, and dysarthric Mandarin speech. Experimental results show that with\na pretrained AM trained on a large-scale English dataset, the proposed AR-SCR\nsystem outperforms the current state-of-the-art results on Arabic and\nLithuanian speech commands datasets, with only a limited amount of training\ndata.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Hao Yen",
      "Pin-Jui Ku",
      "Chao-Han Huck Yang",
      "Hu Hu",
      "Sabato Marco Siniscalchi",
      "Pin-Yu Chen",
      "Yu Tsao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.03894"
  },
  {
    "id": "arXiv:2110.03898",
    "title": "Differentiable Programming of Isometric Tensor Networks",
    "abstract": "Differentiable programming is a new programming paradigm which enables large\nscale optimization through automatic calculation of gradients also known as\nauto-differentiation. This concept emerges from deep learning, and has also\nbeen generalized to tensor network optimizations. Here, we extend the\ndifferentiable programming to tensor networks with isometric constraints with\napplications to multiscale entanglement renormalization ansatz (MERA) and\ntensor network renormalization (TNR). By introducing several gradient-based\noptimization methods for the isometric tensor network and comparing with\nEvenbly-Vidal method, we show that auto-differentiation has a better\nperformance for both stability and accuracy. We numerically tested our methods\non 1D critical quantum Ising spin chain and 2D classical Ising model. We\ncalculate the ground state energy for the 1D quantum model and internal energy\nfor the classical model, and scaling dimensions of scaling operators and find\nthey all agree with the theory well.",
    "descriptor": "\nComments: 17 pages, 22 figures\n",
    "authors": [
      "Chenhua Geng",
      "Hong-Ye Hu",
      "Yijian Zou"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03898"
  },
  {
    "id": "arXiv:2110.03918",
    "title": "Relationship between low-discrepancy sequence and static solution to  multi-bodies problem",
    "abstract": "The main interest of this paper is to study the relationship between the\nlow-discrepancy sequence and the static solution to the multi-bodies problem in\nhigh-dimensional space. An assumption that the static solution to the\nmulti-bodies problem is a low-discrepancy sequence is proposed. Considering the\nstatic solution to the multi-bodies problem corresponds to the minimum\npotential energy principle, we further assume that the distribution of the\nbodies is the most uniform when the potential energy is the smallest. To verify\nthe proposed assumptions, a dynamical evolutionary model (DEM) based on the\nminimum potential energy is established to find out the static solution. The\ncentral difference algorithm is adopted to solve the DEM and an evolutionary\niterative scheme is developed. The selection of the mass and the damping\ncoefficient to ensure the convergence of the evolutionary iteration is\ndiscussed in detail. Based on the DEM, the relationship between the potential\nenergy and the discrepancy during the evolutionary iteration process is\nstudied. It is found that there is a significant positive correlation between\nthem, which confirms the proposed assumptions. We also combine the DEM with the\nrestarting technique to generate a series of low-discrepancy sequences. These\nsequences are unbiased and perform better than other low-discrepancy sequences\nin terms of the discrepancy, the potential energy, integrating eight test\nfunctions and computing the statistical moments for two practical stochastic\nproblems. Numerical examples also show that the DEM can not only generate\nuniformly distributed sequences in cubes, but also in non-cubes.",
    "descriptor": "",
    "authors": [
      "Feng Wu",
      "Yuelin Zhao",
      "Ke Zhao",
      "Wanxie Zhong"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.03918"
  },
  {
    "id": "arXiv:2110.03923",
    "title": "Opportunities for Machine Learning to Accelerate Halide Perovskite  Commercialization and Scale-Up",
    "abstract": "While halide perovskites attract significant academic attention, examples of\nat-scale industrial production are still sparse. In this perspective, we review\npractical challenges hindering the commercialization of halide perovskites, and\ndiscuss how machine-learning (ML) tools could help: (1) active-learning\nalgorithms that blend institutional knowledge and human expertise could help\nstabilize and rapidly update baseline manufacturing processes; (2) ML-powered\nmetrology, including computer imaging, could help narrow the performance gap\nbetween large- and small-area devices; and (3) inference methods could help\naccelerate root-cause analysis by reconciling multiple data streams and\nsimulations, focusing research effort on areas with highest probability for\nimprovement. We conclude that to satisfy many of these challenges, incremental\n-- not radical -- adaptations of existing ML and statistical methods are\nneeded. We identify resources to help develop in-house data-science talent, and\npropose how industry-academic partnerships could help adapt \"ready-now\" ML\ntools to specific industry needs, further improve process control by revealing\nunderlying mechanisms, and develop \"gamechanger\" discovery-oriented algorithms\nto better navigate vast materials combination spaces and the literature.",
    "descriptor": "\nComments: 21 pages, 2 figures\n",
    "authors": [
      "Rishi E. Kumar",
      "Armi Tiihonen",
      "Shijing Sun",
      "David P. Fenning",
      "Zhe Liu",
      "Tonio Buonassisi"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03923"
  },
  {
    "id": "arXiv:2110.03950",
    "title": "Nonconvex-Nonconcave Min-Max Optimization with a Small Maximization  Domain",
    "abstract": "We study the problem of finding approximate first-order stationary points in\noptimization problems of the form $\\min_{x \\in X} \\max_{y \\in Y} f(x,y)$, where\nthe sets $X,Y$ are convex and $Y$ is compact. The objective function $f$ is\nsmooth, but assumed neither convex in $x$ nor concave in $y$. Our approach\nrelies upon replacing the function $f(x,\\cdot)$ with its $k$th order Taylor\napproximation (in $y$) and finding a near-stationary point in the resulting\nsurrogate problem. To guarantee its success, we establish the following result:\nlet the Euclidean diameter of $Y$ be small in terms of the target accuracy\n$\\varepsilon$, namely $O(\\varepsilon^{\\frac{2}{k+1}})$ for $k \\in \\mathbb{N}$\nand $O(\\varepsilon)$ for $k = 0$, with the constant factors controlled by\ncertain regularity parameters of $f$; then any $\\varepsilon$-stationary point\nin the surrogate problem remains $O(\\varepsilon)$-stationary for the initial\nproblem. Moreover, we show that these upper bounds are nearly optimal: the\naforementioned reduction provably fails when the diameter of $Y$ is larger. For\n$0 \\le k \\le 2$ the surrogate function can be efficiently maximized in $y$; our\ngeneral approximation result then leads to efficient algorithms for finding a\nnear-stationary point in nonconvex-nonconcave min-max problems, for which we\nalso provide convergence guarantees.",
    "descriptor": "\nComments: 50 pages\n",
    "authors": [
      "Dmitrii M. Ostrovskii",
      "Babak Barazandeh",
      "Meisam Razaviyayn"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03950"
  },
  {
    "id": "arXiv:2110.03957",
    "title": "Bounds for the Twin-width of Graphs",
    "abstract": "Bonnet, Kim, Thomass\\'{e}, and Watrigant (2020) introduced the twin-width of\na graph. We show that the twin-width of an $n$-vertex graph is less than\n$(n+\\sqrt{n\\ln n}+\\sqrt{n}+2\\ln n)/2$, and the twin-width of an $m$-edge graph\nis less than $\\sqrt{3m}+ m^{1/4} \\sqrt{\\ln m} / (4\\cdot 3^{1/4}) + 3m^{1/4} /\n2$. Conference graphs of order $n$ (when such graphs exist) have twin-width at\nleast $(n-1)/2$, and we show that Paley graphs achieve this lower bound. We\nalso show that the twin-width of the Erd\\H{o}s-R\\'{e}nyi random graph $G(n,p)$\nwith $1/n\\leq p=p(n)\\leq 1/2$ is larger than $2p(1-p)n -\n(2\\sqrt{2}+\\varepsilon)\\sqrt{p(1-p)n\\ln n}$ asymptotically almost surely for\nany positive $\\varepsilon$. Lastly, we calculate the twin-width of random\ngraphs $G(n,p)$ with $p\\leq c/n$ for a constant $c<1$, determining the\nthresholds at which the twin-width jumps from $0$ to $1$ and from $1$ to $2$.",
    "descriptor": "\nComments: 21 pages, 1 figure\n",
    "authors": [
      "Jungho Ahn",
      "Kevin Hendrey",
      "Donggyu Kim",
      "Sang-il Oum"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.03957"
  },
  {
    "id": "arXiv:2110.03965",
    "title": "Joint Scattering for Automatic Chick Call Recognition",
    "abstract": "Animal vocalisations contain important information about health, emotional\nstate, and behaviour, thus can be potentially used for animal welfare\nmonitoring. Motivated by the spectro-temporal patterns of chick calls in the\ntime$-$frequency domain, in this paper we propose an automatic system for chick\ncall recognition using the joint time$-$frequency scattering transform (JTFS).\nTaking full-length recordings as input, the system first extracts chick call\ncandidates by an onset detector and silence removal. After computing their JTFS\nfeatures, a support vector machine classifier groups each candidate into\ndifferent chick call types. Evaluating on a dataset comprising 3013 chick calls\ncollected in laboratory conditions, the proposed recognition system using the\nJTFS features improves the frame- and event-based macro F-measures by 9.5% and\n11.7%, respectively, than that of a mel-frequency cepstral coefficients\nbaseline.",
    "descriptor": "\nComments: 5 pages, submitted to ICASSP 2022\n",
    "authors": [
      "Changhong Wang",
      "Emmanouil Benetos",
      "Shuge Wang",
      "Elisabetta Versace"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.03965"
  },
  {
    "id": "arXiv:2110.03966",
    "title": "Novel EEG-based BCIs for Elderly Rehabilitation Enhancement",
    "abstract": "The ageing process may lead to cognitive and physical impairments, which may\naffect elderly everyday life. In recent years, the use of Brain Computer\nInterfaces (BCIs) based on Electroencephalography (EEG) has revealed to be\nparticularly effective to promote and enhance rehabilitation procedures,\nespecially by exploiting motor imagery experimental paradigms. Moreover, BCIs\nseem to increase patients' engagement and have proved to be reliable tools for\nelderly overall wellness improvement. However, EEG signals usually present a\nlow signal-to-noise ratio and can be recorded for a limited time. Thus,\nirrelevant information and faulty samples could affect the BCI performance.\nIntroducing a methodology that allows the extraction of informative components\nfrom the EEG signal while maintaining its intrinsic characteristics, may\nprovide a solution to both the described issues: noisy data may be avoided by\nhaving only relevant components and combining relevant components may represent\na good strategy to substitute the data without requiring long or repeated EEG\nrecordings. Moreover, substituting faulty trials may significantly improve the\nclassification performances of a BCI when translating imagined movement to\nrehabilitation systems. To this end, in this work the EEG signal decomposition\nby means of multivariate empirical mode decomposition is proposed to obtain its\noscillatory modes, called Intrinsic Mode Functions (IMFs). Subsequently, a\nnovel procedure for relevant IMF selection criterion based on the IMF\ntime-frequency representation and entropy is provided. After having verified\nthe reliability of the EEG signal reconstruction with the relevant IMFs only,\nthe relevant IMFs are combined to produce new artificial data and provide new\nsamples to use for BCI training.",
    "descriptor": "",
    "authors": [
      "Aurora Saibene",
      "Francesca Gasparini",
      "Jordi Sol\u00e9-Casals"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.03966"
  },
  {
    "id": "arXiv:2110.03979",
    "title": "MilliTRACE-IR: Contact Tracing and Temperature Screening via mm-Wave and  Infrared Sensing",
    "abstract": "In this work, we present milliTRACE-IR, a joint mm-wave radar and infrared\nimaging sensing system performing unobtrusive and privacy preserving human body\ntemperature screening and contact tracing in indoor spaces. Social distancing\nand fever detection have been widely employed to counteract the COVID-19\npandemic, sparking great interest from academia, industry and public\nadministrations worldwide. While most solutions have dealt with the two aspects\nseparately, milliTRACE-IR combines, via a robust sensor fusion approach,\nmm-wave radars and infrared thermal cameras. The system achieves fully\nautomated measurement of distancing and body temperature, by jointly tracking\nthe faces of the subjects in the thermal camera image plane and the human\nmotion in the radar reference system. It achieves decimeter-level accuracy in\ndistance estimation, inter-personal distance estimation (effective for subjects\ngetting as close as 0.2 m), and accurate temperature monitoring (max. errors of\n0.5 C). Moreover, milliTRACE-IR performs contact tracing: a person with high\nbody temperature is reliably detected by the thermal camera sensor and\nsubsequently traced across a large indoor area in a non-invasive way by the\nradars. When entering a new room, this subject is re-identified among several\nother individuals with high accuracy (95%), by computing gait-related features\nfrom the radar reflections through a deep neural network and using a weighted\nextreme learning machine as the final re-identification tool.",
    "descriptor": "\nComments: 14 pages, 13 figures, 5 tables\n",
    "authors": [
      "Marco Canil",
      "Jacopo Pegoraro",
      "Michele Rossi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03979"
  },
  {
    "id": "arXiv:2110.03995",
    "title": "Statistical Regeneration Guarantees of the Wasserstein Autoencoder with  Latent Space Consistency",
    "abstract": "The introduction of Variational Autoencoders (VAE) has been marked as a\nbreakthrough in the history of representation learning models. Besides having\nseveral accolades of its own, VAE has successfully flagged off a series of\ninventions in the form of its immediate successors. Wasserstein Autoencoder\n(WAE), being an heir to that realm carries with it all of the goodness and\nheightened generative promises, matching even the generative adversarial\nnetworks (GANs). Needless to say, recent years have witnessed a remarkable\nresurgence in statistical analyses of the GANs. Similar examinations for\nAutoencoders, however, despite their diverse applicability and notable\nempirical performance, remain largely absent. To close this gap, in this paper,\nwe investigate the statistical properties of WAE. Firstly, we provide\nstatistical guarantees that WAE achieves the target distribution in the latent\nspace, utilizing the Vapnik Chervonenkis (VC) theory. The main result,\nconsequently ensures the regeneration of the input distribution, harnessing the\npotential offered by Optimal Transport of measures under the Wasserstein\nmetric. This study, in turn, hints at the class of distributions WAE can\nreconstruct after suffering a compression in the form of a latent law.",
    "descriptor": "\nComments: Accepted for Spotlight Presentation at NeurIPS 2021\n",
    "authors": [
      "Anish Chakrabarty",
      "Swagatam Das"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03995"
  },
  {
    "id": "arXiv:2110.04005",
    "title": "KaraSinger: Score-Free Singing Voice Synthesis with VQ-VAE using  Mel-spectrograms",
    "abstract": "In this paper, we propose a novel neural network model called KaraSinger for\na less-studied singing voice synthesis (SVS) task named score-free SVS, in\nwhich the prosody and melody are spontaneously decided by machine. KaraSinger\ncomprises a vector-quantized variational autoencoder (VQ-VAE) that compresses\nthe Mel-spectrograms of singing audio to sequences of discrete codes, and a\nlanguage model (LM) that learns to predict the discrete codes given the\ncorresponding lyrics. For the VQ-VAE part, we employ a Connectionist Temporal\nClassification (CTC) loss to encourage the discrete codes to carry\nphoneme-related information. For the LM part, we use location-sensitive\nattention for learning a robust alignment between the input phoneme sequence\nand the output discrete code. We keep the architecture of both the VQ-VAE and\nLM light-weight for fast training and inference speed. We validate the\neffectiveness of the proposed design choices using a proprietary collection of\n550 English pop songs sung by multiple amateur singers. The result of a\nlistening test shows that KaraSinger achieves high scores in intelligibility,\nmusicality, and the overall quality.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Chien-Feng Liao",
      "Jen-Yu Liu",
      "Yi-Hsuan Yang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04005"
  },
  {
    "id": "arXiv:2110.04044",
    "title": "Subspace Change-Point Detection via Low-Rank Matrix Factorisation",
    "abstract": "Multivariate time series can often have a large number of dimensions, whether\nit is due to the vast amount of collected features or due to how the data\nsources are processed. Frequently, the main structure of the high-dimensional\ntime series can be well represented by a lower dimensional subspace. As vast\nquantities of data are being collected over long periods of time, it is\nreasonable to assume that the underlying subspace structure would change over\ntime. In this work, we propose a change-point detection method based on\nlow-rank matrix factorisation that can detect multiple changes in the\nunderlying subspace of a multivariate time series. Experimental results on both\nsynthetic and real data sets demonstrate the effectiveness of our approach and\nits advantages against various state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Euan Thomas McGonigle",
      "Hankui Peng"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Applications (stat.AP)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.04044"
  },
  {
    "id": "arXiv:2110.04047",
    "title": "TRUNet: Transformer-Recurrent-U Network for Multi-channel Reverberant  Sound Source Separation",
    "abstract": "In recent years, many deep learning techniques for single-channel sound\nsource separation have been proposed using recurrent, convolutional and\ntransformer networks. When multiple microphones are available, spatial\ndiversity between speakers and background noise in addition to spectro-temporal\ndiversity can be exploited by using multi-channel filters for sound source\nseparation. Aiming at end-to-end multi-channel source separation, in this paper\nwe propose a transformer-recurrent-U network (TRUNet), which directly estimates\nmulti-channel filters from multi-channel input spectra. TRUNet consists of a\nspatial processing network with an attention mechanism across microphone\nchannels aiming at capturing the spatial diversity, and a spectro-temporal\nprocessing network aiming at capturing spectral and temporal diversities. In\naddition to multi-channel filters, we also consider estimating single-channel\nfilters from multi-channel input spectra using TRUNet. We train the network on\na large reverberant dataset using a combined compressed mean-squared error loss\nfunction, which further improves the sound separation performance. We evaluate\nthe network on a realistic and challenging reverberant dataset, generated from\nmeasured room impulse responses of an actual microphone array. The experimental\nresults on realistic reverberant sound source separation show that the proposed\nTRUNet outperforms state-of-the-art single-channel and multi-channel source\nseparation methods.",
    "descriptor": "",
    "authors": [
      "Ali Aroudi",
      "Stefan Uhlich",
      "Marc Ferras Font"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.04047"
  },
  {
    "id": "arXiv:2110.04056",
    "title": "Improving Pseudo-label Training For End-to-end Speech Recognition Using  Gradient Mask",
    "abstract": "In the recent trend of semi-supervised speech recognition, both\nself-supervised representation learning and pseudo-labeling have shown\npromising results. In this paper, we propose a novel approach to combine their\nideas for end-to-end speech recognition model. Without any extra loss function,\nwe utilize the Gradient Mask to optimize the model when training on\npseudo-label. This method forces the speech recognition model to predict from\nthe masked input to learn strong acoustic representation and make training\nrobust to label noise. In our semi-supervised experiments, the method can\nimprove the model performance when training on pseudo-label and our method\nachieved competitive results comparing with other semi-supervised approaches on\nthe Librispeech 100 hours experiments.",
    "descriptor": "",
    "authors": [
      "Shaoshi Ling",
      "Chen Shen",
      "Meng Cai",
      "Zejun Ma"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04056"
  },
  {
    "id": "arXiv:2110.04071",
    "title": "Generative Pre-Trained Transformer for Cardiac Abnormality Detection",
    "abstract": "ECG heartbeat classification plays a vital role in diagnosis of cardiac\narrhythmia. The goal of the Physionet/CinC 2021 challenge was to accurately\nclassify clinical diagnosis based on 12, 6, 4, 3 or 2-lead ECG recordings in\norder to aid doctors in the diagnoses of different heart conditions.\nTransformers have had great success in the field of natural language processing\nin the past years. Our team, CinCSEM, proposes to draw the parallel between\ntext and periodic time series signals by viewing the repeated period as words\nand the whole signal as a sequence of such words. In this way, the attention\nmechanisms of the transformers can be applied to periodic time series signals.\nIn our implementation, we follow the Transformer Encoder architecture, which\ncombines several encoder layers followed by a dense layer with linear or\nsigmoid activation for generative pre-training or classification, respectively.\nThe use case presented here is multi-label classification of heartbeat\nabnormalities of ECG recordings shared by the challenge. Our best entry, not\nexceeding the challenge's hardware limitations, achieved a score of 0.12, 0.07,\n0.10, 0.10 and 0.07 on 12-lead, 6-lead, 4-lead, 3-lead and 2-lead test set\nrespectively. Unfortunately, our team was unable to be ranked because of a\nmissing pre-print.",
    "descriptor": "\nComments: 4 pages, 2 figures, accepted for publication in CinC 2021\n",
    "authors": [
      "Pierre Louis Gaudilliere",
      "Halla Sigurthorsdottir",
      "Cl\u00e9mentine Aguet",
      "J\u00e9r\u00f4me Van Zaen",
      "Mathieu Lemay",
      "Ricard Delgado-Gonzalo"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04071"
  },
  {
    "id": "arXiv:2110.04073",
    "title": "Optimization of Reconfigurable Intelligent Surfaces Through Trace  Maximization",
    "abstract": "Reconfigurable Intelligent Surfaces (RIS) have received significant attention\nrecently as an innovation for enhanced connectivity, capacity, and energy\nefficiency in future wireless networks. Recent works indicate that such\nRIS-augmented communications can significantly enhance performance by\nintelligently shaping the characteristics of the multipath propagation\nenvironment to focus the energy in a desired direction and to circumvent\nimpediments such as blockage, especially for communication at millimeter-wave\n(mmW), Terahertz (THz) and higher frequencies. In this paper, we investigate\noptimized (amplitude and phase) RIS design in a point-to-point multipath MIMO\nlink and study the impact on link capacity under the assumption of perfect\nchannel state information at the transmitter (TX), receiver (RX) and RIS.\nSpecifically, we propose RIS design based on the maximization of the trace of\nthe composite TX-RIS-RX link matrix which is a measure of the average power at\nthe RX. We propose two RIS designs: a diagonal RIS matrix, and a general RIS\nmatrix representing a more advanced architecture. The optimum design, in both\ncases, corresponds to calculating the dominant eigenvector of certain Hermitian\nmatrices induced by the component channel matrices. We illustrate the capacity\nperformance of the optimized RIS designs and compare them to a baseline design\n(random amplitudes and phases) and a recently proposed low-complexity\nphase-only design. We present results for sparse and rich multipath, and also\nconsider the impact of line-of-sight paths. Our results show that while all\ndesigns offer comparable capacity at high signal-to-noise ratios (SNRs), the\nproposed optimum designs offer substantial gains at lower SNRs.",
    "descriptor": "",
    "authors": [
      "Akbar Sayeed"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.04073"
  },
  {
    "id": "arXiv:2110.04074",
    "title": "Active inference, Bayesian optimal design, and expected utility",
    "abstract": "Active inference, a corollary of the free energy principle, is a formal way\nof describing the behavior of certain kinds of random dynamical systems that\nhave the appearance of sentience. In this chapter, we describe how active\ninference combines Bayesian decision theory and optimal Bayesian design\nprinciples under a single imperative to minimize expected free energy. It is\nthis aspect of active inference that allows for the natural emergence of\ninformation-seeking behavior. When removing prior outcomes preferences from\nexpected free energy, active inference reduces to optimal Bayesian design,\ni.e., information gain maximization. Conversely, active inference reduces to\nBayesian decision theory in the absence of ambiguity and relative risk, i.e.,\nexpected utility maximization. Using these limiting cases, we illustrate how\nbehaviors differ when agents select actions that optimize expected utility,\nexpected information gain, and expected free energy. Our T-maze simulations\nshow optimizing expected free energy produces goal-directed information-seeking\nbehavior while optimizing expected utility induces purely exploitive behavior\nand maximizing information gain engenders intrinsically motivated behavior.",
    "descriptor": "\nComments: 19 pages; 3 figures\n",
    "authors": [
      "Noor Sajid",
      "Lancelot Da Costa",
      "Thomas Parr",
      "Karl Friston"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04074"
  },
  {
    "id": "arXiv:2110.04082",
    "title": "A Method for Capturing and Reproducing Directional Reverberation in Six  Degrees of Freedom",
    "abstract": "The reproduction of acoustics is an important aspect of the preservation of\ncultural heritage. A common approach is to capture an impulse response in a\nhall and auralize it by convolving an input signal with the measured\nreverberant response. For immersive applications, it is typical to acquire\nspatial impulse responses using a spherical microphone array to capture the\nreverberant sound field. While this allows a listener to freely rotate their\nhead from the captured location during reproduction, delicate considerations\nmust be made to allow a full six degrees of freedom auralization. Furthermore,\nthe computational cost of convolution with a high-order Ambisonics impulse\nresponse remains prohibitively expensive for current real-time applications,\nwhere most of the resources are dedicated towards rendering graphics. For this\nreason, simplifications are often made in the reproduction of reverberation,\nsuch as using a uniform decay around the listener. However, recent work has\nhighlighted the importance of directional characteristics in the late\nreverberant sound field and more efficient reproduction methods have been\ndeveloped. In this article, we propose a framework that extracts directional\ndecay properties from a set of captured spatial impulse responses to\ncharacterize a directional feedback delay network. For this purpose, a data set\nwas acquired in the main auditorium of the Finnish National Opera and Ballet in\nHelsinki from multiple source-listener positions, in order to analyze the\nanisotropic characteristics of this auditorium and illustrate the proposed\nreproduction framework.",
    "descriptor": "\nComments: This work has been accepted for the I3DA 2021 International Conference and will be submitted to IEEE Xplore Digital Library for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Benoit Alary",
      "Vesa V\u00e4lim\u00e4ki"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.04082"
  },
  {
    "id": "arXiv:2110.04109",
    "title": "Hierarchical Conditional End-to-End ASR with CTC and Multi-Granular  Subword Units",
    "abstract": "In end-to-end automatic speech recognition (ASR), a model is expected to\nimplicitly learn representations suitable for recognizing a word-level\nsequence. However, the huge abstraction gap between input acoustic signals and\noutput linguistic tokens makes it challenging for a model to learn the\nrepresentations. In this work, to promote the word-level representation\nlearning in end-to-end ASR, we propose a hierarchical conditional model that is\nbased on connectionist temporal classification (CTC). Our model is trained by\nauxiliary CTC losses applied to intermediate layers, where the vocabulary size\nof each target subword sequence is gradually increased as the layer becomes\nclose to the word-level output. Here, we make each level of sequence prediction\nexplicitly conditioned on the previous sequences predicted at lower levels.\nWith the proposed approach, we expect the proposed model to learn the\nword-level representations effectively by exploiting a hierarchy of linguistic\nstructures. Experimental results on LibriSpeech-{100h, 960h} and TEDLIUM2\ndemonstrate that the proposed model improves over a standard CTC-based model\nand other competitive models from prior work. We further analyze the results to\nconfirm the effectiveness of the intended representation learning with our\nmodel.",
    "descriptor": "\nComments: Submitted to ICASSP2022\n",
    "authors": [
      "Yosuke Higuchi",
      "Keita Karube",
      "Tetsuji Ogawa",
      "Tetsunori Kobayashi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04109"
  },
  {
    "id": "arXiv:2110.04116",
    "title": "Entanglement Swapping in Quantum Switches: Protocol Design and Stability  Analysis",
    "abstract": "Quantum switches are critical components in quantum networks, distributing\nmaximally entangled pairs among end nodes by entanglement swapping. In this\nwork, we design protocols that schedule entanglement swapping operations in\nquantum switches. Entanglement requests randomly arrive at the switch, and the\ngoal of an entanglement swapping protocol is to stabilize the quantum switch so\nthat the number of unfinished entanglement requests is bounded with a high\nprobability. We determine the capacity region for the rates of entanglement\nrequests and develop entanglement swapping protocols to stabilize the switch.\nAmong these protocols, the on-demand protocols are not only computationally\nefficient, but also achieve high fidelity and low latency demonstrated by\nresults obtained using a quantum network discrete event simulator.",
    "descriptor": "",
    "authors": [
      "Wenhan Dai",
      "Anthony Rinaldi",
      "Don Towsley"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.04116"
  },
  {
    "id": "arXiv:2110.04130",
    "title": "Learning post-processing for QRS detection using Recurrent Neural  Network",
    "abstract": "Deep-learning based QRS-detection algorithms often require essential\npost-processing to refine the prediction streams for R-peak localisation. The\npost-processing performs signal-processing tasks from as simple as, removing\nisolated 0s or 1s in the prediction-stream to sophisticated steps, which\nrequire domain-specific knowledge, including the minimum threshold of a\nQRS-complex extent or R-R interval. Often these thresholds vary among\nQRS-detection studies and are empirically determined for the target dataset,\nwhich may have implications if the target dataset differs. Moreover, these\nstudies, in general, fail to identify the relative strengths of deep-learning\nmodels and post-processing to weigh them appropriately. This study classifies\npost-processing, as found in the QRS-detection literature, into two levels -\nmoderate, and advanced - and advocates that the thresholds be learned by an\nappropriate deep-learning module, called a Gated Recurrent Unit (GRU), to avoid\nexplicitly setting post-processing thresholds. This is done by utilising the\nsame philosophy of shifting from hand-crafted feature-engineering to\ndeep-learning-based feature-extraction. The results suggest that GRU learns the\npost-processing level and the QRS detection performance using GRU-based\npost-processing marginally follows the domain-specific manual post-processing,\nwithout requiring usage of domain-specific threshold parameters. To the best of\nour knowledge, the use of GRU to learn QRS-detection post-processing from CNN\nmodel generated prediction streams is the first of its kind. The outcome was\nused to recommend a modular design for a QRS-detection system, where the level\nof complexity of the CNN model and post-processing can be tuned based on the\ndeployment environment.",
    "descriptor": "",
    "authors": [
      "Ahsan Habib",
      "Chandan Karmakar",
      "John Yearwood"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04130"
  },
  {
    "id": "arXiv:2110.04153",
    "title": "Cross-speaker Emotion Transfer Based on Speaker Condition Layer  Normalization and Semi-Supervised Training in Text-To-Speech",
    "abstract": "In expressive speech synthesis, there are high requirements for emotion\ninterpretation. However, it is time-consuming to acquire emotional audio corpus\nfor arbitrary speakers due to their deduction ability. In response to this\nproblem, this paper proposes a cross-speaker emotion transfer method that can\nrealize the transfer of emotions from source speaker to target speaker. A set\nof emotion tokens is firstly defined to represent various categories of\nemotions. They are trained to be highly correlated with corresponding emotions\nfor controllable synthesis by cross-entropy loss and semi-supervised training\nstrategy. Meanwhile, to eliminate the down-gradation to the timbre similarity\nfrom cross-speaker emotion transfer, speaker condition layer normalization is\nimplemented to model speaker characteristics. Experimental results show that\nthe proposed method outperforms the multi-reference based baseline in terms of\ntimbre similarity, stability and emotion perceive evaluations.",
    "descriptor": "\nComments: 5 pages,2 figures\n",
    "authors": [
      "Pengfei Wu",
      "Junjie Pan",
      "Chenchang Xu",
      "Junhui Zhang",
      "Lin Wu",
      "Xiang Yin",
      "Zejun Ma"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04153"
  },
  {
    "id": "arXiv:2110.04161",
    "title": "A Mechanism Design Approach to Allocating Travel Funds",
    "abstract": "I explain how faculty members could exploit a method to allocate travel funds\nand how to use game theory to design a method that cannot be manipulated.",
    "descriptor": "",
    "authors": [
      "Michael A. Jones"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.04161"
  },
  {
    "id": "arXiv:2110.04187",
    "title": "SCaLa: Supervised Contrastive Learning for End-to-End Automatic Speech  Recognition",
    "abstract": "End-to-end Automatic Speech Recognition (ASR) models are usually trained to\nreduce the losses of the whole token sequences, while neglecting explicit\nphonemic-granularity supervision. This could lead to recognition errors due to\nsimilar-phoneme confusion or phoneme reduction. To alleviate this problem, this\npaper proposes a novel framework of Supervised Contrastive Learning (SCaLa) to\nenhance phonemic information learning for end-to-end ASR systems. Specifically,\nwe introduce the self-supervised Masked Contrastive Predictive Coding (MCPC)\ninto the fully-supervised setting. To supervise phoneme learning explicitly,\nSCaLa first masks the variable-length encoder features corresponding to\nphonemes given phoneme forced-alignment extracted from a pre-trained acoustic\nmodel, and then predicts the masked phonemes via contrastive learning. The\nphoneme forced-alignment can mitigate the noise of positive-negative pairs in\nself-supervised MCPC. Experimental results conducted on reading and spontaneous\nspeech datasets show that the proposed approach achieves 2.84% and 1.38%\nCharacter Error Rate (CER) reductions compared to the baseline, respectively.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Li Fu",
      "Xiaoxiao Li",
      "Runyu Wang",
      "Zhengchen Zhang",
      "Youzheng Wu",
      "Xiaodong He",
      "Bowen Zhou"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04187"
  },
  {
    "id": "arXiv:2110.04191",
    "title": "Parallel Quantum Pebbling: Analyzing the Post-Quantum Security of iMHFs",
    "abstract": "The classical (parallel) black pebbling game is a useful abstraction which\nallows us to analyze the resources (space, space-time, cumulative space)\nnecessary to evaluate a function $f$ with a static data-dependency graph $G$.\nOf particular interest in the field of cryptography are data-independent\nmemory-hard functions $f_{G,H}$ which are defined by a directed acyclic graph\n(DAG) $G$ and a cryptographic hash function $H$. The pebbling complexity of the\ngraph $G$ characterized the amortized cost of evaluating $f_{G,H}$ multiple\ntimes or the total cost to run a brute-force preimage attack over a fixed\ndomain $\\mathcal{X}$, i.e., given $y \\in \\{0,1\\}^*$ find $x \\in \\mathcal{X}$\nsuch that $f_{G,H}(x)=y$. While a classical attacker will need to evaluate the\nfunction $f_{G,H}$ at least $m=|\\mathcal{X}|$ times a quantum attacker running\nGrover's algorithm only requires $\\mathcal{O}(\\sqrt{m})$ blackbox calls to a\nquantum circuit $C_{G,H}$ evaluating the function $f_{G,H}$. Thus, to analyze\nthe cost of a quantum attack it is crucial to understand the space-time cost\n(equivalently width times depth) of the quantum circuit $C_{G,H}$. We first\nobserve that a legal black pebbling strategy for the graph $G$ does not\nnecessarily imply the existence of a quantum circuit with comparable complexity\n-- in contrast to the classical setting where any efficient pebbling strategy\nfor $G$ corresponds to an algorithm with comparable complexity evaluating\n$f_{G,H}$. Motivated by this observation we introduce a new (parallel) quantum\npebbling game which captures additional restrictions imposed by the No-Deletion\nTheorem in Quantum Computing. We apply our new quantum pebbling game to analyze\nthe quantum space-time complexity of several important graphs: the line graph,\nArgon2i-A, Argon2i-B, and DRSample. (See the paper for the full abstract.)",
    "descriptor": "\nComments: 35 pages, 7 figures\n",
    "authors": [
      "Jeremiah Blocki",
      "Seunghoon Lee"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.04191"
  },
  {
    "id": "arXiv:2110.04232",
    "title": "Learning Topic Models: Identifiability and Finite-Sample Analysis",
    "abstract": "Topic models provide a useful text-mining tool for learning, extracting and\ndiscovering latent structures in large text corpora. Although a plethora of\nmethods have been proposed for topic modeling, a formal theoretical\ninvestigation on the statistical identifiability and accuracy of latent topic\nestimation is lacking in the literature. In this paper, we propose a maximum\nlikelihood estimator (MLE) of latent topics based on a specific integrated\nlikelihood, which is naturally connected to the concept of volume minimization\nin computational geometry. Theoretically, we introduce a new set of geometric\nconditions for topic model identifiability, which are weaker than conventional\nseparability conditions relying on the existence of anchor words or pure topic\ndocuments. We conduct finite-sample error analysis for the proposed estimator\nand discuss the connection of our results with existing ones. We conclude with\nempirical studies on both simulated and real datasets.",
    "descriptor": "",
    "authors": [
      "Yinyin Chen",
      "Shishuang He",
      "Yun Yang",
      "Feng Liang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.04232"
  },
  {
    "id": "arXiv:2110.04234",
    "title": "Extremum Seeking Tracking for Derivative-free Distributed Optimization",
    "abstract": "In this paper, we deal with a network of agents that want to cooperatively\nminimize the sum of local cost functions depending on a common decision\nvariable. We consider the challenging scenario in which objective functions are\nunknown and agents have only access to local measurements of their local\nfunction. We propose a novel distributed algorithm which combines a gradient\ntracking policy with an extremum seeking technique to estimate the global\ndescent direction. The joint use of these two techniques results in a\ndistributed optimization scheme which is proven to provide arbitrarily accurate\nsolution estimate through the combination of Lyapunov and averaging analysis\napproaches with consensus theory. To corroborate the theoretical results, we\nperform numerical simulations in a personalized optimization framework and a\ncooperative robotics scenario.",
    "descriptor": "",
    "authors": [
      "Nicola Mimmo",
      "Guido Carnevale",
      "Andrea Testa",
      "Giuseppe Notarstefano"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.04234"
  },
  {
    "id": "arXiv:2110.04241",
    "title": "Cognitive Coding of Speech",
    "abstract": "We propose an approach for cognitive coding of speech by unsupervised\nextraction of contextual representations in two hierarchical levels of\nabstraction. Speech attributes such as phoneme identity that last one hundred\nmilliseconds or less are captured in the lower level of abstraction, while\nspeech attributes such as speaker identity and emotion that persist up to one\nsecond are captured in the higher level of abstraction. This decomposition is\nachieved by a two-stage neural network, with a lower and an upper stage\noperating at different time scales. Both stages are trained to predict the\ncontent of the signal in their respective latent spaces. A top-down pathway\nbetween stages further improves the predictive capability of the network. With\nan application in speech compression in mind, we investigate the effect of\ndimensionality reduction and low bitrate quantization on the extracted\nrepresentations. The performance measured on the LibriSpeech and EmoV-DB\ndatasets reaches, and for some speech attributes even exceeds, that of\nstate-of-the-art approaches.",
    "descriptor": "",
    "authors": [
      "Reza Lotfidereshgi",
      "Philippe Gournay"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04241"
  },
  {
    "id": "arXiv:2110.04243",
    "title": "Heavy Ball Momentum for Conditional Gradient",
    "abstract": "Conditional gradient, aka Frank Wolfe (FW) algorithms, have well-documented\nmerits in machine learning and signal processing applications. Unlike\nprojection-based methods, momentum cannot improve the convergence rate of FW,\nin general. This limitation motivates the present work, which deals with heavy\nball momentum, and its impact to FW. Specifically, it is established that heavy\nball offers a unifying perspective on the primal-dual (PD) convergence, and\nenjoys a tighter per iteration PD error rate, for multiple choices of step\nsizes, where PD error can serve as the stopping criterion in practice. In\naddition, it is asserted that restart, a scheme typically employed jointly with\nNesterov's momentum, can further tighten this PD error bound. Numerical results\ndemonstrate the usefulness of heavy ball momentum in FW iterations.",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Bingcong Li",
      "Alireza Sadeghi",
      "Georgios B. Giannakis"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04243"
  },
  {
    "id": "arXiv:2110.04253",
    "title": "F-Divergences and Cost Function Locality in Generative Modelling with  Quantum Circuits",
    "abstract": "Generative modelling is an important unsupervised task in machine learning.\nIn this work, we study a hybrid quantum-classical approach to this task, based\non the use of a quantum circuit Born machine. In particular, we consider\ntraining a quantum circuit Born machine using $f$-divergences. We first discuss\nthe adversarial framework for generative modelling, which enables the\nestimation of any $f$-divergence in the near term. Based on this capability, we\nintroduce two heuristics which demonstrably improve the training of the Born\nmachine. The first is based on $f$-divergence switching during training. The\nsecond introduces locality to the divergence, a strategy which has proved\nimportant in similar applications in terms of mitigating barren plateaus.\nFinally, we discuss the long-term implications of quantum devices for computing\n$f$-divergences, including algorithms which provide quadratic speedups to their\nestimation. In particular, we generalise existing algorithms for estimating the\nKullback-Leibler divergence and the total variation distance to obtain a\nfault-tolerant quantum algorithm for estimating another $f$-divergence, namely,\nthe Pearson divergence.",
    "descriptor": "\nComments: 20 pages, 9 figures, 4 tables\n",
    "authors": [
      "Chiara Leadbeater",
      "Louis Sharrock",
      "Brian Coyle",
      "Marcello Benedetti"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04253"
  },
  {
    "id": "arXiv:2110.04256",
    "title": "Big Machinery Data Preprocessing Methodology for Data-Driven Models in  Prognostics and Health Management",
    "abstract": "Sensor monitoring networks and advances in big data analytics have guided the\nreliability engineering landscape to a new era of big machinery data. Low-cost\nsensors, along with the evolution of the internet of things and industry 4.0,\nhave resulted in rich databases that can be analyzed through prognostics and\nhealth management (PHM) frameworks. Several da-ta-driven models (DDMs) have\nbeen proposed and applied for diagnostics and prognostics purposes in complex\nsystems. However, many of these models are developed using simulated or\nexperimental data sets, and there is still a knowledge gap for applications in\nreal operating systems. Furthermore, little attention has been given to the\nrequired data preprocessing steps compared to the training processes of these\nDDMs. Up to date, research works do not follow a formal and consistent data\npreprocessing guideline for PHM applications. This paper presents a\ncomprehensive, step-by-step pipeline for the preprocessing of monitoring data\nfrom complex systems aimed for DDMs. The importance of expert knowledge is\ndiscussed in the context of data selection and label generation. Two case\nstudies are presented for validation, with the end goal of creating clean data\nsets with healthy and unhealthy labels that are then used to train machinery\nhealth state classifiers.",
    "descriptor": "\nComments: 41 pages\n",
    "authors": [
      "Sergio Cofre-Martel",
      "Enrique Lopez Droguett",
      "Mohammad Modarres"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04256"
  },
  {
    "id": "arXiv:2110.04261",
    "title": "Extragradient Method: $O(1/K)$ Last-Iterate Convergence for Monotone  Variational Inequalities and Connections With Cocoercivity",
    "abstract": "Extragradient method (EG) Korpelevich [1976] is one of the most popular\nmethods for solving saddle point and variational inequalities problems (VIP).\nDespite its long history and significant attention in the optimization\ncommunity, there remain important open questions about convergence of EG. In\nthis paper, we resolve one of such questions and derive the first last-iterate\n$O(1/K)$ convergence rate for EG for monotone and Lipschitz VIP without any\nadditional assumptions on the operator. The rate is given in terms of reducing\nthe squared norm of the operator. Moreover, we establish several results on the\n(non-)cocoercivity of the update operators of EG, Optimistic Gradient Method,\nand Hamiltonian Gradient Method, when the original operator is monotone and\nLipschitz.",
    "descriptor": "\nComments: 48 pages\n",
    "authors": [
      "Eduard Gorbunov",
      "Nicolas Loizou",
      "Gauthier Gidel"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04261"
  },
  {
    "id": "arXiv:2110.04265",
    "title": "A study of the robustness of raw waveform based speaker embeddings under  mismatched conditions",
    "abstract": "In this paper, we conduct a cross-dataset study on parametric and\nnon-parametric raw-waveform based speaker embeddings through speaker\nverification experiments. In general, we observe a more significant performance\ndegradation of these raw-waveform systems compared to spectral based systems.\nWe then propose two strategies to improve the performance of raw-waveform based\nsystems on cross-dataset tests. The first strategy is to change the real-valued\nfilters into analytic filters to ensure shift-invariance. The second strategy\nis to apply variational dropout to non-parametric filters to prevent them from\noverfitting irrelevant nuance features.",
    "descriptor": "",
    "authors": [
      "Ge Zhu",
      "Frank Cwitkowitz",
      "Zhiyao Dua"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04265"
  },
  {
    "id": "arXiv:2110.04279",
    "title": "StairwayGraphNet for Inter- and Intra-modality Multi-resolution Brain  Graph Alignment and Synthesis",
    "abstract": "Synthesizing multimodality medical data provides complementary knowledge and\nhelps doctors make precise clinical decisions. Although promising, existing\nmultimodal brain graph synthesis frameworks have several limitations. First,\nthey mainly tackle only one problem (intra- or inter-modality), limiting their\ngeneralizability to synthesizing inter- and intra-modality simultaneously.\nSecond, while few techniques work on super-resolving low-resolution brain\ngraphs within a single modality (i.e., intra), inter-modality graph\nsuper-resolution remains unexplored though this would avoid the need for costly\ndata collection and processing. More importantly, both target and source\ndomains might have different distributions, which causes a domain fracture\nbetween them. To fill these gaps, we propose a multi-resolution\nStairwayGraphNet (SG-Net) framework to jointly infer a target graph modality\nbased on a given modality and super-resolve brain graphs in both inter and\nintra domains. Our SG-Net is grounded in three main contributions: (i)\npredicting a target graph from a source one based on a novel graph generative\nadversarial network in both inter (e.g., morphological-functional) and intra\n(e.g., functional-functional) domains, (ii) generating high-resolution brain\ngraphs without resorting to the time consuming and expensive MRI processing\nsteps, and (iii) enforcing the source distribution to match that of the ground\ntruth graphs using an inter-modality aligner to relax the loss function to\noptimize. Moreover, we design a new Ground Truth-Preserving loss function to\nguide both generators in learning the topological structure of ground truth\nbrain graphs more accurately. Our comprehensive experiments on predicting\ntarget brain graphs from source graphs using a multi-resolution stairway showed\nthe outperformance of our method in comparison with its variants and\nstate-of-the-art method.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2107.06281\n",
    "authors": [
      "Islem Mhiri",
      "Mohamed Ali Mahjoub",
      "Islem Rekik"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2110.04279"
  },
  {
    "id": "arXiv:2110.04289",
    "title": "Location-based training for multi-channel talker-independent speaker  separation",
    "abstract": "Permutation-invariant training (PIT) is a dominant approach for addressing\nthe permutation ambiguity problem in talker-independent speaker separation.\nLeveraging spatial information afforded by microphone arrays, we propose a new\ntraining approach to resolving permutation ambiguities for multi-channel\nspeaker separation. The proposed approach, named location-based training (LBT),\nassigns speakers on the basis of their spatial locations. This training\nstrategy is easy to apply, and organizes speakers according to their positions\nin physical space. Specifically, this study investigates azimuth angles and\nsource distances for location-based training. Evaluation results on separating\ntwo- and three-speaker mixtures show that azimuth-based training consistently\noutperforms PIT, and distance-based training further improves the separation\nperformance when speaker azimuths are close. Furthermore, we dynamically select\nazimuth-based or distance-based training by estimating the azimuths of\nseparated speakers, which further improves separation performance. LBT has a\nlinear training complexity with respect to the number of speakers, as opposed\nto the factorial complexity of PIT. We further demonstrate the effectiveness of\nLBT for the separation of four and five concurrent speakers.",
    "descriptor": "\nComments: submitted to ICASSP 22\n",
    "authors": [
      "Hassan Taherian",
      "Ke Tan",
      "DeLiang Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04289"
  },
  {
    "id": "arXiv:1805.07429",
    "title": "Designing communication systems via iterative improvement: error  correction coding with Bayes decoder and codebook optimized for source symbol  error",
    "abstract": "Comments: 24 pages, added Sections 10 and 11",
    "descriptor": "\nComments: 24 pages, added Sections 10 and 11\n",
    "authors": [
      "Chai Wah Wu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/1805.07429"
  },
  {
    "id": "arXiv:1905.03151",
    "title": "Unrestricted Permutation forces Extrapolation: Variable Importance  Requires at least One More Model, or There Is No Free Variable Importance",
    "abstract": "Unrestricted Permutation forces Extrapolation: Variable Importance  Requires at least One More Model, or There Is No Free Variable Importance",
    "descriptor": "",
    "authors": [
      "Giles Hooker",
      "Lucas Mentch",
      "Siyu Zhou"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1905.03151"
  },
  {
    "id": "arXiv:1906.07869",
    "title": "Identifiability of Hierarchical Latent Attribute Models",
    "abstract": "Identifiability of Hierarchical Latent Attribute Models",
    "descriptor": "",
    "authors": [
      "Yuqi Gu",
      "Gongjun Xu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/1906.07869"
  },
  {
    "id": "arXiv:1907.02367",
    "title": "Tent pitching and Trefftz-DG method for the acoustic wave equation",
    "abstract": "Comments: 18 pages, 11 figures",
    "descriptor": "\nComments: 18 pages, 11 figures\n",
    "authors": [
      "Ilaria Perugia",
      "Joachim Sch\u00f6berl",
      "Paul Stocker",
      "Christoph Wintersteiger"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1907.02367"
  },
  {
    "id": "arXiv:1909.09518",
    "title": "Tensors with maximal symmetries",
    "abstract": "Comments: Much cleaner proof of main theorem and additional results added",
    "descriptor": "\nComments: Much cleaner proof of main theorem and additional results added\n",
    "authors": [
      "Austin Conner",
      "Fulvio Gesmundo",
      "Joseph M. Landsberg",
      "Emanuele Ventura"
    ],
    "subjectives": [
      "Representation Theory (math.RT)",
      "Computational Complexity (cs.CC)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/1909.09518"
  },
  {
    "id": "arXiv:1910.04287",
    "title": "Deep localization of protein structures in fluorescence microscopy  images",
    "abstract": "Deep localization of protein structures in fluorescence microscopy  images",
    "descriptor": "",
    "authors": [
      "Muhammad Tahir",
      "Saeed Anwar",
      "Ajmal Mian",
      "Abdul Wahab Muzaffar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/1910.04287"
  },
  {
    "id": "arXiv:1910.08412",
    "title": "On the Sample Complexity of Actor-Critic Method for Reinforcement  Learning with Function Approximation",
    "abstract": "On the Sample Complexity of Actor-Critic Method for Reinforcement  Learning with Function Approximation",
    "descriptor": "",
    "authors": [
      "Harshat Kumar",
      "Alec Koppel",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1910.08412"
  },
  {
    "id": "arXiv:2002.04386",
    "title": "Limited memory predictors based on polynomial approximation of periodic  exponents",
    "abstract": "Limited memory predictors based on polynomial approximation of periodic  exponents",
    "descriptor": "",
    "authors": [
      "Nikolai Dokuchaev"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2002.04386"
  },
  {
    "id": "arXiv:2002.07741",
    "title": "Default Ambiguity: Finding the Best Solution to the Clearing Problem",
    "abstract": "Default Ambiguity: Finding the Best Solution to the Clearing Problem",
    "descriptor": "",
    "authors": [
      "P\u00e1l Andr\u00e1s Papp",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computational Complexity (cs.CC)",
      "Mathematical Finance (q-fin.MF)"
    ],
    "url": "https://arxiv.org/abs/2002.07741"
  },
  {
    "id": "arXiv:2003.05357",
    "title": "On the feasibility of automated prediction of bug and non-bug issues",
    "abstract": "On the feasibility of automated prediction of bug and non-bug issues",
    "descriptor": "",
    "authors": [
      "Steffen Herbold",
      "Alexander Trautsch",
      "Fabian Trautsch"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2003.05357"
  },
  {
    "id": "arXiv:2003.06658",
    "title": "From SCAN to Real Data: Systematic Generalization via Meaningful  Learning",
    "abstract": "Comments: 19 pages, 4 figures, 14 tables",
    "descriptor": "\nComments: 19 pages, 4 figures, 14 tables\n",
    "authors": [
      "Ning Shi",
      "Boxin Wang",
      "Wei Wang",
      "Xiangyu Liu",
      "Rong Zhang",
      "Hui Xue",
      "Xinbing Wang",
      "Zhouhan Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2003.06658"
  },
  {
    "id": "arXiv:2004.10282",
    "title": "SynthMorph: learning contrast-invariant registration without acquired  images",
    "abstract": "Comments: 15 pages, 15 figures, 3 tables, image registration, data independence, deep learning, MRI-contrast invariance, anatomy agnosticism, accepted by IEEE Transactions on Medical Imaging",
    "descriptor": "\nComments: 15 pages, 15 figures, 3 tables, image registration, data independence, deep learning, MRI-contrast invariance, anatomy agnosticism, accepted by IEEE Transactions on Medical Imaging\n",
    "authors": [
      "Malte Hoffmann",
      "Benjamin Billot",
      "Douglas N. Greve",
      "Juan Eugenio Iglesias",
      "Bruce Fischl",
      "Adrian V. Dalca"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2004.10282"
  },
  {
    "id": "arXiv:2005.07036",
    "title": "Infant Crying Detection in Real-World Environments",
    "abstract": "Infant Crying Detection in Real-World Environments",
    "descriptor": "",
    "authors": [
      "Xuewen Yao",
      "Megan Micheletti",
      "Mckensey Johnson",
      "Edison Thomaz",
      "Kaya de Barbaro"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.07036"
  },
  {
    "id": "arXiv:2006.00773",
    "title": "Localization and delocalization of ground states of Bose-Einstein  condensates under disorder",
    "abstract": "Comments: accepted for publication in SIAM J. Appl. Math",
    "descriptor": "\nComments: accepted for publication in SIAM J. Appl. Math\n",
    "authors": [
      "Robert Altmann",
      "Patrick Henning",
      "Daniel Peterseim"
    ],
    "subjectives": [
      "Quantum Gases (cond-mat.quant-gas)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2006.00773"
  },
  {
    "id": "arXiv:2007.15350",
    "title": "Deep neural network approximations for the stable manifolds of the  Hamilton-Jacobi equations",
    "abstract": "Comments: The algorithm is modified. The main point is that the trajectories on stable manifold are found by a combination of two-point BVP near the equilibrium and initial value problem far away from the equilibrium. The algorithm becomes more effective",
    "descriptor": "\nComments: The algorithm is modified. The main point is that the trajectories on stable manifold are found by a combination of two-point BVP near the equilibrium and initial value problem far away from the equilibrium. The algorithm becomes more effective\n",
    "authors": [
      "Guoyuan Chen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2007.15350"
  },
  {
    "id": "arXiv:2008.00422",
    "title": "Rule-based Bayesian regression",
    "abstract": "Rule-based Bayesian regression",
    "descriptor": "",
    "authors": [
      "Themistoklis Botsas",
      "Lachlan R. Mason",
      "Indranil Pan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2008.00422"
  },
  {
    "id": "arXiv:2008.02133",
    "title": "Constant Congestion Brambles",
    "abstract": "Constant Congestion Brambles",
    "descriptor": "",
    "authors": [
      "Meike Hatzel",
      "Pawel Komosa",
      "Marcin Pilipczuk",
      "Manuel Sorge"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2008.02133"
  },
  {
    "id": "arXiv:2008.03628",
    "title": "Appearance-free Tripartite Matching for Multiple Object Tracking",
    "abstract": "Comments: 36 pages, 14 figures",
    "descriptor": "\nComments: 36 pages, 14 figures\n",
    "authors": [
      "Lijun Wang",
      "Yanting Zhu",
      "Jue Shi",
      "Xiaodan Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2008.03628"
  },
  {
    "id": "arXiv:2008.05913",
    "title": "Semi-supervised learning objectives as log-likelihoods in a generative  model of data curation",
    "abstract": "Semi-supervised learning objectives as log-likelihoods in a generative  model of data curation",
    "descriptor": "",
    "authors": [
      "Stoil Ganev",
      "Laurence Aitchison"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.05913"
  },
  {
    "id": "arXiv:2009.05826",
    "title": "On the security of subspace subcodes of Reed-Solomon codes for public  key encryption",
    "abstract": "On the security of subspace subcodes of Reed-Solomon codes for public  key encryption",
    "descriptor": "",
    "authors": [
      "Alain Couvreur",
      "Matthieu Lequesne"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2009.05826"
  },
  {
    "id": "arXiv:2009.10525",
    "title": "Randomized Continuous Frames in Time-Frequency Analysis",
    "abstract": "Randomized Continuous Frames in Time-Frequency Analysis",
    "descriptor": "",
    "authors": [
      "Ron Levie",
      "Haim Avron"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2009.10525"
  },
  {
    "id": "arXiv:2009.12537",
    "title": "Deep Selective Combinatorial Embedding and Consistency Regularization  for Light Field Super-resolution",
    "abstract": "Comments: 14 pages, 12 figures. arXiv admin note: substantial text overlap with arXiv:2004.02215",
    "descriptor": "\nComments: 14 pages, 12 figures. arXiv admin note: substantial text overlap with arXiv:2004.02215\n",
    "authors": [
      "Jing Jin",
      "Junhui Hou",
      "Zhiyu Zhu",
      "Jie Chen",
      "Sam Kwong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.12537"
  },
  {
    "id": "arXiv:2010.03329",
    "title": "Design of Power-Imbalanced SCMA Codebook",
    "abstract": "Design of Power-Imbalanced SCMA Codebook",
    "descriptor": "",
    "authors": [
      "Xudong Li",
      "Zhicheng Gao",
      "Yiming Gui",
      "Zilong Liu",
      "Pei Xiao",
      "Lisu Yu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2010.03329"
  },
  {
    "id": "arXiv:2010.04239",
    "title": "Deterministic Identification Over Channels With Power Constraints",
    "abstract": "Deterministic Identification Over Channels With Power Constraints",
    "descriptor": "",
    "authors": [
      "Mohammad J. Salariseddigh",
      "Uzi Pereg",
      "Holger Boche",
      "Christian Deppe"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2010.04239"
  },
  {
    "id": "arXiv:2010.12239",
    "title": "Domain Adaptation in LiDAR Semantic Segmentation by Aligning Class  Distributions",
    "abstract": "Comments: 7 pages, 3 figures",
    "descriptor": "\nComments: 7 pages, 3 figures\n",
    "authors": [
      "Inigo Alonso",
      "Luis Riazuelo. Luis Montesano",
      "Ana C. Murillo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.12239"
  },
  {
    "id": "arXiv:2011.03943",
    "title": "Fine-grained Style Modeling, Transfer and Prediction in Text-to-Speech  Synthesis via Phone-Level Content-Style Disentanglement",
    "abstract": "Comments: Accepted by Interspeech 2021",
    "descriptor": "\nComments: Accepted by Interspeech 2021\n",
    "authors": [
      "Daxin Tan",
      "Tan Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2011.03943"
  },
  {
    "id": "arXiv:2011.04527",
    "title": "AAAI FSS-20: Artificial Intelligence in Government and Public Sector  Proceedings",
    "abstract": "Comments: Post-symposium proceedings including 13 papers",
    "descriptor": "\nComments: Post-symposium proceedings including 13 papers\n",
    "authors": [
      "Frank Stein",
      "Alun Preece"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2011.04527"
  },
  {
    "id": "arXiv:2011.05653",
    "title": "Skeleton-based Relational Reasoning for Group Activity Analysis",
    "abstract": "Comments: 26 pages, 5 figures, accepted manuscript in Elsevier Pattern Recognition, minor writing revisions and new references",
    "descriptor": "\nComments: 26 pages, 5 figures, accepted manuscript in Elsevier Pattern Recognition, minor writing revisions and new references\n",
    "authors": [
      "Mauricio Perez",
      "Jun Liu",
      "Alex C. Kot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.05653"
  },
  {
    "id": "arXiv:2011.11048",
    "title": "GNNLens: A Visual Analytics Approach for Prediction Error Diagnosis of  Graph Neural Networks",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Zhihua Jin",
      "Yong Wang",
      "Qianwen Wang",
      "Yao Ming",
      "Tengfei Ma",
      "Huamin Qu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2011.11048"
  },
  {
    "id": "arXiv:2011.12485",
    "title": "How to Train Neural Networks for Flare Removal",
    "abstract": "Comments: A new version paper is uploaded",
    "descriptor": "\nComments: A new version paper is uploaded\n",
    "authors": [
      "Yicheng Wu",
      "Qiurui He",
      "Tianfan Xue",
      "Rahul Garg",
      "Jiawen Chen",
      "Ashok Veeraraghavan",
      "Jonathan T. Barron"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.12485"
  },
  {
    "id": "arXiv:2011.12498",
    "title": "An Empirical Study of the Collapsing Problem in Semi-Supervised 2D Human  Pose Estimation",
    "abstract": "An Empirical Study of the Collapsing Problem in Semi-Supervised 2D Human  Pose Estimation",
    "descriptor": "",
    "authors": [
      "Rongchang Xie",
      "Chunyu Wang",
      "Wenjun Zeng",
      "Yizhou Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.12498"
  },
  {
    "id": "arXiv:2011.14503",
    "title": "End-to-End Video Instance Segmentation with Transformers",
    "abstract": "Comments: CVPR2021 Oral",
    "descriptor": "\nComments: CVPR2021 Oral\n",
    "authors": [
      "Yuqing Wang",
      "Zhaoliang Xu",
      "Xinlong Wang",
      "Chunhua Shen",
      "Baoshan Cheng",
      "Hao Shen",
      "Huaxia Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.14503"
  },
  {
    "id": "arXiv:2012.02864",
    "title": "Monte-Carlo Methods for the Neutron Transport Equation",
    "abstract": "Monte-Carlo Methods for the Neutron Transport Equation",
    "descriptor": "",
    "authors": [
      "Alexander M.G. Cox",
      "Simon C. Harris",
      "Andreas E. Kyprianou",
      "Minmin Wang"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2012.02864"
  },
  {
    "id": "arXiv:2012.04473",
    "title": "Quantum Technology for Economists",
    "abstract": "Comments: 106 pages, 13 figures",
    "descriptor": "\nComments: 106 pages, 13 figures\n",
    "authors": [
      "Isaiah Hull",
      "Or Sattath",
      "Eleni Diamanti",
      "G\u00f6ran Wendin"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Cryptography and Security (cs.CR)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2012.04473"
  },
  {
    "id": "arXiv:2012.04713",
    "title": "Classical symmetries and the Quantum Approximate Optimization Algorithm",
    "abstract": "Classical symmetries and the Quantum Approximate Optimization Algorithm",
    "descriptor": "",
    "authors": [
      "Ruslan Shaydulin",
      "Stuart Hadfield",
      "Tad Hogg",
      "Ilya Safro"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.04713"
  },
  {
    "id": "arXiv:2012.06894",
    "title": "On the decoding of lattices constructed via a single parity check",
    "abstract": "Comments: Submitted to IEEE Transactions on Information Theory",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Information Theory\n",
    "authors": [
      "Vincent Corlay",
      "Joseph J. Boutros",
      "Philippe Ciblat",
      "Lo\u00efc Brunel"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2012.06894"
  },
  {
    "id": "arXiv:2012.07032",
    "title": "Neural network approaches to point lattice decoding",
    "abstract": "Comments: submitted to IEEE Transactions on Information Theory. arXiv admin note: text overlap with arXiv:1902.11294",
    "descriptor": "\nComments: submitted to IEEE Transactions on Information Theory. arXiv admin note: text overlap with arXiv:1902.11294\n",
    "authors": [
      "Vincent Corlay",
      "Joseph J. Boutros",
      "Philippe Ciblat",
      "Lo\u00efc Brunel"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.07032"
  },
  {
    "id": "arXiv:2101.01768",
    "title": "Multi-Cell, Multi-Channel URLLC with Probabilistic Per-Packet Real-Time  Guarantee",
    "abstract": "Multi-Cell, Multi-Channel URLLC with Probabilistic Per-Packet Real-Time  Guarantee",
    "descriptor": "",
    "authors": [
      "Zhibo Meng",
      "Hongwei Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2101.01768"
  },
  {
    "id": "arXiv:2101.04749",
    "title": "ChemNODE: A Neural Ordinary Differential Equations Approach for Chemical  Kinetics Solvers",
    "abstract": "ChemNODE: A Neural Ordinary Differential Equations Approach for Chemical  Kinetics Solvers",
    "descriptor": "",
    "authors": [
      "Opeoluwa Owoyele",
      "Pinaki Pal"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2101.04749"
  },
  {
    "id": "arXiv:2101.07968",
    "title": "DynaComm: Accelerating Distributed CNN Training between Edges and Clouds  through Dynamic Communication Scheduling",
    "abstract": "Comments: 16 pages, 12 figures. IEEE Journal on Selected Areas in Communications",
    "descriptor": "\nComments: 16 pages, 12 figures. IEEE Journal on Selected Areas in Communications\n",
    "authors": [
      "Shangming Cai",
      "Dongsheng Wang",
      "Haixia Wang",
      "Yongqiang Lyu",
      "Guangquan Xu",
      "Xi Zheng",
      "Athanasios V. Vasilakos"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.07968"
  },
  {
    "id": "arXiv:2101.10421",
    "title": "English Machine Reading Comprehension Datasets: A Survey",
    "abstract": "Comments: Will appear at EMNLP 2021. Dataset survey paper: 9 pages, 5 figures, 2 tables + attachment",
    "descriptor": "\nComments: Will appear at EMNLP 2021. Dataset survey paper: 9 pages, 5 figures, 2 tables + attachment\n",
    "authors": [
      "Daria Dzendzik",
      "Carl Vogel",
      "Jennifer Foster"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2101.10421"
  },
  {
    "id": "arXiv:2101.12010",
    "title": "Modeling Spatial Nonstationarity via Deformable Convolutions for Deep  Traffic Flow Prediction",
    "abstract": "Modeling Spatial Nonstationarity via Deformable Convolutions for Deep  Traffic Flow Prediction",
    "descriptor": "",
    "authors": [
      "Wei Zeng",
      "Chengqiao Lin",
      "Kang Liu",
      "Juncong Lin",
      "Anthony K. H. Tung"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.12010"
  },
  {
    "id": "arXiv:2102.03129",
    "title": "Integer Programming for Causal Structure Learning in the Presence of  Latent Variables",
    "abstract": "Comments: Published in ICML 2021",
    "descriptor": "\nComments: Published in ICML 2021\n",
    "authors": [
      "Rui Chen",
      "Sanjeeb Dash",
      "Tian Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2102.03129"
  },
  {
    "id": "arXiv:2102.04399",
    "title": "Escaping Stochastic Traps with Aleatoric Mapping Agents",
    "abstract": "Comments: Previously Presented at the NeurIPS (2020) Biological and Artificial Reinforcement Learning Workshop",
    "descriptor": "\nComments: Previously Presented at the NeurIPS (2020) Biological and Artificial Reinforcement Learning Workshop\n",
    "authors": [
      "Augustine N. Mavor-Parker",
      "Kimberly A. Young",
      "Caswell Barry",
      "Lewis D. Griffin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.04399"
  },
  {
    "id": "arXiv:2102.04760",
    "title": "Improving Scene Graph Classification by Exploiting Knowledge from Texts",
    "abstract": "Improving Scene Graph Classification by Exploiting Knowledge from Texts",
    "descriptor": "",
    "authors": [
      "Sahand Sharifzadeh",
      "Sina Moayed Baharlou",
      "Martin Schmitt",
      "Hinrich Sch\u00fctze",
      "Volker Tresp"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.04760"
  },
  {
    "id": "arXiv:2102.06570",
    "title": "User manual for bch, a program for the fast computation of the  Baker-Campbell-Hausdorff and similar series",
    "abstract": "User manual for bch, a program for the fast computation of the  Baker-Campbell-Hausdorff and similar series",
    "descriptor": "",
    "authors": [
      "Harald Hofst\u00e4tter"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2102.06570"
  },
  {
    "id": "arXiv:2102.06810",
    "title": "Understanding self-supervised Learning Dynamics without Contrastive  Pairs",
    "abstract": "Comments: Fix minor typo in Appendix",
    "descriptor": "\nComments: Fix minor typo in Appendix\n",
    "authors": [
      "Yuandong Tian",
      "Xinlei Chen",
      "Surya Ganguli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.06810"
  },
  {
    "id": "arXiv:2102.07100",
    "title": "IMF: Iterative Max-Flow for Node Localizability Detection in Barycentric  Linear Localization",
    "abstract": "IMF: Iterative Max-Flow for Node Localizability Detection in Barycentric  Linear Localization",
    "descriptor": "",
    "authors": [
      "Haodi Ping",
      "Yongcai Wang",
      "Deying Li"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2102.07100"
  },
  {
    "id": "arXiv:2102.09310",
    "title": "VAE Approximation Error: ELBO and Conditional Independence",
    "abstract": "VAE Approximation Error: ELBO and Conditional Independence",
    "descriptor": "",
    "authors": [
      "Alexander Shekhovtsov",
      "Dmitrij Schlesinger",
      "Boris Flach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.09310"
  },
  {
    "id": "arXiv:2102.12620",
    "title": "High-Capacity Reversible Data Hiding in Encrypted Images using Adaptive  Encoding",
    "abstract": "High-Capacity Reversible Data Hiding in Encrypted Images using Adaptive  Encoding",
    "descriptor": "",
    "authors": [
      "Wenjing Ma",
      "Youqing Wu",
      "Zhaoxia Yin"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2102.12620"
  },
  {
    "id": "arXiv:2103.00902",
    "title": "Manifold optimization for non-linear optimal transport problems",
    "abstract": "Comments: technical report, change is title, addition of experiments",
    "descriptor": "\nComments: technical report, change is title, addition of experiments\n",
    "authors": [
      "Bamdev Mishra",
      "N T V Satyadev",
      "Hiroyuki Kasai",
      "Pratik Jawanpuria"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2103.00902"
  },
  {
    "id": "arXiv:2103.01394",
    "title": "Object Allocation Over a Network of Objects: Mobile Agents with Strict  Preferences",
    "abstract": "Comments: List of all changes from v1: (1) publication month on title page corrected from February to March (original submission date was March 1, 2021); (2) page number on title page removed; (3) cleaned up some bibtex entries",
    "descriptor": "\nComments: List of all changes from v1: (1) publication month on title page corrected from February to March (original submission date was March 1, 2021); (2) page number on title page removed; (3) cleaned up some bibtex entries\n",
    "authors": [
      "Fu Li",
      "C. Gregory Plaxton",
      "Vaibhav B. Sinha"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2103.01394"
  },
  {
    "id": "arXiv:2103.11553",
    "title": "Two Metrics on Rooted Unordered Trees with Labels",
    "abstract": "Two Metrics on Rooted Unordered Trees with Labels",
    "descriptor": "",
    "authors": [
      "Yue Wang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2103.11553"
  },
  {
    "id": "arXiv:2103.12634",
    "title": "Epidemic Spreading and Digital Contact Tracing: Effects of Heterogeneous  Mixing and Quarantine Failures",
    "abstract": "Epidemic Spreading and Digital Contact Tracing: Effects of Heterogeneous  Mixing and Quarantine Failures",
    "descriptor": "",
    "authors": [
      "Abbas K. Rizi",
      "Ali Faqeeh",
      "Arash Badie-Modiri",
      "Mikko Kivel\u00e4"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2103.12634"
  },
  {
    "id": "arXiv:2103.13027",
    "title": "Unveiling the Power of Mixup for Stronger Classifiers",
    "abstract": "Comments: The second version of AutoMix. 12 pages, 7 figures",
    "descriptor": "\nComments: The second version of AutoMix. 12 pages, 7 figures\n",
    "authors": [
      "Zicheng Liu",
      "Siyuan Li",
      "Di Wu",
      "Zhiyuan Chen",
      "Lirong Wu",
      "Jianzhu Guo",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.13027"
  },
  {
    "id": "arXiv:2103.14586",
    "title": "Understanding Robustness of Transformers for Image Classification",
    "abstract": "Comments: Accepted for publication at ICCV 2021. Rewrote Section 5 and made other minor changes throughout",
    "descriptor": "\nComments: Accepted for publication at ICCV 2021. Rewrote Section 5 and made other minor changes throughout\n",
    "authors": [
      "Srinadh Bhojanapalli",
      "Ayan Chakrabarti",
      "Daniel Glasner",
      "Daliang Li",
      "Thomas Unterthiner",
      "Andreas Veit"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.14586"
  },
  {
    "id": "arXiv:2103.15722",
    "title": "Transformer-based end-to-end speech recognition with residual  Gaussian-based self-attention",
    "abstract": "Comments: There is an error in the description of section 3.2.1",
    "descriptor": "\nComments: There is an error in the description of section 3.2.1\n",
    "authors": [
      "Chengdong Liang",
      "Menglong Xu",
      "Xiao-Lei Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2103.15722"
  },
  {
    "id": "arXiv:2103.15947",
    "title": "Federated Learning with Taskonomy for Non-IID Data",
    "abstract": "Comments: 30 pages",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Hadi Jamali-Rad",
      "Mohammad Abdizadeh",
      "Anuj Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2103.15947"
  },
  {
    "id": "arXiv:2103.16940",
    "title": "Learning with Memory-based Virtual Classes for Deep Metric Learning",
    "abstract": "Comments: Accepted by ICCV2021",
    "descriptor": "\nComments: Accepted by ICCV2021\n",
    "authors": [
      "Byungsoo Ko",
      "Geonmo Gu",
      "Han-Gyu Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.16940"
  },
  {
    "id": "arXiv:2104.02724",
    "title": "Relaxing the Conditional Independence Assumption of CTC-based ASR by  Conditioning on Intermediate Predictions",
    "abstract": "Comments: Accepted to INTERSPEECH2021",
    "descriptor": "\nComments: Accepted to INTERSPEECH2021\n",
    "authors": [
      "Jumon Nozaki",
      "Tatsuya Komatsu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2104.02724"
  },
  {
    "id": "arXiv:2104.03841",
    "title": "ORBIT: A Real-World Few-Shot Dataset for Teachable Object Recognition",
    "abstract": "Comments: IEEE/CVF International Conference on Computer Vision (ICCV), 2021",
    "descriptor": "\nComments: IEEE/CVF International Conference on Computer Vision (ICCV), 2021\n",
    "authors": [
      "Daniela Massiceti",
      "Luisa Zintgraf",
      "John Bronskill",
      "Lida Theodorou",
      "Matthew Tobias Harris",
      "Edward Cutrell",
      "Cecily Morrison",
      "Katja Hofmann",
      "Simone Stumpf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.03841"
  },
  {
    "id": "arXiv:2104.10078",
    "title": "UNISURF: Unifying Neural Implicit Surfaces and Radiance Fields for  Multi-View Reconstruction",
    "abstract": "Comments: ICCV 2021 oral",
    "descriptor": "\nComments: ICCV 2021 oral\n",
    "authors": [
      "Michael Oechsle",
      "Songyou Peng",
      "Andreas Geiger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.10078"
  },
  {
    "id": "arXiv:2104.12835",
    "title": "Less is more: Selecting informative and diverse subsets with balancing  constraints",
    "abstract": "Comments: Added error bars to the experiments",
    "descriptor": "\nComments: Added error bars to the experiments\n",
    "authors": [
      "Srikumar Ramalingam",
      "Daniel Glasner",
      "Kaushal Patel",
      "Raviteja Vemulapalli",
      "Sadeep Jayasumana",
      "Sanjiv Kumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.12835"
  },
  {
    "id": "arXiv:2105.00534",
    "title": "Metadata Interpretation Driven Development",
    "abstract": "Metadata Interpretation Driven Development",
    "descriptor": "",
    "authors": [
      "J\u00falio G. S. F. da Costa",
      "Reinaldo A. Petta",
      "Samuel Xavier-de-Souza"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.00534"
  },
  {
    "id": "arXiv:2105.02186",
    "title": "RandCrowns: A Quantitative Metric for Imprecisely Labeled Tree Crown  Delineation",
    "abstract": "RandCrowns: A Quantitative Metric for Imprecisely Labeled Tree Crown  Delineation",
    "descriptor": "",
    "authors": [
      "Dylan Stewart",
      "Alina Zare",
      "Sergio Marconi",
      "Ben Weinstein",
      "Ethan White",
      "Sarah Graves",
      "Stephanie Bohlman",
      "Aditya Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.02186"
  },
  {
    "id": "arXiv:2105.05842",
    "title": "Kernel Thinning",
    "abstract": "Comments: Accepted for presentation as an extended abstract at the Conference on Learning Theory (COLT) 2021",
    "descriptor": "\nComments: Accepted for presentation as an extended abstract at the Conference on Learning Theory (COLT) 2021\n",
    "authors": [
      "Raaz Dwivedi",
      "Lester Mackey"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2105.05842"
  },
  {
    "id": "arXiv:2105.06535",
    "title": "Learning Robust Hierarchical Patterns of Human Brain across Many fMRI  Studies",
    "abstract": "Learning Robust Hierarchical Patterns of Human Brain across Many fMRI  Studies",
    "descriptor": "",
    "authors": [
      "Dushyant Sahoo",
      "Christos Davatzikos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2105.06535"
  },
  {
    "id": "arXiv:2105.07402",
    "title": "Is aspect ratio of cells important in deep learning? A robust comparison  of deep learning methods for multi-scale cytopathology cell image  classification: from convolutional neural networks to visual transformers",
    "abstract": "Is aspect ratio of cells important in deep learning? A robust comparison  of deep learning methods for multi-scale cytopathology cell image  classification: from convolutional neural networks to visual transformers",
    "descriptor": "",
    "authors": [
      "Wanli Liu",
      "Chen Li",
      "Md Mamunur Rahamana",
      "Hongzan Sun",
      "Weiming Hu",
      "Haoyuan Chen",
      "Changhao Sun",
      "Yudong Yao",
      "Marcin Grzegorzek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.07402"
  },
  {
    "id": "arXiv:2105.08501",
    "title": "Self-supervised Remote Sensing Images Change Detection at Pixel-level",
    "abstract": "Self-supervised Remote Sensing Images Change Detection at Pixel-level",
    "descriptor": "",
    "authors": [
      "Yuxing Chen",
      "Lorenzo Bruzzone"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.08501"
  },
  {
    "id": "arXiv:2105.09371",
    "title": "VOILA: Visual-Observation-Only Imitation Learning for Autonomous  Navigation",
    "abstract": "Comments: Under Submission to ICRA+RAL 2022",
    "descriptor": "\nComments: Under Submission to ICRA+RAL 2022\n",
    "authors": [
      "Haresh Karnan",
      "Garrett Warnell",
      "Xuesu Xiao",
      "Peter Stone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.09371"
  },
  {
    "id": "arXiv:2105.09437",
    "title": "End-to-End Unsupervised Document Image Blind Denoising",
    "abstract": "Comments: 10 pages main & 10 pages supplementary, the paper is accepted at ICCV 2021",
    "descriptor": "\nComments: 10 pages main & 10 pages supplementary, the paper is accepted at ICCV 2021\n",
    "authors": [
      "Mehrdad J Gangeh",
      "Marcin Plata",
      "Hamid Motahari",
      "Nigel P Duffy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.09437"
  },
  {
    "id": "arXiv:2105.12272",
    "title": "Provable Representation Learning for Imitation with Contrastive Fourier  Features",
    "abstract": "Provable Representation Learning for Imitation with Contrastive Fourier  Features",
    "descriptor": "",
    "authors": [
      "Ofir Nachum",
      "Mengjiao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.12272"
  },
  {
    "id": "arXiv:2105.13645",
    "title": "Learning to Select Cuts for Efficient Mixed-Integer Programming",
    "abstract": "Comments: Paper accepted at Pattern Recognition journal",
    "descriptor": "\nComments: Paper accepted at Pattern Recognition journal\n",
    "authors": [
      "Zeren Huang",
      "Kerong Wang",
      "Furui Liu",
      "Hui-ling Zhen",
      "Weinan Zhang",
      "Mingxuan Yuan",
      "Jianye Hao",
      "Yong Yu",
      "Jun Wang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13645"
  },
  {
    "id": "arXiv:2105.14750",
    "title": "Active Hierarchical Exploration with Stable Subgoal Representation  Learning",
    "abstract": "Active Hierarchical Exploration with Stable Subgoal Representation  Learning",
    "descriptor": "",
    "authors": [
      "Siyuan Li",
      "Jin Zhang",
      "Jianhao Wang",
      "Yang Yu",
      "Chongjie Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.14750"
  },
  {
    "id": "arXiv:2106.01425",
    "title": "Gradient Assisted Learning",
    "abstract": "Gradient Assisted Learning",
    "descriptor": "",
    "authors": [
      "Enmao Diao",
      "Jie Ding",
      "Vahid Tarokh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01425"
  },
  {
    "id": "arXiv:2106.01432",
    "title": "SemiFL: Communication Efficient Semi-Supervised Federated Learning with  Unlabeled Clients",
    "abstract": "SemiFL: Communication Efficient Semi-Supervised Federated Learning with  Unlabeled Clients",
    "descriptor": "",
    "authors": [
      "Enmao Diao",
      "Jie Ding",
      "Vahid Tarokh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01432"
  },
  {
    "id": "arXiv:2106.02449",
    "title": "Hypercontracts",
    "abstract": "Hypercontracts",
    "descriptor": "",
    "authors": [
      "Inigo Incer",
      "Albert Benveniste",
      "Alberto Sangiovanni-Vincentelli",
      "Sanjit A. Seshia"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.02449"
  },
  {
    "id": "arXiv:2106.03374",
    "title": "MixRL: Data Mixing Augmentation for Regression using Reinforcement  Learning",
    "abstract": "Comments: 15 pages, 9 figures, 7 tables",
    "descriptor": "\nComments: 15 pages, 9 figures, 7 tables\n",
    "authors": [
      "Seong-Hyeon Hwang",
      "Steven Euijong Whang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03374"
  },
  {
    "id": "arXiv:2106.03485",
    "title": "Representation mitosis in wide neural networks",
    "abstract": "Representation mitosis in wide neural networks",
    "descriptor": "",
    "authors": [
      "Diego Doimo",
      "Aldo Glielmo",
      "Sebastian Goldt",
      "Alessandro Laio"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03485"
  },
  {
    "id": "arXiv:2106.03693",
    "title": "Increase and Conquer: Training Graph Neural Networks on Growing Graphs",
    "abstract": "Increase and Conquer: Training Graph Neural Networks on Growing Graphs",
    "descriptor": "",
    "authors": [
      "Juan Cervino",
      "Luana Ruiz",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.03693"
  },
  {
    "id": "arXiv:2106.03761",
    "title": "FairCal: Fairness Calibration for Face Verification",
    "abstract": "Comments: 10 pages, 4 tables, 2 figures, + appendix",
    "descriptor": "\nComments: 10 pages, 4 tables, 2 figures, + appendix\n",
    "authors": [
      "Tiago Salvador",
      "Stephanie Cairns",
      "Vikram Voleti",
      "Noah Marshall",
      "Adam Oberman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.03761"
  },
  {
    "id": "arXiv:2106.04149",
    "title": "Understanding Generalized Label Smoothing when Learning with Noisy  Labels",
    "abstract": "Comments: Under Review",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Jiaheng Wei",
      "Hangyu Liu",
      "Tongliang Liu",
      "Gang Niu",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.04149"
  },
  {
    "id": "arXiv:2106.04221",
    "title": "Multi-output Gaussian Processes for Uncertainty-aware Recommender  Systems",
    "abstract": "Comments: Published at UAI 2021",
    "descriptor": "\nComments: Published at UAI 2021\n",
    "authors": [
      "Yinchong Yang",
      "Florian Buettner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.04221"
  },
  {
    "id": "arXiv:2106.05210",
    "title": "Rethinking Space-Time Networks with Improved Memory Coverage for  Efficient Video Object Segmentation",
    "abstract": "Comments: Accepted to NeurIPS 2021. Project page: this https URL",
    "descriptor": "\nComments: Accepted to NeurIPS 2021. Project page: this https URL\n",
    "authors": [
      "Ho Kei Cheng",
      "Yu-Wing Tai",
      "Chi-Keung Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.05210"
  },
  {
    "id": "arXiv:2106.05710",
    "title": "DNN-Based Topology Optimisation: Spatial Invariance and Neural Tangent  Kernel",
    "abstract": "DNN-Based Topology Optimisation: Spatial Invariance and Neural Tangent  Kernel",
    "descriptor": "",
    "authors": [
      "Benjamin Dupuis",
      "Arthur Jacot"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05710"
  },
  {
    "id": "arXiv:2106.12215",
    "title": "Communication in Complex Networks",
    "abstract": "Comments: 28 pages, 7 figures",
    "descriptor": "\nComments: 28 pages, 7 figures\n",
    "authors": [
      "Omar De la Cruz Cabrera",
      "Jiafeng Jin",
      "Silvia Noschese",
      "Lothar Reichel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.12215"
  },
  {
    "id": "arXiv:2106.13709",
    "title": "A constructive theory of shape",
    "abstract": "Comments: 19 pages, 10 figures. Discussion on a convexity property added. Accepted to Chaos. Sol. Fract",
    "descriptor": "\nComments: 19 pages, 10 figures. Discussion on a convexity property added. Accepted to Chaos. Sol. Fract\n",
    "authors": [
      "Vladimir Garc\u00eda-Morales"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.13709"
  },
  {
    "id": "arXiv:2106.14117",
    "title": "Graph Convolutional Memory using Topological Priors",
    "abstract": "Graph Convolutional Memory using Topological Priors",
    "descriptor": "",
    "authors": [
      "Steven D. Morad",
      "Stephan Liwicki",
      "Ryan Kortvelesy",
      "Roberto Mecca",
      "Amanda Prorok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.14117"
  },
  {
    "id": "arXiv:2106.14300",
    "title": "ASK: Adversarial Soft k-Nearest Neighbor Attack and Defense",
    "abstract": "ASK: Adversarial Soft k-Nearest Neighbor Attack and Defense",
    "descriptor": "",
    "authors": [
      "Ren Wang",
      "Tianqi Chen",
      "Philip Yao",
      "Sijia Liu",
      "Indika Rajapakse",
      "Alfred Hero"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.14300"
  },
  {
    "id": "arXiv:2106.15754",
    "title": "Looking Outside the Window: Wide-Context Transformer for the Semantic  Segmentation of High-Resolution Remote Sensing Images",
    "abstract": "Looking Outside the Window: Wide-Context Transformer for the Semantic  Segmentation of High-Resolution Remote Sensing Images",
    "descriptor": "",
    "authors": [
      "Lei Ding",
      "Dong Lin",
      "Shaofu Lin",
      "Jing Zhang",
      "Xiaojie Cui",
      "Yuebin Wang",
      "Hao Tang",
      "Lorenzo Bruzzone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15754"
  },
  {
    "id": "arXiv:2106.15788",
    "title": "Align Yourself: Self-supervised Pre-training for Fine-grained  Recognition via Saliency Alignment",
    "abstract": "Comments: The second version of CVSA. 10 pages, 4 figures",
    "descriptor": "\nComments: The second version of CVSA. 10 pages, 4 figures\n",
    "authors": [
      "Di Wu",
      "Siyuan Li",
      "Zelin Zang",
      "Kai Wang",
      "Lei Shang",
      "Baigui Sun",
      "Hao Li",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15788"
  },
  {
    "id": "arXiv:2107.01554",
    "title": "EditSpeech: A Text Based Speech Editing System Using Partial Inference  and Bidirectional Fusion",
    "abstract": "Comments: Accepted by ASRU 2021",
    "descriptor": "\nComments: Accepted by ASRU 2021\n",
    "authors": [
      "Daxin Tan",
      "Liqun Deng",
      "Yu Ting Yeung",
      "Xin Jiang",
      "Xiao Chen",
      "Tan Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.01554"
  },
  {
    "id": "arXiv:2107.02729",
    "title": "AdaRL: What, Where, and How to Adapt in Transfer Reinforcement Learning",
    "abstract": "AdaRL: What, Where, and How to Adapt in Transfer Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Biwei Huang",
      "Fan Feng",
      "Chaochao Lu",
      "Sara Magliacane",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.02729"
  },
  {
    "id": "arXiv:2107.04649",
    "title": "Accuracy on the Line: On the Strong Correlation Between  Out-of-Distribution and In-Distribution Generalization",
    "abstract": "Accuracy on the Line: On the Strong Correlation Between  Out-of-Distribution and In-Distribution Generalization",
    "descriptor": "",
    "authors": [
      "John Miller",
      "Rohan Taori",
      "Aditi Raghunathan",
      "Shiori Sagawa",
      "Pang Wei Koh",
      "Vaishaal Shankar",
      "Percy Liang",
      "Yair Carmon",
      "Ludwig Schmidt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.04649"
  },
  {
    "id": "arXiv:2107.04663",
    "title": "A cost-aware logical framework",
    "abstract": "A cost-aware logical framework",
    "descriptor": "",
    "authors": [
      "Yue Niu",
      "Jonathan Sterling",
      "Harrison Grodin",
      "Robert Harper"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2107.04663"
  },
  {
    "id": "arXiv:2107.05446",
    "title": "Source-Free Adaptation to Measurement Shift via Bottom-Up Feature  Restoration",
    "abstract": "Source-Free Adaptation to Measurement Shift via Bottom-Up Feature  Restoration",
    "descriptor": "",
    "authors": [
      "Cian Eastwood",
      "Ian Mason",
      "Christopher K. I. Williams",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.05446"
  },
  {
    "id": "arXiv:2107.06353",
    "title": "Distributionally Robust Policy Learning via Adversarial Environment  Generation",
    "abstract": "Distributionally Robust Policy Learning via Adversarial Environment  Generation",
    "descriptor": "",
    "authors": [
      "Allen Z. Ren",
      "Anirudha Majumdar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06353"
  },
  {
    "id": "arXiv:2107.06638",
    "title": "Procedural Content Generation using Behavior Trees (PCGBT)",
    "abstract": "Comments: Accepted to EXAG 2021",
    "descriptor": "\nComments: Accepted to EXAG 2021\n",
    "authors": [
      "Anurag Sarkar",
      "Seth Cooper"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06638"
  },
  {
    "id": "arXiv:2107.12452",
    "title": "Accelerated Gradient Descent Learning over Multiple Access Fading  Channels",
    "abstract": "Comments: This paper has been accepted for publication in the IEEE Journal on Selected Areas in Communications",
    "descriptor": "\nComments: This paper has been accepted for publication in the IEEE Journal on Selected Areas in Communications\n",
    "authors": [
      "Raz Paul",
      "Yuval Friedman",
      "Kobi Cohen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.12452"
  },
  {
    "id": "arXiv:2108.00154",
    "title": "CrossFormer: A Versatile Vision Transformer Hinging on Cross-scale  Attention",
    "abstract": "Comments: 15 pages, 4 figures, and 9 tables",
    "descriptor": "\nComments: 15 pages, 4 figures, and 9 tables\n",
    "authors": [
      "Wenxiao Wang",
      "Lu Yao",
      "Long Chen",
      "Binbin Lin",
      "Deng Cai",
      "Xiaofei He",
      "Wei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.00154"
  },
  {
    "id": "arXiv:2108.00770",
    "title": "Defect reconstruction in a 2D semi-analytical waveguide model via  derivative-based optimization",
    "abstract": "Comments: 22 pages, 11 figures",
    "descriptor": "\nComments: 22 pages, 11 figures\n",
    "authors": [
      "Jannis Bulling",
      "Benjamin Jurgelucks",
      "Jens Prager",
      "Andrea Walther"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.00770"
  },
  {
    "id": "arXiv:2108.01614",
    "title": "Generalized Source-free Domain Adaptation",
    "abstract": "Comments: Accepted by ICCV 2021; Update the acknowledgement section",
    "descriptor": "\nComments: Accepted by ICCV 2021; Update the acknowledgement section\n",
    "authors": [
      "Shiqi Yang",
      "Yaxing Wang",
      "Joost van de Weijer",
      "Luis Herranz",
      "Shangling Jui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.01614"
  },
  {
    "id": "arXiv:2108.01775",
    "title": "Solo-learn: A Library of Self-supervised Methods for Visual  Representation Learning",
    "abstract": "Comments: Under review",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Victor G. Turrisi da Costa",
      "Enrico Fini",
      "Moin Nabi",
      "Nicu Sebe",
      "Elisa Ricci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.01775"
  },
  {
    "id": "arXiv:2108.03685",
    "title": "Context Matters: A Theory of Semantic Discriminability for Perceptual  Encoding Systems",
    "abstract": "Comments: To Appear in IEEE Transactions on Visualization and Computer Graphics",
    "descriptor": "\nComments: To Appear in IEEE Transactions on Visualization and Computer Graphics\n",
    "authors": [
      "Kushin Mukherjee",
      "Brian Yin",
      "Brianne E. Sherman",
      "Laurent Lessard",
      "Karen B. Schloss"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2108.03685"
  },
  {
    "id": "arXiv:2108.04097",
    "title": "Deep Learning for Embodied Vision Navigation: A Survey",
    "abstract": "Comments: 24 pages",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Fengda Zhu",
      "Yi Zhu",
      "Vincent CS Lee",
      "Xiaodan Liang",
      "Xiaojun Chang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.04097"
  },
  {
    "id": "arXiv:2108.04521",
    "title": "Multi-domain Collaborative Feature Representation for Robust Visual  Object Tracking",
    "abstract": "Multi-domain Collaborative Feature Representation for Robust Visual  Object Tracking",
    "descriptor": "",
    "authors": [
      "Jiqing Zhang",
      "Kai Zhao",
      "Bo Dong",
      "Yingkai Fu",
      "Yuxin Wang",
      "Xin Yang",
      "Baocai Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.04521"
  },
  {
    "id": "arXiv:2108.05297",
    "title": "Uniform Complete Observability of Mass and Rotational Inertial  Parameters in Adaptive Identification of Rigid-Body Plant Dynamics",
    "abstract": "Comments: To appear in published proceedings of the 2021 IEEE International Conference on Robotics and Automation (ICRA), Xian, China, May 30 - June 5, 2021. 6 Pages, 2 Figures Replacement submitted to include author's middle initials in metadata",
    "descriptor": "\nComments: To appear in published proceedings of the 2021 IEEE International Conference on Robotics and Automation (ICRA), Xian, China, May 30 - June 5, 2021. 6 Pages, 2 Figures Replacement submitted to include author's middle initials in metadata\n",
    "authors": [
      "Tyler M. Paine",
      "Louis L. Whitcomb"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.05297"
  },
  {
    "id": "arXiv:2108.05533",
    "title": "Efficient Local Planning with Linear Function Approximation",
    "abstract": "Efficient Local Planning with Linear Function Approximation",
    "descriptor": "",
    "authors": [
      "Dong Yin",
      "Botao Hao",
      "Yasin Abbasi-Yadkori",
      "Nevena Lazi\u0107",
      "Csaba Szepesv\u00e1ri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.05533"
  },
  {
    "id": "arXiv:2108.05779",
    "title": "DiagViB-6: A Diagnostic Benchmark Suite for Vision Models in the  Presence of Shortcut and Generalization Opportunities",
    "abstract": "Comments: Accepted for publication at IEEE International Conference on Computer Vision (ICCV) 2021; updated affiliations & corrected typo",
    "descriptor": "\nComments: Accepted for publication at IEEE International Conference on Computer Vision (ICCV) 2021; updated affiliations & corrected typo\n",
    "authors": [
      "Elias Eulig",
      "Piyapat Saranrittichai",
      "Chaithanya Kumar Mummadi",
      "Kilian Rambach",
      "William Beluch",
      "Xiahan Shi",
      "Volker Fischer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.05779"
  },
  {
    "id": "arXiv:2108.07638",
    "title": "A Weakly Supervised Dataset of Fine-Grained Emotions in Portuguese",
    "abstract": "Comments: Paper published at Symposium in Information and Human Language Technology (STIL 2021)",
    "descriptor": "\nComments: Paper published at Symposium in Information and Human Language Technology (STIL 2021)\n",
    "authors": [
      "Diogo Cortiz",
      "Jefferson O. Silva",
      "Newton Calegari",
      "Ana Lu\u00edsa Freitas",
      "Ana Ang\u00e9lica Soares",
      "Carolina Botelho",
      "Gabriel Gaudencio R\u00eago",
      "Waldir Sampaio",
      "Paulo Sergio Boggio"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.07638"
  },
  {
    "id": "arXiv:2108.09026",
    "title": "Federated Distributionally Robust Optimization for Phase Configuration  of RISs",
    "abstract": "Comments: 6 pages, 2 figures",
    "descriptor": "\nComments: 6 pages, 2 figures\n",
    "authors": [
      "Chaouki Ben Issaid",
      "Sumudu Samarakoon",
      "Mehdi Bennis",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.09026"
  },
  {
    "id": "arXiv:2108.10155",
    "title": "Construction Cost Index Forecasting: A Multi-feature Fusion Approach",
    "abstract": "Construction Cost Index Forecasting: A Multi-feature Fusion Approach",
    "descriptor": "",
    "authors": [
      "Tianxiang Zhan",
      "Yuanpeng He",
      "Fuyuan Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.10155"
  },
  {
    "id": "arXiv:2109.00818",
    "title": "Adherence and Constancy in LIME-RS Explanations for Recommendation",
    "abstract": "Comments: accepted at KaRS Workshop @RecSys 2021",
    "descriptor": "\nComments: accepted at KaRS Workshop @RecSys 2021\n",
    "authors": [
      "Vito Walter Anelli",
      "Alejandro Bellog\u00edn",
      "Tommaso Di Noia",
      "Francesco Maria Donini",
      "Vincenzo Paparella",
      "Claudio Pomo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.00818"
  },
  {
    "id": "arXiv:2109.01634",
    "title": "AI Descartes: Combining Data and Theory for Derivable Scientific  Discovery",
    "abstract": "AI Descartes: Combining Data and Theory for Derivable Scientific  Discovery",
    "descriptor": "",
    "authors": [
      "Cristina Cornelio",
      "Sanjeeb Dash",
      "Vernon Austel",
      "Tyler Josephson",
      "Joao Goncalves",
      "Kenneth Clarkson",
      "Nimrod Megiddo",
      "Bachir El Khadir",
      "Lior Horesh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.01634"
  },
  {
    "id": "arXiv:2109.01730",
    "title": "Nonasymptotic one-and two-sample tests in high dimension with unknown  covariance structure",
    "abstract": "Nonasymptotic one-and two-sample tests in high dimension with unknown  covariance structure",
    "descriptor": "",
    "authors": [
      "Gilles Blanchard",
      "Jean-Baptiste Fermanian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.01730"
  },
  {
    "id": "arXiv:2109.01838",
    "title": "RAMA: A Rapid Multicut Algorithm on GPU",
    "abstract": "RAMA: A Rapid Multicut Algorithm on GPU",
    "descriptor": "",
    "authors": [
      "Ahmed Abbas",
      "Paul Swoboda"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.01838"
  },
  {
    "id": "arXiv:2109.02119",
    "title": "Identification of Driver Phone Usage Violations via State-of-the-Art  Object Detection with Tracking",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Steven Carrell",
      "Amir Atapour-Abarghouei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.02119"
  },
  {
    "id": "arXiv:2109.04620",
    "title": "Rule-based Morphological Inflection Improves Neural Terminology  Translation",
    "abstract": "Comments: EMNLP 2021",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Weijia Xu",
      "Marine Carpuat"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04620"
  },
  {
    "id": "arXiv:2109.05729",
    "title": "CPT: A Pre-Trained Unbalanced Transformer for Both Chinese Language  Understanding and Generation",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Yunfan Shao",
      "Zhichao Geng",
      "Yitao Liu",
      "Junqi Dai",
      "Fei Yang",
      "Li Zhe",
      "Hujun Bao",
      "Xipeng Qiu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.05729"
  },
  {
    "id": "arXiv:2109.06099",
    "title": "Uniform Generalization Bounds for Overparameterized Neural Networks",
    "abstract": "Uniform Generalization Bounds for Overparameterized Neural Networks",
    "descriptor": "",
    "authors": [
      "Sattar Vakili",
      "Michael Bromberg",
      "Jezabel Garcia",
      "Da-shan Shiu",
      "Alberto Bernacchia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.06099"
  },
  {
    "id": "arXiv:2109.06165",
    "title": "CDTrans: Cross-domain Transformer for Unsupervised Domain Adaptation",
    "abstract": "CDTrans: Cross-domain Transformer for Unsupervised Domain Adaptation",
    "descriptor": "",
    "authors": [
      "Tongkun Xu",
      "Weihua Chen",
      "Pichao Wang",
      "Fan Wang",
      "Hao Li",
      "Rong Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06165"
  },
  {
    "id": "arXiv:2109.06510",
    "title": "On the bilateral preconditioning for an L2-type all-at-once system  arising from time-space fractional Bloch-Torrey equations",
    "abstract": "Comments: 24 pages, 6 tables, 4 figures",
    "descriptor": "\nComments: 24 pages, 6 tables, 4 figures\n",
    "authors": [
      "Yong-Liang Zhao",
      "Jing Wu",
      "Xian-Ming Gu",
      "Hu Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.06510"
  },
  {
    "id": "arXiv:2109.06822",
    "title": "LM-Critic: Language Models for Unsupervised Grammatical Error Correction",
    "abstract": "Comments: EMNLP 2021. Code & data available at this https URL",
    "descriptor": "\nComments: EMNLP 2021. Code & data available at this https URL\n",
    "authors": [
      "Michihiro Yasunaga",
      "Jure Leskovec",
      "Percy Liang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06822"
  },
  {
    "id": "arXiv:2109.07028",
    "title": "Avengers Ensemble! Improving Transferability of Authorship Obfuscation",
    "abstract": "Comments: Submitted to PETS 2021",
    "descriptor": "\nComments: Submitted to PETS 2021\n",
    "authors": [
      "Muhammad Haroon",
      "Fareed Zaffar",
      "Padmini Srinivasan",
      "Zubair Shafiq"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.07028"
  },
  {
    "id": "arXiv:2109.07690",
    "title": "The Neural Metric Factorization for Computational Drug Repositioning",
    "abstract": "Comments: 14 pages",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Xinxing Yang",
      "Genke Yangand Jian Chu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07690"
  },
  {
    "id": "arXiv:2109.08026",
    "title": "EVAGAN: Evasion Generative Adversarial Network for Low Data Regimes",
    "abstract": "Comments: 12 pages, 10 figures",
    "descriptor": "\nComments: 12 pages, 10 figures\n",
    "authors": [
      "Rizwan Hamid Randhawa",
      "Nauman Aslam",
      "Muhammad Alauthman",
      "Husnain Rafiq"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.08026"
  },
  {
    "id": "arXiv:2109.08265",
    "title": "Probabilistic Stability Analysis of Planar Robots with Piecewise  Constant Derivative Dynamics",
    "abstract": "Comments: 21 pages, 2 figures",
    "descriptor": "\nComments: 21 pages, 2 figures\n",
    "authors": [
      "Spandan Das",
      "Pavithra Prabhakar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.08265"
  },
  {
    "id": "arXiv:2109.08584",
    "title": "A General-Purpose Crowdsourcing Computational Quality Control Toolkit  for Python",
    "abstract": "Comments: accepted at HCOMP 2021 Works-in-Progress and Demonstration Track",
    "descriptor": "\nComments: accepted at HCOMP 2021 Works-in-Progress and Demonstration Track\n",
    "authors": [
      "Dmitry Ustalov",
      "Nikita Pavlichenko",
      "Vladimir Losev",
      "Iulian Giliazev",
      "Evgeny Tulin"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.08584"
  },
  {
    "id": "arXiv:2109.08750",
    "title": "Auto White-Balance Correction for Mixed-Illuminant Scenes",
    "abstract": "Auto White-Balance Correction for Mixed-Illuminant Scenes",
    "descriptor": "",
    "authors": [
      "Mahmoud Afifi",
      "Marcus A. Brubaker",
      "Michael S. Brown"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.08750"
  },
  {
    "id": "arXiv:2109.09510",
    "title": "Conditionally Parameterized, Discretization-Aware Neural Networks for  Mesh-Based Modeling of Physical Systems",
    "abstract": "Conditionally Parameterized, Discretization-Aware Neural Networks for  Mesh-Based Modeling of Physical Systems",
    "descriptor": "",
    "authors": [
      "Jiayang Xu",
      "Aniruddhe Pradhan",
      "Karthik Duraisamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2109.09510"
  },
  {
    "id": "arXiv:2109.09824",
    "title": "Well Googled is Half Done: Multimodal Forecasting of New Fashion Product  Sales with Image-based Google Trends",
    "abstract": "Comments: Paper submitted to Pattern Recognition Journal",
    "descriptor": "\nComments: Paper submitted to Pattern Recognition Journal\n",
    "authors": [
      "Geri Skenderi",
      "Christian Joppi",
      "Matteo Denitto",
      "Marco Cristani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.09824"
  },
  {
    "id": "arXiv:2109.10554",
    "title": "On Conflict-Free Replicated Data Types and Equivocation in Byzantine  Setups",
    "abstract": "On Conflict-Free Replicated Data Types and Equivocation in Byzantine  Setups",
    "descriptor": "",
    "authors": [
      "Florian Jacob",
      "Saskia Bayreuther",
      "Hannes Hartenstein"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.10554"
  },
  {
    "id": "arXiv:2109.10849",
    "title": "DVC-P: Deep Video Compression with Perceptual Optimizations",
    "abstract": "DVC-P: Deep Video Compression with Perceptual Optimizations",
    "descriptor": "",
    "authors": [
      "Saiping Zhang",
      "Marta Mrak",
      "Luis Herranz",
      "Marc G\u00f3rriz",
      "Shuai Wan",
      "Fuzheng Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2109.10849"
  },
  {
    "id": "arXiv:2109.11532",
    "title": "Many nodal domains in random regular graphs",
    "abstract": "Comments: 18 pages",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Shirshendu Ganguly",
      "Theo McKenzie",
      "Sidhanth Mohanty",
      "Nikhil Srivastava"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)",
      "Mathematical Physics (math-ph)",
      "Combinatorics (math.CO)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2109.11532"
  },
  {
    "id": "arXiv:2109.11673",
    "title": "Modeling calcium dynamics in neurons with endoplasmic reticulum:  existence, uniqueness and an implicit-explicit finite element scheme",
    "abstract": "Comments: 25 pages, 4 figures",
    "descriptor": "\nComments: 25 pages, 4 figures\n",
    "authors": [
      "Qingguang Guan",
      "Gillian Queisser"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.11673"
  },
  {
    "id": "arXiv:2109.11797",
    "title": "CPT: Colorful Prompt Tuning for Pre-trained Vision-Language Models",
    "abstract": "Comments: Work in progress",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Yuan Yao",
      "Ao Zhang",
      "Zhengyan Zhang",
      "Zhiyuan Liu",
      "Tat-Seng Chua",
      "Maosong Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.11797"
  },
  {
    "id": "arXiv:2109.14742",
    "title": "A Convex Method of Generalized State Estimation using Circuit-theoretic  Node-breaker Model",
    "abstract": "A Convex Method of Generalized State Estimation using Circuit-theoretic  Node-breaker Model",
    "descriptor": "",
    "authors": [
      "Shimiao Li",
      "Amritanshu Pandey",
      "Larry Pileggi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2109.14742"
  },
  {
    "id": "arXiv:2109.15163",
    "title": "HSVA: Hierarchical Semantic-Visual Adaptation for Zero-Shot Learning",
    "abstract": "Comments: Accepted by NeurIPS 2021",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Shiming Chen",
      "Guo-Sen Xie",
      "Yang Liu",
      "Qinmu Peng",
      "Baigui Sun",
      "Hao Li",
      "Xinge You",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.15163"
  },
  {
    "id": "arXiv:2110.00236",
    "title": "Simulation-based Evaluation of a Synchronous Transaction Model for  Time-Sensitive Software-Defined Networks",
    "abstract": "Comments: Published in: M. Marek, G. Nardini, V. Vesely (Eds.), Proceedings of the 8th OMNeT++ Community Summit, Virtual Summit, September 8-10, 2021",
    "descriptor": "\nComments: Published in: M. Marek, G. Nardini, V. Vesely (Eds.), Proceedings of the 8th OMNeT++ Community Summit, Virtual Summit, September 8-10, 2021\n",
    "authors": [
      "Tobias Haugg",
      "Mohammad Fazel Soltani",
      "Timo H\u00e4ckel",
      "Philipp Meyer",
      "Franz Korf",
      "Thomas C. Schmidt"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2110.00236"
  },
  {
    "id": "arXiv:2110.00242",
    "title": "Data-Efficient Instance Segmentation with a Single GPU",
    "abstract": "Comments: Technical report",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Pengyu Chen",
      "Wanhua Li",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.00242"
  },
  {
    "id": "arXiv:2110.00577",
    "title": "Reconstruction for Powerful Graph Representations",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Leonardo Cotta",
      "Christopher Morris",
      "Bruno Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.00577"
  },
  {
    "id": "arXiv:2110.00744",
    "title": "Random Subgraph Detection Using Queries",
    "abstract": "Comments: 29 pages",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Wasim Huleihel",
      "Arya Mazumdar",
      "Soumyabrata Pal"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.00744"
  },
  {
    "id": "arXiv:2110.01177",
    "title": "The Second DiCOVA Challenge: Dataset and performance analysis for  COVID-19 diagnosis using acoustics",
    "abstract": "The Second DiCOVA Challenge: Dataset and performance analysis for  COVID-19 diagnosis using acoustics",
    "descriptor": "",
    "authors": [
      "Neeraj Kumar Sharma",
      "Srikanth Raj Chetupalli",
      "Debarpan Bhattacharya",
      "Debottam Dutta",
      "Pravin Mote",
      "Sriram Ganapathy"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2110.01177"
  },
  {
    "id": "arXiv:2110.01191",
    "title": "3D-Transformer: Molecular Representation with Transformer in 3D Space",
    "abstract": "3D-Transformer: Molecular Representation with Transformer in 3D Space",
    "descriptor": "",
    "authors": [
      "Fang Wu",
      "Qiang Zhang",
      "Dragomir Radev",
      "Jiyu Cui",
      "Wen Zhang",
      "Huabin Xing",
      "Ningyu Zhang",
      "Huajun Chen"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.01191"
  },
  {
    "id": "arXiv:2110.01343",
    "title": "Taming singular stochastic differential equations: A numerical method",
    "abstract": "Comments: 63 pages",
    "descriptor": "\nComments: 63 pages\n",
    "authors": [
      "Khoa L\u00ea",
      "Chengcheng Ling"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.01343"
  },
  {
    "id": "arXiv:2110.01351",
    "title": "Towards Time-Optimal Tunnel-Following for Quadrotors",
    "abstract": "Towards Time-Optimal Tunnel-Following for Quadrotors",
    "descriptor": "",
    "authors": [
      "Jon Arrizabalaga",
      "Markus Ryll"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.01351"
  },
  {
    "id": "arXiv:2110.01406",
    "title": "MedPerf: Open Benchmarking Platform for Medical Artificial Intelligence  using Federated Evaluation",
    "abstract": "MedPerf: Open Benchmarking Platform for Medical Artificial Intelligence  using Federated Evaluation",
    "descriptor": "",
    "authors": [
      "Alexandros Karargyris",
      "Renato Umeton",
      "Micah J. Sheller",
      "Alejandro Aristizabal",
      "Johnu George",
      "Srini Bala",
      "Daniel J. Beutel",
      "Victor Bittorf",
      "Akshay Chaudhari",
      "Alexander Chowdhury",
      "Cody Coleman",
      "Bala Desinghu",
      "Gregory Diamos",
      "Debo Dutta",
      "Diane Feddema",
      "Grigori Fursin",
      "Junyi Guo",
      "Xinyuan Huang",
      "David Kanter",
      "Satyananda Kashyap",
      "Nicholas Lane",
      "Indranil Mallick",
      "Pietro Mascagni",
      "Virendra Mehta",
      "Vivek Natarajan",
      "Nikola Nikolov",
      "Nicolas Padoy",
      "Gennady Pekhimenko",
      "Vijay Janapa Reddi",
      "G Anthony Reina",
      "Pablo Ribalta",
      "Jacob Rosenthal",
      "Abhishek Singh",
      "Jayaraman J. Thiagarajan",
      "Anna Wuest",
      "Maria Xenochristou",
      "Daguang Xu",
      "Poonam Yadav",
      "Michael Rosenthal",
      "Massimo Loda",
      "Jason M. Johnson",
      "Peter Mattson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.01406"
  },
  {
    "id": "arXiv:2110.02019",
    "title": "FoodChem: A food-chemical relation extraction model",
    "abstract": "Comments: 8 pages, 3 figures, 2 tables",
    "descriptor": "\nComments: 8 pages, 3 figures, 2 tables\n",
    "authors": [
      "Gjorgjina Cenikj",
      "Barbara Korou\u0161i\u0107 Seljak",
      "Tome Eftimov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02019"
  },
  {
    "id": "arXiv:2110.02168",
    "title": "A Community Roadmap for Scientific Workflows Research and Development",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2103.09181",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2103.09181\n",
    "authors": [
      "Rafael Ferreira da Silva",
      "Henri Casanova",
      "Kyle Chard",
      "Ilkay Altintas",
      "Rosa M Badia",
      "Bartosz Balis",
      "Tain\u00e3 Coleman",
      "Frederik Coppens",
      "Frank Di Natale",
      "Bjoern Enders",
      "Thomas Fahringer",
      "Rosa Filgueira",
      "Grigori Fursin",
      "Daniel Garijo",
      "Carole Goble",
      "Dorran Howell",
      "Shantenu Jha",
      "Daniel S. Katz",
      "Daniel Laney",
      "Ulf Leser",
      "Maciej Malawski",
      "Kshitij Mehta",
      "Lo\u00efc Pottier",
      "Jonathan Ozik",
      "J. Luc Peterson",
      "Lavanya Ramakrishnan",
      "Stian Soiland-Reyes",
      "Douglas Thain",
      "Matthew Wolf"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.02168"
  },
  {
    "id": "arXiv:2110.02334",
    "title": "Exploring Conditional Text Generation for Aspect-Based Sentiment  Analysis",
    "abstract": "Comments: This paper is accepted at the PACLIC35 conference on September 30, 2021. It will be published in November, 2021",
    "descriptor": "\nComments: This paper is accepted at the PACLIC35 conference on September 30, 2021. It will be published in November, 2021\n",
    "authors": [
      "Siva Uday Sampreeth Chebolu",
      "Franck Dernoncourt",
      "Nedim Lipka",
      "Thamar Solorio"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02334"
  },
  {
    "id": "arXiv:2110.02396",
    "title": "An Online Scheduling Algorithm for a Community Energy Storage System",
    "abstract": "Comments: 12 pages, 10 body, 2 supplementary material",
    "descriptor": "\nComments: 12 pages, 10 body, 2 supplementary material\n",
    "authors": [
      "Nathaniel Tucker",
      "Mahnoosh Alizadeh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.02396"
  },
  {
    "id": "arXiv:2110.02554",
    "title": "A Regularized Wasserstein Framework for Graph Kernels",
    "abstract": "Comments: 21st IEEE International Conference on Data Mining (ICDM 2021)",
    "descriptor": "\nComments: 21st IEEE International Conference on Data Mining (ICDM 2021)\n",
    "authors": [
      "Asiri Wijesinghe",
      "Qing Wang",
      "Stephen Gould"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.02554"
  },
  {
    "id": "arXiv:2110.02580",
    "title": "Deep Transfer Learning for Land Use Land Cover Classification: A  Comparative Study",
    "abstract": "Deep Transfer Learning for Land Use Land Cover Classification: A  Comparative Study",
    "descriptor": "",
    "authors": [
      "Raoof Naushad",
      "Tarunpreet Kaur"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02580"
  },
  {
    "id": "arXiv:2110.02627",
    "title": "MovingFashion: a Benchmark for the Video-to-Shop Challenge",
    "abstract": "Comments: Accepted at WACV 2022",
    "descriptor": "\nComments: Accepted at WACV 2022\n",
    "authors": [
      "Marco Godi",
      "Christian Joppi",
      "Geri Skenderi",
      "Marco Cristani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02627"
  },
  {
    "id": "arXiv:2110.02830",
    "title": "Parameterized Algorithms for the Steiner Tree Problem on a Directed  Hypercube",
    "abstract": "Parameterized Algorithms for the Steiner Tree Problem on a Directed  Hypercube",
    "descriptor": "",
    "authors": [
      "Sugyani Mahapatra",
      "Manikandan Narayanan",
      "N S Narayanaswamy",
      "Vijayaragunathan Ramamoorthi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.02830"
  },
  {
    "id": "arXiv:2110.03010",
    "title": "AECMOS: A speech quality assessment metric for echo impairment",
    "abstract": "AECMOS: A speech quality assessment metric for echo impairment",
    "descriptor": "",
    "authors": [
      "Marju Purin",
      "Sten Sootla",
      "Mateja Sponza",
      "Ando Saabas",
      "Ross Cutler"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.03010"
  },
  {
    "id": "arXiv:2110.03111",
    "title": "Cut the CARP: Fishing for zero-shot story evaluation",
    "abstract": "Comments: 9 pages, 4 figures",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Shahbuland Matiana",
      "JR Smith",
      "Ryan Teehan",
      "Louis Castricato",
      "Stella Biderman",
      "Leo Gao",
      "Spencer Frazier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.03111"
  },
  {
    "id": "arXiv:2110.03156",
    "title": "StrengthNet: Deep Learning-based Emotion Strength Assessment for  Emotional Speech Synthesis",
    "abstract": "Comments: Submitted to ICASSP 2022. 5 pages, 3 figures, 1 table. Our codes are available at: this https URL",
    "descriptor": "\nComments: Submitted to ICASSP 2022. 5 pages, 3 figures, 1 table. Our codes are available at: this https URL\n",
    "authors": [
      "Rui Liu",
      "Berrak Sisman",
      "Haizhou Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.03156"
  },
  {
    "id": "arXiv:2110.03215",
    "title": "Towards Continual Knowledge Learning of Language Models",
    "abstract": "Towards Continual Knowledge Learning of Language Models",
    "descriptor": "",
    "authors": [
      "Joel Jang",
      "Seonghyeon Ye",
      "Sohee Yang",
      "Joongbo Shin",
      "Janghoon Han",
      "Gyeonghun Kim",
      "Stanley Jungkyu Choi",
      "Minjoon Seo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03215"
  },
  {
    "id": "arXiv:2110.03224",
    "title": "Darts: User-Friendly Modern Machine Learning for Time Series",
    "abstract": "Comments: Darts Github repository: this https URL",
    "descriptor": "\nComments: Darts Github repository: this https URL\n",
    "authors": [
      "Julien Herzen",
      "Francesco L\u00e4ssig",
      "Samuele Giuliano Piazzetta",
      "Thomas Neuer",
      "L\u00e9o Tafti",
      "Guillaume Raille",
      "Tomas Van Pottelbergh",
      "Marek Pasieka",
      "Andrzej Skrodzki",
      "Nicolas Huguenin",
      "Maxime Dumonal",
      "Jan Ko\u015bcisz",
      "Dennis Bader",
      "Fr\u00e9d\u00e9rick Gusset",
      "Mounir Benheddi",
      "Camila Williamson",
      "Michal Kosinski",
      "Matej Petrik",
      "Ga\u00ebl Grosch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.03224"
  },
  {
    "id": "arXiv:2110.03244",
    "title": "Near-Optimal Reward-Free Exploration for Linear Mixture MDPs with  Plug-in Solver",
    "abstract": "Near-Optimal Reward-Free Exploration for Linear Mixture MDPs with  Plug-in Solver",
    "descriptor": "",
    "authors": [
      "Xiaoyu Chen",
      "Jiachen Hu",
      "Lin F. Yang",
      "Liwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03244"
  },
  {
    "id": "arXiv:2110.03267",
    "title": "Propagating State Uncertainty Through Trajectory Forecasting",
    "abstract": "Comments: 8 pages, 6 figures, 4 tables. Fixed author name",
    "descriptor": "\nComments: 8 pages, 6 figures, 4 tables. Fixed author name\n",
    "authors": [
      "Boris Ivanovic",
      "Yifeng Lin",
      "Shubham Shrivastava",
      "Punarjay Chakravarty",
      "Marco Pavone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03267"
  },
  {
    "id": "arXiv:2110.03323",
    "title": "A Logic-Based Framework for Natural Language Inference in Dutch",
    "abstract": "Comments: 18 pages plus references. Presented in Natural Logic Meets Machine Learning (NaLoMa II) workshop at the 14th International Conference on Computational Semantics (IWCS 2021). Presented in the 31st Meeting of Computational Linguistics in The Netherlands (CLIN31). Submitted for publication in Volume 11 of the CLIN Journal. Code available at this http URL",
    "descriptor": "\nComments: 18 pages plus references. Presented in Natural Logic Meets Machine Learning (NaLoMa II) workshop at the 14th International Conference on Computational Semantics (IWCS 2021). Presented in the 31st Meeting of Computational Linguistics in The Netherlands (CLIN31). Submitted for publication in Volume 11 of the CLIN Journal. Code available at this http URL\n",
    "authors": [
      "Lasha Abzianidze",
      "Konstantinos Kogkalidis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.03323"
  },
  {
    "id": "arXiv:2110.03347",
    "title": "Cloning one's voice using very limited data in the wild",
    "abstract": "Cloning one's voice using very limited data in the wild",
    "descriptor": "",
    "authors": [
      "Dongyang Dai",
      "Yuanzhe Chen",
      "Li Chen",
      "Ming Tu",
      "Lu Liu",
      "Rui Xia",
      "Qiao Tian",
      "Yuping Wang",
      "Yuxuan Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Human-Computer Interaction (cs.HC)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.03347"
  },
  {
    "id": "arXiv:2110.03426",
    "title": "Fast learning from label proportions with small bags",
    "abstract": "Comments: submitted to ICASSP 2022",
    "descriptor": "\nComments: submitted to ICASSP 2022\n",
    "authors": [
      "Denis Baru\u010di\u0107",
      "Jan Kybic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03426"
  },
  {
    "id": "arXiv:2110.03473",
    "title": "Unsupervised Image Decomposition with Phase-Correlation Networks",
    "abstract": "Unsupervised Image Decomposition with Phase-Correlation Networks",
    "descriptor": "",
    "authors": [
      "Angel Villar-Corrales",
      "Sven Behnke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03473"
  },
  {
    "id": "arXiv:2110.03503",
    "title": "Cantilevered, Rectangular Plate Dynamics by Finite Difference Methods",
    "abstract": "Comments: 19 pages, 3 figures",
    "descriptor": "\nComments: 19 pages, 3 figures\n",
    "authors": [
      "Benjamin Brown"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.03503"
  },
  {
    "id": "arXiv:2110.03604",
    "title": "Online Markov Decision Processes with Non-oblivious Strategic Adversary",
    "abstract": "Online Markov Decision Processes with Non-oblivious Strategic Adversary",
    "descriptor": "",
    "authors": [
      "Le Cong Dinh",
      "David Henry Mguni",
      "Long Tran-Thanh",
      "Jun Wang",
      "Yaodong Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.03604"
  },
  {
    "id": "arXiv:2110.03611",
    "title": "Adversarial Retriever-Ranker for dense text retrieval",
    "abstract": "Adversarial Retriever-Ranker for dense text retrieval",
    "descriptor": "",
    "authors": [
      "Hang Zhang",
      "Yeyun Gong",
      "Yelong Shen",
      "Jiancheng Lv",
      "Nan Duan",
      "Weizhu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.03611"
  },
  {
    "id": "arXiv:2110.03625",
    "title": "Time Series Forecasting Using Manifold Learning",
    "abstract": "Time Series Forecasting Using Manifold Learning",
    "descriptor": "",
    "authors": [
      "Panagiotis Papaioannou",
      "Ronen Talmon",
      "Daniela di Serafino",
      "Constantinos Siettos"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.03625"
  }
]
[
  {
    "id": "arXiv:2110.13145",
    "title": "An Embedded System for Image-based Crack Detection by using Fine-Tuning  model of Adaptive Structural Learning of Deep Belief Network",
    "abstract": "Deep learning has been a successful model which can effectively represent\nseveral features of input space and remarkably improve image recognition\nperformance on the deep architectures. In our research, an adaptive structural\nlearning method of Restricted Boltzmann Machine (Adaptive RBM) and Deep Belief\nNetwork (Adaptive DBN) have been developed as a deep learning model. The models\nhave a self-organize function which can discover an optimal number of hidden\nneurons for given input data in a RBM by neuron generation-annihilation\nalgorithm, and can obtain an appropriate number of RBM as hidden layers in the\ntrained DBN. The proposed method was applied to a concrete image benchmark data\nset SDNET 2018 for crack detection. The dataset contains about 56,000 crack\nimages for three types of concrete structures: bridge decks, walls, and paved\nroads. The fine-tuning method of the Adaptive DBN can show 99.7%, 99.7%, and\n99.4% classification accuracy for test dataset of three types of structures. In\nthis paper, our developed Adaptive DBN was embedded to a tiny PC with GPU for\nreal-time inference on a drone. For fast inference, the fine tuning algorithm\nalso removed some inactivated hidden neurons to make a small model and then the\nmodel was able to improve not only classification accuracy but also inference\nspeed simultaneously. The inference speed and running time of portable battery\ncharger were evaluated on three kinds of Nvidia embedded systems; Jetson Nano,\nAGX Xavier, and Xavier NX.",
    "descriptor": "\nComments: 6 pages, 4 figures, 2020 IEEE Region 10 Conference. arXiv admin note: substantial text overlap with arXiv:2110.12700\n",
    "authors": [
      "Shin Kamada",
      "Takumi Ichimura"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13145"
  },
  {
    "id": "arXiv:2110.13146",
    "title": "Fast estimation method for rank of a high-dimensional sparse matrix",
    "abstract": "Numerical computing the rank of a matrix is a fundamental problem in\nscientific computation. The data sets generated by Internet often correspond to\nthe analysis of high-dimensional sparse matrices. Notwithstanding the recent\nadvances in the promotion of traditional singular value decomposition (SVD), an\nefficient estimation algorithm for rank of a high-dimensional sparse matrix is\nstill lacked. Inspired by the controllability theory of complex networks, we\nconverted the rank of a matrix into max-matching computing. Then we established\na fast rank estimation algorithm by using cavity method, a powerful approximate\ntechnique for computing the max-matching, to estimate the rank of a sparse\nmatrix. In the merit of its natural low complexity of cavity method, we showed\nthat the rank of a high-dimensional sparse matrix can be estimated in a much\nfaster way than SVD with high accuracy. Our method offers an efficient pathway\nto fast estimate the rank of the high-dimensional sparse matrix, when the time\ncost of computing the rank by SVD is unacceptable.",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Chen Zhao",
      "Yuqing Liu",
      "Li Hu",
      "Zhengzhong Yuan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.13146"
  },
  {
    "id": "arXiv:2110.13148",
    "title": "As if by magic: self-supervised training of deep despeckling networks  with MERLIN",
    "abstract": "Speckle fluctuations seriously limit the interpretability of synthetic\naperture radar (SAR) images. Speckle reduction has thus been the subject of\nnumerous works spanning at least four decades. Techniques based on deep neural\nnetworks have recently achieved a new level of performance in terms of SAR\nimage restoration quality. Beyond the design of suitable network architectures\nor the selection of adequate loss functions, the construction of training sets\nis of uttermost importance. So far, most approaches have considered a\nsupervised training strategy: the networks are trained to produce outputs as\nclose as possible to speckle-free reference images. Speckle-free images are\ngenerally not available, which requires resorting to natural or optical images\nor the selection of stable areas in long time series to circumvent the lack of\nground truth. Self-supervision, on the other hand, avoids the use of\nspeckle-free images. We introduce a self-supervised strategy based on the\nseparation of the real and imaginary parts of single-look complex SAR images,\ncalled MERLIN (coMplex sElf-supeRvised despeckLINg), and show that it offers a\nstraightforward way to train all kinds of deep despeckling networks. Networks\ntrained with MERLIN take into account the spatial correlations due to the SAR\ntransfer function specific to a given sensor and imaging mode. By requiring\nonly a single image, and possibly exploiting large archives, MERLIN opens the\ndoor to hassle-free as well as large-scale training of despeckling networks.\nThe code of the trained models is made freely available at\nhttps://gitlab.telecom-paris.fr/RING/MERLIN.",
    "descriptor": "\nComments: This article is currently under review in IEEE Transactions on Geoscience and Remote Sensing\n",
    "authors": [
      "Emanuele Dalsasso",
      "Lo\u00efc Denis",
      "Florence Tupin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.13148"
  },
  {
    "id": "arXiv:2110.13179",
    "title": "Probabilistic Hierarchical Forecasting with Deep Poisson Mixtures",
    "abstract": "Hierarchical forecasting problems arise when time series compose a group\nstructure that naturally defines aggregation and disaggregation coherence\nconstraints for the predictions. In this work, we explore a new forecast\nrepresentation, the Poisson Mixture Mesh (PMM), that can produce probabilistic,\ncoherent predictions; it is compatible with the neural forecasting innovations,\nand defines simple aggregation and disaggregation rules capable of\naccommodating hierarchical structures, unknown during its optimization. We\nperformed an empirical evaluation to compare the PMM \\ to other hierarchical\nforecasting methods on Australian domestic tourism data, where we obtain a 20\npercent relative improvement.",
    "descriptor": "",
    "authors": [
      "Kin G. Olivares",
      "Nganba Meetei",
      "Ruijun Ma",
      "Rohan Reddy",
      "Mengfei Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13179"
  },
  {
    "id": "arXiv:2110.13185",
    "title": "Generalized Multi-Task Learning from Substantially Unlabeled  Multi-Source Medical Image Data",
    "abstract": "Deep learning-based models, when trained in a fully-supervised manner, can be\neffective in performing complex image analysis tasks, although contingent upon\nthe availability of large labeled datasets. Especially in the medical imaging\ndomain, however, expert image annotation is expensive, time-consuming, and\nprone to variability. Semi-supervised learning from limited quantities of\nlabeled data has shown promise as an alternative. Maximizing knowledge gains\nfrom copious unlabeled data benefits semi-supervised learning models. Moreover,\nlearning multiple tasks within the same model further improves its\ngeneralizability. We propose MultiMix, a new multi-task learning model that\njointly learns disease classification and anatomical segmentation in a\nsemi-supervised manner, while preserving explainability through a novel\nsaliency bridge between the two tasks. Our experiments with varying quantities\nof multi-source labeled data in the training sets confirm the effectiveness of\nMultiMix in the simultaneous classification of pneumonia and segmentation of\nthe lungs in chest X-ray images. Moreover, both in-domain and cross-domain\nevaluations across these tasks further showcase the potential of our model to\nadapt to challenging generalization scenarios.",
    "descriptor": "\nComments: Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) this https URL\n",
    "authors": [
      "Ayaan Haque",
      "Abdullah-Al-Zubaer Imran",
      "Adam Wang",
      "Demetri Terzopoulos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13185"
  },
  {
    "id": "arXiv:2110.13187",
    "title": "Data intensive physics analysis in Azure cloud",
    "abstract": "The Compact Muon Solenoid (CMS) experiment at the Large Hadron Collider (LHC)\nis one of the largest data producers in the scientific world, with standard\ndata products centrally produced, and then used by often competing teams within\nthe collaboration. This work is focused on how a local institution, University\nof California San Diego (UCSD), partnered with the Open Science Grid (OSG) to\nuse Azure cloud resources to augment its available computing to accelerate time\nto results for multiple analyses pursued by a small group of collaborators. The\nOSG is a federated infrastructure allowing many independent resource providers\nto serve many independent user communities in a transparent manner.\nHistorically the resources would come from various research institutions,\nspanning small universities to large HPC centers, based on either community\nneeds or grant allocations, so adding commercial clouds as resource providers\nis a natural evolution. The OSG technology allows for easy integration of cloud\nresources, but the data-intensive nature of CMS compute jobs required the\ndeployment of additional data caching infrastructure to ensure high efficiency.",
    "descriptor": "\nComments: 11 pages, 5 figures, to be published in proceedings of ICOCBI 2021\n",
    "authors": [
      "Igor Sfiligoi",
      "Frank W\u00fcrthwein",
      "Diego Davila"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.13187"
  },
  {
    "id": "arXiv:2110.13188",
    "title": "Multi-Task Meta-Learning Modification with Stochastic Approximation",
    "abstract": "Meta-learning methods aim to build learning algorithms capable of quickly\nadapting to new tasks in low-data regime. One of the main benchmarks of such an\nalgorithms is a few-shot learning problem. In this paper we investigate the\nmodification of standard meta-learning pipeline that takes a multi-task\napproach during training. The proposed method simultaneously utilizes\ninformation from several meta-training tasks in a common loss function. The\nimpact of each of these tasks in the loss function is controlled by the\ncorresponding weight. Proper optimization of these weights can have a big\ninfluence on training of the entire model and might improve the quality on test\ntime tasks. In this work we propose and investigate the use of methods from the\nfamily of simultaneous perturbation stochastic approximation (SPSA) approaches\nfor meta-train tasks weights optimization. We have also compared the proposed\nalgorithms with gradient-based methods and found that stochastic approximation\ndemonstrates the largest quality boost in test time. Proposed multi-task\nmodification can be applied to almost all methods that use meta-learning\npipeline. In this paper we study applications of this modification on\nPrototypical Networks and Model-Agnostic Meta-Learning algorithms on CIFAR-FS,\nFC100, tieredImageNet and miniImageNet few-shot learning benchmarks. During\nthese experiments, multi-task modification has demonstrated improvement over\noriginal methods. The proposed SPSA-Tracking algorithm shows the largest\naccuracy boost. Our code is available online.",
    "descriptor": "",
    "authors": [
      "Andrei Boiarov",
      "Konstantin Khabarlak",
      "Igor Yastrebov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13188"
  },
  {
    "id": "arXiv:2110.13189",
    "title": "Spectral unmixing of Raman microscopic images of single human cells  using Independent Component Analysis",
    "abstract": "Application of independent component analysis (ICA) as an unmixing and image\nclustering technique for high spatial resolution Raman maps is reported. A\nhyperspectral map of a fixed human cell was collected by a Raman micro\nspectrometer in a raster pattern on a 0.5um grid. Unlike previously used\nunsupervised machine learning techniques such as principal component analysis,\nICA is based on non-Gaussianity and statistical independence of data which is\nthe case for mixture Raman spectra. Hence, ICA is a great candidate for\nassembling pseudo-colour maps from the spectral hypercube of Raman spectra. Our\nexperimental results revealed that ICA is capable of reconstructing false\ncolour maps of Raman hyperspectral data of human cells, showing the nuclear\nregion constituents as well as subcellular organelle in the cytoplasm and\ndistribution of mitochondria in the perinuclear region. Minimum preprocessing\nrequirements and label-free nature of the ICA method make it a great unmixed\nmethod for extraction of endmembers in Raman hyperspectral maps of living\ncells.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "M. Hamed Mozaffari",
      "Li-Lin Tay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.13189"
  },
  {
    "id": "arXiv:2110.13194",
    "title": "Covariance-Generalized Matching Component Analysis for Data Fusion and  Transfer Learning",
    "abstract": "In order to allow for the encoding of additional statistical information in\ndata fusion and transfer learning applications, we introduce a generalized\ncovariance constraint for the matching component analysis (MCA) transfer\nlearning technique. After proving a semi-orthogonally constrained trace\nmaximization lemma, we develop a closed-form solution to the resulting\ncovariance-generalized optimization problem and provide an algorithm for its\ncomputation. We call this technique -- applicable to both data fusion and\ntransfer learning -- covariance-generalized MCA (CGMCA).",
    "descriptor": "",
    "authors": [
      "Nick Lorenzo",
      "Sean O'Rourke",
      "Theresa Scarnati"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.13194"
  },
  {
    "id": "arXiv:2110.13197",
    "title": "Nested Graph Neural Networks",
    "abstract": "Graph neural network (GNN)'s success in graph classification is closely\nrelated to the Weisfeiler-Lehman (1-WL) algorithm. By iteratively aggregating\nneighboring node features to a center node, both 1-WL and GNN obtain a node\nrepresentation that encodes a rooted subtree around the center node. These\nrooted subtree representations are then pooled into a single representation to\nrepresent the whole graph. However, rooted subtrees are of limited\nexpressiveness to represent a non-tree graph. To address it, we propose Nested\nGraph Neural Networks (NGNNs). NGNN represents a graph with rooted subgraphs\ninstead of rooted subtrees, so that two graphs sharing many identical subgraphs\n(rather than subtrees) tend to have similar representations. The key is to make\neach node representation encode a subgraph around it more than a subtree. To\nachieve this, NGNN extracts a local subgraph around each node and applies a\nbase GNN to each subgraph to learn a subgraph representation. The whole-graph\nrepresentation is then obtained by pooling these subgraph representations. We\nprovide a rigorous theoretical analysis showing that NGNN is strictly more\npowerful than 1-WL. In particular, we proved that NGNN can discriminate almost\nall r-regular graphs, where 1-WL always fails. Moreover, unlike other more\npowerful GNNs, NGNN only introduces a constant-factor higher time complexity\nthan standard GNNs. NGNN is a plug-and-play framework that can be combined with\nvarious base GNNs. We test NGNN with different base GNNs on several benchmark\ndatasets. NGNN uniformly improves their performance and shows highly\ncompetitive performance on all datasets.",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Muhan Zhang",
      "Pan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13197"
  },
  {
    "id": "arXiv:2110.13200",
    "title": "Support Recovery Guarantees for Periodic Signals with Nested Periodic  Dictionaries",
    "abstract": "Periodic signals composed of periodic mixtures admit sparse representations\nin nested periodic dictionaries (NPDs). Therefore, their underlying hidden\nperiods can be estimated by recovering the exact support of said\nrepresentations. In this paper, support recovery guarantees of such signals are\nderived both in noise-free and noisy settings. While exact recovery conditions\nhave long been studied in the theory of compressive sensing, existing\nconditions fall short of yielding meaningful achievability regions in the\ncontext of periodic signals with sparse representations in NPDs, in part since\nexisting bounds do not capture structures intrinsic to these dictionaries. We\nleverage known properties of NPDs to derive several conditions for exact sparse\nrecovery of periodic mixtures in the noise-free setting. These conditions rest\non newly introduced notions of nested periodic coherence and restricted\ncoherence, which can be efficiently computed and verified. In the presence of\nnoise, we obtain improved conditions for recovering the exact support set of\nthe sparse representation of the periodic mixture via orthogonal matching\npursuit based on the introduced notions of coherence. The theoretical findings\nare corroborated using numerical experiments for different families of NPDs.\nOur results show significant improvement over generic recovery bounds as the\nconditions hold over a larger range of sparsity levels.",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Pouria Saidi",
      "George K. Atia"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.13200"
  },
  {
    "id": "arXiv:2110.13202",
    "title": "Transportation Scenario Planning with Graph Neural Networks",
    "abstract": "Providing efficient human mobility services and infrastructure is one of the\nmajor concerns of most mid-sized to large cities around the world. A proper\nunderstanding of the dynamics of commuting flows is, therefore, a requisite to\nbetter plan urban areas. In this context, an important task is to study\nhypothetical scenarios in which possible future changes are evaluated. For\ninstance, how the increase in residential units or transportation modes in a\nneighborhood will change the commuting flows to or from that region? In this\npaper, we propose to leverage GMEL, a recently introduced graph neural network\nmodel, to evaluate changes in commuting flows taking into account different\nland use and infrastructure scenarios. We validate the usefulness of our\nmethodology through real-world case studies set in two large cities in Brazil.",
    "descriptor": "\nComments: Presented at the 10th International Workshop on Urban Computing, 2021\n",
    "authors": [
      "Ana Alice Peregrino",
      "Soham Pradhan",
      "Zhicheng Liu",
      "Nivan Ferreira",
      "Fabio Miranda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.13202"
  },
  {
    "id": "arXiv:2110.13205",
    "title": "A Probabilistic Framework for Knowledge Graph Data Augmentation",
    "abstract": "We present NNMFAug, a probabilistic framework to perform data augmentation\nfor the task of knowledge graph completion to counter the problem of data\nscarcity, which can enhance the learning process of neural link predictors. Our\nmethod can generate potentially diverse triples with the advantage of being\nefficient and scalable as well as agnostic to the choice of the link prediction\nmodel and dataset used. Experiments and analysis done on popular models and\nbenchmarks show that NNMFAug can bring notable improvements over the baselines.",
    "descriptor": "",
    "authors": [
      "Jatin Chauhan",
      "Priyanshu Gupta",
      "Pasquale Minervini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13205"
  },
  {
    "id": "arXiv:2110.13211",
    "title": "Investigating the Perceived Precision and validity of a Field-Deployable  Machine Learning-based Tool to Detect Post-Traumatic Stress Disorder (PTSD)  Hyperarousal Events",
    "abstract": "Post Traumatic Stress Disorder is a psychiatric condition experienced by\nindividuals after exposure to a traumatic event. Prior work has shown promise\nin detecting PTSD using physiological data such as heart rate. Despite the\npromise shown by the machine learning based algorithms for PTSD, the validation\napproaches used in previous research largely rely on theoretical and\ncomputational validation methods rather than naturalistic evaluations that\naccount for users perceived precision and validity. Previous research has shown\nthat users perceptions of physiological changes may not always align well with\nautomated detection of such variables and such misalignment may lead to\ndistrust in automated detection which may affect adoption or sustainable usage\nof such technologies. Therefore, the goal of this article is to investigate the\nperceived precision of the PTSD hyperarousal detection tool (developed\npreviously) in a home study with a group of PTSD patients. Naturalistic\nevaluation of such data driven algorithms may provide foundational insight into\nthe efficacy of such tools for non intrusive and cost efficient remote\nmonitoring of PTSD symptoms and will pave the way for their future adoption and\nsustainable use. The results showed over sixty five percent of perceived\nprecision in naturalistic validation of the detection tool. Further, the\nresults indicated that longitudinal exposure to the detection tool might\ncalibrate users trust in automation.",
    "descriptor": "\nComments: 36 pages, 4 figures\n",
    "authors": [
      "Mahnoosh Sadeghi",
      "Farzan Sasangohar",
      "Anthony D McDonald"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.13211"
  },
  {
    "id": "arXiv:2110.13212",
    "title": "A machine learning method for real-time numerical simulations of cardiac  electromechanics",
    "abstract": "We propose a machine learning-based method to build a system of differential\nequations that approximates the dynamics of 3D electromechanical models for the\nhuman heart, accounting for the dependence on a set of parameters.\nSpecifically, our method permits to create a reduced-order model (ROM), written\nas a system of Ordinary Differential Equations (ODEs) wherein the forcing term,\ngiven by the right-hand side, consists of an Artificial Neural Network (ANN),\nthat possibly depends on a set of parameters associated with the\nelectromechanical model to be surrogated. This method is non-intrusive, as it\nonly requires a collection of pressure and volume transients obtained from the\nfull-order model (FOM) of cardiac electromechanics. Once trained, the ANN-based\nROM can be coupled with hemodynamic models for the blood circulation external\nto the heart, in the same manner as the original electromechanical model, but\nat a dramatically lower computational cost. Indeed, our method allows for\nreal-time numerical simulations of the cardiac function. We demonstrate the\neffectiveness of the proposed method on two relevant contexts in cardiac\nmodeling. First, we employ the ANN-based ROM to perform a global sensitivity\nanalysis on both the electromechanical and hemodynamic models. Second, we\nperform a Bayesian estimation of two parameters starting from noisy\nmeasurements of two scalar outputs. In both these cases, replacing the FOM of\ncardiac electromechanics with the ANN-based ROM makes it possible to perform in\na few hours of computational time all the numerical simulations that would be\notherwise unaffordable, because of their overwhelming computational cost, if\ncarried out with the FOM. As a matter of fact, our ANN-based ROM is able to\nspeedup the numerical simulations by more than three orders of magnitude.",
    "descriptor": "",
    "authors": [
      "Francesco Regazzoni",
      "Matteo Salvador",
      "Luca Ded\u00e8",
      "Alfio Quarteroni"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2110.13212"
  },
  {
    "id": "arXiv:2110.13213",
    "title": "Findings from Experiments of On-line Joint Reinforcement Learning of  Semantic Parser and Dialogue Manager with real Users",
    "abstract": "Design of dialogue systems has witnessed many advances lately, yet acquiring\nhuge set of data remains an hindrance to their fast development for a new task\nor language. Besides, training interactive systems with batch data is not\nsatisfactory. On-line learning is pursued in this paper as a convenient way to\nalleviate these difficulties. After the system modules are initiated, a single\nprocess handles data collection, annotation and use in training algorithms. A\nnew challenge is to control the cost of the on-line learning borne by the user.\nOur work focuses on learning the semantic parsing and dialogue management\nmodules (speech recognition and synthesis offer ready-for-use solutions). In\nthis context we investigate several variants of simultaneous learning which are\ntested in user trials. In our experiments, with varying merits, they can all\nachieve good performance with only a few hundreds of training dialogues and\noverstep a handcrafted system. The analysis of these experiments gives us some\ninsights, discussed in the paper, into the difficulty for the system's trainers\nto establish a coherent and constant behavioural strategy to enable a fast and\ngood-quality training phase.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1810.00924\n",
    "authors": [
      "Matthieu Riou",
      "Bassam Jabaian",
      "St\u00e9phane Huet",
      "Fabrice Lef\u00e8vre"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.13213"
  },
  {
    "id": "arXiv:2110.13214",
    "title": "IconQA: A New Benchmark for Abstract Diagram Understanding and Visual  Language Reasoning",
    "abstract": "Current visual question answering (VQA) tasks mainly consider answering\nhuman-annotated questions for natural images. However, aside from natural\nimages, abstract diagrams with semantic richness are still understudied in\nvisual understanding and reasoning research. In this work, we introduce a new\nchallenge of Icon Question Answering (IconQA) with the goal of answering a\nquestion in an icon image context. We release IconQA, a large-scale dataset\nthat consists of 107,439 questions and three sub-tasks: multi-image-choice,\nmulti-text-choice, and filling-in-the-blank. The IconQA dataset is inspired by\nreal-world diagram word problems that highlight the importance of abstract\ndiagram understanding and comprehensive cognitive reasoning. Thus, IconQA\nrequires not only perception skills like object recognition and text\nunderstanding, but also diverse cognitive reasoning skills, such as geometric\nreasoning, commonsense reasoning, and arithmetic reasoning. To facilitate\npotential IconQA models to learn semantic representations for icon images, we\nfurther release an icon dataset Icon645 which contains 645,687 colored icons on\n377 classes. We conduct extensive user studies and blind experiments and\nreproduce a wide range of advanced VQA methods to benchmark the IconQA task.\nAlso, we develop a strong IconQA baseline Patch-TRM that applies a pyramid\ncross-modal Transformer with input diagram embeddings pre-trained on the icon\ndataset. IconQA and Icon645 are available at https://iconqa.github.io.",
    "descriptor": "\nComments: Accepted to NeurIPS 2021 Track on Datasets and Benchmarks, 27 pages, 18 figures, project available at this https URL\n",
    "authors": [
      "Pan Lu",
      "Liang Qiu",
      "Jiaqi Chen",
      "Tony Xia",
      "Yizhou Zhao",
      "Wei Zhang",
      "Zhou Yu",
      "Xiaodan Liang",
      "Song-Chun Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13214"
  },
  {
    "id": "arXiv:2110.13220",
    "title": "Demystifying and Generalizing BinaryConnect",
    "abstract": "BinaryConnect (BC) and its many variations have become the de facto standard\nfor neural network quantization. However, our understanding of the inner\nworkings of BC is still quite limited. We attempt to close this gap in four\ndifferent aspects: (a) we show that existing quantization algorithms, including\npost-training quantization, are surprisingly similar to each other; (b) we\nargue for proximal maps as a natural family of quantizers that is both easy to\ndesign and analyze; (c) we refine the observation that BC is a special case of\ndual averaging, which itself is a special case of the generalized conditional\ngradient algorithm; (d) consequently, we propose ProxConnect (PC) as a\ngeneralization of BC and we prove its convergence properties by exploiting the\nestablished connections. We conduct experiments on CIFAR-10 and ImageNet, and\nverify that PC achieves competitive performance.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Tim Dockhorn",
      "Yaoliang Yu",
      "Eyy\u00fcb Sari",
      "Mahdi Zolnouri",
      "Vahid Partovi Nia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.13220"
  },
  {
    "id": "arXiv:2110.13221",
    "title": "Prediction-focused Mixture Models",
    "abstract": "In several applications, besides getting a generative model of the data, we\nalso want the model to be useful for specific downstream tasks. Mixture models\nare useful for identifying discrete components in the data, but may not\nidentify components useful for downstream tasks if misspecified; further,\ncurrent inference techniques often fail to overcome misspecification even when\na supervisory signal is provided. We introduce the prediction-focused mixture\nmodel, which selects and models input features relevant to predicting the\ntargets. We demonstrate that our approach identifies relevant signal from\ninputs even when the model is highly misspecified.",
    "descriptor": "\nComments: 9 pages, 3 figures; accepted at ICML 2021 Workshop on Information-Theoretic Methods for Rigorous, Responsible, and Reliable Machine Learning\n",
    "authors": [
      "Sanjana Narayanan",
      "Abhishek Sharma",
      "Catherine Zeng",
      "Finale Doshi-Velez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.13221"
  },
  {
    "id": "arXiv:2110.13223",
    "title": "Identifying and Benchmarking Natural Out-of-Context Prediction Problems",
    "abstract": "Deep learning systems frequently fail at out-of-context (OOC) prediction, the\nproblem of making reliable predictions on uncommon or unusual inputs or\nsubgroups of the training distribution. To this end, a number of benchmarks for\nmeasuring OOC performance have recently been introduced. In this work, we\nintroduce a framework unifying the literature on OOC performance measurement,\nand demonstrate how rich auxiliary information can be leveraged to identify\ncandidate sets of OOC examples in existing datasets. We present NOOCh: a suite\nof naturally-occurring \"challenge sets\", and show how varying notions of\ncontext can be used to probe specific OOC failure modes. Experimentally, we\nexplore the tradeoffs between various learning approaches on these challenge\nsets and demonstrate how the choices made in designing OOC benchmarks can yield\nvarying conclusions.",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "David Madras",
      "Richard Zemel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13223"
  },
  {
    "id": "arXiv:2110.13224",
    "title": "Transformations for Piola-mapped elements",
    "abstract": "The Arnold-Winther element successfully discretizes the Hellinger-Reissner\nvariational formulation of linear elasticity; its development was one of the\nkey early breakthroughs of the finite element exterior calculus. Despite its\ngreat utility, it is not available in standard finite element software, because\nits degrees of freedom are not preserved under the standard Piola push-forward.\nIn this work we apply the novel transformation theory recently developed by\nKirby [SMAI-JCM, 4:197-224, 2018] to devise the correct map for transforming\nthe basis on a reference cell to a generic physical triangle. This enables the\nuse of the Arnold-Winther elements, both conforming and nonconforming, in the\nwidely-used Firedrake finite element software, composing with its advanced\nsymbolic code generation and geometric multigrid functionality. Similar results\nalso enable the correct transformation of the Mardal-Tai-Winther element for\nincompressible fluid flow. We present numerical results for both elements,\nverifying the correctness of our theory.",
    "descriptor": "\nComments: Submitted to SMAI Journal of Computational Mathematics\n",
    "authors": [
      "Francis Aznaran",
      "Robert Kirby",
      "Patrick Farrell"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.13224"
  },
  {
    "id": "arXiv:2110.13228",
    "title": "Variational framework for partially-measured physical system control:  examples of vision neuroscience and optical random media",
    "abstract": "To characterize a physical system to behave as desired, either its underlying\ngoverning rules must be known a priori or the system itself be accurately\nmeasured. The complexity of full measurements of the system scales with its\nsize. When exposed to real-world conditions, such as perturbations or\ntime-varying settings, the system calibrated for a fixed working condition\nmight require non-trivial re-calibration, a process that could be prohibitively\nexpensive, inefficient and impractical for real-world use cases. In this work,\nwe propose a learning procedure to obtain a desired target output from a\nphysical system. We use Variational Auto-Encoders (VAE) to provide a generative\nmodel of the system function and use this model to obtain the required input of\nthe system that produces the target output. We showcase the applicability of\nour method for two datasets in optical physics and neuroscience.",
    "descriptor": "",
    "authors": [
      "Babak Rahmani",
      "Demetri Psaltis",
      "Christophe Moser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.13228"
  },
  {
    "id": "arXiv:2110.13229",
    "title": "Distributionally Robust Recurrent Decoders with Random Network  Distillation",
    "abstract": "Neural machine learning models can successfully model language that is\nsimilar to their training distribution, but they are highly susceptible to\ndegradation under distribution shift, which occurs in many practical\napplications when processing out-of-domain (OOD) text. This has been attributed\nto \"shortcut learning\": relying on weak correlations over arbitrary large\ncontexts.\nWe propose a method based on OOD detection with Random Network Distillation\nto allow an autoregressive language model to automatically disregard OOD\ncontext during inference, smoothly transitioning towards a less expressive but\nmore robust model as the data becomes more OOD while retaining its full context\ncapability when operating in-distribution. We apply our method to a GRU\narchitecture, demonstrating improvements on multiple language modeling (LM)\ndatasets.",
    "descriptor": "\nComments: 8 pages, 1 figure\n",
    "authors": [
      "Antonio Valerio Miceli-Barone",
      "Alexandra Birch",
      "Rico Sennrich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.13229"
  },
  {
    "id": "arXiv:2110.13231",
    "title": "Improving the Diversity of Unsupervised Paraphrasing with Embedding  Outputs",
    "abstract": "We present a novel technique for zero-shot paraphrase generation. The key\ncontribution is an end-to-end multilingual paraphrasing model that is trained\nusing translated parallel corpora to generate paraphrases into \"meaning spaces\"\n-- replacing the final softmax layer with word embeddings. This architectural\nmodification, plus a training procedure that incorporates an autoencoding\nobjective, enables effective parameter sharing across languages for more fluent\nmonolingual rewriting, and facilitates fluency and diversity in generation. Our\ncontinuous-output paraphrase generation models outperform zero-shot\nparaphrasing baselines when evaluated on two languages using a battery of\ncomputational metrics as well as in human assessment.",
    "descriptor": "",
    "authors": [
      "Monisha Jegadeesan",
      "Sachin Kumar",
      "John Wieting",
      "Yulia Tsvetkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.13231"
  },
  {
    "id": "arXiv:2110.13233",
    "title": "Decomposed Inductive Procedure Learning",
    "abstract": "Recent advances in machine learning have made it possible to train\nartificially intelligent agents that perform with super-human accuracy on a\ngreat diversity of complex tasks. However, the process of training these\ncapabilities often necessitates millions of annotated examples -- far more than\nhumans typically need in order to achieve a passing level of mastery on similar\ntasks. Thus, while contemporary methods in machine learning can produce agents\nthat exhibit super-human performance, their rate of learning per opportunity in\nmany domains is decidedly lower than human-learning. In this work we formalize\na theory of Decomposed Inductive Procedure Learning (DIPL) that outlines how\ndifferent forms of inductive symbolic learning can be used in combination to\nbuild agents that learn educationally relevant tasks such as mathematical, and\nscientific procedures, at a rate similar to human learners. We motivate the\nconstruction of this theory along Marr's concepts of the computational,\nalgorithmic, and implementation levels of cognitive modeling, and outline at\nthe computational-level six learning capacities that must be achieved to\naccurately model human learning. We demonstrate that agents built along the\nDIPL theory are amenable to satisfying these capacities, and demonstrate, both\nempirically and theoretically, that DIPL enables the creation of agents that\nexhibit human-like learning performance.",
    "descriptor": "\nComments: 38 pages, 7 figures, submitted to Journal of Artificial Intelligence\n",
    "authors": [
      "Daniel Weitekamp",
      "Christopher MacLellan",
      "Erik Harpstead",
      "Kenneth Koedinger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13233"
  },
  {
    "id": "arXiv:2110.13234",
    "title": "Let's Wait Awhile: How Temporal Workload Shifting Can Reduce Carbon  Emissions in the Cloud",
    "abstract": "Depending on energy sources and demand, the carbon intensity of the public\npower grid fluctuates over time. Exploiting this variability is an important\nfactor in reducing the emissions caused by data centers. However, regional\ndifferences in the availability of low-carbon energy sources make it hard to\nprovide general best practices for when to consume electricity. Moreover,\nexisting research in this domain focuses mostly on carbon-aware workload\nmigration across geo-distributed data centers, or addresses demand response\npurely from the perspective of power grid stability and costs.\nIn this paper, we examine the potential impact of shifting computational\nworkloads towards times where the energy supply is expected to be less\ncarbon-intensive. To this end, we identify characteristics of delay-tolerant\nworkloads and analyze the potential for temporal workload shifting in Germany,\nGreat Britain, France, and California over the year 2020. Furthermore, we\nexperimentally evaluate two workload shifting scenarios in a simulation to\ninvestigate the influence of time constraints, scheduling strategies, and the\naccuracy of carbon intensity forecasts. To accelerate research in the domain of\ncarbon-aware computing and to support the evaluation of novel scheduling\nalgorithms, our simulation framework and datasets are publicly available.",
    "descriptor": "\nComments: To be published in the proceedings of the 22nd International Middleware Conference (Middleware '21), December 6-10, 2021, Virtual Event, Canada\n",
    "authors": [
      "Philipp Wiesner",
      "Ilja Behnke",
      "Dominik Scheinert",
      "Kordian Gontarska",
      "Lauritz Thamsen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.13234"
  },
  {
    "id": "arXiv:2110.13239",
    "title": "An Uncertainty Principle is a Price of Privacy-Preserving Microdata",
    "abstract": "Privacy-protected microdata are often the desired output of a differentially\nprivate algorithm since microdata is familiar and convenient for downstream\nusers. However, there is a statistical price for this kind of convenience. We\nshow that an uncertainty principle governs the trade-off between accuracy for a\npopulation of interest (\"sum query\") vs. accuracy for its component\nsub-populations (\"point queries\"). Compared to differentially private query\nanswering systems that are not required to produce microdata, accuracy can\ndegrade by a logarithmic factor. For example, in the case of pure differential\nprivacy, without the microdata requirement, one can provide noisy answers to\nthe sum query and all point queries while guaranteeing that each answer has\nsquared error $O(1/\\epsilon^2)$. With the microdata requirement, one must\nchoose between allowing an additional $\\log^2(d)$ factor ($d$ is the number of\npoint queries) for some point queries or allowing an extra $O(d^2)$ factor for\nthe sum query. We present lower bounds for pure, approximate, and concentrated\ndifferential privacy. We propose mitigation strategies and create a collection\nof benchmark datasets that can be used for public study of this problem.",
    "descriptor": "\nComments: Preprint of NeurIPS 2021 paper\n",
    "authors": [
      "John Abowd",
      "Robert Ashmead",
      "Ryan Cumings-Menon",
      "Simson Garfinkel",
      "Daniel Kifer",
      "Philip Leclerc",
      "William Sexton",
      "Ashley Simpson",
      "Christine Task",
      "Pavel Zhuravlev"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.13239"
  },
  {
    "id": "arXiv:2110.13241",
    "title": "Multitask Adaptation by Retrospective Exploration with Learned World  Models",
    "abstract": "Model-based reinforcement learning (MBRL) allows solving complex tasks in a\nsample-efficient manner. However, no information is reused between the tasks.\nIn this work, we propose a meta-learned addressing model called RAMa that\nprovides training samples for the MBRL agent taken from continuously growing\ntask-agnostic storage. The model is trained to maximize the expected agent's\nperformance by selecting promising trajectories solving prior tasks from the\nstorage. We show that such retrospective exploration can accelerate the\nlearning process of the MBRL agent by better informing learned dynamics and\nprompting agent with exploratory trajectories. We test the performance of our\napproach on several domains from the DeepMind control suite, from Metaworld\nmultitask benchmark, and from our bespoke environment implemented with a\nrobotic NVIDIA Isaac simulator to test the ability of the model to act in a\nphotorealistic, ray-traced environment.",
    "descriptor": "",
    "authors": [
      "Artem Zholus",
      "Aleksandr I. Panov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13241"
  },
  {
    "id": "arXiv:2110.13242",
    "title": "2D Grid Map Generation for Deep-Learning-based Navigation Approaches",
    "abstract": "In the last decade, autonomous navigation for roboticshas been leveraged by\ndeep learning and other approachesbased on machine learning. These approaches\nhave demon-strated significant advantages in robotics performance. Butthey have\nthe disadvantage that they require a lot of data toinfer knowledge. In this\npaper, we present an algorithm forbuilding 2D maps with attributes that make\nthem useful fortraining and testing machine-learning-based approaches.The maps\nare based on dungeons environments where sev-eral random rooms are built and\nthen those rooms are con-nected. In addition, we provide a dataset with 10,000\nmapsproduced by the proposed algorithm and a description withextensive\ninformation for algorithm evaluation. Such infor-mation includes validation of\npath existence, the best path,distances, among other attributes. We believe\nthat thesemaps and their related information can be very useful forrobotics\nenthusiasts and researchers who want to test deeplearning approaches. The\ndataset is available athttps://github.com/gbriel21/map2D_dataSet.git",
    "descriptor": "\nComments: 6 pages, 4 figures, conference, dataset\n",
    "authors": [
      "Gabriel O. Flores-Aquino",
      "Jheison Duvier D\u00edaz Ortega",
      "Ricardo Yahir Almazan Arvizu",
      "Ra\u00fal L\u00f3pez Mu\u00f1oz",
      "O. Octavio Gutierrez-Frias",
      "J. Irving Vasquez-Gomez"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.13242"
  },
  {
    "id": "arXiv:2110.13244",
    "title": "DeepHelp: Deep Learning for Shout Crisis Text Conversations",
    "abstract": "The Shout Crisis Text Line provides individuals undergoing mental health\ncrises an opportunity to have an anonymous text message conversation with a\ntrained Crisis Volunteer (CV). This project partners with Shout and its parent\norganisation, Mental Health Innovations, to explore the applications of Machine\nLearning in understanding Shout's conversations and improving its service. The\noverarching aim of this project is to develop a proof-of-concept model to\ndemonstrate the potential of applying deep learning to crisis text messages.\nSpecifically, this project aims to use deep learning to (1) predict an\nindividual's risk of suicide or self-harm, (2) assess conversation success and\nCV skill using robust metrics, and (3) extrapolate demographic information from\na texter survey to conversations where the texter did not complete the survey.\nTo these ends, contributions to deep learning include a modified\nTransformer-over-BERT model; a framework for multitask learning to improve\ngeneralisation in the presence of sparse labels; and a mathematical model for\nusing imperfect machine learning models to estimate population parameters from\na biased training set.\nKey results include a deep learning model with likely better performance at\npredicting suicide risk than trained CVs and the ability to predict whether a\ntexter is 21 or under with 88.4% accuracy. We produce three metrics for\nconversation success and evaluate the validity and usefulness for each.\nFinally, reversal of participation bias provides evidence that women, who make\nup 80.3% of conversations with an associated texter survey, make up closer to\n73.5%- 74.8% of all conversations; and that if, after every conversation, the\ntexter had shared whether they found their conversation helpful, affirmative\nanswers would fall from 85.1% to 45.45% - 46.51%.",
    "descriptor": "\nComments: 81 pages\n",
    "authors": [
      "Daniel Cahn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.13244"
  },
  {
    "id": "arXiv:2110.13246",
    "title": "Adaptive maximum power point tracking using neural networks for a  photovoltaic systems according grid",
    "abstract": "Introduction. This article deals with the optimization of the energy\nconversion of a grid-connected photovoltaic system. The novelty is to develop\nan intelligent maximum power point tracking technique using artificial neural\nnetwork algorithms. Purpose. Intelligent maximum power point tracking technique\nis developed in order to improve the photovoltaic system performances under the\nvariations of the temperature and irradiation. Methods. This work is to\ncalculate and follow the maximum power point for a photovoltaic system\noperating according to the artificial intelligence mechanism is and the latter\nis used an adaptive modified perturbation and observation maximum power point\ntracking algorithm based on function sign to generate an specify duty cycle\napplied to DC-DC converter, where we use the feed forward artificial neural\nnetwork type trained by Levenberg-Marquardt backpropagation. Results. The\nphotovoltaic system that we chose to simulate and apply this intelligent\ntechnique on it is a stand-alone photovoltaic system. According to the results\nobtained from simulation of the photovoltaic system using adaptive modified\nperturbation and observation artificial neural network the efficiency and the\nquality of the production of energy from photovoltaic is increased. Practical\nvalue. The proposed algorithm is validated by a dSPACE DS1104 for different\noperating conditions. All practice results confirm the effectiveness of our\nproposed algorithm.",
    "descriptor": "",
    "authors": [
      "H. Sahraoui",
      "H. Mellah",
      "S. Drid",
      "L. Chrifi-Alaoui"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.13246"
  },
  {
    "id": "arXiv:2110.13248",
    "title": "Partially Explicit Time Discretization for Nonlinear Time Fractional  Diffusion Equations",
    "abstract": "Nonlinear time fractional partial differential equations are widely used in\nmodeling and simulations. In many applications, there are high contrast changes\nin media properties. For solving these problems, one often uses coarse spatial\ngrid for spatial resolution. For temporal discretization, implicit methods are\noften used. For implicit methods, though the time step can be relatively large,\nthe equations are difficult to compute due to the nonlinearity and the fact\nthat one deals with large-scale systems. On the other hand, the discrete system\nin explicit methods are easier to compute but it requires small time steps. In\nthis work, we propose the partially explicit scheme following earlier works on\ndeveloping partially explicit methods for nonlinear diffusion equations. In\nthis scheme, the diffusion term is treated partially explicitly and the\nreaction term is treated fully explicitly. With the appropriate construction of\nspaces and stability analysis, we find that the required time step in our\nproposed scheme scales as the coarse mesh size, which creates a great saving in\ncomputing. The main novelty of this work is the extension of our earlier works\nfor diffusion equations to time fractional diffusion equations. For the case of\nfractional diffusion equations, the constraints on time steps are more severe\nand the proposed methods alleviate this since the time step in partially\nexplicit method scales as the coarse mesh size. We present stability results.\nNumerical results are presented where we compare our proposed partially\nexplicit methods with a fully implicit approach. We show that our proposed\napproach provides similar results, while treating many degrees of freedom in\nnonlinear terms explicitly.",
    "descriptor": "\nComments: 20 pages, 15 figures\n",
    "authors": [
      "Wenyuan Li",
      "Anatoly Alikhanov",
      "Yalchin Efendiev",
      "Wing Tat Leung"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.13248"
  },
  {
    "id": "arXiv:2110.13250",
    "title": "Beyond $L_p$ clipping: Equalization-based Psychoacoustic Attacks against  ASRs",
    "abstract": "Automatic Speech Recognition (ASR) systems convert speech into text and can\nbe placed into two broad categories: traditional and fully end-to-end. Both\ntypes have been shown to be vulnerable to adversarial audio examples that sound\nbenign to the human ear but force the ASR to produce malicious transcriptions.\nOf these attacks, only the \"psychoacoustic\" attacks can create examples with\nrelatively imperceptible perturbations, as they leverage the knowledge of the\nhuman auditory system. Unfortunately, existing psychoacoustic attacks can only\nbe applied against traditional models, and are obsolete against the newer,\nfully end-to-end ASRs. In this paper, we propose an equalization-based\npsychoacoustic attack that can exploit both traditional and fully end-to-end\nASRs. We successfully demonstrate our attack against real-world ASRs that\ninclude DeepSpeech and Wav2Letter. Moreover, we employ a user study to verify\nthat our method creates low audible distortion. Specifically, 80 of the 100\nparticipants voted in favor of all our attack audio samples as less noisier\nthan the existing state-of-the-art attack. Through this, we demonstrate both\ntypes of existing ASR pipelines can be exploited with minimum degradation to\nattack audio quality.",
    "descriptor": "\nComments: accepted at ACML 2021\n",
    "authors": [
      "Hadi Abdullah",
      "Muhammad Sajidur Rahman",
      "Christian Peeters",
      "Cassidy Gibson",
      "Washington Garcia",
      "Vincent Bindschaedler",
      "Thomas Shrimpton",
      "Patrick Traynor"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.13250"
  },
  {
    "id": "arXiv:2110.13252",
    "title": "CNNC: A Visual Analytics System for Comparative Studies of Deep  Convolutional Neural Networks",
    "abstract": "The rapid development of Convolutional Neural Networks (CNNs) in recent years\nhas triggered significant breakthroughs in many machine learning (ML)\napplications. The ability to understand and compare various CNN models\navailable is thus essential. The conventional approach with visualizing each\nmodel's quantitative features, such as classification accuracy and\ncomputational complexity, is not sufficient for a deeper understanding and\ncomparison of the behaviors of different models. Moreover, most of the existing\ntools for assessing CNN behaviors only support comparison between two models\nand lack the flexibility of customizing the analysis tasks according to user\nneeds. This paper presents a visual analytics system, CNN Comparator (CNNC),\nthat supports the in-depth inspection of a single CNN model as well as\ncomparative studies of two or more models. The ability to compare a larger\nnumber of (e.g., tens of) models especially distinguishes our system from\nprevious ones. With a carefully designed model visualization and explaining\nsupport, CNNC facilitates a highly interactive workflow that promptly presents\nboth quantitative and qualitative information at each analysis stage. We\ndemonstrate CNNC's effectiveness for assisting ML practitioners in evaluating\nand comparing multiple CNN models through two use cases and one preliminary\nevaluation study using the image classification tasks on the ImageNet dataset.",
    "descriptor": "\nComments: 10 pages, 6 figures. This manuscript is currently under review\n",
    "authors": [
      "Xiwei Xuan",
      "Xiaoyu Zhang",
      "Oh-Hyun Kwon",
      "Kwan-Liu Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.13252"
  },
  {
    "id": "arXiv:2110.13254",
    "title": "Pediatric Otoscopy Video Screening with Shift Contrastive Anomaly  Detection",
    "abstract": "Ear related concerns and symptoms represents the leading indication for\nseeking pediatric healthcare attention. Despite the high incidence of such\nencounters, the diagnostic process of commonly encountered disease of the\nmiddle and external presents significant challenge. Much of this challenge\nstems from the lack of cost effective diagnostic testing, which necessitating\nthe presence or absence of ear pathology to be determined clinically. Research\nhas however demonstrated considerable variation among clinicians in their\nability to accurately diagnose and consequently manage ear pathology. With\nrecent advances in computer vision and machine learning, there is an increasing\ninterest in helping clinicians to accurately diagnose middle and external ear\npathology with computer-aided systems. It has been shown that AI has the\ncapacity to analyse a single clinical image captured during examination of the\near canal and eardrum from which it can determine the likelihood of a\npathognomonic pattern for a specific diagnosis being present. The capture of\nsuch an image can however be challenging especially to inexperienced\nclinicians. To help mitigate this technical challenge we have developed and\ntested a method using video sequences. We present a two stage method that\nfirst, identifies valid frames by detecting and extracting ear drum patches\nfrom the video sequence, and second, performs the proposed shift contrastive\nanomaly detection to flag the otoscopy video sequences as normal or abnormal.\nOur method achieves an AUROC of 88.0% on the patient-level and also outperforms\nthe average of a group of 25 clinicians in a comparative study, which is the\nlargest of such published to date. We conclude that the presented method\nachieves a promising first step towards automated analysis of otoscopy video.",
    "descriptor": "",
    "authors": [
      "Weiyao Wang",
      "Aniruddha Tamhane",
      "Christine Santos",
      "John R. Rzasa",
      "James H. Clark",
      "Therese L. Canares",
      "Mathias Unberath"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13254"
  },
  {
    "id": "arXiv:2110.13259",
    "title": "Active Learning for Deep Visual Tracking",
    "abstract": "Convolutional neural networks (CNNs) have been successfully applied to the\nsingle target tracking task in recent years. Generally, training a deep CNN\nmodel requires numerous labeled training samples, and the number and quality of\nthese samples directly affect the representational capability of the trained\nmodel. However, this approach is restrictive in practice, because manually\nlabeling such a large number of training samples is time-consuming and\nprohibitively expensive. In this paper, we propose an active learning method\nfor deep visual tracking, which selects and annotates the unlabeled samples to\ntrain the deep CNNs model. Under the guidance of active learning, the tracker\nbased on the trained deep CNNs model can achieve competitive tracking\nperformance while reducing the labeling cost. More specifically, to ensure the\ndiversity of selected samples, we propose an active learning method based on\nmulti-frame collaboration to select those training samples that should be and\nneed to be annotated. Meanwhile, considering the representativeness of these\nselected samples, we adopt a nearest neighbor discrimination method based on\nthe average nearest neighbor distance to screen isolated samples and\nlow-quality samples. Therefore, the training samples subset selected based on\nour method requires only a given budget to maintain the diversity and\nrepresentativeness of the entire sample set. Furthermore, we adopt a Tversky\nloss to improve the bounding box estimation of our tracker, which can ensure\nthat the tracker achieves more accurate target states. Extensive experimental\nresults confirm that our active learning-based tracker (ALT) achieves\ncompetitive tracking accuracy and speed compared with state-of-the-art trackers\non the seven most challenging evaluation benchmarks.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Di Yuan",
      "Xiaojun Chang",
      "Qiao Liu",
      "Dehua Wang",
      "Zhenyu He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13259"
  },
  {
    "id": "arXiv:2110.13264",
    "title": "Memory visualization tool for training neural network",
    "abstract": "Software developed helps world a better place ranging from system software,\nopen source, application software and so on. Software engineering does have\nneural network models applied to code suggestion, bug report summarizing and so\non to demonstrate their effectiveness at a real SE task. Software and machine\nlearning algorithms combine to make software give better solutions and\nunderstanding of environment. In software, there are both generalized\napplications which helps solve problems for entire world and also some specific\napplications which helps one particular community. To address the computational\nchallenge in deep learning, many tools exploit hardware features such as\nmulti-core CPUs and many-core GPUs to shorten the training time. Machine\nlearning algorithms have a greater impact in the world but there is a\nconsiderable amount of memory utilization during the process. We propose a new\ntool for analysis of memory utilized for developing and training deep learning\nmodels. Our tool results in visual utilization of memory concurrently. Various\nparameters affecting the memory utilization are analysed while training. This\ntool helps in knowing better idea of processes or models which consumes more\nmemory.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Mahendran N"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13264"
  },
  {
    "id": "arXiv:2110.13266",
    "title": "Image Quality Assessment using Contrastive Learning",
    "abstract": "We consider the problem of obtaining image quality representations in a\nself-supervised manner. We use prediction of distortion type and degree as an\nauxiliary task to learn features from an unlabeled image dataset containing a\nmixture of synthetic and realistic distortions. We then train a deep\nConvolutional Neural Network (CNN) using a contrastive pairwise objective to\nsolve the auxiliary problem. We refer to the proposed training framework and\nresulting deep IQA model as the CONTRastive Image QUality Evaluator\n(CONTRIQUE). During evaluation, the CNN weights are frozen and a linear\nregressor maps the learned representations to quality scores in a No-Reference\n(NR) setting. We show through extensive experiments that CONTRIQUE achieves\ncompetitive performance when compared to state-of-the-art NR image quality\nmodels, even without any additional fine-tuning of the CNN backbone. The\nlearned representations are highly robust and generalize well across images\nafflicted by either synthetic or authentic distortions. Our results suggest\nthat powerful quality representations with perceptual relevance can be obtained\nwithout requiring large labeled subjective image quality datasets. The\nimplementations used in this paper are available at\n\\url{https://github.com/pavancm/CONTRIQUE}.",
    "descriptor": "",
    "authors": [
      "Pavan C. Madhusudana",
      "Neil Birkbeck",
      "Yilin Wang",
      "Balu Adsumilli",
      "Alan C. Bovik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.13266"
  },
  {
    "id": "arXiv:2110.13269",
    "title": "Facial Recognition in Collaborative Learning Videos",
    "abstract": "Face recognition in collaborative learning videos presents many challenges.\nIn collaborative learning videos, students sit around a typical table at\ndifferent positions to the recording camera, come and go, move around, get\npartially or fully occluded. Furthermore, the videos tend to be very long,\nrequiring the development of fast and accurate methods. We develop a dynamic\nsystem of recognizing participants in collaborative learning systems. We\naddress occlusion and recognition failures by using past information about the\nface detection history. We address the need for detecting faces from different\nposes and the need for speed by associating each participant with a collection\nof prototype faces computed through sampling or K-means clustering. Our results\nshow that the proposed system is proven to be very fast and accurate. We also\ncompare our system against a baseline system that uses InsightFace [2] and the\noriginal training video segments. We achieved an average accuracy of 86.2%\ncompared to 70.8% for the baseline system. On average, our recognition rate was\n28.1 times faster than the baseline system.",
    "descriptor": "",
    "authors": [
      "Phuong Tran",
      "Marios Pattichis",
      "Sylvia Celed\u00f3n-Pattichis",
      "Carlos L\u00f3pezLeiva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13269"
  },
  {
    "id": "arXiv:2110.13272",
    "title": "Learning Neural Transmittance for Efficient Rendering of Reflectance  Fields",
    "abstract": "Recently neural volumetric representations such as neural reflectance fields\nhave been widely applied to faithfully reproduce the appearance of real-world\nobjects and scenes under novel viewpoints and lighting conditions. However, it\nremains challenging and time-consuming to render such representations under\ncomplex lighting such as environment maps, which requires individual ray\nmarching towards each single light to calculate the transmittance at every\nsampled point. In this paper, we propose a novel method based on precomputed\nNeural Transmittance Functions to accelerate the rendering of neural\nreflectance fields. Our neural transmittance functions enable us to efficiently\nquery the transmittance at an arbitrary point in space along an arbitrary ray\nwithout tedious ray marching, which effectively reduces the time-complexity of\nthe rendering. We propose a novel formulation for the neural transmittance\nfunction, and train it jointly with the neural reflectance fields on images\ncaptured under collocated camera and light, while enforcing monotonicity.\nResults on real and synthetic scenes demonstrate almost two order of magnitude\nspeedup for renderings under environment maps with minimal accuracy loss.",
    "descriptor": "",
    "authors": [
      "Mohammad Shafiei",
      "Sai Bi",
      "Zhengqin Li",
      "Aidas Liaudanskas",
      "Rodrigo Ortiz-Cayon",
      "Ravi Ramamoorthi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.13272"
  },
  {
    "id": "arXiv:2110.13280",
    "title": "A Variational Graph Autoencoder for Manipulation Action Recognition and  Prediction",
    "abstract": "Despite decades of research, understanding human manipulation activities is,\nand has always been, one of the most attractive and challenging research topics\nin computer vision and robotics. Recognition and prediction of observed human\nmanipulation actions have their roots in the applications related to, for\ninstance, human-robot interaction and robot learning from demonstration. The\ncurrent research trend heavily relies on advanced convolutional neural networks\nto process the structured Euclidean data, such as RGB camera images. These\nnetworks, however, come with immense computational complexity to be able to\nprocess high dimensional raw data.\nDifferent from the related works, we here introduce a deep graph autoencoder\nto jointly learn recognition and prediction of manipulation tasks from symbolic\nscene graphs, instead of relying on the structured Euclidean data. Our network\nhas a variational autoencoder structure with two branches: one for identifying\nthe input graph type and one for predicting the future graphs. The input of the\nproposed network is a set of semantic graphs which store the spatial relations\nbetween subjects and objects in the scene. The network output is a label set\nrepresenting the detected and predicted class types. We benchmark our new model\nagainst different state-of-the-art methods on two different datasets, MANIAC\nand MSRC-9, and show that our proposed model can achieve better performance. We\nalso release our source code https://github.com/gamzeakyol/GNet.",
    "descriptor": "\nComments: Accepted for publication in the Proceedings of 2021 20th International Conference on Advanced Robotics (ICAR)\n",
    "authors": [
      "Gamze Akyol",
      "Sanem Sariel",
      "Eren Erdal Aksoy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.13280"
  },
  {
    "id": "arXiv:2110.13282",
    "title": "The Pareto Frontier of model selection for general Contextual Bandits",
    "abstract": "Recent progress in model selection raises the question of the fundamental\nlimits of these techniques. Under specific scrutiny has been model selection\nfor general contextual bandits with nested policy classes, resulting in a\nCOLT2020 open problem. It asks whether it is possible to obtain simultaneously\nthe optimal single algorithm guarantees over all policies in a nested sequence\nof policy classes, or if otherwise this is possible for a trade-off\n$\\alpha\\in[\\frac{1}{2},1)$ between complexity term and time:\n$\\ln(|\\Pi_m|)^{1-\\alpha}T^\\alpha$. We give a disappointing answer to this\nquestion. Even in the purely stochastic regime, the desired results are\nunobtainable. We present a Pareto frontier of up to logarithmic factors\nmatching upper and lower bounds, thereby proving that an increase in the\ncomplexity term $\\ln(|\\Pi_m|)$ independent of $T$ is unavoidable for general\npolicy classes. As a side result, we also resolve a COLT2016 open problem\nconcerning second-order bounds in full-information games.",
    "descriptor": "",
    "authors": [
      "Teodor V. Marinov",
      "Julian Zimmert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13282"
  },
  {
    "id": "arXiv:2110.13283",
    "title": "Generating GitHub Repository Descriptions: A Comparison of Manual and  Automated Approaches",
    "abstract": "Given the vast number of repositories hosted on GitHub, project discovery and\nretrieval have become increasingly important for GitHub users. Repository\ndescriptions serve as one of the first points of contact for users who are\naccessing a repository. However, repository owners often fail to provide a\nhigh-quality description; instead, they use vague terms, the purpose of the\nrepository is poorly explained, or the description is omitted entirely. In this\nwork, we examine the current practice of writing GitHub repository\ndescriptions. Our investigation leads to the proposal of the LSP (Language,\nSoftware technology, and Purpose) template to formulate good descriptions for\nGitHub repositories that are clear, concise, and informative. To understand the\nextent to which current automated techniques can support generating repository\ndescriptions, we compare the performance of state-of-the-art text summarization\nmethods on this task. Finally, our user study with GitHub users reveals that\nautomated summarization can adequately be used for default description\ngeneration for GitHub repositories, while the descriptions which follow the LSP\ntemplate offer the most effective instrument for communicating with GitHub\nusers.",
    "descriptor": "",
    "authors": [
      "Jazlyn Hellman",
      "Eunbee Jang",
      "Christoph Treude",
      "Chenzhun Huang",
      "Jin L.C. Guo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.13283"
  },
  {
    "id": "arXiv:2110.13285",
    "title": "Generative Flows as a General Purpose Solution for Inverse Problems",
    "abstract": "Due to the success of generative flows to model data distributions, they have\nbeen explored in inverse problems. Given a pre-trained generative flow,\nprevious work proposed to minimize the 2-norm of the latent variables as a\nregularization term in the main objective. The intuition behind it was to\nensure high likelihood latent variables, however this does not ensure the\ngeneration of realistic samples as we show in our experiments. We therefore\npropose a regularization term to directly produce high likelihood\nreconstructions. Our hypothesis is that our method could make generative flows\na general-purpose solver for inverse problems. We evaluate our method in image\ndenoising, image deblurring, image inpainting, and image colorization. We\nobserve a compelling improvement of our method over prior works in the PSNR and\nSSIM metrics.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Jos\u00e9 A. Ch\u00e1vez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13285"
  },
  {
    "id": "arXiv:2110.13287",
    "title": "Towards Realistic Market Simulations: a Generative Adversarial Networks  Approach",
    "abstract": "Simulated environments are increasingly used by trading firms and investment\nbanks to evaluate trading strategies before approaching real markets.\nBacktesting, a widely used approach, consists of simulating experimental\nstrategies while replaying historical market scenarios. Unfortunately, this\napproach does not capture the market response to the experimental agents'\nactions. In contrast, multi-agent simulation presents a natural bottom-up\napproach to emulating agent interaction in financial markets. It allows to set\nup pools of traders with diverse strategies to mimic the financial market\ntrader population, and test the performance of new experimental strategies.\nSince individual agent-level historical data is typically proprietary and not\navailable for public use, it is difficult to calibrate multiple market agents\nto obtain the realism required for testing trading strategies. To addresses\nthis challenge we propose a synthetic market generator based on Conditional\nGenerative Adversarial Networks (CGANs) trained on real aggregate-level\nhistorical data. A CGAN-based \"world\" agent can generate meaningful orders in\nresponse to an experimental agent. We integrate our synthetic market generator\ninto ABIDES, an open source simulator of financial markets. By means of\nextensive simulations we show that our proposal outperforms previous work in\nterms of stylized facts reflecting market responsiveness and realism.",
    "descriptor": "\nComments: 8 pages, 9 figures, ICAIF'21 - 2nd ACM International Conference on AI in Finance\n",
    "authors": [
      "Andrea Coletta",
      "Matteo Prata",
      "Michele Conti",
      "Emanuele Mercanti",
      "Novella Bartolini",
      "Aymeric Moulin",
      "Svitlana Vyetrenko",
      "Tucker Balch"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2110.13287"
  },
  {
    "id": "arXiv:2110.13288",
    "title": "Controlling Smart Propagation Environments: Long-Term versus Short-Term  Phase Shift Optimization",
    "abstract": "Reconfigurable intelligent surfaces (RISs) have recently gained significant\ninterest as an emerging technology for future wireless networks. This paper\nstudies an RIS-assisted propagation environment, where a single-antenna source\ntransmits data to a single-antenna destination in the presence of a weak direct\nlink. We analyze and compare RIS designs based on long-term and short-term\nchannel statistics in terms of coverage probability and ergodic rate. For the\nconsidered optimization designs, closed-form expressions for the coverage\nprobability and ergodic rate are derived. We use numerical simulations to\nanalyze and compare against analytic results in finite samples. Also, we show\nthat the considered optimal phase shift designs outperform several heuristic\nbenchmarks.",
    "descriptor": "\nComments: 5 pages, 1 figure. Submitted for publication\n",
    "authors": [
      "Trinh Van Chien",
      "Lam Thanh Tu",
      "Dinh-Hieu Tran",
      "Hieu Van Nguyen",
      "Symeon Chatzinotas",
      "Marco Di Renzo",
      "Bj\u00f6rn Ottersten"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.13288"
  },
  {
    "id": "arXiv:2110.13289",
    "title": "Uncertainty quantification in non-rigid image registration via  stochastic gradient Markov chain Monte Carlo",
    "abstract": "We develop a new Bayesian model for non-rigid registration of\nthree-dimensional medical images, with a focus on uncertainty quantification.\nProbabilistic registration of large images with calibrated uncertainty\nestimates is difficult for both computational and modelling reasons. To address\nthe computational issues, we explore connections between the Markov chain Monte\nCarlo by backpropagation and the variational inference by backpropagation\nframeworks, in order to efficiently draw samples from the posterior\ndistribution of transformation parameters. To address the modelling issues, we\nformulate a Bayesian model for image registration that overcomes the existing\nbarriers when using a dense, high-dimensional, and diffeomorphic transformation\nparametrisation. This results in improved calibration of uncertainty estimates.\nWe compare the model in terms of both image registration accuracy and\nuncertainty quantification to VoxelMorph, a state-of-the-art image registration\nmodel based on deep learning.",
    "descriptor": "\nComments: MELBA Special Issue: Uncertainty for Safe Utilization of Machine Learning in Medical Imaging (UNSURE) 2020\n",
    "authors": [
      "Daniel Grzech",
      "Mohammad Farid Azampour",
      "Huaqi Qiu",
      "Ben Glocker",
      "Bernhard Kainz",
      "Lo\u00efc Le Folgoc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13289"
  },
  {
    "id": "arXiv:2110.13290",
    "title": "Exploring System Performance of Continual Learning for Mobile and  Embedded Sensing Applications",
    "abstract": "Continual learning approaches help deep neural network models adapt and learn\nincrementally by trying to solve catastrophic forgetting. However, whether\nthese existing approaches, applied traditionally to image-based tasks, work\nwith the same efficacy to the sequential time series data generated by mobile\nor embedded sensing systems remains an unanswered question.\nTo address this void, we conduct the first comprehensive empirical study that\nquantifies the performance of three predominant continual learning schemes\n(i.e., regularization, replay, and replay with examples) on six datasets from\nthree mobile and embedded sensing applications in a range of scenarios having\ndifferent learning complexities. More specifically, we implement an end-to-end\ncontinual learning framework on edge devices. Then we investigate the\ngeneralizability, trade-offs between performance, storage, computational costs,\nand memory footprint of different continual learning methods.\nOur findings suggest that replay with exemplars-based schemes such as iCaRL\nhas the best performance trade-offs, even in complex scenarios, at the expense\nof some storage space (few MBs) for training examples (1% to 5%). We also\ndemonstrate for the first time that it is feasible and practical to run\ncontinual learning on-device with a limited memory budget. In particular, the\nlatency on two types of mobile and embedded devices suggests that both\nincremental learning time (few seconds - 4 minutes) and training time (1 - 75\nminutes) across datasets are acceptable, as training could happen on the device\nwhen the embedded device is charging thereby ensuring complete data privacy.\nFinally, we present some guidelines for practitioners who want to apply a\ncontinual learning paradigm for mobile sensing tasks.",
    "descriptor": "\nComments: Accepted for publication at SEC 2021\n",
    "authors": [
      "Young D. Kwon",
      "Jagmohan Chauhan",
      "Abhishek Kumar",
      "Pan Hui",
      "Cecilia Mascolo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2110.13290"
  },
  {
    "id": "arXiv:2110.13292",
    "title": "Self-aware Social Learning over Graphs",
    "abstract": "In this paper we study the problem of social learning under multiple true\nhypotheses and self-interested agents which exchange information over a graph.\nIn this setup, each agent receives data that might be generated from a\ndifferent hypothesis (or state) than the data other agents receive. In contrast\nto the related literature in social learning, which focuses on showing that the\nnetwork achieves consensus, here we study the case where every agent is\nself-interested and wants to find the hypothesis that generates its own\nobservations. However, agents do not know which ones of their peers wants to\nfind the same state with them and as a result they do not know which agents\nthey should cooperate with. To this end, we propose a scheme with adaptive\ncombination weights and study the consistency of the agents' learning process.\nThe scheme allows each agent to identify and collaborate with neighbors that\nobserve the same hypothesis, while excluding others, thus resulting in improved\nperformance compared to both non-cooperative learning and cooperative social\nlearning solutions. We analyze the asymptotic behavior of agents' beliefs under\nthe proposed social learning algorithm and provide sufficient conditions that\nenable all agents to correctly identify their true hypotheses. The theoretical\nanalysis is corroborated by numerical simulations.",
    "descriptor": "\nComments: 17 pages, 6 figures\n",
    "authors": [
      "Konstantinos Ntemos",
      "Virginia Bordignon",
      "Stefan Vlaski",
      "Ali H. Sayed"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.13292"
  },
  {
    "id": "arXiv:2110.13293",
    "title": "Emulation of physical processes with Emukit",
    "abstract": "Decision making in uncertain scenarios is an ubiquitous challenge in real\nworld systems. Tools to deal with this challenge include simulations to gather\ninformation and statistical emulation to quantify uncertainty. The machine\nlearning community has developed a number of methods to facilitate decision\nmaking, but so far they are scattered in multiple different toolkits, and\ngenerally rely on a fixed backend. In this paper, we present Emukit, a highly\nadaptable Python toolkit for enriching decision making under uncertainty.\nEmukit allows users to: (i) use state of the art methods including Bayesian\noptimization, multi-fidelity emulation, experimental design, Bayesian\nquadrature and sensitivity analysis; (ii) easily prototype new decision making\nmethods for new problems. Emukit is agnostic to the underlying modeling\nframework and enables users to use their own custom models. We show how Emukit\ncan be used on three exemplary case studies.",
    "descriptor": "\nComments: Second Workshop on Machine Learning and the Physical Sciences, NeurIPS 2019\n",
    "authors": [
      "Andrei Paleyes",
      "Mark Pullin",
      "Maren Mahsereci",
      "Cliff McCollum",
      "Neil D. Lawrence",
      "Javier Gonzalez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13293"
  },
  {
    "id": "arXiv:2110.13297",
    "title": "Fast PDE-constrained optimization via self-supervised operator learning",
    "abstract": "Design and optimal control problems are among the fundamental, ubiquitous\ntasks we face in science and engineering. In both cases, we aim to represent\nand optimize an unknown (black-box) function that associates a\nperformance/outcome to a set of controllable variables through an experiment.\nIn cases where the experimental dynamics can be described by partial\ndifferential equations (PDEs), such problems can be mathematically translated\ninto PDE-constrained optimization tasks, which quickly become intractable as\nthe number of control variables and the cost of experiments increases. In this\nwork we leverage physics-informed deep operator networks (DeepONets) -- a\nself-supervised framework for learning the solution operator of parametric PDEs\n-- to build fast and differentiable surrogates for rapidly solving\nPDE-constrained optimization problems, even in the absence of any paired\ninput-output training data. The effectiveness of the proposed framework will be\ndemonstrated across different applications involving continuous functions as\ncontrol or design variables, including time-dependent optimal control of heat\ntransfer, and drag minimization of obstacles in Stokes flow. In all cases, we\nobserve that DeepONets can minimize high-dimensional cost functionals in a\nmatter of seconds, yielding a significant speed up compared to traditional\nadjoint PDE solvers that are typically costly and limited to relatively\nlow-dimensional control/design parametrizations.",
    "descriptor": "\nComments: 24 pages, 12 figures\n",
    "authors": [
      "Sifan Wang",
      "Mohamed Aziz Bhouri",
      "Paris Perdikaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.13297"
  },
  {
    "id": "arXiv:2110.13300",
    "title": "Adaptive Probabilistic Model for Energy-Efficient Distance-based  Clustering in WSNs (Adapt-P): A LEACH-based Analytical Study",
    "abstract": "Network lifetime and energy consumption of data transmission have been\nprimary Quality of Service (QoS) obligations in Wireless Sensor Networks\n(WSNs). The environment of a WSN is often organized into clusters to mitigate\nthe management complexity of such obligations. However, the distance between\nSensor Nodes (SNs) and the number of clusters per round are vital factors that\naffect QoS performance of a WSN. A designer's conundrum resolves around the\ndesire to sustain a balance between the limited residual energy of SNs and the\ndemand for prolonged network lifetime. Any imbalance in controlling such\nobjectives results in either QoS penalties due to draining SN energies, or an\nover-cost environment that is significantly difficult to distribute and\noperate. Low-Energy Adaptive Clustering Hierarchy (LEACH) is a distributed\nalgorithm proposed to tackle such difficulties. Proposed LEACH-based algorithms\nfocus on residual energies of SNs to compute a probability function that\nselects cluster-heads and an optimal energy-efficient path toward a destination\nSN. Nevertheless, these algorithms do not consider variations in network's\nstate at run-time. Such a state changes in an adaptive manner according to\nexisting network structures and conditions. Thus, cluster-heads per round are\nnot elected adaptively depending on the state and distances between SNs. This\npaper proposes an energy-efficient adaptive distance-based clustering called\nAdapt-P, in which an adaptive probability function is developed to formulate\nclusters. A near-optimal distance between each cluster-head and its\ncluster-members is formulated so that energy consumption of the network is\nmitigated and network lifetime is maximized. The cluster-head selection\nprobability is adapted at the end of each round based on the maximum number of\ncluster-heads permitted per round found a priori and the number of alive SNs in\nthe network.",
    "descriptor": "",
    "authors": [
      "Husam Suleiman",
      "Mohammad Hamdan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.13300"
  },
  {
    "id": "arXiv:2110.13303",
    "title": "Negotiating Networks in Oligopoly Markets for Price-Sensitive Products",
    "abstract": "We present a novel framework to learn functions that estimate decisions of\nsellers and buyers simultaneously in an oligopoly market for a price-sensitive\nproduct. In this setting, the aim of the seller network is to come up with a\nprice for a given context such that the expected revenue is maximized by\nconsidering the buyer's satisfaction as well. On the other hand, the aim of the\nbuyer network is to assign probability of purchase to the offered price to\nmimic the real world buyers' responses while also showing price sensitivity\nthrough its action. In other words, rejecting the unnecessarily high priced\nproducts. Similar to generative adversarial networks, this framework\ncorresponds to a minimax two-player game. In our experiments with simulated and\nreal-world transaction data, we compared our framework with the baseline model\nand demonstrated its potential through proposed evaluation metrics.",
    "descriptor": "\nComments: 10 pages, 4 figures, NeurIPS 2021 Workshop on Learning in Presence of Strategic Behavior\n",
    "authors": [
      "Naman Shukla",
      "Kartik Yellepeddi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2110.13303"
  },
  {
    "id": "arXiv:2110.13306",
    "title": "Reconciling Risk Allocation and Prevalence Estimation in Public Health  Using Batched Bandits",
    "abstract": "In many public health settings, there is a perceived tension between\nallocating resources to known vulnerable areas and learning about the overall\nprevalence of the problem. Inspired by a door-to-door Covid-19 testing program\nwe helped design, we combine multi-armed bandit strategies and insights from\nsampling theory to demonstrate how to recover accurate prevalence estimates\nwhile continuing to allocate resources to at-risk areas. We use the outbreak of\nan infectious disease as our running example. The public health setting has\nseveral characteristics distinguishing it from typical bandit settings, such as\ndistribution shift (the true disease prevalence is changing with time) and\nbatched sampling (multiple decisions must be made simultaneously).\nNevertheless, we demonstrate that several bandit algorithms are capable\nout-performing greedy resource allocation strategies, which often perform worse\nthan random allocation as they fail to notice outbreaks in new areas.",
    "descriptor": "\nComments: Published in Machine Learning in Public Health Workshop at NeurIPS 2021\n",
    "authors": [
      "Ben Chugg",
      "Daniel E. Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13306"
  },
  {
    "id": "arXiv:2110.13309",
    "title": "History Aware Multimodal Transformer for Vision-and-Language Navigation",
    "abstract": "Vision-and-language navigation (VLN) aims to build autonomous visual agents\nthat follow instructions and navigate in real scenes. To remember previously\nvisited locations and actions taken, most approaches to VLN implement memory\nusing recurrent states. Instead, we introduce a History Aware Multimodal\nTransformer (HAMT) to incorporate a long-horizon history into multimodal\ndecision making. HAMT efficiently encodes all the past panoramic observations\nvia a hierarchical vision transformer (ViT), which first encodes individual\nimages with ViT, then models spatial relation between images in a panoramic\nobservation and finally takes into account temporal relation between panoramas\nin the history. It, then, jointly combines text, history and current\nobservation to predict the next action. We first train HAMT end-to-end using\nseveral proxy tasks including single step action prediction and spatial\nrelation prediction, and then use reinforcement learning to further improve the\nnavigation policy. HAMT achieves new state of the art on a broad range of VLN\ntasks, including VLN with fine-grained instructions (R2R, RxR), high-level\ninstructions (R2R-Last, REVERIE), dialogs (CVDN) as well as long-horizon VLN\n(R4R, R2R-Back). We demonstrate HAMT to be particularly effective for\nnavigation tasks with longer trajectories.",
    "descriptor": "\nComments: Accepted in NeurIPS 2021; project page at this https URL\n",
    "authors": [
      "Shizhe Chen",
      "Pierre-Louis Guhur",
      "Cordelia Schmid",
      "Ivan Laptev"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13309"
  },
  {
    "id": "arXiv:2110.13315",
    "title": "EarthGAN: Can we visualize the Earth's mantle convection using a  surrogate model?",
    "abstract": "Scientific simulations are often used to gain insight into foundational\nquestions. However, many potentially useful simulation results are difficult to\nvisualize without powerful computers. In this research, we seek to build a\nsurrogate model, using a generative adversarial network, to allow for the\nvisualization of the Earth's Mantle Convection data set on readily accessible\nhardware. We present our preliminary method and results, and all code is made\npublicly available. The preliminary results show that a surrogate model of the\nEarth's Mantle Convection data set can generate useful results. A comparison to\nthe \"ground-truth\" is provided.",
    "descriptor": "\nComments: Accepted at IEEE VIS 2021 as part of the SciVis contest. For associated code, see this https URL\n",
    "authors": [
      "Tim von Hahn",
      "Chris K. Mechefske"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.13315"
  },
  {
    "id": "arXiv:2110.13317",
    "title": "Exposure of occupations to technologies of the fourth industrial  revolution",
    "abstract": "The fourth industrial revolution (4IR) is likely to have a substantial impact\non the economy. Companies need to build up capabilities to implement new\ntechnologies, and automation may make some occupations obsolete. However,\nwhere, when, and how the change will happen remain to be determined. Robust\nempirical indicators of technological progress linked to occupations can help\nto illuminate this change. With this aim, we provide such an indicator based on\npatent data. Using natural language processing, we calculate patent exposure\nscores for more than 900 occupations, which represent the technological\nprogress related to them. To provide a lens on the impact of the 4IR, we\ndifferentiate between traditional and 4IR patent exposure. Our method differs\nfrom previous approaches in that it both accounts for the diversity of\ntask-level patent exposures within an occupation and reflects work activities\nmore accurately. We find that exposure to 4IR patents differs from traditional\npatent exposure. Manual tasks, and accordingly occupations such as construction\nand production, are exposed mainly to traditional (non-4IR) patents but have\nlow exposure to 4IR patents. The analysis suggests that 4IR technologies may\nhave a negative impact on job growth; this impact appears 10 to 20 years after\npatent filing. Further, we compared the 4IR exposure to other automation and AI\nexposure scores. Whereas many measures refer to theoretical automation\npotential, our patent-based indicator reflects actual technology diffusion. Our\nwork not only allows analyses of the impact of 4IR technologies as a whole, but\nalso provides exposure scores for more than 300 technology fields, such as AI\nand smart office technologies. Finally, the work provides a general mapping of\npatents to tasks and occupations, which enables future researchers to construct\nindividual exposure measures.",
    "descriptor": "\nComments: 65 pages, 18 figures\n",
    "authors": [
      "Benjamin Meindl",
      "Morgan R. Frank",
      "Joana Mendon\u00e7a"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.13317"
  },
  {
    "id": "arXiv:2110.13323",
    "title": "Deep Learning Tools for Audacity: Helping Researchers Expand the  Artist's Toolkit",
    "abstract": "We present a software framework that integrates neural networks into the\npopular open-source audio editing software, Audacity, with a minimal amount of\ndeveloper effort. In this paper, we showcase some example use cases for both\nend-users and neural network developers. We hope that this work fosters a new\nlevel of interactivity between deep learning practitioners and end-users.",
    "descriptor": "",
    "authors": [
      "Hugo Flores Garcia",
      "Aldo Aguilar",
      "Ethan Manilow",
      "Dmitry Vedenko",
      "Bryan Pardo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.13323"
  },
  {
    "id": "arXiv:2110.13324",
    "title": "Sampling Multiple Nodes in Large Networks: Beyond Random Walks",
    "abstract": "Sampling random nodes is a fundamental algorithmic primitive in the analysis\nof massive networks, with many modern graph mining algorithms critically\nrelying on it. We consider the task of generating a large collection of random\nnodes in the network assuming limited query access (where querying a node\nreveals its set of neighbors). In current approaches, based on long random\nwalks, the number of queries per sample scales linearly with the mixing time of\nthe network, which can be prohibitive for large real-world networks. We propose\na new method for sampling multiple nodes that bypasses the dependence in the\nmixing time by explicitly searching for less accessible components in the\nnetwork. We test our approach on a variety of real-world and synthetic networks\nwith up to tens of millions of nodes, demonstrating a query complexity\nimprovement of up to $\\times 20$ compared to the state of the art.",
    "descriptor": "\nComments: To appear in 15th ACM International Conference on Web Search and Data Mining (WSDM 2022). Code available soon at: this https URL\n",
    "authors": [
      "Omri Ben-Eliezer",
      "Talya Eden",
      "Joel Oren",
      "Dimitris Fotakis"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.13324"
  },
  {
    "id": "arXiv:2110.13325",
    "title": "Construction of a set of circulant matrix submatrices for faster MDS  matrix verification",
    "abstract": "The present paper focuses on the construction of a set of submatrices of a\ncirculant matrix such that it is a smaller set to verify that the circulant\nmatrix is an MDS (maximum distance separable) one, comparing to the complete\nset of square submatrices needed in general case. The general MDS verification\nmethod requires to test for singular submatrices: if at least one square\nsubmatrix is singular the matrix is not MDS. However, the complexity of the\ngeneral method dramatically increases for matrices of a greater dimension. We\ndevelop an algorithm that constructs a smaller subset of submatrices thanks to\na simple structure of circulant matrices. The algorithm proposed in the paper\nreduces the size of the testing set by approximately two matrix orders.",
    "descriptor": "",
    "authors": [
      "Stanislav S. Malakhov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.13325"
  },
  {
    "id": "arXiv:2110.13328",
    "title": "Eigenvalue Bounds for Double Saddle-Point Systems",
    "abstract": "We derive bounds on the eigenvalues of a generic form of double saddle-point\nmatrices. The bounds are expressed in terms of extremal eigenvalues and\nsingular values of the associated block matrices. Inertia and algebraic\nmultiplicity of eigenvalues are considered as well. The analysis includes\nbounds for preconditioned matrices based on block diagonal preconditioners\nusing Schur complements, and it is shown that in this case the eigenvalues are\nclustered within a few intervals bounded away from zero. Analysis for\napproximations of Schur complements is included. Some numerical experiments\nvalidate our analytical findings.",
    "descriptor": "",
    "authors": [
      "Susanne Bradley",
      "Chen Greif"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.13328"
  },
  {
    "id": "arXiv:2110.13330",
    "title": "Robust Learning of Physics Informed Neural Networks",
    "abstract": "Physics-informed Neural Networks (PINNs) have been shown to be effective in\nsolving partial differential equations by capturing the physics induced\nconstraints as a part of the training loss function. This paper shows that a\nPINN can be sensitive to errors in training data and overfit itself in\ndynamically propagating these errors over the domain of the solution of the\nPDE. It also shows how physical regularizations based on continuity criteria\nand conservation laws fail to address this issue and rather introduce problems\nof their own causing the deep network to converge to a physics-obeying local\nminimum instead of the global minimum. We introduce Gaussian Process (GP) based\nsmoothing that recovers the performance of a PINN and promises a robust\narchitecture against noise/errors in measurements. Additionally, we illustrate\nan inexpensive method of quantifying the evolution of uncertainty based on the\nvariance estimation of GPs on boundary data. Robust PINN performance is also\nshown to be achievable by choice of sparse sets of inducing points based on\nsparsely induced GPs. We demonstrate the performance of our proposed methods\nand compare the results from existing benchmark models in literature for\ntime-dependent Schr\\\"odinger and Burgers' equations.",
    "descriptor": "",
    "authors": [
      "Chandrajit Bajaj",
      "Luke McLennan",
      "Timothy Andeen",
      "Avik Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.13330"
  },
  {
    "id": "arXiv:2110.13336",
    "title": "Gaussian Mixture Model Based Distributionally Robust Optimal Power Flow  With CVaR Constraints",
    "abstract": "This paper proposes a distributionally robust optimal power flow (OPF) model\nfor transmission grids with wind power generation. The model uses the\nconditional value-at-risk (CVaR) constraints to control the reserve and branch\nflow limit violations caused by wind power forecast errors. Meanwhile, the\nGaussian mixture model (GMM) is integrated into the CVaR constraints to guard\nagainst the non-Gaussian forecast error distributions. Unlike the previous\nstudies considering the GMM with fixed parameters, this paper allows the GMM\nparameters to be variable within some credible regions and develops a\ndata-driven GMM-based ambiguity set to achieve the distributional robustness.\nAlso, rather than using the traditional sample-based approximation of CVaR with\nhigh computational burden, this paper designs a scalable cutting-plane\nalgorithm to handle the distributionally robust CVaR constraints. Case studies\non the IEEE 2736-bus system show the effectiveness and scalability of the\nproposed OPF model.",
    "descriptor": "",
    "authors": [
      "Lei You",
      "Hui Ma",
      "Tapan Kumar Saha",
      "Gang Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.13336"
  },
  {
    "id": "arXiv:2110.13337",
    "title": "Robust Ellipsoid-specific Fitting via Expectation Maximization",
    "abstract": "Ellipsoid fitting is of general interest in machine vision, such as object\ndetection and shape approximation. Most existing approaches rely on the\nleast-squares fitting of quadrics, minimizing the algebraic or geometric\ndistances, with additional constraints to enforce the quadric as an ellipsoid.\nHowever, they are susceptible to outliers and non-ellipsoid or biased results\nwhen the axis ratio exceeds certain thresholds. To address these problems, we\npropose a novel and robust method for ellipsoid fitting in a noisy,\noutlier-contaminated 3D environment. We explicitly model the ellipsoid by\nkernel density estimation (KDE) of the input data. The ellipsoid fitting is\ncast as a maximum likelihood estimation (MLE) problem without extra\nconstraints, where a weighting term is added to depress outliers, and then\neffectively solved via the Expectation-Maximization (EM) framework.\nFurthermore, we introduce the vector {\\epsilon} technique to accelerate the\nconvergence of the original EM. The proposed method is compared with\nrepresentative state-of-the-art approaches by extensive experiments, and\nresults show that our method is ellipsoid-specific, parameter free, and more\nrobust against noise, outliers, and the large axis ratio. Our implementation is\navailable at https://zikai1.github.io/.",
    "descriptor": "",
    "authors": [
      "Zhao Mingyang",
      "Jia Xiaohong",
      "Ma Lei",
      "Qiu Xinlin",
      "Jiang Xin",
      "Yan Dong-Ming"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13337"
  },
  {
    "id": "arXiv:2110.13340",
    "title": "Privacy-Preserving Multi-Target Multi-Domain Recommender Systems with  Assisted AutoEncoders",
    "abstract": "A long-standing challenge in Recommender Systems (RCs) is the data sparsity\nproblem that often arises when users rate very few items. Multi-Target\nMulti-Domain Recommender Systems (MTMDR) aim to improve the recommendation\nperformance in multiple domains simultaneously. The existing works assume that\nthe data of different domains can be fully shared, and the computation can be\nperformed in a centralized manner. However, in many realistic scenarios,\nseparate recommender systems are operated by different organizations, which do\nnot allow the sharing of private data, models, and recommendation tasks. This\nwork proposes an MTMDR based on Assisted AutoEncoders (AAE) and Multi-Target\nAssisted Learning (MTAL) to help organizational learners improve their\nrecommendation performance simultaneously without sharing sensitive assets.\nMoreover, AAE has a broad application scope since it allows explicit or\nimplicit feedback, user- or item-based alignment, and with or without side\ninformation. Extensive experiments demonstrate that our method significantly\noutperforms the case where each domain is locally trained, and it performs\ncompetitively with the centralized training where all data are shared. As a\nresult, AAE can effectively integrate organizations from different domains to\nform a community of shared interest.",
    "descriptor": "",
    "authors": [
      "Enmao Diao",
      "Vahid Tarokh",
      "Jie Ding"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13340"
  },
  {
    "id": "arXiv:2110.13341",
    "title": "How Should AI Interpret Rules? A Defense of Minimally Defeasible  Interpretive Argumentation",
    "abstract": "Can artificially intelligent systems follow rules? The answer might seem an\nobvious `yes', in the sense that all (current) AI strictly acts in accordance\nwith programming code constructed from highly formalized and well-defined\nrulesets. But here I refer to the kinds of rules expressed in human language\nthat are the basis of laws, regulations, codes of conduct, ethical guidelines,\nand so on. The ability to follow such rules, and to reason about them, is not\nnearly as clear-cut as it seems on first analysis. Real-world rules are\nunavoidably rife with open-textured terms, which imbue rules with a possibly\ninfinite set of possible interpretations. Narrowing down this set requires a\ncomplex reasoning process that is not yet within the scope of contemporary AI.\nThis poses a serious problem for autonomous AI: If one cannot reason about\nopen-textured terms, then one cannot reason about (or in accordance with)\nreal-world rules. And if one cannot reason about real-world rules, then one\ncannot: follow human laws, comply with regulations, act in accordance with\nwritten agreements, or even obey mission-specific commands that are anything\nmore than trivial. But before tackling these problems, we must first answer a\nmore fundamental question: Given an open-textured rule, what is its correct\ninterpretation? Or more precisely: How should our artificially intelligent\nsystems determine which interpretation to consider correct? In this essay, I\ndefend the following answer: Rule-following AI should act in accordance with\nthe interpretation best supported by minimally defeasible interpretive\narguments (MDIA).",
    "descriptor": "\nComments: Extended version of a talk given at USF AI+X Seminar, Oct. 29, 2021\n",
    "authors": [
      "John Licato"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.13341"
  },
  {
    "id": "arXiv:2110.13343",
    "title": "The Role of the Scrum Master in an Industry based University Course",
    "abstract": "Background: Scrum is the most commonly used agile software development\nmethod, and the role of the Scrum Master (SM) in a Scrum environment is vital.\nTherefore, through an industry based university course for final year\nundergraduate and masters students, we aimed to give students both theoretical\nand practical understanding of the role of SM via hands-on experience on\nplaying the role in real-world Scrum contexts. Method: We asked them (92\nstudents) to share their experiences and learnings on the role of SM through\nreflective surveys and essays. Students participated in reflective surveys (311\nsurvey responses) over 5 weeks in the course, and they submitted essays (92\nessays) at the end of the course. We used a mixed-methods approach using\nSocio-Technical Grounded Theory analysis techniques and trend and regression\nbased statistical analysis to analyse the survey responses and the essays.\nFindings: We identified the key responsibilities and duties of the SM, common\nchallenges faced by the SM and the team due to the role of the SM, root causes\nof the challenges, strategies used by the SM and the team to overcome the\nchallenges, and the overall experience of the students. Based on the results,\nwe present recommendations for educators.",
    "descriptor": "\nComments: 21 pages, 12 figures, 3 tables, under review at Journal of Systems and Software\n",
    "authors": [
      "Kashumi Madampe",
      "Zainab Masood",
      "Rashina Hoda"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.13343"
  },
  {
    "id": "arXiv:2110.13344",
    "title": "Sinusoidal Flow: A Fast Invertible Autoregressive Flow",
    "abstract": "Normalising flows offer a flexible way of modelling continuous probability\ndistributions. We consider expressiveness, fast inversion and exact Jacobian\ndeterminant as three desirable properties a normalising flow should possess.\nHowever, few flow models have been able to strike a good balance among all\nthese properties. Realising that the integral of a convex sum of sinusoidal\nfunctions squared leads to a bijective residual transformation, we propose\nSinusoidal Flow, a new type of normalising flows that inherits the expressive\npower and triangular Jacobian from fully autoregressive flows while guaranteed\nby Banach fixed-point theorem to remain fast invertible and thereby obviate the\nneed for sequential inversion typically required in fully autoregressive flows.\nExperiments show that our Sinusoidal Flow is not only able to model complex\ndistributions, but can also be reliably inverted to generate realistic-looking\nsamples even with many layers of transformations stacked.",
    "descriptor": "\nComments: Deeply honoured to receive the Best Paper award at Asian Conference on Machine Learning (ACML) 2021\n",
    "authors": [
      "Yumou Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13344"
  },
  {
    "id": "arXiv:2110.13346",
    "title": "Exploring eFPGA-based Redaction for IP Protection",
    "abstract": "Recently, eFPGA-based redaction has been proposed as a promising solution for\nhiding parts of a digital design from untrusted entities, where legitimate\nend-users can restore functionality by loading the withheld bitstream after\nfabrication. However, when deciding which parts of a design to redact, there\nare a number of practical issues that designers need to consider, including\narea and timing overheads, as well as security factors. Adapting an open-source\nFPGA fabric generation flow, we perform a case study to explore the trade-offs\nwhen redacting different modules of open-source intellectual property blocks\n(IPs) and explore how different parts of an eFPGA contribute to the security.\nWe provide new insights into the feasibility and challenges of using\neFPGA-based redaction as a security solution.",
    "descriptor": "\nComments: Accepted to ICCAD 2021\n",
    "authors": [
      "Jitendra Bhandari",
      "Abdul Khader Thalakkattu Moosa",
      "Benjamin Tan",
      "Christian Pilato",
      "Ganesh Gore",
      "Xifan Tang",
      "Scott Temple",
      "Pierre-Emmanuel Gaillardon",
      "Ramesh Karri"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.13346"
  },
  {
    "id": "arXiv:2110.13348",
    "title": "Graph? Yes! Which one? Help!",
    "abstract": "Amazon Neptune is a graph database service that supports two graph\n(meta)models: W3C's Resource Description Framework (RDF) and Labeled Property\nGraphs (LPG). Customers opt in for one or the other model, and this choice\ndetermines which data modeling features can be used, and - perhaps more\nimportantly - which query languages are available to query and manipulate the\ngraph. The choice between the two technology stacks is difficult and requires\nconsideration of data modeling aspects, query language features, their adequacy\nfor current and future use cases, as well as many other factors (including\ndeveloper preferences). Sometimes we see customers make the wrong choice with\nno easy way to reverse it later.\nIt is therefore highly desirable that the choice of the query language can be\nmade without consideration of what graph model is chosen, and can be easily\nrevised or complemented at a later point. In this paper, we advocate and\nexplore the idea of a single, unified graph data model that embraces both RDF\nand LPGs, and naturally supports different graph query languages on top. We\ninvestigate obstacles towards unifying the two graph data models, and propose\nan initial unifying model, dubbed \"one graph\" (\"1G\" for short), as the basis\nfor moving forward.",
    "descriptor": "\nComments: Accepted in the 1st Workshop on Squaring the Circle on Graphs (SCG2021), SEMANTiCS 2021; 12 pages\n",
    "authors": [
      "Ora Lassila",
      "Michael Schmidt",
      "Brad Bebee",
      "Dave Bechberger",
      "Willem Broekema",
      "Ankesh Khandelwal",
      "Kelvin Lawrence",
      "Ronak Sharda",
      "Bryan Thompson"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.13348"
  },
  {
    "id": "arXiv:2110.13349",
    "title": "Cell Zooming with Masked Data for Off-Grid Small Cell Networks:  Distributed Optimization Approach",
    "abstract": "Cell zooming has been becoming an essential enabler for off-grid small cell\nnetworks. Traditional models often utilize the numbers of active users in order\nto determine cell zooming strategies. However, such confidential measurement\ndata must be concealed from others. We therefore propose a novel cell zooming\nmethod with masking noise. The proposed algorithm is designed based on\ndistributed optimization, in which each SBS locally solves a divided\noptimization problem and learns how much a global constraint is satisfied or\nviolated for temporal solutions. The important feature of this distributed\ncontrol method is robustness against masking noise. We analyze the trade-off\nbetween confidentiality and optimization accuracy, using the notion of\ndifferential privacy. Numerical simulations show that the proposed distributed\ncontrol method outperforms a standard centralized control method in the\npresence of masking noise.",
    "descriptor": "\nComments: 15 pages, 15 figures\n",
    "authors": [
      "Masashi Wakaiki",
      "Katsuya Suto",
      "Izumi Masubuchi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.13349"
  },
  {
    "id": "arXiv:2110.13350",
    "title": "Polynomial Integrality Gap of Flow LP for Directed Steiner Tree",
    "abstract": "In the Directed Steiner Tree (DST) problem, we are given a directed graph\n$G=(V,E)$ on $n$ vertices with edge-costs $c \\in \\mathbb{R}_{\\geq 0}^E$, a root\nvertex $r$, and a set $K$ of $k$ terminals. The goal is to find a minimum-cost\nsubgraph of $G$ that contains a path from $r$ to every terminal $t \\in K$. DST\nhas been a notorious problem for decades as there is a large gap between the\nbest-known polynomial-time approximation ratio of $O(k^\\epsilon)$ for any\nconstant $\\epsilon > 0$, and the best quasi-polynomial-time approximation ratio\nof $O\\left(\\frac{\\log^2 k}{\\log \\log k}\\right)$.\nTowards understanding this gap, we study the integrality gap of the standard\nflow LP relaxation for the problem. We show that the LP has an integrality gap\npolynomial in $n$. Previously, the integrality gap LP is only known to be\n$\\Omega\\left(\\frac{\\log^2n}{\\log\\log n}\\right)$ [Halperin et al., SODA'03 \\&\nSIAM J. Comput.] and $\\Omega(\\sqrt{k})$ [Zosin-Khuller, SODA'02] in some\ninstance with $\\sqrt{k}=O\\left(\\frac{\\log n}{\\log \\log n}\\right)$. Our result\ngives the first known lower bound on the integrality gap of this standard LP\nthat is polynomial in $n$, the number of vertices. Consequently, we rule out\nthe possibility of developing a poly-logarithmic approximation algorithm for\nthe problem based on the flow LP relaxation.",
    "descriptor": "\nComments: This manuscript is accepted to SODA'22\n",
    "authors": [
      "Shi Li",
      "Bundit Laekhanukit"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.13350"
  },
  {
    "id": "arXiv:2110.13356",
    "title": "Event-triggered Consensus of Matrix-weighted Networks Subject to  Actuator Saturation",
    "abstract": "The ubiquitous interdependencies among higher-dimensional states of\nneighboring agents can be characterized by matrix-weighted networks. This paper\nexamines event-triggered global consensus of matrix-weighted networks subject\nto actuator saturation. Specifically, a distributed dynamic event-triggered\ncoordination strategy, whose design involves sampled state of agents,\nsaturation constraint and auxiliary systems, is proposed for this category of\ngeneralized network to guarantee its global consensus. Under the proposed\nevent-triggered coordination strategy, sufficient conditions are derived to\nguarantee the leaderless and leader-follower global consensus of the\nmulti-agent systems on matrix-weighted networks, respectively. The Zeno\nphenomenon can be excluded for both cases under the proposed coordination\nstrategy. It turns out that the spectral properties of matrix-valued weights\nare crucial in event-triggered mechanism design for matrix-weighted networks\nwith actuator saturation constraint. Finally, simulations are provided to\ndemonstrate the effectiveness of proposed event-triggered coordination\nstrategy. This work provides a more general design framework compared with\nexisting results that are only applicable to scalar-weighted networks.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2106.06198\n",
    "authors": [
      "Lulu Pan",
      "Haibin Shao",
      "Yuanlong Li",
      "Dewei Li",
      "Yugeng Xi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.13356"
  },
  {
    "id": "arXiv:2110.13362",
    "title": "Camera-Based Physiological Sensing: Challenges and Future Directions",
    "abstract": "Numerous real-world applications have been driven by the recent algorithmic\nadvancement of artificial intelligence (AI). Healthcare is no exception and AI\ntechnologies have great potential to revolutionize the industry. Non-contact\ncamera-based physiological sensing, including remote photoplethysmography\n(rPPG), is a set of imaging methods that leverages ordinary RGB cameras (e.g.,\nwebcam or smartphone camera) to capture subtle changes in electromagnetic\nradiation (e.g., light) reflected by the body caused by physiological\nprocesses. Because of the relative ubiquity of cameras, these methods not only\nhave the ability to measure the signals without contact with the body but also\nhave the opportunity to capture multimodal information (e.g., facial\nexpressions, activities and other context) from the same sensor. However,\ndeveloping accessible, equitable and useful camera-based physiological sensing\nsystems comes with various challenges. In this article, we identify four\nresearch challenges for the field of camera-based physiological sensing and\nbroader AI driven healthcare communities and suggest future directions to\ntackle these. We believe solving these challenges will help deliver accurate,\nequitable and generalizable AI systems for healthcare that are practical in\nreal-world and clinical contexts.",
    "descriptor": "",
    "authors": [
      "Xin Liu",
      "Shwetak Patel",
      "Daniel McDuff"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.13362"
  },
  {
    "id": "arXiv:2110.13363",
    "title": "Exponential Graph is Provably Efficient for Decentralized Deep Training",
    "abstract": "Decentralized SGD is an emerging training method for deep learning known for\nits much less (thus faster) communication per iteration, which relaxes the\naveraging step in parallel SGD to inexact averaging. The less exact the\naveraging is, however, the more the total iterations the training needs to\ntake. Therefore, the key to making decentralized SGD efficient is to realize\nnearly-exact averaging using little communication. This requires a skillful\nchoice of communication topology, which is an under-studied topic in\ndecentralized optimization.\nIn this paper, we study so-called exponential graphs where every node is\nconnected to $O(\\log(n))$ neighbors and $n$ is the total number of nodes. This\nwork proves such graphs can lead to both fast communication and effective\naveraging simultaneously. We also discover that a sequence of $\\log(n)$\none-peer exponential graphs, in which each node communicates to one single\nneighbor per iteration, can together achieve exact averaging. This favorable\nproperty enables one-peer exponential graph to average as effective as its\nstatic counterpart but communicates more efficiently. We apply these\nexponential graphs in decentralized (momentum) SGD to obtain the\nstate-of-the-art balance between per-iteration communication and iteration\ncomplexity among all commonly-used topologies. Experimental results on a\nvariety of tasks and models demonstrate that decentralized (momentum) SGD over\nexponential graphs promises both fast and high-quality training. Our code is\nimplemented through BlueFog and available at\nhttps://github.com/Bluefog-Lib/NeurIPS2021-Exponential-Graph.",
    "descriptor": "",
    "authors": [
      "Bicheng Ying",
      "Kun Yuan",
      "Yiming Chen",
      "Hanbin Hu",
      "Pan Pan",
      "Wotao Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.13363"
  },
  {
    "id": "arXiv:2110.13365",
    "title": "Multi-Faceted Hierarchical Multi-Task Learning for a Large Number of  Tasks with Multi-dimensional Relations",
    "abstract": "There has been many studies on improving the efficiency of shared learning in\nMulti-Task Learning(MTL). Previous work focused on the \"micro\" sharing\nperspective for a small number of tasks, while in Recommender Systems(RS) and\nother AI applications, there are often demands to model a large number of tasks\nwith multi-dimensional task relations. For example, when using MTL to model\nvarious user behaviors in RS, if we differentiate new users and new items from\nold ones, there will be a cartesian product style increase of tasks with\nmulti-dimensional relations. This work studies the \"macro\" perspective of\nshared learning network design and proposes a Multi-Faceted Hierarchical MTL\nmodel(MFH). MFH exploits the multi-dimension task relations with a nested\nhierarchical tree structure which maximizes the shared learning. We evaluate\nMFH and SOTA models in a large industry video platform of 10 billion samples\nand results show that MFH outperforms SOTA MTL models significantly in both\noffline and online evaluations across all user groups, especially remarkable\nfor new users with an online increase of 9.1\\% in app time per user and 1.85\\%\nin next-day retention rate. MFH now has been deployed in a large scale online\nvideo recommender system. MFH is especially beneficial to the cold-start\nproblems in RS where new users and new items often suffer from a \"local\noverfitting\" phenomenon. However, the idea is actually generic and widely\napplicable to other MTL scenarios.",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Junning Liu",
      "Zijie Xia",
      "Yu Lei",
      "Xinjian Li",
      "Xu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13365"
  },
  {
    "id": "arXiv:2110.13366",
    "title": "Newtonian Mechanics Based Transient Stability PART IV: Equivalent  Machine",
    "abstract": "This paper analyzes the mechanisms of the equivalent machine and also its\nadvantages in TSA. Based on the two group separations, an equivalent machine is\nmodeled through the equivalence of the motions of all machines inside each\ngroup. This \"motion equivalence\" fully ensures the modeling of the two-machine\nsystem and the corresponding Newtonian energy conversion. Against this\nbackground, the original system becomes the equivalent system. It is clarified\nthat the equivalent machine strictly follows the machine paradigms. These\nstrict followings bring the two advantages in the equivalent-machine based TSA:\n(i) the stability of the equivalent machine is characterized precisely, and\n(ii) the equivalent-machine trajectory variance is depicted clearly. The two\nadvantages are fully reflected in the precise definitions of the\nequivalent-machine based transient stability concepts. In particular, the\nequivalent machine swing is clearly depicted through the EDSP or EDLP of the\nmachine, and the critical stability of the equivalent system is strictly\ndefined as the critical stability of the equivalent machine. Simulation results\nshow that the effectiveness of the equivalent-machine in TSA.",
    "descriptor": "\nComments: This paper contains 15 pages and 27 figures\n",
    "authors": [
      "Songyan Wang",
      "Jilai Yu",
      "Aoife Foley",
      "Jingrui Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.13366"
  },
  {
    "id": "arXiv:2110.13368",
    "title": "OpenACC Acceleration of an Agent-Based Biological Simulation Framework",
    "abstract": "Computational biology has increasingly turned to agent-based modeling to\nexplore complex biological systems. Biological diffusion (diffusion, decay,\nsecretion, and uptake) is a key driver of biological tissues. GPU computing can\nvastly accelerate the diffusion and decay operators in the partial differential\nequations used to represent biological transport in an agent-based biological\nmodeling system. In this paper, we utilize OpenACC to accelerate the diffusion\nportion of PhysiCell, a cross-platform agent-based biosimulation framework. We\ndemonstrate an almost 40x speedup on the state-of-the-art NVIDIA A100 GPU\ncompared to a serial run on AMD's EPYC 7742. We also demonstrate 9x speedup on\nthe 64 core AMD EPYC 7742 multicore platform. By using OpenACC for both the\nCPUs and the GPUs, we maintain a single source code base, thus creating a\nportable yet performant solution. With the simulator's most significant\ncomputational bottleneck significantly reduced, we can continue cancer\nsimulations over much longer times.",
    "descriptor": "",
    "authors": [
      "Matt Stack",
      "Paul Macklin",
      "Robert Searles",
      "Sunita Chandrasekaran"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.13368"
  },
  {
    "id": "arXiv:2110.13369",
    "title": "Partial order: Finding Consensus among Uncertain Feature Attributions",
    "abstract": "Post-hoc feature importance is progressively being employed to explain\ndecisions of complex machine learning models. Yet in practice, reruns of the\ntraining algorithm and/or the explainer can result in contradicting statements\nof feature importance, henceforth reducing trust in those techniques. A\npossible avenue to address this issue is to develop strategies to aggregate\ndiverse explanations about feature importance. While the arithmetic mean, which\nyields a total order, has been advanced, we introduce an alternative: the\nconsensus among multiple models, which results in partial orders. The two\naggregation strategies are compared using Integrated Gradients and Shapley\nvalues on two regression datasets, and we show that a large portion of the\ninformation provided by the mean aggregation is not supported by the consensus\nof each individual model, raising suspicion on the trustworthiness of this\npractice.",
    "descriptor": "",
    "authors": [
      "Gabriel Laberge",
      "Yann Pequignot",
      "Foutse Khomh",
      "Mario Marchand",
      "Alexandre Mathieu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13369"
  },
  {
    "id": "arXiv:2110.13373",
    "title": "EnTRPO: Trust Region Policy Optimization Method with Entropy  Regularization",
    "abstract": "Trust Region Policy Optimization (TRPO) is a popular and empirically\nsuccessful policy search algorithm in reinforcement learning (RL). It\niteratively solved the surrogate problem which restricts consecutive policies\nto be close to each other. TRPO is an on-policy algorithm. On-policy methods\nbring many benefits, like the ability to gauge each resulting policy. However,\nthey typically discard all the knowledge about the policies which existed\nbefore. In this work, we use a replay buffer to borrow from the off-policy\nlearning setting to TRPO. Entropy regularization is usually used to improve\npolicy optimization in reinforcement learning. It is thought to aid exploration\nand generalization by encouraging more random policy choices. We add an Entropy\nregularization term to advantage over {\\pi}, accumulated over time steps, in\nTRPO. We call this update EnTRPO. Our experiments demonstrate EnTRPO achieves\nbetter performance for controlling a Cart-Pole system compared with the\noriginal TRPO",
    "descriptor": "",
    "authors": [
      "Sahar Roostaie",
      "Mohammad Mehdi Ebadzadeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13373"
  },
  {
    "id": "arXiv:2110.13374",
    "title": "Defining Blockchain Governance Principles: A Comprehensive Framework",
    "abstract": "Blockchain eliminates the need for trusted third party intermediaries in\nbusiness by enabling decentralised architecture in software applications.\nHowever, vulnerabilities in on-chain autonomous decision-making and cumbersome\noff-chain coordination have led to serious concerns about blockchain's ability\nto behave and make decisions in a trustworthy and efficient way. Blockchain\ngovernance has received considerable attention to support the decision-making\nprocess during the use and evolution of blockchain. Nevertheless, conventional\ngovernance frameworks are not applicable to blockchain due to its inherent\ndistributed architecture and decentralised decision process, which leads to the\nabsence of clear source of authority. Currently, there is a lack of systematic\nguidance on how blockchain governance can be implemented. Therefore, in this\npaper, we present a comprehensive blockchain governance framework that\nelucidates an integrated view of the degree of decentralisation, decision\nrights, incentives, accountability, ecosystem, and legal and ethical\nresponsibilities. The proposed framework is evaluated using four well-known\nblockchain platforms in terms of feasibility, applicability, and usability.",
    "descriptor": "\nComments: Submitted to Information Systems, Elsevier\n",
    "authors": [
      "Yue Liu",
      "Qinghua Lu",
      "Hye-Young Paik",
      "Liming Zhu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.13374"
  },
  {
    "id": "arXiv:2110.13376",
    "title": "Task-Specific Dependency-based Word Embedding Methods",
    "abstract": "Two task-specific dependency-based word embedding methods are proposed for\ntext classification in this work. In contrast with universal word embedding\nmethods that work for generic tasks, we design task-specific word embedding\nmethods to offer better performance in a specific task. Our methods follow the\nPPMI matrix factorization framework and derive word contexts from the\ndependency parse tree. The first one, called the dependency-based word\nembedding (DWE), chooses keywords and neighbor words of a target word in the\ndependency parse tree as contexts to build the word-context matrix. The second\nmethod, named class-enhanced dependency-based word embedding (CEDWE), learns\nfrom word-context as well as word-class co-occurrence statistics. DWE and CEDWE\nare evaluated on popular text classification datasets to demonstrate their\neffectiveness. It is shown by experimental results they outperform several\nstate-of-the-art word embedding methods.",
    "descriptor": "",
    "authors": [
      "Chengwei Wei",
      "Bin Wang",
      "C.-C. Jay Kuo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.13376"
  },
  {
    "id": "arXiv:2110.13377",
    "title": "Plug-and-Play Few-shot Object Detection with Meta Strategy and Explicit  Localization Inference",
    "abstract": "Aiming at recognizing and localizing the object of novel categories by a few\nreference samples, few-shot object detection is a quite challenging task.\nPrevious works often depend on the fine-tuning process to transfer their model\nto the novel category and rarely consider the defect of fine-tuning, resulting\nin many drawbacks. For example, these methods are far from satisfying in the\nlow-shot or episode-based scenarios since the fine-tuning process in object\ndetection requires much time and high-shot support data. To this end, this\npaper proposes a plug-and-play few-shot object detection (PnP-FSOD) framework\nthat can accurately and directly detect the objects of novel categories without\nthe fine-tuning process. To accomplish the objective, the PnP-FSOD framework\ncontains two parallel techniques to address the core challenges in the few-shot\nlearning, i.e., across-category task and few-annotation support. Concretely, we\nfirst propose two simple but effective meta strategies for the box classifier\nand RPN module to enable the across-category object detection without\nfine-tuning. Then, we introduce two explicit inferences into the localization\nprocess to reduce its dependence on the annotated data, including explicit\nlocalization score and semi-explicit box regression. In addition to the\nPnP-FSOD framework, we propose a novel one-step tuning method that can avoid\nthe defects in fine-tuning. It is noteworthy that the proposed techniques and\ntuning method are based on the general object detector without other prior\nmethods, so they are easily compatible with the existing FSOD methods.\nExtensive experiments show that the PnP-FSOD framework has achieved the\nstate-of-the-art few-shot object detection performance without any tuning\nmethod. After applying the one-step tuning method, it further shows a\nsignificant lead in both efficiency, precision, and recall, under varied\nevaluation protocols.",
    "descriptor": "\nComments: submitted to TNNLS\n",
    "authors": [
      "Junying Huang",
      "Fan Chen",
      "Liang Lin",
      "Dongyu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13377"
  },
  {
    "id": "arXiv:2110.13384",
    "title": "ViDA-MAN: Visual Dialog with Digital Humans",
    "abstract": "We demonstrate ViDA-MAN, a digital-human agent for multi-modal interaction,\nwhich offers realtime audio-visual responses to instant speech inquiries.\nCompared to traditional text or voice-based system, ViDA-MAN offers human-like\ninteractions (e.g, vivid voice, natural facial expression and body gestures).\nGiven a speech request, the demonstration is able to response with high quality\nvideos in sub-second latency. To deliver immersive user experience, ViDA-MAN\nseamlessly integrates multi-modal techniques including Acoustic Speech\nRecognition (ASR), multi-turn dialog, Text To Speech (TTS), talking heads video\ngeneration. Backed with large knowledge base, ViDA-MAN is able to chat with\nusers on a number of topics including chit-chat, weather, device control, News\nrecommendations, booking hotels, as well as answering questions via structured\nknowledge.",
    "descriptor": "",
    "authors": [
      "Tong Shen",
      "Jiawei Zuo",
      "Fan Shi",
      "Jin Zhang",
      "Liqin Jiang",
      "Meng Chen",
      "Zhengchen Zhang",
      "Wei Zhang",
      "Xiaodong He",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13384"
  },
  {
    "id": "arXiv:2110.13385",
    "title": "IIP-Transformer: Intra-Inter-Part Transformer for Skeleton-Based Action  Recognition",
    "abstract": "Recently, Transformer-based networks have shown great promise on\nskeleton-based action recognition tasks. The ability to capture global and\nlocal dependencies is the key to success while it also brings quadratic\ncomputation and memory cost. Another problem is that previous studies mainly\nfocus on the relationships among individual joints, which often suffers from\nthe noisy skeleton joints introduced by the noisy inputs of sensors or\ninaccurate estimations. To address the above issues, we propose a novel\nTransformer-based network (IIP-Transformer). Instead of exploiting interactions\namong individual joints, our IIP-Transformer incorporates body joints and parts\ninteractions simultaneously and thus can capture both joint-level (intra-part)\nand part-level (inter-part) dependencies efficiently and effectively. From the\ndata aspect, we introduce a part-level skeleton data encoding that\nsignificantly reduces the computational complexity and is more robust to\njoint-level skeleton noise. Besides, a new part-level data augmentation is\nproposed to improve the performance of the model. On two large-scale datasets,\nNTU-RGB+D 60 and NTU RGB+D 120, the proposed IIP-Transformer achieves\nthe-state-of-art performance with more than 8x less computational complexity\nthan DSTA-Net, which is the SOTA Transformer-based method.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Qingtian Wang",
      "Jianlin Peng",
      "Shuze Shi",
      "Tingxi Liu",
      "Jiabin He",
      "Renliang Weng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13385"
  },
  {
    "id": "arXiv:2110.13386",
    "title": "Self-Denoising Neural Networks for Few Shot Learning",
    "abstract": "In this paper, we introduce a new architecture for few shot learning, the\ntask of teaching a neural network from as few as one or five labeled examples.\nInspired by the theoretical results of Alaine et al that Denoising Autoencoders\nrefine features to lie closer to the true data manifold, we present a new\ntraining scheme that adds noise at multiple stages of an existing neural\narchitecture while simultaneously learning to be robust to this added noise.\nThis architecture, which we call a Self-Denoising Neural Network (SDNN), can be\napplied easily to most modern convolutional neural architectures, and can be\nused as a supplement to many existing few-shot learning techniques. We\nempirically show that SDNNs out-perform previous state-of-the-art methods for\nfew shot image recognition using the Wide-ResNet architecture on the\n\\textit{mini}ImageNet, tiered-ImageNet, and CIFAR-FS few shot learning\ndatasets. We also perform a series of ablation experiments to empirically\njustify the construction of the SDNN architecture. Finally, we show that SDNNs\neven improve few shot performance on the task of human action detection in\nvideo using experiments on the ActEV SDL Surprise Activities challenge.",
    "descriptor": "",
    "authors": [
      "Steven Schwarcz",
      "Sai Saketh Rambhatla",
      "Rama Chellappa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13386"
  },
  {
    "id": "arXiv:2110.13388",
    "title": "Semi-Supervised Federated Learning with non-IID Data: Algorithm and  System Design",
    "abstract": "Federated Learning (FL) allows edge devices (or clients) to keep data locally\nwhile simultaneously training a shared high-quality global model. However,\ncurrent research is generally based on an assumption that the training data of\nlocal clients have ground-truth. Furthermore, FL faces the challenge of\nstatistical heterogeneity, i.e., the distribution of the client's local\ntraining data is non-independent identically distributed (non-IID). In this\npaper, we present a robust semi-supervised FL system design, where the system\naims to solve the problem of data availability and non-IID in FL. In\nparticular, this paper focuses on studying the labels-at-server scenario where\nthere is only a limited amount of labeled data on the server and only unlabeled\ndata on the clients. In our system design, we propose a novel method to tackle\nthe problems, which we refer to as Federated Mixing (FedMix). FedMix improves\nthe naive combination of FL and semi-supervised learning methods and designs\nparameter decomposition strategies for disjointed learning of labeled,\nunlabeled data, and global models. To alleviate the non-IID problem, we propose\na novel aggregation rule based on the frequency of the client's participation\nin training, namely the FedFreq aggregation algorithm, which can adjust the\nweight of the corresponding local model according to this frequency. Extensive\nevaluations conducted on CIFAR-10 dataset show that the performance of our\nproposed method is significantly better than those of the current baseline. It\nis worth noting that our system is robust to different non-IID levels of client\ndata.",
    "descriptor": "",
    "authors": [
      "Zhe Zhang",
      "Shiyao Ma",
      "Jiangtian Nie",
      "Yi Wu",
      "Qiang Yan",
      "Xiaoke Xu",
      "Dusit Niyato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13388"
  },
  {
    "id": "arXiv:2110.13389",
    "title": "A Normalized Gaussian Wasserstein Distance for Tiny Object Detection",
    "abstract": "Detecting tiny objects is a very challenging problem since a tiny object only\ncontains a few pixels in size. We demonstrate that state-of-the-art detectors\ndo not produce satisfactory results on tiny objects due to the lack of\nappearance information. Our key observation is that Intersection over Union\n(IoU) based metrics such as IoU itself and its extensions are very sensitive to\nthe location deviation of the tiny objects, and drastically deteriorate the\ndetection performance when used in anchor-based detectors. To alleviate this,\nwe propose a new evaluation metric using Wasserstein distance for tiny object\ndetection. Specifically, we first model the bounding boxes as 2D Gaussian\ndistributions and then propose a new metric dubbed Normalized Wasserstein\nDistance (NWD) to compute the similarity between them by their corresponding\nGaussian distributions. The proposed NWD metric can be easily embedded into the\nassignment, non-maximum suppression, and loss function of any anchor-based\ndetector to replace the commonly used IoU metric. We evaluate our metric on a\nnew dataset for tiny object detection (AI-TOD) in which the average object size\nis much smaller than existing object detection datasets. Extensive experiments\nshow that, when equipped with NWD metric, our approach yields performance that\nis 6.7 AP points higher than a standard fine-tuning baseline, and 6.0 AP points\nhigher than state-of-the-art competitors.",
    "descriptor": "",
    "authors": [
      "Jinwang Wang",
      "Chang Xu",
      "Wen Yang",
      "Lei Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13389"
  },
  {
    "id": "arXiv:2110.13390",
    "title": "Novel Binary Addition Tree Algorithm (BAT) for Calculating the Direct  Lower-Bound of the Highly Reliable Binary-State Network Reliability",
    "abstract": "Real-world applications such as the internet of things, wireless sensor\nnetworks, smart grids, transportation networks, communication networks, social\nnetworks, and computer grid systems are typically modeled as network\nstructures. Network reliability represents the success probability of a network\nand it is an effective and popular metric for evaluating the performance of all\ntypes of networks. Binary-state networks composed of binary-state (e.g.,\nworking or failed) components (arcs and/or nodes) are some of the most popular\nnetwork structures. The scale of networks has grown dramatically in recent\nyears. For example, social networks have more than a billion users.\nAdditionally, the reliability of components has increased as a result of both\nmature and emergent technology. For highly reliable networks, it is more\npractical to calculate approximated reliability, rather than exact reliability,\nwhich is an NP-hard problem. Therefore, we propose a novel direct reliability\nlower bound based on the binary addition tree algorithm to calculate\napproximate reliability. The efficiency and effectiveness of the proposed\nreliability bound are analyzed based on time complexity and validated through\nnumerical experiments.",
    "descriptor": "",
    "authors": [
      "Wei-Chang Yeh"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)",
      "Combinatorics (math.CO)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2110.13390"
  },
  {
    "id": "arXiv:2110.13392",
    "title": "Graph-based Heuristic Solution for Placing Distributed Video Processing  Applications on Moving Vehicle Clusters",
    "abstract": "Vehicular fog computing (VFC) is envisioned as an extension of cloud and\nmobile edge computing to utilize the rich sensing and processing resources\navailable in vehicles. We focus on slow-moving cars that spend a significant\ntime in urban traffic congestion as a potential pool of on-board sensors, video\ncameras, and processing capacity. For leveraging the dynamic network and\nprocessing resources, we utilize a stochastic mobility model to select nodes\nwith similar mobility patterns. We then design two distributed applications\nthat are scaled in real-time and placed as multiple instances on selected\nvehicular fog nodes. We handle the unstable vehicular environment by a), Using\nreal vehicle density data to build a realistic mobility model that helps in\nselecting nodes for service deployment b), Using community-detection algorithms\nfor selecting a robust vehicular cluster using the predicted mobility behavior\nof vehicles. The stability of the chosen cluster is validated using a graph\ncentrality measure, and c), Graph-based placement heuristics are developed to\nfind the optimal placement of service graphs based on a multi-objective\nconstrained optimization problem with the objective of efficient resource\nutilization. The heuristic solves an important problem of processing data\ngenerated from distributed devices by balancing the trade-off between\nincreasing the number of service instances to have enough redundancy of\nprocessing instances to increase resilience in the service in case of node or\nlink failure, versus reducing their number to minimise resource usage. We\ncompare our heuristic to an integer linear program solution and a first-fit\nheuristic. Our approach performs better than these comparable schemes in terms\nof resource utilization and/or has a lesser service latency, which is a crucial\nrequirement for safety-related applications.",
    "descriptor": "\nComments: 14 pages, 10 figures\n",
    "authors": [
      "Kanika Sharma",
      "Bernard Butler",
      "Brendan Jennings"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.13392"
  },
  {
    "id": "arXiv:2110.13395",
    "title": "Transferring Domain-Agnostic Knowledge in Video Question Answering",
    "abstract": "Video question answering (VideoQA) is designed to answer a given question\nbased on a relevant video clip. The current available large-scale datasets have\nmade it possible to formulate VideoQA as the joint understanding of visual and\nlanguage information. However, this training procedure is costly and still less\ncompetent with human performance. In this paper, we investigate a transfer\nlearning method by the introduction of domain-agnostic knowledge and\ndomain-specific knowledge. First, we develop a novel transfer learning\nframework, which finetunes the pre-trained model by applying domain-agnostic\nknowledge as the medium. Second, we construct a new VideoQA dataset with 21,412\nhuman-generated question-answer samples for comparable transfer of knowledge.\nOur experiments show that: (i) domain-agnostic knowledge is transferable and\n(ii) our proposed transfer learning framework can boost VideoQA performance\neffectively.",
    "descriptor": "",
    "authors": [
      "Tianran Wu",
      "Noa Garcia",
      "Mayu Otani",
      "Chenhui Chu",
      "Yuta Nakashima",
      "Haruo Takemura"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13395"
  },
  {
    "id": "arXiv:2110.13398",
    "title": "Unified Instance and Knowledge Alignment Pretraining for Aspect-based  Sentiment Analysis",
    "abstract": "Aspect-based Sentiment Analysis (ABSA) aims to determine the sentiment\npolarity towards an aspect. Because of the expensive and limited labelled data,\nthe pretraining strategy has become the de-facto standard for ABSA. However,\nthere always exists severe domain shift between the pretraining and downstream\nABSA datasets, hindering the effective knowledge transfer when directly\nfinetuning and making the downstream task performs sub-optimal. To mitigate\nsuch domain shift, we introduce a unified alignment pretraining framework into\nthe vanilla pretrain-finetune pipeline with both instance- and knowledge-level\nalignments. Specifically, we first devise a novel coarse-to-fine retrieval\nsampling approach to select target domain-related instances from the\nlarge-scale pretraining dataset, thus aligning the instances between\npretraining and target domains (\\textit{First Stage}). Then, we introduce a\nknowledge guidance-based strategy to further bridge the domain gap at the\nknowledge level. In practice, we formulate the model pretrained on the sampled\ninstances into a knowledge guidance model and a learner model, respectively. On\nthe target dataset, we design an on-the-fly teacher-student joint fine-tuning\napproach to progressively transfer the knowledge from the knowledge guidance\nmodel to the learner model (\\textit{Second Stage}). Thereby, the learner model\ncan maintain more domain-invariant knowledge when learning new knowledge from\nthe target dataset. In the \\textit{Third Stage,} the learner model is finetuned\nto better adapt its learned knowledge to the target dataset. Extensive\nexperiments and analyses on several ABSA benchmarks demonstrate the\neffectiveness and universality of our proposed pretraining framework. Notably,\nour pretraining framework pushes several strong baseline models up to the new\nstate-of-the-art records. We release our code and models.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Juhua Liu",
      "Qihuang Zhong",
      "Liang Ding",
      "Hua Jin",
      "Bo Du",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13398"
  },
  {
    "id": "arXiv:2110.13400",
    "title": "Scale-Free Adversarial Multi-Armed Bandit with Arbitrary Feedback Delays",
    "abstract": "We consider the Scale-Free Adversarial Multi Armed Bandit (MAB) problem with\nunrestricted feedback delays. In contrast to the standard assumption that all\nlosses are $[0,1]$-bounded, in our setting, losses can fall in a general\nbounded interval $[-L, L]$, unknown to the agent before-hand. Furthermore, the\nfeedback of each arm pull can experience arbitrary delays. We propose an\nalgorithm named \\texttt{SFBanker} for this novel setting, which combines a\nrecent banker online mirror descent technique and elaborately designed doubling\ntricks. We show that \\texttt{SFBanker} achieves $\\mathcal\nO(\\sqrt{K(D+T)}L)\\cdot {\\rm polylog}(T, L)$ total regret, where $T$ is the\ntotal number of steps and $D$ is the total feedback delay. \\texttt{SFBanker}\nalso outperforms existing algorithm for non-delayed (i.e., $D=0$) scale-free\nadversarial MAB problem instances. We also present a variant of\n\\texttt{SFBanker} for problem instances with non-negative losses (i.e., they\nrange in $[0, L]$ for some unknown $L$), achieving an $\\tilde{\\mathcal\nO}(\\sqrt{K(D+T)}L)$ total regret, which is near-optimal compared to the\n$\\Omega(\\sqrt{KT}+\\sqrt{D\\log K}L)$ lower-bound ([Cesa-Bianchi et al., 2016]).",
    "descriptor": "",
    "authors": [
      "Jiatai Huang",
      "Yan Dai",
      "Longbo Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.13400"
  },
  {
    "id": "arXiv:2110.13407",
    "title": "VLSI Implementation of Cryptographic Algorithms & Techniques: A  Literature Review",
    "abstract": "Through the years, the flow of Data and its transmission have increased\ntremendously and so has the security issues to it. Cryptography in recent years\nwith the advancement of VLSI has led to its implementation of Encryption and\nDecryption techniques, where the process of translating and converting\nplaintext into cypher text and vice versa is made possible. In this paper, the\nreview of various aspects of VLSI's implementation of encryption and decryption\nare covered. To systemize the material, the information about topics such as\nPrivate Key Encryption, Index Technique, Blowfish Algorithm, DNA cryptography,\nand many more are reviewed. Ultimately, with this review, the basic\nunderstanding of different VLSI techniques of Encryption and Decryption can be\nstudied and implemented.",
    "descriptor": "",
    "authors": [
      "Favin Fernandes",
      "Gauravi Dungarwal",
      "Aishwariya Gaikwad",
      "Ishan Kareliya",
      "Swati Shilaskar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2110.13407"
  },
  {
    "id": "arXiv:2110.13408",
    "title": "Learning Rich Features for Gait Recognition by Integrating Skeletons and  Silhouettes",
    "abstract": "Gait recognition captures gait patterns from the walking sequence of an\nindividual for identification. Most existing gait recognition methods learn\nfeatures from silhouettes or skeletons for the robustness to clothing,\ncarrying, and other exterior factors. The combination of the two data\nmodalities, however, is not fully exploited. This paper proposes a simple yet\neffective bimodal fusion (BiFusion) network, which mines the complementary\nclues of skeletons and silhouettes, to learn rich features for gait\nidentification. Particularly, the inherent hierarchical semantics of body\njoints in a skeleton is leveraged to design a novel Multi-scale Gait Graph\n(MSGG) network for the feature extraction of skeletons. Extensive experiments\non CASIA-B and OUMVLP demonstrate both the superiority of the proposed MSGG\nnetwork in modeling skeletons and the effectiveness of the bimodal fusion for\ngait recognition. Under the most challenging condition of walking in different\nclothes on CASIA-B, our method achieves the rank-1 accuracy of 92.1%.",
    "descriptor": "\nComments: 10 pages,5 figures\n",
    "authors": [
      "Yunjie Peng",
      "Saihui Hou",
      "Kang Ma",
      "Yang Zhang",
      "Yongzhen Huang",
      "Zhiqiang He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13408"
  },
  {
    "id": "arXiv:2110.13409",
    "title": "Task-Aware Meta Learning-based Siamese Neural Network for Classifying  Obfuscated Malware",
    "abstract": "Malware authors apply different obfuscation techniques on the generic feature\nof malware (i.e., unique malware signature) to create new variants to avoid\ndetection. Existing Siamese Neural Network (SNN) based malware detection\nmethods fail to correctly classify different malware families when similar\ngeneric features are shared across multiple malware variants resulting in high\nfalse-positive rates. To address this issue, we propose a novel Task-Aware Meta\nLearning-based Siamese Neural Network resilient against obfuscated malware\nwhile able to detect malware trained with one or a few training samples. Using\nentropy features of each malware signature alongside image features as task\ninputs, our task-aware meta leaner generates the parameters for the feature\nlayers to more accurately adjust the feature embedding for different malware\nfamilies. In addition, our model utilizes meta-learning with the extracted\nfeatures of a pre-trained network (e.g., VGG-16) to avoid the bias typically\nassociated with a model trained with a limited number of training samples. Our\nproposed approach is highly effective in recognizing unique malware signatures,\nthus correctly classifying malware samples that belong to the same malware\nfamily even in the presence of obfuscation technique applied to malware. Our\nexperimental results, validated with N-way on N-shot learning, show that our\nmodel is highly effective in classification accuracy exceeding the rate>91%\ncompared to other similar methods.",
    "descriptor": "",
    "authors": [
      "Jinting Zhu",
      "Julian Jang-Jaccard",
      "Amardeep Singh",
      "Paul A. Watters",
      "Seyit Camtepe"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13409"
  },
  {
    "id": "arXiv:2110.13410",
    "title": "Comparison of Indicators of Location Homophily Using Twitter Follow  Graph",
    "abstract": "Location homophily is a tendency of Twitter users whose followers tend to be\nin the same or nearby areas. Intuitively, although users with a higher number\nof follower relationships might have negative homophily indicators, it is worth\nconsulting actual Twitter data. Moreover, there may be certain functions\nregarding the numbers of friends and followers that are more directly\ncorrelated to the homophily. In this study, the ratio of the number of friends\nto the number of followers is shown to be a more effective negative indicator\nof homophily, and the results for 10 different countries are verified.",
    "descriptor": "\nComments: The 2021 International Conference on Advanced Informatics: Concepts, Theory and Applications (ICAICTA 2021)\n",
    "authors": [
      "Shiori Hironaka",
      "Mitsuo Yoshida",
      "Kyoji Umemura"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.13410"
  },
  {
    "id": "arXiv:2110.13412",
    "title": "TriBERT: Full-body Human-centric Audio-visual Representation Learning  for Visual Sound Separation",
    "abstract": "The recent success of transformer models in language, such as BERT, has\nmotivated the use of such architectures for multi-modal feature learning and\ntasks. However, most multi-modal variants (e.g., ViLBERT) have limited\nthemselves to visual-linguistic data. Relatively few have explored its use in\naudio-visual modalities, and none, to our knowledge, illustrate them in the\ncontext of granular audio-visual detection or segmentation tasks such as sound\nsource separation and localization. In this work, we introduce TriBERT -- a\ntransformer-based architecture, inspired by ViLBERT, which enables contextual\nfeature learning across three modalities: vision, pose, and audio, with the use\nof flexible co-attention. The use of pose keypoints is inspired by recent works\nthat illustrate that such representations can significantly boost performance\nin many audio-visual scenarios where often one or more persons are responsible\nfor the sound explicitly (e.g., talking) or implicitly (e.g., sound produced as\na function of human manipulating an object). From a technical perspective, as\npart of the TriBERT architecture, we introduce a learned visual tokenization\nscheme based on spatial attention and leverage weak-supervision to allow\ngranular cross-modal interactions for visual and pose modalities. Further, we\nsupplement learning with sound-source separation loss formulated across all\nthree streams. We pre-train our model on the large MUSIC21 dataset and\ndemonstrate improved performance in audio-visual sound source separation on\nthat dataset as well as other datasets through fine-tuning. In addition, we\nshow that the learned TriBERT representations are generic and significantly\nimprove performance on other audio-visual tasks such as cross-modal\naudio-visual-pose retrieval by as much as 66.7% in top-1 accuracy.",
    "descriptor": "\nComments: 10 pages, 5 Figures, Neurips 2021\n",
    "authors": [
      "Tanzila Rahman",
      "Mengyu Yang",
      "Leonid Sigal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13412"
  },
  {
    "id": "arXiv:2110.13413",
    "title": "Convergent Boosted Smoothing for Modeling Graph Data with Tabular Node  Features",
    "abstract": "For supervised learning with tabular data, decision tree ensembles produced\nvia boosting techniques generally dominate real-world applications involving\niid training/test sets. However for graph data where the iid assumption is\nviolated due to structured relations between samples, it remains unclear how to\nbest incorporate this structure within existing boosting pipelines. To this\nend, we propose a generalized framework for iterating boosting with graph\npropagation steps that share node/sample information across edges connecting\nrelated samples. Unlike previous efforts to integrate graph-based models with\nboosting, our approach is anchored in a principled meta loss function such that\nprovable convergence can be guaranteed under relatively mild assumptions.\nAcross a variety of non-iid graph datasets with tabular node features, our\nmethod achieves comparable or superior performance than both tabular and graph\nneural network models, as well as existing hybrid strategies that combine the\ntwo. Beyond producing better predictive performance than recently proposed\ngraph models, our proposed techniques are easy to implement, computationally\nmore efficient, and enjoy stronger theoretical guarantees (which make our\nresults more reproducible).",
    "descriptor": "",
    "authors": [
      "Jiuhai Chen",
      "Jonas Mueller",
      "Vassilis N. Ioannidis",
      "Soji Adeshina",
      "Yangkun Wang",
      "Tom Goldstein",
      "David Wipf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13413"
  },
  {
    "id": "arXiv:2110.13414",
    "title": "Semantic Host-free Trojan Attack",
    "abstract": "In this paper, we propose a novel host-free Trojan attack with triggers that\nare fixed in the semantic space but not necessarily in the pixel space. In\ncontrast to existing Trojan attacks which use clean input images as hosts to\ncarry small, meaningless trigger patterns, our attack considers triggers as\nfull-sized images belonging to a semantically meaningful object class. Since in\nour attack, the backdoored classifier is encouraged to memorize the abstract\nsemantics of the trigger images than any specific fixed pattern, it can be\nlater triggered by semantically similar but different looking images. This\nmakes our attack more practical to be applied in the real-world and harder to\ndefend against. Extensive experimental results demonstrate that with only a\nsmall number of Trojan patterns for training, our attack can generalize well to\nnew patterns of the same Trojan class and can bypass state-of-the-art defense\nmethods.",
    "descriptor": "",
    "authors": [
      "Haripriya Harikumar",
      "Kien Do",
      "Santu Rana",
      "Sunil Gupta",
      "Svetha Venkatesh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.13414"
  },
  {
    "id": "arXiv:2110.13418",
    "title": "Research on the inverse kinematics prediction of a soft actuator via BP  neural network",
    "abstract": "In this work we address the inverse kinetics problem of motion planning of\nthe soft actuators driven by three chambers. Although the mathematical model\ndescribing inverse dynamics of this kind of actuator can been employed, this\nmodel is still a complex system. On the one hand, the differential equations\nare nonlinear, therefore, it is very difficult and time consuming to get the\nanalytical solutions. Since the exact solutions of the mechanical model are not\navailable, the elements of the Jacobian matrix cannot be calculated. On the\nother hand, material model is a complicated system with significant\nnonlinearity, non-stationarity, and uncertainty, making it challenging to\ndevelop an appropriate system model. To overcome these intrinsic problems, we\npropose a back-propagation (BP) neural network learning the inverse kinetics of\nthe soft manipulator moving in three-dimensional space. After the training, the\nBP neural network model can represent the relation between the manipulator tip\nposition and the pressures applied to the chambers. The proposed algorithm is\nvery precise, and computationally efficient. The results show that a desired\nterminal position can be achieved with a degree of accuracy of 2.59% relative\naverage error with respect to the total actuator length, demonstrate the\nability of the model to realize inverse kinematic control.",
    "descriptor": "\nComments: 8 pages, 9 fgures\n",
    "authors": [
      "Huichen Ma",
      "Junjie Zhou",
      "Jian Zhang",
      "Lingyu Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.13418"
  },
  {
    "id": "arXiv:2110.13422",
    "title": "Relay Variational Inference: A Method for Accelerated Encoderless VI",
    "abstract": "Variational Inference (VI) offers a method for approximating intractable\nlikelihoods. In neural VI, inference of approximate posteriors is commonly done\nusing an encoder. Alternatively, encoderless VI offers a framework for learning\ngenerative models from data without encountering suboptimalities caused by\namortization via an encoder (e.g. in presence of missing or uncertain data).\nHowever, in absence of an encoder, such methods often suffer in convergence due\nto the slow nature of gradient steps required to learn the approximate\nposterior parameters. In this paper, we introduce Relay VI (RVI), a framework\nthat dramatically improves both the convergence and performance of encoderless\nVI. In our experiments over multiple datasets, we study the effectiveness of\nRVI in terms of convergence speed, loss, representation power and missing data\nimputation. We find RVI to be a unique tool, often superior in both performance\nand convergence speed to previously proposed encoderless as well as amortized\nVI models (e.g. VAE).",
    "descriptor": "",
    "authors": [
      "Amir Zadeh",
      "Santiago Benoit",
      "Louis-Philippe Morency"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.13422"
  },
  {
    "id": "arXiv:2110.13423",
    "title": "Towards More Generalizable One-shot Visual Imitation Learning",
    "abstract": "A general-purpose robot should be able to master a wide range of tasks and\nquickly learn a novel one by leveraging past experiences. One-shot imitation\nlearning (OSIL) approaches this goal by training an agent with (pairs of)\nexpert demonstrations, such that at test time, it can directly execute a new\ntask from just one demonstration. However, so far this framework has been\nlimited to training on many variations of one task, and testing on other unseen\nbut similar variations of the same task. In this work, we push for a higher\nlevel of generalization ability by investigating a more ambitious multi-task\nsetup. We introduce a diverse suite of vision-based robot manipulation tasks,\nconsisting of 7 tasks, a total of 61 variations, and a continuum of instances\nwithin each variation. For consistency and comparison purposes, we first train\nand evaluate single-task agents (as done in prior few-shot imitation work). We\nthen study the multi-task setting, where multi-task training is followed by (i)\none-shot imitation on variations within the training tasks, (ii) one-shot\nimitation on new tasks, and (iii) fine-tuning on new tasks. Prior\nstate-of-the-art, while performing well within some single tasks, struggles in\nthese harder multi-task settings. To address these limitations, we propose\nMOSAIC (Multi-task One-Shot Imitation with self-Attention and Contrastive\nlearning), which integrates a self-attention model architecture and a temporal\ncontrastive module to enable better task disambiguation and more robust\nrepresentation learning. Our experiments show that MOSAIC outperforms prior\nstate of the art in learning efficiency, final performance, and learns a\nmulti-task policy with promising generalization ability via fine-tuning on\nnovel tasks.",
    "descriptor": "",
    "authors": [
      "Zhao Mandi",
      "Fangchen Liu",
      "Kimin Lee",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13423"
  },
  {
    "id": "arXiv:2110.13424",
    "title": "Precise URL Phishing Detection Using Neural Networks",
    "abstract": "With the development of the Internet, ways of obtaining important data such\nas passwords and logins or sensitive personal data have increased. One of the\nways to extract such information is page impersonation, also called phishing.\nSuch websites do not provide service but collect sensitive details from the\nuser. Here, we present you with ways to detect such malicious URLs with state\nof art accuracy with neural networks. Different from previous works, where web\ncontent, URL or traffic statistics are examined, we analyse only the URL text,\nmaking it faster and which detects zero-day attacks. The network is optimised\nand can be used even on small devices such as Ras-Pi without a change in\nperformance.",
    "descriptor": "\nComments: 10 pages, 9 figures\n",
    "authors": [
      "Aman Rangapur",
      "Dr Ajith Jubilson"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.13424"
  },
  {
    "id": "arXiv:2110.13430",
    "title": "Contextual Similarity Aggregation with Self-attention for Visual  Re-ranking",
    "abstract": "In content-based image retrieval, the first-round retrieval result by simple\nvisual feature comparison may be unsatisfactory, which can be refined by visual\nre-ranking techniques. In image retrieval, it is observed that the contextual\nsimilarity among the top-ranked images is an important clue to distinguish the\nsemantic relevance. Inspired by this observation, in this paper, we propose a\nvisual re-ranking method by contextual similarity aggregation with\nself-attention. In our approach, for each image in the top-K ranking list, we\nrepresent it into an affinity feature vector by comparing it with a set of\nanchor images. Then, the affinity features of the top-K images are refined by\naggregating the contextual information with a transformer encoder. Finally, the\naffinity features are used to recalculate the similarity scores between the\nquery and the top-K images for re-ranking of the latter. To further improve the\nrobustness of our re-ranking model and enhance the performance of our method, a\nnew data augmentation scheme is designed. Since our re-ranking model is not\ndirectly involved with the visual feature used in the initial retrieval, it is\nready to be applied to retrieval result lists obtained from various retrieval\nalgorithms. We conduct comprehensive experiments on four benchmark datasets to\ndemonstrate the generality and effectiveness of our proposed visual re-ranking\nmethod.",
    "descriptor": "\nComments: Accepted to NeurIPS, 2021\n",
    "authors": [
      "Jianbo Ouyang",
      "Hui Wu",
      "Min Wang",
      "Wengang Zhou",
      "Houqiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13430"
  },
  {
    "id": "arXiv:2110.13431",
    "title": "Meter-Range Wireless Motor Drive for Pipeline Transportation",
    "abstract": "This paper proposes and implements a meter-range wireless motor drive (WMD)\nsystem for promising applications of underground pipeline transportations or\nin-pipe robots. To power a pipeline network beneath the earth, both the power\ngrid and the control system are usually required to be deployed deep\nunderground, thus increasing the construction cost, maintenance difficulty and\nsystem complexity. The proposed system newly develops a hybrid repeater to\nenable the desired meter-range wireless power and drive transfer, which can\noffer a fault-tolerant network with a robust structure for the underground\nsensor-free WMD while maintaining a high transmission efficiency. Hence, this\nwireless pipeline network can reduce the maintenance requirement and regulate\nthe flow rate effectively. A full-scale prototype has been built for practical\nverification, and the system efficiency can reach 88.8% at a long transfer\ndistance of 150 cm. Theoretical analysis, software simulation and hardware\nexperimentation are given to verify the feasibility of proposed meter-range WMD\nfor underground pipeline transportations.",
    "descriptor": "",
    "authors": [
      "Wei Liu",
      "K. T. Chau",
      "Hui Wang",
      "Tengbo Yang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.13431"
  },
  {
    "id": "arXiv:2110.13434",
    "title": "AVocaDo: Strategy for Adapting Vocabulary to Downstream Domain",
    "abstract": "During the fine-tuning phase of transfer learning, the pretrained vocabulary\nremains unchanged, while model parameters are updated. The vocabulary generated\nbased on the pretrained data is suboptimal for downstream data when domain\ndiscrepancy exists. We propose to consider the vocabulary as an optimizable\nparameter, allowing us to update the vocabulary by expanding it with\ndomain-specific vocabulary based on a tokenization statistic. Furthermore, we\npreserve the embeddings of the added words from overfitting to downstream data\nby utilizing knowledge learned from a pretrained language model with a\nregularization term. Our method achieved consistent performance improvements on\ndiverse domains (i.e., biomedical, computer science, news, and reviews).",
    "descriptor": "\nComments: EMNLP2021 Accepted\n",
    "authors": [
      "Jimin Hong",
      "Taehee Kim",
      "Hyesu Lim",
      "Jaegul Choo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.13434"
  },
  {
    "id": "arXiv:2110.13435",
    "title": "Understanding the Role of Self-Supervised Learning in  Out-of-Distribution Detection Task",
    "abstract": "Self-supervised learning (SSL) has achieved great success in a variety of\ncomputer vision tasks. However, the mechanism of how SSL works in these tasks\nremains a mystery. In this paper, we study how SSL can enhance the performance\nof the out-of-distribution (OOD) detection task. We first point out two general\nproperties that a good OOD detector should have: 1) the overall feature space\nshould be large and 2) the inlier feature space should be small. Then we\ndemonstrate that SSL can indeed increase the intrinsic dimension of the overall\nfeature space. In the meantime, SSL even has the potential to shrink the inlier\nfeature space. As a result, there will be more space spared for the outliers,\nmaking OOD detection much easier. The conditions when SSL can shrink the inlier\nfeature space is also discussed and validated. By understanding the role of SSL\nin the OOD detection task, our study can provide a guideline for designing\nbetter OOD detection algorithms. Moreover, this work can also shed light to\nother tasks where SSL can improve the performance.",
    "descriptor": "",
    "authors": [
      "Jiuhai Chen",
      "Chen Zhu",
      "Bin Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13435"
  },
  {
    "id": "arXiv:2110.13440",
    "title": "A deep learning driven pseudospectral PCE based FFT homogenization  algorithm for complex microstructures",
    "abstract": "This work is directed to uncertainty quantification of homogenized effective\nproperties for composite materials with complex, three dimensional\nmicrostructure. The uncertainties arise in the material parameters of the\nsingle constituents as well as in the fiber volume fraction. They are taken\ninto account by multivariate random variables. Uncertainty quantification is\nachieved by an efficient surrogate model based on pseudospectral polynomial\nchaos expansion and artificial neural networks. An artificial neural network is\ntrained on synthetic binary voxelized unit cells of composite materials with\nuncertain three dimensional microstructures, uncertain linear elastic material\nparameters and different loading directions. The prediction goals of the\nartificial neural network are the corresponding effective components of the\nelasticity tensor, where the labels for training are generated via a fast\nFourier transform based numerical homogenization method. The trained artificial\nneural network is then used as a deterministic solver for a pseudospectral\npolynomial chaos expansion based surrogate model to achieve the corresponding\nstatistics of the effective properties. Three numerical examples deal with the\ncomparison of the presented method to the literature as well as the application\nto different microstructures. It is shown, that the proposed method is able to\npredict central moments of interest while being magnitudes faster to evaluate\nthan traditional approaches.",
    "descriptor": "",
    "authors": [
      "Alexander Henkes",
      "Ismail Caylak",
      "Rolf Mahnken"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13440"
  },
  {
    "id": "arXiv:2110.13444",
    "title": "A time-weighted metric for sets of trajectories to assess multi-object  tracking algorithms",
    "abstract": "This paper proposes a metric for sets of trajectories to evaluate\nmulti-object tracking algorithms that includes time-weighted costs for\nlocalisation errors of properly detected targets, for false targets, missed\ntargets and track switches. The proposed metric extends the metric in [1] by\nincluding weights to the costs associated to different time steps. The\ntime-weighted costs increase the flexibility of the metric [1] to fit more\napplications and user preferences. We first introduce a metric based on\nmulti-dimensional assignments, and then its linear programming relaxation,\nwhich is computable in polynomial time and is also a metric. The metrics can\nalso be extended to metrics on random finite sets of trajectories to evaluate\nand rank algorithms across different scenarios, each with a ground truth set of\ntrajectories.",
    "descriptor": "\nComments: Matlab code available at this https URL (Trajectory metric folder)\n",
    "authors": [
      "\u00c1ngel F. Garc\u00eda-Fern\u00e1ndez",
      "Abu Sajana Rahmathullah",
      "Lennart Svensson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.13444"
  },
  {
    "id": "arXiv:2110.13448",
    "title": "Modeling of Frequency Security Constraints and Quantification of  Frequency Control Reserve Requirements for Unit Commitment",
    "abstract": "The high penetration of converter-based renewable energy sources has brought\nchallenges to the power system frequency control. It is essential to consider\nthe frequency security constraints and frequency control reserve requirements\nin unit commitment (UC). Considering that the risk of frequency insecurity\nvaries under the changeable operational condition, we propose to optimize the\nPFC droop gains and reserve capacities in the UC model to provide diverse\ncontrol efforts in different risk levels adaptively. Copula theory is used to\nestablish the joint distribution model among frequency control performance,\nsecondary frequency control (SFC) reserve capacities, and power fluctuations.\nThen the distributionally robust optimization technique is utilized in the SFC\nreserve requirement determination to handle the possible error in the\nprobability model. The UC simulation is conducted on IEEE 118-bus system to\ntest the proposed optimal PFC droop gain strategy and SFC reserve requirement\nquantification method. Simulation results show that the proposed optimal PFC\ndroop gain strategy is better than the traditional fixed PFC droop gain setting\non economic efficiency and operational flexibility. Besides, the SFC reserve\nrequirement calculated by the proposed method is more appropriate than the\nactual SFC reserve capacity in the historical operation.",
    "descriptor": "\nComments: This paper has been submitted to Journal of Modern Power Systems and Clean Energy\n",
    "authors": [
      "Likai Liu",
      "Zechun Hu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.13448"
  },
  {
    "id": "arXiv:2110.13450",
    "title": "Distributed Multi-Agent Deep Reinforcement Learning Framework for  Whole-building HVAC Control",
    "abstract": "It is estimated that about 40%-50% of total electricity consumption in\ncommercial buildings can be attributed to Heating, Ventilation, and Air\nConditioning (HVAC) systems. Minimizing the energy cost while considering the\nthermal comfort of the occupants is very challenging due to unknown and complex\nrelationships between various HVAC controls and thermal dynamics inside a\nbuilding. To this end, we present a multi-agent, distributed deep reinforcement\nlearning (DRL) framework based on Energy Plus simulation environment for\noptimizing HVAC in commercial buildings. This framework learns the complex\nthermal dynamics in the building and takes advantage of the differential effect\nof cooling and heating systems in the building to reduce energy costs, while\nmaintaining the thermal comfort of the occupants. With adaptive penalty, the RL\nalgorithm can be prioritized for energy savings or maintaining thermal comfort.\nUsing DRL, we achieve more than 75\\% savings in energy consumption. The\ndistributed DRL framework can be scaled to multiple GPUs and CPUs of\nheterogeneous types.",
    "descriptor": "",
    "authors": [
      "Vinay Hanumaiah",
      "Sahika Genc"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.13450"
  },
  {
    "id": "arXiv:2110.13452",
    "title": "On the Optimization Landscape of Maximum Mean Discrepancy",
    "abstract": "Generative models have been successfully used for generating realistic\nsignals. Because the likelihood function is typically intractable in most of\nthese models, the common practice is to use \"implicit\" models that avoid\nlikelihood calculation. However, it is hard to obtain theoretical guarantees\nfor such models. In particular, it is not understood when they can globally\noptimize their non-convex objectives. Here we provide such an analysis for the\ncase of Maximum Mean Discrepancy (MMD) learning of generative models. We prove\nseveral optimality results, including for a Gaussian distribution with low rank\ncovariance (where likelihood is inapplicable) and a mixture of Gaussians. Our\nanalysis shows that that the MMD optimization landscape is benign in these\ncases, and therefore gradient based methods will globally minimize the MMD\nobjective.",
    "descriptor": "",
    "authors": [
      "Itai Alon",
      "Amir Globerson",
      "Ami Wiesel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.13452"
  },
  {
    "id": "arXiv:2110.13458",
    "title": "Estimation-Energy Tradeoff for Scalar Gauss-Markov Signals with Kalman  Filtering",
    "abstract": "In this letter, we investigate a receiver architecture, which uses the\nreceived signal in order to simultaneously harvest energy and estimate a\nGauss-Markov linear process. We study three communication scenarios: i) static\nchannel, ii) Rayleigh block-fading channel, and iii) high power amplifier (HPA)\nnonlinearities at the transmitter side. Theoretical results for the minimum\nmean square error as well as the average harvested energy are given for all\ncases and the fundamental tradeoff between estimation quality and harvested\nenergy is characterized. We show that channel fading improves the estimation\nperformance while HPA requires an extended Kalman filter at the receiver and\nsignificantly affects both the estimation and the harvesting efficiency.",
    "descriptor": "\nComments: 6 figures\n",
    "authors": [
      "Ioannis Krikidis",
      "Constantinos Psomas"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.13458"
  },
  {
    "id": "arXiv:2110.13459",
    "title": "A critical review of the proposed reforms of the academic performance  indicators applied in the assessment of researchers' performance in Hungary",
    "abstract": "The academic performance indicators of the Doctor of Science title, the\nhighest and most prestigious qualification awarded by the Hungarian Academy of\nSciences (HAS), are key in the national assessment system. The types of\nperformance indicators, as well as their minimum values, are incorporated into\nthe application requirements of academic promotions, scientific qualifications,\nand research scholarships. HAS has proposed a reform of these performance\nindicators, to align with the current national and global trends. The proposed\nmodifications are generally based on arbitrary decisions and the consensus\nbetween academicians, namely, the representatives of the sections of HAS. This\npaper contains a bibliometric analysis of 25,000 publications produced between\n2011 and 2020 by 683 researchers affiliated with HAS's Section of Earth\nSciences. The bibliometric data of the publications are processed by integer\nand fractional counting, respectively. The main goal of the paper is to argue\nthat discipline-specific co-authorship patterns should be accounted for in the\nassessment procedure. It is also shown that the homogenization of the\nperformance indicators and the rigid use of the integer counting method favour\nhard natural science disciplines and disadvantage social science disciplines.\nFinally, I describe some components of an alternative publishing strategy which\nwould be most prudent for researchers, given the proposed assessment criteria.",
    "descriptor": "",
    "authors": [
      "Gyorgy Csomos"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2110.13459"
  },
  {
    "id": "arXiv:2110.13463",
    "title": "Multi-scale Deterministic Optimisation of Blended Composite Structures:  Case Study of a Box-Wing",
    "abstract": "This work presents a multi-scale design methodology for the deterministic\noptimisation of thin-walled composite structures integrating a global-local\napproach for the assessment of the buckling strength and a dedicated strategy\nto recover blended stacking sequences. The methodology is based on the\nmulti-scale two-level optimisation strategy for anisotropic materials and\nstructures. In the first step, focused on the macroscopic scale, several design\nrequirements are included in the problem formulation: lightness, feasibility,\nmanufacturing, blending, buckling failure, static failure and stiffness. The\nsecond step, which focuses on the laminate mesoscopic scale, deals with the\nrecovery of blended stacking sequences, for the structure at hand, matching the\noptimal geometric and elastic properties determined in the first step. As a\ncase study, the unconventional PrandtlPlane box-wing system is used to show the\neffectiveness of the proposed design methodology.",
    "descriptor": "",
    "authors": [
      "M. Picchi Scardaoni",
      "M. I. Izzi",
      "M. Montemurro",
      "E. Panettieri",
      "V. Cipolla",
      "V. Binante"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.13463"
  },
  {
    "id": "arXiv:2110.13464",
    "title": "MarS-FL: A Market Share-based Decision Support Framework for  Participation in Federated Learning",
    "abstract": "Federated learning (FL) enables multiple participants (PTs) to build an\naggregate and more powerful learning model without sharing data, thus\nmaintaining data privacy and security. Among the key application scenarios is a\ncompetitive market where market shares represent PTs' competitiveness. An\nunderstanding of the role of FL in evolving market shares plays a key role in\nadvancing the adoption of FL by PTs.\nIn terms of modeling, we adapt a general economic model to the FL context and\nintroduce two notions of $\\delta$-stable market and friendliness to measure the\nviability of FL and the market acceptability to FL. Further, we address related\ndecision-making issues with FL designer and PTs. First, we characterize the\nprocess by which each PT participates in FL as a non-cooperative game and prove\nits dominant strategy. Second, as an FL designer, the final model performance\nimprovement of each PT should be bounded, which relates to the market\nconditions of a particular FL application scenario; we give a sufficient and\nnecessary condition $Q$ to maintain the market $\\delta$-stability and quantify\nthe friendliness $\\kappa$. The condition $Q$ gives a specific requirement while\nan FL designer allocates performance improvements among PTs. In a typical case\nof oligopoly, closed-form expressions of $Q$ and $\\kappa$ are given. Finally,\nnumerical results are given to show the viability of FL in a wide range of\nmarket conditions. Our results help identify optimal PT strategies, the viable\noperational space of an FL designer, and the market conditions under which FL\nis especially beneficial.",
    "descriptor": "",
    "authors": [
      "Xiaohu Wu",
      "Han Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.13464"
  },
  {
    "id": "arXiv:2110.13465",
    "title": "CS-Rep: Making Speaker Verification Networks Embracing  Re-parameterization",
    "abstract": "Automatic speaker verification (ASV) systems, which determine whether two\nspeeches are from the same speaker, mainly focus on verification accuracy while\nignoring inference speed. However, in real applications, both inference speed\nand verification accuracy are essential. This study proposes cross-sequential\nre-parameterization (CS-Rep), a novel topology re-parameterization strategy for\nmulti-type networks, to increase the inference speed and verification accuracy\nof models. CS-Rep solves the problem that existing re-parameterization methods\nare unsuitable for typical ASV backbones. When a model applies CS-Rep, the\ntraining-period network utilizes a multi-branch topology to capture speaker\ninformation, whereas the inference-period model converts to a time-delay neural\nnetwork (TDNN)-like plain backbone with stacked TDNN layers to achieve the fast\ninference speed. Based on CS-Rep, an improved TDNN with friendly test and\ndeployment called Rep-TDNN is proposed. Compared with the state-of-the-art\nmodel ECAPA-TDNN, which is highly recognized in the industry, Rep-TDNN\nincreases the actual inference speed by about 50% and reduces the EER by 10%.\nThe code will be released.",
    "descriptor": "\nComments: submitted to ICASSP 2022\n",
    "authors": [
      "Ruiteng Zhang",
      "Jianguo Wei",
      "Wenhuan Lu",
      "Lin Zhang",
      "Yantao Ji",
      "Junhai Xu",
      "Xugang Lu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.13465"
  },
  {
    "id": "arXiv:2110.13466",
    "title": "Quantitative Evaluation of Snapshot Graphs for the Analysis of Temporal  Networks",
    "abstract": "One of the most common approaches to the analysis of dynamic networks is\nthrough time-window aggregation. The resulting representation is a sequence of\nstatic networks, i.e. the snapshot graph. Despite this representation being\nwidely used in the literature, a general framework to evaluate the soundness of\nsnapshot graphs is still missing. In this article, we propose two scores to\nquantify conflicting objectives: Stability measures how much stable the\nsequence of snapshots is, while Fidelity measures the loss of information\ncompared to the original data. We also develop a technique of targeted\nfiltering of the links, to simplify the original temporal network. Our\nframework is tested on datasets of proximity and face-to-face interactions.",
    "descriptor": "\nComments: 12 pages, 5 figures. To be published in \"Proceedings of the Tenth International Conference on Complex Networks and Their Applications\"\n",
    "authors": [
      "Alessandro Chiappori",
      "R\u00e9my Cazabet"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.13466"
  },
  {
    "id": "arXiv:2110.13468",
    "title": "Enhanced User Grouping and Pairing Schemes for CoMP NOMA based Cellular  Networks",
    "abstract": "Non-orthogonal multiple access (NOMA) has been identified as one of the\npromising technologies to enhance the spectral efficiency and throughput for\nthe 5G and beyond cellular networks. Alternatively, coordinated multi-point\n(CoMP) improves the cell edge users coverage. Thus, CoMP and NOMA can be used\ntogether to improve the overall coverage and throughput of the cell edge users.\nHowever, user grouping and pairing for CoMP-NOMA based cellular networks has\nnot been suitably addressed in the existing literature. Motivated by this, we\npropose two user grouping and pairing schemes for a CoMP-NOMA based system.\nBoth the schemes are compared in terms of overall throughput and coverage.\nNumerical results are presented for various densities of users, base stations,\nand CoMP thresholds. Moreover, the results are compared with the purely\nOMA-based benchmark system, NOMA only, and CoMP only systems. We show through\nsimulation results that the proposed schemes offer a trade-off between\nthroughput and coverage as compared to a purely NOMA or CoMP based system.",
    "descriptor": "\nComments: Submitted to COMSNETS 2022\n",
    "authors": [
      "Akhileswar Chowdary",
      "Garima Chopra",
      "Abhinav Kumar",
      "Linga Reddy Cenkeramaddi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.13468"
  },
  {
    "id": "arXiv:2110.13470",
    "title": "Subject Adaptive EEG-based Visual Recognition",
    "abstract": "This paper focuses on EEG-based visual recognition, aiming to predict the\nvisual object class observed by a subject based on his/her EEG signals. One of\nthe main challenges is the large variation between signals from different\nsubjects. It limits recognition systems to work only for the subjects involved\nin model training, which is undesirable for real-world scenarios where new\nsubjects are frequently added. This limitation can be alleviated by collecting\na large amount of data for each new user, yet it is costly and sometimes\ninfeasible. To make the task more practical, we introduce a novel problem\nsetting, namely subject adaptive EEG-based visual recognition. In this setting,\na bunch of pre-recorded data of existing users (source) is available, while\nonly a little training data from a new user (target) are provided. At inference\ntime, the model is evaluated solely on the signals from the target user. This\nsetting is challenging, especially because training samples from source\nsubjects may not be helpful when evaluating the model on the data from the\ntarget subject. To tackle the new problem, we design a simple yet effective\nbaseline that minimizes the discrepancy between feature distributions from\ndifferent subjects, which allows the model to extract subject-independent\nfeatures. Consequently, our model can learn the common knowledge shared among\nsubjects, thereby significantly improving the recognition performance for the\ntarget subject. In the experiments, we demonstrate the effectiveness of our\nmethod under various settings. Our code is available at\nhttps://github.com/DeepBCI/Deep-BCI/tree/master/1_Intelligent_BCI/Subject_Adaptive_EEG_based_Visual_Recognition.",
    "descriptor": "\nComments: Accepted by ACPR 2021. Code is available at this https URL\n",
    "authors": [
      "Pilhyeon Lee",
      "Sunhee Hwang",
      "Seogkyu Jeon",
      "Hyeran Byun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13470"
  },
  {
    "id": "arXiv:2110.13471",
    "title": "Response-based Distillation for Incremental Object Detection",
    "abstract": "Traditional object detection are ill-equipped for incremental learning.\nHowever, fine-tuning directly on a well-trained detection model with only new\ndata will leads to catastrophic forgetting. Knowledge distillation is a\nstraightforward way to mitigate catastrophic forgetting. In Incremental Object\nDetection (IOD), previous work mainly focuses on feature-level knowledge\ndistillation, but the different response of detector has not been fully\nexplored yet. In this paper, we propose a fully response-based incremental\ndistillation method focusing on learning response from detection bounding boxes\nand classification predictions. Firstly, our method transferring category\nknowledge while equipping student model with the ability to retain localization\nknowledge during incremental learning. In addition, we further evaluate the\nqualities of all locations and provides valuable response by adaptive\npseudo-label selection (APS) strategies. Finally, we elucidate that knowledge\nfrom different responses should be assigned with different importance during\nincremental distillation. Extensive experiments conducted on MS COCO\ndemonstrate significant advantages of our method, which substantially narrow\nthe performance gap towards full training.",
    "descriptor": "",
    "authors": [
      "Tao Feng",
      "Mang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13471"
  },
  {
    "id": "arXiv:2110.13472",
    "title": "Decomposing Complex Questions Makes Multi-Hop QA Easier and More  Interpretable",
    "abstract": "Multi-hop QA requires the machine to answer complex questions through finding\nmultiple clues and reasoning, and provide explanatory evidence to demonstrate\nthe machine reasoning process. We propose Relation Extractor-Reader and\nComparator (RERC), a three-stage framework based on complex question\ndecomposition, which is the first work that the RERC model has been proposed\nand applied in solving the multi-hop QA challenges. The Relation Extractor\ndecomposes the complex question, and then the Reader answers the sub-questions\nin turn, and finally the Comparator performs numerical comparison and\nsummarizes all to get the final answer, where the entire process itself\nconstitutes a complete reasoning evidence path. In the 2WikiMultiHopQA dataset,\nour RERC model has achieved the most advanced performance, with a winning joint\nF1 score of 53.58 on the leaderboard. All indicators of our RERC are close to\nhuman performance, with only 1.95 behind the human level in F1 score of support\nfact. At the same time, the evidence path provided by our RERC framework has\nexcellent readability and faithfulness.",
    "descriptor": "\nComments: Accepted to EMNLP2021 Findings Long Paper\n",
    "authors": [
      "Ruiliu Fu",
      "Han Wang",
      "Xuejun Zhang",
      "Jun Zhou",
      "Yonghong Yan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.13472"
  },
  {
    "id": "arXiv:2110.13473",
    "title": "CTRN: Class-Temporal Relational Network for Action Detection",
    "abstract": "Action detection is an essential and challenging task, especially for densely\nlabelled datasets of untrimmed videos. There are many real-world challenges in\nthose datasets, such as composite action, co-occurring action, and high\ntemporal variation of instance duration. For handling these challenges, we\npropose to explore both the class and temporal relations of detected actions.\nIn this work, we introduce an end-to-end network: Class-Temporal Relational\nNetwork (CTRN). It contains three key components: (1) The Representation\nTransform Module filters the class-specific features from the mixed\nrepresentations to build graph-structured data. (2) The Class-Temporal Module\nmodels the class and temporal relations in a sequential manner. (3)\nG-classifier leverages the privileged knowledge of the snippet-wise\nco-occurring action pairs to further improve the co-occurring action detection.\nWe evaluate CTRN on three challenging densely labelled datasets and achieve\nstate-of-the-art performance, reflecting the effectiveness and robustness of\nour method.",
    "descriptor": "",
    "authors": [
      "Rui Dai",
      "Srijan Das",
      "Francois Bremond"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13473"
  },
  {
    "id": "arXiv:2110.13475",
    "title": "Vector-valued Distance and Gyrocalculus on the Space of Symmetric  Positive Definite Matrices",
    "abstract": "We propose the use of the vector-valued distance to compute distances and\nextract geometric information from the manifold of symmetric positive definite\nmatrices (SPD), and develop gyrovector calculus, constructing analogs of vector\nspace operations in this curved space. We implement these operations and\nshowcase their versatility in the tasks of knowledge graph completion, item\nrecommendation, and question answering. In experiments, the SPD models\noutperform their equivalents in Euclidean and hyperbolic space. The\nvector-valued distance allows us to visualize embeddings, showing that the\nmodels learn to disentangle representations of positive samples from negative\nones.",
    "descriptor": "\nComments: 30 pages. Accepted at NeurIPS 2021 as spotlight presentation (top 3%)\n",
    "authors": [
      "Federico L\u00f3pez",
      "Beatrice Pozzetti",
      "Steve Trettel",
      "Michael Strube",
      "Anna Wienhard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2110.13475"
  },
  {
    "id": "arXiv:2110.13479",
    "title": "Zero-Shot Action Recognition from Diverse Object-Scene Compositions",
    "abstract": "This paper investigates the problem of zero-shot action recognition, in the\nsetting where no training videos with seen actions are available. For this\nchallenging scenario, the current leading approach is to transfer knowledge\nfrom the image domain by recognizing objects in videos using pre-trained\nnetworks, followed by a semantic matching between objects and actions. Where\nobjects provide a local view on the content in videos, in this work we also\nseek to include a global view of the scene in which actions occur. We find that\nscenes on their own are also capable of recognizing unseen actions, albeit more\nmarginally than objects, and a direct combination of object-based and\nscene-based scores degrades the action recognition performance. To get the best\nout of objects and scenes, we propose to construct them as a Cartesian product\nof all possible compositions. We outline how to determine the likelihood of\nobject-scene compositions in videos, as well as a semantic matching from\nobject-scene compositions to actions that enforces diversity among the most\nrelevant compositions for each action. While simple, our composition-based\napproach outperforms object-based approaches and even state-of-the-art\nzero-shot approaches that rely on large-scale video datasets with hundreds of\nseen actions for training and knowledge transfer.",
    "descriptor": "\nComments: BMVC 2021\n",
    "authors": [
      "Carlo Bretti",
      "Pascal Mettes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13479"
  },
  {
    "id": "arXiv:2110.13480",
    "title": "Simultaneous Neural Machine Translation with Constituent Label  Prediction",
    "abstract": "Simultaneous translation is a task in which translation begins before the\nspeaker has finished speaking, so it is important to decide when to start the\ntranslation process. However, deciding whether to read more input words or\nstart to translate is difficult for language pairs with different word orders\nsuch as English and Japanese. Motivated by the concept of pre-reordering, we\npropose a couple of simple decision rules using the label of the next\nconstituent predicted by incremental constituent label prediction. In\nexperiments on English-to-Japanese simultaneous translation, the proposed\nmethod outperformed baselines in the quality-latency trade-off.",
    "descriptor": "\nComments: WMT2021\n",
    "authors": [
      "Yasumasa Kano",
      "Katsuhito Sudoh",
      "Satoshi Nakamura"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.13480"
  },
  {
    "id": "arXiv:2110.13484",
    "title": "Applications of Multi-Agent Reinforcement Learning in Future Internet: A  Comprehensive Survey",
    "abstract": "Future Internet involves several emerging technologies such as 5G and beyond\n5G networks, vehicular networks, unmanned aerial vehicle (UAV) networks, and\nInternet of Things (IoTs). Moreover, future Internet becomes heterogeneous and\ndecentralized with a large number of involved network entities. Each entity may\nneed to make its local decision to improve the network performance under\ndynamic and uncertain network environments. Standard learning algorithms such\nas single-agent Reinforcement Learning (RL) or Deep Reinforcement Learning\n(DRL) have been recently used to enable each network entity as an agent to\nlearn an optimal decision-making policy adaptively through interacting with the\nunknown environments. However, such an algorithm fails to model the\ncooperations or competitions among network entities, and simply treats other\nentities as a part of the environment that may result in the non-stationarity\nissue. Multi-agent Reinforcement Learning (MARL) allows each network entity to\nlearn its optimal policy by observing not only the environments, but also other\nentities' policies. As a result, MARL can significantly improve the learning\nefficiency of the network entities, and it has been recently used to solve\nvarious issues in the emerging networks. In this paper, we thus review the\napplications of MARL in the emerging networks. In particular, we provide a\ntutorial of MARL and a comprehensive survey of applications of MARL in next\ngeneration Internet. In particular, we first introduce single-agent RL and\nMARL. Then, we review a number of applications of MARL to solve emerging issues\nin future Internet. The issues consist of network access, transmit power\ncontrol, computation offloading, content caching, packet routing, trajectory\ndesign for UAV-aided networks, and network security issues.",
    "descriptor": "",
    "authors": [
      "Tianxu Li",
      "Kun Zhu",
      "Nguyen Cong Luong",
      "Dusit Niyato",
      "Qihui Wu",
      "Yang Zhang",
      "Bing Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.13484"
  },
  {
    "id": "arXiv:2110.13488",
    "title": "Wavelet: Code-based postquantum signatures with fast verification on  microcontrollers",
    "abstract": "This work presents the first full implementation of Wave, a postquantum\ncode-based signature scheme. We define Wavelet, a concrete Wave scheme at the\n128-bit classical security level (or NIST postquantum security Level 1)\nequipped with a fast verification algorithm targeting embedded devices. Wavelet\noffers 930-byte signatures, with a public key of 3161 kB. We include\nimplementation details using AVX instructions, and on ARM Cortex-M4, including\na solution to deal with Wavelet's large public keys, which do not fit in the\nSRAM of a typical embedded device. Our verification algorithm is $\\approx 4.65\n\\times$ faster then the original, and verifies in 1 087 538 cycles using AVX\ninstructions, or 13 172 ticks in an ARM Cortex-M4.",
    "descriptor": "",
    "authors": [
      "Gustavo Banegas",
      "Thomas Debris-Alazard",
      "Milena Nedeljkovi\u0107",
      "Benjamin Smith"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.13488"
  },
  {
    "id": "arXiv:2110.13489",
    "title": "Visual Selective Attention System to Intervene User Attention in Sharing  COVID-19 Misinformation",
    "abstract": "Information sharing on social media must be accompanied by attentive behavior\nso that in a distorted digital environment, users are not rushed and distracted\nin deciding to share information. The spread of misinformation, especially\nthose related to the COVID-19, can divide and create negative effects of\nfalsehood in society. Individuals can also cause feelings of fear, health\nanxiety, and confusion in the treatment COVID-19. Although much research has\nfocused on understanding human judgment from a psychological underline, few\nhave addressed the essential issue in the screening phase of what technology\ncan interfere amidst users' attention in sharing information. This research\naims to intervene in the user's attention with a visual selective attention\napproach. This study uses a quantitative method through studies 1 and 2 with\npre-and post-intervention experiments. In study 1, we intervened in user\ndecisions and attention by stimulating ten information and misinformation using\nthe Visual Selective Attention System (VSAS) tool. In Study 2, we identified\nassociations of user tendencies in evaluating information using the Implicit\nAssociation Test (IAT). The significant results showed that the user's\nattention and decision behavior improved after using the VSAS. The IAT results\nshow a change in the association of user exposure, where after the intervention\nusing VSAS, users tend not to share misinformation about COVID-19. The results\nare expected to be the basis for developing social media applications to combat\nthe negative impact of the infodemic COVID-19 misinformation.",
    "descriptor": "",
    "authors": [
      "Zaid Amin",
      "Nazlena Mohamad Ali",
      "Alan F. Smeaton"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.13489"
  },
  {
    "id": "arXiv:2110.13491",
    "title": "Continuous data assimilation for two-phase flow: analysis and  simulations",
    "abstract": "We propose, analyze, and test a novel continuous data assimilation two-phase\nflow algorithm for reservoir simulation. We show that the solutions of the\nalgorithm, constructed using coarse mesh observations, converge at an\nexponential rate in time to the corresponding exact reference solution of the\ntwo-phase model. More precisely, we obtain a stability estimate which\nillustrates an exponential decay of the residual error between the reference\nand approximate solution, until the error hits a threshold depending on the\norder of data resolution. Numerical computations are included to demonstrate\nthe effectiveness of this approach, as well as variants with data on\nsub-domains. In particular, we demonstrate numerically that synchronization is\nachieved for data collected from a small fraction of the domain.",
    "descriptor": "",
    "authors": [
      "Yat Tin Chow",
      "Wing Tat Leung",
      "Ali Pakzad"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.13491"
  },
  {
    "id": "arXiv:2110.13492",
    "title": "TUNet: A Block-online Bandwidth Extension Model based on Transformers  and Self-supervised Pretraining",
    "abstract": "We introduce a block-online variant of the temporal feature-wise linear\nmodulation (TFiLM) model to achieve bandwidth extension. The proposed\narchitecture simplifies the UNet backbone of the TFiLM to reduce inference time\nand employs an efficient transformer at the bottleneck to alleviate performance\ndegradation. We also utilize self-supervised pretraining and data augmentation\nto enhance the quality of bandwidth extended signals and reduce the sensitivity\nwith respect to downsampling methods. Experiment results on the VCTK dataset\nshow that the proposed method outperforms several recent baselines in terms of\nspectral distance and source-to-distortion ratio. Pretraining and filter\naugmentation also help stabilize and enhance the overall performance.",
    "descriptor": "\nComments: ICASSP 2022 submitted, 5 pages, 4 figures, 3 tables\n",
    "authors": [
      "Viet-Anh Nguyen",
      "Anh H. T. Nguyen",
      "Andy W. H. Khong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.13492"
  },
  {
    "id": "arXiv:2110.13494",
    "title": "Meta-Learning for Multi-Label Few-Shot Classification",
    "abstract": "Even with the luxury of having abundant data, multi-label classification is\nwidely known to be a challenging task to address. This work targets the problem\nof multi-label meta-learning, where a model learns to predict multiple labels\nwithin a query (e.g., an image) by just observing a few supporting examples. In\ndoing so, we first propose a benchmark for Few-Shot Learning (FSL) with\nmultiple labels per sample. Next, we discuss and extend several solutions\nspecifically designed to address the conventional and single-label FSL, to work\nin the multi-label regime. Lastly, we introduce a neural module to estimate the\nlabel count of a given sample by exploiting the relational inference. We will\nshow empirically the benefit of the label count module, the label propagation\nalgorithm, and the extensions of conventional FSL methods on three challenging\ndatasets, namely MS-COCO, iMaterialist, and Open MIC. Overall, our thorough\nexperiments suggest that the proposed label-propagation algorithm in\nconjunction with the neural label count module (NLC) shall be considered as the\nmethod of choice.",
    "descriptor": "\nComments: Accepted to WACV 2022\n",
    "authors": [
      "Christian Simon",
      "Piotr Koniusz",
      "Mehrtash Harandi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13494"
  },
  {
    "id": "arXiv:2110.13495",
    "title": "Assessing the Sufficiency of Arguments through Conclusion Generation",
    "abstract": "The premises of an argument give evidence or other reasons to support a\nconclusion. However, the amount of support required depends on the generality\nof a conclusion, the nature of the individual premises, and similar. An\nargument whose premises make its conclusion rationally worthy to be drawn is\ncalled sufficient in argument quality research. Previous work tackled\nsufficiency assessment as a standard text classification problem, not modeling\nthe inherent relation of premises and conclusion. In this paper, we hypothesize\nthat the conclusion of a sufficient argument can be generated from its\npremises. To study this hypothesis, we explore the potential of assessing\nsufficiency based on the output of large-scale pre-trained language models. Our\nbest model variant achieves an F1-score of .885, outperforming the previous\nstate-of-the-art and being on par with human experts. While manual evaluation\nreveals the quality of the generated conclusions, their impact remains low\nultimately.",
    "descriptor": "",
    "authors": [
      "Timon Gurcke",
      "Milad Alshomary",
      "Henning Wachsmuth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.13495"
  },
  {
    "id": "arXiv:2110.13499",
    "title": "SEDML: Securely and Efficiently Harnessing Distributed Knowledge in  Machine Learning",
    "abstract": "Training high-performing deep learning models require a rich amount of data\nwhich is usually distributed among multiple data sources in practice. Simply\ncentralizing these multi-sourced data for training would raise critical\nsecurity and privacy concerns, and might be prohibited given the increasingly\nstrict data regulations. To resolve the tension between privacy and data\nutilization in distributed learning, a machine learning framework called\nprivate aggregation of teacher ensembles(PATE) has been recently proposed. PATE\nharnesses the knowledge (label predictions for an unlabeled dataset) from\ndistributed teacher models to train a student model, obviating access to\ndistributed datasets. Despite being enticing, PATE does not offer protection\nfor the individual label predictions from teacher models, which still entails\nprivacy risks. In this paper, we propose SEDML, a new protocol which allows to\nsecurely and efficiently harness the distributed knowledge in machine learning.\nSEDML builds on lightweight cryptography and provides strong protection for the\nindividual label predictions, as well as differential privacy guarantees on the\naggregation results. Extensive evaluations show that while providing privacy\nprotection, SEDML preserves the accuracy as in the plaintext baseline.\nMeanwhile, SEDML's performance in computing and communication is 43 times and\n1.23 times higher than the latest technology, respectively.",
    "descriptor": "",
    "authors": [
      "Yansong Gao",
      "Qun Li",
      "Yifeng Zheng",
      "Guohong Wang",
      "Jiannan Wei",
      "Mang Su"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.13499"
  },
  {
    "id": "arXiv:2110.13500",
    "title": "Exploring Content Moderation in the Decentralised Web: The Pleroma Case",
    "abstract": "Decentralising the Web is a desirable but challenging goal. One particular\nchallenge is achieving decentralised content moderation in the face of various\nadversaries (e.g. trolls). To overcome this challenge, many Decentralised Web\n(DW) implementations rely on federation policies. Administrators use these\npolicies to create rules that ban or modify content that matches specific\nrules. This, however, can have unintended consequences for many users. In this\npaper, we present the first study of federation policies on the DW, their\nin-the-wild usage, and their impact on users. We identify how these policies\nmay negatively impact \"innocent\" users and outline possible solutions to avoid\nthis problem in the future.",
    "descriptor": "",
    "authors": [
      "Anaobi Ishaku Hassan",
      "Aravindh Raman",
      "Ignacio Castro",
      "Haris Bin Zia",
      "Emiliano De Cristofaro",
      "Nishanth Sastry",
      "Gareth Tyson"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.13500"
  },
  {
    "id": "arXiv:2110.13501",
    "title": "Tensor Network Kalman Filtering for Large-Scale LS-SVMs",
    "abstract": "Least squares support vector machines are a commonly used supervised learning\nmethod for nonlinear regression and classification. They can be implemented in\neither their primal or dual form. The latter requires solving a linear system,\nwhich can be advantageous as an explicit mapping of the data to a possibly\ninfinite-dimensional feature space is avoided. However, for large-scale\napplications, current low-rank approximation methods can perform inadequately.\nFor example, current methods are probabilistic due to their sampling\nprocedures, and/or suffer from a poor trade-off between the ranks and\napproximation power. In this paper, a recursive Bayesian filtering framework\nbased on tensor networks and the Kalman filter is presented to alleviate the\ndemanding memory and computational complexities associated with solving\nlarge-scale dual problems. The proposed method is iterative, does not require\nexplicit storage of the kernel matrix, and allows the formulation of early\nstopping conditions. Additionally, the framework yields confidence estimates of\nobtained models, unlike alternative methods. The performance is tested on two\nregression and three classification experiments, and compared to the Nystr\\\"om\nand fixed size LS-SVM methods. Results show that our method can achieve high\nperformance and is particularly useful when alternative methods are\ncomputationally infeasible due to a slowly decaying kernel matrix spectrum.",
    "descriptor": "",
    "authors": [
      "Maximilian Lucassen",
      "Johan A.K. Suykens",
      "Kim Batselier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.13501"
  },
  {
    "id": "arXiv:2110.13502",
    "title": "Shared Independent Component Analysis for Multi-Subject Neuroimaging",
    "abstract": "We consider shared response modeling, a multi-view learning problem where one\nwants to identify common components from multiple datasets or views. We\nintroduce Shared Independent Component Analysis (ShICA) that models each view\nas a linear transform of shared independent components contaminated by additive\nGaussian noise. We show that this model is identifiable if the components are\neither non-Gaussian or have enough diversity in noise variances. We then show\nthat in some cases multi-set canonical correlation analysis can recover the\ncorrect unmixing matrices, but that even a small amount of sampling noise makes\nMultiset CCA fail. To solve this problem, we propose to use joint\ndiagonalization after Multiset CCA, leading to a new approach called ShICA-J.\nWe show via simulations that ShICA-J leads to improved results while being very\nfast to fit. While ShICA-J is based on second-order statistics, we further\npropose to leverage non-Gaussianity of the components using a\nmaximum-likelihood method, ShICA-ML, that is both more accurate and more\ncostly. Further, ShICA comes with a principled method for shared components\nestimation. Finally, we provide empirical evidence on fMRI and MEG datasets\nthat ShICA yields more accurate estimation of the components than alternatives.",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Hugo Richard",
      "Pierre Ablin",
      "Bertrand Thirion",
      "Alexandre Gramfort",
      "Aapo Hyv\u00e4rinen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13502"
  },
  {
    "id": "arXiv:2110.13504",
    "title": "Managing Bias in Human-Annotated Data: Moving Beyond Bias Removal",
    "abstract": "Due to the widespread use of data-powered systems in our everyday lives, the\nnotions of bias and fairness gained significant attention among researchers and\npractitioners, in both industry and academia. Such issues typically emerge from\nthe data, which comes with varying levels of quality, used to train systems.\nWith the commercialization and employment of such systems that are sometimes\ndelegated to make life-changing decisions, a significant effort is being made\ntowards the identification and removal of possible sources of bias that may\nsurface to the final end-user. In this position paper, we instead argue that\nbias is not something that should necessarily be removed in all cases, and the\nattention and effort should shift from bias removal to the identification,\nmeasurement, indexing, surfacing, and adjustment of bias, which we name bias\nmanagement. We argue that if correctly managed, bias can be a resource that can\nbe made transparent to the the users and empower them to make informed choices\nabout their experience with the system.",
    "descriptor": "\nComments: Accepted at CSCW 2021 Workshop Investigating and Mitigating Biases in Crowdsourced Data, October 23, 2021, Virtual\n",
    "authors": [
      "Gianluca Demartini",
      "Kevin Roitero",
      "Stefano Mizzaro"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.13504"
  },
  {
    "id": "arXiv:2110.13505",
    "title": "Part & Whole Extraction: Towards A Deep Understanding of Quantitative  Facts for Percentages in Text",
    "abstract": "We study the problem of quantitative facts extraction for text with\npercentages. For example, given the sentence \"30 percent of Americans like\nwatching football, while 20% prefer to watch NBA.\", our goal is to obtain a\ndeep understanding of the percentage numbers (\"30 percent\" and \"20%\") by\nextracting their quantitative facts: part (\"like watching football\" and \"prefer\nto watch NBA\") and whole (\"Americans). These quantitative facts can empower new\napplications like automated infographic generation. We formulate part and whole\nextraction as a sequence tagging problem. Due to the large gap between\npart/whole and its corresponding percentage, we introduce skip mechanism in\nsequence modeling, and achieved improved performance on both our task and the\nCoNLL-2003 named entity recognition task. Experimental results demonstrate that\nlearning to skip in sequence tagging is promising.",
    "descriptor": "\nComments: rejected by EMNLP 2020\n",
    "authors": [
      "Lei Fang",
      "Jian-Guang Lou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.13505"
  },
  {
    "id": "arXiv:2110.13506",
    "title": "A DPDK-Based Acceleration Method for Experience Sampling of Distributed  Reinforcement Learning",
    "abstract": "A computing cluster that interconnects multiple compute nodes is used to\naccelerate distributed reinforcement learning based on DQN (Deep Q-Network). In\ndistributed reinforcement learning, Actor nodes acquire experiences by\ninteracting with a given environment and a Learner node optimizes their DQN\nmodel. Since data transfer between Actor and Learner nodes increases depending\non the number of Actor nodes and their experience size, communication overhead\nbetween them is one of major performance bottlenecks. In this paper, their\ncommunication is accelerated by DPDK-based network optimizations, and\nDPDK-based low-latency experience replay memory server is deployed between\nActor and Learner nodes interconnected with a 40GbE (40Gbit Ethernet) network.\nEvaluation results show that, as a network optimization technique, kernel\nbypassing by DPDK reduces network access latencies to a shared memory server by\n32.7% to 58.9%. As another network optimization technique, an in-network\nexperience replay memory server between Actor and Learner nodes reduces access\nlatencies to the experience replay memory by 11.7% to 28.1% and communication\nlatencies for prioritized experience sampling by 21.9% to 29.1%.",
    "descriptor": "",
    "authors": [
      "Masaki Furukawa",
      "Hiroki Matsutani"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13506"
  },
  {
    "id": "arXiv:2110.13509",
    "title": "An Arbitrary High Order and Positivity Preserving Method for the Shallow  Water Equations",
    "abstract": "In this paper, we develop and present an arbitrary high order well-balanced\nfinite volume WENO method combined with the modified Patankar Deferred\nCorrection (mPDeC) time integration method for the shallow water equations. Due\nto the positivity-preserving property of mPDeC, the resulting scheme is\nunconditionally positivity preserving for the water height. To apply the mPDeC\napproach, we have to interpret the spatial semi-discretization in terms of\nproduction-destruction systems. Only small modifications inside the classical\nWENO implementation are necessary and we explain how it can be done. In\nnumerical simulations, focusing on a fifth order method, we demonstrate the\ngood performance of the new method and verify the theoretical properties.",
    "descriptor": "",
    "authors": [
      "Mirco Ciallella",
      "Lorenzo Micalizzi",
      "Philipp \u00d6ffner",
      "Davide Torlo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.13509"
  },
  {
    "id": "arXiv:2110.13511",
    "title": "AutoDEUQ: Automated Deep Ensemble with Uncertainty Quantification",
    "abstract": "Deep neural networks are powerful predictors for a variety of tasks. However,\nthey do not capture uncertainty directly. Using neural network ensembles to\nquantify uncertainty is competitive with approaches based on Bayesian neural\nnetworks while benefiting from better computational scalability. However,\nbuilding ensembles of neural networks is a challenging task because, in\naddition to choosing the right neural architecture or hyperparameters for each\nmember of the ensemble, there is an added cost of training each model. We\npropose AutoDEUQ, an automated approach for generating an ensemble of deep\nneural networks. Our approach leverages joint neural architecture and\nhyperparameter search to generate ensembles. We use the law of total variance\nto decompose the predictive variance of deep ensembles into aleatoric (data)\nand epistemic (model) uncertainties. We show that AutoDEUQ outperforms\nprobabilistic backpropagation, Monte Carlo dropout, deep ensemble,\ndistribution-free ensembles, and hyper ensemble methods on a number of\nregression benchmarks.",
    "descriptor": "",
    "authors": [
      "Romain Egele",
      "Romit Maulik",
      "Krishnan Raghavan",
      "Prasanna Balaprakash",
      "Bethany Lusch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13511"
  },
  {
    "id": "arXiv:2110.13522",
    "title": "Probabilistic Entity Representation Model for Chain Reasoning over  Knowledge Graphs",
    "abstract": "Logical reasoning over Knowledge Graphs (KGs) is a fundamental technique that\ncan provide efficient querying mechanism over large and incomplete databases.\nCurrent approaches employ spatial geometries such as boxes to learn query\nrepresentations that encompass the answer entities and model the logical\noperations of projection and intersection. However, their geometry is\nrestrictive and leads to non-smooth strict boundaries, which further results in\nambiguous answer entities. Furthermore, previous works propose transformation\ntricks to handle unions which results in non-closure and, thus, cannot be\nchained in a stream. In this paper, we propose a Probabilistic Entity\nRepresentation Model (PERM) to encode entities as a Multivariate Gaussian\ndensity with mean and covariance parameters to capture its semantic position\nand smooth decision boundary, respectively. Additionally, we also define the\nclosed logical operations of projection, intersection, and union that can be\naggregated using an end-to-end objective function. On the logical query\nreasoning problem, we demonstrate that the proposed PERM significantly\noutperforms the state-of-the-art methods on various public benchmark KG\ndatasets on standard evaluation metrics. We also evaluate PERM's competence on\na COVID-19 drug-repurposing case study and show that our proposed work is able\nto recommend drugs with substantially better F1 than current methods. Finally,\nwe demonstrate the working of our PERM's query answering process through a\nlow-dimensional visualization of the Gaussian representations.",
    "descriptor": "\nComments: Accepted at Thirty-fifth Conference on Neural Information Processing Systems 2021 (NeurIPS '21)\n",
    "authors": [
      "Nurendra Choudhary",
      "Nikhil Rao",
      "Sumeet Katariya",
      "Karthik Subbian",
      "Chandan K. Reddy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.13522"
  },
  {
    "id": "arXiv:2110.13523",
    "title": "Automating Control of Overestimation Bias for Continuous Reinforcement  Learning",
    "abstract": "Bias correction techniques are used by most of the high-performing methods\nfor off-policy reinforcement learning. However, these techniques rely on a\npre-defined bias correction policy that is either not flexible enough or\nrequires environment-specific tuning of hyperparameters. In this work, we\npresent a simple data-driven approach for guiding bias correction. We\ndemonstrate its effectiveness on the Truncated Quantile Critics -- a\nstate-of-the-art continuous control algorithm. The proposed technique can\nadjust the bias correction across environments automatically. As a result, it\neliminates the need for an extensive hyperparameter search, significantly\nreducing the actual number of interactions and computation.",
    "descriptor": "",
    "authors": [
      "Arsenii Kuznetsov",
      "Alexander Grishin",
      "Artem Tsypin",
      "Arsenii Ashukha",
      "Dmitry Vetrov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.13523"
  },
  {
    "id": "arXiv:2110.13525",
    "title": "A Reinforcement Learning Approach for Re-allocating Drone Swarm Services",
    "abstract": "We propose a novel framework for the re-allocation of drone swarms for\ndelivery services known as Swarm-based Drone-as-a-Service (SDaaS). The\nre-allocation framework ensures maximum profit to drone swarm providers while\nmeeting the time requirement of service consumers. The constraints in the\ndelivery environment (e.g., limited recharging pads) are taken into\nconsideration. We utilize reinforcement learning (RL) to select the best\nallocation and scheduling of drone swarms given a set of requests from multiple\nconsumers. We conduct a set of experiments to evaluate and compare the\nefficiency of the proposed approach considering the provider's profit and\nrun-time efficiency.",
    "descriptor": "\nComments: 8 pages, 2 figures, accepted and to be published in the proceedings of 19th International Conference on Service Oriented Computing (ICSOC 2021)\n",
    "authors": [
      "Balsam Alkouz",
      "Athman Bouguettaya"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.13525"
  },
  {
    "id": "arXiv:2110.13526",
    "title": "Software Implementation of the Krylov Methods Based Reconstruction for  the 3D Cone Beam CT Operator",
    "abstract": "Krylov subspace methods are considered a standard tool to solve large systems\nof linear algebraic equations in many scientific disciplines such as image\nrestoration or solving partial differential equations in mechanics of\ncontinuum. In the context of computer tomography however, the mostly used\nalgebraic reconstruction techniques are based on classical iterative schemes.\nIn this work we present software package that implements fully 3D cone beam\nprojection operator and uses Krylov subspace methods, namely CGLS and LSQR to\nsolve related tomographic reconstruction problems. It also implements basic\npreconditioning strategies. On the example of the cone beam CT reconstruction\nof 3D Shepp-Logan phantom we show that the speed of convergence of the CGLS\nclearly outperforms PSIRT algorithm. Therefore Krylov subspace methods present\nan interesting option for the reconstruction of large 3D cone beam CT problems.",
    "descriptor": "\nComments: 5 pages, 3 figures, published in Proceedings of the 16th Virtual International Meeting on Fully 3D Image Reconstruction in Radiology and Nuclear Medicine 2021 arXiv:2110.04143\n",
    "authors": [
      "Vojt\u011bch Kulvait",
      "Georg Rose"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Image and Video Processing (eess.IV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.13526"
  },
  {
    "id": "arXiv:2110.13530",
    "title": "An extended physics informed neural network for preliminary analysis of  parametric optimal control problems",
    "abstract": "In this work we propose an extension of physics informed supervised learning\nstrategies to parametric partial differential equations. Indeed, even if the\nlatter are indisputably useful in many applications, they can be\ncomputationally expensive most of all in a real-time and many-query setting.\nThus, our main goal is to provide a physics informed learning paradigm to\nsimulate parametrized phenomena in a small amount of time. The physics\ninformation will be exploited in many ways, in the loss function (standard\nphysics informed neural networks), as an augmented input (extra feature\nemployment) and as a guideline to build an effective structure for the neural\nnetwork (physics informed architecture). These three aspects, combined\ntogether, will lead to a faster training phase and to a more accurate\nparametric prediction. The methodology has been tested for several equations\nand also in an optimal control framework.",
    "descriptor": "",
    "authors": [
      "Nicola Demo",
      "Maria Strazzullo",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.13530"
  },
  {
    "id": "arXiv:2110.13532",
    "title": "Playing Repeated Coopetitive Polymatrix Games with Small Manipulation  Cost",
    "abstract": "Repeated coopetitive games capture the situation when one must efficiently\nbalance between cooperation and competition with the other agents over time in\norder to win the game (e.g., to become the player with highest total utility).\nAchieving this balance is typically very challenging or even impossible when\nexplicit communication is not feasible (e.g., negotiation or bargaining are not\nallowed). In this paper we investigate how an agent can achieve this balance to\nwin in repeated coopetitive polymatrix games, without explicit communication.\nIn particular, we consider a 3-player repeated game setting in which our agent\nis allowed to (slightly) manipulate the underlying game matrices of the other\nagents for which she pays a manipulation cost, while the other agents satisfy\nweak behavioural assumptions. We first propose a payoff matrix manipulation\nscheme and sequence of strategies for our agent that provably guarantees that\nthe utility of any opponent would converge to a value we desire. We then use\nthis scheme to design winning policies for our agent. We also prove that these\nwinning policies can be found in polynomial running time. We then turn to\ndemonstrate the efficiency of our framework in several concrete coopetitive\npolymatrix games, and prove that the manipulation costs needed to win are\nbounded above by small budgets. For instance, in the social distancing game, a\npolymatrix version of the lemonade stand coopetitive game, we showcase a policy\nwith an infinitesimally small manipulation cost per round, along with a\nprovable guarantee that, using this policy leads our agent to win in the\nlong-run. Note that our findings can be trivially extended to $n$-player game\nsettings as well (with $n > 3$).",
    "descriptor": "",
    "authors": [
      "Shivakumar Mahesh",
      "Nicholas Bishop",
      "Le Cong Dinh",
      "Long Tran-Thanh"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.13532"
  },
  {
    "id": "arXiv:2110.13535",
    "title": "An in-depth Analysis of Occasional and Recurring Collaborations in  Online Music Co-creation",
    "abstract": "The success of online creative communities depends on the will of\nparticipants to create and derive content in a collaborative environment.\nDespite their growing popularity, the factors that lead to remixing existing\ncontent in online creative communities are not entirely understood. In this\npaper, we focus on overdubbing, that is, a dyadic collaboration where one\nauthor mixes one new track with an audio recording previously uploaded by\nanother. We study musicians who collaborate regularly, that is, frequently\noverdub each other's songs. Building on frequent pattern mining techniques, we\ndevelop an approach to seek instances of such recurring collaborations in the\nSongtree community. We identify 43 instances involving two or three members\nwith a similar reputation in the community. Our findings highlight common and\ndifferent remix factors in occasional and recurring collaborations.\nSpecifically, fresh and less mature songs are generally overdubbed more;\ninstead, exchanging messages and invitations to collaborate are significant\nfactors only for songs generated through recurring collaborations whereas\nauthor reputation (ranking) and applying metadata tags to songs have a positive\neffect only in occasional collaborations.",
    "descriptor": "",
    "authors": [
      "Fabio Calefato",
      "Giuseppe Iaffaldano",
      "Leonardo Trisolini",
      "Filippo Lanubile"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.13535"
  },
  {
    "id": "arXiv:2110.13537",
    "title": "Overlapping Schwarz methods with GenEO coarse spaces for indefinite and  non-self-adjoint problems",
    "abstract": "GenEO (`Generalised Eigenvalue problems on the Overlap') is a method for\ncomputing an operator-dependent spectral coarse space to be combined with local\nsolves on subdomains to form a robust parallel domain decomposition\npreconditioner for elliptic PDEs. It has previously been proved, in the\nself-adjoint and positive-definite case, that this method, when used as a\npreconditioner for conjugate gradients, yields iteration numbers which are\ncompletely independent of the heterogeneity of the coefficient field of the\npartial differential operator. We extend this theory to the case of\nconvection-diffusion-reaction problems, which may be non-self-adjoint and\nindefinite, and whose discretisations are solved with preconditioned GMRES. The\nGenEO coarse space is defined here using a generalised eigenvalue problem based\non a self-adjoint and positive-definite subproblem. We obtain GMRES iteration\ncounts which are independent of the variation of the coefficient of the\ndiffusion term in the operator and depend only very mildly on the variation of\nthe other coefficients. While the iteration number estimates do grow as the\nnon-self-adjointness and indefiniteness of the operator increases, practical\ntests indicate the deterioration is much milder. Thus we obtain an iterative\nsolver which is efficient in parallel and very effective for a wide range of\nconvection-diffusion-reaction problems.",
    "descriptor": "",
    "authors": [
      "Niall Bootland",
      "Victorita Dolean",
      "Ivan G. Graham",
      "Chupeng Ma",
      "Robert Scheichl"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.13537"
  },
  {
    "id": "arXiv:2110.13538",
    "title": "SHECS: A Local Smart Hands-free Elderly Care Support System on Smart AR  Glasses with AI Technology",
    "abstract": "Some elderly care homes attempt to remedy the shortage of skilled caregivers\nand provide long-term care for the elderly residents, by enhancing the\nmanagement of the care support system with the aid of smart devices such as\nmobile phones and tablets. Since mobile phones and tablets lack the flexibility\nrequired for laborious elderly care work, smart AR glasses have already been\nconsidered. Although lightweight smart AR devices with a transparent display\nare more convenient and responsive in an elderly care workplace, fetching data\nfrom the server through the Internet results in network congestion not to\nmention the limited display area. To devise portable smart AR devices that\noperate smoothly, we first present a no keep alive Internet required smart\nhands-free elderly care support system that employs smart glasses with facial\nrecognition and text-to-speech synthesis technologies. Our support system\nutilizes automatic lightweight facial recognition to identify residents, and\ninformation about each resident in question can be obtained hands free link\nwith a local database. Moreover, a resident information can be displayed on\njust a portion of the AR smart glasses on the spot. Due to the limited size of\nthe display area, it cannot show all the necessary information. We exploit\nsynthesized voices in the system to read out the elderly care related\ninformation. By using the support system, caregivers can gain an understanding\nof each resident condition immediately, instead of having to devote\nconsiderable time in advance in obtaining the complete information of all\nelderly residents. Our lightweight facial recognition model achieved high\naccuracy with fewer model parameters than current state-of-the-art methods. The\nvalidation rate of our facial recognition system was 99.3% or higher with the\nfalse accept rate of 0.001, and caregivers rated the acceptability at 3.6 (5\nlevels) or higher.",
    "descriptor": "\nComments: 9 pages, 6 figures, 5 tables\n",
    "authors": [
      "Donghuo Zeng",
      "Jianming Wu",
      "Bo Yang",
      "Tomohiro Obara",
      "Akeri Okawa",
      "Nobuko Iino",
      "Gen Hattori",
      "Ryoichi Kawada",
      "Yasuhiro Takishima"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.13538"
  },
  {
    "id": "arXiv:2110.13541",
    "title": "Qu-ANTI-zation: Exploiting Quantization Artifacts for Achieving  Adversarial Outcomes",
    "abstract": "Quantization is a popular technique that $transforms$ the parameter\nrepresentation of a neural network from floating-point numbers into\nlower-precision ones ($e.g.$, 8-bit integers). It reduces the memory footprint\nand the computational cost at inference, facilitating the deployment of\nresource-hungry models. However, the parameter perturbations caused by this\ntransformation result in $behavioral$ $disparities$ between the model before\nand after quantization. For example, a quantized model can misclassify some\ntest-time samples that are otherwise classified correctly. It is not known\nwhether such differences lead to a new security vulnerability. We hypothesize\nthat an adversary may control this disparity to introduce specific behaviors\nthat activate upon quantization. To study this hypothesis, we weaponize\nquantization-aware training and propose a new training framework to implement\nadversarial quantization outcomes. Following this framework, we present three\nattacks we carry out with quantization: (i) an indiscriminate attack for\nsignificant accuracy loss; (ii) a targeted attack against specific samples; and\n(iii) a backdoor attack for controlling the model with an input trigger. We\nfurther show that a single compromised model defeats multiple quantization\nschemes, including robust quantization techniques. Moreover, in a federated\nlearning scenario, we demonstrate that a set of malicious participants who\nconspire can inject our quantization-activated backdoor. Lastly, we discuss\npotential counter-measures and show that only re-training consistently removes\nthe attack artifacts. Our code is available at\nhttps://github.com/Secure-AI-Systems-Group/Qu-ANTI-zation",
    "descriptor": "\nComments: Accepted to NeurIPS 2021 [Poster]\n",
    "authors": [
      "Sanghyun Hong",
      "Michael-Andrei Panaitescu-Liess",
      "Yi\u011fitcan Kaya",
      "Tudor Dumitra\u015f"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.13541"
  },
  {
    "id": "arXiv:2110.13550",
    "title": "Coherent False Seizure Prediction in Epilepsy, Coincidence or  Providence?",
    "abstract": "Seizure forecasting using machine learning is possible, but the performance\nis far from ideal, as indicated by many false predictions and low specificity.\nHere, we examine false and missing alarms of two algorithms on long-term\ndatasets to show that the limitations are less related to classifiers or\nfeatures, but rather to intrinsic changes in the data. We evaluated two\nalgorithms on three datasets by computing the correlation of false predictions\nand estimating the information transfer between both classification methods.\nFor 9 out of 12 individuals both methods showed a performance better than\nchance. For all individuals we observed a positive correlation in predictions.\nFor individuals with strong correlation in false predictions we were able to\nboost the performance of one method by excluding test samples based on the\nresults of the second method. Substantially different algorithms exhibit a\nhighly consistent performance and a strong coherency in false and missing\nalarms. Hence, changing the underlying hypothesis of a preictal state of fixed\ntime length prior to each seizure to a proictal state is more helpful than\nfurther optimizing classifiers. The outcome is significant for the evaluation\nof seizure prediction algorithms on continuous data.",
    "descriptor": "\nComments: 23 pages, 7 figures, accepted for publication in Clinical Neurophysiology\n",
    "authors": [
      "Jens M\u00fcller",
      "Hongliu Yang",
      "Matthias Eberlein",
      "Georg Leonhardt",
      "Ortrud Uckermann",
      "Levin Kuhlmann",
      "Ronald Tetzlaff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.13550"
  },
  {
    "id": "arXiv:2110.13551",
    "title": "BuffetFS: Serve Yourself Permission Checks without Remote Procedure  Calls",
    "abstract": "The remote procedure call (a.k.a. RPC) latency becomes increasingly\nsignificant in a distributed file system. We propose BuffetFS, a user-level\nfile system that optimizes I/O performance by eliminating the RPCs caused by\n\\texttt{open()} operation. By leveraging \\texttt{open()} from file servers to\nclients, BuffetFS can restrain the procedure calls for permission checks\nlocally, hence avoid RPCs during the initial stage to access a file. BuffetFS\ncan further reduce response time when users are accessing a large number of\nsmall files. We implement a BuffetFS prototype and integrate it into a storage\ncluster. Our preliminary evaluation results show that BuffetFS can offer up to\n70\\% performance gain compared to the Lustre file system.",
    "descriptor": "",
    "authors": [
      "Yanliang Zou",
      "Bin Yang",
      "Jian Zhang",
      "Wei Xue",
      "Shu Yin"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.13551"
  },
  {
    "id": "arXiv:2110.13552",
    "title": "Single Morphing Attack Detection using Feature Selection and  Visualisation based on Mutual Information",
    "abstract": "Face morphing attack detection is a challenging task. Automatic\nclassification methods and manual inspection are realised in automatic border\ncontrol gates to detect morphing attacks. Understanding how a machine learning\nsystem can detect morphed faces and the most relevant facial areas is crucial.\nThose relevant areas contain texture signals that allow us to separate the bona\nfide and the morph images. Also, it helps in the manual examination to detect a\npassport generated with morphed images. This paper explores features extracted\nfrom intensity, shape, texture, and proposes a feature selection stage based on\nthe Mutual Information filter to select the most relevant and less redundant\nfeatures. This selection allows us to reduce the workload and know the exact\nlocalisation of such areas to understand the morphing impact and create a\nrobust classifier. The best results were obtained for the method based on\nConditional Mutual Information and Shape features using only 500 features for\nFERET images and 800 features for FRGCv2 images from 1,048 features available.\nThe eyes and nose are identified as the most critical areas to be analysed.",
    "descriptor": "",
    "authors": [
      "Juan Tapia",
      "Christoph Busch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13552"
  },
  {
    "id": "arXiv:2110.13555",
    "title": "Directional Self-supervised Learning for Risky Image Augmentations",
    "abstract": "Only a few cherry-picked robust augmentation policies are beneficial to\nstandard self-supervised image representation learning, despite the large\naugmentation family. In this paper, we propose a directional self-supervised\nlearning paradigm (DSSL), which is compatible with significantly more\naugmentations. Specifically, we adapt risky augmentation policies after\nstandard views augmented by robust augmentations, to generate harder risky view\n(RV). The risky view usually has a higher deviation from the original image\nthan the standard robust view (SV). Unlike previous methods equally pairing all\naugmented views for symmetrical self-supervised training to maximize their\nsimilarities, DSSL treats augmented views of the same instance as a partially\nordered set (SV$\\leftrightarrow $SV, SV$\\leftarrow$RV), and then equips\ndirectional objective functions respecting to the derived relationships among\nviews. DSSL can be easily implemented with a few lines of Pseudocode and is\nhighly flexible to popular self-supervised learning frameworks, including\nSimCLR, SimSiam, BYOL. The extensive experimental results on CIFAR and ImageNet\ndemonstrated that DSSL can stably improve these frameworks with compatibility\nto a wider range of augmentations.",
    "descriptor": "",
    "authors": [
      "Yalong Bai",
      "Yifan Yang",
      "Wei Zhang",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13555"
  },
  {
    "id": "arXiv:2110.13556",
    "title": "Learning Explicit and Implicit Latent Common Spaces for Audio-Visual  Cross-Modal Retrieval",
    "abstract": "Learning common subspace is prevalent way in cross-modal retrieval to solve\nthe problem of data from different modalities having inconsistent distributions\nand representations that cannot be directly compared. Previous cross-modal\nretrieval methods focus on projecting the cross-modal data into a common space\nby learning the correlation between them to bridge the modality gap. However,\nthe rich semantic information in the video and the heterogeneous nature of\naudio-visual data leads to more serious heterogeneous gaps intuitively, which\nmay lead to the loss of key semantic content of video with single clue by the\nprevious methods when eliminating the modality gap, while the semantics of the\ncategories may undermine the properties of the original features. In this work,\nwe aim to learn effective audio-visual representations to support audio-visual\ncross-modal retrieval (AVCMR). We propose a novel model that maps audio-visual\nmodalities into two distinct shared latent subspaces: explicit and implicit\nshared spaces. In particular, the explicit shared space is used to optimize\npairwise correlations, where learned representations across modalities capture\nthe commonalities of audio-visual pairs and reduce the modality gap. The\nimplicit shared space is used to preserve the distinctive features between\nmodalities by maintaining the discrimination of audio/video patterns from\ndifferent semantic categories. Finally, the fusion of the features learned from\nthe two latent subspaces is used for the similarity computation of the AVCMR\ntask. The comprehensive experimental results on two audio-visual datasets\ndemonstrate that our proposed model for using two different latent subspaces\nfor audio-visual cross-modal learning is effective and significantly\noutperforms the state-of-the-art cross-modal models that learn features from a\nsingle subspace.",
    "descriptor": "",
    "authors": [
      "Donghuo Zeng",
      "Jianming Wu",
      "Gen Hattori",
      "Yi Yu",
      "Rong Xu"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.13556"
  },
  {
    "id": "arXiv:2110.13558",
    "title": "Cross-Region Building Counting in Satellite Imagery using Counting  Consistency",
    "abstract": "Estimating the number of buildings in any geographical region is a vital\ncomponent of urban analysis, disaster management, and public policy decision.\nDeep learning methods for building localization and counting in satellite\nimagery, can serve as a viable and cheap alternative. However, these algorithms\nsuffer performance degradation when applied to the regions on which they have\nnot been trained. Current large datasets mostly cover the developed regions and\ncollecting such datasets for every region is a costly, time-consuming, and\ndifficult endeavor. In this paper, we propose an unsupervised domain adaptation\nmethod for counting buildings where we use a labeled source domain (developed\nregions) and adapt the trained model on an unlabeled target domain (developing\nregions). We initially align distribution maps across domains by aligning the\noutput space distribution through adversarial loss. We then exploit counting\nconsistency constraints, within-image count consistency, and across-image count\nconsistency, to decrease the domain shift. Within-image consistency enforces\nthat building count in the whole image should be greater than or equal to count\nin any of its sub-image. Across-image consistency constraint enforces that if\nan image contains considerably more buildings than the other image, then their\nsub-images shall also have the same order. These two constraints encourage the\nbehavior to be consistent across and within the images, regardless of the\nscale. To evaluate the performance of our proposed approach, we collected and\nannotated a large-scale dataset consisting of challenging South Asian regions\nhaving higher building densities and irregular structures as compared to\nexisting datasets. We perform extensive experiments to verify the efficacy of\nour approach and report improvements of approximately 7% to 20% over the\ncompetitive baseline methods.",
    "descriptor": "",
    "authors": [
      "Muaaz Zakria",
      "Hamza Rawal",
      "Waqas Sultani",
      "Mohsen Ali"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13558"
  },
  {
    "id": "arXiv:2110.13559",
    "title": "Flexible Refinement Proofs in Separation Logic",
    "abstract": "Refinement transforms an abstract system model into a concrete, executable\nprogram, such that properties established for the abstract model carry over to\nthe concrete implementation. Refinement has been used successfully in the\ndevelopment of substantial verified systems. Nevertheless, existing refinement\ntechniques have limitations that impede their practical usefulness. Some\ntechniques generate executable code automatically, which generally leads to\nimplementations with sub-optimal performance. Others employ bottom-up program\nverification to reason about efficient implementations, but impose strict\nrequirements on the structure of the code, the structure of the refinement\nproofs, as well as the employed verification logic and tools.\nIn this paper, we present a novel refinement technique that removes these\nlimitations. Our technique uses separation logic to reason about efficient\nconcurrent implementations. It prescribes only a loose coupling between an\nabstract model and the concrete implementation. It thereby supports a wide\nrange of program structures, data representations, and proof structures. We\nmake only minimal assumptions about the underlying program logic, which allows\nour technique to be used in combination with a wide range of logics and to be\nautomated using off-the-shelf separation logic verifiers. We formalize the\ntechnique, prove the central trace inclusion property, and demonstrate its\nusefulness on several case studies.",
    "descriptor": "\nComments: 35 pages, submitted to 31st European Symposium on Programming\n",
    "authors": [
      "Aurel B\u00edl\u00fd",
      "Christoph Matheja",
      "Peter M\u00fcller"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.13559"
  },
  {
    "id": "arXiv:2110.13561",
    "title": "Non-Gaussian Gaussian Processes for Few-Shot Regression",
    "abstract": "Gaussian Processes (GPs) have been widely used in machine learning to model\ndistributions over functions, with applications including multi-modal\nregression, time-series prediction, and few-shot learning. GPs are particularly\nuseful in the last application since they rely on Normal distributions and\nenable closed-form computation of the posterior probability function.\nUnfortunately, because the resulting posterior is not flexible enough to\ncapture complex distributions, GPs assume high similarity between subsequent\ntasks - a requirement rarely met in real-world conditions. In this work, we\naddress this limitation by leveraging the flexibility of Normalizing Flows to\nmodulate the posterior predictive distribution of the GP. This makes the GP\nposterior locally non-Gaussian, therefore we name our method Non-Gaussian\nGaussian Processes (NGGPs). More precisely, we propose an invertible ODE-based\nmapping that operates on each component of the random variable vectors and\nshares the parameters across all of them. We empirically tested the flexibility\nof NGGPs on various few-shot learning regression datasets, showing that the\nmapping can incorporate context embedding information to model different noise\nlevels for periodic functions. As a result, our method shares the structure of\nthe problem between subsequent tasks, but the contextualization allows for\nadaptation to dissimilarities. NGGPs outperform the competing state-of-the-art\napproaches on a diversified set of benchmarks and applications.",
    "descriptor": "",
    "authors": [
      "Marcin Sendera",
      "Jacek Tabor",
      "Aleksandra Nowak",
      "Andrzej Bedychaj",
      "Massimiliano Patacchiola",
      "Tomasz Trzci\u0144ski",
      "Przemys\u0142aw Spurek",
      "Maciej Zi\u0119ba"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13561"
  },
  {
    "id": "arXiv:2110.13562",
    "title": "Measuring the Effectiveness of Digital Hygiene using Historical DNS Data",
    "abstract": "This paper describes an ongoing experiment evaluating the efficacy of a\ndigital safety intervention in six high-risk, low capacity Civil Society\nOrganisations (CSOs) in Central Asia. The evaluation takes the form of\nstatistical analysis of DNS traffic in each organisation, obtained via security\ntools installed by researchers.\nThe hypothesis is that the digital safety intervention strengthens the\noverall digital security posture of the CSOs, as measured by number of malware\nattacks intercepted by a cloud-based DNS firewall installed on the CSOs\nnetworks.\nThe research collects DNS traffic from CSOs that are participating in the\ndigital safety intervention, and compares a treatment group consisting of four\nCSOs against DNS traffic from a second group of two CSOs in which the\nintervention has not yet taken place.\nThis project is ongoing, with data collection underway at a number of Central\nAsian CSOs. In this paper we outline the experimental design of the project,\nand look at the early data coming out of the DNS firewall. This is done to\nsupport the ultimate question of whether DNS data such as this can be used to\naccurately assess the efficacy of digital hygiene efforts.",
    "descriptor": "",
    "authors": [
      "Oliver Farnan",
      "Gregory Walton",
      "Joss Wright"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.13562"
  },
  {
    "id": "arXiv:2110.13563",
    "title": "Time Complexity Analysis of an Evolutionary Algorithm for approximating  Nash Equilibriums",
    "abstract": "The framework outlined in [arXiv:2010.13024] provides an approximation\nalgorithm for computing Nash equilibria of normal form games. Since NASH is a\nwell-known PPAD-complete problem, this framework has potential applications to\nother $PPAD$ problems. The correctness of this framework has been empirically\nvalidated on 4 well-studied 2x2 games: Prisoner's Dilemma, Stag Hunt, Battle,\nand Chicken. In this paper, we provide the asymptotic time-complexities for\nthese methods and in particular, verify that for 2x2 games the worst-case\ncomplexity is linear in the number of actions an agent can choose from.",
    "descriptor": "\nComments: 3 pages, Time-Complexity extension of an IEEE/SSCI paper\n",
    "authors": [
      "Aadesh Salecha"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2110.13563"
  },
  {
    "id": "arXiv:2110.13567",
    "title": "Pairwise Half-graph Discrimination: A Simple Graph-level Self-supervised  Strategy for Pre-training Graph Neural Networks",
    "abstract": "Self-supervised learning has gradually emerged as a powerful technique for\ngraph representation learning. However, transferable, generalizable, and robust\nrepresentation learning on graph data still remains a challenge for\npre-training graph neural networks. In this paper, we propose a simple and\neffective self-supervised pre-training strategy, named Pairwise Half-graph\nDiscrimination (PHD), that explicitly pre-trains a graph neural network at\ngraph-level. PHD is designed as a simple binary classification task to\ndiscriminate whether two half-graphs come from the same source. Experiments\ndemonstrate that the PHD is an effective pre-training strategy that offers\ncomparable or superior performance on 13 graph classification tasks compared\nwith state-of-the-art strategies, and achieves notable improvements when\ncombined with node-level strategies. Moreover, the visualization of learned\nrepresentation revealed that PHD strategy indeed empowers the model to learn\ngraph-level knowledge like the molecular scaffold. These results have\nestablished PHD as a powerful and effective self-supervised learning strategy\nin graph-level representation learning.",
    "descriptor": "\nComments: accepted at IJCAI 2021\n",
    "authors": [
      "Pengyong Li",
      "Jun Wang",
      "Ziliang Li",
      "Yixuan Qiao",
      "Xianggen Liu",
      "Fei Ma",
      "Peng Gao",
      "Seng Song",
      "Guotong Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13567"
  },
  {
    "id": "arXiv:2110.13569",
    "title": "Two Decades of Game Jams",
    "abstract": "In less than a year's time, March 2022 will mark the twentieth anniversary of\nthe first documented game jam, the Indie Game Jam, which took place in Oakland,\nCalifornia in 2002. Initially, game jams were widely seen as frivolous\nactivities. Since then, they have taken the world by storm. Game jams have not\nonly become part of the day-to-day process of many game developers, but jams\nare also used for activist purposes, for learning and teaching, as part of the\nexperience economy, for making commercial prototypes that gamers can vote on,\nand more. Beyond only surveying game jams and the relevant published scientific\nliterature from the last two decades, this paper has several additional\ncontributions. It builds a history of game jams, and proposes two different\ntaxonomies of game jams - a historical and a categorical. In addition, it\ndiscusses the definition of game jam and identifies the most active research\nareas within the game jam community such as the interplay and development with\nlocal communities, the study and analysis of game jammers and organisers, and\nworks that bring a critical look on game jams.",
    "descriptor": "",
    "authors": [
      "Gorm Lai",
      "Annakaisa Kultima",
      "Foaad Khosmood",
      "Johanna Pirker",
      "Allan Fowler",
      "Ilaria Vecchi",
      "William Latham",
      "Frederic Fol Leymarie"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.13569"
  },
  {
    "id": "arXiv:2110.13570",
    "title": "Learning Graph Representation of Person-specific Cognitive Processes  from Audio-visual Behaviours for Automatic Personality Recognition",
    "abstract": "This approach builds on two following findings in cognitive science: (i)\nhuman cognition partially determines expressed behaviour and is directly linked\nto true personality traits; and (ii) in dyadic interactions individuals'\nnonverbal behaviours are influenced by their conversational partner behaviours.\nIn this context, we hypothesise that during a dyadic interaction, a target\nsubject's facial reactions are driven by two main factors, i.e. their internal\n(person-specific) cognitive process, and the externalised nonverbal behaviours\nof their conversational partner. Consequently, we propose to represent the\ntarget subjects (defined as the listener) person-specific cognition in the form\nof a person-specific CNN architecture that has unique architectural parameters\nand depth, which takes audio-visual non-verbal cues displayed by the\nconversational partner (defined as the speaker) as input, and is able to\nreproduce the target subject's facial reactions. Each person-specific CNN is\nexplored by the Neural Architecture Search (NAS) and a novel adaptive loss\nfunction, which is then represented as a graph representation for recognising\nthe target subject's true personality. Experimental results not only show that\nthe produced graph representations are well associated with target subjects'\npersonality traits in both human-human and human-machine interaction scenarios,\nand outperform the existing approaches with significant advantages, but also\ndemonstrate that the proposed novel strategies such as adaptive loss, and the\nend-to-end vertices/edges feature learning, help the proposed approach in\nlearning more reliable personality representations.",
    "descriptor": "\nComments: Submitted to IJCV\n",
    "authors": [
      "Siyang Song",
      "Zilong Shao",
      "Shashank Jaiswal",
      "Linlin Shen",
      "Michel Valstar",
      "Hatice Gunes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13570"
  },
  {
    "id": "arXiv:2110.13571",
    "title": "Emotion recognition in talking-face videos using persistent entropy and  neural networks",
    "abstract": "The automatic recognition of a person's emotional state has become a very\nactive research field that involves scientists specialized in different areas\nsuch as artificial intelligence, computer vision or psychology, among others.\nOur main objective in this work is to develop a novel approach, using\npersistent entropy and neural networks as main tools, to recognise and classify\nemotions from talking-face videos. Specifically, we combine audio-signal and\nimage-sequence information to compute a topology signature(a 9-dimensional\nvector) for each video. We prove that small changes in the video produce small\nchanges in the signature. These topological signatures are used to feed a\nneural network to distinguish between the following emotions: neutral, calm,\nhappy, sad, angry, fearful, disgust, and surprised. The results reached are\npromising and competitive, beating the performance reached in other\nstate-of-the-art works found in the literature.",
    "descriptor": "",
    "authors": [
      "Eduardo Paluzo-Hidalgo",
      "Guillermo Aguirre-Carrazana",
      "Rocio Gonzalez-Diaz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2110.13571"
  },
  {
    "id": "arXiv:2110.13572",
    "title": "Periodic Activation Functions Induce Stationarity",
    "abstract": "Neural network models are known to reinforce hidden data biases, making them\nunreliable and difficult to interpret. We seek to build models that `know what\nthey do not know' by introducing inductive biases in the function space. We\nshow that periodic activation functions in Bayesian neural networks establish a\nconnection between the prior on the network weights and translation-invariant,\nstationary Gaussian process priors. Furthermore, we show that this link goes\nbeyond sinusoidal (Fourier) activations by also covering triangular wave and\nperiodic ReLU activation functions. In a series of experiments, we show that\nperiodic activation functions obtain comparable performance for in-domain data\nand capture sensitivity to perturbed inputs in deep neural networks for\nout-of-domain detection.",
    "descriptor": "\nComments: To appear in Advances in Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Lassi Meronen",
      "Martin Trapp",
      "Arno Solin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.13572"
  },
  {
    "id": "arXiv:2110.13575",
    "title": "Automated Support for Unit Test Generation: A Tutorial Book Chapter",
    "abstract": "Unit testing is a stage of testing where the smallest segment of code that\ncan be tested in isolation from the rest of the system - often a class - is\ntested. Unit tests are typically written as executable code, often in a format\nprovided by a unit testing framework such as pytest for Python.\nCreating unit tests is a time and effort-intensive process with many\nrepetitive, manual elements. To illustrate how AI can support unit testing,\nthis chapter introduces the concept of search-based unit test generation. This\ntechnique frames the selection of test input as an optimization problem - we\nseek a set of test cases that meet some measurable goal of a tester - and\nunleashes powerful metaheuristic search algorithms to identify the best\npossible test cases within a restricted timeframe. This chapter introduces two\nalgorithms that can generate pytest-formatted unit tests, tuned towards\ncoverage of source code statements. The chapter concludes by discussing more\nadvanced concepts and gives pointers to further reading for how artificial\nintelligence can support developers and testers when unit testing software.",
    "descriptor": "\nComments: This is a preprint of a chapter from the upcoming book, \"Optimising the Software Development Process with Artificial Intelligence\" (Springer, 2022)\n",
    "authors": [
      "Afonso Fontes",
      "Gregory Gay",
      "Francisco Gomes de Oliveira Neto",
      "Robert Feldt"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.13575"
  },
  {
    "id": "arXiv:2110.13576",
    "title": "Learning Robust Controllers Via Probabilistic Model-Based Policy Search",
    "abstract": "Model-based Reinforcement Learning estimates the true environment through a\nworld model in order to approximate the optimal policy. This family of\nalgorithms usually benefits from better sample efficiency than their model-free\ncounterparts. We investigate whether controllers learned in such a way are\nrobust and able to generalize under small perturbations of the environment. Our\nwork is inspired by the PILCO algorithm, a method for probabilistic policy\nsearch. We show that enforcing a lower bound to the likelihood noise in the\nGaussian Process dynamics model regularizes the policy updates and yields more\nrobust controllers. We demonstrate the empirical benefits of our method in a\nsimulation benchmark.",
    "descriptor": "\nComments: Accepted at RobustML Workshop - ICLR 2021\n",
    "authors": [
      "Valentin Charvet",
      "Bj\u00f8rn Sand Jensen",
      "Roderick Murray-Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13576"
  },
  {
    "id": "arXiv:2110.13577",
    "title": "Open Rule Induction",
    "abstract": "Rules have a number of desirable properties. It is easy to understand, infer\nnew knowledge, and communicate with other inference systems. One weakness of\nthe previous rule induction systems is that they only find rules within a\nknowledge base (KB) and therefore cannot generalize to more open and complex\nreal-world rules. Recently, the language model (LM)-based rule generation are\nproposed to enhance the expressive power of the rules. In this paper, we\nrevisit the differences between KB-based rule induction and LM-based rule\ngeneration. We argue that, while KB-based methods inducted rules by discovering\ndata commonalities, the current LM-based methods are \"learning rules from\nrules\". This limits these methods to only produce \"canned\" rules whose patterns\nare constrained by the annotated rules, while discarding the rich expressive\npower of LMs for free text.\nTherefore, in this paper, we propose the open rule induction problem, which\naims to induce open rules utilizing the knowledge in LMs. Besides, we propose\nthe Orion (\\underline{o}pen \\underline{r}ule \\underline{i}nducti\\underline{on})\nsystem to automatically mine open rules from LMs without supervision of\nannotated rules. We conducted extensive experiments to verify the quality and\nquantity of the inducted open rules. Surprisingly, when applying the open rules\nin downstream tasks (i.e. relation extraction), these automatically inducted\nrules even outperformed the manually annotated rules.",
    "descriptor": "",
    "authors": [
      "Wanyun Cui",
      "Xingran Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.13577"
  },
  {
    "id": "arXiv:2110.13578",
    "title": "Distributional Reinforcement Learning for Multi-Dimensional Reward  Functions",
    "abstract": "A growing trend for value-based reinforcement learning (RL) algorithms is to\ncapture more information than scalar value functions in the value network. One\nof the most well-known methods in this branch is distributional RL, which\nmodels return distribution instead of scalar value. In another line of work,\nhybrid reward architectures (HRA) in RL have studied to model source-specific\nvalue functions for each source of reward, which is also shown to be beneficial\nin performance. To fully inherit the benefits of distributional RL and hybrid\nreward architectures, we introduce Multi-Dimensional Distributional DQN\n(MD3QN), which extends distributional RL to model the joint return distribution\nfrom multiple reward sources. As a by-product of joint distribution modeling,\nMD3QN can capture not only the randomness in returns for each source of reward,\nbut also the rich reward correlation between the randomness of different\nsources. We prove the convergence for the joint distributional Bellman operator\nand build our empirical algorithm by minimizing the Maximum Mean Discrepancy\nbetween joint return distribution and its Bellman target. In experiments, our\nmethod accurately models the joint return distribution in environments with\nrichly correlated reward functions, and outperforms previous RL methods\nutilizing multi-dimensional reward functions in the control setting.",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Pushi Zhang",
      "Xiaoyu Chen",
      "Li Zhao",
      "Wei Xiong",
      "Tao Qin",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13578"
  },
  {
    "id": "arXiv:2110.13581",
    "title": "Gradient representations in ReLU networks as similarity functions",
    "abstract": "Feed-forward networks can be interpreted as mappings with linear decision\nsurfaces at the level of the last layer. We investigate how the tangent space\nof the network can be exploited to refine the decision in case of ReLU\n(Rectified Linear Unit) activations. We show that a simple Riemannian metric\nparametrized on the parameters of the network forms a similarity function at\nleast as good as the original network and we suggest a sparse metric to\nincrease the similarity gap.",
    "descriptor": "\nComments: Accepted at 29th ESANN 2021, 6-8 October 2021, Belgium, 7 pages, 1 figure\n",
    "authors": [
      "D\u00e1niel R\u00e1cz",
      "B\u00e1lint Dar\u00f3czy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13581"
  },
  {
    "id": "arXiv:2110.13585",
    "title": "Concepts for Automated Machine Learning in Smart Grid Applications",
    "abstract": "Undoubtedly, the increase of available data and competitive machine learning\nalgorithms has boosted the popularity of data-driven modeling in energy\nsystems. Applications are forecasts for renewable energy generation and energy\nconsumption. Forecasts are elementary for sector coupling, where\nenergy-consuming sectors are interconnected with the power-generating sector to\naddress electricity storage challenges by adding flexibility to the power\nsystem. However, the large-scale application of machine learning methods in\nenergy systems is impaired by the need for expert knowledge, which covers\nmachine learning expertise and a profound understanding of the application's\nprocess. The process knowledge is required for the problem formalization, as\nwell as the model validation and application. The machine learning skills\ninclude the processing steps of i) data pre-processing, ii) feature\nengineering, extraction, and selection, iii) algorithm selection, iv)\nhyperparameter optimization, and possibly v) post-processing of the model's\noutput. Tailoring a model for a particular application requires selecting the\ndata, designing various candidate models and organizing the data flow between\nthe processing steps, selecting the most suitable model, and monitoring the\nmodel during operation - an iterative and time-consuming procedure. Automated\ndesign and operation of machine learning aim to reduce the human effort to\naddress the increasing demand for data-driven models. We define five levels of\nautomation for forecasting in alignment with the SAE standard for autonomous\nvehicles, where manual design and application reflect Automation level 0.",
    "descriptor": "",
    "authors": [
      "Stefan Meisenbacher",
      "Janik Pinter",
      "Tim Martin",
      "Veit Hagenmeyer",
      "Ralf Mikut"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.13585"
  },
  {
    "id": "arXiv:2110.13587",
    "title": "Arbitrary Distribution Modeling with Censorship in Real-Time Bidding  Advertising",
    "abstract": "The purpose of Inventory Pricing is to bid the right prices to online ad\nopportunities, which is crucial for a Demand-Side Platform (DSP) to win\nadvertising auctions in Real-Time Bidding (RTB). In the planning stage,\nadvertisers need the forecast of probabilistic models to make bidding\ndecisions. However, most of the previous works made strong assumptions on the\ndistribution form of the winning price, which reduced their accuracy and\nweakened their ability to make generalizations. Though some works recently\ntried to fit the distribution directly, their complex structure lacked\nefficiency on online inference. In this paper, we devise a novel loss function,\nNeighborhood Likelihood Loss (NLL), collaborating with a proposed framework,\nArbitrary Distribution Modeling (ADM), to predict the winning price\ndistribution under censorship with no pre-assumption required. We conducted\nexperiments on two real-world experimental datasets and one large-scale,\nnon-simulated production dataset in our system. Experiments showed that ADM\noutperformed the baselines both on algorithm and business metrics. By replaying\nhistorical data of the production environment, this method was shown to lead to\ngood yield in our system. Without any pre-assumed specific distribution form,\nADM showed significant advantages in effectiveness and efficiency,\ndemonstrating its great capability in modeling sophisticated price landscapes.",
    "descriptor": "",
    "authors": [
      "Xu Li",
      "Michelle Ma Zhang",
      "Youjun Tong",
      "Zhenya Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13587"
  },
  {
    "id": "arXiv:2110.13588",
    "title": "Distributional Robustness Regularized Scenario Optimization with  Application to Model Predictive Control",
    "abstract": "We provide a functional view of distributional robustness motivated by robust\nstatistics and functional analysis. This results in two practical computational\napproaches for approximate distributionally robust nonlinear optimization based\non gradient norms and reproducing kernel Hilbert spaces. Our method can be\napplied to the settings of statistical learning with small sample size and test\ndistribution shift. As a case study, we robustify scenario-based stochastic\nmodel predictive control with general nonlinear constraints. In particular, we\ndemonstrate constraint satisfaction with only a small number of scenarios under\ndistribution shift.",
    "descriptor": "",
    "authors": [
      "Yassine Nemmour",
      "Bernhard Sch\u00f6lkopf",
      "Jia-Jie Zhu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.13588"
  },
  {
    "id": "arXiv:2110.13589",
    "title": "AQP: An Open Modular Python Platform for Objective Speech and Audio  Quality Metrics",
    "abstract": "Audio quality assessment has been widely researched in the signal processing\narea. Full-reference objective metrics (e.g., POLQA, ViSQOL) have been\ndeveloped to estimate the audio quality relying only on human rating\nexperiments. To evaluate the audio quality of novel audio processing\ntechniques, researchers constantly need to compare objective quality metrics.\nTesting different implementations of the same metric and evaluating new\ndatasets are fundamental and ongoing iterative activities. In this paper, we\npresent AQP - an open-source, node-based, light-weight Python pipeline for\naudio quality assessment. AQP allows researchers to test and compare objective\nquality metrics helping to improve robustness, reproducibility and development\nspeed. We introduce the platform, explain the motivations, and illustrate with\nexamples how, using AQP, objective quality metrics can be (i) compared and\nbenchmarked; (ii) prototyped and adapted in a modular fashion; (iii) visualised\nand checked for errors. The code has been shared on GitHub to encourage\nadoption and contributions from the community.",
    "descriptor": "\nComments: 5 pages, 3 figures, submitted to IEEE ICASSP 2022\n",
    "authors": [
      "Jack Geraghty",
      "Jiazheng Li",
      "Alessandro Ragano",
      "Andrew Hines"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.13589"
  },
  {
    "id": "arXiv:2110.13596",
    "title": "TME-BNA: Temporal Motif-Preserving Network Embedding with Bicomponent  Neighbor Aggregation",
    "abstract": "Evolving temporal networks serve as the abstractions of many real-life\ndynamic systems, e.g., social network and e-commerce. The purpose of temporal\nnetwork embedding is to map each node to a time-evolving low-dimension vector\nfor downstream tasks, e.g., link prediction and node classification. The\ndifficulty of temporal network embedding lies in how to utilize the topology\nand time information jointly to capture the evolution of a temporal network. In\nresponse to this challenge, we propose a temporal motif-preserving network\nembedding method with bicomponent neighbor aggregation, named TME-BNA.\nConsidering that temporal motifs are essential to the understanding of topology\nlaws and functional properties of a temporal network, TME-BNA constructs\nadditional edge features based on temporal motifs to explicitly utilize complex\ntopology with time information. In order to capture the topology dynamics of\nnodes, TME-BNA utilizes Graph Neural Networks (GNNs) to aggregate the\nhistorical and current neighbors respectively according to the timestamps of\nconnected edges. Experiments are conducted on three public temporal network\ndatasets, and the results show the effectiveness of TME-BNA.",
    "descriptor": "",
    "authors": [
      "Ling Chen",
      "Da Wang",
      "Dandan Lyu",
      "Xing Tang",
      "Hongyu Shi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13596"
  },
  {
    "id": "arXiv:2110.13598",
    "title": "Incremental Learning for Animal Pose Estimation using RBF k-DPP",
    "abstract": "Pose estimation is the task of locating keypoints for an object of interest\nin an image. Animal Pose estimation is more challenging than estimating human\npose due to high inter and intra class variability in animals. Existing works\nsolve this problem for a fixed set of predefined animal categories. Models\ntrained on such sets usually do not work well with new animal categories.\nRetraining the model on new categories makes the model overfit and leads to\ncatastrophic forgetting. Thus, in this work, we propose a novel problem of\n\"Incremental Learning for Animal Pose Estimation\". Our method uses an exemplar\nmemory, sampled using Determinantal Point Processes (DPP) to continually adapt\nto new animal categories without forgetting the old ones. We further propose a\nnew variant of k-DPP that uses RBF kernel (termed as \"RBF k-DPP\") which gives\nmore gain in performance over traditional k-DPP. Due to memory constraints, the\nlimited number of exemplars along with new class data can lead to class\nimbalance. We mitigate it by performing image warping as an augmentation\ntechnique. This helps in crafting diverse poses, which reduces overfitting and\nyields further improvement in performance. The efficacy of our proposed\napproach is demonstrated via extensive experiments and ablations where we\nobtain significant improvements over state-of-the-art baseline methods.",
    "descriptor": "\nComments: Accepted in BMVC 2021\n",
    "authors": [
      "Gaurav Kumar Nayak",
      "Het Shah",
      "Anirban Chakraborty"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13598"
  },
  {
    "id": "arXiv:2110.13601",
    "title": "DAG Card is the new Model Card",
    "abstract": "With the progressive commoditization of modeling capabilities, data-centric\nAI recognizes that what happens before and after training becomes crucial for\nreal-world deployments. Following the intuition behind Model Cards, we propose\nDAG Cards as a form of documentation encompassing the tenets of a data-centric\npoint of view. We argue that Machine Learning pipelines (rather than models)\nare the most appropriate level of documentation for many practical use cases,\nand we share with the community an open implementation to generate cards from\ncode.",
    "descriptor": "\nComments: To be presented at Neurips 2021 (DCAI workshop), pre-print\n",
    "authors": [
      "Jacopo Tagliabue",
      "Ville Tuulos",
      "Ciro Greco",
      "Valay Dave"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13601"
  },
  {
    "id": "arXiv:2110.13604",
    "title": "Finite Element Approximation of Large-Scale Isometric Deformations of  Parametrized Surfaces",
    "abstract": "In this paper, the numerical approximation of isometric deformations of thin\nelastic shells is discussed. To this end, for a thin shell represented by a\nparametrized surface, it is shown how to transform the stored elastic energy\nfor an isometric deformation such that the highest order term is quadratic. For\nthis reformulated model, existence of optimal isometric deformations is shown.\nA finite element approximation is obtained using the Discrete Kirchhoff\nTriangle (DKT) approach and the convergence of discrete minimizers to a\ncontinuous minimizer is demonstrated. In that respect, this paper generalizes\nthe results by Bartels for the approximation of bending isometries of plates. A\nNewton scheme is derived to numerically simulate large bending isometries of\nshells. The proven convergence properties are experimentally verified and\ncharacteristics of isometric deformations are discussed.",
    "descriptor": "",
    "authors": [
      "Martin Rumpf",
      "Stefan Simon",
      "Christoph Smoch"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.13604"
  },
  {
    "id": "arXiv:2110.13606",
    "title": "AUTO-DISCERN: Autonomous Driving Using Common Sense Reasoning",
    "abstract": "Driving an automobile involves the tasks of observing surroundings, then\nmaking a driving decision based on these observations (steer, brake, coast,\netc.). In autonomous driving, all these tasks have to be automated. Autonomous\ndriving technology thus far has relied primarily on machine learning\ntechniques. We argue that appropriate technology should be used for the\nappropriate task. That is, while machine learning technology is good for\nobserving and automatically understanding the surroundings of an automobile,\ndriving decisions are better automated via commonsense reasoning rather than\nmachine learning. In this paper, we discuss (i) how commonsense reasoning can\nbe automated using answer set programming (ASP) and the goal-directed s(CASP)\nASP system, and (ii) develop the AUTO-DISCERN system using this technology for\nautomating decision-making in driving. The goal of our research, described in\nthis paper, is to develop an autonomous driving system that works by simulating\nthe mind of a human driver. Since driving decisions are based on human-style\nreasoning, they are explainable, their ethics can be ensured, and they will\nalways be correct, provided the system modeling and system inputs are correct.",
    "descriptor": "",
    "authors": [
      "Suraj Kothawade",
      "Vinaya Khandelwal",
      "Kinjal Basu",
      "Huaduo Wang",
      "Gopal Gupta"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.13606"
  },
  {
    "id": "arXiv:2110.13607",
    "title": "An extension of the order-preserving mapping to the WENO-Z-type schemes",
    "abstract": "In our latest studies, by introducing the novel order-preserving (OP)\ncriterion, we have successfully addressed the widely concerned issue of the\npreviously published mapped weighted essentially non-oscillatory (WENO) schemes\nthat it is rather difficult to achieve high resolutions on the premise of\nremoving spurious oscillations for long-run simulations of the hyperbolic\nsystems. In the present study, we extend the OP criterion to the WENO-Z-type\nschemes as the forementioned issue has also been extensively observed\nnumerically for these schemes. Firstly, we innovatively present the concept of\nthe generalized mapped WENO schemes by rewriting the Z-type weights in a\nuniform formula from the perspective of the mapping relation. Then, we\nnaturally introduce the OP criterion to improve the WENO-Z-type schemes, and\nthe resultant schemes are denoted as MOP-GMWENO-X. Finally, extensive numerical\nexperiments have been conducted to demonstrate the benefits of these new\nschemes. We draw the conclusion that, the convergence propoties of the proposed\nschemes are equivalent to the corresponding WENO-X schemes. The major benefit\nof the new schemes is that they have the capacity to achieve high resolutions\nand simultaneously remove spurious oscillations for long simulations. The new\nschemes have the additional benefit that they can greatly decrease the\npost-shock oscillations on solving 2D Euler problems with strong shock waves.",
    "descriptor": "",
    "authors": [
      "Ruo Li",
      "Wei Zhong"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.13607"
  },
  {
    "id": "arXiv:2110.13608",
    "title": "Using Traceless Genetic Programming for Solving Multiobjective  Optimization Problems",
    "abstract": "Traceless Genetic Programming (TGP) is a Genetic Programming (GP) variant\nthat is used in cases where the focus is rather the output of the program than\nthe program itself. The main difference between TGP and other GP techniques is\nthat TGP does not explicitly store the evolved computer programs. Two genetic\noperators are used in conjunction with TGP: crossover and insertion. In this\npaper, we shall focus on how to apply TGP for solving multi-objective\noptimization problems which are quite unusual for GP. Each TGP individual\nstores the output of a computer program (tree) representing a point in the\nsearch space. Numerical experiments show that TGP is able to solve very fast\nand very well the considered test problems.",
    "descriptor": "\nComments: 9 figures. arXiv admin note: text overlap with arXiv:2110.02014\n",
    "authors": [
      "Mihai Oltean",
      "Crina Grosan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13608"
  },
  {
    "id": "arXiv:2110.13609",
    "title": "Resolving Anomalies in the Behaviour of a Modularity Inducing Problem  Domain with Distributional Fitness Evaluation",
    "abstract": "Discrete gene regulatory networks (GRNs) play a vital role in the study of\nrobustness and modularity. A common method of evaluating the robustness of GRNs\nis to measure their ability to regulate a set of perturbed gene activation\npatterns back to their unperturbed forms. Usually, perturbations are obtained\nby collecting random samples produced by a predefined distribution of gene\nactivation patterns. This sampling method introduces stochasticity, in turn\ninducing dynamicity. This dynamicity is imposed on top of an already complex\nfitness landscape. So where sampling is used, it is important to understand\nwhich effects arise from the structure of the fitness landscape, and which\narise from the dynamicity imposed on it. Stochasticity of the fitness function\nalso causes difficulties in reproducibility and in post-experimental analyses.\nWe develop a deterministic distributional fitness evaluation by considering\nthe complete distribution of gene activity patterns, so as to avoid\nstochasticity in fitness assessment. This fitness evaluation facilitates\nrepeatability. Its determinism permits us to ascertain theoretical bounds on\nthe fitness, and thus to identify whether the algorithm has reached a global\noptimum. It enables us to differentiate the effects of the problem domain from\nthose of the noisy fitness evaluation, and thus to resolve two remaining\nanomalies in the behaviour of the problem domain\nof~\\citet{espinosa2010specialization}. We also reveal some properties of\nsolution GRNs that lead them to be robust and modular, leading to a deeper\nunderstanding of the nature of the problem domain. We conclude by discussing\npotential directions toward simulating and understanding the emergence of\nmodularity in larger, more complex domains, which is key both to generating\nmore useful modular solutions, and to understanding the ubiquity of modularity\nin biological systems.",
    "descriptor": "\nComments: Final version of an paper accepted by the Artificial Life journal\n",
    "authors": [
      "Zhenyue Qin",
      "Tom Gedeon",
      "R.I.",
      "McKay"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13609"
  },
  {
    "id": "arXiv:2110.13610",
    "title": "Robust physics discovery via supervised and unsupervised pattern  recognition using the Euler characteristic",
    "abstract": "Machine learning approaches have been widely used for discovering the\nunderlying physics of dynamical systems from measured data. Existing\napproaches, however, still lack robustness, especially when the measured data\ncontain a large level of noise. The lack of robustness is mainly attributed to\nthe insufficient representativeness of used features. As a result, the\nintrinsic mechanism governing the observed system cannot be accurately\nidentified. In this study, we use an efficient topological descriptor for\ncomplex data, i.e., the Euler characteristics (ECs), as features to\ncharacterize the spatiotemporal data collected from dynamical systems and\ndiscover the underlying physics. Unsupervised manifold learning and supervised\nclassification results show that EC can be used to efficiently distinguish\nsystems with different while similar governing models. We also demonstrate that\nthe machine learning approaches using EC can improve the confidence level of\nsparse regression methods of physics discovery.",
    "descriptor": "",
    "authors": [
      "Zhiming Zhang",
      "Yongming Liu"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13610"
  },
  {
    "id": "arXiv:2110.13611",
    "title": "Dendritic Self-Organizing Maps for Continual Learning",
    "abstract": "Current deep learning architectures show remarkable performance when trained\nin large-scale, controlled datasets. However, the predictive ability of these\narchitectures significantly decreases when learning new classes incrementally.\nThis is due to their inclination to forget the knowledge acquired from\npreviously seen data, a phenomenon termed catastrophic-forgetting. On the other\nhand, Self-Organizing Maps (SOMs) can model the input space utilizing\nconstrained k-means and thus maintain past knowledge. Here, we propose a novel\nalgorithm inspired by biological neurons, termed Dendritic-Self-Organizing Map\n(DendSOM). DendSOM consists of a single layer of SOMs, which extract patterns\nfrom specific regions of the input space accompanied by a set of hit matrices,\none per SOM, which estimate the association between units and labels. The\nbest-matching unit of an input pattern is selected using the maximum cosine\nsimilarity rule, while the point-wise mutual information is employed for class\ninference. DendSOM performs unsupervised feature extraction as it does not use\nlabels for targeted updating of the weights. It outperforms classical SOMs and\nseveral state-of-the-art continual learning algorithms on benchmark datasets,\nsuch as the Split-MNIST and Split-CIFAR-10. We propose that the incorporation\nof neuronal properties in SOMs may help remedy catastrophic forgetting.",
    "descriptor": "\nComments: 12 pages, 13 figures, 7 tables\n",
    "authors": [
      "Kosmas Pinitas",
      "Spyridon Chavlis",
      "Panayiota Poirazi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2110.13611"
  },
  {
    "id": "arXiv:2110.13612",
    "title": "An explicit and non-iterative moving-least-squares immersed-boundary  method with low boundary velocity error",
    "abstract": "In this work, based on the moving-least-squares immersed boundary method, we\nproposed a new technique to improve the calculation of the volume force\nrepresenting the body boundary. For boundary with simple geometry, we\ntheoretically analyse the error between the desired volume force at boundary\nand the actual force given by the original method. The ratio between the two\nforces is very close to a constant. Numerical experiments reveal that for\ncomplex geometry, this ratio exhibits very narrow distribution around certain\nvalue. A spatially uniform coefficient is then introduced to correct the force\nand fixed by the least-square method over all boundary markers. Such method is\nexplicit and non-iterative, and can be easily implemented into the existing\nscheme. Several test cases have been simulated with stationary and moving\nboundaries. Our new method can reduce the residual boundary velocity to the\nlevel comparable to that given by the iterative method, but requires much less\ncomputing time. Moreover, the new method can be readily combined with the\niterative method and further reduces the residual boundary velocity.",
    "descriptor": "\nComments: 21 pages, 10 figures, 4 tables\n",
    "authors": [
      "Wenyuan Chen",
      "Shufan Zou",
      "Qingdong Cai",
      "Yantao Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2110.13612"
  },
  {
    "id": "arXiv:2110.13613",
    "title": "Subsampling Spectral Clustering for Large-Scale Social Networks",
    "abstract": "Online social network platforms such as Twitter and Sina Weibo have been\nextremely popular over the past 20 years. Identifying the network community of\na social platform is essential to exploring and understanding the users'\ninterests. However, the rapid development of science and technology has\ngenerated large amounts of social network data, creating great computational\nchallenges for community detection in large-scale social networks. Here, we\npropose a novel subsampling spectral clustering algorithm to identify community\nstructures in large-scale social networks with limited computing resources.\nMore precisely, spectral clustering is conducted using only the information of\na small subsample of the network nodes, resulting in a huge reduction in\ncomputational time. As a result, for large-scale datasets, the method can be\nrealized even using a personal computer. Specifically, we introduce two\ndifferent sampling techniques, namely simple random subsampling and degree\ncorrected subsampling. The methodology is applied to the dataset collected from\nSina Weibo, which is one of the largest Twitter-type social network platforms\nin China. Our method can very effectively identify the community structure of\nregistered users. This community structure information can be applied to help\nSina Weibo promote advertisements to target users and increase user activity.",
    "descriptor": "",
    "authors": [
      "Jiayi Deng",
      "Yi Ding",
      "Yingqiu Zhu",
      "Danyang Huang",
      "Bingyi Jing",
      "Bo Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.13613"
  },
  {
    "id": "arXiv:2110.13614",
    "title": "Model-Free Prediction of Chaotic Systems Using High Efficient  Next-generation Reservoir Computing",
    "abstract": "To predict the future evolution of dynamical systems purely from observations\nof the past data is of great potential application. In this work, a new\nformulated paradigm of reservoir computing is proposed for achieving model-free\npredication for both low-dimensional and very large spatiotemporal chaotic\nsystems. Compared with traditional reservoir computing models, it is more\nefficient in terms of predication length, training data set required and\ncomputational expense. By taking the Lorenz and Kuramoto-Sivashinsky equations\nas two classical examples of dynamical systems, numerical simulations are\nconducted, and the results show our model excels at predication tasks than the\nlatest reservoir computing methods.",
    "descriptor": "",
    "authors": [
      "Zhuo Liu",
      "Leisheng Jin"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2110.13614"
  },
  {
    "id": "arXiv:2110.13616",
    "title": "Quantitative Learning of LTL from Finite Traces",
    "abstract": "In this paper, we present a novel method for learning LTL properties from a\nset of traces. The main novelty of our method, as compared to many existing\nones, is that we learn formulae in a \"quantitative\" sense : given a sample\n$\\mathcal{S} = (P, N)$ consisting of positive traces $P$ and negative traces\n$N$, we find the formula $\\varphi$ which \"best\" describes the sample such that\nall positive traces satisfy $\\varphi$ and all negative traces do not satisfy\n$\\varphi$. To decide how good a formula is with respect to the sample, we have\ndeveloped a scheme of assigning a value for a formula for a given trace under\nvarious schemes. We use the schemes to encode the optimal property synthesis\nproblem, namely, finding the best property/LTL formula into an optimization\nproblem. Then we use an SMT solver to find the best fit formula for a given set\nof traces. Finally, we present a hybrid approach combining classical LTL\nsatisfaction and the ranking scheme that works on a fragment of LTL and greatly\nimproves performance while maintaining reasonable expressiveness. We have\ndeveloped a tool QuantLearn based on our method and applied on some benchmarks.\nWe also compared different valuation schemes. Our experiments suggest that\nQuantLearn is successful in mining formulae which are reasonably good\nrepresentations of the sample with high resilience to noise in the data.",
    "descriptor": "",
    "authors": [
      "Mohammad Afzal",
      "Sankalp Gambhir",
      "Ashutosh Gupta",
      "Shankaranarayanan Krishna"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.13616"
  },
  {
    "id": "arXiv:2110.13619",
    "title": "Vaccine skepticism detection by network embedding",
    "abstract": "We demonstrate the applicability of network embedding to vaccine skepticism,\na controversial topic of long-past history. With the Covid-19 pandemic outbreak\nat the end of 2019, the topic is more important than ever. Only a year after\nthe first international cases were registered, multiple vaccines were developed\nand passed clinical testing. Besides the challenges of development, testing,\nand logistics, another factor that might play a significant role in the fight\nagainst the pandemic are people who are hesitant to get vaccinated, or even\nstate that they will refuse any vaccine offered to them. Two groups of people\ncommonly referred to as a) pro-vaxxer, those who support vaccinating people b)\nvax-skeptic, those who question vaccine efficacy or the need for general\nvaccination against Covid-19. It is very difficult to tell exactly how many\npeople share each of these views. It is even more difficult to understand all\nthe reasoning why vax-skeptic opinions are getting more popular. In this work,\nour intention was to develop techniques that are able to efficiently\ndifferentiate between pro-vaxxer and vax-skeptic content. After multiple data\npreprocessing steps, we analyzed the tweet text as well as the structure of\nuser interactions on Twitter. We deployed several node embedding and community\ndetection models that scale well for graphs with millions of edges.",
    "descriptor": "\nComments: The data and the source code are available on GitHub: this https URL\n",
    "authors": [
      "Ferenc B\u00e9res",
      "Rita Csoma",
      "Tam\u00e1s Vilmos Michaletzky",
      "Andr\u00e1s A. Bencz\u00far"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13619"
  },
  {
    "id": "arXiv:2110.13621",
    "title": "Model-based Reinforcement Learning for Service Mesh Fault Resiliency in  a Web Application-level",
    "abstract": "Microservice-based architectures enable different aspects of web applications\nto be created and updated independently, even after deployment. Associated\ntechnologies such as service mesh provide application-level fault resilience\nthrough attribute configurations that govern the behavior of request-response\nservice -- and the interactions among them -- in the presence of failures.\nWhile this provides tremendous flexibility, the configured values of these\nattributes -- and the relationships among them -- can significantly affect the\nperformance and fault resilience of the overall application. Furthermore, it is\nimpossible to determine the best and worst combinations of attribute values\nwith respect to fault resiliency via testing, due to the complexities of the\nunderlying distributed system and the many possible attribute value\ncombinations. In this paper, we present a model-based reinforcement learning\nworkflow towards service mesh fault resiliency. Our approach enables the\nprediction of the most significant fault resilience behaviors at a web\napplication-level, scratching from single service to aggregated multi-service\nmanagement with efficient agent collaborations.",
    "descriptor": "\nComments: 10 pages, submitted for the Web Conference 2022\n",
    "authors": [
      "Fanfei Meng",
      "Lalita Jagadeesan",
      "Marina Thottan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.13621"
  },
  {
    "id": "arXiv:2110.13623",
    "title": "Contrastive Neural Processes for Self-Supervised Learning",
    "abstract": "Recent contrastive methods show significant improvement in self-supervised\nlearning in several domains. In particular, contrastive methods are most\neffective where data augmentation can be easily constructed e.g. in computer\nvision. However, they are less successful in domains without established data\ntransformations such as time series data. In this paper, we propose a novel\nself-supervised learning framework that combines contrastive learning with\nneural processes. It relies on recent advances in neural processes to perform\ntime series forecasting. This allows to generate augmented versions of data by\nemploying a set of various sampling functions and, hence, avoid manually\ndesigned augmentations. We extend conventional neural processes and propose a\nnew contrastive loss to learn times series representations in a self-supervised\nsetup. Therefore, unlike previous self-supervised methods, our augmentation\npipeline is task-agnostic, enabling our method to perform well across various\napplications. In particular, a ResNet with a linear classifier trained using\nour approach is able to outperform state-of-the-art techniques across\nindustrial, medical and audio datasets improving accuracy over 10% in ECG\nperiodic data. We further demonstrate that our self-supervised representations\nare more efficient in the latent space, improving multiple clustering indexes\nand that fine-tuning our method on 10% of labels achieves results competitive\nto fully-supervised learning.",
    "descriptor": "\nComments: 16 pages, 6 figures, ACML 2021\n",
    "authors": [
      "Konstantinos Kallidromitis",
      "Denis Gudovskiy",
      "Kozuka Kazuki",
      "Ohama Iku",
      "Luca Rigazio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.13623"
  },
  {
    "id": "arXiv:2110.13624",
    "title": "Deep Learning-based Technology Fitness Landscape: A Biological Analogy",
    "abstract": "This research note presents a deep learning-based technology fitness\nlandscape premised on a technology embedding space and the estimated\nimprovement rates of all domains in it. The technology embedding space is\ntrained via neural embedding techniques on both intrinsic (semantic) features\nand connective (citation) information to derive high-dimensional embedding\nvectors for the 1,757 technology domains curated by Singh et al. (2021),\ncovering 97.2% of the patent database. The estimated improvement rates of these\n1,757 domains were also drawn from Singh et al. (2021). The technology fitness\nlandscape exhibits a high hill related to information, electronics, and\nelectrical technologies and a vast low plain of the remaining domains. The\nconstruction of the technology fitness landscape based on neural embedding\ntraining presents a global picture and bird's eye view of the co-evolution of\nheterogeneous technology domains in the unified technology space.",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Shuo Jiang",
      "Jianxi Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13624"
  },
  {
    "id": "arXiv:2110.13625",
    "title": "Landmark-Guided Subgoal Generation in Hierarchical Reinforcement  Learning",
    "abstract": "Goal-conditioned hierarchical reinforcement learning (HRL) has shown\npromising results for solving complex and long-horizon RL tasks. However, the\naction space of high-level policy in the goal-conditioned HRL is often large,\nso it results in poor exploration, leading to inefficiency in training. In this\npaper, we present HIerarchical reinforcement learning Guided by Landmarks\n(HIGL), a novel framework for training a high-level policy with a reduced\naction space guided by landmarks, i.e., promising states to explore. The key\ncomponent of HIGL is twofold: (a) sampling landmarks that are informative for\nexploration and (b) encouraging the high-level policy to generate a subgoal\ntowards a selected landmark. For (a), we consider two criteria: coverage of the\nentire visited state space (i.e., dispersion of states) and novelty of states\n(i.e., prediction error of a state). For (b), we select a landmark as the very\nfirst landmark in the shortest path in a graph whose nodes are landmarks. Our\nexperiments demonstrate that our framework outperforms prior-arts across a\nvariety of control tasks, thanks to efficient exploration guided by landmarks.",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Junsu Kim",
      "Younggyo Seo",
      "Jinwoo Shin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13625"
  },
  {
    "id": "arXiv:2110.13626",
    "title": "A Pipeline for Graph-Based Monitoring of the Changes in the Information  Space of Russian Social Media during the Lockdown",
    "abstract": "With the COVID-19 outbreak and the subsequent lockdown, social media became a\nvital communication tool. The sudden outburst of online activity influenced\ninformation spread and consumption patterns. It increases the relevance of\nstudying the dynamics of social networks and developing data processing\npipelines that allow a comprehensive analysis of social media data in the\ntemporal dimension. This paper scopes the weekly dynamics of the information\nspace represented by Russian social media (Twitter and Livejournal) during a\ncritical period (massive COVID-19 outbreak and first governmental measures).\nThe approach is twofold: a) build the time series of topic similarity\nindicators by identifying COVID-related topics in each week and measuring user\ncontribution to the topic space, and b) cluster user activity and display\nuser-topic relationships on graphs in a dashboard application. The paper\ndescribes the development of the pipeline, explains the choices made and\nprovides a case study of the adaptation to virus control measures. The results\nconfirm that social processes and behaviour in response to pandemic-triggered\nchanges can be successfully traced in social media. Moreover, the adaptation\ntrends revealed by psychological and sociological studies are reflected in our\ndata and can be explored using the proposed method.",
    "descriptor": "\nComments: 59 pages, 8 figures, 2 tables, 2 appendices, to be published in: Monitoring of Public Opinion: Economic and Social Changes Journal (Public Opinion Monitoring) ISSN 2219-5467\n",
    "authors": [
      "V. Danilova",
      "S. Popova",
      "V. Karpova"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.13626"
  },
  {
    "id": "arXiv:2110.13627",
    "title": "Degree-Based Random Walk Approach for Graph Embedding",
    "abstract": "Graph embedding, representing local and global neighborhood information by\nnumerical vectors, is a crucial part of the mathematical modeling of a wide\nrange of real-world systems. Among the embedding algorithms, random walk-based\nalgorithms have proven to be very successful. These algorithms collect\ninformation by creating numerous random walks with a redefined number of steps.\nCreating random walks is the most demanding part of the embedding process. The\ncomputation demand increases with the size of the network. Moreover, for\nreal-world networks, considering all nodes on the same footing, the abundance\nof low-degree nodes creates an imbalanced data problem. In this work, a\ncomputationally less intensive and node connectivity aware uniform sampling\nmethod is proposed. In the proposed method, the number of random walks is\ncreated proportionally with the degree of the node. The advantages of the\nproposed algorithm become more enhanced when the algorithm is applied to large\ngraphs. A comparative study by using two networks namely CORA and CiteSeer is\npresented. Comparing with the fixed number of walks case, the proposed method\nrequires 50% less computational effort to reach the same accuracy for node\nclassification and link prediction calculations.",
    "descriptor": "",
    "authors": [
      "Sarmad N. Mohammed",
      "Semra G\u00fcnd\u00fc\u00e7"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13627"
  },
  {
    "id": "arXiv:2110.13629",
    "title": "Bayesian Optimization and Deep Learning forsteering wheel angle  prediction",
    "abstract": "Automated driving systems (ADS) have undergone a significant improvement in\nthe last years. ADS and more precisely self-driving cars technologies will\nchange the way we perceive and know the world of transportation systems in\nterms of user experience, mode choices and business models. The emerging field\nof Deep Learning (DL) has been successfully applied for the development of\ninnovative ADS solutions. However, the attempt to single out the best deep\nneural network architecture and tuning its hyperparameters are all expensive\nprocesses, both in terms of time and computational resources. In this work,\nBayesian Optimization (BO) is used to optimize the hyperparameters of a\nSpatiotemporal-Long Short Term Memory (ST-LSTM) network with the aim to obtain\nan accurate model for the prediction of the steering angle in a ADS. BO was\nable to identify, within a limited number of trials, a model -- namely\nBOST-LSTM -- which resulted, on a public dataset, the most accurate when\ncompared to classical end-to-end driving models.",
    "descriptor": "",
    "authors": [
      "Alessandro Riboni",
      "Nicol\u00f2 Ghioldi",
      "Antonio Candelieri",
      "Matteo Borrotti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.13629"
  },
  {
    "id": "arXiv:2110.13632",
    "title": "Generative Networks for Precision Enthusiasts",
    "abstract": "Generative networks are opening new avenues in fast event generation for the\nLHC. We show how generative flow networks can reach percent-level precision for\nkinematic distributions, how they can be trained jointly with a discriminator,\nand how this discriminator improves the generation. Our joint training relies\non a novel coupling of the two networks which does not require a Nash\nequilibrium. We then estimate the generation uncertainties through a Bayesian\nnetwork setup and through conditional data augmentation, while the\ndiscriminator ensures that there are no systematic inconsistencies compared to\nthe training data.",
    "descriptor": "\nComments: 27 pages, 14 figures\n",
    "authors": [
      "Anja Butter",
      "Theo Heimel",
      "Sander Hummerich",
      "Tobias Krebs",
      "Tilman Plehn",
      "Armand Rousselot",
      "Sophia Vent"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.13632"
  },
  {
    "id": "arXiv:2110.13638",
    "title": "EDLaaS; Fully Homomorphic Encryption Over Neural Network Graphs",
    "abstract": "We present automatically parameterised Fully Homomorphic Encryption (FHE),\nfor encrypted neural network inference. We present and exemplify our inference\nover FHE compatible neural networks with our own open-source framework and\nreproducible step-by-step examples. We use the 4th generation Cheon, Kim, Kim\nand Song (CKKS) FHE scheme over fixed points provided by the Microsoft Simple\nEncrypted Arithmetic Library (MS-SEAL). We significantly enhance the usability\nand applicability of FHE in deep learning contexts, with a focus on the\nconstituent graphs, traversal, and optimisation. We find that FHE is not a\npanacea for all privacy preserving machine learning (PPML) problems, and that\ncertain limitations still remain, such as model training. However we also find\nthat in certain contexts FHE is well suited for computing completely private\npredictions with neural networks. We focus on convolutional neural networks\n(CNNs), fashion-MNIST, and levelled FHE operations. The ability to privately\ncompute sensitive problems more easily, while lowering the barriers to entry,\ncan allow otherwise too-sensitive fields to begin advantaging themselves of\nperformant third-party neural networks. Lastly we show encrypted deep learning,\napplied to a sensitive real world problem in agri-food, and how this can have a\nlarge positive impact on food-waste and encourage much-needed data sharing.",
    "descriptor": "\nComments: 12 pages, 11 figures, journal\n",
    "authors": [
      "George Onoufriou",
      "Marc Hanheide",
      "Georgios Leontidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13638"
  },
  {
    "id": "arXiv:2110.13640",
    "title": "s2s-ft: Fine-Tuning Pretrained Transformer Encoders for  Sequence-to-Sequence Learning",
    "abstract": "Pretrained bidirectional Transformers, such as BERT, have achieved\nsignificant improvements in a wide variety of language understanding tasks,\nwhile it is not straightforward to directly apply them for natural language\ngeneration. In this paper, we present a sequence-to-sequence fine-tuning\ntoolkit s2s-ft, which adopts pretrained Transformers for conditional generation\ntasks. Inspired by UniLM, we implement three sequence-to-sequence fine-tuning\nalgorithms, namely, causal fine-tuning, masked fine-tuning, and pseudo-masked\nfine-tuning. By leveraging the existing pretrained bidirectional Transformers,\nexperimental results show that s2s-ft achieves strong performance on several\nbenchmarks of abstractive summarization, and question generation. Moreover, we\ndemonstrate that the package s2s-ft supports both monolingual and multilingual\nNLG tasks. The s2s-ft toolkit is available at\nhttps://github.com/microsoft/unilm/tree/master/s2s-ft.",
    "descriptor": "\nComments: Demo paper for the s2s-ft toolkit: this https URL\n",
    "authors": [
      "Hangbo Bao",
      "Li Dong",
      "Wenhui Wang",
      "Nan Yang",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.13640"
  },
  {
    "id": "arXiv:2110.13649",
    "title": "An algorithm for the computation of joint Hawkes moments with  exponential kernel",
    "abstract": "The purpose of this paper is to present a recursive algorithm and its\nimplementation in Maple and Mathematica for the computation of joint moments\nand cumulants of Hawkes processes with exponential kernels. Numerical results\nand computation times are also discussed. Obtaining closed form expressions can\nbe computationally intensive, as joint fifth cumulant and moment formulas can\nbe respectively expanded into up to 3,288 and 27,116 summands.",
    "descriptor": "",
    "authors": [
      "Nicolas Privault"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2110.13649"
  },
  {
    "id": "arXiv:2110.13650",
    "title": "GANash -- A GAN approach to steganography",
    "abstract": "Data security is of the utmost concern of a communication system. Since the\nearly days, many developments have been made to improve the performance of the\nsystem. PSNR of the received signal, secure transmission channel, quality of\nencoding used, etc. are some of the key attributes of a good system. To ensure\nsecurity, the most commonly used technique is cryptography in which the message\nis altered with respect to a key and using the same, the encoded message is\ndecoded at the receiver side. A complementary technique that is popularly used\nto insure security is steganography. The advancements in Artificial\nIntelligence(AI) have paved way for performing steganography in an intelligent,\ntamper-proof manner. The recent discovery by researchers in the field of Deep\nLearning(DL), an unsupervised learning network known as the Generative\nAdversarial Networks(GAN) has improved the performance of this technique\nexponentially. It has been demonstrated that deep neural networks are highly\nsensitive to tiny perturbations of input data, giving rise to adversarial\nexamples. Though this property is usually considered a weakness of learned\nmodels, it could be beneficial if used appropriately. The work that has been\naccomplished by MIT for this purpose, a deep-neural model by the name of\nSteganoGAN, has shown obligation for using this technique for steganography. In\nthis work, we have proposed a novel approach to improve the performance of the\nexisting system using latent space compression on the encoded data. This\ntheoretically would improve the performance exponentially. Thus, the algorithms\nused to improve the system's performance and the results obtained have been\nenunciated in this work. The results indicate the level of dominance this\nsystem could achieve to be able to diminish the difficulties in solving\nreal-time problems in terms of security, deployment and database management.",
    "descriptor": "\nComments: Presented at the 6 th National Conference on Information and Communication Technologies (NCICT 2020), June 12, 2020\n",
    "authors": [
      "Venkatesh Subramaniyan",
      "Vignesh Sivakumar",
      "A. K. Vagheesan",
      "S. Sakthivelan",
      "K. J. Jegadish Kumar",
      "K. K. Nagarajan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.13650"
  },
  {
    "id": "arXiv:2110.13654",
    "title": "Decentralized Thermal Control of Buildings",
    "abstract": "Energy requirements for heating and cooling of buildings constitute a major\nfraction of end use energy consumed. Therefore, it is important to provide the\noccupant comfort requirements in buildings in an energy efficient manner.\nHowever, buildings are large scale complex systems, susceptible to sensor,\nactuator or communication network failures in their thermal control\ninfrastructure, that can affect their performance in terms of occupant comfort\nand energy efficiency. The degree of decentralization in the control\narchitecture determines a fundamental tradeoff between performance and\nrobustness. This thesis studies the problem of thermal control of buildings\nfrom the perspective of partitioning them into clusters for decentralized\ncontrol, to balance underlying performance and robustness requirements.\nMeasures of deviation in performance and robustness between centralized and\ndecentralized architectures in the Model Predictive Control framework are\nderived. Appropriate clustering algorithms are then proposed to determine\ndecentralized control architectures which provide a satisfactory trade-off\nbetween the underlying performance and robustness objectives. Two different\npartitioning methodologies the CLF-MCS method and the OLF-FPM method are\ndeveloped and compared. The problem of decentralized control design based on\nthe architectures obtained using these methodologies is also considered. It\nentails the use of decentralized extended state observers to address the issue\nof unavailability of unknown states and disturbances in the system. The\npotential use of the proposed control architecture selection and decentralized\ncontrol design methodologies is demonstrated in simulation on a real world\nmulti-zone building.",
    "descriptor": "\nComments: PhD dissertation already published\n",
    "authors": [
      "Vikas Chandan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.13654"
  },
  {
    "id": "arXiv:2110.13655",
    "title": "Bridging the gap to real-world for network intrusion detection systems  with data-centric approach",
    "abstract": "Most research using machine learning (ML) for network intrusion detection\nsystems (NIDS) uses well-established datasets such as KDD-CUP99, NSL-KDD,\nUNSW-NB15, and CICIDS-2017. In this context, the possibilities of machine\nlearning techniques are explored, aiming for metrics improvements compared to\nthe published baselines (model-centric approach). However, those datasets\npresent some limitations as aging that make it unfeasible to transpose those\nML-based solutions to real-world applications. This paper presents a systematic\ndata-centric approach to address the current limitations of NIDS research,\nspecifically the datasets. This approach generates NIDS datasets composed of\nthe most recent network traffic and attacks, with the labeling process\nintegrated by design.",
    "descriptor": "\nComments: Accepted for Data-centric AI workshop at NeurIPS 2021\n",
    "authors": [
      "Gustavo de Carvalho Bertoli",
      "Louren\u00e7o Alves Pereira Junior",
      "Filipe Alves Neto Verri",
      "Aldri Luiz dos Santos",
      "Osamu Saotome"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13655"
  },
  {
    "id": "arXiv:2110.13656",
    "title": "CLLD: Contrastive Learning with Label Distance for Text Classificatioin",
    "abstract": "Existed pre-trained models have achieved state-of-the-art performance on\nvarious text classification tasks. These models have proven to be useful in\nlearning universal language representations. However, the semantic discrepancy\nbetween similar texts cannot be effectively distinguished by advanced\npre-trained models, which have a great influence on the performance of\nhard-to-distinguish classes. To address this problem, we propose a novel\nContrastive Learning with Label Distance (CLLD) in this work. Inspired by\nrecent advances in contrastive learning, we specifically design a\nclassification method with label distance for learning contrastive classes.\nCLLD ensures the flexibility within the subtle differences that lead to\ndifferent label assignments, and generates the distinct representations for\neach class having similarity simultaneously. Extensive experiments on public\nbenchmarks and internal datasets demonstrate that our method improves the\nperformance of pre-trained models on classification tasks. Importantly, our\nexperiments suggest that the learned label distance relieve the adversarial\nnature of interclasses.",
    "descriptor": "",
    "authors": [
      "Jinhe Lan",
      "Qingyuan Zhan",
      "Chenhao Jiang",
      "Kunping Yuan",
      "Desheng Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13656"
  },
  {
    "id": "arXiv:2110.13658",
    "title": "Can Character-based Language Models Improve Downstream Task Performance  in Low-Resource and Noisy Language Scenarios?",
    "abstract": "Recent impressive improvements in NLP, largely based on the success of\ncontextual neural language models, have been mostly demonstrated on at most a\ncouple dozen high-resource languages. Building language models and, more\ngenerally, NLP systems for non-standardized and low-resource languages remains\na challenging task. In this work, we focus on North-African colloquial\ndialectal Arabic written using an extension of the Latin script, called\nNArabizi, found mostly on social media and messaging communication. In this\nlow-resource scenario with data displaying a high level of variability, we\ncompare the downstream performance of a character-based language model on\npart-of-speech tagging and dependency parsing to that of monolingual and\nmultilingual models. We show that a character-based model trained on only 99k\nsentences of NArabizi and fined-tuned on a small treebank of this language\nleads to performance close to those obtained with the same architecture\npre-trained on large multilingual and monolingual models. Confirming these\nresults a on much larger data set of noisy French user-generated content, we\nargue that such character-based language models can be an asset for NLP in\nlow-resource and high language variability set-tings.",
    "descriptor": "\nComments: Camera ready version. Accepted to WNUT 2021\n",
    "authors": [
      "Arij Riabi",
      "Beno\u00eet Sagot",
      "Djam\u00e9 Seddah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13658"
  },
  {
    "id": "arXiv:2110.13661",
    "title": "Hybrid physics-based and data-driven modeling with calibrated  uncertainty for lithium-ion battery degradation diagnosis and prognosis",
    "abstract": "Advancing lithium-ion batteries (LIBs) in both design and usage is key to\npromoting electrification in the coming decades to mitigate human-caused\nclimate change. Inadequate understanding of LIB degradation is an important\nbottleneck that limits battery durability and safety. Here, we propose hybrid\nphysics-based and data-driven modeling for online diagnosis and prognosis of\nbattery degradation. Compared to existing battery modeling efforts, we aim to\nbuild a model with physics as its backbone and statistical learning techniques\nas enhancements. Such a hybrid model has better generalizability and\ninterpretability together with a well-calibrated uncertainty associated with\nits prediction, rendering it more valuable and relevant to safety-critical\napplications under realistic usage scenarios.",
    "descriptor": "\nComments: 6 pages, 3 figures, accepted for poster presentation at Tackling Climate Change with Machine Learning workshop at NeurIPS 2021\n",
    "authors": [
      "Jing Lin",
      "Yu Zhang",
      "Edwin Khoo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.13661"
  },
  {
    "id": "arXiv:2110.13664",
    "title": "Iterative Rule Extension for Logic Analysis of Data: an MILP-based  heuristic to derive interpretable binary classification from large datasets",
    "abstract": "Data-driven decision making is rapidly gaining popularity, fueled by the\never-increasing amounts of available data and encouraged by the development of\nmodels that can identify beyond linear input-output relationships.\nSimultaneously the need for interpretable prediction- and classification\nmethods is increasing, as this improves both our trust in these models and the\namount of information we can abstract from data. An important aspect of this\ninterpretability is to obtain insight in the sensitivity-specificity trade-off\nconstituted by multiple plausible input-output relationships. These are often\nshown in a receiver operating characteristic (ROC) curve. These developments\ncombined lead to the need for a method that can abstract complex yet\ninterpretable input-output relationships from large data, i.e. data containing\nlarge numbers of samples and sample features. Boolean phrases in disjunctive\nnormal form (DNF) are highly suitable for explaining non-linear input-output\nrelationships in a comprehensible way. Mixed integer linear programming (MILP)\ncan be used to abstract these Boolean phrases from binary data, though its\ncomputational complexity prohibits the analysis of large datasets. This work\npresents IRELAND, an algorithm that allows for abstracting Boolean phrases in\nDNF from data with up to 10,000 samples and sample characteristics. The results\nshow that for large datasets IRELAND outperforms the current state-of-the-art\nand can find solutions for datasets where current models run out of memory or\nneed excessive runtimes. Additionally, by construction IRELAND allows for an\nefficient computation of the sensitivity-specificity trade-off curve, allowing\nfor further understanding of the underlying input-output relationship.",
    "descriptor": "",
    "authors": [
      "Marleen Balvert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13664"
  },
  {
    "id": "arXiv:2110.13665",
    "title": "Bootstrapping Concept Formation in Small Neural Networks",
    "abstract": "The question how neural systems (of humans) can perform reasoning is still\nfar from being solved. We posit that the process of forming Concepts is a\nfundamental step required for this. We argue that, first, Concepts are formed\nas closed representations, which are then consolidated by relating them to each\nother. Here we present a model system (agent) with a small neural network that\nuses realistic learning rules and receives only feedback from the environment\nin which the agent performs virtual actions. First, the actions of the agent\nare reflexive. In the process of learning, statistical regularities in the\ninput lead to the formation of neuronal pools representing relations between\nthe entities observed by the agent from its artificial world. This information\nthen influences the behavior of the agent via feedback connections replacing\nthe initial reflex by an action driven by these relational representations. We\nhypothesize that the neuronal pools representing relational information can be\nconsidered as primordial Concepts, which may in a similar way be present in\nsome pre-linguistic animals, too. We argue that systems such as this can help\nformalizing the discussion about what constitutes Concepts and serve as a\nstarting point for constructing artificial cogitating systems.",
    "descriptor": "",
    "authors": [
      "Minija Tamosiunaite",
      "Tomas Kulvicius",
      "Florentin W\u00f6rg\u00f6tter"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2110.13665"
  },
  {
    "id": "arXiv:2110.13666",
    "title": "MEKF Ignoring Initial Conditions for Attitude Estimation Using Vector  Observations",
    "abstract": "In this paper, the well-known multiplicative extended Kalman filter (MEKF) is\nre-investigated for attitude estimation using vector observations. From the Lie\ngroup theory, it is shown that the attitude estimation model is group affine\nand its error state model should be trajectory-independent. Moreover, with such\ntrajectory-independent error state model, the linear Kalman filter is still\neffective for large initialization errors. However, the measurement model of\nthe traditional MEKF is dependent on the attitude prediction, which is\ntherefore trajectory-dependent. This is also the main reason why the\nperformance of traditional MEKF is degraded for large initialization errors.\nThrough substitution of the attitude prediction related term with the vector\nobservation in body frame, a trajectory-independent measurement model is\nderived for MEKF. Meanwhile, the MEKFs with reference attitude error definition\nand with global state formulating on special Euclidean group have also been\nstudied, with main focus on derivation of the trajectory-independent\nmeasurement models. Extensive Monte Carlo simulations and field test of\nattitude estimation implementations demonstrate that the performance of MEKFs\ncan be much improved with trajectory-independent measurement models.",
    "descriptor": "",
    "authors": [
      "Lubin Chang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.13666"
  },
  {
    "id": "arXiv:2110.13669",
    "title": "A Non-linear Differentiable Model for Stormwater-based Irrigation of a  Green Roof in Toronto",
    "abstract": "Green infrastructure has potential to alleviate the environmental impact of\nrapidly growing cities. This potential has inspired laws in Toronto that\nrequire the inclusion of rooftops with large vegetation beds, called green\nroofs, into sufficiently sized construction projects. We study the problem of\nreusing stormwater to irrigate a green roof in Toronto, where potable water is\nthe current irrigation source. The vision is that widespread reuse of\nstormwater runoff for irrigation of green roofs and other purposes can reduce\nsewer overflow volumes without over-building (with the added benefit of\nconserving potable water). Towards this vision, our goal is to develop and\nevaluate two pump controllers for transporting stormwater to the green roof of\ninterest in simulation. A key contribution is our development of a\nsite-specific non-linear model for stormwater flow using smoothing techniques\nthat permits linearization and a standard model predictive controller (MPC). We\ncompare the efficacy of the MPC, which anticipates the weather, and an on/off\ncontroller, which is reactive rather than anticipative, for the site in\nsimulation. With further study, we are hopeful that this research will advance\ncontrol systems technology to improve the performance of green and stormwater\ninfrastructure in growing urban areas.",
    "descriptor": "\nComments: under review for IEEE Conference on Technologies for Sustainability (SusTech 2022)\n",
    "authors": [
      "Chia-Hui Yeh",
      "Margaret P. Chapman"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.13669"
  },
  {
    "id": "arXiv:2110.13674",
    "title": "C$^2$SP-Net: Joint Compression and Classification Network for Epilepsy  Seizure Prediction",
    "abstract": "Recent development in brain-machine interface technology has made seizure\nprediction possible. However, the communication of large volume of\nelectrophysiological signals between sensors and processing apparatus and\nrelated computation become two major bottlenecks for seizure prediction systems\ndue to the constrained bandwidth and limited computation resource, especially\nfor wearable and implantable medical devices. Although compressive sensing (CS)\ncan be adopted to compress the signals to reduce communication bandwidth\nrequirement, it needs a complex reconstruction procedure before the signal can\nbe used for seizure prediction. In this paper, we propose C$^2$SP-Net, to\njointly solve compression, prediction, and reconstruction with a single neural\nnetwork. A plug-and-play in-sensor compression matrix is constructed to reduce\ntransmission bandwidth requirement. The compressed signal can be used for\nseizure prediction without additional reconstruction steps. Reconstruction of\nthe original signal can also be carried out in high fidelity. Prediction\naccuracy, sensitivity, false prediction rate, and reconstruction quality of the\nproposed framework are evaluated under various compression ratios. The\nexperimental results illustrate that our model outperforms the competitive\nstate-of-the-art baselines by a large margin in prediction accuracy. In\nparticular, our proposed method produces an average loss of 0.35 % in\nprediction accuracy with a compression ratio ranging from 1/2 to 1/16.",
    "descriptor": "",
    "authors": [
      "Di Wu",
      "Yi Shi",
      "Ziyu Wang",
      "Jie Yang",
      "Mohamad Sawan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13674"
  },
  {
    "id": "arXiv:2110.13675",
    "title": "Alpha-IoU: A Family of Power Intersection over Union Losses for Bounding  Box Regression",
    "abstract": "Bounding box (bbox) regression is a fundamental task in computer vision. So\nfar, the most commonly used loss functions for bbox regression are the\nIntersection over Union (IoU) loss and its variants. In this paper, we\ngeneralize existing IoU-based losses to a new family of power IoU losses that\nhave a power IoU term and an additional power regularization term with a single\npower parameter $\\alpha$. We call this new family of losses the $\\alpha$-IoU\nlosses and analyze properties such as order preservingness and loss/gradient\nreweighting. Experiments on multiple object detection benchmarks and models\ndemonstrate that $\\alpha$-IoU losses, 1) can surpass existing IoU-based losses\nby a noticeable performance margin; 2) offer detectors more flexibility in\nachieving different levels of bbox regression accuracy by modulating $\\alpha$;\nand 3) are more robust to small datasets and noisy bboxes.",
    "descriptor": "",
    "authors": [
      "Jiabo He",
      "Sarah Erfani",
      "Xingjun Ma",
      "James Bailey",
      "Ying Chi",
      "Xian-Sheng Hua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13675"
  },
  {
    "id": "arXiv:2110.13677",
    "title": "A Personalized Diagnostic Generation Framework Based on Multi-source  Heterogeneous Data",
    "abstract": "Personalized diagnoses have not been possible due to sear amount of data\npathologists have to bear during the day-to-day routine. This lead to the\ncurrent generalized standards that are being continuously updated as new\nfindings are reported. It is noticeable that these effective standards are\ndeveloped based on a multi-source heterogeneous data, including whole-slide\nimages and pathology and clinical reports. In this study, we propose a\nframework that combines pathological images and medical reports to generate a\npersonalized diagnosis result for individual patient. We use nuclei-level image\nfeature similarity and content-based deep learning method to search for a\npersonalized group of population with similar pathological characteristics,\nextract structured prognostic information from descriptive pathology reports of\nthe similar patient population, and assign importance of different prognostic\nfactors to generate a personalized pathological diagnosis result. We use\nmulti-source heterogeneous data from TCGA (The Cancer Genome Atlas) database.\nThe result demonstrate that our framework matches the performance of\npathologists in the diagnosis of renal cell carcinoma. This framework is\ndesigned to be generic, thus could be applied for other types of cancer. The\nweights could provide insights to the known prognostic factors and further\nguide more precise clinical treatment protocols.",
    "descriptor": "\nComments: BIBM 2021 accepted, including 9 pages, 3 figures\n",
    "authors": [
      "Jialun Wu",
      "Zeyu Gao",
      "Haichuan Zhang",
      "Ruonan Zhang",
      "Tieliang Gong",
      "Chunbao Wang",
      "Chen Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13677"
  },
  {
    "id": "arXiv:2110.13681",
    "title": "Malicious Mode Attack on EV Coordinated Charging Load and MIADRC Defense  Strategy",
    "abstract": "The Internet of Things (IoT) provides a salient communication environment to\nfacilitate the coordinated charging of electric vehicle (EV) load. However, as\nIoT is connected with the public network, the coordinated charging system is in\na low-level cyber security and greatly vulnerable to malicious attacks. This\npaper investigates the malicious mode attack (MMA), which is a new cyberattack\npattern that simultaneously attacks massive EV charging piles to generate\ncontinuous sinusoidal power disturbance with the same frequency as the\npoorly-damped wide-area electromechanical mode. Thereby, high amplitude forced\noscillations could be stimulated by MMA, which seriously threats the power\nsystem stability. First, the potential threat of MMA is clarified by\ninvestigating the vulnerability of the IoT-based coordinated charging load\ncontrol system, and an MMA process like Mirai is pointed out as an example. And\nthen, based on the attack process, an MMA model is established for impact\nanalysis where expressions of the mean and stochastic responses of the MMA\nforced oscillation are derived to discover main impact factors. Further, to\nmitigate the impact of MMA, a defense strategy based on multi-index information\nactive disturbance rejection control is proposed to improve the stability and\nanti-disturbance ability of the power system, which considers the impact\nfactors of both mode damping and disturbance compensation. Simulations are\nconducted to verify the existence and characteristics of MMA threats, and the\nefficiency of the proposed defense strategy is also validated.",
    "descriptor": "",
    "authors": [
      "Yichen Zhou",
      "Weidong Liu",
      "Jing Ma",
      "Xinghao Zhen",
      "Yonggang Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.13681"
  },
  {
    "id": "arXiv:2110.13683",
    "title": "BioIE: Biomedical Information Extraction with Multi-head Attention  Enhanced Graph Convolutional Network",
    "abstract": "Constructing large-scaled medical knowledge graphs can significantly boost\nhealthcare applications for medical surveillance, bring much attention from\nrecent research. An essential step in constructing large-scale MKG is\nextracting information from medical reports. Recently, information extraction\ntechniques have been proposed and show promising performance in biomedical\ninformation extraction. However, these methods only consider limited types of\nentity and relation due to the noisy biomedical text data with complex entity\ncorrelations. Thus, they fail to provide enough information for constructing\nMKGs and restrict the downstream applications. To address this issue, we\npropose Biomedical Information Extraction, a hybrid neural network to extract\nrelations from biomedical text and unstructured medical reports. Our model\nutilizes a multi-head attention enhanced graph convolutional network to capture\nthe complex relations and context information while resisting the noise from\nthe data. We evaluate our model on two major biomedical relationship extraction\ntasks, chemical-disease relation and chemical-protein interaction, and a\ncross-hospital pan-cancer pathology report corpus. The results show that our\nmethod achieves superior performance than baselines. Furthermore, we evaluate\nthe applicability of our method under a transfer learning setting and show that\nBioIE achieves promising performance in processing medical text from different\nformats and writing styles.",
    "descriptor": "\nComments: BIBM 2021 accepted, including 9 pages, 1 figure\n",
    "authors": [
      "Jialun Wu",
      "Yang Liu",
      "Zeyu Gao",
      "Tieliang Gong",
      "Chunbao Wang",
      "Chen Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.13683"
  },
  {
    "id": "arXiv:2110.13691",
    "title": "An Explicit-Joint and Supervised-Contrastive Learning Framework for  Few-Shot Intent Classification and Slot Filling",
    "abstract": "Intent classification (IC) and slot filling (SF) are critical building blocks\nin task-oriented dialogue systems. These two tasks are closely-related and can\nflourish each other. Since only a few utterances can be utilized for\nidentifying fast-emerging new intents and slots, data scarcity issue often\noccurs when implementing IC and SF. However, few IC/SF models perform well when\nthe number of training samples per class is quite small. In this paper, we\npropose a novel explicit-joint and supervised-contrastive learning framework\nfor few-shot intent classification and slot filling. Its highlights are as\nfollows. (i) The model extracts intent and slot representations via\nbidirectional interactions, and extends prototypical network to achieve\nexplicit-joint learning, which guarantees that IC and SF tasks can mutually\nreinforce each other. (ii) The model integrates with supervised contrastive\nlearning, which ensures that samples from same class are pulled together and\nsamples from different classes are pushed apart. In addition, the model follows\na not common but practical way to construct the episode, which gets rid of the\ntraditional setting with fixed way and shot, and allows for unbalanced\ndatasets. Extensive experiments on three public datasets show that our model\ncan achieve promising performance.",
    "descriptor": "\nComments: 11 pages, 2 figures, Findings of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP) (long paper), November 2021\n",
    "authors": [
      "Han Liu",
      "Feng Zhang",
      "Xiaotong Zhang",
      "Siyang Zhao",
      "Xianchao Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13691"
  },
  {
    "id": "arXiv:2110.13692",
    "title": "Annotating Implicit Reasoning in Arguments with Causal Links",
    "abstract": "Most of the existing work that focus on the identification of implicit\nknowledge in arguments generally represent implicit knowledge in the form of\ncommonsense or factual knowledge. However, such knowledge is not sufficient to\nunderstand the implicit reasoning link between individual argumentative\ncomponents (i.e., claim and premise). In this work, we focus on identifying the\nimplicit knowledge in the form of argumentation knowledge which can help in\nunderstanding the reasoning link in arguments. Being inspired by the Argument\nfrom Consequences scheme, we propose a semi-structured template to represent\nsuch argumentation knowledge that explicates the implicit reasoning in\narguments via causality. We create a novel two-phase annotation process with\nsimplified guidelines and show how to collect and filter high-quality implicit\nreasonings via crowdsourcing. We find substantial inter-annotator agreement for\nquality evaluation between experts, but find evidence that casts a few\nquestions on the feasibility of collecting high-quality semi-structured\nimplicit reasoning through our crowdsourcing process. We release our\nmaterials(i.e., crowdsourcing guidelines and collected implicit reasonings) to\nfacilitate further research towards the structured representation of\nargumentation knowledge.",
    "descriptor": "\nComments: Accepted to ArgKG:Workshop on Argumentation Knowledge Graphs (AKBC 2021)\n",
    "authors": [
      "Keshav Singh",
      "Naoya Inoue",
      "Farjana Sultana Mim",
      "Shoichi Naitoh",
      "Kentaro Inui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.13692"
  },
  {
    "id": "arXiv:2110.13693",
    "title": "A proposed method using GPU based SDO to optimize retail warehouses",
    "abstract": "Research in warehouse optimization has gotten increased attention in the last\nfew years due to e-commerce. The warehouse contains a waste range of different\nproducts. Due to the nature of the individual order, it is challenging to plan\nthe picking list to optimize the material flow in the process. There are also\nchallenges in minimizing costs and increasing production capacity, and this\ncomplexity can be defined as a multidisciplinary optimization problem with an\nIDF nature. In recent years the use of parallel computing using GPGPUs has\nbecome increasingly popular due to the introduction of CUDA C and accompanying\napplications in, e.g., Python. In the case study at the company in the field of\nretail, a case study including a system design optimization (SDO) resulted in\nan increase in throughput with well over 20% just by clustering different\ncategories and suggesting in which sequence the orders should be picked during\na given time frame. The options provided by implementing a distributed\nhigh-performance computing network based on GPUs for subsystem optimization\nhave shown to be fruitful in developing a functioning SDO for warehouse\noptimization. The toolchain can be used for designing new warehouses or\nevaluating and tuning existing ones.",
    "descriptor": "",
    "authors": [
      "Magnus Bengtsson",
      "Jonas Waidringer"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.13693"
  },
  {
    "id": "arXiv:2110.13694",
    "title": "A Horizon Detection Algorithm for Maritime Surveillance",
    "abstract": "The horizon line is a valuable feature in the maritime environment as it has\na high persistence when compared to other features (e.g., shore corners,\nwaves). It is used in several applications, especially in maritime\nsurveillance. The task of horizon detection may be easy for humans, but it is\nhard on computers due to the high change of color and texture on maritime\nscenes. Moreover, the computational complexity is an important constraint to\ntake into account while developing the algorithm. In this paper, we propose a\nnew method that we expect to enhance the state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Yassir Zardoua",
      "Astito Abdelali",
      "Boulaala Mohammed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13694"
  },
  {
    "id": "arXiv:2110.13699",
    "title": "Addressing out-of-distribution label noise in webly-labelled data",
    "abstract": "A recurring focus of the deep learning community is towards reducing the\nlabeling effort. Data gathering and annotation using a search engine is a\nsimple alternative to generating a fully human-annotated and human-gathered\ndataset. Although web crawling is very time efficient, some of the retrieved\nimages are unavoidably noisy, i.e. incorrectly labeled. Designing robust\nalgorithms for training on noisy data gathered from the web is an important\nresearch perspective that would render the building of datasets easier. In this\npaper we conduct a study to understand the type of label noise to expect when\nbuilding a dataset using a search engine. We review the current limitations of\nstate-of-the-art methods for dealing with noisy labels for image classification\ntasks in the case of web noise distribution. We propose a simple solution to\nbridge the gap with a fully clean dataset using Dynamic Softening of\nOut-of-distribution Samples (DSOS), which we design on corrupted versions of\nthe CIFAR-100 dataset, and compare against state-of-the-art algorithms on the\nweb noise perturbated MiniImageNet and Stanford datasets and on real label\nnoise datasets: WebVision 1.0 and Clothing1M. Our work is fully reproducible\nhttps://git.io/JKGcj",
    "descriptor": "\nComments: Accepted at WACV 2022\n",
    "authors": [
      "Paul Albert",
      "Diego Ortego",
      "Eric Arazo",
      "Noel O'Connor",
      "Kevin McGuinness"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13699"
  },
  {
    "id": "arXiv:2110.13704",
    "title": "Encoding of Predicate Subtyping with Proof Irrelevance in the  $\u03bb$$\u03a0$-Calculus Modulo Theory",
    "abstract": "The $\\lambda$$\\Pi$-calculus modulo theory is a logical framework in which\nvarious logics and type systems can be encoded, thus helping the\ncross-verification and interoperability of proof systems based on those logics\nand type systems. In this paper, we show how to encode predicate subtyping and\nproof irrelevance, two important features of the PVS proof assistant. We prove\nthat this encoding is correct and that encoded proofs can be mechanically\nchecked by Dedukti, a type checker for the $\\lambda$$\\Pi$-calculus modulo\ntheory using rewriting.",
    "descriptor": "\nComments: TYPES 2020 wasn't held in Turin as planned because of the COVID-19 outbreak. TYPES 2020 - 26th International Conference on Types for Proofs and Programs, Mar 2020, Turino, Italy\n",
    "authors": [
      "Gabriel Hondet",
      "Fr\u00e9d\u00e9ric Blanqui"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.13704"
  },
  {
    "id": "arXiv:2110.13705",
    "title": "Causal Effect Estimation using Variational Information Bottleneck",
    "abstract": "Causal inference is to estimate the causal effect in a causal relationship\nwhen intervention is applied. Precisely, in a causal model with binary\ninterventions, i.e., control and treatment, the causal effect is simply the\ndifference between the factual and counterfactual. The difficulty is that the\ncounterfactual may never been obtained which has to be estimated and so the\ncausal effect could only be an estimate. The key challenge for estimating the\ncounterfactual is to identify confounders which effect both outcomes and\ntreatments. A typical approach is to formulate causal inference as a supervised\nlearning problem and so counterfactual could be predicted. Including linear\nregression and deep learning models, recent machine learning methods have been\nadapted to causal inference. In this paper, we propose a method to estimate\nCausal Effect by using Variational Information Bottleneck (CEVIB). The\npromising point is that VIB is able to naturally distill confounding variables\nfrom the data, which enables estimating causal effect by using observational\ndata. We have compared CEVIB to other methods by applying them to three data\nsets showing that our approach achieved the best performance. We also\nexperimentally showed the robustness of our method.",
    "descriptor": "",
    "authors": [
      "Zhenyu Lu",
      "Yurong Cheng",
      "Mingjun Zhong",
      "George Stoian",
      "Ye Yuan",
      "Guoren Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13705"
  },
  {
    "id": "arXiv:2110.13708",
    "title": "TNTC: two-stream network with transformer-based complementarity for  gait-based emotion recognition",
    "abstract": "Recognizing the human emotion automatically from visual characteristics plays\na vital role in many intelligent applications. Recently, gait-based emotion\nrecognition, especially gait skeletons-based characteristic, has attracted much\nattention, while many available methods have been proposed gradually. The\npopular pipeline is to first extract affective features from joint skeletons,\nand then aggregate the skeleton joint and affective features as the feature\nvector for classifying the emotion. However, the aggregation procedure of these\nemerged methods might be rigid, resulting in insufficiently exploiting the\ncomplementary relationship between skeleton joint and affective features.\nMeanwhile, the long range dependencies in both spatial and temporal domains of\nthe gait sequence are scarcely considered. To address these issues, we propose\na novel two-stream network with transformer-based complementarity, termed as\nTNTC. Skeleton joint and affective features are encoded into two individual\nimages as the inputs of two streams, respectively. A new transformer-based\ncomplementarity module (TCM) is proposed to bridge the complementarity between\ntwo streams hierarchically via capturing long range dependencies. Experimental\nresults demonstrate TNTC outperforms state-of-the-art methods on the latest\ndataset in terms of accuracy.",
    "descriptor": "",
    "authors": [
      "Chuanfei Hu",
      "Weijie Sheng",
      "Bo Dong",
      "Xinde Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13708"
  },
  {
    "id": "arXiv:2110.13710",
    "title": "DASentimental: Detecting depression, anxiety and stress in texts via  emotional recall, cognitive networks and machine learning",
    "abstract": "Most current affect scales and sentiment analysis on written text focus on\nquantifying valence (sentiment) -- the most primary dimension of emotion.\nHowever, emotions are broader and more complex than valence. Distinguishing\nnegative emotions of similar valence could be important in contexts such as\nmental health. This project proposes a semi-supervised machine learning model\n(DASentimental) to extract depression, anxiety and stress from written text.\nFirst, we trained the model to spot how sequences of recalled emotion words by\n$N=200$ individuals correlated with their responses to the Depression Anxiety\nStress Scale (DASS-21). Within the framework of cognitive network science, we\nmodel every list of recalled emotions as a walk over a networked mental\nrepresentation of semantic memory, with emotions connected according to free\nassociations in people's memory. Among several tested machine learning\napproaches, we find that a multilayer perceptron neural network trained on word\nsequences and semantic network distances can achieve state-of-art,\ncross-validated predictions for depression ($R = 0.7$), anxiety ($R = 0.44$)\nand stress ($R = 0.52$). Though limited by sample size, this first-of-its-kind\napproach enables quantitative explorations of key semantic dimensions behind\nDAS levels. We find that semantic distances between recalled emotions and the\ndyad \"sad-happy\" are crucial features for estimating depression levels but are\nless important for anxiety and stress. We also find that semantic distance of\nrecalls from \"fear\" can boost the prediction of anxiety but it becomes\nredundant when the \"sad-happy\" dyad is considered. Adopting DASentimental as a\nsemi-supervised learning tool to estimate DAS in text, we apply it to a dataset\nof 142 suicide notes. We conclude by discussing key directions for future\nresearch enabled by artificial intelligence detecting stress, anxiety and\ndepression.",
    "descriptor": "\nComments: 28 pages, 2 figures and 2 tables\n",
    "authors": [
      "Asra Fatima",
      "Li Ying",
      "Thomas Hills",
      "Massimo Stella"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.13710"
  },
  {
    "id": "arXiv:2110.13711",
    "title": "Hierarchical Transformers Are More Efficient Language Models",
    "abstract": "Transformer models yield impressive results on many NLP and sequence modeling\ntasks. Remarkably, Transformers can handle long sequences which allows them to\nproduce long coherent outputs: full paragraphs produced by GPT-3 or\nwell-structured images produced by DALL-E. These large language models are\nimpressive but also very inefficient and costly, which limits their\napplications and accessibility. We postulate that having an explicit\nhierarchical architecture is the key to Transformers that efficiently handle\nlong sequences. To verify this claim, we first study different ways to\ndownsample and upsample activations in Transformers so as to make them\nhierarchical. We use the best performing upsampling and downsampling layers to\ncreate Hourglass - a hierarchical Transformer language model. Hourglass\nimproves upon the Transformer baseline given the same amount of computation and\ncan yield the same results as Transformers more efficiently. In particular,\nHourglass sets new state-of-the-art for Transformer models on the ImageNet32\ngeneration task and improves language modeling efficiency on the widely studied\nenwik8 benchmark.",
    "descriptor": "",
    "authors": [
      "Piotr Nawrot",
      "Szymon Tworkowski",
      "Micha\u0142 Tyrolski",
      "\u0141ukasz Kaiser",
      "Yuhuai Wu",
      "Christian Szegedy",
      "Henryk Michalewski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.13711"
  },
  {
    "id": "arXiv:2110.13713",
    "title": "YOLO-ReT: Towards High Accuracy Real-time Object Detection on Edge GPUs",
    "abstract": "Performance of object detection models has been growing rapidly on two major\nfronts, model accuracy and efficiency. However, in order to map deep neural\nnetwork (DNN) based object detection models to edge devices, one typically\nneeds to compress such models significantly, thus compromising the model\naccuracy. In this paper, we propose a novel edge GPU friendly module for\nmulti-scale feature interaction by exploiting missing combinatorial connections\nbetween various feature scales in existing state-of-the-art methods.\nAdditionally, we propose a novel transfer learning backbone adoption inspired\nby the changing translational information flow across various tasks, designed\nto complement our feature interaction module and together improve both accuracy\nas well as execution speed on various edge GPU devices available in the market.\nFor instance, YOLO-ReT with MobileNetV2x0.75 backbone runs real-time on Jetson\nNano, and achieves 68.75 mAP on Pascal VOC and 34.91 mAP on COCO, beating its\npeers by 3.05 mAP and 0.91 mAP respectively, while executing faster by 3.05\nFPS. Furthermore, introducing our multi-scale feature interaction module in\nYOLOv4-tiny and YOLOv4-tiny (3l) improves their performance to 41.5 and 48.1\nmAP respectively on COCO, outperforming the original versions by 1.3 and 0.9\nmAP.",
    "descriptor": "\nComments: To appear in WACV 2022\n",
    "authors": [
      "Prakhar Ganesh",
      "Yao Chen",
      "Yin Yang",
      "Deming Chen",
      "Marianne Winslett"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13713"
  },
  {
    "id": "arXiv:2110.13715",
    "title": "ConE: Cone Embeddings for Multi-Hop Reasoning over Knowledge Graphs",
    "abstract": "Query embedding (QE) -- which aims to embed entities and first-order logical\n(FOL) queries in low-dimensional spaces -- has shown great power in multi-hop\nreasoning over knowledge graphs. Recently, embedding entities and queries with\ngeometric shapes becomes a promising direction, as geometric shapes can\nnaturally represent answer sets of queries and logical relationships among\nthem. However, existing geometry-based models have difficulty in modeling\nqueries with negation, which significantly limits their applicability. To\naddress this challenge, we propose a novel query embedding model, namely Cone\nEmbeddings (ConE), which is the first geometry-based QE model that can handle\nall the FOL operations, including conjunction, disjunction, and negation.\nSpecifically, ConE represents entities and queries as Cartesian products of\ntwo-dimensional cones, where the intersection and union of cones naturally\nmodel the conjunction and disjunction operations. By further noticing that the\nclosure of complement of cones remains cones, we design geometric complement\noperators in the embedding space for the negation operations. Experiments\ndemonstrate that ConE significantly outperforms existing state-of-the-art\nmethods on benchmark datasets.",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Zhanqiu Zhang",
      "Jie Wang",
      "Jiajun Chen",
      "Shuiwang Ji",
      "Feng Wu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.13715"
  },
  {
    "id": "arXiv:2110.13719",
    "title": "Semi-supervised dry herbage mass estimation using automatic data and  synthetic images",
    "abstract": "Monitoring species-specific dry herbage biomass is an important aspect of\npasture-based milk production systems. Being aware of the herbage biomass in\nthe field enables farmers to manage surpluses and deficits in herbage supply,\nas well as using targeted nitrogen fertilization when necessary. Deep learning\nfor computer vision is a powerful tool in this context as it can accurately\nestimate the dry biomass of a herbage parcel using images of the grass canopy\ntaken using a portable device. However, the performance of deep learning comes\nat the cost of an extensive, and in this case destructive, data gathering\nprocess. Since accurate species-specific biomass estimation is labor intensive\nand destructive for the herbage parcel, we propose in this paper to study low\nsupervision approaches to dry biomass estimation using computer vision. Our\ncontributions include: a synthetic data generation algorithm to generate data\nfor a herbage height aware semantic segmentation task, an automatic process to\nlabel data using semantic segmentation maps, and a robust regression network\ntrained to predict dry biomass using approximate biomass labels and a small\ntrusted dataset with gold standard labels. We design our approach on a herbage\nmass estimation dataset collected in Ireland and also report state-of-the-art\nresults on the publicly released Grass-Clover biomass estimation dataset from\nDenmark. Our code is available at https://git.io/J0L2a",
    "descriptor": "\nComments: Published at CVPPA 2021, ICCVW 2021\n",
    "authors": [
      "Paul Albert",
      "Mohamed Saadeldin",
      "Badri Narayanan",
      "Brian Mac Namee",
      "Deirdre Hennessy",
      "Aisling O'Connor",
      "Noel O'Connor",
      "Kevin McGuinness"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13719"
  },
  {
    "id": "arXiv:2110.13721",
    "title": "Geometric Transformer for End-to-End Molecule Properties Prediction",
    "abstract": "Transformers have become methods of choice in many applications thanks to\ntheir ability to represent complex interaction between elements. However,\nextending the Transformer architecture to non-sequential data such as molecules\nand enabling its training on small datasets remain a challenge. In this work,\nwe introduce a Transformer-based architecture for molecule property prediction,\nwhich is able to capture the geometry of the molecule. We modify the classical\npositional encoder by an initial encoding of the molecule geometry, as well as\na learned gated self-attention mechanism. We further suggest an augmentation\nscheme for molecular data capable of avoiding the overfitting induced by the\noverparameterized architecture. The proposed framework outperforms the\nstate-of-the-art methods while being based on pure machine learning solely,\ni.e. the method does not incorporate domain knowledge from quantum chemistry\nand does not use extended geometric inputs beside the pairwise atomic\ndistances.",
    "descriptor": "",
    "authors": [
      "Yoni Choukroun",
      "Lior Wolf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13721"
  },
  {
    "id": "arXiv:2110.13728",
    "title": "Linearization and Computation for Large-Strain Viscoelasticity",
    "abstract": "Time-discrete numerical minimization schemes for simple viscoelastic\nmaterials in the large strain Kelvin-Voigt rheology are not well-posed due to\nnon-quasiconvexity of the dissipation functional. A possible solution is to\nresort into non-simple material models with higher-order gradients of\ndeformations. This makes, however, numerical computations much more involved.\nHere we propose another approach relying on local minimizers of the\nsimple-material model. Computational tests are provided showing a very good\nagreement between our model and the original one.",
    "descriptor": "\nComments: 14 pages, 4 figures\n",
    "authors": [
      "Patrick Dondl",
      "Martin Jesenko",
      "Martin Kru\u017e\u00edk",
      "Jan Valdman"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.13728"
  },
  {
    "id": "arXiv:2110.13729",
    "title": "Improving Robustness of Deep Neural Networks for Aerial Navigation by  Incorporating Input Uncertainty",
    "abstract": "Uncertainty quantification methods are required in autonomous systems that\ninclude deep learning (DL) components to assess the confidence of their\nestimations. However, to successfully deploy DL components in safety-critical\nautonomous systems, they should also handle uncertainty at the input rather\nthan only at the output of the DL components. Considering a probability\ndistribution in the input enables the propagation of uncertainty through\ndifferent components to provide a representative measure of the overall system\nuncertainty. In this position paper, we propose a method to account for\nuncertainty at the input of Bayesian Deep Learning control policies for Aerial\nNavigation. Our early experiments show that the proposed method improves the\nrobustness of the navigation policy in Out-of-Distribution (OoD) scenarios.",
    "descriptor": "\nComments: Accepted at the Fourth International Workshop on Artificial Intelligence Safety Engineering, WAISE 2021\n",
    "authors": [
      "Fabio Arnez",
      "Huascar Espinoza",
      "Ansgar Radermarcher",
      "Fran\u00e7ois Terrier"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.13729"
  },
  {
    "id": "arXiv:2110.13735",
    "title": "On Deterministic Numerical Methods for the Quantum Boltzmann-Nordheim  Equation. I. Spectrally Accurate Approximations, Bose-Einstein Condensation,  Fermi-Dirac Saturation",
    "abstract": "Spectral methods, thanks to their high accuracy and the possibility to use\nfast algorithms, represent an effective way to approximate the collisional\nkinetic equations of Boltzmann type, such as the Boltzmann-Nordheim equation.\nThis equation, modeled on the seminal Boltzmann equation, describes using a\nstatistical physics formalism the time evolution of a gas composed of bosons or\nfermions. Using the spectral-Galerkin algorithm introduced in [F. Filbet, J.\nHu, and S. Jin, ESAIM: Math. Model. Numer. Anal., 2011], together with some\nnovel parallelization techniques, we investigate some of the conjectured\nproperties of the large time behavior of the solutions to this equation. In\nparticular, we are able to observe numerically both Bose-Einstein condensation\nand Fermi-Dirac relaxation.",
    "descriptor": "",
    "authors": [
      "Alexandre Mouton",
      "Thomas Rey"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.13735"
  },
  {
    "id": "arXiv:2110.13740",
    "title": "DP-SSL: Towards Robust Semi-supervised Learning with A Few Labeled  Samples",
    "abstract": "The scarcity of labeled data is a critical obstacle to deep learning.\nSemi-supervised learning (SSL) provides a promising way to leverage unlabeled\ndata by pseudo labels. However, when the size of labeled data is very small\n(say a few labeled samples per class), SSL performs poorly and unstably,\npossibly due to the low quality of learned pseudo labels. In this paper, we\npropose a new SSL method called DP-SSL that adopts an innovative data\nprogramming (DP) scheme to generate probabilistic labels for unlabeled data.\nDifferent from existing DP methods that rely on human experts to provide\ninitial labeling functions (LFs), we develop a multiple-choice learning~(MCL)\nbased approach to automatically generate LFs from scratch in SSL style. With\nthe noisy labels produced by the LFs, we design a label model to resolve the\nconflict and overlap among the noisy labels, and finally infer probabilistic\nlabels for unlabeled samples. Extensive experiments on four standard SSL\nbenchmarks show that DP-SSL can provide reliable labels for unlabeled data and\nachieve better classification performance on test sets than existing SSL\nmethods, especially when only a small number of labeled samples are available.\nConcretely, for CIFAR-10 with only 40 labeled samples, DP-SSL achieves 93.82%\nannotation accuracy on unlabeled data and 93.46% classification accuracy on\ntest data, which are higher than the SOTA results.",
    "descriptor": "\nComments: Accepted by NeurIPS 2021; 16 pages with appendix\n",
    "authors": [
      "Yi Xu",
      "Jiandong Ding",
      "Lu Zhang",
      "Shuigeng Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13740"
  },
  {
    "id": "arXiv:2110.13741",
    "title": "Disrupting Deep Uncertainty Estimation Without Harming Accuracy",
    "abstract": "Deep neural networks (DNNs) have proven to be powerful predictors and are\nwidely used for various tasks. Credible uncertainty estimation of their\npredictions, however, is crucial for their deployment in many risk-sensitive\napplications. In this paper we present a novel and simple attack, which unlike\nadversarial attacks, does not cause incorrect predictions but instead cripples\nthe network's capacity for uncertainty estimation. The result is that after the\nattack, the DNN is more confident of its incorrect predictions than about its\ncorrect ones without having its accuracy reduced. We present two versions of\nthe attack. The first scenario focuses on a black-box regime (where the\nattacker has no knowledge of the target network) and the second scenario\nattacks a white-box setting. The proposed attack is only required to be of\nminuscule magnitude for its perturbations to cause severe uncertainty\nestimation damage, with larger magnitudes resulting in completely unusable\nuncertainty estimations. We demonstrate successful attacks on three of the most\npopular uncertainty estimation methods: the vanilla softmax score, Deep\nEnsembles and MC-Dropout. Additionally, we show an attack on SelectiveNet, the\nselective classification architecture. We test the proposed attack on several\ncontemporary architectures such as MobileNetV2 and EfficientNetB0, all trained\nto classify ImageNet.",
    "descriptor": "\nComments: To be published in NeurIPS 2021\n",
    "authors": [
      "Ido Galil",
      "Ran El-Yaniv"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13741"
  },
  {
    "id": "arXiv:2110.13743",
    "title": "Towards a Theory of Domains for Harmonic Functions and its Symbolic  Counterpart",
    "abstract": "In this paper, we begin by reviewing the calculus induced by the framework of\n[10]. In there, we extended Polylogarithm functions over a subalgebra of\nnoncommutative rational power series, recognizable by finite state\n(multiplicity) automata over the alphabet X = {x 0 , x 1 }. The stability of\nthis calculus under shuffle products relies on the nuclearity of the target\nspace [31]. We also concentrated on algebraic and analytic aspects of this\nextension allowing to index polylogarithms, at non positive multi-indices, by\nrational series and also allowing to regularize divergent polyzetas, at non\npositive multi-indices [10]. As a continuation of works in [10] and in order to\nunderstand the bridge between the extension of this \"polylogarithmic calculus\"\nand the world of harmonic sums, we propose a local theory, adapted to a full\ncalculus on indices of Harmonic Sums based on the Taylor expansions, around\nzero, of polylogarithms with index x 1 on the rightmost end. This theory is not\nonly compatible with Stuffle products but also with the Analytic Model. In this\nrespect, it provides a stable and fully algorithmic model for Harmonic\ncalculus. Examples by computer are also provided 6 .",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2009.05125\n",
    "authors": [
      "van Chi\u00ean Bui",
      "G\u00e9rard Duchamp",
      "Quoc Ho\u00e0n Ngo",
      "Vincel Hoang Ngoc Minh",
      "Vu Nguyen Dinh"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.13743"
  },
  {
    "id": "arXiv:2110.13744",
    "title": "Robust Multi-view Registration of Point Sets with Laplacian Mixture  Model",
    "abstract": "Point set registration is an essential step in many computer vision\napplications, such as 3D reconstruction and SLAM. Although there exist many\nregistration algorithms for different purposes, however, this topic is still\nchallenging due to the increasing complexity of various real-world scenarios,\nsuch as heavy noise and outlier contamination. In this paper, we propose a\nnovel probabilistic generative method to simultaneously align multiple point\nsets based on the heavy-tailed Laplacian distribution. The proposed method\nassumes each data point is generated by a Laplacian Mixture Model (LMM), where\nits centers are determined by the corresponding points in other point sets.\nDifferent from the previous Gaussian Mixture Model (GMM) based method, which\nminimizes the quadratic distance between points and centers of Gaussian\nprobability density, LMM minimizes the sparsity-induced L1 distance, thereby it\nis more robust against noise and outliers. We adopt Expectation-Maximization\n(EM) framework to solve LMM parameters and rigid transformations. We\napproximate the L1 optimization as a linear programming problem by exponential\nmapping in Lie algebra, which can be effectively solved through the interior\npoint method. To improve efficiency, we also solve the L1 optimization by\nAlternating Direction Multiplier Method (ADMM). We demonstrate the advantages\nof our method by comparing it with representative state-of-the-art approaches\non benchmark challenging data sets, in terms of robustness and accuracy.",
    "descriptor": "",
    "authors": [
      "Jin Zhang",
      "Mingyang Zhao",
      "Xin Jiang",
      "Dong-Ming Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13744"
  },
  {
    "id": "arXiv:2110.13745",
    "title": "PARIS: Personalized Activity Recommendation for Improving Sleep Quality",
    "abstract": "The quality of sleep has a deep impact on people's physical and mental\nhealth. People with insufficient sleep are more likely to report physical and\nmental distress, activity limitation, anxiety, and pain. Moreover, in the past\nfew years, there has been an explosion of applications and devices for activity\nmonitoring and health tracking. Signals collected from these wearable devices\ncan be used to study and improve sleep quality. In this paper, we utilize the\nrelationship between physical activity and sleep quality to find ways of\nassisting people improve their sleep using machine learning techniques. People\nusually have several behavior modes that their bio-functions can be divided\ninto. Performing time series clustering on activity data, we find cluster\ncenters that would correlate to the most evident behavior modes for a specific\nsubject. Activity recipes are then generated for good sleep quality for each\nbehavior mode within each cluster. These activity recipes are supplied to an\nactivity recommendation engine for suggesting a mix of relaxed to intense\nactivities to subjects during their daily routines. The recommendations are\nfurther personalized based on the subjects' lifestyle constraints, i.e. their\nage, gender, body mass index (BMI), resting heart rate, etc, with the objective\nof the recommendation being the improvement of that night's quality of sleep.\nThis would in turn serve a longer-term health objective, like lowering heart\nrate, improving the overall quality of sleep, etc.",
    "descriptor": "\nComments: 18 pages, 7 figures, Submitted to UMUAI: Special Issue on Recommender Systems for Health and Wellbeing, 2020\n",
    "authors": [
      "Meghna Singh",
      "Saksham Goel",
      "Abhiraj Mohan",
      "Louis Kazaglis",
      "Jaideep Srivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.13745"
  },
  {
    "id": "arXiv:2110.13746",
    "title": "H-NeRF: Neural Radiance Fields for Rendering and Temporal Reconstruction  of Humans in Motion",
    "abstract": "We present H-NeRF, neural radiance fields for rendering and temporal (4D)\nreconstruction of a human in motion as captured by a sparse set of cameras or\neven from a monocular video. Our NeRF-inspired approach combines ideas from\nneural scene representation, novel-view synthesis, and implicit statistical\ngeometric human representations. H-NeRF allows to accurately synthesize images\nof the observed subject under novel camera views and human poses. Instead of\nlearning a radiance field in empty space, we attach it to a structured implicit\nhuman body model, represented using signed distance functions. This allows us\nto robustly fuse information from sparse views and, at test time, to\nextrapolate beyond the observed poses or views. Moreover, we apply geometric\nconstraints to co-learn the structure of the observed subject (including both\nbody and clothing) and to regularize the radiance field to geometrical\nplausible solutions. Extensive experiments on multiple datasets demonstrate the\nrobustness and accuracy of our approach and its generalization capabilities\nbeyond the sparse training set of poses and views.",
    "descriptor": "",
    "authors": [
      "Hongyi Xu",
      "Thiemo Alldieck",
      "Cristian Sminchisescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13746"
  },
  {
    "id": "arXiv:2110.13748",
    "title": "Learning to Pre-process Laser Induced Breakdown Spectroscopy Signals  Without Clean Data",
    "abstract": "This work tests whether deep neural networks can clean laser induced\nbreakdown spectroscopy (LIBS) signals by using only uncleaned raw measurements.\nOur view of this problem considers a disentanglement of the effects of the\ntarget of interest from those of the nuisance factors (with non-zero mean) by\nleveraging the vast amounts of redundancies in LIBS data and our proposed\nlearning formulation. This later aims at promoting consistency between repeated\nmeasurement views of a target while simultaneously removing consistencies with\nall other LIBS measurements taken throughout the history of the instrument.\nEvaluations on real data from the ChemCam instrument onboard the Martian\nCuriosity rover show a superior performance in cleaning LIBS signals compared\nto the standard approaches being used by the ChemCam team.",
    "descriptor": "",
    "authors": [
      "Juan Castorena",
      "Diane Oyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.13748"
  },
  {
    "id": "arXiv:2110.13749",
    "title": "Topologically penalized regression on manifolds",
    "abstract": "We study a regression problem on a compact manifold M. In order to take\nadvantage of the underlying geometry and topology of the data, the regression\ntask is performed on the basis of the first several eigenfunctions of the\nLaplace-Beltrami operator of the manifold, that are regularized with\ntopological penalties. The proposed penalties are based on the topology of the\nsub-level sets of either the eigenfunctions or the estimated function. The\noverall approach is shown to yield promising and competitive performance on\nvarious applications to both synthetic and real data sets. We also provide\ntheoretical guarantees on the regression function estimates, on both its\nprediction error and its smoothness (in a topological sense). Taken together,\nthese results support the relevance of our approach in the case where the\ntargeted function is \"topologically smooth\".",
    "descriptor": "",
    "authors": [
      "Olympio Hacquard",
      "Krishnakumar Balasubramanian",
      "Gilles Blanchard",
      "Wolfgang Polonik",
      "Cl\u00e9ment Levrard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.13749"
  },
  {
    "id": "arXiv:2110.13750",
    "title": "Optimizing Information-theoretical Generalization Bounds via Anisotropic  Noise in SGLD",
    "abstract": "Recently, the information-theoretical framework has been proven to be able to\nobtain non-vacuous generalization bounds for large models trained by Stochastic\nGradient Langevin Dynamics (SGLD) with isotropic noise. In this paper, we\noptimize the information-theoretical generalization bound by manipulating the\nnoise structure in SGLD. We prove that with constraint to guarantee low\nempirical risk, the optimal noise covariance is the square root of the expected\ngradient covariance if both the prior and the posterior are jointly optimized.\nThis validates that the optimal noise is quite close to the empirical gradient\ncovariance. Technically, we develop a new information-theoretical bound that\nenables such an optimization analysis. We then apply matrix analysis to derive\nthe form of optimal noise covariance. Presented constraint and results are\nvalidated by the empirical observations.",
    "descriptor": "\nComments: Accepted by Neurips 2021\n",
    "authors": [
      "Bohan Wang",
      "Huishuai Zhang",
      "Jieyu Zhang",
      "Qi Meng",
      "Wei Chen",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.13750"
  },
  {
    "id": "arXiv:2110.13752",
    "title": "Dynamic Trace Estimation",
    "abstract": "We study a dynamic version of the implicit trace estimation problem. Given\naccess to an oracle for computing matrix-vector multiplications with a\ndynamically changing matrix A, our goal is to maintain an accurate\napproximation to A's trace using as few multiplications as possible. We present\na practical algorithm for solving this problem and prove that, in a natural\nsetting, its complexity is quadratically better than the standard solution of\nrepeatedly applying Hutchinson's stochastic trace estimator. We also provide an\nimproved algorithm assuming slightly stronger assumptions on the dynamic matrix\nA. We support our theory with empirical results, showing significant\ncomputational improvements on three applications in machine learning and\nnetwork science: tracking moments of the Hessian spectral density during neural\nnetwork optimization, counting triangles, and estimating natural connectivity\nin a dynamically changing graph.",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Prathamesh Dharangutte",
      "Christopher Musco"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.13752"
  },
  {
    "id": "arXiv:2110.13760",
    "title": "DPCOVID: Privacy-Preserving Federated Covid-19 Detection",
    "abstract": "Coronavirus (COVID-19) has shown an unprecedented global crisis by the\ndetrimental effect on the global economy and health. The number of COVID-19\ncases has been rapidly increasing, and there is no sign of stopping. It leads\nto a severe shortage of test kits and accurate detection models. A recent study\ndemonstrated that the chest X-ray radiography outperformed laboratory testing\nin COVID-19 detection. Therefore, using chest X-ray radiography analysis can\nhelp to screen suspected COVID-19 cases at an early stage. Moreover, the\npatient data is sensitive, and it must be protected to avoid revealing through\nmodel updates and reconstruction from the malicious attacker. In this paper, we\npresent a privacy-preserving Federated Learning system for COVID-19 detection\nbased on chest X-ray images. First, a Federated Learning system is constructed\nfrom chest X-ray images. The main idea is to build a decentralized model across\nmultiple hospitals without sharing data among hospitals. Second, we first show\nthat the accuracy of Federated Learning for COVID-19 identification reduces\nsignificantly for Non-IID data. We then propose a strategy to improve model's\naccuracy on Non-IID COVID-19 data by increasing the total number of clients,\nparallelism (client fraction), and computation per client. Finally, we apply a\nDifferential Privacy Stochastic Gradient Descent (DP-SGD) to enhance the\npreserving of patient data privacy for our Federated Learning model. A strategy\nis also proposed to keep the robustness of Federated Learning to ensure the\nsecurity and accuracy of the model.",
    "descriptor": "\nComments: 7 pages, 8 Figures, 4 Tables\n",
    "authors": [
      "Trang-Thi Ho",
      "Yennun-Huang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.13760"
  },
  {
    "id": "arXiv:2110.13771",
    "title": "AugMax: Adversarial Composition of Random Augmentations for Robust  Training",
    "abstract": "Data augmentation is a simple yet effective way to improve the robustness of\ndeep neural networks (DNNs). Diversity and hardness are two complementary\ndimensions of data augmentation to achieve robustness. For example, AugMix\nexplores random compositions of a diverse set of augmentations to enhance\nbroader coverage, while adversarial training generates adversarially hard\nsamples to spot the weakness. Motivated by this, we propose a data augmentation\nframework, termed AugMax, to unify the two aspects of diversity and hardness.\nAugMax first randomly samples multiple augmentation operators and then learns\nan adversarial mixture of the selected operators. Being a stronger form of data\naugmentation, AugMax leads to a significantly augmented input distribution\nwhich makes model training more challenging. To solve this problem, we further\ndesign a disentangled normalization module, termed DuBIN\n(Dual-Batch-and-Instance Normalization), that disentangles the instance-wise\nfeature heterogeneity arising from AugMax. Experiments show that AugMax-DuBIN\nleads to significantly improved out-of-distribution robustness, outperforming\nprior arts by 3.03%, 3.49%, 1.82% and 0.71% on CIFAR10-C, CIFAR100-C, Tiny\nImageNet-C and ImageNet-C. Codes and pretrained models are available:\nhttps://github.com/VITA-Group/AugMax.",
    "descriptor": "\nComments: NeurIPS, 2021\n",
    "authors": [
      "Haotao Wang",
      "Chaowei Xiao",
      "Jean Kossaifi",
      "Zhiding Yu",
      "Anima Anandkumar",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13771"
  },
  {
    "id": "arXiv:2110.13772",
    "title": "Data-Driven Time Series Reconstruction for Modern Power Systems Research",
    "abstract": "A critical aspect of power systems research is the availability of suitable\ndata, access to which is limited by privacy concerns and the sensitive nature\nof energy infrastructure. This lack of data, in turn, hinders the development\nof modern research avenues such as machine learning approaches or stochastic\nformulations. To overcome this challenge, this paper proposes a systematic,\ndata-driven framework for reconstructing high-fidelity time series, using\npublicly-available grid snapshots and historical data published by transmission\nsystem operators. The proposed approach, from geo-spatial data and generation\ncapacity reconstruction, to time series disaggregation, is applied to the\nFrench transmission grid. Thereby, synthetic but highly realistic time series\ndata, spanning multiple years with a 5-minute granularity, is generated at the\nindividual component level.",
    "descriptor": "",
    "authors": [
      "Minas Chatzos",
      "Mathieu Tanneau",
      "Pascal Van Hentenryck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.13772"
  },
  {
    "id": "arXiv:2110.13774",
    "title": "The Mont Blanc of Twitter: Identifying Hierarchies of Outstanding Peaks  in Social Networks",
    "abstract": "The visualization of social networks is often hindered by their size as such\nnetworks often consist of thousands of vertices and edges. Hence, it is of\nmajor interest to derive compact structures that represent important\nconnections of the original network. In order to do so, we transfer concepts\nfrom the realm of orometry to graphs. These concepts are originally designed to\nidentify outstanding mountain peaks and to provide a small set of key points\nand relationships between them that are representative for the complete\nmountain landscape. With the adoption to social networks, it is possible to\nderive family trees of important vertices and thus to represent key connections\nbetween them. Our approach consist of two steps. We first use a novel method\nfor discarding edges that stand for weak connections. This is done such that\nthe connectivity of the network is preserved. Then, we identify the important\npeaks in the network and the key saddles, i.e., the lower points that connect\nthem. This gives us a compact network that displays which peaks are connected\nthrough which saddles. Additionally, a natural hierarchy on the peaks arises by\nthe question which higher peak comes after the saddle, yielding to chains of\npeaks with increasing heights. This line parent hierarchy provides the means\nfor a completely new navigation paradigm between important vertices. Our\nexperiments on Twitter users and academic collaboration networks show that\nnetworks with hundreds or thousands of edges can be condensed to a small set of\nvertices and key connections.",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Maximilian Stubbemann",
      "Gerd Stumme"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.13774"
  },
  {
    "id": "arXiv:2110.13776",
    "title": "High-Throughput and Energy-Efficient VLSI Architecture for Ordered  Reliability Bits GRAND",
    "abstract": "Ultra-reliable low-latency communication (URLLC), a major 5G New-Radio use\ncase, is the key enabler for applications with strict reliability and latency\nrequirements. These applications necessitate the use of short-length and\nhigh-rate codes. Guessing Random Additive Noise Decoding (GRAND) is a recently\nproposed Maximum Likelihood (ML) decoding technique for these short-length and\nhigh-rate codes. Rather than decoding the received vector, GRAND tries to infer\nthe noise that corrupted the transmitted codeword during transmission through\nthe communication channel. As a result, GRAND can decode any code, structured\nor unstructured. GRAND has hard-input as well as soft-input variants. Among\nthese variants, Ordered Reliability Bits GRAND (ORBGRAND) is a soft-input\nvariant that outperforms hard-input GRAND and is suitable for parallel hardware\nimplementation. This work reports the first hardware architecture for ORBGRAND,\nwhich achieves an average throughput of up to $42.5$ Gbps for a code length of\n$128$ at a target FER of $10^{-7}$. Furthermore, the proposed hardware can be\nused to decode any code as long as the length and rate constraints are met. In\ncomparison to the GRANDAB, a hard-input variant of GRAND, the proposed\narchitecture enhances decoding performance by at least $2$ dB. When compared to\nthe state-of-the-art fast dynamic successive cancellation flip decoder\n(Fast-DSCF) using a 5G polar $(128,105)$ code, the proposed ORBGRAND VLSI\nimplementation has $49\\times$ higher average throughput, $32\\times$ times more\nenergy efficiency, and $5\\times$ more area efficiency while maintaining similar\ndecoding performance.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Very Large Scale Integration Systems (TVLSI). The manuscript is an extension of our previous work \"High-Throughput VLSI Architecture for Soft-Decision Decoding with ORBGRAND\" appeared in 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP-2021)\n",
    "authors": [
      "Syed Mohsin Abbas",
      "Thibaud Tonnellier",
      "Furkan Ercan",
      "Marwan Jalaleddine",
      "Warren J. Gross"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.13776"
  },
  {
    "id": "arXiv:2110.13779",
    "title": "An interface-tracking space-time hybridizable/embedded discontinuous  Galerkin method for nonlinear free-surface flows",
    "abstract": "We present a compatible space-time hybridizable/embedded discontinuous\nGalerkin discretization for nonlinear free-surface waves. We pose this problem\nin a two-fluid (liquid and gas) domain and use a time-dependent level-set\nfunction to identify the sharp interface between the two fluids. The\nincompressible two-fluidd equations are discretized by an exactly mass\nconserving space-time hybridizable discontinuous Galerkin method while the\nlevel-set equation is discretized by a space-time embedded discontinuous\nGalerkin method. Different from alternative discontinuous Galerkin methods is\nthat the embedded discontinuous Galerkin method results in a continuous\napproximation of the interface. This, in combination with the space-time\nframework, results in an interface-tracking method without resorting to\nsmoothing techniques or additional mesh stabilization terms.",
    "descriptor": "",
    "authors": [
      "Giselle Sosa Jones",
      "Sander Rhebergen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.13779"
  },
  {
    "id": "arXiv:2110.13784",
    "title": "Market Design for Drone Traffic Management",
    "abstract": "The rapid development of drone technology is leading to more and more use\ncases being proposed. In response, regulators are drawing up drone traffic\nmanagement frameworks. However, to design solutions that are efficient, fair,\nsimple, non-manipulable, and scalable, we need market design and AI expertise.\nTo this end, we introduce the drone traffic management problem as a new\nresearch challenge to the AI and market design communities. We present five\ndesign desiderata that we have derived from our interviews with stakeholders\nfrom the regulatory side as well as from public and private enterprises.\nFinally, we provide an overview of the solution space to point out possible\ndirections for future research.",
    "descriptor": "\nComments: Preliminary version of a Blue Sky Ideas paper forthcoming at the 36th AAAI Conference on Artificial Intelligence, Vancouver, Canada, 2022\n",
    "authors": [
      "Sven Seuken",
      "Paul Friedrich",
      "Ludwig Dierks"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.13784"
  },
  {
    "id": "arXiv:2110.13786",
    "title": "Diversity and Generalization in Neural Network Ensembles",
    "abstract": "Ensembles are widely used in machine learning and, usually, provide\nstate-of-the-art performance in many prediction tasks. From the very beginning,\nthe diversity of an ensemble has been identified as a key factor for the\nsuperior performance of these models. But the exact role that diversity plays\nin ensemble models is poorly understood, specially in the context of neural\nnetworks. In this work, we combine and expand previously published results in a\ntheoretically sound framework that describes the relationship between diversity\nand ensemble performance for a wide range of ensemble methods. More precisely,\nwe provide sound answers to the following questions: how to measure diversity,\nhow diversity relates to the generalization error of an ensemble, and how\ndiversity is promoted by neural network ensemble algorithms. This analysis\ncovers three widely used loss functions, namely, the squared loss, the\ncross-entropy loss, and the 0-1 loss; and two widely used model combination\nstrategies, namely, model averaging and weighted majority vote. We empirically\nvalidate this theoretical analysis with neural network ensembles.",
    "descriptor": "",
    "authors": [
      "Luis A. Ortega",
      "Rafael Caba\u00f1as",
      "Andr\u00e9s R. Masegosa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.13786"
  },
  {
    "id": "arXiv:2110.13790",
    "title": "A Map of Science in Wikipedia",
    "abstract": "In recent decades, the rapid growth of Internet adoption is offering\nopportunities for convenient and inexpensive access to scientific information.\nWikipedia, one of the largest encyclopedias worldwide, has become a reference\nin this respect, and has attracted widespread attention from scholars. However,\na clear understanding of the scientific sources underpinning Wikipedia's\ncontents remains elusive. In this work, we explore Wikipedia's role in the\npublic understanding of science from the perspective of its scientific sources.\nWe rely on an open dataset of citations from Wikipedia, and use network\nanalysis to map the relationship between Wikipedia articles and scientific\njournal articles. We find that most journal articles cited from Wikipedia\nbelong to STEM fields, in particular biology and medicine ($47.6$\\% of\ncitations; $46.1$\\% of cited articles). Furthermore, Wikipedia's biographies\nplay an important role in connecting STEM fields with the humanities, in\nparticular history. Our results provide valuable insights into the reliance of\nWikipedia on scientific sources, and its role in interconnecting knowledge\nacross different topics.",
    "descriptor": "",
    "authors": [
      "Puyu Yang",
      "Giovanni Colavizza"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.13790"
  },
  {
    "id": "arXiv:2110.13793",
    "title": "Pyramidal Blur Aware X-Corner Chessboard Detector",
    "abstract": "With camera resolution ever increasing and the need to rapidly recalibrate\nrobotic platforms in less than ideal environments, there is a need for faster\nand more robust chessboard fiducial marker detectors. A new chessboard detector\nis proposed that is specifically designed for: high resolution images,\nfocus/motion blur, harsh lighting conditions, and background clutter. This is\naccomplished using a new x-corner detector, where for the first time blur is\nestimated and used in a novel way to enhance corner localization, edge\nvalidation, and connectivity. Performance is measured and compared against\nother libraries using a diverse set of images created by combining multiple\nthird party datasets and including new specially crafted scenarios designed to\nstress the state-of-the-art. The proposed detector has the best F1- Score of\n0.97, runs 1.9x faster than next fastest, and is a top performer for corner\naccuracy, while being the only detector to have consistent good performance in\nall scenarios.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Peter Abeles"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13793"
  },
  {
    "id": "arXiv:2110.13798",
    "title": "Tackling Oversmoothing of GNNs with Contrastive Learning",
    "abstract": "Graph neural networks (GNNs) integrate the comprehensive relation of graph\ndata and the representation learning capability of neural networks, which is\none of the most popular deep learning methods and achieves state-of-the-art\nperformance in many applications, such as natural language processing and\ncomputer vision. In real-world scenarios, increasing the depth (i.e., the\nnumber of layers) of GNNs is sometimes necessary to capture more latent\nknowledge of the input data to mitigate the uncertainty caused by missing\nvalues. However, involving more complex structures and more parameters will\ndecrease the performance of GNN models. One reason called oversmoothing is\nrecently introduced but the relevant research remains nascent. In general,\noversmoothing makes the final representations of nodes indiscriminative, thus\ndeteriorating the node classification and link prediction performance. In this\npaper, we first survey the current de-oversmoothing methods and propose three\nmajor metrics to evaluate a de-oversmoothing method, i.e., constant divergence\nindicator, easy-to-determine divergence indicator, and model-agnostic strategy.\nThen, we propose the Topology-guided Graph Contrastive Layer, named TGCL, which\nis the first de-oversmoothing method maintaining all three mentioned metrics.\nWith the contrastive learning manner, we provide the theoretical analysis of\nthe effectiveness of the proposed TGCL. Last but not least, we design extensive\nexperiments to illustrate the empirical performance of TGCL comparing with\nstate-of-the-art baselines.",
    "descriptor": "",
    "authors": [
      "Lecheng Zheng",
      "Dongqi Fu",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13798"
  },
  {
    "id": "arXiv:2110.13799",
    "title": "Hinge Policy Optimization: Rethinking Policy Improvement and  Reinterpreting PPO",
    "abstract": "Policy optimization is a fundamental principle for designing reinforcement\nlearning algorithms, and one example is the proximal policy optimization\nalgorithm with a clipped surrogate objective (PPO-clip), which has been\npopularly used in deep reinforcement learning due to its simplicity and\neffectiveness. Despite its superior empirical performance, PPO-clip has not\nbeen justified via theoretical proof up to date. This paper proposes to rethink\npolicy optimization and reinterpret the theory of PPO-clip based on hinge\npolicy optimization (HPO), called to improve policy by hinge loss in this\npaper. Specifically, we first identify sufficient conditions of state-wise\npolicy improvement and then rethink policy update as solving a large-margin\nclassification problem with hinge loss. By leveraging various types of\nclassifiers, the proposed design opens up a whole new family of policy-based\nalgorithms, including the PPO-clip as a special case. Based on this construct,\nwe prove that these algorithms asymptotically attain a globally optimal policy.\nTo our knowledge, this is the first ever that can prove global convergence to\nan optimal policy for a variant of PPO-clip. We corroborate the performance of\na variety of HPO algorithms through experiments and an ablation study.",
    "descriptor": "\nComments: 22 pages, 3 figures\n",
    "authors": [
      "Hsuan-Yu Yao",
      "Ping-Chun Hsieh",
      "Kuo-Hao Ho",
      "Kai-Chun Hu",
      "Liang-Chun Ouyang",
      "I-Chen Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13799"
  },
  {
    "id": "arXiv:2110.13801",
    "title": "Endure: A Robust Tuning Paradigm for LSM Trees Under Workload  Uncertainty",
    "abstract": "Log-structured merge-trees (LSM trees) are increasingly used as the storage\nengines behind several data systems, many of which are deployed in the cloud.\nSimilar to other database architectures, LSM trees take into account\ninformation about the expected workloads (e.g., reads vs. writes and point vs.\nrange queries) and optimize their performances by changing tunings. Operating\nin the cloud, however, comes with a degree of uncertainty due to multi-tenancy\nand the fast-evolving nature of modern applications. Databases with static\ntunings discount the variability of such hybrid workloads and hence provide an\ninconsistent and overall suboptimal performance. To address this problem, we\nintroduce ENDURE -- a new paradigm for tuning LSM trees in the presence of\nworkload uncertainty. Specifically, we focus on the impact of the choice of\ncompaction policies, size-ratio, and memory allocation on the overall query\nperformance. ENDURE considers a robust formulation of the throughput\nmaximization problem, and recommends a tuning that maximizes the worst-case\nthroughput over the neighborhood of an expected workload. Additionally, an\nuncertainty tuning parameter controls the size of this neighborhood, thereby\nallowing the output tunings to be conservative or optimistic. We benchmark\nENDURE on a state-of-the-art LSM-based storage engine, RocksDB, and show that\nits tunings comprehensively outperform tunings from classical strategies.\nDrawing upon the results of our extensive analytical and empirical evaluation,\nwe recommend the use of ENDURE for optimizing the performance of LSM tree-based\nstorage engines.",
    "descriptor": "\nComments: 14 pages, 12 figures\n",
    "authors": [
      "Andy Huynh",
      "Harshal Chaudhari",
      "Evimaria Terzi",
      "Manos Athanassoulis"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.13801"
  },
  {
    "id": "arXiv:2110.13802",
    "title": "Linear Approximate Pattern Matching Algorithm",
    "abstract": "Pattern matching is a fundamental process in almost every scientific domain.\nThe problem involves finding the positions of a given pattern (usually of short\nlength) in a reference stream of data (usually of large length). The matching\ncan be as an exact or as an approximate (inexact) matching. Exact matching is\nto search for the pattern without allowing for mismatches (or insertions and\ndeletions) of one or more characters in the pattern), while approximate\nmatching is the opposite. For exact matching, several data structures that can\nbe built in linear time and space are used and in practice nowadays. For\napproximate matching, the solutions proposed to solve this matching are\nnon-linear and currently impractical. In this paper, we designed and\nimplemented a structure that can be built in linear time and space and solve\nthe approximate matching problem in ($O(m + \\frac {log_\\Sigma ^kn}{k!} + occ$)\nsearch costs, where $m$ is the length of the pattern, $n$ is the length of the\nreference, and $k$ is the number of tolerated mismatches (and insertion and\ndeletions).",
    "descriptor": "\nComments: 15 pages double spaced\n",
    "authors": [
      "Anas Al-okaily",
      "Abdelghani Tbakhi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.13802"
  },
  {
    "id": "arXiv:2110.13805",
    "title": "Driving Style Recognition Using Interval Type-2 Fuzzy Inference System  and Multiple Experts Decision Making",
    "abstract": "Driving styles summarize different driving behaviors that reflect in the\nmovements of the vehicles. These behaviors may indicate a tendency to perform\nriskier maneuvers, consume more fuel or energy, break traffic rules, or drive\ncarefully. Therefore, this paper presents a driving style recognition using\nInterval Type-2 Fuzzy Inference System with Multiple Experts Decision-Making\nfor classifying drivers into calm, moderate and aggressive. This system\nreceives as input features longitudinal and lateral kinematic parameters of the\nvehicle motion. The type-2 fuzzy sets are more robust than type-1 fuzzy sets\nwhen handling noisy data, because their membership function are also fuzzy\nsets. In addition, a multiple experts approach can reduce the bias and\nimprecision while building the fuzzy rulebase, which stores the knowledge of\nthe fuzzy system. The proposed approach was evaluated using descriptive\nstatistics analysis, and compared with clustering algorithms and a type-1 fuzzy\ninference system. The results show the tendency to associate lower kinematic\nprofiles for the driving styles classified with the type-2 fuzzy inference\nsystem when compared to other algorithms, which is in line with the more\nconservative approach adopted in the aggregation of the experts' opinions.",
    "descriptor": "\nComments: Submitted to Expert Systems with Applications (ISSN: 0957-4174)\n",
    "authors": [
      "Iago Pach\u00eaco Gomes",
      "Denis Fernando Wolf"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13805"
  },
  {
    "id": "arXiv:2110.13806",
    "title": "Detecting speaking persons in video",
    "abstract": "We present a novel method for detecting speaking persons in video, by\nextracting facial landmarks with a neural network and analysing these landmarks\nstatistically over time",
    "descriptor": "\nComments: Accepted for MMSP 2021\n",
    "authors": [
      "Hannes Fassold"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13806"
  },
  {
    "id": "arXiv:2110.13809",
    "title": "A deep learning based surrogate model for stochastic simulators",
    "abstract": "We propose a deep learning-based surrogate model for stochastic simulators.\nThe basic idea is to use generative neural network to approximate the\nstochastic response. The challenge with such a framework resides in designing\nthe network architecture and selecting loss-function suitable for stochastic\nresponse. While we utilize a simple feed-forward neural network, we propose to\nuse conditional maximum mean discrepancy (CMMD) as the loss-function. CMMD\nexploits the property of reproducing kernel Hilbert space and allows capturing\ndiscrepancy between the between the target and the neural network predicted\ndistributions. The proposed approach is mathematically rigorous, in the sense\nthat it makes no assumptions about the probability density function of the\nresponse. Performance of the proposed approach is illustrated using four\nbenchmark problems selected from the literature. Results obtained indicate the\nexcellent performance of the proposed approach.",
    "descriptor": "",
    "authors": [
      "Akshay Thakur",
      "Souvik Chakraborty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.13809"
  },
  {
    "id": "arXiv:2110.13813",
    "title": "Semantic Segmentation for Urban-Scene Images",
    "abstract": "Urban-scene Image segmentation is an important and trending topic in computer\nvision with wide use cases like autonomous driving [1]. Starting with the\nbreakthrough work of Long et al. [2] that introduces Fully Convolutional\nNetworks (FCNs), the development of novel architectures and practical uses of\nneural networks in semantic segmentation has been expedited in the recent 5\nyears. Aside from seeking solutions in general model design for information\nshrinkage due to pooling, urban-scene image itself has intrinsic features like\npositional patterns [3]. Our project seeks an advanced and integrated solution\nthat specifically targets urban-scene image semantic segmentation among the\nmost novel approaches in the current field. We re-implement the cutting edge\nmodel DeepLabv3+ [4] with ResNet-101 [5] backbone as our strong baseline model.\nBased upon DeepLabv3+, we incorporate HANet [3] to account for the vertical\nspatial priors in urban-scene image tasks. To boost up model efficiency and\nperformance, we further explore the Atrous Spatial Pooling (ASP) layer in\nDeepLabv3+ and infuse a computational efficient variation called \"Waterfall\"\nAtrous Spatial Pooling (WASP) [6] architecture in our model. We find that our\ntwo-step integrated model improves the mean Intersection-Over-Union (mIoU)\nscore gradually from the baseline model. In particular, HANet successfully\nidentifies height-driven patterns and improves per-class IoU of common class\nlabels in urban scenario like fence and bus. We also demonstrate the\nimprovement of model efficiency with help of WASP in terms of computational\ntimes during training and parameter reduction from the original ASPP module.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2003.05128, arXiv:1912.03183 by other authors\n",
    "authors": [
      "Shorya Sharma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13813"
  },
  {
    "id": "arXiv:2110.13817",
    "title": "Real time Simulation of Gird-connected Photovoltaic Multilevel Inverter  using Hybrid GA/PSO Optimization Algorithm",
    "abstract": "This paper presents a new real-time intelligent optimization algorithm to\nminimize the voltage harmonics of a multilevel photovoltaic inverter. Hybrid\nGenetic algorithm /Particle swarm optimization algorithm is employed in a\nreal-time simulation to identify the best fire angels of the multilevel\ninverter to eliminate any destructive effect, such as dc voltage variations and\nchanges in line and dc-link resistors. The dual objective function of harmonic\nminimization and voltage regulation is considered in this real-time simulation.\nThis approach can be applied to any multilevel inverter with various numbers of\nlevels. The validity of the proposed algorithm is proven by real-time\nsimulation of seven and an eleven-level inverter.",
    "descriptor": "",
    "authors": [
      "Hussein Zolfaghari",
      "Dr. Hamidreza Momeni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.13817"
  },
  {
    "id": "arXiv:2110.13819",
    "title": "CloudFindr: A Deep Learning Cloud Artifact Masker for Satellite DEM Data",
    "abstract": "Artifact removal is an integral component of cinematic scientific\nvisualization, and is especially challenging with big datasets in which\nartifacts are difficult to define. In this paper, we describe a method for\ncreating cloud artifact masks which can be used to remove artifacts from\nsatellite imagery using a combination of traditional image processing together\nwith deep learning based on U-Net. Compared to previous methods, our approach\ndoes not require multi-channel spectral imagery but performs successfully on\nsingle-channel Digital Elevation Models (DEMs). DEMs are a representation of\nthe topography of the Earth and have a variety applications including planetary\nscience, geology, flood modeling, and city planning.",
    "descriptor": "",
    "authors": [
      "Kalina Borkiewicz",
      "Viraj Shah",
      "J.P. Naiman",
      "Chuanyue Shen",
      "Stuart Levy",
      "Jeff Carpenter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.13819"
  },
  {
    "id": "arXiv:2110.13825",
    "title": "Synchronous-Clock Range-Angle Relative Acoustic Navigation: A Unified  Approach to Multi-AUV Localization, Command, Control and Coordination",
    "abstract": "This paper presents a scalable acoustic navigation approach for the unified\ncommand, control and coordination of multiple autonomous underwater vehicles\n(AUVs). Existing multi-AUV operations typically achieve coordination manually,\nby programming individual vehicles on the surface via radio communications,\nwhich becomes impractical with large vehicle numbers; or they require\nbi-directional inter-vehicle acoustic communications to achieve limited\ncoordination when submerged, with limited scalability due to the physical\nproperties of the acoustic channel. Our approach utilizes a single,\nperiodically-broadcasting beacon acting as a navigation reference for the group\nof AUVs, each of which carries a chip-scale atomic clock (CSAC) and fixed\nultra-short baseline (USBL) array of acoustic receivers. One-way travel-time\n(OWTT) from synchronized clocks and time-delays between signals received by\neach array element allows any number of vehicles within receive distance to\ndetermine range, angle, and thus determine their relative position to the\nbeacon. The operator can command different vehicle behaviors by selecting\nbetween broadcast signals from a predetermined set, while coordination between\nAUVs is achieved without inter-vehicle communication, by defining individual\nvehicle behaviors within the context of the group. Vehicle behaviors are\ndesigned within a beacon-centric moving frame of reference, allowing the\noperator to control the absolute position of the AUV group by re-positioning\nthe navigation beacon to survey the area of interest. Multiple deployments with\na fleet of three miniature, low-cost SandShark AUVs performing closed-loop\nacoustic navigation in real-time provide experimental results validated against\na secondary long-baseline (LBL) positioning system, demonstrating the\ncapabilities and robustness of our approach with real-world data.",
    "descriptor": "\nComments: 34 pages, 17 figures, to be published in Field Robotics Special Issue on Unmanned Marine Systems\n",
    "authors": [
      "Nicholas R. Rypkema",
      "Henrik Schmidt",
      "Erin M. Fischell"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.13825"
  },
  {
    "id": "arXiv:2110.13827",
    "title": "Learning to Simulate Self-Driven Particles System with Coordinated  Policy Optimization",
    "abstract": "Self-Driven Particles (SDP) describe a category of multi-agent systems common\nin everyday life, such as flocking birds and traffic flows. In a SDP system,\neach agent pursues its own goal and constantly changes its cooperative or\ncompetitive behaviors with its nearby agents. Manually designing the\ncontrollers for such SDP system is time-consuming, while the resulting emergent\nbehaviors are often not realistic nor generalizable. Thus the realistic\nsimulation of SDP systems remains challenging. Reinforcement learning provides\nan appealing alternative for automating the development of the controller for\nSDP. However, previous multi-agent reinforcement learning (MARL) methods define\nthe agents to be teammates or enemies before hand, which fail to capture the\nessence of SDP where the role of each agent varies to be cooperative or\ncompetitive even within one episode. To simulate SDP with MARL, a key challenge\nis to coordinate agents' behaviors while still maximizing individual\nobjectives. Taking traffic simulation as the testing bed, in this work we\ndevelop a novel MARL method called Coordinated Policy Optimization (CoPO),\nwhich incorporates social psychology principle to learn neural controller for\nSDP. Experiments show that the proposed method can achieve superior performance\ncompared to MARL baselines in various metrics. Noticeably the trained vehicles\nexhibit complex and diverse social behaviors that improve performance and\nsafety of the population as a whole. Demo video and source code are available\nat: https://decisionforce.github.io/CoPO/",
    "descriptor": "\nComments: Accepted to NeurIPS 2021. Code and video can be found at: this https URL\n",
    "authors": [
      "Zhenghao Peng",
      "Quanyi Li",
      "Ka Ming Hui",
      "Chunxiao Liu",
      "Bolei Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13827"
  },
  {
    "id": "arXiv:2110.13840",
    "title": "A Scalable Architecture for Electronic Payments",
    "abstract": "We present a scalable architecture for electronic payments via central bank\ndigital currency and offer a solution to the perceived conflict between robust\nregulatory oversight and consumer affordances such as privacy and control. Our\narchitecture combines existing work in payment systems and digital currency\nwith a new approach to digital asset design for managing unforgeable, stateful,\nand oblivious assets without relying on either a central authority or a\nmonolithic consensus system. Regulated financial institutions have a role in\nevery transaction, and the consumer affordances are achieved through the use of\nnon-custodial wallets that unlink the sender from the recipient in the\ntransaction channel. This approach is fully compatible with the existing\ntwo-tiered banking system and can complement and extend the roles of existing\nmoney services businesses and asset custodians.",
    "descriptor": "\nComments: 19 pages, 4 figures, 2 tables\n",
    "authors": [
      "Geoff Goodell",
      "D. R. Toliver",
      "Hazem Danny Nakib"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.13840"
  },
  {
    "id": "arXiv:2110.13846",
    "title": "A Light-weight Interpretable CompositionalNetwork for Nuclei Detection  and Weakly-supervised Segmentation",
    "abstract": "The field of computational pathology has witnessed great advancements since\ndeep neural networks have been widely applied. These deep neural networks\nusually require large numbers of annotated data to train vast parameters.\nHowever, it takes significant effort to annotate a large histopathology\ndataset. We propose to build a data-efficient model, which only requires\npartial annotation, specifically on isolated nucleus, rather than on the whole\nslide image. It exploits shallow features as its backbone and is light-weight,\ntherefore a small number of data is sufficient for training. What's more, it is\na generative compositional model, which enjoys interpretability in its\nprediction. The proposed method could be an alternative solution for the\ndata-hungry problem of deep learning methods.",
    "descriptor": "",
    "authors": [
      "Yixiao Zhang",
      "Adam Kortylewski",
      "Qing Liu",
      "Seyoun Park",
      "Benjamin Green",
      "Elizabeth Engle",
      "Guillermo Almodovar",
      "Ryan Walk",
      "Sigfredo Soto-Diaz",
      "Janis Taube",
      "Alex Szalay",
      "Alan Yuille"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13846"
  },
  {
    "id": "arXiv:2110.13854",
    "title": "Learning Optimal Decision Trees Using MaxSAT",
    "abstract": "We present a Combinatorial Optimization approach based on Maximum\nSatisfiability technology to compute Minimum Pure Decision Trees (MPDTs) for\nthe sake of interpretability. We show that our approach outperforms clearly in\nterms of runtime previous approaches to compute MPDTs. We additionally show\nthat these MPDTs can outperform on average the DT classifiers generated with\nsklearn in terms of accuracy. Therefore, our approach tackles favourably the\nchallenge of balancing interpretability and accuracy.",
    "descriptor": "",
    "authors": [
      "Josep Alos",
      "Carlos Ansotegui",
      "Eduard Torres"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13854"
  },
  {
    "id": "arXiv:2110.13855",
    "title": "Average-Reward Learning and Planning with Options",
    "abstract": "We extend the options framework for temporal abstraction in reinforcement\nlearning from discounted Markov decision processes (MDPs) to average-reward\nMDPs. Our contributions include general convergent off-policy inter-option\nlearning algorithms, intra-option algorithms for learning values and models, as\nwell as sample-based planning variants of our learning algorithms. Our\nalgorithms and convergence proofs extend those recently developed by Wan, Naik,\nand Sutton. We also extend the notion of option-interrupting behavior from the\ndiscounted to the average-reward formulation. We show the efficacy of the\nproposed algorithms with experiments on a continuing version of the Four-Room\ndomain.",
    "descriptor": "",
    "authors": [
      "Yi Wan",
      "Abhishek Naik",
      "Richard S. Sutton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13855"
  },
  {
    "id": "arXiv:2110.13859",
    "title": "Defensive Tensorization",
    "abstract": "We propose defensive tensorization, an adversarial defence technique that\nleverages a latent high-order factorization of the network. The layers of a\nnetwork are first expressed as factorized tensor layers. Tensor dropout is then\napplied in the latent subspace, therefore resulting in dense reconstructed\nweights, without the sparsity or perturbations typically induced by the\nrandomization.Our approach can be readily integrated with any arbitrary neural\narchitecture and combined with techniques like adversarial training. We\nempirically demonstrate the effectiveness of our approach on standard image\nclassification benchmarks. We validate the versatility of our approach across\ndomains and low-precision architectures by considering an audio classification\ntask and binary networks. In all cases, we demonstrate improved performance\ncompared to prior works.",
    "descriptor": "\nComments: To be presented at BMVC 2021\n",
    "authors": [
      "Adrian Bulat",
      "Jean Kossaifi",
      "Sourav Bhattacharya",
      "Yannis Panagakis",
      "Timothy Hospedales",
      "Georgios Tzimiropoulos",
      "Nicholas D Lane",
      "Maja Pantic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13859"
  },
  {
    "id": "arXiv:2110.13864",
    "title": "FL-WBC: Enhancing Robustness against Model Poisoning Attacks in  Federated Learning from a Client Perspective",
    "abstract": "Federated learning (FL) is a popular distributed learning framework that\ntrains a global model through iterative communications between a central server\nand edge devices. Recent works have demonstrated that FL is vulnerable to model\npoisoning attacks. Several server-based defense approaches (e.g. robust\naggregation), have been proposed to mitigate such attacks. However, we\nempirically show that under extremely strong attacks, these defensive methods\nfail to guarantee the robustness of FL. More importantly, we observe that as\nlong as the global model is polluted, the impact of attacks on the global model\nwill remain in subsequent rounds even if there are no subsequent attacks. In\nthis work, we propose a client-based defense, named White Blood Cell for\nFederated Learning (FL-WBC), which can mitigate model poisoning attacks that\nhave already polluted the global model. The key idea of FL-WBC is to identify\nthe parameter space where long-lasting attack effect on parameters resides and\nperturb that space during local training. Furthermore, we derive a certified\nrobustness guarantee against model poisoning attacks and a convergence\nguarantee to FedAvg after applying our FL-WBC. We conduct experiments on\nFasionMNIST and CIFAR10 to evaluate the defense against state-of-the-art model\npoisoning attacks. The results demonstrate that our method can effectively\nmitigate model poisoning attack impact on the global model within 5\ncommunication rounds with nearly no accuracy drop under both IID and Non-IID\nsettings. Our defense is also complementary to existing server-based robust\naggregation approaches and can further improve the robustness of FL under\nextremely strong attacks.",
    "descriptor": "\nComments: To be appeared in NeurIPS 2021 conference\n",
    "authors": [
      "Jingwei Sun",
      "Ang Li",
      "Louis DiValentin",
      "Amin Hassanzadeh",
      "Yiran Chen",
      "Hai Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.13864"
  },
  {
    "id": "arXiv:2110.13871",
    "title": "LayerZero: Trustless Omnichain Interoperability Protocol",
    "abstract": "The proliferation of blockchains has given developers a variety of platforms\non which to run their smart contracts based on application features and\nrequirements for throughput, security, and cost. However, a consequence of this\nfreedom is severe fragmentation; Each chain is isolated, forcing users to silo\ntheir liquidity and limiting options to move liquidity and state between walled\necosystems. This paper presents LayerZero, the first trustless omnichain\ninteroperability protocol, which provides a powerful, low level communication\nprimitive upon which a diverse set of cross-chain applications can be built.\nUsing this new primitive, developers can implement seamless inter-chain\napplications like a cross-chain DEX or multi-chain yield aggregator without\nhaving to rely on a trusted custodian or intermediate transactions. Simply put,\nLayerZero is the first system to trustlessly enable direct transactions across\nall chains. Allowing transactions to flow freely between chains provides\nopportunities for users to consolidate fragmented pockets of liquidity while\nalso making full use of applications on separate chains. With LayerZero, we\nprovide the network fabric underlying the fully-connected omnichain ecosystem\nof the future.",
    "descriptor": "\nComments: 10 Pages, 5 figures\n",
    "authors": [
      "Ryan Zarick",
      "Bryan Pellegrino",
      "Caleb Banister"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.13871"
  },
  {
    "id": "arXiv:2110.13876",
    "title": "Breaking the Moments Condition Barrier: No-Regret Algorithm for Bandits  with Super Heavy-Tailed Payoffs",
    "abstract": "Despite a large amount of effort in dealing with heavy-tailed error in\nmachine learning, little is known when moments of the error can become\nnon-existential: the random noise $\\eta$ satisfies Pr$\\left[|\\eta| > |y|\\right]\n\\le 1/|y|^{\\alpha}$ for some $\\alpha > 0$. We make the first attempt to\nactively handle such super heavy-tailed noise in bandit learning problems: We\npropose a novel robust statistical estimator, mean of medians, which estimates\na random variable by computing the empirical mean of a sequence of empirical\nmedians. We then present a generic reductionist algorithmic framework for\nsolving bandit learning problems (including multi-armed and linear bandit\nproblem): the mean of medians estimator can be applied to nearly any bandit\nlearning algorithm as a black-box filtering for its reward signals and obtain\nsimilar regret bound as if the reward is sub-Gaussian. We show that the regret\nbound is near-optimal even with very heavy-tailed noise. We also empirically\ndemonstrate the effectiveness of the proposed algorithm, which further\ncorroborates our theoretical results.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Han Zhong",
      "Jiayi Huang",
      "Lin F. Yang",
      "Liwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13876"
  },
  {
    "id": "arXiv:2110.13877",
    "title": "Assessing Evaluation Metrics for Speech-to-Speech Translation",
    "abstract": "Speech-to-speech translation combines machine translation with speech\nsynthesis, introducing evaluation challenges not present in either task alone.\nHow to automatically evaluate speech-to-speech translation is an open question\nwhich has not previously been explored. Translating to speech rather than to\ntext is often motivated by unwritten languages or languages without\nstandardized orthographies. However, we show that the previously used automatic\nmetric for this task is best equipped for standardized high-resource languages\nonly. In this work, we first evaluate current metrics for speech-to-speech\ntranslation, and second assess how translation to dialectal variants rather\nthan to standardized languages impacts various evaluation methods.",
    "descriptor": "\nComments: ASRU 2021\n",
    "authors": [
      "Elizabeth Salesky",
      "Julian M\u00e4der",
      "Severin Klinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.13877"
  },
  {
    "id": "arXiv:2110.13878",
    "title": "Deep Explicit Duration Switching Models for Time Series",
    "abstract": "Many complex time series can be effectively subdivided into distinct regimes\nthat exhibit persistent dynamics. Discovering the switching behavior and the\nstatistical patterns in these regimes is important for understanding the\nunderlying dynamical system. We propose the Recurrent Explicit Duration\nSwitching Dynamical System (RED-SDS), a flexible model that is capable of\nidentifying both state- and time-dependent switching dynamics. State-dependent\nswitching is enabled by a recurrent state-to-switch connection and an explicit\nduration count variable is used to improve the time-dependent switching\nbehavior. We demonstrate how to perform efficient inference using a hybrid\nalgorithm that approximates the posterior of the continuous states via an\ninference network and performs exact inference for the discrete switches and\ncounts. The model is trained by maximizing a Monte Carlo lower bound of the\nmarginal log-likelihood that can be computed efficiently as a byproduct of the\ninference routine. Empirical results on multiple datasets demonstrate that\nRED-SDS achieves considerable improvement in time series segmentation and\ncompetitive forecasting performance against the state of the art.",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Abdul Fatir Ansari",
      "Konstantinos Benidis",
      "Richard Kurle",
      "Ali Caner Turkmen",
      "Harold Soh",
      "Alexander J. Smola",
      "Yuyang Wang",
      "Tim Januschowski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13878"
  },
  {
    "id": "arXiv:2110.13880",
    "title": "Understanding Interlocking Dynamics of Cooperative Rationalization",
    "abstract": "Selective rationalization explains the prediction of complex neural networks\nby finding a small subset of the input that is sufficient to predict the neural\nmodel output. The selection mechanism is commonly integrated into the model\nitself by specifying a two-component cascaded system consisting of a rationale\ngenerator, which makes a binary selection of the input features (which is the\nrationale), and a predictor, which predicts the output based only on the\nselected features. The components are trained jointly to optimize prediction\nperformance. In this paper, we reveal a major problem with such cooperative\nrationalization paradigm -- model interlocking. Interlocking arises when the\npredictor overfits to the features selected by the generator thus reinforcing\nthe generator's selection even if the selected rationales are sub-optimal. The\nfundamental cause of the interlocking problem is that the rationalization\nobjective to be minimized is concave with respect to the generator's selection\npolicy. We propose a new rationalization framework, called A2R, which\nintroduces a third component into the architecture, a predictor driven by soft\nattention as opposed to selection. The generator now realizes both soft and\nhard attention over the features and these are fed into the two different\npredictors. While the generator still seeks to support the original predictor\nperformance, it also minimizes a gap between the two predictors. As we will\nshow theoretically, since the attention-based predictor exhibits a better\nconvexity property, A2R can overcome the concavity barrier. Our experiments on\ntwo synthetic benchmarks and two real datasets demonstrate that A2R can\nsignificantly alleviate the interlock problem and find explanations that better\nalign with human judgments. We release our code at\nhttps://github.com/Gorov/Understanding_Interlocking.",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Mo Yu",
      "Yang Zhang",
      "Shiyu Chang",
      "Tommi S. Jaakkola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.13880"
  },
  {
    "id": "arXiv:2110.13883",
    "title": "Estimating Mutual Information via Geodesic $k$NN",
    "abstract": "Estimating mutual information (MI) between two continuous random variables\n$X$ and $Y$ allows to capture non-linear dependencies between them,\nnon-parametrically. As such, MI estimation lies at the core of many data\nscience applications. Yet, robustly estimating MI for high-dimensional $X$ and\n$Y$ is still an open research question.\nIn this paper, we formulate this problem through the lens of manifold\nlearning. That is, we leverage the common assumption that the information of\n$X$ and $Y$ is captured by a low-dimensional manifold embedded in the observed\nhigh-dimensional space and transfer it to MI estimation. As an extension to\nstate-of-the-art $k$NN estimators, we propose to determine the $k$-nearest\nneighbours via geodesic distances on this manifold rather than form the ambient\nspace, which allows us to estimate MI even in the high-dimensional setting. An\nempirical evaluation of our method, G-KSG, against the state-of-the-art shows\nthat it yields good estimations of the MI in classical benchmark, and manifold\ntasks, even for high dimensional datasets, which none of the existing methods\ncan provide.",
    "descriptor": "",
    "authors": [
      "Alexander Marx",
      "Jonas Fischer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.13883"
  },
  {
    "id": "arXiv:2110.13884",
    "title": "Overcoming Pedestrian Blockage in mm-Wave Bands using Ground Reflections",
    "abstract": "mm-Wave communication employs directional beams to overcome high path loss.\nHigh data rate communication is typically along line-of-sight (LoS). In outdoor\nenvironments, such communication is susceptible to temporary blockage by\npedestrians interposed between the transmitter and receiver. It results in\noutages in which the user is lost, and has to be reacquired as a new user,\nseverely disrupting interactive and high throughput applications. It has been\npresumed that the solution is to have a densely deployed set of base stations\nthat will allow the mobile to perform a handover to a different non-blocked\nbase station every time a current base station is blocked. This is however a\nvery costly solution for outdoor environments. Through extensive experiments we\nshow that it is possible to exploit a strong ground reflection with a received\nsignal strength (RSS) about 4dB less than the LoS path in outdoor built\nenvironments with concrete or gravel surfaces, for beams that are narrow in\nazimuth but wide in zenith. While such reflected paths cannot support the high\ndata rates of LoS paths, they can support control channel communication, and,\nimportantly, sustain time synchronization between the mobile and the base\nstation. This allows a mobile to quickly recover to the LoS path upon the\ncessation of the temporary blockage, which typically lasts a few hundred\nmilliseconds. We present a simple in-band protocol that quickly discovers\nground reflected radiation and uses it to recover the LoS link when the\ntemporary blockage disappears.",
    "descriptor": "",
    "authors": [
      "Santosh Ganji",
      "Romil Sonigra",
      "P. R. Kumar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.13884"
  },
  {
    "id": "arXiv:2110.13889",
    "title": "Heterogeneous Temporal Graph Neural Network",
    "abstract": "Graph neural networks (GNNs) have been broadly studied on dynamic graphs for\ntheir representation learning, majority of which focus on graphs with\nhomogeneous structures in the spatial domain. However, many real-world graphs -\ni.e., heterogeneous temporal graphs (HTGs) - evolve dynamically in the context\nof heterogeneous graph structures. The dynamics associated with heterogeneity\nhave posed new challenges for HTG representation learning. To solve this\nproblem, in this paper, we propose heterogeneous temporal graph neural network\n(HTGNN) to integrate both spatial and temporal dependencies while preserving\nthe heterogeneity to learn node representations over HTGs. Specifically, in\neach layer of HTGNN, we propose a hierarchical aggregation mechanism, including\nintra-relation, inter-relation, and across-time aggregations, to jointly model\nheterogeneous spatial dependencies and temporal dimensions. To retain the\nheterogeneity, intra-relation aggregation is first performed over each slice of\nHTG to attentively aggregate information of neighbors with the same type of\nrelation, and then intra-relation aggregation is exploited to gather\ninformation over different types of relations; to handle temporal dependencies,\nacross-time aggregation is conducted to exchange information across different\ngraph slices over the HTG. The proposed HTGNN is a holistic framework tailored\nheterogeneity with evolution in time and space for HTG representation learning.\nExtensive experiments are conducted on the HTGs built from different real-world\ndatasets and promising results demonstrate the outstanding performance of HTGNN\nby comparison with state-of-the-art baselines. Our built HTGs and code have\nbeen made publicly accessible at: https://github.com/YesLab-Code/HTGNN.",
    "descriptor": "",
    "authors": [
      "Yujie Fan",
      "Mingxuan Ju",
      "Chuxu Zhang",
      "Liang Zhao",
      "Yanfang Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.13889"
  },
  {
    "id": "arXiv:2110.13892",
    "title": "HR-RCNN: Hierarchical Relational Reasoning for Object Detection",
    "abstract": "Incorporating relational reasoning in neural networks for object recognition\nremains an open problem. Although many attempts have been made for relational\nreasoning, they generally only consider a single type of relationship. For\nexample, pixel relations through self-attention (e.g., non-local networks),\nscale relations through feature fusion (e.g., feature pyramid networks), or\nobject relations through graph convolutions (e.g., reasoning-RCNN). Little\nattention has been given to more generalized frameworks that can reason across\nthese relationships. In this paper, we propose a hierarchical relational\nreasoning framework (HR-RCNN) for object detection, which utilizes a novel\ngraph attention module (GAM). This GAM is a concise module that enables\nreasoning across heterogeneous nodes by operating on the graph edges directly.\nLeveraging heterogeneous relationships, our HR-RCNN shows great improvement on\nCOCO dataset, for both object detection and instance segmentation.",
    "descriptor": "\nComments: To appear at BMVC 2021\n",
    "authors": [
      "Hao Chen",
      "Abhinav Shrivastava"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13892"
  },
  {
    "id": "arXiv:2110.13900",
    "title": "WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech  Processing",
    "abstract": "Self-supervised learning (SSL) achieves great success in speech recognition,\nwhile limited exploration has been attempted for other speech processing tasks.\nAs speech signal contains multi-faceted information including speaker identity,\nparalinguistics, spoken content, etc., learning universal representations for\nall speech tasks is challenging. In this paper, we propose a new pre-trained\nmodel, WavLM, to solve full-stack downstream speech tasks. WavLM is built based\non the HuBERT framework, with an emphasis on both spoken content modeling and\nspeaker identity preservation. We first equip the Transformer structure with\ngated relative position bias to improve its capability on recognition tasks.\nFor better speaker discrimination, we propose an utterance mixing training\nstrategy, where additional overlapped utterances are created unsupervisely and\nincorporated during model training. Lastly, we scale up the training dataset\nfrom 60k hours to 94k hours of public audio data, and optimize its training\nprocedure for better representation extraction. WavLM Large achieves\nstate-of-the-art performance on the SUPERB benchmark, and brings significant\nimprovements for various speech processing tasks on their representative\nbenchmarks.",
    "descriptor": "",
    "authors": [
      "Sanyuan Chen",
      "Chengyi Wang",
      "Zhengyang Chen",
      "Yu Wu",
      "Shujie Liu",
      "Zhuo Chen",
      "Jinyu Li",
      "Naoyuki Kanda",
      "Takuya Yoshioka",
      "Xiong Xiao",
      "Jian Wu",
      "Long Zhou",
      "Shuo Ren",
      "Yanmin Qian",
      "Yao Qian",
      "Jian Wu",
      "Micheal Zeng",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.13900"
  },
  {
    "id": "arXiv:2110.13903",
    "title": "NeRV: Neural Representations for Videos",
    "abstract": "We propose a novel neural representation for videos (NeRV) which encodes\nvideos in neural networks. Unlike conventional representations that treat\nvideos as frame sequences, we represent videos as neural networks taking frame\nindex as input. Given a frame index, NeRV outputs the corresponding RGB image.\nVideo encoding in NeRV is simply fitting a neural network to video frames and\ndecoding process is a simple feedforward operation. As an image-wise implicit\nrepresentation, NeRV output the whole image and shows great efficiency compared\nto pixel-wise implicit representation, improving the encoding speed by 25x to\n70x, the decoding speed by 38x to 132x, while achieving better video quality.\nWith such a representation, we can treat videos as neural networks, simplifying\nseveral video-related tasks. For example, conventional video compression\nmethods are restricted by a long and complex pipeline, specifically designed\nfor the task. In contrast, with NeRV, we can use any neural network compression\nmethod as a proxy for video compression, and achieve comparable performance to\ntraditional frame-based video compression approaches (H.264, HEVC \\etc).\nBesides compression, we demonstrate the generalization of NeRV for video\ndenoising. The source code and pre-trained model can be found at\nhttps://github.com/haochen-rye/NeRV.git.",
    "descriptor": "\nComments: To appear at NeurIPS 2021\n",
    "authors": [
      "Hao Chen",
      "Bo He",
      "Hanyu Wang",
      "Yixuan Ren",
      "Ser-Nam Lim",
      "Abhinav Shrivastava"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.13903"
  },
  {
    "id": "arXiv:2110.13905",
    "title": "Gradient Descent on Two-layer Nets: Margin Maximization and Simplicity  Bias",
    "abstract": "The generalization mystery of overparametrized deep nets has motivated\nefforts to understand how gradient descent (GD) converges to low-loss solutions\nthat generalize well. Real-life neural networks are initialized from small\nrandom values and trained with cross-entropy loss for classification (unlike\nthe \"lazy\" or \"NTK\" regime of training where analysis was more successful), and\na recent sequence of results (Lyu and Li, 2020; Chizat and Bach, 2020; Ji and\nTelgarsky, 2020) provide theoretical evidence that GD may converge to the\n\"max-margin\" solution with zero loss, which presumably generalizes well.\nHowever, the global optimality of margin is proved only in some settings where\nneural nets are infinitely or exponentially wide. The current paper is able to\nestablish this global optimality for two-layer Leaky ReLU nets trained with\ngradient flow on linearly separable and symmetric data, regardless of the\nwidth. The analysis also gives some theoretical justification for recent\nempirical findings (Kalimeris et al., 2019) on the so-called simplicity bias of\nGD towards linear or other \"simple\" classes of solutions, especially early in\ntraining. On the pessimistic side, the paper suggests that such results are\nfragile. A simple data manipulation can make gradient flow converge to a linear\nclassifier with suboptimal margin.",
    "descriptor": "\nComments: 65 pages; Published in NeurIPS 2021\n",
    "authors": [
      "Kaifeng Lyu",
      "Zhiyuan Li",
      "Runzhe Wang",
      "Sanjeev Arora"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13905"
  },
  {
    "id": "arXiv:2010.08262",
    "title": "Local plasticity rules can learn deep representations using  self-supervised contrastive predictions",
    "abstract": "Learning in the brain is poorly understood and learning rules that respect\nbiological constraints, yet yield deep hierarchical representations, are still\nunknown. Here, we propose a learning rule that takes inspiration from\nneuroscience and recent advances in self-supervised deep learning. Learning\nminimizes a simple layer-specific loss function and does not need to\nback-propagate error signals within or between layers. Instead, weight updates\nfollow a local, Hebbian, learning rule that only depends on pre- and\npost-synaptic neuronal activity, predictive dendritic input and widely\nbroadcasted modulation factors which are identical for large groups of neurons.\nThe learning rule applies contrastive predictive learning to a causal,\nbiological setting using saccades (i.e. rapid shifts in gaze direction). We\nfind that networks trained with this self-supervised and local rule build deep\nhierarchical representations of images, speech and video.",
    "descriptor": "",
    "authors": [
      "Bernd Illing",
      "Jean Ventura",
      "Guillaume Bellec",
      "Wulfram Gerstner"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.08262"
  },
  {
    "id": "arXiv:2110.13142",
    "title": "Light-Field Microscopy for optical imaging of neuronal activity: when  model-based methods meet data-driven approaches",
    "abstract": "Understanding how networks of neurons process information is one of the key\nchallenges in modern neuroscience. A necessary step to achieve this goal is to\nbe able to observe the dynamics of large populations of neurons over a large\narea of the brain. Light-field microscopy (LFM), a type of scanless microscope,\nis a particularly attractive candidate for high-speed three-dimensional (3D)\nimaging. It captures volumetric information in a single snapshot, allowing\nvolumetric imaging at video frame-rates. Specific features of imaging neuronal\nactivity using LFM call for the development of novel machine learning\napproaches that fully exploit priors embedded in physics and optics models.\nSignal processing theory and wave-optics theory could play a key role in\nfilling this gap, and contribute to novel computational methods with enhanced\ninterpretability and generalization by integrating model-driven and data-driven\napproaches. This paper is devoted to a comprehensive survey to state-of-the-art\nof computational methods for LFM, with a focus on model-based and data-driven\napproaches.",
    "descriptor": "\nComments: 20 pages, 9 figures, article accepted by IEEE Signal Processing Magazine\n",
    "authors": [
      "Pingfan Song",
      "Herman Verinaz Jadan",
      "Carmel L. Howe",
      "Amanda J. Foust",
      "Pier Luigi Dragotti"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2110.13142"
  },
  {
    "id": "arXiv:2110.13144",
    "title": "Faster Perturbed Stochastic Gradient Methods for Finding Local Minima",
    "abstract": "Escaping from saddle points and finding local minima is a central problem in\nnonconvex optimization. Perturbed gradient methods are perhaps the simplest\napproach for this problem. However, to find $(\\epsilon,\n\\sqrt{\\epsilon})$-approximate local minima, the existing best stochastic\ngradient complexity for this type of algorithms is $\\tilde O(\\epsilon^{-3.5})$,\nwhich is not optimal. In this paper, we propose \\texttt{Pullback}, a faster\nperturbed stochastic gradient framework for finding local minima. We show that\nPullback with stochastic gradient estimators such as SARAH/SPIDER and STORM can\nfind $(\\epsilon, \\epsilon_{H})$-approximate local minima within $\\tilde\nO(\\epsilon^{-3} + \\epsilon_{H}^{-6})$ stochastic gradient evaluations (or\n$\\tilde O(\\epsilon^{-3})$ when $\\epsilon_H = \\sqrt{\\epsilon}$). The core idea\nof our framework is a step-size ``pullback'' scheme to control the average\nmovement of the iterates, which leads to faster convergence to the local\nminima. Experiments on matrix factorization problems corroborate our theory.",
    "descriptor": "\nComments: 28 pages, 1 figure, 1 table\n",
    "authors": [
      "Zixiang Chen",
      "Dongruo Zhou",
      "Quanquan Gu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.13144"
  },
  {
    "id": "arXiv:2110.13151",
    "title": "Self-supervised similarity search for large scientific datasets",
    "abstract": "We present the use of self-supervised learning to explore and exploit large\nunlabeled datasets. Focusing on 42 million galaxy images from the latest data\nrelease of the Dark Energy Spectroscopic Instrument (DESI) Legacy Imaging\nSurveys, we first train a self-supervised model to distil low-dimensional\nrepresentations that are robust to symmetries, uncertainties, and noise in each\nimage. We then use the representations to construct and publicly release an\ninteractive semantic similarity search tool. We demonstrate how our tool can be\nused to rapidly discover rare objects given only a single example, increase the\nspeed of crowd-sourcing campaigns, and construct and improve training sets for\nsupervised applications. While we focus on images from sky surveys, the\ntechnique is straightforward to apply to any scientific dataset of any\ndimensionality. The similarity search web app can be found at\nhttps://github.com/georgestein/galaxy_search",
    "descriptor": "\nComments: 5 pages, 2 figures. The similarity search web app can be found at this https URL arXiv admin note: text overlap with arXiv:2110.00023\n",
    "authors": [
      "George Stein",
      "Peter Harrington",
      "Jacqueline Blaum",
      "Tomislav Medan",
      "Zarija Lukic"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13151"
  },
  {
    "id": "arXiv:2110.13162",
    "title": "Quantum machine learning beyond kernel methods",
    "abstract": "With noisy intermediate-scale quantum computers showing great promise for\nnear-term applications, a number of machine learning algorithms based on\nparametrized quantum circuits have been suggested as possible means to achieve\nlearning advantages. Yet, our understanding of how these quantum machine\nlearning models compare, both to existing classical models and to each other,\nremains limited. A big step in this direction has been made by relating them to\nso-called kernel methods from classical machine learning. By building on this\nconnection, previous works have shown that a systematic reformulation of many\nquantum machine learning models as kernel models was guaranteed to improve\ntheir training performance. In this work, we first extend the applicability of\nthis result to a more general family of parametrized quantum circuit models\ncalled data re-uploading circuits. Secondly, we show, through simple\nconstructions and numerical simulations, that models defined and trained\nvariationally can exhibit a critically better generalization performance than\ntheir kernel formulations, which is the true figure of merit of machine\nlearning tasks. Our results constitute another step towards a more\ncomprehensive theory of quantum machine learning models next to kernel\nformulations.",
    "descriptor": "\nComments: 13 pages, 12 figures\n",
    "authors": [
      "Sofiene Jerbi",
      "Lukas J. Fiderer",
      "Hendrik Poulsen Nautrup",
      "Jonas M. K\u00fcbler",
      "Hans J. Briegel",
      "Vedran Dunjko"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.13162"
  },
  {
    "id": "arXiv:2110.13217",
    "title": "RBSRICNN: Raw Burst Super-Resolution through Iterative Convolutional  Neural Network",
    "abstract": "Modern digital cameras and smartphones mostly rely on image signal processing\n(ISP) pipelines to produce realistic colored RGB images. However, compared to\nDSLR cameras, low-quality images are usually obtained in many portable mobile\ndevices with compact camera sensors due to their physical limitations. The\nlow-quality images have multiple degradations i.e., sub-pixel shift due to\ncamera motion, mosaick patterns due to camera color filter array,\nlow-resolution due to smaller camera sensors, and the rest information are\ncorrupted by the noise. Such degradations limit the performance of current\nSingle Image Super-resolution (SISR) methods in recovering high-resolution (HR)\nimage details from a single low-resolution (LR) image. In this work, we propose\na Raw Burst Super-Resolution Iterative Convolutional Neural Network (RBSRICNN)\nthat follows the burst photography pipeline as a whole by a forward (physical)\nmodel. The proposed Burst SR scheme solves the problem with classical image\nregularization, convex optimization, and deep learning techniques, compared to\nexisting black-box data-driven methods. The proposed network produces the final\noutput by an iterative refinement of the intermediate SR estimates. We\ndemonstrate the effectiveness of our proposed approach in quantitative and\nqualitative experiments that generalize robustly to real LR burst inputs with\nonl synthetic burst data available for training.",
    "descriptor": "\nComments: Machine Learning and the Physical Sciences workshop at the 35th Conference on Neural Information Processing Systems (NeurIPS), 2021\n",
    "authors": [
      "Rao Muhammad Umer",
      "Christian Micheloni"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13217"
  },
  {
    "id": "arXiv:2110.13240",
    "title": "Integrative Clustering of Multi-View Data by Nonnegative Matrix  Factorization",
    "abstract": "Learning multi-view data is an emerging problem in machine learning research,\nand nonnegative matrix factorization (NMF) is a popular\ndimensionality-reduction method for integrating information from multiple\nviews. These views often provide not only consensus but also diverse\ninformation. However, most multi-view NMF algorithms assign equal weight to\neach view or tune the weight via line search empirically, which can be\ncomputationally expensive or infeasible without any prior knowledge of the\nviews. In this paper, we propose a weighted multi-view NMF (WM-NMF) algorithm.\nIn particular, we aim to address the critical technical gap, which is to learn\nboth view-specific and observation-specific weights to quantify each view's\ninformation content. The introduced weighting scheme can alleviate unnecessary\nviews' adverse effects and enlarge the positive effects of the important views\nby assigning smaller and larger weights, respectively. In addition, we provide\ntheoretical investigations about the convergence, perturbation analysis, and\ngeneralization error of the WM-NMF algorithm. Experimental results confirm the\neffectiveness and advantages of the proposed algorithm in terms of achieving\nbetter clustering performance and dealing with the corrupted data compared to\nthe existing algorithms.",
    "descriptor": "",
    "authors": [
      "Shuo Shuo Liu",
      "Lin Lin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13240"
  },
  {
    "id": "arXiv:2110.13261",
    "title": "SWAP Test for an Arbitrary Number of Quantum States",
    "abstract": "We develop a recursive algorithm to generalize the quantum SWAP test for an\narbitrary number $m$ of quantum states requiring $O(m)$ controlled-swap (CSWAP)\ngates and $O(\\log m)$ ancillary qubits. We construct a quantum circuit able to\nsimultaneously measure overlaps of $m$ arbitrary pure states. Our construction\nrelies on a pairing unitary that generates a superposition state where every\npair of input states is labelled by a basis state formed by the ancillaries.",
    "descriptor": "",
    "authors": [
      "Xavier Gitiaux",
      "Ian Morris",
      "Maria Emelianenko",
      "Mingzhen Tian"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.13261"
  },
  {
    "id": "arXiv:2110.13265",
    "title": "On the Second-order Convergence Properties of Random Search Methods",
    "abstract": "We study the theoretical convergence properties of random-search methods when\noptimizing non-convex objective functions without having access to derivatives.\nWe prove that standard random-search methods that do not rely on second-order\ninformation converge to a second-order stationary point. However, they suffer\nfrom an exponential complexity in terms of the input dimension of the problem.\nIn order to address this issue, we propose a novel variant of random search\nthat exploits negative curvature by only relying on function evaluations. We\nprove that this approach converges to a second-order stationary point at a much\nfaster rate than vanilla methods: namely, the complexity in terms of the number\nof function evaluations is only linear in the problem dimension. We test our\nalgorithm empirically and find good agreements with our theoretical results.",
    "descriptor": "",
    "authors": [
      "Aurelien Lucchi",
      "Antonio Orvieto",
      "Adamos Solomou"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13265"
  },
  {
    "id": "arXiv:2110.13307",
    "title": "Institutional Incentives for the Evolution of Committed Cooperation:  Ensuring Participation is as Important as Enhancing Compliance",
    "abstract": "Both conventional wisdom and empirical evidence suggests that arranging a\nprior commitment or agreement before an interaction enhances the chance of\nreaching mutual cooperation. Yet it is not clear what mechanisms can promote\nthe participation in and compliance with such a commitment, especially when the\nformer is costly and deviating from the latter is profitable. Prior work either\nconsiders regimented commitments where compensation is assumed enforceable from\ndishonest committers, or assume implicit commitments from every individual (so\nthey are all in and thus being treated as such). Here we develop a theory of\nparticipation and compliance with respect to an explicit prior commitment under\ninstitutional incentives where individuals, at first, decide whether or not to\njoin a cooperative agreement to play a one-shot social dilemma game. Using a\nmathematical model, we determine when participating in a costly commitment and\ncomplying with it, is an evolutionary stable strategy (ESS) when playing\nagainst all other possible strategies, and results in high levels of\ncooperation in the population. We show that, given a sufficient budget for\nproviding incentives, reward of commitment compliant behaviours better promotes\ncooperation than punishment of non-compliant ones. Moreover, by sparing part of\nthis budget for rewarding those who are willing to participate in a commitment,\nthe overall frequency of cooperation can be significantly enhanced, for both\nreward and punishment. Finally, we find that, surprisingly, the presence of\nerrors in a participation decision favours evolutionary stability of commitment\ncompliant strategies and higher levels of cooperation.",
    "descriptor": "",
    "authors": [
      "Anh Han"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Multiagent Systems (cs.MA)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2110.13307"
  },
  {
    "id": "arXiv:2110.13311",
    "title": "Physics Informed Machine Learning of SPH: Machine Learning Lagrangian  Turbulence",
    "abstract": "Smoothed particle hydrodynamics (SPH) is a mesh-free Lagrangian method for\nobtaining approximate numerical solutions of the equations of fluid dynamics;\nwhich has been widely applied to weakly- and strongly compressible turbulence\nin astrophysics and engineering applications. We present a learn-able hierarchy\nof parameterized and \"physics-explainable\" SPH informed fluid simulators using\nboth physics based parameters and Neural Networks (NNs) as universal function\napproximators. Our learning algorithm develops a mixed mode approach, mixing\nforward and reverse mode automatic differentiation with forward and adjoint\nbased sensitivity analyses to efficiently perform gradient based optimization.\nWe show that our physics informed learning method is capable of: (a) solving\ninverse problems over the physically interpretable parameter space, as well as\nover the space of NN parameters; (b) learning Lagrangian statistics of\nturbulence (interpolation); (c) combining Lagrangian trajectory based,\nprobabilistic, and Eulerian field based loss functions; and (d) extrapolating\nbeyond training sets into more complex regimes of interest. Furthermore, this\nhierarchy of models gradually introduces more physical structure, which we show\nimproves interpretability, generalizability (over larger ranges of time scales\nand Reynolds numbers), preservation of physical symmetries, and requires less\ntraining data.",
    "descriptor": "",
    "authors": [
      "Michael Woodward",
      "Yifeng Tian",
      "Criston Hyett",
      "Chris Fryer",
      "Daniel Livescu",
      "Mikhail Stepanov",
      "Michael Chertkov"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13311"
  },
  {
    "id": "arXiv:2110.13329",
    "title": "From SKA to SKAO: Early Progress in the SKAO Construction",
    "abstract": "The Square Kilometre Array telescopes have recently started their\nconstruction phase, after years of pre-construction effort. The new SKA\nObservatory (SKAO) intergovernmental organisation has been created, and the\nstart of construction ($\\mathrm{T_0}$) has already happened. In this talk, we\nsummarise the construction progress of our facility, and the role that agile\nsoftware development and open-source collaboration, and in particular the\ndevelopment of our TANGO-based control system, is playing.",
    "descriptor": "\nComments: 7 pages, 4 figures, presented at ICALEPCS21, Shanghai, China, 2021, paper MOAL03\n",
    "authors": [
      "J. Santander-Vela",
      "M. Bartolini",
      "M. Miccolis",
      "N. Rees"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.13329"
  },
  {
    "id": "arXiv:2110.13361",
    "title": "Physics-Informed Neural Networks (PINNs) for Parameterized PDEs: A  Metalearning Approach",
    "abstract": "Physics-informed neural networks (PINNs) as a means of discretizing partial\ndifferential equations (PDEs) are garnering much attention in the Computational\nScience and Engineering (CS&E) world. At least two challenges exist for PINNs\nat present: an understanding of accuracy and convergence characteristics with\nrespect to tunable parameters and identification of optimization strategies\nthat make PINNs as efficient as other computational science tools. The cost of\nPINNs training remains a major challenge of Physics-informed Machine Learning\n(PiML) -- and, in fact, machine learning (ML) in general. This paper is meant\nto move towards addressing the latter through the study of PINNs for\nparameterized PDEs. Following the ML world, we introduce metalearning of PINNs\nfor parameterized PDEs. By introducing metalearning and transfer learning\nconcepts, we can greatly accelerate the PINNs optimization process. We present\na survey of model-agnostic metalearning, and then discuss our model-aware\nmetalearning applied to PINNs. We provide theoretically motivated and\nempirically backed assumptions that make our metalearning approach possible. We\nthen test our approach on various canonical forward parameterized PDEs that\nhave been presented in the emerging PINNs literature.",
    "descriptor": "",
    "authors": [
      "Michael Penwarden",
      "Shandian Zhe",
      "Akil Narayan",
      "Robert M. Kirby"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13361"
  },
  {
    "id": "arXiv:2110.13367",
    "title": "An Automatic Detection Method Of Cerebral Aneurysms In Time-Of-Flight  Magnetic Resonance Angiography Images Based On Attention 3D U-Net",
    "abstract": "Background:Subarachnoid hemorrhage caused by ruptured cerebral aneurysm often\nleads to fatal consequences.However,if the aneurysm can be found and treated\nduring asymptomatic periods,the probability of rupture can be greatly\nreduced.At present,time-of-flight magnetic resonance angiography is one of the\nmost commonly used non-invasive screening techniques for cerebral aneurysm,and\nthe application of deep learning technology in aneurysm detection can\neffectively improve the screening effect of aneurysm.Existing studies have\nfound that three-dimensional features play an important role in aneurysm\ndetection,but they require a large amount of training data and have problems\nsuch as a high false positive rate. Methods:This paper proposed a novel method\nfor aneurysm detection.First,a fully automatic cerebral artery segmentation\nalgorithm without training data was used to extract the volume of interest,and\nthen the 3D U-Net was improved by the 3D SENet module to establish an aneurysm\ndetection model.Eventually a set of fully automated,end-to-end aneurysm\ndetection methods have been formed. Results:A total of 231 magnetic resonance\nangiography image data were used in this study,among which 132 were training\nsets,34 were internal test sets and 65 were external test sets.The presented\nmethod obtained 97.89% sensitivity in the five-fold cross-validation and\nobtained 91.0% sensitivity with 2.48 false positives/case in the detection of\nthe external test sets. Conclusions:Compared with the results of our previous\nstudies and other studies,the method in this paper achieves a very competitive\nsensitivity with less training data and maintains a low false positive rate.As\nthe only method currently using 3D U-Net for aneurysm detection,it proves the\nfeasibility and superior performance of this network in aneurysm detection,and\nalso explores the potential of the channel attention mechanism in this task.",
    "descriptor": "",
    "authors": [
      "Chen Geng",
      "Meng Chen",
      "Ruoyu Di",
      "Dongdong Wang",
      "Liqin Yang",
      "Wei Xia",
      "Yuxin Li",
      "Daoying Geng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13367"
  },
  {
    "id": "arXiv:2110.13402",
    "title": "Revisiting randomized choices in isolation forests",
    "abstract": "Isolation forest or \"iForest\" is an intuitive and widely used algorithm for\nanomaly detection that follows a simple yet effective idea: in a given data\ndistribution, if a threshold (split point) is selected uniformly at random\nwithin the range of some variable and data points are divided according to\nwhether they are greater or smaller than this threshold, outlier points are\nmore likely to end up alone or in the smaller partition. The original procedure\nsuggested the choice of variable to split and split point within a variable to\nbe done uniformly at random at each step, but this paper shows that \"clustered\"\ndiverse outliers - oftentimes a more interesting class of outliers than others\n- can be more easily identified by applying a non-uniformly-random choice of\nvariables and/or thresholds. Different split guiding criteria are compared and\nsome are found to result in significantly better outlier discrimination for\ncertain classes of outliers.",
    "descriptor": "",
    "authors": [
      "David Cortes"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13402"
  },
  {
    "id": "arXiv:2110.13428",
    "title": "Image Magnification Network for Vessel Segmentation in OCTA Images",
    "abstract": "Optical coherence tomography angiography (OCTA) is a novel non-invasive\nimaging modality that allows micron-level resolution to visualize the retinal\nmicrovasculature. The retinal vessel segmentation in OCTA images is still an\nopen problem, and especially the thin and dense structure of the capillary\nplexus is an important challenge of this problem. In this work, we propose a\nnovel image magnification network (IMN) for vessel segmentation in OCTA images.\nContrary to the U-Net structure with a down-sampling encoder and up-sampling\ndecoder, the proposed IMN adopts the design of up-sampling encoding and then\ndown-sampling decoding. This design is to capture more image details and reduce\nthe omission of thin-and-small structures. The experimental results on three\nopen OCTA datasets show that the proposed IMN with an average dice score of\n90.2% achieves the best performance in vessel segmentation of OCTA images.\nBesides, we also demonstrate the superior performance of IMN in cross-field\nimage vessel segmentation and vessel skeleton extraction.",
    "descriptor": "",
    "authors": [
      "Mingchao Li",
      "Yerui Chen",
      "Weiwei Zhang",
      "Qiang Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13428"
  },
  {
    "id": "arXiv:2110.13432",
    "title": "Deep Learning-based Segmentation of Cerebral Aneurysms in 3D TOF-MRA  using Coarse-to-Fine Framework",
    "abstract": "BACKGROUND AND PURPOSE: Cerebral aneurysm is one of the most common\ncerebrovascular diseases, and SAH caused by its rupture has a very high\nmortality and disability rate. Existing automatic segmentation methods based on\nDLMs with TOF-MRA modality could not segment edge voxels very well, so that our\ngoal is to realize more accurate segmentation of cerebral aneurysms in 3D\nTOF-MRA with the help of DLMs. MATERIALS AND METHODS: In this research, we\nproposed an automatic segmentation framework of cerebral aneurysm in 3D\nTOF-MRA. The framework was composed of two segmentation networks ranging from\ncoarse to fine. The coarse segmentation network, namely DeepMedic, completed\nthe coarse segmentation of cerebral aneurysms, and the processed results were\nfed into the fine segmentation network, namely dual-channel SE_3D U-Net trained\nwith weighted loss function, for fine segmentation. Images from ADAM2020\n(n=113) were used for training and validation and images from another center\n(n=45) were used for testing. The segmentation metrics we used include DSC, HD,\nand VS. RESULTS: The trained cerebral aneurysm segmentation model achieved DSC\nof 0.75, HD of 1.52, and VS of 0.91 on validation cohort. On the totally\nindependent test cohort, our method achieved the highest DSC of 0.12, the\nlowest HD of 11.61, and the highest VS of 0.16 in comparison with\nstate-of-the-art segmentation networks. CONCLUSIONS: The coarse-to-fine\nframework, which composed of DeepMedic and dual-channel SE_3D U-Net can segment\ncerebral aneurysms in 3D TOF-MRA with a superior accuracy.",
    "descriptor": "",
    "authors": [
      "Meng Chen",
      "Chen Geng",
      "Dongdong Wang",
      "Jiajun Zhang",
      "Ruoyu Di",
      "Fengmei Li",
      "Zhiyong Zhou",
      "Sirong Piao",
      "Yuxin Li",
      "Yaikang Dai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13432"
  },
  {
    "id": "arXiv:2110.13436",
    "title": "An Analysis of LOS Coverage in Vehicular Networks with Roadside Units  and Relays",
    "abstract": "This paper analyzes the use of vehicular relays as a means to extend the\nLine-of-Sight (LOS) coverage from roadside units(RSUs) toward users on the\nstreets in mmWave or visible light communications. In this paper, we consider\nthe scenario where RSUs select vehicles within their LOS coverage as relays. As\na result, the LOS coverage of those RSUs is extended by the LOS coverage newly\nprovided by the vehicular relays. To account for the spatial relationship\nbetween vehicles and RSUs, we use Cox point processes. We assume that the LOS\ndistances from RSUs or relays are independent and exponentially distributed. To\naddress the spatial interactions between RSU LOS coverage and relay LOS\ncoverage, we use the notion of mean area fraction to evaluate the LOS coverage.",
    "descriptor": "\nComments: submitted for possible IEEE journal publication\n",
    "authors": [
      "Chang-Sik Choi",
      "Fran\u00e7ois Baccelli"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.13436"
  },
  {
    "id": "arXiv:2110.13481",
    "title": "Efficient 6D Vlasov simulation using the dynamical low-rank framework  Ensign",
    "abstract": "Running kinetic simulations using grid-based methods is extremely expensive\ndue to the up to six-dimensional phase space. Recently, it has been shown that\ndynamical low-rank algorithms can drastically reduce the required computational\neffort, while still accurately resolving important physical features such as\nfilamentation and Landau damping. In this paper, we introduce the Ensign\nsoftware framework, which facilitates the efficient implementation of dynamical\nlow-rank algorithms on modern multi-core CPU as well as GPU based systems. In\nparticular, we illustrate its features with the help of a first-order\nprojector-splitting integrator. Then, we propose a new second-order\nprojector-splitting based dynamical low-rank algorithm for the full\nsix-dimensional Vlasov--Poisson equations and implement it using our software\nframework. An exponential integrator based Fourier spectral method is employed\nto obtain a numerical method that is unconditionally stable but fully explicit.\nThe presented numerical results demonstrate that 6D simulations can be run on a\nsingle workstation, as well as highlight the significant speedup that can be\nobtained using GPUs.",
    "descriptor": "",
    "authors": [
      "Fabio Cassini",
      "Lukas Einkemmer"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.13481"
  },
  {
    "id": "arXiv:2110.13515",
    "title": "Modular Gaussian Processes for Transfer Learning",
    "abstract": "We present a framework for transfer learning based on modular variational\nGaussian processes (GP). We develop a module-based method that having a\ndictionary of well fitted GPs, one could build ensemble GP models without\nrevisiting any data. Each model is characterised by its hyperparameters,\npseudo-inputs and their corresponding posterior densities. Our method avoids\nundesired data centralisation, reduces rising computational costs and allows\nthe transfer of learned uncertainty metrics after training. We exploit the\naugmentation of high-dimensional integral operators based on the\nKullback-Leibler divergence between stochastic processes to introduce an\nefficient lower bound under all the sparse variational GPs, with different\ncomplexity and even likelihood distribution. The method is also valid for\nmulti-output GPs, learning correlations a posteriori between independent\nmodules. Extensive results illustrate the usability of our framework in\nlarge-scale and multi-task experiments, also compared with the exact inference\nmethods in the literature.",
    "descriptor": "\nComments: Accepted at Advances in Neural Information Processing Systems (NeurIPS) 2021. arXiv admin note: substantial text overlap with arXiv:2010.02554\n",
    "authors": [
      "Pablo Moreno-Mu\u00f1oz",
      "Antonio Art\u00e9s-Rodr\u00edguez",
      "Mauricio A. \u00c1lvarez"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13515"
  },
  {
    "id": "arXiv:2110.13521",
    "title": "Machine learning spectral functions in lattice QCD",
    "abstract": "We study the inverse problem of reconstructing spectral functions from\nEuclidean correlation functions via machine learning. We propose a novel\nneutral network, sVAE, which is based on the variational autoencoder (VAE) and\ncan be naturally applied to the inverse problem. The prominent feature of the\nsVAE is that a Shannon-Jaynes entropy term having the ground truth values of\nspectral functions as prior information is included in the loss function to be\nminimized. We train the network with general spectral functions produced from a\nGaussian mixture model. As a test, we use correlators generated from four\ndifferent types of physically motivated spectral functions made of one\nresonance peak, a continuum term and perturbative spectral function obtained\nusing non-relativistic QCD. From the mock data test we find that the sVAE in\nmost cases is comparable to the maximum entropy method (MEM) in the quality of\nreconstructing spectral functions and even outperforms the MEM in the case\nwhere the spectral function has sharp peaks with insufficient number of data\npoints in the correlator. By applying to temporal correlation functions of\ncharmonium in the pseudoscalar channel obtained in the quenched lattice QCD at\n0.75 $T_c$ on $128^3\\times96$ lattices and $1.5$ $T_c$ on $128^3\\times48$\nlattices, we find that the resonance peak of $\\eta_c$ extracted from both the\nsVAE and MEM has a substantial dependence on the number of points in the\ntemporal direction ($N_\\tau$) adopted in the lattice simulation and $N_\\tau$\nlarger than 48 is needed to resolve the fate of $\\eta_c$ at 1.5 $T_c$.",
    "descriptor": "\nComments: 20 pages, 11 figures\n",
    "authors": [
      "S.-Y. Chen",
      "H.-T. Ding",
      "F.-Y. Liu",
      "G. Papp",
      "C.-B. Yang"
    ],
    "subjectives": [
      "High Energy Physics - Lattice (hep-lat)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "High Energy Physics - Theory (hep-th)",
      "Nuclear Theory (nucl-th)"
    ],
    "url": "https://arxiv.org/abs/2110.13521"
  },
  {
    "id": "arXiv:2110.13527",
    "title": "Highly Scalable Maximum Likelihood and Conjugate Bayesian Inference for  ERGMs on Graph Sets with Equivalent Vertices",
    "abstract": "The exponential family random graph modeling (ERGM) framework provides a\nflexible approach for the statistical analysis of networks. As ERGMs typically\ninvolve normalizing factors that are costly to compute, practical inference\nrelies on a variety of approximations or other workarounds. Markov Chain Monte\nCarlo maximum likelihood (MCMC MLE) provides a powerful tool to approximate the\nMLE of ERGM parameters, and is feasible for typical models on single networks\nwith as many as a few thousand nodes. MCMC-based algorithms for Bayesian\nanalysis are more expensive, and high-quality answers are challenging to obtain\non large graphs. For both strategies, extension to the pooled case - in which\nwe observe multiple networks from a common generative process - adds further\ncomputational cost, with both time and memory scaling linearly in the number of\ngraphs. This becomes prohibitive for large networks, or where large numbers of\ngraph observations are available. Here, we exploit some basic properties of the\ndiscrete exponential families to develop an approach for ERGM inference in the\npooled case that (where applicable) allows an arbitrarily large number of graph\nobservations to be fit at no additional computational cost beyond preprocessing\nthe data itself. Moreover, a variant of our approach can also be used to\nperform Bayesian inference under conjugate priors, again with no additional\ncomputational cost in the estimation phase. As we show, the conjugate prior is\neasily specified, and is well-suited to applications such as regularization.\nSimulation studies show that the pooled method leads to estimates with good\nfrequentist properties, and posterior estimates under the conjugate prior are\nwell-behaved. We demonstrate our approach with applications to pooled analysis\nof brain functional connectivity networks and to replicated x-ray crystal\nstructures of hen egg-white lysozyme.",
    "descriptor": "",
    "authors": [
      "Fan Yin",
      "Carter T. Butts"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Social and Information Networks (cs.SI)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2110.13527"
  },
  {
    "id": "arXiv:2110.13543",
    "title": "Collective decision-making under changing social environments among  agents adapted to sparse connectivity",
    "abstract": "Humans and other animals often follow the decisions made by others because\nthese are indicative of the quality of possible choices, resulting in `social\nresponse rules': observed relationships between the probability that an agent\nwill make a specific choice and the decisions other individuals have made. The\nform of social responses can be understood by considering the behaviour of\nrational agents that seek to maximise their expected utility using both social\nand private information. Previous derivations of social responses assume that\nagents observe all others within a group, but real interaction networks are\noften characterised by sparse connectivity. Here I analyse the observable\nbehaviour of rational agents that attend to the decisions made by a subset of\nothers in the group. This reveals an adaptive strategy in sparsely-connected\nnetworks based on highly-simplified social information: the difference in the\nobserved number of agents choosing each option. Where agents employ this\nstrategy, collective outcomes and decision-making efficacy are controlled by\nthe social connectivity at the time of the decision, rather than that to which\nthe agents are accustomed, providing an important caveat for sociality observed\nin the laboratory and suggesting a basis for the social dynamics of\nhighly-connected online communities.",
    "descriptor": "",
    "authors": [
      "Richard P. Mann"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Multiagent Systems (cs.MA)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2110.13543"
  },
  {
    "id": "arXiv:2110.13549",
    "title": "Online Variational Filtering and Parameter Learning",
    "abstract": "We present a variational method for online state estimation and parameter\nlearning in state-space models (SSMs), a ubiquitous class of latent variable\nmodels for sequential data. As per standard batch variational techniques, we\nuse stochastic gradients to simultaneously optimize a lower bound on the log\nevidence with respect to both model parameters and a variational approximation\nof the states' posterior distribution. However, unlike existing approaches, our\nmethod is able to operate in an entirely online manner, such that historic\nobservations do not require revisitation after being incorporated and the cost\nof updates at each time step remains constant, despite the growing\ndimensionality of the joint posterior distribution of the states. This is\nachieved by utilizing backward decompositions of this joint posterior\ndistribution and of its variational approximation, combined with Bellman-type\nrecursions for the evidence lower bound and its gradients. We demonstrate the\nperformance of this methodology across several examples, including\nhigh-dimensional SSMs and sequential Variational Auto-Encoders.",
    "descriptor": "\nComments: 27 pages, 6 figures. NeurIPS 2021 (Oral)\n",
    "authors": [
      "Andrew Campbell",
      "Yuyang Shi",
      "Tom Rainforth",
      "Arnaud Doucet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.13549"
  },
  {
    "id": "arXiv:2110.13583",
    "title": "Real-time Human Response Prediction Using a Non-intrusive Data-driven  Model Reduction Scheme",
    "abstract": "Recent research in non-intrusive data-driven model order reduction (MOR)\nenabled accurate and efficient approximation of parameterized ordinary\ndifferential equations (ODEs). However, previous studies have focused on\nconstant parameters, whereas time-dependent parameters have been neglected. The\npurpose of this paper is to introduce a novel two-step MOR scheme to tackle\nthis issue. In a first step, classic MOR approaches are applied to calculate a\nlow-dimensional representation of high-dimensional ODE solutions, i.e. to\nextract the most important features of simulation data. Based on this\nrepresentation, a long short-term memory (LSTM) is trained to predict the\nreduced dynamics iteratively in a second step. This enables the parameters to\nbe taken into account during the respective time step. The potential of this\napproach is demonstrated on an occupant model within a car driving scenario.\nThe reduced model's response to time-varying accelerations matches the\nreference data with high accuracy for a limited amount of time. Furthermore,\nreal-time capability is achieved. Accordingly, it is concluded that the\npresented method is well suited to approximate parameterized ODEs and can\nhandle time-dependent parameters in contrast to common methods.",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "Jonas Kneifl",
      "Julian Hay",
      "J\u00f6rg Fehr"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13583"
  },
  {
    "id": "arXiv:2110.13586",
    "title": "Towards Audio Domain Adaptation for Acoustic Scene Classification using  Disentanglement Learning",
    "abstract": "The deployment of machine listening algorithms in real-life applications is\noften impeded by a domain shift caused for instance by different microphone\ncharacteristics. In this paper, we propose a novel domain adaptation strategy\nbased on disentanglement learning. The goal is to disentangle task-specific and\ndomain-specific characteristics in the analyzed audio recordings. In\nparticular, we combine two strategies: First, we apply different binary masks\nto internal embedding representations and, second, we suggest a novel\ncombination of categorical cross-entropy and variance-based losses. Our results\nconfirm the disentanglement of both tasks on an embedding level but show only\nminor improvement in the acoustic scene classification performance, when\ntraining data from both domains can be used. As a second finding, we can\nconfirm the effectiveness of a state-of-the-art unsupervised domain adaptation\nstrategy, which performs across-domain adaptation on a feature-level instead.",
    "descriptor": "\nComments: submitted to ICASSP 2022\n",
    "authors": [
      "Jakob Abe\u00dfer",
      "Meinard M\u00fcller"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.13586"
  },
  {
    "id": "arXiv:2110.13615",
    "title": "Cramer-Castillon on a Triangle's Incircle and Excircles",
    "abstract": "The Cramer-Castillon problem (CCP) consists in finding one or more polygons\ninscribed in a circle such that their sides pass cyclically through a list of\n$N$ points. We study this problem where the points are the vertices of a\ntriangle and the circle is either the incircle or excircles.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Dominique Laurain",
      "Peter Moses",
      "Dan Reznik"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2110.13615"
  },
  {
    "id": "arXiv:2110.13633",
    "title": "Optimal non-pharmaceutical intervention policy for Covid-19 epidemic via  neuroevolution algorithm",
    "abstract": "National responses to the Covid-19 pandemic varied markedly across countries,\nfrom business-as-usual to complete shutdowns. Policies aimed at disrupting the\nviral transmission cycle and preventing the healthcare system from being\noverwhelmed, simultaneously exact an economic toll. We developed a intervention\npolicy model that comprised the relative human, economic and healthcare costs\nof non-pharmaceutical epidemic intervention and arrived at the optimal strategy\nusing the neuroevolution algorithm. The proposed model finds the minimum\nrequired reduction in contact rates to maintain the burden on the healthcare\nsystem below the maximum capacity. We find that such a policy renders a sharp\nincrease in the control strength at the early stages of the epidemic, followed\nby a steady increase in the subsequent ten weeks as the epidemic approaches its\npeak, and finally control strength is gradually decreased as the population\nmoves towards herd immunity. We have also shown how such a model can provide an\nefficient adaptive intervention policy at different stages of the epidemic\nwithout having access to the entire history of its progression in the\npopulation. This work emphasizes the importance of imposing intervention\nmeasures early and provides insights into adaptive intervention policies to\nminimize the economic impacts of the epidemic without putting an extra burden\non the healthcare system.",
    "descriptor": "\nComments: 18 pages, 10 figures\n",
    "authors": [
      "Arash Saeidpour",
      "Pejman Rohani"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.13633"
  },
  {
    "id": "arXiv:2110.13645",
    "title": "Symmetric properties and two variants of shuffle-cubes",
    "abstract": "Li et al. in [Inf. Process. Lett. 77 (2001) 35--41] proposed the shuffle cube\n$SQ_{n}$ as an attractive interconnection network topology for massive parallel\nand distributed systems. By far, symmetric properties of the shuffle cube\nremains unknown. In this paper, we show that $SQ_{n}$ is not vertex-transitive\nfor all $n>2$, which is not an appealing property in interconnection networks.\nTo overcome this limitation, two novel vertex-transitive variants of the\nshuffle-cube, namely simplified shuffle-cube $SSQ_{n}$ and balanced shuffle\ncube $BSQ_{n}$ are introduced. Then, routing algorithms of $SSQ_{n}$ and\n$BSQ_{n}$ for all $n>2$ are given respectively. Furthermore, we show that both\n$SSQ_{n}$ and $BSQ_{n}$ possess Hamiltonian cycle embedding for all $n>2$.\nFinally, as a by-product, we mend a flaw in the Property 3 in [IEEE Trans.\nComput. 46 (1997) 484--490].",
    "descriptor": "",
    "authors": [
      "Huazhong L\u00fc",
      "Kai Deng"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.13645"
  },
  {
    "id": "arXiv:2110.13652",
    "title": "A Precision Diagnostic Framework of Renal Cell Carcinoma on Whole-Slide  Images using Deep Learning",
    "abstract": "Diagnostic pathology, which is the basis and gold standard of cancer\ndiagnosis, provides essential information on the prognosis of the disease and\nvital evidence for clinical treatment. Tumor region detection, subtype and\ngrade classification are the fundamental diagnostic indicators for renal cell\ncarcinoma (RCC) in whole-slide images (WSIs). However, pathological diagnosis\nis subjective, differences in observation and diagnosis between pathologists is\ncommon in hospitals with inadequate diagnostic capacity. The main challenge for\ndeveloping deep learning based RCC diagnostic system is the lack of large-scale\ndatasets with precise annotations. In this work, we proposed a deep\nlearning-based framework for analyzing histopathological images of patients\nwith renal cell carcinoma, which has the potential to achieve pathologist-level\naccuracy in diagnosis. A deep convolutional neural network (InceptionV3) was\ntrained on the high-quality annotated dataset of The Cancer Genome Atlas (TCGA)\nwhole-slide histopathological image for accurate tumor area detection,\nclassification of RCC subtypes, and ISUP grades classification of clear cell\ncarcinoma subtypes. These results suggest that our framework can help\npathologists in the detection of cancer region and classification of subtypes\nand grades, which could be applied to any cancer type, providing auxiliary\ndiagnosis and promoting clinical consensus.",
    "descriptor": "\nComments: BIBM 2021 accepted, 9 pages including reference, 3 figures and 1 table\n",
    "authors": [
      "Jialun Wu",
      "Haichuan Zhang",
      "Zeyu Gao",
      "Xinrui Bao",
      "Tieliang Gong",
      "Chunbao Wang",
      "Chen Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13652"
  },
  {
    "id": "arXiv:2110.13653",
    "title": "Learning Speaker Representation with Semi-supervised Learning approach  for Speaker Profiling",
    "abstract": "Speaker profiling, which aims to estimate speaker characteristics such as age\nand height, has a wide range of applications inforensics, recommendation\nsystems, etc. In this work, we propose a semisupervised learning approach to\nmitigate the issue of low training data for speaker profiling. This is done by\nutilizing external corpus with speaker information to train a better\nrepresentation which can help to improve the speaker profiling systems.\nSpecifically, besides the standard supervised learning path, the proposed\nframework has two more paths: (1) an unsupervised speaker representation\nlearning path that helps to capture the speaker information; (2) a consistency\ntraining path that helps to improve the robustness of the system by enforcing\nit to produce similar predictions for utterances of the same speaker.The\nproposed approach is evaluated on the TIMIT and NISP datasets for age, height,\nand gender estimation, while the Librispeech is used as the unsupervised\nexternal corpus. Trained both on single-task and multi-task settings, our\napproach was able to achieve state-of-the-art results on age estimation on the\nTIMIT Test dataset with Root Mean Square Error(RMSE) of6.8 and 7.4 years and\nMean Absolute Error(MAE) of 4.8 and5.0 years for male and female speakers\nrespectively.",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Shangeth Rajaa",
      "Pham Van Tung",
      "Chng Eng Siong"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.13653"
  },
  {
    "id": "arXiv:2110.13670",
    "title": "W-Net: A Two-Stage Convolutional Network for Nucleus Detection in  Histopathology Image",
    "abstract": "Pathological diagnosis is the gold standard for cancer diagnosis, but it is\nlabor-intensive, in which tasks such as cell detection, classification, and\ncounting are particularly prominent. A common solution for automating these\ntasks is using nucleus segmentation technology. However, it is hard to train a\nrobust nucleus segmentation model, due to several challenging problems, the\nnucleus adhesion, stacking, and excessive fusion with the background. Recently,\nsome researchers proposed a series of automatic nucleus segmentation methods\nbased on point annotation, which can significant improve the model performance.\nNevertheless, the point annotation needs to be marked by experienced\npathologists. In order to take advantage of segmentation methods based on point\nannotation, further alleviate the manual workload, and make cancer diagnosis\nmore efficient and accurate, it is necessary to develop an automatic nucleus\ndetection algorithm, which can automatically and efficiently locate the\nposition of the nucleus in the pathological image and extract valuable\ninformation for pathologists. In this paper, we propose a W-shaped network for\nautomatic nucleus detection. Different from the traditional U-Net based method,\nmapping the original pathology image to the target mask directly, our proposed\nmethod split the detection task into two sub-tasks. The first sub-task maps the\noriginal pathology image to the binary mask, then the binary mask is mapped to\nthe density mask in the second sub-task. After the task is split, the task's\ndifficulty is significantly reduced, and the network's overall performance is\nimproved.",
    "descriptor": "\nComments: BIBM 2021 accepted,including 8 pages, 3 figures\n",
    "authors": [
      "Anyu Mao",
      "Jialun Wu",
      "Xinrui Bao",
      "Zeyu Gao",
      "Tieliang Gong",
      "Chen Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13670"
  },
  {
    "id": "arXiv:2110.13680",
    "title": "Uncertainty quantification in a mechanical submodel driven by a  Wasserstein-GAN",
    "abstract": "The analysis of parametric and non-parametric uncertainties of very large\ndynamical systems requires the construction of a stochastic model of said\nsystem. Linear approaches relying on random matrix theory and principal\ncomponant analysis can be used when systems undergo low-frequency vibrations.\nIn the case of fast dynamics and wave propagation, we investigate a random\ngenerator of boundary conditions for fast submodels by using machine learning.\nWe show that the use of non-linear techniques in machine learning and\ndata-driven methods is highly relevant.\nPhysics-informed neural networks is a possible choice for a data-driven\nmethod to replace linear modal analysis. An architecture that support a random\ncomponent is necessary for the construction of the stochastic model of the\nphysical system for non-parametric uncertainties, since the goal is to learn\nthe underlying probabilistic distribution of uncertainty in the data.\nGenerative Adversarial Networks (GANs) are suited for such applications, where\nthe Wasserstein-GAN with gradient penalty variant offers improved convergence\nresults for our problem.\nThe objective of our approach is to train a GAN on data from a finite element\nmethod code (Fenics) so as to extract stochastic boundary conditions for faster\nfinite element predictions on a submodel. The submodel and the training data\nhave both the same geometrical support. It is a zone of interest for\nuncertainty quantification and relevant to engineering purposes. In the\nexploitation phase, the framework can be viewed as a randomized and\nparametrized simulation generator on the submodel, which can be used as a Monte\nCarlo estimator.",
    "descriptor": "",
    "authors": [
      "Hamza Boukraichi",
      "Nissrine Akkari",
      "Fabien Casenave",
      "David Ryckelynck"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13680"
  },
  {
    "id": "arXiv:2110.13688",
    "title": "A Closer Look at Reference Learning for Fourier Phase Retrieval",
    "abstract": "Reconstructing images from their Fourier magnitude measurements is a problem\nthat often arises in different research areas. This process is also referred to\nas phase retrieval. In this work, we consider a modified version of the phase\nretrieval problem, which allows for a reference image to be added onto the\nimage before the Fourier magnitudes are measured. We analyze an unrolled\nGerchberg-Saxton (GS) algorithm that can be used to learn a good reference\nimage from a dataset. Furthermore, we take a closer look at the learned\nreference images and propose a simple and efficient heuristic to construct\nreference images that, in some cases, yields reconstructions of comparable\nquality as approaches that learn references. Our code is available at\nhttps://github.com/tuelwer/reference-learning.",
    "descriptor": "\nComments: Accepted at the NeurIPS 2021 Workshop on Deep Learning and Inverse Problems\n",
    "authors": [
      "Tobias Uelwer",
      "Nick Rucks",
      "Stefan Harmeling"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13688"
  },
  {
    "id": "arXiv:2110.13716",
    "title": "HIST: A Graph-based Framework for Stock Trend Forecasting via Mining  Concept-Oriented Shared Information",
    "abstract": "Stock trend forecasting, which forecasts stock prices' future trends, plays\nan essential role in investment. The stocks in a market can share information\nso that their stock prices are highly correlated. Several methods were recently\nproposed to mine the shared information through stock concepts (e.g.,\ntechnology, Internet Retail) extracted from the Web to improve the forecasting\nresults. However, previous work assumes the connections between stocks and\nconcepts are stationary, and neglects the dynamic relevance between stocks and\nconcepts, limiting the forecasting results. Moreover, existing methods overlook\nthe invaluable shared information carried by hidden concepts, which measure\nstocks' commonness beyond the manually defined stock concepts. To overcome the\nshortcomings of previous work, we proposed a novel stock trend forecasting\nframework that can adequately mine the concept-oriented shared information from\npredefined concepts and hidden concepts. The proposed framework simultaneously\nutilize the stock's shared information and individual information to improve\nthe stock trend forecasting performance. Experimental results on the real-world\ntasks demonstrate the efficiency of our framework on stock trend forecasting.\nThe investment simulation shows that our framework can achieve a higher\ninvestment return than the baselines.",
    "descriptor": "",
    "authors": [
      "Wentao Xu",
      "Weiqing Liu",
      "Lewen Wang",
      "Yingce Xia",
      "Jiang Bian",
      "Jian Yin",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13716"
  },
  {
    "id": "arXiv:2110.13720",
    "title": "Deep DIC: Deep Learning-Based Digital Image Correlation for End-to-End  Displacement and Strain Measurement",
    "abstract": "Digital image correlation (DIC) has become an industry standard to retrieve\naccurate displacement and strain measurement in tensile testing and other\nmaterial characterization. Though traditional DIC offers a high precision\nestimation of deformation for general tensile testing cases, the prediction\nbecomes unstable at large deformation or when the speckle patterns start to\ntear. In addition, traditional DIC requires a long computation time and often\nproduces a low spatial resolution output affected by filtering and speckle\npattern quality. To address these challenges, we propose a new deep\nlearning-based DIC approach -- Deep DIC, in which two convolutional neural\nnetworks, DisplacementNet and StrainNet, are designed to work together for\nend-to-end prediction of displacements and strains. DisplacementNet predicts\nthe displacement field and adaptively tracks the change of a region of\ninterest. StrainNet predicts the strain field directly from the image input\nwithout relying on the displacement prediction, which significantly improves\nthe strain prediction accuracy. A new dataset generation method is proposed to\nsynthesize a realistic and comprehensive dataset including artificial speckle\npatterns, randomly generated displacement and strain fields, and deformed\nimages based on the given deformation. Proposed Deep DIC is trained purely on a\nsynthetic dataset, but designed to perform both on simulated and experimental\ndata. Its performance is systematically evaluated and compared with commercial\nDIC software. Deep DIC gives highly consistent and comparable predictions of\ndisplacement and strain with those obtained from commercial DIC software, while\nit outperforms commercial software with very robust strain prediction even with\nlarge and localized deformation and varied pattern qualities.",
    "descriptor": "\nComments: 39 pages, 19 figures\n",
    "authors": [
      "Ru Yang",
      "Yang Li",
      "Danielle Zeng",
      "Ping Guo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13720"
  },
  {
    "id": "arXiv:2110.13732",
    "title": "Improving the efficacy of Deep Learning models for Heart Beat detection  on heterogeneous datasets",
    "abstract": "Deep Learning (DL) have greatly contributed to bioelectric signals\nprocessing, in particular to extract physiological markers. However, the\nefficacy and applicability of the results proposed in the literature is often\nconstrained to the population represented by the data used to train the models.\nIn this study, we investigate the issues related to applying a DL model on\nheterogeneous datasets. In particular, by focusing on heart beat detection from\nElectrocardiogram signals (ECG), we show that the performance of a model\ntrained on data from healthy subjects decreases when applied to patients with\ncardiac conditions and to signals collected with different devices. We then\nevaluate the use of Transfer Learning (TL) to adapt the model to the different\ndatasets. In particular, we show that the classification performance is\nimproved, even with datasets with a small sample size. These results suggest\nthat a greater effort should be made towards generalizability of DL models\napplied on bioelectric signals, in particular by retrieving more representative\ndatasets.",
    "descriptor": "",
    "authors": [
      "Andrea Bizzego",
      "Giulio Gabrieli",
      "Michelle Jin-Yee Neoh",
      "Gianluca Esposito"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13732"
  },
  {
    "id": "arXiv:2110.13753",
    "title": "On some combinatorial sequences associated to invariant theory",
    "abstract": "We study the enumerative and analytic properties of some sequences\nconstructed using tensor invariant theory. The octant sequences are constructed\nfrom the exceptional Lie group $G_2$ and the quadrant sequences from the\nspecial linear group $SL(3)$. In each case we show that the corresponding\nsequences are related by binomial transforms. The first three octant sequences\nand the first four quadrant sequences are listed in the On-Line Encyclopedia of\nInteger Sequences (OEIS). These sequences all have interpretations as\nenumerating two-dimensional lattice walks but for the octant sequences the\nboundary conditions are unconventional. These sequences are all P-recursive and\nwe give the corresponding recurrence relations. In all cases the associated\ndifferential operators are of third order and have the remarkable property that\nthey can be solved to give closed formulae for the ordinary generating\nfunctions in terms of classical Gaussian hypergeometric functions. Moreover, we\nshow that the octant sequences and the quadrant sequences are related by the\nbranching rules for the inclusion of $SL(3)$ in $G_2$.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1911.10288\n",
    "authors": [
      "Alin Bostan",
      "Jordan Tirrell",
      "Bruce W. Westbury",
      "Yi Zhang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2110.13753"
  },
  {
    "id": "arXiv:2110.13769",
    "title": "Min-similarity association rules for identifying past comorbidities of  recurrent ED and inpatient patients",
    "abstract": "In the hospital setting, a small percentage of recurrent frequent patients\ncontribute to a disproportional amount of healthcare resource usage. Moreover,\nin many of these cases, patient outcomes can be greatly improved by reducing\nreoccurring visits, especially when they are associated with substance abuse,\nmental health, and medical factors that could be improved by social-behavioral\ninterventions, outpatient or preventative care. To address this, we developed a\ncomputationally efficient and interpretable framework that both identifies\nrecurrent patients with high utilization and determines which comorbidities\ncontribute most to their recurrent visits. Specifically, we present a novel\nalgorithm, called the minimum similarity association rules (MSAR), balancing\nconfidence-support trade-off, to determine the conditions most associated with\nreoccurring Emergency department (ED) and inpatient visits. We validate MSAR on\na large Electric Health Record (EHR) dataset. Part of the solution is deployed\nin Philips product Patient Flow Capacity Suite (PFCS).",
    "descriptor": "",
    "authors": [
      "Luoluo Liu",
      "Eran Simhon",
      "Chaitanya Kulkarni",
      "Ronny Mans"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13769"
  },
  {
    "id": "arXiv:2110.13796",
    "title": "Post-processing for Individual Fairness",
    "abstract": "Post-processing in algorithmic fairness is a versatile approach for\ncorrecting bias in ML systems that are already used in production. The main\nappeal of post-processing is that it avoids expensive retraining. In this work,\nwe propose general post-processing algorithms for individual fairness (IF). We\nconsider a setting where the learner only has access to the predictions of the\noriginal model and a similarity graph between individuals, guiding the desired\nfairness constraints. We cast the IF post-processing problem as a graph\nsmoothing problem corresponding to graph Laplacian regularization that\npreserves the desired \"treat similar individuals similarly\" interpretation. Our\ntheoretical results demonstrate the connection of the new objective function to\na local relaxation of the original individual fairness. Empirically, our\npost-processing algorithms correct individual biases in large-scale NLP models\nsuch as BERT, while preserving accuracy.",
    "descriptor": "\nComments: Published at NeurIPS 2021, Code @ this https URL, Video @ this https URL\n",
    "authors": [
      "Felix Petersen",
      "Debarghya Mukherjee",
      "Yuekai Sun",
      "Mikhail Yurochkin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13796"
  },
  {
    "id": "arXiv:2110.13814",
    "title": "Learning New Auction Format by Bidders in Internet Display Ad Auctions",
    "abstract": "We study actual bidding behavior when a new auction format gets introduced\ninto the marketplace. More specifically, we investigate this question using a\nnovel data set on internet display ad auctions that exploits a staggered\nadoption by different publishers (sellers) of first-price auctions (FPAs), in\nplace for the traditional second-price auctions (SPAs). Event study regression\nestimates indicate a significant jump, immediately after the auction format\nchange, in revenue per sold impression (price) of the treated publishers\nrelative to that of control publishers, ranging from 35% to 75% of\npre-treatment price levels of the treated group. Further, we observe that in\nlater auction format changes the lift in price relative to SPAs dissipates over\ntime, reminiscent of the celebrated revenue equivalence theorem. We take this\nas evidence of initially insufficient bid shading after the format change\nrather than an immediate shift to a new Bayesian Nash equilibrium. Prices then\nwent down as bidders learned to shade their bids. We also show that bidders\nsophistication impacted their response to the auction format change. Our work\nconstitutes one of the first field studies on bidders' responses to auction\nformat changes, providing an important complement to theoretical model\npredictions. As such, it provides valuable information to auction designers\nwhen considering the implementation of different formats.",
    "descriptor": "\nComments: 31 pages, 34 figures\n",
    "authors": [
      "Shumpei Goke",
      "Gabriel Y. Weintraub",
      "Ralph Mastromonaco",
      "Sam Seljan"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.13814"
  },
  {
    "id": "arXiv:2110.13815",
    "title": "As long as you talk about me: The importance of family firm brands and  the contingent role of family-firm identity",
    "abstract": "This study explores the role of external audiences in determining the\nimportance of family firm brands and the relationship with firm performance.\nDrawing on text mining and social network analysis techniques, and considering\nthe brand prevalence, diversity, and connectivity dimensions, we use the\nsemantic brand score to measure the importance the media give to family firm\nbrands. The analysis of a sample of 52,555 news articles published in 2017\nabout 63 Italian entrepreneurial families reveals that brand importance is\npositively associated with family firm revenues, and this relationship is\nstronger when there is identity match between the family and the firm. This\nstudy advances current literature by offering a rich and multifaceted\nperspective on how external audiences perceptions of the brand shape family\nfirm performance.",
    "descriptor": "",
    "authors": [
      "P. Rovelli",
      "C. Benedetti",
      "A. Fronzetti Colladon",
      "A. De Massis"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.13815"
  },
  {
    "id": "arXiv:2110.13823",
    "title": "Real-time division-of-focal-plane polarization imaging system with  progressive networks",
    "abstract": "Division-of-focal-plane (DoFP) polarization imaging technical recently has\nbeen applied in many fields. However, the images captured by such sensors\ncannot be used directly because they suffer from instantaneous field-of-view\nerrors and low resolution problem. This paper builds a fast DoFP demosaicing\nsystem with proposed progressive polarization demosaicing convolutional neural\nnetwork (PPDN), which is specifically designed for edge-side GPU devices like\nNavidia Jetson TX2. The proposed network consists of two parts: reconstruction\nstage and refining stage. The former recovers four polarization channels from a\nsingle DoFP image. The latter fine-tune the four channels to obtain more\naccurate polarization information. PPDN can be implemented in another version:\nPPDN-L (large), for the platforms of high computing resources. Experiments show\nthat PPDN can compete with the best existing methods with fewer parameters and\nfaster inference speed and meet the real-time demands of imaging system.",
    "descriptor": "\nComments: Submit to IEEE Sensors Journal\n",
    "authors": [
      "Rongyuan Wu",
      "Yongqiang Zhao",
      "Ning Li",
      "Seong G.Kong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13823"
  },
  {
    "id": "arXiv:2110.13891",
    "title": "Dynamic Causal Bayesian Optimization",
    "abstract": "This paper studies the problem of performing a sequence of optimal\ninterventions in a causal dynamical system where both the target variable of\ninterest and the inputs evolve over time. This problem arises in a variety of\ndomains e.g. system biology and operational research. Dynamic Causal Bayesian\nOptimization (DCBO) brings together ideas from sequential decision making,\ncausal inference and Gaussian process (GP) emulation. DCBO is useful in\nscenarios where all causal effects in a graph are changing over time. At every\ntime step DCBO identifies a local optimal intervention by integrating both\nobservational and past interventional data collected from the system. We give\ntheoretical results detailing how one can transfer interventional information\nacross time steps and define a dynamic causal GP model which can be used to\nquantify uncertainty and find optimal interventions in practice. We demonstrate\nhow DCBO identifies optimal interventions faster than competing approaches in\nmultiple settings and applications.",
    "descriptor": "",
    "authors": [
      "Virginia Aglietti",
      "Neil Dhir",
      "Javier Gonz\u00e1lez",
      "Theodoros Damoulas"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13891"
  },
  {
    "id": "arXiv:1805.08079",
    "title": "Faster Neural Network Training with Approximate Tensor Operations",
    "abstract": "Comments: NeurIPS 2021 camera ready",
    "descriptor": "\nComments: NeurIPS 2021 camera ready\n",
    "authors": [
      "Menachem Adelman",
      "Kfir Y. Levy",
      "Ido Hakimi",
      "Mark Silberstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1805.08079"
  },
  {
    "id": "arXiv:1806.01380",
    "title": "A General Framework for Bandit Problems Beyond Cumulative Objectives",
    "abstract": "Comments: Preliminary version accepted for presentation at Conference on Learning Theory (COLT) 2018",
    "descriptor": "\nComments: Preliminary version accepted for presentation at Conference on Learning Theory (COLT) 2018\n",
    "authors": [
      "Asaf Cassel",
      "Shie Mannor",
      "Assaf Zeevi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1806.01380"
  },
  {
    "id": "arXiv:1903.07138",
    "title": "A Brain-inspired Algorithm for Training Highly Sparse Neural Networks",
    "abstract": "A Brain-inspired Algorithm for Training Highly Sparse Neural Networks",
    "descriptor": "",
    "authors": [
      "Zahra Atashgahi",
      "Joost Pieterse",
      "Shiwei Liu",
      "Decebal Constantin Mocanu",
      "Raymond Veldhuis",
      "Mykola Pechenizkiy"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1903.07138"
  },
  {
    "id": "arXiv:1904.05254",
    "title": "Attraction-Repulsion clustering with applications to fairness",
    "abstract": "Comments: 35 pages, 11 figures, 5 tables",
    "descriptor": "\nComments: 35 pages, 11 figures, 5 tables\n",
    "authors": [
      "Eustasio del Barrio",
      "Hristo Inouzhe",
      "Jean-Michel Loubes"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1904.05254"
  },
  {
    "id": "arXiv:1906.08635",
    "title": "Energy Models for Better Pseudo-Labels: Improving Semi-Supervised  Classification with the 1-Laplacian Graph Energy",
    "abstract": "Energy Models for Better Pseudo-Labels: Improving Semi-Supervised  Classification with the 1-Laplacian Graph Energy",
    "descriptor": "",
    "authors": [
      "Angelica I. Aviles-Rivero",
      "Nicolas Papadakis",
      "Ruoteng Li",
      "Philip Sellars",
      "Samar M Alsaleh",
      "Robby T Tan",
      "Carola-Bibiane Sch\u00f6nlieb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.08635"
  },
  {
    "id": "arXiv:1908.03265",
    "title": "On the Variance of the Adaptive Learning Rate and Beyond",
    "abstract": "Comments: ICLR 2020. Fix several typos in the previous version",
    "descriptor": "\nComments: ICLR 2020. Fix several typos in the previous version\n",
    "authors": [
      "Liyuan Liu",
      "Haoming Jiang",
      "Pengcheng He",
      "Weizhu Chen",
      "Xiaodong Liu",
      "Jianfeng Gao",
      "Jiawei Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1908.03265"
  },
  {
    "id": "arXiv:1909.13035",
    "title": "Bridging Explicit and Implicit Deep Generative Models via Neural Stein  Estimators",
    "abstract": "Comments: Accepted by NeurIPS2021 main conference",
    "descriptor": "\nComments: Accepted by NeurIPS2021 main conference\n",
    "authors": [
      "Qitian Wu",
      "Rui Gao",
      "Hongyuan Zha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1909.13035"
  },
  {
    "id": "arXiv:1911.04250",
    "title": "How to GENERALize Across Many Software Projects? (with case studies on  Predicting Defect and Project Health)",
    "abstract": "Comments: 34 pages, 9 figures, 3 Tables",
    "descriptor": "\nComments: 34 pages, 9 figures, 3 Tables\n",
    "authors": [
      "Suvodeep Majumder",
      "Tianpei Xia",
      "Rahul Krishna",
      "Tim Menzies"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1911.04250"
  },
  {
    "id": "arXiv:1912.12284",
    "title": "Decision Making in Star Networks with Incorrect Beliefs",
    "abstract": "Comments: final version, to appear in IEEE Transactions on Signal Processing",
    "descriptor": "\nComments: final version, to appear in IEEE Transactions on Signal Processing\n",
    "authors": [
      "Daewon Seo",
      "Ravi Kiran Raman",
      "Lav R. Varshney"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/1912.12284"
  },
  {
    "id": "arXiv:2001.04896",
    "title": "Minimax adaptive estimation in manifold inference",
    "abstract": "Minimax adaptive estimation in manifold inference",
    "descriptor": "",
    "authors": [
      "Vincent Divol"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2001.04896"
  },
  {
    "id": "arXiv:2002.03016",
    "title": "Safe Wasserstein Constrained Deep Q-Learning",
    "abstract": "Safe Wasserstein Constrained Deep Q-Learning",
    "descriptor": "",
    "authors": [
      "Aaron Kandel",
      "Scott J. Moura"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.03016"
  },
  {
    "id": "arXiv:2002.04758",
    "title": "Salvaging Federated Learning by Local Adaptation",
    "abstract": "Salvaging Federated Learning by Local Adaptation",
    "descriptor": "",
    "authors": [
      "Tao Yu",
      "Eugene Bagdasaryan",
      "Vitaly Shmatikov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.04758"
  },
  {
    "id": "arXiv:2002.05308",
    "title": "Efficient Adaptive Experimental Design for Average Treatment Effect  Estimation",
    "abstract": "Efficient Adaptive Experimental Design for Average Treatment Effect  Estimation",
    "descriptor": "",
    "authors": [
      "Masahiro Kato",
      "Takuya Ishihara",
      "Junya Honda",
      "Yusuke Narita"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2002.05308"
  },
  {
    "id": "arXiv:2003.08907",
    "title": "Overinterpretation reveals image classification model pathologies",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Brandon Carter",
      "Siddhartha Jain",
      "Jonas Mueller",
      "David Gifford"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.08907"
  },
  {
    "id": "arXiv:2005.01649",
    "title": "Resonance based schemes for dispersive equations via decorated trees",
    "abstract": "Comments: 91 pages, to appear in Forum Mathematics, Pi",
    "descriptor": "\nComments: 91 pages, to appear in Forum Mathematics, Pi\n",
    "authors": [
      "Yvain Bruned",
      "Katharina Schratz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2005.01649"
  },
  {
    "id": "arXiv:2005.13938",
    "title": "Computing Subset Transversals in $H$-Free Graphs",
    "abstract": "Comments: Minor changes incorporating suggestions of reviewers",
    "descriptor": "\nComments: Minor changes incorporating suggestions of reviewers\n",
    "authors": [
      "Nick Brettell",
      "Matthew Johnson",
      "Giacomo Paesani",
      "Dani\u00ebl Paulusma"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2005.13938"
  },
  {
    "id": "arXiv:2006.02894",
    "title": "Secure Sum Outperforms Homomorphic Encryption in (Current) Collaborative  Deep Learning",
    "abstract": "Comments: submitted to Journal of Artificial Intelligence",
    "descriptor": "\nComments: submitted to Journal of Artificial Intelligence\n",
    "authors": [
      "Derian Boer",
      "Stefan Kramer"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.02894"
  },
  {
    "id": "arXiv:2008.07146",
    "title": "Open Bandit Dataset and Pipeline: Towards Realistic and Reproducible  Off-Policy Evaluation",
    "abstract": "Comments: Accepted at NeurIPS2021 Datasets and Benchmarks Track",
    "descriptor": "\nComments: Accepted at NeurIPS2021 Datasets and Benchmarks Track\n",
    "authors": [
      "Yuta Saito",
      "Shunsuke Aihara",
      "Megumi Matsutani",
      "Yusuke Narita"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.07146"
  },
  {
    "id": "arXiv:2008.09569",
    "title": "Revisiting Process versus Product Metrics: a Large Scale Analysis",
    "abstract": "Comments: 36 pages, 12 figures and 5 tables",
    "descriptor": "\nComments: 36 pages, 12 figures and 5 tables\n",
    "authors": [
      "Suvodeep Majumder",
      "Pranav Mody",
      "Tim Menzies"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.09569"
  },
  {
    "id": "arXiv:2008.13607",
    "title": "Ranking Policy Decisions",
    "abstract": "Ranking Policy Decisions",
    "descriptor": "",
    "authors": [
      "Hadrien Pouget",
      "Hana Chockler",
      "Youcheng Sun",
      "Daniel Kroening"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.13607"
  },
  {
    "id": "arXiv:2009.05204",
    "title": "Transfer Learning of Graph Neural Networks with Ego-graph Information  Maximization",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Qi Zhu",
      "Carl Yang",
      "Yidan Xu",
      "Haonan Wang",
      "Chao Zhang",
      "Jiawei Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.05204"
  },
  {
    "id": "arXiv:2009.06891",
    "title": "Global-aware Beam Search for Neural Abstractive Summarization",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Ye Ma",
      "Zixun Lan",
      "Lu Zong",
      "Kaizhu Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2009.06891"
  },
  {
    "id": "arXiv:2009.06924",
    "title": "360-Degree Gaze Estimation in the Wild Using Multiple Zoom Scales",
    "abstract": "Comments: accepted at BMVC 2021",
    "descriptor": "\nComments: accepted at BMVC 2021\n",
    "authors": [
      "Ashesh",
      "Chu-Song Chen",
      "Hsuan-Tien Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.06924"
  },
  {
    "id": "arXiv:2009.07629",
    "title": "Central algorithms for accurately predicting non classical non-linear  waves in Dense Gases over simple geometries",
    "abstract": "Comments: 29 pages. arXiv admin note: text overlap with arXiv:2003.10695",
    "descriptor": "\nComments: 29 pages. arXiv admin note: text overlap with arXiv:2003.10695\n",
    "authors": [
      "Ramesh Kolluru",
      "S. V. Raghurama Rao",
      "G.N.Sekhar"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2009.07629"
  },
  {
    "id": "arXiv:2009.08228",
    "title": "LeadCache: Regret-Optimal Caching in Networks",
    "abstract": "Comments: To appear in NeurIPS 2021",
    "descriptor": "\nComments: To appear in NeurIPS 2021\n",
    "authors": [
      "Debjit Paria",
      "Abhishek Sinha"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2009.08228"
  },
  {
    "id": "arXiv:2009.09026",
    "title": "Adversarial Robustness through Bias Variance Decomposition: A New  Perspective for Federated Learning",
    "abstract": "Adversarial Robustness through Bias Variance Decomposition: A New  Perspective for Federated Learning",
    "descriptor": "",
    "authors": [
      "Yao Zhou",
      "Jun Wu",
      "Haixun Wang",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.09026"
  },
  {
    "id": "arXiv:2009.13961",
    "title": "Online Action Learning in High Dimensions: A Conservative Perspective",
    "abstract": "Online Action Learning in High Dimensions: A Conservative Perspective",
    "descriptor": "",
    "authors": [
      "Claudio Cardoso Flores",
      "Marcelo Cunha Medeiros"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2009.13961"
  },
  {
    "id": "arXiv:2010.08262",
    "title": "Local plasticity rules can learn deep representations using  self-supervised contrastive predictions",
    "abstract": "Local plasticity rules can learn deep representations using  self-supervised contrastive predictions",
    "descriptor": "",
    "authors": [
      "Bernd Illing",
      "Jean Ventura",
      "Guillaume Bellec",
      "Wulfram Gerstner"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.08262"
  },
  {
    "id": "arXiv:2010.08281",
    "title": "Embedding and Extraction of Knowledge in Tree Ensemble Classifiers",
    "abstract": "Embedding and Extraction of Knowledge in Tree Ensemble Classifiers",
    "descriptor": "",
    "authors": [
      "Wei Huang",
      "Xingyu Zhao",
      "Xiaowei Huang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.08281"
  },
  {
    "id": "arXiv:2010.09541",
    "title": "On the Difficulty of Unbiased Alpha Divergence Minimization",
    "abstract": "Comments: ICML 2021",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Tomas Geffner",
      "Justin Domke"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.09541"
  },
  {
    "id": "arXiv:2010.14622",
    "title": "Vertex nomination between graphs via spectral embedding and quadratic  programming",
    "abstract": "Vertex nomination between graphs via spectral embedding and quadratic  programming",
    "descriptor": "",
    "authors": [
      "Runbing Zheng",
      "Vince Lyzinski",
      "Carey E. Priebe",
      "Minh Tang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2010.14622"
  },
  {
    "id": "arXiv:2010.16358",
    "title": "AgEBO-Tabular: Joint Neural Architecture and Hyperparameter Search with  Autotuned Data-Parallel Training for Tabular Data",
    "abstract": "AgEBO-Tabular: Joint Neural Architecture and Hyperparameter Search with  Autotuned Data-Parallel Training for Tabular Data",
    "descriptor": "",
    "authors": [
      "Romain Egele",
      "Prasanna Balaprakash",
      "Venkatram Vishwanath",
      "Isabelle Guyon",
      "Zhengying Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.16358"
  },
  {
    "id": "arXiv:2011.04569",
    "title": "Informed Source Extraction With Application to Acoustic Echo Reduction",
    "abstract": "Comments: Published at ITG 2021",
    "descriptor": "\nComments: Published at ITG 2021\n",
    "authors": [
      "Mohamed Elminshawi",
      "Wolfgang Mack",
      "Emanu\u00ebl A. P. Habets"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2011.04569"
  },
  {
    "id": "arXiv:2011.09468",
    "title": "Gradient Starvation: A Learning Proclivity in Neural Networks",
    "abstract": "Comments: Proceeding of NeurIPS 2021",
    "descriptor": "\nComments: Proceeding of NeurIPS 2021\n",
    "authors": [
      "Mohammad Pezeshki",
      "S\u00e9kou-Oumar Kaba",
      "Yoshua Bengio",
      "Aaron Courville",
      "Doina Precup",
      "Guillaume Lajoie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.09468"
  },
  {
    "id": "arXiv:2011.12101",
    "title": "Space-time POD-Galerkin approach for parametric flow control",
    "abstract": "Space-time POD-Galerkin approach for parametric flow control",
    "descriptor": "",
    "authors": [
      "Francesco Ballarin",
      "Gianluigi Rozza",
      "Maria Strazzullo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2011.12101"
  },
  {
    "id": "arXiv:2011.12572",
    "title": "A combination of Residual Distribution and the Active Flux formulations  or a new class of schemes that can combine several writings of the same  hyperbolic problem: application to the 1D Euler equations",
    "abstract": "A combination of Residual Distribution and the Active Flux formulations  or a new class of schemes that can combine several writings of the same  hyperbolic problem: application to the 1D Euler equations",
    "descriptor": "",
    "authors": [
      "R\u00e9mi Abgrall"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2011.12572"
  },
  {
    "id": "arXiv:2011.14164",
    "title": "Towards Robust Partially Supervised Multi-Structure Medical Image  Segmentation on Small-Scale Data",
    "abstract": "Comments: Accepted by Applied Soft Computing",
    "descriptor": "\nComments: Accepted by Applied Soft Computing\n",
    "authors": [
      "Nanqing Dong",
      "Michael Kampffmeyer",
      "Xiaodan Liang",
      "Min Xu",
      "Irina Voiculescu",
      "Eric P. Xing"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2011.14164"
  },
  {
    "id": "arXiv:2012.00901",
    "title": "Deep Multi-Fidelity Active Learning of High-dimensional Outputs",
    "abstract": "Deep Multi-Fidelity Active Learning of High-dimensional Outputs",
    "descriptor": "",
    "authors": [
      "Shibo Li",
      "Robert M. Kirby",
      "Shandian Zhe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.00901"
  },
  {
    "id": "arXiv:2012.01644",
    "title": "Capturing implicit hierarchical structure in 3D biomedical images with  self-supervised hyperbolic representations",
    "abstract": "Comments: To appear at NeurIPS 2021",
    "descriptor": "\nComments: To appear at NeurIPS 2021\n",
    "authors": [
      "Joy Hsu",
      "Jeffrey Gu",
      "Gong-Her Wu",
      "Wah Chiu",
      "Serena Yeung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.01644"
  },
  {
    "id": "arXiv:2012.08508",
    "title": "Attention over learned object embeddings enables complex visual  reasoning",
    "abstract": "Comments: 22 pages, 5 figures",
    "descriptor": "\nComments: 22 pages, 5 figures\n",
    "authors": [
      "David Ding",
      "Felix Hill",
      "Adam Santoro",
      "Malcolm Reynolds",
      "Matt Botvinick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.08508"
  },
  {
    "id": "arXiv:2101.00300",
    "title": "When Is Generalizable Reinforcement Learning Tractable?",
    "abstract": "Comments: Neurips 2021, v3 fixes minor typos",
    "descriptor": "\nComments: Neurips 2021, v3 fixes minor typos\n",
    "authors": [
      "Dhruv Malik",
      "Yuanzhi Li",
      "Pradeep Ravikumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2101.00300"
  },
  {
    "id": "arXiv:2101.06203",
    "title": "Reviving Purpose Limitation and Data Minimisation in Data-Driven Systems",
    "abstract": "Comments: In Technology and Regulation (2021): this https URL",
    "descriptor": "\nComments: In Technology and Regulation (2021): this https URL\n",
    "authors": [
      "Asia J. Biega",
      "Mich\u00e8le Finck"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.06203"
  },
  {
    "id": "arXiv:2101.06572",
    "title": "Tracial smooth functions of non-commuting variables and the free  Wasserstein manifold",
    "abstract": "Comments: 134 pages, revised",
    "descriptor": "\nComments: 134 pages, revised\n",
    "authors": [
      "David Jekel",
      "Wuchen Li",
      "Dimitri Shlyakhtenko"
    ],
    "subjectives": [
      "Operator Algebras (math.OA)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2101.06572"
  },
  {
    "id": "arXiv:2101.09752",
    "title": "AQuA: Analytical Quality Assessment for Optimizing Video Analytics  Systems",
    "abstract": "AQuA: Analytical Quality Assessment for Optimizing Video Analytics  Systems",
    "descriptor": "",
    "authors": [
      "Sibendu Paul",
      "Utsav Drolia",
      "Y. Charlie Hu",
      "Srimat T. Chakradhar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.09752"
  },
  {
    "id": "arXiv:2102.00225",
    "title": "Learning From Human Correction For Data-Centric Deep Learning",
    "abstract": "Learning From Human Correction For Data-Centric Deep Learning",
    "descriptor": "",
    "authors": [
      "Tong Guo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2102.00225"
  },
  {
    "id": "arXiv:2102.00865",
    "title": "Global types and event structure semantics for asynchronous multiparty  sessions",
    "abstract": "Global types and event structure semantics for asynchronous multiparty  sessions",
    "descriptor": "",
    "authors": [
      "Ilaria Castellani",
      "Mariangiola Dezani-Ciancaglini",
      "Paola Giannini"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2102.00865"
  },
  {
    "id": "arXiv:2102.01951",
    "title": "Mind the Gap: Assessing Temporal Generalization in Neural Language  Models",
    "abstract": "Comments: To appear as a Spotlight at NeurIPS 2021",
    "descriptor": "\nComments: To appear as a Spotlight at NeurIPS 2021\n",
    "authors": [
      "Angeliki Lazaridou",
      "Adhiguna Kuncoro",
      "Elena Gribovskaya",
      "Devang Agrawal",
      "Adam Liska",
      "Tayfun Terzi",
      "Mai Gimenez",
      "Cyprien de Masson d'Autume",
      "Tomas Kocisky",
      "Sebastian Ruder",
      "Dani Yogatama",
      "Kris Cao",
      "Susannah Young",
      "Phil Blunsom"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.01951"
  },
  {
    "id": "arXiv:2102.03034",
    "title": "Hyperparameter Optimization Is Deceiving Us, and How to Stop It",
    "abstract": "Comments: To appear, NeurIPS 2021",
    "descriptor": "\nComments: To appear, NeurIPS 2021\n",
    "authors": [
      "A. Feder Cooper",
      "Yucheng Lu",
      "Jessica Zosa Forde",
      "Christopher De Sa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2102.03034"
  },
  {
    "id": "arXiv:2102.03324",
    "title": "GIBBON: General-purpose Information-Based Bayesian OptimisatioN",
    "abstract": "GIBBON: General-purpose Information-Based Bayesian OptimisatioN",
    "descriptor": "",
    "authors": [
      "Henry B. Moss",
      "David S. Leslie",
      "Javier Gonzalez",
      "Paul Rayson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.03324"
  },
  {
    "id": "arXiv:2102.03448",
    "title": "Federated Reconstruction: Partially Local Federated Learning",
    "abstract": "Comments: 35th Conference on Neural Information Processing Systems (NeurIPS 2021)",
    "descriptor": "\nComments: 35th Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Karan Singhal",
      "Hakim Sidahmed",
      "Zachary Garrett",
      "Shanshan Wu",
      "Keith Rush",
      "Sushant Prakash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2102.03448"
  },
  {
    "id": "arXiv:2102.04716",
    "title": "Better Safe Than Sorry: Preventing Delusive Adversaries with Adversarial  Training",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Lue Tao",
      "Lei Feng",
      "Jinfeng Yi",
      "Sheng-Jun Huang",
      "Songcan Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.04716"
  },
  {
    "id": "arXiv:2102.05242",
    "title": "Patterns, predictions, and actions: A story about machine learning",
    "abstract": "Comments: Manuscript submitted to publisher for copy editing",
    "descriptor": "\nComments: Manuscript submitted to publisher for copy editing\n",
    "authors": [
      "Moritz Hardt",
      "Benjamin Recht"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.05242"
  },
  {
    "id": "arXiv:2102.05762",
    "title": "Risk-Averse Bayes-Adaptive Reinforcement Learning",
    "abstract": "Comments: Full version of NeurIPS 2021 paper",
    "descriptor": "\nComments: Full version of NeurIPS 2021 paper\n",
    "authors": [
      "Marc Rigter",
      "Bruno Lacerda",
      "Nick Hawes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.05762"
  },
  {
    "id": "arXiv:2102.06199",
    "title": "A-NeRF: Articulated Neural Radiance Fields for Learning Human Shape,  Appearance, and Pose",
    "abstract": "Comments: Project website: this https URL",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Shih-Yang Su",
      "Frank Yu",
      "Michael Zollhoefer",
      "Helge Rhodin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2102.06199"
  },
  {
    "id": "arXiv:2102.06442",
    "title": "Broad-UNet: Multi-scale feature learning for nowcasting tasks",
    "abstract": "Comments: 9 pages, 11 figures",
    "descriptor": "\nComments: 9 pages, 11 figures\n",
    "authors": [
      "Jesus Garcia Fernandez",
      "Siamak Mehrkanoon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.06442"
  },
  {
    "id": "arXiv:2102.06589",
    "title": "Generalization Bounds for Meta-Learning via PAC-Bayes and Uniform  Stability",
    "abstract": "Generalization Bounds for Meta-Learning via PAC-Bayes and Uniform  Stability",
    "descriptor": "",
    "authors": [
      "Alec Farid",
      "Anirudha Majumdar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.06589"
  },
  {
    "id": "arXiv:2102.06604",
    "title": "Cockpit: A Practical Debugging Tool for the Training of Deep Neural  Networks",
    "abstract": "Comments: (NeurIPS 2021) Main text: 13 pages, 6 figures, 1 table; Supplements: 23 pages, 13 figures, 1 table, 1 listing",
    "descriptor": "\nComments: (NeurIPS 2021) Main text: 13 pages, 6 figures, 1 table; Supplements: 23 pages, 13 figures, 1 table, 1 listing\n",
    "authors": [
      "Frank Schneider",
      "Felix Dangel",
      "Philipp Hennig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.06604"
  },
  {
    "id": "arXiv:2102.06648",
    "title": "A Critical Look at the Consistency of Causal Estimation With Deep Latent  Variable Models",
    "abstract": "Comments: 10 pages for main text + 19 pages for references and supplementary. 18 Figures",
    "descriptor": "\nComments: 10 pages for main text + 19 pages for references and supplementary. 18 Figures\n",
    "authors": [
      "Severi Rissanen",
      "Pekka Marttinen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.06648"
  },
  {
    "id": "arXiv:2102.07037",
    "title": "Robust Lane Detection via Expanded Self Attention",
    "abstract": "Comments: Accepted to IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2022",
    "descriptor": "\nComments: Accepted to IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2022\n",
    "authors": [
      "Minhyeok Lee",
      "Junhyeop Lee",
      "Dogyoon Lee",
      "Woojin Kim",
      "Sangwon Hwang",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.07037"
  },
  {
    "id": "arXiv:2102.07650",
    "title": "Learning Student-Friendly Teacher Networks for Knowledge Distillation",
    "abstract": "Comments: Accepted by NeurIPS 2021",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Dae Young Park",
      "Moon-Hyun Cha",
      "Changwook Jeong",
      "Dae Sin Kim",
      "Bohyung Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.07650"
  },
  {
    "id": "arXiv:2102.07966",
    "title": "A Hybrid Semi-Lagrangian Cut Cell Method for Advection-Diffusion  Problems with Robin Boundary Conditions in Moving Domains",
    "abstract": "A Hybrid Semi-Lagrangian Cut Cell Method for Advection-Diffusion  Problems with Robin Boundary Conditions in Moving Domains",
    "descriptor": "",
    "authors": [
      "Aaron Barrett",
      "Aaron L. Fogelson",
      "Boyce E. Griffith"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2102.07966"
  },
  {
    "id": "arXiv:2102.08604",
    "title": "SWAD: Domain Generalization by Seeking Flat Minima",
    "abstract": "Comments: NeurIPS 2021 camera-ready",
    "descriptor": "\nComments: NeurIPS 2021 camera-ready\n",
    "authors": [
      "Junbum Cha",
      "Sanghyuk Chun",
      "Kyungjae Lee",
      "Han-Cheol Cho",
      "Seunghyun Park",
      "Yunsung Lee",
      "Sungrae Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.08604"
  },
  {
    "id": "arXiv:2102.10570",
    "title": "Symbolic regression for scientific discovery: an application to wind  speed forecasting",
    "abstract": "Comments: 8 pages, 8 figs",
    "descriptor": "\nComments: 8 pages, 8 figs\n",
    "authors": [
      "Ismail Alaoui Abdellaoui",
      "Siamak Mehrkanoon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2102.10570"
  },
  {
    "id": "arXiv:2102.12002",
    "title": "Adversarial Robustness with Non-uniform Perturbations",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Ecenaz Erdemir",
      "Jeffrey Bickford",
      "Luca Melis",
      "Sergul Aydore"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.12002"
  },
  {
    "id": "arXiv:2102.12090",
    "title": "Continuous Mean-Covariance Bandits",
    "abstract": "Continuous Mean-Covariance Bandits",
    "descriptor": "",
    "authors": [
      "Yihan Du",
      "Siwei Wang",
      "Zhixuan Fang",
      "Longbo Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.12090"
  },
  {
    "id": "arXiv:2102.12094",
    "title": "Combinatorial Pure Exploration with Bottleneck Reward Function",
    "abstract": "Combinatorial Pure Exploration with Bottleneck Reward Function",
    "descriptor": "",
    "authors": [
      "Yihan Du",
      "Yuko Kuroki",
      "Wei Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.12094"
  },
  {
    "id": "arXiv:2102.12781",
    "title": "Do Input Gradients Highlight Discriminative Features?",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Harshay Shah",
      "Prateek Jain",
      "Praneeth Netrapalli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.12781"
  },
  {
    "id": "arXiv:2103.00112",
    "title": "Transformer in Transformer",
    "abstract": "Comments: Accepted by NeurIPS 2021",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Kai Han",
      "An Xiao",
      "Enhua Wu",
      "Jianyuan Guo",
      "Chunjing Xu",
      "Yunhe Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.00112"
  },
  {
    "id": "arXiv:2103.01286",
    "title": "Hyperbolic relaxation technique for solving the dispersive  Serre-Green-Naghdi Equations with topography",
    "abstract": "Comments: Accepted by Journal of Computational Physics - October 25, 2021",
    "descriptor": "\nComments: Accepted by Journal of Computational Physics - October 25, 2021\n",
    "authors": [
      "Jean-Luc Guermond",
      "Chris Kees",
      "Bojan Popov",
      "Eric Tovar"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2103.01286"
  },
  {
    "id": "arXiv:2103.01306",
    "title": "Scalable Scene Flow from Point Clouds in the Real World",
    "abstract": "Scalable Scene Flow from Point Clouds in the Real World",
    "descriptor": "",
    "authors": [
      "Philipp Jund",
      "Chris Sweeney",
      "Nichola Abdo",
      "Zhifeng Chen",
      "Jonathon Shlens"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.01306"
  },
  {
    "id": "arXiv:2103.01615",
    "title": "Mini-Batch Consistent Slot Set Encoder for Scalable Set Encoding",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Bruno Andreis",
      "Jeffrey Willette",
      "Juho Lee",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.01615"
  },
  {
    "id": "arXiv:2103.02227",
    "title": "Data Augmentation with Hierarchical SQL-to-Question Generation for  Cross-domain Text-to-SQL Parsing",
    "abstract": "Data Augmentation with Hierarchical SQL-to-Question Generation for  Cross-domain Text-to-SQL Parsing",
    "descriptor": "",
    "authors": [
      "Kun Wu",
      "Lijie Wang",
      "Zhenghua Li",
      "Ao Zhang",
      "Xinyan Xiao",
      "Hua Wu",
      "Min Zhang",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.02227"
  },
  {
    "id": "arXiv:2103.05154",
    "title": "Explanations in Autonomous Driving: A Survey",
    "abstract": "Comments: Accepted for publication in IEEE Transactions on Intelligent Transportation Systems",
    "descriptor": "\nComments: Accepted for publication in IEEE Transactions on Intelligent Transportation Systems\n",
    "authors": [
      "Daniel Omeiza",
      "Helena Webb",
      "Marina Jirotka",
      "Lars Kunze"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2103.05154"
  },
  {
    "id": "arXiv:2103.05342",
    "title": "Cut-Thumbnail: A Novel Data Augmentation for Convolutional Neural  Network",
    "abstract": "Comments: Accepted at ACM MM 2021",
    "descriptor": "\nComments: Accepted at ACM MM 2021\n",
    "authors": [
      "Tianshu Xie",
      "Xuan Cheng",
      "Minghui Liu",
      "Jiali Deng",
      "Xiaomin Wang",
      "Ming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.05342"
  },
  {
    "id": "arXiv:2103.05904",
    "title": "Combining Learning from Demonstration with Learning by Exploration to  Facilitate Contact-Rich Tasks",
    "abstract": "Comments: Accepted by the 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2021)",
    "descriptor": "\nComments: Accepted by the 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2021)\n",
    "authors": [
      "Yunlei Shi",
      "Zhaopeng Chen",
      "Yansong Wu",
      "Dimitri Henkel",
      "Sebastian Riedel",
      "Hongxu Liu",
      "Qian Feng",
      "Jianwei Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.05904"
  },
  {
    "id": "arXiv:2103.06511",
    "title": "Does the Magic of BERT Apply to Medical Code Assignment? A Quantitative  Study",
    "abstract": "Does the Magic of BERT Apply to Medical Code Assignment? A Quantitative  Study",
    "descriptor": "",
    "authors": [
      "Shaoxiong Ji",
      "Matti H\u00f6ltt\u00e4",
      "Pekka Marttinen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.06511"
  },
  {
    "id": "arXiv:2103.07450",
    "title": "Reaching Agreement in Competitive Microbial Systems",
    "abstract": "Comments: 21 pages, 6 figures",
    "descriptor": "\nComments: 21 pages, 6 figures\n",
    "authors": [
      "Victoria Andaur",
      "Janna Burman",
      "Matthias F\u00fcgger",
      "Manish Kushwaha",
      "Bilal Manssouri",
      "Thomas Nowak",
      "Joel Rybicki"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2103.07450"
  },
  {
    "id": "arXiv:2103.09480",
    "title": "Hessian Chain Bracketing",
    "abstract": "Hessian Chain Bracketing",
    "descriptor": "",
    "authors": [
      "Uwe Naumann",
      "Shubhaditya Burela"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.09480"
  },
  {
    "id": "arXiv:2103.12028",
    "title": "Quality at a Glance: An Audit of Web-Crawled Multilingual Datasets",
    "abstract": "Comments: Accepted at TACL; pre-MIT Press publication version",
    "descriptor": "\nComments: Accepted at TACL; pre-MIT Press publication version\n",
    "authors": [
      "Julia Kreutzer",
      "Isaac Caswell",
      "Lisa Wang",
      "Ahsan Wahab",
      "Daan van Esch",
      "Nasanbayar Ulzii-Orshikh",
      "Allahsera Tapo",
      "Nishant Subramani",
      "Artem Sokolov",
      "Claytone Sikasote",
      "Monang Setyawan",
      "Supheakmungkol Sarin",
      "Sokhar Samb",
      "Beno\u00eet Sagot",
      "Clara Rivera",
      "Annette Rios",
      "Isabel Papadimitriou",
      "Salomey Osei",
      "Pedro Ortiz Su\u00e1rez",
      "Iroro Orife",
      "Kelechi Ogueji",
      "Andre Niyongabo Rubungo",
      "Toan Q. Nguyen",
      "Mathias M\u00fcller",
      "Andr\u00e9 M\u00fcller",
      "Shamsuddeen Hassan Muhammad",
      "Nanda Muhammad",
      "Ayanda Mnyakeni",
      "Jamshidbek Mirzakhalov",
      "Tapiwanashe Matangira",
      "Colin Leong",
      "Nze Lawson",
      "Sneha Kudugunta",
      "Yacine Jernite",
      "Mathias Jenny",
      "Orhan Firat",
      "Bonaventure F. P. Dossou",
      "Sakhile Dlamini",
      "Nisansa de Silva",
      "Sakine \u00c7abuk Ball\u0131",
      "Stella Biderman",
      "Alessia Battisti",
      "Ahmed Baruwa",
      "Ankur Bapna",
      "Pallavi Baljekar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.12028"
  },
  {
    "id": "arXiv:2103.14712",
    "title": "Generating and Evaluating Explanations of Attended and Error-Inducing  Input Regions for VQA Models",
    "abstract": "Comments: Applied AI Letters, Wiley, 25 October 2021",
    "descriptor": "\nComments: Applied AI Letters, Wiley, 25 October 2021\n",
    "authors": [
      "Arijit Ray",
      "Michael Cogswell",
      "Xiao Lin",
      "Kamran Alipour",
      "Ajay Divakaran",
      "Yi Yao",
      "Giedrius Burachas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2103.14712"
  },
  {
    "id": "arXiv:2103.16075",
    "title": "Equivalence between Sobolev spaces of first-order dominating mixed  smoothness and unanchored ANOVA spaces on $\\mathbb{R}^d$",
    "abstract": "Equivalence between Sobolev spaces of first-order dominating mixed  smoothness and unanchored ANOVA spaces on $\\mathbb{R}^d$",
    "descriptor": "",
    "authors": [
      "Alexander D. Gilbert",
      "Frances Y. Kuo",
      "Ian H. Sloan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2103.16075"
  },
  {
    "id": "arXiv:2104.00428",
    "title": "Storchastic: A Framework for General Stochastic Automatic  Differentiation",
    "abstract": "Comments: 30 pages, 2 figures, 1 table, accepted in NeurIPS 2021",
    "descriptor": "\nComments: 30 pages, 2 figures, 1 table, accepted in NeurIPS 2021\n",
    "authors": [
      "Emile van Krieken",
      "Jakub M. Tomczak",
      "Annette ten Teije"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.00428"
  },
  {
    "id": "arXiv:2104.03015",
    "title": "RTIC: Residual Learning for Text and Image Composition using Graph  Convolutional Network",
    "abstract": "RTIC: Residual Learning for Text and Image Composition using Graph  Convolutional Network",
    "descriptor": "",
    "authors": [
      "Minchul Shin",
      "Yoonjae Cho",
      "Byungsoo Ko",
      "Geonmo Gu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.03015"
  },
  {
    "id": "arXiv:2104.03736",
    "title": "Towards Enabling Meta-Learning from Target Models",
    "abstract": "Towards Enabling Meta-Learning from Target Models",
    "descriptor": "",
    "authors": [
      "Su Lu",
      "Han-Jia Ye",
      "Le Gan",
      "De-Chuan Zhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.03736"
  },
  {
    "id": "arXiv:2104.04606",
    "title": "RaidaR: A Rich Annotated Image Dataset of Rainy Street Scenes",
    "abstract": "Comments: Presented in Second ICCV Workshop on Autonomous Vehicle Vision (AVVision), 2021. Website: this https URL",
    "descriptor": "\nComments: Presented in Second ICCV Workshop on Autonomous Vehicle Vision (AVVision), 2021. Website: this https URL\n",
    "authors": [
      "Jiongchao Jin",
      "Arezou Fatemi",
      "Wallace Lira",
      "Fenggen Yu",
      "Biao Leng",
      "Rui Ma",
      "Ali Mahdavi-Amiri",
      "Hao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.04606"
  },
  {
    "id": "arXiv:2104.05687",
    "title": "Semi-Infinite Linear Regression and Its Applications",
    "abstract": "Semi-Infinite Linear Regression and Its Applications",
    "descriptor": "",
    "authors": [
      "Paz Fink Shustin",
      "Haim Avron"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.05687"
  },
  {
    "id": "arXiv:2104.07472",
    "title": "Fabula Entropy Indexing: Objective Measures of Story Coherence",
    "abstract": "Fabula Entropy Indexing: Objective Measures of Story Coherence",
    "descriptor": "",
    "authors": [
      "Louis Castricato",
      "Spencer Frazier",
      "Jonathan Balloch",
      "Mark Riedl"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.07472"
  },
  {
    "id": "arXiv:2104.08642",
    "title": "Customized determination of stop words using Random Matrix Theory  approach",
    "abstract": "Customized determination of stop words using Random Matrix Theory  approach",
    "descriptor": "",
    "authors": [
      "Bogdan \u0141obodzi\u0144ski"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08642"
  },
  {
    "id": "arXiv:2104.11404",
    "title": "Reduced order models for Lagrangian hydrodynamics",
    "abstract": "Comments: 42 pages, 7 figure, 8 tables",
    "descriptor": "\nComments: 42 pages, 7 figure, 8 tables\n",
    "authors": [
      "Dylan Matthew Copeland",
      "Siu Wun Cheung",
      "Kevin Huynh",
      "Youngsoo Choi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.11404"
  },
  {
    "id": "arXiv:2105.01718",
    "title": "Spanners in randomly weighted graphs: independent edge lengths",
    "abstract": "Spanners in randomly weighted graphs: independent edge lengths",
    "descriptor": "",
    "authors": [
      "Alan Frieze",
      "Wesley Pegden"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2105.01718"
  },
  {
    "id": "arXiv:2105.04683",
    "title": "Deep Bandits Show-Off: Simple and Efficient Exploration with Deep  Networks",
    "abstract": "Deep Bandits Show-Off: Simple and Efficient Exploration with Deep  Networks",
    "descriptor": "",
    "authors": [
      "Rong Zhu",
      "Mattia Rigotti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.04683"
  },
  {
    "id": "arXiv:2105.08547",
    "title": "Partitioned Active Learning for Heterogeneous Systems",
    "abstract": "Partitioned Active Learning for Heterogeneous Systems",
    "descriptor": "",
    "authors": [
      "Cheolhei Lee",
      "Kaiwen Wang",
      "Jianguo Wu",
      "Wenjun Cai",
      "Xiaowei Yue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.08547"
  },
  {
    "id": "arXiv:2105.08866",
    "title": "Localization, Convexity, and Star Aggregation",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Suhas Vijaykumar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.08866"
  },
  {
    "id": "arXiv:2105.09384",
    "title": "Graph Sanitation with Application to Node Classification",
    "abstract": "Graph Sanitation with Application to Node Classification",
    "descriptor": "",
    "authors": [
      "Zhe Xu",
      "Boxin Du",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.09384"
  },
  {
    "id": "arXiv:2105.10018",
    "title": "Scalable Multi-Robot System for Non-myopic Spatial Sampling",
    "abstract": "Comments: Under review for Autonomous Robots (Journal), Spl. Issue on Robot Swarms in the Real World: from Design to Deployment",
    "descriptor": "\nComments: Under review for Autonomous Robots (Journal), Spl. Issue on Robot Swarms in the Real World: from Design to Deployment\n",
    "authors": [
      "Sandeep Manjanna",
      "M. Ani Hsieh",
      "Gregory Dudek"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.10018"
  },
  {
    "id": "arXiv:2105.11832",
    "title": "Estimating Redundancy in Clinical Text",
    "abstract": "Estimating Redundancy in Clinical Text",
    "descriptor": "",
    "authors": [
      "Thomas Searle",
      "Zina Ibrahim",
      "James Teo",
      "Richard JB Dobson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.11832"
  },
  {
    "id": "arXiv:2105.12827",
    "title": "Massive MIMO Adaptive Modulation and Coding Using Online Deep Learning  Algorithm",
    "abstract": "Comments: The paper has been submitted to the IEEE WCL journal and has 6 pages, 8 figures, and 1 table",
    "descriptor": "\nComments: The paper has been submitted to the IEEE WCL journal and has 6 pages, 8 figures, and 1 table\n",
    "authors": [
      "Evgeny Bobrov",
      "Dmitry Kropotov",
      "Hao Lu",
      "Danila Zaev"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.12827"
  },
  {
    "id": "arXiv:2105.12909",
    "title": "Deconditional Downscaling with Gaussian Processes",
    "abstract": "Deconditional Downscaling with Gaussian Processes",
    "descriptor": "",
    "authors": [
      "Siu Lun Chau",
      "Shahine Bouabid",
      "Dino Sejdinovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.12909"
  },
  {
    "id": "arXiv:2105.13954",
    "title": "A Gradient Method for Multilevel Optimization",
    "abstract": "Comments: NeurIPS 2021 camera-ready, 27 pages",
    "descriptor": "\nComments: NeurIPS 2021 camera-ready, 27 pages\n",
    "authors": [
      "Ryo Sato",
      "Mirai Tanaka",
      "Akiko Takeda"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13954"
  },
  {
    "id": "arXiv:2105.13977",
    "title": "Perturbation Theory for the Information Bottleneck",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Vudtiwat Ngampruetikorn",
      "David J. Schwab"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Information Theory (cs.IT)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2105.13977"
  },
  {
    "id": "arXiv:2105.14033",
    "title": "An Inexact Projected Gradient Method with Rounding and Lifting by  Nonlinear Programming for Solving Rank-One Semidefinite Relaxation of  Polynomial Optimization",
    "abstract": "Comments: Code available at this https URL",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Heng Yang",
      "Ling Liang",
      "Luca Carlone",
      "Kim-Chuan Toh"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14033"
  },
  {
    "id": "arXiv:2105.14039",
    "title": "Towards mental time travel: a hierarchical memory for reinforcement  learning agents",
    "abstract": "Comments: NeurIPS 2021; 10 pages main text; 29 pages total",
    "descriptor": "\nComments: NeurIPS 2021; 10 pages main text; 29 pages total\n",
    "authors": [
      "Andrew Kyle Lampinen",
      "Stephanie C.Y. Chan",
      "Andrea Banino",
      "Felix Hill"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.14039"
  },
  {
    "id": "arXiv:2105.14099",
    "title": "Bridging the Gap Between Practice and PAC-Bayes Theory in Few-Shot  Meta-Learning",
    "abstract": "Comments: Neural Information Processing Systems 2021",
    "descriptor": "\nComments: Neural Information Processing Systems 2021\n",
    "authors": [
      "Nan Ding",
      "Xi Chen",
      "Tomer Levinboim",
      "Sebastian Goodman",
      "Radu Soricut"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14099"
  },
  {
    "id": "arXiv:2105.14655",
    "title": "UNiTE: Unitary N-body Tensor Equivariant Network with Applications to  Quantum Chemistry",
    "abstract": "UNiTE: Unitary N-body Tensor Equivariant Network with Applications to  Quantum Chemistry",
    "descriptor": "",
    "authors": [
      "Zhuoran Qiao",
      "Anders S. Christensen",
      "Matthew Welborn",
      "Frederick R. Manby",
      "Anima Anandkumar",
      "Thomas F. Miller III"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.14655"
  },
  {
    "id": "arXiv:2105.14835",
    "title": "Towards Lower Bounds on the Depth of ReLU Neural Networks",
    "abstract": "Comments: Camera-ready version for NeurIPS 2021 conference",
    "descriptor": "\nComments: Camera-ready version for NeurIPS 2021 conference\n",
    "authors": [
      "Christoph Hertrich",
      "Amitabh Basu",
      "Marco Di Summa",
      "Martin Skutella"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Discrete Mathematics (cs.DM)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Combinatorics (math.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14835"
  },
  {
    "id": "arXiv:2105.14937",
    "title": "Safe Pontryagin Differentiable Programming",
    "abstract": "Comments: This paper has been accepted by NeurIPS 2021",
    "descriptor": "\nComments: This paper has been accepted by NeurIPS 2021\n",
    "authors": [
      "Wanxin Jin",
      "Shaoshuai Mou",
      "George J. Pappas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.14937"
  },
  {
    "id": "arXiv:2105.14995",
    "title": "Choose a Transformer: Fourier or Galerkin",
    "abstract": "Comments: 36 pages, 13 figures. Published as a conference paper at NeurIPS 2021",
    "descriptor": "\nComments: 36 pages, 13 figures. Published as a conference paper at NeurIPS 2021\n",
    "authors": [
      "Shuhao Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14995"
  },
  {
    "id": "arXiv:2105.15075",
    "title": "Not All Images are Worth 16x16 Words: Dynamic Transformers for Efficient  Image Recognition",
    "abstract": "Comments: Accepted by NeurIPS 2021",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Yulin Wang",
      "Rui Huang",
      "Shiji Song",
      "Zeyi Huang",
      "Gao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.15075"
  },
  {
    "id": "arXiv:2106.00306",
    "title": "Understanding peacefulness through the world news",
    "abstract": "Comments: 40 pages, 23 figures",
    "descriptor": "\nComments: 40 pages, 23 figures\n",
    "authors": [
      "Vasiliki Voukelatou",
      "Ioanna Miliou",
      "Fosca Giannotti",
      "Luca Pappalardo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00306"
  },
  {
    "id": "arXiv:2106.00651",
    "title": "Asymptotics of representation learning in finite Bayesian neural  networks",
    "abstract": "Comments: 13+28 pages, 4 figures; v3: extensive revision with improved exposition and new section on CNNs, accepted to NeurIPS 2021",
    "descriptor": "\nComments: 13+28 pages, 4 figures; v3: extensive revision with improved exposition and new section on CNNs, accepted to NeurIPS 2021\n",
    "authors": [
      "Jacob A. Zavatone-Veth",
      "Abdulkadir Canatar",
      "Benjamin S. Ruben",
      "Cengiz Pehlevan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00651"
  },
  {
    "id": "arXiv:2106.00769",
    "title": "Improving Compositionality of Neural Networks by Decoding  Representations to Inputs",
    "abstract": "Comments: 9 pages content",
    "descriptor": "\nComments: 9 pages content\n",
    "authors": [
      "Mike Wu",
      "Noah Goodman",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00769"
  },
  {
    "id": "arXiv:2106.01336",
    "title": "Improved Rates for Differentially Private Stochastic Convex Optimization  with Heavy-Tailed Data",
    "abstract": "Improved Rates for Differentially Private Stochastic Convex Optimization  with Heavy-Tailed Data",
    "descriptor": "",
    "authors": [
      "Gautam Kamath",
      "Xingtu Liu",
      "Huanyu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.01336"
  },
  {
    "id": "arXiv:2106.01551",
    "title": "Matching-Theory-Based Multi-User Cooperative Computing Framework",
    "abstract": "Matching-Theory-Based Multi-User Cooperative Computing Framework",
    "descriptor": "",
    "authors": [
      "Ya Zhou",
      "Guopeng Zhang",
      "Kezhi Wang",
      "Kun Yang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.01551"
  },
  {
    "id": "arXiv:2106.01609",
    "title": "Tail-to-Tail Non-Autoregressive Sequence Prediction for Chinese  Grammatical Error Correction",
    "abstract": "Comments: ACL 2021. Code: this https URL Fix the results of SpellGCN on Oct.26,2021",
    "descriptor": "\nComments: ACL 2021. Code: this https URL Fix the results of SpellGCN on Oct.26,2021\n",
    "authors": [
      "Piji Li",
      "Shuming Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01609"
  },
  {
    "id": "arXiv:2106.01862",
    "title": "Self-Supervised Learning of Event-Based Optical Flow with Spiking Neural  Networks",
    "abstract": "Comments: Accepted at NeurIPS 2021; code and additional material can be found at this https URL",
    "descriptor": "\nComments: Accepted at NeurIPS 2021; code and additional material can be found at this https URL\n",
    "authors": [
      "Jesse Hagenaars",
      "Federico Paredes-Vall\u00e9s",
      "Guido de Croon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.01862"
  },
  {
    "id": "arXiv:2106.01921",
    "title": "Sample Selection Bias in Evaluation of Prediction Performance of Causal  Models",
    "abstract": "Comments: 12 pages, 4 figures, 2 tables",
    "descriptor": "\nComments: 12 pages, 4 figures, 2 tables\n",
    "authors": [
      "James P. Long",
      "Min Jin Ha"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.01921"
  },
  {
    "id": "arXiv:2106.02034",
    "title": "DynamicViT: Efficient Vision Transformers with Dynamic Token  Sparsification",
    "abstract": "Comments: Accepted to NeurIPS 2021. Project page: this https URL",
    "descriptor": "\nComments: Accepted to NeurIPS 2021. Project page: this https URL\n",
    "authors": [
      "Yongming Rao",
      "Wenliang Zhao",
      "Benlin Liu",
      "Jiwen Lu",
      "Jie Zhou",
      "Cho-Jui Hsieh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02034"
  },
  {
    "id": "arXiv:2106.02105",
    "title": "A Little Robustness Goes a Long Way: Leveraging Robust Features for  Targeted Transfer Attacks",
    "abstract": "Comments: NeurIPS '21",
    "descriptor": "\nComments: NeurIPS '21\n",
    "authors": [
      "Jacob M. Springer",
      "Melanie Mitchell",
      "Garrett T. Kenyon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.02105"
  },
  {
    "id": "arXiv:2106.02126",
    "title": "A Closer Look at the Worst-case Behavior of Multi-armed Bandit  Algorithms",
    "abstract": "A Closer Look at the Worst-case Behavior of Multi-armed Bandit  Algorithms",
    "descriptor": "",
    "authors": [
      "Anand Kalvit",
      "Assaf Zeevi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02126"
  },
  {
    "id": "arXiv:2106.02159",
    "title": "On the implementation of a robust and efficient finite element-based  parallel solver for the compressible Navier-Stokes equations",
    "abstract": "On the implementation of a robust and efficient finite element-based  parallel solver for the compressible Navier-Stokes equations",
    "descriptor": "",
    "authors": [
      "Jean-Luc Guermond",
      "Martin Kronbichler",
      "Matthias Maier",
      "Bojan Popov",
      "Ignacio Tomas"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.02159"
  },
  {
    "id": "arXiv:2106.02520",
    "title": "CATs: Cost Aggregation Transformers for Visual Correspondence",
    "abstract": "Comments: Code and trained models are available at this https URL",
    "descriptor": "\nComments: Code and trained models are available at this https URL\n",
    "authors": [
      "Seokju Cho",
      "Sunghwan Hong",
      "Sangryul Jeon",
      "Yunsung Lee",
      "Kwanghoon Sohn",
      "Seungryong Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02520"
  },
  {
    "id": "arXiv:2106.02656",
    "title": "Approximating Nash Social Welfare under Binary XOS and Binary  Subadditive Valuations",
    "abstract": "Comments: 25 pages",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Siddharth Barman",
      "Paritosh Verma"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.02656"
  },
  {
    "id": "arXiv:2106.02720",
    "title": "An Even More Optimal Stochastic Optimization Algorithm: Minibatching and  Interpolation Learning",
    "abstract": "Comments: 24 pages",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Blake Woodworth",
      "Nathan Srebro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.02720"
  },
  {
    "id": "arXiv:2106.02734",
    "title": "Revisiting Hilbert-Schmidt Information Bottleneck for Adversarial  Robustness",
    "abstract": "Comments: Published as a conference paper at NeurIPS 2021",
    "descriptor": "\nComments: Published as a conference paper at NeurIPS 2021\n",
    "authors": [
      "Zifeng Wang",
      "Tong Jian",
      "Aria Masoomi",
      "Stratis Ioannidis",
      "Jennifer Dy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02734"
  },
  {
    "id": "arXiv:2106.02848",
    "title": "Numerical Composition of Differential Privacy",
    "abstract": "Comments: NeurIPS 2021 Spotlight",
    "descriptor": "\nComments: NeurIPS 2021 Spotlight\n",
    "authors": [
      "Sivakanth Gopi",
      "Yin Tat Lee",
      "Lukas Wutschitz"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02848"
  },
  {
    "id": "arXiv:2106.03194",
    "title": "Robust Implicit Networks via Non-Euclidean Contractions",
    "abstract": "Robust Implicit Networks via Non-Euclidean Contractions",
    "descriptor": "",
    "authors": [
      "Saber Jafarpour",
      "Alexander Davydov",
      "Anton V. Proskurnikov",
      "Francesco Bullo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.03194"
  },
  {
    "id": "arXiv:2106.03400",
    "title": "Believe What You See: Implicit Constraint Approach for Offline  Multi-Agent Reinforcement Learning",
    "abstract": "Comments: Accepted by NeurIPS2021. The first two authors contributed equally to the work",
    "descriptor": "\nComments: Accepted by NeurIPS2021. The first two authors contributed equally to the work\n",
    "authors": [
      "Yiqin Yang",
      "Xiaoteng Ma",
      "Chenghao Li",
      "Zewu Zheng",
      "Qiyuan Zhang",
      "Gao Huang",
      "Jun Yang",
      "Qianchuan Zhao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.03400"
  },
  {
    "id": "arXiv:2106.03668",
    "title": "Recovery Analysis for Plug-and-Play Priors using the Restricted  Eigenvalue Condition",
    "abstract": "Comments: 27 pages, 13 figures",
    "descriptor": "\nComments: 27 pages, 13 figures\n",
    "authors": [
      "Jiaming Liu",
      "M. Salman Asif",
      "Brendt Wohlberg",
      "Ulugbek S. Kamilov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.03668"
  },
  {
    "id": "arXiv:2106.03696",
    "title": "Dynamics of Stochastic Momentum Methods on Large-scale, Quadratic Models",
    "abstract": "Comments: 39 pages, 7 figures",
    "descriptor": "\nComments: 39 pages, 7 figures\n",
    "authors": [
      "Courtney Paquette",
      "Elliot Paquette"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.03696"
  },
  {
    "id": "arXiv:2106.03831",
    "title": "Counterfactual Maximum Likelihood Estimation for Training Deep Networks",
    "abstract": "Comments: 10 pages, 2 figures, accepted to NeurIPS 2021",
    "descriptor": "\nComments: 10 pages, 2 figures, accepted to NeurIPS 2021\n",
    "authors": [
      "Xinyi Wang",
      "Wenhu Chen",
      "Michael Saxon",
      "William Yang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.03831"
  },
  {
    "id": "arXiv:2106.03894",
    "title": "Differentiable Quality Diversity",
    "abstract": "Comments: Accepted to NeurIPS 2021 (oral presentation)",
    "descriptor": "\nComments: Accepted to NeurIPS 2021 (oral presentation)\n",
    "authors": [
      "Matthew C. Fontaine",
      "Stefanos Nikolaidis"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.03894"
  },
  {
    "id": "arXiv:2106.04538",
    "title": "What Makes Multi-modal Learning Better than Single (Provably)",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Yu Huang",
      "Chenzhuang Du",
      "Zihui Xue",
      "Xuanyao Chen",
      "Hang Zhao",
      "Longbo Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.04538"
  },
  {
    "id": "arXiv:2106.05933",
    "title": "PARP: Prune, Adjust and Re-Prune for Self-Supervised Speech Recognition",
    "abstract": "PARP: Prune, Adjust and Re-Prune for Self-Supervised Speech Recognition",
    "descriptor": "",
    "authors": [
      "Cheng-I Jeff Lai",
      "Yang Zhang",
      "Alexander H. Liu",
      "Shiyu Chang",
      "Yi-Lun Liao",
      "Yung-Sung Chuang",
      "Kaizhi Qian",
      "Sameer Khurana",
      "David Cox",
      "James Glass"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.05933"
  },
  {
    "id": "arXiv:2106.05956",
    "title": "Beyond BatchNorm: Towards a Unified Understanding of Normalization in  Deep Learning",
    "abstract": "Comments: Accepted at NeurIPS 2021",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Ekdeep Singh Lubana",
      "Robert P. Dick",
      "Hidenori Tanaka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.05956"
  },
  {
    "id": "arXiv:2106.06048",
    "title": "Optimizing Bayesian Recurrent Neural Networks on an FPGA-based  Accelerator",
    "abstract": "Comments: Accepted to FPT'21. Martin Ferianc and Zhiqiang Que share an equal contribution",
    "descriptor": "\nComments: Accepted to FPT'21. Martin Ferianc and Zhiqiang Que share an equal contribution\n",
    "authors": [
      "Martin Ferianc",
      "Zhiqiang Que",
      "Hongxiang Fan",
      "Wayne Luk",
      "Miguel Rodrigues"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06048"
  },
  {
    "id": "arXiv:2106.06426",
    "title": "Catch-A-Waveform: Learning to Generate Audio from a Single Short Example",
    "abstract": "Catch-A-Waveform: Learning to Generate Audio from a Single Short Example",
    "descriptor": "",
    "authors": [
      "Gal Greshler",
      "Tamar Rott Shaham",
      "Tomer Michaeli"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.06426"
  },
  {
    "id": "arXiv:2106.06762",
    "title": "Solving Graph-based Public Good Games with Tree Search and Imitation  Learning",
    "abstract": "Comments: To appear in Proceedings of 35th Conference on Neural Information Processing Systems (NeurIPS 2021)",
    "descriptor": "\nComments: To appear in Proceedings of 35th Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Victor-Alexandru Darvariu",
      "Stephen Hailes",
      "Mirco Musolesi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.06762"
  },
  {
    "id": "arXiv:2106.07807",
    "title": "Dynamic Distillation Network for Cross-Domain Few-Shot Recognition with  Unlabeled Data",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Ashraful Islam",
      "Chun-Fu Chen",
      "Rameswar Panda",
      "Leonid Karlinsky",
      "Rogerio Feris",
      "Richard J. Radke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07807"
  },
  {
    "id": "arXiv:2106.07841",
    "title": "Randomized Exploration for Reinforcement Learning with General Value  Function Approximation",
    "abstract": "Comments: 32 page, 5 figures, in Proceedings of the 38th International Conference on Machine Learning, PMLR 139, 2021",
    "descriptor": "\nComments: 32 page, 5 figures, in Proceedings of the 38th International Conference on Machine Learning, PMLR 139, 2021\n",
    "authors": [
      "Haque Ishfaq",
      "Qiwen Cui",
      "Viet Nguyen",
      "Alex Ayoub",
      "Zhuoran Yang",
      "Zhaoran Wang",
      "Doina Precup",
      "Lin F. Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07841"
  },
  {
    "id": "arXiv:2106.07936",
    "title": "Modeling morphology with Linear Discriminative Learning: considerations  and design choices",
    "abstract": "Comments: 38 pages, 5 figures, 10 tables; minor changes of phrasing, footnotes added",
    "descriptor": "\nComments: 38 pages, 5 figures, 10 tables; minor changes of phrasing, footnotes added\n",
    "authors": [
      "Maria Heitmeier",
      "Yu-Ying Chuang",
      "R. Harald Baayen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.07936"
  },
  {
    "id": "arXiv:2106.07998",
    "title": "Revisiting the Calibration of Modern Neural Networks",
    "abstract": "Comments: 35th Conference on Neural Information Processing Systems (NeurIPS 2021)",
    "descriptor": "\nComments: 35th Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Matthias Minderer",
      "Josip Djolonga",
      "Rob Romijnders",
      "Frances Hubis",
      "Xiaohua Zhai",
      "Neil Houlsby",
      "Dustin Tran",
      "Mario Lucic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.07998"
  },
  {
    "id": "arXiv:2106.08233",
    "title": "Spot the Difference: Detection of Topological Changes via Geometric  Alignment",
    "abstract": "Comments: Accepted to 35th Conference on Neural Information Processing Systems (NeurIPS 2021). Camera-ready version. code repository: this https URL",
    "descriptor": "\nComments: Accepted to 35th Conference on Neural Information Processing Systems (NeurIPS 2021). Camera-ready version. code repository: this https URL\n",
    "authors": [
      "Steffen Czolbe",
      "Aasa Feragen",
      "Oswin Krause"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.08233"
  },
  {
    "id": "arXiv:2106.08615",
    "title": "EdgeConv with Attention Module for Monocular Depth Estimation",
    "abstract": "Comments: Accepted to IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2022",
    "descriptor": "\nComments: Accepted to IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2022\n",
    "authors": [
      "Minhyeok Lee",
      "Sangwon Hwang",
      "Chaewon Park",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08615"
  },
  {
    "id": "arXiv:2106.08762",
    "title": "Shape from Blur: Recovering Textured 3D Shape and Motion of Fast Moving  Objects",
    "abstract": "Comments: Accepted to 35th Conference on Neural Information Processing Systems (NeurIPS 2021)",
    "descriptor": "\nComments: Accepted to 35th Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Denys Rozumnyi",
      "Martin R. Oswald",
      "Vittorio Ferrari",
      "Marc Pollefeys"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08762"
  },
  {
    "id": "arXiv:2106.09191",
    "title": "The Biot-Stokes coupling using total pressure: formulation, analysis and  application to interfacial flow in the eye",
    "abstract": "Comments: 36 pages",
    "descriptor": "\nComments: 36 pages\n",
    "authors": [
      "Ricardo Ruiz-Baier",
      "Matteo Taffetani",
      "Hans D. Westermeyer",
      "Ivan Yotov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.09191"
  },
  {
    "id": "arXiv:2106.09884",
    "title": "Batch Multi-Fidelity Bayesian Optimization with Deep Auto-Regressive  Networks",
    "abstract": "Batch Multi-Fidelity Bayesian Optimization with Deep Auto-Regressive  Networks",
    "descriptor": "",
    "authors": [
      "Shibo Li",
      "Robert M. Kirby",
      "Shandian Zhe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09884"
  },
  {
    "id": "arXiv:2106.09993",
    "title": "Accumulative Poisoning Attacks on Real-time Data",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Tianyu Pang",
      "Xiao Yang",
      "Yinpeng Dong",
      "Hang Su",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09993"
  },
  {
    "id": "arXiv:2106.10812",
    "title": "ToAlign: Task-oriented Alignment for Unsupervised Domain Adaptation",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Guoqiang Wei",
      "Cuiling Lan",
      "Wenjun Zeng",
      "Zhizheng Zhang",
      "Zhibo Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10812"
  },
  {
    "id": "arXiv:2106.11113",
    "title": "Matrix Encoding Networks for Neural Combinatorial Optimization",
    "abstract": "Comments: Accepted at NeurIPS 2021",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Yeong-Dae Kwon",
      "Jinho Choo",
      "Iljoo Yoon",
      "Minah Park",
      "Duwon Park",
      "Youngjune Gwon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11113"
  },
  {
    "id": "arXiv:2106.11378",
    "title": "Dual-port grid-forming control of MMCs and its applications to grids of  grids",
    "abstract": "Dual-port grid-forming control of MMCs and its applications to grids of  grids",
    "descriptor": "",
    "authors": [
      "Dominic Gro\u00df",
      "S\u00e1nchez-S\u00e1nchez",
      "Eduardo Prieto-Araujo",
      "Oriol Gomis-Bellmunt"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.11378"
  },
  {
    "id": "arXiv:2106.11535",
    "title": "Particle Cloud Generation with Message Passing Generative Adversarial  Networks",
    "abstract": "Comments: 14 pages, 4 figures, 2 tables, and an 8 page appendix",
    "descriptor": "\nComments: 14 pages, 4 figures, 2 tables, and an 8 page appendix\n",
    "authors": [
      "Raghav Kansal",
      "Javier Duarte",
      "Hao Su",
      "Breno Orzari",
      "Thiago Tomei",
      "Maurizio Pierini",
      "Mary Touranakou",
      "Jean-Roch Vlimant",
      "Dimitrios Gunopulos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ],
    "url": "https://arxiv.org/abs/2106.11535"
  },
  {
    "id": "arXiv:2106.13033",
    "title": "A Transformer-based Cross-modal Fusion Model with Adversarial Training  for VQA Challenge 2021",
    "abstract": "Comments: CVPR 2021 Workshop: Visual Question Answering (VQA) Challenge",
    "descriptor": "\nComments: CVPR 2021 Workshop: Visual Question Answering (VQA) Challenge\n",
    "authors": [
      "Ke-Han Lu",
      "Bo-Han Fang",
      "Kuan-Yu Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.13033"
  },
  {
    "id": "arXiv:2106.13695",
    "title": "CADDA: Class-wise Automatic Differentiable Data Augmentation for EEG  Signals",
    "abstract": "CADDA: Class-wise Automatic Differentiable Data Augmentation for EEG  Signals",
    "descriptor": "",
    "authors": [
      "C\u00e9dric Rommel",
      "Thomas Moreau",
      "Joseph Paillard",
      "Alexandre Gramfort"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13695"
  },
  {
    "id": "arXiv:2106.13703",
    "title": "Task-Driven Out-of-Distribution Detection with Statistical Guarantees  for Robot Learning",
    "abstract": "Task-Driven Out-of-Distribution Detection with Statistical Guarantees  for Robot Learning",
    "descriptor": "",
    "authors": [
      "Alec Farid",
      "Sushant Veer",
      "Anirudha Majumdar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.13703"
  },
  {
    "id": "arXiv:2106.13906",
    "title": "Compositional Reinforcement Learning from Logical Specifications",
    "abstract": "Compositional Reinforcement Learning from Logical Specifications",
    "descriptor": "",
    "authors": [
      "Kishor Jothimurugan",
      "Suguman Bansal",
      "Osbert Bastani",
      "Rajeev Alur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.13906"
  },
  {
    "id": "arXiv:2106.14308",
    "title": "Concentration of Contractive Stochastic Approximation and Reinforcement  Learning",
    "abstract": "Comments: 17 pages, Submitted to Stochastic Systems",
    "descriptor": "\nComments: 17 pages, Submitted to Stochastic Systems\n",
    "authors": [
      "Siddharth Chandak",
      "Vivek S. Borkar",
      "Parth Dodhia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.14308"
  },
  {
    "id": "arXiv:2106.14881",
    "title": "Early Convolutions Help Transformers See Better",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Tete Xiao",
      "Mannat Singh",
      "Eric Mintun",
      "Trevor Darrell",
      "Piotr Doll\u00e1r",
      "Ross Girshick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.14881"
  },
  {
    "id": "arXiv:2106.14952",
    "title": "Adversarial Robustness of Streaming Algorithms through Importance  Sampling",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Vladimir Braverman",
      "Avinatan Hassidim",
      "Yossi Matias",
      "Mariano Schain",
      "Sandeep Silwal",
      "Samson Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.14952"
  },
  {
    "id": "arXiv:2106.15087",
    "title": "O2O-Afford: Annotation-Free Large-Scale Object-Object Affordance  Learning",
    "abstract": "Comments: to appear in CoRL 2021",
    "descriptor": "\nComments: to appear in CoRL 2021\n",
    "authors": [
      "Kaichun Mo",
      "Yuzhe Qin",
      "Fanbo Xiang",
      "Hao Su",
      "Leonidas Guibas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.15087"
  },
  {
    "id": "arXiv:2106.15482",
    "title": "Personalized Federated Learning with Gaussian Processes",
    "abstract": "Personalized Federated Learning with Gaussian Processes",
    "descriptor": "",
    "authors": [
      "Idan Achituve",
      "Aviv Shamsian",
      "Aviv Navon",
      "Gal Chechik",
      "Ethan Fetaya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.15482"
  },
  {
    "id": "arXiv:2106.15905",
    "title": "Faithful Edge Federated Learning: Scalability and Privacy",
    "abstract": "Comments: Under review by JSAC",
    "descriptor": "\nComments: Under review by JSAC\n",
    "authors": [
      "Meng Zhang",
      "Ermin Wei",
      "Randall Berry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.15905"
  },
  {
    "id": "arXiv:2106.16048",
    "title": "Resilient UAV Swarm Communications with Graph Convolutional Neural  Network",
    "abstract": "Resilient UAV Swarm Communications with Graph Convolutional Neural  Network",
    "descriptor": "",
    "authors": [
      "Zhiyu Mou",
      "Feifei Gao",
      "Jun Liu",
      "Qihui Wu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.16048"
  },
  {
    "id": "arXiv:2107.00645",
    "title": "Global Filter Networks for Image Classification",
    "abstract": "Comments: Accepted to NeurIPS 2021. Project page: this https URL",
    "descriptor": "\nComments: Accepted to NeurIPS 2021. Project page: this https URL\n",
    "authors": [
      "Yongming Rao",
      "Wenliang Zhao",
      "Zheng Zhu",
      "Jiwen Lu",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00645"
  },
  {
    "id": "arXiv:2107.01105",
    "title": "Memory Efficient Meta-Learning with Large Images",
    "abstract": "Memory Efficient Meta-Learning with Large Images",
    "descriptor": "",
    "authors": [
      "John Bronskill",
      "Daniela Massiceti",
      "Massimiliano Patacchiola",
      "Katja Hofmann",
      "Sebastian Nowozin",
      "Richard E. Turner"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01105"
  },
  {
    "id": "arXiv:2107.01163",
    "title": "Unveiling the structure of wide flat minima in neural networks",
    "abstract": "Comments: 15 pages, 8 figures",
    "descriptor": "\nComments: 15 pages, 8 figures\n",
    "authors": [
      "Carlo Baldassi",
      "Clarissa Lauditi",
      "Enrico M. Malatesta",
      "Gabriele Perugini",
      "Riccardo Zecchina"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2107.01163"
  },
  {
    "id": "arXiv:2107.01214",
    "title": "Truncated Marginal Neural Ratio Estimation",
    "abstract": "Comments: 10 pages. 27 pages with references and supplemental material. Implementation of experiments at this https URL Ready-to-use implementation of underlying algorithm at this https URL Accepted at NeurIPS 2021",
    "descriptor": "\nComments: 10 pages. 27 pages with references and supplemental material. Implementation of experiments at this https URL Ready-to-use implementation of underlying algorithm at this https URL Accepted at NeurIPS 2021\n",
    "authors": [
      "Benjamin Kurt Miller",
      "Alex Cole",
      "Patrick Forr\u00e9",
      "Gilles Louppe",
      "Christoph Weniger"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.01214"
  },
  {
    "id": "arXiv:2107.01264",
    "title": "Beyond Value-Function Gaps: Improved Instance-Dependent Regret Bounds  for Episodic Reinforcement Learning",
    "abstract": "Beyond Value-Function Gaps: Improved Instance-Dependent Regret Bounds  for Episodic Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Christoph Dann",
      "Teodor V. Marinov",
      "Mehryar Mohri",
      "Julian Zimmert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01264"
  },
  {
    "id": "arXiv:2107.02968",
    "title": "Deep Extrapolation for Attribute-Enhanced Generation",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Alvin Chan",
      "Ali Madani",
      "Ben Krause",
      "Nikhil Naik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2107.02968"
  },
  {
    "id": "arXiv:2107.03463",
    "title": "CHASE: Robust Visual Tracking via Cell-Level Differentiable Neural  Architecture Search",
    "abstract": "Comments: The first two authors contributed equally to this work. Accepted manuscript in BMVC 2021",
    "descriptor": "\nComments: The first two authors contributed equally to this work. Accepted manuscript in BMVC 2021\n",
    "authors": [
      "Seyed Mojtaba Marvasti-Zadeh",
      "Javad Khaghani",
      "Li Cheng",
      "Hossein Ghanei-Yakhdan",
      "Shohreh Kasaei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.03463"
  },
  {
    "id": "arXiv:2107.03554",
    "title": "Automated Object Behavioral Feature Extraction for Potential Risk  Analysis based on Video Sensor",
    "abstract": "Comments: 6 pages, 9 figures",
    "descriptor": "\nComments: 6 pages, 9 figures\n",
    "authors": [
      "Byeongjoon Noh",
      "Dongho Ka",
      "Wonjun Noh",
      "Hwasoo Yeo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.03554"
  },
  {
    "id": "arXiv:2107.03964",
    "title": "CamTuner: Reinforcement-Learning based System for Camera Parameter  Tuning to enhance Analytics",
    "abstract": "CamTuner: Reinforcement-Learning based System for Camera Parameter  Tuning to enhance Analytics",
    "descriptor": "",
    "authors": [
      "Sibendu Paul",
      "Kunal Rao",
      "Giuseppe Coviello",
      "Murugan Sankaradas",
      "Oliver Po",
      "Y. Charlie Hu",
      "Srimat T. Chakradhar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.03964"
  },
  {
    "id": "arXiv:2107.04150",
    "title": "MCMC Variational Inference via Uncorrected Hamiltonian Annealing",
    "abstract": "Comments: Published at NeurIPS (2021)",
    "descriptor": "\nComments: Published at NeurIPS (2021)\n",
    "authors": [
      "Tomas Geffner",
      "Justin Domke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.04150"
  },
  {
    "id": "arXiv:2107.04616",
    "title": "A deep convolutional neural network that is invariant to time rescaling",
    "abstract": "A deep convolutional neural network that is invariant to time rescaling",
    "descriptor": "",
    "authors": [
      "Brandon G. Jacques",
      "Zoran Tiganj",
      "Aakash Sarkar",
      "Marc W. Howard",
      "Per B. Sederberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.04616"
  },
  {
    "id": "arXiv:2107.05330",
    "title": "Personalized Federated Learning via Maximizing Correlation with Sparse  and Hierarchical Extensions",
    "abstract": "Personalized Federated Learning via Maximizing Correlation with Sparse  and Hierarchical Extensions",
    "descriptor": "",
    "authors": [
      "Yinchuan Li",
      "Xiaofeng Liu",
      "Xu Zhang",
      "Yunfeng Shao",
      "Qing Wang",
      "Yanhui Geng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05330"
  },
  {
    "id": "arXiv:2107.05466",
    "title": "Learning and Adaptation for Millimeter-Wave Beam Tracking and Training:  a Dual Timescale Variational Framework",
    "abstract": "Comments: accepted for publication in IEEE Journal on Selected Areas in Communications 2021",
    "descriptor": "\nComments: accepted for publication in IEEE Journal on Selected Areas in Communications 2021\n",
    "authors": [
      "Muddassar Hussain",
      "Nicolo Michelusi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.05466"
  },
  {
    "id": "arXiv:2107.05945",
    "title": "CentripetalText: An Efficient Text Instance Representation for Scene  Text Detection",
    "abstract": "Comments: Accepted by NeurIPS 2021",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Tao Sheng",
      "Jie Chen",
      "Zhouhui Lian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05945"
  },
  {
    "id": "arXiv:2107.08037",
    "title": "CCVS: Context-aware Controllable Video Synthesis",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Guillaume Le Moing",
      "Jean Ponce",
      "Cordelia Schmid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.08037"
  },
  {
    "id": "arXiv:2107.09584",
    "title": "Active 3D Shape Reconstruction from Vision and Touch",
    "abstract": "Active 3D Shape Reconstruction from Vision and Touch",
    "descriptor": "",
    "authors": [
      "Edward J. Smith",
      "David Meger",
      "Luis Pineda",
      "Roberto Calandra",
      "Jitendra Malik",
      "Adriana Romero",
      "Michal Drozdzal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.09584"
  },
  {
    "id": "arXiv:2107.12211",
    "title": "On The Impact of Client Sampling on Federated Learning Convergence",
    "abstract": "On The Impact of Client Sampling on Federated Learning Convergence",
    "descriptor": "",
    "authors": [
      "Yann Fraboni",
      "Richard Vidal",
      "Laetitia Kameni",
      "Marco Lorenzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.12211"
  },
  {
    "id": "arXiv:2107.12479",
    "title": "Terrain-perception-free Quadrupedal Spinning Locomotion on Versatile  Terrains: Modeling, Analysis, and Experimental Validation",
    "abstract": "Terrain-perception-free Quadrupedal Spinning Locomotion on Versatile  Terrains: Modeling, Analysis, and Experimental Validation",
    "descriptor": "",
    "authors": [
      "Hongwu Zhu",
      "Dong Wang",
      "Nathan Boyd",
      "Ziyi Zhou",
      "Lecheng Ruan",
      "Aidong Zhang",
      "Ning Ding",
      "Ye Zhao",
      "Jianwen Luo"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.12479"
  },
  {
    "id": "arXiv:2107.13440",
    "title": "Study on Precoding Optimization Algorithms in Massive MIMO System with  Multi-Antenna Users",
    "abstract": "Comments: The work was presented at the MOTOR 2021 conference. It consists of 15 pages, 4 figures, 3 tables. arXiv admin note: text overlap with arXiv:2107.00853",
    "descriptor": "\nComments: The work was presented at the MOTOR 2021 conference. It consists of 15 pages, 4 figures, 3 tables. arXiv admin note: text overlap with arXiv:2107.00853\n",
    "authors": [
      "Evgeny Bobrov",
      "Dmitry Kropotov",
      "Sergey Troshin",
      "Danila Zaev"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.13440"
  },
  {
    "id": "arXiv:2108.01490",
    "title": "Extending dynamic mode decomposition to data from multiple outputs",
    "abstract": "Comments: Submitted to the American Control Conference 2022",
    "descriptor": "\nComments: Submitted to the American Control Conference 2022\n",
    "authors": [
      "Nibodh Boddupalli"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2108.01490"
  },
  {
    "id": "arXiv:2108.02492",
    "title": "Symplectic integration of learned Hamiltonian systems",
    "abstract": "Symplectic integration of learned Hamiltonian systems",
    "descriptor": "",
    "authors": [
      "Christian Offen",
      "Sina Ober-Bl\u00f6baum"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.02492"
  },
  {
    "id": "arXiv:2108.03414",
    "title": "Vision Transformer for femur fracture classification",
    "abstract": "Comments: Under consideration at Artificial Intelligence in Medicine",
    "descriptor": "\nComments: Under consideration at Artificial Intelligence in Medicine\n",
    "authors": [
      "Leonardo Tanzi",
      "Andrea Audisio",
      "Giansalvo Cirrincione",
      "Alessandro Aprato",
      "Enrico Vezzetti"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.03414"
  },
  {
    "id": "arXiv:2108.04105",
    "title": "Towards better data discovery and collection with flow-based programming",
    "abstract": "Comments: Extended version. Short version is accepted to Data-Centric AI Workshop, NeurIPS 2021",
    "descriptor": "\nComments: Extended version. Short version is accepted to Data-Centric AI Workshop, NeurIPS 2021\n",
    "authors": [
      "Andrei Paleyes",
      "Christian Cabrera",
      "Neil D. Lawrence"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.04105"
  },
  {
    "id": "arXiv:2108.05673",
    "title": "An Extreme Learning Machine-Based System Frequency Nadir Constraint  Linearization Method",
    "abstract": "Comments: This paper has been submitted to the CSEE Journal of Power and Energy Systems",
    "descriptor": "\nComments: This paper has been submitted to the CSEE Journal of Power and Energy Systems\n",
    "authors": [
      "Likai Liu",
      "Zechun Hu",
      "Nikhil Pathak",
      "Haocheng Luo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.05673"
  },
  {
    "id": "arXiv:2108.05818",
    "title": "PatrickStar: Parallel Training of Pre-trained Models via Chunk-based  Memory Management",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Jiarui Fang",
      "Yang Yu",
      "Zilin Zhu",
      "Shenggui Li",
      "Yang You",
      "Jie Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2108.05818"
  },
  {
    "id": "arXiv:2108.06458",
    "title": "Cross-Modal Graph with Meta Concepts for Video Captioning",
    "abstract": "Cross-Modal Graph with Meta Concepts for Video Captioning",
    "descriptor": "",
    "authors": [
      "Hao Wang",
      "Guosheng Lin",
      "Steven C. H. Hoi",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.06458"
  },
  {
    "id": "arXiv:2108.06514",
    "title": "Active Assessment of Prediction Services as Accuracy Surface Over  Attribute Combinations",
    "abstract": "Comments: NeurIPS 2021; Code and dataset at: this https URL; 19 pages",
    "descriptor": "\nComments: NeurIPS 2021; Code and dataset at: this https URL; 19 pages\n",
    "authors": [
      "Vihari Piratla",
      "Soumen Chakrabarty",
      "Sunita Sarawagi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.06514"
  },
  {
    "id": "arXiv:2108.07063",
    "title": "Multistream Graph Attention Networks for Wind Speed Forecasting",
    "abstract": "Comments: 8 pages, 5 figures",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Dogan Aykas",
      "Siamak Mehrkanoon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.07063"
  },
  {
    "id": "arXiv:2108.07994",
    "title": "EviDR: Evidence-Emphasized Discrete Reasoning for Reasoning Machine  Reading Comprehension",
    "abstract": "Comments: 12 pages, 1 figure and 5 tables",
    "descriptor": "\nComments: 12 pages, 1 figure and 5 tables\n",
    "authors": [
      "Yongwei Zhou",
      "Junwei Bao",
      "Haipeng Sun",
      "Jiahui Liang",
      "Youzheng Wu",
      "Xiaodong He",
      "Bowen Zhou",
      "Tiejun Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.07994"
  },
  {
    "id": "arXiv:2108.08597",
    "title": "Beyond NED: Fast and Effective Search Space Reduction for Complex  Question Answering over Knowledge Bases",
    "abstract": "Comments: WSDM 2022 Research Track Long Paper (Extended version)",
    "descriptor": "\nComments: WSDM 2022 Research Track Long Paper (Extended version)\n",
    "authors": [
      "Philipp Christmann",
      "Rishiraj Saha Roy",
      "Gerhard Weikum"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.08597"
  },
  {
    "id": "arXiv:2108.08728",
    "title": "Counterfactual Attention Learning for Fine-Grained Visual Categorization  and Re-identification",
    "abstract": "Comments: Accepted to ICCV 2021",
    "descriptor": "\nComments: Accepted to ICCV 2021\n",
    "authors": [
      "Yongming Rao",
      "Guangyi Chen",
      "Jiwen Lu",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.08728"
  },
  {
    "id": "arXiv:2108.08887",
    "title": "Risk Bounds and Calibration for a Smart Predict-then-Optimize Method",
    "abstract": "Comments: To appear in NeurIPS 2021",
    "descriptor": "\nComments: To appear in NeurIPS 2021\n",
    "authors": [
      "Heyuan Liu",
      "Paul Grigas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.08887"
  },
  {
    "id": "arXiv:2108.11575",
    "title": "Shifted Chunk Transformer for Spatio-Temporal Representational Learning",
    "abstract": "Comments: 15 pages, 3 figures",
    "descriptor": "\nComments: 15 pages, 3 figures\n",
    "authors": [
      "Xuefan Zha",
      "Wentao Zhu",
      "Tingxun Lv",
      "Sen Yang",
      "Ji Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.11575"
  },
  {
    "id": "arXiv:2108.13157",
    "title": "DQLEL: Deep Q-Learning for Energy-Optimized LoS/NLoS UWB Node Selection",
    "abstract": "DQLEL: Deep Q-Learning for Energy-Optimized LoS/NLoS UWB Node Selection",
    "descriptor": "",
    "authors": [
      "Zohreh Hajiakhondi-Meybodi",
      "Arash Mohammadi",
      "Ming Hou",
      "Konstantinos N. Plataniotis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2108.13157"
  },
  {
    "id": "arXiv:2109.01116",
    "title": "An Empirical Study of Graph Contrastive Learning",
    "abstract": "Comments: Accepted to NeurIPS 2021 (Datasets and Benchmarks track). Open-sourced library at this https URL",
    "descriptor": "\nComments: Accepted to NeurIPS 2021 (Datasets and Benchmarks track). Open-sourced library at this https URL\n",
    "authors": [
      "Yanqiao Zhu",
      "Yichen Xu",
      "Qiang Liu",
      "Shu Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2109.01116"
  },
  {
    "id": "arXiv:2109.01801",
    "title": "Dual Transfer Learning for Event-based End-task Prediction via Pluggable  Event to Image Translation",
    "abstract": "Comments: ICCV 2021 (with fixed references in this version)",
    "descriptor": "\nComments: ICCV 2021 (with fixed references in this version)\n",
    "authors": [
      "Lin Wang",
      "Yujeong Chae",
      "Kuk-Jin Yoon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.01801"
  },
  {
    "id": "arXiv:2109.01902",
    "title": "Barycentric-alignment and invertibility for domain generalization",
    "abstract": "Comments: Title changes",
    "descriptor": "\nComments: Title changes\n",
    "authors": [
      "Boyang Lyu",
      "Thuan Nguyen",
      "Prakash Ishwar",
      "Matthias Scheutz",
      "Shuchin Aeron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.01902"
  },
  {
    "id": "arXiv:2109.04405",
    "title": "An Accelerated Proximal Gradient-based Model Predictive Control  Algorithm",
    "abstract": "An Accelerated Proximal Gradient-based Model Predictive Control  Algorithm",
    "descriptor": "",
    "authors": [
      "Jia Wang",
      "Ying Yang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.04405"
  },
  {
    "id": "arXiv:2109.04468",
    "title": "Leveraging Local Domains for Image-to-Image Translation",
    "abstract": "Comments: Submitted to conference; added supplementary material",
    "descriptor": "\nComments: Submitted to conference; added supplementary material\n",
    "authors": [
      "Anthony Dell'Eva",
      "Fabio Pizzati",
      "Massimo Bertozzi",
      "Raoul de Charette"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04468"
  },
  {
    "id": "arXiv:2109.04617",
    "title": "Efficiently Identifying Task Groupings for Multi-Task Learning",
    "abstract": "Comments: In NeurIPS 2021 (spotlight). Code is available at this https URL",
    "descriptor": "\nComments: In NeurIPS 2021 (spotlight). Code is available at this https URL\n",
    "authors": [
      "Christopher Fifty",
      "Ehsan Amid",
      "Zhe Zhao",
      "Tianhe Yu",
      "Rohan Anil",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04617"
  },
  {
    "id": "arXiv:2109.05542",
    "title": "Unsupervised Domain Adaptive Learning via Synthetic Data for Person  Re-identification",
    "abstract": "Unsupervised Domain Adaptive Learning via Synthetic Data for Person  Re-identification",
    "descriptor": "",
    "authors": [
      "Qi Wang",
      "Sikai Bai",
      "Junyu Gao",
      "Yuan Yuan",
      "Xuelong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.05542"
  },
  {
    "id": "arXiv:2109.06153",
    "title": "Relaxed Marginal Consistency for Differentially Private Query Answering",
    "abstract": "Relaxed Marginal Consistency for Differentially Private Query Answering",
    "descriptor": "",
    "authors": [
      "Ryan McKenna",
      "Siddhant Pradhan",
      "Daniel Sheldon",
      "Gerome Miklau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.06153"
  },
  {
    "id": "arXiv:2109.06721",
    "title": "Linear block and convolutional MDS codes to required rate, distance and  type",
    "abstract": "Linear block and convolutional MDS codes to required rate, distance and  type",
    "descriptor": "",
    "authors": [
      "Ted Hurley"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.06721"
  },
  {
    "id": "arXiv:2109.08080",
    "title": "Non-hyperbolicity in large-scale dynamics of a chaotic system",
    "abstract": "Comments: 19 pages",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Caroline L. Wormell"
    ],
    "subjectives": [
      "Chaotic Dynamics (nlin.CD)",
      "Mathematical Physics (math-ph)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.08080"
  },
  {
    "id": "arXiv:2109.09406",
    "title": "EdgeFlow: Achieving Practical Interactive Segmentation with Edge-Guided  Flow",
    "abstract": "Comments: accepted by ICCV Workshop",
    "descriptor": "\nComments: accepted by ICCV Workshop\n",
    "authors": [
      "Yuying Hao",
      "Yi Liu",
      "Zewu Wu",
      "Lin Han",
      "Yizhou Chen",
      "Guowei Chen",
      "Lutao Chu",
      "Shiyu Tang",
      "Zhiliang Yu",
      "Zeyu Chen",
      "Baohua Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.09406"
  },
  {
    "id": "arXiv:2109.09510",
    "title": "Conditionally Parameterized, Discretization-Aware Neural Networks for  Mesh-Based Modeling of Physical Systems",
    "abstract": "Conditionally Parameterized, Discretization-Aware Neural Networks for  Mesh-Based Modeling of Physical Systems",
    "descriptor": "",
    "authors": [
      "Jiayang Xu",
      "Aniruddhe Pradhan",
      "Karthik Duraisamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2109.09510"
  },
  {
    "id": "arXiv:2109.09697",
    "title": "How to train your solver: A method of manufactured solutions for  weakly-compressible SPH",
    "abstract": "Comments: 18 pages, 26 figures",
    "descriptor": "\nComments: 18 pages, 26 figures\n",
    "authors": [
      "Pawan Negi",
      "Prabhu Ramachandran"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2109.09697"
  },
  {
    "id": "arXiv:2109.09710",
    "title": "Understanding neural networks with reproducing kernel Banach spaces",
    "abstract": "Understanding neural networks with reproducing kernel Banach spaces",
    "descriptor": "",
    "authors": [
      "Francesca Bartolucci",
      "Ernesto De Vito",
      "Lorenzo Rosasco",
      "Stefano Vigogna"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2109.09710"
  },
  {
    "id": "arXiv:2109.09824",
    "title": "Well Googled is Half Done: Multimodal Forecasting of New Fashion Product  Sales with Image-based Google Trends",
    "abstract": "Comments: Paper submitted to Pattern Recognition Journal",
    "descriptor": "\nComments: Paper submitted to Pattern Recognition Journal\n",
    "authors": [
      "Geri Skenderi",
      "Christian Joppi",
      "Matteo Denitto",
      "Marco Cristani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.09824"
  },
  {
    "id": "arXiv:2109.10132",
    "title": "Manifesto for Putting 'Chartjunk' in the Trash 2021!",
    "abstract": "Comments: For associated site, see this https URL",
    "descriptor": "\nComments: For associated site, see this https URL\n",
    "authors": [
      "Derya Akbaba",
      "Jack Wilburn",
      "Main T. Nance",
      "Miriah Meyer"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.10132"
  },
  {
    "id": "arXiv:2109.11154",
    "title": "Rank Overspecified Robust Matrix Recovery: Subgradient Method and Exact  Recovery",
    "abstract": "Comments: 75 pages, 3 figures",
    "descriptor": "\nComments: 75 pages, 3 figures\n",
    "authors": [
      "Lijun Ding",
      "Liwei Jiang",
      "Yudong Chen",
      "Qing Qu",
      "Zhihui Zhu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.11154"
  },
  {
    "id": "arXiv:2109.11888",
    "title": "Robustness and Sensitivity of BERT Models Predicting Alzheimer's Disease  from Text",
    "abstract": "Comments: Accepted to W-NUT @ EMNLP 2021 (upd: correction in Table 3)",
    "descriptor": "\nComments: Accepted to W-NUT @ EMNLP 2021 (upd: correction in Table 3)\n",
    "authors": [
      "Jekaterina Novikova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.11888"
  },
  {
    "id": "arXiv:2109.14433",
    "title": "Multi-loss ensemble deep learning for chest X-ray classification",
    "abstract": "Comments: 32 pages, 9 figures, 5 tables",
    "descriptor": "\nComments: 32 pages, 9 figures, 5 tables\n",
    "authors": [
      "Sivaramakrishnan Rajaraman",
      "Ghada Zamzmi",
      "Sameer Antani"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.14433"
  },
  {
    "id": "arXiv:2109.15025",
    "title": "3D Pose Transfer with Correspondence Learning and Mesh Refinement",
    "abstract": "3D Pose Transfer with Correspondence Learning and Mesh Refinement",
    "descriptor": "",
    "authors": [
      "Chaoyue Song",
      "Jiacheng Wei",
      "Ruibo Li",
      "Fayao Liu",
      "Guosheng Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.15025"
  },
  {
    "id": "arXiv:2110.00201",
    "title": "Error-free approximation of explicit linear MPC through lattice  piecewise affine expression",
    "abstract": "Error-free approximation of explicit linear MPC through lattice  piecewise affine expression",
    "descriptor": "",
    "authors": [
      "Jun Xu",
      "Yunjiang Lou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.00201"
  },
  {
    "id": "arXiv:2110.00577",
    "title": "Reconstruction for Powerful Graph Representations",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Leonardo Cotta",
      "Christopher Morris",
      "Bruno Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.00577"
  },
  {
    "id": "arXiv:2110.00959",
    "title": "Boost Neural Networks by Checkpoints",
    "abstract": "Boost Neural Networks by Checkpoints",
    "descriptor": "",
    "authors": [
      "Feng Wang",
      "Guoyizhe Wei",
      "Qiao Liu",
      "Jinxiang Ou",
      "Xian Wei",
      "Hairong Lv"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.00959"
  },
  {
    "id": "arXiv:2110.01571",
    "title": "Causal Representation Learning for Fine-Grained Face Transfer",
    "abstract": "Causal Representation Learning for Fine-Grained Face Transfer",
    "descriptor": "",
    "authors": [
      "Gege Gao",
      "Huaibo Huang",
      "Chaoyou Fu",
      "Ran He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.01571"
  },
  {
    "id": "arXiv:2110.02878",
    "title": "An Investigation of the Effectiveness of Phase for Audio Classification",
    "abstract": "Comments: 5 pages, 3 figures",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Shunsuke Hidaka",
      "Kohei Wakamiya",
      "Tokihiko Kaburagi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.02878"
  },
  {
    "id": "arXiv:2110.03111",
    "title": "Cut the CARP: Fishing for zero-shot story evaluation",
    "abstract": "Comments: 9 pages, 4 figures",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Shahbuland Matiana",
      "JR Smith",
      "Ryan Teehan",
      "Louis Castricato",
      "Stella Biderman",
      "Leo Gao",
      "Spencer Frazier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.03111"
  },
  {
    "id": "arXiv:2110.03163",
    "title": "Transliteration of Foreign Words in Burmese",
    "abstract": "Transliteration of Foreign Words in Burmese",
    "descriptor": "",
    "authors": [
      "Chenchen Ding"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.03163"
  },
  {
    "id": "arXiv:2110.03215",
    "title": "Towards Continual Knowledge Learning of Language Models",
    "abstract": "Towards Continual Knowledge Learning of Language Models",
    "descriptor": "",
    "authors": [
      "Joel Jang",
      "Seonghyeon Ye",
      "Sohee Yang",
      "Joongbo Shin",
      "Janghoon Han",
      "Gyeonghun Kim",
      "Stanley Jungkyu Choi",
      "Minjoon Seo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03215"
  },
  {
    "id": "arXiv:2110.03643",
    "title": "From Weighted Conditionals of Multilayer Perceptrons to Gradual  Argumentation and Back",
    "abstract": "Comments: 21 pages. arXiv admin note: text overlap with arXiv:2106.00390",
    "descriptor": "\nComments: 21 pages. arXiv admin note: text overlap with arXiv:2106.00390\n",
    "authors": [
      "Laura Giordano"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.03643"
  },
  {
    "id": "arXiv:2110.03991",
    "title": "Combining Differential Privacy and Byzantine Resilience in Distributed  SGD",
    "abstract": "Combining Differential Privacy and Byzantine Resilience in Distributed  SGD",
    "descriptor": "",
    "authors": [
      "Rachid Guerraoui",
      "Nirupam Gupta",
      "Rafael Pinot",
      "Sebastien Rouault",
      "John Stephan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.03991"
  },
  {
    "id": "arXiv:2110.04439",
    "title": "A Generic Knowledge Based Medical Diagnosis Expert System",
    "abstract": "A Generic Knowledge Based Medical Diagnosis Expert System",
    "descriptor": "",
    "authors": [
      "Xin Huang",
      "Xuejiao Tang",
      "Wenbin Zhang",
      "Shichao Pei",
      "Ji Zhang",
      "Mingli Zhang",
      "Zhen Liu",
      "Ruijun Chen",
      "Yiyi Huang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04439"
  },
  {
    "id": "arXiv:2110.04471",
    "title": "Provably Efficient Black-Box Action Poisoning Attacks Against  Reinforcement Learning",
    "abstract": "Provably Efficient Black-Box Action Poisoning Attacks Against  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Guanlin Liu",
      "Lifeng Lai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.04471"
  },
  {
    "id": "arXiv:2110.04997",
    "title": "IoT Equipped Intelligent Distributed Framework for Smart Healthcare  Systems",
    "abstract": "Comments: 30 pages and 9 figures",
    "descriptor": "\nComments: 30 pages and 9 figures\n",
    "authors": [
      "Sita Rani",
      "Meetali Chauhan",
      "Aman Kataria",
      "Alex Khang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.04997"
  },
  {
    "id": "arXiv:2110.05651",
    "title": "Learning with Algorithmic Supervision via Continuous Relaxations",
    "abstract": "Comments: Published at NeurIPS 2021, Code @ this https URL, Video @ this https URL",
    "descriptor": "\nComments: Published at NeurIPS 2021, Code @ this https URL, Video @ this https URL\n",
    "authors": [
      "Felix Petersen",
      "Christian Borgelt",
      "Hilde Kuehne",
      "Oliver Deussen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.05651"
  },
  {
    "id": "arXiv:2110.05745",
    "title": "VarArray: Array-Geometry-Agnostic Continuous Speech Separation",
    "abstract": "Comments: 5 pages, 1 figure, 3 tables, submitted to ICASSP 2022; updated reference information of [33]",
    "descriptor": "\nComments: 5 pages, 1 figure, 3 tables, submitted to ICASSP 2022; updated reference information of [33]\n",
    "authors": [
      "Takuya Yoshioka",
      "Xiaofei Wang",
      "Dongmei Wang",
      "Min Tang",
      "Zirun Zhu",
      "Zhuo Chen",
      "Naoyuki Kanda"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.05745"
  },
  {
    "id": "arXiv:2110.06742",
    "title": "A Review of the Deep Sea Treasure problem as a Multi-Objective  Reinforcement Learning Benchmark",
    "abstract": "Comments: 10 pages, 4 figures; Fixed Supplementary Materials PDF",
    "descriptor": "\nComments: 10 pages, 4 figures; Fixed Supplementary Materials PDF\n",
    "authors": [
      "Thomas Cassimon",
      "Reinout Eyckerman",
      "Siegfried Mercelis",
      "Steven Latr\u00e9",
      "Peter Hellinckx"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06742"
  },
  {
    "id": "arXiv:2110.06893",
    "title": "Newer is not always better: Rethinking transferability metrics, their  peculiarities, stability and performance",
    "abstract": "Comments: A smaller version of the paper has been accepted at NeurIPS 2021 Workshop on Distribution Shifts (DistShift)",
    "descriptor": "\nComments: A smaller version of the paper has been accepted at NeurIPS 2021 Workshop on Distribution Shifts (DistShift)\n",
    "authors": [
      "Shibal Ibrahim",
      "Natalia Ponomareva",
      "Rahul Mazumder"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06893"
  },
  {
    "id": "arXiv:2110.07020",
    "title": "Top 3 in FG 2021 Families In the Wild Kinship Verification Challenge",
    "abstract": "Top 3 in FG 2021 Families In the Wild Kinship Verification Challenge",
    "descriptor": "",
    "authors": [
      "Junyi Huang",
      "Maxwell Benjamin Strome",
      "Ian Jenkins",
      "Parker Williams",
      "Bo Feng",
      "Yaning Wang",
      "Roman Wang",
      "Vaibhav Bagri",
      "Newman Cheng",
      "Iddo Drori"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.07020"
  },
  {
    "id": "arXiv:2110.07468",
    "title": "SingGAN: Generative Adversarial Network For High-Fidelity Singing Voice  Generation",
    "abstract": "Comments: vocoder, generative adversarial network, singing voice synthesis",
    "descriptor": "\nComments: vocoder, generative adversarial network, singing voice synthesis\n",
    "authors": [
      "Feiyang Chen",
      "Rongjie Huang",
      "Chenye Cui",
      "Yi Ren",
      "Jinglin Liu",
      "Zhou Zhao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.07468"
  },
  {
    "id": "arXiv:2110.07472",
    "title": "Capacity of Group-invariant Linear Readouts from Equivariant  Representations: How Many Objects can be Linearly Classified Under All  Possible Views?",
    "abstract": "Comments: v2: A duplicate References section heading was removed",
    "descriptor": "\nComments: v2: A duplicate References section heading was removed\n",
    "authors": [
      "Matthew Farrell",
      "Blake Bordelon",
      "Shubhendu Trivedi",
      "Cengiz Pehlevan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.07472"
  },
  {
    "id": "arXiv:2110.07788",
    "title": "Gaussian Process Bandit Optimization with Few Batches",
    "abstract": "Gaussian Process Bandit Optimization with Few Batches",
    "descriptor": "",
    "authors": [
      "Zihan Li",
      "Jonathan Scarlett"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.07788"
  },
  {
    "id": "arXiv:2110.08339",
    "title": "A Static Analysis Framework for Data Science Notebooks",
    "abstract": "A Static Analysis Framework for Data Science Notebooks",
    "descriptor": "",
    "authors": [
      "Pavle Suboti\u0107",
      "Lazar Miliki\u0107",
      "Milan Stoji\u0107"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.08339"
  },
  {
    "id": "arXiv:2110.08471",
    "title": "Fast Projection onto the Capped Simplex with Applications to Sparse  Regression in Bioinformatics",
    "abstract": "Comments: 12 pages, 5 figures",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Andersen Ang",
      "Jianzhu Ma",
      "Nianjun Liu",
      "Kun Huang",
      "Yijie Wang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2110.08471"
  },
  {
    "id": "arXiv:2110.09251",
    "title": "Predicting Indian Supreme Court Judgments, Decisions, Or Appeals",
    "abstract": "Predicting Indian Supreme Court Judgments, Decisions, Or Appeals",
    "descriptor": "",
    "authors": [
      "Sugam Sharma",
      "Ritu Shandilya",
      "Swadesh Sharma"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.09251"
  },
  {
    "id": "arXiv:2110.09903",
    "title": "Unrestricted Adversarial Attacks on ImageNet Competition",
    "abstract": "Comments: CVPR-2021 AIC Phase VI Track2: Unrestricted Adversarial Attacks on ImageNet",
    "descriptor": "\nComments: CVPR-2021 AIC Phase VI Track2: Unrestricted Adversarial Attacks on ImageNet\n",
    "authors": [
      "Yuefeng Chen",
      "Xiaofeng Mao",
      "Yuan He",
      "Hui Xue",
      "Chao Li",
      "Yinpeng Dong",
      "Qi-An Fu",
      "Xiao Yang",
      "Wenzhao Xiang",
      "Tianyu Pang",
      "Hang Su",
      "Jun Zhu",
      "Fangcheng Liu",
      "Chao Zhang",
      "Hongyang Zhang",
      "Yichi Zhang",
      "Shilong Liu",
      "Chang Liu",
      "Wenzhao Xiang",
      "Yajie Wang",
      "Huipeng Zhou",
      "Haoran Lyu",
      "Yidan Xu",
      "Zixuan Xu",
      "Taoyu Zhu",
      "Wenjun Li",
      "Xianfeng Gao",
      "Guoqiu Wang",
      "Huanqian Yan",
      "Ying Guo",
      "Chaoning Zhang",
      "Zheng Fang",
      "Yang Wang",
      "Bingyang Fu",
      "Yunfei Zheng",
      "Yekui Wang",
      "Haorong Luo",
      "Zhen Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09903"
  },
  {
    "id": "arXiv:2110.10423",
    "title": "ProxyBO: Accelerating Neural Architecture Search via Bayesian  Optimization with Zero-cost Proxies",
    "abstract": "ProxyBO: Accelerating Neural Architecture Search via Bayesian  Optimization with Zero-cost Proxies",
    "descriptor": "",
    "authors": [
      "Yu Shen",
      "Yang Li",
      "Jian Zheng",
      "Wentao Zhang",
      "Peng Yao",
      "Jixiang Li",
      "Sen Yang",
      "Ji Liu",
      "Bin Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10423"
  },
  {
    "id": "arXiv:2110.10909",
    "title": "On the benefits of being constrained when receiving signals",
    "abstract": "On the benefits of being constrained when receiving signals",
    "descriptor": "",
    "authors": [
      "Shih-Tang Su",
      "David Kempe",
      "Vijay G. Subramanian"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.10909"
  },
  {
    "id": "arXiv:2110.11445",
    "title": "Reliability-Aware Probabilistic Reserve Procurement",
    "abstract": "Reliability-Aware Probabilistic Reserve Procurement",
    "descriptor": "",
    "authors": [
      "Lars Herre",
      "Pierre Pinson",
      "Spyros Chatzivasileiadis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.11445"
  },
  {
    "id": "arXiv:2110.11464",
    "title": "FDGATII : Fast Dynamic Graph Attention with Initial Residual and  Identity Mapping",
    "abstract": "Comments: 10 pages, 4 figures. Reworded section 2.1 with references. Reworded argument in section 2.3 para 2",
    "descriptor": "\nComments: 10 pages, 4 figures. Reworded section 2.1 with references. Reworded argument in section 2.3 para 2\n",
    "authors": [
      "Gayan K. Kulatilleke",
      "Marius Portmann",
      "Ryan Ko",
      "Shekhar S. Chandra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11464"
  },
  {
    "id": "arXiv:2110.11536",
    "title": "Neural-guided, Bidirectional Program Search for Abstraction and  Reasoning",
    "abstract": "Comments: Published as a conference paper at Complex Networks 2021",
    "descriptor": "\nComments: Published as a conference paper at Complex Networks 2021\n",
    "authors": [
      "Simon Alford",
      "Anshula Gandhi",
      "Akshay Rangamani",
      "Andrzej Banburski",
      "Tony Wang",
      "Sylee Dandekar",
      "John Chin",
      "Tomaso Poggio",
      "Peter Chin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11536"
  },
  {
    "id": "arXiv:2110.11709",
    "title": "Creating Knowledge Graphs Subsets using Shape Expressions",
    "abstract": "Creating Knowledge Graphs Subsets using Shape Expressions",
    "descriptor": "",
    "authors": [
      "Jose Emilio Labra Gayo"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11709"
  },
  {
    "id": "arXiv:2110.11758",
    "title": "The Crew: The Quest for Planet Nine is NP-Complete",
    "abstract": "Comments: 14 pages, 3 figures",
    "descriptor": "\nComments: 14 pages, 3 figures\n",
    "authors": [
      "Frederick Reiber"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.11758"
  },
  {
    "id": "arXiv:2110.11911",
    "title": "Self-supervised denoising for massive noisy images",
    "abstract": "Self-supervised denoising for massive noisy images",
    "descriptor": "",
    "authors": [
      "Feng Wang",
      "Trond R. Henninen",
      "Debora Keller",
      "Rolf Erni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.11911"
  },
  {
    "id": "arXiv:2110.11981",
    "title": "How to Quantify Polarization in Models of Opinion Dynamics",
    "abstract": "How to Quantify Polarization in Models of Opinion Dynamics",
    "descriptor": "",
    "authors": [
      "Christopher Musco",
      "Indu Ramesh",
      "Johan Ugander",
      "R. Teal Witter"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.11981"
  },
  {
    "id": "arXiv:2110.12059",
    "title": "Two-Timescale End-to-End Learning for Channel Acquisition and Hybrid  Precoding",
    "abstract": "Comments: 18 pages, 26 figures",
    "descriptor": "\nComments: 18 pages, 26 figures\n",
    "authors": [
      "Qiyu Hu",
      "Yunlong Cai",
      "Kai Kang",
      "Guanding Yu",
      "Jakob Hoydis",
      "Yonina C. Eldar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.12059"
  },
  {
    "id": "arXiv:2110.12241",
    "title": "Changing Software Engineers' Self-Efficacy with Bootcamps:A Research  Proposal",
    "abstract": "Comments: 7 pages, 0 figures, SEET",
    "descriptor": "\nComments: 7 pages, 0 figures, SEET\n",
    "authors": [
      "Danilo Monteiro Ribeiro",
      "Alberto Souza",
      "Victor Santiago",
      "Danilo Lucena",
      "Geraldo Gomes",
      "Gustavo Pinto"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.12241"
  },
  {
    "id": "arXiv:2110.12427",
    "title": "Image-Based CLIP-Guided Essence Transfer",
    "abstract": "Image-Based CLIP-Guided Essence Transfer",
    "descriptor": "",
    "authors": [
      "Hila Chefer",
      "Sagie Benaim",
      "Roni Paiss",
      "Lior Wolf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12427"
  },
  {
    "id": "arXiv:2110.12459",
    "title": "Non-convex Distributionally Robust Optimization: Non-asymptotic Analysis",
    "abstract": "Comments: 25 pages; to appear in NeurIPS 2021",
    "descriptor": "\nComments: 25 pages; to appear in NeurIPS 2021\n",
    "authors": [
      "Jikai Jin",
      "Bohang Zhang",
      "Haiyang Wang",
      "Liwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12459"
  },
  {
    "id": "arXiv:2110.12555",
    "title": "hSDB-instrument: Instrument Localization Database for Laparoscopic and  Robotic Surgeries",
    "abstract": "Comments: this https URL",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Jihun Yoon",
      "Jiwon Lee",
      "Sunghwan Heo",
      "Hayeong Yu",
      "Jayeon Lim",
      "Chi Hyun Song",
      "SeulGi Hong",
      "Seungbum Hong",
      "Bokyung Park",
      "SungHyun Park",
      "Woo Jin Hyung",
      "Min-Kook Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12555"
  },
  {
    "id": "arXiv:2110.12743",
    "title": "Collapsing the Tower -- On the Complexity of Multistage Stochastic IPs",
    "abstract": "Comments: 17 pages, 3 figures",
    "descriptor": "\nComments: 17 pages, 3 figures\n",
    "authors": [
      "Kim-Manuel Klein",
      "Janina Reuter"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.12743"
  },
  {
    "id": "arXiv:2110.12782",
    "title": "NetMF+: Network Embedding Based on Fast and Effective Single-Pass  Randomized Matrix Factorization",
    "abstract": "NetMF+: Network Embedding Based on Fast and Effective Single-Pass  Randomized Matrix Factorization",
    "descriptor": "",
    "authors": [
      "Yuyang Xie",
      "Jiezhong Qiu",
      "Wenjian Yu",
      "Xu Feng",
      "Yuxiang Chen",
      "Jie Tang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.12782"
  },
  {
    "id": "arXiv:2110.12786",
    "title": "Dictionary Learning Using Rank-One Atomic Decomposition (ROAD)",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1911.08975",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1911.08975\n",
    "authors": [
      "Cheng Cheng",
      "Wei Dai"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12786"
  },
  {
    "id": "arXiv:2110.12805",
    "title": "Algorithms for the Communication of Samples",
    "abstract": "Algorithms for the Communication of Samples",
    "descriptor": "",
    "authors": [
      "Lucas Theis",
      "Noureldin Yosri"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12805"
  },
  {
    "id": "arXiv:2110.12899",
    "title": "No One Representation to Rule Them All: Overlapping Features of Training  Methods",
    "abstract": "No One Representation to Rule Them All: Overlapping Features of Training  Methods",
    "descriptor": "",
    "authors": [
      "Raphael Gontijo-Lopes",
      "Yann Dauphin",
      "Ekin D. Cubuk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12899"
  },
  {
    "id": "arXiv:2110.12911",
    "title": "Instance-Dependent Partial Label Learning",
    "abstract": "Comments: NeurIPS 2021 Spotlight",
    "descriptor": "\nComments: NeurIPS 2021 Spotlight\n",
    "authors": [
      "Ning Xu",
      "Congyu Qiao",
      "Xin Geng",
      "Min-Ling Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12911"
  },
  {
    "id": "arXiv:2110.12985",
    "title": "Goal-Aware Cross-Entropy for Multi-Target Reinforcement Learning",
    "abstract": "Comments: NeurIPS 2021 accepted, 19 pages including appendix and reference, 8 figures",
    "descriptor": "\nComments: NeurIPS 2021 accepted, 19 pages including appendix and reference, 8 figures\n",
    "authors": [
      "Kibeom Kim",
      "Min Whoo Lee",
      "Yoonsung Kim",
      "Je-Hwan Ryu",
      "Minsu Lee",
      "Byoung-Tak Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.12985"
  },
  {
    "id": "arXiv:2110.12997",
    "title": "Unsupervised Domain Adaptation with Dynamics-Aware Rewards in  Reinforcement Learning",
    "abstract": "Comments: Accepted by NeurIPS 2021",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Jinxin Liu",
      "Hao Shen",
      "Donglin Wang",
      "Yachen Kang",
      "Qiangxing Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12997"
  },
  {
    "id": "arXiv:2110.13006",
    "title": "Gradient-based Quadratic Multiform Separation",
    "abstract": "Comments: 47 pages, 11 figures",
    "descriptor": "\nComments: 47 pages, 11 figures\n",
    "authors": [
      "Wen-Teng Chang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13006"
  }
]
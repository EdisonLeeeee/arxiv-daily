[
  {
    "id": "arXiv:2110.14635",
    "title": "An Improved Positioning Accuracy Method of a Robot Based on Particle  Filter",
    "abstract": "This paper aims to improve the performance and positioning accuracy of a\nrobot by using the particle filter method. The laser range information is a\nwireless navigation system mainly used to measure, position, and control\nautonomous robots. Its localization is more flexible to control than wired\nguidance systems. However, the navigation through the laser range finder occurs\nwith a large positioning error while it moves or turns fast. For solving this\nproblem, the paper proposes a method to improve the positioning accuracy of a\nrobot in an indoor environment by using a particle filter with robust\ncharacteristics in a nonlinear or non-Gaussian system. In this experiment, a\nrobot is equipped with a laser range finder, two encoders, and a gyro for\nnavigation to verify the positioning accuracy and performance. The positioning\naccuracy and performance could improve by approximately 85.5% in this proposed\nmethod.",
    "descriptor": "\nComments: 12 pages, 6 figures, conference\n",
    "authors": [
      "Rashid Ali",
      "Dil Nawaz Hakro",
      "Yongping He",
      "Wenpeng Fu",
      "Zhiqiang Cao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.14635"
  },
  {
    "id": "arXiv:2110.14636",
    "title": "Emoji-aware Co-attention Network with EmoGraph2vec Model for Sentiment  Anaylsis",
    "abstract": "In social media platforms, emojis have an extremely high occurrence in\ncomputer-mediated communications. Many emojis are used to strengthen the\nemotional expressions and the emojis that co-occurs in a sentence also have a\nstrong sentiment connection. However, when it comes to emoji representation\nlearning, most studies have only utilized the fixed descriptions provided by\nthe Unicode Consortium, without consideration of actual usage scenario. As for\nthe sentiment analysis task, many researchers ignore the emotional impact of\nthe interaction between text and emojis. It results that the emotional\nsemantics of emojis cannot be fully explored. In this work, we propose a method\nto learn emoji representations called EmoGraph2vec and design an emoji-aware\nco-attention network that learns the mutual emotional semantics between text\nand emojis on short texts of social media. In EmoGraph2vec, we form an emoji\nco-occurrence network on real social data and enrich the semantic information\nbased on an external knowledge base EmojiNet to obtain emoji node embeddings.\nOur model designs a co-attention mechanism to incorporate the text and emojis,\nand integrates a squeeze-and-excitation (SE) block into a convolutional neural\nnetwork as a classifier. Finally, we use the transfer learning method to\nincrease converge speed and achieve higher accuracy. Experimental results show\nthat the proposed model can outperform several baselines for sentiment analysis\non benchmark datasets. Additionally, we conduct a series of ablation and\ncomparison experiments to investigate the effectiveness of our model.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2110.14227\n",
    "authors": [
      "Xiaowei Yuan",
      "Jingyuan Hu",
      "Xiaodan Zhang",
      "Honglei Lv",
      "Hao Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.14636"
  },
  {
    "id": "arXiv:2110.14676",
    "title": "Algorithmic Reconstruction of the Fiber of Persistent Homology on Cell  Complexes",
    "abstract": "Let $K$ be a finite simplicial, cubical, delta or CW complex. The persistence\nmap $\\mathrm{PH}$ takes a filter $f:K \\rightarrow \\mathbb{R}$ as input and\nreturns the barcodes $\\mathrm{PH}(f)$ of the associated sublevel set persistent\nhomology modules. We address the inverse problem: given a target barcode $D$,\ncomputing the fiber $\\mathrm{PH}^{-1}(D)$. For this, we use the fact that\n$\\mathrm{PH}^{-1}(D)$ decomposes as complex of polyhedra when $K$ is a\nsimplicial complex, and we generalise this result to arbitrary based chain\ncomplexes. We then design and implement a depth first search algorithm that\nrecovers the polyhedra forming the fiber $\\mathrm{PH}^{-1}(D)$. As an\napplication, we solve a corpus of 120 sample problems, providing a first\ninsight into the statistical structure of these fibers, for general CW\ncomplexes.",
    "descriptor": "\nComments: 22 pages. 15 figures\n",
    "authors": [
      "Jacob Leygonie",
      "Gregory Henselman-Petrusek"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2110.14676"
  },
  {
    "id": "arXiv:2110.14678",
    "title": "Meta-Learning Sparse Implicit Neural Representations",
    "abstract": "Implicit neural representations are a promising new avenue of representing\ngeneral signals by learning a continuous function that, parameterized as a\nneural network, maps the domain of a signal to its codomain; the mapping from\nspatial coordinates of an image to its pixel values, for example. Being capable\nof conveying fine details in a high dimensional signal, unboundedly of its\ndomain, implicit neural representations ensure many advantages over\nconventional discrete representations. However, the current approach is\ndifficult to scale for a large number of signals or a data set, since learning\na neural representation -- which is parameter heavy by itself -- for each\nsignal individually requires a lot of memory and computations. To address this\nissue, we propose to leverage a meta-learning approach in combination with\nnetwork compression under a sparsity constraint, such that it renders a\nwell-initialized sparse parameterization that evolves quickly to represent a\nset of unseen signals in the subsequent training. We empirically demonstrate\nthat meta-learned sparse neural representations achieve a much smaller loss\nthan dense meta-learned models with the same number of parameters, when trained\nto fit each signal using the same number of optimization steps.",
    "descriptor": "\nComments: Published as a conference proceeding for NeurIPS 2021. First two authors contributed equally\n",
    "authors": [
      "Jaeho Lee",
      "Jihoon Tack",
      "Namhoon Lee",
      "Jinwoo Shin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14678"
  },
  {
    "id": "arXiv:2110.14693",
    "title": "Towards Robust Reasoning over Knowledge Graphs",
    "abstract": "Answering complex logical queries over large-scale knowledge graphs (KGs)\nrepresents an important artificial intelligence task, entailing a range of\napplications. Recently, knowledge representation learning (KRL) has emerged as\nthe state-of-the-art approach, wherein KG entities and the query are embedded\ninto a latent space such that entities that answer the query are embedded close\nto the query. Yet, despite its surging popularity, the potential security risks\nof KRL are largely unexplored, which is concerning, given the increasing use of\nsuch capabilities in security-critical domains (e.g., cyber-security and\nhealthcare).\nThis work represents a solid initial step towards bridging this gap. We\nsystematize the potential security threats to KRL according to the underlying\nattack vectors (e.g., knowledge poisoning and query perturbation) and the\nadversary's background knowledge. More importantly, we present ROAR(Reasoning\nOver Adversarial Representations), a new class of attacks that instantiate a\nvariety of such threats. We demonstrate the practicality of ROAR in two\nrepresentative use cases (i.e., cyber-threat hunting and drug repurposing). For\ninstance, ROAR attains over 99% attack success rate in misleading the threat\nintelligence engine to give pre-defined answers for target queries, yet without\nany impact on non-target ones. Further, we discuss potential countermeasures\nagainst ROAR, including filtering of poisoning facts and robust training with\nadversarial queries, which leads to several promising research directions.",
    "descriptor": "\nComments: Under Review,. Will release source codes after accepted by a vendor\n",
    "authors": [
      "Zhaohan Xi",
      "Ren Pang",
      "Changjiang Li",
      "Shouling Ji",
      "Xiapu Luo",
      "Xusheng Xiao",
      "Ting Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.14693"
  },
  {
    "id": "arXiv:2110.14694",
    "title": "Towards Realistic Single-Task Continuous Learning Research for NER",
    "abstract": "There is an increasing interest in continuous learning (CL), as data privacy\nis becoming a priority for real-world machine learning applications. Meanwhile,\nthere is still a lack of academic NLP benchmarks that are applicable for\nrealistic CL settings, which is a major challenge for the advancement of the\nfield. In this paper we discuss some of the unrealistic data characteristics of\npublic datasets, study the challenges of realistic single-task continuous\nlearning as well as the effectiveness of data rehearsal as a way to mitigate\naccuracy loss. We construct a CL NER dataset from an existing publicly\navailable dataset and release it along with the code to the research community.",
    "descriptor": "\nComments: 11 pages, 2 figures, Findings of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP) (short paper), November 2021\n",
    "authors": [
      "Justin Payan",
      "Yuval Merhav",
      "He Xie",
      "Satyapriya Krishna",
      "Anil Ramakrishna",
      "Mukund Sridhar",
      "Rahul Gupta"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14694"
  },
  {
    "id": "arXiv:2110.14699",
    "title": "Event-Driven Architecture and REST: An Exploratory Study on Modularity",
    "abstract": "Event-driven architecture has been widely adopted in the software industry,\nemerging as an alternative to the development of enterprise applications based\non the REST architectural style. However, little is known about the effects of\nevent-driven architecture on modularity while enterprise applications evolve.\nConsequently, practitioners end up adopting it without any empirical evidence\nabout its impacts on essential indicators, including separation of concerns,\ncoupling, cohesion, complexity and size. This article, therefore, reports an\nexploratory study comparing event-driven architecture and REST style in terms\nof modularity. A real-world application was developed using an event-driven\narchitecture and REST through five evolution scenarios. In each scenario, a\nfeature was added. The generated versions were compared using ten metrics. The\ninitial results suggest that the event-driven architecture improved the\nseparation of concerns, but was outperformed considering the metrics of\ncoupling, cohesion, complexity and size. The findings are encouraging and can\nbe seen as a first step in a more ambitious agenda to empirically evaluate the\nbenefits of event-driven architecture against the REST style.",
    "descriptor": "\nComments: 23 pages, in Portuguese, 5 figures\n",
    "authors": [
      "Luan Lazzari",
      "Kleinner Farias"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.14699"
  },
  {
    "id": "arXiv:2110.14700",
    "title": "DDK: A Deep Koopman Approach for Dynamics Modeling and Trajectory  Tracking of Autonomous Vehicles",
    "abstract": "Autonomous driving has attracted lots of attention in recent years. An\naccurate vehicle dynamics is important for autonomous driving techniques, e.g.\ntrajectory prediction, motion planning, and control of trajectory tracking.\nAlthough previous works have made some results, the strong nonlinearity,\nprecision, and interpretability of dynamics for autonomous vehicles are open\nproblems worth being studied. In this paper, the approach based on the Koopman\noperator named deep direct Koopman (DDK) is proposed to identify the model of\nthe autonomous vehicle and the identified model is a linear time-invariant\n(LTI) version, which is convenient for motion planning and controller design.\nIn the approach, the Koopman eigenvalues and system matrix are considered as\ntrainable tensors with the original states of the autonomous vehicle being\nconcatenated to a part of the Koopman eigenfunctions so that a physically\ninterpretable subsystem can be extracted from the identified latent dynamics.\nSubsequently, the process of the identification model is trained under the\nproposed method based on the dataset which consists of about 60km of data\ncollected with a real electric SUV while the effectiveness of the identified\nmodel is validated. Meanwhile, a high-fidelity vehicle dynamics is identified\nin CarSim with DDK, and then, a linear model predictive control (MPC) called\nDDK-MPC integrating DDK is designed to validate the performance for the control\nof trajectory tracking. Simulation results illustrate that the model of the\nnonlinear vehicle dynamics can be identified effectively via the proposed\nmethod and that excellent tracking performance can be obtained with the\nidentified model under DDK-MPC.",
    "descriptor": "",
    "authors": [
      "Yongqian Xiao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.14700"
  },
  {
    "id": "arXiv:2110.14706",
    "title": "Sensing Anomalies as Potential Hazards: Datasets and Benchmarks",
    "abstract": "We consider the problem of detecting, in the visual sensing data stream of an\nautonomous mobile robot, semantic patterns that are unusual (i.e., anomalous)\nwith respect to the robot's previous experience in similar environments. These\nanomalies might indicate unforeseen hazards and, in scenarios where failure is\ncostly, can be used to trigger an avoidance behavior. We contribute three novel\nimage-based datasets acquired in robot exploration scenarios, comprising a\ntotal of more than 200k labeled frames, spanning various types of anomalies. On\nthese datasets, we study the performance of an anomaly detection approach based\non autoencoders operating at different scales.",
    "descriptor": "",
    "authors": [
      "Dario Mantegazza",
      "Carlos Redondo",
      "Fran Espada",
      "Luca M. Gambardella",
      "Alessandro Giusti",
      "J\u00e9r\u00f4me Guzzi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.14706"
  },
  {
    "id": "arXiv:2110.14708",
    "title": "Identifiable Generative Models for Missing Not at Random Data Imputation",
    "abstract": "Real-world datasets often have missing values associated with complex\ngenerative processes, where the cause of the missingness may not be fully\nobserved. This is known as missing not at random (MNAR) data. However, many\nimputation methods do not take into account the missingness mechanism,\nresulting in biased imputation values when MNAR data is present. Although there\nare a few methods that have considered the MNAR scenario, their model's\nidentifiability under MNAR is generally not guaranteed. That is, model\nparameters can not be uniquely determined even with infinite data samples,\nhence the imputation results given by such models can still be biased. This\nissue is especially overlooked by many modern deep generative models. In this\nwork, we fill in this gap by systematically analyzing the identifiability of\ngenerative models under MNAR. Furthermore, we propose a practical deep\ngenerative model which can provide identifiability guarantees under mild\nassumptions, for a wide range of MNAR mechanisms. Our method demonstrates a\nclear advantage for tasks on both synthetic data and multiple real-world\nscenarios with MNAR data.",
    "descriptor": "",
    "authors": [
      "Chao Ma",
      "Cheng Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.14708"
  },
  {
    "id": "arXiv:2110.14711",
    "title": "A Survey of Self-Supervised and Few-Shot Object Detection",
    "abstract": "Labeling data is often expensive and time-consuming, especially for tasks\nsuch as object detection and instance segmentation, which require dense\nlabeling of the image. While few-shot object detection is about training a\nmodel on novel (unseen) object classes with little data, it still requires\nprior training on many labeled examples of base (seen) classes. On the other\nhand, self-supervised methods aim at learning representations from unlabeled\ndata which transfer well to downstream tasks such as object detection.\nCombining few-shot and self-supervised object detection is a promising research\ndirection. In this survey, we review and characterize the most recent\napproaches on few-shot and self-supervised object detection. Then, we give our\nmain takeaways and discuss future research directions.",
    "descriptor": "",
    "authors": [
      "Gabriel Huang",
      "Issam Laradji",
      "David Vazquez",
      "Simon Lacoste-Julien",
      "Pau Rodriguez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14711"
  },
  {
    "id": "arXiv:2110.14717",
    "title": "An Efficient Reversible Algorithm for Linear Regression",
    "abstract": "This paper presents an efficient reversible algorithm for linear regression,\nboth with and without ridge regression. Our reversible algorithm matches the\nasymptotic time and space complexity of standard irreversible algorithms for\nthis problem. Needed for this result is the expansion of the analysis of\nefficient reversible matrix multiplication to rectangular matrices and matrix\ninversion.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Jayson Lynch",
      "Jiaying Sun"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2110.14717"
  },
  {
    "id": "arXiv:2110.14724",
    "title": "Optimal strategies in concurrent reachability games",
    "abstract": "We study two-player reachability games on finite graphs. At each state the\ninteraction between the players is concurrent and there is a stochastic Nature.\nPlayers also play stochastically. The literature tells us that 1) Player B, who\nwants to avoid the target state, has a positional strategy that maximizes the\nprobability to win (uniformly from every state) and 2) from every state, for\nevery {\\epsilon} > 0, Player A has a strategy that maximizes up to {\\epsilon}\nthe probability to win. Our work is two-fold. First, we present a\ndouble-fixed-point procedure that says from which state Player A has a strategy\nthat maximizes (exactly) the probability to win. This is computable if Nature's\nprobability distributions are rational. We call these states maximizable.\nMoreover, we show that for every {\\epsilon} > 0, Player A has a positional\nstrategy that maximizes the probability to win, exactly from maximizable states\nand up to {\\epsilon} from sub-maximizable states. Second, we consider\nthree-state games with one main state, one target, and one bin. We characterize\nthe local interactions at the main state that guarantee the existence of an\noptimal Player A strategy. In this case there is a positional one. It turns out\nthat in many-state games, these local interactions also guarantee the existence\nof a uniform optimal Player A strategy. In a way, these games are well-behaved\nby design of their elementary bricks, the local interactions. It is decidable\nwhether a local interaction has this desirable property.",
    "descriptor": "",
    "authors": [
      "Benjamin Bordais",
      "Patricia Bouyer",
      "St\u00e9phane Le Roux"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.14724"
  },
  {
    "id": "arXiv:2110.14729",
    "title": "Anomaly-Injected Deep Support Vector Data Description for Text Outlier  Detection",
    "abstract": "Anomaly detection or outlier detection is a common task in various domains,\nwhich has attracted significant research efforts in recent years. Existing\nworks mainly focus on structured data such as numerical or categorical data;\nhowever, anomaly detection on unstructured textual data is less attended. In\nthis work, we target the textual anomaly detection problem and propose a deep\nanomaly-injected support vector data description (AI-SVDD) framework. AI-SVDD\nnot only learns a more compact representation of the data hypersphere but also\nadopts a small number of known anomalies to increase the discriminative power.\nTo tackle text input, we employ a multilayer perceptron (MLP) network in\nconjunction with BERT to obtain enriched text representations. We conduct\nexperiments on three text anomaly detection applications with multiple\ndatasets. Experimental results show that the proposed AI-SVDD is promising and\noutperforms existing works.",
    "descriptor": "\nComments: 11 pages, 5 figures, 3 tables\n",
    "authors": [
      "Zeyu You",
      "Yichu Zhou",
      "Tao Yang",
      "Wei Fan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14729"
  },
  {
    "id": "arXiv:2110.14731",
    "title": "Vision Transformer for Classification of Breast Ultrasound Images",
    "abstract": "Medical ultrasound (US) imaging has become a prominent modality for breast\ncancer imaging due to its ease-of-use, low-cost and safety. In the past decade,\nconvolutional neural networks (CNNs) have emerged as the method of choice in\nvision applications and have shown excellent potential in automatic\nclassification of US images. Despite their success, their restricted local\nreceptive field limits their ability to learn global context information.\nRecently, Vision Transformer (ViT) designs that are based on self-attention\nbetween image patches have shown great potential to be an alternative to CNNs.\nIn this study, for the first time, we utilize ViT to classify breast US images\nusing different augmentation strategies. The results are provided as\nclassification accuracy and Area Under the Curve (AUC) metrics, and the\nperformance is compared with the state-of-the-art CNNs. The results indicate\nthat the ViT models have comparable efficiency with or even better than the\nCNNs in classification of US breast images.",
    "descriptor": "\nComments: 5 pages, 2 figures, submitted to International Symposium on Biomedical Imaging (IEEE ISBI 2022)\n",
    "authors": [
      "Behnaz Gheflati",
      "Hassan Rivaz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.14731"
  },
  {
    "id": "arXiv:2110.14734",
    "title": "Approximating 1-Wasserstein Distance between Persistence Diagrams by  Graph Sparsification",
    "abstract": "Persistence diagrams (PD)s play a central role in topological data analysis.\nThis analysis requires computing distances among such diagrams such as the\n1-Wasserstein distance. Accurate computation of these PD distances for large\ndata sets that render large diagrams may not scale appropriately with the\nexisting methods. The main source of difficulty ensues from the size of the\nbipartite graph on which a matching needs to be computed for determining these\nPD distances. We address this problem by making several algorithmic and\ncomputational observations in order to obtain an approximation. First, taking\nadvantage of the proximity of PD points, we condense them thereby decreasing\nthe number of nodes in the graph for computation. The increase in point\nmultiplicities is addressed by reducing the matching problem to a min-cost flow\nproblem on a transshipment network. Second, we use Well Separated Pair\nDecomposition to sparsify the graph to a size that is linear in the number of\npoints. Both node and arc sparsifications contribute to the approximation\nfactor where we leverage a lower bound given by the Relaxed Word Mover's\ndistance. Third, we eliminate bottlenecks during the sparsification procedure\nby introducing parallelism. Fourth, we develop an open source software called\nPDoptFlow based on our algorithm, exploiting parallelism by GPU and multicore.\nWe perform extensive experiments and show that the actual empirical error is\nvery low. We also show that we can achieve high performance at low guaranteed\nrelative errors, improving upon the state of the arts.",
    "descriptor": "\nComments: 31 pages, 12 figures; extended version of paper published in ALENEX 2022\n",
    "authors": [
      "Tamal K. Dey",
      "Simon Zhang"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2110.14734"
  },
  {
    "id": "arXiv:2110.14735",
    "title": "Towards Evaluating the Robustness of Neural Networks Learned by  Transduction",
    "abstract": "There has been emerging interest in using transductive learning for\nadversarial robustness (Goldwasser et al., NeurIPS 2020; Wu et al., ICML 2020;\nWang et al., ArXiv 2021). Compared to traditional defenses, these defense\nmechanisms \"dynamically learn\" the model based on test-time input; and\ntheoretically, attacking these defenses reduces to solving a bilevel\noptimization problem, which poses difficulty in crafting adaptive attacks. In\nthis paper, we examine these defense mechanisms from a principled threat\nanalysis perspective. We formulate and analyze threat models for\ntransductive-learning based defenses, and point out important subtleties. We\npropose the principle of attacking model space for solving bilevel attack\nobjectives, and present Greedy Model Space Attack (GMSA), an attack framework\nthat can serve as a new baseline for evaluating transductive-learning based\ndefenses. Through systematic evaluation, we show that GMSA, even with weak\ninstantiations, can break previous transductive-learning based defenses, which\nwere resilient to previous attacks, such as AutoAttack (Croce and Hein, ICML\n2020). On the positive side, we report a somewhat surprising empirical result\nof \"transductive adversarial training\": Adversarially retraining the model\nusing fresh randomness at the test time gives a significant increase in\nrobustness against attacks we consider.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2106.08387\n",
    "authors": [
      "Jiefeng Chen",
      "Xi Wu",
      "Yang Guo",
      "Yingyu Liang",
      "Somesh Jha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14735"
  },
  {
    "id": "arXiv:2110.14738",
    "title": "An Autonomous Probing System for Collecting Measurements at Depth from  Small Surface Vehicles",
    "abstract": "This paper presents the portable autonomous probing system (APS), a low-cost\nrobotic design for collecting water quality measurements at targeted depths\nfrom an autonomous surface vehicle (ASV). This system fills an important but\noften overlooked niche in marine sampling by enabling mobile sensor\nobservations throughout the near-surface water column without the need for\nadvanced underwater equipment. We present a probe delivery mechanism built with\ncommercially available components and describe the corresponding open-source\nsimulator and winch controller. Finally, we demonstrate the system in a field\ndeployment and discuss design trade-offs and areas for future improvement.\nProject details are available on\nhttps://johannah.github.io/publication/sample-at-depth our website",
    "descriptor": "\nComments: Presented at OCEANS 2021\n",
    "authors": [
      "Yuying Huang",
      "Yiming Yao",
      "Johanna Hansen",
      "Jeremy Mallette",
      "Sandeep Manjanna",
      "Gregory Dudek",
      "David Meger"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.14738"
  },
  {
    "id": "arXiv:2110.14742",
    "title": "Efficient Placard Discovery for Semantic Mapping During Frontier  Exploration",
    "abstract": "Semantic mapping is the task of providing a robot with a map of its\nenvironment beyond the open, navigable space of traditional Simultaneous\nLocalization and Mapping (SLAM) algorithms by attaching semantics to locations.\nThe system presented in this work reads door placards to annotate the locations\nof offices. Whereas prior work on this system developed hand-crafted detectors,\nthis system leverages YOLOv2 for detection and a segmentation network for\nsegmentation. Placards are localized by computing their pose from a homography\ncomputed from a segmented quadrilateral outline. This work also introduces an\nInterruptable Frontier Exploration algorithm, enabling the robot to explore its\nenvironment to construct its SLAM map while pausing to inspect placards\nobserved during this process. This allows the robot to autonomously discover\nroom placards without human intervention while speeding up significantly over\nprevious autonomous exploration methods.",
    "descriptor": "",
    "authors": [
      "David Balaban",
      "Harshavardhan Jagannathan",
      "Henry Liu",
      "Justin Hart"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.14742"
  },
  {
    "id": "arXiv:2110.14747",
    "title": "Dynamic Review-based Recommenders",
    "abstract": "Just as user preferences change with time, item reviews also reflect those\nsame preference changes. In a nutshell, if one is to sequentially incorporate\nreview content knowledge into recommender systems, one is naturally led to\ndynamical models of text. In the present work we leverage the known power of\nreviews to enhance rating predictions in a way that (i) respects the causality\nof review generation and (ii) includes, in a bidirectional fashion, the ability\nof ratings to inform language review models and vice-versa, language\nrepresentations that help predict ratings end-to-end. Moreover, our\nrepresentations are time-interval aware and thus yield a continuous-time\nrepresentation of the dynamics. We provide experiments on real-world datasets\nand show that our methodology is able to outperform several state-of-the-art\nmodels. Source code for all models can be found at [1].",
    "descriptor": "\nComments: 6pages, Published at International Data Science Conference 2021 (iDSC21)\n",
    "authors": [
      "Kostadin Cvejoski",
      "Ramses J. Sanchez",
      "Christian Bauckhage",
      "Cesar Ojeda"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14747"
  },
  {
    "id": "arXiv:2110.14748",
    "title": "Context-Tree-Based Lossy Compression and Its Application to CSI  Representation",
    "abstract": "We propose novel compression algorithms to time-varying channel state\ninformation (CSI) for wireless communications. The proposed scheme combines\n(lossy) vector quantisation and (lossless) compression. First, the new vector\nquantisation technique is based on a class of parametrised companders applied\non each component of the normalised vector. Our algorithm chooses a suitable\ncompander in an intuitively simple way whenever empirical data are available.\nThen, we compress the quantised index sequences using a context-tree-based\napproach. Essentially, we update the estimate of the conditional distribution\nof the source at each instant and encode the current symbol with the estimated\ndistribution. The algorithms have low complexity, are linear-time in both the\nspatial dimension and time duration, and can be implemented in an online\nfashion. We run simulations to demonstrate the effectiveness of the proposed\nalgorithms in such scenarios.",
    "descriptor": "\nComments: 30 pages, 8 figures\n",
    "authors": [
      "Henrique K. Miyamoto",
      "Sheng Yang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.14748"
  },
  {
    "id": "arXiv:2110.14751",
    "title": "Xar-Trek: Run-time Execution Migration among FPGAs and Heterogeneous-ISA  CPUs",
    "abstract": "Datacenter servers are increasingly heterogeneous: from x86 host CPUs, to ARM\nor RISC-V CPUs in NICs/SSDs, to FPGAs. Previous works have demonstrated that\nmigrating application execution at run-time across heterogeneous-ISA CPUs can\nyield significant performance and energy gains, with relatively little\nprogrammer effort. However, FPGAs have often been overlooked in that context:\nhardware acceleration using FPGAs involves statically implementing select\napplication functions, which prohibits dynamic and transparent migration. We\npresent Xar-Trek, a new compiler and run-time software framework that overcomes\nthis limitation. Xar-Trek compiles an application for several CPU ISAs and\nselect application functions for acceleration on an FPGA, allowing execution\nmigration between heterogeneous-ISA CPUs and FPGAs at run-time. Xar-Trek's\nrun-time monitors server workloads and migrates application functions to an\nFPGA or to heterogeneous-ISA CPUs based on a scheduling policy. We develop a\nheuristic policy that uses application workload profiles to make scheduling\ndecisions. Our evaluations conducted on a system with x86-64 server CPUs, ARM64\nserver CPUs, and an Alveo accelerator card reveal 88%-1% performance gains over\nno-migration baselines.",
    "descriptor": "",
    "authors": [
      "Edson Horta",
      "Ho-Ren Chuang",
      "Naarayanan Rao VSathish",
      "Cesar Philippidis",
      "Antonio Barbalace",
      "Pierre Olivier",
      "Binoy Ravindran"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.14751"
  },
  {
    "id": "arXiv:2110.14754",
    "title": "Confidence-Aware Imitation Learning from Demonstrations with Varying  Optimality",
    "abstract": "Most existing imitation learning approaches assume the demonstrations are\ndrawn from experts who are optimal, but relaxing this assumption enables us to\nuse a wider range of data. Standard imitation learning may learn a suboptimal\npolicy from demonstrations with varying optimality. Prior works use confidence\nscores or rankings to capture beneficial information from demonstrations with\nvarying optimality, but they suffer from many limitations, e.g., manually\nannotated confidence scores or high average optimality of demonstrations. In\nthis paper, we propose a general framework to learn from demonstrations with\nvarying optimality that jointly learns the confidence score and a\nwell-performing policy. Our approach, Confidence-Aware Imitation Learning\n(CAIL) learns a well-performing policy from confidence-reweighted\ndemonstrations, while using an outer loss to track the performance of our model\nand to learn the confidence. We provide theoretical guarantees on the\nconvergence of CAIL and evaluate its performance in both simulated and real\nrobot experiments. Our results show that CAIL significantly outperforms other\nimitation learning methods from demonstrations with varying optimality. We\nfurther show that even without access to any optimal demonstrations, CAIL can\nstill learn a successful policy, and outperforms prior work.",
    "descriptor": "\nComments: 18 pages, 4 figures, 3 tables. Published at Conference on Neural Information Processing Systems (NeurIPS) 2021\n",
    "authors": [
      "Songyuan Zhang",
      "Zhangjie Cao",
      "Dorsa Sadigh",
      "Yanan Sui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.14754"
  },
  {
    "id": "arXiv:2110.14755",
    "title": "Algorithmic encoding of protected characteristics and its implications  on disparities across subgroups",
    "abstract": "It has been rightfully emphasized that the use of AI for clinical decision\nmaking could amplify health disparities. A machine learning model may pick up\nundesirable correlations, for example, between a patient's racial identity and\nclinical outcome. Such correlations are often present in (historical) data used\nfor model development. There has been an increase in studies reporting biases\nin disease detection models across patient subgroups. Besides the scarcity of\ndata from underserved populations, very little is known about how these biases\nare encoded and how one may reduce or even remove disparate performance. There\nis some speculation whether algorithms may recognize patient characteristics\nsuch as biological sex or racial identity, and then directly or indirectly use\nthis information when making predictions. But it remains unclear how we can\nestablish whether such information is actually used. This article aims to shed\nsome light on these issues by exploring new methodology allowing intuitive\ninspections of the inner working of machine learning models for image-based\ndetection of disease. We also evaluate an effective yet debatable technique for\naddressing disparities leveraging the automatic prediction of patient\ncharacteristics, resulting in models with comparable true and false positive\nrates across subgroups. Our findings may stimulate the discussion about safe\nand ethical use of AI.",
    "descriptor": "\nComments: Code available on this https URL\n",
    "authors": [
      "Ben Glocker",
      "Stefan Winzeck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.14755"
  },
  {
    "id": "arXiv:2110.14759",
    "title": "Regularized Frank-Wolfe for Dense CRFs: Generalizing Mean Field and  Beyond",
    "abstract": "We introduce regularized Frank-Wolfe, a general and effective algorithm for\ninference and learning of dense conditional random fields (CRFs). The algorithm\noptimizes a nonconvex continuous relaxation of the CRF inference problem using\nvanilla Frank-Wolfe with approximate updates, which are equivalent to\nminimizing a regularized energy function. Our proposed method is a\ngeneralization of existing algorithms such as mean field or concave-convex\nprocedure. This perspective not only offers a unified analysis of these\nalgorithms, but also allows an easy way of exploring different variants that\npotentially yield better performance. We illustrate this in our empirical\nresults on standard semantic segmentation datasets, where several\ninstantiations of our regularized Frank-Wolfe outperform mean field inference,\nboth as a standalone component and as an end-to-end trainable layer in a neural\nnetwork. We also show that dense CRFs, coupled with our new algorithms, produce\nsignificant improvements over strong CNN baselines.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "\u0110.Khu\u00ea L\u00ea-Huu",
      "Karteek Alahari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.14759"
  },
  {
    "id": "arXiv:2110.14763",
    "title": "Using PPP Information to Implement a Global Real-Time Virtual Network  DGNSS Approach",
    "abstract": "Global Navigation Satellite Systems (GNSS) provide positioning services for\nconnected and autonomous vehicles. Differential GNSS (DGNSS) has been\ndemonstrated to provide reliable, high quality range correction information\nenabling real-time navigation with sub-meter or centimeter accuracy. However,\nDGNSS requires a local reference station near each user, which for a\ncontinental or global scale implementation would require a dense network of\nreference stations whose construction and maintenance would be prohibitively\nexpensive. Precise Point Positioning (PPP) affords more flexibility as a public\nservice for GNSS receivers, but its State Space Representation (SSR) format is\nnot currently supported by most receivers. This article proposes a novel\nVirtual Network DGNSS (VN-DGNSS) design that capitalizes on the PPP\ninfrastructure to provide global coverage for real-time navigation without\nbuilding physical reference stations. Correction information is computed using\ndata from public GNSS SSR data services and transmitted to users by Radio\nTechnical Commission for Maritime Services (RTCM) Observation Space\nRepresentation (OSR) messages which are accepted by most receivers. The\nreal-time stationary and moving platform testing performance, using u-blox M8P\nand ZED-F9P receivers, surpasses the Society of Automotive Engineering (SAE)\nspecification (68% of horizontal error $\\leqslant$ 1.5 m and vertical error\n$\\leqslant$ 3 m) and shows significantly better horizontal performance than\nGNSS Open Service (OS). The moving tests also show better horizontal\nperformance than the ZEDF9P receiver with Satellite Based Augmentation Systems\n(SBAS) enabled and achieve the lane-level accuracy which requires 95% of\nhorizontal errors less than 1 meter.",
    "descriptor": "\nComments: 14 pages, 8 tables, 4 figures, Code and data are available at this https URL\n",
    "authors": [
      "Wang Hu",
      "Ashim Neupane",
      "Jay A. Farrell"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.14763"
  },
  {
    "id": "arXiv:2110.14764",
    "title": "Generalized Funnelling: Ensemble Learning and Heterogeneous Document  Embeddings for Cross-Lingual Text Classification",
    "abstract": "\\emph{Funnelling} (Fun) is a recently proposed method for cross-lingual text\nclassification (CLTC) based on a two-tier learning ensemble for heterogeneous\ntransfer learning (HTL). In this ensemble method, 1st-tier classifiers, each\nworking on a different and language-dependent feature space, return a vector of\ncalibrated posterior probabilities (with one dimension for each class) for each\ndocument, and the final classification decision is taken by a metaclassifier\nthat uses this vector as its input. The metaclassifier can thus exploit\nclass-class correlations, and this (among other things) gives Fun an edge over\nCLTC systems in which these correlations cannot be brought to bear. In this\npaper we describe \\emph{Generalized Funnelling} (gFun), a generalization of Fun\nconsisting of an HTL architecture in which 1st-tier components can be arbitrary\n\\emph{view-generating functions}, i.e., language-dependent functions that each\nproduce a language-independent representation (\"view\") of the document. We\ndescribe an instance of gFun in which the metaclassifier receives as input a\nvector of calibrated posterior probabilities (as in Fun) aggregated to other\nembedded representations that embody other types of correlations, such as\nword-class correlations (as encoded by \\emph{Word-Class Embeddings}), word-word\ncorrelations (as encoded by \\emph{Multilingual Unsupervised or Supervised\nEmbeddings}), and word-context correlations (as encoded by \\emph{multilingual\nBERT}). We show that this instance of \\textsc{gFun} substantially improves over\nFun and over state-of-the-art baselines, by reporting experimental results\nobtained on two large, standard datasets for multilingual multilabel text\nclassification. Our code that implements gFun is publicly available.",
    "descriptor": "",
    "authors": [
      "Alejandro Moreo",
      "Andrea Pedrotti",
      "Fabrizio Sebastiani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14764"
  },
  {
    "id": "arXiv:2110.14765",
    "title": "Cryptocurrencies Activity as a Complex Network: Analysis of Transactions  Graphs",
    "abstract": "The number of users approaching the world of cryptocurrencies exploded in the\nlast years, and consequently the daily interactions on their underlying\ndistributed ledgers have intensified. In this paper, we analyze the flow of\nthese digital transactions in a certain period of time, trying to discover\nimportant insights on the typical use of these technologies by studying,\nthrough complex network theory, the patterns of interactions in four prominent\nand different Distributed Ledger Technologies (DLTs), namely Bitcoin, DogeCoin,\nEthereum, Ripple. In particular, we describe the Distributed Ledger Network\nAnalyzer (DiLeNA), a software tool for the investigation of the transactions\nnetwork recorded in DLTs. We show that studying the network characteristics and\npeculiarities is of paramount importance, in order to understand how users\ninteract in the DLT. For instance, our analyses reveal that all transaction\ngraphs exhibit small world properties.",
    "descriptor": "",
    "authors": [
      "Luca Serena",
      "Stefano Ferretti",
      "Gabriele D'Angelo"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Computers and Society (cs.CY)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.14765"
  },
  {
    "id": "arXiv:2110.14766",
    "title": "Fine Grained Human Evaluation for English-to-Chinese Machine  Translation: A Case Study on Scientific Text",
    "abstract": "Recent research suggests that neural machine translation (MT) in the news\ndomain has reached human-level performance, but for other professional domains,\nit is far below the level. In this paper, we conduct a fine-grained systematic\nhuman evaluation for four widely used Chinese-English NMT systems on scientific\nabstracts which are collected from published journals and books. Our human\nevaluation results show that all the systems return with more than 10\\% error\nrates on average, which requires much post editing effort for real academic\nuse. Furthermore, we categorize six main error types and and provide some real\nexamples. Our findings emphasise the needs that research attention in the MT\ncommunity should be shifted from short text generic translation to professional\nmachine translation and build large scale bilingual corpus for these specific\ndomains.",
    "descriptor": "\nComments: 12 pages, 3 tables\n",
    "authors": [
      "Ming Liu",
      "He Zhang",
      "Guanhao Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.14766"
  },
  {
    "id": "arXiv:2110.14768",
    "title": "Distributed Asynchronous Games With Causal Memory are Undecidable",
    "abstract": "We show the undecidability of the controller synthesis problem when both the\nplant and the controllers are asynchronous automata and the controllers have\ncausal memory",
    "descriptor": "",
    "authors": [
      "Hugo Gimbert"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.14768"
  },
  {
    "id": "arXiv:2110.14769",
    "title": "Detecting Dementia from Speech and Transcripts using Transformers",
    "abstract": "Alzheimer's disease (AD) constitutes a neurodegenerative disease with serious\nconsequences to peoples' everyday lives, if it is not diagnosed early since\nthere is no available cure. Because of the cost of examinations for diagnosing\ndementia, i.e., Magnetic Resonance Imaging (MRI), electroencephalogram (EEG)\nsignals etc., current work has been focused on diagnosing dementia from\nspontaneous speech. However, little work has been done regarding the conversion\nof speech data to Log-Mel spectrograms and Mel-frequency cepstral coefficients\n(MFCCs) and the usage of pretrained models. Concurrently, little work has been\ndone in terms of both the usage of transformer networks and the way the two\nmodalities, i.e., speech and transcripts, are combined in a single neural\nnetwork. To address these limitations, first we employ several pretrained\nmodels, with Vision Transformer (ViT) achieving the highest evaluation results.\nSecondly, we propose multimodal models. More specifically, our introduced\nmodels include Gated Multimodal Unit in order to control the influence of each\nmodality towards the final classification and crossmodal attention so as to\ncapture in an effective way the relationships between the two modalities.\nExtensive experiments conducted on the ADReSS Challenge dataset demonstrate the\neffectiveness of the proposed models and their superiority over\nstate-of-the-art approaches.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Loukas Ilias",
      "Dimitris Askounis",
      "John Psarras"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.14769"
  },
  {
    "id": "arXiv:2110.14770",
    "title": "TRAIL: Near-Optimal Imitation Learning with Suboptimal Data",
    "abstract": "The aim in imitation learning is to learn effective policies by utilizing\nnear-optimal expert demonstrations. However, high-quality demonstrations from\nhuman experts can be expensive to obtain in large numbers. On the other hand,\nit is often much easier to obtain large quantities of suboptimal or\ntask-agnostic trajectories, which are not useful for direct imitation, but can\nnevertheless provide insight into the dynamical structure of the environment,\nshowing what could be done in the environment even if not what should be done.\nWe ask the question, is it possible to utilize such suboptimal offline datasets\nto facilitate provably improved downstream imitation learning? In this work, we\nanswer this question affirmatively and present training objectives that use\noffline datasets to learn a factored transition model whose structure enables\nthe extraction of a latent action space. Our theoretical analysis shows that\nthe learned latent action space can boost the sample-efficiency of downstream\nimitation learning, effectively reducing the need for large near-optimal expert\ndatasets through the use of auxiliary non-expert data. To learn the latent\naction space in practice, we propose TRAIL (Transition-Reparametrized Actions\nfor Imitation Learning), an algorithm that learns an energy-based transition\nmodel contrastively, and uses the transition model to reparametrize the action\nspace for sample-efficient imitation learning. We evaluate the practicality of\nour objective through experiments on a set of navigation and locomotion tasks.\nOur results verify the benefits suggested by our theory and show that TRAIL is\nable to improve baseline imitation learning by up to 4x in performance.",
    "descriptor": "",
    "authors": [
      "Mengjiao Yang",
      "Sergey Levine",
      "Ofir Nachum"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14770"
  },
  {
    "id": "arXiv:2110.14771",
    "title": "ABIDES-Gym: Gym Environments for Multi-Agent Discrete Event Simulation  and Application to Financial Markets",
    "abstract": "Model-free Reinforcement Learning (RL) requires the ability to sample\ntrajectories by taking actions in the original problem environment or a\nsimulated version of it. Breakthroughs in the field of RL have been largely\nfacilitated by the development of dedicated open source simulators with easy to\nuse frameworks such as OpenAI Gym and its Atari environments. In this paper we\npropose to use the OpenAI Gym framework on discrete event time based Discrete\nEvent Multi-Agent Simulation (DEMAS). We introduce a general technique to wrap\na DEMAS simulator into the Gym framework. We expose the technique in detail and\nimplement it using the simulator ABIDES as a base. We apply this work by\nspecifically using the markets extension of ABIDES, ABIDES-Markets, and develop\ntwo benchmark financial markets OpenAI Gym environments for training daily\ninvestor and execution agents. As a result, these two environments describe\nclassic financial problems with a complex interactive market behavior response\nto the experimental agent's action.",
    "descriptor": "",
    "authors": [
      "Selim Amrouni",
      "Aymeric Moulin",
      "Jared Vann",
      "Svitlana Vyetrenko",
      "Tucker Balch",
      "Manuela Veloso"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2110.14771"
  },
  {
    "id": "arXiv:2110.14773",
    "title": "SiamPolar: Semi-supervised Realtime Video Object Segmentation with Polar  Representation",
    "abstract": "Video object segmentation (VOS) is an essential part of autonomous vehicle\nnavigation. The real-time speed is very important for the autonomous vehicle\nalgorithms along with the accuracy metric. In this paper, we propose a\nsemi-supervised real-time method based on the Siamese network using a new polar\nrepresentation. The input of bounding boxes is initialized rather than the\nobject masks, which are applied to the video object detection tasks. The polar\nrepresentation could reduce the parameters for encoding masks with subtle\naccuracy loss so that the algorithm speed can be improved significantly. An\nasymmetric siamese network is also developed to extract the features from\ndifferent spatial scales. Moreover, the peeling convolution is proposed to\nreduce the antagonism among the branches of the polar head. The repeated\ncross-correlation and semi-FPN are designed based on this idea. The\nexperimental results on the DAVIS-2016 dataset and other public datasets\ndemonstrate the effectiveness of the proposed method.",
    "descriptor": "\nComments: 11 pages, 11 figures, journal\n",
    "authors": [
      "Yaochen Li",
      "Yuhui Hong",
      "Yonghong Song",
      "Chao Zhu",
      "Ying Zhang",
      "Ruihao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.14773"
  },
  {
    "id": "arXiv:2110.14775",
    "title": "BI-GCN: Boundary-Aware Input-Dependent Graph Convolution Network for  Biomedical Image Segmentation",
    "abstract": "Segmentation is an essential operation of image processing. The convolution\noperation suffers from a limited receptive field, while global modelling is\nfundamental to segmentation tasks. In this paper, we apply graph convolution\ninto the segmentation task and propose an improved \\textit{Laplacian}.\nDifferent from existing methods, our \\textit{Laplacian} is data-dependent, and\nwe introduce two attention diagonal matrices to learn a better vertex\nrelationship. In addition, it takes advantage of both region and boundary\ninformation when performing graph-based information propagation. Specifically,\nwe model and reason about the boundary-aware region-wise correlations of\ndifferent classes through learning graph representations, which is capable of\nmanipulating long range semantic reasoning across various regions with the\nspatial enhancement along the object's boundary. Our model is well-suited to\nobtain global semantic region information while also accommodates local spatial\nboundary characteristics simultaneously. Experiments on two types of\nchallenging datasets demonstrate that our method outperforms the\nstate-of-the-art approaches on the segmentation of polyps in colonoscopy images\nand of the optic disc and optic cup in colour fundus images.",
    "descriptor": "\nComments: Accepted in BMVC2021 as Oral\n",
    "authors": [
      "Yanda Meng",
      "Hongrun Zhang",
      "Dongxu Gao",
      "Yitian Zhao",
      "Xiaoyun Yang",
      "Xuesheng Qian",
      "Xiaowei Huang",
      "Yalin Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.14775"
  },
  {
    "id": "arXiv:2110.14777",
    "title": "Analyzing Photovoltaic's Impact on Conservation Voltage Reduction in  Distribution Networks",
    "abstract": "Conservation voltage reduction (CVR) has been widely implemented in\ndistribution networks and helped utilities effectively reduce energy and peak\nload. However, the increasing penetration level of solar photovoltaic (PV) has\naffected voltage profiles and the performance of CVR. It remains an outstanding\nquestion how CVR and solar PV interact with each other. Understanding this\ninteraction is important for utilities in implementing CVR and assessing its\nperformance. This paper studies the impact of solar PV on CVR in a real\ndistribution system in the Midwest U.S. using comprehensive simulations. We\nhave considered various PV allocations and penetration levels, as well as\ndifferent inverter control modes according to IEEE Std 1547-2018. Three metrics\nare used to quantify the impact of solar PV on CVR: voltages at the substation,\nvoltage distribution across the network, and energy consumption reduction due\nto CVR. The results show that the allocations of solar PV have the most\nsignificant effect on the CVR performance, where a dispersed allocation of\nsolar PV will help flatten voltage profile and achieve deeper voltage\nreductions at the substation, less energy consumption and line losses.",
    "descriptor": "",
    "authors": [
      "Rui Cheng",
      "Zhaoyu Wang",
      "Yifei Guo",
      "Fankun Bu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.14777"
  },
  {
    "id": "arXiv:2110.14780",
    "title": "Combining Vagueness Detection with Deep Learning to Identify Fake News",
    "abstract": "In this paper, we combine two independent detection methods for identifying\nfake news: the algorithm VAGO uses semantic rules combined with NLP techniques\nto measure vagueness and subjectivity in texts, while the classifier FAKE-CLF\nrelies on Convolutional Neural Network classification and supervised deep\nlearning to classify texts as biased or legitimate. We compare the results of\nthe two methods on four corpora. We find a positive correlation between the\nvagueness and subjectivity measures obtained by VAGO, and the classification of\ntext as biased by FAKE-CLF. The comparison yields mutual benefits: VAGO helps\nexplain the results of FAKE-CLF. Conversely FAKE-CLF helps us corroborate and\nexpand VAGO's database. The use of two complementary techniques (rule-based vs\ndata-driven) proves a fruitful approach for the challenging problem of\nidentifying fake news.",
    "descriptor": "\nComments: Paper to appear in the Proceedings of the 24th International Conference on Information Fusion. Johannesburg\n",
    "authors": [
      "Paul Gu\u00e9lorget",
      "Benjamin Icard",
      "Guillaume Gadek",
      "Souhir Ghabiche",
      "Sylvain Gatepaille",
      "Ghislain Atemezing",
      "Paul \u00c9gr\u00e9"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14780"
  },
  {
    "id": "arXiv:2110.14782",
    "title": "When is BERT Multilingual? Isolating Crucial Ingredients for  Cross-lingual Transfer",
    "abstract": "While recent work on multilingual language models has demonstrated their\ncapacity for cross-lingual zero-shot transfer on downstream tasks, there is a\nlack of consensus in the community as to what shared properties between\nlanguages enable such transfer. Analyses involving pairs of natural languages\nare often inconclusive and contradictory since languages simultaneously differ\nin many linguistic aspects. In this paper, we perform a large-scale empirical\nstudy to isolate the effects of various linguistic properties by measuring\nzero-shot transfer between four diverse natural languages and their\ncounterparts constructed by modifying aspects such as the script, word order,\nand syntax. Among other things, our experiments show that the absence of\nsub-word overlap significantly affects zero-shot transfer when languages differ\nin their word order, and there is a strong correlation between transfer\nperformance and word embedding alignment between languages (e.g., R=0.94 on the\ntask of NLI). Our results call for focus in multilingual models on explicitly\nimproving word embedding alignment between languages rather than relying on its\nimplicit emergence.",
    "descriptor": "",
    "authors": [
      "Ameet Deshpande",
      "Partha Talukdar",
      "Karthik Narasimhan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14782"
  },
  {
    "id": "arXiv:2110.14786",
    "title": "Spatial Constraint Generation for Motion Planning in Dynamic  Environments",
    "abstract": "This paper presents a novel method to generate spatial constraints for motion\nplanning in dynamic environments. Motion planning methods for autonomous\ndriving and mobile robots typically need to rely on the spatial constraints\nimposed by a map-based global planner to generate a collision-free trajectory.\nThese methods may fail without an offline map or where the map is invalid due\nto dynamic changes in the environment such as road obstruction, construction,\nand traffic congestion. To address this problem, triangulation-based methods\ncan be used to obtain a spatial constraint. However, the existing methods fall\nshort when dealing with dynamic environments and may lead the motion planner to\nan unrecoverable state. In this paper, we propose a new method to generate a\nsequence of channels across different triangulation mesh topologies to serve as\nthe spatial constraints. This can be applied to motion planning of autonomous\nvehicles or robots in cluttered, unstructured environments. The proposed method\nis evaluated and compared with other triangulation-based methods in synthetic\nand complex scenarios collected from a real-world autonomous driving dataset.\nWe have shown that the proposed method results in a more stable, long-term plan\nwith a higher task completion rate, faster arrival time, a higher rate of\nsuccessful plans, and fewer collisions compared to existing methods.",
    "descriptor": "\nComments: This is the author's version of the paper that's accepted by IROS2021\n",
    "authors": [
      "Han Hu",
      "Peyman Yadmellat"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.14786"
  },
  {
    "id": "arXiv:2110.14789",
    "title": "Millimeter Wave Wireless-Assisted Robotic Navigation with Link State  Classification",
    "abstract": "The millimeter wave (mmWave) bands have attracted considerable attention for\nhigh precision localization applications due to the ability to capture high\nangular and temporal resolution measurements. This paper explores mmWave-based\npositioning for a target localization problem where a fixed target broadcasts\nmmWave signals and a mobile robotic agent attempts to listen to the signals to\nlocate and navigate to the target. A three strage procedure is proposed: First,\nthe mobile agent uses tensor decomposition methods to detect the wireless paths\nand their angles. Second, a machine-learning trained classifier is then used to\npredict the link state, meaning if the strongest path is line-of-sight (LOS) or\nnon-LOS (NLOS). For the NLOS case, the link state predictor also determines if\nthe strongest path arrived via one or more reflections. Third, based on the\nlink state, the agent either follows the estimated angles or explores the\nenvironment. The method is demonstrated on a large dataset of indoor\nenvironments supplemented with ray tracing to simulate the wireless\npropagation. The path estimation and link state classification are also\nintegrated into a state-ofthe-art neural simultaneous localization and mapping\n(SLAM) module to augment camera and LIDAR-based navigation. It is shown that\nthe link state classifier can successfully generalize to completely new\nenvironments outside the training set. In addition, the neural-SLAM module with\nthe wireless path estimation and link state classifier provides rapid\nnavigation to the target, close to a baseline that knows the target location.",
    "descriptor": "\nComments: 13 pages, 20 figures\n",
    "authors": [
      "Mingsheng Yin",
      "Akshaj Veldanda",
      "Amee Trivedi",
      "Jeff Zhang",
      "Kai Pfeiffer",
      "Yaqi Hu",
      "Siddharth Garg",
      "Elza Erkip",
      "Ludovic Righetti",
      "Sundeep Rangan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.14789"
  },
  {
    "id": "arXiv:2110.14794",
    "title": "Masked LARk: Masked Learning, Aggregation and Reporting worKflow",
    "abstract": "Today, many web advertising data flows involve passive cross-site tracking of\nusers. Enabling such a mechanism through the usage of third party tracking\ncookies (3PC) exposes sensitive user data to a large number of parties, with\nlittle oversight on how that data can be used. Thus, most browsers are moving\ntowards removal of 3PC in subsequent browser iterations. In order to\nsubstantially improve end-user privacy while allowing sites to continue to\nsustain their business through ad funding, new privacy-preserving primitives\nneed to be introduced.\nIn this paper, we discuss a new proposal, called Masked LARk, for aggregation\nof user engagement measurement and model training that prevents cross-site\ntracking, while remaining (a) flexible, for engineering development and\nmaintenance, (b) secure, in the sense that cross-site tracking and tracing are\nblocked and (c) open for continued model development and training, allowing\nadvertisers to serve relevant ads to interested users. We introduce a secure\nmulti-party compute (MPC) protocol that utilizes \"helper\" parties to train\nmodels, so that once data leaves the browser, no downstream system can\nindividually construct a complete picture of the user activity. For training,\nour key innovation is through the usage of masking, or the obfuscation of the\ntrue labels, while still allowing a gradient to be accurately computed in\naggregate over a batch of data. Our protocol only utilizes light cryptography,\nat such a level that an interested yet inexperienced reader can understand the\ncore algorithm. We develop helper endpoints that implement this system, and\ngive example usage of training in PyTorch.",
    "descriptor": "\nComments: Microsoft Journal of Applied Research (MSJAR Volume 16)\n",
    "authors": [
      "Joseph J. Pfeiffer III",
      "Denis Charles",
      "Davis Gilton",
      "Young Hun Jung",
      "Mehul Parsana",
      "Erik Anderson"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.14794"
  },
  {
    "id": "arXiv:2110.14795",
    "title": "MedMNIST v2: A Large-Scale Lightweight Benchmark for 2D and 3D  Biomedical Image Classification",
    "abstract": "We introduce MedMNIST v2, a large-scale MNIST-like dataset collection of\nstandardized biomedical images, including 12 datasets for 2D and 6 datasets for\n3D. All images are pre-processed into a small size of 28x28 (2D) or 28x28x28\n(3D) with the corresponding classification labels so that no background\nknowledge is required for users. Covering primary data modalities in biomedical\nimages, MedMNIST v2 is designed to perform classification on lightweight 2D and\n3D images with various dataset scales (from 100 to 100,000) and diverse tasks\n(binary/multi-class, ordinal regression, and multi-label). The resulting\ndataset, consisting of 708,069 2D images and 10,214 3D images in total, could\nsupport numerous research / educational purposes in biomedical image analysis,\ncomputer vision, and machine learning. We benchmark several baseline methods on\nMedMNIST v2, including 2D / 3D neural networks and open-source / commercial\nAutoML tools. The data and code are publicly available at\nhttps://medmnist.com/.",
    "descriptor": "\nComments: The data and code are publicly available at this https URL arXiv admin note: text overlap with arXiv:2010.14925\n",
    "authors": [
      "Jiancheng Yang",
      "Rui Shi",
      "Donglai Wei",
      "Zequan Liu",
      "Lin Zhao",
      "Bilian Ke",
      "Hanspeter Pfister",
      "Bingbing Ni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.14795"
  },
  {
    "id": "arXiv:2110.14798",
    "title": "Reinforcement Learning in Linear MDPs: Constant Regret and  Representation Selection",
    "abstract": "We study the role of the representation of state-action value functions in\nregret minimization in finite-horizon Markov Decision Processes (MDPs) with\nlinear structure. We first derive a necessary condition on the representation,\ncalled universally spanning optimal features (UNISOFT), to achieve constant\nregret in any MDP with linear reward function. This result encompasses the\nwell-known settings of low-rank MDPs and, more generally, zero inherent Bellman\nerror (also known as the Bellman closure assumption). We then demonstrate that\nthis condition is also sufficient for these classes of problems by deriving a\nconstant regret bound for two optimistic algorithms (LSVI-UCB and ELEANOR).\nFinally, we propose an algorithm for representation selection and we prove that\nit achieves constant regret when one of the given representations, or a\nsuitable combination of them, satisfies the UNISOFT condition.",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Matteo Papini",
      "Andrea Tirinzoni",
      "Aldo Pacchiano",
      "Marcello Restelli",
      "Alessandro Lazaric",
      "Matteo Pirotta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14798"
  },
  {
    "id": "arXiv:2110.14802",
    "title": "You Are the Best Reviewer of Your Own Papers: An Owner-Assisted Scoring  Mechanism",
    "abstract": "I consider the setting where reviewers offer very noisy scores for a number\nof items for the selection of high-quality ones (e.g., peer review of large\nconference proceedings) whereas the owner of these items knows the true\nunderlying scores but prefers not to provide this information. To address this\nwithholding of information, in this paper, I introduce the \\textit{Isotonic\nMechanism}, a simple and efficient approach to improving on the imprecise raw\nscores by leveraging certain information that the owner is incentivized to\nprovide. This mechanism takes as input the ranking of the items from best to\nworst provided by the owner, in addition to the raw scores provided by the\nreviewers. It reports adjusted scores for the items by solving a convex\noptimization problem. Under certain conditions, I show that the owner's optimal\nstrategy is to honestly report the true ranking of the items to her best\nknowledge in order to maximize the expected utility. Moreover, I prove that the\nadjusted scores provided by this owner-assisted mechanism are indeed\nsignificantly more accurate than the raw scores provided by the reviewers. This\npaper concludes with several extensions of the Isotonic Mechanism and some\nrefinements of the mechanism for practical considerations.",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Weijie J. Su"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.14802"
  },
  {
    "id": "arXiv:2110.14805",
    "title": "Intermediate Layers Matter in Momentum Contrastive Self Supervised  Learning",
    "abstract": "We show that bringing intermediate layers' representations of two augmented\nversions of an image closer together in self-supervised learning helps to\nimprove the momentum contrastive (MoCo) method. To this end, in addition to the\ncontrastive loss, we minimize the mean squared error between the intermediate\nlayer representations or make their cross-correlation matrix closer to an\nidentity matrix. Both loss objectives either outperform standard MoCo, or\nachieve similar performances on three diverse medical imaging datasets:\nNIH-Chest Xrays, Breast Cancer Histopathology, and Diabetic Retinopathy. The\ngains of the improved MoCo are especially large in a low-labeled data regime\n(e.g. 1% labeled data) with an average gain of 5% across three datasets. We\nanalyze the models trained using our novel approach via feature similarity\nanalysis and layer-wise probing. Our analysis reveals that models trained via\nour approach have higher feature reuse compared to a standard MoCo and learn\ninformative features earlier in the network. Finally, by comparing the output\nprobability distribution of models fine-tuned on small versus large labeled\ndata, we conclude that our proposed method of pre-training leads to lower\nKolmogorov-Smirnov distance, as compared to a standard MoCo. This provides\nadditional evidence that our proposed method learns more informative features\nin the pre-training phase which could be leveraged in a low-labeled data\nregime.",
    "descriptor": "\nComments: Accepted at NeurIPS 2021 (main conference)\n",
    "authors": [
      "Aakash Kaku",
      "Sahana Upadhya",
      "Narges Razavian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.14805"
  },
  {
    "id": "arXiv:2110.14807",
    "title": "L2ight: Enabling On-Chip Learning for Optical Neural Networks via  Efficient in-situ Subspace Optimization",
    "abstract": "Silicon-photonics-based optical neural network (ONN) is a promising hardware\nplatform that could represent a paradigm shift in efficient AI with its\nCMOS-compatibility, flexibility, ultra-low execution latency, and high energy\nefficiency. In-situ training on the online programmable photonic chips is\nappealing but still encounters challenging issues in on-chip implementability,\nscalability, and efficiency. In this work, we propose a closed-loop ONN on-chip\nlearning framework L2ight to enable scalable ONN mapping and efficient in-situ\nlearning. L2ight adopts a three-stage learning flow that first calibrates the\ncomplicated photonic circuit states under challenging physical constraints,\nthen performs photonic core mapping via combined analytical solving and\nzeroth-order optimization. A subspace learning procedure with multi-level\nsparsity is integrated into L2ight to enable in-situ gradient evaluation and\nfast adaptation, unleashing the power of optics for real on-chip intelligence.\nExtensive experiments demonstrate our proposed L2ight outperforms prior ONN\ntraining protocols with 3-order-of-magnitude higher scalability and over 30X\nbetter efficiency, when benchmarked on various models and learning tasks. This\nsynergistic framework is the first scalable on-chip learning solution that\npushes this emerging field from intractable to scalable and further to\nefficient for next-generation self-learnable photonic neural chips. From a\nco-design perspective, L2ight also provides essential insights for\nhardware-restricted unitary subspace optimization and efficient sparse\ntraining. We open-source our framework at\nhttps://github.com/JeremieMelo/L2ight.",
    "descriptor": "\nComments: 10 pages. Accepted to NeurIPS 2021\n",
    "authors": [
      "Jiaqi Gu",
      "Hanqing Zhu",
      "Chenghao Feng",
      "Zixuan Jiang",
      "Ray T. Chen",
      "David Z. Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2110.14807"
  },
  {
    "id": "arXiv:2110.14809",
    "title": "Towards a Taxonomy of Graph Learning Datasets",
    "abstract": "Graph neural networks (GNNs) have attracted much attention due to their\nability to leverage the intrinsic geometries of the underlying data. Although\nmany different types of GNN models have been developed, with many benchmarking\nprocedures to demonstrate the superiority of one GNN model over the others,\nthere is a lack of systematic understanding of the underlying benchmarking\ndatasets, and what aspects of the model are being tested. Here, we provide a\nprincipled approach to taxonomize graph benchmarking datasets by carefully\ndesigning a collection of graph perturbations to probe the essential data\ncharacteristics that GNN models leverage to perform predictions. Our\ndata-driven taxonomization of graph datasets provides a new understanding of\ncritical dataset characteristics that will enable better model evaluation and\nthe development of more specialized GNN models.",
    "descriptor": "\nComments: in Data-Centric AI Workshop at NeurIPS 2021\n",
    "authors": [
      "Renming Liu",
      "Semih Cant\u00fcrk",
      "Frederik Wenkel",
      "Dylan Sandfelder",
      "Devin Kreuzer",
      "Anna Little",
      "Sarah McGuire",
      "Leslie O'Bray",
      "Michael Perlmutter",
      "Bastian Rieck",
      "Matthew Hirn",
      "Guy Wolf",
      "Ladislav Ramp\u00e1\u0161ek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14809"
  },
  {
    "id": "arXiv:2110.14810",
    "title": "Telling Creative Stories Using Generative Visual Aids",
    "abstract": "Can visual artworks created using generative visual algorithms inspire human\ncreativity in storytelling? We asked writers to write creative stories from a\nstarting prompt, and provided them with visuals created by generative AI models\nfrom the same prompt. Compared to a control group, writers who used the visuals\nas story writing aid wrote significantly more creative, original, complete and\nvisualizable stories, and found the task more fun. Of the generative algorithms\nused (BigGAN, VQGAN, DALL-E, CLIPDraw), VQGAN was the most preferred. The\ncontrol group that did not view the visuals did significantly better in\nintegrating the starting prompts. Findings indicate that cross modality inputs\nby AI can benefit divergent aspects of creativity in human-AI co-creation, but\nhinders convergent thinking.",
    "descriptor": "\nComments: Accepted in the Machine Learning for Creativity and Design Workshop at NeurIPS 2021\n",
    "authors": [
      "Safinah Ali",
      "Devi Parikh"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.14810"
  },
  {
    "id": "arXiv:2110.14811",
    "title": "Equivariant vector field network for many-body system modeling",
    "abstract": "Modeling many-body systems has been a long-standing challenge in science,\nfrom classical and quantum physics to computational biology. Equivariance is a\ncritical physical symmetry for many-body dynamic systems, which enables robust\nand accurate prediction under arbitrary reference transformations. In light of\nthis, great efforts have been put on encoding this symmetry into deep neural\nnetworks, which significantly boosts the prediction performance of\ndown-streaming tasks. Some general equivariant models which are computationally\nefficient have been proposed, however, these models have no guarantee on the\napproximation power and may have information loss. In this paper, we leverage\ninsights from the scalarization technique in differential geometry to model\nmany-body systems by learning the gradient vector fields, which are SE(3) and\npermutation equivariant. Specifically, we propose the Equivariant Vector Field\nNetwork (EVFN), which is built on a novel tuple of equivariant basis and the\nassociated scalarization and vectorization layers. Since our tuple equivariant\nbasis forms a complete basis, learning the dynamics with our EVFN has no\ninformation loss and no tensor operations are involved before the final\nvectorization, which reduces the complex optimization on tensors to a minimum.\nWe evaluate our method on predicting trajectories of simulated Newton mechanics\nsystems with both full and partially observed data, as well as the equilibrium\nstate of small molecules (molecular conformation) evolving as a statistical\nmechanics system. Experimental results across multiple tasks demonstrate that\nour model achieves best or competitive performance on baseline models in\nvarious types of datasets.",
    "descriptor": "",
    "authors": [
      "Weitao Du",
      "He Zhang",
      "Yuanqi Du",
      "Qi Meng",
      "Wei Chen",
      "Bin Shao",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Differential Geometry (math.DG)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.14811"
  },
  {
    "id": "arXiv:2110.14812",
    "title": "Differentiable NAS Framework and Application to Ads CTR Prediction",
    "abstract": "Neural architecture search (NAS) methods aim to automatically find the\noptimal deep neural network (DNN) architecture as measured by a given objective\nfunction, typically some combination of task accuracy and inference efficiency.\nFor many areas, such as computer vision and natural language processing, this\nis a critical, yet still time consuming process. New NAS methods have recently\nmade progress in improving the efficiency of this process. We implement an\nextensible and modular framework for Differentiable Neural Architecture Search\n(DNAS) to help solve this problem. We include an overview of the major\ncomponents of our codebase and how they interact, as well as a section on\nimplementing extensions to it (including a sample), in order to help users\nadopt our framework for their applications across different categories of deep\nlearning models. To assess the capabilities of our methodology and\nimplementation, we apply DNAS to the problem of ads click-through rate (CTR)\nprediction, arguably the highest-value and most worked on AI problem at\nhyperscalers today. We develop and tailor novel search spaces to a Deep\nLearning Recommendation Model (DLRM) backbone for CTR prediction, and report\nstate-of-the-art results on the Criteo Kaggle CTR prediction dataset.",
    "descriptor": "",
    "authors": [
      "Ravi Krishna",
      "Aravind Kalaiah",
      "Bichen Wu",
      "Maxim Naumov",
      "Dheevatsa Mudigere",
      "Misha Smelyanskiy",
      "Kurt Keutzer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.14812"
  },
  {
    "id": "arXiv:2110.14813",
    "title": "Stable Anderson Acceleration for Deep Learning",
    "abstract": "Anderson acceleration (AA) is an extrapolation technique designed to speed-up\nfixed-point iterations like those arising from the iterative training of DL\nmodels. Training DL models requires large datasets processed in randomly\nsampled batches that tend to introduce in the fixed-point iteration stochastic\noscillations of amplitude roughly inversely proportional to the size of the\nbatch. These oscillations reduce and occasionally eliminate the positive effect\nof AA. To restore AA's advantage, we combine it with an adaptive moving average\nprocedure that smoothes the oscillations and results in a more regular sequence\nof gradient descent updates. By monitoring the relative standard deviation\nbetween consecutive iterations, we also introduce a criterion to automatically\nassess whether the moving average is needed. We applied the method to the\nfollowing DL instantiations: (i) multi-layer perceptrons (MLPs) trained on the\nopen-source graduate admissions dataset for regression, (ii) physics informed\nneural networks (PINNs) trained on source data to solve 2d and 100d Burgers'\npartial differential equations (PDEs), and (iii) ResNet50 trained on the\nopen-source ImageNet1k dataset for image classification. Numerical results\nobtained using up to 1,536 NVIDIA V100 GPUs on the OLCF supercomputer Summit\nshowed the stabilizing effect of the moving average on AA for all the problems\nabove.",
    "descriptor": "",
    "authors": [
      "Massimiliano Lupo Pasini",
      "Junqi Yin",
      "Viktor Reshniak",
      "Miroslav Stoyanov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.14813"
  },
  {
    "id": "arXiv:2110.14814",
    "title": "Ensemble Federated Adversarial Training with Non-IID data",
    "abstract": "Despite federated learning endows distributed clients with a cooperative\ntraining mode under the premise of protecting data privacy and security, the\nclients are still vulnerable when encountering adversarial samples due to the\nlack of robustness. The adversarial samples can confuse and cheat the client\nmodels to achieve malicious purposes via injecting elaborate noise into normal\ninput. In this paper, we introduce a novel Ensemble Federated Adversarial\nTraining Method, termed as EFAT, that enables an efficacious and robust coupled\ntraining mechanism. Our core idea is to enhance the diversity of adversarial\nexamples through expanding training data with different disturbances generated\nfrom other participated clients, which helps adversarial training perform well\nin Non-IID settings. Experimental results on different Non-IID situations,\nincluding feature distribution skew and label distribution skew, show that our\nproposed method achieves promising results compared with solely combining\nfederated learning with adversarial approaches.",
    "descriptor": "",
    "authors": [
      "Shuang Luo",
      "Didi Zhu",
      "Zexi Li",
      "Chao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.14814"
  },
  {
    "id": "arXiv:2110.14815",
    "title": "Deterministic enumeration of all minimum cut-sets and $k$-cut-sets in  hypergraphs for fixed $k$",
    "abstract": "We consider the problem of deterministically enumerating all minimum\n$k$-cut-sets in a given hypergraph for any fixed $k$. The input here is a\nhypergraph $G = (V, E)$ with non-negative hyperedge costs. A subset $F$ of\nhyperedges is a $k$-cut-set if the number of connected components in $G - F$ is\nat least $k$ and it is a minimum $k$-cut-set if it has the least cost among all\n$k$-cut-sets. For fixed $k$, we call the problem of finding a minimum\n$k$-cut-set as Hypergraph-$k$-Cut and the problem of enumerating all minimum\n$k$-cut-sets as Enum-Hypergraph-$k$-Cut. The special cases of\nHypergraph-$k$-Cut and Enum-Hypergraph-$k$-Cut restricted to graph inputs are\nwell-known to be solvable in (randomized as well as deterministic) polynomial\ntime. In contrast, it is only recently that polynomial-time algorithms for\nHypergraph-$k$-Cut were developed. The randomized polynomial-time algorithm for\nHypergraph-$k$-Cut that was designed in 2018 (Chandrasekaran, Xu, and Yu, SODA\n2018) showed that the number of minimum $k$-cut-sets in a hypergraph is\n$O(n^{2k-2})$, where $n$ is the number of vertices in the input hypergraph, and\nthat they can all be enumerated in randomized polynomial time, thus resolving\nEnum-Hypergraph-$k$-Cut in randomized polynomial time. A deterministic\npolynomial-time algorithm for Hypergraph-$k$-Cut was subsequently designed in\n2020 (Chandrasekaran and Chekuri, FOCS 2020), but it is not guaranteed to\nenumerate all minimum $k$-cut-sets. In this work, we give the first\ndeterministic polynomial-time algorithm to solve Enum-Hypergraph-$k$-Cut (this\nis non-trivial even for $k = 2$). Our algorithms are based on new structural\nresults that allow for efficient recovery of all minimum $k$-cut-sets by\nsolving minimum $(S,T)$-terminal cuts. Our techniques give new structural\ninsights even for enumerating all minimum cut-sets (i.e., minimum 2-cut-sets)\nin a given hypergraph.",
    "descriptor": "\nComments: Accepted to SODA'22\n",
    "authors": [
      "Calvin Beideman",
      "Karthekeyan Chandrasekaran",
      "Weihang Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.14815"
  },
  {
    "id": "arXiv:2110.14817",
    "title": "Similarity-Aware Skill Reproduction based on Multi-Representational  Learning from Demonstration",
    "abstract": "Learning from Demonstration (LfD) algorithms enable humans to teach new\nskills to robots through demonstrations. The learned skills can be robustly\nreproduced from the identical or near boundary conditions (e.g., initial\npoint). However, when generalizing a learned skill over boundary conditions\nwith higher variance, the similarity of the reproductions changes from one\nboundary condition to another, and a single LfD representation cannot preserve\na consistent similarity across a generalization region. We propose a novel\nsimilarity-aware framework including multiple LfD representations and a\nsimilarity metric that can improve skill generalization by finding\nreproductions with the highest similarity values for a given boundary\ncondition. Given a demonstration of the skill, our framework constructs a\nsimilarity region around a point of interest (e.g., initial point) by\nevaluating individual LfD representations using the similarity metric. Any\npoint within this volume corresponds to a representation that reproduces the\nskill with the greatest similarity. We validate our multi-representational\nframework in three simulated and four sets of real-world experiments using a\nphysical 6-DOF robot. We also evaluate 11 different similarity metrics and\ncategorize them according to their biases in 286 simulated experiments.",
    "descriptor": "\nComments: 6 pages, 7 figures. Accepted to ICAR 2021. Code available at: this https URL, Accompanying video at: this https URL\n",
    "authors": [
      "Brendan Hertel",
      "S. Reza Ahmadzadeh"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.14817"
  },
  {
    "id": "arXiv:2110.14818",
    "title": "Temporal-Difference Value Estimation via Uncertainty-Guided Soft Updates",
    "abstract": "Temporal-Difference (TD) learning methods, such as Q-Learning, have proven\neffective at learning a policy to perform control tasks. One issue with methods\nlike Q-Learning is that the value update introduces bias when predicting the TD\ntarget of a unfamiliar state. Estimation noise becomes a bias after the max\noperator in the policy improvement step, and carries over to value estimations\nof other states, causing Q-Learning to overestimate the Q value. Algorithms\nlike Soft Q-Learning (SQL) introduce the notion of a soft-greedy policy, which\nreduces the estimation bias via soft updates in early stages of training.\nHowever, the inverse temperature $\\beta$ that controls the softness of an\nupdate is usually set by a hand-designed heuristic, which can be inaccurate at\ncapturing the uncertainty in the target estimate. Under the belief that $\\beta$\nis closely related to the (state dependent) model uncertainty, Entropy\nRegularized Q-Learning (EQL) further introduces a principled scheduling of\n$\\beta$ by maintaining a collection of the model parameters that characterizes\nmodel uncertainty. In this paper, we present Unbiased Soft Q-Learning (UQL),\nwhich extends the work of EQL from two action, finite state spaces to\nmulti-action, infinite state space Markov Decision Processes. We also provide a\nprincipled numerical scheduling of $\\beta$, extended from SQL and using model\nuncertainty, during the optimization process. We show the theoretical\nguarantees and the effectiveness of this update method in experiments on\nseveral discrete control environments.",
    "descriptor": "\nComments: Accepted to Deep Reinforcement Learning Workshop @ NeurIPS 2021\n",
    "authors": [
      "Litian Liang",
      "Yaosheng Xu",
      "Stephen McAleer",
      "Dailin Hu",
      "Alexander Ihler",
      "Pieter Abbeel",
      "Roy Fox"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.14818"
  },
  {
    "id": "arXiv:2110.14819",
    "title": "Characterizing and Taming Resolution in Convolutional Neural Networks",
    "abstract": "Image resolution has a significant effect on the accuracy and computational,\nstorage, and bandwidth costs of computer vision model inference. These costs\nare exacerbated when scaling out models to large inference serving systems and\nmake image resolution an attractive target for optimization. However, the\nchoice of resolution inherently introduces additional tightly coupled choices,\nsuch as image crop size, image detail, and compute kernel implementation that\nimpact computational, storage, and bandwidth costs. Further complicating this\nsetting, the optimal choices from the perspective of these metrics are highly\ndependent on the dataset and problem scenario. We characterize this tradeoff\nspace, quantitatively studying the accuracy and efficiency tradeoff via\nsystematic and automated tuning of image resolution, image quality and\nconvolutional neural network operators. With the insights from this study, we\npropose a dynamic resolution mechanism that removes the need to statically\nchoose a resolution ahead of time.",
    "descriptor": "",
    "authors": [
      "Eddie Yan",
      "Liang Luo",
      "Luis Ceze"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14819"
  },
  {
    "id": "arXiv:2110.14824",
    "title": "A GNN Based Approach to LTL Model Checking",
    "abstract": "Model Checking is widely applied in verifying complicated and especially\nconcurrent systems. Despite of its popularity, model checking suffers from the\nstate space explosion problem that restricts it from being applied to certain\nsystems, or specifications. Many works have been proposed in the past to\naddress the state space explosion problem, and they have achieved some success,\nbut the inherent complexity still remains an obstacle for purely symbolic\napproaches. In this paper, we propose a Graph Neural Network (GNN) based\napproach for model checking, where the model is expressed using a B{\\\"u}chi\nautomaton and the property to be verified is expressed using Linear Temporal\nLogic (LTL). We express the model as a GNN, and propose a novel node embedding\nframework that encodes the LTL property and characteristics of the model. We\nreduce the LTL model checking problem to a graph classification problem, where\nthere are two classes, 1 (if the model satisfies the specification) and 0 (if\nthe model does not satisfy the specification). The experimental results show\nthat our framework is up to 17 times faster than state-of-the-art tools. Our\napproach is particularly useful when dealing with very large LTL formulae and\nsmall to moderate sized models.",
    "descriptor": "",
    "authors": [
      "Prasita Mukherjee",
      "Tiark Rompf"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.14824"
  },
  {
    "id": "arXiv:2110.14825",
    "title": "Normality-Calibrated Autoencoder for Unsupervised Anomaly Detection on  Data Contamination",
    "abstract": "In this paper, we propose Normality-Calibrated Autoencoder (NCAE), which can\nboost anomaly detection performance on the contaminated datasets without any\nprior information or explicit abnormal samples in the training phase. The NCAE\nadversarially generates high confident normal samples from a latent space\nhaving low entropy and leverages them to predict abnormal samples in a training\ndataset. NCAE is trained to minimise reconstruction errors in uncontaminated\nsamples and maximise reconstruction errors in contaminated samples. The\nexperimental results demonstrate that our method outperforms shallow, hybrid,\nand deep methods for unsupervised anomaly detection and achieves comparable\nperformance compared with semi-supervised methods using labelled anomaly\nsamples in the training phase. The source code is publicly available on\n`https://github.com/andreYoo/NCAE_UAD.git'.",
    "descriptor": "\nComments: Accepted for NeurIPS 2021 Workshop DGMs Applications\n",
    "authors": [
      "Jongmin Yu",
      "Hyeontaek Oh",
      "Minkyung Kim",
      "Junsik Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.14825"
  },
  {
    "id": "arXiv:2110.14830",
    "title": "ODMTCNet: An Interpretable Multi-view Deep Neural Network Architecture  for Image Feature Representation",
    "abstract": "This work proposes an interpretable multi-view deep neural network\narchitecture, namely optimal discriminant multi-view tensor convolutional\nnetwork (ODMTCNet), by integrating statistical machine learning (SML)\nprinciples with the deep neural network (DNN) architecture.",
    "descriptor": "\nComments: Submitted to IEEE TPAMI\n",
    "authors": [
      "Lei Gao",
      "Zheng Guo",
      "Ling Guan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.14830"
  },
  {
    "id": "arXiv:2110.14833",
    "title": "Modeling 3D geometry using 1D laser distance measurements with  application to cylinder for visualization and evaluating surface quality",
    "abstract": "Geometric metrology includes one or two-dimensional (1D or 2D) distance or\nplane measurements, as well as the three-dimensional (3D) scanning. The 1D or\n2D measuring system is unable to obtain advanced 3D feature, while the 3D\nscanning system is relatively costly and time-consuming. Accordingly, in this\nstudy I developed a 3D geometry and surface prediction method by using 1D laser\ndistance measurements to achieve 3D features while saving cost and time. The\nmodel is based on the natural neighbor function for data interpolation and\nlinear model for extrapolation. I implemented the model to the cylinder body\nfor evaluating 3D circularity and surface quality. Results show that the model\ncould achieve reasonable accuracy in constructing the 3D geometry and surface\ndeviation using limited distance measurement (e.g. only 100 data points). It\naccurately predicts the shape of a curved dent (30.48 mm) and identified minor\ndents (less than 0.18mm in depth) which are unable to be detected by eyes and\nfinger touch. It also detects the surface corrugation (1.59 mm) and small local\nfeatures (6.35 mm) using a measurement resolution of 21.34 mm by 15.49 mm. The\npredicted 3D circularity is higher than the measured 2D circularity as\nexpected. The 3D model may be extended to other continuous geometry shapes for\nthe future study.",
    "descriptor": "",
    "authors": [
      "Qinwu Xu"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.14833"
  },
  {
    "id": "arXiv:2110.14835",
    "title": "SIM-ECG: A Signal Importance Mask-driven ECGClassification System",
    "abstract": "Heart disease is the number one killer, and ECGs can assist in the early\ndiagnosis and prevention of deadly outcomes. Accurate ECG interpretation is\ncritical in detecting heart diseases; however, they are often misinterpreted\ndue to a lack of training or insufficient time spent to detect minute\nanomalies. Subsequently, researchers turned to machine learning to assist in\nthe analysis. However, existing systems are not as accurate as skilled ECG\nreaders, and black-box approaches to providing diagnosis result in a lack of\ntrust by medical personnel in a given diagnosis. To address these issues, we\npropose a signal importance mask feedback-based machine learning system that\ncontinuously accepts feedback, improves accuracy, and ex-plains the resulting\ndiagnosis. This allows medical personnel to quickly glance at the output and\neither accept the results, validate the explanation and diagnosis, or quickly\ncorrect areas of misinterpretation, giving feedback to the system for\nimprovement. We have tested our system on a publicly available dataset\nconsisting of healthy and disease-indicating samples. We empirically show that\nour algorithm is better in terms of standard performance measures such as\nF-score and MacroAUC compared to normal training baseline (without feedback);\nwe also show that our model generates better interpretability maps.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Dharma KC",
      "Chicheng Zhang",
      "Chris Gniady",
      "Parth Sandeep Agarwal",
      "Sushil Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14835"
  },
  {
    "id": "arXiv:2110.14839",
    "title": "Hate Speech Classifiers Learn Human-Like Social Stereotypes",
    "abstract": "Social stereotypes negatively impact individuals' judgements about different\ngroups and may have a critical role in how people understand language directed\ntoward minority social groups. Here, we assess the role of social stereotypes\nin the automated detection of hateful language by examining the relation\nbetween individual annotator biases and erroneous classification of texts by\nhate speech classifiers. Specifically, in Study 1 we investigate the impact of\nnovice annotators' stereotypes on their hate-speech-annotation behavior. In\nStudy 2 we examine the effect of language-embedded stereotypes on expert\nannotators' aggregated judgements in a large annotated corpus. Finally, in\nStudy 3 we demonstrate how language-embedded stereotypes are associated with\nsystematic prediction errors in a neural-network hate speech classifier. Our\nresults demonstrate that hate speech classifiers learn human-like biases which\ncan further perpetuate social inequalities when propagated at scale. This\nframework, combining social psychological and computational linguistic methods,\nprovides insights into additional sources of bias in hate speech moderation,\ninforming ongoing debates regarding fairness in machine learning.",
    "descriptor": "",
    "authors": [
      "Aida Mostafazadeh Davani",
      "Mohammad Atari",
      "Brendan Kennedy",
      "Morteza Dehghani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.14839"
  },
  {
    "id": "arXiv:2110.14843",
    "title": "A Sequence to Sequence Model for Extracting Multiple Product Name  Entities from Dialog",
    "abstract": "E-commerce voice ordering systems need to recognize multiple product name\nentities from ordering utterances. Existing voice ordering systems such as\nAmazon Alexa can capture only a single product name entity. This restrains\nusers from ordering multiple items with one utterance. In recent years,\npre-trained language models, e.g., BERT and GPT-2, have shown promising results\non NLP benchmarks like Super-GLUE. However, they can't perfectly generalize to\nthis Multiple Product Name Entity Recognition (MPNER) task due to the ambiguity\nin voice ordering utterances. To fill this research gap, we propose Entity\nTransformer (ET) neural network architectures which recognize up to 10 items in\nan utterance. In our evaluation, the best ET model (conveRT + ngram + ET) has a\nperformance improvement of 12% on our test set compared to the non-neural\nmodel, and outperforms BERT with ET as well. This helps customers finalize\ntheir shopping cart via voice dialog, which improves shopping efficiency and\nexperience.",
    "descriptor": "\nComments: WeCNLP 2021 camera-ready\n",
    "authors": [
      "Praneeth Gubbala",
      "Xuan Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14843"
  },
  {
    "id": "arXiv:2110.14844",
    "title": "From Intrinsic to Counterfactual: On the Explainability of  Contextualized Recommender Systems",
    "abstract": "With the prevalence of deep learning based embedding approaches, recommender\nsystems have become a proven and indispensable tool in various information\nfiltering applications. However, many of them remain difficult to diagnose what\naspects of the deep models' input drive the final ranking decision, thus, they\ncannot often be understood by human stakeholders. In this paper, we investigate\nthe dilemma between recommendation and explainability, and show that by\nutilizing the contextual features (e.g., item reviews from users), we can\ndesign a series of explainable recommender systems without sacrificing their\nperformance. In particular, we propose three types of explainable\nrecommendation strategies with gradual change of model transparency: whitebox,\ngraybox, and blackbox. Each strategy explains its ranking decisions via\ndifferent mechanisms: attention weights, adversarial perturbations, and\ncounterfactual perturbations. We apply these explainable models on five\nreal-world data sets under the contextualized setting where users and items\nhave explicit interactions. The empirical results show that our model achieves\nhighly competitive ranking performance, and generates accurate and effective\nexplanations in terms of numerous quantitative metrics and qualitative\nvisualizations.",
    "descriptor": "",
    "authors": [
      "Yao Zhou",
      "Haonan Wang",
      "Jingrui He",
      "Haixun Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.14844"
  },
  {
    "id": "arXiv:2110.14845",
    "title": "Clinical Brain-Computer Interface Challenge 2020 (CBCIC at WCCI2020):  Overview, methods and results",
    "abstract": "In the field of brain-computer interface (BCI) research, the availability of\nhigh-quality open-access datasets is essential to benchmark the performance of\nemerging algorithms. The existing open-access datasets from past competitions\nmostly deal with healthy individuals' data, while the major application area of\nBCI is in the clinical domain. Thus the newly proposed algorithms to enhance\nthe performance of BCI technology are very often tested against the healthy\nsubjects' datasets only, which doesn't guarantee their success on patients'\ndatasets which are more challenging due to the presence of more nonstationarity\nand altered neurodynamics. In order to partially mitigate this scarcity,\nClinical BCI Challenge aimed to provide an open-access rich dataset of stroke\npatients recorded similar to a neurorehabilitation paradigm. Another key\nfeature of this challenge is that unlike many competitions in the past, it was\ndesigned for algorithms in both with-in subject and cross-subject categories as\na major thrust area of current BCI technology is to realize calibration-free\nBCI designs. In this paper, we have discussed the winning algorithms and their\nperformances across both competition categories which may help develop advanced\nalgorithms for reliable BCIs for real-world practical applications.",
    "descriptor": "",
    "authors": [
      "Anirban Chowdhury",
      "Javier Andreu-Perez"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.14845"
  },
  {
    "id": "arXiv:2110.14854",
    "title": "RIM: Reliable Influence-based Active Learning on Graphs",
    "abstract": "Message passing is the core of most graph models such as Graph Convolutional\nNetwork (GCN) and Label Propagation (LP), which usually require a large number\nof clean labeled data to smooth out the neighborhood over the graph. However,\nthe labeling process can be tedious, costly, and error-prone in practice. In\nthis paper, we propose to unify active learning (AL) and message passing\ntowards minimizing labeling costs, e.g., making use of few and unreliable\nlabels that can be obtained cheaply. We make two contributions towards that\nend. First, we open up a perspective by drawing a connection between AL\nenforcing message passing and social influence maximization, ensuring that the\nselected samples effectively improve the model performance. Second, we propose\nan extension to the influence model that incorporates an explicit quality\nfactor to model label noise. In this way, we derive a fundamentally new AL\nselection criterion for GCN and LP--reliable influence maximization (RIM)--by\nconsidering quantity and quality of influence simultaneously. Empirical studies\non public datasets show that RIM significantly outperforms current AL methods\nin terms of accuracy and efficiency.",
    "descriptor": "\nComments: 15 pages, 5 figures\n",
    "authors": [
      "Wentao Zhang",
      "Yexin Wang",
      "Zhenbang You",
      "Meng Cao",
      "Ping Huang",
      "Jiulong Shan",
      "Zhi Yang",
      "Bin Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14854"
  },
  {
    "id": "arXiv:2110.14855",
    "title": "CAP: Co-Adversarial Perturbation on Weights and Features for Improving  Generalization of Graph Neural Networks",
    "abstract": "Despite the recent advances of graph neural networks (GNNs) in modeling graph\ndata, the training of GNNs on large datasets is notoriously hard due to the\noverfitting. Adversarial training, which augments data with the worst-case\nadversarial examples, has been widely demonstrated to improve model's\nrobustness against adversarial attacks and generalization ability. However,\nwhile the previous adversarial training generally focuses on protecting GNNs\nfrom spiteful attacks, it remains unclear how the adversarial training could\nimprove the generalization abilities of GNNs in the graph analytics problem. In\nthis paper, we investigate GNNs from the lens of weight and feature loss\nlandscapes, i.e., the loss changes with respect to model weights and node\nfeatures, respectively. We draw the conclusion that GNNs are prone to falling\ninto sharp local minima in these two loss landscapes, where GNNs possess poor\ngeneralization performances. To tackle this problem, we construct the\nco-adversarial perturbation (CAP) optimization problem in terms of weights and\nfeatures, and design the alternating adversarial perturbation algorithm to\nflatten the weight and feature loss landscapes alternately. Furthermore, we\ndivide the training process into two stages: one conducting the standard\ncross-entropy minimization to ensure the quick convergence of GNN models, the\nother applying our alternating adversarial training to avoid falling into\nlocally sharp minima. The extensive experiments demonstrate our CAP can\ngenerally improve the generalization performance of GNNs on a variety of\nbenchmark graph datasets.",
    "descriptor": "",
    "authors": [
      "Haotian Xue",
      "Kaixiong Zhou",
      "Tianlong Chen",
      "Kai Guo",
      "Xia Hu",
      "Yi Chang",
      "Xin Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14855"
  },
  {
    "id": "arXiv:2110.14856",
    "title": "An Operator Theoretic Perspective on Pruning Deep Neural Networks",
    "abstract": "The discovery of sparse subnetworks that are able to perform as well as full\nmodels has found broad applied and theoretical interest. While many pruning\nmethods have been developed to this end, the na\\\"ive approach of removing\nparameters based on their magnitude has been found to be as robust as more\ncomplex, state-of-the-art algorithms. The lack of theory behind magnitude\npruning's success, especially pre-convergence, and its relation to other\npruning methods, such as gradient based pruning, are outstanding open questions\nin the field that are in need of being addressed. We make use of recent\nadvances in dynamical systems theory, namely Koopman operator theory, to define\na new class of theoretically motivated pruning algorithms. We show that these\nalgorithms can be equivalent to magnitude and gradient based pruning, unifying\nthese seemingly disparate methods, and that they can be used to shed light on\nmagnitude pruning's performance during early training.",
    "descriptor": "\nComments: 10 pages (main text), 4 figures\n",
    "authors": [
      "William T. Redman",
      "Maria Fonoberova",
      "Ryan Mohr",
      "Ioannis G. Kevrekidis",
      "Igor Mezic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.14856"
  },
  {
    "id": "arXiv:2110.14859",
    "title": "Approximate Decomposable Submodular Function Minimization for  Cardinality-Based Components",
    "abstract": "Minimizing a sum of simple submodular functions of limited support is a\nspecial case of general submodular function minimization that has seen numerous\napplications in machine learning. We develop fast techniques for instances\nwhere components in the sum are cardinality-based, meaning they depend only on\nthe size of the input set. This variant is one of the most widely applied in\npractice, encompassing, e.g., common energy functions arising in image\nsegmentation and recent generalized hypergraph cut functions. We develop the\nfirst approximation algorithms for this problem, where the approximations can\nbe quickly computed via reduction to a sparse graph cut problem, with graph\nsparsity controlled by the desired approximation factor. Our method relies on a\nnew connection between sparse graph reduction techniques and piecewise linear\napproximations to concave functions. Our sparse reduction technique leads to\nsignificant improvements in theoretical runtimes, as well as substantial\npractical gains in problems ranging from benchmark image segmentation tasks to\nhypergraph clustering problems.",
    "descriptor": "",
    "authors": [
      "Nate Veldt",
      "Austin R. Benson",
      "Jon Kleinberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.14859"
  },
  {
    "id": "arXiv:2110.14860",
    "title": "A lightweight two-layer blockchain mechanism for reliable  crossing-domain communication in smart cities",
    "abstract": "The smart city is an emerging notion that is leveraging the Internet of\nThings (IoT) technique to achieve more comfortable, smart and controllable\ncities. The communications crossing domains between smart cities is\nindispensable to enhance collaborations. However, crossing-domain\ncommunications are more vulnerable since there are in different domains.\nMoreover, there are huge different devices with different computation\ncapabilities, from sensors to the cloud servers. In this paper, we propose a\nlightweight two-layer blockchain mechanism for reliable crossing-domain\ncommunication in smart cities. Our mechanism provides a reliable communication\nmechanism for data sharing and communication between smart cities. We defined a\ntwo-layer blockchain structure for the communications inner and between smart\ncities to achieve reliable communications. We present a new block structure for\nthe lightweight IoT devices. Moreover, we present a reputation-based\nmulti-weight consensus protocol in order to achieve efficient communication\nwhile resistant to the nodes collusion attack for the proposed blockchain\nsystem. We also conduct a secure analysis to demonstrate the security of the\nproposed scheme. Finally, performance evaluation shows that our scheme is\nefficient and practical.",
    "descriptor": "\nComments: 13 pages,1 figure\n",
    "authors": [
      "Xiangyu Xu",
      "Jianfei Peng"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.14860"
  },
  {
    "id": "arXiv:2110.14862",
    "title": "Audio-visual Representation Learning for Anomaly Events Detection in  Crowds",
    "abstract": "In recent years, anomaly events detection in crowd scenes attracts many\nresearchers' attention, because of its importance to public safety. Existing\nmethods usually exploit visual information to analyze whether any abnormal\nevents have occurred due to only visual sensors are generally equipped in\npublic places. However, when an abnormal event in crowds occurs, sound\ninformation may be discriminative to assist the crowd analysis system to\ndetermine whether there is an abnormality. Compare with vision information that\nis easily occluded, audio signals have a certain degree of penetration. Thus,\nthis paper attempt to exploit multi-modal learning for modeling the audio and\nvisual signals simultaneously. To be specific, we design a two-branch network\nto model different types of information. The first is a typical 3D CNN model to\nextract temporal appearance features from video clips. The second is an audio\nCNN for encoding Log Mel-Spectrogram of audio signals. Finally, by fusing the\nabove features, a more accurate prediction will be produced. We conduct the\nexperiments on SHADE dataset, a synthetic audio-visual dataset in surveillance\nscenes, and find introducing audio signals effectively improves the performance\nof anomaly events detection and outperforms other state-of-the-art methods.\nFurthermore, we will release the code and the pre-trained models as soon as\npossible.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Junyu Gao",
      "Maoguo Gong",
      "Xuelong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.14862"
  },
  {
    "id": "arXiv:2110.14863",
    "title": "Graph Communal Contrastive Learning",
    "abstract": "Graph representation learning is crucial for many real-world applications\n(e.g. social relation analysis). A fundamental problem for graph representation\nlearning is how to effectively learn representations without human labeling,\nwhich is usually costly and time-consuming. Graph contrastive learning (GCL)\naddresses this problem by pulling the positive node pairs (or similar nodes)\ncloser while pushing the negative node pairs (or dissimilar nodes) apart in the\nrepresentation space. Despite the success of the existing GCL methods, they\nprimarily sample node pairs based on the node-level proximity yet the community\nstructures have rarely been taken into consideration. As a result, two nodes\nfrom the same community might be sampled as a negative pair. We argue that the\ncommunity information should be considered to identify node pairs in the same\ncommunities, where the nodes insides are semantically similar. To address this\nissue, we propose a novel Graph Communal Contrastive Learning (gCooL) framework\nto jointly learn the community partition and learn node representations in an\nend-to-end fashion. Specifically, the proposed gCooL consists of two\ncomponents: a Dense Community Aggregation (DeCA) algorithm for community\ndetection and a Reweighted Self-supervised Cross-contrastive (ReSC) training\nscheme to utilize the community information. Additionally, the real-world\ngraphs are complex and often consist of multiple views. In this paper, we\ndemonstrate that the proposed gCooL can also be naturally adapted to multiplex\ngraphs. Finally, we comprehensively evaluate the proposed gCooL on a variety of\nreal-world graphs. The experimental results show that the gCooL outperforms the\nstate-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Bolian Li",
      "Baoyu Jing",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.14863"
  },
  {
    "id": "arXiv:2110.14864",
    "title": "Selective Sampling for Online Best-arm Identification",
    "abstract": "This work considers the problem of selective-sampling for best-arm\nidentification. Given a set of potential options\n$\\mathcal{Z}\\subset\\mathbb{R}^d$, a learner aims to compute with probability\ngreater than $1-\\delta$, $\\arg\\max_{z\\in \\mathcal{Z}} z^{\\top}\\theta_{\\ast}$\nwhere $\\theta_{\\ast}$ is unknown. At each time step, a potential measurement\n$x_t\\in \\mathcal{X}\\subset\\mathbb{R}^d$ is drawn IID and the learner can either\nchoose to take the measurement, in which case they observe a noisy measurement\nof $x^{\\top}\\theta_{\\ast}$, or to abstain from taking the measurement and wait\nfor a potentially more informative point to arrive in the stream. Hence the\nlearner faces a fundamental trade-off between the number of labeled samples\nthey take and when they have collected enough evidence to declare the best arm\nand stop sampling. The main results of this work precisely characterize this\ntrade-off between labeled samples and stopping time and provide an algorithm\nthat nearly-optimally achieves the minimal label complexity given a desired\nstopping time. In addition, we show that the optimal decision rule has a simple\ngeometric form based on deciding whether a point is in an ellipse or not.\nFinally, our framework is general enough to capture binary classification\nimproving upon previous works.",
    "descriptor": "\nComments: 42 pages, 2 figures, Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Romain Camilleri",
      "Zhihan Xiong",
      "Maryam Fazel",
      "Lalit Jain",
      "Kevin Jamieson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14864"
  },
  {
    "id": "arXiv:2110.14865",
    "title": "Counterbalancing Learning and Strategic Incentives in Allocation Markets",
    "abstract": "Motivated by the high discard rate of donated organs in the United States, we\nstudy an allocation problem in the presence of learning and strategic\nincentives. We consider a setting where a benevolent social planner decides\nwhether and how to allocate a single indivisible object to a queue of strategic\nagents. The object has a common true quality, good or bad, which is ex-ante\nunknown to everyone. Each agent holds an informative, yet noisy, private signal\nabout the quality. To make a correct allocation decision the planner attempts\nto learn the object quality by truthfully eliciting agents' signals. Under the\ncommonly applied sequential offering mechanism, we show that learning is\nhampered by the presence of strategic incentives as herding may emerge. This\ncan result in incorrect allocation and welfare loss. To overcome these issues,\nwe propose a novel class of incentive-compatible mechanisms. Our mechanism\ninvolves a batch-by-batch, dynamic voting process using a majority rule. We\nprove that the proposed voting mechanisms improve the probability of correct\nallocation whenever agents are sufficiently well informed. Particularly, we\nshow that such an improvement can be achieved via a simple greedy algorithm. We\nquantify the improvement using simulations.",
    "descriptor": "\nComments: To appear in Thirty-fifth Annual Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Jamie Kang",
      "Faidra Monachou",
      "Moran Koren",
      "Itai Ashlagi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.14865"
  },
  {
    "id": "arXiv:2110.14867",
    "title": "Modeling, simulation, and optimization of a monopod hopping on yielding  terrain",
    "abstract": "Legged locomotion on deformable terrain is a challenging and open\nrobo-physics problem since the uncertainty in terrain dynamics introduced by\nground deformation complicates the dynamical modelling and control methods.\nMoreover, learning how (e.g. what controls and mechanisms) to move efficiently\nand stably on soft ground is a bigger issue. This work seeks to control a 1D\nmonopod hopper to jump to desired height. To achieve this goal, I first set up\nand validate a discrete element method (DEM) based soft ground simulation\nenvironment of a spherical granular material. With this simulation environment,\nI generate resistive force theory (RFT) based models of the ground reaction\nforce. Then I use the RFT model to develop a feedforward force control for this\nrobot. In the DEM simulation, I use feedback control to compensate for\nvariations in the ground reaction force from the RFT model predictions. With\nthe feedback control, the robot tracks the desired trajectories well and\nreaches the desired height after five hops. It reduces the apex position errors\na lot more than a pure feedforward control. I also change the area of the\nrobots square foot from 1cm^2 to 49cm^2. The feedback controller is able to\ndeal with the ground reaction force fluctuations even when the foot dimensions\nare on the order of a grain diameter.",
    "descriptor": "",
    "authors": [
      "Juntao He"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.14867"
  },
  {
    "id": "arXiv:2110.14870",
    "title": "A Scenario-Based Platform for Testing Autonomous Vehicle Behavior  Prediction Models in Simulation",
    "abstract": "Behavior prediction remains one of the most challenging tasks in the\nautonomous vehicle (AV) software stack. Forecasting the future trajectories of\nnearby agents plays a critical role in ensuring road safety, as it equips AVs\nwith the necessary information to plan safe routes of travel. However, these\nprediction models are data-driven and trained on data collected in real life\nthat may not represent the full range of scenarios an AV can encounter. Hence,\nit is important that these prediction models are extensively tested in various\ntest scenarios involving interactive behaviors prior to deployment. To support\nthis need, we present a simulation-based testing platform which supports (1)\nintuitive scenario modeling with a probabilistic programming language called\nScenic, (2) specifying a multi-objective evaluation metric with a partial\npriority ordering, (3) falsification of the provided metric, and (4)\nparallelization of simulations for scalable testing. As a part of the platform,\nwe provide a library of 25 Scenic programs that model challenging test\nscenarios involving interactive traffic participant behaviors. We demonstrate\nthe effectiveness and the scalability of our platform by testing a trained\nbehavior prediction model and searching for failure scenarios.",
    "descriptor": "\nComments: Accepted to the NeurIPS 2021 Workshop on Machine Learning for Autonomous Driving\n",
    "authors": [
      "Francis Indaheng",
      "Edward Kim",
      "Kesav Viswanadha",
      "Jay Shenoy",
      "Jinkyu Kim",
      "Daniel J. Fremont",
      "Sanjit A. Seshia"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.14870"
  },
  {
    "id": "arXiv:2110.14871",
    "title": "Generalized Depthwise-Separable Convolutions for Adversarially Robust  and Efficient Neural Networks",
    "abstract": "Despite their tremendous successes, convolutional neural networks (CNNs)\nincur high computational/storage costs and are vulnerable to adversarial\nperturbations. Recent works on robust model compression address these\nchallenges by combining model compression techniques with adversarial training.\nBut these methods are unable to improve throughput (frames-per-second) on\nreal-life hardware while simultaneously preserving robustness to adversarial\nperturbations. To overcome this problem, we propose the method of Generalized\nDepthwise-Separable (GDWS) convolution -- an efficient, universal,\npost-training approximation of a standard 2D convolution. GDWS dramatically\nimproves the throughput of a standard pre-trained network on real-life hardware\nwhile preserving its robustness. Lastly, GDWS is scalable to large problem\nsizes since it operates on pre-trained models and doesn't require any\nadditional training. We establish the optimality of GDWS as a 2D convolution\napproximator and present exact algorithms for constructing optimal GDWS\nconvolutions under complexity and error constraints. We demonstrate the\neffectiveness of GDWS via extensive experiments on CIFAR-10, SVHN, and ImageNet\ndatasets. Our code can be found at https://github.com/hsndbk4/GDWS.",
    "descriptor": "\nComments: NeurIPS 2021 (Spotlight)\n",
    "authors": [
      "Hassan Dbouk",
      "Naresh R. Shanbhag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.14871"
  },
  {
    "id": "arXiv:2110.14873",
    "title": "Optimal Stochastic Coded Computation Offloading in Unmanned Aerial  Vehicles Network",
    "abstract": "Today, modern unmanned aerial vehicles (UAVs) are equipped with increasingly\nadvanced capabilities that can run applications enabled by machine learning\ntechniques, which require computationally intensive operations such as matrix\nmultiplications. Due to computation constraints, the UAVs can offload their\ncomputation tasks to edge servers. To mitigate stragglers, coded distributed\ncomputing (CDC) based offloading can be adopted. In this paper, we propose an\nOptimal Task Allocation Scheme (OTAS) based on Stochastic Integer Programming\nwith the objective to minimize energy consumption during computation\noffloading. The simulation results show that amid uncertainty of task\ncompletion, the energy consumption in the UAV network is minimized.",
    "descriptor": "\nComments: To be published in IEEE Global Communications Conference\n",
    "authors": [
      "Wei Chong Ng",
      "Wei Yang Bryan Lim",
      "Jer Shyuan Ng",
      "Suttinee Sawadsitang",
      "Zehui Xiong",
      "Dusit Niyato"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.14873"
  },
  {
    "id": "arXiv:2110.14874",
    "title": "Sayer: Using Implicit Feedback to Optimize System Policies",
    "abstract": "We observe that many system policies that make threshold decisions involving\na resource (e.g., time, memory, cores) naturally reveal additional, or implicit\nfeedback. For example, if a system waits X min for an event to occur, then it\nautomatically learns what would have happened if it waited <X min, because time\nhas a cumulative property. This feedback tells us about alternative decisions,\nand can be used to improve the system policy. However, leveraging implicit\nfeedback is difficult because it tends to be one-sided or incomplete, and may\ndepend on the outcome of the event. As a result, existing practices for using\nfeedback, such as simply incorporating it into a data-driven model, suffer from\nbias.\nWe develop a methodology, called Sayer, that leverages implicit feedback to\nevaluate and train new system policies. Sayer builds on two ideas from\nreinforcement learning -- randomized exploration and unbiased counterfactual\nestimators -- to leverage data collected by an existing policy to estimate the\nperformance of new candidate policies, without actually deploying those\npolicies. Sayer uses implicit exploration and implicit data augmentation to\ngenerate implicit feedback in an unbiased form, which is then used by an\nimplicit counterfactual estimator to evaluate and train new policies. The key\nidea underlying these techniques is to assign implicit probabilities to\ndecisions that are not actually taken but whose feedback can be inferred; these\nprobabilities are carefully calculated to ensure statistical unbiasedness. We\napply Sayer to two production scenarios in Azure, and show that it can evaluate\narbitrary policies accurately, and train new policies that outperform the\nproduction policies.",
    "descriptor": "",
    "authors": [
      "Mathias L\u00e9cuyer",
      "Sang Hoon Kim",
      "Mihir Nanavati",
      "Junchen Jiang",
      "Siddhartha Sen",
      "Amit Sharma",
      "Aleksandrs Slivkins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.14874"
  },
  {
    "id": "arXiv:2110.14875",
    "title": "Finding a Concise, Precise, and Exhaustive Set of Near Bi-Cliques in  Dynamic Graphs",
    "abstract": "A variety of tasks on dynamic graphs, including anomaly detection, community\ndetection, compression, and graph understanding, have been formulated as\nproblems of identifying constituent (near) bi-cliques (i.e., complete bipartite\ngraphs). Even when we restrict our attention to maximal ones, there can be\nexponentially many near bi-cliques, and thus finding all of them is practically\nimpossible for large graphs. Then, two questions naturally arise: (Q1) What is\na \"good\" set of near bi-cliques? That is, given a set of near bi-cliques in the\ninput dynamic graph, how should we evaluate its quality? (Q2) Given a large\ndynamic graph, how can we rapidly identify a high-quality set of near\nbi-cliques in it? Regarding Q1, we measure how concisely, precisely, and\nexhaustively a given set of near bi-cliques describes the input dynamic graph.\nWe combine these three perspectives systematically on the Minimum Description\nLength principle. Regarding Q2, we propose CutNPeel, a fast search algorithm\nfor a high-quality set of near bi-cliques. By adaptively re-partitioning the\ninput graph, CutNPeel reduces the search space and at the same time improves\nthe search quality. Our experiments using six real-world dynamic graphs\ndemonstrate that CutNPeel is (a) High-quality: providing near bi-cliques of up\nto 51.2% better quality than its state-of-the-art competitors, (b) Fast: up to\n68.8x faster than the next-best competitor, and (c) Scalable: scaling to graphs\nwith 134 million edges. We also show successful applications of CutNPeel to\ngraph compression and pattern discovery.",
    "descriptor": "\nComments: To be published in WSDM 2022\n",
    "authors": [
      "Hyeonjeong Shin",
      "Taehyung Kwon",
      "Neil Shah",
      "Kijung Shin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.14875"
  },
  {
    "id": "arXiv:2110.14879",
    "title": "Pilot Optimization and Channel Estimation for Two-way Relaying Network  Aided by IRS with Finite Discrete Phase Shifters",
    "abstract": "In this paper, we investigate the problem of pilot optimization and channel\nestimation of two-way relaying network (TWRN) aided by an intelligent\nreflecting surface (IRS) with finite discrete phase shifters. In a TWRN, there\nexists a challenging problem that the two cascading channels from\nsource-to-IRS-to-Relay and destination-to-IRS-to-relay interfere with each\nother. Via designing the initial phase shifts of IRS and pilot pattern, the two\ncascading channels are separated by using simple arithmetic operations like\naddition and subtraction. Then, the least-squares estimator is adopted to\nestimate the two cascading channels and two direct channels from source to\nrelay and destination to relay. The corresponding mean square errors (MSE) of\nchannel estimators are derived. By minimizing MSE, the optimal phase shift\nmatrix of IRS is proved. Then, two special matrices Hadamard and discrete\nFourier transform (DFT) matrix is shown to be two optimal training matrices for\nIRS. Furthermore, the IRS with discrete finite phase shifters is taken into\naccount. Using theoretical derivation and numerical simulations, we find that\n3-4 bits phase shifters are sufficient for IRS to achieve a negligible MSE\nperformance loss. More importantly, the Hadamard matrix requires only one-bit\nphase shifters to achieve the optimal MSE performance while the DFT matrix\nrequires at least three or four bits to achieve the same performance. Thus, the\nHadamard matrix is a perfect choice for channel estimation using low-resolution\nphase-shifting IRS.",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "Zhongwen Sun",
      "Xuehui Wang",
      "Siling Feng",
      "Xinrong Guan",
      "Feng Shu",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.14879"
  },
  {
    "id": "arXiv:2110.14880",
    "title": "AEVA: Black-box Backdoor Detection Using Adversarial Extreme Value  Analysis",
    "abstract": "Deep neural networks (DNNs) are proved to be vulnerable against backdoor\nattacks. A backdoor is often embedded in the target DNNs through injecting a\nbackdoor trigger into training examples, which can cause the target DNNs\nmisclassify an input attached with the backdoor trigger.\nExisting backdoor detection methods often require the access to the original\npoisoned training data, the parameters of the target DNNs, or the predictive\nconfidence for each given input, which are impractical in many real-world\napplications, e.g., on-device deployed DNNs. We address the black-box\nhard-label backdoor detection problem where the DNN is fully black-box and only\nits final output label is accessible. We approach this problem from the\noptimization perspective and show that the objective of backdoor detection is\nbounded by an adversarial objective. Further theoretical and empirical studies\nreveal that this adversarial objective leads to a solution with highly skewed\ndistribution; a singularity is often observed in the adversarial map of a\nbackdoor-infected example, which we call the adversarial singularity\nphenomenon. Based on this observation, we propose the adversarial extreme value\nanalysis(AEVA) to detect backdoors in black-box neural networks. AEVA is based\non an extreme value analysis of the adversarial map, computed from the\nmonte-carlo gradient estimation. Evidenced by extensive experiments across\nmultiple popular tasks and backdoor attacks, our approach is shown effective in\ndetecting backdoor attacks under the black-box hard-label scenarios.",
    "descriptor": "",
    "authors": [
      "Junfeng Guo",
      "Ang Li",
      "Cong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.14880"
  },
  {
    "id": "arXiv:2110.14883",
    "title": "Colossal-AI: A Unified Deep Learning System For Large-Scale Parallel  Training",
    "abstract": "The Transformer architecture has improved the performance of deep learning\nmodels in domains such as Computer Vision and Natural Language Processing.\nTogether with better performance come larger model sizes. This imposes\nchallenges to the memory wall of the current accelerator hardware such as GPU.\nIt is never ideal to train large models such as Vision Transformer, BERT, and\nGPT on a single GPU or a single machine. There is an urgent demand to train\nmodels in a distributed environment. However, distributed training, especially\nmodel parallelism, often requires domain expertise in computer systems and\narchitecture. It remains a challenge for AI researchers to implement complex\ndistributed training solutions for their models.\nIn this paper, we introduce Colossal-AI, which is a unified parallel training\nsystem designed to seamlessly integrate different paradigms of parallelization\ntechniques including data parallelism, pipeline parallelism, multiple tensor\nparallelism, and sequence parallelism. Colossal-AI aims to support the AI\ncommunity to write distributed models in the same way as how they write models\nnormally. This allows them to focus on developing the model architecture and\nseparates the concerns of distributed training from the development process.\nThe documentations can be found at https://www.colossalai.org and the source\ncode can be found at https://github.com/hpcaitech/ColossalAI.",
    "descriptor": "",
    "authors": [
      "Zhengda Bian",
      "Hongxin Liu",
      "Boxiang Wang",
      "Haichen Huang",
      "Yongbin Li",
      "Chuanrui Wang",
      "Fan Cui",
      "Yang You"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.14883"
  },
  {
    "id": "arXiv:2110.14888",
    "title": "Teaching an Active Learner with Contrastive Examples",
    "abstract": "We study the problem of active learning with the added twist that the learner\nis assisted by a helpful teacher. We consider the following natural interaction\nprotocol: At each round, the learner proposes a query asking for the label of\nan instance $x^q$, the teacher provides the requested label $\\{x^q, y^q\\}$\nalong with explanatory information to guide the learning process. In this\npaper, we view this information in the form of an additional contrastive\nexample ($\\{x^c, y^c\\}$) where $x^c$ is picked from a set constrained by $x^q$\n(e.g., dissimilar instances with the same label). Our focus is to design a\nteaching algorithm that can provide an informative sequence of contrastive\nexamples to the learner to speed up the learning process. We show that this\nleads to a challenging sequence optimization problem where the algorithm's\nchoices at a given round depend on the history of interactions. We investigate\nan efficient teaching algorithm that adaptively picks these contrastive\nexamples. We derive strong performance guarantees for our algorithm based on\ntwo problem-dependent parameters and further show that for specific types of\nactive learners (e.g., a generalized binary search learner), the proposed\nteaching algorithm exhibits strong approximation guarantees. Finally, we\nillustrate our bounds and demonstrate the effectiveness of our teaching\nframework via two numerical case studies.",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Chaoqi Wang",
      "Adish Singla",
      "Yuxin Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.14888"
  },
  {
    "id": "arXiv:2110.14890",
    "title": "SMORE: Knowledge Graph Completion and Multi-hop Reasoning in Massive  Knowledge Graphs",
    "abstract": "Knowledge graphs (KGs) capture knowledge in the form of head--relation--tail\ntriples and are a crucial component in many AI systems. There are two important\nreasoning tasks on KGs: (1) single-hop knowledge graph completion, which\ninvolves predicting individual links in the KG; and (2), multi-hop reasoning,\nwhere the goal is to predict which KG entities satisfy a given logical query.\nEmbedding-based methods solve both tasks by first computing an embedding for\neach entity and relation, then using them to form predictions. However,\nexisting scalable KG embedding frameworks only support single-hop knowledge\ngraph completion and cannot be applied to the more challenging multi-hop\nreasoning task. Here we present Scalable Multi-hOp REasoning (SMORE), the first\ngeneral framework for both single-hop and multi-hop reasoning in KGs. Using a\nsingle machine SMORE can perform multi-hop reasoning in Freebase KG (86M\nentities, 338M edges), which is 1,500x larger than previously considered KGs.\nThe key to SMORE's runtime performance is a novel bidirectional rejection\nsampling that achieves a square root reduction of the complexity of online\ntraining data generation. Furthermore, SMORE exploits asynchronous scheduling,\noverlapping CPU-based data sampling, GPU-based embedding computation, and\nfrequent CPU--GPU IO. SMORE increases throughput (i.e., training speed) over\nprior multi-hop KG frameworks by 2.2x with minimal GPU memory requirements (2GB\nfor training 400-dim embeddings on 86M-node Freebase) and achieves near linear\nspeed-up with the number of GPUs. Moreover, on the simpler single-hop knowledge\ngraph completion task SMORE achieves comparable or even better runtime\nperformance to state-of-the-art frameworks on both single GPU and multi-GPU\nsettings.",
    "descriptor": "",
    "authors": [
      "Hongyu Ren",
      "Hanjun Dai",
      "Bo Dai",
      "Xinyun Chen",
      "Denny Zhou",
      "Jure Leskovec",
      "Dale Schuurmans"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.14890"
  },
  {
    "id": "arXiv:2110.14891",
    "title": "Integrated Task Assignment and Path Planning for Capacitated Multi-Agent  Pickup and Delivery",
    "abstract": "Multi-agent Pickup and Delivery (MAPD) is a challenging industrial problem\nwhere a team of robots is tasked with transporting a set of tasks, each from an\ninitial location and each to a specified target location. Appearing in the\ncontext of automated warehouse logistics and automated mail sortation, MAPD\nrequires first deciding which robot is assigned what task (i.e., Task\nAssignment or TA) followed by a subsequent coordination problem where each\nrobot must be assigned collision-free paths so as to successfully complete its\nassignment (i.e., Multi-Agent Path Finding or MAPF). Leading methods in this\narea solve MAPD sequentially: first assigning tasks, then assigning paths. In\nthis work we propose a new coupled method where task assignment choices are\ninformed by actual delivery costs instead of by lower-bound estimates. The main\ningredients of our approach are a marginal-cost assignment heuristic and a\nmeta-heuristic improvement strategy based on Large Neighbourhood Search. As a\nfurther contribution, we also consider a variant of the MAPD problem where each\nrobot can carry multiple tasks instead of just one. Numerical simulations show\nthat our approach yields efficient and timely solutions and we report\nsignificant improvement compared with other recent methods from the literature.",
    "descriptor": "",
    "authors": [
      "Zhe Chen",
      "Javier Alonso-Mora",
      "Xiaoshan Bai",
      "Daniel D. Harabor",
      "Peter J. Stuckey"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.14891"
  },
  {
    "id": "arXiv:2110.14892",
    "title": "Analysis of COVID-19 in Japan with Extended SEIR model and ensemble  Kalman filter",
    "abstract": "We introduce an extended SEIR infectious disease model with data assimilation\nfor the study of the spread of COVID-19.In this framework, undetected\nasymptomatic and pre-symptomatic cases are taken into account, and the impact\nof their uncertain proportion is fully investigated. The standard SEIR model\ndoes not consider these populations, while their role in the propagation of the\ndisease is acknowledged. An ensemble Kalman filter is implemented to assimilate\nreliable observations of three compartments in the model. The system tracks the\nevolution of the effective reproduction number and estimates the unobservable\nsubpopulations. The analysis is carried out for three main prefectures of Japan\nand for the entire population of Japan. For these four populations, our\nestimated effective reproduction numbers are more stable than the corresponding\nones estimated by a different method (Toyokeizai). We also perform sensitivity\ntests for different values of some uncertain medical parameters, like the\nrelative infectivity of symptomatic / asymptomatic cases. The regional analysis\nresults suggest the decreasing efficiency of the states of emergency.",
    "descriptor": "\nComments: 29 pages, 18 figures, 1 table\n",
    "authors": [
      "Qiwen Sun",
      "Serge Richard",
      "Takemasa Miyoshi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2110.14892"
  },
  {
    "id": "arXiv:2110.14895",
    "title": "Pipeline Parallelism for Inference on Heterogeneous Edge Computing",
    "abstract": "Deep neural networks with large model sizes achieve state-of-the-art results\nfor tasks in computer vision (CV) and natural language processing (NLP).\nHowever, these large-scale models are too compute- or memory-intensive for\nresource-constrained edge devices. Prior works on parallel and distributed\nexecution primarily focus on training -- rather than inference -- using\nhomogeneous accelerators in data centers. We propose EdgePipe, a distributed\nframework for edge systems that uses pipeline parallelism to both speed up\ninference and enable running larger (and more accurate) models that otherwise\ncannot fit on single edge devices. EdgePipe achieves these results by using an\noptimal partition strategy that considers heterogeneity in compute, memory, and\nnetwork bandwidth. Our empirical evaluation demonstrates that EdgePipe achieves\n$10.59\\times$ and $11.88\\times$ speedup using 16 edge devices for the ViT-Large\nand ViT-Huge models, respectively, with no accuracy loss. Similarly, EdgePipe\nimproves ViT-Huge throughput by $3.93\\times$ over a 4-node baseline using 16\nedge devices, which independently cannot fit the model in memory. Finally, we\nshow up to $4.16\\times$ throughput improvement over the state-of-the-art\nPipeDream when using a heterogeneous set of devices.",
    "descriptor": "",
    "authors": [
      "Yang Hu",
      "Connor Imes",
      "Xuanang Zhao",
      "Souvik Kundu",
      "Peter A. Beerel",
      "Stephen P. Crago",
      "John Paul N. Walters"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14895"
  },
  {
    "id": "arXiv:2110.14902",
    "title": "NetDAM: Network Direct Attached Memory with Programmable In-Memory  Computing ISA",
    "abstract": "Data-intensive applications like distributed AI-training may require\nmulti-terabytes memory capacity with multi-terabits bandwidth. We directly\nattach the memory to the ethernet controller with some programable logic to\ndesign an efficient hardware \"template\" for Memory pooling and in-memory /\nin-network computing. We built an FPGA prototype of the NetDAM, andwe\ndemonstrate MPI-Allreduce communication case, the NetDAM can be used as a\nsoftware and hardware friendly programmable architeture with high performance\nalternative for RDMA.",
    "descriptor": "",
    "authors": [
      "Kevin Fang",
      "David Peng"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.14902"
  },
  {
    "id": "arXiv:2110.14904",
    "title": "SIMCNN -- Exploiting Computational Similarity to Accelerate CNN Training  in Hardware",
    "abstract": "Convolution neural networks (CNN) are computation intensive to train. It\nconsists of a substantial number of multidimensional dot products between many\nkernels and inputs. We observe that there are notable similarities among the\nvectors extracted from inputs (i.e., input vectors). If one input vector is\nsimilar to another one, its computations with the kernels are also similar to\nthose of the other and therefore, can be skipped by reusing the\nalready-computed results. Based on this insight, we propose a novel scheme\nbased on locality sensitive hashing (LSH) to exploit the similarity of\ncomputations during CNN training in a hardware accelerator. The proposed\nscheme, called SIMCNN, uses a cache (SIMCACHE) to store LSH signatures of\nrecent input vectors along with the computed results. If the LSH signature of a\nnew input vector matches with that of an already existing vector in the\nSIMCACHE, the already-computed result is reused for the new vector. SIMCNN is\nthe first work that exploits computational similarity for accelerating CNN\ntraining in hardware. The paper presents a detailed design, workflow, and\nimplementation of SIMCNN. Our experimental evaluation with four different deep\nlearning models shows that SIMCNN saves a significant number of computations\nand therefore, improves training time up to 43%.",
    "descriptor": "\nComments: 12 pages, 17 figures, 4 tables\n",
    "authors": [
      "Vahid Janfaza",
      "Kevin Weston",
      "Moein Razavi",
      "Shantanu Mandal",
      "Abdullah Muzahid"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.14904"
  },
  {
    "id": "arXiv:2110.14906",
    "title": "Distributed Joint Multi-cell Optimization of IRS Parameters with Linear  Precoders",
    "abstract": "We present distributed methods for jointly optimizing Intelligent Reflecting\nSurface (IRS) phase-shifts and beamformers in a cellular network. The proposed\nschemes require knowledge of only the intra-cell training sequences and\ncorresponding received signals without explicit channel estimation. Instead, an\nSINR objective is estimated via sample means and maximized directly. This\nautomatically includes and mitigates both intra- and inter-cell interference\nprovided that the uplink training is synchronized across cells. Different\nschemes are considered that limit the set of known training sequences from\ninterferers. With MIMO links an iterative synchronous bi-directional training\nscheme jointly optimizes the IRS parameters with the beamformers and combiners.\nSimulation results show that the proposed distributed methods show a modest\nperformance degradation compared to centralized channel estimation schemes,\nwhich estimate and exchange all cross-channels between cells, and perform\nsignificantly better than channel estimation schemes which ignore the\ninter-cell interference.",
    "descriptor": "\nComments: Submitted for publication in an IEEE conference\n",
    "authors": [
      "Reinhard Wiesmayr",
      "Michael Honig",
      "Michael Joham",
      "Wolfgang Utschick"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.14906"
  },
  {
    "id": "arXiv:2110.14908",
    "title": "E-ffective: A Visual Analytic System for Exploring the Emotion and  Effectiveness of Inspirational Speeches",
    "abstract": "What makes speeches effective has long been a subject for debate, and until\ntoday there is broad controversy among public speaking experts about what\nfactors make a speech effective as well as the roles of these factors in\nspeeches. Moreover, there is a lack of quantitative analysis methods to help\nunderstand effective speaking strategies. In this paper, we propose E-ffective,\na visual analytic system allowing speaking experts and novices to analyze both\nthe role of speech factors and their contribution in effective speeches. From\ninterviews with domain experts and investigating existing literature, we\nidentified important factors to consider in inspirational speeches. We obtained\nthe generated factors from multi-modal data that were then related to\neffectiveness data. Our system supports rapid understanding of critical factors\nin inspirational speeches, including the influence of emotions by means of\nnovel visualization methods and interaction. Two novel visualizations include\nE-spiral (that shows the emotional shifts in speeches in a visually compact\nway) and E-script (that connects speech content with key speech delivery\ninformation). In our evaluation we studied the influence of our system on\nexperts' domain knowledge about speech factors. We further studied the\nusability of the system by speaking novices and experts on assisting analysis\nof inspirational speech effectiveness.",
    "descriptor": "\nComments: IEEE Transactions of Visualization and Computer Graphics (TVCG, Proc. VIS 2021), to appear\n",
    "authors": [
      "Kevin Maher",
      "Zeyuan Huang",
      "Jiancheng Song",
      "Xiaoming Deng",
      "Yu-Kun Lai",
      "Cuixia Ma",
      "Hao Wang",
      "Yong-Jin Liu",
      "Hongan Wang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.14908"
  },
  {
    "id": "arXiv:2110.14911",
    "title": "A Machine Learning Approach for DDoS Detection on IoT Devices",
    "abstract": "In the current world, the Internet is being used almost everywhere. With the\nrise of IoT technology, which is one of the most used technologies, billions of\nIoT devices are interconnected over the Internet. However, DoS/DDoS attacks are\nthe most frequent and perilous threat to this growing technology. New types of\nDDoS attacks are highly advanced and complicated, and it is almost impossible\nto detect or mitigate by the existing intrusion detection systems and\ntraditional methods. Fortunately, Big Data, Data mining, and Machine Learning\ntechnologies make it possible to detect DDoS traffic effectively. This paper\nsuggests a DDoS detection model based on data mining and machine learning\ntechniques. For writing this paper, the latest available Dataset, CICDDoS2019,\nexperimented with the most popular machine learning algorithms and specified\nthe most correlated features with predicted classes are being used. It is\ndiscovered that AdaBoost and XGBoost were extraordinarily accurate and\ncorrectly predicted the type of network traffic with 100% accuracy. Future\nresearch can be extended by enhancing the model for multiclassification of\ndifferent DDoS attack types and testing hybrid algorithms and newer datasets on\nthis model.",
    "descriptor": "",
    "authors": [
      "Alireza Seifousadati",
      "Saeid Ghasemshirazi",
      "Mohammad Fathian"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.14911"
  },
  {
    "id": "arXiv:2110.14921",
    "title": "3D Object Tracking with Transformer",
    "abstract": "Feature fusion and similarity computation are two core problems in 3D object\ntracking, especially for object tracking using sparse and disordered point\nclouds. Feature fusion could make similarity computing more efficient by\nincluding target object information. However, most existing LiDAR-based\napproaches directly use the extracted point cloud feature to compute similarity\nwhile ignoring the attention changes of object regions during tracking. In this\npaper, we propose a feature fusion network based on transformer architecture.\nBenefiting from the self-attention mechanism, the transformer encoder captures\nthe inter- and intra- relations among different regions of the point cloud. By\nusing cross-attention, the transformer decoder fuses features and includes more\ntarget cues into the current point cloud feature to compute the region\nattentions, which makes the similarity computing more efficient. Based on this\nfeature fusion network, we propose an end-to-end point cloud object tracking\nframework, a simple yet effective method for 3D object tracking using point\nclouds. Comprehensive experimental results on the KITTI dataset show that our\nmethod achieves new state-of-the-art performance. Code is available at:\nhttps://github.com/3bobo/lttr.",
    "descriptor": "\nComments: BMVC2021\n",
    "authors": [
      "Yubo Cui",
      "Zheng Fang",
      "Jiayao Shan",
      "Zuoxu Gu",
      "Sifan Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.14921"
  },
  {
    "id": "arXiv:2110.14923",
    "title": "Modeling Heterogeneous Hierarchies with Relation-specific Hyperbolic  Cones",
    "abstract": "Hierarchical relations are prevalent and indispensable for organizing human\nknowledge captured by a knowledge graph (KG). The key property of hierarchical\nrelations is that they induce a partial ordering over the entities, which needs\nto be modeled in order to allow for hierarchical reasoning. However, current KG\nembeddings can model only a single global hierarchy (single global partial\nordering) and fail to model multiple heterogeneous hierarchies that exist in a\nsingle KG. Here we present ConE (Cone Embedding), a KG embedding model that is\nable to simultaneously model multiple hierarchical as well as non-hierarchical\nrelations in a knowledge graph. ConE embeds entities into hyperbolic cones and\nmodels relations as transformations between the cones. In particular, ConE uses\ncone containment constraints in different subspaces of the hyperbolic embedding\nspace to capture multiple heterogeneous hierarchies. Experiments on standard\nknowledge graph benchmarks show that ConE obtains state-of-the-art performance\non hierarchical reasoning tasks as well as knowledge graph completion task on\nhierarchical graphs. In particular, our approach yields new state-of-the-art\nHits@1 of 45.3% on WN18RR and 16.1% on DDB14 (0.231 MRR). As for hierarchical\nreasoning task, our approach outperforms previous best results by an average of\n20% across three hierarchical datasets.",
    "descriptor": "\nComments: To be published in NeurIPS 2021, full version including appendix\n",
    "authors": [
      "Yushi Bai",
      "Rex Ying",
      "Hongyu Ren",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.14923"
  },
  {
    "id": "arXiv:2110.14925",
    "title": "Hierarchical User Intent Graph Network forMultimedia Recommendation",
    "abstract": "In this work, we aim to learn multi-level user intents from the co-interacted\npatterns of items, so as to obtain high-quality representations of users and\nitems and further enhance the recommendation performance. Towards this end, we\ndevelop a novel framework, Hierarchical User Intent Graph Network, which\nexhibits user intents in a hierarchical graph structure, from the fine-grained\nto coarse-grained intents. In particular, we get the multi-level user intents\nby recursively performing two operations: 1) intra-level aggregation, which\ndistills the signal pertinent to user intents from co-interacted item graphs;\nand 2) inter-level aggregation, which constitutes the supernode in higher\nlevels to model coarser-grained user intents via gathering the nodes'\nrepresentations in the lower ones. Then, we refine the user and item\nrepresentations as a distribution over the discovered intents, instead of\nsimple pre-existing features. To demonstrate the effectiveness of our model, we\nconducted extensive experiments on three public datasets. Our model achieves\nsignificant improvements over the state-of-the-art methods, including MMGCN and\nDisenGCN. Furthermore, by visualizing the item representations, we provide the\nsemantics of user intents.",
    "descriptor": "",
    "authors": [
      "Wei Yinwei",
      "Wang Xiang",
      "He Xiangnan",
      "Nie Liqiang",
      "Rui Yong",
      "Chua Tat-Seng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.14925"
  },
  {
    "id": "arXiv:2110.14928",
    "title": "Learning Actions for Drift-Free Navigation in Highly Dynamic Scenes",
    "abstract": "We embark on a hitherto unreported problem of an autonomous robot\n(self-driving car) navigating in dynamic scenes in a manner that reduces its\nlocalization error and eventual cumulative drift or Absolute Trajectory Error,\nwhich is pronounced in such dynamic scenes. With the hugely popular Velodyne-16\n3D LIDAR as the main sensing modality, and the accurate LIDAR-based\nLocalization and Mapping algorithm, LOAM, as the state estimation framework, we\nshow that in the absence of a navigation policy, drift rapidly accumulates in\nthe presence of moving objects. To overcome this, we learn actions that lead to\ndrift-minimized navigation through a suitable set of reward and penalty\nfunctions. We use Proximal Policy Optimization, a class of Deep Reinforcement\nLearning methods, to learn the actions that result in drift-minimized\ntrajectories. We show by extensive comparisons on a variety of synthetic, yet\nphoto-realistic scenes made available through the CARLA Simulator the superior\nperformance of the proposed framework vis-a-vis methods that do not adopt such\npolicies.",
    "descriptor": "\nComments: Submitted to ACC 2022\n",
    "authors": [
      "Mohd Omama",
      "Sundar Sripada V. S.",
      "Sandeep Chinchali",
      "K. Madhava Krishna"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.14928"
  },
  {
    "id": "arXiv:2110.14932",
    "title": "A recursive robust filtering approach for 3D registration",
    "abstract": "This work presents a new recursive robust filtering approach for\nfeature-based 3D registration. Unlike the common state-of-the-art alignment\nalgorithms, the proposed method has four advantages that have not yet occurred\naltogether in any previous solution. For instance, it is able to deal with\ninherent noise contaminating sensory data; it is robust to uncertainties caused\nby noisy feature localisation; it also combines the advantages of both (Formula\npresented.) and (Formula presented.) norms for a higher performance and a more\nprospective prevention of local minima. The result is an accurate and stable\nrigid body transformation. The latter enables a thorough control over the\nconvergence regarding the alignment as well as a correct assessment of the\nquality of registration. The mathematical rationale behind the proposed\napproach is explained, and the results are validated on physical and synthetic\ndata.",
    "descriptor": "\nComments: Accepted in the journal of Signal Image and Video Processing\n",
    "authors": [
      "Abdenour Amamra",
      "Nabil Aouf",
      "Dowling Stuart",
      "Mark Richardson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.14932"
  },
  {
    "id": "arXiv:2110.14933",
    "title": "Analysis of a finite-volume scheme for a single-species biofilm model",
    "abstract": "An implicit Euler finite-volume scheme for a parabolic reaction-diffusion\nsystem modeling biofilm growth is analyzed and implemented. The system consists\nof a degenerate-singular diffusion equation for the biomass fraction, which is\ncoupled to a diffusion equation for the nutrient concentration, and it is\nsolved in a bounded domain with Dirichlet boundary conditions. By transforming\nthe biomass fraction to an entropy-type variable, it is shown that the\nnumerical scheme preserves the lower and upper bounds of the biomass fraction.\nThe existence and uniqueness of a discrete solution and the convergence of the\nscheme are proved. Numerical experiments in one and two space dimensions\nillustrate, respectively, the rate of convergence in space of our scheme and\nthe temporal evolution of the biomass fraction and the nutrient concentration.",
    "descriptor": "",
    "authors": [
      "Christoph Helmer",
      "Ansgar J\u00fcngel",
      "Antoine Zurek"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.14933"
  },
  {
    "id": "arXiv:2110.14934",
    "title": "GPU based GMM segmentation of kinect data",
    "abstract": "This paper presents a novel approach for background/foreground segmentation\nof RGBD data with the Gaussian Mixture Models (GMM). We first start by the\nbackground subtraction from the colour and depth images separately. The\nforegrounds resulting from both streams are then fused for a more accurate\ndetection. Our segmentation solution is implemented on the GPU. Thus, it works\nat the full frame rate of the sensor (30fps). Test results show its robustness\nagainst illumination change, shadows and reflections.",
    "descriptor": "\nComments: Accepted in ELMAR-2014 conference\n",
    "authors": [
      "Abdenour Amamra",
      "Tarek Mouats",
      "Nabil Aouf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.14934"
  },
  {
    "id": "arXiv:2110.14936",
    "title": "Exploration of Algorithmic Trading Strategies for the Bitcoin Market",
    "abstract": "Bitcoin is firmly becoming a mainstream asset in our global society. Its\nhighly volatile nature has traders and speculators flooding into the market to\ntake advantage of its significant price swings in the hope of making money.\nThis work brings an algorithmic trading approach to the Bitcoin market to\nexploit the variability in its price on a day-to-day basis through the\nclassification of its direction. Building on previous work, in this paper, we\nutilise both features internal to the Bitcoin network and external features to\ninform the prediction of various machine learning models. As an empirical test\nof our models, we evaluate them using a real-world trading strategy on\ncompletely unseen data collected throughout the first quarter of 2021. Using\nonly a binary predictor, at the end of our three-month trading period, our\nmodels showed an average profit of 86\\%, matching the results of the more\ntraditional buy-and-hold strategy. However, after incorporating a risk\ntolerance score into our trading strategy by utilising the model's prediction\nconfidence scores, our models were 12.5\\% more profitable than the simple\nbuy-and-hold strategy. These results indicate the credible potential that\nmachine learning models have in extracting profit from the Bitcoin market and\nact as a front-runner for further research into real-world Bitcoin trading.",
    "descriptor": "\nComments: 9 pages, 4 figures, submitted to Soft Computing Letters\n",
    "authors": [
      "Nathan Crone",
      "Eoin Brophy",
      "Tomas Ward"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14936"
  },
  {
    "id": "arXiv:2110.14937",
    "title": "Computational Intelligence and Deep Learning for Next-Generation  Edge-Enabled Industrial IoT",
    "abstract": "In this paper, we investigate how to deploy computational intelligence and\ndeep learning (DL) in edge-enabled industrial IoT networks. In this system, the\nIoT devices can collaboratively train a shared model without compromising data\nprivacy. However, due to limited resources in the industrial IoT networks,\nincluding computational power, bandwidth, and channel state, it is challenging\nfor many devices to accomplish local training and upload weights to the edge\nserver in time. To address this issue, we propose a novel multi-exit-based\nfederated edge learning (ME-FEEL) framework, where the deep model can be\ndivided into several sub-models with different depths and output prediction\nfrom the exit in the corresponding sub-model. In this way, the devices with\ninsufficient computational power can choose the earlier exits and avoid\ntraining the complete model, which can help reduce computational latency and\nenable devices to participate into aggregation as much as possible within a\nlatency threshold. Moreover, we propose a greedy approach-based exit selection\nand bandwidth allocation algorithm to maximize the total number of exits in\neach communication round. Simulation experiments are conducted on the classical\nFashion-MNIST dataset under a non-independent and identically distributed\n(non-IID) setting, and it shows that the proposed strategy outperforms the\nconventional FL. In particular, the proposed ME-FEEL can achieve an accuracy\ngain up to 32.7% in the industrial IoT networks with the severely limited\nresources.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version will be superseded\n",
    "authors": [
      "Shunpu Tang",
      "Lunyuan Chen",
      "Ke HeJunjuan Xia",
      "Lisheng Fan",
      "Arumugam Nallanathan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.14937"
  },
  {
    "id": "arXiv:2110.14940",
    "title": "FocusFace: Multi-task Contrastive Learning for Masked Face Recognition",
    "abstract": "SARS-CoV-2 has presented direct and indirect challenges to the scientific\ncommunity. One of the most prominent indirect challenges advents from the\nmandatory use of face masks in a large number of countries. Face recognition\nmethods struggle to perform identity verification with similar accuracy on\nmasked and unmasked individuals. It has been shown that the performance of\nthese methods drops considerably in the presence of face masks, especially if\nthe reference image is unmasked. We propose FocusFace, a multi-task\narchitecture that uses contrastive learning to be able to accurately perform\nmasked face recognition. The proposed architecture is designed to be trained\nfrom scratch or to work on top of state-of-the-art face recognition methods\nwithout sacrificing the capabilities of a existing models in conventional face\nrecognition tasks. We also explore different approaches to design the\ncontrastive learning module. Results are presented in terms of masked-masked\n(M-M) and unmasked-masked (U-M) face verification performance. For both\nsettings, the results are on par with published methods, but for M-M\nspecifically, the proposed method was able to outperform all the solutions that\nit was compared to. We further show that when using our method on top of\nalready existing methods the training computational costs decrease\nsignificantly while retaining similar performances. The implementation and the\ntrained models are available at GitHub.",
    "descriptor": "\nComments: Accepted at Face and Gesture for Covid 2021 (FG4COVID2021)\n",
    "authors": [
      "Pedro C. Neto",
      "Fadi Boutros",
      "Jo\u00e3o Ribeiro Pinto",
      "Naser Damer",
      "Ana F. Sequeira",
      "Jaime S. Cardoso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14940"
  },
  {
    "id": "arXiv:2110.14941",
    "title": "A Novel Sample-efficient Deep Reinforcement Learning with Episodic  Policy Transfer for PID-Based Control in Cardiac Catheterization Robots",
    "abstract": "Robotic catheterization is typically used for percutaneous coronary\nintervention procedures nowadays and it involves steering flexible endovascular\ntools to open up occlusion in the coronaries. In this study, a sample-efficient\ndeep reinforcement learning with episodic policy transfer is, for the first\ntime, used for motion control during robotic catheterization with fully\nadaptive PID tuning strategy. The reinforcement model aids the agent to\ncontinuously learn from its interactions in its environment and adaptively tune\nPID control gains for axial navigation of endovascular tool. The model was\nvalidated for axial motion control of a robotic system designed for\nintravascular catheterization. Simulation and experimental trials were done to\nvalidate the application of the model, and results obtained shows it could\nself-tune PID gains appropriately for motion control of a robotic catheter\nsystem. Performance comparison with conventional methods in average of 10\ntrials shows the agent tunes the gain better with error of 0.003 mm. Thus, the\nproposed model would offer more stable set-point motion control robotic\ncatheterization.",
    "descriptor": "\nComments: 6 pages, 7 figures\n",
    "authors": [
      "Olatunji Mumini Omisore",
      "Toluwanimi Akinyemi",
      "Wenke Duan",
      "Wenjing Du",
      "Lei Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.14941"
  },
  {
    "id": "arXiv:2110.14943",
    "title": "Semi-Siamese Bi-encoder Neural Ranking Model Using Lightweight  Fine-Tuning",
    "abstract": "A BERT-based Neural Ranking Model (NRM) can be either a cross-encoder or a\nbi-encoder. Between the two, bi-encoder is highly efficient because all the\ndocuments can be pre-processed before the actual query time. Although query and\ndocument are independently encoded, the existing bi-encoder NRMs are Siamese\nmodels where a single language model is used for consistently encoding both of\nquery and document. In this work, we show two approaches for improving the\nperformance of BERT-based bi-encoders. The first approach is to replace the\nfull fine-tuning step with a lightweight fine-tuning. We examine lightweight\nfine-tuning methods that are adapter-based, prompt-based, and hybrid of the\ntwo. The second approach is to develop semi-Siamese models where queries and\ndocuments are handled with a limited amount of difference. The limited\ndifference is realized by learning two lightweight fine-tuning modules, where\nthe main language model of BERT is kept common for both query and document. We\nprovide extensive experiment results for monoBERT, TwinBERT, and ColBERT where\nthree performance metrics are evaluated over Robust04, ClueWeb09b, and MS-MARCO\ndatasets. The results confirm that both lightweight fine-tuning and\nsemi-Siamese are considerably helpful for improving BERT-based bi-encoders. In\nfact, lightweight fine-tuning is helpful for cross-encoder, too.",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Euna Jung",
      "Jaekeol Choi",
      "Wonjong Rhee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.14943"
  },
  {
    "id": "arXiv:2110.14944",
    "title": "Dispensed Transformer Network for Unsupervised Domain Adaptation",
    "abstract": "Accurate segmentation is a crucial step in medical image analysis and\napplying supervised machine learning to segment the organs or lesions has been\nsubstantiated effective. However, it is costly to perform data annotation that\nprovides ground truth labels for training the supervised algorithms, and the\nhigh variance of data that comes from different domains tends to severely\ndegrade system performance over cross-site or cross-modality datasets. To\nmitigate this problem, a novel unsupervised domain adaptation (UDA) method\nnamed dispensed Transformer network (DTNet) is introduced in this paper. Our\nnovel DTNet contains three modules. First, a dispensed residual transformer\nblock is designed, which realizes global attention by dispensed interleaving\noperation and deals with the excessive computational cost and GPU memory usage\nof the Transformer. Second, a multi-scale consistency regularization is\nproposed to alleviate the loss of details in the low-resolution output for\nbetter feature alignment. Finally, a feature ranking discriminator is\nintroduced to automatically assign different weights to domain-gap features to\nlessen the feature distribution distance, reducing the performance shift of two\ndomains. The proposed method is evaluated on large fluorescein angiography (FA)\nretinal nonperfusion (RNP) cross-site dataset with 676 images and a wide used\ncross-modality dataset from the MM-WHS challenge. Extensive results demonstrate\nthat our proposed network achieves the best performance in comparison with\nseveral state-of-the-art techniques.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Yunxiang Li",
      "Jingxiong Li",
      "Ruilong Dan",
      "Shuai Wang",
      "Kai Jin",
      "Guodong Zeng",
      "Jun Wang",
      "Xiangji Pan",
      "Qianni Zhang",
      "Huiyu Zhou",
      "Qun Jin",
      "Li Wang",
      "Yaqi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.14944"
  },
  {
    "id": "arXiv:2110.14945",
    "title": "Preventing posterior collapse in variational autoencoders for text  generation via decoder regularization",
    "abstract": "Variational autoencoders trained to minimize the reconstruction error are\nsensitive to the posterior collapse problem, that is the proposal posterior\ndistribution is always equal to the prior. We propose a novel regularization\nmethod based on fraternal dropout to prevent posterior collapse. We evaluate\nour approach using several metrics and observe improvements in all the tested\nconfigurations.",
    "descriptor": "\nComments: Accepted at NeurIPS 2021 Workshop DGMs Applications\n",
    "authors": [
      "Alban Petit",
      "Caio Corro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.14945"
  },
  {
    "id": "arXiv:2110.14946",
    "title": "Towards Large-Scale Rendering of Simulated Crops for Synthetic Ground  Truth Generation on Modular Supercomputers",
    "abstract": "Computer Vision problems deal with the semantic extraction of information\nfrom camera images. Especially for field crop images, the underlying problems\nare hard to label and even harder to learn, and the availability of\nhigh-quality training data is low. Deep neural networks do a good job of\nextracting the necessary models from training examples. However, they rely on\nan abundance of training data that is not feasible to generate or label by\nexpert annotation. To address this challenge, we make use of the Unreal Engine\nto render large and complex virtual scenes. We rely on the performance of\nindividual nodes by distributing plant simulations across nodes and both\ngenerate scenes as well as train neural networks on GPUs, restricting node\ncommunication to parallel learning.",
    "descriptor": "\nComments: Accepted Poster for the 11th IEEE Symposium on Large Data Analysis and Visualization\n",
    "authors": [
      "Dirk Norbert Helmrich",
      "Jens Henrik G\u00f6bbert",
      "Mona Giraud",
      "Hanno Scharr",
      "Andrea Schnepf",
      "Morris Riedel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.14946"
  },
  {
    "id": "arXiv:2110.14948",
    "title": "Better Sum Estimation via Weighted Sampling",
    "abstract": "Given a large set $U$ where each item $a\\in U$ has weight $w(a)$, we want to\nestimate the total weight $W=\\sum_{a\\in U} w(a)$ to within factor of\n$1\\pm\\varepsilon$ with some constant probability $>1/2$. Since $n=|U|$ is\nlarge, we want to do this without looking at the entire set $U$. In the\ntraditional setting in which we are allowed to sample elements from $U$\nuniformly, sampling $\\Omega(n)$ items is necessary to provide any non-trivial\nguarantee on the estimate. Therefore, we investigate this problem in different\nsettings: in the \\emph{proportional} setting we can sample items with\nprobabilities proportional to their weights, and in the \\emph{hybrid} setting\nwe can sample both proportionally and uniformly. These settings have\napplications, for example, in sublinear-time algorithms and distribution\ntesting.\nSum estimation in the proportional and hybrid setting has been considered\nbefore by Motwani, Panigrahy, and Xu [ICALP, 2007]. In their paper, they give\nboth upper and lower bounds in terms of $n$. Their bounds are near-matching in\nterms of $n$, but not in terms of $\\varepsilon$. In this paper, we improve both\ntheir upper and lower bounds. Our bounds are matching up to constant factors in\nboth settings, in terms of both $n$ and $\\varepsilon$. No lower bounds with\ndependency on $\\varepsilon$ were known previously. In the proportional setting,\nwe improve their $\\tilde{O}(\\sqrt{n}/\\varepsilon^{7/2})$ algorithm to\n$O(\\sqrt{n}/\\varepsilon)$. In the hybrid setting, we improve\n$\\tilde{O}(\\sqrt[3]{n}/ \\varepsilon^{9/2})$ to\n$O(\\sqrt[3]{n}/\\varepsilon^{4/3})$. Our algorithms are also significantly\nsimpler and do not have large constant factors. We also investigate the\npreviously unexplored setting where $n$ is unknown to the algorithm. Finally,\nwe show how our techniques apply to the problem of edge counting in graphs.",
    "descriptor": "\nComments: To appear at SODA 2022\n",
    "authors": [
      "Lorenzo Beretta",
      "Jakub T\u011btek"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.14948"
  },
  {
    "id": "arXiv:2110.14953",
    "title": "Multi-Task Processes",
    "abstract": "Neural Processes (NPs) consider a task as a function realized from a\nstochastic process and flexibly adapt to unseen tasks through inference on\nfunctions. However, naive NPs can model data from only a single stochastic\nprocess and are designed to infer each task independently. Since many\nreal-world data represent a set of correlated tasks from multiple sources\n(e.g., multiple attributes and multi-sensor data), it is beneficial to infer\nthem jointly and exploit the underlying correlation to improve the predictive\nperformance. To this end, we propose Multi-Task Processes (MTPs), an extension\nof NPs designed to jointly infer tasks realized from multiple stochastic\nprocesses. We build our MTPs in a hierarchical manner such that inter-task\ncorrelation is considered by conditioning all per-task latent variables on a\nsingle global latent variable. In addition, we further design our MTPs so that\nthey can address multi-task settings with incomplete data (i.e., not all tasks\nshare the same set of input points), which has high practical demands in\nvarious applications. Experiments demonstrate that MTPs can successfully model\nmultiple tasks jointly by discovering and exploiting their correlations in\nvarious real-world data such as time series of weather attributes and\npixel-aligned visual modalities.",
    "descriptor": "\nComments: 33 pages, 13 figures\n",
    "authors": [
      "Donggyun Kim",
      "Seongwoong Cho",
      "Wonkwang Lee",
      "Seunghoon Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.14953"
  },
  {
    "id": "arXiv:2110.14957",
    "title": "End-to-End Speech Emotion Recognition: Challenges of Real-Life Emergency  Call Centers Data Recordings",
    "abstract": "Recognizing a speaker's emotion from their speech can be a key element in\nemergency call centers. End-to-end deep learning systems for speech emotion\nrecognition now achieve equivalent or even better results than conventional\nmachine learning approaches. In this paper, in order to validate the\nperformance of our neural network architecture for emotion recognition from\nspeech, we first trained and tested it on the widely used corpus accessible by\nthe community, IEMOCAP. We then used the same architecture as the real life\ncorpus, CEMO, composed of 440 dialogs (2h16m) from 485 speakers. The most\nfrequent emotions expressed by callers in these real life emergency dialogues\nare fear, anger and positive emotions such as relief. In the IEMOCAP general\ntopic conversations, the most frequent emotions are sadness, anger and\nhappiness. Using the same end-to-end deep learning architecture, an Unweighted\nAccuracy Recall (UA) of 63% is obtained on IEMOCAP and a UA of 45.6% on CEMO,\neach with 4 classes. Using only 2 classes (Anger, Neutral), the results for\nCEMO are 76.9% UA compared to 81.1% UA for IEMOCAP. We expect that these\nencouraging results with CEMO can be improved by combining the audio channel\nwith the linguistic channel. Real-life emotions are clearly more complex than\nacted ones, mainly due to the large diversity of emotional expressions of\nspeakers. Index Terms-emotion detection, end-to-end deep learning architecture,\ncall center, real-life database, complex emotions.",
    "descriptor": "",
    "authors": [
      "Th\u00e9o Deschamps-Berger",
      "Lori Lamel",
      "Laurence Devillers"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.14957"
  },
  {
    "id": "arXiv:2110.14960",
    "title": "An AI-based Approach for Tracing Content Requirements in Financial  Documents",
    "abstract": "The completeness (in terms of content) of financial documents is a\nfundamental requirement for investment funds. To ensure completeness, financial\nregulators spend a huge amount of time for carefully checking every financial\ndocument based on the relevant content requirements, which prescribe the\ninformation types to be included in financial documents (e.g., the description\nof shares' issue conditions). Although several techniques have been proposed to\nautomatically detect certain types of information in documents in various\napplication domains, they provide limited support to help regulators\nautomatically identify the text chunks related to financial information types,\ndue to the complexity of financial documents and the diversity of the sentences\ncharacterizing an information type. In this paper, we propose FITI, an\nartificial intelligence (AI)-based method for tracing content requirements in\nfinancial documents. Given a new financial document, FITI selects a set of\ncandidate sentences for efficient information type identification. Then, FITI\nuses a combination of rule-based and data-centric approaches, by leveraging\ninformation retrieval (IR) and machine learning (ML) techniques that analyze\nthe words, sentences, and contexts related to an information type, to rank\ncandidate sentences. Finally, using a list of indicator phrases related to each\ninformation type, a heuristic-based selector, which considers both the sentence\nranking and the domain-specific phrases, determines a list of sentences\ncorresponding to each information type. We evaluated FITI by assessing its\neffectiveness in tracing financial content requirements in 100 financial\ndocuments. Experimental results show that FITI provides accurate identification\nwith average precision and recall values of 0.824 and 0.646, respectively.\nFurthermore, FITI can detect about 80% of missing information types in\nfinancial documents.",
    "descriptor": "\nComments: 17 pages, 3 figures\n",
    "authors": [
      "Xiaochen Li",
      "Domenico Bianculli",
      "Lionel C. Briand"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.14960"
  },
  {
    "id": "arXiv:2110.14961",
    "title": "Roto-translated Local Coordinate Frames For Interacting Dynamical  Systems",
    "abstract": "Modelling interactions is critical in learning complex dynamical systems,\nnamely systems of interacting objects with highly non-linear and time-dependent\nbehaviour. A large class of such systems can be formalized as\n$\\textit{geometric graphs}$, $\\textit{i.e.}$, graphs with nodes positioned in\nthe Euclidean space given an $\\textit{arbitrarily}$ chosen global coordinate\nsystem, for instance vehicles in a traffic scene. Notwithstanding the arbitrary\nglobal coordinate system, the governing dynamics of the respective dynamical\nsystems are invariant to rotations and translations, also known as\n$\\textit{Galilean invariance}$. As ignoring these invariances leads to worse\ngeneralization, in this work we propose local coordinate frames per node-object\nto induce roto-translation invariance to the geometric graph of the interacting\ndynamical system. Further, the local coordinate frames allow for a natural\ndefinition of anisotropic filtering in graph neural networks. Experiments in\ntraffic scenes, 3D motion capture, and colliding particles demonstrate that the\nproposed approach comfortably outperforms the recent state-of-the-art.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Miltiadis Kofinas",
      "Naveen Shankar Nagaraja",
      "Efstratios Gavves"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.14961"
  },
  {
    "id": "arXiv:2110.14962",
    "title": "Gradient Inversion with Generative Image Prior",
    "abstract": "Federated Learning (FL) is a distributed learning framework, in which the\nlocal data never leaves clients devices to preserve privacy, and the server\ntrains models on the data via accessing only the gradients of those local data.\nWithout further privacy mechanisms such as differential privacy, this leaves\nthe system vulnerable against an attacker who inverts those gradients to reveal\nclients sensitive data. However, a gradient is often insufficient to\nreconstruct the user data without any prior knowledge. By exploiting a\ngenerative model pretrained on the data distribution, we demonstrate that data\nprivacy can be easily breached. Further, when such prior knowledge is\nunavailable, we investigate the possibility of learning the prior from a\nsequence of gradients seen in the process of FL training. We experimentally\nshow that the prior in a form of generative model is learnable from iterative\ninteractions in FL. Our findings strongly suggest that additional mechanisms\nare necessary to prevent privacy leakage in FL.",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Jinwoo Jeon",
      "Jaechang Kim",
      "Kangwook Lee",
      "Sewoong Oh",
      "Jungseul Ok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14962"
  },
  {
    "id": "arXiv:2110.14968",
    "title": "DocScanner: Robust Document Image Rectification with Progressive  Learning",
    "abstract": "Compared to flatbed scanners, portable smartphones are much more convenient\nfor physical documents digitizing. However, such digitized documents are often\ndistorted due to uncontrolled physical deformations, camera positions, and\nillumination variations. To this end, this work presents DocScanner, a new deep\nnetwork architecture for document image rectification. Different from existing\nmethods, DocScanner addresses this issue by introducing a progressive learning\nmechanism. Specifically, DocScanner maintains a single estimate of the\nrectified image, which is progressively corrected with a recurrent\narchitecture. The iterative refinements make DocScanner converge to a robust\nand superior performance, and the lightweight recurrent architecture ensures\nthe running efficiency. In addition, before the above rectification process,\nobserving the corrupted rectified boundaries existing in prior works,\nDocScanner exploits a document localization module to explicitly segment the\nforeground document from the cluttered background environments. To further\nimprove the rectification quality, based on the geometric priori between the\ndistorted and the rectified images, a geometric regularization is introduced\nduring training to further facilitate the performance. Extensive experiments\nare conducted on the Doc3D dataset and the DocUNet benchmark dataset, and the\nquantitative and qualitative evaluation results verify the effectiveness of\nDocScanner, which outperforms previous methods on OCR accuracy, image\nsimilarity, and our proposed distortion metric by a considerable margin.\nFurthermore, our DocScanner shows the highest efficiency in inference time and\nparameter count.",
    "descriptor": "",
    "authors": [
      "Hao Feng",
      "Wengang Zhou",
      "Jiajun Deng",
      "Qi Tian",
      "Houqiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.14968"
  },
  {
    "id": "arXiv:2110.14972",
    "title": "Streaming Local Community Detection through Approximate Conductance",
    "abstract": "Community is a universal structure in various complex networks, and community\ndetection is a fundamental task for network analysis. With the rapid growth of\nnetwork scale, networks are massive, changing rapidly and could naturally be\nmodeled as graph streams. Due to the limited memory and access constraint in\ngraph streams, existing non-streaming community detection methods are no longer\napplicable. This raises an emerging need for online approaches. In this work,\nwe consider the problem of uncovering the local community containing a few\nquery nodes in graph streams, termed streaming local community detection. This\nis a new problem raised recently that is more challenging for community\ndetection and only a few works address this online setting. Correspondingly, we\ndesign an online single-pass streaming local community detection approach.\nInspired by the \"local\" property of communities, our method samples the local\nstructure around the query nodes in graph streams, and extracts the target\ncommunity on the sampled subgraph using our proposed metric called the\napproximate conductance. Comprehensive experiments show that our method\nremarkably outperforms the streaming baseline on both effectiveness and\nefficiency, and even achieves similar accuracy comparing to the\nstate-of-the-art non-streaming local community detection methods that use\nstatic and complete graphs.",
    "descriptor": "",
    "authors": [
      "Yanhao Yang",
      "Meng Wang",
      "David Bindel",
      "Kun He"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.14972"
  },
  {
    "id": "arXiv:2110.14979",
    "title": "Unmanned Aerial Vehicles Traffic Management Solution Using Crowd-sensing  and Blockchain",
    "abstract": "Unmanned aerial vehicles (UAVs) are gaining immense attention due to their\npotential to revolutionize various businesses and industries. However, the\nadoption of UAV-assisted applications will strongly rely on the provision of\nreliable systems that allow managing UAV operations at high levels of safety\nand security. Recently, the concept of UAV traffic management (UTM) has been\nintroduced to support safe, efficient, and fair access to low-altitude airspace\nfor commercial UAVs. A UTM system identifies multiple cooperating parties with\ndifferent roles and levels of authority to provide real-time services to\nairspace users. However, current UTM systems are centralized and lack a clear\ndefinition of protocols that govern a secure interaction between authorities,\nservice providers, and end-users. The lack of such protocols renders the UTM\nsystem unscalable and prone to various cyber attacks. Another limitation of the\ncurrently proposed UTM architecture is the absence of an efficient mechanism to\nenforce airspace rules and regulations. To address this issue, we propose a\ndecentralized UTM protocol that controls access to airspace while ensuring high\nlevels of integrity, availability, and confidentiality of airspace operations.\nTo achieve this, we exploit key features of the blockchain and smart contract\ntechnologies. In addition, we employ a mobile crowdsensing (MCS) mechanism to\nseamlessly enforce airspace rules and regulations that govern the UAV\noperations. The solution is implemented on top of the Etheruem platform and\nverified using four different smart contract verification tools. We also\nprovided a security and cost analysis of our solution. For reproducibility, we\nmade our implementation publicly available on Github.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication\n",
    "authors": [
      "Ruba Alkadi",
      "Abdulhadi Shoufan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.14979"
  },
  {
    "id": "arXiv:2110.14980",
    "title": "Multivariate Empirical Mode Decomposition based Hybrid Model for  Day-ahead Peak Load Forecasting",
    "abstract": "Accurate day-ahead peak load forecasting is crucial not only for power\ndispatching but also has a great interest to investors and energy policy maker\nas well as government. Literature reveals that 1% error drop of forecast can\nreduce 10 million pounds operational cost. Thus, this study proposed a novel\nhybrid predictive model built upon multivariate empirical mode decomposition\n(MEMD) and support vector regression (SVR) with parameters optimized by\nparticle swarm optimization (PSO), which is able to capture precise electricity\npeak load. The novelty of this study mainly comes from the application of MEMD,\nwhich enables the multivariate data decomposition to effectively extract\ninherent information among relevant variables at different time frequency\nduring the deterioration of multivariate over time. Two real-world load data\nsets from the New South Wales (NSW) and the Victoria (VIC) in Australia have\nbeen considered to verify the superiority of the proposed MEMD-PSO-SVR hybrid\nmodel. The quantitative and comprehensive assessments are performed, and the\nresults indicate that the proposed MEMD-PSO-SVR method is a promising\nalternative for day-ahead electricity peak load forecasting.",
    "descriptor": "",
    "authors": [
      "Yanmei Huang",
      "Najmul Hasan",
      "Changrui Deng",
      "Yukun Bao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14980"
  },
  {
    "id": "arXiv:2110.14982",
    "title": "An Optimal Factorization Preconditioner for Periodic Schr\u00f6dinger  Eigenstates in Anisotropically Expanding Domains",
    "abstract": "This paper provides a provably optimal preconditioning strategy of the linear\nSchr\\\"odinger eigenvalue problem with periodic potentials for a possibly\nnon-uniform spatial expansion of the domain. The optimality is achieved by\nhaving the iterative eigenvalue algorithms converge in a constant number of\niterations with respect to different domain sizes. In the analysis, we derive\nan analytic factorization of the spectrum and asymptotically describe it using\nconcepts from the homogenization theory. This decomposition allows us to\nexpress the eigenpair as an easy-to-calculate cell problem solution combined\nwith an asymptotically vanishing remainder. We then prove that the\neasy-to-calculate limit eigenvalue can be used in a shift-and-invert\npreconditioning strategy to uniformly bound the number of eigensolver\niterations. Several numerical examples illustrate the effectiveness of this\noptimal preconditioning strategy.",
    "descriptor": "\nComments: 29 pages, 9 figures, 2 tables\n",
    "authors": [
      "Benjamin Stamm",
      "Lambert Theisen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2110.14982"
  },
  {
    "id": "arXiv:2110.14985",
    "title": "Fighting the curse of dimensionality: A machine learning approach to  finding global optima",
    "abstract": "Finding global optima in high-dimensional optimization problems is extremely\nchallenging since the number of function evaluations required to sufficiently\nexplore the design space increases exponentially with its dimensionality.\nFurthermore, non-convex cost functions render local gradient-based search\ntechniques ineffective. To overcome these difficulties, here we demonstrate the\nuse of machine learning to find global minima, whereby autoencoders are used to\ndrastically reduce the search space dimensionality, and optima are found by\nsurveying the lower-dimensional latent spaces. The methodology is tested on\nbenchmark functions and on a structural optimization problem, where we show\nthat by exploiting the behavior of certain cost functions we either obtain the\nglobal optimum at best or obtain superior results at worst when compared to\nestablished optimization procedures.",
    "descriptor": "\nComments: Main text 21 pages, 4 figures, currently submitted to science\n",
    "authors": [
      "Julian F. Schumann",
      "Alejandro M. Arag\u00f3n"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.14985"
  },
  {
    "id": "arXiv:2110.14990",
    "title": "IMDB-WIKI-SbS: An Evaluation Dataset for Crowdsourced Pairwise  Comparisons",
    "abstract": "Today, comprehensive evaluation of large-scale machine learning models is\npossible thanks to the open datasets produced using crowdsourcing, such as\nSQuAD, MS COCO, ImageNet, SuperGLUE, etc. These datasets capture objective\nresponses, assuming the single correct answer, which does not allow to capture\nthe subjective human perception. In turn, pairwise comparison tasks, in which\none has to choose between only two options, allow taking peoples' preferences\ninto account for very challenging artificial intelligence tasks, such as\ninformation retrieval and recommender system evaluation. Unfortunately, the\navailable datasets are either small or proprietary, slowing down progress in\ngathering better feedback from human users. In this paper, we present\nIMDB-WIKI-SbS, a new large-scale dataset for evaluating pairwise comparisons.\nIt contains 9,150 images appearing in 250,249 pairs annotated on a\ncrowdsourcing platform. Our dataset has balanced distributions of age and\ngender using the well-known IMDB-WIKI dataset as ground truth. We describe how\nour dataset is built and then compare several baseline methods, indicating its\nsuitability for model evaluation.",
    "descriptor": "",
    "authors": [
      "Nikita Pavlichenko",
      "Dmitry Ustalov"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.14990"
  },
  {
    "id": "arXiv:2110.14993",
    "title": "Using Time-Series Privileged Information for Provably Efficient Learning  of Prediction Models",
    "abstract": "We study prediction of future outcomes with supervised models that use\nprivileged information during learning. The privileged information comprises\nsamples of time series observed between the baseline time of prediction and the\nfuture outcome; this information is only available at training time which\ndiffers from the traditional supervised learning. Our question is when using\nthis privileged data leads to more sample-efficient learning of models that use\nonly baseline data for predictions at test time. We give an algorithm for this\nsetting and prove that when the time series are drawn from a non-stationary\nGaussian-linear dynamical system of fixed horizon, learning with privileged\ninformation is more efficient than learning without it. On synthetic data, we\ntest the limits of our algorithm and theory, both when our assumptions hold and\nwhen they are violated. On three diverse real-world datasets, we show that our\napproach is generally preferable to classical learning, particularly when data\nis scarce. Finally, we relate our estimator to a distillation approach both\ntheoretically and empirically.",
    "descriptor": "",
    "authors": [
      "Rickard Karlsson",
      "Martin Willbo",
      "Zeshan Hussain",
      "Rahul G. Krishnan",
      "David Sontag",
      "Fredrik D. Johansson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.14993"
  },
  {
    "id": "arXiv:2110.14994",
    "title": "Skeleton-Based Mutually Assisted Interacted Object Localization and  Human Action Recognition",
    "abstract": "Skeleton data carries valuable motion information and is widely explored in\nhuman action recognition. However, not only the motion information but also the\ninteraction with the environment provides discriminative cues to recognize the\naction of persons. In this paper, we propose a joint learning framework for\nmutually assisted \"interacted object localization\" and \"human action\nrecognition\" based on skeleton data. The two tasks are serialized together and\ncollaborate to promote each other, where preliminary action type derived from\nskeleton alone helps improve interacted object localization, which in turn\nprovides valuable cues for the final human action recognition. Besides, we\nexplore the temporal consistency of interacted object as constraint to better\nlocalize the interacted object with the absence of ground-truth labels.\nExtensive experiments on the datasets of SYSU-3D, NTU60 RGB+D and\nNorthwestern-UCLA show that our method achieves the best or competitive\nperformance with the state-of-the-art methods for human action recognition.\nVisualization results show that our method can also provide reasonable\ninteracted object localization results.",
    "descriptor": "\nComments: 10 pages, 3 figures\n",
    "authors": [
      "Liang Xu",
      "Cuiling Lan",
      "Wenjun Zeng",
      "Cewu Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.14994"
  },
  {
    "id": "arXiv:2110.14998",
    "title": "An Adaptable Approach to Learn Realistic Legged Locomotion without  Examples",
    "abstract": "Learning controllers that reproduce legged locomotion in nature have been a\nlong-time goal in robotics and computer graphics. While yielding promising\nresults, recent approaches are not yet flexible enough to be applicable to\nlegged systems of different morphologies. This is partly because they often\nrely on precise motion capture references or elaborate learning environments\nthat ensure the naturality of the emergent locomotion gaits but prevent\ngeneralization. This work proposes a generic approach for ensuring realism in\nlocomotion by guiding the learning process with the spring-loaded inverted\npendulum model as a reference. Leveraging on the exploration capacities of\nReinforcement Learning (RL), we learn a control policy that fills in the\ninformation gap between the template model and full-body dynamics required to\nmaintain stable and periodic locomotion. The proposed approach can be applied\nto robots of different sizes and morphologies and adapted to any RL technique\nand control architecture. We present experimental results showing that even in\na model-free setup and with a simple reactive control architecture, the learned\npolicies can generate realistic and energy-efficient locomotion gaits for a\nbipedal and a quadrupedal robot. And most importantly, this is achieved without\nusing motion capture, strong constraints in the dynamics or kinematics of the\nrobot, nor prescribing limb coordination. We provide supplemental videos for\nqualitative analysis of the naturality of the learned gaits.",
    "descriptor": "",
    "authors": [
      "Daniel Felipe Ordo\u00f1ez Apraez",
      "Antonio Agudo",
      "Francesc Moreno-Noguer",
      "Mario Martin"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.14998"
  },
  {
    "id": "arXiv:2110.15002",
    "title": "On the explainability of hospitalization prediction on a large COVID-19  patient dataset",
    "abstract": "We develop various AI models to predict hospitalization on a large (over\n110$k$) cohort of COVID-19 positive-tested US patients, sourced from March 2020\nto February 2021. Models range from Random Forest to Neural Network (NN) and\nTime Convolutional NN, where combination of the data modalities (tabular and\ntime dependent) are performed at different stages (early vs. model fusion).\nDespite high data unbalance, the models reach average precision 0.96-0.98\n(0.75-0.85), recall 0.96-0.98 (0.74-0.85), and $F_1$-score 0.97-0.98\n(0.79-0.83) on the non-hospitalized (or hospitalized) class. Performances do\nnot significantly drop even when selected lists of features are removed to\nstudy model adaptability to different scenarios. However, a systematic study of\nthe SHAP feature importance values for the developed models in the different\nscenarios shows a large variability across models and use cases. This calls for\neven more complete studies on several explainability methods before their\nadoption in high-stakes scenarios.",
    "descriptor": "\nComments: 10 pages, 5 figures, accepted to AMIA 2021\n",
    "authors": [
      "Ivan Girardi",
      "Panagiotis Vagenas",
      "Dario Arcos-D\u00edaz",
      "Lydia Bessa\u00ef",
      "Alexander B\u00fcsser",
      "Ludovico Furlan",
      "Raffaello Furlan",
      "Mauro Gatti",
      "Andrea Giovannini",
      "Ellen Hoeven",
      "Chiara Marchiori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15002"
  },
  {
    "id": "arXiv:2110.15010",
    "title": "NOMA Joint Decoding based on Soft-Output Ordered-Statistics Decoder for  Short Block Codes",
    "abstract": "In this paper, we design the joint decoding (JD) of non-orthogonal multiple\naccess (NOMA) systems employing short block length codes. We first proposed a\nlow-complexity soft-output ordered-statistics decoding (LC-SOSD) based on a\ndecoding stopping condition, derived from approximations of the a-posterior\nprobabilities of codeword estimates. Simulation results show that LC-SOSD has\nthe similar mutual information transform property to the original SOSD with a\nsignificantly reduced complexity. Then, based on the analysis, an efficient JD\nreceiver which combines the parallel interference cancellation (PIC) and the\nproposed LC-SOSD is developed for NOMA systems. Two novel techniques, namely\ndecoding switch (DS) and decoding combiner (DC), are introduced to accelerate\nthe convergence speed. Simulation results show that the proposed receiver can\nachieve a lower bit-error rate (BER) compared to the successive interference\ncancellation (SIC) decoding over the additive-white-Gaussian-noise (AWGN) and\nfading channel, with a lower complexity in terms of the number of decoding\niterations.",
    "descriptor": "\nComments: 6 pages; 5 figures\n",
    "authors": [
      "Chentao Yue",
      "Alva Kosasih",
      "Mahyar Shirvanimoghaddam",
      "Giyoon Park",
      "Ok-Sun Park",
      "Wibowo Hardjawana",
      "Branka Vucetic",
      "Yonghui Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.15010"
  },
  {
    "id": "arXiv:2110.15011",
    "title": "Simulating a questionnaire on the framing effects in decision-making  processes in a serious game",
    "abstract": "The rapid development of technology has introduced new formats of\nhuman-computer interaction, which have in turn produced many new forms of media\nand a whole new field of interactive multimedia. One of the major mediums that\nhas grown in popularity since its early development is video games. For a long\ntime, video games have been developed and distributed for the purpose of\nentertainment, however, in the late 2010s, researchers have taken an interest\nin the characteristics of games and how they can be used for different\npurposes. Video games allow a tight loop of action-reaction which provides\nfertile ground for many types of experiments which would be impossible or\nprohibitively difficult to perform in the physical world, and as such serve as\nstrong virtual alternatives. A video game that is able to produce an immersive\nexperience for the player in which the player believes that they are \"actually\nthere\" in the game, and that the game is an extension of reality provides an\nalternate way to explore human behaviors and decision-making processes.\nProspect theory questionnaires explore decision-making in hypothetical\nsituations. In most cases, these experiments are done in controlled\nenvironments and rely on the respondent's imagination to reproduce the\nsituation which is presented to them. Creating a virtual world with which the\nplayers can directly interact with and face tangible consequences of their\ndecisions brings the hypothetical situations of the prospect theory questions\ncloser to the respondent. If the players can interact with and manipulate the\nvirtual world, then it is much easier for them to empathize with it and their\ncharacter, and thus, the assumption is that the answers represent a more\nrealistic image of the player's decision making.",
    "descriptor": "",
    "authors": [
      "Sara Kne\u017eevi\u0107",
      "Mla\u0111an Jovanovi\u0107"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.15011"
  },
  {
    "id": "arXiv:2110.15015",
    "title": "Engineering Uniform Sampling of Graphs with a Prescribed Power-law  Degree Sequence",
    "abstract": "We consider the following common network analysis problem: given a degree\nsequence $\\mathbf{d} = (d_1, \\dots, d_n) \\in \\mathbb N^n$ return a uniform\nsample from the ensemble of all simple graphs with matching degrees. In\npractice, the problem is typically solved using Markov Chain Monte Carlo\napproaches, such as Edge-Switching or Curveball, even if no practical useful\nrigorous bounds are known on their mixing times. In contrast, Arman et al.\nsketch Inc-Powerlaw, a novel and much more involved algorithm capable of\ngenerating graphs for power-law bounded degree sequences with $\\gamma\n\\gtrapprox 2.88$ in expected linear time.\nFor the first time, we give a complete description of the algorithm and add\nnovel switchings. To the best of our knowledge, our open-source implementation\nof Inc-Powerlaw is the first practical generator with rigorous uniformity\nguarantees for the aforementioned degree sequences. In an empirical\ninvestigation, we find that for small average-degrees Inc-Powerlaw is very\nefficient and generates graphs with one million nodes in less than a second.\nFor larger average-degrees, parallelism can partially mitigate the increased\nrunning-time.",
    "descriptor": "\nComments: Scheduled for presentation at ALENEX 2022\n",
    "authors": [
      "Daniel Allendorf",
      "Ulrich Meyer",
      "Manuel Penschuck",
      "Hung Tran",
      "Nick Wormald"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.15015"
  },
  {
    "id": "arXiv:2110.15016",
    "title": "Sliding Sequential CVAE with Time Variant Socially-aware Rethinking for  Trajectory Prediction",
    "abstract": "Pedestrian trajectory prediction is a key technology in many applications\nsuch as video surveillance, social robot navigation, and autonomous driving,\nand significant progress has been made in this research topic. However, there\nremain two limitations of previous studies. First, with the continuation of\ntime, the prediction error at each time step increases significantly, causing\nthe final displacement error to be impossible to ignore. Second, the prediction\nresults of multiple pedestrians might be impractical in the prediction horizon,\ni.e., the predicted trajectories might collide with each other. To overcome\nthese limitations, this work proposes a novel trajectory prediction method\ncalled CSR, which consists of a cascaded conditional variational autoencoder\n(CVAE) module and a socially-aware regression module. The cascaded CVAE module\nfirst estimates the future trajectories in a sequential pattern. Specifically,\neach CVAE concatenates the past trajectories and the predicted points so far as\nthe input and predicts the location at the following time step. Then, the\nsocially-aware regression module generates offsets from the estimated future\ntrajectories to produce the socially compliant final predictions, which are\nmore reasonable and accurate results than the estimated trajectories. Moreover,\nconsidering the large model parameters of the cascaded CVAE module, a slide\nCVAE module is further exploited to improve the model efficiency using one\nshared CVAE, in a slidable manner. Experiments results demonstrate that the\nproposed method exhibits improvements over state-of-the-art method on the\nStanford Drone Dataset (SDD) and ETH/UCY of approximately 38.0% and 22.2%,\nrespectively.",
    "descriptor": "",
    "authors": [
      "Hao Zhou",
      "Dongchun Ren",
      "Xu Yang",
      "Mingyu Fan",
      "Hai Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15016"
  },
  {
    "id": "arXiv:2110.15017",
    "title": "Bridging Non Co-occurrence with Unlabeled In-the-wild Data for  Incremental Object Detection",
    "abstract": "Deep networks have shown remarkable results in the task of object detection.\nHowever, their performance suffers critical drops when they are subsequently\ntrained on novel classes without any sample from the base classes originally\nused to train the model. This phenomenon is known as catastrophic forgetting.\nRecently, several incremental learning methods are proposed to mitigate\ncatastrophic forgetting for object detection. Despite the effectiveness, these\nmethods require co-occurrence of the unlabeled base classes in the training\ndata of the novel classes. This requirement is impractical in many real-world\nsettings since the base classes do not necessarily co-occur with the novel\nclasses. In view of this limitation, we consider a more practical setting of\ncomplete absence of co-occurrence of the base and novel classes for the object\ndetection task. We propose the use of unlabeled in-the-wild data to bridge the\nnon co-occurrence caused by the missing base classes during the training of\nadditional novel classes. To this end, we introduce a blind sampling strategy\nbased on the responses of the base-class model and pre-trained novel-class\nmodel to select a smaller relevant dataset from the large in-the-wild dataset\nfor incremental learning. We then design a dual-teacher distillation framework\nto transfer the knowledge distilled from the base- and novel-class teacher\nmodels to the student model using the sampled in-the-wild data. Experimental\nresults on the PASCAL VOC and MS COCO datasets show that our proposed method\nsignificantly outperforms other state-of-the-art class-incremental object\ndetection methods when there is no co-occurrence between the base and novel\nclasses during training.",
    "descriptor": "\nComments: Accepted paper at NeurIPS 2021\n",
    "authors": [
      "Na Dong",
      "Yongqiang Zhang",
      "Mingli Ding",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15017"
  },
  {
    "id": "arXiv:2110.15023",
    "title": "Empirical Analysis of Korean Public AI Hub Parallel Corpora and in-depth  Analysis using LIWC",
    "abstract": "Machine translation (MT) system aims to translate source language into target\nlanguage. Recent studies on MT systems mainly focus on neural machine\ntranslation (NMT). One factor that significantly affects the performance of NMT\nis the availability of high-quality parallel corpora. However, high-quality\nparallel corpora concerning Korean are relatively scarce compared to those\nassociated with other high-resource languages, such as German or Italian. To\naddress this problem, AI Hub recently released seven types of parallel corpora\nfor Korean. In this study, we conduct an in-depth verification of the quality\nof corresponding parallel corpora through Linguistic Inquiry and Word Count\n(LIWC) and several relevant experiments. LIWC is a word-counting software\nprogram that can analyze corpora in multiple ways and extract linguistic\nfeatures as a dictionary base. To the best of our knowledge, this study is the\nfirst to use LIWC to analyze parallel corpora in the field of NMT. Our findings\nsuggest the direction of further research toward obtaining the improved quality\nparallel corpora through our correlation analysis in LIWC and NMT performance.",
    "descriptor": "",
    "authors": [
      "Chanjun Park",
      "Midan Shim",
      "Sugyeong Eo",
      "Seolhwa Lee",
      "Jaehyung Seo",
      "Hyeonseok Moon",
      "Heuiseok Lim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.15023"
  },
  {
    "id": "arXiv:2110.15024",
    "title": "Exact Analytical Model of Age of Information in Multi-source Status  Update Systems with Per-source Queueing",
    "abstract": "We consider an information update system consisting of $N$ sources sending\nstatus packets at random instances according to a Poisson process to a remote\nmonitor through a single server. We assume a heteregeneous server with\nexponentially distributed service times which is equipped with a waiting room\nholding the freshest packet from each source referred to as Single Buffer\nPer-Source Queueing (SBPSQ). The sources are assumed to be equally important,\ni.e., non-weighted average AoI is used as the information freshness metric, and\nsubsequently two symmetric scheduling policies are studied in this paper,\nnamely First Source First Serve (FSFS) and the Earliest Served First Serve\n(ESFS) policies, the latter policy being proposed the first time in the current\npaper to the best of our knowledge. By employing the theory of Markov Fluid\nQueues (MFQ), an analytical model is proposed to obtain the exact distribution\nof the Age of Information (AoI) for each source when the FSFS and ESFS policies\nare employed at the server. Subsequently, a benchmark scheduling-free scheme\nnamed as Single Buffer with Replacement (SBR) that uses a single one-packet\nbuffer shared by all sources is also studied with a similar but less complex\nanalytical model. We comparatively study the performance of the three schemes\nthrough numerical examples and show that the proposed ESFS policy outperforms\nthe other two schemes in terms of the average AoI and the age violation\nprobability averaged across all sources, in a scenario of sources possessing\ndifferent traffic intensities but sharing a common service time.",
    "descriptor": "\nComments: 16 pages, 7 figures\n",
    "authors": [
      "Ege Orkun Gamgam",
      "Nail Akar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Performance (cs.PF)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2110.15024"
  },
  {
    "id": "arXiv:2110.15027",
    "title": "Deformable Registration of Brain MR Images via a Hybrid Loss",
    "abstract": "We learn a deformable registration model for T1-weighted MR images by\nconsidering multiple image characteristics via a hybrid loss. Our method\nregisters the OASIS dataset with high accuracy while preserving deformation\nsmoothness.",
    "descriptor": "",
    "authors": [
      "Luyi Han",
      "Haoran Dou",
      "Yunzhi Huang",
      "Pew-Thian Yap"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15027"
  },
  {
    "id": "arXiv:2110.15028",
    "title": "Facial Emotion Recognition: A multi-task approach using deep learning",
    "abstract": "Facial Emotion Recognition is an inherently difficult problem, due to vast\ndifferences in facial structures of individuals and ambiguity in the emotion\ndisplayed by a person. Recently, a lot of work is being done in the field of\nFacial Emotion Recognition, and the performance of the CNNs for this task has\nbeen inferior compared to the results achieved by CNNs in other fields like\nObject detection, Facial recognition etc. In this paper, we propose a\nmulti-task learning algorithm, in which a single CNN detects gender, age and\nrace of the subject along with their emotion. We validate this proposed\nmethodology using two datasets containing real-world images. The results show\nthat this approach is significantly better than the current State of the art\nalgorithms for this task.",
    "descriptor": "",
    "authors": [
      "Aakash Saroop",
      "Pathik Ghugare",
      "Sashank Mathamsetty",
      "Vaibhav Vasani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15028"
  },
  {
    "id": "arXiv:2110.15029",
    "title": "Adaptive finite element approximations for elliptic problems using  regularized forcing data",
    "abstract": "We propose an adaptive finite element algorithm to approximate solutions of\nelliptic problems whose forcing data is locally defined and is approximated by\nregularization (or mollification). We show that the energy error decay is\nquasi-optimal in two dimensional space and sub-optimal in three dimensional\nspace. Numerical simulations are provided to confirm our findings.",
    "descriptor": "\nComments: 35 pages, 11 Figures, 1 Table\n",
    "authors": [
      "Luca Heltai",
      "Wenyu Lei"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.15029"
  },
  {
    "id": "arXiv:2110.15030",
    "title": "Explicitly Modeling the Discriminability for Instance-Aware Visual  Object Tracking",
    "abstract": "Visual object tracking performance has been dramatically improved in recent\nyears, but some severe challenges remain open, like distractors and occlusions.\nWe suspect the reason is that the feature representations of the tracking\ntargets are only expressively learned but not fully discriminatively modeled.\nIn this paper, we propose a novel Instance-Aware Tracker (IAT) to explicitly\nexcavate the discriminability of feature representations, which improves the\nclassical visual tracking pipeline with an instance-level classifier. First, we\nintroduce a contrastive learning mechanism to formulate the classification\ntask, ensuring that every training sample could be uniquely modeled and be\nhighly distinguishable from plenty of other samples. Besides, we design an\neffective negative sample selection scheme to contain various intra and inter\nclasses in the instance classification branch. Furthermore, we implement two\nvariants of the proposed IAT, including a video-level one and an object-level\none. They realize the concept of \\textbf{instance} in different granularity as\nvideos and target bounding boxes, respectively. The former enhances the ability\nto recognize the target from the background while the latter boosts the\ndiscriminative power for mitigating the target-distractor dilemma. Extensive\nexperimental evaluations on 8 benchmark datasets show that both two versions of\nthe proposed IAT achieve leading results against state-of-the-art methods while\nrunning at 30FPS. Code will be available when it is published.",
    "descriptor": "",
    "authors": [
      "Mengmeng Wang",
      "Xiaoqian Yang",
      "Yong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15030"
  },
  {
    "id": "arXiv:2110.15032",
    "title": "OneFlow: Redesign the Distributed Deep Learning Framework from Scratch",
    "abstract": "Deep learning frameworks such as TensorFlow and PyTorch provide a productive\ninterface for expressing and training a deep neural network (DNN) model on a\nsingle device or using data parallelism. Still, they may not be flexible or\nefficient enough in training emerging large models on distributed devices,\nwhich require more sophisticated parallelism beyond data parallelism. Plugins\nor wrappers have been developed to strengthen these frameworks for model or\npipeline parallelism, but they complicate the usage and implementation of\ndistributed deep learning. Aiming at a simple, neat redesign of distributed\ndeep learning frameworks for various parallelism paradigms, we present OneFlow,\na novel distributed training framework based on an SBP (split, broadcast and\npartial-value) abstraction and the actor model. SBP enables much easier\nprogramming of data parallelism and model parallelism than existing frameworks,\nand the actor model provides a succinct runtime mechanism to manage the complex\ndependencies imposed by resource constraints, data movement and computation in\ndistributed deep learning. We demonstrate the general applicability and\nefficiency of OneFlow for training various large DNN models with case studies\nand extensive experiments. The results show that OneFlow outperforms many\nwell-known customized libraries built on top of the state-of-the-art\nframeworks. The code of OneFlow is available at:\nhttps://github.com/Oneflow-Inc/oneflow.",
    "descriptor": "",
    "authors": [
      "Jinhui Yuan",
      "Xinqi Li",
      "Cheng Cheng",
      "Juncheng Liu",
      "Ran Guo",
      "Shenghang Cai",
      "Chi Yao",
      "Fei Yang",
      "Xiaodong Yi",
      "Chuan Wu",
      "Haoran Zhang",
      "Jie Zhao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15032"
  },
  {
    "id": "arXiv:2110.15036",
    "title": "Orientation Probabilistic Movement Primitives on Riemannian Manifolds",
    "abstract": "Learning complex robot motions necessarily demands to have models that are\nable to encode and retrieve full-pose trajectories when tasks are defined in\noperational spaces. Probabilistic movement primitives (ProMPs) stand out as a\nprincipled approach that models trajectory distributions learned from\ndemonstrations. ProMPs allow for trajectory modulation and blending to achieve\nbetter generalization to novel situations. However, when ProMPs are employed in\noperational space, their original formulation does not directly apply to\nfull-pose movements including rotational trajectories described by quaternions.\nThis paper proposes a Riemannian formulation of ProMPs that enables encoding\nand retrieving of quaternion trajectories. Our method builds on Riemannian\nmanifold theory, and exploits multilinear geodesic regression for estimating\nthe ProMPs parameters. This novel approach makes ProMPs a suitable model for\nlearning complex full-pose robot motion patterns. Riemannian ProMPs are tested\non toy examples to illustrate their workflow, and on real\nlearning-from-demonstration experiments.",
    "descriptor": "\nComments: To appear at CoRL 2021\n",
    "authors": [
      "Leonel Rozo",
      "Vedant Dave"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15036"
  },
  {
    "id": "arXiv:2110.15037",
    "title": "Learning Deep Representation with Energy-Based Self-Expressiveness for  Subspace Clustering",
    "abstract": "Deep subspace clustering has attracted increasing attention in recent years.\nAlmost all the existing works are required to load the whole training data into\none batch for learning the self-expressive coefficients in the framework of\ndeep learning. Although these methods achieve promising results, such a\nlearning fashion severely prevents from the usage of deeper neural network\narchitectures (e.g., ResNet), leading to the limited representation abilities\nof the models. In this paper, we propose a new deep subspace clustering\nframework, motivated by the energy-based models. In contrast to previous\napproaches taking the weights of a fully connected layer as the self-expressive\ncoefficients, we propose to learn an energy-based network to obtain the\nself-expressive coefficients by mini-batch training. By this means, it is no\nlonger necessary to load all data into one batch for learning, and it thus\nbecomes a reality that we can utilize deeper neural network models for subspace\nclustering. Considering the powerful representation ability of the recently\npopular self-supervised learning, we attempt to leverage self-supervised\nrepresentation learning to learn the dictionary. Finally, we propose a joint\nframework to learn both the self-expressive coefficients and dictionary\nsimultaneously, and train the model in an end-to-end manner. The experiments\nare performed on three publicly available datasets, and extensive experimental\nresults demonstrate our method can significantly outperform the other related\napproaches. For instance, on the three datasets, our method can averagely\nachieve $13.8\\%$, $15.4\\%$, $20.8\\%$ improvements in terms of Accuracy, NMI,\nand ARI over SENet which is proposed very recently and obtains the second best\nresults in the experiments.",
    "descriptor": "",
    "authors": [
      "Yanming Li",
      "Changsheng Li",
      "Shiye Wang",
      "Ye Yuan",
      "Guoren Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15037"
  },
  {
    "id": "arXiv:2110.15043",
    "title": "Hindsight Goal Ranking on Replay Buffer for Sparse Reward Environment",
    "abstract": "This paper proposes a method for prioritizing the replay experience referred\nto as Hindsight Goal Ranking (HGR) in overcoming the limitation of Hindsight\nExperience Replay (HER) that generates hindsight goals based on uniform\nsampling. HGR samples with higher probability on the states visited in an\nepisode with larger temporal difference (TD) error, which is considered as a\nproxy measure of the amount which the RL agent can learn from an experience.\nThe actual sampling for large TD error is performed in two steps: first, an\nepisode is sampled from the relay buffer according to the average TD error of\nits experiences, and then, for the sampled episode, the hindsight goal leading\nto larger TD error is sampled with higher probability from future visited\nstates. The proposed method combined with Deep Deterministic Policy Gradient\n(DDPG), an off-policy model-free actor-critic algorithm, accelerates learning\nsignificantly faster than that without any prioritization on four challenging\nsimulated robotic manipulation tasks. The empirical results show that HGR uses\nsamples more efficiently than previous methods across all tasks.",
    "descriptor": "",
    "authors": [
      "Tung M. Luu",
      "Chang D. Yoo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15043"
  },
  {
    "id": "arXiv:2110.15045",
    "title": "LF-YOLO: A Lighter and Faster YOLO for Weld Defect Detection of X-ray  Image",
    "abstract": "X-ray image plays an important role in manufacturing for quality assurance,\nbecause it can reflect the internal condition of weld region. However, the\nshape and scale of different defect types vary greatly, which makes it\nchallenging for model to detect weld defects. In this paper, we propose a weld\ndefect detection method based on convolution neural network (CNN), namely\nLighter and Faster YOLO (LF-YOLO). In particularly, an enhanced multiscale\nfeature (EMF) module is designed to implement both parameter-based and\nparameter-free multi-scale information extracting operation. EMF enables the\nextracted feature map capable to represent more plentiful information, which is\nachieved by superior hierarchical fusion structure. To improve the performance\nof detection network, we propose an efficient feature extraction (EFE) module.\nEFE processes input data with extremely low consumption, and improve the\npracticability of whole network in actual industry. Experimental results show\nthat our weld defect network achieves satisfactory balance between performance\nand consumption, and reaches 92.9 mAP50 with 61.5 FPS. To further prove the\nability of our method, we test it on public dataset MS COCO, and the results\nshow that our LF-YOLO has a outstanding versatility detection performance. The\ncode is available at https://github.com/lmomoy/LF-YOLO.",
    "descriptor": "",
    "authors": [
      "Moyun Liu",
      "Youping Chen",
      "Lei He",
      "Yang Zhang",
      "Jingming Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15045"
  },
  {
    "id": "arXiv:2110.15047",
    "title": "The chemical space of terpenes: insights from data science and AI",
    "abstract": "Terpenes are a widespread class of natural products with significant chemical\nand biological diversity and many of these molecules have already made their\nway into medicines. Given the thousands of molecules already described, the\nfull characterization of this chemical space can be a challenging task when\nrelying in classical approaches. In this work we employ a data science-based\napproach to identify, compile and characterize the diversity of terpenes\ncurrently known in a systematic way. We worked with a natural product database,\nCOCONUT, from which we extracted information for nearly 60000 terpenes. For\nthese molecules, we conducted a subclass-by-subclass analysis in which we\nhighlight several chemical and physical properties relevant to several fields,\nsuch as natural products chemistry, medicinal chemistry and drug discovery,\namong others. We were also interested in assessing the potential of this data\nfor clustering and classification tasks. For clustering, we have applied and\ncompared k-means with agglomerative clustering, both to the original data and\nfollowing a step of dimensionality reduction. To this end, PCA, FastICA, Kernel\nPCA, t-SNE and UMAP were used and benchmarked. We also employed a number of\nmethods for the purpose of classifying terpene subclasses using their\nphysico-chemical descriptors. Light gradient boosting machine, k-nearest\nneighbors, random forests, Gaussian naiive Bayes and Multilayer perceptron,\nwith the best-performing algorithms yielding accuracy, F1 score, precision and\nother metrics all over 0.9, thus showing the capabilities of these approaches\nfor the classification of terpene subclasses.",
    "descriptor": "\nComments: 27 pages, 8 figures\n",
    "authors": [
      "Morteza Hosseini",
      "David M. Pereira"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.15047"
  },
  {
    "id": "arXiv:2110.15048",
    "title": "Accelerating Parameter Extraction of Power MOSFET Models Using Automatic  Differentiation",
    "abstract": "The extraction of the model parameters is as important as the development of\ncompact model itself because simulation accuracy is fully determined by the\naccuracy of the parameters used. This study proposes an efficient\nmodel-parameter extraction method for compact models of power MOSFETs. The\nproposed method employs automatic differentiation (AD), which is extensively\nused for training artificial neural networks. In the proposed AD-based\nparameter extraction, gradient of all the model parameters is analytically\ncalculated by forming a graph that facilitates the backward propagation of\nerrors. Based on the calculated gradient, computationally intensive numerical\ndifferentiation is eliminated and the model parameters are efficiently\noptimized. Experiments are conducted to fit current and capacitance\ncharacteristics of commercially available silicon carbide MOSFET using power\nMOSFET models having 13 model parameters. Results demonstrated that the\nproposed method could successfully derive the model parameters 3.50x faster\nthan a conventional numerical-differentiation method while achieving the equal\naccuracy.",
    "descriptor": "\nComments: 13 pages, 18 figures\n",
    "authors": [
      "Michihiro Shintani",
      "Aoi Ueda",
      "Takashi Sato"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.15048"
  },
  {
    "id": "arXiv:2110.15049",
    "title": "Validating Gaussian Process Models with Simulation-Based Calibration",
    "abstract": "Gaussian process priors are a popular choice for Bayesian analysis of\nregression problems. However, the implementation of these models can be\ncomplex, and ensuring that the implementation is correct can be challenging. In\nthis paper we introduce Gaussian process simulation-based calibration, a\nprocedure for validating the implementation of Gaussian process models and\ndemonstrate the efficacy of this procedure in identifying a bug in existing\ncode. We also present a novel application of this procedure to identify when\nmarginalisation of the model hyperparameters is necessary.",
    "descriptor": "\nComments: 2 pages, 1 figure\n",
    "authors": [
      "John Mcleod",
      "Fergus Simpson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15049"
  },
  {
    "id": "arXiv:2110.15053",
    "title": "Adversarial Robustness in Multi-Task Learning: Promises and Illusions",
    "abstract": "Vulnerability to adversarial attacks is a well-known weakness of Deep Neural\nnetworks. While most of the studies focus on single-task neural networks with\ncomputer vision datasets, very little research has considered complex\nmulti-task models that are common in real applications. In this paper, we\nevaluate the design choices that impact the robustness of multi-task deep\nlearning networks. We provide evidence that blindly adding auxiliary tasks, or\nweighing the tasks provides a false sense of robustness. Thereby, we tone down\nthe claim made by previous research and study the different factors which may\naffect robustness. In particular, we show that the choice of the task to\nincorporate in the loss function are important factors that can be leveraged to\nyield more robust models.",
    "descriptor": "",
    "authors": [
      "Salah Ghamizi",
      "Maxime Cordy",
      "Mike Papadakis",
      "Yves Le Traon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15053"
  },
  {
    "id": "arXiv:2110.15054",
    "title": "Adaptive Multimodal and Multisensory Empathic Technologies for Enhanced  Human Communication",
    "abstract": "As digital social platforms and mobile technologies are becoming more\nprevalent and robust, the use of Artificial Intelligence (AI) in facilitating\nhuman communication will grow. This, in turn, will pave the way for the\ndevelopment of intuitive, adaptive, and effective empathic AI interfaces that\nbetter address the needs of socially and culturally diverse communities. I\nbelieve such developments must consider a principled framework that includes\nthe human perceptual senses in the digital design process right from the start,\nfor a more accurate, as well as a more aesthetic, memorable, and soothing\nexperience. In this position paper, I suggest features, identify some\nchallenges that need to be addressed in the process, and propose some future\nresearch directions that I think should be part of the design and\nimplementation. Such an approach will allow various communities of practice to\ninvestigate the areas of intersection between artificial intelligence, on one\nside, and human communication, perceptual needs and social and cultural values,\non the other.",
    "descriptor": "\nComments: 10 pages; This position paper was presented at the Rethinking the Senses: A Workshop on Multisensory Embodied Experiences and Disability Interactions associated with the ACM CHI Conference on Human Factors in Computing Systems, May 2021\n",
    "authors": [
      "Roxana Girju"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.15054"
  },
  {
    "id": "arXiv:2110.15056",
    "title": "Brain-inspired feature exaggeration in generative replay for continual  learning",
    "abstract": "The catastrophic forgetting of previously learnt classes is one of the main\nobstacles to the successful development of a reliable and accurate generative\ncontinual learning model. When learning new classes, the internal\nrepresentation of previously learnt ones can often be overwritten, resulting in\nthe model's \"memory\" of earlier classes being lost over time. Recent\ndevelopments in neuroscience have uncovered a method through which the brain\navoids its own form of memory interference. Applying a targeted exaggeration of\nthe differences between features of similar, yet competing memories, the brain\ncan more easily distinguish and recall them. In this paper, the application of\nsuch exaggeration, via the repulsion of replayed samples belonging to competing\nclasses, is explored. Through the development of a 'reconstruction repulsion'\nloss, this paper presents a new state-of-the-art performance on the\nclassification of early classes in the class-incremental learning dataset\nCIFAR100.",
    "descriptor": "\nComments: 5 pages, 3 figures, submitted to ICASSP\n",
    "authors": [
      "Jack Millichamp",
      "Xi Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.15056"
  },
  {
    "id": "arXiv:2110.15057",
    "title": "Mapping conditional distributions for domain adaptation under  generalized target shift",
    "abstract": "We consider the problem of unsupervised domain adaptation (UDA) between a\nsource and a target domain under conditional and label shift a.k.a Generalized\nTarget Shift (GeTarS). Unlike simpler UDA settings, few works have addressed\nthis challenging problem. Recent approaches learn domain-invariant\nrepresentations, yet they have practical limitations and rely on strong\nassumptions that may not hold in practice. In this paper, we explore a novel\nand general approach to align pretrained representations, which circumvents\nexisting drawbacks. Instead of constraining representation invariance, it\nlearns an optimal transport map, implemented as a NN, which maps source\nrepresentations onto target ones. Our approach is flexible and scalable, it\npreserves the problem's structure and it has strong theoretical guarantees\nunder mild assumptions. In particular, our solution is unique, matches\nconditional distributions across domains, recovers target proportions and\nexplicitly controls the target generalization risk. Through an exhaustive\ncomparison on several datasets, we challenge the state-of-the-art in GeTarS.",
    "descriptor": "",
    "authors": [
      "Matthieu Kirchmeyer",
      "Alain Rakotomamonjy",
      "Emmanuel de Bezenac",
      "Patrick Gallinari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15057"
  },
  {
    "id": "arXiv:2110.15058",
    "title": "cgSpan: Pattern Mining in Conceptual Graphs",
    "abstract": "Conceptual Graphs (CGs) are a graph-based knowledge representation formalism.\nIn this paper we propose cgSpan a CG frequent pattern mining algorithm. It\nextends the DMGM-GSM algorithm that takes taxonomy-based labeled graphs as\ninput; it includes three more kinds of knowledge of the CG formalism: (a) the\nfixed arity of relation nodes, handling graphs of neighborhoods centered on\nrelations rather than graphs of nodes, (b) the signatures, avoiding patterns\nwith concept types more general than the maximal types specified in signatures\nand (c) the inference rules, applying them during the pattern mining process.\nThe experimental study highlights that cgSpan is a functional CG Frequent\nPattern Mining algorithm and that including CGs specificities results in a\nfaster algorithm with more expressive results and less redundancy with\nvocabulary.",
    "descriptor": "",
    "authors": [
      "Adam Faci",
      "Marie-Jeanne Lesot",
      "Claire Laudy"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15058"
  },
  {
    "id": "arXiv:2110.15062",
    "title": "SenTag: a Web-based Tool for Semantic Annotation of Textual Documents",
    "abstract": "In this work, we present SenTag, a lightweight web-based tool focused on\nsemantic annotation of textual documents. The platform allows multiple users to\nwork on a corpus of documents. The tool enables to tag a corpus of documents\nthrough an intuitive and easy-to-use user interface that adopts the Extensible\nMarkup Language (XML) as output format. The main goal of the application is\ntwo-fold: facilitating the tagging process and reducing or avoiding for errors\nin the output documents. Moreover, it allows to identify arguments and other\nentities that are used to build an arguments graph. It is also possible to\nassess the level of agreement of annotators working on a corpus of text.",
    "descriptor": "",
    "authors": [
      "Andrea Loreggia",
      "Simone Mosco",
      "Alberto Zerbinati"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.15062"
  },
  {
    "id": "arXiv:2110.15063",
    "title": "TEXTOIR: An Integrated and Visualized Platform for Text Open Intent  Recognition",
    "abstract": "TEXTOIR is the first integrated and visualized platform for text open intent\nrecognition. It is composed of two main modules: open intent detection and open\nintent discovery. Each module integrates most of the state-of-the-art\nalgorithms and benchmark intent datasets. It also contains an overall framework\nconnecting the two modules in a pipeline scheme. In addition, this platform has\nvisualized tools for data and model management, training, evaluation and\nanalysis of the performance from different aspects. TEXTOIR provides useful\ntoolkits and convenient visualized interfaces for each sub-module (Toolkit\ncode: https://github.com/thuiar/TEXTOIR), and designs a framework to implement\na complete process to both identify known intents and discover open intents\n(Demo code: https://github.com/thuiar/TEXTOIR-DEMO).",
    "descriptor": "\nComments: Published in ACL 2021, demo paper\n",
    "authors": [
      "Hanlei Zhang",
      "Xiaoteng Li",
      "Hua Xu",
      "Panpan Zhang",
      "Kang Zhao",
      "Kai Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.15063"
  },
  {
    "id": "arXiv:2110.15064",
    "title": "Towards Fine-Grained Reasoning for Fake News Detection",
    "abstract": "The detection of fake news often requires sophisticated reasoning skills,\nsuch as logically combining information by considering word-level subtle clues.\nIn this paper, we move towards fine-grained reasoning for fake news detection\nby better reflecting the logical processes of human thinking and enabling the\nmodeling of subtle clues. In particular, we propose a fine-grained reasoning\nframework by following the human's information-processing model, introduce a\nmutual-reinforcement-based method for incorporating human knowledge about which\nevidence is more important, and design a prior-aware bi-channel kernel graph\nnetwork to model subtle differences between pieces of evidence. Extensive\nexperiments show that our model outperforms the state-of-art methods and\ndemonstrate the explainability of our approach.",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Yiqiao Jin",
      "Xiting Wang",
      "Ruichao Yang",
      "Yizhou Sun",
      "Wei Wang",
      "Hao Liao",
      "Xing Xie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15064"
  },
  {
    "id": "arXiv:2110.15070",
    "title": "Improved Strongly Polynomial Algorithms for Deterministic MDPs, 2VPI  Feasibility, and Discounted All-Pairs Shortest Paths",
    "abstract": "We revisit the problem of finding optimal strategies for deterministic Markov\nDecision Processes (DMDPs), and a closely related problem of testing\nfeasibility of systems of $m$ linear inequalities on $n$ real variables with at\nmost two variables per inequality (2VPI).\nWe give a randomized trade-off algorithm solving both problems and running in\n$\\tilde{O}(nmh+(n/h)^3)$ time using $\\tilde{O}(n^2/h+m)$ space for any\nparameter $h\\in [1,n]$. In particular, using subquadratic space we get\n$\\tilde{O}(nm+n^{3/2}m^{3/4})$ running time, which improves by a polynomial\nfactor upon all the known upper bounds for non-dense instances with\n$m=O(n^{2-\\epsilon})$. Moreover, using linear space we match the randomized\n$\\tilde{O}(nm+n^3)$ time bound of Cohen and Megiddo [SICOMP'94] that required\n$\\tilde{\\Theta}(n^2+m)$ space.\nAdditionally, we show a new algorithm for the Discounted All-Pairs Shortest\nPaths problem, introduced by Madani et al. [TALG'10], that extends the DMDPs\nwith optional end vertices. For the case of uniform discount factors, we give a\ndeterministic algorithm running in $\\tilde{O}(n^{3/2}m^{3/4})$ time, which\nimproves significantly upon the randomized bound $\\tilde{O}(n^2\\sqrt{m})$ of\nMadani et al.",
    "descriptor": "\nComments: Full version of a SODA'22 paper\n",
    "authors": [
      "Adam Karczmarz"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.15070"
  },
  {
    "id": "arXiv:2110.15072",
    "title": "Leveraging Recursive Gumbel-Max Trick for Approximate Inference in  Combinatorial Spaces",
    "abstract": "Structured latent variables allow incorporating meaningful prior knowledge\ninto deep learning models. However, learning with such variables remains\nchallenging because of their discrete nature. Nowadays, the standard learning\napproach is to define a latent variable as a perturbed algorithm output and to\nuse a differentiable surrogate for training. In general, the surrogate puts\nadditional constraints on the model and inevitably leads to biased gradients.\nTo alleviate these shortcomings, we extend the Gumbel-Max trick to define\ndistributions over structured domains. We avoid the differentiable surrogates\nby leveraging the score function estimators for optimization. In particular, we\nhighlight a family of recursive algorithms with a common feature we call\nstochastic invariant. The feature allows us to construct reliable gradient\nestimates and control variates without additional constraints on the model. In\nour experiments, we consider various structured latent variable models and\nachieve results competitive with relaxation-based counterparts.",
    "descriptor": "\nComments: Accepted as a conference paper at NeurIPS 2021\n",
    "authors": [
      "Kirill Struminsky",
      "Artyom Gadetsky",
      "Denis Rakitin",
      "Danil Karpushkin",
      "Dmitry Vetrov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15072"
  },
  {
    "id": "arXiv:2110.15074",
    "title": "Meta Guided Metric Learner for Overcoming Class Confusion in Few-Shot  Road Object Detection",
    "abstract": "Localization and recognition of less-occurring road objects have been a\nchallenge in autonomous driving applications due to the scarcity of data\nsamples. Few-Shot Object Detection techniques extend the knowledge from\nexisting base object classes to learn novel road objects given few training\nexamples. Popular techniques in FSOD adopt either meta or metric learning\ntechniques which are prone to class confusion and base class forgetting. In\nthis work, we introduce a novel Meta Guided Metric Learner (MGML) to overcome\nclass confusion in FSOD. We re-weight the features of the novel classes higher\nthan the base classes through a novel Squeeze and Excite module and encourage\nthe learning of truly discriminative class-specific features by applying an\nOrthogonality Constraint to the meta learner. Our method outperforms\nState-of-the-Art (SoTA) approaches in FSOD on the India Driving Dataset (IDD)\nby upto 11 mAP points while suffering from the least class confusion of 20%\ngiven only 10 examples of each novel road object. We further show similar\nimprovements on the few-shot splits of PASCAL VOC dataset where we outperform\nSoTA approaches by upto 5.8 mAP accross all splits.",
    "descriptor": "\nComments: Accepted to NeurIPS 2021 Workshop on Machine Learning For Autonomous Driving, 12 pages, 6 figures\n",
    "authors": [
      "Anay Majee",
      "Anbumani Subramanian",
      "Kshitij Agrawal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15074"
  },
  {
    "id": "arXiv:2110.15075",
    "title": "Improving Causal Effect Estimation of Weighted RegressionBased Estimator  using Neural Networks",
    "abstract": "Estimating causal effects from observational data informs us about which\nfactors are important in an autonomous system, and enables us to take better\ndecisions. This is important because it has applications in selecting a\ntreatment in medical systems or making better strategies in industries or\nmaking better policies for our government or even the society. Unavailability\nof complete data, coupled with high cardinality of data, makes this estimation\ntask computationally intractable. Recently, a regression-based weighted\nestimator has been introduced that is capable of producing solution using\nbounded samples of a given problem. However, as the data dimension increases,\nthe solution produced by the regression-based method degrades. Against this\nbackground, we introduce a neural network based estimator that improves the\nsolution quality in case of non-linear and finitude of samples. Finally, our\nempirical evaluation illustrates a significant improvement of solution quality,\nup to around $55\\%$, compared to the state-of-the-art estimators.",
    "descriptor": "\nComments: Author one and author two have same contribution\n",
    "authors": [
      "Plabon Shaha",
      "Talha Islam Zadid",
      "Ismat Rahman",
      "Md. Mosaddek Khan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15075"
  },
  {
    "id": "arXiv:2110.15082",
    "title": "SpineOne: A One-Stage Detection Framework for Degenerative Discs and  Vertebrae",
    "abstract": "Spinal degeneration plagues many elders, office workers, and even the younger\ngenerations. Effective pharmic or surgical interventions can help relieve\ndegenerative spine conditions. However, the traditional diagnosis procedure is\noften too laborious. Clinical experts need to detect discs and vertebrae from\nspinal magnetic resonance imaging (MRI) or computed tomography (CT) images as a\npreliminary step to perform pathological diagnosis or preoperative evaluation.\nMachine learning systems have been developed to aid this procedure generally\nfollowing a two-stage methodology: first perform anatomical localization, then\npathological classification. Towards more efficient and accurate diagnosis, we\npropose a one-stage detection framework termed SpineOne to simultaneously\nlocalize and classify degenerative discs and vertebrae from MRI slices.\nSpineOne is built upon the following three key techniques: 1) a new design of\nthe keypoint heatmap to facilitate simultaneous keypoint localization and\nclassification; 2) the use of attention modules to better differentiate the\nrepresentations between discs and vertebrae; and 3) a novel gradient-guided\nobjective association mechanism to associate multiple learning objectives at\nthe later training stage. Empirical results on the Spinal Disease Intelligent\nDiagnosis Tianchi Competition (SDID-TC) dataset of 550 exams demonstrate that\nour approach surpasses existing methods by a large margin.",
    "descriptor": "",
    "authors": [
      "Jiabo He",
      "Wei Liu",
      "Yu Wang",
      "Xingjun Ma",
      "Xian-Sheng Hua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15082"
  },
  {
    "id": "arXiv:2110.15087",
    "title": "MOOMIN: Deep Molecular Omics Network for Anti-Cancer Drug Combination  Therapy",
    "abstract": "We propose the molecular omics network (MOOMIN) a multimodal graph neural\nnetwork that can predict the synergistic effect of drug combinations for cancer\ntreatment. Our model captures the representation based on the context of drugs\nat multiple scales based on a drug-protein interaction network and metadata.\nStructural properties of the compounds and proteins are encoded to create\nvertex features for a message-passing scheme that operates on the bipartite\ninteraction graph. Propagated messages form multi-resolution drug\nrepresentations which we utilized to create drug pair descriptors. By\nconditioning the drug combination representations on the cancer cell type we\ndefine a synergy scoring function that can inductively score unseen pairs of\ndrugs. Experimental results on the synergy scoring task demonstrate that MOOMIN\noutperforms state-of-the-art graph fingerprinting, proximity preserving node\nembedding, and existing deep learning approaches. Further results establish\nthat the predictive performance of our model is robust to hyperparameter\nchanges. We demonstrate that the model makes high-quality predictions over a\nwide range of cancer cell line tissues, out-of-sample predictions can be\nvalidated with external synergy databases, and that the proposed model is\ndata-efficient at learning.",
    "descriptor": "",
    "authors": [
      "Benedek Rozemberczki",
      "Anna Gogleva",
      "Sebastian Nilsson",
      "Gavin Edwards",
      "Andriy Nikolov",
      "Eliseo Papa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.15087"
  },
  {
    "id": "arXiv:2110.15089",
    "title": "D2RLIR : an improved and diversified ranking function in interactive  recommendation systems based on deep reinforcement learning",
    "abstract": "Recently, interactive recommendation systems based on reinforcement learning\nhave been attended by researchers due to the consider recommendation procedure\nas a dynamic process and update the recommendation model based on immediate\nuser feedback, which is neglected in traditional methods. The existing works\nhave two significant drawbacks. Firstly, inefficient ranking function to\nproduce the Top-N recommendation list. Secondly, focusing on recommendation\naccuracy and inattention to other evaluation metrics such as diversity. This\npaper proposes a deep reinforcement learning based recommendation system by\nutilizing Actor-Critic architecture to model dynamic users' interaction with\nthe recommender agent and maximize the expected long-term reward. Furthermore,\nwe propose utilizing Spotify's ANNoy algorithm to find the most similar items\nto generated action by actor-network. After that, the Total Diversity Effect\nRanking algorithm is used to generate the recommendations concerning relevancy\nand diversity. Moreover, we apply positional encoding to compute\nrepresentations of the user's interaction sequence without using\nsequence-aligned recurrent neural networks. Extensive experiments on the\nMovieLens dataset demonstrate that our proposed model is able to generate a\ndiverse while relevance recommendation list based on the user's preferences.",
    "descriptor": "",
    "authors": [
      "Vahid Baghi",
      "Seyed Mohammad Seyed Motehayeri",
      "Ali Moeini",
      "Rooholah Abedian"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15089"
  },
  {
    "id": "arXiv:2110.15092",
    "title": "A Law of Iterated Logarithm for Multi-Agent Reinforcement Learning",
    "abstract": "In Multi-Agent Reinforcement Learning (MARL), multiple agents interact with a\ncommon environment, as also with each other, for solving a shared problem in\nsequential decision-making. It has wide-ranging applications in gaming,\nrobotics, finance, etc. In this work, we derive a novel law of iterated\nlogarithm for a family of distributed nonlinear stochastic approximation\nschemes that is useful in MARL. In particular, our result describes the\nconvergence rate on almost every sample path where the algorithm converges.\nThis result is the first of its kind in the distributed setup and provides\ndeeper insights than the existing ones, which only discuss convergence rates in\nthe expected or the CLT sense. Importantly, our result holds under\nsignificantly weaker assumptions: neither the gossip matrix needs to be doubly\nstochastic nor the stepsizes square summable. As an application, we show that,\nfor the stepsize $n^{-\\gamma}$ with $\\gamma \\in (0, 1),$ the distributed TD(0)\nalgorithm with linear function approximation has a convergence rate of\n$O(\\sqrt{n^{-\\gamma} \\ln n })$ a.s.; for the $1/n$ type stepsize, the same is\n$O(\\sqrt{n^{-1} \\ln \\ln n})$ a.s. These decay rates do not depend on the graph\ndepicting the interactions among the different agents.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Gugan Thoppe",
      "Bhumesh Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15092"
  },
  {
    "id": "arXiv:2110.15093",
    "title": "Finite Horizon Q-learning: Stability, Convergence and Simulations",
    "abstract": "Q-learning is a popular reinforcement learning algorithm. This algorithm has\nhowever been studied and analysed mainly in the infinite horizon setting. There\nare several important applications which can be modeled in the framework of\nfinite horizon Markov decision processes. We develop a version of Q-learning\nalgorithm for finite horizon Markov decision processes (MDP) and provide a full\nproof of its stability and convergence. Our analysis of stability and\nconvergence of finite horizon Q-learning is based entirely on the ordinary\ndifferential equations (O.D.E) method. We also demonstrate the performance of\nour algorithm on a setting of random MDP.",
    "descriptor": "",
    "authors": [
      "Vivek VP",
      "Dr.Shalabh Bhatnagar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15093"
  },
  {
    "id": "arXiv:2110.15094",
    "title": "Mosaicking to Distill: Knowledge Distillation from Out-of-Domain Data",
    "abstract": "Knowledge distillation~(KD) aims to craft a compact student model that\nimitates the behavior of a pre-trained teacher in a target domain. Prior KD\napproaches, despite their gratifying results, have largely relied on the\npremise that \\emph{in-domain} data is available to carry out the knowledge\ntransfer. Such an assumption, unfortunately, in many cases violates the\npractical setting, since the original training data or even the data domain is\noften unreachable due to privacy or copyright reasons. In this paper, we\nattempt to tackle an ambitious task, termed as \\emph{out-of-domain} knowledge\ndistillation~(OOD-KD), which allows us to conduct KD using only OOD data that\ncan be readily obtained at a very low cost. Admittedly, OOD-KD is by nature a\nhighly challenging task due to the agnostic domain gap. To this end, we\nintroduce a handy yet surprisingly efficacious approach, dubbed\nas~\\textit{MosaicKD}. The key insight behind MosaicKD lies in that, samples\nfrom various domains share common local patterns, even though their global\nsemantic may vary significantly; these shared local patterns, in turn, can be\nre-assembled analogous to mosaic tiling, to approximate the in-domain data and\nto further alleviating the domain discrepancy. In MosaicKD, this is achieved\nthrough a four-player min-max game, in which a generator, a discriminator, a\nstudent network, are collectively trained in an adversarial manner, partially\nunder the guidance of a pre-trained teacher. We validate MosaicKD over\n{classification and semantic segmentation tasks} across various benchmarks, and\ndemonstrate that it yields results much superior to the state-of-the-art\ncounterparts on OOD data. Our code is available at\n\\url{https://github.com/zju-vipa/MosaicKD}.",
    "descriptor": "",
    "authors": [
      "Gongfan Fang",
      "Yifan Bao",
      "Jie Song",
      "Xinchao Wang",
      "Donglin Xie",
      "Chengchao Shen",
      "Mingli Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15094"
  },
  {
    "id": "arXiv:2110.15097",
    "title": "Choosing the Best of Both Worlds: Diverse and Novel Recommendations  through Multi-Objective Reinforcement Learning",
    "abstract": "Since the inception of Recommender Systems (RS), the accuracy of the\nrecommendations in terms of relevance has been the golden criterion for\nevaluating the quality of RS algorithms. However, by focusing on item\nrelevance, one pays a significant price in terms of other important metrics:\nusers get stuck in a \"filter bubble\" and their array of options is\nsignificantly reduced, hence degrading the quality of the user experience and\nleading to churn. Recommendation, and in particular session-based/sequential\nrecommendation, is a complex task with multiple - and often conflicting\nobjectives - that existing state-of-the-art approaches fail to address.\nIn this work, we take on the aforementioned challenge and introduce\nScalarized Multi-Objective Reinforcement Learning (SMORL) for the RS setting, a\nnovel Reinforcement Learning (RL) framework that can effectively address\nmulti-objective recommendation tasks. The proposed SMORL agent augments\nstandard recommendation models with additional RL layers that enforce it to\nsimultaneously satisfy three principal objectives: accuracy, diversity, and\nnovelty of recommendations. We integrate this framework with four\nstate-of-the-art session-based recommendation models and compare it with a\nsingle-objective RL agent that only focuses on accuracy. Our experimental\nresults on two real-world datasets reveal a substantial increase in aggregate\ndiversity, a moderate increase in accuracy, reduced repetitiveness of\nrecommendations, and demonstrate the importance of reinforcing diversity and\nnovelty as complementary objectives.",
    "descriptor": "\nComments: 9 pages, 4 figures, Proc. ACM WSDM, 2022 In Proceedings of the 15th ACM International Conference on Web Search and Data Mining (WSDM '22), February 21-25, 2022, Phoenix, Arizona\n",
    "authors": [
      "Dusan Stamenkovic",
      "Alexandros Karatzoglou",
      "Ioannis Arapakis",
      "Xin Xin",
      "Kleomenis Katevas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.15097"
  },
  {
    "id": "arXiv:2110.15098",
    "title": "A Framework for Parameterized Subexponential Algorithms for Generalized  Cycle Hitting Problems on Planar Graphs",
    "abstract": "Subexponential parameterized algorithms are known for a wide range of natural\nproblems on planar graphs, but the techniques are usually highly problem\nspecific. The goal of this paper is to introduce a framework for obtaining\n$n^{O(\\sqrt{k})}$ time algorithms for a family of graph modification problems\nthat includes problems that can be seen as generalized cycle hitting problems.\nOur starting point is the Node Unique Label Cover problem (that is, given a\nCSP instance where each constraint is a permutation of values on two variables,\nthe task is to delete $k$ variables to make the instance satisfiable). We\nintroduce a variant of the problem where $k$ vertices have to be deleted such\nthat every 2-connected component of the remaining instance is satisfiable. Then\nwe extend the problem with cardinality constraints that restrict the number of\ntimes a certain value can be used (globally or within a 2-connected component\nof the solution). We show that there is an $n^{O(\\sqrt{k})}$ time algorithm on\nplanar graphs for any problem that can be formulated this way, which includes a\nlarge number of well-studied problems, for example, Odd Cycle Transversal,\nSubset Feedback Vertex Set, Group Feedback Vertex Set, Subset Group Feedback\nVertex Set, Vertex Multiway Cut, and Component Order Connectivity.\nFor those problems that admit appropriate (quasi)polynomial kernels (that\nincrease the parameter only linearly and preserve planarity), our results\nimmediately imply $2^{O(\\sqrt{k}\\cdot\\operatorname{polylog}(k))}n^{O(1)}$ time\nparameterized algorithms on planar graphs. In particular, we use or adapt known\nkernelization results to obtain $2^{O(\\sqrt{k}\\cdot \\operatorname{polylog}(k))}\nn^{O(1)}$ time (randomized) algorithms for Vertex Multiway Cut, Group Feedback\nVertex Set, and Subset Feedback Vertex Set.",
    "descriptor": "\nComments: 97 pages, 8 figures\n",
    "authors": [
      "D\u00e1niel Marx",
      "Pranabendu Misra",
      "Daniel Neuen",
      "Prafullkumar Tale"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2110.15098"
  },
  {
    "id": "arXiv:2110.15101",
    "title": "Identification over Compound MIMO Broadcast Channels",
    "abstract": "The identification (ID) capacity region of the compound broadcast channel is\ndetermined under an average error criterion, where the sender has no channel\nstate information. We give single-letter ID capacity formulas for discrete\nchannels and MIMO Gaussian channels, under an average input constraint. The\ncapacity theorems apply to general broadcast channels. This is in contrast to\nthe transmission setting, where the capacity is only known for special cases,\nnotably the degraded broadcast channel and the MIMO broadcast channel with\nprivate messages. Furthermore, the ID capacity region of the compound MIMO\nbroadcast channel is in general larger than the transmission capacity region.\nThis is a departure from the single-user behavior of ID, since the ID capacity\nof a single-user channel equals the transmission capacity.",
    "descriptor": "",
    "authors": [
      "Johannes Rosenberger",
      "Uzi Pereg",
      "Christian Deppe"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.15101"
  },
  {
    "id": "arXiv:2110.15103",
    "title": "Be Lean -- How to Fit a Model-Based System Architecture Development  Process Based on ARP4754 Into an Agile Environment",
    "abstract": "An emerging service is moving the known aviation sector in terms of\ntechnology, paradigms, and key players - the Urban Air Mobility. The reason:\nnew developments in non-aviation industries are driving technological progress\nin aviation. For instance electrical motors, modern sensor technologies and\nbetter energy storage expand the possibilities and enable novel vehicle\nconcepts which require also novel system architectures for flight control\nsystems. Their development is governed by aviation authority and industry\nrecognized standards, guidelines and recommended practices. Comprehensive\nmethods for Model-Based Systems Engineering exist which address these guidance\nmaterials but their setup and their application can be quite\nresource-demanding. Especially the new and rather small key players - start-ups\nand development teams in an educational environment - can be overwhelmed to\nsetup such development processes. For these clients, the authors propose a\ncustom workflow for the development of system architectures. It shall ensure\ndevelopment rigor, quality and consistency. The authors show how the custom\nworkflow has been established based on the ARP4754A and its level of compliance\nto the standard's process objectives. Based on automation of life cycle\nactivities, manual effort can be reduced to allow the application even in small\nteams. The custom workflow's activities are explained and demonstrated within a\ncase study of an Experimental Autopilot system architecture.",
    "descriptor": "\nComments: Published at DASC 2021\n",
    "authors": [
      "Daniel Dollinger",
      "Julian Rhein",
      "Kevin Schmiechen",
      "Florian Holzapfel"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.15103"
  },
  {
    "id": "arXiv:2110.15105",
    "title": "A Game-Theoretic Approach for Improving Generalization Ability of TSP  Solvers",
    "abstract": "In this paper, we shed new light on the generalization ability of deep\nlearning-based solvers for Traveling Salesman Problems (TSP). Specifically, we\nintroduce a two-player zero-sum framework between a trainable \\emph{Solver} and\na \\emph{Data Generator}, where the Solver aims to solve the task instances\nprovided by the Generator, and the Generator aims to generate increasingly\ndifficult instances for improving the Solver. Grounded in \\textsl{Policy Space\nResponse Oracle} (PSRO) methods, our two-player framework outputs a population\nof best-responding Solvers, over which we can mix and output a combined model\nthat achieves the least exploitability against the Generator, and thereby the\nmost generalizable performance on different TSP tasks. We conduct experiments\non a variety of TSP instances with different types and sizes. Results suggest\nthat our Solvers achieve the state-of-the-art performance even on tasks the\nSolver never meets, whilst the performance of other deep learning-based Solvers\ndrops sharply due to over-fitting. On real-world instances from\n\\textsc{TSPLib}, our method also attains a \\textbf{12\\%} improvement, in terms\nof optimal gap, over the best baseline model. To demonstrate the principle of\nour framework, we study the learning outcome of the proposed two-player game\nand demonstrate that the exploitability of the Solver population decreases\nduring training, and it eventually approximates the Nash equilibrium along with\nthe Generator.",
    "descriptor": "",
    "authors": [
      "Chenguang Wang",
      "Yaodong Yang",
      "Oliver Slumbers",
      "Congying Han",
      "Tiande Guo",
      "Haifeng Zhang",
      "Jun Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15105"
  },
  {
    "id": "arXiv:2110.15108",
    "title": "Generalized Anomaly Detection",
    "abstract": "We study anomaly detection for the case when the normal class consists of\nmore than one object category. This is an obvious generalization of the\nstandard one-class anomaly detection problem. However, we show that jointly\nusing multiple one-class anomaly detectors to solve this problem yields poorer\nresults as compared to training a single one-class anomaly detector on all\nnormal object categories together. We further develop a new anomaly detector\ncalled DeepMAD that learns compact distinguishing features by exploiting the\nmultiple normal objects categories. This algorithm achieves higher AUC values\nfor different datasets compared to two top performing one-class algorithms that\neither are trained on each normal object category or jointly trained on all\nnormal object categories combined. In addition to theoretical results we\npresent empirical results using the CIFAR-10, fMNIST, CIFAR-100, and a new\ndataset we developed called RECYCLE.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Suresh Singh",
      "Minwei Luo",
      "Yu Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15108"
  },
  {
    "id": "arXiv:2110.15114",
    "title": "UltraGCN: Ultra Simplification of Graph Convolutional Networks for  Recommendation",
    "abstract": "With the recent success of graph convolutional networks (GCNs), they have\nbeen widely applied for recommendation, and achieved impressive performance\ngains. The core of GCNs lies in its message passing mechanism to aggregate\nneighborhood information. However, we observed that message passing largely\nslows down the convergence of GCNs during training, especially for large-scale\nrecommender systems, which hinders their wide adoption. LightGCN makes an early\nattempt to simplify GCNs for collaborative filtering by omitting feature\ntransformations and nonlinear activations. In this paper, we take one step\nfurther to propose an ultra-simplified formulation of GCNs (dubbed UltraGCN),\nwhich skips infinite layers of message passing for efficient recommendation.\nInstead of explicit message passing, UltraGCN resorts to directly approximate\nthe limit of infinite-layer graph convolutions via a constraint loss.\nMeanwhile, UltraGCN allows for more appropriate edge weight assignments and\nflexible adjustment of the relative importances among different types of\nrelationships. This finally yields a simple yet effective UltraGCN model, which\nis easy to implement and efficient to train. Experimental results on four\nbenchmark datasets show that UltraGCN not only outperforms the state-of-the-art\nGCN models but also achieves more than 10x speedup over LightGCN.",
    "descriptor": "\nComments: Paper accepted in CIKM'2021. Code available at: this https URL\n",
    "authors": [
      "Kelong Mao",
      "Jieming Zhu",
      "Xi Xiao",
      "Biao Lu",
      "Zhaowei Wang",
      "Xiuqiang He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.15114"
  },
  {
    "id": "arXiv:2110.15116",
    "title": "Abstract, Rationale, Stance: A Joint Model for Scientific Claim  Verification",
    "abstract": "Scientific claim verification can help the researchers to easily find the\ntarget scientific papers with the sentence evidence from a large corpus for the\ngiven claim. Some existing works propose pipeline models on the three tasks of\nabstract retrieval, rationale selection and stance prediction. Such works have\nthe problems of error propagation among the modules in the pipeline and lack of\nsharing valuable information among modules. We thus propose an approach, named\nas ARSJoint, that jointly learns the modules for the three tasks with a machine\nreading comprehension framework by including claim information. In addition, we\nenhance the information exchanges and constraints among tasks by proposing a\nregularization term between the sentence attention scores of abstract retrieval\nand the estimated outputs of rational selection. The experimental results on\nthe benchmark dataset SciFact show that our approach outperforms the existing\nworks.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Zhiwei Zhang",
      "Jiyi Li",
      "Fumiyo Fukumoto",
      "Yanming Ye"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.15116"
  },
  {
    "id": "arXiv:2110.15122",
    "title": "CAFE: Catastrophic Data Leakage in Vertical Federated Learning",
    "abstract": "Recent studies show that private training data can be leaked through the\ngradients sharing mechanism deployed in distributed machine learning systems,\nsuch as federated learning (FL). Increasing batch size to complicate data\nrecovery is often viewed as a promising defense strategy against data leakage.\nIn this paper, we revisit this defense premise and propose an advanced data\nleakage attack with theoretical justification to efficiently recover batch data\nfrom the shared aggregated gradients. We name our proposed method as\n\\textit{\\underline{c}atastrophic d\\underline{a}ta leakage in vertical\n\\underline{f}ederated l\\underline{e}arning} (CAFE). Comparing to existing data\nleakage attacks, our extensive experimental results on vertical FL settings\ndemonstrate the effectiveness of CAFE to perform large-batch data leakage\nattack with improved data recovery quality. We also propose a practical\ncountermeasure to mitigate CAFE. Our results suggest that private data\nparticipated in standard FL, especially the vertical case, have a high risk of\nbeing leaked from the training gradients. Our analysis implies unprecedented\nand practical data leakage risks in those learning settings. The code of our\nwork is available at\n\\href{https://github.com/DeRafael/CAFE}{\\textcolor{blue}{\\url{https://github.com/DeRafael/CAFE}}}.",
    "descriptor": "",
    "authors": [
      "Xiao Jin",
      "Pin-Yu Chen",
      "Chia-Yi Hsu",
      "Chia-Mu Yu",
      "Tianyi Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15122"
  },
  {
    "id": "arXiv:2110.15125",
    "title": "Numerical solution of the Cauchy problem for Volterra  integrodifferential equations with difference kernels",
    "abstract": "We consider the problems of the numerical solution of the Cauchy problem for\nan evolutionary equation with memory when the kernel of the integral term is a\ndifference one. The computational implementation is associated with the need to\nwork with an approximate solution for all previous points in time. In this\npaper, the considered nonlocal problem is transformed into a local one; a\nloosely coupled equation system with additional ordinary differential equations\nis solved. This approach is based on the approximation of the difference kernel\nby the sum of exponentials. Estimates for the stability of the solution\nconcerning the initial data and the right-hand side for the corresponding\nCauchy problem are obtained. Two-level schemes with weights with convenient\ncomputational implementation are constructed and investigated. The theoretical\nconsideration is supplemented by the results of the numerical solution of the\nintegrodifferential equation when the kernel is the stretching exponential\nfunction.",
    "descriptor": "\nComments: 15 pages, 5 figures\n",
    "authors": [
      "Petr N. Vabishchevich"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.15125"
  },
  {
    "id": "arXiv:2110.15127",
    "title": "Lightweight Mobile Automated Assistant-to-physician for Global  Lower-resource Areas",
    "abstract": "Importance: Lower-resource areas in Africa and Asia face a unique set of\nhealthcare challenges: the dual high burden of communicable and\nnon-communicable diseases; a paucity of highly trained primary healthcare\nproviders in both rural and densely populated urban areas; and a lack of\nreliable, inexpensive internet connections. Objective: To address these\nchallenges, we designed an artificial intelligence assistant to help primary\nhealthcare providers in lower-resource areas document demographic and medical\nsign/symptom data and to record and share diagnostic data in real-time with a\ncentralized database. Design: We trained our system using multiple data sets,\nincluding US-based electronic medical records (EMRs) and open-source medical\nliterature and developed an adaptive, general medical assistant system based on\nmachine learning algorithms. Main outcomes and Measure: The application\ncollects basic information from patients and provides primary care providers\nwith diagnoses and prescriptions suggestions. The application is unique from\nexisting systems in that it covers a wide range of common diseases, signs, and\nmedication typical in lower-resource countries; the application works with or\nwithout an active internet connection. Results: We have built and implemented\nan adaptive learning system that assists trained primary care professionals by\nmeans of an Android smartphone application, which interacts with a central\ndatabase and collects real-time data. The application has been tested by dozens\nof primary care providers. Conclusions and Relevance: Our application would\nprovide primary healthcare providers in lower-resource areas with a tool that\nenables faster and more accurate documentation of medical encounters. This\napplication could be leveraged to automatically populate local or national EMR\nsystems.",
    "descriptor": "",
    "authors": [
      "Chao Zhang",
      "Hanxin Zhang",
      "Atif Khan",
      "Ted Kim",
      "Olasubomi Omoleye",
      "Oluwamayomikun Abiona",
      "Amy Lehman",
      "Christopher O. Olopade",
      "Olufunmilayo I. Olopade",
      "Pedro Lopes",
      "Andrey Rzhetsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.15127"
  },
  {
    "id": "arXiv:2110.15128",
    "title": "Contrast and Mix: Temporal Contrastive Video Domain Adaptation with  Background Mixing",
    "abstract": "Unsupervised domain adaptation which aims to adapt models trained on a\nlabeled source domain to a completely unlabeled target domain has attracted\nmuch attention in recent years. While many domain adaptation techniques have\nbeen proposed for images, the problem of unsupervised domain adaptation in\nvideos remains largely underexplored. In this paper, we introduce Contrast and\nMix (CoMix), a new contrastive learning framework that aims to learn\ndiscriminative invariant feature representations for unsupervised video domain\nadaptation. First, unlike existing methods that rely on adversarial learning\nfor feature alignment, we utilize temporal contrastive learning to bridge the\ndomain gap by maximizing the similarity between encoded representations of an\nunlabeled video at two different speeds as well as minimizing the similarity\nbetween different videos played at different speeds. Second, we propose a novel\nextension to the temporal contrastive loss by using background mixing that\nallows additional positives per anchor, thus adapting contrastive learning to\nleverage action semantics shared across both domains. Moreover, we also\nintegrate a supervised contrastive learning objective using target\npseudo-labels to enhance discriminability of the latent space for video domain\nadaptation. Extensive experiments on several benchmark datasets demonstrate the\nsuperiority of our proposed approach over state-of-the-art methods. Project\npage: https://cvir.github.io/projects/comix",
    "descriptor": "\nComments: Accepted to NeurIPS 2021. Project page: this https URL\n",
    "authors": [
      "Aadarsh Sahoo",
      "Rutav Shah",
      "Rameswar Panda",
      "Kate Saenko",
      "Abir Das"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15128"
  },
  {
    "id": "arXiv:2110.15130",
    "title": "Confounds and Overestimations in Fake Review Detection: Experimentally  Controlling for Product-Ownership and Data-Origin",
    "abstract": "The popularity of online shopping is steadily increasing. At the same time,\nfake product reviewsare published widely and have the potential to affect\nconsumer purchasing behavior. In response,previous work has developed automated\nmethods for the detection of deceptive product reviews.However, studies vary\nconsiderably in terms of classification performance, and many use data\nthatcontain potential confounds, which makes it difficult to determine their\nvalidity. Two possibleconfounds are data-origin (i.e., the dataset is composed\nof more than one source) and productownership (i.e., reviews written by\nindividuals who own or do not own the reviewed product). Inthe present study,\nwe investigate the effect of both confounds for fake review detection. Using\nanexperimental design, we manipulate data-origin, product ownership, review\npolarity, and veracity.Supervised learning analysis suggests that review\nveracity (60.26 - 69.87%) is somewhat detectablebut reviews additionally\nconfounded with product-ownership (66.19 - 74.17%), or with data-origin(84.44 -\n86.94%) are easier to classify. Review veracity is most easily classified if\nconfounded withproduct-ownership and data-origin combined (87.78 - 88.12%),\nsuggesting overestimations of thetrue performance in other work. These findings\nare moderated by review polarity.",
    "descriptor": "\nComments: This paper is a pre-print\n",
    "authors": [
      "Felix Soldner",
      "Bennett Kleinberg",
      "Shane Johnson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.15130"
  },
  {
    "id": "arXiv:2110.15132",
    "title": "Generating Table Vector Representations",
    "abstract": "High-quality Web tables are rich sources of information that can be used to\npopulate Knowledge Graphs (KG). The focus of this paper is an evaluation of\nmethods for table-to-class annotation, which is a sub-task of Table\nInterpretation (TI). We provide a formal definition for table classification as\na machine learning task. We propose an experimental setup and we evaluate 5\nfundamentally different approaches to find the best method for generating\nvector table representations. Our findings indicate that although transfer\nlearning methods achieve high F1 score on the table classification task,\ndedicated table encoding models are a promising direction as they appear to\ncapture richer semantics.",
    "descriptor": "\nComments: Accepted at DL4KF@ISWC\n",
    "authors": [
      "Aneta Koleva",
      "Martin Ringsquandl",
      "Mitchell Joblin",
      "Volker Tresp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.15132"
  },
  {
    "id": "arXiv:2110.15134",
    "title": "An Analysis of Programming Course Evaluations Before and After the  Introduction of an Autograder",
    "abstract": "Commonly, introductory programming courses in higher education institutions\nhave hundreds of participating students eager to learn to program. The manual\neffort for reviewing the submitted source code and for providing feedback can\nno longer be managed. Manually reviewing the submitted homework can be\nsubjective and unfair, particularly if many tutors are responsible for grading.\nDifferent autograders can help in this situation; however, there is a lack of\nknowledge about how autograders can impact students' overall perception of\nprogramming classes and teaching. This is relevant for course organizers and\ninstitutions to keep their programming courses attractive while coping with\nincreasing students.\nThis paper studies the answers to the standardized university evaluation\nquestionnaires of multiple large-scale foundational computer science courses\nwhich recently introduced autograding. The differences before and after this\nintervention are analyzed. By incorporating additional observations, we\nhypothesize how the autograder might have contributed to the significant\nchanges in the data, such as, improved interactions between tutors and\nstudents, improved overall course quality, improved learning success, increased\ntime spent, and reduced difficulty. This qualitative study aims to provide\nhypotheses for future research to define and conduct quantitative surveys and\ndata analysis. The autograder technology can be validated as a teaching method\nto improve student satisfaction with programming courses.",
    "descriptor": "\nComments: Accepted full paper article on IEEE ITHET 2021\n",
    "authors": [
      "Gerhard Hagerer",
      "Laura Lahesoo",
      "Miriam Ansch\u00fctz",
      "Stephan Krusche",
      "Georg Groh"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.15134"
  },
  {
    "id": "arXiv:2110.15136",
    "title": "Aggregation as Unsupervised Learning and its Evaluation",
    "abstract": "Regression uses supervised machine learning to find a model that combines\nseveral independent variables to predict a dependent variable based on ground\ntruth (labeled) data, i.e., tuples of independent and dependent variables\n(labels). Similarly, aggregation also combines several independent variables to\na dependent variable. The dependent variable should preserve properties of the\nindependent variables, e.g., the ranking or relative distance of the\nindependent variable tuples, and/or represent a latent ground truth that is a\nfunction of these independent variables. However, ground truth data is not\navailable for finding the aggregation model. Consequently, aggregation models\nare data agnostic or can only be derived with unsupervised machine learning\napproaches.\nWe introduce a novel unsupervised aggregation approach based on intrinsic\nproperties of unlabeled training data, such as the cumulative probability\ndistributions of the single independent variables and their mutual\ndependencies.\nWe present an empirical evaluation framework that allows assessing the\nproposed approach against other aggregation approaches from two perspectives:\n(i) how well the aggregation output represents properties of the input tuples,\nand (ii) how well can aggregated output predict a latent ground truth. To this\nend, we use data sets for assessing supervised regression approaches that\ncontain explicit ground truth labels. However, the ground truth is not used for\nderiving the aggregation models, but it allows for the assessment from a\nperspective (ii). More specifically, we use regression data sets from the UCI\nmachine learning repository and benchmark several data-agnostic and\nunsupervised approaches for aggregation against ours.\nThe benchmark results indicate that our approach outperforms the other\ndata-agnostic and unsupervised aggregation approaches. It is almost on par with\nlinear regression.",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Maria Ulan",
      "Welf L\u00f6we",
      "Morgan Ericsson",
      "Anna Wingkvist"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15136"
  },
  {
    "id": "arXiv:2110.15137",
    "title": "Learning Aggregations of Binary Activated Neural Networks with  Probabilities over Representations",
    "abstract": "Considering a probability distribution over parameters is known as an\nefficient strategy to learn a neural network with non-differentiable activation\nfunctions. We study the expectation of a probabilistic neural network as a\npredictor by itself, focusing on the aggregation of binary activated neural\nnetworks with normal distributions over real-valued weights. Our work leverages\na recent analysis derived from the PAC-Bayesian framework that derives tight\ngeneralization bounds and learning procedures for the expected output value of\nsuch an aggregation, which is given by an analytical expression. While the\ncombinatorial nature of the latter has been circumvented by approximations in\nprevious works, we show that the exact computation remains tractable for deep\nbut narrow neural networks, thanks to a dynamic programming approach. This\nleads us to a peculiar bound minimization learning algorithm for binary\nactivated neural networks, where the forward pass propagates probabilities over\nrepresentations instead of activation values. A stochastic counterpart of this\nnew neural networks training scheme that scales to wider architectures is\nproposed.",
    "descriptor": "",
    "authors": [
      "Louis Fortier-Dubois",
      "Ga\u00ebl Letarte",
      "Benjamin Leblanc",
      "Fran\u00e7ois Laviolette",
      "Pascal Germain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15137"
  },
  {
    "id": "arXiv:2110.15138",
    "title": "Deep Learning Aided Routing for Space-Air-Ground Integrated Networks  Relying on Real Satellite, Flight, and Shipping Data",
    "abstract": "Current maritime communications mainly rely on satellites having meager\ntransmission resources, hence suffering from poorer performance than modern\nterrestrial wireless networks. With the growth of transcontinental air traffic,\nthe promising concept of aeronautical ad hoc networking relying on commercial\npassenger airplanes is potentially capable of enhancing satellite-based\nmaritime communications via air-to-ground and multi-hop air-to-air links. In\nthis article, we conceive space-air-ground integrated networks (SAGINs) for\nsupporting ubiquitous maritime communications, where the low-earth-orbit\nsatellite constellations, passenger airplanes, terrestrial base stations,\nships, respectively, serve as the space-, air-, ground- and sea-layer. To meet\nheterogeneous service requirements, and accommodate the time-varying and\nself-organizing nature of SAGINs, we propose a deep learning (DL) aided\nmulti-objective routing algorithm, which exploits the quasi-predictable network\ntopology and operates in a distributed manner. Our simulation results based on\nreal satellite, flight, and shipping data in the North Atlantic region show\nthat the integrated network enhances the coverage quality by reducing the\nend-to-end (E2E) delay and by boosting the E2E throughput as well as improving\nthe path-lifetime. The results demonstrate that our DL-aided multi-objective\nrouting algorithm is capable of achieving near Pareto-optimal performance.",
    "descriptor": "\nComments: Accepted by IEEE Wireless Communications\n",
    "authors": [
      "Dong Liu",
      "Jiankang Zhang",
      "Jingjing Cui",
      "Soon-Xin Ng",
      "Robert G. Maunder",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15138"
  },
  {
    "id": "arXiv:2110.15142",
    "title": "Learning Feasibility to Imitate Demonstrators with Different Dynamics",
    "abstract": "The goal of learning from demonstrations is to learn a policy for an agent\n(imitator) by mimicking the behavior in the demonstrations. Prior works on\nlearning from demonstrations assume that the demonstrations are collected by a\ndemonstrator that has the same dynamics as the imitator. However, in many\nreal-world applications, this assumption is limiting -- to improve the problem\nof lack of data in robotics, we would like to be able to leverage\ndemonstrations collected from agents with different dynamics. This can be\nchallenging as the demonstrations might not even be feasible for the imitator.\nOur insight is that we can learn a feasibility metric that captures the\nlikelihood of a demonstration being feasible by the imitator. We develop a\nfeasibility MDP (f-MDP) and derive the feasibility score by learning an optimal\npolicy in the f-MDP. Our proposed feasibility measure encourages the imitator\nto learn from more informative demonstrations, and disregard the far from\nfeasible demonstrations. Our experiments on four simulated environments and on\na real robot show that the policy learned with our approach achieves a higher\nexpected return than prior works. We show the videos of the real robot arm\nexperiments on our website\n(https://sites.google.com/view/learning-feasibility).",
    "descriptor": "",
    "authors": [
      "Zhangjie Cao",
      "Yilun Hao",
      "Mengxi Li",
      "Dorsa Sadigh"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15142"
  },
  {
    "id": "arXiv:2110.15145",
    "title": "Deep Learning Aided Packet Routing in Aeronautical Ad-Hoc Networks  Relying on Real Flight Data: From Single-Objective to Near-Pareto  Multi-Objective Optimization",
    "abstract": "Data packet routing in aeronautical ad-hoc networks (AANETs) is challenging\ndue to their high-dynamic topology. In this paper, we invoke deep learning (DL)\nto assist routing in AANETs. We set out from the single objective of minimizing\nthe end-to-end (E2E) delay. Specifically, a deep neural network (DNN) is\nconceived for mapping the local geographic information observed by the\nforwarding node into the information required for determining the optimal next\nhop. The DNN is trained by exploiting the regular mobility pattern of\ncommercial passenger airplanes from historical flight data. After training, the\nDNN is stored by each airplane for assisting their routing decisions during\nflight relying solely on local geographic information. Furthermore, we extend\nthe DL-aided routing algorithm to a multi-objective scenario, where we aim for\nsimultaneously minimizing the delay, maximizing the path capacity, and\nmaximizing the path lifetime. Our simulation results based on real flight data\nshow that the proposed DL-aided routing outperforms existing position-based\nrouting protocols in terms of its E2E delay, path capacity as well as path\nlifetime, and it is capable of approaching the Pareto front that is obtained\nusing global link information.",
    "descriptor": "\nComments: Published in IEEE Internet of Things Journal\n",
    "authors": [
      "Dong Liu",
      "Jiankang Zhang",
      "Jingjing Cui",
      "Soon-Xin Ng",
      "Robert G. Maunder",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15145"
  },
  {
    "id": "arXiv:2110.15146",
    "title": "Deep Reinforcement Learning Aided Packet-Routing For Aeronautical Ad-Hoc  Networks Formed by Passenger Planes",
    "abstract": "Data packet routing in aeronautical ad-hoc networks (AANETs) is challenging\ndue to their high-dynamic topology. In this paper, we invoke deep reinforcement\nlearning for routing in AANETs aiming at minimizing the end-to-end (E2E) delay.\nSpecifically, a deep Q-network (DQN) is conceived for capturing the\nrelationship between the optimal routing decision and the local geographic\ninformation observed by the forwarding node. The DQN is trained in an offline\nmanner based on historical flight data and then stored by each airplane for\nassisting their routing decisions during flight. To boost the learning\nefficiency and the online adaptability of the proposed DQN-routing, we further\nexploit the knowledge concerning the system's dynamics by using a deep value\nnetwork (DVN) conceived with a feedback mechanism. Our simulation results show\nthat both DQN-routing and DVN-routing achieve lower E2E delay than the\nbenchmark protocol, and DVN-routing performs similarly to the optimal routing\nthat relies on perfect global information.",
    "descriptor": "",
    "authors": [
      "Dong Liu",
      "Jingjing Cui",
      "Jiankang Zhang",
      "Chenyang Yang",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15146"
  },
  {
    "id": "arXiv:2110.15149",
    "title": "Diversity-Driven Combination for Grammatical Error Correction",
    "abstract": "Grammatical error correction (GEC) is the task of detecting and correcting\nerrors in a written text. The idea of combining multiple system outputs has\nbeen successfully used in GEC. To achieve successful system combination,\nmultiple component systems need to produce corrected sentences that are both\ndiverse and of comparable quality. However, most existing state-of-the-art GEC\napproaches are based on similar sequence-to-sequence neural networks, so the\ngains are limited from combining the outputs of component systems similar to\none another. In this paper, we present Diversity-Driven Combination (DDC) for\nGEC, a system combination strategy that encourages diversity among component\nsystems. We evaluate our system combination strategy on the CoNLL-2014 shared\ntask and the BEA-2019 shared task. On both benchmarks, DDC achieves significant\nperformance gain with a small number of training examples and outperforms the\ncomponent systems by a large margin. Our source code is available at\nhttps://github.com/nusnlp/gec-ddc.",
    "descriptor": "\nComments: Accepted by ICTAI 2021\n",
    "authors": [
      "Wenjuan Han",
      "Hwee Tou Ng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.15149"
  },
  {
    "id": "arXiv:2110.15150",
    "title": "Messaging with Purpose Limitation -- Privacy-Compliant Publish-Subscribe  Systems",
    "abstract": "Purpose limitation is an important privacy principle to ensure that personal\ndata may only be used for the declared purposes it was originally collected\nfor. Ensuring compliance with respective privacy regulations like the GDPR,\nwhich codify purpose limitation as an obligation, consequently, is a major\nchallenge in real-world enterprise systems. Technical solutions under the\numbrella of purpose-based access control (PBAC), however, focus mostly on data\nbeing held at-rest in databases, while PBAC for communication and\npublish-subscribe messaging in particular has received only little attention.\nIn this paper, we argue for PBAC to be also applied to data-in-transit and\nintroduce and study a concrete proof-of-concept implementation, which extends a\npopular MQTT message broker with purpose limitation. On this basis, purpose\nlimitation as a core privacy principle can be addressed in enterprise IoT and\nmessage-driven integration architectures that do not focus on databases but\nevent-driven communication and integration instead.",
    "descriptor": "",
    "authors": [
      "Karl Wolf",
      "Frank Pallas",
      "Stefan Tai"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.15150"
  },
  {
    "id": "arXiv:2110.15152",
    "title": "Share-a-ride problems: Models and Solution Algorithms",
    "abstract": "Some of today's greatest challenges in urban environments concern individual\nmobility and rapid parcel delivery. Given the surge of e-commerce and the\never-increasing volume of goods to be delivered, we explore possible logistic\nsolutions by proposing algorithms to add parcel-transport services to\nride-hailing systems. Toward this end, we present and solve mixed-integer\nlinear programming (MILP) formulations of the share-a-ride problem and\nquantitatively analyze the service revenues and use of vehicle resources. We\ncreate five scenarios that represent joint transportation situations for\nparcels and people, and that consider different densities in request types and\ndifferent requirements for vehicle resources. For one scenario, we propose an\nalternative MILP formulation that significantly reduces computation times. The\nproposed model also improves scalability by solving instances with 260% more\nrequests than those solved with general MILP. The results show that the\ngreatest profit margins occur when several parcels share trips with customers.\nIn contrast, with all metrics considered, the worst results occur when parcels\nand people are transported in separate dedicated vehicles. The integration of\nparcel services in ride-hailing systems also reduces vehicle waiting times when\nthe number of parcel requests exceeds the number of ride-hailing customers.",
    "descriptor": "",
    "authors": [
      "Ana Beatriz Herthel",
      "Richard Hartl",
      "Thibaut Vidal",
      "Anand Subramanian"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.15152"
  },
  {
    "id": "arXiv:2110.15154",
    "title": "Cross-Batch Negative Sampling for Training Two-Tower Recommenders",
    "abstract": "The two-tower architecture has been widely applied for learning item and user\nrepresentations, which is important for large-scale recommender systems. Many\ntwo-tower models are trained using various in-batch negative sampling\nstrategies, where the effects of such strategies inherently rely on the size of\nmini-batches. However, training two-tower models with a large batch size is\ninefficient, as it demands a large volume of memory for item and user contents\nand consumes a lot of time for feature encoding. Interestingly, we find that\nneural encoders can output relatively stable features for the same input after\nwarming up in the training process. Based on such facts, we propose a simple\nyet effective sampling strategy called Cross-Batch Negative Sampling (CBNS),\nwhich takes advantage of the encoded item embeddings from recent mini-batches\nto boost the model training. Both theoretical analysis and empirical\nevaluations demonstrate the effectiveness and the efficiency of CBNS.",
    "descriptor": "\nComments: Paper accepted in SIGIR'2021\n",
    "authors": [
      "Jinpeng Wang",
      "Jieming Zhu",
      "Xiuqiang He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.15154"
  },
  {
    "id": "arXiv:2110.15155",
    "title": "Online Facility Location with Linear Delay",
    "abstract": "We study the problem of online facility location with delay. In this problem,\na sequence of $n$ clients appear in the metric space, and they need to be\neventually connected to some open facility. The clients do not have to be\nconnected immediately, but such a choice comes with a penalty: each client\nincurs a waiting cost (the difference between its arrival and connection time).\nAt any point in time, an algorithm may decide to open a facility and connect\nany subset of clients to it. This is a well-studied problem both of its own,\nand within the general class of network design problems with delays.\nOur main focus is on a new variant of this problem, where clients may be\nconnected also to an already open facility, but such action incurs an extra\ncost: an algorithm pays for waiting of the facility (a cost incurred separately\nfor each such \"late\" connection). This is reminiscent of online matching with\ndelays, where both sides of the connection incur a waiting cost. We call this\nvariant two-sided delay to differentiate it from the previously studied\none-sided delay.\nWe present an $O(1)$-competitive deterministic algorithm for the two-sided\ndelay variant. On the technical side, we study a greedy strategy, which grows\nbudgets with increasing waiting delays and opens facilities for subsets of\nclients once sums of these budgets reach certain thresholds. Our technique is a\nsubstantial extension of the approach used by Jain, Mahdian and Saberi [STOC\n2002] for analyzing the performance of offline algorithms for facility\nlocation.\nWe then show how to transform our $O(1)$-competitive algorithm for the\ntwo-sided delay variant to $O(\\log n / \\log \\log n)$-competitive deterministic\nalgorithm for one-sided delays. We note that all previous online algorithms for\nproblems with delays in general metrics have at least logarithmic ratios.",
    "descriptor": "",
    "authors": [
      "Marcin Bienkowski",
      "Martin B\u00f6hm",
      "Jaros\u0142aw Byrka",
      "Jan Marcinkowski"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.15155"
  },
  {
    "id": "arXiv:2110.15156",
    "title": "Blending Anti-Aliasing into Vision Transformer",
    "abstract": "The transformer architectures, based on self-attention mechanism and\nconvolution-free design, recently found superior performance and booming\napplications in computer vision. However, the discontinuous patch-wise\ntokenization process implicitly introduces jagged artifacts into attention\nmaps, arising the traditional problem of aliasing for vision transformers.\nAliasing effect occurs when discrete patterns are used to produce high\nfrequency or continuous information, resulting in the indistinguishable\ndistortions. Recent researches have found that modern convolution networks\nstill suffer from this phenomenon. In this work, we analyze the uncharted\nproblem of aliasing in vision transformer and explore to incorporate\nanti-aliasing properties. Specifically, we propose a plug-and-play\nAliasing-Reduction Module(ARM) to alleviate the aforementioned issue. We\ninvestigate the effectiveness and generalization of the proposed method across\nmultiple tasks and various vision transformer families. This lightweight design\nconsistently attains a clear boost over several famous structures. Furthermore,\nour module also improves data efficiency and robustness of vision transformers.",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Shengju Qian",
      "Hao Shao",
      "Yi Zhu",
      "Mu Li",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15156"
  },
  {
    "id": "arXiv:2110.15157",
    "title": "Optimizing Tail Latency in Commodity Datacenters using Forward Error  Correction",
    "abstract": "Long tail latency of short flows (or messages) greatly affects user-facing\napplications in datacenters. Prior solutions to the problem introduce\nsignificant implementation complexities, such as global state monitoring,\ncomplex network control, or non-trivial switch modifications. While promising\nsuperior performance, they are hard to implement in practice. This paper\npresents CloudBurst, a simple, effective yet readily deployable solution\nachieving similar or even better results without introducing the above\ncomplexities. At its core, CloudBurst explores forward error correction (FEC)\nover multipath - it proactively spreads FEC-coded packets generated from\nmessages over multipath in parallel, and recovers them with the first few\narriving ones. As a result, CloudBurst is able to obliviously exploit\nunderutilized paths, thus achieving low tail latency. We have implemented\nCloudBurst as a user-space library, and deployed it on a testbed with commodity\nswitches. Our testbed and simulation experiments show the superior performance\nof CloudBurst. For example, CloudBurst achieves 63.69% and 60.06% reduction in\n99th percentile message/flow completion time (FCT) compared to DCTCP and PIAS,\nrespectively.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Zeng Gaoxiong",
      "Chen Li",
      "Yi Bairen",
      "Chen Kai"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.15157"
  },
  {
    "id": "arXiv:2110.15160",
    "title": "Feature Learning for Neural-Network-Based Positioning with Channel State  Information",
    "abstract": "Recent channel state information (CSI)-based positioning pipelines rely on\ndeep neural networks (DNNs) in order to learn a mapping from estimated CSI to\nposition. Since real-world communication transceivers suffer from hardware\nimpairments, CSI-based positioning systems typically rely on features that are\ndesigned by hand. In this paper, we propose a CSI-based positioning pipeline\nthat directly takes raw CSI measurements and learns features using a structured\nDNN in order to generate probability maps describing the likelihood of the\ntransmitter being at pre-defined grid points. To further improve the\npositioning accuracy of moving user equipments, we propose to fuse a\ntime-series of learned CSI features or a time-series of probability maps. To\ndemonstrate the efficacy of our methods, we perform experiments with real-world\nindoor line-of-sight (LoS) and non-LoS channel measurements. We show that CSI\nfeature learning and time-series fusion can reduce the mean distance error by\nup to 2.5$\\boldsymbol\\times$ compared to the state-of-the-art.",
    "descriptor": "\nComments: to appear at ASILOMAR 2021\n",
    "authors": [
      "Emre G\u00f6n\u00fclta\u015f",
      "Sueda Taner",
      "Howard Huang",
      "Christoph Studer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.15160"
  },
  {
    "id": "arXiv:2110.15161",
    "title": "Secure Blockchain Platform for Industrial IoT with Trusted Computing  Hardware",
    "abstract": "As a disruptive technology that originates from cryptocurrency, blockchain\nprovides a trusted platform to facilitate industrial IoT (IIoT) applications.\nHowever, implementing a blockchain platform in IIoT scenarios confronts various\nsecurity challenges due to the rigorous deployment condition. To this end, we\npresent a novel design of secure blockchain based on trusted computing hardware\nfor IIoT applications. Specifically, we employ the trusted execution\nenvironment (TEE) module and a customized security chip to safeguard the\nblockchain against different attacking vectors. Furthermore, we implement the\nproposed secure IIoT blockchain on the ARM-based embedded device and build a\nsmall-scale IIoT network to evaluate its performance. Our experimental results\nshow that the secure blockchain platform achieves a high throughput (150TPS)\nwith low transaction confirmation delay (below 66ms), demonstrating its\nfeasibility in practical IIoT scenarios. Finally, we outline the open\nchallenges and future research directions.",
    "descriptor": "",
    "authors": [
      "Qing Yang",
      "Hao Wang",
      "Xiaoxiao Wu",
      "Taotao Wang",
      "Shengli Zhang",
      "Naijin Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.15161"
  },
  {
    "id": "arXiv:2110.15163",
    "title": "Authentication Attacks on Projection-based Cancelable Biometric Schemes",
    "abstract": "Cancelable biometric schemes aim at generating secure biometric templates by\ncombining user specific tokens, such as password, stored secret or salt, along\nwith biometric data. This type of transformation is constructed as a\ncomposition of a biometric transformation with a feature extraction algorithm.\nThe security requirements of cancelable biometric schemes concern the\nirreversibility, unlinkability and revocability of templates, without losing in\naccuracy of comparison. While several schemes were recently attacked regarding\nthese requirements, full reversibility of such a composition in order to\nproduce colliding biometric characteristics, and specifically presentation\nattacks, were never demonstrated to the best of our knowledge. In this paper,\nwe formalize these attacks for a traditional cancelable scheme with the help of\ninteger linear programming (ILP) and quadratically constrained quadratic\nprogramming (QCQP). Solving these optimization problems allows an adversary to\nslightly alter its fingerprint image in order to impersonate any individual.\nMoreover, in an even more severe scenario, it is possible to simultaneously\nimpersonate several individuals.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1910.01389 by other authors\n",
    "authors": [
      "Axel Durbet",
      "Pascal Lafourcade",
      "Denis Migdal",
      "Kevin Thiry-Atighehchi",
      "Paul-Marie Grollemund"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15163"
  },
  {
    "id": "arXiv:2110.15165",
    "title": "Extracting Clinician's Goals by What-if Interpretable Modeling",
    "abstract": "Although reinforcement learning (RL) has tremendous success in many fields,\napplying RL to real-world settings such as healthcare is challenging when the\nreward is hard to specify and no exploration is allowed. In this work, we focus\non recovering clinicians' rewards in treating patients. We incorporate the\nwhat-if reasoning to explain clinician's actions based on future outcomes. We\nuse generalized additive models (GAMs) - a class of accurate, interpretable\nmodels - to recover the reward. In both simulation and a real-world hospital\ndataset, we show our model outperforms baselines. Finally, our model's\nexplanations match several clinical guidelines when treating patients while we\nfound the previously-used linear model often contradicts them.",
    "descriptor": "\nComments: Submitted to AISTATS 2022\n",
    "authors": [
      "Chun-Hao Chang",
      "George Alexandru Adam",
      "Rich Caruana",
      "Anna Goldenberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15165"
  },
  {
    "id": "arXiv:2110.15169",
    "title": "Multimotion Visual Odometry (MVO)",
    "abstract": "Visual motion estimation is a well-studied challenge in autonomous\nnavigation. Recent work has focused on addressing multimotion estimation in\nhighly dynamic environments. These environments not only comprise multiple,\ncomplex motions but also tend to exhibit significant occlusion.\nEstimating third-party motions simultaneously with the sensor egomotion is\ndifficult because an object's observed motion consists of both its true motion\nand the sensor motion. Most previous works in multimotion estimation simplify\nthis problem by relying on appearance-based object detection or\napplication-specific motion constraints. These approaches are effective in\nspecific applications and environments but do not generalize well to the full\nmultimotion estimation problem (MEP).\nThis paper presents Multimotion Visual Odometry (MVO), a multimotion\nestimation pipeline that estimates the full SE(3) trajectory of every motion in\nthe scene, including the sensor egomotion, without relying on appearance-based\ninformation. MVO extends the traditional visual odometry (VO) pipeline with\nmultimotion segmentation and tracking techniques. It uses physically founded\nmotion priors to extrapolate motions through temporary occlusions and identify\nthe reappearance of motions through motion closure. Evaluations on real-world\ndata from the Oxford Multimotion Dataset (OMD) and the KITTI Vision Benchmark\nSuite demonstrate that MVO achieves good estimation accuracy compared to\nsimilar approaches and is applicable to a variety of multimotion estimation\nchallenges.",
    "descriptor": "\nComments: Under review for the International Journal of Robotics Research (IJRR), Manuscript #IJR-21-4311. 25 pages, 14 figures, 11 tables. Videos available at this https URL and this https URL\n",
    "authors": [
      "Kevin M. Judd",
      "Jonathan D. Gammell"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.15169"
  },
  {
    "id": "arXiv:2110.15170",
    "title": "Color image restoration with impulse noise based on fractional-order  total variation and framelet",
    "abstract": "Restore lost images due to noise and blurred is a burgeoning subject in image\nprocessing and despite the different algorithms on this subject, but the effort\nto improve is always considered. The definition of fractional derivatives in\nrecent years has created a powerful tool for this purpose. In the present\npaper, using fractional-order total variation and framelet transform, the\nnonconvex model for image restoration with impulse noise problem is improved.\nThen by alternating direction method of multipliers (ADMM) and primal-dual\nproblem, the proposed model is solved.\nThe convergence of the proposed algorithm is studied. And the proposed\nalgorithm is evaluated using different types of tests. The output results show\nthe efficiency of proposed method.",
    "descriptor": "",
    "authors": [
      "Reza Parvaz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.15170"
  },
  {
    "id": "arXiv:2110.15171",
    "title": "Privacy Aware Person Detection in Surveillance Data",
    "abstract": "Crowd management relies on inspection of surveillance video either by\noperators or by object detection models. These models are large, making it\ndifficult to deploy them on resource constrained edge hardware. Instead, the\ncomputations are often offloaded to a (third party) cloud platform. While crowd\nmanagement may be a legitimate application, transferring video from the camera\nto remote infrastructure may open the door for extracting additional\ninformation that are infringements of privacy, like person tracking or face\nrecognition. In this paper, we use adversarial training to obtain a lightweight\nobfuscator that transforms video frames to only retain the necessary\ninformation for person detection. Importantly, the obfuscated data can be\nprocessed by publicly available object detectors without retraining and without\nsignificant loss of accuracy.",
    "descriptor": "",
    "authors": [
      "Sander De Coninck",
      "Sam Leroux",
      "Pieter Simoens"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15171"
  },
  {
    "id": "arXiv:2110.15172",
    "title": "Conditioning Sparse Variational Gaussian Processes for Online  Decision-making",
    "abstract": "With a principled representation of uncertainty and closed form posterior\nupdates, Gaussian processes (GPs) are a natural choice for online decision\nmaking. However, Gaussian processes typically require at least\n$\\mathcal{O}(n^2)$ computations for $n$ training points, limiting their general\napplicability. Stochastic variational Gaussian processes (SVGPs) can provide\nscalable inference for a dataset of fixed size, but are difficult to\nefficiently condition on new data. We propose online variational conditioning\n(OVC), a procedure for efficiently conditioning SVGPs in an online setting that\ndoes not require re-training through the evidence lower bound with the addition\nof new data. OVC enables the pairing of SVGPs with advanced look-ahead\nacquisition functions for black-box optimization, even with non-Gaussian\nlikelihoods. We show OVC provides compelling performance in a range of\napplications including active learning of malaria incidence, and reinforcement\nlearning on MuJoCo simulated robotic control tasks.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Wesley J. Maddox",
      "Samuel Stanton",
      "Andrew Gordon Wilson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.15172"
  },
  {
    "id": "arXiv:2110.15174",
    "title": "On Provable Benefits of Depth in Training Graph Convolutional Networks",
    "abstract": "Graph Convolutional Networks (GCNs) are known to suffer from performance\ndegradation as the number of layers increases, which is usually attributed to\nover-smoothing. Despite the apparent consensus, we observe that there exists a\ndiscrepancy between the theoretical understanding of over-smoothing and the\npractical capabilities of GCNs. Specifically, we argue that over-smoothing does\nnot necessarily happen in practice, a deeper model is provably expressive, can\nconverge to global optimum with linear convergence rate, and achieve very high\ntraining accuracy as long as properly trained. Despite being capable of\nachieving high training accuracy, empirical results show that the deeper models\ngeneralize poorly on the testing stage and existing theoretical understanding\nof such behavior remains elusive. To achieve better understanding, we carefully\nanalyze the generalization capability of GCNs, and show that the training\nstrategies to achieve high training accuracy significantly deteriorate the\ngeneralization capability of GCNs. Motivated by these findings, we propose a\ndecoupled structure for GCNs that detaches weight matrices from feature\npropagation to preserve the expressive power and ensure good generalization\nperformance. We conduct empirical evaluations on various synthetic and\nreal-world datasets to validate the correctness of our theory.",
    "descriptor": "",
    "authors": [
      "Weilin Cong",
      "Morteza Ramezani",
      "Mehrdad Mahdavi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15174"
  },
  {
    "id": "arXiv:2110.15178",
    "title": "Consensus-Based Decentralized Energy Trading for Distributed Energy  Resources",
    "abstract": "In smart grids, distributed energy resources (DERs) have penetrated\nresidential zones to provide a new form of electricity supply, mainly from\nrenewable energy. Residential households and commercial buildings with DERs\nhave become prosumers in the local grids, since they can sell surplus power to\nothers. Researches have been initiated to integrate and utilize DERs through\nbetter control and communication strategies. With the advances in the Internet\nof Things (IoT) technology, unprecedented coordination among DERs can be\nachieved to facilitate energy trading and transactive energy management.\nHowever, preventing leakage of users' information during the optimization\nprocess keeps challenging researchers, which drives them to develop\nprivacy-preserving energy management systems. In this paper, we develop a fully\ndecentralized transactive energy management using the consensus-based\nalgorithm. To be specific, we design a virtual pool for prosumers to trade\nenergy and exchange information with IoT technologies' support. The\nconsensus-based algorithm enables prosumers to obtain the optimal energy\nschedule independently in a coordinated manner without revealing any personal\ndata. We use real-world data to perform simulations and validate our developed\nalgorithm. The results show that our consensus-based decentralized transactive\nenergy management strategy is feasible and can significantly reduce the overall\nsystem cost.",
    "descriptor": "",
    "authors": [
      "Zhenyu Wang",
      "Xiaoyu Zhang",
      "Hao Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.15178"
  },
  {
    "id": "arXiv:2110.15179",
    "title": "A Comparative Study of Coarse to Dense 3D Indoor Scene Registration  Algorithms",
    "abstract": "3D alignment has become a very important part of 3D scanning technology. For\ninstance, we can divide the alignment process into four steps: key point\ndetection, key point description, initial pose estimation, and alignment\nrefinement. Researchers have contributed several approaches to the literature\nfor each step, which suggests a natural need for a comparative study for an\neducated more appropriate choice. In this work, we propose a description and an\nevaluation of the different methods used for 3D registration with special focus\non RGB-D data to find the best combinations that permit a complete and more\naccurate 3D reconstruction of indoor scenes with cheap depth cameras.",
    "descriptor": "\nComments: Accepted in International Conference on Advanced Electrical Engineering (ICAEE)\n",
    "authors": [
      "Abdenour Amamra",
      "Khalid Boumaza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.15179"
  },
  {
    "id": "arXiv:2110.15181",
    "title": "BERTian Poetics: Constrained Composition with Masked LMs",
    "abstract": "Masked language models have recently been interpreted as energy-based\nsequence models that can be generated from using a Metropolis--Hastings\nsampler. This short paper demonstrates how this can be instrumentalized for\nconstrained composition and explores the poetics implied by such a usage. Our\nfocus on constraints makes it especially apt to understand the generated text\nthrough the poetics of the OuLiPo movement.",
    "descriptor": "\nComments: Accepted as a poster at the 2021 NeurIPS Workshop on Machine Learning for Creativity and Design\n",
    "authors": [
      "Christopher Akiki",
      "Martin Potthast"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.15181"
  },
  {
    "id": "arXiv:2110.15182",
    "title": "Dist2Cycle: A Simplicial Neural Network for Homology Localization",
    "abstract": "Simplicial complexes can be viewed as high dimensional generalizations of\ngraphs that explicitly encode multi-way ordered relations between vertices at\ndifferent resolutions, all at once. This concept is central towards detection\nof higher dimensional topological features of data, features to which graphs,\nencoding only pairwise relationships, remain oblivious. While attempts have\nbeen made to extend Graph Neural Networks (GNNs) to a simplicial complex\nsetting, the methods do not inherently exploit, or reason about, the underlying\ntopological structure of the network. We propose a graph convolutional model\nfor learning functions parametrized by the $k$-homological features of\nsimplicial complexes. By spectrally manipulating their combinatorial\n$k$-dimensional Hodge Laplacians, the proposed model enables learning\ntopological features of the underlying simplicial complexes, specifically, the\ndistance of each $k$-simplex from the nearest \"optimal\" $k$-th homology\ngenerator, effectively providing an alternative to homology localization.",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Alexandros Dimitrios Keros",
      "Vidit Nanda",
      "Kartic Subr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2110.15182"
  },
  {
    "id": "arXiv:2110.15183",
    "title": "A Theory of RPC Calculi for Client-Server Model",
    "abstract": "With multi-tier programming languages, programmers can specify the locations\nof code to run in order to reduce development efforts for the web-based\nclient-server model where programmers write client and server programs\nseparately and test the multiple programs together. The RPC calculus, one of\nthe foundations of those languages by Cooper and Wadler, has the feature of\nsymmetric communication in programmer's writing arbitrarily deep nested\nclient-server interactions. However, the existing research only considers\ndynamically typed locations. We propose a typed RPC calculus where locations\nare tracked in type-level. A new located type system paves the way for a theory\nof RPC calculi for the client-server model.\n(In the following papers published in SCP2020 and PPDP2021, the typed RPC\ncalculus will be enhanced with polymorphic locations and a type-based slicing\ncompilation.)",
    "descriptor": "\nComments: ArXiv version of the JFP2019 published paper\n",
    "authors": [
      "Kwanghoon Choi",
      "Byeong-Mo Chang"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2110.15183"
  },
  {
    "id": "arXiv:2110.15187",
    "title": "Coexistence and Spectrum Sharing Above 100 GHz",
    "abstract": "[...] This paper explores how spectrum policy and spectrum technologies can\nevolve to enable sharing among different stakeholders in the above 100 GHz\nspectrum, without introducing harmful interference or disrupting either\nsecurity applications or fundamental science exploration. This portion of the\nspectrum presents new opportunities to design spectrum sharing schemes, based\non novel antenna designs, directional ultra-high-rate communications, and\nactive/passive user coordination. The paper provides a tutorial on current\nregulations above 100 GHz, and highlights how sharing is central to allowing\neach stakeholder to make the most out of this spectrum. It then defines -\nthrough detailed simulations based on standard International Telecommunications\nUnion (ITU) channel and antenna models - scenarios in which active users may\nintroduce harmful interference to passive sensing. Based on this evaluation, it\nreviews a number of promising techniques that can enable active/passive sharing\nabove 100 GHz. The critical review and tutorial on policy and technologies of\nthis paper have the potential to kickstart future research and regulations that\npromote safe coexistence between active and passive users above 100 GHz,\nfurther benefiting the development of digital technologies and scientific\nexploration.",
    "descriptor": "\nComments: This paper has been submitted to IEEE for publication. Copyright may change without notice. 21 pages, 15 figures, 5 tables\n",
    "authors": [
      "Michele Polese",
      "Xavier Cantos-Roman",
      "Arjun Singh",
      "Michael J. Marcus",
      "Thomas J. Maccarone",
      "Tommaso Melodia",
      "Josep M. Jornet"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.15187"
  },
  {
    "id": "arXiv:2110.15188",
    "title": "The magnitude vector of images",
    "abstract": "The magnitude of a finite metric space is a recently-introduced invariant\nquantity. Despite beneficial theoretical and practical properties, such as a\ngeneral utility for outlier detection, and a close connection to Laplace radial\nbasis kernels, magnitude has received little attention by the machine learning\ncommunity so far. In this work, we investigate the properties of magnitude on\nindividual images, with each image forming its own metric space. We show that\nthe known properties of outlier detection translate to edge detection in images\nand we give supporting theoretical justifications. In addition, we provide a\nproof of concept of its utility by using a novel magnitude layer to defend\nagainst adversarial attacks. Since naive magnitude calculations may be\ncomputationally prohibitive, we introduce an algorithm that leverages the\nregular structure of images to dramatically reduce the computational cost.",
    "descriptor": "\nComments: 15 pages, 8 figures\n",
    "authors": [
      "Michael F. Adamer",
      "Leslie O'Bray",
      "Edward De Brouwer",
      "Bastian Rieck",
      "Karsten Borgwardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2110.15188"
  },
  {
    "id": "arXiv:2110.15191",
    "title": "URLB: Unsupervised Reinforcement Learning Benchmark",
    "abstract": "Deep Reinforcement Learning (RL) has emerged as a powerful paradigm to solve\na range of complex yet specific control tasks. Yet training generalist agents\nthat can quickly adapt to new tasks remains an outstanding challenge. Recent\nadvances in unsupervised RL have shown that pre-training RL agents with\nself-supervised intrinsic rewards can result in efficient adaptation. However,\nthese algorithms have been hard to compare and develop due to the lack of a\nunified benchmark. To this end, we introduce the Unsupervised Reinforcement\nLearning Benchmark (URLB). URLB consists of two phases: reward-free\npre-training and downstream task adaptation with extrinsic rewards. Building on\nthe DeepMind Control Suite, we provide twelve continuous control tasks from\nthree domains for evaluation and open-source code for eight leading\nunsupervised RL methods. We find that the implemented baselines make progress\nbut are not able to solve URLB and propose directions for future research.",
    "descriptor": "\nComments: Code for the Unsupervised Reinforcement Learning Benchmark is available at this https URL\n",
    "authors": [
      "Michael Laskin",
      "Denis Yarats",
      "Hao Liu",
      "Kimin Lee",
      "Albert Zhan",
      "Kevin Lu",
      "Catherine Cang",
      "Lerrel Pinto",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.15191"
  },
  {
    "id": "arXiv:2110.15192",
    "title": "RGP: Neural Network Pruning through Its Regular Graph Structure",
    "abstract": "Lightweight model design has become an important direction in the application\nof deep learning technology, pruning is an effective mean to achieve a large\nreduction in model parameters and FLOPs. The existing neural network pruning\nmethods mostly start from the importance of parameters, and design parameter\nevaluation metrics to perform parameter pruning iteratively. These methods are\nnot studied from the perspective of model topology, may be effective but not\nefficient, and requires completely different pruning for different datasets. In\nthis paper, we study the graph structure of the neural network, and propose\nregular graph based pruning (RGP) to perform a one-shot neural network pruning.\nWe generate a regular graph, set the node degree value of the graph to meet the\npruning ratio, and reduce the average shortest path length of the graph by\nswapping the edges to obtain the optimal edge distribution. Finally, the\nobtained graph is mapped into a neural network structure to realize pruning.\nExperiments show that the average shortest path length of the graph is\nnegatively correlated with the classification accuracy of the corresponding\nneural network, and the proposed RGP shows a strong precision retention\ncapability with extremely high parameter reduction (more than 90%) and FLOPs\nreduction (more than 90%).",
    "descriptor": "\nComments: 13 pages, 9 figures, 3 tables\n",
    "authors": [
      "Zhuangzhi Chen",
      "Jingyang Xiang",
      "Yao Lu",
      "Qi Xuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15192"
  },
  {
    "id": "arXiv:2110.15196",
    "title": "Four-dimensional hybrid chaos system and its application in creating a  secure image transfer environment by cellular automata",
    "abstract": "One of the most important and practical researches which has been considered\nby researchers is creating secure environments for information exchanges. Due\nto their structures, chaos systems are efficient tools in the are of data\ntransferring. In this research, using a mathematical structure such as\ncomposing and transferring, we improve classical chaotic systems by creating a\nfour-dimensional system. Then we introduce a new encryption algorithm based on\nthe chaos and cellular automata. The security of the proposed environment which\nis evaluated using different types of security tests shows the efficiency of\nthe proposed algorithm.",
    "descriptor": "",
    "authors": [
      "R. Parvaz",
      "Y. Khedmati",
      "Y. Behroo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.15196"
  },
  {
    "id": "arXiv:2110.15204",
    "title": "Energy Efficient Resource Allocation in Federated Fog Computing Networks",
    "abstract": "There is a continuous growth in demand for time sensitive applications which\nhas shifted the cloud paradigm from a centralized computing architecture\ntowards distributed heterogeneous computing platforms where resources located\nat the edge of the network are used to provide cloud-like services. This\nparadigm is widely known as fog computing. Virtual machines (VMs) have been\nwidely utilized in both paradigms to enhance the network scalability, improve\nresource utilization, and energy efficiency. Moreover, Passive Optical Networks\n(PONs) are a technology suited to handling the enormous volumes of data\ngenerated in the access network due to their energy efficiency and large\nbandwidth. In this paper, we utilize a PON to provide the connectivity between\nmultiple distributed fog units to achieve federated (i.e. cooperative)\ncomputing units in the access network to serve intensive demands. We propose a\nmixed integer linear program (MILP) to optimize the VM placement in the\nfederated fog computing units with the objective of minimizing the total power\nconsumption while considering inter-VM traffic. The results show a significant\npower saving as a result of the proposed optimization model by up to 52%, in\nthe VM-allocation compared to a baseline approach that allocates the VM\nrequests while neglecting the power consumption and inter-VMs traffic in the\noptimization framework.",
    "descriptor": "",
    "authors": [
      "Abdullah M. Alqahtani",
      "Barzan Yosuf",
      "Sanaa H. Mohamed",
      "Taisir E.H. El-Gorashi",
      "Jaafar M.H. Elmirghani"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.15204"
  },
  {
    "id": "arXiv:2110.15206",
    "title": "An Efficient Multi-Link Channel Model for LiFi",
    "abstract": "In this paper, we report for the first time on a new channel modelling\ntechnique for multi-link LiFi scenarios. By considering simplified numerical\ncalculation, it models the links between multiple optical frontends and\nmultiple mobile devices much faster than previous approaches. For the first two\ndiffuse reflections, we replace ray-tracing method by frequency domain channel\nmodelling technique. For the other higher order diffuse reflections, we use a\nwell-established model based on the integrating sphere. For validation of our\nnew approach, we performed distributed 4x2 MIMO channel measurements.\nComparison of simulation and measurement yields a relative mean square error\nbelow 5 percent for the signals with a free line-of-sight. Our new technique\nenables efficient modeling of mobile scenarios and analyzing statistical\nproperties of the LiFi channels.",
    "descriptor": "",
    "authors": [
      "Sreelal Maravanchery Mana",
      "Kerolos Gabra Kamel Gabra",
      "Sepideh Mohammadi Kouhini",
      "Peter Hellwig",
      "Jonas Hilt",
      "Volker Jungnickel"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.15206"
  },
  {
    "id": "arXiv:2110.15207",
    "title": "Black-Box Assessment of Optical Spectrum Services",
    "abstract": "A spectral sweep process is introduced to discover performance issues in\noptical spectrum services. We detect filtering penalty, spectral ripple/tilt\nand channel crosstalk in field measurements, potentially leading to increased\nservice robustness in low-margin networks.",
    "descriptor": "\nComments: Presented at 2021 Optical Fiber Communications Conference and Exhibition (OFC), San Francisco, CA, USA. arXiv admin note: text overlap with arXiv:2108.07322\n",
    "authors": [
      "Kaida Kaeval",
      "J\u00f6rg-Peter Elbers",
      "Klaus Grobe",
      "Marko Tikas",
      "Tobias Fehenberger",
      "Helmut Griesser",
      "Gert Jervan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.15207"
  },
  {
    "id": "arXiv:2110.15208",
    "title": "A New Remote Monitor and Control System Based on Sigfox IoT Network",
    "abstract": "We describe a new, low-cost system designed to provide multi-sensor remote\ncondition monitoring of modern scientific laboratories, as well as to allow\nusers to perform actions from remote locations in case of detection of\nspecified events. The system is battery operated and does not require the\npresence of a Local Area Network (LAN) or WiFi (which are typically not\navailable in case of, e.g. power losses), as it exploits the growing\ninfrastructure of Internet of Things (IoT) Low Power Wide Area Networks\n(LPWAN). In particular our system exploits the new SigFox\nultra-narrow-bandwidth (UNB) infrastructure, and provides for a bidirectional\nlink between the instrumentation and the remote user even in case of power line\noutages, which are among the most critical situations that a scientific\nlaboratory can withstand. The system can detect the occurrence of predefined\nevents in very short times, and either autonomously react with a series of\npredefined actions, also allowing a remote user to timely perform additional\nactions on the system through an user-friendly smartphone application or via a\nbrowser interface. The system also embeds a novel power-loss detection\narchitecture, which detects power line failures in less than 2 ms. We provide a\nfull characterization of the prototype, including reaction times, connection\nlatencies, sensors sensitivity, and power consumption.",
    "descriptor": "\nComments: Accepted for publication on Review of Scientific Instruments; 8 pages, 5 figures\n",
    "authors": [
      "Lorenzo Francesco Livi",
      "Jacopo Catani"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Quantum Gases (cond-mat.quant-gas)"
    ],
    "url": "https://arxiv.org/abs/2110.15208"
  },
  {
    "id": "arXiv:2110.15210",
    "title": "Towards Model Agnostic Federated Learning Using Knowledge Distillation",
    "abstract": "An often unquestioned assumption underlying most current federated learning\nalgorithms is that all the participants use identical model architectures. In\nthis work, we initiate a theoretical study of model agnostic communication\nprotocols which would allow data holders (agents) using different models to\ncollaborate with each other and perform federated learning. We focus on the\nsetting where the two agents are attempting to perform kernel regression using\ndifferent kernels (and hence have different models). Our study yields a\nsurprising result -- the most natural algorithm of using alternating knowledge\ndistillation (AKD) imposes overly strong regularization and may lead to severe\nunder-fitting. Our theory also shows an interesting connection between AKD and\nthe alternating projection algorithm for finding intersection of sets.\nLeveraging this connection, we propose a new algorithms which improve upon AKD.\nOur theoretical predictions also closely match real world experiments using\nneural networks. Thus, our work proposes a rich yet tractable framework for\nanalyzing and developing new practical model agnostic federated learning\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Andrei Afonin",
      "Sai Praneeth Karimireddy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.15210"
  },
  {
    "id": "arXiv:2110.15214",
    "title": "Conditional Inference and Activation of Knowledge Entities in ACT-R",
    "abstract": "Activation-based conditional inference applies conditional reasoning to\nACT-R, a cognitive architecture developed to formalize human reasoning. The\nidea of activation-based conditional inference is to determine a reasonable\nsubset of a conditional belief base in order to draw inductive inferences in\ntime. Central to activation-based conditional inference is the activation\nfunction which assigns to the conditionals in the belief base a degree of\nactivation mainly based on the conditional's relevance for the current query\nand its usage history. Therewith, our approach integrates several aspects of\nhuman reasoning into expert systems such as focusing, forgetting, and\nremembering.",
    "descriptor": "",
    "authors": [
      "Marco Wilhelm",
      "Diana Howey",
      "Gabriele Kern-Isberner",
      "Kai Sauerwald",
      "Christoph Beierle"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15214"
  },
  {
    "id": "arXiv:2110.15220",
    "title": "An Add-On for Empowering Google Forms to be an Automatic Question  Generator in Online Assessments",
    "abstract": "This research suggests an add-on to empower Google Forms to be an automatic\nmachine for generating multiple-choice questions (MCQs) used in online\nassessments. In this paper, we elaborate an add-on design mainly comprising\nquestion-formulating software and data storage. The algorithm as an\nintellectual mechanism of this software can produce MCQs at an analytical\nlevel. In an experiment, we found the MCQs could assess levels of students'\nknowledge comparably with those generated by human experts. This add-on can be\napplied generally to formulate MCQs for any rational concepts. With no effort\nfrom an instructor at runtime, the add-on can transform a few data instances\ndescribing rational concepts to be variety sets of MCQs.",
    "descriptor": "",
    "authors": [
      "Pornpat Sirithumgul",
      "Pimpaka Prasertsilp",
      "Lorne Olfman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.15220"
  },
  {
    "id": "arXiv:2110.15221",
    "title": "retworkx: A High-Performance Graph Library for Python",
    "abstract": "Network and graph analysis is a widely applicable field of research, and\nPython is a popular programming language. In retworkx, we provide a\nhigh-performance, flexible graph and network analysis library for Python.\nretworkx is inspired by NetworkX (Hagberg et al., 2008) but addresses many\nperformance concerns of the latter. retworkx is particularly suited for\nperformance-sensitive applications that use graph representations.",
    "descriptor": "\nComments: Submitted to the Journal of Open Source Software\n",
    "authors": [
      "Matthew Treinish",
      "Ivan Carvalho",
      "Georgios Tsilimigkounakis",
      "Nahum S\u00e1"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.15221"
  },
  {
    "id": "arXiv:2110.15222",
    "title": "Word-level confidence estimation for RNN transducers",
    "abstract": "Confidence estimate is an often requested feature in applications such as\nmedical transcription where errors can impact patient care and the confidence\nestimate could be used to alert medical professionals to verify potential\nerrors in recognition.\nIn this paper, we present a lightweight neural confidence model tailored for\nAutomatic Speech Recognition (ASR) system with Recurrent Neural Network\nTransducers (RNN-T). Compared to other existing approaches, our model utilizes:\n(a) the time information associated with recognized words, which reduces the\ncomputational complexity, and (b) a simple and elegant trick for mapping\nbetween sub-word and word sequences. The mapping addresses the non-unique\ntokenization and token deletion problems while amplifying differences between\nconfusable words. Through extensive empirical evaluations on two different\nlong-form test sets, we demonstrate that the model achieves a performance of\n0.4 Normalized Cross Entropy (NCE) and 0.05 Expected Calibration Error (ECE).\nIt is robust across different ASR configurations, including target types\n(graphemes vs. morphemes), traffic conditions (streaming vs. non-streaming),\nand encoder types. We further discuss the importance of evaluation metrics to\nreflect practical applications and highlight the need for further work in\nimproving Area Under the Curve (AUC) for Negative Precision Rate (NPV) and True\nNegative Rate (TNR).",
    "descriptor": "",
    "authors": [
      "Mingqiu Wang",
      "Hagen Soltau",
      "Laurent El Shafey",
      "Izhak Shafran"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.15222"
  },
  {
    "id": "arXiv:2110.15225",
    "title": "Pruning Attention Heads of Transformer Models Using A* Search: A Novel  Approach to Compress Big NLP Architectures",
    "abstract": "Recent years have seen a growing adoption of Transformer models such as BERT\nin Natural Language Processing and even in Computer Vision. However, due to the\nsize, there has been limited adoption of such models within\nresource-constrained computing environments This paper proposes novel pruning\nalgorithms to compress transformer models by eliminating redundant Attention\nHeads. We apply the A* search algorithm to obtain a pruned model with minimal\naccuracy guarantees. Our results indicate that the method could eliminate as\nmuch as 40% of the attention heads in the BERT transformer model with almost no\nloss in accuracy.",
    "descriptor": "\nComments: 23 Pages, 18 figures, 3 tables\n",
    "authors": [
      "Archit Parnami",
      "Rahul Singh",
      "Tarun Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15225"
  },
  {
    "id": "arXiv:2110.15231",
    "title": "Exploring Covariate and Concept Shift for Detection and Calibration of  Out-of-Distribution Data",
    "abstract": "Moving beyond testing on in-distribution data works on Out-of-Distribution\n(OOD) detection have recently increased in popularity. A recent attempt to\ncategorize OOD data introduces the concept of near and far OOD detection.\nSpecifically, prior works define characteristics of OOD data in terms of\ndetection difficulty. We propose to characterize the spectrum of OOD data using\ntwo types of distribution shifts: covariate shift and concept shift, where\ncovariate shift corresponds to change in style, e.g., noise, and concept shift\nindicates a change in semantics. This characterization reveals that sensitivity\nto each type of shift is important to the detection and confidence calibration\nof OOD data. Consequently, we investigate score functions that capture\nsensitivity to each type of dataset shift and methods that improve them. To\nthis end, we theoretically derive two score functions for OOD detection, the\ncovariate shift score and concept shift score, based on the decomposition of\nKL-divergence for both scores, and propose a geometrically-inspired method\n(Geometric ODIN) to improve OOD detection under both shifts with only\nin-distribution data. Additionally, the proposed method naturally leads to an\nexpressive post-hoc calibration function which yields state-of-the-art\ncalibration performance on both in-distribution and out-of-distribution data.\nWe are the first to propose a method that works well across both OOD detection\nand calibration and under different types of shifts. Specifically, we improve\nthe previous state-of-the-art OOD detection by relatively 7% AUROC on CIFAR100\nvs. SVHN and achieve the best calibration performance of 0.084 Expected\nCalibration Error on the corrupted CIFAR100C dataset. View project page at\nhttps://sites.google.com/view/geometric-decomposition.",
    "descriptor": "\nComments: A short version of the paper is accepted to NeurIPS DistShift Workshop 2021\n",
    "authors": [
      "Junjiao Tian",
      "Yen-Change Hsu",
      "Yilin Shen",
      "Hongxia Jin",
      "Zsolt Kira"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15231"
  },
  {
    "id": "arXiv:2110.15232",
    "title": "Guided Evolution for Neural Architecture Search",
    "abstract": "Neural Architecture Search (NAS) methods have been successfully applied to\nimage tasks with excellent results. However, NAS methods are often complex and\ntend to converge to local minima as soon as generated architectures seem to\nyield good results. In this paper, we propose G-EA, a novel approach for guided\nevolutionary NAS. The rationale behind G-EA, is to explore the search space by\ngenerating and evaluating several architectures in each generation at\ninitialization stage using a zero-proxy estimator, where only the\nhighest-scoring network is trained and kept for the next generation. This\nevaluation at initialization stage allows continuous extraction of knowledge\nfrom the search space without increasing computation, thus allowing the search\nto be efficiently guided. Moreover, G-EA forces exploitation of the most\nperformant networks by descendant generation while at the same time forcing\nexploration by parent mutation and by favouring younger architectures to the\ndetriment of older ones. Experimental results demonstrate the effectiveness of\nthe proposed method, showing that G-EA achieves state-of-the-art results in\nNAS-Bench-201 search space in CIFAR-10, CIFAR-100 and ImageNet16-120, with mean\naccuracies of 93.98%, 72.12% and 45.94% respectively.",
    "descriptor": "\nComments: Paper accepted at 35th Conference on Neural Information Processing Systems (NeurIPS) - New In ML. 9 pages, 2 figures, 1 table\n",
    "authors": [
      "Vasco Lopes",
      "Miguel Santos",
      "Bruno Degardin",
      "Lu\u00eds A. Alexandre"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.15232"
  },
  {
    "id": "arXiv:2110.15233",
    "title": "Subpixel object segmentation using wavelets and multi resolution  analysis",
    "abstract": "We propose a novel deep learning framework for fast prediction of boundaries\nof two-dimensional simply connected domains using wavelets and Multi Resolution\nAnalysis (MRA). The boundaries are modelled as (piecewise) smooth closed curves\nusing wavelets and the so-called Pyramid Algorithm. Our network architecture is\na hybrid analog of the U-Net, where the down-sampling path is a two-dimensional\nencoder with learnable filters, and the upsampling path is a one-dimensional\ndecoder, which builds curves up from low to high resolution levels. Any wavelet\nbasis induced by a MRA can be used. This flexibility allows for incorporation\nof priors on the smoothness of curves. The effectiveness of the proposed method\nis demonstrated by delineating boundaries of simply connected domains (organs)\nin medical images using Debauches wavelets and comparing performance with a\nU-Net baseline. Our model demonstrates up to 5x faster inference speed compared\nto the U-Net, while maintaining similar performance in terms of Dice score and\nHausdorff distance.",
    "descriptor": "\nComments: 19 pages, 10 figures, 1 table\n",
    "authors": [
      "Ray Sheombarsing",
      "Nikita Moriakov",
      "Jan-Jakob Sonke",
      "Jonas Teuwen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.15233"
  },
  {
    "id": "arXiv:2110.15235",
    "title": "Multi-stage Clarification in Conversational AI: The case of  Question-Answering Dialogue Systems",
    "abstract": "Clarification resolution plays an important role in various information\nretrieval tasks such as interactive question answering and conversational\nsearch. In such context, the user often formulates their information needs as\nshort and ambiguous queries, some popular search interfaces then prompt the\nuser to confirm her intent (e.g. \"Did you mean ... ?\") or to rephrase if\nneeded. When it comes to dialogue systems, having fluid user-bot exchanges is\nkey to good user experience. In the absence of such clarification mechanism,\none of the following responses is given to the user: 1) A direct answer, which\ncan potentially be non-relevant if the intent was not clear, 2) a generic\nfallback message informing the user that the retrieval tool is incapable of\nhandling the query. Both scenarios might raise frustration and degrade the user\nexperience. To this end, we propose a multi-stage clarification mechanism for\nprompting clarification and query selection in the context of a question\nanswering dialogue system. We show that our proposed mechanism improves the\noverall user experience and outperforms competitive baselines with two\ndatasets, namely the public in-scope out-of-scope dataset and a commercial\ndataset based on real user logs.",
    "descriptor": "\nComments: 9 pages, 3 figures, 2 tables\n",
    "authors": [
      "Hadrien Lautraite",
      "Nada Naji",
      "Louis Marceau",
      "Marc Queudot",
      "Eric Charton"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.15235"
  },
  {
    "id": "arXiv:2110.15237",
    "title": "Incremental Adaptive Dynamic Programming for Approximate Optimal  Tracking Control: a Decoupled and Model-Free Approach",
    "abstract": "This paper proposes a new formulation for the optimal tracking control\nproblem (OTCP) of Euler-Lagrange systems. This formulation extends the\nincremental adaptive dynamic programming (IADP) technique, a reinforcement\nlearning based method for solving the robust optimal regulation control problem\n(RORCP), to learn the approximate solution to the OTCP. Departing from\navailable solutions to the OTCP, our developed tracking control scheme settles\nthe curse of complexity problem in value function approximation from a\ndecoupled way, circumvents the learning inefficiency regarding varying desired\ntrajectories by avoiding introducing a reference trajectory dynamics into the\nlearning process, and requires neither an accurate nor identified dynamics\nthrough the time delay estimation technique. Specifically, we first convert the\nintractable OTCP of a high-dimensional uncertain system into multiple\nmanageable sub-RORCPs of low-dimensional incremental error subsystems. Then,\nthe resulting sub-RORCPs are approximately solved by IADP implemented as a\nparallel critic learning structure. The proposed tracking control scheme is\ndeveloped with rigorous theoretical analysis of system stability and weight\nconvergence, and validated numerically on a 6-DoF quadrotor and experimentally\non a 3-DoF robot manipulator.",
    "descriptor": "",
    "authors": [
      "Cong Li",
      "Yongchao Wang",
      "Fangzhou Liu",
      "Martin Buss"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.15237"
  },
  {
    "id": "arXiv:2110.15238",
    "title": "Bolt: Bridging the Gap between Auto-tuners and Hardware-native  Performance",
    "abstract": "Today's auto-tuners (e.g., AutoTVM, Ansor) generate efficient tensor programs\nby navigating a large search space to identify effective implementations, but\nthey do so with opaque hardware details. Thus, their performance could fall\nbehind that of hardware-native libraries (e.g., cuBLAS, cuDNN), which are\nhand-optimized by device vendors to extract high performance. On the other\nhand, these vendor libraries have a fixed set of supported functions and lack\nthe customization and automation support afforded by auto-tuners. Bolt is based\non the recent trend that vendor libraries are increasingly modularized and\nreconfigurable via declarative control (e.g., CUTLASS). It enables a novel\napproach that bridges this gap and achieves the best of both worlds, via\nhardware-native templated search. Bolt provides new opportunities to rethink\nend-to-end tensor optimizations at the graph, operator, and model levels. Bolt\ndemonstrates this concept by prototyping on a popular auto-tuner in TVM and a\nclass of widely-used platforms (i.e., NVIDIA GPUs) -- both in large deployment\nin our production environment. Bolt improves the inference speed of common\nconvolutional neural networks by 2.5x on average over the state of the art, and\nit auto-tunes these models within 20 minutes.",
    "descriptor": "",
    "authors": [
      "Jiarong Xing",
      "Leyuan Wang",
      "Shang Zhang",
      "Jack Chen",
      "Ang Chen",
      "Yibo Zhu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15238"
  },
  {
    "id": "arXiv:2110.15242",
    "title": "Multi-Pair Two-Way Massive MIMO DF Relaying Over Rician Fading Channels  Under Imperfect CSI",
    "abstract": "We investigate a multi-pair two-way decode-andforward relaying aided massive\nmultiple-input multiple-output antenna system under Rician fading channels, in\nwhich multiple pairs of users exchange information through a relay station\nhaving multiple antennas. Imperfect channel state information is considered in\nthe context of maximum-ratio processing. Closedform expressions are derived for\napproximating the sum spectral efficiency (SE) of the system. Moreover, we\nobtain the powerscaling laws at the users and the relay station to satisfy a\ncertain SE requirement in three typical scenarios. Finally, simulations\nvalidate the accuracy of the derived results.",
    "descriptor": "\nComments: Accepted by IEEE Wireless Communications Letters\n",
    "authors": [
      "Zhangjie Peng",
      "Shuxian Wang",
      "Cunhua Pan",
      "Xianzhe Chen",
      "Julian Cheng",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.15242"
  },
  {
    "id": "arXiv:2110.15245",
    "title": "From Machine Learning to Robotics: Challenges and Opportunities for  Embodied Intelligence",
    "abstract": "Machine learning has long since become a keystone technology, accelerating\nscience and applications in a broad range of domains. Consequently, the notion\nof applying learning methods to a particular problem set has become an\nestablished and valuable modus operandi to advance a particular field. In this\narticle we argue that such an approach does not straightforwardly extended to\nrobotics -- or to embodied intelligence more generally: systems which engage in\na purposeful exchange of energy and information with a physical environment. In\nparticular, the purview of embodied intelligent agents extends significantly\nbeyond the typical considerations of main-stream machine learning approaches,\nwhich typically (i) do not consider operation under conditions significantly\ndifferent from those encountered during training; (ii) do not consider the\noften substantial, long-lasting and potentially safety-critical nature of\ninteractions during learning and deployment; (iii) do not require ready\nadaptation to novel tasks while at the same time (iv) effectively and\nefficiently curating and extending their models of the world through targeted\nand deliberate actions. In reality, therefore, these limitations result in\nlearning-based systems which suffer from many of the same operational\nshortcomings as more traditional, engineering-based approaches when deployed on\na robot outside a well defined, and often narrow operating envelope. Contrary\nto viewing embodied intelligence as another application domain for machine\nlearning, here we argue that it is in fact a key driver for the advancement of\nmachine learning technology. In this article our goal is to highlight\nchallenges and opportunities that are specific to embodied intelligence and to\npropose research directions which may significantly advance the\nstate-of-the-art in robot learning.",
    "descriptor": "",
    "authors": [
      "Nicholas Roy",
      "Ingmar Posner",
      "Tim Barfoot",
      "Philippe Beaudoin",
      "Yoshua Bengio",
      "Jeannette Bohg",
      "Oliver Brock",
      "Isabelle Depatie",
      "Dieter Fox",
      "Dan Koditschek",
      "Tomas Lozano-Perez",
      "Vikash Mansinghka",
      "Christopher Pal",
      "Blake Richards",
      "Dorsa Sadigh",
      "Stefan Schaal",
      "Gaurav Sukhatme",
      "Denis Therien",
      "Marc Toussaint",
      "Michiel Van de Panne"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15245"
  },
  {
    "id": "arXiv:2110.15246",
    "title": "On the Importance and Shortcomings of Code Readability Metrics: A Case  Study on Reactive Programming",
    "abstract": "Well structured and readable source code is a pre-requisite for maintainable\nsoftware and successful collaboration among developers. Static analysis enables\nthe automated extraction of code complexity and readability metrics which can\nbe leveraged to highlight potential improvements in code to both attain\nsoftware of high quality and reinforce good practices for developers as an\neducational tool. This assumes reliable readability metrics which are not\ntrivial to obtain since code readability is somewhat subjective. Recent\nresearch has resulted in increasingly sophisticated models for predicting\nreadability as perceived by humans primarily with a procedural and object\noriented focus, while functional and declarative languages and language\nextensions advance as they often are said to lead to more concise and readable\ncode. In this paper, we investigate whether the existing complexity and\nreadability metrics reflect that wisdom or whether the notion of readability\nand its constituents requires overhaul in the light of programming language\nchanges. We therefore compare traditional object oriented and reactive\nprogramming in terms of code complexity and readability in a case study.\nReactive programming is claimed to increase code quality but few studies have\nsubstantiated these claims empirically. We refactored an object oriented open\nsource project into a reactive candidate and compare readability with the\noriginal using cyclomatic complexity and two state-of-the-art readability\nmetrics. More elaborate investigations are required, but our findings suggest\nthat both cyclomatic complexity and readability decrease significantly at the\nsame time in the reactive candidate, which seems counter-intuitive. We\nexemplify and substantiate why readability metrics may require adjustment to\nbetter suit popular programming styles other than imperative and\nobject-oriented to better match human expectations.",
    "descriptor": "",
    "authors": [
      "Gustaf Holst",
      "Felix Dobslaw"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.15246"
  },
  {
    "id": "arXiv:2110.15248",
    "title": "\u00daFAL at MultiLexNorm 2021: Improving Multilingual Lexical  Normalization by Fine-tuning ByT5",
    "abstract": "We present the winning entry to the Multilingual Lexical Normalization\n(MultiLexNorm) shared task at W-NUT 2021 (van der Goot et al., 2021a), which\nevaluates lexical-normalization systems on 12 social media datasets in 11\nlanguages. We base our solution on a pre-trained byte-level language model,\nByT5 (Xue et al., 2021a), which we further pre-train on synthetic data and then\nfine-tune on authentic normalization data. Our system achieves the best\nperformance by a wide margin in intrinsic evaluation, and also the best\nperformance in extrinsic evaluation through dependency parsing. The source code\nis released at https://github.com/ufal/multilexnorm2021 and the fine-tuned\nmodels at https://huggingface.co/ufal.",
    "descriptor": "\nComments: Accepted to W-NUT 2021\n",
    "authors": [
      "David Samuel",
      "Milan Straka"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.15248"
  },
  {
    "id": "arXiv:2110.15250",
    "title": "End-to-end Learning the Partial Permutation Matrix for Robust 3D Point  Cloud Registration",
    "abstract": "Even though considerable progress has been made in deep learning-based 3D\npoint cloud processing, how to obtain accurate correspondences for robust\nregistration remains a major challenge because existing hard assignment methods\ncannot deal with outliers naturally. Alternatively, the soft matching-based\nmethods have been proposed to learn the matching probability rather than hard\nassignment. However, in this paper, we prove that these methods have an\ninherent ambiguity causing many deceptive correspondences. To address the above\nchallenges, we propose to learn a partial permutation matching matrix, which\ndoes not assign corresponding points to outliers, and implements hard\nassignment to prevent ambiguity. However, this proposal poses two new problems,\ni.e., existing hard assignment algorithms can only solve a full rank\npermutation matrix rather than a partial permutation matrix, and this desired\nmatrix is defined in the discrete space, which is non-differentiable. In\nresponse, we design a dedicated soft-to-hard (S2H) matching procedure within\nthe registration pipeline consisting of two steps: solving the soft matching\nmatrix (S-step) and projecting this soft matrix to the partial permutation\nmatrix (H-step). Specifically, we augment the profit matrix before the hard\nassignment to solve an augmented permutation matrix, which is cropped to\nachieve the final partial permutation matrix. Moreover, to guarantee end-to-end\nlearning, we supervise the learned partial permutation matrix but propagate the\ngradient to the soft matrix instead. Our S2H matching procedure can be easily\nintegrated with existing registration frameworks, which has been verified in\nrepresentative frameworks including DCP, RPMNet, and DGR. Extensive experiments\nhave validated our method, which creates a new state-of-the-art performance for\nrobust 3D point cloud registration. The code will be made public.",
    "descriptor": "",
    "authors": [
      "Zhiyuan Zhang",
      "Jiadai Sun",
      "Yuchao Dai",
      "Dingfu Zhou",
      "Xibin Song",
      "Mingyi He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15250"
  },
  {
    "id": "arXiv:2110.15252",
    "title": "FeO2: Federated Learning with Opt-Out Differential Privacy",
    "abstract": "Federated learning (FL) is an emerging privacy-preserving paradigm, where a\nglobal model is trained at a central server while keeping client data local.\nHowever, FL can still indirectly leak private client information through model\nupdates during training. Differential privacy (DP) can be employed to provide\nprivacy guarantees within FL, typically at the cost of degraded final trained\nmodel. In this work, we consider a heterogeneous DP setup where clients are\nconsidered private by default, but some might choose to opt out of DP. We\npropose a new algorithm for federated learning with opt-out DP, referred to as\n\\emph{FeO2}, along with a discussion on its advantages compared to the\nbaselines of private and personalized FL algorithms. We prove that the\nserver-side and client-side procedures in \\emph{FeO2} are optimal for a\nsimplified linear problem. We also analyze the incentive for opting out of DP\nin terms of performance gain. Through numerical experiments, we show that\n\\emph{FeO2} provides up to $9.27\\%$ performance gain in the global model\ncompared to the baseline DP FL for the considered datasets. Additionally, we\nshow a gap in the average performance of personalized models between\nnon-private and private clients of up to $3.49\\%$, empirically illustrating an\nincentive for clients to opt out.",
    "descriptor": "",
    "authors": [
      "Nasser Aldaghri",
      "Hessam Mahdavifar",
      "Ahmad Beirami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.15252"
  },
  {
    "id": "arXiv:2110.15253",
    "title": "Understanding How Encoder-Decoder Architectures Attend",
    "abstract": "Encoder-decoder networks with attention have proven to be a powerful way to\nsolve many sequence-to-sequence tasks. In these networks, attention aligns\nencoder and decoder states and is often used for visualizing network behavior.\nHowever, the mechanisms used by networks to generate appropriate attention\nmatrices are still mysterious. Moreover, how these mechanisms vary depending on\nthe particular architecture used for the encoder and decoder (recurrent,\nfeed-forward, etc.) are also not well understood. In this work, we investigate\nhow encoder-decoder networks solve different sequence-to-sequence tasks. We\nintroduce a way of decomposing hidden states over a sequence into temporal\n(independent of input) and input-driven (independent of sequence position)\ncomponents. This reveals how attention matrices are formed: depending on the\ntask requirements, networks rely more heavily on either the temporal or\ninput-driven components. These findings hold across both recurrent and\nfeed-forward architectures despite their differences in forming the temporal\ncomponents. Overall, our results provide new insight into the inner workings of\nattention-based encoder-decoder networks.",
    "descriptor": "\nComments: 10+14 pages, 16 figures. NeurIPS 2021\n",
    "authors": [
      "Kyle Aitken",
      "Vinay V Ramasesh",
      "Yuan Cao",
      "Niru Maheswaranathan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.15253"
  },
  {
    "id": "arXiv:2110.15255",
    "title": "Self-Supervised Learning Disentangled Group Representation as Feature",
    "abstract": "A good visual representation is an inference map from observations (images)\nto features (vectors) that faithfully reflects the hidden modularized\ngenerative factors (semantics). In this paper, we formulate the notion of\n\"good\" representation from a group-theoretic view using Higgins' definition of\ndisentangled representation, and show that existing Self-Supervised Learning\n(SSL) only disentangles simple augmentation features such as rotation and\ncolorization, thus unable to modularize the remaining semantics. To break the\nlimitation, we propose an iterative SSL algorithm: Iterative Partition-based\nInvariant Risk Minimization (IP-IRM), which successfully grounds the abstract\nsemantics and the group acting on them into concrete contrastive learning. At\neach iteration, IP-IRM first partitions the training samples into two subsets\nthat correspond to an entangled group element. Then, it minimizes a\nsubset-invariant contrastive loss, where the invariance guarantees to\ndisentangle the group element. We prove that IP-IRM converges to a fully\ndisentangled representation and show its effectiveness on various benchmarks.\nCodes are available at https://github.com/Wangt-CN/IP-IRM.",
    "descriptor": "\nComments: Accepted by NeurIPS 2021 (Spotlight). arXiv admin note: text overlap with arXiv:2012.09276 by other authors\n",
    "authors": [
      "Tan Wang",
      "Zhongqi Yue",
      "Jianqiang Huang",
      "Qianru Sun",
      "Hanwang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15255"
  },
  {
    "id": "arXiv:2110.15260",
    "title": "Approximating the Arboricity in Sublinear Time",
    "abstract": "We consider the problem of approximating the arboricity of a graph $G=\n(V,E)$, which we denote by $\\mathsf{arb}(G)$, in sublinear time, where the\narboricity of a graph is the minimal number of forests required to cover its\nedges. An algorithm for this problem may perform degree and neighbor queries,\nand is allowed a small error probability. We design an algorithm that outputs\nan estimate $\\hat{\\alpha}$, such that with probability $1-1/\\textrm{poly}(n)$,\n$\\mathsf{arb}(G)/c\\log^2 n \\leq \\hat{\\alpha} \\leq \\mathsf{arb}(G)$, where\n$n=|V|$ and $c$ is a constant. The expected query complexity and running time\nof the algorithm are\n$O(n/\\mathsf{arb}(G))\\cdot \\textrm{poly}(\\log n)$, and this upper bound also\nholds with high probability. %($\\widetilde{O}(\\cdot)$ is used to suppress\n$\\textrm{poly}(\\log n)$ dependencies).\nThis bound is optimal for such an approximation up to a $\\textrm{poly}(\\log\nn)$ factor.",
    "descriptor": "",
    "authors": [
      "Talya Eden",
      "Saleet Mossel",
      "Dana Ron"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.15260"
  },
  {
    "id": "arXiv:2110.15263",
    "title": "Coresets for Time Series Clustering",
    "abstract": "We study the problem of constructing coresets for clustering problems with\ntime series data. This problem has gained importance across many fields\nincluding biology, medicine, and economics due to the proliferation of sensors\nfacilitating real-time measurement and rapid drop in storage costs. In\nparticular, we consider the setting where the time series data on $N$ entities\nis generated from a Gaussian mixture model with autocorrelations over $k$\nclusters in $\\mathbb{R}^d$. Our main contribution is an algorithm to construct\ncoresets for the maximum likelihood objective for this mixture model. Our\nalgorithm is efficient, and under a mild boundedness assumption on the\ncovariance matrices of the underlying Gaussians, the size of the coreset is\nindependent of the number of entities $N$ and the number of observations for\neach entity, and depends only polynomially on $k$, $d$ and $1/\\varepsilon$,\nwhere $\\varepsilon$ is the error parameter. We empirically assess the\nperformance of our coreset with synthetic data.",
    "descriptor": "\nComments: Full version of a paper appearing in NeurIPS 2021\n",
    "authors": [
      "Lingxiao Huang",
      "K. Sudhir",
      "Nisheeth K. Vishnoi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)",
      "Econometrics (econ.EM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.15263"
  },
  {
    "id": "arXiv:2110.15264",
    "title": "CIIA:A New Algorithm for Community Detection",
    "abstract": "In this paper, through thinking on the modularity function that measures the\nstandard of community division, a new algorithm for dividing communities is\nproposed, called the Connect Intensity Iteration algorithm, or CIIA for short.\nIn this algorithm, a new indicator is proposed.This indicator is the difference\nbetween the actual number of edges between two nodes and the number of edges\nwhen the edges are randomly placed. It can reflect more information between the\nnodes. The larger the value of this index, the greater the possibility that the\ntwo nodes are divided into the same community, and vice versa. This paper also\nverifies the algorithm through numerical simulations and real cases, and the\nresults show the feasibility of the algorithm.",
    "descriptor": "\nComments: 10 pages,8 figures\n",
    "authors": [
      "Zhang Renquan",
      "Wang Yu",
      "Wang Xiaolin",
      "Sun Yuze",
      "Tai Jilei"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.15264"
  },
  {
    "id": "arXiv:2110.15265",
    "title": "Geometric two-scale integrators for highly oscillatory system: uniform  accuracy and near conservations",
    "abstract": "In this paper, we consider a class of highly oscillatory Hamiltonian systems\nwhich involve a scaling parameter $\\varepsilon\\in(0,1]$. The problem arises\nfrom many physical models in some limit parameter regime or from some\ntime-compressed perturbation problems. The solution of the model exhibits rapid\ntemporal oscillations with $\\mathcal{O}(1)$-amplitude and\n$\\mathcal{O}(1/\\varepsilon)$-frequency, which makes classical numerical methods\ninefficient. We apply the two-scale formulation approach to the problem and\npropose two new time-symmetric numerical integrators. The methods are proved to\nhave the uniform second order accuracy for all $\\varepsilon$ at finite times\nand some near-conservation laws in long times. Numerical experiments on a\nH\\'{e}non-Heiles model, a nonlinear Schr\\\"{o}dinger equation and a\ncharged-particle system illustrate the performance of the proposed methods over\nthe existing ones.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Bin Wang",
      "Xiaofei Zhao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.15265"
  },
  {
    "id": "arXiv:2110.15267",
    "title": "UltraPose: Synthesizing Dense Pose with 1 Billion Points by Human-body  Decoupling 3D Model",
    "abstract": "Recovering dense human poses from images plays a critical role in\nestablishing an image-to-surface correspondence between RGB images and the 3D\nsurface of the human body, serving the foundation of rich real-world\napplications, such as virtual humans, monocular-to-3d reconstruction. However,\nthe popular DensePose-COCO dataset relies on a sophisticated manual annotation\nsystem, leading to severe limitations in acquiring the denser and more accurate\nannotated pose resources. In this work, we introduce a new 3D human-body model\nwith a series of decoupled parameters that could freely control the generation\nof the body. Furthermore, we build a data generation system based on this\ndecoupling 3D model, and construct an ultra dense synthetic benchmark\nUltraPose, containing around 1.3 billion corresponding points. Compared to the\nexisting manually annotated DensePose-COCO dataset, the synthetic UltraPose has\nultra dense image-to-surface correspondences without annotation cost and error.\nOur proposed UltraPose provides the largest benchmark and data resources for\nlifting the model capability in predicting more accurate dense poses. To\npromote future researches in this field, we also propose a transformer-based\nmethod to model the dense correspondence between 2D and 3D worlds. The proposed\nmodel trained on synthetic UltraPose can be applied to real-world scenarios,\nindicating the effectiveness of our benchmark and model.",
    "descriptor": "\nComments: Accepted to ICCV 2021\n",
    "authors": [
      "Haonan Yan",
      "Jiaqi Chen",
      "Xujie Zhang",
      "Shengkai Zhang",
      "Nianhong Jiao",
      "Xiaodan Liang",
      "Tianxiang Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15267"
  },
  {
    "id": "arXiv:2110.15268",
    "title": "Learning Continuous Face Representation with Explicit Functions",
    "abstract": "How to represent a face pattern? While it is presented in a continuous way in\nour visual system, computers often store and process the face image in a\ndiscrete manner with 2D arrays of pixels. In this study, we attempt to learn a\ncontinuous representation for face images with explicit functions. First, we\npropose an explicit model (EmFace) for human face representation in the form of\na finite sum of mathematical terms, where each term is an analytic function\nelement. Further, to estimate the unknown parameters of EmFace, a novel neural\nnetwork, EmNet, is designed with an encoder-decoder structure and trained using\nthe backpropagation algorithm, where the encoder is defined by a deep\nconvolutional neural network and the decoder is an explicit mathematical\nexpression of EmFace. Experimental results show that EmFace has a higher\nrepresentation performance on faces with various expressions, postures, and\nother factors, compared to that of other methods. Furthermore, EmFace achieves\nreasonable performance on several face image processing tasks, including face\nimage restoration, denoising, and transformation.",
    "descriptor": "",
    "authors": [
      "Liping Zhang",
      "Weijun Li",
      "Linjun Sun",
      "Lina Yu",
      "Xin Ning",
      "Xiaoli Dong",
      "Jian Xu",
      "Hong Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15268"
  },
  {
    "id": "arXiv:2110.15269",
    "title": "Cognitive network science quantifies feelings expressed in suicide  letters and Reddit mental health communities",
    "abstract": "Writing messages is key to expressing feelings. This study adopts cognitive\nnetwork science to reconstruct how individuals report their feelings in\nclinical narratives like suicide notes or mental health posts. We achieve this\nby reconstructing syntactic/semantic associations between conceptsin texts as\nco-occurrences enriched with affective data. We transform 142 suicide notes and\n77,000 Reddit posts from the r/anxiety, r/depression, r/schizophrenia, and\nr/do-it-your-own (r/DIY) forums into 5 cognitive networks, each one expressing\nmeanings and emotions as reported by authors. These networks reconstruct the\nsemantic frames surrounding \\textit{feel}, enabling a quantification of\nprominent associations and emotions focused around feelings. We find strong\nfeelings of sadness across all clinical Reddit boards, added to fear\nr/depression, and replaced by joy/anticipation in r/DIY. Semantic communities\nand topic modelling both highlight key narrative topics of \\textit{regret},\n\\textit{unhealthy lifestyle} and \\textit{low mental well-being}. Importantly,\nnegative associations and emotions co-existed with trustful/positive language,\nfocused on \\textit{getting better}. This emotional polarisation provides\nquantitative evidence that online clinical boards possess a complex structure,\nwhere users mix both positive and negative outlooks. This dichotomy is absent\nin the r/DIY reference board and in suicide notes, where negative emotional\nassociations about regret and pain persist but are overwhelmed by positive\njargon addressing loved ones. Our quantitative comparisons provide strong\nevidence that suicide notes encapsulate different ways of expressing feelings\ncompared to online Reddit boards, the latter acting more like personal diaries\nand relief valve. Our findings provide an interpretable, quantitative aid for\nsupporting psychological inquiries of human feelings in digital and clinical\nsettings.",
    "descriptor": "",
    "authors": [
      "Simmi Marina Joseph",
      "Salvatore Citraro",
      "Virginia Morini",
      "Giulio Rossetti",
      "Massimo Stella"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.15269"
  },
  {
    "id": "arXiv:2110.15273",
    "title": "OMASGAN: Out-of-Distribution Minimum Anomaly Score GAN for Sample  Generation on the Boundary",
    "abstract": "Generative models trained in an unsupervised manner may set high likelihood\nand low reconstruction loss to Out-of-Distribution (OoD) samples. This\nincreases Type II errors and leads to missed anomalies, overall decreasing\nAnomaly Detection (AD) performance. In addition, AD models underperform due to\nthe rarity of anomalies. To address these limitations, we propose the OoD\nMinimum Anomaly Score GAN (OMASGAN). OMASGAN generates, in a negative data\naugmentation manner, anomalous samples on the estimated distribution boundary.\nThese samples are then used to refine an AD model, leading to more accurate\nestimation of the underlying data distribution including multimodal supports\nwith disconnected modes. OMASGAN performs retraining by including the abnormal\nminimum-anomaly-score OoD samples generated on the distribution boundary in a\nself-supervised learning manner. For inference, for AD, we devise a\ndiscriminator which is trained with negative and positive samples either\ngenerated (negative or positive) or real (only positive). OMASGAN addresses the\nrarity of anomalies by generating strong and adversarial OoD samples on the\ndistribution boundary using only normal class data, effectively addressing mode\ncollapse. A key characteristic of our model is that it uses any f-divergence\ndistribution metric in its variational representation, not requiring\ninvertibility. OMASGAN does not use feature engineering and makes no\nassumptions about the data distribution. The evaluation of OMASGAN on image\ndata using the leave-one-out methodology shows that it achieves an improvement\nof at least 0.24 and 0.07 points in AUROC on average on the MNIST and CIFAR-10\ndatasets, respectively, over other benchmark and state-of-the-art models for\nAD.",
    "descriptor": "\nComments: Research work paper, 9 pages, 10 figures, Appendix\n",
    "authors": [
      "Nikolaos Dionelis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.15273"
  },
  {
    "id": "arXiv:2110.15288",
    "title": "Self-Supervised Representation Learning on Neural Network Weights for  Model Characteristic Prediction",
    "abstract": "Self-Supervised Learning (SSL) has been shown to learn useful and\ninformation-preserving representations. Neural Networks (NNs) are widely\napplied, yet their weight space is still not fully understood. Therefore, we\npropose to use SSL to learn neural representations of the weights of\npopulations of NNs. To that end, we introduce domain specific data\naugmentations and an adapted attention architecture. Our empirical evaluation\ndemonstrates that self-supervised representation learning in this domain is\nable to recover diverse NN model characteristics. Further, we show that the\nproposed learned representations outperform prior work for predicting\nhyper-parameters, test accuracy, and generalization gap as well as transfer to\nout-of-distribution settings.",
    "descriptor": "\nComments: Published at 35th Conference on Neural Information Processing Systems (NeurIPS 2021), Sydney, Australia. 31 Pages, 14 figures\n",
    "authors": [
      "Konstantin Sch\u00fcrholt",
      "Dimche Kostadinov",
      "Damian Borth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15288"
  },
  {
    "id": "arXiv:2110.15290",
    "title": "Learning to Control using Image Feedback",
    "abstract": "Learning to control complex systems using non-traditional feedback, e.g., in\nthe form of snapshot images, is an important task encountered in diverse\ndomains such as robotics, neuroscience, and biology (cellular systems). In this\npaper, we present a two neural-network (NN)-based feedback control framework to\ndesign control policies for systems that generate feedback in the form of\nimages. In particular, we develop a deep $Q$-network (DQN)-driven learning\ncontrol strategy to synthesize a sequence of control inputs from snapshot\nimages that encode the information pertaining to the current state and control\naction of the system. Further, to train the networks we employ a direct\nerror-driven learning (EDL) approach that utilizes a set of linear\ntransformations of the NN training error to update the NN weights in each\nlayer. We verify the efficacy of the proposed control strategy using numerical\nexamples.",
    "descriptor": "",
    "authors": [
      "Krishnan Raghavan",
      "Vignesh Narayanan",
      "Jagannathan Saraangapani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.15290"
  },
  {
    "id": "arXiv:2110.15292",
    "title": "Class-wise Thresholding for Detecting Out-of-Distribution Data",
    "abstract": "We consider the problem of detecting OoD(Out-of-Distribution) input data when\nusing deep neural networks, and we propose a simple yet effective way to\nimprove the robustness of several popular OoD detection methods against label\nshift. Our work is motivated by the observation that most existing OoD\ndetection algorithms consider all training/test data as a whole, regardless of\nwhich class entry each input activates (inter-class differences). Through\nextensive experimentation, we have found that such practice leads to a detector\nwhose performance is sensitive and vulnerable to label shift. To address this\nissue, we propose a class-wise thresholding scheme that can apply to most\nexisting OoD detection algorithms and can maintain similar OoD detection\nperformance even in the presence of label shift in the test distribution.",
    "descriptor": "\nComments: 12 pages, 7 figures, 7 tables\n",
    "authors": [
      "Matteo Guarrera",
      "Baihong Jin",
      "Tung-Wei Lin",
      "Maria Zuluaga",
      "Yuxin Chen",
      "Alberto Sangiovanni-Vincentelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15292"
  },
  {
    "id": "arXiv:2110.15305",
    "title": "Cooperative Deep $Q$-learning Framework for Environments Providing Image  Feedback",
    "abstract": "In this paper, we address two key challenges in deep reinforcement learning\nsetting, sample inefficiency and slow learning, with a dual NN-driven learning\napproach. In the proposed approach, we use two deep NNs with independent\ninitialization to robustly approximate the action-value function in the\npresence of image inputs. In particular, we develop a temporal difference (TD)\nerror-driven learning approach, where we introduce a set of linear\ntransformations of the TD error to directly update the parameters of each layer\nin the deep NN. We demonstrate theoretically that the cost minimized by the\nerror-driven learning (EDL) regime is an approximation of the empirical cost\nand the approximation error reduces as learning progresses, irrespective of the\nsize of the network. Using simulation analysis, we show that the proposed\nmethods enables faster learning and convergence and requires reduced buffer\nsize (thereby increasing the sample efficiency).",
    "descriptor": "",
    "authors": [
      "Krishnan Raghavan",
      "Vignesh Narayanan",
      "Jagannathan Sarangapani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15305"
  },
  {
    "id": "arXiv:2110.15307",
    "title": "How to boost autoencoders?",
    "abstract": "Autoencoders are a category of neural networks with applications in numerous\ndomains and hence, improvement of their performance is gaining substantial\ninterest from the machine learning community. Ensemble methods, such as\nboosting, are often adopted to enhance the performance of regular neural\nnetworks. In this work, we discuss the challenges associated with boosting\nautoencoders and propose a framework to overcome them. The proposed method\nensures that the advantages of boosting are realized when either output\n(encoded or reconstructed) is used. The usefulness of the boosted ensemble is\ndemonstrated in two applications that widely employ autoencoders: anomaly\ndetection and clustering.",
    "descriptor": "",
    "authors": [
      "Sai Krishna",
      "Thulasi Tholeti",
      "Sheetal Kalyani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15307"
  },
  {
    "id": "arXiv:2110.15310",
    "title": "On the Fairness of Machine-Assisted Human Decisions",
    "abstract": "When machine-learning algorithms are deployed in high-stakes decisions, we\nwant to ensure that their deployment leads to fair and equitable outcomes. This\nconcern has motivated a fast-growing literature that focuses on diagnosing and\naddressing disparities in machine predictions. However, many machine\npredictions are deployed to assist in decisions where a human decision-maker\nretains the ultimate decision authority. In this article, we therefore consider\nhow properties of machine predictions affect the resulting human decisions. We\nshow in a formal model that the inclusion of a biased human decision-maker can\nrevert common relationships between the structure of the algorithm and the\nqualities of resulting decisions. Specifically, we document that excluding\ninformation about protected groups from the prediction may fail to reduce, and\nmay even increase, ultimate disparities. While our concrete results rely on\nspecific assumptions about the data, algorithm, and decision-maker, they show\nmore broadly that any study of critical properties of complex decision systems,\nsuch as the fairness of machine-assisted human decisions, should go beyond\nfocusing on the underlying algorithmic predictions in isolation.",
    "descriptor": "",
    "authors": [
      "Talia Gillis",
      "Bryce McLaughlin",
      "Jann Spiess"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "General Economics (econ.GN)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.15310"
  },
  {
    "id": "arXiv:2110.15313",
    "title": "Clustering of the Blendshape Facial Model",
    "abstract": "Digital human animation relies on high-quality 3D models of the human face --\nrigs. A face rig must be accurate and, at the same time, fast to compute. One\nof the most common rigging models is the blendshape model. We present a novel\napproach for learning the inverse rig parameters at increased accuracy and\ndecreased computational cost at the same time. It is based on a two-fold\nclustering of the blendshape face model. Our method focuses exclusively on the\nunderlying space of deformation and produces clusters in both the mesh space\nand the controller space -- something that was not investigated in previous\nliterature. This segmentation finds intuitive and meaningful connections\nbetween groups of vertices on the face and deformation controls, and further\nthese segments can be observed independently. A separate model for solving the\ninverse rig problem is then learned for each segment. Our method is completely\nunsupervised and highly parallelizable.",
    "descriptor": "",
    "authors": [
      "Stevo Rackovi\u0107",
      "Cl\u00e1udia Soares",
      "Du\u0161an Jakoveti\u0107",
      "Zoranka Desnica",
      "Relja Ljubobratovi\u0107"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15313"
  },
  {
    "id": "arXiv:2110.15316",
    "title": "VRM-Phase I VKW system description of long-short video customizable  keyword wakeup challenge",
    "abstract": "Keyword wakeup technology has always been a research hotspot in speech\nprocessing, but many related works were done on different datasets. We\norganized a Chinese long-short video keyword wakeup challenge (Video Keyword\nWakeup Challenge, VKW) for testing the ability of each participating team to\nbuild a keyword wakeup system under the public dataset. All submitted systems\nnot only need to support the setting of multiple different keywords, but also\nneed to support the wakeup of any costumed keyword.This paper mainly describes\nthe basic situation of the VKW challenge and the experimental results of some\nparticipating teams.",
    "descriptor": "\nComments: 6 pages, in Chinese language, 3 tables, NCMMC 2021 conference paper\n",
    "authors": [
      "Yougen Yuan",
      "Zhiqiang Lv",
      "Shen Huang",
      "Pengfei Hu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.15316"
  },
  {
    "id": "arXiv:2110.15317",
    "title": "Bridge the Gap Between CV and NLP! A Gradient-based Textual Adversarial  Attack Framework",
    "abstract": "Despite great success on many machine learning tasks, deep neural networks\nare still vulnerable to adversarial samples. While gradient-based adversarial\nattack methods are well-explored in the field of computer vision, it is\nimpractical to directly apply them in natural language processing due to the\ndiscrete nature of text. To bridge this gap, we propose a general framework to\nadapt existing gradient-based methods to craft textual adversarial samples. In\nthis framework, gradient-based continuous perturbations are added to the\nembedding layer and are amplified in the forward propagation process. Then the\nfinal perturbed latent representations are decoded with a mask language model\nhead to obtain potential adversarial samples. In this paper, we instantiate our\nframework with \\textbf{T}extual \\textbf{P}rojected \\textbf{G}radient\n\\textbf{D}escent (\\textbf{TPGD}). We conduct comprehensive experiments to\nevaluate our framework by performing transfer black-box attacks on BERT,\nRoBERTa and ALBERT on three benchmark datasets. Experimental results\ndemonstrate our method achieves an overall better performance and produces more\nfluent and grammatical adversarial samples compared to strong baseline methods.\nAll the code and data will be made public.",
    "descriptor": "\nComments: Work on progress\n",
    "authors": [
      "Lifan Yuan",
      "Yichi Zhang",
      "Yangyi Chen",
      "Wei Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15317"
  },
  {
    "id": "arXiv:2110.15318",
    "title": "Communication-Efficient ADMM-based Federated Learning",
    "abstract": "Federated learning has shown its advances over the last few years but is\nfacing many challenges, such as how algorithms save communication resources,\nhow they reduce computational costs, and whether they converge. To address\nthese issues, this paper proposes exact and inexact ADMM-based federated\nlearning. They are not only communication-efficient but also converge linearly\nunder very mild conditions, such as convexity-free and irrelevance to data\ndistributions. Moreover, the inexact version has low computational complexity,\nthereby alleviating the computational burdens significantly.",
    "descriptor": "",
    "authors": [
      "Shenglong Zhou",
      "Geoffrey Ye Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15318"
  },
  {
    "id": "arXiv:2110.15326",
    "title": "GOMP-FIT: Grasp-Optimized Motion Planning for Fast Inertial Transport",
    "abstract": "High-speed motions in pick-and-place operations are critical to making robots\ncost-effective in many automation scenarios, from warehouses and manufacturing\nto hospitals and homes. However, motions can be too fast -- such as when the\nobject being transported has an open-top, is fragile, or both. One way to avoid\nspills or damage, is to move the arm slowly. We propose Grasp-Optimized Motion\nPlanning for Fast Inertial Transport (GOMP-FIT), a time-optimizing motion\nplanner based on our prior work, that includes constraints based on\naccelerations at the robot end-effector. With GOMP-FIT, a robot can perform\nhigh-speed motions that avoid obstacles and use inertial forces to its\nadvantage. In experiments transporting open-top containers with varying tilt\ntolerances, whereas GOMP computes sub-second motions that spill up to 90% of\nthe contents during transport, GOMP-FIT generates motions that spill 0% of\ncontents while being slowed by as little as 0% when there are few obstacles,\n30% when there are high obstacles and 45-degree tolerances, and 50% when there\n15-degree tolerances and few obstacles.",
    "descriptor": "\nComments: 7 pages, 6 figures\n",
    "authors": [
      "Jeffrey Ichnowski",
      "Yahav Avigal",
      "Yi Liu",
      "Ken Goldberg"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.15326"
  },
  {
    "id": "arXiv:2110.15327",
    "title": "MEGAN: Memory Enhanced Graph Attention Network for Space-Time Video  Super-Resolution",
    "abstract": "Space-time video super-resolution (STVSR) aims to construct a high space-time\nresolution video sequence from the corresponding low-frame-rate, low-resolution\nvideo sequence. Inspired by the recent success to consider spatial-temporal\ninformation for space-time super-resolution, our main goal in this work is to\ntake full considerations of spatial and temporal correlations within the video\nsequences of fast dynamic events. To this end, we propose a novel one-stage\nmemory enhanced graph attention network (MEGAN) for space-time video\nsuper-resolution. Specifically, we build a novel long-range memory graph\naggregation (LMGA) module to dynamically capture correlations along the channel\ndimensions of the feature maps and adaptively aggregate channel features to\nenhance the feature representations. We introduce a non-local residual block,\nwhich enables each channel-wise feature to attend global spatial hierarchical\nfeatures. In addition, we adopt a progressive fusion module to further enhance\nthe representation ability by extensively exploiting spatial-temporal\ncorrelations from multiple frames. Experiment results demonstrate that our\nmethod achieves better results compared with the state-of-the-art methods\nquantitatively and visually.",
    "descriptor": "",
    "authors": [
      "Chenyu You",
      "Lianyi Han",
      "Aosong Feng",
      "Ruihan Zhao",
      "Hui Tang",
      "Wei Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.15327"
  },
  {
    "id": "arXiv:2110.15328",
    "title": "DeepNP: Deep Learning-Based Noise Prediction for Ultra-Reliable  Low-Latency Communications",
    "abstract": "Closing the gap between high data rates and low delay in real-time streaming\napplications is a major challenge in advanced communication systems. While\nadaptive network coding schemes have the potential of balancing rate and delay\nin real-time, they often rely on prediction of the channel behavior. In\npractice, such prediction is based on delayed feedback, making it difficult to\nacquire causally, particularly when the underlying channel model is unknown. In\nthis work, we propose a deep learning-based noise prediction (DeepNP)\nalgorithm, which augments the recently proposed adaptive and causal random\nlinear network coding scheme with a dedicated deep neural network, that learns\nto carry out noise prediction from data. This neural augmentation is utilized\nto maximize the throughput while minimizing in-order delivery delay of the\nnetwork coding scheme, and operate in a channel-model-agnostic manner. We\nnumerically show that performance can dramatically increase by the learned\nprediction of the channel noise rate. In particular, we demonstrate that DeepNP\ngains up to a factor of four in mean and maximum delay and a factor two in\nthroughput compared with statistic-based network coding approaches.",
    "descriptor": "",
    "authors": [
      "Alejandro Cohen",
      "Amit Solomon",
      "Nir Shlezinger"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.15328"
  },
  {
    "id": "arXiv:2110.15331",
    "title": "Wasserstein Distance Maximizing Intrinsic Control",
    "abstract": "This paper deals with the problem of learning a skill-conditioned policy that\nacts meaningfully in the absence of a reward signal. Mutual information based\nobjectives have shown some success in learning skills that reach a diverse set\nof states in this setting. These objectives include a KL-divergence term, which\nis maximized by visiting distinct states even if those states are not far apart\nin the MDP. This paper presents an approach that rewards the agent for learning\nskills that maximize the Wasserstein distance of their state visitation from\nthe start state of the skill. It shows that such an objective leads to a policy\nthat covers more distance in the MDP than diversity based objectives, and\nvalidates the results on a variety of Atari environments.",
    "descriptor": "",
    "authors": [
      "Ishan Durugkar",
      "Steven Hansen",
      "Stephen Spencer",
      "Volodymyr Mnih"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15331"
  },
  {
    "id": "arXiv:2110.15332",
    "title": "Proximal Reinforcement Learning: Efficient Off-Policy Evaluation in  Partially Observed Markov Decision Processes",
    "abstract": "In applications of offline reinforcement learning to observational data, such\nas in healthcare or education, a general concern is that observed actions might\nbe affected by unobserved factors, inducing confounding and biasing estimates\nderived under the assumption of a perfect Markov decision process (MDP) model.\nHere we tackle this by considering off-policy evaluation in a partially\nobserved MDP (POMDP). Specifically, we consider estimating the value of a given\ntarget policy in a POMDP given trajectories with only partial state\nobservations generated by a different and unknown policy that may depend on the\nunobserved state. We tackle two questions: what conditions allow us to identify\nthe target policy value from the observed data and, given identification, how\nto best estimate it. To answer these, we extend the framework of proximal\ncausal inference to our POMDP setting, providing a variety of settings where\nidentification is made possible by the existence of so-called bridge functions.\nWe then show how to construct semiparametrically efficient estimators in these\nsettings. We term the resulting framework proximal reinforcement learning\n(PRL). We demonstrate the benefits of PRL in an extensive simulation study.",
    "descriptor": "",
    "authors": [
      "Andrew Bennett",
      "Nathan Kallus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.15332"
  },
  {
    "id": "arXiv:2110.15335",
    "title": "Bayesian Sequential Optimal Experimental Design for Nonlinear Models  Using Policy Gradient Reinforcement Learning",
    "abstract": "We present a mathematical framework and computational methods to optimally\ndesign a finite number of sequential experiments. We formulate this sequential\noptimal experimental design (sOED) problem as a finite-horizon partially\nobservable Markov decision process (POMDP) in a Bayesian setting and with\ninformation-theoretic utilities. It is built to accommodate continuous random\nvariables, general non-Gaussian posteriors, and expensive nonlinear forward\nmodels. sOED then seeks an optimal design policy that incorporates elements of\nboth feedback and lookahead, generalizing the suboptimal batch and greedy\ndesigns. We solve for the sOED policy numerically via policy gradient (PG)\nmethods from reinforcement learning, and derive and prove the PG expression for\nsOED. Adopting an actor-critic approach, we parameterize the policy and value\nfunctions using deep neural networks and improve them using gradient estimates\nproduced from simulated episodes of designs and observations. The overall\nPG-sOED method is validated on a linear-Gaussian benchmark, and its advantages\nover batch and greedy designs are demonstrated through a contaminant source\ninversion problem in a convection-diffusion field.",
    "descriptor": "\nComments: Preprint 34 pages, 14 figures\n",
    "authors": [
      "Wanggang Shen",
      "Xun Huan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.15335"
  },
  {
    "id": "arXiv:2110.15343",
    "title": "Scatterbrain: Unifying Sparse and Low-rank Attention Approximation",
    "abstract": "Recent advances in efficient Transformers have exploited either the sparsity\nor low-rank properties of attention matrices to reduce the computational and\nmemory bottlenecks of modeling long sequences. However, it is still challenging\nto balance the trade-off between model quality and efficiency to perform a\none-size-fits-all approximation for different tasks. To better understand this\ntrade-off, we observe that sparse and low-rank approximations excel in\ndifferent regimes, determined by the softmax temperature in attention, and\nsparse + low-rank can outperform each individually. Inspired by the classical\nrobust-PCA algorithm for sparse and low-rank decomposition, we propose\nScatterbrain, a novel way to unify sparse (via locality sensitive hashing) and\nlow-rank (via kernel feature map) attention for accurate and efficient\napproximation. The estimation is unbiased with provably low error. We\nempirically show that Scatterbrain can achieve 2.1x lower error than baselines\nwhen serving as a drop-in replacement in BigGAN image generation and\npre-trained T2T-ViT. On a pre-trained T2T Vision transformer, even without\nfine-tuning, Scatterbrain can reduce 98% of attention memory at the cost of\nonly 1% drop in accuracy. We demonstrate Scatterbrain for end-to-end training\nwith up to 4 points better perplexity and 5 points better average accuracy than\nsparse or low-rank efficient transformers on language modeling and\nlong-range-arena tasks.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Beidi Chen",
      "Tri Dao",
      "Eric Winsor",
      "Zhao Song",
      "Atri Rudra",
      "Christopher R\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15343"
  },
  {
    "id": "arXiv:2110.15344",
    "title": "Learning to Jump from Pixels",
    "abstract": "Today's robotic quadruped systems can robustly walk over a diverse range of\nrough but continuous terrains, where the terrain elevation varies gradually.\nLocomotion on discontinuous terrains, such as those with gaps or obstacles,\npresents a complementary set of challenges. In discontinuous settings, it\nbecomes necessary to plan ahead using visual inputs and to execute agile\nbehaviors beyond robust walking, such as jumps. Such dynamic motion results in\nsignificant motion of onboard sensors, which introduces a new set of challenges\nfor real-time visual processing. The requirement for agility and terrain\nawareness in this setting reinforces the need for robust control. We present\nDepth-based Impulse Control (DIC), a method for synthesizing highly agile\nvisually-guided locomotion behaviors. DIC affords the flexibility of model-free\nlearning but regularizes behavior through explicit model-based optimization of\nground reaction forces. We evaluate the proposed method both in simulation and\nin the real world.",
    "descriptor": "\nComments: Accepted for publication at Conference on Robot Learning (CoRL) 2021\n",
    "authors": [
      "Gabriel B. Margolis",
      "Tao Chen",
      "Kartik Paigwar",
      "Xiang Fu",
      "Donghyun Kim",
      "Sangbae Kim",
      "Pulkit Agrawal"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.15344"
  },
  {
    "id": "arXiv:2110.15345",
    "title": "A First Look at the Consolidation of DNS and Web Hosting Providers",
    "abstract": "Although the Internet continues to grow, it increasingly depends on a small\nset of dominant service providers for Domain Name System (DNS) hosting and web\nhosting providers. This consolidation of Internet resources poses a variety of\npotential threats to the Internet, including susceptibility to outages,\nfailures, and even overt censorship from platforms. Increasingly, an outage\nfrom a single organization can create widespread disruption across a large\nnumber of sites and services. Consolidation trends have been noted for several\nyears, yet these trends have not been quantified. Towards this end, this paper\naims to quantify these trends, in particular, the reliance of the most popular\ndomains on a small set of organizations for DNS and web hosting. We highlight\nthe extent to which the hosting of authoritative name servers and web hosting\nfor the top 10,000 websites are consolidated on relatively few platforms. The\nstatistics are surprising and somewhat alarming. We find that over 75% of the\ntop 10,000 domains rely on only a single organization for hosting authoritative\nDNS resolution. Furthermore, two organizations, Cloudflare and Amazon, are the\nsole host of DNS name servers for over 40% of these popular domains. In terms\nof web hosting, we find that 62% of index pages and many external page\nresources for the top 10,000 websites are hosted by only five organizations:\nCloudflare, Amazon, Akamai, Fastly, and Google.",
    "descriptor": "",
    "authors": [
      "Synthia Wang",
      "Kyle MacMillan",
      "Brennan Schaffner",
      "Nick Feamster",
      "Marshini Chetty"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.15345"
  },
  {
    "id": "arXiv:2110.15348",
    "title": "Residual Relaxation for Multi-view Representation Learning",
    "abstract": "Multi-view methods learn representations by aligning multiple views of the\nsame image and their performance largely depends on the choice of data\naugmentation. In this paper, we notice that some other useful augmentations,\nsuch as image rotation, are harmful for multi-view methods because they cause a\nsemantic shift that is too large to be aligned well. This observation motivates\nus to relax the exact alignment objective to better cultivate stronger\naugmentations. Taking image rotation as a case study, we develop a generic\napproach, Pretext-aware Residual Relaxation (Prelax), that relaxes the exact\nalignment by allowing an adaptive residual vector between different views and\nencoding the semantic shift through pretext-aware learning. Extensive\nexperiments on different backbones show that our method can not only improve\nmulti-view methods with existing augmentations, but also benefit from stronger\nimage augmentations like rotation.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Yifei Wang",
      "Zhengyang Geng",
      "Feng Jiang",
      "Chuming Li",
      "Yisen Wang",
      "Jiansheng Yang",
      "Zhouchen Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15348"
  },
  {
    "id": "arXiv:2110.15349",
    "title": "Learning to Ground Multi-Agent Communication with Autoencoders",
    "abstract": "Communication requires having a common language, a lingua franca, between\nagents. This language could emerge via a consensus process, but it may require\nmany generations of trial and error. Alternatively, the lingua franca can be\ngiven by the environment, where agents ground their language in representations\nof the observed world. We demonstrate a simple way to ground language in\nlearned representations, which facilitates decentralized multi-agent\ncommunication and coordination. We find that a standard representation learning\nalgorithm -- autoencoding -- is sufficient for arriving at a grounded common\nlanguage. When agents broadcast these representations, they learn to understand\nand respond to each other's utterances and achieve surprisingly strong task\nperformance across a variety of multi-agent communication environments.",
    "descriptor": "\nComments: Project page, code, and videos can be found at this https URL\n",
    "authors": [
      "Toru Lin",
      "Minyoung Huh",
      "Chris Stauffer",
      "Ser-Nam Lim",
      "Phillip Isola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.15349"
  },
  {
    "id": "arXiv:2110.15350",
    "title": "XDEEP-MSI: Explainable Bias-Rejecting Microsatellite Instability Deep  Learning System In Colorectal Cancer",
    "abstract": "We present a system for the prediction of microsatellite instability (MSI)\nfrom H&E images of colorectal cancer using deep learning (DL) techniques\ncustomized for tissue microarrays (TMAs). The system incorporates an end-to-end\nimage preprocessing module that produces tiles at multiple magnifications in\nthe regions of interest as guided by a tissue classifier module, and a\nmultiple-bias rejecting module. The training and validation TMA samples were\nobtained from the EPICOLON project and further enriched with samples from a\nsingle institution. A systematic study of biases at tile level identified three\nprotected (bias) variables associated with the learned representations of a\nbaseline model: the project of origin of samples, the patient spot and the TMA\nglass where each spot was placed. A multiple bias rejecting technique based on\nadversarial training is implemented at the DL architecture so to directly avoid\nlearning the batch effects of those variables. The learned features from the\nbias-ablated model have maximum discriminative power with respect to the task\nand minimal statistical mean dependence with the biases. The impact of\ndifferent magnifications, types of tissues and the model performance at tile vs\npatient level is analyzed. The AUC at tile level, and including all three\nselected tissues (tumor epithelium, mucine and lymphocytic regions) and 4\nmagnifications, was 0.87 +/- 0.03 and increased to 0.9 +/- 0.03 at patient\nlevel. To the best of our knowledge, this is the first work that incorporates a\nmultiple bias ablation technique at the DL architecture in digital pathology,\nand the first using TMAs for the MSI prediction task.",
    "descriptor": "\nComments: 16 pages, 8 figures\n",
    "authors": [
      "Aurelia Bustos",
      "Artemio Pay\u00e1",
      "Andres Torrubia",
      "Rodrigo Jover",
      "Xavier Llor",
      "Xavier Bessa",
      "Antoni Castells",
      "Cristina Alenda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15350"
  },
  {
    "id": "arXiv:2110.15352",
    "title": "MCUNetV2: Memory-Efficient Patch-based Inference for Tiny Deep Learning",
    "abstract": "Tiny deep learning on microcontroller units (MCUs) is challenging due to the\nlimited memory size. We find that the memory bottleneck is due to the\nimbalanced memory distribution in convolutional neural network (CNN) designs:\nthe first several blocks have an order of magnitude larger memory usage than\nthe rest of the network. To alleviate this issue, we propose a generic\npatch-by-patch inference scheduling, which operates only on a small spatial\nregion of the feature map and significantly cuts down the peak memory. However,\nnaive implementation brings overlapping patches and computation overhead. We\nfurther propose network redistribution to shift the receptive field and FLOPs\nto the later stage and reduce the computation overhead. Manually redistributing\nthe receptive field is difficult. We automate the process with neural\narchitecture search to jointly optimize the neural architecture and inference\nscheduling, leading to MCUNetV2. Patch-based inference effectively reduces the\npeak memory usage of existing networks by 4-8x. Co-designed with neural\nnetworks, MCUNetV2 sets a record ImageNet accuracy on MCU (71.8%), and achieves\n>90% accuracy on the visual wake words dataset under only 32kB SRAM. MCUNetV2\nalso unblocks object detection on tiny devices, achieving 16.9% higher mAP on\nPascal VOC compared to the state-of-the-art result. Our study largely addressed\nthe memory bottleneck in tinyML and paved the way for various vision\napplications beyond image classification.",
    "descriptor": "",
    "authors": [
      "Ji Lin",
      "Wei-Ming Chen",
      "Han Cai",
      "Chuang Gan",
      "Song Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.15352"
  },
  {
    "id": "arXiv:2110.15355",
    "title": "Explaining Latent Representations with a Corpus of Examples",
    "abstract": "Modern machine learning models are complicated. Most of them rely on\nconvoluted latent representations of their input to issue a prediction. To\nachieve greater transparency than a black-box that connects inputs to\npredictions, it is necessary to gain a deeper understanding of these latent\nrepresentations. To that aim, we propose SimplEx: a user-centred method that\nprovides example-based explanations with reference to a freely selected set of\nexamples, called the corpus. SimplEx uses the corpus to improve the user's\nunderstanding of the latent space with post-hoc explanations answering two\nquestions: (1) Which corpus examples explain the prediction issued for a given\ntest example? (2) What features of these corpus examples are relevant for the\nmodel to relate them to the test example? SimplEx provides an answer by\nreconstructing the test latent representation as a mixture of corpus latent\nrepresentations. Further, we propose a novel approach, the Integrated Jacobian,\nthat allows SimplEx to make explicit the contribution of each corpus feature in\nthe mixture. Through experiments on tasks ranging from mortality prediction to\nimage classification, we demonstrate that these decompositions are robust and\naccurate. With illustrative use cases in medicine, we show that SimplEx\nempowers the user by highlighting relevant patterns in the corpus that explain\nmodel representations. Moreover, we demonstrate how the freedom in choosing the\ncorpus allows the user to have personalized explanations in terms of examples\nthat are meaningful for them.",
    "descriptor": "\nComments: Presented at the Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Jonathan Crabb\u00e9",
      "Zhaozhi Qian",
      "Fergus Imrie",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.15355"
  },
  {
    "id": "arXiv:2110.15358",
    "title": "Dynamic Visual Reasoning by Learning Differentiable Physics Models from  Video and Language",
    "abstract": "In this work, we propose a unified framework, called Visual Reasoning with\nDiffer-entiable Physics (VRDP), that can jointly learn visual concepts and\ninfer physics models of objects and their interactions from videos and\nlanguage. This is achieved by seamlessly integrating three components: a visual\nperception module, a concept learner, and a differentiable physics engine. The\nvisual perception module parses each video frame into object-centric\ntrajectories and represents them as latent scene representations. The concept\nlearner grounds visual concepts (e.g., color, shape, and material) from these\nobject-centric representations based on the language, thus providing prior\nknowledge for the physics engine. The differentiable physics model, implemented\nas an impulse-based differentiable rigid-body simulator, performs\ndifferentiable physical simulation based on the grounded concepts to infer\nphysical properties, such as mass, restitution, and velocity, by fitting the\nsimulated trajectories into the video observations. Consequently, these learned\nconcepts and physical models can explain what we have seen and imagine what is\nabout to happen in future and counterfactual scenarios. Integrating\ndifferentiable physics into the dynamic reasoning framework offers several\nappealing benefits. More accurate dynamics prediction in learned physics models\nenables state-of-the-art performance on both synthetic and real-world\nbenchmarks while still maintaining high transparency and interpretability; most\nnotably, VRDP improves the accuracy of predictive and counterfactual questions\nby 4.5% and 11.5% compared to its best counterpart. VRDP is also highly\ndata-efficient: physical parameters can be optimized from very few videos, and\neven a single video can be sufficient. Finally, with all physical parameters\ninferred, VRDP can quickly learn new concepts from a few examples.",
    "descriptor": "\nComments: NeurIPS 2021. Project page: this http URL\n",
    "authors": [
      "Mingyu Ding",
      "Zhenfang Chen",
      "Tao Du",
      "Ping Luo",
      "Joshua B. Tenenbaum",
      "Chuang Gan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15358"
  },
  {
    "id": "arXiv:2110.15360",
    "title": "Accelerating Robotic Reinforcement Learning via Parameterized Action  Primitives",
    "abstract": "Despite the potential of reinforcement learning (RL) for building\ngeneral-purpose robotic systems, training RL agents to solve robotics tasks\nstill remains challenging due to the difficulty of exploration in purely\ncontinuous action spaces. Addressing this problem is an active area of research\nwith the majority of focus on improving RL methods via better optimization or\nmore efficient exploration. An alternate but important component to consider\nimproving is the interface of the RL algorithm with the robot. In this work, we\nmanually specify a library of robot action primitives (RAPS), parameterized\nwith arguments that are learned by an RL policy. These parameterized primitives\nare expressive, simple to implement, enable efficient exploration and can be\ntransferred across robots, tasks and environments. We perform a thorough\nempirical study across challenging tasks in three distinct domains with image\ninput and a sparse terminal reward. We find that our simple change to the\naction interface substantially improves both the learning efficiency and task\nperformance irrespective of the underlying RL algorithm, significantly\noutperforming prior methods which learn skills from offline expert data. Code\nand videos at https://mihdalal.github.io/raps/",
    "descriptor": "\nComments: Published at NeurIPS 2021. Website at this https URL\n",
    "authors": [
      "Murtaza Dalal",
      "Deepak Pathak",
      "Ruslan Salakhutdinov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.15360"
  },
  {
    "id": "arXiv:2009.09780",
    "title": "Impact of lung segmentation on the diagnosis and explanation of COVID-19  in chest X-ray images",
    "abstract": "COVID-19 frequently provokes pneumonia, which can be diagnosed using imaging\nexams. Chest X-ray (CXR) is often useful because it is cheap, fast, widespread,\nand uses less radiation. Here, we demonstrate the impact of lung segmentation\nin COVID-19 identification using CXR images and evaluate which contents of the\nimage influenced the most. Semantic segmentation was performed using a U-Net\nCNN architecture, and the classification using three CNN architectures (VGG,\nResNet, and Inception). Explainable Artificial Intelligence techniques were\nemployed to estimate the impact of segmentation. A three-classes database was\ncomposed: lung opacity (pneumonia), COVID-19, and normal. We assessed the\nimpact of creating a CXR image database from different sources, and the\nCOVID-19 generalization from one source to another. The segmentation achieved a\nJaccard distance of 0.034 and a Dice coefficient of 0.982. The classification\nusing segmented images achieved an F1-Score of 0.88 for the multi-class setup,\nand 0.83 for COVID-19 identification. In the cross-dataset scenario, we\nobtained an F1-Score of 0.74 and an area under the ROC curve of 0.9 for\nCOVID-19 identification using segmented images. Experiments support the\nconclusion that even after segmentation, there is a strong bias introduced by\nunderlying factors from different sources.",
    "descriptor": "\nComments: Submitted to Sensors\n",
    "authors": [
      "Lucas O. Teixeira",
      "Rodolfo M. Pereira",
      "Diego Bertolini",
      "Luiz S. Oliveira",
      "Loris Nanni",
      "George D. C. Cavalcanti",
      "Yandre M. G. Costa"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.09780"
  },
  {
    "id": "arXiv:2110.14638",
    "title": "Improving Super-Resolution Performance using Meta-Attention Layers",
    "abstract": "Convolutional Neural Networks (CNNs) have achieved impressive results across\nmany super-resolution (SR) and image restoration tasks. While many such\nnetworks can upscale low-resolution (LR) images using just the raw pixel-level\ninformation, the ill-posed nature of SR can make it difficult to accurately\nsuper-resolve an image which has undergone multiple different degradations.\nAdditional information (metadata) describing the degradation process (such as\nthe blur kernel applied, compression level, etc.) can guide networks to\nsuper-resolve LR images with higher fidelity to the original source. Previous\nattempts at informing SR networks with degradation parameters have indeed been\nable to improve performance in a number of scenarios. However, due to the\nfully-convolutional nature of many SR networks, most of these metadata fusion\nmethods either require a complete architectural change, or necessitate the\naddition of significant extra complexity. Thus, these approaches are difficult\nto introduce into arbitrary SR networks without considerable design\nalterations. In this paper, we introduce meta-attention, a simple mechanism\nwhich allows any SR CNN to exploit the information available in relevant\ndegradation parameters. The mechanism functions by translating the metadata\ninto a channel attention vector, which in turn selectively modulates the\nnetwork's feature maps. Incorporating meta-attention into SR networks is\nstraightforward, as it requires no specific type of architecture to function\ncorrectly. Extensive testing has shown that meta-attention can consistently\nimprove the pixel-level accuracy of state-of-the-art (SOTA) networks when\nprovided with relevant degradation metadata. For PSNR, the gain on\nblurred/downsampled (X4) images is of 0.2969 dB (on average) and 0.3320 dB for\nSOTA general and face SR models, respectively.",
    "descriptor": "\nComments: Accepted for publication in the IEEE Signal Processing Letters. This is the accepted version of the paper, for the final formatted version and supplementary information, please visit the IEEE's publication at the linked DOI\n",
    "authors": [
      "Matthew Aquilina",
      "Christian Galea",
      "John Abela",
      "Kenneth P. Camilleri",
      "Reuben A. Farrugia"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14638"
  },
  {
    "id": "arXiv:2110.14677",
    "title": "Stabilising viscous extensional flows using Reinforcement Learning",
    "abstract": "The four-roll mill, wherein four identical cylinders undergo rotation of\nidentical magnitude but alternate signs, was originally proposed by GI Taylor\nto create local extensional flows and study their ability to deform small\nliquid drops. Since an extensional flow has an unstable eigendirection, a drop\nlocated at the flow stagnation point will have a tendency to escape. This\nunstable dynamics can however be stabilised using, e.g., a modulation of the\nrotation rates of the cylinders. Here we use Reinforcement Learning, a branch\nof Machine Learning devoted to the optimal selection of actions based on\ncumulative rewards, in order to devise a stabilisation algorithm for the\nfour-roll mill flow. The flow is modelled as the linear superposition of four\ntwo-dimensional rotlets and the drop is treated as a rigid spherical particle\nsmaller than all other length scales in the problem. Unlike previous attempts\nto devise control, we take a probabilistic approach whereby speed adjustments\nare drawn from a probability density function whose shape is improved over time\nvia a form of gradient ascent know as Actor-Critic method. With enough\ntraining, our algorithm is able to precisely control the drop and keep it close\nto the stagnation point for as long as needed. We explore the impact of the\nphysical and learning parameters on the effectiveness of the control and\ndemonstrate the robustness of the algorithm against thermal noise. We finally\nshow that Reinforcement Learning can provide a control algorithm effective for\nall initial positions and that can be adapted to limit the magnitude of the\nflow extension near the position of the drop.",
    "descriptor": "",
    "authors": [
      "Marco Vona",
      "Eric Lauga"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.14677"
  },
  {
    "id": "arXiv:2110.14690",
    "title": "VACA: Design of Variational Graph Autoencoders for Interventional and  Counterfactual Queries",
    "abstract": "In this paper, we introduce VACA, a novel class of variational graph\nautoencoders for causal inference in the absence of hidden confounders, when\nonly observational data and the causal graph are available. Without making any\nparametric assumptions, VACA mimics the necessary properties of a Structural\nCausal Model (SCM) to provide a flexible and practical framework for\napproximating interventions (do-operator) and abduction-action-prediction\nsteps. As a result, and as shown by our empirical results, VACA accurately\napproximates the interventional and counterfactual distributions on diverse\nSCMs. Finally, we apply VACA to evaluate counterfactual fairness in fair\nclassification problems, as well as to learn fair classifiers without\ncompromising performance.",
    "descriptor": "",
    "authors": [
      "Pablo Sanchez-Martin",
      "Miriam Rateike",
      "Isabel Valera"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14690"
  },
  {
    "id": "arXiv:2110.14701",
    "title": "Cybersecurity for Quantum Computing",
    "abstract": "With rising cyberattack frequency and range, Quantum Computing companies,\ninstitutions and research groups may become targets of nation-state actors,\ncybercriminals and hacktivists for sabotage, espionage and fiscal motivations\nas the Quantum computing race intensifies. Quantum applications have expanded\ninto commercial, classical information systems and services approaching the\nnecessity to protect their networks, software, hardware and data from digital\nattacks. This paper discusses the status quo of quantum computing technologies\nand the quantum threat associated with it. We proceed to outline threat vectors\nfor quantum computing systems and the respective defensive measures,\nmitigations and best practices to defend against the rapidly evolving threat\nlandscape. We subsequently propose recommendations on how to proactively reduce\nthe cyberattack surface through threat intelligence and by ensuring security by\ndesign of quantum software and hardware components.",
    "descriptor": "",
    "authors": [
      "Natalie Kilber",
      "Daniel Kaestle",
      "Stefan Wagner"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.14701"
  },
  {
    "id": "arXiv:2110.14703",
    "title": "Alternating Learning Approach for Variational Networks and Undersampling  Pattern in Parallel MRI Applications",
    "abstract": "Purpose: To propose an alternating learning approach to learn the sampling\npattern (SP) and the parameters of variational networks (VN) in accelerated\nparallel magnetic resonance imaging (MRI). Methods: The approach alternates\nbetween improving the SP, using bias-accelerated subset selection, and\nimproving parameters of the VN, using ADAM with monotonicity verification. The\nalgorithm learns an effective pair: an SP that captures fewer k-space samples\ngenerating undersampling artifacts that are removed by the VN reconstruction.\nThe proposed approach was tested for stability and convergence, considering\ndifferent initial SPs. The quality of the VNs and SPs was compared against\nother approaches, including joint learning methods and VN learning with fixed\nvariable density Poisson-disc SPs, using two different datasets and different\nacceleration factors (AF). Results: The root mean squared error (RMSE)\nimprovements ranged from 14.9% to 51.2% considering AF from 2 to 20 in the\ntested brain and knee joint datasets when compared to the other approaches. The\nproposed approach has shown stable convergence, obtaining similar SPs with the\nsame RMSE under different initial conditions. Conclusion: The proposed approach\nwas stable and learned effective SPs with the corresponding VN parameters that\nproduce images with better quality than other approaches, improving accelerated\nparallel MRI applications.",
    "descriptor": "",
    "authors": [
      "Marcelo V. W. Zibetti",
      "Florian Knoll",
      "Ravinder R. Regatte"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.14703"
  },
  {
    "id": "arXiv:2110.14709",
    "title": "Sharp-GAN: Sharpness Loss Regularized GAN for Histopathology Image  Synthesis",
    "abstract": "Existing deep learning-based approaches for histopathology image analysis\nrequire large annotated training sets to achieve good performance; but\nannotating histopathology images is slow and resource-intensive. Conditional\ngenerative adversarial networks have been applied to generate synthetic\nhistopathology images to alleviate this issue, but current approaches fail to\ngenerate clear contours for overlapped and touching nuclei. In this study, We\npropose a sharpness loss regularized generative adversarial network to\nsynthesize realistic histopathology images. The proposed network uses\nnormalized nucleus distance map rather than the binary mask to encode nuclei\ncontour information. The proposed sharpness loss enhances the contrast of\nnuclei contour pixels. The proposed method is evaluated using four image\nquality metrics and segmentation results on two public datasets. Both\nquantitative and qualitative results demonstrate that the proposed approach can\ngenerate realistic histopathology images with clear nuclei contours.",
    "descriptor": "",
    "authors": [
      "Sujata Butte",
      "Haotian Wang",
      "Min Xian",
      "Aleksandar Vakanski"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.14709"
  },
  {
    "id": "arXiv:2110.14714",
    "title": "Designing Machine Learning Surrogates using Outputs of Molecular  Dynamics Simulations as Soft Labels",
    "abstract": "Molecular dynamics simulations are powerful tools to extract the microscopic\nmechanisms characterizing the properties of soft materials. We recently\nintroduced machine learning surrogates for molecular dynamics simulations of\nsoft materials and demonstrated that artificial neural network based regression\nmodels can successfully predict the relationships between the input material\nattributes and the simulation outputs. Here, we show that statistical\nuncertainties associated with the outputs of molecular dynamics simulations can\nbe utilized to train artificial neural networks and design machine learning\nsurrogates with higher accuracy and generalizability. We design soft labels for\nthe simulation outputs by incorporating the uncertainties in the estimated\naverage output quantities, and introduce a modified loss function that\nleverages these soft labels during training to significantly reduce the\nsurrogate prediction error for input systems in the unseen test data. The\napproach is illustrated with the design of a surrogate for molecular dynamics\nsimulations of confined electrolytes to predict the complex relationship\nbetween the input electrolyte attributes and the output ionic structure. The\nsurrogate predictions for the ionic density profiles show excellent agreement\nwith the ground truth results produced using molecular dynamics simulations.\nThe high accuracy and small inference times associated with the surrogate\npredictions provide quick access to quantities derived using the number density\nprofiles and facilitate rapid sensitivity analysis.",
    "descriptor": "\nComments: 14 pages, 8 figures\n",
    "authors": [
      "J.C.S. Kadupitiya",
      "Nasim Anousheh",
      "Vikram Jadhao"
    ],
    "subjectives": [
      "Soft Condensed Matter (cond-mat.soft)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.14714"
  },
  {
    "id": "arXiv:2110.14728",
    "title": "Lung Cancer Lesion Detection in Histopathology Images Using Graph-Based  Sparse PCA Network",
    "abstract": "Early detection of lung cancer is critical for improvement of patient\nsurvival. To address the clinical need for efficacious treatments, genetically\nengineered mouse models (GEMM) have become integral in identifying and\nevaluating the molecular underpinnings of this complex disease that may be\nexploited as therapeutic targets. Assessment of GEMM tumor burden on\nhistopathological sections performed by manual inspection is both time\nconsuming and prone to subjective bias. Therefore, an interplay of needs and\nchallenges exists for computer-aided diagnostic tools, for accurate and\nefficient analysis of these histopathology images. In this paper, we propose a\nsimple machine learning approach called the graph-based sparse principal\ncomponent analysis (GS-PCA) network, for automated detection of cancerous\nlesions on histological lung slides stained by hematoxylin and eosin (H&E). Our\nmethod comprises four steps: 1) cascaded graph-based sparse PCA, 2) PCA binary\nhashing, 3) block-wise histograms, and 4) support vector machine (SVM)\nclassification. In our proposed architecture, graph-based sparse PCA is\nemployed to learn the filter banks of the multiple stages of a convolutional\nnetwork. This is followed by PCA hashing and block histograms for indexing and\npooling. The meaningful features extracted from this GS-PCA are then fed to an\nSVM classifier. We evaluate the performance of the proposed algorithm on H&E\nslides obtained from an inducible K-rasG12D lung cancer mouse model using\nprecision/recall rates, F-score, Tanimoto coefficient, and area under the curve\n(AUC) of the receiver operator characteristic (ROC) and show that our algorithm\nis efficient and provides improved detection accuracy compared to existing\nalgorithms.",
    "descriptor": "\nComments: 10 pages, 9 figures, 3 tables\n",
    "authors": [
      "Sundaresh Ram",
      "Wenfei Tang",
      "Alexander J. Bell",
      "Cara Spencer",
      "Alexander Buschhaus",
      "Charles R. Hatt",
      "Marina Pasca diMagliano",
      "Jeffrey J. Rodriguez",
      "Stefanie Galban",
      "Craig J. Galban"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.14728"
  },
  {
    "id": "arXiv:2110.14733",
    "title": "Feedback-Induced Flutter Oscillations in a Flexible Tail-Like Appendage  for Underwater Propulsion",
    "abstract": "Oscillating propulsors can provide both propulsive and maneuvering forces to\nan underwater vehicle. Because the working area is the same, it is possible to\nprovide maneuvering forces that are similar in magnitude to that of the\npropulsive forces. An oscillating propulsor in the form of a flexible beam is\ninvestigated; the flexible beam is appended to an underwater vehicle by a pin\njoint and actuated by a motor. It is shown that the flexible propulsor can be\ndriven into post-flutter limit cycle oscillations using feedback of the state\nof the propulsor. The limit cycle oscillations result in traveling waves, which\nin turn generate propulsive forces. The elastic strain of the propulsor is used\nto provide feedback; it is shown that changing the location of strain\nmeasurement can result in a rich set of stability transitions, each stability\ntransition is associated with a specific mode of flutter-based propulsion with\nunique thrust and efficiency characteristics.",
    "descriptor": "",
    "authors": [
      "Mahmoud Abdullatif",
      "Ranjan Mukherjee",
      "Aren Hellum"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.14733"
  },
  {
    "id": "arXiv:2110.14739",
    "title": "Generalized Shape Metrics on Neural Representations",
    "abstract": "Understanding the operation of biological and artificial networks remains a\ndifficult and important challenge. To identify general principles, researchers\nare increasingly interested in surveying large collections of networks that are\ntrained on, or biologically adapted to, similar tasks. A standardized set of\nanalysis tools is now needed to identify how network-level covariates -- such\nas architecture, anatomical brain region, and model organism -- impact neural\nrepresentations (hidden layer activations). Here, we provide a rigorous\nfoundation for these analyses by defining a broad family of metric spaces that\nquantify representational dissimilarity. Using this framework we modify\nexisting representational similarity measures based on canonical correlation\nanalysis to satisfy the triangle inequality, formulate a novel metric that\nrespects the inductive biases in convolutional layers, and identify approximate\nEuclidean embeddings that enable network representations to be incorporated\ninto essentially any off-the-shelf machine learning method. We demonstrate\nthese methods on large-scale datasets from biology (Allen Institute Brain\nObservatory) and deep learning (NAS-Bench-101). In doing so, we identify\nrelationships between neural representations that are interpretable in terms of\nanatomical features and model performance.",
    "descriptor": "\nComments: 26 pages, 7 figures, NeurIPS 2021\n",
    "authors": [
      "Alex H. Williams",
      "Erin Kunz",
      "Simon Kornblith",
      "Scott W. Linderman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14739"
  },
  {
    "id": "arXiv:2110.14746",
    "title": "MutFormer: A context-dependent transformer-based model to predict  pathogenic missense mutations",
    "abstract": "A missense mutation is a point mutation that results in a substitution of an\namino acid in a protein sequence. Currently, missense mutations account for\napproximately half of the known variants responsible for human inherited\ndiseases, but accurate prediction of the pathogenicity of missense variants is\nstill challenging. Recent advances in deep learning show that transformer\nmodels are particularly powerful at modeling sequences. In this study, we\nintroduce MutFormer, a transformer-based model for prediction of pathogenic\nmissense mutations. We pre-trained MutFormer on reference protein sequences and\nalternative protein sequences result from common genetic variants. We tested\ndifferent fine-tuning methods for pathogenicity prediction. Our results show\nthat MutFormer outperforms a variety of existing tools. MutFormer and\npre-computed variant scores are publicly available on GitHub at\nhttps://github.com/WGLab/mutformer.",
    "descriptor": "\nComments: 15 pages, 4 figures, 4 tables\n",
    "authors": [
      "Theodore Jiang",
      "Li Fang",
      "Kai Wang"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2110.14746"
  },
  {
    "id": "arXiv:2110.14753",
    "title": "Subtleties in the trainability of quantum machine learning models",
    "abstract": "A new paradigm for data science has emerged, with quantum data, quantum\nmodels, and quantum computational devices. This field, called Quantum Machine\nLearning (QML), aims to achieve a speedup over traditional machine learning for\ndata analysis. However, its success usually hinges on efficiently training the\nparameters in quantum neural networks, and the field of QML is still lacking\ntheoretical scaling results for their trainability. Some trainability results\nhave been proven for a closely related field called Variational Quantum\nAlgorithms (VQAs). While both fields involve training a parametrized quantum\ncircuit, there are crucial differences that make the results for one setting\nnot readily applicable to the other. In this work we bridge the two frameworks\nand show that gradient scaling results for VQAs can also be applied to study\nthe gradient scaling of QML models. Our results indicate that features deemed\ndetrimental for VQA trainability can also lead to issues such as barren\nplateaus in QML. Consequently, our work has implications for several QML\nproposals in the literature. In addition, we provide theoretical and numerical\nevidence that QML models exhibit further trainability issues not present in\nVQAs, arising from the use of a training dataset. We refer to these as\ndataset-induced barren plateaus. These results are most relevant when dealing\nwith classical data, as here the choice of embedding scheme (i.e., the map\nbetween classical data and quantum states) can greatly affect the gradient\nscaling.",
    "descriptor": "\nComments: 12+12 pages, 8+2 figures\n",
    "authors": [
      "Supanut Thanasilp",
      "Samson Wang",
      "Nhat A. Nghiem",
      "Patrick J. Coles",
      "M. Cerezo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.14753"
  },
  {
    "id": "arXiv:2110.14787",
    "title": "SCALP -- Supervised Contrastive Learning for Cardiopulmonary Disease  Classification and Localization in Chest X-rays using Patient Metadata",
    "abstract": "Computer-aided diagnosis plays a salient role in more accessible and accurate\ncardiopulmonary diseases classification and localization on chest radiography.\nMillions of people get affected and die due to these diseases without an\naccurate and timely diagnosis. Recently proposed contrastive learning heavily\nrelies on data augmentation, especially positive data augmentation. However,\ngenerating clinically-accurate data augmentations for medical images is\nextremely difficult because the common data augmentation methods in computer\nvision, such as sharp, blur, and crop operations, can severely alter the\nclinical settings of medical images. In this paper, we proposed a novel and\nsimple data augmentation method based on patient metadata and supervised\nknowledge to create clinically accurate positive and negative augmentations for\nchest X-rays. We introduce an end-to-end framework, SCALP, which extends the\nself-supervised contrastive approach to a supervised setting. Specifically,\nSCALP pulls together chest X-rays from the same patient (positive keys) and\npushes apart chest X-rays from different patients (negative keys). In addition,\nit uses ResNet-50 along with the triplet-attention mechanism to identify\ncardiopulmonary diseases, and Grad-CAM++ to highlight the abnormal regions. Our\nextensive experiments demonstrate that SCALP outperforms existing baselines\nwith significant margins in both classification and localization tasks.\nSpecifically, the average classification AUCs improve from 82.8% (SOTA using\nDenseNet-121) to 83.9% (SCALP using ResNet-50), while the localization results\nimprove on average by 3.7% over different IoU thresholds.",
    "descriptor": "",
    "authors": [
      "Ajay Jaiswal",
      "Tianhao Li",
      "Cyprian Zander",
      "Yan Han",
      "Justin F. Rousseau",
      "Yifan Peng",
      "Ying Ding"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.14787"
  },
  {
    "id": "arXiv:2110.14800",
    "title": "Convolutional Deep Exponential Families",
    "abstract": "We describe convolutional deep exponential families (CDEFs) in this paper.\nCDEFs are built based on deep exponential families, deep probabilistic models\nthat capture the hierarchical dependence between latent variables. CDEFs\ngreatly reduce the number of free parameters by tying the weights of DEFs. Our\nexperiments show that CDEFs are able to uncover time correlations with a small\namount of data.",
    "descriptor": "",
    "authors": [
      "Chengkuan Hong",
      "Christian R. Shelton"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14800"
  },
  {
    "id": "arXiv:2110.14804",
    "title": "Minimax Optimal Quantile and Semi-Adversarial Regret via  Root-Logarithmic Regularizers",
    "abstract": "Quantile (and, more generally, KL) regret bounds, such as those achieved by\nNormalHedge (Chaudhuri, Freund, and Hsu 2009) and its variants, relax the goal\nof competing against the best individual expert to only competing against a\nmajority of experts on adversarial data. More recently, the semi-adversarial\nparadigm (Bilodeau, Negrea, and Roy 2020) provides an alternative relaxation of\nadversarial online learning by considering data that may be neither fully\nadversarial nor stochastic (i.i.d.). We achieve the minimax optimal regret in\nboth paradigms using FTRL with separate, novel, root-logarithmic regularizers,\nboth of which can be interpreted as yielding variants of NormalHedge. We extend\nexisting KL regret upper bounds, which hold uniformly over target\ndistributions, to possibly uncountable expert classes with arbitrary priors;\nprovide the first full-information lower bounds for quantile regret on finite\nexpert classes (which are tight); and provide an adaptively minimax optimal\nalgorithm for the semi-adversarial paradigm that adapts to the true, unknown\nconstraint faster, leading to uniformly improved regret bounds over existing\nmethods.",
    "descriptor": "\nComments: 30 pages, 2 figures. Jeffrey Negrea and Blair Bilodeau are equal-contribution authors\n",
    "authors": [
      "Jeffrey Negrea",
      "Blair Bilodeau",
      "Nicol\u00f2 Campolongo",
      "Francesco Orabona",
      "Daniel M. Roy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14804"
  },
  {
    "id": "arXiv:2110.14838",
    "title": "Continuous Speech Separation with Recurrent Selective Attention Network",
    "abstract": "While permutation invariant training (PIT) based continuous speech separation\n(CSS) significantly improves the conversation transcription accuracy, it often\nsuffers from speech leakages and failures in separation at \"hot spot\" regions\nbecause it has a fixed number of output channels. In this paper, we propose to\napply recurrent selective attention network (RSAN) to CSS, which generates a\nvariable number of output channels based on active speaker counting. In\naddition, we propose a novel block-wise dependency extension of RSAN by\nintroducing dependencies between adjacent processing blocks in the CSS\nframework. It enables the network to utilize the separation results from the\nprevious blocks to facilitate the current block processing. Experimental\nresults on the LibriCSS dataset show that the RSAN-based CSS (RSAN-CSS) network\nconsistently improves the speech recognition accuracy over PIT-based models.\nThe proposed block-wise dependency modeling further boosts the performance of\nRSAN-CSS.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Yixuan Zhang",
      "Zhuo Chen",
      "Jian Wu",
      "Takuya Yoshioka",
      "Peidong Wang",
      "Zhong Meng",
      "Jinyu Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.14838"
  },
  {
    "id": "arXiv:2110.14842",
    "title": "Ultimate Limits of Quantum Channel Discrimination",
    "abstract": "This paper studies the difficulty of discriminating quantum channels under\noperational regimes, proves the quantum channel Stein's lemma (strong converse\npart), and provides a unified framework to show the operational meaning of\nquantum channel divergences. First, we establish the exponentially strong\nconverse of quantum channel hypothesis testing under coherent strategies,\nmeaning that any strategy to make the Type II error decays with an exponent\nlarger than the regularized channel relative entropy will unavoidably result in\nthe Type I error converging to one exponentially fast in the asymptotic limit.\nThis result notably delivers the desirable quantum channel Stein's Lemma,\nenclosing a long-term open problem in quantum information theory. As a\nbyproduct, we show the continuity of the regularized (amortized) Sandwiched\nR\\'{e}nyi channel divergence at $\\alpha=1$, resolving another open problem in\nthe field. Second, we develop a framework to show the interplay between the\nstrategies of channel discrimination, the operational regimes, and variants of\nchannel divergences. This framework systematically underlies the operational\nmeaning of quantum channel divergences in quantum channel discrimination. Our\nwork establishes the ultimate limit of quantum channel discrimination,\ndeepening our understanding of quantum channel discrimination and quantum\nchannel divergences in the asymptotic regime. As quantum channel discrimination\nis strongly connected to many other fundamental tasks in quantum information\ntheory, we expect plentiful applications on related topics such as quantum\nmetrology and quantum communication.",
    "descriptor": "\nComments: 31 pages, 2 figures; comments are welcome\n",
    "authors": [
      "Kun Fang",
      "Gilad Gour",
      "Xin Wang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.14842"
  },
  {
    "id": "arXiv:2110.14846",
    "title": "Generalizability of density functionals learned from differentiable  programming on weakly correlated spin-polarized systems",
    "abstract": "Kohn-Sham regularizer (KSR) is a machine learning approach that optimizes a\nphysics-informed exchange-correlation functional within a differentiable\nKohn-Sham density functional theory framework. We evaluate the generalizability\nof KSR by training on atomic systems and testing on molecules at equilibrium.\nWe propose a spin-polarized version of KSR with local, semilocal, and nonlocal\napproximations for the exchange-correlation functional. The generalization\nerror from our semilocal approximation is comparable to other differentiable\napproaches. Our nonlocal functional outperforms any existing machine learning\nfunctionals by predicting the ground-state energies of the test systems with a\nmean absolute error of 2.7 milli-Hartrees.",
    "descriptor": "\nComments: Accepted as a conference paper in NeurIPS workshop on differentiable programming, 2021\n",
    "authors": [
      "Bhupalee Kalita",
      "Ryan Pederson",
      "Li Li",
      "Kieron Burke"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14846"
  },
  {
    "id": "arXiv:2110.14848",
    "title": "V2iFi: in-Vehicle Vital Sign Monitoring via Compact RF Sensing",
    "abstract": "Given the significant amount of time people spend in vehicles, health issues\nunder driving condition have become a major concern. Such issues may vary from\nfatigue, asthma, stroke, to even heart attack, yet they can be adequately\nindicated by vital signs and abnormal activities. Therefore, in-vehicle vital\nsign monitoring can help us predict and hence prevent these issues. Whereas\nexisting sensor-based (including camera) methods could be used to detect these\nindicators, privacy concern and system complexity both call for a convenient\nyet effective and robust alternative. This paper aims to develop V2iFi, an\nintelligent system performing monitoring tasks using a COTS impulse radio\nmounted on the windshield. V2iFi is capable of reliably detecting driver's\nvital signs under driving condition and with the presence of passengers, thus\nallowing for potentially inferring corresponding health issues. Compared with\nprior work based on Wi-Fi CSI, V2iFi is able to distinguish reflected signals\nfrom multiple users, and hence provide finer-grained measurements under more\nrealistic settings. We evaluate V2iFi both in lab environments and during\nreal-life road tests; the results demonstrate that respiratory rate, heart\nrate, and heart rate variability can all be estimated accurately. Based on\nthese estimation results, we further discuss how machine learning models can be\napplied on top of V2iFi so as to improve both physiological and psychological\nwellbeing in driving environments.",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Tianyue Zheng",
      "Zhe Chen",
      "Chao Cai",
      "Jun Luo",
      "Xu Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.14848"
  },
  {
    "id": "arXiv:2110.14849",
    "title": "Enhancing RF Sensing with Deep Learning: A Layered Approach",
    "abstract": "In recent years, radio frequency (RF) sensing has gained increasing\npopularity due to its pervasiveness, low cost, non-intrusiveness, and privacy\npreservation. However, realizing the promises of RF sensing is highly\nnontrivial, given typical challenges such as multipath and interference. One\npotential solution leverages deep learning to build direct mappings from the RF\ndomain to target domains, hence avoiding complex RF physical modeling. While\nearlier solutions exploit only simple feature extraction and classification\nmodules, an emerging trend adds functional layers on top of elementary modules\nfor more powerful generalizability and flexible applicability. To better\nunderstand this potential, this article takes a layered approach to summarize\nRF sensing enabled by deep learning. Essentially, we present a four-layer\nframework: physical, backbone, generalization, and application. While this\nlayered framework provides readers a systematic methodology for designing deep\ninterpreted RF sensing, it also facilitates making improvement proposals and\nhints at future research opportunities.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Tianyue Zheng",
      "Zhe Chen",
      "Shuya Ding",
      "Jun Luo"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.14849"
  },
  {
    "id": "arXiv:2110.14868",
    "title": "An $\\ell^p$-based Kernel Conditional Independence Test",
    "abstract": "We propose a new computationally efficient test for conditional independence\nbased on the $L^{p}$ distance between two kernel-based representatives of well\nsuited distributions. By evaluating the difference of these two representatives\nat a finite set of locations, we derive a finite dimensional approximation of\nthe $L^{p}$ metric, obtain its asymptotic distribution under the null\nhypothesis of conditional independence and design a simple statistical test\nfrom it. The test obtained is consistent and computationally efficient. We\nconduct a series of experiments showing that the performance of our new tests\noutperforms state-of-the-art methods both in term of statistical power and\ntype-I error even in the high dimensional setting.",
    "descriptor": "",
    "authors": [
      "Meyer Scetbon",
      "Laurent Meunier",
      "Yaniv Romano"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14868"
  },
  {
    "id": "arXiv:2110.14881",
    "title": "Convergence of Conditional Entropy for Long Range Dependent Markov  Chains",
    "abstract": "In this paper we consider the convergence of the conditional entropy to the\nentropy rate for Markov chains. Convergence of certain statistics of long range\ndependent processes, such as the sample mean, is slow. It has been shown in\nCarpio and Daley \\cite{carpio2007long} that the convergence of the $n$-step\ntransition probabilities to the stationary distribution is slow, without\nquantifying the convergence rate. We prove that the slow convergence also\napplies to convergence to an information-theoretic measure, the entropy rate,\nby showing that the convergence rate is equivalent to the convergence rate of\nthe $n$-step transition probabilities to the stationary distribution, which is\nequivalent to the Markov chain mixing time problem. Then we quantify this\nconvergence rate, and show that it is $O(n^{2H-2})$, where $n$ is the number of\nsteps of the Markov chain and $H$ is the Hurst parameter. Finally, we show that\ndue to this slow convergence, the mutual information between past and future is\ninfinite if and only if the Markov chain is long range dependent. This is a\ndiscrete analogue of characterisations which have been shown for other long\nrange dependent processes.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Andrew Feutrill",
      "Matthew Roughan"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.14881"
  },
  {
    "id": "arXiv:2110.14899",
    "title": "Degraded Reference Image Quality Assessment",
    "abstract": "In practical media distribution systems, visual content usually undergoes\nmultiple stages of quality degradation along the delivery chain, but the\npristine source content is rarely available at most quality monitoring points\nalong the chain to serve as a reference for quality assessment. As a result,\nfull-reference (FR) and reduced-reference (RR) image quality assessment (IQA)\nmethods are generally infeasible. Although no-reference (NR) methods are\nreadily applicable, their performance is often not reliable. On the other hand,\nintermediate references of degraded quality are often available, e.g., at the\ninput of video transcoders, but how to make the best use of them in proper ways\nhas not been deeply investigated. Here we make one of the first attempts to\nestablish a new paradigm named degraded-reference IQA (DR IQA). Specifically,\nwe lay out the architectures of DR IQA and introduce a 6-bit code to denote the\nchoices of configurations. We construct the first large-scale databases\ndedicated to DR IQA and will make them publicly available. We make novel\nobservations on distortion behavior in multi-stage distortion pipelines by\ncomprehensively analyzing five multiple distortion combinations. Based on these\nobservations, we develop novel DR IQA models and make extensive comparisons\nwith a series of baseline models derived from top-performing FR and NR models.\nThe results suggest that DR IQA may offer significant performance improvement\nin multiple distortion environments, thereby establishing DR IQA as a valid IQA\nparadigm that is worth further exploration.",
    "descriptor": "\nComments: 15 pages, 11 figures, 9 tables\n",
    "authors": [
      "Shahrukh Athar",
      "Zhou Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.14899"
  },
  {
    "id": "arXiv:2110.14910",
    "title": "Diagnosis of COVID-19 Using Machine Learning and Deep Learning: A review",
    "abstract": "Background: This paper provides a systematic review of the application of\nArtificial Intelligence (AI) in the form of Machine Learning (ML) and Deep\nLearning (DL) techniques in fighting against the effects of novel coronavirus\ndisease (COVID-19). Objective & Methods: The objective is to perform a scoping\nreview on AI for COVID-19 using preferred reporting items of systematic reviews\nand meta-analysis (PRISMA) guidelines. A literature search was performed for\nrelevant studies published from 1 January 2020 till 27 March 2021. Out of 4050\nresearch papers available in reputed publishers, a full-text review of 440\narticles was done based on the keywords of AI, COVID-19, ML, forecasting, DL,\nX-ray, and Computed Tomography (CT). Finally, 52 articles were included in the\nresult synthesis of this paper. As part of the review, different ML regression\nmethods were reviewed first in predicting the number of confirmed and death\ncases. Secondly, a comprehensive survey was carried out on the use of ML in\nclassifying COVID-19 patients. Thirdly, different datasets on medical imaging\nwere compared in terms of the number of images, number of positive samples and\nnumber of classes in the datasets. The different stages of the diagnosis,\nincluding preprocessing, segmentation and feature extraction were also\nreviewed. Fourthly, the performance results of different research papers were\ncompared to evaluate the effectiveness of DL methods on different datasets.\nResults: Results show that residual neural network (ResNet-18) and densely\nconnected convolutional network (DenseNet 169) exhibit excellent classification\naccuracy for X-ray images, while DenseNet-201 has the maximum accuracy in\nclassifying CT scan images. This indicates that ML and DL are useful tools in\nassisting researchers and medical professionals in predicting, screening and\ndetecting COVID-19.",
    "descriptor": "\nComments: 17 Pages, 3 Figures\n",
    "authors": [
      "M. Rubaiyat Hossain Mondal",
      "Subrato Bharati",
      "Prajoy Podder"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.14910"
  },
  {
    "id": "arXiv:2110.14914",
    "title": "Trading via Selective Classification",
    "abstract": "A binary classifier that tries to predict if the price of an asset will\nincrease or decrease naturally gives rise to a trading strategy that follows\nthe prediction and thus always has a position in the market. Selective\nclassification extends a binary or many-class classifier to allow it to abstain\nfrom making a prediction for certain inputs, thereby allowing a trade-off\nbetween the accuracy of the resulting selective classifier against coverage of\nthe input feature space. Selective classifiers give rise to trading strategies\nthat do not take a trading position when the classifier abstains. We\ninvestigate the application of binary and ternary selective classification to\ntrading strategy design. For ternary classification, in addition to classes for\nthe price going up or down, we include a third class that corresponds to\nrelatively small price moves in either direction, and gives the classifier\nanother way to avoid making a directional prediction. We use a walk-forward\ntrain-validate-test approach to evaluate and compare binary and ternary,\nselective and non-selective classifiers across several different feature sets\nbased on four classification approaches: logistic regression, random forests,\nfeed-forward, and recurrent neural networks. We then turn these classifiers\ninto trading strategies for which we perform backtests on commodity futures\nmarkets. Our empirical results demonstrate the potential of selective\nclassification for trading.",
    "descriptor": "\nComments: (8 pages, 6 figures, 4 tables, ICAIF'21)\n",
    "authors": [
      "Nestoras Chalkidis",
      "Rahul Savani"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14914"
  },
  {
    "id": "arXiv:2110.14920",
    "title": "Meta Subspace Optimization",
    "abstract": "Subspace optimization methods have the attractive property of reducing\nlarge-scale optimization problems to a sequence of low-dimensional subspace\noptimization problems. However, existing subspace optimization frameworks adopt\na fixed update policy of the subspace, and therefore, appear to be sub-optimal.\nIn this paper we propose a new \\emph{Meta Subspace Optimization} (MSO)\nframework for large-scale optimization problems, which allows to determine the\nsubspace matrix at each optimization iteration. In order to remain invariant to\nthe optimization problem's dimension, we design an efficient meta optimizer\nbased on very low-dimensional subspace optimization coefficients, inducing a\nrule-based agent that can significantly improve performance. Finally, we design\nand analyze a reinforcement learning procedure based on the subspace\noptimization dynamics whose learnt policies outperform existing subspace\noptimization methods.",
    "descriptor": "",
    "authors": [
      "Yoni Choukroun",
      "Michael Katz"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14920"
  },
  {
    "id": "arXiv:2110.14927",
    "title": "Counterfactual Explanation of Brain Activity Classifiers using  Image-to-Image Transfer by Generative Adversarial Network",
    "abstract": "Deep neural networks (DNNs) can accurately decode task-related information\nfrom brain activations. However, because of the nonlinearity of the DNN, the\ndecisions made by DNNs are hardly interpretable. One of the promising\napproaches for explaining such a black-box system is counterfactual\nexplanation. In this framework, the behavior of a black-box system is explained\nby comparing real data and realistic synthetic data that are specifically\ngenerated such that the black-box system outputs an unreal outcome. Here we\nintroduce a novel generative DNN (counterfactual activation generator, CAG)\nthat can provide counterfactual explanations for DNN-based classifiers of brain\nactivations. Importantly, CAG can simultaneously handle image transformation\namong multiple classes associated with different behavioral tasks. Using CAG,\nwe demonstrated counterfactual explanation of DNN-based classifiers that\nlearned to discriminate brain activations of seven behavioral tasks.\nFurthermore, by iterative applications of CAG, we were able to enhance and\nextract subtle spatial brain activity patterns that affected the classifier's\ndecisions. Together, these results demonstrate that the counterfactual\nexplanation based on image-to-image transformation would be a promising\napproach to understand and extend the current application of DNNs in fMRI\nanalyses.",
    "descriptor": "\nComments: 28 pages, 6 figures, 3 tables, 2 supplementary figures, 1 supplementary table\n",
    "authors": [
      "Teppei Matsui",
      "Masato Taki",
      "Trung Quang Pham",
      "Junichi Chikazoe",
      "Koji Jimura"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14927"
  },
  {
    "id": "arXiv:2110.14947",
    "title": "Probabilistic Autoencoder using Fisher Information",
    "abstract": "Neural Networks play a growing role in many science disciplines, including\nphysics. Variational Autoencoders (VAEs) are neural networks that are able to\nrepresent the essential information of a high dimensional data set in a low\ndimensional latent space, which have a probabilistic interpretation. In\nparticular the so-called encoder network, the first part of the VAE, which maps\nits input onto a position in latent space, additionally provides uncertainty\ninformation in terms of a variance around this position. In this work, an\nextension to the Autoencoder architecture is introduced, the FisherNet. In this\narchitecture, the latent space uncertainty is not generated using an additional\ninformation channel in the encoder, but derived from the decoder, by means of\nthe Fisher information metric. This architecture has advantages from a\ntheoretical point of view as it provides a direct uncertainty quantification\nderived from the model, and also accounts for uncertainty cross-correlations.\nWe can show experimentally that the FisherNet produces more accurate data\nreconstructions than a comparable VAE and its learning performance also\napparently scales better with the number of latent space dimensions.",
    "descriptor": "\nComments: 23 pages, 10 figures\n",
    "authors": [
      "Johannes Zacherl",
      "Philipp Frank",
      "Torsten A. En\u00dflin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14947"
  },
  {
    "id": "arXiv:2110.14975",
    "title": "Model-based electron density profile estimation and control, applied to  ITER",
    "abstract": "In contemporary magnetic confinement devices, the density distribution is\nsensed with interferometers and actuated with feedback controlled gas injection\nand open-loop pellet injection. This is at variance with the density control\nfor ITER and DEMO, that will depend mainly on pellet injection as an actuator\nin feed-back control. This paper presents recent developments in state\nestimation and control of the electron density profile for ITER using relevant\nsensors and actuators. As a first step, Thomson scattering is included in an\nexisting dynamic state observer. Second, model predictive control is developed\nas a strategy to regulate the density profile while avoiding limits associated\nwith the total density (Greenwald limit) or gradients in the density\ndistribution (e.g. neo-classical impurity transport). Simulations show that\nhigh quality density profile estimation can be achieved with Thomson Scattering\nand that the controller is capable of regulating the distribution as desired.",
    "descriptor": "",
    "authors": [
      "T. O. S. J. Bosman",
      "M. van Berkel",
      "M. R. de Baar"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.14975"
  },
  {
    "id": "arXiv:2110.15013",
    "title": "Deeptime: a Python library for machine learning dynamical models from  time series data",
    "abstract": "Generation and analysis of time-series data is relevant to many quantitative\nfields ranging from economics to fluid mechanics. In the physical sciences,\nstructures such as metastable and coherent sets, slow relaxation processes,\ncollective variables dominant transition pathways or manifolds and channels of\nprobability flow can be of great importance for understanding and\ncharacterizing the kinetic, thermodynamic and mechanistic properties of the\nsystem. Deeptime is a general purpose Python library offering various tools to\nestimate dynamical models based on time-series data including conventional\nlinear learning methods, such as Markov state models (MSMs), Hidden Markov\nModels and Koopman models, as well as kernel and deep learning approaches such\nas VAMPnets and deep MSMs. The library is largely compatible with scikit-learn,\nhaving a range of Estimator classes for these different models, but in contrast\nto scikit-learn also provides deep Model classes, e.g. in the case of an MSM,\nwhich provide a multitude of analysis methods to compute interesting\nthermodynamic, kinetic and dynamical quantities, such as free energies,\nrelaxation times and transition paths. The library is designed for ease of use\nbut also easily maintainable and extensible code. In this paper we introduce\nthe main features and structure of the deeptime software.",
    "descriptor": "",
    "authors": [
      "Moritz Hoffmann",
      "Martin Scherer",
      "Tim Hempel",
      "Andreas Mardt",
      "Brian de Silva",
      "Brooke E. Husic",
      "Stefan Klus",
      "Hao Wu",
      "Nathan Kutz",
      "Steven L. Brunton",
      "Frank No\u00e9"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)",
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.15013"
  },
  {
    "id": "arXiv:2110.15018",
    "title": "TorchAudio: Building Blocks for Audio and Speech Processing",
    "abstract": "This document describes version 0.10 of torchaudio: building blocks for\nmachine learning applications in the audio and speech processing domain. The\nobjective of torchaudio is to accelerate the development and deployment of\nmachine learning applications for researchers and engineers by providing\noff-the-shelf building blocks. The building blocks are designed to be\nGPU-compatible, automatically differentiable, and production-ready. torchaudio\ncan be easily installed from Python Package Index repository and the source\ncode is publicly available under a BSD-2-Clause License (as of September 2021)\nat https://github.com/pytorch/audio. In this document, we provide an overview\nof the design principles, functionalities, and benchmarks of torchaudio. We\nalso benchmark our implementation of several audio and speech operations and\nmodels. We verify through the benchmarks that our implementations of various\noperations and models are valid and perform similarly to other publicly\navailable implementations.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Yao-Yuan Yang",
      "Moto Hira",
      "Zhaoheng Ni",
      "Anjali Chourdia",
      "Artyom Astafurov",
      "Caroline Chen",
      "Ching-Feng Yeh",
      "Christian Puhrsch",
      "David Pollack",
      "Dmitriy Genzel",
      "Donny Greenberg",
      "Edward Z. Yang",
      "Jason Lian",
      "Jay Mahadeokar",
      "Jeff Hwang",
      "Ji Chen",
      "Peter Goldsborough",
      "Prabhat Roy",
      "Sean Narenthiran",
      "Shinji Watanabe",
      "Soumith Chintala",
      "Vincent Quenneville-B\u00e9lair",
      "Yangyang Shi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.15018"
  },
  {
    "id": "arXiv:2110.15066",
    "title": "Thermodynamics of Evolution and the Origin of Life",
    "abstract": "We outline a phenomenological theory of evolution and origin of life by\ncombining the formalism of classical thermodynamics with a statistical\ndescription of learning. The maximum entropy principle constrained by the\nrequirement for minimization of the loss function is employed to derive a\ncanonical ensemble of organisms (population), the corresponding partition\nfunction (macroscopic counterpart of fitness) and free energy (macroscopic\ncounterpart of additive fitness). We further define the biological counterparts\nof temperature (biological temperature) as the measure of stochasticity of the\nevolutionary process and of chemical potential (evolutionary potential) as the\namount of evolutionary work required to add a new trainable variable (such as\nan additional gene) to the evolving system. We then develop a phenomenological\napproach to the description of evolution, which involves modeling the grand\npotential as a function of the biological temperature and evolutionary\npotential. We demonstrate how this phenomenological approach can be used to\nstudy the \"ideal mutation\" model of evolution and its generalizations. Finally,\nwe show that, within this thermodynamics framework, major transitions in\nevolution, such as the transition from an ensemble of molecules to an ensemble\nof organisms, that is, the origin of life, can be modeled as a special case of\nbona fide physical phase transitions that are associated with the emergence of\na new type of grand canonical ensemble and the corresponding new level of\ndescription",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Vitaly Vanchurin",
      "Yuri I. Wolf",
      "Eugene V. Koonin",
      "Mikhail I. Katsnelson"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15066"
  },
  {
    "id": "arXiv:2110.15073",
    "title": "MMD Aggregated Two-Sample Test",
    "abstract": "We propose a novel nonparametric two-sample test based on the Maximum Mean\nDiscrepancy (MMD), which is constructed by aggregating tests with different\nkernel bandwidths. This aggregation procedure, called MMDAgg, ensures that test\npower is maximised over the collection of kernels used, without requiring\nheld-out data for kernel selection (which results in a loss of test power), or\narbitrary kernel choices such as the median heuristic. We work in the\nnon-asymptotic framework, and prove that our aggregated test is minimax\nadaptive over Sobolev balls. Our guarantees are not restricted to a specific\nkernel, but hold for any product of one-dimensional translation invariant\ncharacteristic kernels which are absolutely and square integrable. Moreover,\nour results apply for popular numerical procedures to determine the test\nthreshold, namely permutations and the wild bootstrap. Through numerical\nexperiments on both synthetic and real-world datasets, we demonstrate that\nMMDAgg outperforms alternative state-of-the-art approaches to MMD kernel\nadaptation for two-sample testing.",
    "descriptor": "\nComments: 71 pages\n",
    "authors": [
      "Antonin Schrab",
      "Ilmun Kim",
      "M\u00e9lisande Albert",
      "B\u00e9atrice Laurent",
      "Benjamin Guedj",
      "Arthur Gretton"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.15073"
  },
  {
    "id": "arXiv:2110.15084",
    "title": "Using Non-Linear Causal Models to Study Aerosol-Cloud Interactions in  the Southeast Pacific",
    "abstract": "Aerosol-cloud interactions include a myriad of effects that all begin when\naerosol enters a cloud and acts as cloud condensation nuclei (CCN). An increase\nin CCN results in a decrease in the mean cloud droplet size (r$_{e}$). The\nsmaller droplet size leads to brighter, more expansive, and longer lasting\nclouds that reflect more incoming sunlight, thus cooling the earth. Globally,\naerosol-cloud interactions cool the Earth, however the strength of the effect\nis heterogeneous over different meteorological regimes. Understanding how\naerosol-cloud interactions evolve as a function of the local environment can\nhelp us better understand sources of error in our Earth system models, which\ncurrently fail to reproduce the observed relationships. In this work we use\nrecent non-linear, causal machine learning methods to study the heterogeneous\neffects of aerosols on cloud droplet radius.",
    "descriptor": "",
    "authors": [
      "Andrew Jesson",
      "Peter Manshausen",
      "Alyson Douglas",
      "Duncan Watson-Parris",
      "Yarin Gal",
      "Philip Stier"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2110.15084"
  },
  {
    "id": "arXiv:2110.15133",
    "title": "Deep Calibration of Interest Rates Model",
    "abstract": "For any financial institution it is a necessity to be able to apprehend the\nbehavior of interest rates. Despite the use of Deep Learning that is growing\nvery fastly, due to many reasons (expertise, ease of use, ...) classic rates\nmodels such as CIR, or the Gaussian family are still being used widely. We\npropose to calibrate the five parameters of the G2++ model using Neural\nNetworks. To achieve that, we construct synthetic data sets of parameters drawn\nuniformly from a reference set of parameters calibrated from the market. From\nthose parameters, we compute Zero-Coupon and Forward rates and their\ncovariances and correlations. Our first model is a Fully Connected Neural\nnetwork and uses only covariances and correlations. We show that covariances\nare more suited to the problem than correlations. The second model is a\nConvulutional Neural Network using only Zero-Coupon rates with no\ntransformation. The methods we propose perform very quickly (less than 0.3\nseconds for 2 000 calibrations) and have low errors and good fitting.",
    "descriptor": "",
    "authors": [
      "Mohamed Ben Alaya",
      "Ahmed Kebaier",
      "Djibril Sarr"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15133"
  },
  {
    "id": "arXiv:2110.15144",
    "title": "Deep Learning Analysis of Cardiac MRI in Legacy Datasets: Multi-Ethnic  Study of Atherosclerosis",
    "abstract": "The shape and motion of the heart provide essential clues to understanding\nthe mechanisms of cardiovascular disease. With the advent of large-scale\ncardiac imaging data, statistical atlases become a powerful tool to provide\nautomated and precise quantification of the status of patient-specific heart\ngeometry with respect to reference populations. The Multi-Ethnic Study of\nAtherosclerosis (MESA), begun in 2000, was the first large cohort study to\nincorporate cardiovascular MRI in over 5000 participants, and there is now a\nwealth of follow-up data over 20 years. Building a machine learning based\nautomated analysis is necessary to extract the additional imaging information\nnecessary for expanding original manual analyses. However, machine learning\ntools trained on MRI datasets with different pulse sequences fail on such\nlegacy datasets. Here, we describe an automated atlas construction pipeline\nusing deep learning methods applied to the legacy cardiac MRI data in MESA. For\ndetection of anatomical cardiac landmark points, a modified VGGNet\nconvolutional neural network architecture was used in conjunction with a\ntransfer learning sequence between two-chamber, four-chamber, and short-axis\nMRI views. A U-Net architecture was used for detection of the endocardial and\nepicardial boundaries in short axis images. Both network architectures resulted\nin good segmentation and landmark detection accuracies compared with\ninter-observer variations. Statistical relationships with common risk factors\nwere similar between atlases derived from automated vs manual annotations. The\nautomated atlas can be employed in future studies to examine the relationships\nbetween cardiac morphology and future events.",
    "descriptor": "",
    "authors": [
      "Avan Suinesiaputra",
      "Charlene A Mauger",
      "Bharath Ambale-Venkatesh",
      "David A Bluemke",
      "Josefine Dam Gade",
      "Kathleen Gilbert",
      "Mark Janse",
      "Line Sofie Hald",
      "Conrad Werkhoven",
      "Colin Wu",
      "Joao A Lima",
      "Alistair A Young"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.15144"
  },
  {
    "id": "arXiv:2110.15148",
    "title": "A first-order primal-dual method with adaptivity to local smoothness",
    "abstract": "We consider the problem of finding a saddle point for the convex-concave\nobjective $\\min_x \\max_y f(x) + \\langle Ax, y\\rangle - g^*(y)$, where $f$ is a\nconvex function with locally Lipschitz gradient and $g$ is convex and possibly\nnon-smooth. We propose an adaptive version of the Condat-V\\~u algorithm, which\nalternates between primal gradient steps and dual proximal steps. The method\nachieves stepsize adaptivity through a simple rule involving $\\|A\\|$ and the\nnorm of recently computed gradients of $f$. Under standard assumptions, we\nprove an $\\mathcal{O}(k^{-1})$ ergodic convergence rate. Furthermore, when $f$\nis also locally strongly convex and $A$ has full row rank we show that our\nmethod converges with a linear rate. Numerical experiments are provided for\nillustrating the practical performance of the algorithm.",
    "descriptor": "",
    "authors": [
      "Maria-Luiza Vladarean",
      "Yura Malitsky",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15148"
  },
  {
    "id": "arXiv:2110.15162",
    "title": "Exoplanet atmosphere evolution: emulation with random forests",
    "abstract": "Atmospheric mass-loss is known to play a leading role in sculpting the\ndemographics of small, close-in exoplanets. Understanding the impact of such\nmass-loss driven evolution requires modelling large populations of planets to\ncompare with the observed exoplanet distributions. As the quality of planet\nobservations increases, so should the accuracy of the models used to understand\nthem. However, to date, only simple semi-analytic models have been used in such\ncomparisons since modelling populations of planets with high accuracy demands a\nhigh computational cost. To address this, we turn to machine learning. We\nimplement random forests trained on atmospheric evolution models, including XUV\nphotoevaporation, to predict a given planet's final radius and atmospheric\nmass. This evolution emulator is found to have an RMS fractional radius error\nof 1$\\%$ from the original models and is $\\sim 400$ times faster to evaluate.\nAs a test case, we use the emulator to infer the initial properties of\nKepler-36b and c, confirming that their architecture is consistent with\natmospheric mass loss. Our new approach opens the door to highly sophisticated\nmodels of atmospheric evolution being used in demographic analysis, which will\nyield further insight into planet formation and evolution.",
    "descriptor": "\nComments: 5 pages, 3 figures. Submitted to MNRAS letters\n",
    "authors": [
      "James G. Rogers",
      "Cl\u00e0udia Jan\u00f3 Mu\u00f1oz",
      "James E. Owen",
      "Richard A. Booth"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15162"
  },
  {
    "id": "arXiv:2110.15168",
    "title": "Labeled sample compression schemes for complexes of oriented matroids",
    "abstract": "We show that the topes of a complex of oriented matroids (abbreviated COM) of\nVC-dimension $d$ admit a proper labeled sample compression scheme of size $d$.\nThis considerably extends results of Moran and Warmuth and the authors and is a\nstep towards the sample compression conjecture -- one of the oldest open in\ncomputational learning theory. On the one hand, our approach exploits the rich\ncombinatorial cell structure of COMs via oriented matroid theory. On the other\nhand viewing tope graphs of COMs as partial cubes creates a fruitful link to\nmetric graph theory",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Victor Chepoi",
      "Kolja Knauer",
      "Manon Philibert"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15168"
  },
  {
    "id": "arXiv:2110.15200",
    "title": "Generating 3D Molecules Conditional on Receptor Binding Sites with Deep  Generative Models",
    "abstract": "The goal of structure-based drug discovery is to find small molecules that\nbind to a given target protein. Deep learning has been used to generate\ndrug-like molecules with certain cheminformatic properties, but has not yet\nbeen applied to generating 3D molecules predicted to bind to proteins by\nsampling the conditional distribution of protein-ligand binding interactions.\nIn this work, we describe for the first time a deep learning system for\ngenerating 3D molecular structures conditioned on a receptor binding site. We\napproach the problem using a conditional variational autoencoder trained on an\natomic density grid representation of cross-docked protein-ligand structures.\nWe apply atom fitting and bond inference procedures to construct valid\nmolecular conformations from generated atomic densities. We evaluate the\nproperties of the generated molecules and demonstrate that they change\nsignificantly when conditioned on mutated receptors. We also explore the latent\nspace learned by our generative model using sampling and interpolation\ntechniques. This work opens the door for end-to-end prediction of stable\nbioactive molecules from protein structures with deep learning.",
    "descriptor": "\nComments: Main: 12 pages, 7 figures; Supplement: 4 pages, 7 figures\n",
    "authors": [
      "Matthew Ragoza",
      "Tomohide Masuda",
      "David Ryan Koes"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15200"
  },
  {
    "id": "arXiv:2110.15219",
    "title": "A Robust Efficient Dynamic Mechanism",
    "abstract": "Athey and Segal introduced an efficient budget-balanced mechanism for a\ndynamic stochastic model with quasilinear payoffs and private values, using the\nsolution concept of perfect Bayesian equilibrium (PBE). However, this\nimplementation is not robust in multiple senses. For example, we will show a\ngeneric setup where the efficient strategy profiles can be eliminated by\niterative elimination of weakly dominated strategies. Furthermore, this model\nused strong assumptions about the information of the agents, and the mechanism\nwas not robust to the relaxation of these assumptions. In this paper, we will\nshow a different mechanism that implements efficiency under weaker assumptions\nand using the stronger solution concept of \"efficient Nash equilibrium with\nguaranteed expected payoffs\".",
    "descriptor": "",
    "authors": [
      "Endre Cs\u00f3ka"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.15219"
  },
  {
    "id": "arXiv:2110.15277",
    "title": "A Novel Sleep Stage Classification Using CNN Generated by an Efficient  Neural Architecture Search with a New Data Processing Trick",
    "abstract": "With the development of automatic sleep stage classification (ASSC)\ntechniques, many classical methods such as k-means, decision tree, and SVM have\nbeen used in automatic sleep stage classification. However, few methods explore\ndeep learning on ASSC. Meanwhile, most deep learning methods require extensive\nexpertise and suffer from a mass of handcrafted steps which are time-consuming\nespecially when dealing with multi-classification tasks. In this paper, we\npropose an efficient five-sleep-stage classification method using convolutional\nneural networks (CNNs) with a novel data processing trick and we design neural\narchitecture search (NAS) technique based on genetic algorithm (GA), NAS-G, to\nsearch for the best CNN architecture. Firstly, we attach each kernel with an\nadaptive coefficient to enhance the signal processing of the inputs. This can\nenhance the propagation of informative features and suppress the propagation of\nuseless features in the early stage of the network. Then, we make full use of\nGA's heuristic search and the advantage of no need for the gradient to search\nfor the best architecture of CNN. This can achieve a CNN with better\nperformance than a handcrafted one in a large search space at the minimum cost.\nWe verify the convergence of our data processing trick and compare the\nperformance of traditional CNNs before and after using our trick. Meanwhile, we\ncompare the performance between the CNN generated through NAS-G and the\ntraditional CNNs with our trick. The experiments demonstrate that the\nconvergence of CNNs with data processing trick is faster than without data\nprocessing trick and the CNN with data processing trick generated by NAS-G\noutperforms the handcrafted counterparts that use the data processing trick\ntoo.",
    "descriptor": "",
    "authors": [
      "Yu Xue",
      "Ziming Yuan",
      "Adam Slowik"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15277"
  },
  {
    "id": "arXiv:2110.15278",
    "title": "Self-supervised EEG Representation Learning for Automatic Sleep Staging",
    "abstract": "Objective: In this paper, we aim to learn robust vector representations from\nmassive unlabeled Electroencephalogram (EEG) signals, such that the learned\nrepresentations (1) are expressive enough to replace the raw signals in the\nsleep staging task; and (2) provide better predictive performance than\nsupervised models in scenarios of fewer labels and noisy samples.\nMaterials and Methods: We propose a self-supervised model, named Contrast\nwith the World Representation (ContraWR), for EEG signal representation\nlearning, which uses global statistics from the dataset to distinguish signals\nassociated with different sleep stages. The ContraWR model is evaluated on\nthree real-world EEG datasets that include both at-home and in-lab recording\nsettings.\nResults: ContraWR outperforms recent self-supervised learning methods, MoCo,\nSimCLR, BYOL, SimSiam on the sleep staging task across three datasets. ContraWR\nalso beats supervised learning when fewer training labels are available (e.g.,\n4% accuracy improvement when less than 2% data is labeled). Moreover, the model\nprovides informative representations in 2D projection.\nDiscussion: The proposed model can be generalized to other unsupervised\nphysiological signal learning tasks. Future directions include exploring\ntask-specific data augmentations and combining self-supervised with supervised\nmethods, building upon the initial success of self-supervised learning in this\npaper.\nConclusions: We show that ContraWR is robust to noise and can provide\nhigh-quality EEG representations for downstream prediction tasks. In low-label\nscenarios (e.g., only 2% data has labels), ContraWR shows much better\npredictive power (e.g., 4% improvement on sleep staging accuracy) than\nsupervised baselines.",
    "descriptor": "\nComments: The code is available here: this https URL\n",
    "authors": [
      "Chaoqi Yang",
      "Danica Xiao",
      "M. Brandon Westover",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15278"
  },
  {
    "id": "arXiv:2110.15279",
    "title": "SVM and ANN based Classification of EMG signals by using PCA and LDA",
    "abstract": "In recent decades, biomedical signals have been used for communication in\nHuman-Computer Interfaces (HCI) for medical applications; an instance of these\nsignals are the myoelectric signals (MES), which are generated in the muscles\nof the human body as unidimensional patterns. Because of this, the methods and\nalgorithms developed for pattern recognition in signals can be applied for\ntheir analyses once these signals have been sampled and turned into\nelectromyographic (EMG) signals. Additionally, in recent years, many\nresearchers have dedicated their efforts to studying prosthetic control\nutilizing EMG signal classification, that is, by logging a set of MES in a\nproper range of frequencies to classify the corresponding EMG signals. The\nfeature classification can be carried out on the time domain or by using other\ndomains such as the frequency domain (also known as the spectral domain), time\nscale, and time-frequency, amongst others. One of the main methods used for\npattern recognition in myoelectric signals is the Support Vector Machines (SVM)\ntechnique whose primary function is to identify an n-dimensional hyperplane to\nseparate a set of input feature points into different classes. This technique\nhas the potential to recognize complex patterns and on several occasions, it\nhas proven its worth when compared to other classifiers such as Artificial\nNeural Network (ANN), Linear Discriminant Analysis (LDA), and Principal\nComponent Analysis(PCA). The key concepts underlying the SVM are (a) the\nhyperplane separator; (b) the kernel function; (c) the optimal separation\nhyperplane; and (d) a soft margin (hyperplane tolerance).",
    "descriptor": "",
    "authors": [
      "Hritam Basak",
      "Alik Roy",
      "Jeet Bandhu Lahiri",
      "Sayantan Bose",
      "Soumyadeep Patra"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15279"
  },
  {
    "id": "arXiv:2110.15283",
    "title": "Decentralized Feature-Distributed Optimization for Generalized Linear  Models",
    "abstract": "We consider the \"all-for-one\" decentralized learning problem for generalized\nlinear models. The features of each sample are partitioned among several\ncollaborating agents in a connected network, but only one agent observes the\nresponse variables. To solve the regularized empirical risk minimization in\nthis distributed setting, we apply the Chambolle--Pock primal--dual algorithm\nto an equivalent saddle-point formulation of the problem. The primal and dual\niterations are either in closed-form or reduce to coordinate-wise minimization\nof scalar convex functions. We establish convergence rates for the empirical\nrisk minimization under two different assumptions on the loss function\n(Lipschitz and square root Lipschitz), and show how they depend on the\ncharacteristics of the design matrix and the Laplacian of the network.",
    "descriptor": "",
    "authors": [
      "Brighton Ancelin",
      "Sohail Bahmani",
      "Justin Romberg"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.15283"
  },
  {
    "id": "arXiv:2110.15304",
    "title": "Sobolev-type embeddings for neural network approximation spaces",
    "abstract": "We consider neural network approximation spaces that classify functions\naccording to the rate at which they can be approximated (with error measured in\n$L^p$) by ReLU neural networks with an increasing number of coefficients,\nsubject to bounds on the magnitude of the coefficients and the number of hidden\nlayers. We prove embedding theorems between these spaces for different values\nof $p$. Furthermore, we derive sharp embeddings of these approximation spaces\ninto H\\\"older spaces. We find that, analogous to the case of classical function\nspaces (such as Sobolev spaces, or Besov spaces) it is possible to trade\n\"smoothness\" (i.e., approximation rate) for increased integrability.\nCombined with our earlier results in [arXiv:2104.02746], our embedding\ntheorems imply a somewhat surprising fact related to \"learning\" functions from\na given neural network space based on point samples: if accuracy is measured\nwith respect to the uniform norm, then an optimal \"learning\" algorithm for\nreconstructing functions that are well approximable by ReLU neural networks is\nsimply given by piecewise constant interpolation on a tensor product grid.",
    "descriptor": "",
    "authors": [
      "Philipp Grohs",
      "Felix Voigtlaender"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15304"
  },
  {
    "id": "arXiv:2110.15321",
    "title": "Homogenisation of dynamical optimal transport on periodic graphs",
    "abstract": "This paper deals with the large-scale behaviour of dynamical optimal\ntransport on $\\mathbb{Z}^d$-periodic graphs with general lower semicontinuous\nand convex energy densities. Our main contribution is a homogenisation result\nthat describes the effective behaviour of the discrete problems in terms of a\ncontinuous optimal transport problem. The effective energy density can be\nexplicitly expressed in terms of a cell formula, which is a finite-dimensional\nconvex programming problem that depends non-trivially on the local geometry of\nthe discrete graph and the discrete energy density.\nOur homogenisation result is derived from a $\\Gamma$-convergence result for\naction functionals on curves of measures, which we prove under very mild growth\nconditions on the energy density. We investigate the cell formula in several\ncases of interest, including finite-volume discretisations of the Wasserstein\ndistance, where non-trivial limiting behaviour occurs.",
    "descriptor": "\nComments: 72 pages\n",
    "authors": [
      "Peter Gladbach",
      "Eva Kopfer",
      "Jan Maas",
      "Lorenzo Portinale"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Metric Geometry (math.MG)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.15321"
  },
  {
    "id": "arXiv:2110.15334",
    "title": "Gohberg-Kaashoek Numbers and Forward Stability of the Schur Canonical  Form",
    "abstract": "In the present paper we complete the stability of Schur decomposition\ndepending on the Jordan structure of the perturbation, started in \\cite{MNO}.",
    "descriptor": "\nComments: 18 pages. arXiv admin note: text overlap with arXiv:2108.02312\n",
    "authors": [
      "Anastasiia Minenkova",
      "Evelyn Nitch-Griffin",
      "Vadim Olshevsky"
    ],
    "subjectives": [
      "Classical Analysis and ODEs (math.CA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.15334"
  },
  {
    "id": "arXiv:1708.08739",
    "title": "Exact and Approximate Algorithms for Computing Betweenness Centrality in  Directed Graphs",
    "abstract": "Exact and Approximate Algorithms for Computing Betweenness Centrality in  Directed Graphs",
    "descriptor": "",
    "authors": [
      "Mostafa Haghir Chehreghani",
      "Albert Bifet",
      "Talel Abdessalem"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/1708.08739"
  },
  {
    "id": "arXiv:1805.00265",
    "title": "Performance Analysis of Distributed Radio Interferometric Calibration",
    "abstract": "Comments: published in the Proceedings of IEEE Sensor Array and Multichannel Signal Processing Workshop (IEEE SAM 2018), published by IEEE",
    "descriptor": "\nComments: published in the Proceedings of IEEE Sensor Array and Multichannel Signal Processing Workshop (IEEE SAM 2018), published by IEEE\n",
    "authors": [
      "Sarod Yatawatta"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/1805.00265"
  },
  {
    "id": "arXiv:1908.09874",
    "title": "Sufficient Representations for Categorical Variables",
    "abstract": "Sufficient Representations for Categorical Variables",
    "descriptor": "",
    "authors": [
      "Jonathan Johannemann",
      "Vitor Hadad",
      "Susan Athey",
      "Stefan Wager"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1908.09874"
  },
  {
    "id": "arXiv:1908.11642",
    "title": "Weight Annotation in Information Extraction",
    "abstract": "Weight Annotation in Information Extraction",
    "descriptor": "",
    "authors": [
      "Johannes Doleschal",
      "Benny Kimelfeld",
      "Wim Martens",
      "Liat Peterfreund"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1908.11642"
  },
  {
    "id": "arXiv:1910.00471",
    "title": "Error Thresholds for Arbitrary Pauli Noise",
    "abstract": "Comments: 56 pages, 20 figures; code repositories available at this https URL and this https URL",
    "descriptor": "\nComments: 56 pages, 20 figures; code repositories available at this https URL and this https URL\n",
    "authors": [
      "Johannes Bausch",
      "Felix Leditzky"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1910.00471"
  },
  {
    "id": "arXiv:1910.05065",
    "title": "Relation learning in a neurocomputational architecture supports  cross-domain transfer",
    "abstract": "Comments: Includes supplemental material",
    "descriptor": "\nComments: Includes supplemental material\n",
    "authors": [
      "Leonidas A. A. Doumas",
      "Guillermo Puebla",
      "Andrea E. Martin",
      "John E. Hummel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/1910.05065"
  },
  {
    "id": "arXiv:1910.13028",
    "title": "DEPA: Self-Supervised Audio Embedding for Depression Detection",
    "abstract": "DEPA: Self-Supervised Audio Embedding for Depression Detection",
    "descriptor": "",
    "authors": [
      "Pingyue Zhang",
      "Mengyue Wu",
      "Heinrich Dinkel",
      "Kai Yu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/1910.13028"
  },
  {
    "id": "arXiv:1911.06276",
    "title": "LGN-CNN: a biologically inspired CNN architecture",
    "abstract": "LGN-CNN: a biologically inspired CNN architecture",
    "descriptor": "",
    "authors": [
      "Federico Bertoni",
      "Giovanna Citti",
      "Alessandro Sarti"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/1911.06276"
  },
  {
    "id": "arXiv:1911.13034",
    "title": "Model structures and fitting criteria for system identification with  neural networks",
    "abstract": "Comments: Source code generating the results of the paper available at this https URL",
    "descriptor": "\nComments: Source code generating the results of the paper available at this https URL\n",
    "authors": [
      "Marco Forgione",
      "Dario Piga"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1911.13034"
  },
  {
    "id": "arXiv:1912.02563",
    "title": "Universality of persistence diagrams and the bottleneck and Wasserstein  distances",
    "abstract": "Comments: 24 pages, v4: Made changes suggested by the referees",
    "descriptor": "\nComments: 24 pages, v4: Made changes suggested by the referees\n",
    "authors": [
      "Peter Bubenik",
      "Alex Elchesen"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/1912.02563"
  },
  {
    "id": "arXiv:1912.03646",
    "title": "Universal Limitations on Quantum Key Distribution over a Network",
    "abstract": "Comments: Published version. Extended discussion on applicability to realistic setups of MDI-QKD",
    "descriptor": "\nComments: Published version. Extended discussion on applicability to realistic setups of MDI-QKD\n",
    "authors": [
      "Siddhartha Das",
      "Stefan B\u00e4uml",
      "Marek Winczewski",
      "Karol Horodecki"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1912.03646"
  },
  {
    "id": "arXiv:1912.03677",
    "title": "Domain-adaptive Crowd Counting via High-quality Image Translation and  Density Reconstruction",
    "abstract": "Comments: Accepted by IEEE T-NNLS",
    "descriptor": "\nComments: Accepted by IEEE T-NNLS\n",
    "authors": [
      "Junyu Gao",
      "Tao Han",
      "Qi Wang",
      "Yuan Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1912.03677"
  },
  {
    "id": "arXiv:2001.04812",
    "title": "Generic Decoding in the Sum-Rank Metric",
    "abstract": "Generic Decoding in the Sum-Rank Metric",
    "descriptor": "",
    "authors": [
      "Sven Puchinger",
      "Julian Renner",
      "Johan Rosenkilde"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2001.04812"
  },
  {
    "id": "arXiv:2002.07088",
    "title": "GRAPHITE: A Practical Framework for Generating Automatic Physical  Adversarial Machine Learning Attacks",
    "abstract": "GRAPHITE: A Practical Framework for Generating Automatic Physical  Adversarial Machine Learning Attacks",
    "descriptor": "",
    "authors": [
      "Ryan Feng",
      "Neal Mangaokar",
      "Jiefeng Chen",
      "Earlence Fernandes",
      "Somesh Jha",
      "Atul Prakash"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2002.07088"
  },
  {
    "id": "arXiv:2002.08030",
    "title": "An Efficient Transfer Learning Framework for Multiagent Reinforcement  Learning",
    "abstract": "Comments: Accepted by NeurIPS'2021",
    "descriptor": "\nComments: Accepted by NeurIPS'2021\n",
    "authors": [
      "Tianpei Yang",
      "Weixun Wang",
      "Hongyao Tang",
      "Jianye Hao",
      "Zhaopeng Meng",
      "Hangyu Mao",
      "Dong Li",
      "Wulong Liu",
      "Chengwei Zhang",
      "Yujing Hu",
      "Yingfeng Chen",
      "Changjie Fan"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2002.08030"
  },
  {
    "id": "arXiv:2002.08828",
    "title": "The Complexity of Aggregates over Extractions by Regular Expressions",
    "abstract": "The Complexity of Aggregates over Extractions by Regular Expressions",
    "descriptor": "",
    "authors": [
      "Johannes Doleschal",
      "Benny Kimelfeld",
      "Wim Martens"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2002.08828"
  },
  {
    "id": "arXiv:2003.08773",
    "title": "Do CNNs Encode Data Augmentations?",
    "abstract": "Do CNNs Encode Data Augmentations?",
    "descriptor": "",
    "authors": [
      "Eddie Yan",
      "Yanping Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.08773"
  },
  {
    "id": "arXiv:2003.13731",
    "title": "Affective Automotive User Interfaces -- Reviewing the State of Emotion  Regulation in the Car",
    "abstract": "Affective Automotive User Interfaces -- Reviewing the State of Emotion  Regulation in the Car",
    "descriptor": "",
    "authors": [
      "Michael Braun",
      "Florian Weber",
      "Florian Alt"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2003.13731"
  },
  {
    "id": "arXiv:2006.04593",
    "title": "ARIANN: Low-Interaction Privacy-Preserving Deep Learning via Function  Secret Sharing",
    "abstract": "Comments: 26 pages",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Th\u00e9o Ryffel",
      "Pierre Tholoniat",
      "David Pointcheval",
      "Francis Bach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.04593"
  },
  {
    "id": "arXiv:2006.08495",
    "title": "Overparameterization and generalization error: weighted trigonometric  interpolation",
    "abstract": "Comments: Add high-dimensional case and modify proofs",
    "descriptor": "\nComments: Add high-dimensional case and modify proofs\n",
    "authors": [
      "Yuege Xie",
      "Hung-Hsu Chou",
      "Holger Rauhut",
      "Rachel Ward"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.08495"
  },
  {
    "id": "arXiv:2007.00427",
    "title": "Distributed Model Predictive Control with Reconfigurable Terminal  Ingredients for Reference Tracking",
    "abstract": "Distributed Model Predictive Control with Reconfigurable Terminal  Ingredients for Reference Tracking",
    "descriptor": "",
    "authors": [
      "Ahmed Aboudonia",
      "Annika Eichler",
      "Francesco Cordiano",
      "Goran Banjac",
      "John Lygeros"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2007.00427"
  },
  {
    "id": "arXiv:2007.07977",
    "title": "An Adaptive Self-Scheduling Loop Scheduler",
    "abstract": "An Adaptive Self-Scheduling Loop Scheduler",
    "descriptor": "",
    "authors": [
      "Joshua Dennis Booth",
      "Phillip Lane"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2007.07977"
  },
  {
    "id": "arXiv:2007.10824",
    "title": "Parameter estimation for Gibbs distributions",
    "abstract": "Comments: This is a significantly extended version of a paper \"A Faster Approximation Algorithm for the Gibbs Partition Function\" (arXiv:1608.04223), which was published in COLT 2018. It covers many additional topics; most importantly, algorithms to estimate counts and algorithm specialized for integer-valued distributions",
    "descriptor": "\nComments: This is a significantly extended version of a paper \"A Faster Approximation Algorithm for the Gibbs Partition Function\" (arXiv:1608.04223), which was published in COLT 2018. It covers many additional topics; most importantly, algorithms to estimate counts and algorithm specialized for integer-valued distributions\n",
    "authors": [
      "David G. Harris",
      "Vladimir Kolmogorov"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2007.10824"
  },
  {
    "id": "arXiv:2007.11393",
    "title": "Optimal Pacing of a Cyclist in a Time Trial Based on Individualized  Models of Fatigue and Recovery",
    "abstract": "Comments: 18 pages, 12 figures",
    "descriptor": "\nComments: 18 pages, 12 figures\n",
    "authors": [
      "Faraz Ashtiani",
      "Vijay Sarthy M Sreedhara",
      "Ardalan Vahidi",
      "Randolph Hutchison",
      "Gregory Mocko"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2007.11393"
  },
  {
    "id": "arXiv:2009.03218",
    "title": "Fast simulation of planar Clifford circuits",
    "abstract": "Fast simulation of planar Clifford circuits",
    "descriptor": "",
    "authors": [
      "David Gosset",
      "Daniel Grier",
      "Alex Kerzner",
      "Luke Schaeffer"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2009.03218"
  },
  {
    "id": "arXiv:2010.00788",
    "title": "Effective Regularization Through Loss-Function Metalearning",
    "abstract": "Effective Regularization Through Loss-Function Metalearning",
    "descriptor": "",
    "authors": [
      "Santiago Gonzalez",
      "Risto Miikkulainen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.00788"
  },
  {
    "id": "arXiv:2010.01600",
    "title": "Detecting Short-lasting Topics Using Nonnegative Tensor Decomposition",
    "abstract": "Detecting Short-lasting Topics Using Nonnegative Tensor Decomposition",
    "descriptor": "",
    "authors": [
      "Lara Kassab",
      "Alona Kryshchenko",
      "Hanbaek Lyu",
      "Denali Molitor",
      "Deanna Needell",
      "Elizaveta Rebrova"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2010.01600"
  },
  {
    "id": "arXiv:2010.02387",
    "title": "Metadata-Based Detection of Child Sexual Abuse Material",
    "abstract": "Metadata-Based Detection of Child Sexual Abuse Material",
    "descriptor": "",
    "authors": [
      "Mayana Pereira",
      "Rahul Dodhia",
      "Hyrum Anderson",
      "Richard Brown"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2010.02387"
  },
  {
    "id": "arXiv:2010.07212",
    "title": "Geometry matters: Exploring language examples at the decision boundary",
    "abstract": "Comments: Ongoing Work, Presented at TADA 2021",
    "descriptor": "\nComments: Ongoing Work, Presented at TADA 2021\n",
    "authors": [
      "Debajyoti Datta",
      "Shashwat Kumar",
      "Laura Barnes",
      "Tom Fletcher"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.07212"
  },
  {
    "id": "arXiv:2010.14746",
    "title": "Continuous Lyapunov Controller and Chaotic Non-linear System  Optimization using Deep Machine Learning",
    "abstract": "Comments: 7 pages, 12 figures",
    "descriptor": "\nComments: 7 pages, 12 figures\n",
    "authors": [
      "Amr Mahmoud",
      "Youmna Ismaeil",
      "Mohamed Zohdy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.14746"
  },
  {
    "id": "arXiv:2011.00165",
    "title": "FireCommander: An Interactive, Probabilistic Multi-agent Environment for  Heterogeneous Robot Teams",
    "abstract": "FireCommander: An Interactive, Probabilistic Multi-agent Environment for  Heterogeneous Robot Teams",
    "descriptor": "",
    "authors": [
      "Esmaeil Seraj",
      "Xiyang Wu",
      "Matthew Gombolay"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2011.00165"
  },
  {
    "id": "arXiv:2011.09416",
    "title": "Exact nuclear norm, completion and decomposition for random overcomplete  tensors via degree-4 SOS",
    "abstract": "Comments: This is an updated version of the paper. The introduction and section 2 were reorganized. Appendices B and C are added. 144 pages, 28 figures",
    "descriptor": "\nComments: This is an updated version of the paper. The introduction and section 2 were reorganized. Appendices B and C are added. 144 pages, 28 figures\n",
    "authors": [
      "Bohdan Kivva",
      "Aaron Potechin"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.09416"
  },
  {
    "id": "arXiv:2011.10065",
    "title": "Anderson acceleration of coordinate descent",
    "abstract": "Anderson acceleration of coordinate descent",
    "descriptor": "",
    "authors": [
      "Quentin Bertrand",
      "Mathurin Massias"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.10065"
  },
  {
    "id": "arXiv:2011.13034",
    "title": "Accommodating Picky Customers: Regret Bound and Exploration Complexity  for Multi-Objective Reinforcement Learning",
    "abstract": "Comments: NeurIPS 2021 Camera Ready Version",
    "descriptor": "\nComments: NeurIPS 2021 Camera Ready Version\n",
    "authors": [
      "Jingfeng Wu",
      "Vladimir Braverman",
      "Lin F. Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.13034"
  },
  {
    "id": "arXiv:2012.01244",
    "title": "General Characterization of Agents by States they Visit",
    "abstract": "Comments: Deep Reinforcement Learning Workshop, NeurIPS 2021",
    "descriptor": "\nComments: Deep Reinforcement Learning Workshop, NeurIPS 2021\n",
    "authors": [
      "Anssi Kanervisto",
      "Tomi Kinnunen",
      "Ville Hautam\u00e4ki"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2012.01244"
  },
  {
    "id": "arXiv:2012.04713",
    "title": "Classical symmetries and the Quantum Approximate Optimization Algorithm",
    "abstract": "Classical symmetries and the Quantum Approximate Optimization Algorithm",
    "descriptor": "",
    "authors": [
      "Ruslan Shaydulin",
      "Stuart Hadfield",
      "Tad Hogg",
      "Ilya Safro"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.04713"
  },
  {
    "id": "arXiv:2012.15680",
    "title": "Unsupervised Monocular Depth Reconstruction of Non-Rigid Scenes",
    "abstract": "Unsupervised Monocular Depth Reconstruction of Non-Rigid Scenes",
    "descriptor": "",
    "authors": [
      "Ay\u00e7a Takmaz",
      "Danda Pani Paudel",
      "Thomas Probst",
      "Ajad Chhatkuli",
      "Martin R. Oswald",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.15680"
  },
  {
    "id": "arXiv:2101.01945",
    "title": "Fine-Grained Complexity of Regular Path Queries",
    "abstract": "Fine-Grained Complexity of Regular Path Queries",
    "descriptor": "",
    "authors": [
      "Katrin Casel",
      "Markus L. Schmid"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Databases (cs.DB)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2101.01945"
  },
  {
    "id": "arXiv:2101.04003",
    "title": "QMA: A Resource-efficient, Q-Learning-based Multiple Access Scheme for  the IIoT",
    "abstract": "Comments: 23 pages, 26 figures",
    "descriptor": "\nComments: 23 pages, 26 figures\n",
    "authors": [
      "Florian Meyer",
      "Volker Turau"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2101.04003"
  },
  {
    "id": "arXiv:2101.09624",
    "title": "A Review of Speaker Diarization: Recent Advances with Deep Learning",
    "abstract": "Comments: This preprint is accepted for publication in Computer Speech & Language",
    "descriptor": "\nComments: This preprint is accepted for publication in Computer Speech & Language\n",
    "authors": [
      "Tae Jin Park",
      "Naoyuki Kanda",
      "Dimitrios Dimitriadis",
      "Kyu J. Han",
      "Shinji Watanabe",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2101.09624"
  },
  {
    "id": "arXiv:2101.11223",
    "title": "Multi-Instance Pose Networks: Rethinking Top-Down Pose Estimation",
    "abstract": "Comments: ICCV 2021",
    "descriptor": "\nComments: ICCV 2021\n",
    "authors": [
      "Rawal Khirodkar",
      "Visesh Chari",
      "Amit Agrawal",
      "Ambrish Tyagi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.11223"
  },
  {
    "id": "arXiv:2101.12745",
    "title": "Variance-Aware Confidence Set: Variance-Dependent Bound for Linear  Bandits and Horizon-Free Bound for Linear Mixture MDP",
    "abstract": "Comments: 31 pages",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Zihan Zhang",
      "Jiaqi Yang",
      "Xiangyang Ji",
      "Simon S. Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.12745"
  },
  {
    "id": "arXiv:2102.02079",
    "title": "Federated Learning on Non-IID Data Silos: An Experimental Study",
    "abstract": "Federated Learning on Non-IID Data Silos: An Experimental Study",
    "descriptor": "",
    "authors": [
      "Qinbin Li",
      "Yiqun Diao",
      "Quan Chen",
      "Bingsheng He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2102.02079"
  },
  {
    "id": "arXiv:2102.03327",
    "title": "Symbolic Models for Infinite Networks of Control Systems: A  Compositional Approach",
    "abstract": "Symbolic Models for Infinite Networks of Control Systems: A  Compositional Approach",
    "descriptor": "",
    "authors": [
      "Siyuan Liu",
      "Navid Noroozi",
      "Majid Zamani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.03327"
  },
  {
    "id": "arXiv:2102.04130",
    "title": "Bias Out-of-the-Box: An Empirical Analysis of Intersectional  Occupational Biases in Popular Generative Language Models",
    "abstract": "Comments: Accepted to NeurIPS 2021. Code and data at this https URL",
    "descriptor": "\nComments: Accepted to NeurIPS 2021. Code and data at this https URL\n",
    "authors": [
      "Hannah Kirk",
      "Yennie Jun",
      "Haider Iqbal",
      "Elias Benussi",
      "Filippo Volpin",
      "Frederic A. Dreyer",
      "Aleksandar Shtedritski",
      "Yuki M. Asano"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.04130"
  },
  {
    "id": "arXiv:2102.04133",
    "title": "Local certification of graphs on surfaces",
    "abstract": "Comments: 10 pages, 5 figures - v3: revised version",
    "descriptor": "\nComments: 10 pages, 5 figures - v3: revised version\n",
    "authors": [
      "Louis Esperet",
      "Benjamin L\u00e9v\u00eaque"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2102.04133"
  },
  {
    "id": "arXiv:2102.05713",
    "title": "SCA-Net: A Self-Correcting Two-Layer Autoencoder for Hyper-spectral  Unmixing",
    "abstract": "SCA-Net: A Self-Correcting Two-Layer Autoencoder for Hyper-spectral  Unmixing",
    "descriptor": "",
    "authors": [
      "Gurpreet Singh",
      "Soumyajit Gupta",
      "Clint Dawson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.05713"
  },
  {
    "id": "arXiv:2102.06408",
    "title": "Supervised training of spiking neural networks for robust deployment on  mixed-signal neuromorphic processors",
    "abstract": "Supervised training of spiking neural networks for robust deployment on  mixed-signal neuromorphic processors",
    "descriptor": "",
    "authors": [
      "Julian B\u00fcchel",
      "Dmitrii Zendrikov",
      "Sergio Solinas",
      "Giacomo Indiveri",
      "Dylan R. Muir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.06408"
  },
  {
    "id": "arXiv:2102.06857",
    "title": "On Robust Optimal Transport: Computational Complexity and Barycenter  Computation",
    "abstract": "Comments: Advances in NeurIPS, 2021; 52 pages, 10 figures; Khang Le and Huy Nguyen contributed equally to this week",
    "descriptor": "\nComments: Advances in NeurIPS, 2021; 52 pages, 10 figures; Khang Le and Huy Nguyen contributed equally to this week\n",
    "authors": [
      "Khang Le",
      "Huy Nguyen",
      "Quang Nguyen",
      "Tung Pham",
      "Hung Bui",
      "Nhat Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.06857"
  },
  {
    "id": "arXiv:2102.06928",
    "title": "Strong Call-by-Value is Reasonable, Implosively",
    "abstract": "Comments: Technical report associated to a LICS 2021 paper",
    "descriptor": "\nComments: Technical report associated to a LICS 2021 paper\n",
    "authors": [
      "Beniamino Accattoli",
      "Andrea Condoluci",
      "Claudio Sacerdoti Coen"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2102.06928"
  },
  {
    "id": "arXiv:2102.07492",
    "title": "DOBF: A Deobfuscation Pre-Training Objective for Programming Languages",
    "abstract": "DOBF: A Deobfuscation Pre-Training Objective for Programming Languages",
    "descriptor": "",
    "authors": [
      "Baptiste Roziere",
      "Marie-Anne Lachaux",
      "Marc Szafraniec",
      "Guillaume Lample"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2102.07492"
  },
  {
    "id": "arXiv:2102.07567",
    "title": "Learning Accurate Decision Trees with Bandit Feedback via Quantized  Gradient Descent",
    "abstract": "Learning Accurate Decision Trees with Bandit Feedback via Quantized  Gradient Descent",
    "descriptor": "",
    "authors": [
      "Ajaykrishna Karthikeyan",
      "Naman Jain",
      "Nagarajan Natarajan",
      "Prateek Jain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.07567"
  },
  {
    "id": "arXiv:2102.07804",
    "title": "Scaling Up Exact Neural Network Compression by ReLU Stability",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Thiago Serra",
      "Xin Yu",
      "Abhinav Kumar",
      "Srikumar Ramalingam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2102.07804"
  },
  {
    "id": "arXiv:2102.07927",
    "title": "Structured Dropout Variational Inference for Bayesian Neural Networks",
    "abstract": "Comments: 45 pages, 9 figures",
    "descriptor": "\nComments: 45 pages, 9 figures\n",
    "authors": [
      "Son Nguyen",
      "Duong Nguyen",
      "Khai Nguyen",
      "Khoat Than",
      "Hung Bui",
      "Nhat Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.07927"
  },
  {
    "id": "arXiv:2102.08578",
    "title": "Evolving GAN Formulations for Higher Quality Image Synthesis",
    "abstract": "Evolving GAN Formulations for Higher Quality Image Synthesis",
    "descriptor": "",
    "authors": [
      "Santiago Gonzalez",
      "Mohak Kant",
      "Risto Miikkulainen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.08578"
  },
  {
    "id": "arXiv:2102.08689",
    "title": "Symmetry Breaking for k-Robust Multi-Agent Path Finding",
    "abstract": "Comments: 8 pages. Accepted by Thirty-Fifth AAAI Conference on Artificial Intelligence",
    "descriptor": "\nComments: 8 pages. Accepted by Thirty-Fifth AAAI Conference on Artificial Intelligence\n",
    "authors": [
      "Zhe Chen",
      "Daniel Harabor",
      "Jiaoyang Li",
      "Peter J. Stuckey"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.08689"
  },
  {
    "id": "arXiv:2102.10739",
    "title": "Dissecting the Diffusion Process in Linear Graph Convolutional Networks",
    "abstract": "Comments: NeurIPS 2021. Code is available at this https URL",
    "descriptor": "\nComments: NeurIPS 2021. Code is available at this https URL\n",
    "authors": [
      "Yifei Wang",
      "Yisen Wang",
      "Jiansheng Yang",
      "Zhouchen Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.10739"
  },
  {
    "id": "arXiv:2102.11503",
    "title": "Two Sides of Meta-Learning Evaluation: In vs. Out of Distribution",
    "abstract": "Two Sides of Meta-Learning Evaluation: In vs. Out of Distribution",
    "descriptor": "",
    "authors": [
      "Amrith Setlur",
      "Oscar Li",
      "Virginia Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.11503"
  },
  {
    "id": "arXiv:2102.11755",
    "title": "Analytical Study of Momentum-Based Acceleration Methods in Paradigmatic  High-Dimensional Non-Convex Problems",
    "abstract": "Comments: To appear in NeurIPS 2021",
    "descriptor": "\nComments: To appear in NeurIPS 2021\n",
    "authors": [
      "Stefano Sarao Mannelli",
      "Pierfrancesco Urbani"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.11755"
  },
  {
    "id": "arXiv:2102.11929",
    "title": "PolicySpace2: modeling markets and endogenous public policies",
    "abstract": "Comments: 42 pages, 7 figures, 5 tables",
    "descriptor": "\nComments: 42 pages, 7 figures, 5 tables\n",
    "authors": [
      "Bernardo Alves Furtado"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "General Economics (econ.GN)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2102.11929"
  },
  {
    "id": "arXiv:2102.12090",
    "title": "Continuous Mean-Covariance Bandits",
    "abstract": "Continuous Mean-Covariance Bandits",
    "descriptor": "",
    "authors": [
      "Yihan Du",
      "Siwei Wang",
      "Zhixuan Fang",
      "Longbo Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.12090"
  },
  {
    "id": "arXiv:2102.12722",
    "title": "Combinatorial Bandits under Strategic Manipulations",
    "abstract": "Combinatorial Bandits under Strategic Manipulations",
    "descriptor": "",
    "authors": [
      "Jing Dong",
      "Ke Li",
      "Shuai Li",
      "Baoxiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.12722"
  },
  {
    "id": "arXiv:2102.12909",
    "title": "Docking and Undocking a Modular Underactuated Oscillating Swimming Robot",
    "abstract": "Comments: 6 pages. Submitted to the 2021 IEEE International Conference on Robotics and Automation (ICRA)",
    "descriptor": "\nComments: 6 pages. Submitted to the 2021 IEEE International Conference on Robotics and Automation (ICRA)\n",
    "authors": [
      "Gedaliah Knizhnik",
      "Mark Yim"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2102.12909"
  },
  {
    "id": "arXiv:2102.12959",
    "title": "Bayesian OOD detection with aleatoric uncertainty and outlier exposure",
    "abstract": "Bayesian OOD detection with aleatoric uncertainty and outlier exposure",
    "descriptor": "",
    "authors": [
      "Xi Wang",
      "Laurence Aitchison"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.12959"
  },
  {
    "id": "arXiv:2102.13289",
    "title": "Optimal Pricing of Information",
    "abstract": "Optimal Pricing of Information",
    "descriptor": "",
    "authors": [
      "Shuze Liu",
      "Weiran Shen",
      "Haifeng Xu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2102.13289"
  },
  {
    "id": "arXiv:2103.00882",
    "title": "k-apices of minor-closed graph classes. I. Bounding the obstructions",
    "abstract": "Comments: 46 pages and 12 figures. arXiv admin note: text overlap with arXiv:2004.12692",
    "descriptor": "\nComments: 46 pages and 12 figures. arXiv admin note: text overlap with arXiv:2004.12692\n",
    "authors": [
      "Ignasi Sau",
      "Giannos Stamoulis",
      "Dimitrios M. Thilikos"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2103.00882"
  },
  {
    "id": "arXiv:2103.01495",
    "title": "Task-Adaptive Neural Network Search with Meta-Contrastive Learning",
    "abstract": "Comments: NeurIPS 2021 (Spotlight)",
    "descriptor": "\nComments: NeurIPS 2021 (Spotlight)\n",
    "authors": [
      "Wonyong Jeong",
      "Hayeon Lee",
      "Gun Park",
      "Eunyoung Hyung",
      "Jinheon Baek",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.01495"
  },
  {
    "id": "arXiv:2103.01795",
    "title": "Context Decoupling Augmentation for Weakly Supervised Semantic  Segmentation",
    "abstract": "Comments: To appear in ICCV2021. Code: this https URL",
    "descriptor": "\nComments: To appear in ICCV2021. Code: this https URL\n",
    "authors": [
      "Yukun Su",
      "Ruizhou Sun",
      "Guosheng Lin",
      "Qingyao Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.01795"
  },
  {
    "id": "arXiv:2103.02284",
    "title": "Columnar Storage and List-based Processing for Graph Database Management  Systems",
    "abstract": "Comments: VLDB Conference 2021 (this https URL)",
    "descriptor": "\nComments: VLDB Conference 2021 (this https URL)\n",
    "authors": [
      "Pranjal Gupta",
      "Amine Mhedhbi",
      "Semih Salihoglu"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2103.02284"
  },
  {
    "id": "arXiv:2103.02553",
    "title": "Finite-sample-based Spectral Radius Estimation and Stabilizability Test  for Networked Control Systems",
    "abstract": "Finite-sample-based Spectral Radius Estimation and Stabilizability Test  for Networked Control Systems",
    "descriptor": "",
    "authors": [
      "Liang Xu",
      "Baiwei Guo",
      "Giancarlo Ferrari-Trecate"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.02553"
  },
  {
    "id": "arXiv:2103.02886",
    "title": "Improving Computational Efficiency in Visual Reinforcement Learning via  Stored Embeddings",
    "abstract": "Improving Computational Efficiency in Visual Reinforcement Learning via  Stored Embeddings",
    "descriptor": "",
    "authors": [
      "Lili Chen",
      "Kimin Lee",
      "Aravind Srinivas",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.02886"
  },
  {
    "id": "arXiv:2103.03452",
    "title": "FedDR -- Randomized Douglas-Rachford Splitting Algorithms for Nonconvex  Federated Composite Optimization",
    "abstract": "Comments: 39 pages, and 12 figures",
    "descriptor": "\nComments: 39 pages, and 12 figures\n",
    "authors": [
      "Quoc Tran-Dinh",
      "Nhan H. Pham",
      "Dzung T. Phan",
      "Lam M. Nguyen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.03452"
  },
  {
    "id": "arXiv:2103.04257",
    "title": "Student-Teacher Feature Pyramid Matching for Anomaly Detection",
    "abstract": "Comments: Accepted by BMVC'2021",
    "descriptor": "\nComments: Accepted by BMVC'2021\n",
    "authors": [
      "Guodong Wang",
      "Shumin Han",
      "Errui Ding",
      "Di Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.04257"
  },
  {
    "id": "arXiv:2103.04551",
    "title": "Behavior From the Void: Unsupervised Active Pre-Training",
    "abstract": "Comments: Advances in Neural Information Processing Systems(NeurIPS), 2021 Spotlight",
    "descriptor": "\nComments: Advances in Neural Information Processing Systems(NeurIPS), 2021 Spotlight\n",
    "authors": [
      "Hao Liu",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.04551"
  },
  {
    "id": "arXiv:2103.04885",
    "title": "Data-driven Cloud Clustering via a Rotationally Invariant Autoencoder",
    "abstract": "Comments: 25 pages. Accepted by IEEE Transactions on Geoscience and Remote Sensing (TGRS)",
    "descriptor": "\nComments: 25 pages. Accepted by IEEE Transactions on Geoscience and Remote Sensing (TGRS)\n",
    "authors": [
      "Takuya Kurihana",
      "Elisabeth Moyer",
      "Rebecca Willett",
      "Davis Gilton",
      "Ian Foster"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2103.04885"
  },
  {
    "id": "arXiv:2103.05788",
    "title": "Selling Data to an Agent with Endogenous Information",
    "abstract": "Selling Data to an Agent with Endogenous Information",
    "descriptor": "",
    "authors": [
      "Yingkai Li"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2103.05788"
  },
  {
    "id": "arXiv:2103.09159",
    "title": "Learning to Shape Rewards using a Game of Two Partners",
    "abstract": "Learning to Shape Rewards using a Game of Two Partners",
    "descriptor": "",
    "authors": [
      "David Mguni",
      "Jianhong Wang",
      "Taher Jafferjee",
      "Nicolas Perez-Nieves",
      "Wenbin Song",
      "Yaodong Yang",
      "Feifei Tong",
      "Hui Chen",
      "Jiangcheng Zhu",
      "Jun Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2103.09159"
  },
  {
    "id": "arXiv:2103.09174",
    "title": "Monocular Multi-Layer Layout Estimation for Warehouse Racks",
    "abstract": "Comments: Visit our project repository at this https URL",
    "descriptor": "\nComments: Visit our project repository at this https URL\n",
    "authors": [
      "Meher Shashwat Nigam",
      "Avinash Prabhu",
      "Anurag Sahu",
      "Puru Gupta",
      "Tanvi Karandikar",
      "N. Sai Shankar",
      "Ravi Kiran Sarvadevabhatla",
      "K. Madhava Krishna"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.09174"
  },
  {
    "id": "arXiv:2103.10690",
    "title": "Efficient Deep Reinforcement Learning with Imitative Expert Priors for  Autonomous Driving",
    "abstract": "Efficient Deep Reinforcement Learning with Imitative Expert Priors for  Autonomous Driving",
    "descriptor": "",
    "authors": [
      "Zhiyu Huang",
      "Jingda Wu",
      "Chen Lv"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.10690"
  },
  {
    "id": "arXiv:2103.11474",
    "title": "#PraCegoVer: A Large Dataset for Image Captioning in Portuguese",
    "abstract": "Comments: 23 pages, 21 figures, 2 tables",
    "descriptor": "\nComments: 23 pages, 21 figures, 2 tables\n",
    "authors": [
      "Gabriel Oliveira dos Santos",
      "Esther Luna Colombini",
      "Sandra Avila"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.11474"
  },
  {
    "id": "arXiv:2103.12711",
    "title": "A Pseudo-Metric between Probability Distributions based on Depth-Trimmed  Regions",
    "abstract": "A Pseudo-Metric between Probability Distributions based on Depth-Trimmed  Regions",
    "descriptor": "",
    "authors": [
      "Guillaume Staerman",
      "Pavlo Mozharovskyi",
      "Pierre Colombo",
      "St\u00e9phan Cl\u00e9men\u00e7on",
      "Florence d'Alch\u00e9-Buc"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.12711"
  },
  {
    "id": "arXiv:2103.16547",
    "title": "The Elastic Lottery Ticket Hypothesis",
    "abstract": "Comments: Accepted at NeurIPS 2021",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Xiaohan Chen",
      "Yu Cheng",
      "Shuohang Wang",
      "Zhe Gan",
      "Jingjing Liu",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.16547"
  },
  {
    "id": "arXiv:2103.17268",
    "title": "Fast Certified Robust Training with Short Warmup",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Zhouxing Shi",
      "Yihan Wang",
      "Huan Zhang",
      "Jinfeng Yi",
      "Cho-Jui Hsieh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.17268"
  },
  {
    "id": "arXiv:2104.01177",
    "title": "How Powerful are Performance Predictors in Neural Architecture Search?",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Colin White",
      "Arber Zela",
      "Binxin Ru",
      "Yang Liu",
      "Frank Hutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.01177"
  },
  {
    "id": "arXiv:2104.02836",
    "title": "Non-Asymptotic Analysis for Two Time-scale TDC with General Smooth  Function Approximation",
    "abstract": "Comments: Accepted by NeurIPS 2021",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Yue Wang",
      "Shaofeng Zou",
      "Yi Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.02836"
  },
  {
    "id": "arXiv:2104.03736",
    "title": "Towards Enabling Meta-Learning from Target Models",
    "abstract": "Towards Enabling Meta-Learning from Target Models",
    "descriptor": "",
    "authors": [
      "Su Lu",
      "Han-Jia Ye",
      "Le Gan",
      "De-Chuan Zhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.03736"
  },
  {
    "id": "arXiv:2104.05077",
    "title": "CoPE: Conditional image generation using Polynomial Expansions",
    "abstract": "Comments: Accepted in NeurIPS 2021",
    "descriptor": "\nComments: Accepted in NeurIPS 2021\n",
    "authors": [
      "Grigorios G Chrysos",
      "Markos Georgopoulos",
      "Yannis Panagakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.05077"
  },
  {
    "id": "arXiv:2104.05418",
    "title": "Contrastive Learning of Global-Local Video Representations",
    "abstract": "Contrastive Learning of Global-Local Video Representations",
    "descriptor": "",
    "authors": [
      "Shuang Ma",
      "Zhaoyang Zeng",
      "Daniel McDuff",
      "Yale Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2104.05418"
  },
  {
    "id": "arXiv:2104.05438",
    "title": "Actors -- A Process Algebra Based Approach",
    "abstract": "Comments: 143 pages, 12 figures, 29 tables. arXiv admin note: text overlap with arXiv:2101.05140",
    "descriptor": "\nComments: 143 pages, 12 figures, 29 tables. arXiv admin note: text overlap with arXiv:2101.05140\n",
    "authors": [
      "Yong Wang"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.05438"
  },
  {
    "id": "arXiv:2104.10536",
    "title": "Multi-RAT for IoT: The Potential in Combining LoRaWAN and NB-IoT",
    "abstract": "Comments: 7 pages, 6 figures",
    "descriptor": "\nComments: 7 pages, 6 figures\n",
    "authors": [
      "Guus Leenders",
      "Gilles Callebaut",
      "Geoffrey Ottoy",
      "Liesbet Van der Perre",
      "Lieven De Strycker"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.10536"
  },
  {
    "id": "arXiv:2104.12167",
    "title": "A Novel Binocular Eye-Tracking SystemWith Stereo Stimuli for 3D Gaze  Estimation",
    "abstract": "A Novel Binocular Eye-Tracking SystemWith Stereo Stimuli for 3D Gaze  Estimation",
    "descriptor": "",
    "authors": [
      "Jinglin Sun",
      "Zhipeng Wu",
      "Han Wang",
      "Peiguang Jing",
      "Yu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.12167"
  },
  {
    "id": "arXiv:2105.00381",
    "title": "AGMB-Transformer: Anatomy-Guided Multi-Branch Transformer Network for  Automated Evaluation of Root Canal Therapy",
    "abstract": "Comments: under review",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Yunxiang Li",
      "Guodong Zeng",
      "Yifan Zhang",
      "Jun Wang",
      "Qianni Zhang",
      "Qun Jin",
      "Lingling Sun",
      "Qisi Lian",
      "Neng Xia",
      "Ruizi Peng",
      "Kai Tang",
      "Yaqi Wang",
      "Shuai Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.00381"
  },
  {
    "id": "arXiv:2105.00564",
    "title": "Encoding Tight Typing in a Unified Framework",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2002.04011",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2002.04011\n",
    "authors": [
      "Delia Kesner",
      "Andr\u00e9s Viso"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2105.00564"
  },
  {
    "id": "arXiv:2105.01017",
    "title": "Learning Graph Embeddings for Open World Compositional Zero-Shot  Learning",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2101.12609",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2101.12609\n",
    "authors": [
      "Massimiliano Mancini",
      "Muhammad Ferjad Naeem",
      "Yongqin Xian",
      "Zeynep Akata"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.01017"
  },
  {
    "id": "arXiv:2105.01466",
    "title": "GraphTMT: Unsupervised Graph-based Topic Modeling from Video Transcripts",
    "abstract": "Comments: JT and LS contributed equally to this work",
    "descriptor": "\nComments: JT and LS contributed equally to this work\n",
    "authors": [
      "Lukas Stappen",
      "Jason Thies",
      "Gerhard Hagerer",
      "Bj\u00f6rn W. Schuller",
      "Georg Groh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2105.01466"
  },
  {
    "id": "arXiv:2105.04017",
    "title": "Infill topology and shape optimisation of lattice-skin structures",
    "abstract": "Comments: 20 pages, 17 figures",
    "descriptor": "\nComments: 20 pages, 17 figures\n",
    "authors": [
      "Xiao Xiao",
      "Fehmi Cirak"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2105.04017"
  },
  {
    "id": "arXiv:2105.04170",
    "title": "AutoDebias: Learning to Debias for Recommendation",
    "abstract": "Comments: Accepted by SIGIR 2021",
    "descriptor": "\nComments: Accepted by SIGIR 2021\n",
    "authors": [
      "Jiawei Chen",
      "Hande Dong",
      "Yang Qiu",
      "Xiangnan He",
      "Xin Xin",
      "Liang Chen",
      "Guli Lin",
      "Keping Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.04170"
  },
  {
    "id": "arXiv:2105.06496",
    "title": "Deepfake Detection by Human Crowds, Machines, and Machine-informed  Crowds",
    "abstract": "Deepfake Detection by Human Crowds, Machines, and Machine-informed  Crowds",
    "descriptor": "",
    "authors": [
      "Matthew Groh",
      "Ziv Epstein",
      "Chaz Firestone",
      "Rosalind Picard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.06496"
  },
  {
    "id": "arXiv:2105.07264",
    "title": "Neural Trees for Learning on Graphs",
    "abstract": "Neural Trees for Learning on Graphs",
    "descriptor": "",
    "authors": [
      "Rajat Talak",
      "Siyi Hu",
      "Lisa Peng",
      "Luca Carlone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.07264"
  },
  {
    "id": "arXiv:2105.08495",
    "title": "IRS-Aided Wireless Relaying: Optimal Deployment and Capacity Scaling",
    "abstract": "IRS-Aided Wireless Relaying: Optimal Deployment and Capacity Scaling",
    "descriptor": "",
    "authors": [
      "Zhenyu Kang",
      "Changsheng You",
      "Rui Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.08495"
  },
  {
    "id": "arXiv:2105.10545",
    "title": "HyFed: A Hybrid Federated Framework for Privacy-preserving Machine  Learning",
    "abstract": "HyFed: A Hybrid Federated Framework for Privacy-preserving Machine  Learning",
    "descriptor": "",
    "authors": [
      "Reza Nasirigerdeh",
      "Reihaneh Torkzadehmahani",
      "Julian Matschinske",
      "Jan Baumbach",
      "Daniel Rueckert",
      "Georgios Kaissis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.10545"
  },
  {
    "id": "arXiv:2105.10919",
    "title": "Continual World: A Robotic Benchmark For Continual Reinforcement  Learning",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Maciej Wo\u0142czyk",
      "Micha\u0142 Zaj\u0105c",
      "Razvan Pascanu",
      "\u0141ukasz Kuci\u0144ski",
      "Piotr Mi\u0142o\u015b"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.10919"
  },
  {
    "id": "arXiv:2105.11010",
    "title": "Post-Training Sparsity-Aware Quantization",
    "abstract": "Post-Training Sparsity-Aware Quantization",
    "descriptor": "",
    "authors": [
      "Gil Shomron",
      "Freddy Gabbay",
      "Samer Kurzum",
      "Uri Weiser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.11010"
  },
  {
    "id": "arXiv:2105.13179",
    "title": "A stabilized mixed finite element scheme for frictional contact  mechanics and shear failure analyses in deformable media with crossing  fractures",
    "abstract": "A stabilized mixed finite element scheme for frictional contact  mechanics and shear failure analyses in deformable media with crossing  fractures",
    "descriptor": "",
    "authors": [
      "Luyu Wang",
      "Cornelis Vuik",
      "Hadi Hajibeygi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.13179"
  },
  {
    "id": "arXiv:2105.13345",
    "title": "Adversarial Intrinsic Motivation for Reinforcement Learning",
    "abstract": "Adversarial Intrinsic Motivation for Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Ishan Durugkar",
      "Mauricio Tec",
      "Scott Niekum",
      "Peter Stone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13345"
  },
  {
    "id": "arXiv:2105.14119",
    "title": "Towards optimally abstaining from prediction with OOD test examples",
    "abstract": "Comments: In NeurIPS 2021 (+spotlight), 24 pages",
    "descriptor": "\nComments: In NeurIPS 2021 (+spotlight), 24 pages\n",
    "authors": [
      "Adam Tauman Kalai",
      "Varun Kanade"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14119"
  },
  {
    "id": "arXiv:2105.14944",
    "title": "The effectiveness of feature attribution methods and its correlation  with automatic evaluation scores",
    "abstract": "Comments: NeurIPS 2021; 10 pages of Main text; 28 pages of Appendix",
    "descriptor": "\nComments: NeurIPS 2021; 10 pages of Main text; 28 pages of Appendix\n",
    "authors": [
      "Giang Nguyen",
      "Daeyoung Kim",
      "Anh Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.14944"
  },
  {
    "id": "arXiv:2105.15203",
    "title": "SegFormer: Simple and Efficient Design for Semantic Segmentation with  Transformers",
    "abstract": "Comments: Accepted by NeurIPS 2021",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Enze Xie",
      "Wenhai Wang",
      "Zhiding Yu",
      "Anima Anandkumar",
      "Jose M. Alvarez",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.15203"
  },
  {
    "id": "arXiv:2106.00185",
    "title": "Construction of simplicial complexes with prescribed degree-size  sequences",
    "abstract": "Comments: 6 pages, 4 figures; 3-page supplemental material. Code implementing our methods is available at this https URL (Python, pip installable). Read the Docs at this https URL v2: revised and accepted at Phys. Rev. E",
    "descriptor": "\nComments: 6 pages, 4 figures; 3-page supplemental material. Code implementing our methods is available at this https URL (Python, pip installable). Read the Docs at this https URL v2: revised and accepted at Phys. Rev. E\n",
    "authors": [
      "Tzu-Chi Yen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)",
      "Algebraic Topology (math.AT)",
      "Combinatorics (math.CO)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.00185"
  },
  {
    "id": "arXiv:2106.00786",
    "title": "The Out-of-Distribution Problem in Explainability and Search Methods for  Feature Importance Explanations",
    "abstract": "Comments: NeurIPS 2021 (25 pages)",
    "descriptor": "\nComments: NeurIPS 2021 (25 pages)\n",
    "authors": [
      "Peter Hase",
      "Harry Xie",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.00786"
  },
  {
    "id": "arXiv:2106.01151",
    "title": "Towards Deeper Deep Reinforcement Learning",
    "abstract": "Towards Deeper Deep Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Johan Bjorck",
      "Carla P. Gomes",
      "Kilian Q. Weinberger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01151"
  },
  {
    "id": "arXiv:2106.01553",
    "title": "Spline Positional Encoding for Learning 3D Implicit Signed Distance  Fields",
    "abstract": "Comments: Accepted by IJCAI 2021; Code: this https URL",
    "descriptor": "\nComments: Accepted by IJCAI 2021; Code: this https URL\n",
    "authors": [
      "Peng-Shuai Wang",
      "Yang Liu",
      "Yu-Qi Yang",
      "Xin Tong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.01553"
  },
  {
    "id": "arXiv:2106.01939",
    "title": "Causal Effect Inference for Structured Treatments",
    "abstract": "Comments: NeurIPS 2021 Camera-Ready submission",
    "descriptor": "\nComments: NeurIPS 2021 Camera-Ready submission\n",
    "authors": [
      "Jean Kaddour",
      "Yuchen Zhu",
      "Qi Liu",
      "Matt J. Kusner",
      "Ricardo Silva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.01939"
  },
  {
    "id": "arXiv:2106.02900",
    "title": "Differentially Private Multi-Armed Bandits in the Shuffle Model",
    "abstract": "Differentially Private Multi-Armed Bandits in the Shuffle Model",
    "descriptor": "",
    "authors": [
      "Jay Tenenbaum",
      "Haim Kaplan",
      "Yishay Mansour",
      "Uri Stemmer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.02900"
  },
  {
    "id": "arXiv:2106.02923",
    "title": "Local Disentanglement in Variational Auto-Encoders Using Jacobian $L_1$  Regularization",
    "abstract": "Comments: 17 pages, 10 figures, NeurIPS 2021 camera ready",
    "descriptor": "\nComments: 17 pages, 10 figures, NeurIPS 2021 camera ready\n",
    "authors": [
      "Travers Rhodes",
      "Daniel D. Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02923"
  },
  {
    "id": "arXiv:2106.03922",
    "title": "Interactive Label Cleaning with Example-based Explanations",
    "abstract": "Interactive Label Cleaning with Example-based Explanations",
    "descriptor": "",
    "authors": [
      "Stefano Teso",
      "Andrea Bontempelli",
      "Fausto Giunchiglia",
      "Andrea Passerini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.03922"
  },
  {
    "id": "arXiv:2106.04066",
    "title": "Semantically Controllable Generation of Physical Scenes with Explicit  Knowledge",
    "abstract": "Comments: 14 pages, 6 figures. Under review",
    "descriptor": "\nComments: 14 pages, 6 figures. Under review\n",
    "authors": [
      "Wenhao Ding",
      "Bo Li",
      "Kim Ji Eun",
      "Ding Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.04066"
  },
  {
    "id": "arXiv:2106.04379",
    "title": "Learning Markov State Abstractions for Deep Reinforcement Learning",
    "abstract": "Comments: Code available at this https URL",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Cameron Allen",
      "Neev Parikh",
      "Omer Gottesman",
      "George Konidaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.04379"
  },
  {
    "id": "arXiv:2106.04619",
    "title": "Self-Supervised Learning with Data Augmentations Provably Isolates  Content from Style",
    "abstract": "Comments: NeurIPS 2021 camera-ready version",
    "descriptor": "\nComments: NeurIPS 2021 camera-ready version\n",
    "authors": [
      "Julius von K\u00fcgelgen",
      "Yash Sharma",
      "Luigi Gresele",
      "Wieland Brendel",
      "Bernhard Sch\u00f6lkopf",
      "Michel Besserve",
      "Francesco Locatello"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.04619"
  },
  {
    "id": "arXiv:2106.04856",
    "title": "Strongly Sublinear Algorithms for Testing Pattern Freeness",
    "abstract": "Comments: 27 pages, 2 figures; We thank anonymous reviewers for finding a mistake in an earlier version of the paper and for comments that helped us considerably improve the presentation",
    "descriptor": "\nComments: 27 pages, 2 figures; We thank anonymous reviewers for finding a mistake in an earlier version of the paper and for comments that helped us considerably improve the presentation\n",
    "authors": [
      "Ilan Newman",
      "Nithin Varma"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.04856"
  },
  {
    "id": "arXiv:2106.05001",
    "title": "No Fear of Heterogeneity: Classifier Calibration for Federated Learning  with Non-IID Data",
    "abstract": "Comments: 22 pages, NeurIPS 2021",
    "descriptor": "\nComments: 22 pages, NeurIPS 2021\n",
    "authors": [
      "Mi Luo",
      "Fei Chen",
      "Dapeng Hu",
      "Yifan Zhang",
      "Jian Liang",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.05001"
  },
  {
    "id": "arXiv:2106.05152",
    "title": "Rethink Transfer Learning in Medical Image Classification",
    "abstract": "Comments: Under review for MICCAI 2021",
    "descriptor": "\nComments: Under review for MICCAI 2021\n",
    "authors": [
      "Le Peng",
      "Hengyue Liang",
      "Taihui Li",
      "Ju Sun"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05152"
  },
  {
    "id": "arXiv:2106.05200",
    "title": "Independent mechanism analysis, a new concept?",
    "abstract": "Comments: NeurIPS 2021 camera-ready version",
    "descriptor": "\nComments: NeurIPS 2021 camera-ready version\n",
    "authors": [
      "Luigi Gresele",
      "Julius von K\u00fcgelgen",
      "Vincent Stimper",
      "Bernhard Sch\u00f6lkopf",
      "Michel Besserve"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05200"
  },
  {
    "id": "arXiv:2106.05566",
    "title": "A Neural Tangent Kernel Perspective of GANs",
    "abstract": "A Neural Tangent Kernel Perspective of GANs",
    "descriptor": "",
    "authors": [
      "Jean-Yves Franceschi",
      "Emmanuel de B\u00e9zenac",
      "Ibrahim Ayed",
      "Micka\u00ebl Chen",
      "Sylvain Lamprier",
      "Patrick Gallinari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.05566"
  },
  {
    "id": "arXiv:2106.06596",
    "title": "Disentangling the Roles of Curation, Data-Augmentation and the Prior in  the Cold Posterior Effect",
    "abstract": "Disentangling the Roles of Curation, Data-Augmentation and the Prior in  the Cold Posterior Effect",
    "descriptor": "",
    "authors": [
      "Lorenzo Noci",
      "Kevin Roth",
      "Gregor Bachmann",
      "Sebastian Nowozin",
      "Thomas Hofmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06596"
  },
  {
    "id": "arXiv:2106.06615",
    "title": "Precise characterization of the prior predictive distribution of deep  ReLU networks",
    "abstract": "Precise characterization of the prior predictive distribution of deep  ReLU networks",
    "descriptor": "",
    "authors": [
      "Lorenzo Noci",
      "Gregor Bachmann",
      "Kevin Roth",
      "Sebastian Nowozin",
      "Thomas Hofmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06615"
  },
  {
    "id": "arXiv:2106.07760",
    "title": "RETRIEVE: Coreset Selection for Efficient and Robust Semi-Supervised  Learning",
    "abstract": "Comments: To appear in NeurIPS21",
    "descriptor": "\nComments: To appear in NeurIPS21\n",
    "authors": [
      "Krishnateja Killamsetty",
      "Xujiang Zhao",
      "Feng Chen",
      "Rishabh Iyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07760"
  },
  {
    "id": "arXiv:2106.07822",
    "title": "Canonical Face Embeddings",
    "abstract": "Comments: 13 pages, 9 figures, 3 tables",
    "descriptor": "\nComments: 13 pages, 9 figures, 3 tables\n",
    "authors": [
      "David McNeely-White",
      "Ben Sattelberg",
      "Nathaniel Blanchard",
      "Ross Beveridge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07822"
  },
  {
    "id": "arXiv:2106.09481",
    "title": "Stochastic Bias-Reduced Gradient Methods",
    "abstract": "Stochastic Bias-Reduced Gradient Methods",
    "descriptor": "",
    "authors": [
      "Hilal Asi",
      "Yair Carmon",
      "Arun Jambulapati",
      "Yujia Jin",
      "Aaron Sidford"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09481"
  },
  {
    "id": "arXiv:2106.09876",
    "title": "Anomaly Detection in Dynamic Graphs via Transformer",
    "abstract": "Comments: 13 pages, 5 figures",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "Yixin Liu",
      "Shirui Pan",
      "Yu Guang Wang",
      "Fei Xiong",
      "Liang Wang",
      "Qingfeng Chen",
      "Vincent CS Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09876"
  },
  {
    "id": "arXiv:2106.10394",
    "title": "Uncertain Decisions Facilitate Better Preference Learning",
    "abstract": "Comments: Accepted at NeurIPS 2021 (Spotlight)",
    "descriptor": "\nComments: Accepted at NeurIPS 2021 (Spotlight)\n",
    "authors": [
      "Cassidy Laidlaw",
      "Stuart Russell"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10394"
  },
  {
    "id": "arXiv:2106.10891",
    "title": "Open-set Label Noise Can Improve Robustness Against Inherent Label Noise",
    "abstract": "Comments: Accepted by NeurIPS 2021",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Hongxin Wei",
      "Lue Tao",
      "Renchunzi Xie",
      "Bo An"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10891"
  },
  {
    "id": "arXiv:2106.11068",
    "title": "Affine-Invariant Integrated Rank-Weighted Depth: Definition, Properties  and Finite Sample Analysis",
    "abstract": "Affine-Invariant Integrated Rank-Weighted Depth: Definition, Properties  and Finite Sample Analysis",
    "descriptor": "",
    "authors": [
      "Guillaume Staerman",
      "Pavlo Mozharovskyi",
      "St\u00e9phan Cl\u00e9men\u00e7on"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11068"
  },
  {
    "id": "arXiv:2106.11560",
    "title": "Finding Valid Adjustments under Non-ignorability with Minimal DAG  Knowledge",
    "abstract": "Finding Valid Adjustments under Non-ignorability with Minimal DAG  Knowledge",
    "descriptor": "",
    "authors": [
      "Abhin Shah",
      "Karthikeyan Shanmugam",
      "Kartik Ahuja"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11560"
  },
  {
    "id": "arXiv:2106.12151",
    "title": "Width-based Lookaheads with Learnt Base Policies and Heuristics Over the  Atari-2600 Benchmark",
    "abstract": "Width-based Lookaheads with Learnt Base Policies and Heuristics Over the  Atari-2600 Benchmark",
    "descriptor": "",
    "authors": [
      "Stefan O'Toole",
      "Nir Lipovetzky",
      "Miquel Ramirez",
      "Adrian Pearce"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.12151"
  },
  {
    "id": "arXiv:2106.12484",
    "title": "From Canonical Correlation Analysis to Self-supervised Graph Neural  Networks",
    "abstract": "Comments: Accepted by NeurIPS 2021 main conference",
    "descriptor": "\nComments: Accepted by NeurIPS 2021 main conference\n",
    "authors": [
      "Hengrui Zhang",
      "Qitian Wu",
      "Junchi Yan",
      "David Wipf",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.12484"
  },
  {
    "id": "arXiv:2106.12684",
    "title": "A Pure HTTP/3 Alternative to MQTT-over-QUIC in Resource-Constrained IoT",
    "abstract": "A Pure HTTP/3 Alternative to MQTT-over-QUIC in Resource-Constrained IoT",
    "descriptor": "",
    "authors": [
      "Darius Saif",
      "Ashraf Matrawy"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.12684"
  },
  {
    "id": "arXiv:2106.12997",
    "title": "Bayesian Optimization with High-Dimensional Outputs",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Wesley J. Maddox",
      "Maximilian Balandat",
      "Andrew Gordon Wilson",
      "Eytan Bakshy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.12997"
  },
  {
    "id": "arXiv:2106.13430",
    "title": "Subgraph Federated Learning with Missing Neighbor Generation",
    "abstract": "Comments: Accepted to NeurIPS 2021 (spotlight presentation)",
    "descriptor": "\nComments: Accepted to NeurIPS 2021 (spotlight presentation)\n",
    "authors": [
      "Ke Zhang",
      "Carl Yang",
      "Xiaoxiao Li",
      "Lichao Sun",
      "Siu Ming Yiu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.13430"
  },
  {
    "id": "arXiv:2106.13718",
    "title": "Black Box Probabilistic Numerics",
    "abstract": "Black Box Probabilistic Numerics",
    "descriptor": "",
    "authors": [
      "Onur Teymur",
      "Christopher N. Foley",
      "Philip G. Breen",
      "Toni Karvonen",
      "Chris. J. Oates"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.13718"
  },
  {
    "id": "arXiv:2106.13871",
    "title": "Transflower: probabilistic autoregressive dance generation with  multimodal attention",
    "abstract": "Transflower: probabilistic autoregressive dance generation with  multimodal attention",
    "descriptor": "",
    "authors": [
      "Guillermo Valle-P\u00e9rez",
      "Gustav Eje Henter",
      "Jonas Beskow",
      "Andr\u00e9 Holzapfel",
      "Pierre-Yves Oudeyer",
      "Simon Alexanderson"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.13871"
  },
  {
    "id": "arXiv:2106.15580",
    "title": "Continuous Latent Process Flows",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Ruizhi Deng",
      "Marcus A. Brubaker",
      "Greg Mori",
      "Andreas M. Lehrmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.15580"
  },
  {
    "id": "arXiv:2107.02173",
    "title": "Is Automated Topic Model Evaluation Broken?: The Incoherence of  Coherence",
    "abstract": "Comments: Accepted to NeurIPS 2021 (spotlight presentation). CR version",
    "descriptor": "\nComments: Accepted to NeurIPS 2021 (spotlight presentation). CR version\n",
    "authors": [
      "Alexander Hoyle",
      "Pranav Goel",
      "Denis Peskov",
      "Andrew Hian-Cheong",
      "Jordan Boyd-Graber",
      "Philip Resnik"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.02173"
  },
  {
    "id": "arXiv:2107.04139",
    "title": "Learning to Delegate for Large-scale Vehicle Routing",
    "abstract": "Learning to Delegate for Large-scale Vehicle Routing",
    "descriptor": "",
    "authors": [
      "Sirui Li",
      "Zhongxia Yan",
      "Cathy Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.04139"
  },
  {
    "id": "arXiv:2107.04205",
    "title": "On the Variance of the Fisher Information for Deep Learning",
    "abstract": "Comments: Published in Advances in Neural Information Processing Systems 34 (NeurIPS 2021)",
    "descriptor": "\nComments: Published in Advances in Neural Information Processing Systems 34 (NeurIPS 2021)\n",
    "authors": [
      "Alexander Soen",
      "Ke Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.04205"
  },
  {
    "id": "arXiv:2107.04832",
    "title": "Dirichlet polynomials and entropy",
    "abstract": "Dirichlet polynomials and entropy",
    "descriptor": "",
    "authors": [
      "David I. Spivak",
      "Timothy Hosgood"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2107.04832"
  },
  {
    "id": "arXiv:2107.05768",
    "title": "Combiner: Full Attention Transformer with Sparse Computation Cost",
    "abstract": "Comments: NeurIPS 2021 spotlight",
    "descriptor": "\nComments: NeurIPS 2021 spotlight\n",
    "authors": [
      "Hongyu Ren",
      "Hanjun Dai",
      "Zihang Dai",
      "Mengjiao Yang",
      "Jure Leskovec",
      "Dale Schuurmans",
      "Bo Dai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05768"
  },
  {
    "id": "arXiv:2107.06591",
    "title": "Useful Open Call-by-Need",
    "abstract": "Comments: This is the version with proofs of the paper with the same title and authors in the proceedings of CSL 2022",
    "descriptor": "\nComments: This is the version with proofs of the paper with the same title and authors in the proceedings of CSL 2022\n",
    "authors": [
      "Beniamino Accattoli",
      "Maico Leberle"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2107.06591"
  },
  {
    "id": "arXiv:2107.07197",
    "title": "RBUE: A ReLU-Based Uncertainty Estimation Method of Deep Neural Networks",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2012.08334 by other authors",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2012.08334 by other authors\n",
    "authors": [
      "Yufeng Xia",
      "Jun Zhang",
      "Zhiqiang Gong",
      "Tingsong Jiang",
      "Wen Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07197"
  },
  {
    "id": "arXiv:2107.07208",
    "title": "Design of Distributed Reconfigurable Robotics Systems with ReconROS",
    "abstract": "Comments: The paper will be published in a future version of the journal ACM TRETS",
    "descriptor": "\nComments: The paper will be published in a future version of the journal ACM TRETS\n",
    "authors": [
      "Christian Lienen",
      "Marco Platzner"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.07208"
  },
  {
    "id": "arXiv:2107.08353",
    "title": "Top-label calibration and multiclass-to-binary reductions",
    "abstract": "Comments: Improved exposition and additional experiments compared to previous version. Multiclass-to-binary were implicit in the previous version; they have now been made explicit now",
    "descriptor": "\nComments: Improved exposition and additional experiments compared to previous version. Multiclass-to-binary were implicit in the previous version; they have now been made explicit now\n",
    "authors": [
      "Chirag Gupta",
      "Aaditya K. Ramdas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.08353"
  },
  {
    "id": "arXiv:2107.08440",
    "title": "Fully Automated Machine Learning Pipeline for Echocardiogram  Segmentation",
    "abstract": "Fully Automated Machine Learning Pipeline for Echocardiogram  Segmentation",
    "descriptor": "",
    "authors": [
      "Hang Duong Thi Thuy",
      "Tuan Nguyen Minh",
      "Phi Nguyen Van",
      "Long Tran Quoc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.08440"
  },
  {
    "id": "arXiv:2107.09721",
    "title": "Online Projected Gradient Descent for Stochastic Optimization with  Decision-Dependent Distributions",
    "abstract": "Comments: To appear in IEEE L-CSS",
    "descriptor": "\nComments: To appear in IEEE L-CSS\n",
    "authors": [
      "Killian Wood",
      "Gianluca Bianchin",
      "Emiliano Dall'Anese"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.09721"
  },
  {
    "id": "arXiv:2107.10295",
    "title": "How to Tell Deep Neural Networks What We Know: A Review of Methods for  Inclusion of Domain-Knowledge",
    "abstract": "Comments: 15 pages; Revised version for Nature Scientific Reports. arXiv admin note: substantial text overlap with arXiv:2103.00180",
    "descriptor": "\nComments: 15 pages; Revised version for Nature Scientific Reports. arXiv admin note: substantial text overlap with arXiv:2103.00180\n",
    "authors": [
      "Tirtharaj Dash",
      "Sharad Chitlangia",
      "Aditya Ahuja",
      "Ashwin Srinivasan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.10295"
  },
  {
    "id": "arXiv:2107.11960",
    "title": "Temporal Alignment Prediction for Few-Shot Video Classification",
    "abstract": "Temporal Alignment Prediction for Few-Shot Video Classification",
    "descriptor": "",
    "authors": [
      "Fei Pan",
      "Chunlei Xu",
      "Jie Guo",
      "Yanwen Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.11960"
  },
  {
    "id": "arXiv:2107.11975",
    "title": "A Transductive Maximum Margin Classifier for Few-Shot Learning",
    "abstract": "A Transductive Maximum Margin Classifier for Few-Shot Learning",
    "descriptor": "",
    "authors": [
      "Fei Pan",
      "Chunlei Xu",
      "Jie Guo",
      "Yanwen Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.11975"
  },
  {
    "id": "arXiv:2107.11976",
    "title": "One Question Answering Model for Many Languages with Cross-lingual Dense  Passage Retrieval",
    "abstract": "Comments: Published as a conference paper at NeurIPS 2021. Our code and trained model are publicly available at this https URL",
    "descriptor": "\nComments: Published as a conference paper at NeurIPS 2021. Our code and trained model are publicly available at this https URL\n",
    "authors": [
      "Akari Asai",
      "Xinyan Yu",
      "Jungo Kasai",
      "Hannaneh Hajishirzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.11976"
  },
  {
    "id": "arXiv:2107.12085",
    "title": "Learning to Adversarially Blur Visual Object Tracking",
    "abstract": "Comments: This work has been accepted to ICCV 2021",
    "descriptor": "\nComments: This work has been accepted to ICCV 2021\n",
    "authors": [
      "Qing Guo",
      "Ziyi Cheng",
      "Felix Juefei-Xu",
      "Lei Ma",
      "Xiaofei Xie",
      "Yang Liu",
      "Jianjun Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.12085"
  },
  {
    "id": "arXiv:2107.12569",
    "title": "Self-Supervised Video Object Segmentation by Motion-Aware Mask  Propagation",
    "abstract": "Self-Supervised Video Object Segmentation by Motion-Aware Mask  Propagation",
    "descriptor": "",
    "authors": [
      "Bo Miao",
      "Mohammed Bennamoun",
      "Yongsheng Gao",
      "Ajmal Mian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.12569"
  },
  {
    "id": "arXiv:2107.12931",
    "title": "Autonomous Reinforcement Learning via Subgoal Curricula",
    "abstract": "Autonomous Reinforcement Learning via Subgoal Curricula",
    "descriptor": "",
    "authors": [
      "Archit Sharma",
      "Abhishek Gupta",
      "Sergey Levine",
      "Karol Hausman",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.12931"
  },
  {
    "id": "arXiv:2107.13034",
    "title": "Dataset Distillation with Infinitely Wide Convolutional Networks",
    "abstract": "Comments: Accepted to NeurIPS 2021. Code and datasets available at this https URL",
    "descriptor": "\nComments: Accepted to NeurIPS 2021. Code and datasets available at this https URL\n",
    "authors": [
      "Timothy Nguyen",
      "Roman Novak",
      "Lechao Xiao",
      "Jaehoon Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.13034"
  },
  {
    "id": "arXiv:2107.14641",
    "title": "Investigating Disagreement in the Scientific Literature",
    "abstract": "Comments: 49 pages, 10 figures",
    "descriptor": "\nComments: 49 pages, 10 figures\n",
    "authors": [
      "Wout S. Lamers",
      "Kevin Boyack",
      "Vincent Larivi\u00e8re",
      "Cassidy R. Sugimoto",
      "Nees Jan van Eck",
      "Ludo Waltman",
      "Dakota Murray"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.14641"
  },
  {
    "id": "arXiv:2108.02312",
    "title": "Backward Stability of the Schur Canonical Form",
    "abstract": "Comments: 19 pages",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Anastasiia Minenkova",
      "Evelyn Nitch-Griffin",
      "Vadim Olshevsky"
    ],
    "subjectives": [
      "Classical Analysis and ODEs (math.CA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.02312"
  },
  {
    "id": "arXiv:2108.10048",
    "title": "How Transferable Are Self-supervised Features in Medical Image  Classification Tasks?",
    "abstract": "Comments: Accepted to Machine Learning for Health (ML4H) (ML4H 2021)",
    "descriptor": "\nComments: Accepted to Machine Learning for Health (ML4H) (ML4H 2021)\n",
    "authors": [
      "Tuan Truong",
      "Sadegh Mohammadi",
      "Matthias Lenga"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.10048"
  },
  {
    "id": "arXiv:2108.10252",
    "title": "Federated Multi-Task Learning under a Mixture of Distributions",
    "abstract": "Comments: 77 pages, NeurIPS 2021",
    "descriptor": "\nComments: 77 pages, NeurIPS 2021\n",
    "authors": [
      "Othmane Marfoq",
      "Giovanni Neglia",
      "Aur\u00e9lien Bellet",
      "Laetitia Kameni",
      "Richard Vidal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.10252"
  },
  {
    "id": "arXiv:2108.11084",
    "title": "Efficient Transformer for Single Image Super-Resolution",
    "abstract": "Efficient Transformer for Single Image Super-Resolution",
    "descriptor": "",
    "authors": [
      "Zhisheng Lu",
      "Hong Liu",
      "Juncheng Li",
      "Linlin Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.11084"
  },
  {
    "id": "arXiv:2108.11204",
    "title": "Subgoal Search For Complex Reasoning Tasks",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Konrad Czechowski",
      "Tomasz Odrzyg\u00f3\u017ad\u017a",
      "Marek Zbysi\u0144ski",
      "Micha\u0142 Zawalski",
      "Krzysztof Olejnik",
      "Yuhuai Wu",
      "\u0141ukasz Kuci\u0144ski",
      "Piotr Mi\u0142o\u015b"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.11204"
  },
  {
    "id": "arXiv:2108.11575",
    "title": "Shifted Chunk Transformer for Spatio-Temporal Representational Learning",
    "abstract": "Comments: 15 pages, 3 figures",
    "descriptor": "\nComments: 15 pages, 3 figures\n",
    "authors": [
      "Xuefan Zha",
      "Wentao Zhu",
      "Tingxun Lv",
      "Sen Yang",
      "Ji Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.11575"
  },
  {
    "id": "arXiv:2108.11684",
    "title": "Disentangled generative models for robust dynamical system prediction",
    "abstract": "Comments: We provide code for reproducing our experiments at this https URL, Animated phase-space and video predictions are available at this https URL",
    "descriptor": "\nComments: We provide code for reproducing our experiments at this https URL, Animated phase-space and video predictions are available at this https URL\n",
    "authors": [
      "Stathi Fotiadis",
      "Shunlong Hu",
      "Mario Lino",
      "Chris Cantwell",
      "Anil Bharath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.11684"
  },
  {
    "id": "arXiv:2108.12097",
    "title": "A novel class of energy-preserving Runge-Kutta methods for the  Korteweg-de Vries equation",
    "abstract": "Comments: 22 pages, 15 figures",
    "descriptor": "\nComments: 22 pages, 15 figures\n",
    "authors": [
      "Yue Chen",
      "Yuezheng Gong",
      "Qi Hong",
      "Chuwu Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.12097"
  },
  {
    "id": "arXiv:2108.13294",
    "title": "The missing link: Developing a safety case for perception components in  automated driving",
    "abstract": "The missing link: Developing a safety case for perception components in  automated driving",
    "descriptor": "",
    "authors": [
      "Rick Salay",
      "Krzysztof Czarnecki",
      "Hiroshi Kuwajima",
      "Hirotoshi Yasuoka",
      "Toshihiro Nakae",
      "Vahdat Abdelzad",
      "Chengjie Huang",
      "Maximilian Kahn",
      "Van Duong Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.13294"
  },
  {
    "id": "arXiv:2108.13643",
    "title": "Learning to Synthesize Programs as Interpretable and Generalizable  Policies",
    "abstract": "Comments: NeurIPS 2021. 53 pages, 16 figures, 12 tables. Website at this https URL",
    "descriptor": "\nComments: NeurIPS 2021. 53 pages, 16 figures, 12 tables. Website at this https URL\n",
    "authors": [
      "Dweep Trivedi",
      "Jesse Zhang",
      "Shao-Hua Sun",
      "Joseph J. Lim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2108.13643"
  },
  {
    "id": "arXiv:2108.13720",
    "title": "Riemannian Optimization for Distance-Geometric Inverse Kinematics",
    "abstract": "Comments: Accepted for publication in IEEE Transactions on Robotics",
    "descriptor": "\nComments: Accepted for publication in IEEE Transactions on Robotics\n",
    "authors": [
      "Filip Mari\u0107",
      "Matthew Giamou",
      "Adam W. Hall",
      "Soroush Khoubyarian",
      "Ivan Petrovi\u0107",
      "Jonathan Kelly"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.13720"
  },
  {
    "id": "arXiv:2109.00482",
    "title": "Looking at the whole picture: constrained unsupervised anomaly  segmentation",
    "abstract": "Comments: Accepted at BMVC'21",
    "descriptor": "\nComments: Accepted at BMVC'21\n",
    "authors": [
      "Julio Silva-Rodr\u00edguez",
      "Valery Naranjo",
      "Jose Dolz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.00482"
  },
  {
    "id": "arXiv:2109.01896",
    "title": "GamePlan: Game-Theoretic Multi-Agent Planning with Human Drivers at  Intersections, Roundabouts, and Merging",
    "abstract": "Comments: Added Proof for v_k &gt; b_k in Section 5",
    "descriptor": "\nComments: Added Proof for v_k &gt; b_k in Section 5\n",
    "authors": [
      "Rohan Chandra",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2109.01896"
  },
  {
    "id": "arXiv:2109.03430",
    "title": "Can Noise on Qubits Be Learned in Quantum Neural Network? A Case Study  on QuantumFlow",
    "abstract": "Can Noise on Qubits Be Learned in Quantum Neural Network? A Case Study  on QuantumFlow",
    "descriptor": "",
    "authors": [
      "Zhiding Liang",
      "Zhepeng Wang",
      "Junhuan Yang",
      "Lei Yang",
      "Jinjun Xiong",
      "Yiyu Shi",
      "Weiwen Jiang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03430"
  },
  {
    "id": "arXiv:2109.05378",
    "title": "Modelling the Utility of Group Testing for Public Health Surveillance",
    "abstract": "Comments: 27 pages, 3 figures",
    "descriptor": "\nComments: 27 pages, 3 figures\n",
    "authors": [
      "G\u00fcnther Koliander",
      "Georg Pichler"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.05378"
  },
  {
    "id": "arXiv:2109.06287",
    "title": "Project 412Connect: Bridging Students and Communities",
    "abstract": "Comments: Published in EAAMO '21, New Horizons Award; fixed minor errors in appendix",
    "descriptor": "\nComments: Published in EAAMO '21, New Horizons Award; fixed minor errors in appendix\n",
    "authors": [
      "Alex DiChristofano",
      "Michael L. Hamilton",
      "Sera Linardi",
      "Mara F. McCloud"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2109.06287"
  },
  {
    "id": "arXiv:2109.07804",
    "title": "Detection Accuracy for Evaluating Compositional Explanations of Units",
    "abstract": "Comments: To appear in AIxIA 2021 conference (10 pages, 7 figures)",
    "descriptor": "\nComments: To appear in AIxIA 2021 conference (10 pages, 7 figures)\n",
    "authors": [
      "Sayo M. Makinwa",
      "Biagio La Rosa",
      "Roberto Capobianco"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07804"
  },
  {
    "id": "arXiv:2109.09704",
    "title": "BabelCalib: A Universal Approach to Calibrating Central Cameras",
    "abstract": "BabelCalib: A Universal Approach to Calibrating Central Cameras",
    "descriptor": "",
    "authors": [
      "Yaroslava Lochman",
      "Kostiantyn Liepieshov",
      "Jianhui Chen",
      "Michal Perdoch",
      "Christopher Zach",
      "James Pritts"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.09704"
  },
  {
    "id": "arXiv:2109.09854",
    "title": "Object Detection in Thermal Spectrum for Advanced Driver-Assistance  Systems (ADAS)",
    "abstract": "Comments: This work is carried under EU funded project (this https URL)",
    "descriptor": "\nComments: This work is carried under EU funded project (this https URL)\n",
    "authors": [
      "Muhammad Ali Farooq",
      "Peter Corcoran",
      "Cosmin Rotariu",
      "Waseem Shariff"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.09854"
  },
  {
    "id": "arXiv:2109.14523",
    "title": "Online Robust Reinforcement Learning with Model Uncertainty",
    "abstract": "Comments: Accepted by NeurIPS 2021",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Yue Wang",
      "Shaofeng Zou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.14523"
  },
  {
    "id": "arXiv:2110.00054",
    "title": "Learning to Predict Trustworthiness with Steep Slope Loss",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Yan Luo",
      "Yongkang Wong",
      "Mohan S. Kankanhalli",
      "Qi Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.00054"
  },
  {
    "id": "arXiv:2110.00455",
    "title": "Towards Gradient-based Bilevel Optimization with Non-convex Followers  and Beyond",
    "abstract": "Comments: Accepted by NeurIPS 2021, 13 pages. Supplementary materials, 5 pages",
    "descriptor": "\nComments: Accepted by NeurIPS 2021, 13 pages. Supplementary materials, 5 pages\n",
    "authors": [
      "Risheng Liu",
      "Yaohua Liu",
      "Shangzhi Zeng",
      "Jin Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.00455"
  },
  {
    "id": "arXiv:2110.00965",
    "title": "Coverage Axis: Inner Point Selection for 3D Shape Skeletonization",
    "abstract": "Coverage Axis: Inner Point Selection for 3D Shape Skeletonization",
    "descriptor": "",
    "authors": [
      "Zhiyang Dou",
      "Cheng Lin",
      "Rui Xu",
      "Lei Yang",
      "Shiqing Xin",
      "Taku Komura",
      "Wenping Wang"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.00965"
  },
  {
    "id": "arXiv:2110.01147",
    "title": "On the Interplay Between Sparsity, Naturalness, Intelligibility, and  Prosody in Speech Synthesis",
    "abstract": "On the Interplay Between Sparsity, Naturalness, Intelligibility, and  Prosody in Speech Synthesis",
    "descriptor": "",
    "authors": [
      "Cheng-I Jeff Lai",
      "Erica Cooper",
      "Yang Zhang",
      "Shiyu Chang",
      "Kaizhi Qian",
      "Yi-Lun Liao",
      "Yung-Sung Chuang",
      "Alexander H. Liu",
      "Junichi Yamagishi",
      "David Cox",
      "James Glass"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.01147"
  },
  {
    "id": "arXiv:2110.01168",
    "title": "BLEnD: Improving NDN Performance Over Wireless Links Using Interest  Bundling",
    "abstract": "Comments: Accepted for the proceedings of Military Communications Conference 2021 - NDN Session (MILCOM 2021) [Camera-ready version]",
    "descriptor": "\nComments: Accepted for the proceedings of Military Communications Conference 2021 - NDN Session (MILCOM 2021) [Camera-ready version]\n",
    "authors": [
      "Md Ashiqur Rahman",
      "Teng Liang",
      "Beichuan Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.01168"
  },
  {
    "id": "arXiv:2110.01732",
    "title": "Faster algorithm for counting of the integer points number in  $\u0394$-modular polyhedra",
    "abstract": "Faster algorithm for counting of the integer points number in  $\u0394$-modular polyhedra",
    "descriptor": "",
    "authors": [
      "D. V. Gribanov",
      "D. S. Malyshev"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.01732"
  },
  {
    "id": "arXiv:2110.01775",
    "title": "Deep Instance Segmentation with High-Resolution Automotive Radar",
    "abstract": "Deep Instance Segmentation with High-Resolution Automotive Radar",
    "descriptor": "",
    "authors": [
      "Jianan Liu",
      "Weiyi Xiong",
      "Liping Bai",
      "Yuxuan Xia",
      "Bing Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.01775"
  },
  {
    "id": "arXiv:2110.02912",
    "title": "Generative Optimization Networks for Memory Efficient Data Generation",
    "abstract": "Comments: Accepted in NeurIPS 2021 - Workshop on ML for Systems",
    "descriptor": "\nComments: Accepted in NeurIPS 2021 - Workshop on ML for Systems\n",
    "authors": [
      "Shreshth Tuli",
      "Shikhar Tuli",
      "Giuliano Casale",
      "Nicholas R. Jennings"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02912"
  },
  {
    "id": "arXiv:2110.02914",
    "title": "Foolish Crowds Support Benign Overfitting",
    "abstract": "Foolish Crowds Support Benign Overfitting",
    "descriptor": "",
    "authors": [
      "Niladri S. Chatterji",
      "Philip M. Long"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.02914"
  },
  {
    "id": "arXiv:2110.05529",
    "title": "HUNTER: AI based Holistic Resource Management for Sustainable Cloud  Computing",
    "abstract": "Comments: Accepted in Elsevier Journal of Systems and Software, 2021",
    "descriptor": "\nComments: Accepted in Elsevier Journal of Systems and Software, 2021\n",
    "authors": [
      "Shreshth Tuli",
      "Sukhpal Singh Gill",
      "Minxian Xu",
      "Peter Garraghan",
      "Rami Bahsoon",
      "Schahram Dustdar",
      "Rizos Sakellariou",
      "Omer Rana",
      "Rajkumar Buyya",
      "Giuliano Casale",
      "Nicholas R. Jennings"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2110.05529"
  },
  {
    "id": "arXiv:2110.06309",
    "title": "Exploring Wav2vec 2.0 fine-tuning for improved speech emotion  recognition",
    "abstract": "Comments: Submitted to ICASSP 2022",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Li-Wei Chen",
      "Alexander Rudnicky"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.06309"
  },
  {
    "id": "arXiv:2110.06356",
    "title": "Poncelet Parabola Pirouettes",
    "abstract": "Comments: 20 pages, 21 figures",
    "descriptor": "\nComments: 20 pages, 21 figures\n",
    "authors": [
      "Dan Reznik"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Computational Geometry (cs.CG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.06356"
  },
  {
    "id": "arXiv:2110.06726",
    "title": "Scalable Anytime Algorithms for Learning Formulas in Linear Temporal  Logic",
    "abstract": "Scalable Anytime Algorithms for Learning Formulas in Linear Temporal  Logic",
    "descriptor": "",
    "authors": [
      "Ritam Raha",
      "Rajarshi Roy",
      "Nathana\u00ebl Fijalkow",
      "Daniel Neider"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06726"
  },
  {
    "id": "arXiv:2110.07360",
    "title": "Multi-center, multi-vendor automated segmentation of left ventricular  anatomy in contrast-enhanced MRI",
    "abstract": "Multi-center, multi-vendor automated segmentation of left ventricular  anatomy in contrast-enhanced MRI",
    "descriptor": "",
    "authors": [
      "Carla Sendra-Balcells",
      "V\u00edctor M. Campello",
      "Carlos Mart\u00edn-Isla",
      "David Vilades Medel",
      "Mart\u00edn Lu\u00eds Descalzo",
      "Andrea Guala",
      "Jos\u00e9 F. Rodr\u00edguez Palomares",
      "Karim Lekadir"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.07360"
  },
  {
    "id": "arXiv:2110.07723",
    "title": "EMDS-7: Environmental Microorganism Image Dataset Seventh Version for  Multiple Object Detection Evaluation",
    "abstract": "EMDS-7: Environmental Microorganism Image Dataset Seventh Version for  Multiple Object Detection Evaluation",
    "descriptor": "",
    "authors": [
      "Hechen Yang",
      "Chen Li",
      "Xin Zhao",
      "Bencheng Cai",
      "Jiawei Zhang",
      "Pingli Ma",
      "Peng Zhao",
      "Ao Chen",
      "Tao Jiang",
      "Hongzan Sun",
      "Yueyang Teng",
      "Shouliang Qi",
      "Tao Jiang",
      "Marcin Grzegorzek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.07723"
  },
  {
    "id": "arXiv:2110.07797",
    "title": "EFENet: Reference-based Video Super-Resolution with Enhanced Flow  Estimation",
    "abstract": "Comments: 12 pages, 6 figures",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Yaping Zhao",
      "Mengqi Ji",
      "Ruqi Huang",
      "Bin Wang",
      "Shengjin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.07797"
  },
  {
    "id": "arXiv:2110.07922",
    "title": "Anomaly Detection in Multi-Agent Trajectories for Automated Driving",
    "abstract": "Comments: 15 pages incl. supplementary material, 8 figures, 4 tables (accepted by CoRL 2021)",
    "descriptor": "\nComments: 15 pages incl. supplementary material, 8 figures, 4 tables (accepted by CoRL 2021)\n",
    "authors": [
      "Julian Wiederer",
      "Arij Bouazizi",
      "Marco Troina",
      "Ulrich Kressel",
      "Vasileios Belagiannis"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.07922"
  },
  {
    "id": "arXiv:2110.08402",
    "title": "sbp-env: Sampling-based Motion Planners' Testing Environment",
    "abstract": "sbp-env: Sampling-based Motion Planners' Testing Environment",
    "descriptor": "",
    "authors": [
      "Tin Lai"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08402"
  },
  {
    "id": "arXiv:2110.08599",
    "title": "Mapping illegal waste dumping sites with neural-network classification  of satellite imagery",
    "abstract": "Comments: 5 pages, 3 figures, KDD Workshop on Data-driven Humanitarian Mapping held with the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, August 14, 2021",
    "descriptor": "\nComments: 5 pages, 3 figures, KDD Workshop on Data-driven Humanitarian Mapping held with the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, August 14, 2021\n",
    "authors": [
      "Maria Roberta Devesa",
      "Antonio Vazquez Brust"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.08599"
  },
  {
    "id": "arXiv:2110.08944",
    "title": "Developing a novel fair-loan-predictor through a multi-sensitive  debiasing pipeline: DualFair",
    "abstract": "Comments: 10 pages, 2 figures, 3 tables, 1 pseudocode",
    "descriptor": "\nComments: 10 pages, 2 figures, 3 tables, 1 pseudocode\n",
    "authors": [
      "Arashdeep Singh",
      "Jashandeep Singh",
      "Ariba Khan",
      "Amar Gupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.08944"
  },
  {
    "id": "arXiv:2110.10332",
    "title": "AI-Based Detection, Classification and Prediction/Prognosis in Medical  Imaging: Towards Radiophenomics",
    "abstract": "AI-Based Detection, Classification and Prediction/Prognosis in Medical  Imaging: Towards Radiophenomics",
    "descriptor": "",
    "authors": [
      "Fereshteh Yousefirizi",
      "Pierre Decazes",
      "Amine Amyar",
      "Su Ruan",
      "Babak Saboury",
      "Arman Rahmim"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.10332"
  },
  {
    "id": "arXiv:2110.10527",
    "title": "Sampling from Arbitrary Functions via PSD Models",
    "abstract": "Sampling from Arbitrary Functions via PSD Models",
    "descriptor": "",
    "authors": [
      "Ulysse Marteau-Ferey",
      "Francis Bach",
      "Alessandro Rudi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.10527"
  },
  {
    "id": "arXiv:2110.10540",
    "title": "On the Integration of Course of Action Playbooks into Shareable Cyber  Threat Intelligence",
    "abstract": "On the Integration of Course of Action Playbooks into Shareable Cyber  Threat Intelligence",
    "descriptor": "",
    "authors": [
      "Vasileios Mavroeidis",
      "Pavel Eis",
      "Martin Zadnik",
      "Marco Caseli",
      "Bret Jordan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.10540"
  },
  {
    "id": "arXiv:2110.11216",
    "title": "User-friendly introduction to PAC-Bayes bounds",
    "abstract": "User-friendly introduction to PAC-Bayes bounds",
    "descriptor": "",
    "authors": [
      "Pierre Alquier"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.11216"
  },
  {
    "id": "arXiv:2110.11405",
    "title": "Illiterate DALL-E Learns to Compose",
    "abstract": "Illiterate DALL-E Learns to Compose",
    "descriptor": "",
    "authors": [
      "Gautam Singh",
      "Fei Deng",
      "Sungjin Ahn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11405"
  },
  {
    "id": "arXiv:2110.11437",
    "title": "An echelon form of weakly infeasible semidefinite programs and bad  projections of the psd cone",
    "abstract": "Comments: to appear",
    "descriptor": "\nComments: to appear\n",
    "authors": [
      "G\u00e1bor Pataki",
      "Aleksandr Touzov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Symbolic Computation (cs.SC)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2110.11437"
  },
  {
    "id": "arXiv:2110.11501",
    "title": "Cortico-cerebellar networks as decoupling neural interfaces",
    "abstract": "Comments: To appear in Advances in Neural Information Processing Systems 35 (NeurIPS 2021); 15 pages and 5 figures in the main manuscript; 8 pages and 8 figures in the supplementary material",
    "descriptor": "\nComments: To appear in Advances in Neural Information Processing Systems 35 (NeurIPS 2021); 15 pages and 5 figures in the main manuscript; 8 pages and 8 figures in the supplementary material\n",
    "authors": [
      "Joseph Pemberton",
      "Ellen Boven",
      "Richard Apps",
      "Rui Ponte Costa"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11501"
  },
  {
    "id": "arXiv:2110.11540",
    "title": "Wacky Weights in Learned Sparse Representations and the Revenge of  Score-at-a-Time Query Evaluation",
    "abstract": "Wacky Weights in Learned Sparse Representations and the Revenge of  Score-at-a-Time Query Evaluation",
    "descriptor": "",
    "authors": [
      "Joel Mackenzie",
      "Andrew Trotman",
      "Jimmy Lin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.11540"
  },
  {
    "id": "arXiv:2110.11767",
    "title": "Exploiting Cross-Modal Prediction and Relation Consistency for  Semi-Supervised Image Captioning",
    "abstract": "Exploiting Cross-Modal Prediction and Relation Consistency for  Semi-Supervised Image Captioning",
    "descriptor": "",
    "authors": [
      "Yang Yang",
      "Hongchen Wei",
      "Hengshu Zhu",
      "Dianhai Yu",
      "Hui Xiong",
      "Jian Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11767"
  },
  {
    "id": "arXiv:2110.11943",
    "title": "Solving N-player dynamic routing games with congestion: a mean field  approach",
    "abstract": "Solving N-player dynamic routing games with congestion: a mean field  approach",
    "descriptor": "",
    "authors": [
      "Theophile Cabannes",
      "Mathieu Lauriere",
      "Julien Perolat",
      "Raphael Marinier",
      "Sertan Girgin",
      "Sarah Perrin",
      "Olivier Pietquin",
      "Alexandre M. Bayen",
      "Eric Goubault",
      "Romuald Elie"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.11943"
  },
  {
    "id": "arXiv:2110.12081",
    "title": "Off-policy Reinforcement Learning with Optimistic Exploration and  Distribution Correction",
    "abstract": "Off-policy Reinforcement Learning with Optimistic Exploration and  Distribution Correction",
    "descriptor": "",
    "authors": [
      "Jiachen Li",
      "Shuo Cheng",
      "Zhenyu Liao",
      "Huayan Wang",
      "William Yang Wang",
      "Qinxun Bai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.12081"
  },
  {
    "id": "arXiv:2110.12090",
    "title": "Towards Demystifying Intra-Function Parallelism in Serverless Computing",
    "abstract": "Comments: International Workshop on Serverless Computing (WoSC@Middleware 2021)",
    "descriptor": "\nComments: International Workshop on Serverless Computing (WoSC@Middleware 2021)\n",
    "authors": [
      "Michael Kiener",
      "Mohak Chadha",
      "Michael Gerndt"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2110.12090"
  },
  {
    "id": "arXiv:2110.12621",
    "title": "Accelerate 3D Object Processing via Spectral Layout",
    "abstract": "Accelerate 3D Object Processing via Spectral Layout",
    "descriptor": "",
    "authors": [
      "Yongyu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12621"
  },
  {
    "id": "arXiv:2110.13221",
    "title": "On Learning Prediction-Focused Mixtures",
    "abstract": "On Learning Prediction-Focused Mixtures",
    "descriptor": "",
    "authors": [
      "Abhishek Sharma",
      "Catherine Zeng",
      "Sanjana Narayanan",
      "Sonali Parbhoo",
      "Finale Doshi-Velez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.13221"
  },
  {
    "id": "arXiv:2110.13656",
    "title": "CLLD: Contrastive Learning with Label Distance for Text Classificatioin",
    "abstract": "CLLD: Contrastive Learning with Label Distance for Text Classificatioin",
    "descriptor": "",
    "authors": [
      "Jinhe Lan",
      "Qingyuan Zhan",
      "Chenhao Jiang",
      "Kunping Yuan",
      "Desheng Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13656"
  },
  {
    "id": "arXiv:2110.13970",
    "title": "Rademacher Random Projections with Tensor Networks",
    "abstract": "Rademacher Random Projections with Tensor Networks",
    "descriptor": "",
    "authors": [
      "Beheshteh T. Rakhshan",
      "Guillaume Rabusseau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.13970"
  },
  {
    "id": "arXiv:2110.14000",
    "title": "Towards Hyperparameter-free Policy Selection for Offline Reinforcement  Learning",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Siyuan Zhang",
      "Nan Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.14000"
  },
  {
    "id": "arXiv:2110.14047",
    "title": "Bounding the Distance to Unsafe Sets with Convex Optimization",
    "abstract": "Comments: 23 pages, 17 figures",
    "descriptor": "\nComments: 23 pages, 17 figures\n",
    "authors": [
      "Jared Miller",
      "Mario Sznaier"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.14047"
  },
  {
    "id": "arXiv:2110.14053",
    "title": "NeuroComb: Improving SAT Solving with Graph Neural Networks",
    "abstract": "NeuroComb: Improving SAT Solving with Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Wenxi Wang",
      "Yang Hu",
      "Mohit Tiwari",
      "Sarfraz Khurshid",
      "Kenneth McMillan",
      "Risto Miikkulainen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14053"
  },
  {
    "id": "arXiv:2110.14109",
    "title": "Eigencurve: Optimal Learning Rate Schedule for SGD on Quadratic  Objectives with Skewed Hessian Spectrums",
    "abstract": "Eigencurve: Optimal Learning Rate Schedule for SGD on Quadratic  Objectives with Skewed Hessian Spectrums",
    "descriptor": "",
    "authors": [
      "Rui Pan",
      "Haishan Ye",
      "Tong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.14109"
  },
  {
    "id": "arXiv:2110.14147",
    "title": "Image Comes Dancing with Collaborative Parsing-Flow Video Synthesis",
    "abstract": "Comments: TIP 2021",
    "descriptor": "\nComments: TIP 2021\n",
    "authors": [
      "Bowen Wu",
      "Zhenyu Xie",
      "Xiaodan Liang",
      "Yubei Xiao",
      "Haoye Dong",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.14147"
  },
  {
    "id": "arXiv:2110.14248",
    "title": "Learning Domain Invariant Representations in Goal-conditioned Block MDPs",
    "abstract": "Comments: 33 pages",
    "descriptor": "\nComments: 33 pages\n",
    "authors": [
      "Beining Han",
      "Chongyi Zheng",
      "Harris Chan",
      "Keiran Paster",
      "Michael R. Zhang",
      "Jimmy Ba"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.14248"
  },
  {
    "id": "arXiv:2110.14279",
    "title": "SiWa: See into Walls via Deep UWB Radar",
    "abstract": "Comments: 14 pages",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Tianyue Zheng",
      "Zhe Chen",
      "Jun Luo",
      "Lin Ke",
      "Chaoyang Zhao",
      "Yaowen Yang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.14279"
  },
  {
    "id": "arXiv:2110.14307",
    "title": "RF-Based Human Activity Recognition Using Signal Adapted Convolutional  Neural Network",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Zhe Chen",
      "Chao Cai",
      "Tianyue Zheng",
      "Jun Luo",
      "Jie Xiong",
      "Xin Wang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.14307"
  },
  {
    "id": "arXiv:2110.14341",
    "title": "Active-LATHE: An Active Learning Algorithm for Boosting the Error  Exponent for Learning Homogeneous Ising Trees",
    "abstract": "Active-LATHE: An Active Learning Algorithm for Boosting the Error  Exponent for Learning Homogeneous Ising Trees",
    "descriptor": "",
    "authors": [
      "Fengzhuo Zhang",
      "Anshoo Tandon",
      "Vincent Y. F. Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.14341"
  },
  {
    "id": "arXiv:2110.14381",
    "title": "Temporal-attentive Covariance Pooling Networks for Video Recognition",
    "abstract": "Comments: Accepted to NeurIPS 2021; Project page: this https URL",
    "descriptor": "\nComments: Accepted to NeurIPS 2021; Project page: this https URL\n",
    "authors": [
      "Zilin Gao",
      "Qilong Wang",
      "Bingbing Zhang",
      "Qinghua Hu",
      "Peihua Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14381"
  },
  {
    "id": "arXiv:2110.14423",
    "title": "Vector-valued Gaussian Processes on Riemannian Manifolds via Gauge  Equivariant Projected Kernels",
    "abstract": "Vector-valued Gaussian Processes on Riemannian Manifolds via Gauge  Equivariant Projected Kernels",
    "descriptor": "",
    "authors": [
      "Michael Hutchinson",
      "Alexander Terenin",
      "Viacheslav Borovitskiy",
      "So Takao",
      "Yee Whye Teh",
      "Marc Peter Deisenroth"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14423"
  },
  {
    "id": "arXiv:2110.14431",
    "title": "Discrete Hamilton-Jacobi theory for systems with external forces",
    "abstract": "Comments: 30 pages, 3 figures",
    "descriptor": "\nComments: 30 pages, 3 figures\n",
    "authors": [
      "Manuel de Le\u00f3n",
      "Manuel Lainz",
      "Asier L\u00f3pez-Gord\u00f3n"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Numerical Analysis (math.NA)",
      "Classical Physics (physics.class-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.14431"
  },
  {
    "id": "arXiv:2110.14513",
    "title": "Neural Analysis and Synthesis: Reconstructing Speech from  Self-Supervised Representations",
    "abstract": "Comments: Neural Information Processing Systems (NeurIPS) 2021",
    "descriptor": "\nComments: Neural Information Processing Systems (NeurIPS) 2021\n",
    "authors": [
      "Hyeong-Seok Choi",
      "Juheon Lee",
      "Wansoo Kim",
      "Jie Hwan Lee",
      "Hoon Heo",
      "Kyogu Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.14513"
  },
  {
    "id": "arXiv:2110.14577",
    "title": "A Geometric Perspective towards Neural Calibration via Sensitivity  Decomposition",
    "abstract": "Comments: Accepted at NeurIPS 2021 as a spotlight paper",
    "descriptor": "\nComments: Accepted at NeurIPS 2021 as a spotlight paper\n",
    "authors": [
      "Junjiao Tian",
      "Dylan Yung",
      "Yen-Chang Hsu",
      "Zsolt Kira"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14577"
  }
]
[
  {
    "id": "arXiv:2110.08252",
    "title": "A Rate-Distortion Framework for Explaining Black-box Model Decisions",
    "abstract": "We present the Rate-Distortion Explanation (RDE) framework, a mathematically\nwell-founded method for explaining black-box model decisions. The framework is\nbased on perturbations of the target input signal and applies to any\ndifferentiable pre-trained model such as neural networks. Our experiments\ndemonstrate the framework's adaptability to diverse data modalities,\nparticularly images, audio, and physical simulations of urban environments.",
    "descriptor": "",
    "authors": [
      "Stefan Kolek",
      "Duc Anh Nguyen",
      "Ron Levie",
      "Joan Bruna",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.08252"
  },
  {
    "id": "arXiv:2110.08253",
    "title": "A Field Guide to Scientific XAI: Transparent and Interpretable Deep  Learning for Bioinformatics Research",
    "abstract": "Deep learning has become popular because of its potential to achieve high\naccuracy in prediction tasks. However, accuracy is not always the only goal of\nstatistical modelling, especially for models developed as part of scientific\nresearch. Rather, many scientific models are developed to facilitate scientific\ndiscovery, by which we mean to abstract a human-understandable representation\nof the natural world. Unfortunately, the opacity of deep neural networks limit\ntheir role in scientific discovery, creating a new demand for models that are\ntransparently interpretable. This article is a field guide to transparent model\ndesign. It provides a taxonomy of transparent model design concepts, a\npractical workflow for putting design concepts into practice, and a general\ntemplate for reporting design choices. We hope this field guide will help\nresearchers more effectively design transparently interpretable models, and\nthus enable them to use deep learning for scientific discovery.",
    "descriptor": "",
    "authors": [
      "Thomas P Quinn",
      "Sunil Gupta",
      "Svetha Venkatesh",
      "Vuong Le"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2110.08253"
  },
  {
    "id": "arXiv:2110.08254",
    "title": "Inconsistent Few-Shot Relation Classification via Cross-Attentional  Prototype Networks with Contrastive Learning",
    "abstract": "Standard few-shot relation classification (RC) is designed to learn a robust\nclassifier with only few labeled data for each class. However, previous works\nrarely investigate the effects of a different number of classes (i.e., $N$-way)\nand number of labeled data per class (i.e., $K$-shot) during training vs.\ntesting. In this work, we define a new task, \\textit{inconsistent few-shot RC},\nwhere the model needs to handle the inconsistency of $N$ and $K$ between\ntraining and testing. To address this new task, we propose Prototype\nNetwork-based cross-attention contrastive learning (ProtoCACL) to capture the\nrich mutual interactions between the support set and query set. Experimental\nresults demonstrate that our ProtoCACL can outperform the state-of-the-art\nbaseline model under both inconsistent $K$ and inconsistent $N$ settings, owing\nto its more robust and discriminate representations. Moreover, we identify that\nin the inconsistent few-shot learning setting, models can achieve better\nperformance with \\textit{less data} than the standard few-shot setting with\ncarefully-selected $N$ and $K$. In the end of the paper, we provide further\nanalyses and suggestions to systematically guide the selection of $N$ and $K$\nunder different scenarios.",
    "descriptor": "",
    "authors": [
      "Hongru Wang",
      "Zhijing Jin",
      "Jiarun Cao",
      "Gabriel Pui Cheong Fung",
      "Kam-Fai Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08254"
  },
  {
    "id": "arXiv:2110.08255",
    "title": "Yformer: U-Net Inspired Transformer Architecture for Far Horizon Time  Series Forecasting",
    "abstract": "Time series data is ubiquitous in research as well as in a wide variety of\nindustrial applications. Effectively analyzing the available historical data\nand providing insights into the far future allows us to make effective\ndecisions. Recent research has witnessed the superior performance of\ntransformer-based architectures, especially in the regime of far horizon time\nseries forecasting. However, the current state of the art sparse Transformer\narchitectures fail to couple down- and upsampling procedures to produce outputs\nin a similar resolution as the input. We propose the Yformer model, based on a\nnovel Y-shaped encoder-decoder architecture that (1) uses direct connection\nfrom the downscaled encoder layer to the corresponding upsampled decoder layer\nin a U-Net inspired architecture, (2) Combines the downscaling/upsampling with\nsparse attention to capture long-range effects, and (3) stabilizes the\nencoder-decoder stacks with the addition of an auxiliary reconstruction loss.\nExtensive experiments have been conducted with relevant baselines on four\nbenchmark datasets, demonstrating an average improvement of 19.82, 18.41\npercentage MSE and 13.62, 11.85 percentage MAE in comparison to the current\nstate of the art for the univariate and the multivariate settings respectively.",
    "descriptor": "",
    "authors": [
      "Kiran Madhusudhanan",
      "Johannes Burchert",
      "Nghia Duong-Trung",
      "Stefan Born",
      "Lars Schmidt-Thieme"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08255"
  },
  {
    "id": "arXiv:2110.08256",
    "title": "Model-Agnostic Meta-Attack: Towards Reliable Evaluation of Adversarial  Robustness",
    "abstract": "The vulnerability of deep neural networks to adversarial examples has\nmotivated an increasing number of defense strategies for promoting model\nrobustness. However, the progress is usually hampered by insufficient\nrobustness evaluations. As the de facto standard to evaluate adversarial\nrobustness, adversarial attacks typically solve an optimization problem of\ncrafting adversarial examples with an iterative process. In this work, we\npropose a Model-Agnostic Meta-Attack (MAMA) approach to discover stronger\nattack algorithms automatically. Our method learns the optimizer in adversarial\nattacks parameterized by a recurrent neural network, which is trained over a\nclass of data samples and defenses to produce effective update directions\nduring adversarial example generation. Furthermore, we develop a model-agnostic\ntraining algorithm to improve the generalization ability of the learned\noptimizer when attacking unseen defenses. Our approach can be flexibly\nincorporated with various attacks and consistently improves the performance\nwith little extra computational cost. Extensive experiments demonstrate the\neffectiveness of the learned attacks by MAMA compared to the state-of-the-art\nattacks on different defenses, leading to a more reliable evaluation of\nadversarial robustness.",
    "descriptor": "",
    "authors": [
      "Xiao Yang",
      "Yinpeng Dong",
      "Wenzhao Xiang",
      "Tianyu Pang",
      "Hang Su",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.08256"
  },
  {
    "id": "arXiv:2110.08257",
    "title": "C-AllOut: Catching & Calling Outliers by Type",
    "abstract": "Given an unlabeled dataset, wherein we have access only to pairwise\nsimilarities (or distances), how can we effectively (1) detect outliers, and\n(2) annotate/tag the outliers by type? Outlier detection has a large\nliterature, yet we find a key gap in the field: to our knowledge, no existing\nwork addresses the outlier annotation problem. Outliers are broadly classified\ninto 3 types, representing distinct patterns that could be valuable to\nanalysts: (a) global outliers are severe yet isolate cases that do not repeat,\ne.g., a data collection error; (b) local outliers diverge from their peers\nwithin a context, e.g., a particularly short basketball player; and (c)\ncollective outliers are isolated micro-clusters that may indicate coalition or\nrepetitions, e.g., frauds that exploit the same loophole. This paper presents\nC-AllOut: a novel and effective outlier detector that annotates outliers by\ntype. It is parameter-free and scalable, besides working only with pairwise\nsimilarities (or distances) when it is needed. We show that C-AllOut achieves\non par or significantly better performance than state-of-the-art detectors when\nspotting outliers regardless of their type. It is also highly effective in\nannotating outliers of particular types, a task that none of the baselines can\nperform.",
    "descriptor": "\nComments: 9+4 pages, 3 figures, 11 tables\n",
    "authors": [
      "Guilherme D. F. Silva",
      "Leman Akoglu",
      "Robson L. F. Cordeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08257"
  },
  {
    "id": "arXiv:2110.08258",
    "title": "Learning When and What to Ask: a Hierarchical Reinforcement Learning  Framework",
    "abstract": "Reliable AI agents should be mindful of the limits of their knowledge and\nconsult humans when sensing that they do not have sufficient knowledge to make\nsound decisions. We formulate a hierarchical reinforcement learning framework\nfor learning to decide when to request additional information from humans and\nwhat type of information would be helpful to request. Our framework extends\npartially-observed Markov decision processes (POMDPs) by allowing an agent to\ninteract with an assistant to leverage their knowledge in accomplishing tasks.\nResults on a simulated human-assisted navigation problem demonstrate the\neffectiveness of our framework: aided with an interaction policy learned by our\nmethod, a navigation policy achieves up to a 7x improvement in task success\nrate compared to performing tasks only by itself. The interaction policy is\nalso efficient: on average, only a quarter of all actions taken during a task\nexecution are requests for information. We analyze benefits and challenges of\nlearning with a hierarchical policy structure and suggest directions for future\nwork.",
    "descriptor": "\nComments: 15 pages, 3 figures, 4 tables\n",
    "authors": [
      "Khanh Nguyen",
      "Yonatan Bisk",
      "Hal Daum\u00e9 III"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.08258"
  },
  {
    "id": "arXiv:2110.08259",
    "title": "Training Neural Networks for Solving 1-D Optimal Piecewise Linear  Approximation",
    "abstract": "Recently, the interpretability of deep learning has attracted a lot of\nattention. A plethora of methods have attempted to explain neural networks by\nfeature visualization, saliency maps, model distillation, and so on. However,\nit is hard for these methods to reveal the intrinsic properties of neural\nnetworks. In this work, we studied the 1-D optimal piecewise linear\napproximation (PWLA) problem, and associated it with a designed neural network,\nnamed lattice neural network (LNN). We asked four essential questions as\nfollowing: (1) What are the characters of the optimal solution of the PWLA\nproblem? (2) Can an LNN converge to the global optimum? (3) Can an LNN converge\nto the local optimum? (4) Can an LNN solve the PWLA problem? Our main\ncontributions are that we propose the theorems to characterize the optimal\nsolution of the PWLA problem and present the LNN method for solving it. We\nevaluated the proposed LNNs on approximation tasks, forged an empirical method\nto improve the performance of LNNs. The experiments verified that our LNN\nmethod is competitive with the start-of-the-art method.",
    "descriptor": "",
    "authors": [
      "Hangcheng Dong",
      "Jingxiao Liao",
      "Yan Wang",
      "Yixin Chen",
      "Bingguo Liu",
      "Dong Ye",
      "Guodong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.08259"
  },
  {
    "id": "arXiv:2110.08260",
    "title": "Effective Certification of Monotone Deep Equilibrium Models",
    "abstract": "Monotone Operator Equilibrium Models (monDEQs) represent a class of models\ncombining the powerful deep equilibrium paradigm with convergence guarantees.\nFurther, their inherent robustness to adversarial perturbations makes\ninvestigating their certifiability a promising research direction.\nUnfortunately, existing approaches are either imprecise or severely limited in\nscalability. In this work, we propose the first scalable and precise monDEQ\nverifier, based on two key ideas: (i) a novel convex relaxation enabling\nefficient inclusion checks, and (ii) non-trivial mathematical insights\ncharacterizing the fixpoint operations at the heart of monDEQs on sets rather\nthan concrete inputs. An extensive evaluation of our verifier on the\nchallenging $\\ell_\\infty$ perturbations demonstrates that it exceeds\nstate-of-the-art performance in terms of speed (two orders of magnitude) and\nscalability (an order of magnitude) while yielding 25% higher certified\naccuracies on the same networks.",
    "descriptor": "",
    "authors": [
      "Mark Niklas M\u00fcller",
      "Robin Staab",
      "Marc Fischer",
      "Martin Vechev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08260"
  },
  {
    "id": "arXiv:2110.08263",
    "title": "FlexMatch: Boosting Semi-Supervised Learning with Curriculum Pseudo  Labeling",
    "abstract": "The recently proposed FixMatch achieved state-of-the-art results on most\nsemi-supervised learning (SSL) benchmarks. However, like other modern SSL\nalgorithms, FixMatch uses a pre-defined constant threshold for all classes to\nselect unlabeled data that contribute to the training, thus failing to consider\ndifferent learning status and learning difficulties of different classes. To\naddress this issue, we propose Curriculum Pseudo Labeling (CPL), a curriculum\nlearning approach to leverage unlabeled data according to the model's learning\nstatus. The core of CPL is to flexibly adjust thresholds for different classes\nat each time step to let pass informative unlabeled data and their pseudo\nlabels. CPL does not introduce additional parameters or computations (forward\nor backward propagation). We apply CPL to FixMatch and call our improved\nalgorithm FlexMatch. FlexMatch achieves state-of-the-art performance on a\nvariety of SSL benchmarks, with especially strong performances when the labeled\ndata are extremely limited or when the task is challenging. For example,\nFlexMatch outperforms FixMatch by 14.32% and 24.55% on CIFAR-100 and STL-10\ndatasets respectively, when there are only 4 labels per class. CPL also\nsignificantly boosts the convergence speed, e.g., FlexMatch can use only 1/5\ntraining time of FixMatch to achieve even better performance. Furthermore, we\nshow that CPL can be easily adapted to other SSL algorithms and remarkably\nimprove their performances. We open source our code at\nhttps://github.com/TorchSSL/TorchSSL.",
    "descriptor": "\nComments: Accepted by NeurIPS 2021; 16 pages with appendix; code: this https URL\n",
    "authors": [
      "Bowen Zhang",
      "Yidong Wang",
      "Wenxin Hou",
      "Hao Wu",
      "Jindong Wang",
      "Manabu Okumura",
      "Takahiro Shinozaki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08263"
  },
  {
    "id": "arXiv:2110.08264",
    "title": "Self-supervised Contrastive Attributed Graph Clustering",
    "abstract": "Attributed graph clustering, which learns node representation from node\nattribute and topological graph for clustering, is a fundamental but\nchallenging task for graph analysis. Recently, methods based on graph\ncontrastive learning (GCL) have obtained impressive clustering performance on\nthis task. Yet, we observe that existing GCL-based methods 1) fail to benefit\nfrom imprecise clustering labels; 2) require a post-processing operation to get\nclustering labels; 3) cannot solve out-of-sample (OOS) problem. To address\nthese issues, we propose a novel attributed graph clustering network, namely\nSelf-supervised Contrastive Attributed Graph Clustering (SCAGC). In SCAGC, by\nleveraging inaccurate clustering labels, a self-supervised contrastive loss,\nwhich aims to maximize the similarities of intra-cluster nodes while minimizing\nthe similarities of inter-cluster nodes, are designed for node representation\nlearning. Meanwhile, a clustering module is built to directly output clustering\nlabels by contrasting the representation of different clusters. Thus, for the\nOOS nodes, SCAGC can directly calculate their clustering labels. Extensive\nexperimental results on four benchmark datasets have shown that SCAGC\nconsistently outperforms 11 competitive clustering methods.",
    "descriptor": "",
    "authors": [
      "Wei Xia",
      "Quanxue Gao",
      "Ming Yang",
      "Xinbo Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08264"
  },
  {
    "id": "arXiv:2110.08265",
    "title": "Knowledge-driven Active Learning",
    "abstract": "In the last few years, Deep Learning models have become increasingly popular.\nHowever, their deployment is still precluded in those contexts where the amount\nof supervised data is limited and manual labelling expensive. Active learning\nstrategies aim at solving this problem by requiring supervision only on few\nunlabelled samples, which improve the most model performances after adding them\nto the training set. Most strategies are based on uncertain sample selection,\nand even often restricted to samples lying close to the decision boundary. Here\nwe propose a very different approach, taking into consideration domain\nknowledge. Indeed, in the case of multi-label classification, the relationships\namong classes offer a way to spot incoherent predictions, i.e., predictions\nwhere the model may most likely need supervision. We have developed a framework\nwhere first-order-logic knowledge is converted into constraints and their\nviolation is checked as a natural guide for sample selection. We empirically\ndemonstrate that knowledge-driven strategy outperforms standard strategies,\nparticularly on those datasets where domain knowledge is complete. Furthermore,\nwe show how the proposed approach enables discovering data distributions lying\nfar from training data. Finally, the proposed knowledge-driven strategy can be\nalso easily used in object-detection problems where standard uncertainty-based\ntechniques are difficult to apply.",
    "descriptor": "\nComments: Submitted to the ICLR 2022 conference\n",
    "authors": [
      "Gabriele Ciravegna",
      "Frederic Precioso",
      "Marco Gori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08265"
  },
  {
    "id": "arXiv:2110.08266",
    "title": "PG$^2$Net: Personalized and Group Preferences Guided Network for Next  Place Prediction",
    "abstract": "Predicting the next place to visit is a key in human mobility behavior\nmodeling, which plays a significant role in various fields, such as epidemic\ncontrol, urban planning, traffic management, and travel recommendation. To\nachieve this, one typical solution is designing modules based on RNN to capture\ntheir preferences to various locations. Although these RNN-based methods can\neffectively learn individual's hidden personalized preferences to her visited\nplaces, the interactions among users can only be weakly learned through the\nrepresentations of locations. Targeting this, we propose an end-to-end\nframework named personalized and group preference guided network (PG$^2$Net),\nconsidering the users' preferences to various places at both individual and\ncollective levels. Specifically, PG$^2$Net concatenates Bi-LSTM and attention\nmechanism to capture each user's long-term mobility tendency. To learn\npopulation's group preferences, we utilize spatial and temporal information of\nthe visitations to construct a spatio-temporal dependency module. We adopt a\ngraph embedding method to map users' trajectory into a hidden space, capturing\ntheir sequential relation. In addition, we devise an auxiliary loss to learn\nthe vectorial representation of her next location. Experiment results on two\nFoursquare check-in datasets and one mobile phone dataset indicate the\nadvantages of our model compared to the state-of-the-art baselines. Source\ncodes are available at https://github.com/urbanmobility/PG2Net.",
    "descriptor": "",
    "authors": [
      "Huifeng Li",
      "Bin Wang",
      "Fan Xia",
      "Xi Zhai",
      "Sulei Zhu",
      "Yanyan Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.08266"
  },
  {
    "id": "arXiv:2110.08267",
    "title": "A Broad-Spectrum Diffractive Network via Ensemble Learning",
    "abstract": "We proposed a broad-spectrum diffractive deep neural network (BS-D2NN)\nframework, which incorporates multi-wavelength channels of input lightfields\nand performs a parallel phase-only modulation utilizing a layered passive mask\narchitecture. A complementary multi-channel base learner cluster is formed in a\nhomogeneous ensemble framework based on the diffractive dispersion during\nlightwave modulation. In addition, both the optical Sum operation and the\nHybrid (optical-electronic) Maxout operation are performed for motivating the\nBS-D2NN to learn and construct a mapping between input lightfields and truth\nlabels under heterochromatic ambient lighting. The BS-D2NN can be trained using\ndeep learning algorithms so as to perform a kind of wavelength-insensitive\nhigh-accuracy object classification.",
    "descriptor": "\nComments: 4 pages, 3 figures\n",
    "authors": [
      "Jiashuo Shi",
      "Yingshi Chen",
      "Xinyu Zhang"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2110.08267"
  },
  {
    "id": "arXiv:2110.08268",
    "title": "Explainable Student Performance Prediction With Personalized Attention  for Explaining Why A Student Fails",
    "abstract": "As student failure rates continue to increase in higher education, predicting\nstudent performance in the following semester has become a significant demand.\nPersonalized student performance prediction helps educators gain a\ncomprehensive view of student status and effectively intervene in advance.\nHowever, existing works scarcely consider the explainability of student\nperformance prediction, which educators are most concerned about. In this\npaper, we propose a novel Explainable Student performance prediction method\nwith Personalized Attention (ESPA) by utilizing relationships in student\nprofiles and prior knowledge of related courses. The designed Bidirectional\nLong Short-Term Memory (BiLSTM) architecture extracts the semantic information\nin the paths with specific patterns. As for leveraging similar paths' internal\nrelations, a local and global-level attention mechanism is proposed to\ndistinguish the influence of different students or courses for making\npredictions. Hence, valid reasoning on paths can be applied to predict the\nperformance of students. The ESPA consistently outperforms the other\nstate-of-the-art models for student performance prediction, and the results are\nintuitively explainable. This work can help educators better understand the\ndifferent impacts of behavior on students' studies.",
    "descriptor": "\nComments: AAAI 2021 Workshop on AI Education/TIPCE 2021\n",
    "authors": [
      "Kun Niu",
      "Xipeng Cao",
      "Yicong Yu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08268"
  },
  {
    "id": "arXiv:2110.08270",
    "title": "From Multimodal to Unimodal Attention in Transformers using Knowledge  Distillation",
    "abstract": "Multimodal Deep Learning has garnered much interest, and transformers have\ntriggered novel approaches, thanks to the cross-attention mechanism. Here we\npropose an approach to deal with two key existing challenges: the high\ncomputational resource demanded and the issue of missing modalities. We\nintroduce for the first time the concept of knowledge distillation in\ntransformers to use only one modality at inference time. We report a full study\nanalyzing multiple student-teacher configurations, levels at which distillation\nis applied, and different methodologies. With the best configuration, we\nimproved the state-of-the-art accuracy by 3%, we reduced the number of\nparameters by 2.5 times and the inference time by 22%. Such\nperformance-computation tradeoff can be exploited in many applications and we\naim at opening a new research area where the deployment of complex models with\nlimited resources is demanded.",
    "descriptor": "\nComments: Preprint. Final paper accepted at the 17th IEEE International Conference on Advanced Video and Signal-based Surveillance, AVSS 2021, Virtual, November 16-19, 2021. 8 pages\n",
    "authors": [
      "Dhruv Agarwal",
      "Tanay Agrawal",
      "Laura M. Ferrari",
      "Fran\u00e7ois Bremond"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08270"
  },
  {
    "id": "arXiv:2110.08271",
    "title": "Training Deep Neural Networks with Joint Quantization and Pruning of  Weights and Activations",
    "abstract": "Quantization and pruning are core techniques used to reduce the inference\ncosts of deep neural networks. State-of-the-art quantization techniques are\ncurrently applied to both the weights and activations; however, pruning is most\noften applied to only the weights of the network. In this work, we jointly\napply novel uniform quantization and unstructured pruning methods to both the\nweights and activations of deep neural networks during training. Using our\nmethods, we empirically evaluate the currently accepted prune-then-quantize\nparadigm across a wide range of computer vision tasks and observe a\nnon-commutative nature when applied to both the weights and activations of deep\nneural networks. Informed by these observations, we articulate the\nnon-commutativity hypothesis: for a given deep neural network being trained for\na specific task, there exists an exact training schedule in which quantization\nand pruning can be introduced to optimize network performance. We identify that\nthis optimal ordering not only exists, but also varies across discriminative\nand generative tasks. Using the optimal training schedule within our training\nframework, we demonstrate increased performance per memory footprint over\nexisting solutions.",
    "descriptor": "",
    "authors": [
      "Xinyu Zhang",
      "Ian Colbert",
      "Ken Kreutz-Delgado",
      "Srinjoy Das"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08271"
  },
  {
    "id": "arXiv:2110.08272",
    "title": "Tree-based local explanations of machine learning model predictions,  AraucanaXAI",
    "abstract": "Increasingly complex learning methods such as boosting, bagging and deep\nlearning have made ML models more accurate, but harder to understand and\ninterpret. A tradeoff between performance and intelligibility is often to be\nfaced, especially in high-stakes applications like medicine. In the present\narticle we propose a novel methodological approach for generating explanations\nof the predictions of a generic ML model, given a specific instance for which\nthe prediction has been made, that can tackle both classification and\nregression tasks. Advantages of the proposed XAI approach include improved\nfidelity to the original model, the ability to deal with non-linear decision\nboundaries, and native support to both classification and regression problems",
    "descriptor": "\nComments: XAI Healthcare workshop 2021, AIME 2021\n",
    "authors": [
      "Enea Parimbelli",
      "Giovanna Nicora",
      "Szymon Wilk",
      "Wojtek Michalowski",
      "Riccardo Bellazzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08272"
  },
  {
    "id": "arXiv:2110.08294",
    "title": "Boosting coherence of language models",
    "abstract": "Naturality of long-term information structure -- coherence -- remains a\nchallenge in language generation. Large language models have insufficiently\nlearned such structure, as their long-form generations differ from natural text\nin measures of coherence. To alleviate this divergence, we propose coherence\nboosting, an inference procedure that increases the effect of distant context\non next-token prediction. We show the benefits of coherence boosting with\npretrained models by distributional analyses of generated ordinary text and\ndialog responses. We also find that coherence boosting with state-of-the-art\nmodels for various zero-shot NLP tasks yields performance gains with no\nadditional training.",
    "descriptor": "",
    "authors": [
      "Nikolay Malkin",
      "Zhen Wang",
      "Nebojsa Jojic"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08294"
  },
  {
    "id": "arXiv:2110.08296",
    "title": "Aspect-Oriented Summarization through Query-Focused Extraction",
    "abstract": "A reader interested in a particular topic might be interested in summarizing\ndocuments on that subject with a particular focus, rather than simply seeing\ngeneric summaries produced by most summarization systems. While query-focused\nsummarization has been explored in prior work, this is often approached from\nthe standpoint of document-specific questions or on synthetic data. Real users'\nneeds often fall more closely into aspects, broad topics in a dataset the user\nis interested in rather than specific queries. In this paper, we collect a\ndataset of realistic aspect-oriented test cases, AspectNews, which covers\ndifferent subtopics about articles in news sub-domains. We then investigate how\nquery-focused methods, for which we can construct synthetic data, can handle\nthis aspect-oriented setting: we benchmark extractive query-focused training\nschemes, and propose a contrastive augmentation approach to train the model. We\nevaluate on two aspect-oriented datasets and find this approach yields (a)\nfocused summaries, better than those from a generic summarization system, which\ngo beyond simple keyword matching; (b) a system sensitive to the choice of\nkeywords.",
    "descriptor": "",
    "authors": [
      "Ojas Ahuja",
      "Jiacheng Xu",
      "Akshay Gupta",
      "Kevin Horecka",
      "Greg Durrett"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08296"
  },
  {
    "id": "arXiv:2110.08297",
    "title": "Strong $L^p$-error analysis of nonlinear Monte Carlo approximations for  high-dimensional semilinear partial differential equations",
    "abstract": "Full-history recursive multilevel Picard (MLP) approximation schemes have\nbeen shown to overcome the curse of dimensionality in the numerical\napproximation of high-dimensional semilinear partial differential equations\n(PDEs) with general time horizons and Lipschitz continuous nonlinearities.\nHowever, each of the error analyses for MLP approximation schemes in the\nexisting literature studies the $L^2$-root-mean-square distance between the\nexact solution of the PDE under consideration and the considered MLP\napproximation and none of the error analyses in the existing literature\nprovides an upper bound for the more general $L^p$-distance between the exact\nsolution of the PDE under consideration and the considered MLP approximation.\nIt is the key contribution of this article to extend the $L^2$-error analysis\nfor MLP approximation schemes in the literature to a more general $L^p$-error\nanalysis with $p\\in (0,\\infty)$. In particular, the main result of this article\nproves that the proposed MLP approximation scheme indeed overcomes the curse of\ndimensionality in the numerical approximation of high-dimensional semilinear\nPDEs with the approximation error measured in the $L^p$-sense with $p \\in\n(0,\\infty)$.",
    "descriptor": "\nComments: 42 pages. arXiv admin note: text overlap with arXiv:2108.04620\n",
    "authors": [
      "Martin Hutzenthaler",
      "Arnulf Jentzen",
      "Benno Kuckuck",
      "Joshua Lee Padgett"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2110.08297"
  },
  {
    "id": "arXiv:2110.08300",
    "title": "When Combating Hype, Proceed with Caution",
    "abstract": "In an effort to avoid reinforcing widespread hype about the capabilities of\nstate-of-the-art language technology, researchers have developed practices in\nframing and citation that serve to deemphasize the field's successes. Though\nwell-meaning, these practices often yield misleading or even false claims about\nthe limits of our best technology. This is a problem, and it may be more\nserious than it looks: It limits our ability to mitigate short-term harms from\nNLP deployments and it limits our ability to prepare for the potentially\nenormous impacts of more distant future advances. This paper urges researchers\nto be careful about these claims and suggests some research directions and\ncommunication strategies that will make it easier to avoid or rebut them.",
    "descriptor": "",
    "authors": [
      "Samuel R. Bowman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08300"
  },
  {
    "id": "arXiv:2110.08303",
    "title": "Minimal Viable IO drivers for TrustZone",
    "abstract": "While TrustZone can isolate IO hardware, it lacks drivers for modern IO\ndevices. Rather than porting drivers, we propose a novel approach to deriving\nminimum viable drivers: developers exercise a full driver and record the\ndriver/device interactions; the processed recordings, dubbed driverlets, are\nreplayed in the TEE at run time to access IO devices.\nDriverlets address two key challenges: correctness and expressiveness, for\nwhich they build on a key construct called interaction template. The\ninteraction template ensures faithful reproduction of recorded IO jobs (albeit\non new IO data); it accepts dynamic input values; it tolerates nondeterministic\ndevice behaviors.\nWe demonstrate driverlets on a series of sophisticated devices, making them\naccessible to TrustZone for the first time to our knowledge. Our experiments\nshow that driverlets are secure, easy to build, and incur acceptable overhead\n(1.4x -2.7x compared to native drivers). Driverlets fill a critical gap in the\nTrustZone TEE, realizing its long-promised vision of secure IO.",
    "descriptor": "\nComments: 13 pages. Under submission\n",
    "authors": [
      "Liwei Guo",
      "Felix Xiaozhu Lin"
    ],
    "subjectives": [
      "Operating Systems (cs.OS)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.08303"
  },
  {
    "id": "arXiv:2110.08306",
    "title": "Memory-augmented Adversarial Autoencoders for Multivariate Time-series  Anomaly Detection with Deep Reconstruction and Prediction",
    "abstract": "Detecting anomalies for multivariate time-series without manual supervision\ncontinues a challenging problem due to the increased scale of dimensions and\ncomplexity of today's IT monitoring systems. Recent progress of unsupervised\ntime-series anomaly detection mainly use deep autoencoders to solve this\nproblem, i.e. training on normal samples and producing significant\nreconstruction error on abnormal inputs. However, in practice, autoencoders can\nreconstruct anomalies so well, due to powerful capabilites of neural networks.\nBesides, these approaches can be ineffective for identifying non-point\nanomalies, e.g. contextual anomalies and collective anomalies, since they\nsolely utilze a point-wise reconstruction objective. To tackle the above\nissues, we propose MemAAE (\\textit{Memory-augmented Adversarial Autoencoders\nwith Deep Reconstruction and Prediction}), a novel unsupervised anomaly\ndetection method for time-series. By jointly training two complementary proxy\ntasks, reconstruction and prediction, with a shared network architecture, we\nshow that detecting anomalies via multiple tasks obtains superior performance\nrather than single-task training. Additionally, a compressive memory module is\nintroduced to preserve normal patterns, avoiding unexpected generalization on\nabnormal inputs. Through extensive experiments, MemAAE achieves an overall F1\nscore of 0.90 on four public datasets, significantly outperforming the best\nbaseline by 0.02.",
    "descriptor": "",
    "authors": [
      "Qinfeng Xiao",
      "Shikuan Shao",
      "Jing Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08306"
  },
  {
    "id": "arXiv:2110.08307",
    "title": "GrowSpace: Learning How to Shape Plants",
    "abstract": "Plants are dynamic systems that are integral to our existence and survival.\nPlants face environment changes and adapt over time to their surrounding\nconditions. We argue that plant responses to an environmental stimulus are a\ngood example of a real-world problem that can be approached within a\nreinforcement learning (RL)framework. With the objective of controlling a plant\nby moving the light source, we propose GrowSpace, as a new RL benchmark. The\nback-end of the simulator is implemented using the Space Colonisation\nAlgorithm, a plant growing model based on competition for space. Compared to\nvideo game RL environments, this simulator addresses a real-world problem and\nserves as a test bed to visualize plant growth and movement in a faster way\nthan physical experiments. GrowSpace is composed of a suite of challenges that\ntackle several problems such as control, multi-stage learning,fairness and\nmulti-objective learning. We provide agent baselines alongside case studies to\ndemonstrate the difficulty of the proposed benchmark.",
    "descriptor": "",
    "authors": [
      "Yasmeen Hitti",
      "Ionelia Buzatu",
      "Manuel Del Verme",
      "Mark Lefsrud",
      "Florian Golemo",
      "Audrey Durand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08307"
  },
  {
    "id": "arXiv:2110.08308",
    "title": "Adaptive and Fair Transformation for Recoverable Mutual Exclusion",
    "abstract": "Mutual exclusion is one of the most commonly used techniques to handle\ncontention in concurrent systems. Traditionally, mutual exclusion algorithms\nhave been designed under the assumption that a process does not fail while\nacquiring/releasing a lock or while executing its critical section. However,\nfailures do occur in real life, potentially leaving the lock in an inconsistent\nstate. This gives rise to the problem of recoverable mutual exclusion (RME)\nthat involves designing a mutual exclusion (ME) algorithm that can tolerate\nfailures, while maintaining safety and liveness properties.\nIn this work, we present a framework that transforms any algorithm that\nsolves the RME problem into an algorithm that can also simultaneously adapt to\n(1) the number of processes competing for the lock, as well as (2) the number\nof failures that have occurred in the recent past, while maintaining the\ncorrectness and performance properties of the underlying RME algorithm.\nAdditionally, the algorithm constructed as a result of this transformation adds\ncertain desirable properties like fairness (a variation of FCFS) and bounded\nrecovery. Assume that the worst-case RMR complexity of a critical section\nrequest in the underlying RME algorithm is $R(n)$. Then, our framework yields\nan RME algorithm for which the worst-case RMR complexity of a critical section\nrequest is given by $\\mathcal{O}(\\min \\{\\ddot{c}, \\sqrt{F+1}, R(n)\\})$, where\n$\\ddot{c}$ denotes the point contention of the request and $F$ denotes the\nnumber of failures in the recent past of the request.\nWe further extend our framework by presenting a novel memory reclamation\nalgorithm to bound the worst-case space complexity of the RME algorithm. The\nmemory reclamation techniques maintain the fairness, performance and\ncorrectness properties of our transformation and is general enough to be\nemployed to bound the space of other RME algorithms.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2006.07086\n",
    "authors": [
      "Sahil Dhoked",
      "Neeraj Mittal"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.08308"
  },
  {
    "id": "arXiv:2110.08313",
    "title": "Reduced Order Dynamical Models For Complex Dynamics in Manufacturing and  Natural Systems Using Machine Learning",
    "abstract": "Dynamical analysis of manufacturing and natural systems provides critical\ninformation about production of manufactured and natural resources\nrespectively, thus playing an important role in assessing sustainability of\nthese systems. However, current dynamic models for these systems exist as\nmechanistic models, simulation of which is computationally intensive and does\nnot provide a simplified understanding of the mechanisms driving the overall\ndynamics. For such systems, lower-order models can prove useful to enable\nsustainability analysis through coupled dynamical analysis. There have been few\nattempts at finding low-order models of manufacturing and natural systems, with\nexisting work focused on model development of individual mechanism level. This\nwork seeks to fill this current gap in the literature of developing simplified\ndynamical models for these systems by developing reduced-order models using a\nmachine learning (ML) approach. The approach is demonstrated on an entire\nsoybean-oil to soybean-diesel process plant and a lake system. We use a\ngrey-box ML method with a standard nonlinear optimization approach to identify\nrelevant models of governing dynamics as ODEs using the data simulated from\nmechanistic models. Results show that the method identifies a high accuracy\nlinear ODE models for the process plant, reflective of underlying linear\nstoichiometric mechanisms and mass balance driving the dynamics. For the\nnatural systems, we modify the ML approach to include the effect of past\ndynamics, which gives non-linear ODE. While the modified approach provides a\nbetter match to dynamics of stream flow, it falls short of completely\nrecreating the dynamics. We conclude that the proposed ML approach work well\nfor systems where dynamics is smooth, such as in manufacturing plant whereas\ndoes not work perfectly well in case of chaotic dynamics such as water stream\nflow.",
    "descriptor": "\nComments: 16 pages, 11 figures\n",
    "authors": [
      "William Farlessyost",
      "Shweta Singh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08313"
  },
  {
    "id": "arXiv:2110.08314",
    "title": "3D Human Pose Estimation for Free-form Activity Using WiFi Signals",
    "abstract": "WiFi human sensing has become increasingly attractive in enabling emerging\nhuman-computer interaction applications. The corresponding technique has\ngradually evolved from the classification of multiple activity types to more\nfine-grained tracking of 3D human poses. However, existing WiFi-based 3D human\npose tracking is limited to a set of predefined activities. In this work, we\npresent Winect, a 3D human pose tracking system for free-form activity using\ncommodity WiFi devices. Our system tracks free-form activity by estimating a 3D\nskeleton pose that consists of a set of joints of the human body. In\nparticular, we combine signal separation and joint movement modeling to achieve\nfree-form activity tracking. Our system first identifies the moving limbs by\nleveraging the two-dimensional angle of arrival of the signals reflected off\nthe human body and separates the entangled signals for each limb. Then, it\ntracks each limb and constructs a 3D skeleton of the body by modeling the\ninherent relationship between the movements of the limb and the corresponding\njoints. Our evaluation results show that Winect is environment-independent and\nachieves centimeter-level accuracy for free-form activity tracking under\nvarious challenging environments including the none-line-of-sight (NLoS)\nscenarios.",
    "descriptor": "",
    "authors": [
      "Yili Ren",
      "Jie Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.08314"
  },
  {
    "id": "arXiv:2110.08317",
    "title": "Coverage Probability of Double-IRS Assisted Communication Systems",
    "abstract": "In this paper, we focus on the coverage probability of a double-intelligent\nreflecting surface (IRS) assisted wireless network and study the impact of\nmultiplicative beamforming gain and correlated Rayleigh fading. In particular,\nwe obtain a novel closed-form expression of the coverage probability of a\nsingle-input single-output (SISO) system assisted by two large IRSs while being\ndependent on the corresponding arbitrary reflecting beamforming matrices (RBMs)\nand large-scale statistics in terms of correlation matrices. Taking advantage\nof the large-scale statistics, i.e., statistical channel state information\n(CSI), we perform optimization of the RBMs of both IRSs once per several\ncoherence intervals rather than at each interval. Hence, we achieve a reduction\nof the computational complexity, otherwise increased in multi-IRS-assisted\nnetworks during their RBM optimization. Numerical results validate the\nanalytical expressions even for small IRSs, confirm enhanced performance over\nthe conventional single-IRS counterpart, and reveal insightful properties.",
    "descriptor": "\nComments: accepted in IEEE Wireless Communications Letters\n",
    "authors": [
      "Anastasios Papazafeiropoulos",
      "Pandelis Kourtessis",
      "Symeon Chatzinotas",
      "John M. Senior"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.08317"
  },
  {
    "id": "arXiv:2110.08318",
    "title": "Dynamic probabilistic logic models for effective abstractions in RL",
    "abstract": "State abstraction enables sample-efficient learning and better task transfer\nin complex reinforcement learning environments. Recently, we proposed RePReL\n(Kokel et al. 2021), a hierarchical framework that leverages a relational\nplanner to provide useful state abstractions for learning. We present a brief\noverview of this framework and the use of a dynamic probabilistic logic model\nto design these state abstractions. Our experiments show that RePReL not only\nachieves better performance and efficient learning on the task at hand but also\ndemonstrates better generalization to unseen tasks.",
    "descriptor": "\nComments: Accepted at StarAI 2021 (held in conjunction with IJCLR 2021)\n",
    "authors": [
      "Harsha Kokel",
      "Arjun Manoharan",
      "Sriraam Natarajan",
      "Balaraman Ravindran",
      "Prasad Tadepalli"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08318"
  },
  {
    "id": "arXiv:2110.08321",
    "title": "Efficient Representations for Privacy-Preserving Inference",
    "abstract": "Deep neural networks have a wide range of applications across multiple\ndomains such as computer vision and medicine. In many cases, the input of a\nmodel at inference time can consist of sensitive user data, which raises\nquestions concerning the levels of privacy and trust guaranteed by such\nservices. Much existing work has leveraged homomorphic encryption (HE) schemes\nthat enable computation on encrypted data to achieve private inference for\nmulti-layer perceptrons and CNNs. An early work along this direction was\nCryptoNets, which takes 250 seconds for one MNIST inference. The main\nlimitation of such approaches is that of compute, which is due to the costly\nnature of the NTT (number theoretic transform)operations that constitute HE\noperations. Others have proposed the use of model pruning and efficient data\nrepresentations to reduce the number of HE operations required. In this paper,\nwe focus on improving upon existing work by proposing changes to the\nrepresentations of intermediate tensors during CNN inference. We construct and\nevaluate private CNNs on the MNIST and CIFAR-10 datasets, and achieve over a\ntwo-fold reduction in the number of operations used for inferences of the\nCryptoNets architecture.",
    "descriptor": "\nComments: 8 pages, 2 figures\n",
    "authors": [
      "Han Xuanyuan",
      "Francisco Vargas",
      "Stephen Cummins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.08321"
  },
  {
    "id": "arXiv:2110.08322",
    "title": "Robustness of different loss functions and their impact on networks  learning capability",
    "abstract": "Recent developments in AI have made it ubiquitous, every industry is trying\nto adopt some form of intelligent processing of their data. Despite so many\nadvances in the field, AIs full capability is yet to be exploited by the\nindustry. Industries that involve some risk factors still remain cautious about\nthe usage of AI due to the lack of trust in such autonomous systems.\nPresent-day AI might be very good in a lot of things but it is very bad in\nreasoning and this behavior of AI can lead to catastrophic results. Autonomous\ncars crashing into a person or a drone getting stuck in a tree are a few\nexamples where AI decisions lead to catastrophic results. To develop insight\nand generate an explanation about the learning capability of AI, we will try to\nanalyze the working of loss functions. For our case, we will use two sets of\nloss functions, generalized loss functions like Binary cross-entropy or BCE and\nspecialized loss functions like Dice loss or focal loss. Through a series of\nexperiments, we will establish whether combining different loss functions is\nbetter than using a single loss function and if yes, then what is the reason\nbehind it. In order to establish the difference between generalized loss and\nspecialized losses, we will train several models using the above-mentioned\nlosses and then compare their robustness on adversarial examples. In\nparticular, we will look at how fast the accuracy of different models decreases\nwhen we change the pixels corresponding to the most salient gradients.",
    "descriptor": "",
    "authors": [
      "Vishal Rajput"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08322"
  },
  {
    "id": "arXiv:2110.08323",
    "title": "On Learning the Transformer Kernel",
    "abstract": "In this work we introduce KERNELIZED TRANSFORMER, a generic, scalable, data\ndriven framework for learning the kernel function in Transformers. Our\nframework approximates the Transformer kernel as a dot product between spectral\nfeature maps and learns the kernel by learning the spectral distribution. This\nnot only helps in learning a generic kernel end-to-end, but also reduces the\ntime and space complexity of Transformers from quadratic to linear. We show\nthat KERNELIZED TRANSFORMERS achieve performance comparable to existing\nefficient Transformer architectures, both in terms of accuracy as well as\ncomputational efficiency. Our study also demonstrates that the choice of the\nkernel has a substantial impact on performance, and kernel learning variants\nare competitive alternatives to fixed kernel Transformers, both in long as well\nas short sequence tasks.",
    "descriptor": "\nComments: 26 pages, of which 11 form the appendix. 6 figures of which 2 are part of appendix\n",
    "authors": [
      "Sankalan Pal Chowdhury",
      "Adamos Solomou",
      "Avinava Dubey",
      "Mrinmaya Sachan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08323"
  },
  {
    "id": "arXiv:2110.08324",
    "title": "Mitigating Membership Inference Attacks by Self-Distillation Through a  Novel Ensemble Architecture",
    "abstract": "Membership inference attacks are a key measure to evaluate privacy leakage in\nmachine learning (ML) models. These attacks aim to distinguish training members\nfrom non-members by exploiting differential behavior of the models on member\nand non-member inputs. The goal of this work is to train ML models that have\nhigh membership privacy while largely preserving their utility; we therefore\naim for an empirical membership privacy guarantee as opposed to the provable\nprivacy guarantees provided by techniques like differential privacy, as such\ntechniques are shown to deteriorate model utility. Specifically, we propose a\nnew framework to train privacy-preserving models that induces similar behavior\non member and non-member inputs to mitigate membership inference attacks. Our\nframework, called SELENA, has two major components. The first component and the\ncore of our defense is a novel ensemble architecture for training. This\narchitecture, which we call Split-AI, splits the training data into random\nsubsets, and trains a model on each subset of the data. We use an adaptive\ninference strategy at test time: our ensemble architecture aggregates the\noutputs of only those models that did not contain the input sample in their\ntraining data. We prove that our Split-AI architecture defends against a large\nfamily of membership inference attacks, however, it is susceptible to new\nadaptive attacks. Therefore, we use a second component in our framework called\nSelf-Distillation to protect against such stronger attacks. The\nSelf-Distillation component (self-)distills the training dataset through our\nSplit-AI ensemble, without using any external public datasets. Through\nextensive experiments on major benchmark datasets we show that SELENA presents\na superior trade-off between membership privacy and utility compared to the\nstate of the art.",
    "descriptor": "",
    "authors": [
      "Xinyu Tang",
      "Saeed Mahloujifar",
      "Liwei Song",
      "Virat Shejwalkar",
      "Milad Nasr",
      "Amir Houmansadr",
      "Prateek Mittal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08324"
  },
  {
    "id": "arXiv:2110.08327",
    "title": "Solving Image PDEs with a Shallow Network",
    "abstract": "Partial differential equations (PDEs) are typically used as models of\nphysical processes but are also of great interest in PDE-based image\nprocessing. However, when it comes to their use in imaging, conventional\nnumerical methods for solving PDEs tend to require very fine grid resolution\nfor stability, and as a result have impractically high computational cost. This\nwork applies BLADE (Best Linear Adaptive Enhancement), a shallow learnable\nfiltering framework, to PDE solving, and shows that the resulting approach is\nefficient and accurate, operating more reliably at coarse grid resolutions than\nclassical methods. As such, the model can be flexibly used for a wide variety\nof problems in imaging.",
    "descriptor": "\nComments: 21 pages, 22 figures, references arXiv:1802.06130, arXiv:1711.10700, arXiv:1606.01299\n",
    "authors": [
      "Pascal Tom Getreuer",
      "Peyman Milanfar",
      "Xiyang Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.08327"
  },
  {
    "id": "arXiv:2110.08329",
    "title": "Control Prefixes for Text Generation",
    "abstract": "Prompt learning methods adapt pre-trained language models to downstream\napplications by using a task-specific prompt together with the input. Most of\nthe current work on prompt learning in text generation relies on a shared\ndataset-level prompt for all examples in the dataset. We extend this approach\nand propose a dynamic method, Control Prefixes, which allows for the inclusion\nof conditional input-dependent information in each prompt. Control Prefixes is\nat the intersection of prompt learning and controlled generation, empowering\nthe model to have finer-grained control during text generation. The method\nincorporates attribute-level learnable representations into different layers of\na pre-trained transformer, allowing for the generated text to be guided in a\nparticular direction. We provide a systematic evaluation of the technique and\napply it to five datasets from the GEM benchmark for natural language\ngeneration (NLG). We present state-of-the-art results on several data-to-text\ndatasets, including WebNLG.",
    "descriptor": "",
    "authors": [
      "Jordan Clive",
      "Kris Cao",
      "Marek Rei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08329"
  },
  {
    "id": "arXiv:2110.08330",
    "title": "Nothing Wasted: Full Contribution Enforcement in Federated Edge Learning",
    "abstract": "The explosive amount of data generated at the network edge makes mobile edge\ncomputing an essential technology to support real-time applications, calling\nfor powerful data processing and analysis provided by machine learning (ML)\ntechniques. In particular, federated edge learning (FEL) becomes prominent in\nsecuring the privacy of data owners by keeping the data locally used to train\nML models. Existing studies on FEL either utilize in-process optimization or\nremove unqualified participants in advance. In this paper, we enhance the\ncollaboration from all edge devices in FEL to guarantee that the ML model is\ntrained using all available local data to accelerate the learning process. To\nthat aim, we propose a collective extortion (CE) strategy under the\nimperfect-information multi-player FEL game, which is proved to be effective in\nhelping the server efficiently elicit the full contribution of all devices\nwithout worrying about suffering from any economic loss. Technically, our\nproposed CE strategy extends the classical extortion strategy in controlling\nthe proportionate share of expected utilities for a single opponent to the\nswiftly homogeneous control over a group of players, which further presents an\nattractive trait of being impartial for all participants. Moreover, the CE\nstrategy enriches the game theory hierarchy, facilitating a wider application\nscope of the extortion strategy. Both theoretical analysis and experimental\nevaluations validate the effectiveness and fairness of our proposed scheme.",
    "descriptor": "",
    "authors": [
      "Qin Hu",
      "Shengling Wang",
      "Zeihui Xiong",
      "Xiuzhen Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08330"
  },
  {
    "id": "arXiv:2110.08331",
    "title": "A New Approach for Interpretability and Reliability in Clinical Risk  Prediction: Acute Coronary Syndrome Scenario",
    "abstract": "We intend to create a new risk assessment methodology that combines the best\ncharacteristics of both risk score and machine learning models. More\nspecifically, we aim to develop a method that, besides having a good\nperformance, offers a personalized model and outcome for each patient, presents\nhigh interpretability, and incorporates an estimation of the prediction\nreliability which is not usually available. By combining these features in the\nsame approach we expect that it can boost the confidence of physicians to use\nsuch a tool in their daily activity. In order to achieve the mentioned goals, a\nthree-step methodology was developed: several rules were created by\ndichotomizing risk factors; such rules were trained with a machine learning\nclassifier to predict the acceptance degree of each rule (the probability that\nthe rule is correct) for each patient; that information was combined and used\nto compute the risk of mortality and the reliability of such prediction. The\nmethodology was applied to a dataset of patients admitted with any type of\nacute coronary syndromes (ACS), to assess the 30-days all-cause mortality risk.\nThe performance was compared with state-of-the-art approaches: logistic\nregression (LR), artificial neural network (ANN), and clinical risk score model\n(Global Registry of Acute Coronary Events - GRACE). The proposed approach\nachieved testing results identical to the standard LR, but offers superior\ninterpretability and personalization; it also significantly outperforms the\nGRACE risk model and the standard ANN model. The calibration curve also\nsuggests a very good generalization ability of the obtained model as it\napproaches the ideal curve. Finally, the reliability estimation of individual\npredictions presented a great correlation with the misclassifications rate.\nThose properties may have a beneficial application in other clinical scenarios\nas well. [abridged]",
    "descriptor": "\nComments: Accepted for publication in the Artificial Intelligence in Medicine journal. Abstract abridged to respect the arXiv's characters limit\n",
    "authors": [
      "Francisco Valente",
      "Jorge Henriques",
      "Sim\u00e3o Paredes",
      "Teresa Rocha",
      "Paulo de Carvalho",
      "Jo\u00e3o Morais"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.08331"
  },
  {
    "id": "arXiv:2110.08335",
    "title": "Trigger Hunting with a Topological Prior for Trojan Detection",
    "abstract": "Despite their success and popularity, deep neural networks (DNNs) are\nvulnerable when facing backdoor attacks. This impedes their wider adoption,\nespecially in mission critical applications. This paper tackles the problem of\nTrojan detection, namely, identifying Trojaned models -- models trained with\npoisoned data. One popular approach is reverse engineering, i.e., recovering\nthe triggers on a clean image by manipulating the model's prediction. One major\nchallenge of reverse engineering approach is the enormous search space of\ntriggers. To this end, we propose innovative priors such as diversity and\ntopological simplicity to not only increase the chances of finding the\nappropriate triggers but also improve the quality of the found triggers.\nMoreover, by encouraging a diverse set of trigger candidates, our method can\nperform effectively in cases with unknown target labels. We demonstrate that\nthese priors can significantly improve the quality of the recovered triggers,\nresulting in substantially improved Trojan detection accuracy as validated on\nboth synthetic and publicly available TrojAI benchmarks.",
    "descriptor": "\nComments: 16 pages, 9 figures\n",
    "authors": [
      "Xiaoling Hu",
      "Xiao Lin",
      "Michael Cogswell",
      "Yi Yao",
      "Susmit Jha",
      "Chao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2110.08335"
  },
  {
    "id": "arXiv:2110.08338",
    "title": "Exploratory Lagrangian-Based Particle Tracing Using Deep Learning",
    "abstract": "Time-varying vector fields produced by computational fluid dynamics\nsimulations are often prohibitively large and pose challenges for accurate\ninteractive analysis and exploration. To address these challenges, reduced\nLagrangian representations have been increasingly researched as a means to\nimprove scientific time-varying vector field exploration capabilities. This\npaper presents a novel deep neural network-based particle tracing method to\nexplore time-varying vector fields represented by Lagrangian flow maps. In our\nworkflow, in situ processing is first utilized to extract Lagrangian flow maps,\nand deep neural networks then use the extracted data to learn flow field\nbehavior. Using a trained model to predict new particle trajectories offers a\nfixed small memory footprint and fast inference. To demonstrate and evaluate\nthe proposed method, we perform an in-depth study of performance using a\nwell-known analytical data set, the Double Gyre. Our study considers two flow\nmap extraction strategies as well as the impact of the number of training\nsamples and integration durations on efficacy, evaluates multiple sampling\noptions for training and testing and informs hyperparameter settings. Overall,\nwe find our method requires a fixed memory footprint of 10.5 MB to encode a\nLagrangian representation of a time-varying vector field while maintaining\naccuracy. For post hoc analysis, loading the trained model costs only two\nseconds, significantly reducing the burden of I/O when reading data for\nvisualization. Moreover, our parallel implementation can infer one hundred\nlocations for each of two thousand new pathlines across the entire temporal\nresolution in 1.3 seconds using one NVIDIA Titan RTX GPU.",
    "descriptor": "",
    "authors": [
      "Mengjiao Han",
      "Sudhanshu Sane",
      "Chris R. Johnson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2110.08338"
  },
  {
    "id": "arXiv:2110.08339",
    "title": "A Static Analysis Framework for Data Science Notebooks",
    "abstract": "Notebooks provide an interactive environment for programmers to develop code,\nanalyse data and inject interleaved visualizations in a single environment.\nDespite their flexibility, a major pitfall that data scientists encounter is\nunexpected behaviour caused by the unique out-of-order execution model of\nnotebooks. As a result, data scientists face various challenges ranging from\nnotebook correctness, reproducibility and cleaning. In this paper, we propose a\nframework that performs static analysis on notebooks, incorporating their\nunique execution semantics. Our framework is general in the sense that it\naccommodate for a wide range of analyses, useful for various notebook use\ncases. We have instantiated our framework on a diverse set of analyses and have\nevaluated them on 2211 real world notebooks. Our evaluation demonstrates that\nthe vast majority (98.7%) of notebooks can be analysed in less than a second,\nwell within the time frame required by interactive notebook clients",
    "descriptor": "",
    "authors": [
      "Pavle Suboti\u0107",
      "Lazar Miliki\u0107",
      "Milan Stoji\u0107"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.08339"
  },
  {
    "id": "arXiv:2110.08340",
    "title": "Return migration of German-affiliated researchers: Analyzing departure  and return by gender, cohort, and discipline using Scopus bibliometric data  1996-2020",
    "abstract": "The international migration of researchers is a highly prized dimension of\nscientific mobility and motivates considerable policy debate. However, tracking\nmigration life courses of researchers is challenging due to data limitations.\nIn this study, we use Scopus bibliometric data on 8 million publications from\n1.1 million researchers who have published at least once with an affiliation\naddress from Germany in 1996-2020. We describe several key steps and algorithms\nwe develop that enable us to construct the partial life histories of published\nresearchers in this period. These tools allow us to explore both the\nout-migration of researchers with German affiliations as well as the subsequent\nreturn of a share of this group - the returnees. Our analyses shed light on\nimportant career stages and gender disparities between researchers who remain\nin Germany and those who both migrate out and those who eventually return.\nReturn migration streams are even more gender imbalanced and point to the\nimportance of additional efforts to attract female researchers back to Germany.\nWe document a slightly declining trend in return migration with cohorts which,\nfor most disciplines, is associated with decreasing German collaboration ties\namong cohorts of researchers who leave Germany. Also, gender disparities for\nthe most gender imbalanced disciplines are unlikely to be mitigated by return\nmigration given the gender compositions in cohorts of researchers who leave\nGermany and those who return. This analysis reveals new dimensions of scholarly\nmigration by investigating the return migration of published researchers which\nis critical for science policy development.",
    "descriptor": "\nComments: 21 pages, 6 figures\n",
    "authors": [
      "Xinyi Zhao",
      "Samin Aref",
      "Emilio Zagheni",
      "Guy Stecklov"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08340"
  },
  {
    "id": "arXiv:2110.08343",
    "title": "HyperSeed: Unsupervised Learning with Vector Symbolic Architectures",
    "abstract": "Motivated by recent innovations in biologically-inspired neuromorphic\nhardware, this paper presents a novel unsupervised machine learning approach\nnamed Hyperseed that leverages Vector Symbolic Architectures (VSA) for fast\nlearning a topology preserving feature map of unlabelled data. It relies on two\nmajor capabilities of VSAs: the binding operation and computing in\nsuperposition. In this paper, we introduce the algorithmic part of Hyperseed\nexpressed within Fourier Holographic Reduced Representations VSA model, which\nis specifically suited for implementation on spiking neuromorphic hardware. The\ntwo distinctive novelties of the Hyperseed algorithm are: 1) Learning from only\nfew input data samples and 2) A learning rule based on a single vector\noperation. These properties are demonstrated on synthetic datasets as well as\non illustrative benchmark use-cases, IRIS classification and a language\nidentification task using n-gram statistics.",
    "descriptor": "",
    "authors": [
      "Evgeny Osipov",
      "Sachin Kahawala",
      "Dilantha Haputhanthri",
      "Thimal Kempitiya",
      "Daswin De Silva",
      "Damminda Alahakoon",
      "Denis Kleyko"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08343"
  },
  {
    "id": "arXiv:2110.08345",
    "title": "Towards Transparent Interactive Semantic Parsing via Step-by-Step  Correction",
    "abstract": "Existing studies on semantic parsing focus primarily on mapping a\nnatural-language utterance to a corresponding logical form in one turn.\nHowever, because natural language can contain a great deal of ambiguity and\nvariability, this is a difficult challenge. In this work, we investigate an\ninteractive semantic parsing framework that explains the predicted logical form\nstep by step in natural language and enables the user to make corrections\nthrough natural-language feedback for individual steps. We focus on question\nanswering over knowledge bases (KBQA) as an instantiation of our framework,\naiming to increase the transparency of the parsing process and help the user\nappropriately trust the final answer. To do so, we construct INSPIRED, a\ncrowdsourced dialogue dataset derived from the ComplexWebQuestions dataset. Our\nexperiments show that the interactive framework with human feedback has the\npotential to greatly improve overall parse accuracy. Furthermore, we develop a\npipeline for dialogue simulation to evaluate our framework w.r.t. a variety of\nstate-of-the-art KBQA models without involving further crowdsourcing effort.\nThe results demonstrate that our interactive semantic parsing framework\npromises to be effective across such models.",
    "descriptor": "",
    "authors": [
      "Lingbo Mo",
      "Ashley Lewis",
      "Huan Sun",
      "Michael White"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08345"
  },
  {
    "id": "arXiv:2110.08350",
    "title": "Differentiable Network Pruning for Microcontrollers",
    "abstract": "Embedded and personal IoT devices are powered by microcontroller units\n(MCUs), whose extreme resource scarcity is a major obstacle for applications\nrelying on on-device deep learning inference. Orders of magnitude less storage,\nmemory and computational capacity, compared to what is typically required to\nexecute neural networks, impose strict structural constraints on the network\narchitecture and call for specialist model compression methodology. In this\nwork, we present a differentiable structured network pruning method for\nconvolutional neural networks, which integrates a model's MCU-specific resource\nusage and parameter importance feedback to obtain highly compressed yet\naccurate classification models. Our methodology (a) improves key resource usage\nof models up to 80x; (b) prunes iteratively while a model is trained, resulting\nin little to no overhead or even improved training time; (c) produces\ncompressed models with matching or improved resource usage up to 1.7x in less\ntime compared to prior MCU-specific methods. Compressed models are available\nfor download.",
    "descriptor": "",
    "authors": [
      "Edgar Liberis",
      "Nicholas D. Lane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.08350"
  },
  {
    "id": "arXiv:2110.08352",
    "title": "Omni-sparsity DNN: Fast Sparsity Optimization for On-Device Streaming  E2E ASR via Supernet",
    "abstract": "From wearables to powerful smart devices, modern automatic speech recognition\n(ASR) models run on a variety of edge devices with different computational\nbudgets. To navigate the Pareto front of model accuracy vs model size,\nresearchers are trapped in a dilemma of optimizing model accuracy by training\nand fine-tuning models for each individual edge device while keeping the\ntraining GPU-hours tractable. In this paper, we propose Omni-sparsity DNN,\nwhere a single neural network can be pruned to generate optimized model for a\nlarge range of model sizes. We develop training strategies for Omni-sparsity\nDNN that allows it to find models along the Pareto front of word-error-rate\n(WER) vs model size while keeping the training GPU-hours to no more than that\nof training one singular model. We demonstrate the Omni-sparsity DNN with\nstreaming E2E ASR models. Our results show great saving on training time and\nresources with similar or better accuracy on LibriSpeech compared to\nindividually pruned sparse models: 2%-6.6% better WER on Test-other.",
    "descriptor": "",
    "authors": [
      "Haichuan Yang",
      "Yuan Shangguan",
      "Dilin Wang",
      "Meng Li",
      "Pierce Chuang",
      "Xiaohui Zhang",
      "Ganesh Venkatesh",
      "Ozlem Kalinli",
      "Vikas Chandra"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.08352"
  },
  {
    "id": "arXiv:2110.08353",
    "title": "Revisiting Popularity and Demographic Biases in Recommender Evaluation  and Effectiveness",
    "abstract": "Recommendation algorithms are susceptible to popularity bias: a tendency to\nrecommend popular items even when they fail to meet user needs. A related issue\nis that the recommendation quality can vary by demographic groups. Marginalized\ngroups or groups that are under-represented in the training data may receive\nless relevant recommendations from these algorithms compared to others. In a\nrecent study, Ekstrand et al. investigate how recommender performance varies\naccording to popularity and demographics, and find statistically significant\ndifferences in recommendation utility between binary genders on two datasets,\nand significant effects based on age on one dataset. Here we reproduce those\nresults and extend them with additional analyses. We find statistically\nsignificant differences in recommender performance by both age and gender. We\nobserve that recommendation utility steadily degrades for older users, and is\nlower for women than men. We also find that the utility is higher for users\nfrom countries with more representation in the dataset. In addition, we find\nthat total usage and the popularity of consumed content are strong predictors\nof recommender performance and also vary significantly across demographic\ngroups.",
    "descriptor": "",
    "authors": [
      "Nicola Neophytou",
      "Bhaskar Mitra",
      "Catherine Stinson"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08353"
  },
  {
    "id": "arXiv:2110.08354",
    "title": "Faster Modular Composition",
    "abstract": "A new Las Vegas algorithm is presented for the composition of two polynomials\nmodulo a third one, over an arbitrary field. When the degrees of these\npolynomials are bounded by $n$, the algorithm uses $O(n^{1.43})$ field\noperations, breaking through the $3/2$ barrier in the exponent for the first\ntime. The previous fastest algebraic algorithms, due to Brent and Kung in 1978,\nrequire $O(n^{1.63})$ field operations in general, and ${n^{3/2+o(1)}}$ field\noperations in the particular case of power series over a field of large enough\ncharacteristic. If using cubic-time matrix multiplication, the new algorithm\nruns in ${n^{5/3+o(1)}}$ operations, while previous ones run in $O(n^2)$\noperations.\nOur approach relies on the computation of a matrix of algebraic relations\nthat is typically of small size. Randomization is used to reduce arbitrary\ninput to this favorable situation.",
    "descriptor": "",
    "authors": [
      "Vincent Neiger",
      "Bruno Salvy",
      "\u00c9ric Schost",
      "Gilles Villard"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2110.08354"
  },
  {
    "id": "arXiv:2110.08355",
    "title": "Learning with Noisy Labels by Targeted Relabeling",
    "abstract": "Crowdsourcing platforms are often used to collect datasets for training deep\nneural networks, despite higher levels of inaccurate labeling compared to\nexpert labeling. There are two common strategies to manage the impact of this\nnoise, the first involves aggregating redundant annotations, but comes at the\nexpense of labeling substantially fewer examples. Secondly, prior works have\nalso considered using the entire annotation budget to label as many examples as\npossible and subsequently apply denoising algorithms to implicitly clean up the\ndataset. We propose an approach which instead reserves a fraction of\nannotations to explicitly relabel highly probable labeling errors. In\nparticular, we allocate a large portion of the labeling budget to form an\ninitial dataset used to train a model. This model is then used to identify\nspecific examples that appear most likely to be incorrect, which we spend the\nremaining budget to relabel. Experiments across three model variations and four\nnatural language processing tasks show our approach outperforms both label\naggregation and advanced denoising methods designed to handle noisy labels when\nallocated the same annotation budget.",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Derek Chen",
      "Zhou Yu",
      "Samuel R. Bowman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08355"
  },
  {
    "id": "arXiv:2110.08362",
    "title": "Fast and Reliable Formal Verification of Smart Contracts with the Move  Prover",
    "abstract": "The Move Prover (MVP) is a formal verifier for smart contracts written in the\nMove programming language. MVP has an expressive specification language, and is\nfast and reliable enough that it can be run routinely by developers and in\nintegration testing in a few minutes. Besides the simplicity of smart contracts\nand the Move language, three transformations are responsible for the\npracticality of MVP: (1) an alias-free memory model, (2) fine-grained invariant\nchecking, and (3) monomorphization. The entirety of the Move code for the Diem\nblockchain has been extensively specified and can be completely verified by MVP\nin a few minutes. Changes in the Diem framework must be successfully verified\nbefore being integrated into the open source repository on GitHub.",
    "descriptor": "",
    "authors": [
      "David Dill",
      "Wolfgang Grieskamp",
      "Junkil Park",
      "Shaz Qadeer",
      "Meng Xu",
      "Emma Zhong"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Symbolic Computation (cs.SC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.08362"
  },
  {
    "id": "arXiv:2110.08365",
    "title": "Counting Objects by Diffused Index: geometry-free and training-free  approach",
    "abstract": "Counting objects is a fundamental but challenging problem. In this paper, we\npropose diffusion-based, geometry-free, and learning-free methodologies to\ncount the number of objects in images. The main idea is to represent each\nobject by a unique index value regardless of its intensity or size, and to\nsimply count the number of index values. First, we place different vectors,\nrefer to as seed vectors, uniformly throughout the mask image. The mask image\nhas boundary information of the objects to be counted. Secondly, the seeds are\ndiffused using an edge-weighted harmonic variational optimization model within\neach object. We propose an efficient algorithm based on an operator splitting\napproach and alternating direction minimization method, and theoretical\nanalysis of this algorithm is given. An optimal solution of the model is\nobtained when the distributed seeds are completely diffused such that there is\na unique intensity within each object, which we refer to as an index. For\ncomputational efficiency, we stop the diffusion process before a full\nconvergence, and propose to cluster these diffused index values. We refer to\nthis approach as Counting Objects by Diffused Index (CODI). We explore scalar\nand multi-dimensional seed vectors. For Scalar seeds, we use Gaussian fitting\nin histogram to count, while for vector seeds, we exploit a high-dimensional\nclustering method for the final step of counting via clustering. The proposed\nmethod is flexible even if the boundary of the object is not clear nor fully\nenclosed. We present counting results in various applications such as\nbiological cells, agriculture, concert crowd, and transportation. Some\ncomparisons with existing methods are presented.",
    "descriptor": "",
    "authors": [
      "Mengyi Tang",
      "Maryam Yashtini",
      "Sung Ha Kang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.08365"
  },
  {
    "id": "arXiv:2110.08368",
    "title": "Existence and convergence of a discontinuous Galerkin method for the  compressible three-phase flow problem in porous media",
    "abstract": "This paper presents and analyzes a discontinuous Galerkin method for the\ncompressible three-phase flow problem in porous media. We use a first order\ntime extrapolation which allows us to solve the equations implicitly and\nsequentially. We show that the discrete problem is well-posed, and obtain a\npriori error estimates. Our numerical results validate the theoretical results,\ni.e. the algorithm converges with first order, under different setups that\ninvolve variable density and effects of gravity.",
    "descriptor": "",
    "authors": [
      "Giselle Sosa Jones",
      "Beatrice Riviere",
      "Loic Cappanera"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.08368"
  },
  {
    "id": "arXiv:2110.08370",
    "title": "Training Dynamics for Text Summarization Models",
    "abstract": "Pre-trained language models (e.g. BART) have shown impressive results when\nfine-tuned on large summarization datasets. However, little is understood about\nthis fine-tuning process, including what knowledge is retained from\npre-training models or how content selection and generation strategies are\nlearnt across iterations. In this work, we analyze the training dynamics for\ngeneration models, focusing on news summarization. Across different datasets\n(CNN/DM, XSum, MediaSum) and summary properties, such as abstractiveness and\nhallucination, we study what the model learns at different stages of its\nfine-tuning process. We find that properties such as copy behavior are learnt\nearlier in the training process and these observations are robust across\ndomains. On the other hand, factual errors, such as hallucination of\nunsupported facts, are learnt in the later stages, and this behavior is more\nvaried across domains. Based on these observations, we explore complementary\napproaches for modifying training: first, disregarding high-loss tokens that\nare challenging to learn and second, disregarding low-loss tokens that are\nlearnt very quickly. This simple training modification allows us to configure\nour model to achieve different goals, such as improving factuality or improving\nabstractiveness.",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Tanya Goyal",
      "Jiacheng Xu",
      "Junyi Jessy Li",
      "Greg Durrett"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08370"
  },
  {
    "id": "arXiv:2110.08374",
    "title": "Gemini: Practical Reconfigurable Datacenter Networks with Topology and  Traffic Engineering",
    "abstract": "To reduce cost, datacenter network operators are exploring blocking network\ndesigns. An example of such a design is a \"spine-free\" form of a Fat-Tree, in\nwhich pods directly connect to each other, rather than via spine blocks. To\nmaintain application-perceived performance in the face of dynamic workloads,\nthese new designs must be able to reconfigure routing and the inter-pod\ntopology. Gemini is a system designed to achieve these goals on commodity\nhardware while reconfiguring the network infrequently, rendering these blocking\ndesigns practical enough for deployment in the near future. The key to Gemini\nis the joint optimization of topology and routing, using as input a robust\nestimation of future traffic derived from multiple historical traffic matrices.\nGemini \"hedges\" against unpredicted bursts, by spreading these bursts across\nmultiple paths, to minimize packet loss in exchange for a small increase in\npath lengths. It incorporates a robust decision algorithm to determine when to\nreconfigure, and whether to use hedging. Data from tens of production fabrics\nallows us to categorize these as either low-or high-volatility; these\ncategories seem stable. For the former, Gemini finds topologies and routing\nwith near-optimal performance and cost. For the latter, Gemini's use of\nmulti-traffic-matrix optimization and hedging avoids the need for frequent\ntopology reconfiguration, with only marginal increases in path length. As a\nresult, Gemini can support existing workloads on these production fabrics using\na spine-free topology that is half the cost of the existing topology on these\nfabrics.",
    "descriptor": "",
    "authors": [
      "Mingyang Zhang",
      "Jianan Zhang",
      "Rui Wang",
      "Ramesh Govindan",
      "Jeffrey C. Mogul",
      "Amin Vahdat"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.08374"
  },
  {
    "id": "arXiv:2110.08375",
    "title": "Least Squares on GPUs in Multiple Double Precision",
    "abstract": "This paper describes the application of the code generated by the CAMPARY\nsoftware to accelerate the solving of linear systems in the least squares sense\non Graphics Processing Units (GPUs), in double double, quad double, and octo\ndouble precision. The goal is to use accelerators to offset the cost overhead\ncaused by multiple double precision arithmetic. For the blocked Householder QR\nand the back substitution, of interest are those dimensions at which teraflop\nperformance is attained. The other interesting question is the cost overhead\nfactor that appears each time the precision is doubled.\nExperimental results are reported on five different NVIDIA GPUs, with a\nparticular focus on the P100 and the V100, both capable of teraflop\nperformance. Thanks to the high Compute to Global Memory Access (CGMA) ratios\nof multiple double arithmetic, teraflop performance is already attained running\nthe double double QR on 1,024-by-1,024 matrices, both on the P100 and the V100.\nFor the back substitution, the dimension of the upper triangular system must be\nas high as 17,920 to reach one teraflops on the V100, in quad double precision,\nand then taking only the times spent by the kernels into account. The lower\nperformance of the back substitution in small dimensions does not prevent\nteraflop performance of the solver at dimension 1,024, as the time for the QR\ndecomposition dominates.\nIn doubling the precision from double double to quad double and from quad\ndouble to octo double, the observed cost overhead factors are lower than the\nfactors predicted by the arithmetical operation counts. This observation\ncorrelates with the increased performance for increased precision, which can\nagain be explained by the high CGMA ratios.",
    "descriptor": "\nComments: 22 pages, 10 tables, 4 figures\n",
    "authors": [
      "Jan Verschelde"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.08375"
  },
  {
    "id": "arXiv:2110.08377",
    "title": "Starkit: RoboCup Humanoid KidSize 2021 Worldwide Champion Team Paper",
    "abstract": "This article is devoted to the features that were under development between\nRoboCup 2019 Sydney and RoboCup 2021 Worldwide. These features include\nvision-related matters, such as detection and localization, mechanical and\nalgorithmic novelties. Since the competition was held virtually, the\nsimulation-specific features are also considered in the article. We give an\noverview of the approaches that were tried out along with the analysis of their\npreconditions, perspectives and the evaluation of their performance.",
    "descriptor": "\nComments: 15 pages, 10 figures\n",
    "authors": [
      "Egor Davydenko",
      "Ivan Khokhlov",
      "Vladimir Litvinenko",
      "Ilya Ryakin",
      "Ilya Osokin",
      "Azer Babaev"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08377"
  },
  {
    "id": "arXiv:2110.08378",
    "title": "FedSLD: Federated Learning with Shared Label Distribution for Medical  Image Classification",
    "abstract": "Machine learning in medical research, by nature, needs careful attention on\nobeying the regulations of data privacy, making it difficult to train a machine\nlearning model over gathered data from different medical centers. Failure of\nleveraging data of the same kind may result in poor generalizability for the\ntrained model. Federated learning (FL) enables collaboratively training a joint\nmodel while keeping the data decentralized for multiple medical centers.\nHowever, federated optimizations often suffer from the heterogeneity of the\ndata distribution across medical centers. In this work, we propose Federated\nLearning with Shared Label Distribution (FedSLD) for classification tasks, a\nmethod that assumes knowledge of the label distributions for all the\nparticipating clients in the federation. FedSLD adjusts the contribution of\neach data sample to the local objective during optimization given knowledge of\nthe distribution, mitigating the instability brought by data heterogeneity\nacross all clients. We conduct extensive experiments on four publicly available\nimage datasets with different types of non-IID data distributions. Our results\nshow that FedSLD achieves better convergence performance than the compared\nleading FL optimization algorithms, increasing the test accuracy by up to 5.50\npercentage points.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Jun Luo",
      "Shandong Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08378"
  },
  {
    "id": "arXiv:2110.08381",
    "title": "On The Ingredients of an Effective Zero-shot Semantic Parser",
    "abstract": "Semantic parsers map natural language utterances into meaning representations\n(e.g., programs). Such models are typically bottlenecked by the paucity of\ntraining data due to the required laborious annotation efforts. Recent studies\nhave performed zero-shot learning by synthesizing training examples of\ncanonical utterances and programs from a grammar, and further paraphrasing\nthese utterances to improve linguistic diversity. However, such synthetic\nexamples cannot fully capture patterns in real data. In this paper we analyze\nzero-shot parsers through the lenses of the language and logical gaps (Herzig\nand Berant, 2019), which quantify the discrepancy of language and programmatic\npatterns between the canonical examples and real-world user-issued ones. We\npropose bridging these gaps using improved grammars, stronger paraphrasers, and\nefficient learning methods using canonical examples that most likely reflect\nreal user intents. Our model achieves strong performance on two semantic\nparsing benchmarks (Scholar, Geo) with zero labeled data.",
    "descriptor": "",
    "authors": [
      "Pengcheng Yin",
      "John Wieting",
      "Avirup Sil",
      "Graham Neubig"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08381"
  },
  {
    "id": "arXiv:2110.08382",
    "title": "A Neural Network Ensemble Approach to System Identification",
    "abstract": "We present a new algorithm for learning unknown governing equations from\ntrajectory data, using and ensemble of neural networks. Given samples of\nsolutions $x(t)$ to an unknown dynamical system $\\dot{x}(t)=f(t,x(t))$, we\napproximate the function $f$ using an ensemble of neural networks. We express\nthe equation in integral form and use Euler method to predict the solution at\nevery successive time step using at each iteration a different neural network\nas a prior for $f$. This procedure yields M-1 time-independent networks, where\nM is the number of time steps at which $x(t)$ is observed. Finally, we obtain a\nsingle function $f(t,x(t))$ by neural network interpolation. Unlike our earlier\nwork, where we numerically computed the derivatives of data, and used them as\ntarget in a Lipschitz regularized neural network to approximate $f$, our new\nmethod avoids numerical differentiations, which are unstable in presence of\nnoise. We test the new algorithm on multiple examples both with and without\nnoise in the data. We empirically show that generalization and recovery of the\ngoverning equation improve by adding a Lipschitz regularization term in our\nloss function and that this method improves our previous one especially in\npresence of noise, when numerical differentiation provides low quality target\ndata. Finally, we compare our results with the method proposed by Raissi, et\nal. arXiv:1801.01236 (2018) and with SINDy.",
    "descriptor": "",
    "authors": [
      "Elisa Negrini",
      "Giovanna Citti",
      "Luca Capogna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.08382"
  },
  {
    "id": "arXiv:2110.08383",
    "title": "Training Conversational Agents with Generative Conversational Networks",
    "abstract": "Rich, open-domain textual data available on the web resulted in great\nadvancements for language processing. However, while that data may be suitable\nfor language processing tasks, they are mostly non-conversational, lacking many\nphenomena that appear in human interactions and this is one of the reasons why\nwe still have many unsolved challenges in conversational AI. In this work, we\nattempt to address this by using Generative Conversational Networks to\nautomatically generate data and train social conversational agents. We evaluate\nour approach on TopicalChat with automatic metrics and human evaluators,\nshowing that with 10% of seed data it performs close to the baseline that uses\n100% of the data.",
    "descriptor": "\nComments: Accepted at WeCNLP 2021\n",
    "authors": [
      "Yen-Ting Lin",
      "Alexandros Papangelis",
      "Seokhwan Kim",
      "Dilek Hakkani-Tur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08383"
  },
  {
    "id": "arXiv:2110.08385",
    "title": "Robust Correlation Clustering with Asymmetric Noise",
    "abstract": "Graph clustering problems typically aim to partition the graph nodes such\nthat two nodes belong to the same partition set if and only if they are\nsimilar. Correlation Clustering is a graph clustering formulation which: (1)\ntakes as input a signed graph with edge weights representing a\nsimilarity/dissimilarity measure between the nodes, and (2) requires no prior\nestimate of the number of clusters in the input graph. However, the\ncombinatorial optimization problem underlying Correlation Clustering is\nNP-hard. In this work, we propose a novel graph generative model, called the\nNode Factors Model (NFM), which is based on generating feature\nvectors/embeddings for the graph nodes. The graphs generated by the NFM contain\nasymmetric noise in the sense that there may exist pairs of nodes in the same\ncluster which are negatively correlated. We propose a novel Correlation\nClustering algorithm, called \\anormd, using techniques from semidefinite\nprogramming. Using a combination of theoretical and computational results, we\ndemonstrate that $\\texttt{$\\ell_2$-norm-diag}$ recovers nodes with sufficiently\nstrong cluster membership in graph instances generated by the NFM, thereby\nmaking progress towards establishing the provable robustness of our proposed\nalgorithm.",
    "descriptor": "",
    "authors": [
      "Jimit Majmudar",
      "Stephen Vavasis"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.08385"
  },
  {
    "id": "arXiv:2110.08387",
    "title": "Generated Knowledge Prompting for Commonsense Reasoning",
    "abstract": "Despite their ability to capture large amount of knowledge during\npretraining, large-scale language models often benefit from incorporating\nexternal knowledge bases, especially on commonsense reasoning tasks. This\nmotivates us to explore how we can best leverage knowledge elicited from\nlanguage models themselves. We propose generating knowledge statements directly\nfrom a language model with a generic prompt format, then selecting the\nknowledge which maximizes prediction probability. Despite its simplicity, this\napproach improves performance of both off-the-shelf and finetuned language\nmodels on four commonsense reasoning tasks, improving the state-of-the-art on\nnumerical commonsense (NumerSense), general commonsense (CommonsenseQA 2.0),\nand scientific commonsense (QASC) benchmarks. Notably, we find that a model's\npredictions can improve when using its own generated knowledge, demonstrating\nthe importance of symbolic knowledge representation in neural reasoning\nprocesses.",
    "descriptor": "",
    "authors": [
      "Jiacheng Liu",
      "Alisa Liu",
      "Ximing Lu",
      "Sean Welleck",
      "Peter West",
      "Ronan Le Bras",
      "Yejin Choi",
      "Hannaneh Hajishirzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08387"
  },
  {
    "id": "arXiv:2110.08388",
    "title": "Probing as Quantifying the Inductive Bias of Pre-trained Representations",
    "abstract": "Pre-trained contextual representations have led to dramatic performance\nimprovements on a range of downstream tasks. This has motivated researchers to\nquantify and understand the linguistic information encoded in them. In general,\nthis is done by probing, which consists of training a supervised model to\npredict a linguistic property from said representations. Unfortunately, this\ndefinition of probing has been subject to extensive criticism, and can lead to\nparadoxical or counter-intuitive results. In this work, we present a novel\nframework for probing where the goal is to evaluate the inductive bias of\nrepresentations for a particular task, and provide a practical avenue to do\nthis using Bayesian inference. We apply our framework to a series of token-,\narc-, and sentence-level tasks. Our results suggest that our framework solves\nproblems of previous approaches and that fastText can offer a better inductive\nbias than BERT in certain situations.",
    "descriptor": "",
    "authors": [
      "Alexander Immer",
      "Lucas Torroba Hennigen",
      "Vincent Fortuin",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08388"
  },
  {
    "id": "arXiv:2110.08389",
    "title": "Tweed and wireframe: accelerated relaxation algorithms for multigrid  solution of elliptic PDEs on stretched structured grids",
    "abstract": "Two new relaxation schemes are proposed for the smoothing step in the\ngeometric multigrid solution of PDEs on 2D and 3D stretched structured grids.\nThe new schemes are characterized by efficient line relaxation on branched sets\nof lines of alternating colour, where the lines are constructed to be\neverywhere orthogonal to the local direction of maximum grid clustering. Tweed\nrelaxation is best suited for grid clustering near the boundaries of the\ncomputational domain, whereas wireframe relaxation is best suited for grid\nclustering near the centre of the computational domain. On strongly stretched\ngrids of these types, multigrid leveraging these new smoothing schemes\nsignificantly outperforms multigrid based on other leading relaxation schemes,\nsuch as checkerboard and alternating-direction zebra relaxation, for the\nnumerical solution of large linear systems arising from the discretization of\nelliptic PDEs.",
    "descriptor": "",
    "authors": [
      "Thomas Bewley",
      "Ali Mashayek",
      "Daniele Cavaglieri",
      "Paolo Luchini"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.08389"
  },
  {
    "id": "arXiv:2110.08390",
    "title": "Non-Isolated Single-Switch Zeta Based High-Step up DC-DC Converter with  Coupled Inductor",
    "abstract": "In this paper, a non-isolated high step-up DC-DC converter has been proposed\nfor renewable energy applications. The proposed structure converter has been\nderived from the fundamental Zeta converter, in both of which only a single\nswitch is employed. The voltage gain ratio has considerably enhanced in this\nconverter with the absence of using switched capacity. To magnify voltage gain\nof the converter, a coupled-inductor has adopted. Increase and decrease of gain\nby changing the ratio of coupled-inductor assist the duty cycle. The number of\ncomponents is low in this structure. The operating principle and evaluation of\nthe proposed converter, considering designing approaches for elements, are\ndiscussed in detail. To verify the feasibility of the proposed converter,\nsimulation results have been provided and evaluated.",
    "descriptor": "",
    "authors": [
      "Armin Abadifard",
      "Pedram Ghavidel",
      "Seyed Hossein Hosseini",
      "Masoud Farhadi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.08390"
  },
  {
    "id": "arXiv:2110.08393",
    "title": "A Bayesian Approach for Medical Inquiry and Disease Inference in  Automated Differential Diagnosis",
    "abstract": "We propose a Bayesian approach for both medical inquiry and disease\ninference, the two major phases in differential diagnosis. Unlike previous work\nthat simulates data from given probabilities and uses ML algorithms on them, we\ndirectly use the Quick Medical Reference (QMR) belief network, and apply\nBayesian inference in the inference phase and Bayesian experimental design in\nthe inquiry phase. Moreover, we improve the inquiry phase by extending the\nBayesian experimental design framework from one-step search to multi-step\nsearch. Our approach has some practical advantages as it is interpretable, free\nof costly training, and able to adapt to new changes without any additional\neffort. Our experiments show that our approach achieves new state-of-the-art\nresults on two simulated datasets, SymCAT and HPO, and competitive results on\ntwo diagnosis dialogue datasets, Muzhi and Dxy.",
    "descriptor": "",
    "authors": [
      "Hong Guan",
      "Chitta Baral"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08393"
  },
  {
    "id": "arXiv:2110.08394",
    "title": "Adapt to Adaptation: Learning Personalization for Cross-Silo Federated  Learning",
    "abstract": "The goal of conventional federated learning (FL) is to train a global model\nfor a federation of clients with decentralized data, reducing the systemic\nprivacy risk of centralized training. The distribution shift across non-IID\ndatasets, also known as the data heterogeneity, often poses a challenge for\nthis one-global-model-fits-all solution. In this work, we propose APPLE, a\npersonalized cross-silo FL framework that adaptively learns how much each\nclient can benefit from other clients' models. We also introduce a method to\nflexibly control the focus of training APPLE between global and local\nobjectives. We empirically evaluate our method's convergence and generalization\nbehavior and performed extensive experiments on two benchmark datasets and two\nmedical imaging datasets under two non-IID settings. The results show that the\nproposed personalized FL framework, APPLE, achieves state-of-the-art\nperformance compared to several other personalized FL approaches in the\nliterature.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Jun Luo",
      "Shandong Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08394"
  },
  {
    "id": "arXiv:2110.08395",
    "title": "DS-TOD: Efficient Domain Specialization for Task Oriented Dialog",
    "abstract": "Recent work has shown that self-supervised dialog-specific pretraining on\nlarge conversational datasets yields substantial gains over traditional\nlanguage modeling (LM) pretraining in downstream task-oriented dialog (TOD).\nThese approaches, however, exploit general dialogic corpora (e.g., Reddit) and\nthus presumably fail to reliably embed domain-specific knowledge useful for\nconcrete downstream TOD domains. In this work, we investigate the effects of\ndomain specialization of pretrained language models (PLMs) for task-oriented\ndialog. Within our DS-TOD framework, we first automatically extract salient\ndomain-specific terms, and then use them to construct DomainCC and DomainReddit\n-- resources that we leverage for domain-specific pretraining, based on (i)\nmasked language modeling (MLM) and (ii) response selection (RS) objectives,\nrespectively. We further propose a resource-efficient and modular domain\nspecialization by means of domain adapters -- additional parameter-light layers\nin which we encode the domain knowledge. Our experiments with two prominent TOD\ntasks -- dialog state tracking (DST) and response retrieval (RR) --\nencompassing five domains from the MultiWOZ TOD benchmark demonstrate the\neffectiveness of our domain specialization approach. Moreover, we show that the\nlight-weight adapter-based specialization (1) performs comparably to full\nfine-tuning in single-domain setups and (2) is particularly suitable for\nmulti-domain specialization, in which, besides advantageous computational\nfootprint, it can offer better downstream performance.",
    "descriptor": "",
    "authors": [
      "Chia-Chien Hung",
      "Anne Lauscher",
      "Simone Paolo Ponzetto",
      "Goran Glava\u0161"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08395"
  },
  {
    "id": "arXiv:2110.08396",
    "title": "Comparing Human and Machine Bias in Face Recognition",
    "abstract": "Much recent research has uncovered and discussed serious concerns of bias in\nfacial analysis technologies, finding performance disparities between groups of\npeople based on perceived gender, skin type, lighting condition, etc. These\naudits are immensely important and successful at measuring algorithmic bias but\nhave two major challenges: the audits (1) use facial recognition datasets which\nlack quality metadata, like LFW and CelebA, and (2) do not compare their\nobserved algorithmic bias to the biases of their human alternatives. In this\npaper, we release improvements to the LFW and CelebA datasets which will enable\nfuture researchers to obtain measurements of algorithmic bias that are not\ntainted by major flaws in the dataset (e.g. identical images appearing in both\nthe gallery and test set). We also use these new data to develop a series of\nchallenging facial identification and verification questions that we\nadministered to various algorithms and a large, balanced sample of human\nreviewers. We find that both computer models and human survey participants\nperform significantly better at the verification task, generally obtain lower\naccuracy rates on dark-skinned or female subjects for both tasks, and obtain\nhigher accuracy rates when their demographics match that of the question.\nComputer models are observed to achieve a higher level of accuracy than the\nsurvey participants on both tasks and exhibit bias to similar degrees as the\nhuman survey participants.",
    "descriptor": "",
    "authors": [
      "Samuel Dooley",
      "Ryan Downing",
      "George Wei",
      "Nathan Shankar",
      "Bradon Thymes",
      "Gudrun Thorkelsdottir",
      "Tiye Kurtz-Miott",
      "Rachel Mattson",
      "Olufemi Obiwumi",
      "Valeriia Cherepanova",
      "Micah Goldblum",
      "John P Dickerson",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08396"
  },
  {
    "id": "arXiv:2110.08398",
    "title": "Mind the Gap: Domain Gap Control for Single Shot Domain Adaptation for  Generative Adversarial Networks",
    "abstract": "We present a new method for one shot domain adaptation. The input to our\nmethod is trained GAN that can produce images in domain A and a single\nreference image I_B from domain B. The proposed algorithm can translate any\noutput of the trained GAN from domain A to domain B. There are two main\nadvantages of our method compared to the current state of the art: First, our\nsolution achieves higher visual quality, e.g. by noticeably reducing\noverfitting. Second, our solution allows for more degrees of freedom to control\nthe domain gap, i.e. what aspects of image I_B are used to define the domain B.\nTechnically, we realize the new method by building on a pre-trained StyleGAN\ngenerator as GAN and a pre-trained CLIP model for representing the domain gap.\nWe propose several new regularizers for controlling the domain gap to optimize\nthe weights of the pre-trained StyleGAN generator to output images in domain B\ninstead of domain A. The regularizers prevent the optimization from taking on\ntoo many attributes of the single reference image. Our results show significant\nvisual improvements over the state of the art as well as multiple applications\nthat highlight improved control.",
    "descriptor": "\nComments: Video: this https URL\n",
    "authors": [
      "Peihao Zhu",
      "Rameen Abdal",
      "John Femiani",
      "Peter Wonka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08398"
  },
  {
    "id": "arXiv:2110.08402",
    "title": "sbp-env: A Python Package for Sampling-based Motion Planner and Samplers",
    "abstract": "Sampling-based motion planners' testing environment (sbp-env) is a full\nfeature framework to quickly test different sampling-based algorithms for\nmotion planning. sbp-env focuses on the flexibility of tinkering with different\naspects of the framework, and had divided the main planning components into two\ncategories (i) samplers and (ii) planners.\nThe focus of motion planning research had been mainly on (i) improving the\nsampling efficiency (with methods such as heuristic or learned distribution)\nand (ii) the algorithmic aspect of the planner using different routines to\nbuild a connected graph. Therefore, by separating the two components one can\nquickly swap out different components to test novel ideas.",
    "descriptor": "",
    "authors": [
      "Tin Lai"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08402"
  },
  {
    "id": "arXiv:2110.08403",
    "title": "Nalanda: A Socio-Technical Graph for Building Software Analytics Tools  at Enterprise Scale",
    "abstract": "Software development is information-dense knowledge work that requires\ncollaboration with other developers and awareness of artifacts such as work\nitems, pull requests, and files. With the speed of development increasing,\ninformation overload is a challenge for people developing and maintaining these\nsystems. In this paper, we build a large scale socio-technical graph to address\nchallenges of information overload and discovery, with an initial focus on\nartifacts central to the software development and delivery process. The Nalanda\ngraph is an enterprise scale graph with data from 6,500repositories, with\n37,410,706 nodes and 128,745,590 edges. On top of this, we built software\nanalytics applications including a newsfeed named MyNalanda, and based on\norganic growth alone, it has Daily Active Users (DAU) of 290 and Monthly Active\nUsers (MAU) of590. A preliminary user study shows that 74% of developers and\nengineering managers surveyed are favorable toward continued use of the\nplatform for information discovery. This work provides a view into a new\nlarge-scale socio-technical graph and the technical choices made for this\napproach, the implications for information discovery and overload among\ndevelopers and managers, and the implications of future development on the\nNalanda graph.",
    "descriptor": "",
    "authors": [
      "Chandra Maddila",
      "Apoorva Agrawal",
      "Thomas Zimmermann",
      "Nicole Forsgren",
      "Kim Herzig",
      "Arie van Deursen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.08403"
  },
  {
    "id": "arXiv:2110.08406",
    "title": "Surrogate- and invariance-boosted contrastive learning for data-scarce  applications in science",
    "abstract": "Deep learning techniques have been increasingly applied to the natural\nsciences, e.g., for property prediction and optimization or material discovery.\nA fundamental ingredient of such approaches is the vast quantity of labelled\ndata needed to train the model; this poses severe challenges in data-scarce\nsettings where obtaining labels requires substantial computational or labor\nresources. Here, we introduce surrogate- and invariance-boosted contrastive\nlearning (SIB-CL), a deep learning framework which incorporates three\n``inexpensive'' and easily obtainable auxiliary information sources to overcome\ndata scarcity. Specifically, these are: 1)~abundant unlabeled data, 2)~prior\nknowledge of symmetries or invariances and 3)~surrogate data obtained at\nnear-zero cost. We demonstrate SIB-CL's effectiveness and generality on various\nscientific problems, e.g., predicting the density-of-states of 2D photonic\ncrystals and solving the 3D time-independent Schrodinger equation. SIB-CL\nconsistently results in orders of magnitude reduction in the number of labels\nneeded to achieve the same network accuracies.",
    "descriptor": "\nComments: 21 pages, 10 figures\n",
    "authors": [
      "Charlotte Loh",
      "Thomas Christensen",
      "Rumen Dangovski",
      "Samuel Kim",
      "Marin Soljacic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Applied Physics (physics.app-ph)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2110.08406"
  },
  {
    "id": "arXiv:2110.08412",
    "title": "Evaluating the Faithfulness of Importance Measures in NLP by Recursively  Masking Allegedly Important Tokens and Retraining",
    "abstract": "To explain NLP models, many methods inform which inputs tokens are important\nfor a prediction. However, an open question is if these methods accurately\nreflect the model's logic, a property often called faithfulness. In this work,\nwe adapt and improve a recently proposed faithfulness benchmark from computer\nvision called ROAR (RemOve And Retrain), by Hooker et al. (2019).\nWe improve ROAR by recursively removing dataset redundancies, which otherwise\ninterfere with ROAR. We adapt and apply ROAR, to popular NLP importance\nmeasures, namely attention, gradient, and integrated gradients. Additionally,\nwe use mutual information as an additional baseline. Evaluation is done on a\nsuite of classification tasks often used in the faithfulness of attention\nliterature. Finally, we propose a scalar faithfulness metric, which makes it\neasy to compare results across papers.\nWe find that, importance measures considered to be unfaithful for computer\nvision tasks perform favorably for NLP tasks, the faithfulness of an importance\nmeasure is task-dependent, and the computational overhead of integrated\ngradient is rarely justified.",
    "descriptor": "",
    "authors": [
      "Andreas Madsen",
      "Nicholas Meade",
      "Vaibhav Adlakha",
      "Siva Reddy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08412"
  },
  {
    "id": "arXiv:2110.08413",
    "title": "Invariant Language Modeling",
    "abstract": "Modern pretrained language models are critical components of NLP pipelines.\nYet, they suffer from spurious correlations, poor out-of-domain generalization,\nand biases. Inspired by recent progress in causal machine learning, in\nparticular the invariant risk minimization (IRM) paradigm, we propose invariant\nlanguage modeling, a framework for learning invariant representations that\ngeneralize better across multiple environments. In particular, we adapt a\ngame-theoretic implementation of IRM (IRM-games) to language models, where the\ninvariance emerges from a specific training schedule in which all the\nenvironments compete to optimize their own environment-specific loss by\nupdating subsets of the model in a round-robin fashion. In a series of\ncontrolled experiments, we demonstrate the ability of our method to (i) remove\nstructured noise, (ii) ignore specific spurious correlations without affecting\nglobal performance, and (iii) achieve better out-of-domain generalization.\nThese benefits come with a negligible computational overhead compared to\nstandard training, do not require changing the local loss, and can be applied\nto any language model architecture. We believe this framework is promising to\nhelp mitigate spurious correlations and biases in language models.",
    "descriptor": "",
    "authors": [
      "Maxime Peyrard",
      "Sarvjeet Singh Ghotra",
      "Martin Josifoski",
      "Vidhan Agarwal",
      "Barun Patra",
      "Dean Carignan",
      "Emre Kiciman",
      "Robert West"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08413"
  },
  {
    "id": "arXiv:2110.08415",
    "title": "Multilingual unsupervised sequence segmentation transfers to extremely  low-resource languages",
    "abstract": "We show that unsupervised sequence-segmentation performance can be\ntransferred to extremely low-resource languages by pre-training a Masked\nSegmental Language Model (Downey et al., 2021) multilingually. Further, we show\nthat this transfer can be achieved by training over a collection of\nlow-resource languages that are typologically similar (but phylogenetically\nunrelated) to the target language. In our experiments, we transfer from a\ncollection of 10 Indigenous American languages (AmericasNLP, Mager et al.,\n2021) to K'iche', a Mayan language. We compare our model to a monolingual\nbaseline, and show that the multilingual pre-trained approach yields much more\nconsistent segmentation quality across target dataset sizes, including a\nzero-shot performance of 20.6 F1, and exceeds the monolingual performance in\n9/10 experimental settings. These results have promising implications for\nlow-resource NLP pipelines involving human-like linguistic units, such as the\nsparse transcription framework proposed by Bird (2020).",
    "descriptor": "",
    "authors": [
      "C.M. Downey",
      "Shannon Drizin",
      "Levon Haroutunian",
      "Shivin Thukral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08415"
  },
  {
    "id": "arXiv:2110.08417",
    "title": "Open Domain Question Answering over Virtual Documents: A Unified  Approach for Data and Text",
    "abstract": "Due to its potential for a universal interface over both data and text,\ndata-to-text generation is becoming increasingly popular recently. However, few\nprevious work has focused on its application to downstream tasks, e.g. using\nthe converted data for grounding or reasoning. In this work, we aim to bridge\nthis gap and use the data-to-text method as a means for encoding structured\nknowledge for knowledge-intensive applications, i.e. open-domain question\nanswering (QA). Specifically, we propose a verbalizer-retriever-reader\nframework for open-domain QA over data and text where verbalized tables from\nWikipedia and triples from Wikidata are used as augmented knowledge sources. We\nshow that our Unified Data and Text QA, UDT-QA, can effectively benefit from\nthe expanded knowledge index, leading to large gains over text-only baselines.\nNotably, our approach sets the single-model state-of-the-art on Natural\nQuestions. Furthermore, our analyses indicate that verbalized knowledge is\npreferred for answer reasoning for both adapted and hot-swap settings.",
    "descriptor": "",
    "authors": [
      "Kaixin Ma",
      "Hao Cheng",
      "Xiaodong Liu",
      "Eric Nyberg",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08417"
  },
  {
    "id": "arXiv:2110.08419",
    "title": "What do Compressed Large Language Models Forget? Robustness Challenges  in Model Compression",
    "abstract": "Recent works have focused on compressing pre-trained language models (PLMs)\nlike BERT where the major focus has been to improve the compressed model\nperformance for downstream tasks. However, there has been no study in analyzing\nthe impact of compression on the generalizability and robustness of these\nmodels. Towards this end, we study two popular model compression techniques\nincluding knowledge distillation and pruning and show that compressed models\nare significantly less robust than their PLM counterparts on adversarial test\nsets although they obtain similar performance on in-distribution development\nsets for a task. Further analysis indicates that the compressed models overfit\non the easy samples and generalize poorly on the hard ones. We further leverage\nthis observation to develop a regularization strategy for model compression\nbased on sample uncertainty. Experimental results on several natural language\nunderstanding tasks demonstrate our mitigation framework to improve both the\nadversarial generalization as well as in-distribution task performance of the\ncompressed models.",
    "descriptor": "",
    "authors": [
      "Mengnan Du",
      "Subhabrata Mukherjee",
      "Yu Cheng",
      "Milad Shokouhi",
      "Xia Hu",
      "Ahmed Hassan Awadallah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08419"
  },
  {
    "id": "arXiv:2110.08420",
    "title": "Information-Theoretic Measures of Dataset Difficulty",
    "abstract": "Estimating the difficulty of a dataset typically involves comparing\nstate-of-the-art models to humans; the bigger the performance gap, the harder\nthe dataset is said to be. Not only is this framework informal, but it also\nprovides little understanding of how difficult each instance is, or what\nattributes make it difficult for a given model. To address these problems, we\npropose an information-theoretic perspective, framing dataset difficulty as the\nabsence of $\\textit{usable information}$. Measuring usable information is as\neasy as measuring performance, but has certain theoretical advantages. While\nthe latter only allows us to compare different models w.r.t the same dataset,\nthe former also allows us to compare different datasets w.r.t the same model.\nWe then introduce $\\textit{pointwise}$ $\\mathcal{V}-$$\\textit{information}$\n(PVI) for measuring the difficulty of individual instances, where instances\nwith higher PVI are easier for model $\\mathcal{V}$. By manipulating the input\nbefore measuring usable information, we can understand $\\textit{why}$ a dataset\nis easy or difficult for a given model, which we use to discover annotation\nartefacts in widely-used benchmarks.",
    "descriptor": "",
    "authors": [
      "Kawin Ethayarajh",
      "Yejin Choi",
      "Swabha Swayamdipta"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08420"
  },
  {
    "id": "arXiv:2110.08421",
    "title": "Dataset Knowledge Transfer for Class-Incremental Learning without Memory",
    "abstract": "Incremental learning enables artificial agents to learn from sequential data.\nWhile important progress was made by exploiting deep neural networks,\nincremental learning remains very challenging. This is particularly the case\nwhen no memory of past data is allowed and catastrophic forgetting has a strong\nnegative effect. We tackle class-incremental learning without memory by\nadapting prediction bias correction, a method which makes predictions of past\nand new classes more comparable. It was proposed when a memory is allowed and\ncannot be directly used without memory, since samples of past classes are\nrequired. We introduce a two-step learning process which allows the transfer of\nbias correction parameters between reference and target datasets. Bias\ncorrection is first optimized offline on reference datasets which have an\nassociated validation memory. The obtained correction parameters are then\ntransferred to target datasets, for which no memory is available. The second\ncontribution is to introduce a finer modeling of bias correction by learning\nits parameters per incremental state instead of the usual past vs. new class\nmodeling. The proposed dataset knowledge transfer is applicable to any\nincremental method which works without memory. We test its effectiveness by\napplying it to four existing methods. Evaluation with four target datasets and\ndifferent configurations shows consistent improvement, with practically no\ncomputational and memory overhead.",
    "descriptor": "\nComments: Accepted to WACV 2022\n",
    "authors": [
      "Habib Slim",
      "Eden Belouadah",
      "Adrian Popescu",
      "Darian Onchis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08421"
  },
  {
    "id": "arXiv:2110.08422",
    "title": "Toward Uncensorable, Anonymous and Private Access Over Satoshi  Blockchains",
    "abstract": "Providing unrestricted access to sensitive content such as news and software\nis difficult in the presence of adaptive and resourceful surveillance and\ncensoring adversaries. In this paper we leverage the distributed and resilient\nnature of commercial Satoshi blockchains to develop the first provably secure,\ncensorship resistant, cost-efficient storage system with anonymous and private\naccess, built on top of commercial cryptocurrency transactions. We introduce\nmax-rate transactions, a practical construct to persist data of arbitrary size\nentirely in a Satoshi blockchain. We leverage max-rate transactions to develop\nUWeb, a blockchain-based storage system that charges publishers to self-sustain\nits decentralized infrastructure. UWeb organizes blockchainstored content for\neasy retrieval, and enables clients to store and access content with provable\nanonymity, privacy and censorship resistance properties.\nWe present results from UWeb experiments with writing 268.21 MB of data into\nthe live Litecoin blockchain, including 4.5 months of live-feed BBC articles,\nand 41 censorship resistant tools. The max-rate writing throughput (183 KB/s)\nand blockchain utilization (88%) exceed those of state-of-the-art solutions by\n2-3 orders of magnitude and broke Litecoin's record of the daily average block\nsize. Our simulations with up to 3,000 concurrent UWeb writers confirm that\nUWeb does not impact the confirmation delays of financial transactions.",
    "descriptor": "",
    "authors": [
      "Ruben Recabarren",
      "Bogdan Carbunar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.08422"
  },
  {
    "id": "arXiv:2110.08423",
    "title": "Finding Backdoors to Integer Programs: A Monte Carlo Tree Search  Framework",
    "abstract": "In Mixed Integer Linear Programming (MIP), a (strong) backdoor is a \"small\"\nsubset of an instance's integer variables with the following property: in a\nbranch-and-bound procedure, the instance can be solved to global optimality by\nbranching only on the variables in the backdoor. Constructing datasets of\npre-computed backdoors for widely used MIP benchmark sets or particular problem\nfamilies can enable new questions around novel structural properties of a MIP,\nor explain why a problem that is hard in theory can be solved efficiently in\npractice. Existing algorithms for finding backdoors rely on sampling candidate\nvariable subsets in various ways, an approach which has demonstrated the\nexistence of backdoors for some instances from MIPLIB2003 and MIPLIB2010.\nHowever, these algorithms fall short of consistently succeeding at the task due\nto an imbalance between exploration and exploitation. We propose BaMCTS, a\nMonte Carlo Tree Search framework for finding backdoors to MIPs. Extensive\nalgorithmic engineering, hybridization with traditional MIP concepts, and close\nintegration with the CPLEX solver have enabled our method to outperform\nbaselines on MIPLIB2017 instances, finding backdoors more frequently and more\nefficiently.",
    "descriptor": "",
    "authors": [
      "Elias B. Khalil",
      "Pashootan Vaezipoor",
      "Bistra Dilkina"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08423"
  },
  {
    "id": "arXiv:2110.08426",
    "title": "EncT5: Fine-tuning T5 Encoder for Non-autoregressive Tasks",
    "abstract": "Encoder-decoder transformer architectures have become popular recently with\nthe advent of T5 models. It is also more favorable over architectures like BERT\nfor pre-training on language model task when it comes to large scale models\nwhich could take months to train given it's generality. While being able to\ngeneralize to more tasks, it is not evident if the proposed encoder-decoder\narchitecture is the most efficient for fine-tuning on classification and\nregression tasks given the pre-trained model. In this work, we study\nfine-tuning pre-trained encoder-decoder models such as T5. Particularly, we\npropose \\textbf{EncT5} as a way to efficiently fine-tune pre-trained\nencoder-decoder T5 models for classification and regression tasks by using the\nencoder layers. Our experimental results show that \\textbf{EncT5} with less\nthan half of the parameters of T5 performs similarly to T5 models on GLUE\nbenchmark. We believe our proposed approach can be easily applied to any\npre-trained encoder-decoder model.",
    "descriptor": "",
    "authors": [
      "Frederick Liu",
      "Siamak Shakeri",
      "Hongkun Yu",
      "Jing Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08426"
  },
  {
    "id": "arXiv:2110.08429",
    "title": "TorchEsegeta: Framework for Interpretability and Explainability of  Image-based Deep Learning Models",
    "abstract": "Clinicians are often very sceptical about applying automatic image processing\napproaches, especially deep learning based methods, in practice. One main\nreason for this is the black-box nature of these approaches and the inherent\nproblem of missing insights of the automatically derived decisions. In order to\nincrease trust in these methods, this paper presents approaches that help to\ninterpret and explain the results of deep learning algorithms by depicting the\nanatomical areas which influence the decision of the algorithm most. Moreover,\nthis research presents a unified framework, TorchEsegeta, for applying various\ninterpretability and explainability techniques for deep learning models and\ngenerate visual interpretations and explanations for clinicians to corroborate\ntheir clinical findings. In addition, this will aid in gaining confidence in\nsuch methods. The framework builds on existing interpretability and\nexplainability techniques that are currently focusing on classification models,\nextending them to segmentation tasks. In addition, these methods have been\nadapted to 3D models for volumetric analysis. The proposed framework provides\nmethods to quantitatively compare visual explanations using infidelity and\nsensitivity metrics. This framework can be used by data scientists to perform\npost-hoc interpretations and explanations of their models, develop more\nexplainable tools and present the findings to clinicians to increase their\nfaith in such models. The proposed framework was evaluated based on a use case\nscenario of vessel segmentation models trained on Time-of-fight (TOF) Magnetic\nResonance Angiogram (MRA) images of the human brain. Quantitative and\nqualitative results of a comparative study of different models and\ninterpretability methods are presented. Furthermore, this paper provides an\nextensive overview of several existing interpretability and explainability\nmethods.",
    "descriptor": "",
    "authors": [
      "Soumick Chatterjee",
      "Arnab Das",
      "Chirag Mandal",
      "Budhaditya Mukhopadhyay",
      "Manish Vipinraj",
      "Aniruddh Shukla",
      "Rajatha Nagaraja Rao",
      "Chompunuch Sarasaen",
      "Oliver Speck",
      "Andreas N\u00fcrnberger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08429"
  },
  {
    "id": "arXiv:2110.08430",
    "title": "Metadata Shaping: Natural Language Annotations for the Tail",
    "abstract": "Language models (LMs) have made remarkable progress, but still struggle to\ngeneralize beyond the training data to rare linguistic patterns. Since rare\nentities and facts are prevalent in the queries users submit to popular\napplications such as search and personal assistant systems, improving the\nability of LMs to reliably capture knowledge over rare entities is a pressing\nchallenge studied in significant prior work. Noticing that existing approaches\nprimarily modify the LM architecture or introduce auxiliary objectives to\ninject useful entity knowledge, we ask to what extent we could match the\nquality of these architectures using a base LM architecture, and only changing\nthe data? We propose metadata shaping, a method in which readily available\nmetadata, such as entity descriptions and categorical tags, are appended to\nexamples based on information theoretic metrics. Intuitively, if metadata\ncorresponding to popular entities overlap with metadata for rare entities, the\nLM may be able to better reason about the rare entities using patterns learned\nfrom similar popular entities. On standard entity-rich tasks (TACRED, FewRel,\nOpenEntity), with no changes to the LM whatsoever, metadata shaping exceeds the\nBERT-baseline by up to 5.3 F1 points, and achieves or competes with\nstate-of-the-art results. We further show the improvements are up to 10x larger\non examples containing tail versus popular entities.",
    "descriptor": "",
    "authors": [
      "Simran Arora",
      "Sen Wu",
      "Enci Liu",
      "Christopher Re"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08430"
  },
  {
    "id": "arXiv:2110.08432",
    "title": "Meta-Learning with Adjoint Methods",
    "abstract": "Model Agnostic Meta-Learning (MAML) is widely used to find a good\ninitialization for a family of tasks. Despite its success, a critical challenge\nin MAML is to calculate the gradient w.r.t the initialization of a long\ntraining trajectory for the sampled tasks, because the computation graph can\nrapidly explode and the computational cost is very expensive. To address this\nproblem, we propose Adjoint MAML (A-MAML). We view gradient descent in the\ninner optimization as the evolution of an Ordinary Differential Equation (ODE).\nTo efficiently compute the gradient of the validation loss w.r.t the\ninitialization, we use the adjoint method to construct a companion, backward\nODE. To obtain the gradient w.r.t the initialization, we only need to run the\nstandard ODE solver twice -- one is forward in time that evolves a long\ntrajectory of gradient flow for the sampled task; the other is backward and\nsolves the adjoint ODE. We need not create or expand any intermediate\ncomputational graphs, adopt aggressive approximations, or impose proximal\nregularizers in the training loss. Our approach is cheap, accurate, and\nadaptable to different trajectory lengths. We demonstrate the advantage of our\napproach in both synthetic and real-world meta-learning tasks.",
    "descriptor": "",
    "authors": [
      "Shibo Li",
      "Zheng Wang",
      "Akil Narayan",
      "Robert Kirby",
      "Shandian Zhe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08432"
  },
  {
    "id": "arXiv:2110.08436",
    "title": "Extended Version of Reactive Task Allocation and Planning of A  Heterogeneous Multi-Robot System",
    "abstract": "This paper takes the first step towards a reactive, hierarchical multi-robot\ntask allocation and planning framework given a global Linear Temporal Logic\nspecification. In our scenario, legged and wheeled robots collaborate in a\nheterogeneous team to accomplish a variety of navigation and delivery tasks.\nHowever, all robots are susceptible to different types of disturbances\nincluding locomotion failures, human interventions, and obstructions from the\nenvironment. To address these disturbances, we propose task-level local and\nglobal reallocation strategies to efficiently generate updated action-state\nsequences online while guaranteeing the completion of the original task. In\naddition, these task reallocation approaches eliminate reconstructing the\nentire plan or resynthesizing a new task. Lastly, a Behavior Tree execution\nlayer monitors different types of disturbances and employs the reallocation\nmethods to make corresponding recovery strategies. To evaluate this planning\nframework, dynamic simulations are conducted in a realistic hospital\nenvironment with a heterogeneous robot team consisting of quadrupeds and\nwheeled robots for delivery tasks.",
    "descriptor": "",
    "authors": [
      "Ziyi Zhou",
      "Dong Jae Lee",
      "Yuki Yoshinaga",
      "Dejun Guo",
      "Ye Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.08436"
  },
  {
    "id": "arXiv:2110.08437",
    "title": "NN3A: Neural Network supported Acoustic Echo Cancellation, Noise  Suppression and Automatic Gain Control for Real-Time Communications",
    "abstract": "Acoustic echo cancellation (AEC), noise suppression (NS) and automatic gain\ncontrol (AGC) are three often required modules for real-time communications\n(RTC). This paper proposes a neural network supported algorithm for RTC, namely\nNN3A, which incorporates an adaptive filter and a multi-task model for residual\necho suppression, noise reduction and near-end speech activity detection. The\nproposed algorithm is shown to outperform both a method using separate models\nand an end-to-end alternative. It is further shown that there exists a\ntrade-off in the model between residual suppression and near-end speech\ndistortion, which could be balanced by a novel loss weighting function. Several\npractical aspects of training the joint model are also investigated to push its\nperformance to limit.",
    "descriptor": "\nComments: submitted to ICASSP2022\n",
    "authors": [
      "Ziteng Wang",
      "Yueyue Na",
      "Biao Tian",
      "Qiang Fu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.08437"
  },
  {
    "id": "arXiv:2110.08438",
    "title": "Unsupervised Natural Language Inference Using PHL Triplet Generation",
    "abstract": "Transformer-based models have achieved impressive performance on various\nNatural Language Inference (NLI) benchmarks, when trained on respective\ntraining datasets. However, in certain cases, training samples may not be\navailable or collecting them could be time-consuming and resource-intensive. In\nthis work, we address this challenge and present an explorative study on\nunsupervised NLI, a paradigm in which no human-annotated training samples are\navailable. We investigate NLI under three challenging settings: PH, P, and NPH\nthat differ in the extent of unlabeled data available for learning. As a\nsolution, we propose a procedural data generation approach that leverages a set\nof sentence transformations to collect PHL (Premise, Hypothesis, Label)\ntriplets for training NLI models, bypassing the need for human-annotated\ntraining datasets. Comprehensive experiments show that this approach results in\naccuracies of 66.75%, 65.9%, 65.39% in PH, P, NPH settings respectively,\noutperforming all existing baselines. Furthermore, fine-tuning our models with\nas little as ~0.1% of the training dataset (500 samples) leads to 12.2% higher\naccuracy than the model trained from scratch on the same 500 instances.",
    "descriptor": "\nComments: 9 pages, 2 figures, 8 tables\n",
    "authors": [
      "Neeraj Varshney",
      "Pratyay Banerjee",
      "Tejas Gokhale",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08438"
  },
  {
    "id": "arXiv:2110.08439",
    "title": "Controllable Multichannel Speech Dereverberation based on Deep Neural  Networks",
    "abstract": "Neural network based speech dereverberation has achieved promising results in\nrecent studies. Nevertheless, many are focused on recovery of only the direct\npath sound and early reflections, which could be beneficial to speech\nperception, are discarded. The performance of a model trained to recover clean\nspeech degrades when evaluated on early reverberation targets, and vice versa.\nThis paper proposes a novel deep neural network based multichannel speech\ndereverberation algorithm, in which the dereverberation level is controllable.\nThis is realized by adding a simple floating-point number as target controller\nof the model. Experiments are conducted using spatially distributed\nmicrophones, and the efficacy of the proposed algorithm is confirmed in various\nsimulated conditions.",
    "descriptor": "\nComments: submitted to ICASSP2022\n",
    "authors": [
      "Ziteng Wang",
      "Yueyue Na",
      "Biao Tian",
      "Qiang Fu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.08439"
  },
  {
    "id": "arXiv:2110.08440",
    "title": "Online Target Q-learning with Reverse Experience Replay: Efficiently  finding the Optimal Policy for Linear MDPs",
    "abstract": "Q-learning is a popular Reinforcement Learning (RL) algorithm which is widely\nused in practice with function approximation \\citep{mnih2015human}. In\ncontrast, existing theoretical results are pessimistic about Q-learning. For\nexample, \\citep{baird1995residual} shows that Q-learning does not converge even\nwith linear function approximation for linear MDPs. Furthermore, even for\ntabular MDPs with synchronous updates, Q-learning was shown to have sub-optimal\nsample complexity \\citep{li2021q,azar2013minimax}. The goal of this work is to\nbridge the gap between practical success of Q-learning and the relatively\npessimistic theoretical results. The starting point of our work is the\nobservation that in practice, Q-learning is used with two important\nmodifications: (i) training with two networks, called online network and target\nnetwork simultaneously (online target learning, or OTL) , and (ii) experience\nreplay (ER) \\citep{mnih2015human}. While they have been observed to play a\nsignificant role in the practical success of Q-learning, a thorough theoretical\nunderstanding of how these two modifications improve the convergence behavior\nof Q-learning has been missing in literature. By carefully combining Q-learning\nwith OTL and \\emph{reverse} experience replay (RER) (a form of experience\nreplay), we present novel methods Q-Rex and Q-RexDaRe (Q-Rex + data reuse). We\nshow that Q-Rex efficiently finds the optimal policy for linear MDPs (or more\ngenerally for MDPs with zero inherent Bellman error with linear approximation\n(ZIBEL)) and provide non-asymptotic bounds on sample complexity -- the first\nsuch result for a Q-learning method for this class of MDPs under standard\nassumptions. Furthermore, we demonstrate that Q-RexDaRe in fact achieves near\noptimal sample complexity in the tabular setting, improving upon the existing\nresults for vanilla Q-learning.",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Naman Agarwal",
      "Syomantak Chaudhuri",
      "Prateek Jain",
      "Dheeraj Nagaraj",
      "Praneeth Netrapalli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.08440"
  },
  {
    "id": "arXiv:2110.08443",
    "title": "Prix-LM: Pretraining for Multilingual Knowledge Base Construction",
    "abstract": "Knowledge bases (KBs) contain plenty of structured world and commonsense\nknowledge. As such, they often complement distributional text-based information\nand facilitate various downstream tasks. Since their manual construction is\nresource- and time-intensive, recent efforts have tried leveraging large\npretrained language models (PLMs) to generate additional monolingual knowledge\nfacts for KBs. However, such methods have not been attempted for building and\nenriching multilingual KBs. Besides wider application, such multilingual KBs\ncan provide richer combined knowledge than monolingual (e.g., English) KBs.\nKnowledge expressed in different languages may be complementary and unequally\ndistributed: this implies that the knowledge available in high-resource\nlanguages can be transferred to low-resource ones. To achieve this, it is\ncrucial to represent multilingual knowledge in a shared/unified space. To this\nend, we propose a unified framework, Prix-LM, for multilingual KB construction\nand completion. We leverage two types of knowledge, monolingual triples and\ncross-lingual links, extracted from existing multilingual KBs, and tune a\nmultilingual language encoder XLM-R via a causal language modeling objective.\nPrix-LM integrates useful multilingual and KB-based factual knowledge into a\nsingle model. Experiments on standard entity-related tasks, such as link\nprediction in multiple languages, cross-lingual entity linking and bilingual\nlexicon induction, demonstrate its effectiveness, with gains reported over\nstrong task-specialised baselines.",
    "descriptor": "",
    "authors": [
      "Wenxuan Zhou",
      "Fangyu Liu",
      "Ivan Vuli\u0107",
      "Nigel Collier",
      "Muhao Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08443"
  },
  {
    "id": "arXiv:2110.08445",
    "title": "How Well Do You Know Your Audience? Reader-aware Question Generation",
    "abstract": "When writing, a person may need to anticipate questions from their readers,\nbut different types of readers may ask very different types of questions. If\nsomeone is writing for advice about a problem, what question will a domain\nexpert ask, and is this different from how a novice might react? In this paper,\nwe address the task of reader-aware question generation. We collect a new data\nset of questions and posts from social media, augmented with background\ninformation about the post readers. Based on predictive analysis and\ndescriptive differences, we find that different readers, such as experts and\nnovices, consistently ask different types of questions. We next develop several\ntext generation models that incorporate different types of reader background,\nincluding discrete and continuous reader representations based on the readers'\nprior behavior. We demonstrate that reader-aware models can perform on par or\nslightly better than the text-only model in some cases, particularly in cases\nwhere a post attracts very different questions from readers of different\ngroups. Our work has the potential to help writers anticipate the information\nneeds of different readers.",
    "descriptor": "",
    "authors": [
      "Ian Stewart",
      "Rada Mihalcea"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08445"
  },
  {
    "id": "arXiv:2110.08446",
    "title": "Self-Annotated Training for Controllable Image Captioning",
    "abstract": "The Controllable Image Captioning (CIC) task aims to generate captions\nconditioned on designated control signals. In this paper, we improve CIC from\ntwo aspects: 1) Existing reinforcement training methods are not applicable to\nstructure-related CIC models due to the fact that the accuracy-based reward\nfocuses mainly on contents rather than semantic structures. The lack of\nreinforcement training prevents the model from generating more accurate and\ncontrollable sentences. To solve the problem above, we propose a novel\nreinforcement training method for structure-related CIC models: Self-Annotated\nTraining (SAT), where a recursive sampling mechanism (RSM) is designed to force\nthe input control signal to match the actual output sentence. Extensive\nexperiments conducted on MSCOCO show that our SAT method improves C-Transformer\n(XE) on CIDEr-D score from 118.6 to 130.1 in the length-control task and from\n132.2 to 142.7 in the tense-control task, while maintaining more than 99$\\%$\nmatching accuracy with the control signal. 2) We introduce a new control\nsignal: sentence quality. Equipped with it, CIC models are able to generate\ncaptions of different quality levels as needed. Experiments show that without\nadditional information of ground truth captions, models controlled by the\nhighest level of sentence quality perform much better in accuracy than baseline\nmodels.",
    "descriptor": "",
    "authors": [
      "Zhangzi Zhu",
      "Tianlei Wang",
      "Hong Qu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08446"
  },
  {
    "id": "arXiv:2110.08447",
    "title": "TESDA: Transform Enabled Statistical Detection of Attacks in Deep Neural  Networks",
    "abstract": "Deep neural networks (DNNs) are now the de facto choice for computer vision\ntasks such as image classification. However, their complexity and \"black box\"\nnature often renders the systems they're deployed in vulnerable to a range of\nsecurity threats. Successfully identifying such threats, especially in\nsafety-critical real-world applications is thus of utmost importance, but still\nvery much an open problem. We present TESDA, a low-overhead, flexible, and\nstatistically grounded method for {online detection} of attacks by exploiting\nthe discrepancies they cause in the distributions of intermediate layer\nfeatures of DNNs. Unlike most prior work, we require neither dedicated hardware\nto run in real-time, nor the presence of a Trojan trigger to detect\ndiscrepancies in behavior. We empirically establish our method's usefulness and\npracticality across multiple architectures, datasets and diverse attacks,\nconsistently achieving detection coverages of above 95% with operation count\noverheads as low as 1-2%.",
    "descriptor": "\nComments: 10 pages, 2 reference pages, 2 appendix pages, 14 figures, 2 tables\n",
    "authors": [
      "Chandramouli Amarnath",
      "Aishwarya H. Balwani",
      "Kwondo Ma",
      "Abhijit Chatterjee"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08447"
  },
  {
    "id": "arXiv:2110.08450",
    "title": "Accelerating Training and Inference of Graph Neural Networks with Fast  Sampling and Pipelining",
    "abstract": "Improving the training and inference performance of graph neural networks\n(GNNs) is faced with a challenge uncommon in general neural networks: creating\nmini-batches requires a lot of computation and data movement due to the\nexponential growth of multi-hop graph neighborhoods along network layers. Such\na unique challenge gives rise to a diverse set of system design choices. We\nargue in favor of performing mini-batch training with neighborhood sampling in\na distributed multi-GPU environment, under which we identify major performance\nbottlenecks hitherto under-explored by developers: mini-batch preparation and\ntransfer. We present a sequence of improvements to mitigate these bottlenecks,\nincluding a performance-engineered neighborhood sampler, a shared-memory\nparallelization strategy, and the pipelining of batch transfer with GPU\ncomputation. We also conduct an empirical analysis that supports the use of\nsampling for inference, showing that test accuracies are not materially\ncompromised. Such an observation unifies training and inference, simplifying\nmodel implementation. We report comprehensive experimental results with several\nbenchmark data sets and GNN architectures, including a demonstration that, for\nthe ogbn-papers100M data set, our system SALIENT achieves a speedup of 3x over\na standard PyTorch-Geometric implementation with a single GPU and a further 8x\nparallel speedup with 16 GPUs. Therein, training a 3-layer GraphSAGE model with\nsampling fanout (15, 10, 5) takes 2.0 seconds per epoch and inference with\nfanout (20, 20, 20) takes 2.4 seconds, attaining test accuracy 64.58%.",
    "descriptor": "",
    "authors": [
      "Tim Kaler",
      "Nickolas Stathas",
      "Anne Ouyang",
      "Alexandros-Stavros Iliopoulos",
      "Tao B. Schardl",
      "Charles E. Leiserson",
      "Jie Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2110.08450"
  },
  {
    "id": "arXiv:2110.08451",
    "title": "Sum-of-Squares Geometry Processing",
    "abstract": "Geometry processing presents a variety of difficult numerical problems, each\nseeming to require its own tailored solution. This breadth is largely due to\nthe expansive list of geometric primitives, e.g., splines, triangles, and\nhexahedra, joined with an ever-expanding variety of objectives one might want\nto achieve with them. With the recent increase in attention toward higher-order\nsurfaces, we can expect a variety of challenges porting existing solutions that\nwork on triangle meshes to work on these more complex geometry types. In this\npaper, we present a framework for solving many core geometry processing\nproblems on higher-order surfaces. We achieve this goal through sum-of-squares\noptimization, which transforms nonlinear polynomial optimization problems into\nsequences of convex problems whose complexity is captured by a single degree\nparameter. This allows us to solve a suite of problems on higher-order\nsurfaces, such as continuous collision detection and closest point queries on\ncurved patches, with only minor changes between formulations and geometries.",
    "descriptor": "",
    "authors": [
      "Zo\u00eb Marschner",
      "Paul Zhang",
      "David Palmer",
      "Justin Solomon"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.08451"
  },
  {
    "id": "arXiv:2110.08453",
    "title": "Voting Theory in the Lean Theorem Prover",
    "abstract": "There is a long tradition of fruitful interaction between logic and social\nchoice theory. In recent years, much of this interaction has focused on\ncomputer-aided methods such as SAT solving and interactive theorem proving. In\nthis paper, we report on the development of a framework for formalizing voting\ntheory in the Lean theorem prover, which we have applied to verify properties\nof a recently studied voting method. While previous applications of interactive\ntheorem proving to social choice (using Isabelle/HOL and Mizar) have focused on\nthe verification of impossibility theorems, we aim to cover a variety of\nresults ranging from impossibility theorems to the verification of properties\nof specific voting methods (e.g., Condorcet consistency, independence of\nclones, etc.). In order to formalize voting theoretic axioms concerning adding\nor removing candidates and voters, we work in a variable-election setting whose\nformalization makes use of dependent types in Lean.",
    "descriptor": "\nComments: Postprint of the paper in Proceedings of the Eighth International Conference on Logic, Rationality and Interaction (Springer) with two typos fixed\n",
    "authors": [
      "Wesley H. Holliday",
      "Chase Norman",
      "Eric Pacuit"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.08453"
  },
  {
    "id": "arXiv:2110.08454",
    "title": "Good Examples Make A Faster Learner: Simple Demonstration-based Learning  for Low-resource NER",
    "abstract": "Recent advances in prompt-based learning have shown impressive results on\nfew-shot text classification tasks by using cloze-style language prompts. There\nhave been attempts on prompt-based learning for NER which use manually designed\ntemplates to predict entity types. However, these two-step methods may suffer\nfrom error propagation (from entity span detection), need to prompt for all\npossible text spans which is costly, and neglect the interdependency when\npredicting labels for different spans in a sentence. In this paper, we present\na simple demonstration-based learning method for NER, which augments the prompt\n(learning context) with a few task demonstrations. Such demonstrations help the\nmodel learn the task better under low-resource settings and allow for span\ndetection and classification over all tokens jointly. Here, we explore\nentity-oriented demonstration which selects an appropriate entity example per\neach entity type, and instance-oriented demonstration which retrieves a similar\ninstance example. Through extensive experiments, we find empirically that\nshowing entity example per each entity type, along with its example sentence,\ncan improve the performance both in in-domain and cross-domain settings by 1-3\nF1 score.",
    "descriptor": "\nComments: 7 pages, 4 figures, 4 tables\n",
    "authors": [
      "Dong-Ho Lee",
      "Mahak Agarwal",
      "Akshen Kadakia",
      "Jay Pujara",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08454"
  },
  {
    "id": "arXiv:2110.08455",
    "title": "Knowledge Enhanced Pretrained Language Models: A Compreshensive Survey",
    "abstract": "Pretrained Language Models (PLM) have established a new paradigm through\nlearning informative contextualized representations on large-scale text corpus.\nThis new paradigm has revolutionized the entire field of natural language\nprocessing, and set the new state-of-the-art performance for a wide variety of\nNLP tasks. However, though PLMs could store certain knowledge/facts from\ntraining corpus, their knowledge awareness is still far from satisfactory. To\naddress this issue, integrating knowledge into PLMs have recently become a very\nactive research area and a variety of approaches have been developed. In this\npaper, we provide a comprehensive survey of the literature on this emerging and\nfast-growing field - Knowledge Enhanced Pretrained Language Models (KE-PLMs).\nWe introduce three taxonomies to categorize existing work. Besides, we also\nsurvey the various NLU and NLG applications on which KE-PLM has demonstrated\nsuperior performance over vanilla PLMs. Finally, we discuss challenges that\nface KE-PLMs and also promising directions for future research.",
    "descriptor": "",
    "authors": [
      "Xiaokai Wei",
      "Shen Wang",
      "Dejiao Zhang",
      "Parminder Bhatia",
      "Andrew Arnold"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08455"
  },
  {
    "id": "arXiv:2110.08458",
    "title": "Controllable Semantic Parsing via Retrieval Augmentation",
    "abstract": "In practical applications of semantic parsing, we often want to rapidly\nchange the behavior of the parser, such as enabling it to handle queries in a\nnew domain, or changing its predictions on certain targeted queries. While we\ncan introduce new training examples exhibiting the target behavior, a mechanism\nfor enacting such behavior changes without expensive model re-training would be\npreferable. To this end, we propose ControllAble Semantic Parser via Exemplar\nRetrieval (CASPER). Given an input query, the parser retrieves related\nexemplars from a retrieval index, augments them to the query, and then applies\na generative seq2seq model to produce an output parse. The exemplars act as a\ncontrol mechanism over the generic generative model: by manipulating the\nretrieval index or how the augmented query is constructed, we can manipulate\nthe behavior of the parser. On the MTOP dataset, in addition to achieving\nstate-of-the-art on the standard setup, we show that CASPER can parse queries\nin a new domain, adapt the prediction toward the specified patterns, or adapt\nto new semantic schemas without having to further re-train the model.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Panupong Pasupat",
      "Yuan Zhang",
      "Kelvin Guu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08458"
  },
  {
    "id": "arXiv:2110.08460",
    "title": "A Short Study on Compressing Decoder-Based Language Models",
    "abstract": "Pre-trained Language Models (PLMs) have been successful for a wide range of\nnatural language processing (NLP) tasks. The state-of-the-art of PLMs, however,\nare extremely large to be used on edge devices. As a result, the topic of model\ncompression has attracted increasing attention in the NLP community. Most of\nthe existing works focus on compressing encoder-based models (tiny-BERT,\ndistilBERT, distilRoBERTa, etc), however, to the best of our knowledge, the\ncompression of decoder-based models (such as GPT-2) has not been investigated\nmuch. Our paper aims to fill this gap. Specifically, we explore two directions:\n1) we employ current state-of-the-art knowledge distillation techniques to\nimprove fine-tuning of DistilGPT-2. 2) we pre-train a compressed GPT-2 model\nusing layer truncation and compare it against the distillation-based method\n(DistilGPT2). The training time of our compressed model is significantly less\nthan DistilGPT-2, but it can achieve better performance when fine-tuned on\ndownstream tasks. We also demonstrate the impact of data cleaning on model\nperformance.",
    "descriptor": "",
    "authors": [
      "Tianda Li",
      "Yassir El Mesbahi",
      "Ivan Kobyzev",
      "Ahmad Rashid",
      "Atif Mahmud",
      "Nithin Anchuri",
      "Habib Hajimolahoseini",
      "Yang Liu",
      "Mehdi Rezagholizadeh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08460"
  },
  {
    "id": "arXiv:2110.08462",
    "title": "Leveraging Knowledge in Multilingual Commonsense Reasoning",
    "abstract": "Commonsense reasoning (CSR) requires the model to be equipped with general\nworld knowledge. While CSR is a language-agnostic process, most comprehensive\nknowledge sources are in few popular languages, especially English. Thus, it\nremains unclear how to effectively conduct multilingual commonsense reasoning\n(XCSR) for various languages. In this work, we propose to utilize English\nknowledge sources via a translate-retrieve-translate (TRT) strategy. For\nmultilingual commonsense questions and choices, we collect related knowledge\nvia translation and retrieval from the knowledge sources. The retrieved\nknowledge is then translated into the target language and integrated into a\npre-trained multilingual language model via visible knowledge attention. Then\nwe utilize a diverse of 4 English knowledge sources to provide more\ncomprehensive coverage of knowledge in different formats. Extensive results on\nthe XCSR benchmark demonstrate that TRT with external knowledge can\nsignificantly improve multilingual commonsense reasoning in both zero-shot and\ntranslate-train settings, outperforming 3.3 and 3.6 points over the previous\nstate-of-the-art on XCSR benchmark datasets (X-CSQA and X-CODAH).",
    "descriptor": "\nComments: First place in XCSR Leaderboard: this https URL Work in progress\n",
    "authors": [
      "Yuwei Fang",
      "Shuohang Wang",
      "Yichong Xu",
      "Ruochen Xu",
      "Siqi Sun",
      "Chenguang Zhu",
      "Michael Zeng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08462"
  },
  {
    "id": "arXiv:2110.08464",
    "title": "Seeking Patterns, Not just Memorizing Procedures: Contrastive Learning  for Solving Math Word Problems",
    "abstract": "Math Word Problem (MWP) solving needs to discover the quantitative\nrelationships over natural language narratives. Recent work shows that existing\nmodels memorize procedures from context and rely on shallow heuristics to solve\nMWPs. In this paper, we look at this issue and argue that the cause is a lack\nof overall understanding of MWP patterns. We first investigate how a neural\nnetwork understands patterns only from semantics, and observe that, if the\nprototype equations are the same, most problems get closer representations and\nthose representations apart from them or close to other prototypes tend to\nproduce wrong solutions. Inspired by it, we propose a contrastive learning\napproach, where the neural network perceives the divergence of patterns. We\ncollect contrastive examples by converting the prototype equation into a tree\nand seeking similar tree structures. The solving model is trained with an\nauxiliary objective on the collected examples, resulting in the representations\nof problems with similar prototypes being pulled closer. We conduct experiments\non the Chinese dataset Math23k and the English dataset MathQA. Our method\ngreatly improves the performance in monolingual and multilingual settings.",
    "descriptor": "",
    "authors": [
      "Zhongli Li",
      "Wenxuan Zhang",
      "Chao Yan",
      "Qingyu Zhou",
      "Chao Li",
      "Hongzhi Liu",
      "Yunbo Cao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08464"
  },
  {
    "id": "arXiv:2110.08465",
    "title": "A Heterogeneous Graph Based Framework for Multimodal Neuroimaging Fusion  Learning",
    "abstract": "Here, we present a Heterogeneous Graph neural network for Multimodal\nneuroimaging fusion learning (HGM). Traditional GNN-based models usually assume\nthe brain network is a homogeneous graph with single type of nodes and edges.\nHowever, vast literatures have shown the heterogeneity of the human brain\nespecially between the two hemispheres. Homogeneous brain network is\ninsufficient to model the complicated brain state. Therefore, in this work we\nfirstly model the brain network as heterogeneous graph with multi-type nodes\n(i.e., left and right hemispheric nodes) and multi-type edges (i.e., intra- and\ninter-hemispheric edges). Besides, we also propose a self-supervised\npre-training strategy based on heterogeneou brain network to address the\noverfitting problem due to the complex model and small sample size. Our results\non two datasets show the superiority of proposed model over other multimodal\nmethods for disease prediction task. Besides, ablation experiments show that\nour model with pre-training strategy can alleviate the problem of limited\ntraining sample size.",
    "descriptor": "",
    "authors": [
      "Gen Shi",
      "Yifan Zhu",
      "Wenjin Liu",
      "Xuesong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2110.08465"
  },
  {
    "id": "arXiv:2110.08466",
    "title": "On the Safety of Conversational Models: Taxonomy, Dataset, and Benchmark",
    "abstract": "Dialogue safety problems severely limit the real-world deployment of neural\nconversational models and attract great research interests recently. We propose\na taxonomy for dialogue safety specifically designed to capture unsafe\nbehaviors that are unique in human-bot dialogue setting, with focuses on\ncontext-sensitive unsafety, which is under-explored in prior works. To spur\nresearch in this direction, we compile DiaSafety, a dataset of 6 unsafe\ncategories with rich context-sensitive unsafe examples. Experiments show that\nexisting utterance-level safety guarding tools fail catastrophically on our\ndataset. As a remedy, we train a context-level dialogue safety classifier to\nprovide a strong baseline for context-sensitive dialogue unsafety detection.\nWith our classifier, we perform safety evaluations on popular conversational\nmodels and show that existing dialogue systems are still stuck in\ncontext-sensitive safety problems.",
    "descriptor": "",
    "authors": [
      "Hao Sun",
      "Guangxuan Xu",
      "Jiawen Deng",
      "Jiale Cheng",
      "Chujie Zheng",
      "Hao Zhou",
      "Nanyun Peng",
      "Xiaoyan Zhu",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08466"
  },
  {
    "id": "arXiv:2110.08467",
    "title": "Improving Compositional Generalization with Self-Training for  Data-to-Text Generation",
    "abstract": "Data-to-text generation focuses on generating fluent natural language\nresponses from structured semantic representations. Such representations are\ncompositional, allowing for the combination of atomic meaning schemata in\nvarious ways to express the rich semantics in natural language. Recently,\npretrained language models (LMs) have achieved impressive results on\ndata-to-text tasks, though it remains unclear the extent to which these LMs\ngeneralize to new semantic representations. In this work, we systematically\nstudy the compositional generalization of current state-of-the-art generation\nmodels in data-to-text tasks. By simulating structural shifts in the\ncompositional Weather dataset, we show that T5 models fail to generalize to\nunseen structures. Next, we show that template-based input representations\ngreatly improve the model performance and model scale does not trivially solve\nthe lack of generalization. To further improve the model's performance, we\npropose an approach based on self-training using finetuned BLEURT for\npseudo-response selection. Extensive experiments on the few-shot Weather and\nmulti-domain SGD datasets demonstrate strong gains of our method.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Sanket Vaibhav Mehta",
      "Jinfeng Rao",
      "Yi Tay",
      "Mihir Kale",
      "Ankur Parikh",
      "Hongtao Zhong",
      "Emma Strubell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08467"
  },
  {
    "id": "arXiv:2110.08470",
    "title": "Case-based Reasoning for Better Generalization in Text-Adventure Games",
    "abstract": "Text-based games (TBG) have emerged as promising environments for driving\nresearch in grounded language understanding and studying problems like\ngeneralization and sample efficiency. Several deep reinforcement learning (RL)\nmethods with varying architectures and learning schemes have been proposed for\nTBGs. However, these methods fail to generalize efficiently, especially under\ndistributional shifts. In a departure from deep RL approaches, in this paper,\nwe propose a general method inspired by case-based reasoning to train agents\nand generalize out of the training distribution. The case-based reasoner\ncollects instances of positive experiences from the agent's interaction with\nthe world in the past and later reuses the collected experiences to act\nefficiently. The method can be applied in conjunction with any existing\non-policy neural agent in the literature for TBGs. Our experiments show that\nthe proposed approach consistently improves existing methods, obtains good\nout-of-distribution generalization, and achieves new state-of-the-art results\non widely used environments.",
    "descriptor": "",
    "authors": [
      "Mattia Atzeni",
      "Shehzaad Dhuliawala",
      "Keerthiram Murugesan",
      "Mrinmaya Sachan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08470"
  },
  {
    "id": "arXiv:2110.08472",
    "title": "Joint 3D Human Shape Recovery from A Single Imag with Bilayer-Graph",
    "abstract": "The ability to estimate the 3D human shape and pose from images can be useful\nin many contexts. Recent approaches have explored using graph convolutional\nnetworks and achieved promising results. The fact that the 3D shape is\nrepresented by a mesh, an undirected graph, makes graph convolutional networks\na natural fit for this problem. However, graph convolutional networks have\nlimited representation power. Information from nodes in the graph is passed to\nconnected neighbors, and propagation of information requires successive graph\nconvolutions. To overcome this limitation, we propose a dual-scale graph\napproach. We use a coarse graph, derived from a dense graph, to estimate the\nhuman's 3D pose, and the dense graph to estimate the 3D shape. Information in\ncoarse graphs can be propagated over longer distances compared to dense graphs.\nIn addition, information about pose can guide to recover local shape detail and\nvice versa. We recognize that the connection between coarse and dense is itself\na graph, and introduce graph fusion blocks to exchange information between\ngraphs with different scales. We train our model end-to-end and show that we\ncan achieve state-of-the-art results for several evaluation datasets.",
    "descriptor": "\nComments: 3DV'21\n",
    "authors": [
      "Xin Yu",
      "Jeroen van Baar",
      "Siheng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08472"
  },
  {
    "id": "arXiv:2110.08477",
    "title": "FedMM: Saddle Point Optimization for Federated Adversarial Domain  Adaptation",
    "abstract": "Federated adversary domain adaptation is a unique distributed minimax\ntraining task due to the prevalence of label imbalance among clients, with each\nclient only seeing a subset of the classes of labels required to train a global\nmodel. To tackle this problem, we propose a distributed minimax optimizer\nreferred to as FedMM, designed specifically for the federated adversary domain\nadaptation problem. It works well even in the extreme case where each client\nhas different label classes and some clients only have unsupervised tasks. We\nprove that FedMM ensures convergence to a stationary point with domain-shifted\nunsupervised data. On a variety of benchmark datasets, extensive experiments\nshow that FedMM consistently achieves either significant communication savings\nor significant accuracy improvements over federated optimizers based on the\ngradient descent ascent (GDA) algorithm. When training from scratch, for\nexample, it outperforms other GDA based federated average methods by around\n$20\\%$ in accuracy over the same communication rounds; and it consistently\noutperforms when training from pre-trained models with an accuracy improvement\nfrom $5.4\\%$ to $9\\%$ for different networks.",
    "descriptor": "",
    "authors": [
      "Yan Shen",
      "Jian Du",
      "Hao Zhang",
      "Benyu Zhang",
      "Zhanghexuan Ji",
      "Mingchen Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08477"
  },
  {
    "id": "arXiv:2110.08480",
    "title": "Learning Cooperation and Online Planning Through Simulation and Graph  Convolutional Network",
    "abstract": "Multi-agent Markov Decision Process (MMDP) has been an effective way of\nmodelling sequential decision making algorithms for multi-agent cooperative\nenvironments. A number of algorithms based on centralized and decentralized\nplanning have been developed in this domain. However, dynamically changing\nenvironment, coupled with exponential size of the state and joint action space,\nmake it difficult for these algorithms to provide both efficiency and\nscalability. Recently, Centralized planning algorithm FV-MCTS-MP and\ndecentralized planning algorithm \\textit{Alternate maximization with\nBehavioural Cloning} (ABC) have achieved notable performance in solving MMDPs.\nHowever, they are not capable of adapting to dynamically changing environments\nand accounting for the lack of communication among agents, respectively.\nAgainst this background, we introduce a simulation based online planning\nalgorithm, that we call SiCLOP, for multi-agent cooperative environments.\nSpecifically, SiCLOP tailors Monte Carlo Tree Search (MCTS) and uses\nCoordination Graph (CG) and Graph Neural Network (GCN) to learn cooperation and\nprovides real time solution of a MMDP problem. It also improves scalability\nthrough an effective pruning of action space. Additionally, unlike FV-MCTS-MP\nand ABC, SiCLOP supports transfer learning, which enables learned agents to\noperate in different environments. We also provide theoretical discussion about\nthe convergence property of our algorithm within the context of multi-agent\nsettings. Finally, our extensive empirical results show that SiCLOP\nsignificantly outperforms the state-of-the-art online planning algorithms.",
    "descriptor": "",
    "authors": [
      "Rafid Ameer Mahmud",
      "Fahim Faisal",
      "Saaduddin Mahmud",
      "Md. Mosaddek Khan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08480"
  },
  {
    "id": "arXiv:2110.08481",
    "title": "On the randomness analysis of link quality prediction: limitations and  benefits",
    "abstract": "In wireless multi-hop networks, such as wireless sensor networks, link\nquality (LQ) is one of the most important metrics and is widely used in\nhigher-layer applications such as routing protocols. An accurate link quality\nprediction may greatly help to improve the performance of wireless multi-hop\nnetworks. Researchers have proposed a lot of link quality prediction models in\nrecent years. However, due to the dynamic and stochastic nature of wireless\ntransmission, the performance of link quality prediction remains challenging.\nIn this article, we mainly analyze the influence of the stochastic nature of\nwireless transmission on the link quality prediction model and discuss the\nbenefits in the application of wireless multi-hop networks with the\nperformance-limited link quality prediction models.",
    "descriptor": "",
    "authors": [
      "Shi Xiaofei",
      "Liao Wenxing"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.08481"
  },
  {
    "id": "arXiv:2110.08483",
    "title": "Streaming Decision Trees and Forests",
    "abstract": "Machine learning has successfully leveraged modern data and provided\ncomputational solutions to innumerable real-world problems, including physical\nand biomedical discoveries. Currently, estimators could handle both scenarios\nwith all samples available and situations requiring continuous updates.\nHowever, there is still room for improvement on streaming algorithms based on\nbatch decision trees and random forests, which are the leading methods in batch\ndata tasks. In this paper, we explore the simplest partial fitting algorithm to\nextend batch trees and test our models: stream decision tree (SDT) and stream\ndecision forest (SDF) on three classification tasks of varying complexities.\nFor reference, both existing streaming trees (Hoeffding trees and Mondrian\nforests) and batch estimators are included in the experiments. In all three\ntasks, SDF consistently produces high accuracy, whereas existing estimators\nencounter space restraints and accuracy fluctuations. Thus, our streaming trees\nand forests show great potential for further improvements, which are good\ncandidates for solving problems like distribution drift and transfer learning.",
    "descriptor": "",
    "authors": [
      "Haoyin Xu",
      "Jayanta Dey",
      "Sambit Panda",
      "Joshua T. Vogelstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.08483"
  },
  {
    "id": "arXiv:2110.08484",
    "title": "A Good Prompt Is Worth Millions of Parameters? Low-resource Prompt-based  Learning for Vision-Language Models",
    "abstract": "Large pretrained vision-language (VL) models can learn a new task with a\nhandful of examples or generalize to a new task without fine-tuning. However,\nthese gigantic VL models are hard to deploy for real-world applications due to\ntheir impractically huge model size and slow inference speed. In this work, we\npropose FewVLM, a few-shot prompt-based learner on vision-language tasks. We\npretrain a sequence-to-sequence Transformer model with both prefix language\nmodeling (PrefixLM) and masked language modeling (MaskedLM), and introduce\nsimple prompts to improve zero-shot and few-shot performance on VQA and image\ncaptioning. Experimental results on five VQA and captioning datasets show that\n\\method\\xspace outperforms Frozen which is 31 times larger than ours by 18.2%\npoint on zero-shot VQAv2 and achieves comparable results to a 246$\\times$\nlarger model, PICa. We observe that (1) prompts significantly affect zero-shot\nperformance but marginally affect few-shot performance, (2) MaskedLM helps\nfew-shot VQA tasks while PrefixLM boosts captioning performance, and (3)\nperformance significantly increases when training set size is small.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Woojeong Jin",
      "Yu Cheng",
      "Yelong Shen",
      "Weizhu Chen",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08484"
  },
  {
    "id": "arXiv:2110.08485",
    "title": "Design of Link-Quality-prediction-based Software-Defined Wireless Sensor  Networks",
    "abstract": "In wireless multi-hop networks, the instability of the wireless links leads\nto unstable networking. Even in the newly designed Software-Defined Wireless\nSensor Networks (SDWSN), similar problems exist. To further improve the\nstability of SDWSN, we introduce a Link Quality (LQ) prediction model into the\nSDWSN architecture. The prediction model is used to improve the stability\nbetween neighbor nodes, and thus the stability of wireless multi-hop routes.\nSimulation results show that the LQ prediction model can make reasonable\ncorrections to the reality wireless link model, which can well address the\nrestrictive nature of unstable links. As a result, by reducing the use of\nunstable wireless links, the stability of the SDWSN network improved.",
    "descriptor": "",
    "authors": [
      "Liao Wenxing",
      "Shi Xiaofei"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.08485"
  },
  {
    "id": "arXiv:2110.08486",
    "title": "Understanding Procedural Knowledge by Sequencing Multimodal  Instructional Manuals",
    "abstract": "The ability to sequence unordered events is an essential skill to comprehend\nand reason about real world task procedures, which often requires thorough\nunderstanding of temporal common sense and multimodal information, as these\nprocedures are often communicated through a combination of texts and images.\nSuch capability is essential for applications such as sequential task planning\nand multi-source instruction summarization. While humans are capable of\nreasoning about and sequencing unordered multimodal procedural instructions,\nwhether current machine learning models have such essential capability is still\nan open question. In this work, we benchmark models' capability of reasoning\nover and sequencing unordered multimodal instructions by curating datasets from\npopular online instructional manuals and collecting comprehensive human\nannotations. We find models not only perform significantly worse than humans\nbut also seem incapable of efficiently utilizing the multimodal information. To\nimprove machines' performance on multimodal event sequencing, we propose\nsequentiality-aware pretraining techniques that exploit the sequential\nalignment properties of both texts and images, resulting in > 5% significant\nimprovements.",
    "descriptor": "",
    "authors": [
      "Te-Lin Wu",
      "Alex Spangher",
      "Pegah Alipoormolabashi",
      "Marjorie Freedman",
      "Ralph Weischedel",
      "Nanyun Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08486"
  },
  {
    "id": "arXiv:2110.08488",
    "title": "Lifelong Topological Visual Navigation",
    "abstract": "The ability for a robot to navigate with only the use of vision is appealing\ndue to its simplicity. Traditional vision-based navigation approaches required\na prior map-building step that was arduous and prone to failure, or could only\nexactly follow previously executed trajectories. Newer learning-based visual\nnavigation techniques reduce the reliance on a map and instead directly learn\npolicies from image inputs for navigation. There are currently two prevalent\nparadigms: end-to-end approaches forego the explicit map representation\nentirely, and topological approaches which still preserve some loose\nconnectivity of the space. However, while end-to-end methods tend to struggle\nin long-distance navigation tasks, topological map-based solutions are prone to\nfailure due to spurious edges in the graph. In this work, we propose a\nlearning-based topological visual navigation method with graph update\nstrategies that improve lifelong navigation performance over time. We take\ninspiration from sampling-based planning algorithms to build image-based\ntopological graphs, resulting in sparser graphs yet with higher navigation\nperformance compared to baseline methods. Also, unlike controllers that learn\nfrom fixed training environments, we show that our model can be finetuned using\na relatively small dataset from the real-world environment where the robot is\ndeployed. We further assess performance of our system in real-world\ndeployments.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Rey Reza Wiyatno",
      "Anqi Xu",
      "Liam Paull"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08488"
  },
  {
    "id": "arXiv:2110.08493",
    "title": "Grayscale Based Algorithm for Remote Sensing with Deep Learning",
    "abstract": "Remote sensing is the image acquisition of a target without having physical\ncontact with it. Nowadays remote sensing data is widely preferred due to its\nreduced image acquisition period. The remote sensing of ground targets is more\nchallenging because of the various factors that affect the propagation of light\nthrough different mediums from a satellite acquisition. Several Convolutional\nNeural Network-based algorithms are being implemented in the field of remote\nsensing. Supervised learning is a machine learning technique where the data is\nlabelled according to their classes prior to the training. In order to detect\nand classify the targets more accurately, YOLOv3, an algorithm based on\nbounding and anchor boxes is adopted. In order to handle the various effects of\nlight travelling through the atmosphere, Grayscale based YOLOv3 configuration\nis introduced. For better prediction and for solving the Rayleigh scattering\neffect, RGB based grayscale algorithms are proposed. The acquired images are\nanalysed and trained with the grayscale based YOLO3 algorithm for target\ndetection. The results show that the grayscale-based method can sense the\ntarget more accurately and effectively than the traditional YOLOv3 approach.",
    "descriptor": "\nComments: 14 pages, 4 figures, Journal Expert Systems with Applications\n",
    "authors": [
      "Sai Ganesh CS",
      "Aouthithiye Barathwaj SR Y",
      "R. Azhagumurugan",
      "R. Swethaa S"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.08493"
  },
  {
    "id": "arXiv:2110.08494",
    "title": "Feedforward Control of DGs for a Self-healing Microgrid",
    "abstract": "Network reconfiguration (NR) has recently received significant attention due\nto its potential to improve grid resilience by realizing self-healing\nmicrogrids (MGs). This paper proposes a new strategy for the real-time\nfrequency regulation of a reconfigurable MG, wherein the feedforward control of\nsynchronous and inverter-interfaced distributed generators (DGs) is achieved in\ncoordination with the operations of sectionalizing and tie switches (SWs). This\nenables DGs to compensate more quickly, and preemptively, for a forthcoming\nvariation in load demand due to NR-aided restoration. An analytical dynamic\nmodel of a reconfigurable MG is developed to analyze the MG frequency response\nto NR and hence determine the desired dynamics of the feedforward controllers,\nwith the integration of feedback loops for inertial response emulation and\nprimary and secondary frequency control. A small-signal analysis is conducted\nto analyze the contribution of the supplementary feedforward control to the MG\nfrequency regulation. Simulation case studies of NR-aided load restoration are\nalso performed. The results of the small-signal analysis and case studies\nconfirm that the proposed strategy is effective for improving the MG frequency\nregulation under various conditions of load demand, model parameter errors, and\ncommunication time delays.",
    "descriptor": "",
    "authors": [
      "Young-Jin Kim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.08494"
  },
  {
    "id": "arXiv:2110.08495",
    "title": "Hybrid Mutimodal Fusion for Dimensional Emotion Recognition",
    "abstract": "In this paper, we extensively present our solutions for the MuSe-Stress\nsub-challenge and the MuSe-Physio sub-challenge of Multimodal Sentiment\nChallenge (MuSe) 2021. The goal of MuSe-Stress sub-challenge is to predict the\nlevel of emotional arousal and valence in a time-continuous manner from\naudio-visual recordings and the goal of MuSe-Physio sub-challenge is to predict\nthe level of psycho-physiological arousal from a) human annotations fused with\nb) galvanic skin response (also known as Electrodermal Activity (EDA)) signals\nfrom the stressed people. The Ulm-TSST dataset which is a novel subset of the\naudio-visual textual Ulm-Trier Social Stress dataset that features German\nspeakers in a Trier Social Stress Test (TSST) induced stress situation is used\nin both sub-challenges. For the MuSe-Stress sub-challenge, we highlight our\nsolutions in three aspects: 1) the audio-visual features and the bio-signal\nfeatures are used for emotional state recognition. 2) the Long Short-Term\nMemory (LSTM) with the self-attention mechanism is utilized to capture complex\ntemporal dependencies within the feature sequences. 3) the late fusion strategy\nis adopted to further boost the model's recognition performance by exploiting\ncomplementary information scattered across multimodal sequences. Our proposed\nmodel achieves CCC of 0.6159 and 0.4609 for valence and arousal respectively on\nthe test set, which both rank in the top 3. For the MuSe-Physio sub-challenge,\nwe first extract the audio-visual features and the bio-signal features from\nmultiple modalities. Then, the LSTM module with the self-attention mechanism,\nand the Gated Convolutional Neural Networks (GCNN) as well as the LSTM network\nare utilized for modeling the complex temporal dependencies in the sequence.\nFinally, the late fusion strategy is used. Our proposed method also achieves\nCCC of 0.5412 on the test set, which ranks in the top 3.",
    "descriptor": "\nComments: 8 pages, 2 figures, accepted by ACM MM2021\n",
    "authors": [
      "Ziyu Ma",
      "Fuyan Ma",
      "Bin Sun",
      "Shutao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08495"
  },
  {
    "id": "arXiv:2110.08499",
    "title": "PRIMER: Pyramid-based Masked Sentence Pre-training for Multi-document  Summarization",
    "abstract": "Recently proposed pre-trained generation models achieve strong performance on\nsingle-document summarization benchmarks. However, most of them are pre-trained\nwith general-purpose objectives and mainly aim to process single document\ninputs. In this paper, we propose PRIMER, a pre-trained model for\nmulti-document representation with focus on summarization that reduces the need\nfor dataset-specific architectures and large amounts of fine-tuning labeled\ndata. Specifically, we adopt the Longformer architecture with proper input\ntransformation and global attention to fit for multi-document inputs, and we\nuse Gap Sentence Generation objective with a new strategy to select salient\nsentences for the whole cluster, called Entity Pyramid, to teach the model to\nselect and aggregate information across a cluster of related documents. With\nextensive experiments on 6 multi-document summarization datasets from 3\ndifferent domains on the zero-shot, few-shot, and full-supervised settings, our\nmodel, PRIMER, outperforms current state-of-the-art models on most of these\nsettings with large margins. Code and pre-trained models are released at\nhttps://github.com/allenai/PRIMER",
    "descriptor": "",
    "authors": [
      "Wen Xiao",
      "Iz Beltagy",
      "Giuseppe Carenini",
      "Arman Cohan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08499"
  },
  {
    "id": "arXiv:2110.08501",
    "title": "Think Before You Speak: Using Self-talk to Generate Implicit Commonsense  Knowledge for Response Generation",
    "abstract": "Implicit knowledge, such as common sense, is key to fluid human\nconversations. Current neural response generation (RG) models are trained\nend-to-end, omitting unstated implicit knowledge. In this paper, we present a\nself-talk approach that first generates the implicit commonsense knowledge and\nthen generates response by referencing the externalized knowledge, all using\none generative model. We analyze different choices to collect knowledge-aligned\ndialogues, represent implicit knowledge, and elicit knowledge and responses. We\nintroduce three evaluation aspects: knowledge quality, knowledge-response\nconnection, and response quality and perform extensive human evaluations. Our\nexperimental results show that compared with end-to-end RG models, self-talk\nmodels that externalize the knowledge grounding process by explicitly\ngenerating implicit knowledge also produce responses that are more informative,\nspecific, and follow common sense. We also find via human evaluation that\nself-talk models generate high-quality knowledge around 75% of the time. We\nhope that our findings encourage further work on different approaches to\nmodeling implicit commonsense knowledge and training knowledgeable RG models.",
    "descriptor": "\nComments: 13 pages, 2 figures, 7 tables\n",
    "authors": [
      "Pei Zhou",
      "Karthik Gopalakrishnan",
      "Behnam Hedayatnia",
      "Seokhwan Kim",
      "Jay Pujara",
      "Xiang Ren",
      "Yang Liu",
      "Dilek Hakkani-Tur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08501"
  },
  {
    "id": "arXiv:2110.08507",
    "title": "Can CAV Reduce Non-Recurrent Urban Road Congestion?",
    "abstract": "A well-designed resilient and sustainable urban transportation system can\nrecover quickly from the non-recurrent road congestion (NRC), which is often\ncaused by en-route events (e.g., road closure due to car collisions). Existing\nsolutions, such as on-board navigation systems and temporary rerouting road\nsigns, are not effective due to delayed responses. Connected Autonomous\nVehicles (CAV) can be helpful in improving recurrent traffic as they can\nautonomously adjust their speed according to their real-time surrounding\ntraffic, sensed by vehicular communications. Preliminary simulation results in\nthis short paper show that CAV can also improve traffic when non-recurrent\ncongestion occurs. Other results in fuel consumption, CO2 emission, and\ntraditional traffic safety indicators are open for future discussions.",
    "descriptor": "",
    "authors": [
      "Yunkai Li",
      "Haotian Li",
      "Beatriz Martinez-Pastor",
      "Shen Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.08507"
  },
  {
    "id": "arXiv:2110.08510",
    "title": "DFW-PP: Dynamic Feature Weighting based Popularity Prediction for Social  Media Content",
    "abstract": "The increasing popularity of social media platforms makes it important to\nstudy user engagement, which is a crucial aspect of any marketing strategy or\nbusiness model. The over-saturation of content on social media platforms has\npersuaded us to identify the important factors that affect content popularity.\nThis comes from the fact that only an iota of the humongous content available\nonline receives the attention of the target audience. Comprehensive research\nhas been done in the area of popularity prediction using several Machine\nLearning techniques. However, we observe that there is still significant scope\nfor improvement in analyzing the social importance of media content. We propose\nthe DFW-PP framework, to learn the importance of different features that vary\nover time. Further, the proposed method controls the skewness of the\ndistribution of the features by applying a log-log normalization. The proposed\nmethod is experimented with a benchmark dataset, to show promising results. The\ncode will be made publicly available at\nhttps://github.com/chaitnayabasava/DFW-PP.",
    "descriptor": "",
    "authors": [
      "Viswanatha Reddy G",
      "Chaitanya B S N V",
      "Prathyush P",
      "Sumanth M",
      "Mrinalini C",
      "Dileep Kumar P",
      "Snehasis Mukherjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.08510"
  },
  {
    "id": "arXiv:2110.08511",
    "title": "What can we learn from universal Turing machines?",
    "abstract": "In the present paper, we construct what we call a pedagogical universal\nTuring machine. We try to understand which comparisons with biological\nphenomena can be deduced from its encoding and from its working.",
    "descriptor": "\nComments: 35 pages, 5 tables\n",
    "authors": [
      "Maurice Margenstern"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08511"
  },
  {
    "id": "arXiv:2110.08512",
    "title": "AugmentedCode: Examining the Effects of Natural Language Resources in  Code Retrieval Models",
    "abstract": "Code retrieval is allowing software engineers to search codes through a\nnatural language query, which relies on both natural language processing and\nsoftware engineering techniques. There have been several attempts on code\nretrieval from searching snippet codes to function codes. In this paper, we\nintroduce Augmented Code (AugmentedCode) retrieval which takes advantage of\nexisting information within the code and constructs augmented programming\nlanguage to improve the code retrieval models' performance. We curated a large\ncorpus of Python and showcased the the framework and the results of augmented\nprogramming language which outperforms on CodeSearchNet and CodeBERT with a\nMean Reciprocal Rank (MRR) of 0.73 and 0.96, respectively. The outperformed\nfine-tuned augmented code retrieval model is published in HuggingFace at\nhttps://huggingface.co/Fujitsu/AugCode and a demonstration video is available\nat: https://youtu.be/mnZrUTANjGs .",
    "descriptor": "\nComments: 7 pages, 2 figures, 5 tables, 1 video\n",
    "authors": [
      "Mehdi Bahrami",
      "N.C. Shrikanth",
      "Yuji Mizobuchi",
      "Lei Liu",
      "Masahiro Fukuyori",
      "Wei-Peng Chen",
      "Kazuki Munakata"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08512"
  },
  {
    "id": "arXiv:2110.08513",
    "title": "Deep Reinforcement Learning for Practical Phase Shift Optimization in  RIS-aided MISO URLLC Systems",
    "abstract": "Reconfigurable intelligent surfaces (RISs) can assist the wireless systems in\nproviding reliable and low-latency links to realize the requirements in\nIndustry 4.0. In this paper, the practical phase shift optimization in a\nRIS-aided ultra-reliable and low-latency communication (URLLC) system at a\nfactory setting is performed by applying a novel deep reinforcement learning\n(DRL) algorithm named as twin-delayed deep deterministic policy gradient (TD3).\nFirst, the system achievable rate in finite blocklength (FBL) regime is\nidentified for each actuator then, the problem is formulated where the\nobjective is to maximize the total achievable FBL rate, subject to non-linear\namplitude response and the phase shift values constraint. Since the amplitude\nresponse equality constraint is highly non-convex and non-linear, we employ the\nTD3 to tackle the problem. The considered method relies on interacting RIS with\nindustrial scenario by taking actions which are the phase shifts at the RIS\nelements, to maximize the total FBL rate. We assess the performance loss of the\nsystem when the RIS is non-ideal, i.e., non-linear amplitude response\nwith/without phase quantization and compare it with ideal RIS. The numerical\nresults show that optimizing phase shifts in non-ideal RIS via the considered\nTD3 method is highly beneficial to improve the performance.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Ramin Hashemi",
      "Samad Ali",
      "Nurul Huda Mahmood",
      "Matti Latva-aho"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.08513"
  },
  {
    "id": "arXiv:2110.08514",
    "title": "Analyzing Dynamic Adversarial Training Data in the Limit",
    "abstract": "To create models that are robust across a wide range of test inputs, training\ndatasets should include diverse examples that span numerous phenomena. Dynamic\nadversarial data collection (DADC), where annotators craft examples that\nchallenge continually improving models, holds promise as an approach for\ngenerating such diverse training sets. Prior work has shown that running DADC\nover 1-3 rounds can help models fix some error types, but it does not\nnecessarily lead to better generalization beyond adversarial test data. We\nargue that running DADC over many rounds maximizes its training-time benefits,\nas the different rounds can together cover many of the task-relevant phenomena.\nWe present the first study of longer-term DADC, where we collect 20 rounds of\nNLI examples for a small set of premise paragraphs, with both adversarial and\nnon-adversarial approaches. Models trained on DADC examples make 26% fewer\nerrors on our expert-curated test set compared to models trained on\nnon-adversarial data. Our analysis shows that DADC yields examples that are\nmore difficult, more lexically and syntactically diverse, and contain fewer\nannotation artifacts compared to non-adversarial examples.",
    "descriptor": "",
    "authors": [
      "Eric Wallace",
      "Adina Williams",
      "Robin Jia",
      "Douwe Kiela"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08514"
  },
  {
    "id": "arXiv:2110.08515",
    "title": "Multimodal Dialogue Response Generation",
    "abstract": "Responsing with image has been recognized as an important capability for an\nintelligent conversational agent. Yet existing works only focus on exploring\nthe multimodal dialogue models which depend on retrieval-based methods, but\nneglecting generation methods. To fill in the gaps, we first present a\nmultimodal dialogue generation model, which takes the dialogue history as\ninput, then generates a textual sequence or an image as response. Learning such\na model often requires multimodal dialogues containing both texts and images\nwhich are difficult to obtain. Motivated by the challenge in practice, we\nconsider multimodal dialogue generation under a natural assumption that only\nlimited training examples are available. In such a low-resource setting, we\ndevise a novel conversational agent, Divter, in order to isolate parameters\nthat depend on multimodal dialogues from the entire generation model. By this\nmeans, the major part of the model can be learned from a large number of\ntext-only dialogues and text-image pairs respectively, then the whole\nparameters can be well fitted using the limited training examples. Extensive\nexperiments demonstrate our method achieves state-of-the-art results in both\nautomatic and human evaluation, and can generate informative text and\nhigh-resolution image responses.",
    "descriptor": "\nComments: This paper has been submitted before 15th October @ 11:59pm AOE(UTC -12)\n",
    "authors": [
      "Qingfeng Sun",
      "Yujing Wang",
      "Can Xu",
      "Kai Zheng",
      "Yaming Yang",
      "Huang Hu",
      "Fei Xu",
      "Jessica Zhang",
      "Xiubo Geng",
      "Daxin Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.08515"
  },
  {
    "id": "arXiv:2110.08517",
    "title": "Characterizing Improper Input Validation Vulnerabilities of Mobile  Crowdsourcing Services",
    "abstract": "Mobile crowdsourcing services (MCS), enable fast and economical data\nacquisition at scale and find applications in a variety of domains. Prior work\nhas shown that Foursquare and Waze (a location-based and a navigation MCS) are\nvulnerable to different kinds of data poisoning attacks. Such attacks can be\nupsetting and even dangerous especially when they are used to inject improper\ninputs to mislead users. However, to date, there is no comprehensive study on\nthe extent of improper input validation (IIV) vulnerabilities and the\nfeasibility of their exploits in MCSs across domains. In this work, we leverage\nthe fact that MCS interface with their participants through mobile apps to\ndesign tools and new methodologies embodied in an end-to-end feedback-driven\nanalysis framework which we use to study 10 popular and previously unexplored\nservices in five different domains. Using our framework we send tens of\nthousands of API requests with automatically generated input values to\ncharacterize their IIV attack surface. Alarmingly, we found that most of them\n(8/10) suffer from grave IIV vulnerabilities which allow an adversary to launch\ndata poisoning attacks at scale: 7400 spoofed API requests were successful in\nfaking online posts for robberies, gunshots, and other dangerous incidents,\nfaking fitness activities with supernatural speeds and distances among many\nothers. Lastly, we discuss easy to implement and deploy mitigation strategies\nwhich can greatly reduce the IIV attack surface and argue for their use as a\nnecessary complementary measure working toward trustworthy mobile crowdsourcing\nservices.",
    "descriptor": "",
    "authors": [
      "Sojhal Ismail Khan",
      "Dominika Woszczyk",
      "Chengzeng You",
      "Soteris Demetriou",
      "Muhammad Naveed"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.08517"
  },
  {
    "id": "arXiv:2110.08518",
    "title": "MarkupLM: Pre-training of Text and Markup Language for Visually-rich  Document Understanding",
    "abstract": "Multimodal pre-training with text, layout, and image has made significant\nprogress for Visually-rich Document Understanding (VrDU), especially the\nfixed-layout documents such as scanned document images. While, there are still\na large number of digital documents where the layout information is not fixed\nand needs to be interactively and dynamically rendered for visualization,\nmaking existing layout-based pre-training approaches not easy to apply. In this\npaper, we propose MarkupLM for document understanding tasks with markup\nlanguages as the backbone such as HTML/XML-based documents, where text and\nmarkup information is jointly pre-trained. Experiment results show that the\npre-trained MarkupLM significantly outperforms the existing strong baseline\nmodels on several document understanding tasks. The pre-trained model and code\nwill be publicly available at https://aka.ms/markuplm.",
    "descriptor": "\nComments: Work in Progress\n",
    "authors": [
      "Junlong Li",
      "Yiheng Xu",
      "Lei Cui",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08518"
  },
  {
    "id": "arXiv:2110.08520",
    "title": "A Dataset for Discourse Structure in Peer Review Discussions",
    "abstract": "At the foundation of scientific evaluation is the labor-intensive process of\npeer review. This critical task requires participants to consume and interpret\nvast amounts of highly technical text. We show that discourse cues from\nrebuttals can shed light on the quality and interpretation of reviews. Further,\nan understanding of the argumentative strategies employed by the reviewers and\nauthors provides useful signal for area chairs and other decision makers.\nThis paper presents a new labeled dataset of 20k sentences contained in 506\nreview-rebuttal pairs in English, annotated by experts. While existing datasets\nannotate a subset of review sentences using various schemes, ours synthesizes\nexisting label sets and extends them to include fine-grained annotation of the\nrebuttal sentences, characterizing the authors' stance towards the reviewers'\ncriticisms and their commitment to addressing them. Further, we annotate\n\\textit{every} sentence in both the review and the rebuttal, including a\ndescription of the context for each rebuttal sentence.",
    "descriptor": "",
    "authors": [
      "Neha Nayak Kennard",
      "Tim O'Gorman",
      "Akshay Sharma",
      "Chhandak Bagchi",
      "Matthew Clinton",
      "Pranay Kumar Yelugam",
      "Rajarshi Das",
      "Hamed Zamani",
      "Andrew McCallum"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08520"
  },
  {
    "id": "arXiv:2110.08525",
    "title": "The Power of Prompt Tuning for Low-Resource Semantic Parsing",
    "abstract": "Prompt tuning has recently emerged as an effective method for adapting\npre-trained language models to a number of language tasks. In this paper, we\ninvestigate prompt tuning for semantic parsing, the task of mapping natural\nlanguage utterances onto formal meaning representations. For large T5 models we\nfind (i) that prompt tuning significantly outperforms fine-tuning in the low\ndata regime and (ii) that canonicalization -- i.e. naturalizing the meaning\nrepresentations -- barely improves performance. This last result is surprising\nas it suggests that large T5 models can be modulated to generate sequences that\nare far from the pre-training distribution.",
    "descriptor": "",
    "authors": [
      "Nathan Schucher",
      "Siva Reddy",
      "Harm de Vries"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08525"
  },
  {
    "id": "arXiv:2110.08527",
    "title": "An Empirical Survey of the Effectiveness of Debiasing Techniques for  Pre-Trained Language Models",
    "abstract": "Recent work has shown that pre-trained language models capture social biases\nfrom the text corpora they are trained on. This has attracted attention to\ndeveloping techniques that mitigate such biases. In this work, we perform a\nempirical survey of five recently proposed debiasing techniques: Counterfactual\nData Augmentation (CDA), Dropout, Iterative Nullspace Projection, Self-Debias,\nand SentenceDebias. We quantify the effectiveness of each technique using three\ndifferent bias benchmarks while also measuring the impact of these techniques\non a model's language modeling ability, as well as its performance on\ndownstream NLU tasks. We experimentally find that: (1) CDA and Self-Debias are\nthe strongest of the debiasing techniques, obtaining improved scores on most of\nthe bias benchmarks (2) Current debiasing techniques do not generalize well\nbeyond gender bias; And (3) improvements on bias benchmarks such as StereoSet\nand CrowS-Pairs by using debiasing strategies are usually accompanied by a\ndecrease in language modeling ability, making it difficult to determine whether\nthe bias mitigation is effective.",
    "descriptor": "",
    "authors": [
      "Nicholas Meade",
      "Elinor Poole-Dayan",
      "Siva Reddy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08527"
  },
  {
    "id": "arXiv:2110.08529",
    "title": "Sharpness-Aware Minimization Improves Language Model Generalization",
    "abstract": "The allure of superhuman-level capabilities has led to considerable interest\nin language models like GPT-3 and T5, wherein the research has, by and large,\nrevolved around new model architectures, training tasks, and loss objectives,\nalong with substantial engineering efforts to scale up model capacity and\ndataset size. Comparatively little work has been done to improve the\ngeneralization of these models through better optimization. In this work, we\nshow that Sharpness-Aware Minimization (SAM), a recently proposed optimization\nprocedure that encourages convergence to flatter minima, can substantially\nimprove the generalization of language models without much computational\noverhead. We show that SAM is able to boost performance on SuperGLUE, GLUE, Web\nQuestions, Natural Questions, Trivia QA, and TyDiQA, with particularly large\ngains when training data for these tasks is limited.",
    "descriptor": "",
    "authors": [
      "Dara Bahri",
      "Hossein Mobahi",
      "Yi Tay"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08529"
  },
  {
    "id": "arXiv:2110.08532",
    "title": "Pro-KD: Progressive Distillation by Following the Footsteps of the  Teacher",
    "abstract": "With ever growing scale of neural models, knowledge distillation (KD)\nattracts more attention as a prominent tool for neural model compression.\nHowever, there are counter intuitive observations in the literature showing\nsome challenging limitations of KD. A case in point is that the best performing\ncheckpoint of the teacher might not necessarily be the best teacher for\ntraining the student in KD. Therefore, one important question would be how to\nfind the best checkpoint of the teacher for distillation? Searching through the\ncheckpoints of the teacher would be a very tedious and computationally\nexpensive process, which we refer to as the \\textit{checkpoint-search problem}.\nMoreover, another observation is that larger teachers might not necessarily be\nbetter teachers in KD which is referred to as the \\textit{capacity-gap}\nproblem. To address these challenging problems, in this work, we introduce our\nprogressive knowledge distillation (Pro-KD) technique which defines a smoother\ntraining path for the student by following the training footprints of the\nteacher instead of solely relying on distilling from a single mature\nfully-trained teacher. We demonstrate that our technique is quite effective in\nmitigating the capacity-gap problem and the checkpoint search problem. We\nevaluate our technique using a comprehensive set of experiments on different\ntasks such as image classification (CIFAR-10 and CIFAR-100), natural language\nunderstanding tasks of the GLUE benchmark, and question answering (SQuAD 1.1\nand 2.0) using BERT-based models and consistently got superior results over\nstate-of-the-art techniques.",
    "descriptor": "",
    "authors": [
      "Mehdi Rezagholizadeh",
      "Aref Jafari",
      "Puneeth Salad",
      "Pranav Sharma",
      "Ali Saheb Pasand",
      "Ali Ghodsi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08532"
  },
  {
    "id": "arXiv:2110.08534",
    "title": "Lifelong Pretraining: Continually Adapting Language Models to Emerging  Corpora",
    "abstract": "Pretrained language models (PTLMs) are typically learned over a large, static\ncorpus and further fine-tuned for various downstream tasks. However, when\ndeployed in the real world, a PTLM-based model must deal with data from a new\ndomain that deviates from what the PTLM was initially trained on, or newly\nemerged data that contains out-of-distribution information. In this paper, we\nstudy a lifelong language model pretraining challenge where a PTLM is\ncontinually updated so as to adapt to emerging data. Over a domain-incremental\nresearch paper stream and a chronologically ordered tweet stream, we\nincrementally pretrain a PTLM with different continual learning algorithms, and\nkeep track of the downstream task performance (after fine-tuning) to analyze\nits ability of acquiring new knowledge and preserving learned knowledge. Our\nexperiments show continual learning algorithms improve knowledge preservation,\nwith logit distillation being the most effective approach. We further show that\ncontinual pretraining improves generalization when training and testing data of\ndownstream tasks are drawn from different time steps, but do not improve when\nthey are from the same time steps. We believe our problem formulation, methods,\nand analysis will inspire future studies towards continual pretraining of\nlanguage models.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Xisen Jin",
      "Dejiao Zhang",
      "Henghui Zhu",
      "Wei Xiao",
      "Shang-Wen Li",
      "Xiaokai Wei",
      "Andrew Arnold",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08534"
  },
  {
    "id": "arXiv:2110.08536",
    "title": "Sparse Distillation: Speeding Up Text Classification by Using Bigger  Models",
    "abstract": "Distilling state-of-the-art transformer models into lightweight student\nmodels is an effective way to reduce computation cost at inference time.\nHowever, the improved inference speed may be still unsatisfactory for certain\ntime-sensitive applications. In this paper, we aim to further push the limit of\ninference speed by exploring a new area in the design space of the student\nmodel. More specifically, we consider distilling a transformer-based text\nclassifier into a billion-parameter, sparsely-activated student model with a\nembedding-averaging architecture. Our experiments show that the student models\nretain 97% of the RoBERTa-Large teacher performance on a collection of six text\nclassification tasks. Meanwhile, the student model achieves up to 600x speed-up\non both GPUs and CPUs, compared to the teacher models. Further investigation\nshows that our pipeline is also effective in privacy-preserving and domain\ngeneralization settings.",
    "descriptor": "",
    "authors": [
      "Qinyuan Ye",
      "Madian Khabsa",
      "Mike Lewis",
      "Sinong Wang",
      "Xiang Ren",
      "Aaron Jaech"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08536"
  },
  {
    "id": "arXiv:2110.08537",
    "title": "Verification of MPI programs",
    "abstract": "In this paper, we outline an approach to verifying parallel programs. A new\nmathematical model of parallel programs is introduced. The introduced model is\nillustrated by the verification of the matrix multiplication MPI program.",
    "descriptor": "",
    "authors": [
      "Andrew M. Mironov"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2110.08537"
  },
  {
    "id": "arXiv:2110.08538",
    "title": "Substructure Distribution Projection for Zero-Shot Cross-Lingual  Dependency Parsing",
    "abstract": "We present substructure distribution projection (SubDP), a technique that\nprojects a distribution over structures in one domain to another, by projecting\nsubstructure distributions separately. Models for the target domains can be\nthen trained, using the projected distributions as soft silver labels. We\nevaluate SubDP on zero-shot cross-lingual dependency parsing, taking dependency\narcs as substructures: we project the predicted dependency arc distributions in\nthe source language(s) to target language(s), and train a target language\nparser to fit the resulting distributions. When an English treebank is the only\nannotation that involves human effort, SubDP achieves better unlabeled\nattachment score than all prior work on the Universal Dependencies v2.2 (Nivre\net al., 2020) test set across eight diverse target languages, as well as the\nbest labeled attachment score on six out of eight languages. In addition, SubDP\nimproves zero-shot cross-lingual dependency parsing with very few (e.g., 50)\nsupervised bitext pairs, across a broader range of target languages.",
    "descriptor": "",
    "authors": [
      "Haoyue Shi",
      "Kevin Gimpel",
      "Karen Livescu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08538"
  },
  {
    "id": "arXiv:2110.08542",
    "title": "Learning to Solve Complex Tasks by Talking to Agents",
    "abstract": "Humans often solve complex problems by interacting (in natural language) with\nexisting agents, such as AI assistants, that can solve simpler sub-tasks. These\nagents themselves can be powerful systems built using extensive resources and\nprivately held data. In contrast, common NLP benchmarks aim for the development\nof self-sufficient models for every task. To address this gap and facilitate\nresearch towards ``green'' AI systems that build upon existing agents, we\npropose a new benchmark called CommaQA that contains three kinds of complex\nreasoning tasks that are designed to be solved by ``talking'' to four agents\nwith different capabilities. We demonstrate that state-of-the-art black-box\nmodels, which are unable to leverage existing agents, struggle on CommaQA\n(exact match score only reaches 40pts) even when given access to the agents'\ninternal knowledge and gold fact supervision. On the other hand, models using\ngold question decomposition supervision can indeed solve CommaQA to a high\naccuracy (over 96\\% exact match) by learning to utilize the agents. Even these\nadditional supervision models, however, do not solve our compositional\ngeneralization test set. Finally the end-goal of learning to solve complex\ntasks by communicating with existing agents \\emph{without relying on any\nadditional supervision} remains unsolved and we hope CommaQA serves as a novel\nbenchmark to enable the development of such systems.",
    "descriptor": "",
    "authors": [
      "Tushar Khot",
      "Kyle Richardson",
      "Daniel Khashabi",
      "Ashish Sabharwal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08542"
  },
  {
    "id": "arXiv:2110.08544",
    "title": "Tackling Multi-Answer Open-Domain Questions via a Recall-then-Verify  Framework",
    "abstract": "Open domain questions are likely to be open-ended and ambiguous, leading to\nmultiple valid answers. Existing approaches typically adopt the\nrerank-then-read framework, where a reader reads top-ranking evidence to\npredict answers. According to our empirical analyses, this framework is faced\nwith three problems: to leverage the power of a large reader, the reranker is\nforced to select only a few relevant passages that cover diverse answers, which\nis non-trivial due to unknown effect on the reader's performance; the small\nreading budget also prevents the reader from making use of valuable retrieved\nevidence filtered out by the reranker; besides, as the reader generates\npredictions all at once based on all selected evidence, it may learn\npathological dependencies among answers, i.e., whether to predict an answer may\nalso depend on evidence of the other answers. To avoid these problems, we\npropose to tackle multi-answer open-domain questions with a recall-then-verify\nframework, which separates the reasoning process of each answer so that we can\nmake better use of retrieved evidence while also leveraging the power of large\nmodels under the same memory constraint. Our framework achieves new\nstate-of-the-art results on two multi-answer datasets, and predicts\nsignificantly more gold answers than a rerank-then-read system with an oracle\nreranker.",
    "descriptor": "",
    "authors": [
      "Zhihong Shao",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08544"
  },
  {
    "id": "arXiv:2110.08547",
    "title": "Towards Making the Most of Multilingual Pretraining for Zero-Shot Neural  Machine Translation",
    "abstract": "This paper demonstrates that multilingual pretraining, a proper fine-tuning\nmethod and a large-scale parallel dataset from multiple auxiliary languages are\nall critical for zero-shot translation, where the NMT model is tested on source\nlanguages unseen during supervised training. Following this idea, we present\nSixT++, a strong many-to-English NMT model that supports 100 source languages\nbut is trained once with a parallel dataset from only six source languages.\nSixT++ initializes the decoder embedding and the full encoder with XLM-R large,\nand then trains the encoder and decoder layers with a simple two-stage training\nstrategy. SixT++ achieves impressive performance on many-to-English\ntranslation. It significantly outperforms CRISS and m2m-100, two strong\nmultilingual NMT systems, with an average gain of 7.2 and 5.0 BLEU\nrespectively. Additionally, SixT++ offers a set of model parameters that can be\nfurther fine-tuned to develop unsupervised NMT models for low-resource\nlanguages. With back-translation on monolingual data of low-resource language,\nit outperforms all current state-of-the-art unsupervised methods on Nepali and\nSinhal for both translating into and from English.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Guanhua Chen",
      "Shuming Ma",
      "Yun Chen",
      "Dongdong Zhang",
      "Jia Pan",
      "Wenping Wang",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08547"
  },
  {
    "id": "arXiv:2110.08551",
    "title": "HRKD: Hierarchical Relational Knowledge Distillation for Cross-domain  Language Model Compression",
    "abstract": "On many natural language processing tasks, large pre-trained language models\n(PLMs) have shown overwhelming performances compared with traditional neural\nnetwork methods. Nevertheless, their huge model size and low inference speed\nhave hindered the deployment on resource-limited devices in practice. In this\npaper, we target to compress PLMs with knowledge distillation, and propose a\nhierarchical relational knowledge distillation (HRKD) method to capture both\nhierarchical and domain relational information. Specifically, to enhance the\nmodel capability and transferability, we leverage the idea of meta-learning and\nset up domain-relational graphs to capture the relational information across\ndifferent domains. And to dynamically select the most representative prototypes\nfor each domain, we propose a hierarchical compare-aggregate mechanism to\ncapture hierarchical relationships. Extensive experiments on public\nmulti-domain datasets demonstrate the superior performance of our HRKD method\nas well as its strong few-shot learning ability. For reproducibility, we\nrelease the code at https://github.com/cheneydon/hrkd.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Chenhe Dong",
      "Yaliang Li",
      "Ying Shen",
      "Minghui Qiu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08551"
  },
  {
    "id": "arXiv:2110.08552",
    "title": "Virtual Augmentation Supported Contrastive Learning of Sentence  Representations",
    "abstract": "Despite profound successes, contrastive representation learning relies on\ncarefully designed data augmentations using domain specific knowledge. This\nchallenge is magnified in natural language processing where no general rules\nexist for data augmentation due to the discrete nature of natural language. We\ntackle this challenge by presenting a Virtual augmentation Supported\nContrastive Learning of sentence representations (VaSCL). Originating from the\ninterpretation that data augmentation essentially constructs the neighborhoods\nof each training instance, we in turn utilize the neighborhood to generate\neffective data augmentations. Leveraging the large training batch size of\ncontrastive learning, we approximate the neighborhood of an instance via its\nK-nearest in-batch neighbors in the representation space. We then define an\ninstance discrimination task within this neighborhood, and generate the virtual\naugmentation in an adversarial training manner. We access the performance of\nVaSCL on a wide range of downstream tasks, and set a new state-of-the-art for\nunsupervised sentence representation learning.",
    "descriptor": "\nComments: 8 pages, 3 figures, 3 tables\n",
    "authors": [
      "Dejiao Zhang",
      "Wei Xiao",
      "Henghui Zhu",
      "Xiaofei Ma",
      "Andrew O. Arnold"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08552"
  },
  {
    "id": "arXiv:2110.08554",
    "title": "PAGnol: An Extra-Large French Generative Model",
    "abstract": "Access to large pre-trained models of varied architectures, in many different\nlanguages, is central to the democratization of NLP. We introduce PAGnol, a\ncollection of French GPT models. Using scaling laws, we efficiently train\nPAGnol-XL (1.5B parameters) with the same computational budget as CamemBERT, a\nmodel 13 times smaller. PAGnol-XL is the largest model trained to date for the\nFrench language. We plan to train increasingly large and performing versions of\nPAGnol, exploring the capabilities of French extreme-scale models.\nFor this first release, we focus on the pre-training and scaling calculations\nunderlining PAGnol. We fit a scaling law for compute for the French language,\nand compare it with its English counterpart. We find the pre-training dataset\nsignificantly conditions the quality of the outputs, with common datasets such\nas OSCAR leading to low-quality offensive text. We evaluate our models on\ndiscriminative and generative tasks in French, comparing to other\nstate-of-the-art French and multilingual models, and reaching the state of the\nart in the abstract summarization task. Our research was conducted on the\npublic GENCI Jean Zay supercomputer, and our models up to the Large are made\npublicly available.",
    "descriptor": "",
    "authors": [
      "Julien Launay",
      "E.L. Tommasone",
      "Baptiste Pannier",
      "Fran\u00e7ois Boniface",
      "Am\u00e9lie Chatelain",
      "Alessandro Cappelli",
      "Iacopo Poli",
      "Djam\u00e9 Seddah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08554"
  },
  {
    "id": "arXiv:2110.08555",
    "title": "On the Robustness of Reading Comprehension Models to Entity Renaming",
    "abstract": "We study the robustness of machine reading comprehension (MRC) models to\nentity renaming -- do models make more wrong predictions when answer entities\nhave different names? Such failures would indicate that models are overly\nreliant on entity knowledge to answer questions, and therefore may generalize\npoorly when facts about the world change or questions are asked about novel\nentities. To systematically audit model robustness, we propose a general and\nscalable method to replace person names with names from a variety of sources,\nranging from common English names to names from other languages to arbitrary\nstrings. Across four datasets and three pretrained model architectures, MRC\nmodels consistently perform worse when entities are renamed, with particularly\nlarge accuracy drops on datasets constructed via distant supervision. We also\nfind large differences between models: SpanBERT, which is pretrained with\nspan-level masking, is more robust than RoBERTa, despite having similar\naccuracy on unperturbed test data. Inspired by this, we experiment with\nspan-level and entity-level masking as a continual pretraining objective and\nfind that they can further improve the robustness of MRC models.",
    "descriptor": "",
    "authors": [
      "Jun Yan",
      "Yang Xiao",
      "Sagnik Mukherjee",
      "Bill Yuchen Lin",
      "Robin Jia",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08555"
  },
  {
    "id": "arXiv:2110.08556",
    "title": "Multi-View Stereo Network with attention thin volume",
    "abstract": "We propose an efficient multi-view stereo (MVS) network for infering depth\nvalue from multiple RGB images. Recent studies have shown that mapping the\ngeometric relationship in real space to neural network is an essential topic of\nthe MVS problem. Specifically, these methods focus on how to express the\ncorrespondence between different views by constructing a nice cost volume. In\nthis paper, we propose a more complete cost volume construction approach based\non absorbing previous experience. First of all, we introduce the self-attention\nmechanism to fully aggregate the dominant information from input images and\naccurately model the long-range dependency, so as to selectively aggregate\nreference features. Secondly, we introduce the group-wise correlation to\nfeature aggregation, which greatly reduces the memory and calculation burden.\nMeanwhile, this method enhances the information interaction between different\nfeature channels. With this approach, a more lightweight and efficient cost\nvolume is constructed. Finally we follow the coarse to fine strategy and refine\nthe depth sampling range scale by scale with the help of uncertainty\nestimation. We further combine the previous steps to get the attention thin\nvolume. Quantitative and qualitative experiments are presented to demonstrate\nthe performance of our model.",
    "descriptor": "",
    "authors": [
      "Zihang Wan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08556"
  },
  {
    "id": "arXiv:2110.08557",
    "title": "DPNAS: Neural Architecture Search for Deep Learningwith Differential  Privacy",
    "abstract": "Training deep neural networks (DNNs) for meaningful differential privacy (DP)\nguarantees severely degrades model utility. In this paper, we demonstrate that\nthe architecture of DNNs has a significant impact on model utility in the\ncontext of private deep learning, whereas its effect is largely unexplored in\nprevious studies. In light of this missing, we propose the very first framework\nthat employs neural architecture search to automatic model design for private\ndeep learning, dubbed as DPNAS. To integrate private learning with architecture\nsearch, we delicately design a novel search space and propose a DP-aware method\nfor training candidate models. We empirically certify the effectiveness of the\nproposed framework. The searched model DPNASNet achieves state-of-the-art\nprivacy/utility trade-offs, e.g., for the privacy budget of $(\\epsilon,\n\\delta)=(3, 1\\times10^{-5})$, our model obtains test accuracy of $98.57\\%$ on\nMNIST, $88.09\\%$ on FashionMNIST, and $68.33\\%$ on CIFAR-10. Furthermore, by\nstudying the generated architectures, we provide several intriguing findings of\ndesigning private-learning-friendly DNNs, which can shed new light on model\ndesign for deep learning with differential privacy.",
    "descriptor": "",
    "authors": [
      "Anda Cheng",
      "Jiaxing Wang",
      "Xi Sheryl Zhang",
      "Qiang Chen",
      "Peisong Wang",
      "Jian Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.08557"
  },
  {
    "id": "arXiv:2110.08558",
    "title": "Neural Network Pruning Through Constrained Reinforcement Learning",
    "abstract": "Network pruning reduces the size of neural networks by removing (pruning)\nneurons such that the performance drop is minimal. Traditional pruning\napproaches focus on designing metrics to quantify the usefulness of a neuron\nwhich is often quite tedious and sub-optimal. More recent approaches have\ninstead focused on training auxiliary networks to automatically learn how\nuseful each neuron is however, they often do not take computational limitations\ninto account. In this work, we propose a general methodology for pruning neural\nnetworks. Our proposed methodology can prune neural networks to respect\npre-defined computational budgets on arbitrary, possibly non-differentiable,\nfunctions. Furthermore, we only assume the ability to be able to evaluate these\nfunctions for different inputs, and hence they do not need to be fully\nspecified beforehand. We achieve this by proposing a novel pruning strategy via\nconstrained reinforcement learning algorithms. We prove the effectiveness of\nour approach via comparison with state-of-the-art methods on standard image\nclassification datasets. Specifically, we reduce 83-92.90 of total parameters\non various variants of VGG while achieving comparable or better performance\nthan that of original networks. We also achieved 75.09 reduction in parameters\non ResNet18 without incurring any loss in accuracy.",
    "descriptor": "\nComments: Submitted to ICASSP 2021\n",
    "authors": [
      "Shehryar Malik",
      "Muhammad Umair Haider",
      "Omer Iqbal",
      "Murtaza Taj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08558"
  },
  {
    "id": "arXiv:2110.08559",
    "title": "FrugalScore: Learning Cheaper, Lighter and Faster Evaluation Metricsfor  Automatic Text Generation",
    "abstract": "Fast and reliable evaluation metrics are key to R&D progress. While\ntraditional natural language generation metrics are fast, they are not very\nreliable. Conversely, new metrics based on large pretrained language models are\nmuch more reliable, but require significant computational resources. In this\npaper, we propose FrugalScore, an approach to learn a fixed, low cost version\nof any expensive NLG metric, while retaining most of its original performance.\nExperiments with BERTScore and MoverScore on summarization and translation show\nthat FrugalScore is on par with the original metrics (and sometimes better),\nwhile having several orders of magnitude less parameters and running several\ntimes faster. On average over all learned metrics, tasks, and variants,\nFrugalScore retains 96.8% of the performance, runs 24 times faster, and has 35\ntimes less parameters than the original metrics. We make our trained metrics\npublicly available, to benefit the entire NLP community and in particular\nresearchers and practitioners with limited resources.",
    "descriptor": "",
    "authors": [
      "Moussa Kamal Eddine",
      "Guokan Shang",
      "Antoine J.-P. Tixier",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08559"
  },
  {
    "id": "arXiv:2110.08561",
    "title": "Sahlqvist Correspondence Theory for Second-Order Propositional Modal  Logic",
    "abstract": "Modal logic with propositional quantifiers (i.e. second-order propositional\nmodal logic (SOPML)) has been considered since the early time of modal logic.\nIts expressive power and complexity are high, and its van-Benthem-Rosen theorem\nand Goldblatt-Thomason theorem have been proved by ten Cate (2006). However,\nthe Sahlqvist theory of SOPML has not been considered in the literature. In the\npresent paper, we fill in this gap. We develop the Sahlqvist correspondence\ntheory for SOPML, which covers and properly extends existing Sahlqvist formulas\nin basic modal logic. We define the class of Sahlqvist formulas for SOMPL step\nby step in a hierarchical way, each formula of which is shown to have a\nfirst-order correspondent over Kripke frames effectively computable by an\nalgorithm $ALBA^{SOMPL}$. In addition, we show that certain $\\Pi_2$-rules\ncorrespond to $\\Pi_2$-Sahlqvist formulas in SOMPL, which further correspond to\nfirst-order conditions, and that even for very simple SOMPL Sahlqvist formulas,\nthey could already be non-canonical.",
    "descriptor": "",
    "authors": [
      "Zhiguang Zhao"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.08561"
  },
  {
    "id": "arXiv:2110.08562",
    "title": "BNAS v2: Learning Architectures for Binary Networks with Empirical  Improvements",
    "abstract": "Backbone architectures of most binary networks are well-known floating point\n(FP) architectures such as the ResNet family. Questioning that the\narchitectures designed for FP networks might not be the best for binary\nnetworks, we propose to search architectures for binary networks (BNAS) by\ndefining a new search space for binary architectures and a novel search\nobjective. Specifically, based on the cell based search method, we define the\nnew search space of binary layer types, design a new cell template, and\nrediscover the utility of and propose to use the Zeroise layer instead of using\nit as a placeholder. The novel search objective diversifies early search to\nlearn better performing binary architectures. We show that our method searches\narchitectures with stable training curves despite the quantization error\ninherent in binary networks. Quantitative analyses demonstrate that our\nsearched architectures outperform the architectures used in state-of-the-art\nbinary networks and outperform or perform on par with state-of-the-art binary\nnetworks that employ various techniques other than architectural changes. In\naddition, we further propose improvements to the training scheme of our\nsearched architectures. With the new training scheme for our searched\narchitectures, we achieve the state-of-the-art performance by binary networks\nby outperforming all previous methods by non-trivial margins.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2002.06963\n",
    "authors": [
      "Dahyun Kim",
      "Kunal Pratap Singh",
      "Jonghyun Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08562"
  },
  {
    "id": "arXiv:2110.08565",
    "title": "Dynamic Graph Echo State Networks",
    "abstract": "Dynamic temporal graphs represent evolving relations between entities, e.g.\ninteractions between social network users or infection spreading. We propose an\nextension of graph echo state networks for the efficient processing of dynamic\ntemporal graphs, with a sufficient condition for their echo state property, and\nan experimental analysis of reservoir layout impact. Compared to temporal graph\nkernels that need to hold the entire history of vertex interactions, our model\nprovides a vector encoding for the dynamic graph that is updated at each\ntime-step without requiring training. Experiments show accuracy comparable to\napproximate temporal graph kernels on twelve dissemination process\nclassification tasks.",
    "descriptor": "\nComments: Accepted for oral presentation at ESANN 2021\n",
    "authors": [
      "Domenico Tortorella",
      "Alessio Micheli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.08565"
  },
  {
    "id": "arXiv:2110.08567",
    "title": "Directional forces in the evolution of grammar",
    "abstract": "Languages have diverse characteristics that have emerged through evolution.\nIn modern English grammar, the perfect is formed with have+PP (past\nparticiple), but in older English the be+PP form existed as well. It is widely\nrecognised that the auxiliary verb BE was replaced by HAVE throughout\nevolution, except in several exceptional cases. However, prior studies have not\nclarified the evolutionary factors behind this phenomenon. In this study, we\ncombined three large-scale corpora of English (Early English Books Online,\nCorpora of Historical American English, and Google Books) and analysed them to\nilluminate the factors that drove the evolution of the perfect in English. Our\nresults provide important insights into the evolution of grammar. We found that\nmost intransitive verbs exhibited an increase in the frequency of have+PP, some\nof which passed the Frequency Increment Test (FIT), indicating a rapid S-shape\nincrease. This finding strongly suggests that the perfect could have evolved\nthrough natural selection rather than random drift.",
    "descriptor": "\nComments: 12 pages, 3 figures, 3 tables, with SM\n",
    "authors": [
      "Shimpei Okuda",
      "Michio Hosaka",
      "Kazutoshi Sasahara"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.08567"
  },
  {
    "id": "arXiv:2110.08568",
    "title": "ASFormer: Transformer for Action Segmentation",
    "abstract": "Algorithms for the action segmentation task typically use temporal models to\npredict what action is occurring at each frame for a minute-long daily\nactivity. Recent studies have shown the potential of Transformer in modeling\nthe relations among elements in sequential data. However, there are several\nmajor concerns when directly applying the Transformer to the action\nsegmentation task, such as the lack of inductive biases with small training\nsets, the deficit in processing long input sequence, and the limitation of the\ndecoder architecture to utilize temporal relations among multiple action\nsegments to refine the initial predictions. To address these concerns, we\ndesign an efficient Transformer-based model for action segmentation task, named\nASFormer, with three distinctive characteristics: (i) We explicitly bring in\nthe local connectivity inductive priors because of the high locality of\nfeatures. It constrains the hypothesis space within a reliable scope, and is\nbeneficial for the action segmentation task to learn a proper target function\nwith small training sets. (ii) We apply a pre-defined hierarchical\nrepresentation pattern that efficiently handles long input sequences. (iii) We\ncarefully design the decoder to refine the initial predictions from the\nencoder. Extensive experiments on three public datasets demonstrate that\neffectiveness of our methods. Code is available at\n\\url{https://github.com/ChinaYi/ASFormer}.",
    "descriptor": "\nComments: Accepted by BMVC 2021\n",
    "authors": [
      "Fangqiu Yi",
      "Hongyu Wen",
      "Tingting Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08568"
  },
  {
    "id": "arXiv:2110.08571",
    "title": "Explore before Moving: A Feasible Path Estimation and Memory Recalling  Framework for Embodied Navigation",
    "abstract": "An embodied task such as embodied question answering (EmbodiedQA), requires\nan agent to explore the environment and collect clues to answer a given\nquestion that related with specific objects in the scene. The solution of such\ntask usually includes two stages, a navigator and a visual Q&A module. In this\npaper, we focus on the navigation and solve the problem of existing navigation\nalgorithms lacking experience and common sense, which essentially results in a\nfailure finding target when robot is spawn in unknown environments.\nInspired by the human ability to think twice before moving and conceive\nseveral feasible paths to seek a goal in unfamiliar scenes, we present a route\nplanning method named Path Estimation and Memory Recalling (PEMR) framework.\nPEMR includes a \"looking ahead\" process, \\textit{i.e.} a visual feature\nextractor module that estimates feasible paths for gathering 3D navigational\ninformation, which is mimicking the human sense of direction. PEMR contains\nanother process ``looking behind'' process that is a memory recall mechanism\naims at fully leveraging past experience collected by the feature extractor.\nLast but not the least, to encourage the navigator to learn more accurate prior\nexpert experience, we improve the original benchmark dataset and provide a\nfamily of evaluation metrics for diagnosing both navigation and question\nanswering modules. We show strong experimental results of PEMR on the\nEmbodiedQA navigation task.",
    "descriptor": "",
    "authors": [
      "Yang Wu",
      "Shirui Feng",
      "Guanbin Li",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08571"
  },
  {
    "id": "arXiv:2110.08572",
    "title": "Greedy and Random Broyden's Methods with Explicit Superlinear  Convergence Rates in Nonlinear Equations",
    "abstract": "In this paper, we propose the greedy and random Broyden's method for solving\nnonlinear equations. Specifically, the greedy method greedily selects the\ndirection to maximize a certain measure of progress for approximating the\ncurrent Jacobian matrix, while the random method randomly chooses a direction.\nWe establish explicit (local) superlinear convergence rates of both methods if\nthe initial point and approximate Jacobian are close enough to a solution and\ncorresponding Jacobian. Our two novel variants of Broyden's method enjoy two\nimportant advantages that the approximate Jacobians of our algorithms will\nconverge to the exact ones and the convergence rates of our algorithms are\nasymptotically faster than the original Broyden's method. Our work is the first\ntime to achieve such two advantages theoretically. Our experiments also\nempirically validate the advantages of our algorithms.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2109.01974\n",
    "authors": [
      "Haishan Ye",
      "Dachao Lin",
      "Zhihua Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.08572"
  },
  {
    "id": "arXiv:2110.08578",
    "title": "Visual-aware Attention Dual-stream Decoder for Video Captioning",
    "abstract": "Video captioning is a challenging task that captures different visual parts\nand describes them in sentences, for it requires visual and linguistic\ncoherence. The attention mechanism in the current video captioning method\nlearns to assign weight to each frame, promoting the decoder dynamically. This\nmay not explicitly model the correlation and the temporal coherence of the\nvisual features extracted in the sequence frames.To generate semantically\ncoherent sentences, we propose a new Visual-aware Attention (VA) model, which\nconcatenates dynamic changes of temporal sequence frames with the words at the\nprevious moment, as the input of attention mechanism to extract sequence\nfeatures.In addition, the prevalent approaches widely use the teacher-forcing\n(TF) learning during training, where the next token is generated conditioned on\nthe previous ground-truth tokens. The semantic information in the previously\ngenerated tokens is lost. Therefore, we design a self-forcing (SF) stream that\ntakes the semantic information in the probability distribution of the previous\ntoken as input to enhance the current token.The Dual-stream Decoder (DD)\narchitecture unifies the TF and SF streams, generating sentences to promote the\nannotated captioning for both streams.Meanwhile, with the Dual-stream Decoder\nutilized, the exposure bias problem is alleviated, caused by the discrepancy\nbetween the training and testing in the TF learning.The effectiveness of the\nproposed Visual-aware Attention Dual-stream Decoder (VADD) is demonstrated\nthrough the result of experimental studies on Microsoft video description\n(MSVD) corpus and MSR-Video to text (MSR-VTT) datasets.",
    "descriptor": "",
    "authors": [
      "Zhixin Sun",
      "Xian Zhong",
      "Shuqin Chen",
      "Lin Li",
      "Luo Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08578"
  },
  {
    "id": "arXiv:2110.08580",
    "title": "Intelligent Video Editing: Incorporating Modern Talking Face Generation  Algorithms in a Video Editor",
    "abstract": "This paper proposes a video editor based on OpenShot with several\nstate-of-the-art facial video editing algorithms as added functionalities. Our\neditor provides an easy-to-use interface to apply modern lip-syncing algorithms\ninteractively. Apart from lip-syncing, the editor also uses audio and facial\nre-enactment to generate expressive talking faces. The manual control improves\nthe overall experience of video editing without missing out on the benefits of\nmodern synthetic video generation algorithms. This control enables us to\nlip-sync complex dubbed movie scenes, interviews, television shows, and other\nvisual content. Furthermore, our editor provides features that automatically\ntranslate lectures from spoken content, lip-sync of the professor, and\nbackground content like slides. While doing so, we also tackle the critical\naspect of synchronizing background content with the translated speech. We\nqualitatively evaluate the usefulness of the proposed editor by conducting\nhuman evaluations. Our evaluations show a clear improvement in the efficiency\nof using human editors and an improved video generation quality. We attach demo\nvideos with the supplementary material clearly explaining the tool and also\nshowcasing multiple results.",
    "descriptor": "\nComments: 9 pages, 7 figures, accepted in ICVGIP 2021\n",
    "authors": [
      "Anchit Gupta",
      "Faizan Farooq Khan",
      "Rudrabha Mukhopadhyay",
      "Vinay P. Namboodiri",
      "C. V. Jawahar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08580"
  },
  {
    "id": "arXiv:2110.08584",
    "title": "Surveying Wonderland for many more literature visualization techniques",
    "abstract": "There are still many potential literature visualizations to be discovered. By\nfocusing on a single text, the author surveys many existing visualizations\nacross research domains, in the wild, and creates new visualizations. 58\ntechniques are indicated, suggesting a wider variety of visualizations beyond\nresearch disciplines.",
    "descriptor": "\nComments: 7 pages. 58 figures, each a different visualization of Alice's Adventures in Wonderland\n",
    "authors": [
      "Richard Brath"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.08584"
  },
  {
    "id": "arXiv:2110.08586",
    "title": "Generative Adversarial Imitation Learning for End-to-End Autonomous  Driving on Urban Environments",
    "abstract": "Autonomous driving is a complex task, which has been tackled since the first\nself-driving car ALVINN in 1989, with a supervised learning approach, or\nbehavioral cloning (BC). In BC, a neural network is trained with state-action\npairs that constitute the training set made by an expert, i.e., a human driver.\nHowever, this type of imitation learning does not take into account the\ntemporal dependencies that might exist between actions taken in different\nmoments of a navigation trajectory. These type of tasks are better handled by\nreinforcement learning (RL) algorithms, which need to define a reward function.\nOn the other hand, more recent approaches to imitation learning, such as\nGenerative Adversarial Imitation Learning (GAIL), can train policies without\nexplicitly requiring to define a reward function, allowing an agent to learn by\ntrial and error directly on a training set of expert trajectories. In this\nwork, we propose two variations of GAIL for autonomous navigation of a vehicle\nin the realistic CARLA simulation environment for urban scenarios. Both of them\nuse the same network architecture, which process high dimensional image input\nfrom three frontal cameras, and other nine continuous inputs representing the\nvelocity, the next point from the sparse trajectory and a high-level driving\ncommand. We show that both of them are capable of imitating the expert\ntrajectory from start to end after training ends, but the GAIL loss function\nthat is augmented with BC outperforms the former in terms of convergence time\nand training stability.",
    "descriptor": "",
    "authors": [
      "Gustavo Claudio Karl Couto",
      "Eric Aislan Antonelo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.08586"
  },
  {
    "id": "arXiv:2110.08588",
    "title": "Preproduction Deploys: Cloud-Native Integration Testing",
    "abstract": "The microservice architecture for cloud-based systems is extended to not only\nrequire each loosely coupled component to be independently deployable, but also\nto provide independent routing for each component. This supports canary\ndeployments, green/blue deployments and roll-back. Both ad hoc and system\nintegration test traffic can be directed to components before they are released\nto production traffic. Front-end code is included in this architecture by using\nserver-side rendering of JS bundles. Environments for integration testing are\ncreated with preproduction deploys side by side with production deploys using\nappropriate levels of isolation. After a successful integration test run,\npreproduction components are known to work with production precisely as it is.\nFor isolation, test traffic uses staging databases that are copied daily from\nthe production databases, omitting sensitive data. Safety and security concerns\nare dealt with in a targeted fashion, not monolithically. This architecture\nscales well with organization size; is more effective for integration testing;\nand is better aligned with agile business practices than traditional\napproaches.",
    "descriptor": "\nComments: 8 pages, 1 figure, submitted to IEEE CloudSummit 2021\n",
    "authors": [
      "Jeremy J. Carroll",
      "Pankaj Anand",
      "David Guo"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.08588"
  },
  {
    "id": "arXiv:2110.08589",
    "title": "Pseudo-label refinement using superpixels for semi-supervised brain  tumour segmentation",
    "abstract": "Training neural networks using limited annotations is an important problem in\nthe medical domain. Deep Neural Networks (DNNs) typically require large,\nannotated datasets to achieve acceptable performance which, in the medical\ndomain, are especially difficult to obtain as they require significant time\nfrom expert radiologists. Semi-supervised learning aims to overcome this\nproblem by learning segmentations with very little annotated data, whilst\nexploiting large amounts of unlabelled data. However, the best-known technique,\nwhich utilises inferred pseudo-labels, is vulnerable to inaccurate\npseudo-labels degrading the performance. We propose a framework based on\nsuperpixels - meaningful clusters of adjacent pixels - to improve the accuracy\nof the pseudo labels and address this issue. Our framework combines superpixels\nwith semi-supervised learning, refining the pseudo-labels during training using\nthe features and edges of the superpixel maps. This method is evaluated on a\nmultimodal magnetic resonance imaging (MRI) dataset for the task of brain\ntumour region segmentation. Our method demonstrates improved performance over\nthe standard semi-supervised pseudo-labelling baseline when there is a reduced\nannotator burden and only 5 annotated patients are available. We report\nDSC=0.824 and DSC=0.707 for the test set whole tumour and tumour core regions\nrespectively.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Bethany H. Thompson",
      "Gaetano Di Caterina",
      "Jeremy P. Voisey"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08589"
  },
  {
    "id": "arXiv:2110.08590",
    "title": "Automated Remote Sensing Forest Inventory Using Satelite Imagery",
    "abstract": "For many countries like Russia, Canada, or the USA, a robust and detailed\ntree species inventory is essential to manage their forests sustainably. Since\none can not apply unmanned aerial vehicle (UAV) imagery-based approaches to\nlarge-scale forest inventory applications, the utilization of machine learning\nalgorithms on satellite imagery is a rising topic of research. Although\nsatellite imagery quality is relatively low, additional spectral channels\nprovide a sufficient amount of information for tree crown classification tasks.\nAssuming that tree crowns are detected already, we use embeddings of tree\ncrowns generated by Autoencoders as a data set to train classical Machine\nLearning algorithms. We compare our Autoencoder (AE) based approach to\ntraditional convolutional neural networks (CNN) end-to-end classifiers.",
    "descriptor": "\nComments: 15 pages, 11 figures, 71th International Astronautical Congress (IAC) - The CyberSpace Edition\n",
    "authors": [
      "Abduragim Shtanchaev",
      "Artur Bille",
      "Olga Sutyrina",
      "Sara Elelimy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08590"
  },
  {
    "id": "arXiv:2110.08591",
    "title": "n-stage Latent Dirichlet Allocation: A Novel Approach for LDA",
    "abstract": "Nowadays, data analysis has become a problem as the amount of data is\nconstantly increasing. In order to overcome this problem in textual data, many\nmodels and methods are used in natural language processing. The topic modeling\nfield is one of these methods. Topic modeling allows determining the semantic\nstructure of a text document. Latent Dirichlet Allocation (LDA) is the most\ncommon method among topic modeling methods. In this article, the proposed\nn-stage LDA method, which can enable the LDA method to be used more\neffectively, is explained in detail. The positive effect of the method has been\ndemonstrated by the applied English and Turkish studies. Since the method\nfocuses on reducing the word count in the dictionary, it can be used\nlanguage-independently. You can access the open-source code of the method and\nthe example: https://github.com/anil1055/n-stage_LDA",
    "descriptor": "\nComments: Published in: 2019 4th International Conference on Computer Science and Engineering (UBMK). This study is extension version of \"Comparison of Topic Modeling Methods for Type Detection of Turkish News\" this http URL . Please citation this IEEE paper\n",
    "authors": [
      "Zekeriya Anil Guven",
      "Banu Diri",
      "Tolgahan Cakaloglu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.08591"
  },
  {
    "id": "arXiv:2110.08592",
    "title": "Self-stabilizing Byzantine- and Intrusion-tolerant Consensus",
    "abstract": "One of the most celebrated problems of fault-tolerant distributed computing\nis the consensus problem. It was shown to abstract a myriad of problems in\nwhich processes have to agree on a single value. Consensus applications include\nfundamental services for the environments of the Cloud or Blockchain. In such\nchallenging environments, malicious behavior is often modeled as adversarial\nByzantine faults. At OPODIS 2010, Most\\'efaoui and Raynal, in short, MR,\npresented a Byzantine- and intrusion-tolerant solution to consensus in which\nthe decided value cannot be a value proposed only by Byzantine processes. In\naddition to this validity property, MR has optimal resilience since it can deal\nwith up to $t < n/3$ Byzantine processes, where $n$ is the number of processes.\nWe note that MR provides this multivalued consensus object (which accepts\nproposals taken from a set with a finite number of values) assuming the\navailability of a single Binary consensus object (which accepts proposals taken\nfrom the set {0,1}).\nThis work, which focuses on multivalued consensus, aims at the design of an\neven more robust solution than MR. Our proposal expands MR's fault-model with\nself-stabilization, a vigorous notion of fault-tolerance. In addition to\ntolerating Byzantine and communication failures, self-stabilizing systems can\nautomatically recover after the occurrence of \\emph{arbitrary\ntransient-faults}. These faults represent any violation of the assumptions\naccording to which the system was designed to operate (provided that the\nalgorithm code remains intact). We propose, to the best of our knowledge, the\nfirst self-stabilizing solution for intrusion-tolerant multivalued consensus\nfor asynchronous message-passing systems prone to Byzantine failures.",
    "descriptor": "",
    "authors": [
      "Romaric Duvignau",
      "Michel Raynal",
      "Elad Michael Schiller"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.08592"
  },
  {
    "id": "arXiv:2110.08599",
    "title": "Mapping illegal waste dumping sites with neural-network classification  of satellite imagery",
    "abstract": "Public health and habitat quality are crucial goals of urban planning. In\nrecent years, the severe social and environmental impact of illegal waste\ndumping sites has made them one of the most serious problems faced by cities in\nthe Global South, in a context of scarce information available for decision\nmaking. To help identify the location of dumping sites and track their\nevolution over time we adopt a data-driven model from the machine learning\ndomain, analyzing satellite images. This allows us to take advantage of the\nincreasing availability of geo-spatial open-data, high-resolution satellite\nimagery, and open source tools to train machine learning algorithms with a\nsmall set of known waste dumping sites in Buenos Aires, and then predict the\nlocation of other sites over vast areas at high speed and low cost. This case\nstudy shows the results of a collaboration between Dymaxion Labs and\nFundaci\\'on Bunge y Born to harness this technique in order to create a\ncomprehensive map of potential locations of illegal waste dumping sites in the\nregion.",
    "descriptor": "\nComments: 5 pages, 3 figures, KDD Workshop on Data-driven Humanitarian Mapping held with the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, August 14, 2021\n",
    "authors": [
      "Devesa",
      "Maria Roberta",
      "Vazquez Brust",
      "H. Antonio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.08599"
  },
  {
    "id": "arXiv:2110.08604",
    "title": "Back to Reality: Leveraging Pattern-driven Modeling to Enable Affordable  Sentiment Dependency Learning",
    "abstract": "Aspect-based Sentiment Classification (ABSC) is a challenging sub-task of\ntraditional sentiment analysis. Due to the difficulty of handling potential\ncorrelations among sentiment polarities of multiple aspects, i.e., sentiment\ndependency, recent popular works tend to exploit syntactic information guiding\nsentiment dependency parsing. However, syntax information (e.g., syntactic\ndependency trees) usually occupies expensive computational resources in terms\nof the operation of the adjacent matrix. Instead, we define the consecutive\naspects with the same sentiment as the sentiment cluster in the case that we\nfind that most sentiment dependency occurs between adjacent aspects. Motivated\nby this finding, we propose the sentiment patterns (SP) to guide the model\ndependency learning. Thereafter, we introduce the local sentiment aggregating\n(LSA) mechanism to focus on learning the sentiment dependency in the sentiment\ncluster. The LSA is more efficient than existing dependency tree-based models\ndue to the absence of additional dependency matrix constructing and modeling.\nFurthermore, we propose differential weighting for aggregation window building\nto measure the importance of sentiment dependency. Experiments on four public\ndatasets show that our models achieve state-of-the-art performance with\nespecially improvement on learning sentiment cluster.",
    "descriptor": "",
    "authors": [
      "Heng Yang",
      "Biqing Zeng",
      "Mayi Xu",
      "Tianxing Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08604"
  },
  {
    "id": "arXiv:2110.08605",
    "title": "Statistics in everyone's backyard: an impact study via citation network  analysis",
    "abstract": "The increasing availability of curated citation data provides a wealth of\nresources for analyzing and understanding the intellectual influence of\nscientific publications. In the field of statistics, current studies of\ncitation data have mostly focused on the interactions between statistical\njournals and papers, limiting the measure of influence to mainly within\nstatistics itself. In this paper, we take the first step towards understanding\nthe impact statistics has made on other scientific fields in the era of Big\nData. By collecting comprehensive bibliometric data from the Web of Science\ndatabase for selected statistical journals, we investigate the citation trends\nand compositions of citing fields over time to show that their diversity has\nbeen increasing. Furthermore, we use the local clustering technique involving\npersonalized PageRank with conductance for size selection to find the most\nrelevant statistical research area for a given external topic of interest. We\nprovide theoretical guarantees for the procedure and, through a number of case\nstudies, show the results from our citation data align well with our knowledge\nand intuition about these external topics. Overall, we have found that the\nstatistical theory and methods recently invented by the statistics community\nhave made increasing impact on other scientific fields.",
    "descriptor": "",
    "authors": [
      "Lijia Wang",
      "Xin Tong",
      "Y.X. Rachel Wang"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.08605"
  },
  {
    "id": "arXiv:2110.08607",
    "title": "Physics-guided Deep Markov Models for Learning Nonlinear Dynamical  Systems with Uncertainty",
    "abstract": "In this paper, we propose a probabilistic physics-guided framework, termed\nPhysics-guided Deep Markov Model (PgDMM). The framework is especially targeted\nto the inference of the characteristics and latent structure of nonlinear\ndynamical systems from measurement data, where it is typically intractable to\nperform exact inference of latent variables. A recently surfaced option\npertains to leveraging variational inference to perform approximate inference.\nIn such a scheme, transition and emission functions of the system are\nparameterized via feed-forward neural networks (deep generative models).\nHowever, due to the generalized and highly versatile formulation of neural\nnetwork functions, the learned latent space is often prone to lack physical\ninterpretation and structured representation. To address this, we bridge\nphysics-based state space models with Deep Markov Models, thus delivering a\nhybrid modeling framework for unsupervised learning and identification for\nnonlinear dynamical systems. Specifically, the transition process can be\nmodeled as a physics-based model enhanced with an additive neural network\ncomponent, which aims to learn the discrepancy between the physics-based model\nand the actual dynamical system being monitored. The proposed framework takes\nadvantage of the expressive power of deep learning, while retaining the driving\nphysics of the dynamical system by imposing physics-driven restrictions on the\nside of the latent space. We demonstrate the benefits of such a fusion in terms\nof achieving improved performance on illustrative simulation examples and\nexperimental case studies of nonlinear systems. Our results indicate that the\nphysics-based models involved in the employed transition and emission functions\nessentially enforce a more structured and physically interpretable latent\nspace, which is essential to generalization and prediction capabilities.",
    "descriptor": "",
    "authors": [
      "Wei Liu",
      "Zhilu Lai",
      "Kiran Bacsa",
      "Eleni Chatzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Chaotic Dynamics (nlin.CD)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.08607"
  },
  {
    "id": "arXiv:2110.08610",
    "title": "MAAD: A Model and Dataset for \"Attended Awareness\" in Driving",
    "abstract": "We propose a computational model to estimate a person's attended awareness of\ntheir environment. We define attended awareness to be those parts of a\npotentially dynamic scene which a person has attended to in recent history and\nwhich they are still likely to be physically aware of. Our model takes as input\nscene information in the form of a video and noisy gaze estimates, and outputs\nvisual saliency, a refined gaze estimate, and an estimate of the person's\nattended awareness. In order to test our model, we capture a new dataset with a\nhigh-precision gaze tracker including 24.5 hours of gaze sequences from 23\nsubjects attending to videos of driving scenes. The dataset also contains\nthird-party annotations of the subjects' attended awareness based on\nobservations of their scan path. Our results show that our model is able to\nreasonably estimate attended awareness in a controlled setting, and in the\nfuture could potentially be extended to real egocentric driving data to help\nenable more effective ahead-of-time warnings in safety systems and thereby\naugment driver performance. We also demonstrate our model's effectiveness on\nthe tasks of saliency, gaze calibration, and denoising, using both our dataset\nand an existing saliency dataset. We make our model and dataset available at\nhttps://github.com/ToyotaResearchInstitute/att-aware/.",
    "descriptor": "\nComments: 25 pages, 13 figures, 14 tables, Accepted at EPIC@ICCV 2021 Workshop. Main paper + Supplementary Material\n",
    "authors": [
      "Deepak Gopinath",
      "Guy Rosman",
      "Simon Stent",
      "Katsuya Terahata",
      "Luke Fletcher",
      "Brenna Argall",
      "John Leonard"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.08610"
  },
  {
    "id": "arXiv:2110.08611",
    "title": "Deep Active Learning by Leveraging Training Dynamics",
    "abstract": "Active learning theories and methods have been extensively studied in\nclassical statistical learning settings. However, deep active learning, i.e.,\nactive learning with deep learning models, is usually based on empirical\ncriteria without solid theoretical justification, thus suffering from heavy\ndoubts when some of those fail to provide benefits in applications. In this\npaper, by exploring the connection between the generalization performance and\nthe training dynamics, we propose a theory-driven deep active learning method\n(dynamicAL) which selects samples to maximize training dynamics. In particular,\nwe prove that convergence speed of training and the generalization performance\nis positively correlated under the ultra-wide condition and show that\nmaximizing the training dynamics leads to a better generalization performance.\nFurther on, to scale up to large deep neural networks and data sets, we\nintroduce two relaxations for the subset selection problem and reduce the time\ncomplexity from polynomial to constant. Empirical results show that dynamicAL\nnot only outperforms the other baselines consistently but also scales well on\nlarge deep learning models. We hope our work inspires more attempts in bridging\nthe theoretical findings of deep networks and practical impacts in deep active\nlearning applications.",
    "descriptor": "",
    "authors": [
      "Haonan Wang",
      "Wei Huang",
      "Andrew Margenot",
      "Hanghang Tong",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08611"
  },
  {
    "id": "arXiv:2110.08613",
    "title": "Enabling Large-Reach TLBs for High-Throughput Processors by Exploiting  Memory Subregion Contiguity",
    "abstract": "Accelerators, like GPUs, have become a trend to deliver future performance\ndesire, and sharing the same virtual memory space between CPUs and GPUs is\nincreasingly adopted to simplify programming. However, address translation,\nwhich is the key factor of virtual memory, is becoming the bottleneck of\nperformance for GPUs. In GPUs, a single TLB miss can stall hundreds of threads\ndue to the SIMT execute model, degrading performance dramatically. Through real\nsystem analysis, we observe that the OS shows an advanced contiguity (e.g.,\nhundreds of contiguous pages), and more large memory regions with advanced\ncontiguity tend to be allocated with the increase of working sets. Leveraging\nthe observation, we propose MESC to improve the translation efficiency for\nGPUs. The key idea of MESC is to divide each large page frame (2MB size) in\nvirtual memory space into memory subregions with fixed size (i.e., 64 4KB\npages), and store the contiguity information of subregions and large page\nframes in L2PTEs. With MESC, address translations of up to 512 pages can be\ncoalesced into single TLB entry, without the needs of changing memory\nallocation policy (i.e., demand paging) and the support of large pages. In the\nexperimental results, MESC achieves 77.2% performance improvement and 76.4%\nreduction in dynamic translation energy for translation-sensitive workloads.",
    "descriptor": "",
    "authors": [
      "Chao Yu",
      "Yuebin Bai",
      "Rui Wang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2110.08613"
  },
  {
    "id": "arXiv:2110.08614",
    "title": "Deep Learning and Spectral Embedding for Graph Partitioning",
    "abstract": "We present a graph bisection and partitioning algorithm based on graph neural\nnetworks. For each node in the graph, the network outputs probabilities for\neach of the partitions. The graph neural network consists of two modules: an\nembedding phase and a partitioning phase. The embedding phase is trained first\nby minimizing a loss function inspired by spectral graph theory. The\npartitioning module is trained through a loss function that corresponds to the\nexpected value of the normalized cut. Both parts of the neural network rely on\nSAGE convolutional layers and graph coarsening using heavy edge matching. The\nmultilevel structure of the neural network is inspired by the multigrid\nalgorithm. Our approach generalizes very well to bigger graphs and has\npartition quality comparable to METIS, Scotch and spectral partitioning, with\nshorter runtime compared to METIS and spectral partitioning.",
    "descriptor": "",
    "authors": [
      "Alice Gatti",
      "Zhixiong Hu",
      "Tess Smidt",
      "Esmond G. Ng",
      "Pieter Ghysels"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08614"
  },
  {
    "id": "arXiv:2110.08616",
    "title": "GradSign: Model Performance Inference with Theoretical Insights",
    "abstract": "A key challenge in neural architecture search (NAS) is quickly inferring the\npredictive performance of a broad spectrum of networks to discover\nstatistically accurate and computationally efficient ones. We refer to this\ntask as model performance inference (MPI). The current practice for efficient\nMPI is gradient-based methods that leverage the gradients of a network at\ninitialization to infer its performance. However, existing gradient-based\nmethods rely only on heuristic metrics and lack the necessary theoretical\nfoundations to consolidate their designs. We propose GradSign, an accurate,\nsimple, and flexible metric for model performance inference with theoretical\ninsights. The key idea behind GradSign is a quantity {\\Psi} to analyze the\noptimization landscape of different networks at the granularity of individual\ntraining samples. Theoretically, we show that both the network's training and\ntrue population losses are proportionally upper-bounded by {\\Psi} under\nreasonable assumptions. In addition, we design GradSign, an accurate and simple\napproximation of {\\Psi} using the gradients of a network evaluated at a random\ninitialization state. Evaluation on seven NAS benchmarks across three training\ndatasets shows that GradSign generalizes well to real-world networks and\nconsistently outperforms state-of-the-art gradient-based methods for MPI\nevaluated by Spearman's {\\rho} and Kendall's Tau. Additionally, we integrate\nGradSign into four existing NAS algorithms and show that the GradSign-assisted\nNAS algorithms outperform their vanilla counterparts by improving the\naccuracies of best-discovered networks by up to 0.3%, 1.1%, and 1.0% on three\nreal-world tasks.",
    "descriptor": "\nComments: Preprint. Under review\n",
    "authors": [
      "Zhihao Zhang",
      "Zhihao Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08616"
  },
  {
    "id": "arXiv:2110.08620",
    "title": "Learning Cloth Folding Tasks with Refined Flow Based Spatio-Temporal  Graphs",
    "abstract": "Cloth folding is a widespread domestic task that is seemingly performed by\nhumans but which is highly challenging for autonomous robots to execute due to\nthe highly deformable nature of textiles; It is hard to engineer and learn\nmanipulation pipelines to efficiently execute it. In this paper, we propose a\nnew solution for robotic cloth folding (using a standard folding board) via\nlearning from demonstrations. Our demonstration video encoding is based on a\nhigh-level abstraction, namely, a refined optical flow-based spatiotemporal\ngraph, as opposed to a low-level encoding such as image pixels. By constructing\na new spatiotemporal graph with an advanced visual corresponding descriptor,\nthe policy learning can focus on key points and relations with a 3D spatial\nconfiguration, which allows to quickly generalize across different\nenvironments. To further boost the policy searching, we combine optical flow\nand static motion saliency maps to discriminate the dominant motions for better\nhandling the system dynamics in real-time, which aligns with the attentional\nmotion mechanism that dominates the human imitation process. To validate the\nproposed approach, we analyze the manual folding procedure and developed a\ncustom-made end-effector to efficiently interact with the folding board.\nMultiple experiments on a real robotic platform were conducted to validate the\neffectiveness and robustness of the proposed method.",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Peng Zhou",
      "Omar Zahra",
      "Anqing Duan",
      "Shengzeng Huo",
      "Zeyu Wu",
      "David Navarro-Alarcon"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.08620"
  },
  {
    "id": "arXiv:2110.08626",
    "title": "Learning velocity model for complex media with deep convolutional neural  networks",
    "abstract": "The paper considers the problem of velocity model acquisition for a complex\nmedia based on boundary measurements. The acoustic model is used to describe\nthe media. We used an open-source dataset of velocity distributions to compare\nthe presented results with the previous works directly. Forward modeling is\nperformed using the grid-characteristic numerical method. The inverse problem\nis solved using deep convolutional neural networks. Modifications for a\nbaseline UNet architecture are proposed to improve both structural similarity\nindex measure quantitative correspondence of the velocity profiles with the\nground truth. We evaluate our enhancements and demonstrate the statistical\nsignificance of the results.",
    "descriptor": "\nComments: 14 pages, 6 figures, 6 tables\n",
    "authors": [
      "A. Stankevich",
      "I. Nechepurenko",
      "A. Shevchenko",
      "L. Gremyachikh",
      "A. Ustyuzhanin",
      "A. Vasyukov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.08626"
  },
  {
    "id": "arXiv:2110.08627",
    "title": "On the Pareto Frontier of Regret Minimization and Best Arm  Identification in Stochastic Bandits",
    "abstract": "We study the Pareto frontier of two archetypal objectives in stochastic\nbandits, namely, regret minimization (RM) and best arm identification (BAI)\nwith a fixed horizon. It is folklore that the balance between exploitation and\nexploration is crucial for both RM and BAI, but exploration is more critical in\nachieving the optimal performance for the latter objective. To make this\nprecise, we first design and analyze the BoBW-lil'UCB$({\\gamma})$ algorithm,\nwhich achieves order-wise optimal performance for RM or BAI under different\nvalues of ${\\gamma}$. Complementarily, we show that no algorithm can\nsimultaneously perform optimally for both the RM and BAI objectives. More\nprecisely, we establish non-trivial lower bounds on the regret achievable by\nany algorithm with a given BAI failure probability. This analysis shows that in\nsome regimes BoBW-lil'UCB$({\\gamma})$ achieves Pareto-optimality up to constant\nor small terms. Numerical experiments further demonstrate that when applied to\ndifficult instances, BoBW-lil'UCB outperforms a close competitor UCB$_{\\alpha}$\n(Degenne et al., 2019), which is designed for RM and BAI with a fixed\nconfidence.",
    "descriptor": "\nComments: 27 pages, 8 figures\n",
    "authors": [
      "Zixin Zhong",
      "Wang Chi Cheung",
      "Vincent Y. F. Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.08627"
  },
  {
    "id": "arXiv:2110.08631",
    "title": "Learning Continuous Chaotic Attractors with a Reservoir Computer",
    "abstract": "Neural systems are well known for their ability to learn and store\ninformation as memories. Even more impressive is their ability to abstract\nthese memories to create complex internal representations, enabling advanced\nfunctions such as the spatial manipulation of mental representations. While\nrecurrent neural networks (RNNs) are capable of representing complex\ninformation, the exact mechanisms of how dynamical neural systems perform\nabstraction are still not well-understood, thereby hindering the development of\nmore advanced functions. Here, we train a 1000-neuron RNN -- a reservoir\ncomputer (RC) -- to abstract a continuous dynamical attractor memory from\nisolated examples of dynamical attractor memories. Further, we explain the\nabstraction mechanism with new theory. By training the RC on isolated and\nshifted examples of either stable limit cycles or chaotic Lorenz attractors,\nthe RC learns a continuum of attractors, as quantified by an extra Lyapunov\nexponent equal to zero. We propose a theoretical mechanism of this abstraction\nby combining ideas from differentiable generalized synchronization and feedback\ndynamics. Our results quantify abstraction in simple neural systems, enabling\nus to design artificial RNNs for abstraction, and leading us towards a neural\nbasis of abstraction.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Lindsay M. Smith",
      "Jason Z. Kim",
      "Zhixin Lu",
      "Dani S. Bassett"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2110.08631"
  },
  {
    "id": "arXiv:2110.08632",
    "title": "Sampling based Computation of Viability Domain to Prevent Safety  Violations by Attackers",
    "abstract": "This paper studies the security of cyber-physical systems under attacks. Our\ngoal is to design system parameters, such as a set of initial conditions and\ninput bounds so that it is secure by design. To this end, we propose new\nsufficient conditions to guarantee the safety of a system under adversarial\nactuator attacks. Using these conditions, we propose a computationally\nefficient sampling-based method to verify whether a set is a viability domain\nfor a general class of nonlinear systems. In particular, we devise a method of\nchecking a modified barrier function condition on a finite set of points to\nassess whether a set can be rendered forward invariant. Then, we propose an\niterative algorithm to compute the set of initial conditions and input\nconstraint set to limit what an adversary can do if it compromises the\nvulnerable inputs. Finally, we utilize a Quadratic Program approach for online\ncontrol synthesis.",
    "descriptor": "",
    "authors": [
      "Kunal Garg",
      "Ricardo G. Sanfelice",
      "Alvaro A. Cardenas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.08632"
  },
  {
    "id": "arXiv:2110.08633",
    "title": "Hydra: A System for Large Multi-Model Deep Learning",
    "abstract": "Training deep learning (DL) models that do not fit into the memory of a\nsingle GPU is a vexed process, forcing users to procure multiple GPUs to adopt\nmodel-parallel execution. Unfortunately, sequential dependencies in neural\narchitectures often block efficient multi-device training, leading to\nsuboptimal performance. We present 'model spilling', a technique aimed at\nmodels such as Transformers and CNNs to move groups of layers, or shards,\nbetween DRAM and GPU memory, thus enabling arbitrarily large models to be\ntrained even on just one GPU. We then present a set of novel techniques\nleveraging spilling to raise efficiency for multi-model training workloads such\nas model selection: a new hybrid of task- and model-parallelism, a new shard\nscheduling heuristic, and 'double buffering' to hide latency. We prototype our\nideas into a system we call HYDRA to support seamless single-model and\nmulti-model training of large DL models. Experiments with real benchmark\nworkloads show that HYDRA is over 7x faster than regular model parallelism and\nover 50% faster than state-of-the-art industrial tools for pipeline\nparallelism.",
    "descriptor": "\nComments: 12 pages including references. Under submission at Conference on Systems and Machine Learning Foundation\n",
    "authors": [
      "Kabir Nagrecha",
      "Arun Kumar"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08633"
  },
  {
    "id": "arXiv:2110.08634",
    "title": "Towards Robust Waveform-Based Acoustic Models",
    "abstract": "We propose an approach for learning robust acoustic models in adverse\nenvironments, characterized by a significant mismatch between training and test\nconditions. This problem is of paramount importance for the deployment of\nspeech recognition systems that need to perform well in unseen environments.\nOur approach is an instance of vicinal risk minimization, which aims to improve\nrisk estimates during training by replacing the delta functions that define the\nempirical density over the input space with an approximation of the marginal\npopulation density in the vicinity of the training samples. More specifically,\nwe assume that local neighborhoods centered at training samples can be\napproximated using a mixture of Gaussians, and demonstrate theoretically that\nthis can incorporate robust inductive bias into the learning process. We\ncharacterize the individual mixture components implicitly via data augmentation\nschemes, designed to address common sources of spurious correlations in\nacoustic models. To avoid potential confounding effects on robustness due to\ninformation loss, which has been associated with standard feature extraction\ntechniques (e.g., FBANK and MFCC features), we focus our evaluation on the\nwaveform-based setting. Our empirical results show that the proposed approach\ncan generalize to unseen noise conditions, with 150% relative improvement in\nout-of-distribution generalization compared to training using the standard risk\nminimization principle. Moreover, the results demonstrate competitive\nperformance relative to models learned using a training sample designed to\nmatch the acoustic conditions characteristic of test utterances (i.e., optimal\nvicinal densities).",
    "descriptor": "",
    "authors": [
      "Dino Oglic",
      "Zoran Cvetkovic",
      "Peter Sollich",
      "Steve Renals",
      "Bin Yu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.08634"
  },
  {
    "id": "arXiv:2110.08636",
    "title": "DPC: Unsupervised Deep Point Correspondence via Cross and Self  Construction",
    "abstract": "We present a new method for real-time non-rigid dense correspondence between\npoint clouds based on structured shape construction. Our method, termed Deep\nPoint Correspondence (DPC), requires a fraction of the training data compared\nto previous techniques and presents better generalization capabilities. Until\nnow, two main approaches have been suggested for the dense correspondence\nproblem. The first is a spectral-based approach that obtains great results on\nsynthetic datasets but requires mesh connectivity of the shapes and long\ninference processing time while being unstable in real-world scenarios. The\nsecond is a spatial approach that uses an encoder-decoder framework to regress\nan ordered point cloud for the matching alignment from an irregular input.\nUnfortunately, the decoder brings considerable disadvantages, as it requires a\nlarge amount of training data and struggles to generalize well in cross-dataset\nevaluations. DPC's novelty lies in its lack of a decoder component. Instead, we\nuse latent similarity and the input coordinates themselves to construct the\npoint cloud and determine correspondence, replacing the coordinate regression\ndone by the decoder. Extensive experiments show that our construction scheme\nleads to a performance boost in comparison to recent state-of-the-art\ncorrespondence methods. Our code is publicly available at\nhttps://github.com/dvirginz/DPC.",
    "descriptor": "\nComments: 3DV 2021\n",
    "authors": [
      "Itai Lang",
      "Dvir Ginzburg",
      "Shai Avidan",
      "Dan Raviv"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08636"
  },
  {
    "id": "arXiv:2110.08637",
    "title": "Conceptual Modeling and Artificial Intelligence: Mutual Benefits from  Complementary Worlds",
    "abstract": "Conceptual modeling (CM) applies abstraction to reduce the complexity of a\nsystem under study (e.g., an excerpt of reality). As a result of the conceptual\nmodeling process a human interpretable, formalized representation (i.e., a\nconceptual model) is derived which enables understanding and communication\namong humans, and processing by machines. Artificial Intelligence (AI)\nalgorithms are also applied to complex realities (regularly represented by vast\namounts of data) to identify patterns or to classify entities in the data.\nAside from the commonalities of both approaches, a significant difference can\nbe observed by looking at the results. While conceptual models are\ncomprehensible, reproducible, and explicit knowledge representations, AI\ntechniques are capable of efficiently deriving an output from a given input\nwhile acting as a black box. AI solutions often lack comprehensiveness and\nreproducibility. Even the developers of AI systems can't explain why a certain\noutput is derived. In the Conceptual Modeling meets Artificial Intelligence\n(CMAI) workshop, we are interested in tackling the intersection of the two,\nthus far, mostly isolated approached disciplines of CM and AI. The workshop\nembraces the assumption, that manifold mutual benefits can be realized by i)\ninvestigating what Conceptual Modeling (CM) can contribute to AI, and ii) the\nother way around, what Artificial Intelligence (AI) can contribute to CM.",
    "descriptor": "\nComments: Editorial preface to the 3rd Int. Workshop on Conceptual Modeling Meets Artificial Intelligence (CMAI'2021)\n",
    "authors": [
      "Dominik Bork"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.08637"
  },
  {
    "id": "arXiv:2110.08639",
    "title": "Partial Hierarchical Pose Graph Optimization for SLAM",
    "abstract": "In this paper we consider a hierarchical pose graph optimization (HPGO) for\nSimultaneous Localization and Mapping (SLAM). We propose a fast incremental\nprocedure for building hierarchy levels in pose graphs. We study the properties\nof this procedure and show that our solution delivers high execution speed,\nhigh reduction rate and good flexibility. We propose a way to do partial\nhierarchical optimization and compare it to other optimization modes. We show\nthat given a comparatively large amount of poses, partial HPGO gives a 10x\nspeed up comparing to the original optimization, not sacrificing the quality.",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Alexander Korovko",
      "Dmitry Robustov"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.08639"
  },
  {
    "id": "arXiv:2110.08642",
    "title": "Local Advantage Actor-Critic for Robust Multi-Agent Deep Reinforcement  Learning",
    "abstract": "Policy gradient methods have become popular in multi-agent reinforcement\nlearning, but they suffer from high variance due to the presence of\nenvironmental stochasticity and exploring agents (i.e., non-stationarity),\nwhich is potentially worsened by the difficulty in credit assignment. As a\nresult, there is a need for a method that is not only capable of efficiently\nsolving the above two problems but also robust enough to solve a variety of\ntasks. To this end, we propose a new multi-agent policy gradient method, called\nRobust Local Advantage (ROLA) Actor-Critic. ROLA allows each agent to learn an\nindividual action-value function as a local critic as well as ameliorating\nenvironment non-stationarity via a novel centralized training approach based on\na centralized critic. By using this local critic, each agent calculates a\nbaseline to reduce variance on its policy gradient estimation, which results in\nan expected advantage action-value over other agents' choices that implicitly\nimproves credit assignment. We evaluate ROLA across diverse benchmarks and show\nits robustness and effectiveness over a number of state-of-the-art multi-agent\npolicy gradient algorithms.",
    "descriptor": "",
    "authors": [
      "Yuchen Xiao",
      "Xueguang Lyu",
      "Christopher Amato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.08642"
  },
  {
    "id": "arXiv:2110.08645",
    "title": "Modelling Behaviour Change using Cognitive Agent Simulations",
    "abstract": "In health psychology, Behaviour Change Theories(BCTs) play an important role\nin modelling human goal achievement in adverse environments. Some of these\ntheories use concepts that are also used in computational modelling of\ncognition and affect in AI. Examples include dual-process architecture and\nmodels of motivation. It is therefore important to ask whether some BCTs can be\ncomputationally implemented as cognitive agents in a way that builds on\nexisting AI research in cognitive architecture. This paper presents\nwork-in-progress research to apply selected behaviour change theories to\nsimulated agents, so that an agent is acting according to the theory while\nattempting to complete a task in a challenging scenario. Two behaviour change\ntheories are selected as examples (CEOS and PRIME). The research is focusing on\ncomplex agent architectures required for self-determined goal achievement in\nadverse circumstances where the action is difficult to maintain (e.g. healthy\neating at office parties). Such simulations are useful because they can provide\nnew insights into human behaviour change and improve conceptual precision. In\naddition, they can act as a rapid-prototyping environment for technology\ndevelopment. High-level descriptive simulations also provide an opportunity for\ntransparency and participatory design, which is important for user ownership of\nthe behaviour change process.",
    "descriptor": "\nComments: This paper was accepted for a planned symposium at AISB-2019, but the symposium had to be cancelled\n",
    "authors": [
      "Catriona M. Kennedy"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.08645"
  },
  {
    "id": "arXiv:2110.08649",
    "title": "Equivariant Discrete Normalizing Flows",
    "abstract": "At its core, generative modeling seeks to uncover the underlying factors that\ngive rise to observed data that can often be modelled as the natural symmetries\nthat manifest themselves through invariances and equivariances to certain\ntransformations laws. However, current approaches are couched in the formalism\nof continuous normalizing flows that require the construction of equivariant\nvector fields -- inhibiting their simple application to conventional higher\ndimensional generative modelling domains like natural images. In this paper we\nfocus on building equivariant normalizing flows using discrete layers. We first\ntheoretically prove the existence of an equivariant map for compact groups\nwhose actions are on compact spaces. We further introduce two new equivariant\nflows: $G$-coupling Flows and $G$-Residual Flows that elevate classical\nCoupling and Residual Flows with equivariant maps to a prescribed group $G$.\nOur construction of $G$-Residual Flows are also universal, in the sense that we\nprove an $G$-equivariant diffeomorphism can be exactly mapped by a $G$-residual\nflow. Finally, we complement our theoretical insights with experiments -- for\nthe first time -- on image datasets like CIFAR-10 and show $G$-Equivariant\nDiscrete Normalizing flows lead to increased data efficiency, faster\nconvergence, and improved likelihood estimates.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Avishek Joey Bose",
      "Ivan Kobyzev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08649"
  },
  {
    "id": "arXiv:2110.08650",
    "title": "Challenges Porting a C++ Template-Metaprogramming Abstraction Layer to  Directive-based Offloading",
    "abstract": "HPC systems employ a growing variety of compute accelerators with different\narchitectures and from different vendors. Large scientific applications are\nrequired to run efficiently across these systems but need to retain a single\ncode-base in order to not stifle development. Directive-based offloading\nprogramming models set out to provide the required portability, but, to\nexisting codes, they themselves represent yet another API to port to. Here, we\npresent our approach of porting the GPU-accelerated particle-in-cell code\nPIConGPU to OpenACC and OpenMP target by adding two new backends to its\nexisting C++-template metaprogramming-based offloading abstraction layer alpaka\nand avoiding other modifications to the application code. We introduce our\napproach in the face of conflicts between requirements and available features\nin the standards as well as practical hurdles posed by immature compiler\nsupport.",
    "descriptor": "\nComments: 20 pages, 1 figure, 3 tables, WACCPD@SC21\n",
    "authors": [
      "Jeffrey Kelling",
      "Sergei Bastrakov",
      "Alexander Debus",
      "Thomas Kluge",
      "Matt Leinhauser",
      "Richard Pausch2",
      "Klaus Steiniger",
      "Jan Stephan",
      "Ren\u00e9 Widera",
      "Jeff Young",
      "Michael Bussmann",
      "Sunita Chandrasekaran",
      "Guido Juckeland"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.08650"
  },
  {
    "id": "arXiv:2110.08653",
    "title": "Learning UI Navigation through Demonstrations composed of Macro Actions",
    "abstract": "We have developed a framework to reliably build agents capable of UI\nnavigation. The state space is simplified from raw-pixels to a set of UI\nelements extracted from screen understanding, such as OCR and icon detection.\nThe action space is restricted to the UI elements plus a few global actions.\nActions can be customized for tasks and each action is a sequence of basic\noperations conditioned on status checks. With such a design, we are able to\ntrain DQfD and BC agents with a small number of demonstration episodes. We\npropose demo augmentation that significantly reduces the required number of\nhuman demonstrations. We made a customization of DQfD to allow demos collected\non screenshots to facilitate the demo coverage of rare cases. Demos are only\ncollected for the failed cases during the evaluation of the previous version of\nthe agent. With 10s of iterations looping over evaluation, demo collection, and\ntraining, the agent reaches a 98.7\\% success rate on the search task in an\nenvironment of 80+ apps and websites where initial states and viewing\nparameters are randomized.",
    "descriptor": "",
    "authors": [
      "Wei Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08653"
  },
  {
    "id": "arXiv:2110.08654",
    "title": "LEO Satellites in 5G and Beyond Networks: A Review from a  Standardization Perspective",
    "abstract": "Low Earth Orbit (LEO) Satellite Network (SatNet) with their\nmega-constellations are expected to play a key role in providing ubiquitous\nInternet and communications services in the future. LEO SatNets will provide\nwide-area coverage and support service availability, continuity, and\nscalability. To support the integration of SatNets and terrestrial Fifth\nGeneration (5G)networks and beyond, the satellite communication industry has\nbecome increasingly involved with the 3rd Generation Partnership Project (3GPP)\nstandardization activities for 5G. In this work, we review the 3GPP\nstandardization activities for the integration of SatNets in 5G and beyond. The\n3GPP use cases of SatNets are highlighted and potential requirements to realize\nthem are summarized as well. The impacted areas of New Radio(NR) are discussed\nwith some potential solutions. The foreseen requirements for the management and\norchestration of SatNets within 5G are described. Future standardization\ndirections are discussed to support the full integration of SatNets in\nSixthGeneration (6G) with the goal of ubiquitous global connectivity.",
    "descriptor": "",
    "authors": [
      "Tasneem Darwish",
      "Gunes Karabulut Kurt",
      "Halim Yanikomeroglu",
      "Michel Bellemare",
      "Guillaume Lamontagne"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.08654"
  },
  {
    "id": "arXiv:2110.08658",
    "title": "Dynamic Compressed Sensing of Unsteady Flows with a Mobile Robot",
    "abstract": "Large-scale environmental sensing with a finite number of mobile sensor is a\nchallenging task that requires a lot of resources and time. This is especially\ntrue when features in the environment are spatiotemporally changing with\nunknown or partially known dynamics. However, these dynamic features often\nevolve in a low-dimensional space, making it possible to capture their dynamics\nsufficiently well with only one or several properly planned mobile sensors.\nThis paper investigates the problem of dynamic compressed sensing (DCS) of an\nunsteady flow field, which takes advantage of the inherently low dimensionality\nof the underlying flow dynamics to reduce number of waypoints for a mobile\nsensing robot. The optimal sensing waypoints are identified by an iterative\ncompressed sensing algorithm that optimizes the flow reconstruction based on\nthe proper orthogonal decomposition (POD) modes. An optimized robot trajectory\nis then found to traverse these waypoints while minimizing the energy\nconsumption, time, and flow reconstruction error. Simulation results in an\nunsteady double-gyre flow field is presented to demonstrate the efficacy of the\nproposed algorithms. Experimental results with an indoor quadcopter are\npresented to show the feasibility of the resulting trajectory.",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Sachin Shriwastav",
      "Gregory Snyder",
      "Zhuoyuan Song"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.08658"
  },
  {
    "id": "arXiv:2110.08661",
    "title": "Making Existing Software Quantum Safe: Lessons Learned",
    "abstract": "In the era of quantum computing, Shor's algorithm running on quantum\ncomputers (QCs) can break asymmetric encryption algorithms that classical\ncomputers essentially cannot. QCs, with the help of Grover's algorithm, can\nalso speed up the breaking of symmetric encryption algorithms. Though the exact\ndate when QCs will become \"dangerous\" for practical problems is unknown, the\nconsensus is that this future is near. Thus, one needs to start preparing for\nthe era of quantum advantage and ensure quantum safety proactively.\nIn this paper, we discuss the effect of quantum advantage on the existing\nsoftware systems and recap our seven-step roadmap, deemed 7E. The roadmap gives\ndevelopers a structured way to start preparing for the quantum advantage era.\nWe then report the results of a case study, which validates 7E. Our software\nunder study is the IBM Db2 database system, where we upgrade the existing\ncryptographic schemes to post-quantum cryptography (using Kyber and Dilithium\nschemes) and report our findings and learned lessons. The outcome of the study\nshows that the 7E roadmap is effective in helping to plan the evolution of\nexisting software security features towards quantum safety.",
    "descriptor": "",
    "authors": [
      "Lei Zhang",
      "Andriy Miranskyy",
      "Walid Rjaibi",
      "Greg Stager",
      "Michael Gray",
      "John Peck"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2110.08661"
  },
  {
    "id": "arXiv:2110.08662",
    "title": "An Effective Attack Scenario Construction Model based on Attack Steps  and Stages Identification",
    "abstract": "A Network Intrusion Detection System (NIDS) is a network security technology\nfor detecting intruder attacks. However, it produces a great amount of\nlow-level alerts which makes the analysis difficult, especially to construct\nthe attack scenarios. Attack scenario construction (ASC) via Alert Correlation\n(AC) is important to reveal the strategy of attack in terms of steps and stages\nthat need to be launched to make the attack successful. In most of the existing\nworks, alerts are correlated by classifying the alerts based on the\ncause-effect relationship. However, the drawback of these works is the\nidentification of false and incomplete correlations due to the infiltration of\nraw alerts. To address this problem, this work proposes an effective ASC model\nto discover the complete relationship among alerts. The model is successfully\nexperimented using two types of datasets, which are DARPA 2000, and ISCX2012.\nThe Completeness and Soundness of the proposed model are measured to evaluate\nthe overall correlation effectiveness.",
    "descriptor": "",
    "authors": [
      "Taqwa Ahmed Alhaj",
      "Maheyzah Md Siraj",
      "Anazida Zainal",
      "Inshirah Idris",
      "Anjum Nazir",
      "Fatin Elhaj",
      "Tasneem Darwish"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.08662"
  },
  {
    "id": "arXiv:2110.08664",
    "title": "Finding Critical Scenarios for Automated Driving Systems: A Systematic  Literature Review",
    "abstract": "Scenario-based approaches have been receiving a huge amount of attention in\nresearch and engineering of automated driving systems. Due to the complexity\nand uncertainty of the driving environment, and the complexity of the driving\ntask itself, the number of possible driving scenarios that an ADS or ADAS may\nencounter is virtually infinite. Therefore it is essential to be able to reason\nabout the identification of scenarios and in particular critical ones that may\nimpose unacceptable risk if not considered. Critical scenarios are particularly\nimportant to support design, verification and validation efforts, and as a\nbasis for a safety case. In this paper, we present the results of a systematic\nliterature review in the context of autonomous driving. The main contributions\nare: (i) introducing a comprehensive taxonomy for critical scenario\nidentification methods; (ii) giving an overview of the state-of-the-art\nresearch based on the taxonomy encompassing 86 papers between 2017 and 2020;\nand (iii) identifying open issues and directions for further research. The\nprovided taxonomy comprises three main perspectives encompassing the problem\ndefinition (the why), the solution (the methods to derive scenarios), and the\nassessment of the established scenarios. In addition, we discuss open research\nissues considering the perspectives of coverage, practicability, and scenario\nspace explosion.",
    "descriptor": "\nComments: 37 pages, 24 figures\n",
    "authors": [
      "Xinhai Zhang",
      "Jianbo Tao",
      "Kaige Tan",
      "Martin T\u00f6rngren",
      "Jos\u00e9 Manuel Gaspar S\u00e1nchez",
      "Muhammad Rusyadi Ramli",
      "Xin Tao",
      "Magnus Gyllenhammar",
      "Franz Wotawa",
      "Naveen Mohan",
      "Mihai Nica",
      "Hermann Felbinger"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.08664"
  },
  {
    "id": "arXiv:2110.08667",
    "title": "Face Verification with Challenging Imposters and Diversified  Demographics",
    "abstract": "Face verification aims to distinguish between genuine and imposter pairs of\nfaces, which include the same or different identities, respectively. The\nperformance reported in recent years gives the impression that the task is\npractically solved. Here, we revisit the problem and argue that existing\nevaluation datasets were built using two oversimplifying design choices. First,\nthe usual identity selection to form imposter pairs is not challenging enough\nbecause, in practice, verification is needed to detect challenging imposters.\nSecond, the underlying demographics of existing datasets are often insufficient\nto account for the wide diversity of facial characteristics of people from\nacross the world. To mitigate these limitations, we introduce the $FaVCI2D$\ndataset. Imposter pairs are challenging because they include visually similar\nfaces selected from a large pool of demographically diversified identities. The\ndataset also includes metadata related to gender, country and age to facilitate\nfine-grained analysis of results. $FaVCI2D$ is generated from freely\ndistributable resources. Experiments with state-of-the-art deep models that\nprovide nearly 100\\% performance on existing datasets show a significant\nperformance drop for $FaVCI2D$, confirming our starting hypothesis. Equally\nimportant, we analyze legal and ethical challenges which appeared in recent\nyears and hindered the development of face analysis research. We introduce a\nseries of design choices which address these challenges and make the dataset\nconstitution and usage more sustainable and fairer. $FaVCI2D$ is available\nat~\\url{https://github.com/AIMultimediaLab/FaVCI2D-Face-Verification-with-Challenging-Imposters-and-Diversified-Demographics}.",
    "descriptor": "",
    "authors": [
      "Adrian Popescu",
      "Liviu-Daniel \u015etefan",
      "J\u00e9r\u00f4me Deshayes-Chossart",
      "Bogdan Ionescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08667"
  },
  {
    "id": "arXiv:2110.08669",
    "title": "Constructing Many Faces in Arrangements of Lines and Segments",
    "abstract": "We present new algorithms for computing many faces in arrangements of lines\nand segments. Given a set $S$ of $n$ lines (resp., segments) and a set $P$ of\n$m$ points in the plane, the problem is to compute the faces of the\narrangements of $S$ that contain at least one point of $P$. For the line case,\nwe give a deterministic algorithm of $O(m^{2/3}n^{2/3}\\log^{2/3}\n(n/\\sqrt{m})+(m+n)\\log n)$ time. This improves the previously best\ndeterministic algorithm [Agarwal, 1990] by a factor of $\\log^{2.22}n$ and\nimproves the previously best randomized algorithm [Agarwal, Matou\\v{s}ek, and\nSchwarzkopf, 1998] by a factor of $\\log^{1/3}n$ in certain cases (e.g., when\n$m=\\Theta(n)$). For the segment case, we present a deterministic algorithm of\n$O(n^{2/3}m^{2/3}\\log n+\\tau(n\\alpha^2(n)+n\\log m+m)\\log n)$ time, where\n$\\tau=\\min\\{\\log m,\\log (n/\\sqrt{m})\\}$ and $\\alpha(n)$ is the inverse\nAckermann function. This improves the previously best deterministic algorithm\n[Agarwal, 1990] by a factor of $\\log^{2.11}n$ and improves the previously best\nrandomized algorithm [Agarwal, Matou\\v{s}ek, and Schwarzkopf, 1998] by a factor\nof $\\log n$ in certain cases (e.g., when $m=\\Theta(n)$). We also give a\nrandomized algorithm of $O(m^{2/3}K^{1/3}\\log n+\\tau(n\\alpha(n)+n\\log m+m)\\log\nn\\log K)$ expected time, where $K$ is the number of intersections of all\nsegments of $S$. In addition, we consider the query version of the problem,\nthat is, preprocess $S$ to compute the face of the arrangement of $S$ that\ncontains any query point. We present new results that improve the previous work\nfor both the line and the segment cases.",
    "descriptor": "\nComments: To be presented at SODA 2022\n",
    "authors": [
      "Haitao Wang"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.08669"
  },
  {
    "id": "arXiv:2110.08671",
    "title": "Blockchain and Federated Edge Learning for Privacy-Preserving Mobile  Crowdsensing",
    "abstract": "Mobile crowdsensing (MCS) counting on the mobility of massive workers helps\nthe requestor accomplish various sensing tasks with more flexibility and lower\ncost. However, for the conventional MCS, the large consumption of communication\nresources for raw data transmission and high requirements on data storage and\ncomputing capability hinder potential requestors with limited resources from\nusing MCS. To facilitate the widespread application of MCS, we propose a novel\nMCS learning framework leveraging on blockchain technology and the new concept\nof edge intelligence based on federated learning (FL), which involves four\nmajor entities, including requestors, blockchain, edge servers and mobile\ndevices as workers. Even though there exist several studies on blockchain-based\nMCS and blockchain-based FL, they cannot solve the essential challenges of MCS\nwith respect to accommodating resource-constrained requestors or deal with the\nprivacy concerns brought by the involvement of requestors and workers in the\nlearning process. To fill the gaps, four main procedures, i.e., task\npublication, data sensing and submission, learning to return final results, and\npayment settlement and allocation, are designed to address major challenges\nbrought by both internal and external threats, such as malicious edge servers\nand dishonest requestors. Specifically, a mechanism design based data\nsubmission rule is proposed to guarantee the data privacy of mobile devices\nbeing truthfully preserved at edge servers; consortium blockchain based FL is\nelaborated to secure the distributed learning process; and a\ncooperation-enforcing control strategy is devised to elicit full payment from\nthe requestor. Extensive simulations are carried out to evaluate the\nperformance of our designed schemes.",
    "descriptor": "",
    "authors": [
      "Qin Hu",
      "Zhilin Wang",
      "Minghui Xu",
      "Xiuzhen Cheng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08671"
  },
  {
    "id": "arXiv:2110.08673",
    "title": "Scaling Blockchains: Can Elected Committees Help?",
    "abstract": "In the high-stakes race to develop more scalable blockchains, some platforms\n(Cosmos, EOS, TRON, etc.) have adopted committee-based consensus protocols,\nwhereby the blockchain's record-keeping rights are entrusted to a committee of\nelected block producers. In theory, the smaller the committee, the faster the\nblockchain can reach consensus and the more it can scale. What's less clear, is\nwhether this mechanism ensures that honest committees can be consistently\nelected, given voters typically have limited information. Using EOS' Delegated\nProof of Stake (DPoS) protocol as a backdrop, we show that identifying the\noptimal voting strategy is complex and practically out of reach. We empirically\ncharacterize some simpler (suboptimal) voting strategies that token holders\nresort to in practice and show that these nonetheless converge to optimality,\nexponentially quickly. This yields efficiency gains over other PoS protocols\nthat rely on randomized block producer selection. Our results suggest that\n(elected) committee-based consensus, as implemented in DPoS, can be robust and\nefficient, despite its complexity.",
    "descriptor": "",
    "authors": [
      "Alon Benhaim",
      "Brett Hemenway Falk",
      "Gerry Tsoukalas"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)",
      "Information Theory (cs.IT)",
      "General Economics (econ.GN)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2110.08673"
  },
  {
    "id": "arXiv:2110.08677",
    "title": "Algorithmic Thresholds for Refuting Random Polynomial Systems",
    "abstract": "Consider a system of $m$ polynomial equations $\\{p_i(x) = b_i\\}_{i \\leq m}$\nof degree $D\\geq 2$ in $n$-dimensional variable $x \\in \\mathbb{R}^n$ such that\neach coefficient of every $p_i$ and $b_i$s are chosen at random and\nindependently from some continuous distribution. We study the basic question of\ndetermining the smallest $m$ -- the algorithmic threshold -- for which\nefficient algorithms can find refutations (i.e. certificates of\nunsatisfiability) for such systems. This setting generalizes problems such as\nrefuting random SAT instances, low-rank matrix sensing and certifying\npseudo-randomness of Goldreich's candidate generators and generalizations.\nWe show that for every $d \\in \\mathbb{N}$, the $(n+m)^{O(d)}$-time canonical\nsum-of-squares (SoS) relaxation refutes such a system with high probability\nwhenever $m \\geq O(n) \\cdot (\\frac{n}{d})^{D-1}$. We prove a lower bound in the\nrestricted low-degree polynomial model of computation which suggests that this\ntrade-off between SoS degree and the number of equations is nearly tight for\nall $d$. We also confirm the predictions of this lower bound in a limited\nsetting by showing a lower bound on the canonical degree-$4$ sum-of-squares\nrelaxation for refuting random quadratic polynomials. Together, our results\nprovide evidence for an algorithmic threshold for the problem at $m \\gtrsim\n\\widetilde{O}(n) \\cdot n^{(1-\\delta)(D-1)}$ for $2^{n^{\\delta}}$-time\nalgorithms for all $\\delta$.",
    "descriptor": "",
    "authors": [
      "Jun-Ting Hsieh",
      "Pravesh K. Kothari"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.08677"
  },
  {
    "id": "arXiv:2110.08678",
    "title": "Transformer with a Mixture of Gaussian Keys",
    "abstract": "Multi-head attention is a driving force behind state-of-the-art transformers\nwhich achieve remarkable performance across a variety of natural language\nprocessing (NLP) and computer vision tasks. It has been observed that for many\napplications, those attention heads learn redundant embedding, and most of them\ncan be removed without degrading the performance of the model. Inspired by this\nobservation, we propose Transformer with a Mixture of Gaussian Keys\n(Transformer-MGK), a novel transformer architecture that replaces redundant\nheads in transformers with a mixture of keys at each head. These mixtures of\nkeys follow a Gaussian mixture model and allow each attention head to focus on\ndifferent parts of the input sequence efficiently. Compared to its conventional\ntransformer counterpart, Transformer-MGK accelerates training and inference,\nhas fewer parameters, and requires less FLOPs to compute while achieving\ncomparable or better accuracy across tasks. Transformer-MGK can also be easily\nextended to use with linear attentions. We empirically demonstrate the\nadvantage of Transformer-MGK in a range of practical applications including\nlanguage modeling and tasks that involve very long sequences. On the\nWikitext-103 and Long Range Arena benchmark, Transformer-MGKs with 4 heads\nattain comparable or better performance to the baseline transformers with 8\nheads.",
    "descriptor": "\nComments: 21 pages, 8 figures, 4 tables\n",
    "authors": [
      "Tam Nguyen",
      "Tan M. Nguyen",
      "Dung Le",
      "Khuong Nguyen",
      "Anh Tran",
      "Richard G. Baraniuk",
      "Nhat Ho",
      "Stanley J. Osher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.08678"
  },
  {
    "id": "arXiv:2110.08679",
    "title": "An Acceleration Method Based on Deep Learning and Multilinear Feature  Space",
    "abstract": "Computer vision plays a crucial role in Advanced Assistance Systems. Most\ncomputer vision systems are based on Deep Convolutional Neural Networks (deep\nCNN) architectures. However, the high computational resource to run a CNN\nalgorithm is demanding. Therefore, the methods to speed up computation have\nbecome a relevant research issue. Even though several works on architecture\nreduction found in the literature have not yet been achieved satisfactory\nresults for embedded real-time system applications. This paper presents an\nalternative approach based on the Multilinear Feature Space (MFS) method\nresorting to transfer learning from large CNN architectures. The proposed\nmethod uses CNNs to generate feature maps, although it does not work as\ncomplexity reduction approach. After the training process, the generated\nfeatures maps are used to create vector feature space. We use this new vector\nspace to make projections of any new sample to classify them. Our method, named\nAMFC, uses the transfer learning from pre-trained CNN to reduce the\nclassification time of new sample image, with minimal accuracy loss. Our method\nuses the VGG-16 model as the base CNN architecture for experiments; however,\nthe method works with any similar CNN model. Using the well-known Vehicle Image\nDatabase and the German Traffic Sign Recognition Benchmark, we compared the\nclassification time of the original VGG-16 model with the AMFC method, and our\nmethod is, on average, 17 times faster. The fast classification time reduces\nthe computational and memory demands in embedded applications requiring a large\nCNN architecture.",
    "descriptor": "\nComments: 20 pages, International Journal of Artificial Intelligence and Applications\n",
    "authors": [
      "Michel Vinagreiro Edson Kitani Armando Lagana Leopoldo Yoshioka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08679"
  },
  {
    "id": "arXiv:2110.08683",
    "title": "GP-MOOD: A positive-preserving high-order finite volume method for  hyperbolic conservation laws",
    "abstract": "We present an a posteriori shock-capturing finite volume method algorithm\ncalled GP-MOOD that solves a compressible hyperbolic conservative system at\nhigh-order solution accuracy (e.g., third-, fifth-, and seventh-order) in\nmultiple spatial dimensions. The GP-MOOD method combines two methodologies, the\npolynomial-free spatial reconstruction methods of GP (Gaussian Process) and the\na posteriori detection algorithms of MOOD (Multidimensional Optimal Order\nDetection). The spatial approximation of our GP-MOOD method uses GP's unlimited\nspatial reconstruction that builds upon our previous studies on GP reported in\nReyes et al., Journal of Scientific Computing, 76 (2017) and Journal of\nComputational Physics, 381 (2019). This paper focuses on extending GP's\nflexible variability of spatial accuracy to an a posteriori detection formalism\nbased on the MOOD approach. We show that GP's polynomial-free reconstruction\nprovides a seamless pathway to the MOOD's order cascading formalism by\nutilizing GP's novel property of variable (2R+1)th-order spatial accuracy on a\nmultidimensional GP stencil defined by the GP radius R, whose size is smaller\nthan that of the standard polynomial MOOD methods. The resulting GP-MOOD method\nis a positivity-preserving method. We examine the numerical stability and\naccuracy of GP-MOOD on smooth and discontinuous flows in multiple spatial\ndimensions without resorting to any conventional, computationally expensive a\npriori nonlinear limiting mechanism to maintain numerical stability.",
    "descriptor": "",
    "authors": [
      "R\u00e9mi Bourgeois",
      "Dongwook Lee"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.08683"
  },
  {
    "id": "arXiv:2110.08685",
    "title": "A Learning-based Approach Towards Automated Tuning of SSD Configurations",
    "abstract": "Thanks to the mature manufacturing techniques, solid-state drives (SSDs) are\nhighly customizable for applications today, which brings opportunities to\nfurther improve their storage performance and resource utilization. However,\nthe SSD efficiency is usually determined by many hardware parameters, making it\nhard for developers to manually tune them and determine the optimal SSD\nconfigurations.\nIn this paper, we present an automated learning-based framework, named\nLearnedSSD, that utilizes both supervised and unsupervised machine learning\n(ML) techniques to drive the tuning of hardware configurations for SSDs.\nLearnedSSD automatically extracts the unique access patterns of a new workload\nusing its block I/O traces, maps the workload to previously workloads for\nutilizing the learned experiences, and recommends an optimal SSD configuration\nbased on the validated storage performance. LearnedSSD accelerates the\ndevelopment of new SSD devices by automating the hard-ware parameter\nconfigurations and reducing the manual efforts. We develop LearnedSSD with\nsimple yet effective learning algorithms that can run efficiently on multi-core\nCPUs. Given a target storage workload, our evaluation shows that LearnedSSD can\nalways deliver an optimal SSD configuration for the target workload, and this\nconfiguration will not hurt the performance of non-target workloads.",
    "descriptor": "",
    "authors": [
      "Daixuan Li",
      "Jian Huang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)",
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2110.08685"
  },
  {
    "id": "arXiv:2110.08688",
    "title": "MG-GCN: Scalable Multi-GPU GCN Training Framework",
    "abstract": "Full batch training of Graph Convolutional Network (GCN) models is not\nfeasible on a single GPU for large graphs containing tens of millions of\nvertices or more. Recent work has shown that, for the graphs used in the\nmachine learning community, communication becomes a bottleneck and scaling is\nblocked outside of the single machine regime. Thus, we propose MG-GCN, a\nmulti-GPU GCN training framework taking advantage of the high-speed\ncommunication links between the GPUs present in multi-GPU systems. MG-GCN\nemploys multiple High-Performance Computing optimizations, including efficient\nre-use of memory buffers to reduce the memory footprint of training GNN models,\nas well as communication and computation overlap. These optimizations enable\nexecution on larger datasets, that generally do not fit into memory of a single\nGPU in state-of-the-art implementations. Furthermore, they contribute to\nachieve superior speedup compared to the state-of-the-art. For example, MG-GCN\nachieves super-linear speedup with respect to DGL, on the Reddit graph on both\nDGX-1 (V100) and DGX-A100.",
    "descriptor": "\nComments: 12 pages, 13 figures, Under Review\n",
    "authors": [
      "Muhammed Fatih Bal\u0131n",
      "Kaan Sancak",
      "\u00dcmit V. \u00c7ataly\u00fcrek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08688"
  },
  {
    "id": "arXiv:2110.08689",
    "title": "Classical-to-Quantum Transfer Learning for Spoken Command Recognition  Based on Quantum Neural Networks",
    "abstract": "This work investigates an extension of transfer learning applied in machine\nlearning algorithms to the emerging hybrid end-to-end quantum neural network\n(QNN) for spoken command recognition (SCR). Our QNN-based SCR system is\ncomposed of classical and quantum components: (1) the classical part mainly\nrelies on a 1D convolutional neural network (CNN) to extract speech features;\n(2) the quantum part is built upon the variational quantum circuit with a few\nlearnable parameters. Since it is inefficient to train the hybrid end-to-end\nQNN from scratch on a noisy intermediate-scale quantum (NISQ) device, we put\nforth a hybrid transfer learning algorithm that allows a pre-trained classical\nnetwork to be transferred to the classical part of the hybrid QNN model. The\npre-trained classical network is further modified and augmented through jointly\nfine-tuning with a variational quantum circuit (VQC). The hybrid transfer\nlearning methodology is particularly attractive for the task of QNN-based SCR\nbecause low-dimensional classical features are expected to be encoded into\nquantum states. We assess the hybrid transfer learning algorithm applied to the\nhybrid classical-quantum QNN for SCR on the Google speech command dataset, and\nour classical simulation results suggest that the hybrid transfer learning can\nboost our baseline performance on the SCR task.",
    "descriptor": "\nComments: submitted to ICASSP'22\n",
    "authors": [
      "Jun Qi",
      "Javier Tejedor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.08689"
  },
  {
    "id": "arXiv:2110.08690",
    "title": "Tackling the Imbalance for GNNs",
    "abstract": "Different from deep neural networks for non-graph data classification, graph\nneural networks (GNNs) leverage the information exchange between nodes (or\nsamples) when representing nodes. The category distribution shows an imbalance\nor even a highly-skewed trend on nearly all existing benchmark GNN data sets.\nThe imbalanced distribution will cause misclassification of nodes in the\nminority classes, and even cause the classification performance on the entire\ndata set to decrease. This study explores the effects of the imbalance problem\non the performances of GNNs and proposes new methodologies to solve it. First,\na node-level index, namely, the label difference index ($LDI$), is defined to\nquantitatively analyze the relationship between imbalance and\nmisclassification. The less samples in a class, the higher the value of its\naverage $LDI$; the higher the $LDI$ of a sample, the more likely the sample\nwill be misclassified. We define a new loss and propose four new methods based\non $LDI$. Experimental results indicate that the classification accuracies of\nthe three among our proposed four new methods are better in both transductive\nand inductive settings. The $LDI$ can be applied to other GNNs.",
    "descriptor": "",
    "authors": [
      "Rui Wang",
      "Weixuan Xiong",
      "Qinghu Hou",
      "Ou Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08690"
  },
  {
    "id": "arXiv:2110.08691",
    "title": "Terminal Embeddings in Sublinear Time",
    "abstract": "Recently (Elkin, Filtser, Neiman 2017) introduced the concept of a {\\it\nterminal embedding} from one metric space $(X,d_X)$ to another $(Y,d_Y)$ with a\nset of designated terminals $T\\subset X$. Such an embedding $f$ is said to have\ndistortion $\\rho\\ge 1$ if $\\rho$ is the smallest value such that there exists a\nconstant $C>0$ satisfying\n\\begin{equation*}\n\\forall x\\in T\\ \\forall q\\in X,\\ C d_X(x, q) \\le d_Y(f(x), f(q)) \\le C \\rho\nd_X(x, q) .\n\\end{equation*}\nIn the case that $X,Y$ are both Euclidean metrics with $Y$ being\n$m$-dimensional, recently (Narayanan, Nelson 2019), following work of\n(Mahabadi, Makarychev, Makarychev, Razenshteyn 2018), showed that distortion\n$1+\\epsilon$ is achievable via such a terminal embedding with $m =\nO(\\epsilon^{-2}\\log n)$ for $n := |T|$. This generalizes the\nJohnson-Lindenstrauss lemma, which only preserves distances within $T$ and not\nto $T$ from the rest of space. The downside is that evaluating the embedding on\nsome $q\\in \\mathbb{R}^d$ required solving a semidefinite program with\n$\\Theta(n)$ constraints in $m$ variables and thus required some superlinear\n$\\mathrm{poly}(n)$ runtime. Our main contribution in this work is to give a new\ndata structure for computing terminal embeddings. We show how to pre-process\n$T$ to obtain an almost linear-space data structure that supports computing the\nterminal embedding image of any $q\\in\\mathbb{R}^d$ in sublinear time\n$n^{1-\\Theta(\\epsilon^2)+o(1)} + dn^{o(1)}$. To accomplish this, we leverage\ntools developed in the context of approximate nearest neighbor search.",
    "descriptor": "\nComments: Accepted to FOCS 2021\n",
    "authors": [
      "Yeshwanth Cherapanamjeri",
      "Jelani Nelson"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.08691"
  },
  {
    "id": "arXiv:2110.08693",
    "title": "On the Statistical Analysis of Complex Tree-shaped 3D Objects",
    "abstract": "How can one analyze detailed 3D biological objects, such as neurons and\nbotanical trees, that exhibit complex geometrical and topological variation? In\nthis paper, we develop a novel mathematical framework for representing,\ncomparing, and computing geodesic deformations between the shapes of such\ntree-like 3D objects. A hierarchical organization of subtrees characterizes\nthese objects -- each subtree has the main branch with some side branches\nattached -- and one needs to match these structures across objects for\nmeaningful comparisons. We propose a novel representation that extends the\nSquare-Root Velocity Function (SRVF), initially developed for Euclidean curves,\nto tree-shaped 3D objects. We then define a new metric that quantifies the\nbending, stretching, and branch sliding needed to deform one tree-shaped object\ninto the other. Compared to the current metrics, such as the Quotient Euclidean\nDistance (QED) and the Tree Edit Distance (TED), the proposed representation\nand metric capture the full elasticity of the branches (i.e., bending and\nstretching) as well as the topological variations (i.e., branch death/birth and\nsliding). It completely avoids the shrinkage that results from the edge\ncollapse and node split operations of the QED and TED metrics. We demonstrate\nthe utility of this framework in comparing, matching, and computing geodesics\nbetween biological objects such as neurons and botanical trees. The framework\nis also applied to various shape analysis tasks: (i) symmetry analysis and\nsymmetrization of tree-shaped 3D objects, (ii) computing summary statistics\n(means and modes of variations) of populations of tree-shaped 3D objects, (iii)\nfitting parametric probability distributions to such populations, and (iv)\nfinally synthesizing novel tree-shaped 3D objects through random sampling from\nestimated probability distributions.",
    "descriptor": "",
    "authors": [
      "Guan Wang",
      "Hamid Laga",
      "Anuj Srivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Geometry (cs.CG)",
      "Graphics (cs.GR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.08693"
  },
  {
    "id": "arXiv:2110.08695",
    "title": "Towards Instance-Optimal Offline Reinforcement Learning with Pessimism",
    "abstract": "We study the offline reinforcement learning (offline RL) problem, where the\ngoal is to learn a reward-maximizing policy in an unknown Markov Decision\nProcess (MDP) using the data coming from a policy $\\mu$. In particular, we\nconsider the sample complexity problems of offline RL for finite-horizon MDPs.\nPrior works study this problem based on different data-coverage assumptions,\nand their learning guarantees are expressed by the covering coefficients which\nlack the explicit characterization of system quantities. In this work, we\nanalyze the Adaptive Pessimistic Value Iteration (APVI) algorithm and derive\nthe suboptimality upper bound that nearly matches \\[\nO\\left(\\sum_{h=1}^H\\sum_{s_h,a_h}d^{\\pi^\\star}_h(s_h,a_h)\\sqrt{\\frac{\\mathrm{Var}_{P_{s_h,a_h}}{(V^\\star_{h+1}+r_h)}}{d^\\mu_h(s_h,a_h)}}\\sqrt{\\frac{1}{n}}\\right).\n\\] In complementary, we also prove a per-instance information-theoretical lower\nbound under the weak assumption that $d^\\mu_h(s_h,a_h)>0$ if\n$d^{\\pi^\\star}_h(s_h,a_h)>0$. Different from the previous minimax lower bounds,\nthe per-instance lower bound (via local minimaxity) is a much stronger\ncriterion as it applies to individual instances separately. Here $\\pi^\\star$ is\na optimal policy, $\\mu$ is the behavior policy and $d_h^\\mu$ is the marginal\nstate-action probability. We call the above equation the intrinsic offline\nreinforcement learning bound since it directly implies all the existing optimal\nresults: minimax rate under uniform data-coverage assumption, horizon-free\nsetting, single policy concentrability, and the tight problem-dependent\nresults. Later, we extend the result to the assumption-free regime (where we\nmake no assumption on $ \\mu$) and obtain the assumption-free intrinsic bound.\nDue to its generic form, we believe the intrinsic bound could help illuminate\nwhat makes a specific problem hard and reveal the fundamental challenges in\noffline RL.",
    "descriptor": "\nComments: NeurIPS, 2021\n",
    "authors": [
      "Ming Yin",
      "Yu-Xiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.08695"
  },
  {
    "id": "arXiv:2110.08697",
    "title": "Improving Dither Modulation based Robust Steganography by Overflow  Suppression",
    "abstract": "Nowadays, people are sharing their pictures on online social networks (OSNs),\nso OSN is a good platform for Steganography. But OSNs usually perform JPEG\ncompression on the uploaded image, which will invalidate most of the existing\nsteganography algorithms. Recently, some works try to design robust\nsteganography which can resist JPEG compression, such as Dither\nModulation-based robust Adaptive Steganography (DMAS) and Generalized dither\nModulation-based robust Adaptive Steganography (GMAS). They relieve the problem\nthat the receivers cannot extract the message correctly when the quality factor\nof channel JPEG compression is larger than that of cover images. However, they\nonly can realize limited resistance to detection and compression due to robust\ndomain selection. To overcome this problem, we meticulously explore three lossy\noperations in the JPEG recompression and discover that the key problem is\nspatial overflow. Then two preprocessing methods Overall Scaling (OS) and\nSpecific Truncation (ST) are presented to remove overflow before message\nembedding as well as generate a reference image. The reference image is\nemployed as the guidance to build asymmetric distortion for removing overflow\nduring embedding. Experimental results show that the proposed methods\nsignificantly surpass GMAS in terms of security and achieve comparable\nrobustness.",
    "descriptor": "\nComments: submitted to IEEE TDSC on 18-Mar-2021\n",
    "authors": [
      "Kai Zeng",
      "Kejiang Chen",
      "Yaofei Wang",
      "Weiming Zhang",
      "Nenghai Yu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.08697"
  },
  {
    "id": "arXiv:2110.08698",
    "title": "State of the Art of Augmented Reality (AR) Capabilities for Civil  Infrastructure Applications",
    "abstract": "Augmented Reality (AR) is a technology superimposing interactional virtual\nobjects onto a real environment. Since the beginning of the millennium, AR\ntechnologies have shown rapid growth, with significant research publications in\nengineering and science. However, the civil infrastructure community has\nminimally implemented AR technologies to date. One of the challenges that civil\nengineers face when understanding and using AR is the lack of a classification\nof AR in the context of capabilities for civil infrastructure applications.\nPractitioners in civil infrastructure, like most engineering fields, prioritize\nunderstanding the level of maturity of a new technology before considering its\nadoption and field implementation. This paper compares the capabilities of\nsixteen AR Head-Mounted Devices (HMDs) available in the market since 2017,\nranking them in terms of performance for civil infrastructure implementations.\nFinally, the authors recommend a development framework for practical AR\ninterfaces with civil infrastructure and operations.",
    "descriptor": "\nComments: 17 pages, 5 figures, 4 tables\n",
    "authors": [
      "Jiaqi Xu",
      "Derek Doyle",
      "Fernando Moreu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "General Literature (cs.GL)"
    ],
    "url": "https://arxiv.org/abs/2110.08698"
  },
  {
    "id": "arXiv:2110.08700",
    "title": "Visualization of Real-time Displacement Time History superimposed with  Dynamic Experiments using Wireless Smart Sensors (WSS) and Augmented Reality  (AR)",
    "abstract": "Wireless Smart Sensors (WSS) process field data and inform structural\nengineers and owners about the infrastructure health and safety. In bridge\nengineering, inspectors make decisions using objective data from each bridge.\nThey decide about repairs and replacements and prioritize the maintenance of\ncertain structure elements on the basis of changes in displacements under\nloads. However, access to displacement information in the field and in\nreal-time remains a challenge. Displacement data provided by WSS in the field\nundergoes additional processing and is seen at a different location by an\ninspector and a sensor specialist. When the data is shared and streamed to the\nfield inspector, there is a inter-dependence between inspectors, sensor\nspecialists, and infrastructure owners, which limits the actionability of the\ndata related to the bridge condition. If inspectors were able to see structural\ndisplacements in real-time at the locations of interest, they could conduct\nadditional observations, which would create a new, information-based,\ndecision-making reality in the field. This paper develops a new, human-centered\ninterface that provides inspectors with real-time access to actionable\nstructural data (real-time displacements under loads) during inspection and\nmonitoring enhanced by Augmented Reality (AR). It summarizes the development\nand validation of the new human-infrastructure interface and evaluates its\nefficiency through laboratory experiments. The experiments demonstrate that the\ninterface accurately estimates dynamic displacements in comparison with the\nlaser. Using this new AR interface tool, inspectors can observe and compare\ndisplacement data, share it across space and time, and visualize displacements\nin time history.",
    "descriptor": "\nComments: 30 pages, 26 figures, 5 tables\n",
    "authors": [
      "M. Aguero",
      "D. Doyle",
      "D. Mascarenas",
      "F. Moreu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Databases (cs.DB)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.08700"
  },
  {
    "id": "arXiv:2110.08702",
    "title": "SIN:Superpixel Interpolation Network",
    "abstract": "Superpixels have been widely used in computer vision tasks due to their\nrepresentational and computational efficiency. Meanwhile, deep learning and\nend-to-end framework have made great progress in various fields including\ncomputer vision. However, existing superpixel algorithms cannot be integrated\ninto subsequent tasks in an end-to-end way. Traditional algorithms and deep\nlearning-based algorithms are two main streams in superpixel segmentation. The\nformer is non-differentiable and the latter needs a non-differentiable\npost-processing step to enforce connectivity, which constraints the integration\nof superpixels and downstream tasks. In this paper, we propose a deep\nlearning-based superpixel segmentation algorithm SIN which can be integrated\nwith downstream tasks in an end-to-end way. Owing to some downstream tasks such\nas visual tracking require real-time speed, the speed of generating superpixels\nis also important. To remove the post-processing step, our algorithm enforces\nspatial connectivity from the start. Superpixels are initialized by sampled\npixels and other pixels are assigned to superpixels through multiple updating\nsteps. Each step consists of a horizontal and a vertical interpolation, which\nis the key to enforcing spatial connectivity. Multi-layer outputs of a fully\nconvolutional network are utilized to predict association scores for\ninterpolations. Experimental results show that our approach runs at about 80fps\nand performs favorably against state-of-the-art methods. Furthermore, we design\na simple but effective loss function which reduces much training time. The\nimprovements of superpixel-based tasks demonstrate the effectiveness of our\nalgorithm. We hope SIN will be integrated into downstream tasks in an\nend-to-end way and benefit the superpixel-based community. Code is available\nat: \\href{https://github.com/yuanqqq/SIN}{https://github.com/yuanqqq/SIN}.",
    "descriptor": "\nComments: 15 pages, 8 figures, to be published in PRICAI-2021\n",
    "authors": [
      "Qing Yuan",
      "Songfeng Lu",
      "Yan Huang",
      "Wuxin Sha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08702"
  },
  {
    "id": "arXiv:2110.08704",
    "title": "A Q-Learning-based Approach for Distributed Beam Scheduling in mmWave  Networks",
    "abstract": "We consider the problem of distributed downlink beam scheduling and power\nallocation for millimeter-Wave (mmWave) cellular networks where multiple base\nstations (BSs) belonging to different service operators share the same\nunlicensed spectrum with no central coordination or cooperation among them. Our\ngoal is to design efficient distributed beam scheduling and power allocation\nalgorithms such that the network-level payoff, defined as the weighted sum of\nthe total throughput and a power penalization term, can be maximized. To this\nend, we propose a distributed scheduling approach to power allocation and\nadaptation for efficient interference management over the shared spectrum by\nmodeling each BS as an independent Q-learning agent. As a baseline, we compare\nthe proposed approach to the state-of-the-art non-cooperative game-based\napproach which was previously developed for the same problem. We conduct\nextensive experiments under various scenarios to verify the effect of multiple\nfactors on the performance of both approaches. Experiment results show that the\nproposed approach adapts well to different interference situations by learning\nfrom experience and can achieve higher payoff than the game-based approach. The\nproposed approach can also be integrated into our previously developed Lyapunov\nstochastic optimization framework for the purpose of network utility\nmaximization with optimality guarantee. As a result, the weights in the payoff\nfunction can be automatically and optimally determined by the virtual queue\nvalues from the sub-problems derived from the Lyapunov optimization framework.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Xiang Zhang",
      "Shamik Sarkar",
      "Arupjyoti Bhuyan",
      "Sneha Kumar Kasera",
      "Mingyue Ji"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08704"
  },
  {
    "id": "arXiv:2110.08707",
    "title": "Novel Secret-Key-Assisted Schemes for Secure MISOME-OFDM Systems",
    "abstract": "We propose a new secure transmission scheme for uplink multiple-input\nsingle-output (MISO) orthogonal-frequency multiplexing (OFDM) systems in the\npresence of multiple eavesdroppers. Our proposed scheme utilizes the\nsub-channels orthogonality of OFDM systems to simultaneously transmit data and\nsecret key symbols. The base station, Bob, shares secret key symbols with the\nlegitimate user, Alice, using wiretap coding over a portion of the\nsub-channels. Concurrently, Alice uses the accumulated secret keys in her\nsecret-key queue to encrypt data symbols using a one time pad (OTP) cipher and\ntransmits them to Bob over the remaining sub-channels. if Alice did not\naccumulate sufficient keys in her secret-key queue, she employs wiretap coding\nto secure her data transmissions. We propose fixed and dynamic sub-channel\nallocation schemes to divide the sub-channels between data and secret keys. We\nderive the secrecy outage probability (SOP) and the secure throughput for the\nproposed scheme. We quantify the system's security under practical non-Gaussian\ntransmissions where discrete signal constellation points are transmitted by the\nlegitimate source nodes. Numerical results validate our theoretical findings\nand quantify the impact of different system design parameters.",
    "descriptor": "",
    "authors": [
      "Mohamed Marzban",
      "Ahmed El Shafie",
      "Naofal Al-Dhahir"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.08707"
  },
  {
    "id": "arXiv:2110.08708",
    "title": "Robust Pedestrian Attribute Recognition Using Group Sparsity for  Occlusion Videos",
    "abstract": "Occlusion processing is a key issue in pedestrian attribute recognition\n(PAR). Nevertheless, several existing video-based PAR methods have not yet\nconsidered occlusion handling in depth. In this paper, we formulate finding\nnon-occluded frames as sparsity-based temporal attention of a crowded video. In\nthis manner, a model is guided not to pay attention to the occluded frame.\nHowever, temporal sparsity cannot include a correlation between attributes when\nocclusion occurs. For example, \"boots\" and \"shoe color\" cannot be recognized\nwhen the foot is invisible. To solve the uncorrelated attention issue, we also\npropose a novel group sparsity-based temporal attention module. Group sparsity\nis applied across attention weights in correlated attributes. Thus, attention\nweights in a group are forced to pay attention to the same frames. Experimental\nresults showed that the proposed method achieved a higher F1-score than the\nstate-of-the-art methods on two video-based PAR datasets and five occlusion\nscenarios.",
    "descriptor": "\nComments: 35 pages, 9 figures\n",
    "authors": [
      "Geonu Lee",
      "Kimin Yun",
      "Jungchan Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08708"
  },
  {
    "id": "arXiv:2110.08710",
    "title": "NeuralArTS: Structuring Neural Architecture Search with Type Theory",
    "abstract": "Neural Architecture Search (NAS) algorithms automate the task of finding\noptimal deep learning architectures given an initial search space of possible\noperations. Developing these search spaces is usually a manual affair with\npre-optimized search spaces being more efficient, rather than searching from\nscratch. In this paper we present a new framework called Neural Architecture\nType System (NeuralArTS) that categorizes the infinite set of network\noperations in a structured type system. We further demonstrate how NeuralArTS\ncan be applied to convolutional layers and propose several future directions.",
    "descriptor": "",
    "authors": [
      "Robert Wu",
      "Nayan Saxena",
      "Rohan Jain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.08710"
  },
  {
    "id": "arXiv:2110.08712",
    "title": "Black-box Adversarial Attacks on Network-wide Multi-step Traffic State  Prediction Models",
    "abstract": "Traffic state prediction is necessary for many Intelligent Transportation\nSystems applications. Recent developments of the topic have focused on\nnetwork-wide, multi-step prediction, where state of the art performance is\nachieved via deep learning models, in particular, graph neural network-based\nmodels. While the prediction accuracy of deep learning models is high, these\nmodels' robustness has raised many safety concerns, given that imperceptible\nperturbations added to input can substantially degrade the model performance.\nIn this work, we propose an adversarial attack framework by treating the\nprediction model as a black-box, i.e., assuming no knowledge of the model\narchitecture, training data, and (hyper)parameters. However, we assume that the\nadversary can oracle the prediction model with any input and obtain\ncorresponding output. Next, the adversary can train a substitute model using\ninput-output pairs and generate adversarial signals based on the substitute\nmodel. To test the attack effectiveness, two state of the art, graph neural\nnetwork-based models (GCGRNN and DCRNN) are examined. As a result, the\nadversary can degrade the target model's prediction accuracy up to $54\\%$. In\ncomparison, two conventional statistical models (linear regression and\nhistorical average) are also examined. While these two models do not produce\nhigh prediction accuracy, they are either influenced negligibly (less than\n$3\\%$) or are immune to the adversary's attack.",
    "descriptor": "\nComments: Accepted to IEEE International Conference on Intelligent Transportation Systems (ITSC), 2021\n",
    "authors": [
      "Bibek Poudel",
      "Weizi Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.08712"
  },
  {
    "id": "arXiv:2110.08716",
    "title": "Multifractal of mass function",
    "abstract": "Multifractal plays an important role in many fields. However, there is few\nattentions about mass function, which can better deal with uncertain\ninformation than probability. In this paper, we proposed multifractal of mass\nfunction. Firstly, the definition of multifractal spectrum of mass function is\ngiven. Secondly, the multifractal dimension of mass function is defined as\n$D_{\\alpha}$. When mass function degenerates to probability distribution,\n$D_{\\alpha}$ degenerates to $d_{\\alpha}$, which is information dimension\nproposed by Renyi. One interesting property is that the multifractal dimension\nof mass function with maximum Deng entropy is 1.585 no matter the order. Other\ninteresting properties and numerical examples are shown to illustrate proposed\nmodel.",
    "descriptor": "",
    "authors": [
      "Chenhui Qiang",
      "Yong Deng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.08716"
  },
  {
    "id": "arXiv:2110.08717",
    "title": "Hand Gesture Recognition Using Temporal Convolutions and Attention  Mechanism",
    "abstract": "Advances in biosignal signal processing and machine learning, in particular\nDeep Neural Networks (DNNs), have paved the way for the development of\ninnovative Human-Machine Interfaces for decoding the human intent and\ncontrolling artificial limbs. DNN models have shown promising results with\nrespect to other algorithms for decoding muscle electrical activity, especially\nfor recognition of hand gestures. Such data-driven models, however, have been\nchallenged by their need for a large number of trainable parameters and their\nstructural complexity. Here we propose the novel Temporal Convolutions-based\nHand Gesture Recognition architecture (TC-HGR) to reduce this computational\nburden. With this approach, we classified 17 hand gestures via surface\nElectromyogram (sEMG) signals by the adoption of attention mechanisms and\ntemporal convolutions. The proposed method led to 81.65% and 80.72%\nclassification accuracy for window sizes of 300ms and 200ms, respectively. The\nnumber of parameters to train the proposed TC-HGR architecture is 11.9 times\nless than that of its state-of-the-art counterpart.",
    "descriptor": "",
    "authors": [
      "Elahe Rahimian",
      "Soheil Zabihi",
      "Amir Asif",
      "Dario Farina",
      "S. Farokh Atashzar",
      "Arash Mohammadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.08717"
  },
  {
    "id": "arXiv:2110.08718",
    "title": "AE-StyleGAN: Improved Training of Style-Based Auto-Encoders",
    "abstract": "StyleGANs have shown impressive results on data generation and manipulation\nin recent years, thanks to its disentangled style latent space. A lot of\nefforts have been made in inverting a pretrained generator, where an encoder is\ntrained ad hoc after the generator is trained in a two-stage fashion. In this\npaper, we focus on style-based generators asking a scientific question: Does\nforcing such a generator to reconstruct real data lead to more disentangled\nlatent space and make the inversion process from image to latent space easy? We\ndescribe a new methodology to train a style-based autoencoder where the encoder\nand generator are optimized end-to-end. We show that our proposed model\nconsistently outperforms baselines in terms of image inversion and generation\nquality. Supplementary, code, and pretrained models are available on the\nproject website.",
    "descriptor": "\nComments: Accepted at WACV-22\n",
    "authors": [
      "Ligong Han",
      "Sri Harsha Musunuri",
      "Martin Renqiang Min",
      "Ruijiang Gao",
      "Yu Tian",
      "Dimitris Metaxas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.08718"
  },
  {
    "id": "arXiv:2110.08719",
    "title": "CLASP: Constrained Latent Shape Projection for Refining Object Shape  from Robot Contact",
    "abstract": "Robots need both visual and contact sensing to effectively estimate the state\nof their environment. Camera RGBD data provides rich information of the objects\nsurrounding the robot, and shape priors can help correct noise and fill in gaps\nand occluded regions. However, when the robot senses unexpected contact, the\nestimate should be updated to explain the contact. To address this need, we\npropose CLASP: Constrained Latent Shape Projection. This approach consists of a\nshape completion network that generates a prior from RGBD data and a procedure\nto generate shapes consistent with both the network prior and robot contact\nobservations. We find CLASP consistently decreases the Chamfer Distance between\nthe predicted and ground truth scenes, while other approaches do not benefit\nfrom contact information.",
    "descriptor": "\nComments: 16 pages, 10 figures, Accepted at the Conference on Robot Learning (CoRL) 2021\n",
    "authors": [
      "Brad Saund",
      "Dmitry Berenson"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.08719"
  },
  {
    "id": "arXiv:2110.08720",
    "title": "Centroid Approximation for Bootstrap",
    "abstract": "Bootstrap is a principled and powerful frequentist statistical tool for\nuncertainty quantification. Unfortunately, standard bootstrap methods are\ncomputationally intensive due to the need of drawing a large i.i.d. bootstrap\nsample to approximate the ideal bootstrap distribution; this largely hinders\ntheir application in large-scale machine learning, especially deep learning\nproblems. In this work, we propose an efficient method to explicitly\n\\emph{optimize} a small set of high quality \"centroid\" points to better\napproximate the ideal bootstrap distribution. We achieve this by minimizing a\nsimple objective function that is asymptotically equivalent to the Wasserstein\ndistance to the ideal bootstrap distribution. This allows us to provide an\naccurate estimation of uncertainty with a small number of bootstrap centroids,\noutperforming the naive i.i.d. sampling approach. Empirically, we show that our\nmethod can boost the performance of bootstrap in a variety of applications.",
    "descriptor": "",
    "authors": [
      "Mao Ye",
      "Qiang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.08720"
  },
  {
    "id": "arXiv:2110.08725",
    "title": "A Riemannian Mean Field Formulation for Two-layer Neural Networks with  Batch Normalization",
    "abstract": "The training dynamics of two-layer neural networks with batch normalization\n(BN) is studied. It is written as the training dynamics of a neural network\nwithout BN on a Riemannian manifold. Therefore, we identify BN's effect of\nchanging the metric in the parameter space. Later, the infinite-width limit of\nthe two-layer neural networks with BN is considered, and a mean-field\nformulation is derived for the training dynamics. The training dynamics of the\nmean-field formulation is shown to be the Wasserstein gradient flow on the\nmanifold. Theoretical analysis are provided on the well-posedness and\nconvergence of the Wasserstein gradient flow.",
    "descriptor": "",
    "authors": [
      "Chao Ma",
      "Lexing Ying"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08725"
  },
  {
    "id": "arXiv:2110.08727",
    "title": "Graph-less Neural Networks: Teaching Old MLPs New Tricks via  Distillation",
    "abstract": "Graph Neural Networks (GNNs) have recently become popular for graph machine\nlearning and have shown great results on wide node classification tasks. Yet,\nGNNs are less popular for practical deployments in the industry owing to their\nscalability challenges incurred by data dependency. Namely, GNN inference\ndepends on neighbor nodes multiple hops away from the target, and fetching\nthese nodes burdens latency-constrained applications. Existing inference\nacceleration methods like pruning and quantization can speed up GNNs to some\nextent by reducing Multiplication-and-ACcumulation (MAC) operations. However,\ntheir improvements are limited given the data dependency is not resolved.\nConversely, multi-layer perceptrons (MLPs) have no dependency on graph data and\ninfer much faster than GNNs, even though they are less accurate than GNNs for\nnode classification in general. Motivated by these complementary strengths and\nweaknesses, we bring GNNs and MLPs together via knowledge distillation (KD).\nOur work shows that the performance of MLPs can be improved by large margins\nwith GNN KD. We call the distilled MLPs Graph-less Neural Networks (GLNNs) as\nthey have no inference graph dependency. We show that GLNN with competitive\nperformance infer faster than GNNs by 146X-273X and faster than other\nacceleration methods by 14X-27X. Meanwhile, under a production setting\ninvolving both transductive and inductive predictions across 7 datasets, GLNN\naccuracies improve over stand alone MLPs by 12.36% on average and match GNNs on\n6/7 datasets. A comprehensive analysis of GLNN shows when and why GLNN can\nachieve competitive results to GNNs and suggests GLNN as a handy choice for\nlatency-constrained applications.",
    "descriptor": "",
    "authors": [
      "Shichang Zhang",
      "Yozen Liu",
      "Yizhou Sun",
      "Neil Shah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08727"
  },
  {
    "id": "arXiv:2110.08729",
    "title": "VoteHMR: Occlusion-Aware Voting Network for Robust 3D Human Mesh  Recovery from Partial Point Clouds",
    "abstract": "3D human mesh recovery from point clouds is essential for various tasks,\nincluding AR/VR and human behavior understanding. Previous works in this field\neither require high-quality 3D human scans or sequential point clouds, which\ncannot be easily applied to low-quality 3D scans captured by consumer-level\ndepth sensors. In this paper, we make the first attempt to reconstruct reliable\n3D human shapes from single-frame partial point clouds.To achieve this, we\npropose an end-to-end learnable method, named VoteHMR. The core of VoteHMR is a\nnovel occlusion-aware voting network that can first reliably produce visible\njoint-level features from the input partial point clouds, and then complete the\njoint-level features through the kinematic tree of the human skeleton. Compared\nwith holistic features used by previous works, the joint-level features can not\nonly effectively encode the human geometry information but also be robust to\nnoisy inputs with self-occlusions and missing areas. By exploiting the rich\ncomplementary clues from the joint-level features and global features from the\ninput point clouds, the proposed method encourages reliable and disentangled\nparameter predictions for statistical 3D human models, such as SMPL. The\nproposed method achieves state-of-the-art performances on two large-scale\ndatasets, namely SURREAL and DFAUST. Furthermore, VoteHMR also demonstrates\nsuperior generalization ability on real-world datasets, such as Berkeley MHAD.",
    "descriptor": "\nComments: Our paper are accepted to MM 2021 as oral\n",
    "authors": [
      "Guanze Liu",
      "Yu Rong",
      "Lu Sheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08729"
  },
  {
    "id": "arXiv:2110.08731",
    "title": "Improving End-To-End Modeling for Mispronunciation Detection with  Effective Augmentation Mechanisms",
    "abstract": "Recently, end-to-end (E2E) models, which allow to take spectral vector\nsequences of L2 (second-language) learners' utterances as input and produce the\ncorresponding phone-level sequences as output, have attracted much research\nattention in developing mispronunciation detection (MD) systems. However, due\nto the lack of sufficient labeled speech data of L2 speakers for model\nestimation, E2E MD models are prone to overfitting in relation to conventional\nones that are built on DNN-HMM acoustic models. To alleviate this critical\nissue, we in this paper propose two modeling strategies to enhance the\ndiscrimination capability of E2E MD models, each of which can implicitly\nleverage the phonetic and phonological traits encoded in a pretrained acoustic\nmodel and contained within reference transcripts of the training data,\nrespectively. The first one is input augmentation, which aims to distill\nknowledge about phonetic discrimination from a DNN-HMM acoustic model. The\nsecond one is label augmentation, which manages to capture more phonological\npatterns from the transcripts of training data. A series of empirical\nexperiments conducted on the L2-ARCTIC English dataset seem to confirm the\nefficacy of our E2E MD model when compared to some top-of-the-line E2E MD\nmodels and a classic pronunciation-scoring based method built on a DNN-HMM\nacoustic model.",
    "descriptor": "\nComments: 7 pages, 2 figures, 4 tables, accepted to Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC 2021)\n",
    "authors": [
      "Tien-Hong Lo",
      "Yao-Ting Sung",
      "Berlin Chen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.08731"
  },
  {
    "id": "arXiv:2110.08732",
    "title": "A Deep Learning-based Approach for Real-time Facemask Detection",
    "abstract": "The COVID-19 pandemic is causing a global health crisis. Public spaces need\nto be safeguarded from the adverse effects of this pandemic. Wearing a facemask\nbecomes one of the effective protection solutions adopted by many governments.\nManual real-time monitoring of facemask wearing for a large group of people is\nbecoming a difficult task. The goal of this paper is to use deep learning (DL),\nwhich has shown excellent results in many real-life applications, to ensure\nefficient real-time facemask detection. The proposed approach is based on two\nsteps. An off-line step aiming to create a DL model that is able to detect and\nlocate facemasks and whether they are appropriately worn. An online step that\ndeploys the DL model at edge computing in order to detect masks in real-time.\nIn this study, we propose to use MobileNetV2 to detect facemask in real-time.\nSeveral experiments are conducted and show good performances of the proposed\napproach (99% for training and testing accuracy). In addition, several\ncomparisons with many state-of-the-art models namely ResNet50, DenseNet, and\nVGG16 show good performance of the MobileNetV2 in terms of training time and\naccuracy.",
    "descriptor": "",
    "authors": [
      "Wadii Boulila",
      "Ayyub Alzahem",
      "Aseel Almoudi",
      "Muhanad Afifi",
      "Ibrahim Alturki",
      "Maha Driss"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08732"
  },
  {
    "id": "arXiv:2110.08733",
    "title": "LoveDA: A Remote Sensing Land-Cover Dataset for Domain Adaptive Semantic  Segmentation",
    "abstract": "Deep learning approaches have shown promising results in remote sensing high\nspatial resolution (HSR) land-cover mapping. However, urban and rural scenes\ncan show completely different geographical landscapes, and the inadequate\ngeneralizability of these algorithms hinders city-level or national-level\nmapping. Most of the existing HSR land-cover datasets mainly promote the\nresearch of learning semantic representation, thereby ignoring the model\ntransferability. In this paper, we introduce the Land-cOVEr Domain Adaptive\nsemantic segmentation (LoveDA) dataset to advance semantic and transferable\nlearning. The LoveDA dataset contains 5927 HSR images with 166768 annotated\nobjects from three different cities. Compared to the existing datasets, the\nLoveDA dataset encompasses two domains (urban and rural), which brings\nconsiderable challenges due to the: 1) multi-scale objects; 2) complex\nbackground samples; and 3) inconsistent class distributions. The LoveDA dataset\nis suitable for both land-cover semantic segmentation and unsupervised domain\nadaptation (UDA) tasks. Accordingly, we benchmarked the LoveDA dataset on\neleven semantic segmentation methods and eight UDA methods. Some exploratory\nstudies including multi-scale architectures and strategies, additional\nbackground supervision, and pseudo-label analysis were also carried out to\naddress these challenges. The code and data are available at\nhttps://github.com/Junjue-Wang/LoveDA.",
    "descriptor": "\nComments: Accepted by NeurIPS 2021 Datasets and Benchmarks Track\n",
    "authors": [
      "Junjue Wang",
      "Zhuo zheng",
      "Ailong Ma",
      "Xiaoyan Lu",
      "Yanfei Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08733"
  },
  {
    "id": "arXiv:2110.08741",
    "title": "Minimal Conditions for Beneficial Local Search",
    "abstract": "This paper investigates why it is beneficial, when solving a problem, to\nsearch in the neighbourhood of a current solution. The paper identifies\nproperties of problems and neighbourhoods that support two novel proofs that\nneighbourhood search is beneficial over blind search. These are: firstly a\nproof that search within the neighbourhood is more likely to find an improving\nsolution in a single search step than blind search; and secondly a proof that a\nlocal improvement, using a sequence of neighbourhood search steps, is likely to\nachieve a greater improvement than a sequence of blind search steps. To explore\nthe practical impact of these properties, a range of problem sets and\nneighbourhoods are generated, where these properties are satisfied to different\ndegrees. Experiments reveal that the benefits of neighbourhood search vary\ndramatically in consequence. Random problems of a classical combinatorial\noptimisation problem are analysed, in order to demonstrate that the underlying\ntheory is reflected in practice.",
    "descriptor": "\nComments: 31 pages plus 18 pages of appendix\n",
    "authors": [
      "Mark G Wallace"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.08741"
  },
  {
    "id": "arXiv:2110.08743",
    "title": "GNN-LM: Language Modeling based on Global Contexts via GNN",
    "abstract": "Inspired by the notion that ``{\\it to copy is easier than to memorize}``, in\nthis work, we introduce GNN-LM, which extends the vanilla neural language model\n(LM) by allowing to reference similar contexts in the entire training corpus.\nWe build a directed heterogeneous graph between an input context and its\nsemantically related neighbors selected from the training corpus, where nodes\nare tokens in the input context and retrieved neighbor contexts, and edges\nrepresent connections between nodes. Graph neural networks (GNNs) are\nconstructed upon the graph to aggregate information from similar contexts to\ndecode the token. This learning paradigm provides direct access to the\nreference contexts and helps improve a model's generalization ability. We\nconduct comprehensive experiments to validate the effectiveness of the GNN-LM:\nGNN-LM achieves a new state-of-the-art perplexity of 14.8 on WikiText-103 (a\n4.5 point improvement over its counterpart of the vanilla LM model) and shows\nsubstantial improvement on One Billion Word and Enwiki8 datasets against strong\nbaselines. In-depth ablation studies are performed to understand the mechanics\nof GNN-LM.",
    "descriptor": "",
    "authors": [
      "Yuxian Meng",
      "Shi Zong",
      "Xiaoya Li",
      "Xiaofei Sun",
      "Tianwei Zhang",
      "Fei Wu",
      "Jiwei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08743"
  },
  {
    "id": "arXiv:2110.08744",
    "title": "A model for full local image interpretation",
    "abstract": "We describe a computational model of humans' ability to provide a detailed\ninterpretation of components in a scene. Humans can identify in an image\nmeaningful components almost everywhere, and identifying these components is an\nessential part of the visual process, and of understanding the surrounding\nscene and its potential meaning to the viewer. Detailed interpretation is\nbeyond the scope of current models of visual recognition. Our model suggests\nthat this is a fundamental limitation, related to the fact that existing models\nrely on feed-forward but limited top-down processing. In our model, a first\nrecognition stage leads to the initial activation of class candidates, which is\nincomplete and with limited accuracy. This stage then triggers the application\nof class-specific interpretation and validation processes, which recover richer\nand more accurate interpretation of the visible scene. We discuss implications\nof the model for visual interpretation by humans and by computer vision models.",
    "descriptor": "\nComments: Published in the Proceedings of the 37th Annual Meeting of the Cognitive Science Society (CogSci), 2015\n",
    "authors": [
      "Guy Ben-Yosef",
      "Liav Assif",
      "Daniel Harari",
      "Shimon Ullman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2110.08744"
  },
  {
    "id": "arXiv:2110.08745",
    "title": "Reminding the Incremental Language Model via Data-Free Self-Distillation",
    "abstract": "Incremental language learning with pseudo-data can alleviate catastrophic\nforgetting in neural networks. However, to obtain better performance, former\nmethods have higher demands for pseudo-data of the previous tasks. The\nperformance dramatically decreases when fewer pseudo-data are employed. In\naddition, the distribution of pseudo-data gradually deviates from the real data\nwith the sequential learning of different tasks. The deviation will be greater\nwith more tasks learned, which results in more serious catastrophic forgetting.\nTo address these issues, we propose reminding incremental language model via\ndata-free self-distillation (DFSD), which includes self-distillation based on\nthe Earth Mover's Distance and hidden data augmentation. By estimating the\nknowledge distribution in all layers of GPT-2 and transforming it from teacher\nmodel to student model, the Self-distillation based on the Earth Mover's\nDistance can significantly reduce the demand for pseudo-data. Hidden data\naugmentation can greatly alleviate the catastrophic forgetting caused by\ndeviations via modeling the generation of pseudo-data as a hidden data\naugmentation process, where each sample is a mixture of all trained task data.\nThe experimental results demonstrate that our DFSD can exceed the previous\nstate-of-the-art methods even if the maximum decrease in pseudo-data is 90%.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Han Wang",
      "Ruiliu Fu",
      "Chengzhang Li",
      "Xuejun Zhang",
      "Jun Zhou",
      "Yonghong Yan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08745"
  },
  {
    "id": "arXiv:2110.08746",
    "title": "Spectral Efficiency of OTFS Based Orthogonal Multiple Access with  Rectangular Pulses",
    "abstract": "In this paper we consider Orthogonal Time Frequency Space (OTFS) modulation\nbased multiple-access (MA). We specifically consider Orthogonal MA methods\n(OMA) where the user terminals (UTs) are allocated non-overlapping physical\nresource in the delay-Doppler (DD) and/or time-frequency (TF) domain. To the\nbest of our knowledge, in prior literature, the performance of OMA methods have\nbeen reported only for ideal transmit and receive pulses. In [20] and [21], OMA\nmethods were proposed which were shown to achieve multi-user interference (MUI)\nfree communication with ideal pulses. Since ideal pulses are not realizable, in\nthis paper we study the spectral efficiency (SE) performance of these OMA\nmethods with practical rectangular pulses. For these OMA methods, we derive the\nexpression for the received DD domain symbols at the base station (BS) receiver\nand the effective DD domain channel matrix when rectangular pulses are used. We\nthen derive the expression for the achievable sum SE. These expressions are\nalso derived for another well known OMA method where guard bands (GB) are used\nto reduce MUI (called as the GB based MA methods) [19]. Through simulations, we\nobserve that with rectangular pulses the sum SE achieved by the method in [21]\nis almost invariant of the Doppler shift and is higher than that achieved by\nthe methods in [19], [20] at practical values of the received signal-to-noise\nratio.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Venkatesh Khammammetti",
      "Saif Khan Mohammed"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.08746"
  },
  {
    "id": "arXiv:2110.08750",
    "title": "TIP: Task-Informed Motion Prediction for Intelligent Systems",
    "abstract": "Motion prediction is important for intelligent driving systems, providing the\nfuture distributions of road agent behaviors and supporting various decision\nmaking tasks. Existing motion predictors are often optimized and evaluated via\ntask-agnostic measures based on prediction accuracy. Such measures fail to\naccount for the use of prediction in downstream tasks, and could result in\nsub-optimal task performance. We propose a task-informed motion prediction\nframework that jointly reasons about prediction accuracy and task utility, to\nbetter support downstream tasks through its predictions. The task utility\nfunction does not require the full task information, but rather a specification\nof the utility of the task, resulting in predictors that serve a wide range of\ndownstream tasks. We demonstrate our framework on two use cases of task\nutilities, in the context of autonomous driving and parallel autonomy, and show\nthe advantage of task-informed predictors over task-agnostic ones on the Waymo\nOpen Motion dataset.",
    "descriptor": "\nComments: 8 pages, 6 figures, 2 tables\n",
    "authors": [
      "Xin Huang",
      "Guy Rosman",
      "Ashkan Jasour",
      "Stephen G. McGill",
      "John J. Leonard",
      "Brian C. Williams"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08750"
  },
  {
    "id": "arXiv:2110.08753",
    "title": "Understanding Players' Interaction Patterns with Mobile Game App UI via  Visualizations",
    "abstract": "Understanding how players interact with the mobile game app on smartphone\ndevices is important for game experts to develop and refine their app products.\nConventionally, the game experts achieve their purposes through intensive user\nstudies with target players or iterative UI design processes, which can not\ncapture interaction patterns of large-scale individual players. Visualizing the\nrecorded logs of users' UI operations is a promising way for quantitatively\nunderstanding the interaction patterns. However, few visualization tools have\nbeen developed for mobile game app interaction, which is challenging with\nmulti-touch dynamic operations and complex UI. In this work, we fill the gap by\npresenting a visualization approach that aims to understand players'\ninteraction patterns in a multi-touch gaming app with more complex interactions\nsupported by joysticks and a series of skill buttons. Particularly, we identify\nplayers' dynamic gesture patterns, inspect the similarities and differences of\ngesture behaviors, and explore the potential gaps between the current mobile\ngame app UI design and the real-world practice of players. Three case studies\nindicate that our approach is promising and can be potentially complementary to\ntheoretical UI designs for further research.",
    "descriptor": "\nComments: Chinese CHI 2021\n",
    "authors": [
      "Quan Li",
      "Haipeng Zeng",
      "Zhenhui Peng",
      "Xiaojuan Ma"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.08753"
  },
  {
    "id": "arXiv:2110.08754",
    "title": "Fully-Connected Tensor Network Decomposition for Robust Tensor  Completion Problem",
    "abstract": "The robust tensor completion (RTC) problem, which aims to reconstruct a\nlow-rank tensor from partially observed tensor contaminated by a sparse tensor,\nhas received increasing attention. In this paper, by leveraging the superior\nexpression of the fully-connected tensor network (FCTN) decomposition, we\npropose a $\\textbf{FCTN}$-based $\\textbf{r}$obust $\\textbf{c}$onvex\noptimization model (RC-FCTN) for the RTC problem. Then, we rigorously establish\nthe exact recovery guarantee for the RC-FCTN. For solving the constrained\noptimization model RC-FCTN, we develop an alternating direction method of\nmultipliers (ADMM)-based algorithm, which enjoys the global convergence\nguarantee. Moreover, we suggest a $\\textbf{FCTN}$-based $\\textbf{r}$obust\n$\\textbf{n}$on$\\textbf{c}$onvex optimization model (RNC-FCTN) for the RTC\nproblem. A proximal alternating minimization (PAM)-based algorithm is developed\nto solve the proposed RNC-FCTN. Meanwhile, we theoretically derive the\nconvergence of the PAM-based algorithm. Comprehensive numerical experiments in\nseveral applications, such as video completion and video background\nsubtraction, demonstrate that proposed methods are superior to several\nstate-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Yun-Yang Liu",
      "Xi-Le Zhao",
      "Guang-Jing Song",
      "Yu-Bang Zheng",
      "Ting-Zhu Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08754"
  },
  {
    "id": "arXiv:2110.08756",
    "title": "Stability evaluation of the Russian sociologists online community:  2011-2018 years",
    "abstract": "This study deals with the stability evaluation of the online community of\nRussian sociologists. Based on the data from the Facebook group, which consists\nof 7 years of communication from 2011 till 2018, we constructed the networks\nbased on commenting and reacting. The participants activity includes four main\nperiods for stability evaluation of the community. The blockmodeling discloses\nthe structural patterns of interactions in the community. The results show the\n\"core-periphery\" type of the global structure. The core and periphery are\nstructured differently in the networks of comments and reactions. The stability\nbetween the positions in the global structure is high and while the structure\nmay vary in some periods, the size of the core and periphery fluctuates.\nHowever, the stability within the positions of the global structure is low,\naccording to the modified Rand index (Cugmas, Ferligoj, 2018).",
    "descriptor": "\nComments: submitted to Journal of Community Practice\n",
    "authors": [
      "Aryuna Kim",
      "Daria Maltseva"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.08756"
  },
  {
    "id": "arXiv:2110.08760",
    "title": "Adapting Membership Inference Attacks to GNN for Graph Classification:  Approaches and Implications",
    "abstract": "Graph Neural Networks (GNNs) are widely adopted to analyse non-Euclidean\ndata, such as chemical networks, brain networks, and social networks, modelling\ncomplex relationships and interdependency between objects. Recently, Membership\nInference Attack (MIA) against GNNs raises severe privacy concerns, where\ntraining data can be leaked from trained GNN models. However, prior studies\nfocus on inferring the membership of only the components in a graph, e.g., an\nindividual node or edge. How to infer the membership of an entire graph record\nis yet to be explored.\nIn this paper, we take the first step in MIA against GNNs for graph-level\nclassification. Our objective is to infer whether a graph sample has been used\nfor training a GNN model. We present and implement two types of attacks, i.e.,\ntraining-based attacks and threshold-based attacks from different adversarial\ncapabilities. We perform comprehensive experiments to evaluate our attacks in\nseven real-world datasets using five representative GNN models. Both our\nattacks are shown effective and can achieve high performance, i.e., reaching\nover 0.7 attack F1 scores in most cases. Furthermore, we analyse the\nimplications behind the MIA against GNNs. Our findings confirm that GNNs can be\neven more vulnerable to MIA than the models with non-graph structures. And\nunlike the node-level classifier, MIAs on graph-level classification tasks are\nmore co-related with the overfitting level of GNNs rather than the statistic\nproperty of their training graphs.",
    "descriptor": "\nComments: The short version of this paper has been published in the IEEE International Conference on Data Mining (ICDM) 2021\n",
    "authors": [
      "Bang Wu",
      "Xiangwen Yang",
      "Shirui Pan",
      "Xingliang Yuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.08760"
  },
  {
    "id": "arXiv:2110.08762",
    "title": "Inconsistency-aware Uncertainty Estimation for Semi-supervised Medical  Image Segmentation",
    "abstract": "In semi-supervised medical image segmentation, most previous works draw on\nthe common assumption that higher entropy means higher uncertainty. In this\npaper, we investigate a novel method of estimating uncertainty. We observe\nthat, when assigned different misclassification costs in a certain degree, if\nthe segmentation result of a pixel becomes inconsistent, this pixel shows a\nrelative uncertainty in its segmentation. Therefore, we present a new\nsemi-supervised segmentation model, namely, conservative-radical network\n(CoraNet in short) based on our uncertainty estimation and separate\nself-training strategy. In particular, our CoraNet model consists of three\nmajor components: a conservative-radical module (CRM), a certain region\nsegmentation network (C-SN), and an uncertain region segmentation network\n(UC-SN) that could be alternatively trained in an end-to-end manner. We have\nextensively evaluated our method on various segmentation tasks with publicly\navailable benchmark datasets, including CT pancreas, MR endocardium, and MR\nmulti-structures segmentation on the ACDC dataset. Compared with the current\nstate of the art, our CoraNet has demonstrated superior performance. In\naddition, we have also analyzed its connection with and difference from\nconventional methods of uncertainty estimation in semi-supervised medical image\nsegmentation.",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Medical Imaging (TMI)\n",
    "authors": [
      "Yinghuan Shi",
      "Jian Zhang",
      "Tong Ling",
      "Jiwen Lu",
      "Yefeng Zheng",
      "Qian Yu",
      "Lei Qi",
      "Yang Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08762"
  },
  {
    "id": "arXiv:2110.08764",
    "title": "S-Cyc: A Learning Rate Schedule for Iterative Pruning of ReLU-based  Networks",
    "abstract": "We explore a new perspective on adapting the learning rate (LR) schedule to\nimprove the performance of the ReLU-based network as it is iteratively pruned.\nOur work and contribution consist of four parts: (i) We find that, as the\nReLU-based network is iteratively pruned, the distribution of weight gradients\ntends to become narrower. This leads to the finding that as the network becomes\nmore sparse, a larger value of LR should be used to train the pruned network.\n(ii) Motivated by this finding, we propose a novel LR schedule, called\nS-Cyclical (S-Cyc) which adapts the conventional cyclical LR schedule by\ngradually increasing the LR upper bound (max_lr) in an S-shape as the network\nis iteratively pruned.We highlight that S-Cyc is a method agnostic LR schedule\nthat applies to many iterative pruning methods. (iii) We evaluate the\nperformance of the proposed S-Cyc and compare it to four LR schedule\nbenchmarks. Our experimental results on three state-of-the-art networks (e.g.,\nVGG-19, ResNet-20, ResNet-50) and two popular datasets (e.g., CIFAR-10,\nImageNet-200) demonstrate that S-Cyc consistently outperforms the best\nperforming benchmark with an improvement of 2.1% - 3.4%, without substantial\nincrease in complexity. (iv) We evaluate S-Cyc against an oracle and show that\nS-Cyc achieves comparable performance to the oracle, which carefully tunes\nmax_lr via grid search.",
    "descriptor": "\nComments: 7 pages main paper with 5 pages appendix\n",
    "authors": [
      "Shiyu Liu",
      "Chong Min John Tan",
      "Mehul Motani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.08764"
  },
  {
    "id": "arXiv:2110.08765",
    "title": "Temporal Knowledge Graph Reasoning Triggered by Memories",
    "abstract": "Inferring missing facts in temporal knowledge graphs is a critical task and\nhas been widely explored. Extrapolation in temporal reasoning tasks is more\nchallenging and gradually attracts the attention of researchers since no direct\nhistory facts for prediction. Previous works attempted to apply evolutionary\nrepresentation learning to solve the extrapolation problem. However, these\ntechniques do not explicitly leverage various time-aware attribute\nrepresentations, i.e. the reasoning performance is significantly affected by\nthe history length. To alleviate the time dependence when reasoning future\nmissing facts, we propose a memory-triggered decision-making (MTDM) network,\nwhich incorporates transient memories, long-short-term memories, and deep\nmemories. Specifically, the transient learning network considers transient\nmemories as a static knowledge graph, and the time-aware recurrent evolution\nnetwork learns representations through a sequence of recurrent evolution units\nfrom long-short-term memories. Each evolution unit consists of a structural\nencoder to aggregate edge information, a time encoder with a gating unit to\nupdate attribute representations of entities. MTDM utilizes the crafted\nresidual multi-relational aggregator as the structural encoder to solve the\nmulti-hop coverage problem. We also introduce the dissolution learning\nconstraint for better understanding the event dissolution process. Extensive\nexperiments demonstrate the MTDM alleviates the history dependence and achieves\nstate-of-the-art prediction performance. Moreover, compared with the most\nadvanced baseline, MTDM shows a faster convergence speed and training speed.",
    "descriptor": "",
    "authors": [
      "Mengnan Zhao",
      "Lihe Zhang",
      "Yuqiu Kong",
      "Baocai Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.08765"
  },
  {
    "id": "arXiv:2110.08768",
    "title": "A Framework of Mahalanobis-Distance Metric with Supervised Learning for  Clustering Multipath Components in MIMO Channel Analysis",
    "abstract": "As multipath components (MPCs) are experimentally observed to appear in\nclusters, cluster-based channel models have been focused in the wireless\nchannel study. However, most of the MPC clustering algorithms for MIMO channels\nwith delay and angle information of MPCs are based on the distance metric that\nquantifies the similarity of two MPCs and determines the preferred cluster\nshape, greatly impacting MPC clustering quality. In this paper, a general\nframework of Mahalanobis-distance metric is proposed for MPC clustering in MIMO\nchannel analysis, without user-specified parameters. Remarkably, the popular\nmultipath component distance (MCD) is proved to be a special case of the\nproposed distance metric framework. Furthermore, two machine learning\nalgorithms, namely, weak-supervised Mahalanobis metric for clustering and\nsupervised large margin nearest neighbor, are introduced to learn the distance\nmetric. To evaluate the effectiveness, a modified channel model is proposed\nbased on the 3GPP spatial channel model to generate clustered MPCs with delay\nand angular information, since the original 3GPP spatial channel model (SCM) is\nincapable to evaluate clustering quality. Experiment results show that the\nproposed distance metric can significantly improve the clustering quality of\nexisting clustering algorithms, while the learning phase requires considerably\nlimited efforts of labeling MPCs.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Yi Chen",
      "Chong Han",
      "Jia He",
      "Guangjian Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.08768"
  },
  {
    "id": "arXiv:2110.08770",
    "title": "Towards Better Long-range Time Series Forecasting using Generative  Adversarial Networks",
    "abstract": "Accurate long-range forecasting of time series data is an important problem\nin many sectors, such as energy, healthcare, and finance. In recent years,\nGenerative Adversarial Networks (GAN) have provided a revolutionary approach to\nmany problems. However, the use of GAN to improve long-range time series\nforecasting remains relatively unexplored. In this paper, we utilize a\nConditional Wasserstein GAN (CWGAN) and augment it with an error penalty term,\nleading to a new generative model which aims to generate high-quality synthetic\ntime series data, called CWGAN-TS. By using such synthetic data, we develop a\nlong-range forecasting approach, called Generative Forecasting (GenF),\nconsisting of three components: (i) CWGAN-TS to generate synthetic data for the\nnext few time steps. (ii) a predictor which makes long-range predictions based\non generated and observed data. (iii) an information theoretic clustering (ITC)\nalgorithm to better train the CWGAN-TS and the predictor. Our experimental\nresults on three public datasets demonstrate that GenF significantly\noutperforms a diverse range of state-of-the-art benchmarks and classical\napproaches. In most cases, we find a 6% - 12% improvement in predictive\nperformance (mean absolute error) and a 37% reduction in parameters compared to\nthe best performing benchmark. Lastly, we conduct an ablation study to\ndemonstrate the effectiveness of the CWGAN-TS and the ITC algorithm.",
    "descriptor": "\nComments: 7 pages main paper with 4 pages appendix\n",
    "authors": [
      "Shiyu Liu",
      "Mehul Motani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08770"
  },
  {
    "id": "arXiv:2110.08771",
    "title": "An LSTM-based Plagiarism Detection via Attention Mechanism and a  Population-based Approach for Pre-Training Parameters with imbalanced Classes",
    "abstract": "Plagiarism is one of the leading problems in academic and industrial\nenvironments, which its goal is to find the similar items in a typical document\nor source code. This paper proposes an architecture based on a Long Short-Term\nMemory (LSTM) and attention mechanism called LSTM-AM-ABC boosted by a\npopulation-based approach for parameter initialization. Gradient-based\noptimization algorithms such as back-propagation (BP) are widely used in the\nliterature for learning process in LSTM, attention mechanism, and feed-forward\nneural network, while they suffer from some problems such as getting stuck in\nlocal optima. To tackle this problem, population-based metaheuristic (PBMH)\nalgorithms can be used. To this end, this paper employs a PBMH algorithm,\nartificial bee colony (ABC), to moderate the problem. Our proposed algorithm\ncan find the initial values for model learning in all LSTM, attention\nmechanism, and feed-forward neural network, simultaneously. In other words, ABC\nalgorithm finds a promising point for starting BP algorithm. For evaluation, we\ncompare our proposed algorithm with both conventional and population-based\nmethods. The results clearly show that the proposed method can provide\ncompetitive performance.",
    "descriptor": "\nComments: 12 pages, The 28th International Conference on Neural Information Processing (ICONIP2021), BALI, Indonesia\n",
    "authors": [
      "Seyed Vahid Moravvej",
      "Seyed Jalaleddin Mousavirad",
      "Mahshid Helali Moghadam",
      "Mehrdad Saadatmand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.08771"
  },
  {
    "id": "arXiv:2110.08774",
    "title": "Nonlinear Transform Induced Tensor Nuclear Norm for Tensor Completion",
    "abstract": "The linear transform-based tensor nuclear norm (TNN) methods have recently\nobtained promising results for tensor completion. The main idea of this type of\nmethods is exploiting the low-rank structure of frontal slices of the targeted\ntensor under the linear transform along the third mode. However, the\nlow-rankness of frontal slices is not significant under linear transforms\nfamily. To better pursue the low-rank approximation, we propose a nonlinear\ntransform-based TNN (NTTNN). More concretely, the proposed nonlinear transform\nis a composite transform consisting of the linear semi-orthogonal transform\nalong the third mode and the element-wise nonlinear transform on frontal slices\nof the tensor under the linear semi-orthogonal transform, which are\nindispensable and complementary in the composite transform to fully exploit the\nunderlying low-rankness. Based on the suggested low-rankness metric, i.e.,\nNTTNN, we propose a low-rank tensor completion (LRTC) model. To tackle the\nresulting nonlinear and nonconvex optimization model, we elaborately design the\nproximal alternating minimization (PAM) algorithm and establish the theoretical\nconvergence guarantee of the PAM algorithm. Extensive experimental results on\nhyperspectral images, multispectral images, and videos show that the our method\noutperforms linear transform-based state-of-the-art LRTC methods qualitatively\nand quantitatively.",
    "descriptor": "\nComments: Nonlinear transform, tensor nuclear norm, proximal alternating minimization, tensor completion\n",
    "authors": [
      "Ben-Zheng Li",
      "Xi-Le Zhao",
      "Teng-Yu Ji",
      "Xiong-Jun Zhang",
      "Ting-Zhu Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.08774"
  },
  {
    "id": "arXiv:2110.08777",
    "title": "A Novel Watermarking Approach for Protecting Image Integrity based on a  Hybrid Security Technique",
    "abstract": "Digital Photo images are everywhere around us in journals, on walls, and over\nthe Internet. However we have to be conscious that seeing does not always imply\nreality. Photo images become a rich subject of manipulations due to the\nadvanced digital cameras as well as photo editing software. Accordingly, image\nforgery is becoming much easier using the existing tools in terms of time and\naccuracy, and thus the forensics of detecting an image forgery case is becoming\ndifficult and needs more and more time and techniques to prove the image\noriginality especially as crime evidences and court related cases. In this\npaper, a framework with associated algorithms and methodologies is proposed to\nensure the authenticity of the image and the integrity of the content in\naddition to protecting the photo image against forgery suspects. The framework\ndepends on developing new generation of certified digital cameras that could\nproduce authenticated and forgery-proof photos. The proposed methodology\ngenerates an irreversible hash integrity code from the image content based on\ncolor matrix calculations and steganography algorithms. The simulation results\nproved the capability of the proposed technique to detect image forgery cases\nin more than 16 scenarios of manipulation.",
    "descriptor": "\nComments: 9 pages, 4 figures, 4 tables, International Journal of Computer Applications, Vol. 178, No.30, 14-22 July 2019, ISSN 0975-8887\n",
    "authors": [
      "Ahmad M. Nagm",
      "Mohamed Torky",
      "Khaled Y. Youssef"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.08777"
  },
  {
    "id": "arXiv:2110.08779",
    "title": "A robust watermarking algorithm for medical images",
    "abstract": "Integrated healthcare systems require the transmission of medical images\nbetween medical centers. The presence of watermarks in such images has become\nimportant for patient privacy protection. However, some important issues should\nbe considered while watermarking an image. Among these issues, the watermark\nshould be robust against attacks and does not affect the quality of the image.\nIn this paper, a watermarking approach employing a robust dynamic secret code\nis proposed. This approach is to process every pixel of the digital image and\nnot only the pixels of the regions of non-interest at the same time it\npreserves the image details. The performance of the proposed approach is\nevaluated using several performance measures such as the Mean Square Error\n(MSE), the Mean Absolute Error (MAE), the Peak Signal to Noise Ratio (PSNR),\nthe Universal Image Quality Index (UIQI) and the Structural Similarity Index\n(SSIM). The proposed approach has been tested and shown robustness in detecting\nthe intentional attacks that change image, specifically the most important\ndiagnostic information.",
    "descriptor": "\nComments: 12 pages, 13 figures, 5 tables, Indonesian Journal of Electrical Engineering and Computer Science, Vol. 20, No. 3, December 2020, pp. 1601~1612, ISSN: 2502-4752, pp1601-1612\n",
    "authors": [
      "Ahmed Nagm",
      "Mohammed Safy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.08779"
  },
  {
    "id": "arXiv:2110.08781",
    "title": "On Estimating the Probabilistic Region of Attraction for Partially  Unknown Nonlinear Systems: An Sum-of-Squares Approach",
    "abstract": "Estimating the region of attraction for partially unknown nonlinear systems\nis a challenging issue. In this paper, we propose a tractable method to\ngenerate an estimated region of attraction with probability bounds, by\nsearching an optimal polynomial barrier function. Chebyshev interpolants,\nGaussian processes and sum-of-squares programmings are used in this paper. To\napproximate the unknown non-polynomial dynamics, a polynomial mean function of\nGaussian processes model is computed to represent the exact dynamics based on\nthe Chebyshev interpolants. Furthermore, probabilistic conditions are given\nsuch that all the estimates are located in certain probability bounds.\nNumerical examples are provided to demonstrate the effectiveness of the\nproposed method.",
    "descriptor": "\nComments: 9 pages, 7 figures, 1 algorithm, 1 table, 34 references. Submitted to the 34th Chinese Control and Decision Conference\n",
    "authors": [
      "Hejun Huang",
      "Dongkun Han"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.08781"
  },
  {
    "id": "arXiv:2110.08782",
    "title": "Faster Algorithms for Bounded-Difference Min-Plus Product",
    "abstract": "Min-plus product of two $n\\times n$ matrices is a fundamental problem in\nalgorithm research. It is known to be equivalent to APSP, and in general it has\nno truly subcubic algorithms. In this paper, we focus on the min-plus product\non a special class of matrices, called $\\delta$-bounded-difference matrices, in\nwhich the difference between any two adjacent entries is bounded by\n$\\delta=O(1)$. Our algorithm runs in randomized time $O(n^{2.779})$ by the fast\nrectangular matrix multiplication algorithm [Le Gall \\& Urrutia 18], better\nthan $\\tilde{O}(n^{2+\\omega/3})=O(n^{2.791})$ ($\\omega<2.373$ [Alman \\&\nV.V.Williams 20]). This improves previous result of $\\tilde{O}(n^{2.824})$\n[Bringmann et al. 16]. When $\\omega=2$ in the ideal case, our complexity is\n$\\tilde{O}(n^{2+2/3})$, improving Bringmann et al.'s result of\n$\\tilde{O}(n^{2.755})$.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Shucheng Chi",
      "Ran Duan",
      "Tianle Xie"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.08782"
  },
  {
    "id": "arXiv:2110.08785",
    "title": "Correct Probabilistic Model Checking with Floating-Point Arithmetic",
    "abstract": "Probabilistic model checking computes probabilities and expected values\nrelated to designated behaviours of interest in Markov models. As a formal\nverification approach, it is applied to critical systems; thus we trust that\nprobabilistic model checkers deliver correct results. To achieve scalability\nand performance, however, these tools use finite-precision floating-point\nnumbers to represent and calculate probabilities and other values. As a\nconsequence, their results are affected by rounding errors that may accumulate\nand interact in hard-to-predict ways. In this paper, we show how to implement\nfast and correct probabilistic model checking by exploiting the ability of\ncurrent hardware to control the direction of rounding in floating-point\ncalculations. We outline the complications in achieving correct rounding from\nhigher-level programming languages, describe our implementation as part of the\nModest Toolset's 'mcsta' model checker, and exemplify the tradeoffs between\nperformance and correctness in an extensive experimental evaluation across\ndifferent operating systems and CPU architectures.",
    "descriptor": "",
    "authors": [
      "Arnd Hartmanns"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.08785"
  },
  {
    "id": "arXiv:2110.08787",
    "title": "PixelPyramids: Exact Inference Models from Lossless Image Pyramids",
    "abstract": "Autoregressive models are a class of exact inference approaches with highly\nflexible functional forms, yielding state-of-the-art density estimates for\nnatural images. Yet, the sequential ordering on the dimensions makes these\nmodels computationally expensive and limits their applicability to\nlow-resolution imagery. In this work, we propose Pixel-Pyramids, a\nblock-autoregressive approach employing a lossless pyramid decomposition with\nscale-specific representations to encode the joint distribution of image\npixels. Crucially, it affords a sparser dependency structure compared to fully\nautoregressive approaches. Our PixelPyramids yield state-of-the-art results for\ndensity estimation on various image datasets, especially for high-resolution\ndata. For CelebA-HQ 1024 x 1024, we observe that the density estimates (in\nterms of bits/dim) are improved to ~44% of the baseline despite sampling speeds\nsuperior even to easily parallelizable flow-based models.",
    "descriptor": "\nComments: To appear at ICCV 2021\n",
    "authors": [
      "Shweta Mahajan",
      "Stefan Roth"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.08787"
  },
  {
    "id": "arXiv:2110.08791",
    "title": "Taming Visually Guided Sound Generation",
    "abstract": "Recent advances in visually-induced audio generation are based on sampling\nshort, low-fidelity, and one-class sounds. Moreover, sampling 1 second of audio\nfrom the state-of-the-art model takes minutes on a high-end GPU. In this work,\nwe propose a single model capable of generating visually relevant,\nhigh-fidelity sounds prompted with a set of frames from open-domain videos in\nless time than it takes to play it on a single GPU.\nWe train a transformer to sample a new spectrogram from the pre-trained\nspectrogram codebook given the set of video features. The codebook is obtained\nusing a variant of VQGAN trained to produce a compact sampling space with a\nnovel spectrogram-based perceptual loss. The generated spectrogram is\ntransformed into a waveform using a window-based GAN that significantly speeds\nup generation. Considering the lack of metrics for automatic evaluation of\ngenerated spectrograms, we also build a family of metrics called FID and MKL.\nThese metrics are based on a novel sound classifier, called Melception, and\ndesigned to evaluate the fidelity and relevance of open-domain samples.\nBoth qualitative and quantitative studies are conducted on small- and\nlarge-scale datasets to evaluate the fidelity and relevance of generated\nsamples. We also compare our model to the state-of-the-art and observe a\nsubstantial improvement in quality, size, and computation time. Code, demo, and\nsamples: v-iashin.github.io/SpecVQGAN",
    "descriptor": "\nComments: Accepted as an oral presentation for the BMVC 2021. Code: this https URL Project page: this https URL\n",
    "authors": [
      "Vladimir Iashin",
      "Esa Rahtu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.08791"
  },
  {
    "id": "arXiv:2110.08796",
    "title": "Stable Marriage Matching for Traffic-Aware Space-Air-Ground Integrated  Networks: A Gale-Shapley Algorithmic Approach",
    "abstract": "In keeping with the rapid development of communication technology, a new\ncommunication structure is required in a next-generation communication system.\nIn particular, research using High Altitude Platform (HAP) or Unmanned Aerial\nVehicle(UAV) in existing terrestrial networks is active. In this paper, we\npropose matching HAP and UAV using the Gale-Shapley algorithm in a relay\ncommunication situation. The numerical simulation results demonstrate that\napplying the Gale-Shapley algorithm shows superior performance compared to\nrandom matching.",
    "descriptor": "",
    "authors": [
      "Hyunsoo Lee",
      "Haemin Lee",
      "Soyi Jung",
      "Joongheon Kim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.08796"
  },
  {
    "id": "arXiv:2110.08797",
    "title": "Towards Language-guided Visual Recognition via Dynamic Convolutions",
    "abstract": "In this paper, we are committed to establishing an unified and end-to-end\nmulti-modal network via exploring the language-guided visual recognition. To\napproach this target, we first propose a novel multi-modal convolution module\ncalled Language-dependent Convolution (LaConv). Its convolution kernels are\ndynamically generated based on natural language information, which can help\nextract differentiated visual features for different multi-modal examples.\nBased on the LaConv module, we further build the first fully language-driven\nconvolution network, termed as LaConvNet, which can unify the visual\nrecognition and multi-modal reasoning in one forward structure. To validate\nLaConv and LaConvNet, we conduct extensive experiments on four benchmark\ndatasets of two vision-and-language tasks, i.e., visual question answering\n(VQA) and referring expression comprehension (REC). The experimental results\nnot only shows the performance gains of LaConv compared to the existing\nmulti-modal modules, but also witness the merits of LaConvNet as an unified\nnetwork, including compact network, high generalization ability and excellent\nperformance, e.g., +4.7% on RefCOCO+.",
    "descriptor": "",
    "authors": [
      "Gen Luo",
      "Yiyi Zhou",
      "Xiaoshuai Sun",
      "Xinghao Ding",
      "Yongjian Wu",
      "Feiyue Huang",
      "Yue Gao",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08797"
  },
  {
    "id": "arXiv:2110.08802",
    "title": "Coordinated Multi-Agent Pathfinding for Drones and Trucks over Road  Networks",
    "abstract": "We address the problem of routing a team of drones and trucks over\nlarge-scale urban road networks. To conserve their limited flight energy,\ndrones can use trucks as temporary modes of transit en route to their own\ndestinations. Such coordination can yield significant savings in total vehicle\ndistance traveled, i.e., truck travel distance and drone flight distance,\ncompared to operating drones and trucks independently. But it comes at the\npotentially prohibitive computational cost of deciding which trucks and drones\nshould coordinate and when and where it is most beneficial to do so. We tackle\nthis fundamental trade-off by decoupling our overall intractable problem into\ntractable sub-problems that we solve stage-wise. The first stage solves only\nfor trucks, by computing paths that make them more likely to be useful transit\noptions for drones. The second stage solves only for drones, by routing them\nover a composite of the road network and the transit network defined by truck\npaths from the first stage. We design a comprehensive algorithmic framework\nthat frames each stage as a multi-agent path-finding problem and implement two\ndistinct methods for solving them. We evaluate our approach on extensive\nsimulations with up to $100$ agents on the real-world Manhattan road network\ncontaining nearly $4500$ vertices and $10000$ edges. Our framework saves on\nmore than $50\\%$ of vehicle distance traveled compared to independently solving\nfor trucks and drones, and computes solutions for all settings within $5$\nminutes on commodity hardware.",
    "descriptor": "",
    "authors": [
      "Shushman Choudhury",
      "Kiril Solovey",
      "Mykel Kochenderfer",
      "Marco Pavone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.08802"
  },
  {
    "id": "arXiv:2110.08805",
    "title": "Revealing Disocclusions in Temporal View Synthesis through Infilling  Vector Prediction",
    "abstract": "We consider the problem of temporal view synthesis, where the goal is to\npredict a future video frame from the past frames using knowledge of the depth\nand relative camera motion. In contrast to revealing the disoccluded regions\nthrough intensity based infilling, we study the idea of an infilling vector to\ninfill by pointing to a non-disoccluded region in the synthesized view. To\nexploit the structure of disocclusions created by camera motion during their\ninfilling, we rely on two important cues, temporal correlation of infilling\ndirections and depth. We design a learning framework to predict the infilling\nvector by computing a temporal prior that reflects past infilling directions\nand a normalized depth map as input to the network. We conduct extensive\nexperiments on a large scale dataset we build for evaluating temporal view\nsynthesis in addition to the SceneNet RGB-D dataset. Our experiments\ndemonstrate that our infilling vector prediction approach achieves superior\nquantitative and qualitative infilling performance compared to other approaches\nin literature.",
    "descriptor": "\nComments: WACV 2022. this https URL\n",
    "authors": [
      "Vijayalakshmi Kanchana",
      "Nagabhushan Somraj",
      "Suraj Yadwad",
      "Rajiv Soundararajan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08805"
  },
  {
    "id": "arXiv:2110.08810",
    "title": "Learning First-Order Rules with Relational Path Contrast for Inductive  Relation Reasoning",
    "abstract": "Relation reasoning in knowledge graphs (KGs) aims at predicting missing\nrelations in incomplete triples, whereas the dominant paradigm is learning the\nembeddings of relations and entities, which is limited to a transductive\nsetting and has restriction on processing unseen entities in an inductive\nsituation. Previous inductive methods are scalable and consume less resource.\nThey utilize the structure of entities and triples in subgraphs to own\ninductive ability. However, in order to obtain better reasoning results, the\nmodel should acquire entity-independent relational semantics in latent rules\nand solve the deficient supervision caused by scarcity of rules in subgraphs.\nTo address these issues, we propose a novel graph convolutional network\n(GCN)-based approach for interpretable inductive reasoning with relational path\ncontrast, named RPC-IR. RPC-IR firstly extracts relational paths between two\nentities and learns representations of them, and then innovatively introduces a\ncontrastive strategy by constructing positive and negative relational paths. A\njoint training strategy considering both supervised and contrastive information\nis also proposed. Comprehensive experiments on three inductive datasets show\nthat RPC-IR achieves outstanding performance comparing with the latest\ninductive reasoning methods and could explicitly represent logical rules for\ninterpretability.",
    "descriptor": "\nComments: This work is going to be submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Yudai Pan",
      "Jun Liu",
      "Lingling Zhang",
      "Xin Hu",
      "Tianzhe Zhao",
      "Qika Lin"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08810"
  },
  {
    "id": "arXiv:2110.08814",
    "title": "TEAM-Net: Multi-modal Learning for Video Action Recognition with Partial  Decoding",
    "abstract": "Most of existing video action recognition models ingest raw RGB frames.\nHowever, the raw video stream requires enormous storage and contains\nsignificant temporal redundancy. Video compression (e.g., H.264, MPEG-4)\nreduces superfluous information by representing the raw video stream using the\nconcept of Group of Pictures (GOP). Each GOP is composed of the first I-frame\n(aka RGB image) followed by a number of P-frames, represented by motion vectors\nand residuals, which can be regarded and used as pre-extracted features. In\nthis work, we 1) introduce sampling the input for the network from partially\ndecoded videos based on the GOP-level, and 2) propose a plug-and-play\nmulTi-modal lEArning Module (TEAM) for training the network using information\nfrom I-frames and P-frames in an end-to-end manner. We demonstrate the superior\nperformance of TEAM-Net compared to the baseline using RGB only. TEAM-Net also\nachieves the state-of-the-art performance in the area of video action\nrecognition with partial decoding. Code is provided at\nhttps://github.com/villawang/TEAM-Net.",
    "descriptor": "\nComments: To appear in BMVC 2021\n",
    "authors": [
      "Zhengwei Wang",
      "Qi She",
      "Aljosa Smolic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08814"
  },
  {
    "id": "arXiv:2110.08818",
    "title": "MeronymNet: A Hierarchical Approach for Unified and Controllable  Multi-Category Object Generation",
    "abstract": "We introduce MeronymNet, a novel hierarchical approach for controllable,\npart-based generation of multi-category objects using a single unified model.\nWe adopt a guided coarse-to-fine strategy involving semantically conditioned\ngeneration of bounding box layouts, pixel-level part layouts and ultimately,\nthe object depictions themselves. We use Graph Convolutional Networks, Deep\nRecurrent Networks along with custom-designed Conditional Variational\nAutoencoders to enable flexible, diverse and category-aware generation of 2-D\nobjects in a controlled manner. The performance scores for generated objects\nreflect MeronymNet's superior performance compared to multiple strong baselines\nand ablative variants. We also showcase MeronymNet's suitability for\ncontrollable object generation and interactive object editing at various levels\nof structural and semantic granularity.",
    "descriptor": "\nComments: Accepted at ACM Multimedia (ACMMM) 2021 [ORAL] . Website : this https URL arXiv admin note: text overlap with arXiv:2006.00190\n",
    "authors": [
      "Rishabh Baghel",
      "Abhishek Trivedi",
      "Tejas Ravichandran",
      "Ravi Kiran Sarvadevabhatla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.08818"
  },
  {
    "id": "arXiv:2110.08820",
    "title": "On-board Fault Diagnosis of a Laboratory Mini SR-30 Gas Turbine Engine",
    "abstract": "Inspired by recent progress in machine learning, a data-driven fault\ndiagnosis and isolation (FDI) scheme is explicitly developed for failure in the\nfuel supply system and sensor measurements of the laboratory gas turbine\nsystem. A passive approach of fault diagnosis is implemented where a model is\ntrained using machine learning classifiers to detect a given set of fault\nscenarios in real-time on which it is trained. Towards the end, a comparative\nstudy is presented for well-known classification techniques, namely Support\nvector classifier, linear discriminant analysis, K-neighbor, and decision\ntrees. Several simulation studies were carried out to demonstrate and\nillustrate the proposed fault diagnosis scheme's advantages, capabilities, and\nperformance.",
    "descriptor": "",
    "authors": [
      "Richa Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.08820"
  },
  {
    "id": "arXiv:2110.08821",
    "title": "Storage and Authentication of Audio Footage for IoAuT Devices Using  Distributed Ledger Technology",
    "abstract": "Detection of fabricated or manipulated audio content to prevent, e.g.,\ndistribution of forgeries in digital media, is crucial, especially in political\nand reputational contexts. Better tools for protecting the integrity of media\ncreation are desired. Within the paradigm of the Internet of Audio\nThings(IoAuT), we discuss the ability of the IoAuT network to verify the\nauthenticity of original audio using distributed ledger technology. By storing\naudio recordings in combination with associated recording-specific metadata\nobtained by the IoAuT capturing device, this architecture enables secure\ndistribution of original audio footage, authentication of unknown audio\ncontent, and referencing of original audio material in future derivative works.\nBy developing a proof-of-concept system, the feasibility of the proposed\narchitecture is evaluated and discussed.",
    "descriptor": "\nComments: 11 pages, 3 Figures, 1 code listing\n",
    "authors": [
      "Srivatsav Chenna",
      "Nils Peters"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.08821"
  },
  {
    "id": "arXiv:2110.08822",
    "title": "Siamese Transformer Pyramid Networks for Real-Time UAV Tracking",
    "abstract": "Recent object tracking methods depend upon deep networks or convoluted\narchitectures. Most of those trackers can hardly meet real-time processing\nrequirements on mobile platforms with limited computing resources. In this\nwork, we introduce the Siamese Transformer Pyramid Network (SiamTPN), which\ninherits the advantages from both CNN and Transformer architectures.\nSpecifically, we exploit the inherent feature pyramid of a lightweight network\n(ShuffleNetV2) and reinforce it with a Transformer to construct a robust\ntarget-specific appearance model. A centralized architecture with lateral cross\nattention is developed for building augmented high-level feature maps. To avoid\nthe computation and memory intensity while fusing pyramid representations with\nthe Transformer, we further introduce the pooling attention module, which\nsignificantly reduces memory and time complexity while improving the\nrobustness. Comprehensive experiments on both aerial and prevalent tracking\nbenchmarks achieve competitive results while operating at high speed,\ndemonstrating the effectiveness of SiamTPN. Moreover, our fastest variant\ntracker operates over 30 Hz on a single CPU-core and obtaining an AUC score of\n58.1% on the LaSOT dataset. Source codes are available at\nhttps://github.com/RISCNYUAD/SiamTPNTracker",
    "descriptor": "\nComments: 10 pages, 8 figures, accepted by WACV2022\n",
    "authors": [
      "Daitao Xing",
      "Nikolaos Evangeliou",
      "Athanasios Tsoukalas",
      "Anthony Tzes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.08822"
  },
  {
    "id": "arXiv:2110.08825",
    "title": "Localization with Sampling-Argmax",
    "abstract": "Soft-argmax operation is commonly adopted in detection-based methods to\nlocalize the target position in a differentiable manner. However, training the\nneural network with soft-argmax makes the shape of the probability map\nunconstrained. Consequently, the model lacks pixel-wise supervision through the\nmap during training, leading to performance degradation. In this work, we\npropose sampling-argmax, a differentiable training method that imposes implicit\nconstraints to the shape of the probability map by minimizing the expectation\nof the localization error. To approximate the expectation, we introduce a\ncontinuous formulation of the output distribution and develop a differentiable\nsampling process. The expectation can be approximated by calculating the\naverage error of all samples drawn from the output distribution. We show that\nsampling-argmax can seamlessly replace the conventional soft-argmax operation\non various localization tasks. Comprehensive experiments demonstrate the\neffectiveness and flexibility of the proposed method. Code is available at\nhttps://github.com/Jeff-sjtu/sampling-argmax",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Jiefeng Li",
      "Tong Chen",
      "Ruiqi Shi",
      "Yujing Lou",
      "Yong-Lu Li",
      "Cewu Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08825"
  },
  {
    "id": "arXiv:2110.08826",
    "title": "Exploring Deep Neural Networks on Edge TPU",
    "abstract": "This paper explores the performance of Google's Edge TPU on feed forward\nneural networks. We consider Edge TPU as a hardware platform and explore\ndifferent architectures of deep neural network classifiers, which traditionally\nhas been a challenge to run on resource constrained edge devices. Based on the\nuse of a joint-time-frequency data representation, also known as spectrogram,\nwe explore the trade-off between classification performance and the energy\nconsumed for inference. The energy efficiency of Edge TPU is compared with that\nof widely-used embedded CPU ARM Cortex-A53. Our results quantify the impact of\nneural network architectural specifications on the Edge TPU's performance,\nguiding decisions on the TPU's optimal operating point, where it can provide\nhigh classification accuracy with minimal energy consumption. Also, our\nevaluations highlight the crossover in performance between the Edge TPU and\nCortex-A53, depending on the neural network specifications. Based on our\nanalysis, we provide a decision chart to guide decisions on platform selection\nbased on the model parameters and context.",
    "descriptor": "\nComments: 12 pages, 16 figures\n",
    "authors": [
      "Seyedehfaezeh Hosseininoorbin",
      "Siamak Layeghy",
      "Brano Kusy",
      "Raja Jurdak",
      "Marius Portmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08826"
  },
  {
    "id": "arXiv:2110.08828",
    "title": "Compression-aware Projection with Greedy Dimension Reduction for  Convolutional Neural Network Activations",
    "abstract": "Convolutional neural networks (CNNs) achieve remarkable performance in a wide\nrange of fields. However, intensive memory access of activations introduces\nconsiderable energy consumption, impeding deployment of CNNs on\nresourceconstrained edge devices. Existing works in activation compression\npropose to transform feature maps for higher compressibility, thus enabling\ndimension reduction. Nevertheless, in the case of aggressive dimension\nreduction, these methods lead to severe accuracy drop. To improve the trade-off\nbetween classification accuracy and compression ratio, we propose a\ncompression-aware projection system, which employs a learnable projection to\ncompensate for the reconstruction loss. In addition, a greedy selection metric\nis introduced to optimize the layer-wise compression ratio allocation by\nconsidering both accuracy and #bits reduction simultaneously. Our test results\nshow that the proposed methods effectively reduce 2.91x~5.97x memory access\nwith negligible accuracy drop on MobileNetV2/ResNet18/VGG16.",
    "descriptor": "\nComments: 5 pages, 5 figures, submitted to 2022 ICASSP\n",
    "authors": [
      "Yu-Shan Tai",
      "Chieh-Fang Teng",
      "Cheng-Yang Chang",
      "An-Yeu Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.08828"
  },
  {
    "id": "arXiv:2110.08835",
    "title": "Towards More Accountable Search Engines: Online Evaluation of  Representation Bias",
    "abstract": "Information availability affects people's behavior and perception of the\nworld. Notably, people rely on search engines to satisfy their need for\ninformation. Search engines deliver results relevant to user requests usually\nwithout being or making themselves accountable for the information they\ndeliver, which may harm people's lives and, in turn, society. This potential\nrisk urges the development of evaluation mechanisms of bias in order to empower\nthe user in judging the results of search engines. In this paper, we give a\npossible solution to measuring representation bias with respect to societal\nfeatures for search engines and apply it to evaluating the gender\nrepresentation bias for Google's Knowledge Graph Carousel for listing\noccupations.",
    "descriptor": "",
    "authors": [
      "Aldo Lipani",
      "Florina Piroi",
      "Emine Yilmaz"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.08835"
  },
  {
    "id": "arXiv:2110.08836",
    "title": "On the singular two-parameter eigenvalue problem II",
    "abstract": "In the 1960s, Atkinson introduced an abstract algebraic setting for\nmultiparameter eigenvalue problems. He showed that a nonsingular multiparameter\neigenvalue problem is equivalent to the associated system of generalized\neigenvalue problems, which is a key relation for many theoretical results and\nnumerical methods for nonsingular multiparameter eigenvalue problems. In 2009,\nMuhi\\v{c} and Plestenjak extended the above relation to a class of singular\ntwo-parameter eigenvalue problems with coprime characteristic polynomials and\nsuch that all finite eigenvalues are algebraically simple. They introduced a\nway to solve a singular two-parameter eigenvalue problem by computing the\ncommon regular eigenvalues of the associated system of two singular generalized\neigenvalue problems. Using new tools, in particular the stratification theory,\nwe extend this connection to singular two-parameter eigenvalue problems with\npossibly multiple eigenvalues and such that characteristic polynomials can have\na nontrivial common factor.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Toma\u017e Ko\u0161ir",
      "Bor Plestenjak"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.08836"
  },
  {
    "id": "arXiv:2110.08837",
    "title": "Category-theoretical Semantics of the Description Logic ALC (extended  version)",
    "abstract": "Category theory can be used to state formulas in First-Order Logic without\nusing set membership. Several notable results in logic such as proof of the\ncontinuum hypothesis can be elegantly rewritten in category theory. We propose\nin this paper a reformulation of the usual set-theoretical semantics of the\ndescription logic ALC by using categorical language. In this setting,\n$\\mathcal{ALC}$ concepts are represented as objects, concept subsumptions as\narrows, and memberships as logical quantifiers over objects and arrows of\ncategories. Such a category-theore\\-tical semantics provides a more modular\nrepresentation of the semantics of $\\mathcal{ALC}$ and a new way to design\nalgorithms for reasoning.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Chan Le Duc"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.08837"
  },
  {
    "id": "arXiv:2110.08840",
    "title": "Online Facility Location with Predictions",
    "abstract": "We provide nearly optimal algorithms for online facility location (OFL) with\npredictions. In OFL, $n$ demand points arrive in order and the algorithm must\nirrevocably assign each demand point to an open facility upon its arrival. The\nobjective is to minimize the total connection costs from demand points to\nassigned facilities plus the facility opening cost. We further assume the\nalgorithm is additionally given for each demand point $x_i$ a natural\nprediction $f_{x_i}^{\\mathrm{pred}}$ which is supposed to be the facility\n$f_{x_i}^{\\mathrm{opt}}$ that serves $x_i$ in the offline optimal solution.\nOur main result is an $O(\\min\\{\\log {\\frac{n\\eta_\\infty}{\\mathrm{OPT}}},\n\\log{n} \\})$-competitive algorithm where $\\eta_\\infty$ is the maximum\nprediction error (i.e., the distance between $f_{x_i}^{\\mathrm{pred}}$ and\n$f_{x_i}^{\\mathrm{opt}}$). Our algorithm overcomes the fundamental\n$\\Omega(\\frac{\\log n}{\\log \\log n})$ lower bound of OFL (without predictions)\nwhen $\\eta_\\infty$ is small, and it still maintains $O(\\log n)$ ratio even when\n$\\eta_\\infty$ is unbounded. Furthermore, our theoretical analysis is supported\nby empirical evaluations for the tradeoffs between $\\eta_\\infty$ and the\ncompetitive ratio on various real datasets of different types.",
    "descriptor": "",
    "authors": [
      "Shaofeng H.-C. Jiang",
      "Erzhi Liu",
      "You Lyu",
      "Zhihao Gavin Tang",
      "Yubo Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.08840"
  },
  {
    "id": "arXiv:2110.08842",
    "title": "Exploring Novel Pooling Strategies for Edge Preserved Feature Maps in  Convolutional Neural Networks",
    "abstract": "With the introduction of anti-aliased convolutional neural networks (CNN),\nthere has been some resurgence in relooking the way pooling is done in CNNs.\nThe fundamental building block of the anti-aliased CNN has been the application\nof Gaussian smoothing before the pooling operation to reduce the distortion due\nto aliasing thereby making CNNs shift invariant. Wavelet based approaches have\nalso been proposed as a possibility of additional noise removal capability and\ngave interesting results for even segmentation tasks. However, all the\napproaches proposed completely remove the high frequency components under the\nassumption that they are noise. However, by removing high frequency components,\nthe edges in the feature maps are also smoothed. In this work, an exhaustive\nanalysis of the edge preserving pooling options for classification,\nsegmentation and autoencoders are presented. Two novel pooling approaches are\npresented such as Laplacian-Gaussian Concatenation with Attention (LGCA)\npooling and Wavelet based approximate-detailed coefficient concatenation with\nattention (WADCA) pooling. The results suggest that the proposed pooling\napproaches outperform the conventional pooling as well as blur pooling for\nclassification, segmentation and autoencoders.",
    "descriptor": "\nComments: 29 pages, Submitted to Elsevier Pattern Recognition for review\n",
    "authors": [
      "Adithya Sineesh",
      "Mahesh Raveendranatha Panicker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.08842"
  },
  {
    "id": "arXiv:2110.08845",
    "title": "Fine-Grained Opinion Summarization with Minimal Supervision",
    "abstract": "Opinion summarization aims to profile a target by extracting opinions from\nmultiple documents. Most existing work approaches the task in a semi-supervised\nmanner due to the difficulty of obtaining high-quality annotation from\nthousands of documents. Among them, some use aspect and sentiment analysis as a\nproxy for identifying opinions. In this work, we propose a new framework,\nFineSum, which advances this frontier in three aspects: (1) minimal\nsupervision, where only aspect names and a few aspect/sentiment keywords are\navailable; (2) fine-grained opinion analysis, where sentiment analysis drills\ndown to the sub-aspect level; and (3) phrase-based summarization, where opinion\nis summarized in the form of phrases. FineSum automatically identifies opinion\nphrases from the raw corpus, classifies them into different aspects and\nsentiments, and constructs multiple fine-grained opinion clusters under each\naspect/sentiment. Each cluster consists of semantically coherent phrases,\nexpressing uniform opinions towards certain sub-aspect or characteristics\n(e.g., positive feelings for ``burgers'' in the ``food'' aspect). An\nopinion-oriented spherical word embedding space is trained to provide weak\nsupervision for the phrase classifier, and phrase clustering is performed using\nthe aspect-aware contextualized embedding generated from the phrase classifier.\nBoth automatic evaluation on the benchmark and quantitative human evaluation\nvalidate the effectiveness of our approach.",
    "descriptor": "",
    "authors": [
      "Suyu Ge",
      "Jiaxin Huang",
      "Yu Meng",
      "Sharon Wang",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08845"
  },
  {
    "id": "arXiv:2110.08847",
    "title": "Provable RL with Exogenous Distractors via Multistep Inverse Dynamics",
    "abstract": "Many real-world applications of reinforcement learning (RL) require the agent\nto deal with high-dimensional observations such as those generated from a\nmegapixel camera. Prior work has addressed such problems with representation\nlearning, through which the agent can provably extract endogenous, latent state\ninformation from raw observations and subsequently plan efficiently. However,\nsuch approaches can fail in the presence of temporally correlated noise in the\nobservations, a phenomenon that is common in practice. We initiate the formal\nstudy of latent state discovery in the presence of such exogenous noise sources\nby proposing a new model, the Exogenous Block MDP (EX-BMDP), for rich\nobservation RL. We start by establishing several negative results, by\nhighlighting failure cases of prior representation learning based approaches.\nThen, we introduce the Predictive Path Elimination (PPE) algorithm, that learns\na generalization of inverse dynamics and is provably sample and computationally\nefficient in EX-BMDPs when the endogenous state dynamics are near\ndeterministic. The sample complexity of PPE depends polynomially on the size of\nthe latent endogenous state space while not directly depending on the size of\nthe observation space, nor the exogenous state space. We provide experiments on\nchallenging exploration problems which show that our approach works\nempirically.",
    "descriptor": "",
    "authors": [
      "Yonathan Efroni",
      "Dipendra Misra",
      "Akshay Krishnamurthy",
      "Alekh Agarwal",
      "John Langford"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08847"
  },
  {
    "id": "arXiv:2110.08848",
    "title": "HIDE & SEEK: Privacy-Preserving Rebalancing on Payment Channel Networks",
    "abstract": "Payment channels effectively move the transaction load off-chain thereby\nsuccessfully addressing the inherent scalability problem most cryptocurrencies\nface. A major drawback of payment channels is the need to ``top up'' funds\non-chain when a channel is depleted. Rebalancing was proposed to alleviate this\nissue, where parties with depleting channels move their funds along a cycle to\nreplenish their channels off-chain. Protocols for rebalancing so far either\nintroduce local solutions or compromise privacy.\nIn this work, we present an opt-in rebalancing protocol that is both private\nand globally optimal, meaning our protocol maximizes the total amount of\nrebalanced funds. We study rebalancing from the framework of linear\nprogramming. To obtain full privacy guarantees, we leverage multi-party\ncomputation in solving the linear program, which is executed by selected\nparticipants to maintain efficiency. Finally, we efficiently decompose the\nrebalancing solution into incentive-compatible cycles which conserve user\nbalances when executed atomically.\nKeywords: Payment Channel Networks, Privacy and Rebalancing.",
    "descriptor": "",
    "authors": [
      "Zeta Avarikioti",
      "Krzysztof Pietrzak",
      "Iosif Salem",
      "Stefan Schmid",
      "Samarth Tiwari",
      "Michelle Yeo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.08848"
  },
  {
    "id": "arXiv:2110.08851",
    "title": "Self-Supervised Learning for Binary Networks by Joint Classifier  Training",
    "abstract": "Despite the great success of self-supervised learning with large floating\npoint networks, such networks are not readily deployable to edge devices. To\naccelerate deployment of models to edge devices for various downstream tasks by\nunsupervised representation learning, we propose a self-supervised learning\nmethod for binary networks. In particular, we propose to use a randomly\ninitialized classifier attached to a pretrained floating point feature\nextractor as targets and jointly train it with a binary network. For better\ntraining of the binary network, we propose a feature similarity loss, a dynamic\nbalancing scheme of loss terms, and modified multi-stage training. We call our\nmethod as BSSL. Our empirical validations show that BSSL outperforms\nself-supervised learning baselines for binary networks in various downstream\ntasks and outperforms supervised pretraining in certain tasks.",
    "descriptor": "",
    "authors": [
      "Dahyun Kim",
      "Jonghyun Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08851"
  },
  {
    "id": "arXiv:2110.08853",
    "title": "On-line Optimal Ranging Sensor Deployment for Robotic Exploration",
    "abstract": "Navigation in an unknown environment without any preexisting positioning\ninfrastructure has always been hard for mobile robots. This paper presents a\nself-deployable ultra wideband UWB infrastructure by mobile agents, that\npermits a dynamic placement and runtime extension of UWB anchors infrastructure\nwhile the robot explores the new environment. We provide a detailed analysis of\nthe uncertainty of the positioning system while the UWB infrastructure grows.\nMoreover, we developed a genetic algorithm that minimizes the deployment of new\nanchors, saving energy and resources on the mobile robot and maximizing the\ntime of the mission. Although the presented approach is general for any class\nof mobile system, we run simulations and experiments with indoor drones.\nResults demonstrate that maximum positioning uncertainty is always controlled\nunder the user's threshold, using the Geometric Dilution of Precision (GDoP).",
    "descriptor": "\nComments: 10 pages, 12 figures, 3 tables, in IEEE Sensors Journal\n",
    "authors": [
      "Luca Santoro",
      "Davide Brunelli",
      "Daniele Fontanelli"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.08853"
  },
  {
    "id": "arXiv:2110.08855",
    "title": "Online Continual Learning Via Candidates Voting",
    "abstract": "Continual learning in online scenario aims to learn a sequence of new tasks\nfrom data stream using each data only once for training, which is more\nrealistic than in offline mode assuming data from new task are all available.\nHowever, this problem is still under-explored for the challenging\nclass-incremental setting in which the model classifies all classes seen so far\nduring inference. Particularly, performance struggles with increased number of\ntasks or additional classes to learn for each task. In addition, most existing\nmethods require storing original data as exemplars for knowledge replay, which\nmay not be feasible for certain applications with limited memory budget or\nprivacy concerns. In this work, we introduce an effective and memory-efficient\nmethod for online continual learning under class-incremental setting through\ncandidates selection from each learned task together with prior incorporation\nusing stored feature embeddings instead of original data as exemplars. Our\nproposed method implemented for image classification task achieves the best\nresults under different benchmark datasets for online continual learning\nincluding CIFAR-10, CIFAR-100 and CORE-50 while requiring much less memory\nresource compared with existing works.",
    "descriptor": "\nComments: Accepted paper at Winter Conference on Applications of Computer Vision (WACV 2022)\n",
    "authors": [
      "Jiangpeng He",
      "Fengqing Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08855"
  },
  {
    "id": "arXiv:2110.08857",
    "title": "Growing Representation Learning",
    "abstract": "Machine learning continues to grow in popularity due to its ability to learn\nincreasingly complex tasks. However, for many supervised models, the shift in a\ndata distribution or the appearance of a new event can result in a severe\ndecrease in model performance. Retraining a model from scratch with updated\ndata can be resource intensive or impossible depending on the constraints\nplaced on an organization or system. Continual learning methods attempt to\nadapt models to new classes instead of retraining. However, many of these\nmethods do not have a detection method for new classes or make assumptions\nabout the distribution of classes. In this paper, we develop an attention based\nGaussian Mixture, called GMAT, that learns interpretable representations of\ndata with or without labels. We incorporate this method with existing Neural\nArchitecture Search techniques to develop an algorithm for detection new events\nfor an optimal number of representations through an iterative process of\ntraining a growing. We show that our method is capable learning new\nrepresentations of data without labels or assumptions about the distributions\nof labels. We additionally develop a method that allows our model to utilize\nlabels to more accurately develop representations. Lastly, we show that our\nmethod can avoid catastrophic forgetting by replaying samples from learned\nrepresentations.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Ryan King",
      "Bobak Mortazavi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08857"
  },
  {
    "id": "arXiv:2110.08858",
    "title": "Backpropagation with Biologically Plausible Spatio-Temporal Adjustment  For Training Deep Spiking Neural Networks",
    "abstract": "The spiking neural network (SNN) mimics the information processing operation\nin the human brain, represents and transmits information in spike trains\ncontaining wealthy spatial and temporal information, and shows superior\nperformance on many cognitive tasks. In addition, the event-driven information\nprocessing enables the energy-efficient implementation on neuromorphic chips.\nThe success of deep learning is inseparable from backpropagation. Due to the\ndiscrete information transmission, directly applying the backpropagation to the\ntraining of the SNN still has a performance gap compared with the traditional\ndeep neural networks. Also, a large simulation time is required to achieve\nbetter performance, which results in high latency. To address the problems, we\npropose a biological plausible spatial adjustment, which rethinks the\nrelationship between membrane potential and spikes and realizes a reasonable\nadjustment of gradients to different time steps. And it precisely controls the\nbackpropagation of the error along the spatial dimension. Secondly, we propose\na biologically plausible temporal adjustment making the error propagate across\nthe spikes in the temporal dimension, which overcomes the problem of the\ntemporal dependency within a single spike period of the traditional spiking\nneurons. We have verified our algorithm on several datasets, and the\nexperimental results have shown that our algorithm greatly reduces the network\nlatency and energy consumption while also improving network performance. We\nhave achieved state-of-the-art performance on the neuromorphic datasets\nN-MNIST, DVS-Gesture, and DVS-CIFAR10. For the static datasets MNIST and\nCIFAR10, we have surpassed most of the traditional SNN backpropagation training\nalgorithm and achieved relatively superior performance.",
    "descriptor": "",
    "authors": [
      "Guobin Shen",
      "Dongcheng Zhao",
      "Yi Zeng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08858"
  },
  {
    "id": "arXiv:2110.08861",
    "title": "3D-RETR: End-to-End Single and Multi-View 3D Reconstruction with  Transformers",
    "abstract": "3D reconstruction aims to reconstruct 3D objects from 2D views. Previous\nworks for 3D reconstruction mainly focus on feature matching between views or\nusing CNNs as backbones. Recently, Transformers have been shown effective in\nmultiple applications of computer vision. However, whether or not Transformers\ncan be used for 3D reconstruction is still unclear. In this paper, we fill this\ngap by proposing 3D-RETR, which is able to perform end-to-end 3D REconstruction\nwith TRansformers. 3D-RETR first uses a pretrained Transformer to extract\nvisual features from 2D input images. 3D-RETR then uses another Transformer\nDecoder to obtain the voxel features. A CNN Decoder then takes as input the\nvoxel features to obtain the reconstructed objects. 3D-RETR is capable of 3D\nreconstruction from a single view or multiple views. Experimental results on\ntwo datasets show that 3DRETR reaches state-of-the-art performance on 3D\nreconstruction. Additional ablation study also demonstrates that 3D-DETR\nbenefits from using Transformers.",
    "descriptor": "",
    "authors": [
      "Zai Shi",
      "Zhao Meng",
      "Yiran Xing",
      "Yunpu Ma",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08861"
  },
  {
    "id": "arXiv:2110.08865",
    "title": "System Outage Probability and Diversity Analysis of SWIPT Enabled  Two-Way DF Relaying under Hardware Impairments",
    "abstract": "This paper investigates the system outage performance of a simultaneous\nwireless information and power transfer (SWIPT) based two-way\ndecode-and-forward (DF) relay network, where potential hardware impairments\n(HIs) in all transceivers are considered. After harvesting energy and decoding\nmessages simultaneously via a power splitting scheme, the energy-limited relay\nnode forwards the decoded information to both terminals. Each terminal combines\nthe signals from the direct and relaying links via selection combining. We\nderive the system outage probability under independent but non-identically\ndistributed Nakagami-m fading channels. It reveals an overall system ceiling\n(OSC) effect, i.e., the system falls in outage if the target rate exceeds an\nOSC threshold that is determined by the levels of HIs. Furthermore, we derive\nthe diversity gain of the considered network. The result reveals that when the\ntransmission rate is below the OSC threshold, the achieved diversity gain\nequals the sum of the shape parameter of the direct link and the smaller shape\nparameter of the terminal-to-relay links; otherwise, the diversity gain is\nzero. This is different from the amplify-and-forward (AF) strategy, under which\nthe relaying links have no contribution to the diversity gain. Simulation\nresults validate the analytical results and reveal that compared with the AF\nstrategy, the SWIPT based two-way relaying links under the DF strategy are more\nrobust to HIs and achieve a lower system outage probability.",
    "descriptor": "\nComments: This paper has been accepted by China Communications\n",
    "authors": [
      "Guangyue Lu",
      "Zhipeng Liu",
      "Yinghui Ye",
      "Xiaoli Chu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.08865"
  },
  {
    "id": "arXiv:2110.08866",
    "title": "Alleviating Noisy-label Effects in Image Classification via Probability  Transition Matrix",
    "abstract": "Deep-learning-based image classification frameworks often suffer from the\nnoisy label problem caused by the inter-observer variation. Recent studies\nemployed learning-to-learn paradigms (e.g., Co-teaching and JoCoR) to filter\nthe samples with noisy labels from the training set. However, most of them use\na simple cross-entropy loss as the criterion for noisy label identification.\nThe hard samples, which are beneficial for classifier learning, are often\nmistakenly treated as noises in such a setting since both the hard samples and\nones with noisy labels lead to a relatively larger loss value than the easy\ncases. In this paper, we propose a plugin module, namely noise ignoring block\n(NIB), consisting of a probability transition matrix and an inter-class\ncorrelation (IC) loss, to separate the hard samples from the mislabeled ones,\nand further boost the accuracy of image classification network trained with\nnoisy labels. Concretely, our IC loss is calculated as Kullback-Leibler\ndivergence between the network prediction and the accumulative soft label\ngenerated by the probability transition matrix. Such that, with the lower value\nof IC loss, the hard cases can be easily distinguished from mislabeled cases.\nExtensive experiments are conducted on natural and medical image datasets\n(CIFAR-10 and ISIC 2019). The experimental results show that our NIB module\nconsistently improves the performances of the state-of-the-art robust training\nmethods.",
    "descriptor": "",
    "authors": [
      "Ziqi Zhang",
      "Yuexiang Li",
      "Hongxin Wei",
      "Kai Ma",
      "Tao Xu",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08866"
  },
  {
    "id": "arXiv:2110.08871",
    "title": "Noise-robust Clustering",
    "abstract": "This paper presents noise-robust clustering techniques in unsupervised\nmachine learning. The uncertainty about the noise, consistency, and other\nambiguities can become severe obstacles in data analytics. As a result, data\nquality, cleansing, management, and governance remain critical disciplines when\nworking with Big Data. With this complexity, it is no longer sufficient to\ntreat data deterministically as in a classical setting, and it becomes\nmeaningful to account for noise distribution and its impact on data sample\nvalues. Classical clustering methods group data into \"similarity classes\"\ndepending on their relative distances or similarities in the underlying space.\nThis paper addressed this problem via the extension of classical $K$-means and\n$K$-medoids clustering over data distributions (rather than the raw data). This\ninvolves measuring distances among distributions using two types of measures:\nthe optimal mass transport (also called Wasserstein distance, denoted $W_2$)\nand a novel distance measure proposed in this paper, the expected value of\nrandom variable distance (denoted ED). The presented distribution-based\n$K$-means and $K$-medoids algorithms cluster the data distributions first and\nthen assign each raw data to the cluster of data's distribution.",
    "descriptor": "",
    "authors": [
      "Rahmat Adesunkanmi",
      "Ratnesh Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.08871"
  },
  {
    "id": "arXiv:2110.08872",
    "title": "Contrastive Learning of Visual-Semantic Embeddings",
    "abstract": "Contrastive learning is a powerful technique to learn representations that\nare semantically distinctive and geometrically invariant. While most of the\nearlier approaches have demonstrated its effectiveness on single-modality\nlearning tasks such as image classification, recently there have been a few\nattempts towards extending this idea to multi-modal data. In this paper, we\npropose two loss functions based on normalized cross-entropy to perform the\ntask of learning joint visual-semantic embedding using batch contrastive\ntraining. In a batch, for a given anchor point from one modality, we consider\nits negatives only from another modality, and define our first contrastive loss\nbased on expected violations incurred by all the negatives. Next, we update\nthis loss and define the second contrastive loss based on the violation\nincurred only by the hardest negative. We compare our results with existing\nvisual-semantic embedding methods on cross-modal image-to-text and\ntext-to-image retrieval tasks using the MS-COCO and Flickr30K datasets, where\nwe outperform the state-of-the-art on the MS-COCO dataset and achieve\ncomparable results on the Flickr30K dataset.",
    "descriptor": "",
    "authors": [
      "Anurag Jain",
      "Yashaswi Verma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.08872"
  },
  {
    "id": "arXiv:2110.08874",
    "title": "Prioritization of COVID-19-related literature via unsupervised keyphrase  extraction and document representation learning",
    "abstract": "The COVID-19 pandemic triggered a wave of novel scientific literature that is\nimpossible to inspect and study in a reasonable time frame manually. Current\nmachine learning methods offer to project such body of literature into the\nvector space, where similar documents are located close to each other, offering\nan insightful exploration of scientific papers and other knowledge sources\nassociated with COVID-19. However, to start searching, such texts need to be\nappropriately annotated, which is seldom the case due to the lack of human\nresources. In our system, the current body of COVID-19-related literature is\nannotated using unsupervised keyphrase extraction, facilitating the initial\nqueries to the latent space containing the learned document embeddings\n(low-dimensional representations). The solution is accessible through a web\nserver capable of interactive search, term ranking, and exploration of\npotentially interesting literature. We demonstrate the usefulness of the\napproach via case studies from the medicinal chemistry domain.",
    "descriptor": "",
    "authors": [
      "Bla\u017e \u0160krlj",
      "Marko Juki\u010d",
      "Nika Er\u017een",
      "Senja Pollak",
      "Nada Lavra\u010d"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2110.08874"
  },
  {
    "id": "arXiv:2110.08875",
    "title": "Predicting the Performance of Multilingual NLP Models",
    "abstract": "Recent advancements in NLP have given us models like mBERT and XLMR that can\nserve over 100 languages. The languages that these models are evaluated on,\nhowever, are very few in number, and it is unlikely that evaluation datasets\nwill cover all the languages that these models support. Potential solutions to\nthe costly problem of dataset creation are to translate datasets to new\nlanguages or use template-filling based techniques for creation. This paper\nproposes an alternate solution for evaluating a model across languages which\nmake use of the existing performance scores of the model on languages that a\nparticular task has test sets for. We train a predictor on these performance\nscores and use this predictor to predict the model's performance in different\nevaluation settings. Our results show that our method is effective in filling\nthe gaps in the evaluation for an existing set of languages, but might require\nadditional improvements if we want it to generalize to unseen languages.",
    "descriptor": "",
    "authors": [
      "Anirudh Srinivasan",
      "Sunayana Sitaram",
      "Tanuja Ganu",
      "Sandipan Dandapat",
      "Kalika Bali",
      "Monojit Choudhury"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08875"
  },
  {
    "id": "arXiv:2110.08879",
    "title": "Dynamic Tolling for Inducing Socially Optimal Traffic Loads",
    "abstract": "How to design tolls that induce socially optimal traffic loads with\ndynamically arriving travelers who make selfish routing decisions? We propose a\ntwo-timescale discrete-time stochastic dynamics that adaptively adjusts the\ntoll prices on a parallel link network while accounting for the updates of\ntraffic loads induced by the incoming and outgoing travelers and their route\nchoices. The updates of loads and tolls in our dynamics have three key\nfeatures: (i) The total demand of incoming and outgoing travelers is\nstochastically realized; (ii) Travelers are myopic and selfish in that they\nchoose routes according to a perturbed best response given the current latency\nand tolls on parallel links; (iii) The update of tolls is at a slower timescale\nas compared to the the update of loads. We show that the loads and the tolls\neventually concentrate in a neighborhood of the fixed point, which corresponds\nto the socially optimal load and toll price. Moreover, the fixed point load is\nalso a stochastic user equilibrium with respect to the toll price. Our results\nare useful for traffic authorities to efficiently manage traffic loads in\nresponse to the arrival and departure of travelers.",
    "descriptor": "\nComments: 18 pages, 3 figures\n",
    "authors": [
      "Chinmay Maheshwari",
      "Kshitij Kulkarni",
      "Manxi Wu",
      "Shankar Sastry"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.08879"
  },
  {
    "id": "arXiv:2110.08883",
    "title": "Blockchain Enabled Secure Authentication for Unmanned Aircraft Systems",
    "abstract": "The integration of air and ground smart vehicles is becoming a new paradigm\nof future transportation. A decent number of smart unmanned vehicles or UAS\nwill be sharing the national airspace for various purposes, such as express\ndelivery, surveillance, etc. However, the proliferation of UAS also brings\nchallenges considering the safe integration of them into the current Air\nTraffic Management (ATM) systems. Especially when the current Automatic\nDependent Surveillance Broadcasting (ADS-B) systems do not have message\nauthentication mechanisms, it can not distinguish whether an authorized UAS is\nusing the corresponding airspace. In this paper, we aim to address these\npractical challenges in two folds. We first use blockchain to provide a secure\nauthentication platform for flight plan approval and sharing between the\nexisting ATM facilities. We then use the fountain code to encode the\nauthentication payloads and adapt them into the de facto communication protocol\nof ATM. This maintains backward compatibility and ensures the verification\nsuccess rate under the noisy broadcasting channel. We simulate the realistic\nwireless communication scenarios and theoretically prove that our proposed\nauthentication framework is with low latency and highly compatible with\nexisting ATM communication protocols.",
    "descriptor": "\nComments: Accepted for publication in IEEE GlobalCom as a workshop paper\n",
    "authors": [
      "Yongxin Liu",
      "Jian Wang",
      "Yingjie Chen",
      "Shuteng Niu",
      "Zhihan Lv",
      "Lei Wu",
      "Dahai Liu",
      "Houbing Song"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.08883"
  },
  {
    "id": "arXiv:2110.08886",
    "title": "On Monotonicity of Number-Partitioning Algorithms",
    "abstract": "An algorithm for number-partitioning is called value-monotone if whenever one\nof the input numbers increases, the objective function (the largest sum or the\nsmallest sum of a subset in the output) weakly increases. This note proves that\nthe List Scheduling algorithm and the Longest Processing Time algorithm are\nboth value-monotone. This is in contrast to another algorithm -- MultiFit --\nwhich is not value-monotone.",
    "descriptor": "\nComments: I needed this lemma for something else, and could not find it anywhere, so I wrote a short proof. Is it already known?\n",
    "authors": [
      "Erel Segal-Halevi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.08886"
  },
  {
    "id": "arXiv:2110.08887",
    "title": "Schr\u00f6dinger's Tree -- On Syntax and Neural Language Models",
    "abstract": "In the last half-decade, the field of natural language processing (NLP) has\nundergone two major transitions: the switch to neural networks as the primary\nmodeling paradigm and the homogenization of the training regime (pre-train,\nthen fine-tune). Amidst this process, language models have emerged as NLP's\nworkhorse, displaying increasingly fluent generation capabilities and proving\nto be an indispensable means of knowledge transfer downstream. Due to the\notherwise opaque, black-box nature of such models, researchers have employed\naspects of linguistic theory in order to characterize their behavior. Questions\ncentral to syntax -- the study of the hierarchical structure of language --\nhave factored heavily into such work, shedding invaluable insights about\nmodels' inherent biases and their ability to make human-like generalizations.\nIn this paper, we attempt to take stock of this growing body of literature. In\ndoing so, we observe a lack of clarity across numerous dimensions, which\ninfluences the hypotheses that researchers form, as well as the conclusions\nthey draw from their findings. To remedy this, we urge researchers make careful\nconsiderations when investigating coding properties, selecting representations,\nand evaluating via downstream tasks. Furthermore, we outline the implications\nof the different types of research questions exhibited in studies on syntax, as\nwell as the inherent pitfalls of aggregate metrics. Ultimately, we hope that\nour discussion adds nuance to the prospect of studying language models and\npaves the way for a less monolithic perspective on syntax in this context.",
    "descriptor": "\nComments: preprint, submitted to Frontiers in Artificial Intelligence: Perspectives for Natural Language Processing between AI, Linguistics and Cognitive Science\n",
    "authors": [
      "Artur Kulmizev",
      "Joakim Nivre"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08887"
  },
  {
    "id": "arXiv:2110.08889",
    "title": "Neural-adaptive Stochastic Attitude Filter on SO(3)",
    "abstract": "Successful control of a rigid-body rotating in three dimensional space\nrequires accurate estimation of its attitude. The attitude dynamics are highly\nnonlinear and are posed on the Special Orthogonal Group $SO(3)$. In addition,\nmeasurements supplied by low-cost sensing units pose a challenge for the\nestimation process. This paper proposes a novel stochastic nonlinear\nneural-adaptive-based filter on $SO(3)$ for the attitude estimation problem.\nThe proposed filter produces good results given measurements extracted from\nlow-cost sensing units (e.g., IMU or MARG sensor modules). The filter is\nguaranteed to be almost semi-globally uniformly ultimately bounded in the mean\nsquare. In addition to Lie Group formulation, quaternion representation of the\nproposed filter is provided. The effectiveness of the proposed neural-adaptive\nfilter is tested and evaluated in its discrete form under the conditions of\nlarge initialization error and high measurement uncertainties. keywords /\nindex-terms: Neuro-adaptive, stochastic differential equations (SDEs), Brownian\nmotion process, attitude estimator, Special Orthogonal Group, Unit-quaternion,\nSO(3), IMU, MARG.",
    "descriptor": "\nComments: IEEE Control Systems Letters\n",
    "authors": [
      "Hashim A. Hashim",
      "Mohammed Abouheaf",
      "Kyriakos G. Vamvoudakis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.08889"
  },
  {
    "id": "arXiv:2110.08890",
    "title": "Network Augmentation for Tiny Deep Learning",
    "abstract": "We introduce Network Augmentation (NetAug), a new training method for\nimproving the performance of tiny neural networks. Existing regularization\ntechniques (e.g., data augmentation, dropout) have shown much success on large\nneural networks (e.g., ResNet50) by adding noise to overcome over-fitting.\nHowever, we found these techniques hurt the performance of tiny neural\nnetworks. We argue that training tiny models are different from large models:\nrather than augmenting the data, we should augment the model, since tiny models\ntend to suffer from under-fitting rather than over-fitting due to limited\ncapacity. To alleviate this issue, NetAug augments the network (reverse\ndropout) instead of inserting noise into the dataset or the network. It puts\nthe tiny model into larger models and encourages it to work as a sub-model of\nlarger models to get extra supervision, in addition to functioning as an\nindependent model. At test time, only the tiny model is used for inference,\nincurring zero inference overhead. We demonstrate the effectiveness of NetAug\non image classification and object detection. NetAug consistently improves the\nperformance of tiny models, achieving up to 2.1% accuracy improvement on\nImageNet, and 4.3% on Cars. On Pascal VOC, NetAug provides 2.96% mAP\nimprovement with the same computational cost.",
    "descriptor": "",
    "authors": [
      "Han Cai",
      "Chuang Gan",
      "Ji Lin",
      "Song Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08890"
  },
  {
    "id": "arXiv:2110.08893",
    "title": "Temporally stable video segmentation without video annotations",
    "abstract": "Temporally consistent dense video annotations are scarce and hard to collect.\nIn contrast, image segmentation datasets (and pre-trained models) are\nubiquitous, and easier to label for any novel task. In this paper, we introduce\na method to adapt still image segmentation models to video in an unsupervised\nmanner, by using an optical flow-based consistency measure. To ensure that the\ninferred segmented videos appear more stable in practice, we verify that the\nconsistency measure is well correlated with human judgement via a user study.\nTraining a new multi-input multi-output decoder using this measure as a loss,\ntogether with a technique for refining current image segmentation datasets and\na temporal weighted-guided filter, we observe stability improvements in the\ngenerated segmented videos with minimal loss of accuracy.",
    "descriptor": "",
    "authors": [
      "Aharon Azulay",
      "Tavi Halperin",
      "Orestis Vantzos",
      "Nadav Bornstein",
      "Ofir Bibi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08893"
  },
  {
    "id": "arXiv:2110.08895",
    "title": "Deep Clustering For General-Purpose Audio Representations",
    "abstract": "We introduce DECAR, a self-supervised pre-training approach for learning\ngeneral-purpose audio representations. Our system is based on clustering: it\nutilizes an offline clustering step to provide target labels that act as\npseudo-labels for solving a prediction task. We develop on top of recent\nadvances in self-supervised learning for computer vision and design a\nlightweight, easy-to-use self-supervised pre-training scheme. We pre-train\nDECAR embeddings on a balanced subset of the large-scale Audioset dataset and\ntransfer those representations to 9 downstream classification tasks, including\nspeech, music, animal sounds, and acoustic scenes. Furthermore, we conduct\nablation studies identifying key design choices and also make all our code and\npre-trained models publicly available.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Sreyan Ghosh",
      "Sandesh V Katta",
      "Ashish Seth",
      "S. Umesh"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.08895"
  },
  {
    "id": "arXiv:2110.08896",
    "title": "Damped Anderson Mixing for Deep Reinforcement Learning: Acceleration,  Convergence, and Stabilization",
    "abstract": "Anderson mixing has been heuristically applied to reinforcement learning (RL)\nalgorithms for accelerating convergence and improving the sampling efficiency\nof deep RL. Despite its heuristic improvement of convergence, a rigorous\nmathematical justification for the benefits of Anderson mixing in RL has not\nyet been put forward. In this paper, we provide deeper insights into a class of\nacceleration schemes built on Anderson mixing that improve the convergence of\ndeep RL algorithms. Our main results establish a connection between Anderson\nmixing and quasi-Newton methods and prove that Anderson mixing increases the\nconvergence radius of policy iteration schemes by an extra contraction factor.\nThe key focus of the analysis roots in the fixed-point iteration nature of RL.\nWe further propose a stabilization strategy by introducing a stable\nregularization term in Anderson mixing and a differentiable, non-expansive\nMellowMax operator that can allow both faster convergence and more stable\nbehavior. Extensive experiments demonstrate that our proposed method enhances\nthe convergence, stability, and performance of RL algorithms.",
    "descriptor": "",
    "authors": [
      "Ke Sun",
      "Yafei Wang",
      "Yi Liu",
      "Yingnan Zhao",
      "Bo Pan",
      "Shangling Jui",
      "Bei Jiang",
      "Linglong Kong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.08896"
  },
  {
    "id": "arXiv:2110.08898",
    "title": "Spy game: FPT-algorithm, hardness and graph products",
    "abstract": "In the $(s,d)$-spy game over a graph $G$, $k$ guards and one spy occupy some\nvertices of $G$ and, at each turn, the spy may move with speed $s$ (along at\nmost $s$ edges) and each guard may move along one edge. The spy and the guards\nmay occupy the same vertices. The spy wins if she reaches a vertex at distance\nmore than the surveilling distance $d$ from every guard. This game was\nintroduced by Cohen et al. in 2016 and is related to two well-studied games:\nCops and robber game and Eternal Dominating game. The guard number\n$gn_{s,d}(G)$ is the minimum number of guards such that the guards have a\nwinning strategy (of controlling the spy) in the graph $G$. In 2018, it was\nproved that deciding if the spy has a winning strategy is NP-hard for every\nspeed $s\\geq 2$ and distance $d\\geq 0$. In this paper, we initiate the\ninvestigation of the guard number in grids and in graph products. We obtain a\nstrict upper bound on the strong product of two general graphs and obtain\nexamples with King grids that match this bound and other examples for which the\nguard number is smaller. We also obtain the exact value of the guard number in\nthe lexicographical product of two general graphs for any distance $d\\geq 2$.\nFrom the algorithmic point of view, we prove a positive result: if the number\n$k$ of guards is fixed, the spy game is solvable in polynomial XP time\n$O(n^{3k+2})$ for every speed $s\\geq 2$ and distance $d\\geq 0$. In other words,\nthe spy game is XP when parameterized by the number of guards. This XP\nalgorithm is used to obtain an FPT algorithm on the $P_4$-fewness of the graph.\nAs a negative result, we prove that the spy game is W[2]-hard even in bipartite\ngraphs when parameterized by the number of guards, for every speed $s\\geq 2$\nand distance $d\\geq 0$, extending the hardness result of Cohen et al. in 2018.",
    "descriptor": "\nComments: 17 pages, 9 figures\n",
    "authors": [
      "Eurinardo Costa",
      "Nicolas Martins",
      "Rudini Sampaio"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.08898"
  },
  {
    "id": "arXiv:2110.08902",
    "title": "Green Simulation Assisted Policy Gradient to Accelerate Stochastic  Process Control",
    "abstract": "This study is motivated by the critical challenges in the biopharmaceutical\nmanufacturing, including high complexity, high uncertainty, and very limited\nprocess data. Each experiment run is often very expensive. To support the\noptimal and robust process control, we propose a general green simulation\nassisted policy gradient (GS-PG) framework for both online and offline learning\nsettings. Basically, to address the key limitations of state-of-art\nreinforcement learning (RL), such as sample inefficiency and low reliability,\nwe create a mixture likelihood ratio based policy gradient estimation that can\nleverage on the information from historical experiments conducted under\ndifferent inputs, including process model coefficients and decision policy\nparameters. Then, to accelerate the learning of optimal and robust policy, we\nfurther propose a variance reduction based sample selection method that allows\nGS-PG to intelligently select and reuse most relevant historical trajectories.\nThe selection rule automatically updates the samples to be reused during the\nlearning of process mechanisms and the search for optimal policy. Our\ntheoretical and empirical studies demonstrate that the proposed framework can\nperform better than the state-of-art policy gradient approach and accelerate\nthe optimal robust process control for complex stochastic systems under high\nuncertainty.",
    "descriptor": "\nComments: 36 pages, 7 figures\n",
    "authors": [
      "Hua Zheng",
      "Wei Xie",
      "M. Ben Feng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08902"
  },
  {
    "id": "arXiv:2110.08904",
    "title": "Deep forecasting of translational impact in medical research",
    "abstract": "The value of biomedical research--a $1.7 trillion annual investment--is\nultimately determined by its downstream, real-world impact. Current objective\npredictors of impact rest on proxy, reductive metrics of dissemination, such as\npaper citation rates, whose relation to real-world translation remains\nunquantified. Here we sought to determine the comparative predictability of\nfuture real-world translation--as indexed by inclusion in patents, guidelines\nor policy documents--from complex models of the abstract-level content of\nbiomedical publications versus citations and publication meta-data alone. We\ndevelop a suite of representational and discriminative mathematical models of\nmulti-scale publication data, quantifying predictive performance out-of-sample,\nahead-of-time, across major biomedical domains, using the entire corpus of\nbiomedical research captured by Microsoft Academic Graph from 1990 to 2019,\nencompassing 43.3 million papers across all domains. We show that citations are\nonly moderately predictive of translational impact as judged by inclusion in\npatents, guidelines, or policy documents. By contrast, high-dimensional models\nof publication titles, abstracts and metadata exhibit high fidelity (AUROC >\n0.9), generalise across time and thematic domain, and transfer to the task of\nrecognising papers of Nobel Laureates. The translational impact of a paper\nindexed by inclusion in patents, guidelines, or policy documents can be\npredicted--out-of-sample and ahead-of-time--with substantially higher fidelity\nfrom complex models of its abstract-level content than from models of\npublication meta-data or citation metrics. We argue that content-based models\nof impact are superior in performance to conventional, citation-based measures,\nand sustain a stronger evidence-based claim to the objective measurement of\ntranslational potential.",
    "descriptor": "\nComments: 28 pages, 6 figures\n",
    "authors": [
      "Amy PK Nelson",
      "Robert J Gray",
      "James K Ruffle",
      "Henry C Watkins",
      "Daniel Herron",
      "Nick Sorros",
      "Danil Mikhailov",
      "M. Jorge Cardoso",
      "Sebastien Ourselin",
      "Nick McNally",
      "Bryan Williams",
      "Geraint E. Rees",
      "Parashkev Nachev"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08904"
  },
  {
    "id": "arXiv:2110.08906",
    "title": "Characterizing and Improving the Resilience of Accelerators in  Autonomous Robots",
    "abstract": "Motion planning is a computationally intensive and well-studied problem in\nautonomous robots. However, motion planning hardware accelerators (MPA) must be\nsoft-error resilient for deployment in safety-critical applications, and\nblanket application of traditional mitigation techniques is ill-suited due to\ncost, power, and performance overheads. We propose Collision Exposure Factor\n(CEF), a novel metric to assess the failure vulnerability of circuits\nprocessing spatial relationships, including motion planning. CEF is based on\nthe insight that the safety violation probability increases with the surface\narea of the physical space exposed by a bit-flip. We evaluate CEF on four MPAs.\nWe demonstrate empirically that CEF is correlated with safety violation\nprobability, and that CEF-aware selective error mitigation provides 12.3x,\n9.6x, and 4.2x lower Failures-In-Time (FIT) rate on average for the same amount\nof protected memory compared to uniform, bit-position, and\naccess-frequency-aware selection of critical data. Furthermore, we show how to\nemploy CEF to enable fault characterization using 23,000x fewer fault injection\n(FI) experiments than exhaustive FI, and evaluate our FI approach on different\nrobots and MPAs. We demonstrate that CEF-aware FI can provide insights on\nvulnerable bits in an MPA while taking the same amount of time as uniform\nstatistical FI. Finally, we use the CEF to formulate guidelines for designing\nsoft-error resilient MPAs.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Deval Shah",
      "Zi Yu Xue",
      "Karthik Pattabiraman",
      "Tor M. Aamodt"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.08906"
  },
  {
    "id": "arXiv:2110.08908",
    "title": "Studying Eventual Connectivity Issues in Android Apps",
    "abstract": "Mobile apps have become indispensable for daily life, not only for\nindividuals but also for companies/organizations that offer their services\ndigitally. Inherited by the mobility of devices, there are no limitations\nregarding the locations or conditions in which apps are being used. For\nexample, apps can be used where no internet connection is available. Therefore,\noffline-first is a highly desired quality of mobile apps. Accordingly,\ninappropriate handling of connectivity issues and miss-implementation of good\npractices lead to bugs and crashes occurrences that reduce the confidence of\nusers on the apps' quality. In this paper, we present the first study on\nEventual Connectivity (ECn) issues exhibited by Android apps, by manually\ninspecting 971 scenarios related to 50 open-source apps. We found 304 instances\nof ECn issues (6 issues per app, on average) that we organized in a taxonomy of\n10 categories. We found that the majority of ECn issues are related to the use\nof messages not providing correct information to the user about the\nconnectivity status and to the improper use of external libraries/apps to which\nthe check of the connectivity status is delegated. Based on our findings, we\ndistill a list of lessons learned for both practitioners and researchers,\nindicating directions for future work.",
    "descriptor": "\nComments: 41 pages, accepted to EMSE journal\n",
    "authors": [
      "Camilo Escobar-Vel\u00e1squez",
      "Alejandro Mazuera-Rozo",
      "Claudia Bedoya",
      "Michael Osorio-Ria\u00f1o",
      "Mario Linares-V\u00e1squez",
      "Gabriele Bavota"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.08908"
  },
  {
    "id": "arXiv:2110.08913",
    "title": "Real Time Cluster Path Tracing",
    "abstract": "Photorealistic rendering effects are common in films, but most real time\ngraphics today still rely on scan-line based multi-pass rendering to deliver\nrich visual experiences. While there have been prior works in distributed path\ntracing for static scene and objects under rigid motion, real time path tracing\nof deforming characters has to support per-frame dynamic BVH changes. We\npresent the architecture and implementation of the first real-time production\nquality cluster path tracing renderer that supports film quality animation and\ndeformation. We build our cluster path tracing system using the open source\nBlender and its GPU accelerated production quality renderer Cycles. Our\nsystem's rendering performance and quality scales linearly with the number of\nRTX cluster nodes used. It is able to generate and deliver path traced images\nwith global illumination effects to remote light-weight client systems at 15-30\nframes per second for a variety of Blender scenes including animated digital\nhuman characters with skin deformation and virtual objects.",
    "descriptor": "\nComments: 5 pages, 7 figures. To be published in Siggraph Asia 2021's telecommunication program\n",
    "authors": [
      "Feng Xie",
      "Petro Mishchuk",
      "Warren Hunt"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.08913"
  },
  {
    "id": "arXiv:2110.08918",
    "title": "Using Clinical Drug Representations for Improving Mortality and Length  of Stay Predictions",
    "abstract": "Drug representations have played an important role in cheminformatics.\nHowever, in the healthcare domain, drug representations have been underused\nrelative to the rest of Electronic Health Record (EHR) data, due to the\ncomplexity of high dimensional drug representations and the lack of proper\npipeline that will allow to convert clinical drugs to their representations.\nTime-varying vital signs, laboratory measurements, and related time-series\nsignals are commonly used to predict clinical outcomes. In this work, we\ndemonstrated that using clinical drug representations in addition to other\nclinical features has significant potential to increase the performance of\nmortality and length of stay (LOS) models. We evaluate the two different drug\nrepresentation methods (Extended-Connectivity Fingerprint-ECFP and\nSMILES-Transformer embedding) on clinical outcome predictions. The results have\nshown that the proposed multimodal approach achieves substantial enhancement on\nclinical tasks over baseline models. Using clinical drug representations as\nadditional features improve the LOS prediction for Area Under the Receiver\nOperating Characteristics (AUROC) around %6 and for Area Under Precision-Recall\nCurve (AUPRC) by around %5. Furthermore, for the mortality prediction task,\nthere is an improvement of around %2 over the time series baseline in terms of\nAUROC and %3.5 in terms of AUPRC. The code for the proposed method is available\nat https://github.com/tanlab/MIMIC-III-Clinical-Drug-Representations.",
    "descriptor": "\nComments: Published in IEEE CIBCB 2021\n",
    "authors": [
      "Batuhan Bardak",
      "Mehmet Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2110.08918"
  },
  {
    "id": "arXiv:2110.08919",
    "title": "Low-Precision Quantization for Efficient Nearest Neighbor Search",
    "abstract": "Fast k-Nearest Neighbor search over real-valued vector spaces (KNN) is an\nimportant algorithmic task for information retrieval and recommendation\nsystems. We present a method for using reduced precision to represent vectors\nthrough quantized integer values, enabling both a reduction in the memory\noverhead of indexing these vectors and faster distance computations at query\ntime. While most traditional quantization techniques focus on minimizing the\nreconstruction error between a point and its uncompressed counterpart, we focus\ninstead on preserving the behavior of the underlying distance metric.\nFurthermore, our quantization approach is applied at the implementation level\nand can be combined with existing KNN algorithms. Our experiments on both open\nsource and proprietary datasets across multiple popular KNN frameworks validate\nthat quantized distance metrics can reduce memory by 60% and improve query\nthroughput by 30%, while incurring only a 2% reduction in recall.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Anthony Ko",
      "Iman Keivanloo",
      "Vihan Lakshman",
      "Eric Schkufza"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.08919"
  },
  {
    "id": "arXiv:2110.08920",
    "title": "Semantics of Conjectures",
    "abstract": "This paper aims to expand and detail the notion of formal semantics of\nConjectures by applying a theoretic-model approach. After a short introduction\nto the concepts and basics of Conjectures, we will start from the notion of\nSimple Interpretation of RDF, applying and extending the semantic rules and\nconditions to fully cover the concepts and features of Conjectures.",
    "descriptor": "\nComments: 17 pages, 1 figure\n",
    "authors": [
      "Alessio Rolfini"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.08920"
  },
  {
    "id": "arXiv:2110.08922",
    "title": "Explaining generalization in deep learning: progress and fundamental  limits",
    "abstract": "This dissertation studies a fundamental open challenge in deep learning\ntheory: why do deep networks generalize well even while being\noverparameterized, unregularized and fitting the training data to zero error?\nIn the first part of the thesis, we will empirically study how training deep\nnetworks via stochastic gradient descent implicitly controls the networks'\ncapacity. Subsequently, to show how this leads to better generalization, we\nwill derive {\\em data-dependent} {\\em uniform-convergence-based} generalization\nbounds with improved dependencies on the parameter count.\nUniform convergence has in fact been the most widely used tool in deep\nlearning literature, thanks to its simplicity and generality. Given its\npopularity, in this thesis, we will also take a step back to identify the\nfundamental limits of uniform convergence as a tool to explain generalization.\nIn particular, we will show that in some example overparameterized settings,\n{\\em any} uniform convergence bound will provide only a vacuous generalization\nbound.\nWith this realization in mind, in the last part of the thesis, we will change\ncourse and introduce an {\\em empirical} technique to estimate generalization\nusing unlabeled data. Our technique does not rely on any notion of\nuniform-convergece-based complexity and is remarkably precise. We will\ntheoretically show why our technique enjoys such precision.\nWe will conclude by discussing how future work could explore novel ways to\nincorporate distributional assumptions in generalization bounds (such as in the\nform of unlabeled data) and explore other tools to derive bounds, perhaps by\nmodifying uniform convergence or by developing completely new tools altogether.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1902.04742\n",
    "authors": [
      "Vaishnavh Nagarajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.08922"
  },
  {
    "id": "arXiv:2110.08923",
    "title": "A Dual Approach to Constrained Markov Decision Processes with Entropy  Regularization",
    "abstract": "We study entropy-regularized constrained Markov decision processes (CMDPs)\nunder the soft-max parameterization, in which an agent aims to maximize the\nentropy-regularized value function while satisfying constraints on the expected\ntotal utility. By leveraging the entropy regularization, our theoretical\nanalysis shows that its Lagrangian dual function is smooth and the Lagrangian\nduality gap can be decomposed into the primal optimality gap and the constraint\nviolation. Furthermore, we propose an accelerated dual-descent method for\nentropy-regularized CMDPs. We prove that our method achieves the global\nconvergence rate $\\widetilde{\\mathcal{O}}(1/T)$ for both the optimality gap and\nthe constraint violation for entropy-regularized CMDPs. A discussion about a\nlinear convergence rate for CMDPs with a single constraint is also provided.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Donghao Ying",
      "Yuhao Ding",
      "Javad Lavaei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.08923"
  },
  {
    "id": "arXiv:2110.08924",
    "title": "Sensor Scheduling for Linear Systems: A Covariance Tracking Approach",
    "abstract": "We consider the classical sensor scheduling problem for linear systems where\nonly one sensor is activated at each time. We show that the sensor scheduling\nproblem has a close relation to the sensor design problem and the solution of a\nsensor schedule problem can be extracted from an equivalent sensor design\nproblem. We propose a convex relaxation to the sensor design problem and a\nreference covariance trajectory is obtained from solving the relaxed sensor\ndesign problem. Afterwards, a covariance tracking algorithm is designed to\nobtain an approximate solution to the sensor scheduling problem using the\nreference covariance trajectory obtained from the sensor design problem. While\nthe sensor scheduling problem is NP-hard, the proposed framework circumvents\nthis computational complexity by decomposing this problem into a convex sensor\ndesign problem and a covariance tracking problem. We provide theoretical\njustification and a sub-optimality bound for the proposed method using dynamic\nprogramming. The proposed method is validated over several experiments\nportraying the efficacy of the framework.",
    "descriptor": "\nComments: To appear in Automatica\n",
    "authors": [
      "Dipankar Maity",
      "David Hartman",
      "John S. Baras"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.08924"
  },
  {
    "id": "arXiv:2110.08927",
    "title": "MARTINI: Smart Meter Driven Estimation of HVAC Schedules and Energy  Savings Based on WiFi Sensing and Clustering",
    "abstract": "HVAC systems account for a significant portion of building energy use.\nNighttime setback scheduling is an energy conservation measure where cooling\nand heating setpoints are increased and decreased respectively during\nunoccupied periods with the goal of obtaining energy savings. However,\nknowledge of a building's real occupancy is required to maximize the success of\nthis measure. In addition, there is the need for a scalable way to estimate\nenergy savings potential from energy conservation measures that is not limited\nby building specific parameters and experimental or simulation modeling\ninvestments. Here, we propose MARTINI, a sMARt meTer drIveN estImation of\noccupant-derived HVAC schedules and energy savings that leverages the ubiquity\nof energy smart meters and WiFi infrastructure in commercial buildings. We\nestimate the schedules by clustering WiFi-derived occupancy profiles and,\nenergy savings by shifting ramp-up and setback times observed in\ntypical/measured load profiles obtained by clustering smart meter energy\nprofiles. Our case-study results with five buildings over seven months show an\naverage of 8.1%-10.8% (summer) and 0.2%-5.9% (fall) chilled water energy\nsavings when HVAC system operation is aligned with occupancy. We validate our\nmethod with results from building energy performance simulation (BEPS) and find\nthat estimated average savings of MARTINI are within 0.9%-2.4% of the BEPS\npredictions. In the absence of occupancy information, we can still estimate\npotential savings from increasing ramp-up time and decreasing setback start\ntime. In 51 academic buildings, we find savings potentials between 1%-5%.",
    "descriptor": "\nComments: submitted\n",
    "authors": [
      "Kingsley Nweye",
      "Zoltan Nagy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08927"
  },
  {
    "id": "arXiv:2110.08931",
    "title": "Quantifying the Task-Specific Information in Text-Based Classifications",
    "abstract": "Recently, neural natural language models have attained state-of-the-art\nperformance on a wide variety of tasks, but the high performance can result\nfrom superficial, surface-level cues (Bender and Koller, 2020; Niven and Kao,\n2020). These surface cues, as the ``shortcuts'' inherent in the datasets, do\nnot contribute to the *task-specific information* (TSI) of the classification\ntasks. While it is essential to look at the model performance, it is also\nimportant to understand the datasets. In this paper, we consider this question:\nApart from the information introduced by the shortcut features, how much\ntask-specific information is required to classify a dataset? We formulate this\nquantity in an information-theoretic framework. While this quantity is hard to\ncompute, we approximate it with a fast and stable method. TSI quantifies the\namount of linguistic knowledge modulo a set of predefined shortcuts -- that\ncontributes to classifying a sample from each dataset. This framework allows us\nto compare across datasets, saying that, apart from a set of ``shortcut\nfeatures'', classifying each sample in the Multi-NLI task involves around 0.4\nnats more TSI than in the Quora Question Pair.",
    "descriptor": "",
    "authors": [
      "Zining Zhu",
      "Aparna Balagopalan",
      "Marzyeh Ghassemi",
      "Frank Rudzicz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08931"
  },
  {
    "id": "arXiv:2110.08932",
    "title": "Poisoning Attacks on Fair Machine Learning",
    "abstract": "Both fair machine learning and adversarial learning have been extensively\nstudied. However, attacking fair machine learning models has received less\nattention. In this paper, we present a framework that seeks to effectively\ngenerate poisoning samples to attack both model accuracy and algorithmic\nfairness. Our attacking framework can target fair machine learning models\ntrained with a variety of group based fairness notions such as demographic\nparity and equalized odds. We develop three online attacks, adversarial\nsampling , adversarial labeling, and adversarial feature modification. All\nthree attacks effectively and efficiently produce poisoning samples via\nsampling, labeling, or modifying a fraction of training data in order to reduce\nthe test accuracy. Our framework enables attackers to flexibly adjust the\nattack's focus on prediction accuracy or fairness and accurately quantify the\nimpact of each candidate point to both accuracy loss and fairness violation,\nthus producing effective poisoning samples. Experiments on two real datasets\ndemonstrate the effectiveness and efficiency of our framework.",
    "descriptor": "",
    "authors": [
      "Minh-Hao Van",
      "Wei Du",
      "Xintao Wu",
      "Aidong Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.08932"
  },
  {
    "id": "arXiv:2110.08934",
    "title": "On the Effect of Selfie Beautification Filters on Face Detection and  Recognition",
    "abstract": "Beautification and augmented reality filters are very popular in applications\nthat use selfie images captured with smartphones or personal devices. However,\nthey can distort or modify biometric features, severely affecting the\ncapability of recognizing individuals' identity or even detecting the face.\nAccordingly, we address the effect of such filters on the accuracy of automated\nface detection and recognition. The social media image filters studied either\nmodify the image contrast or illumination or occlude parts of the face with for\nexample artificial glasses or animal noses. We observe that the effect of some\nof these filters is harmful both to face detection and identity recognition,\nspecially if they obfuscate the eye or (to a lesser extent) the nose. To\ncounteract such effect, we develop a method to reconstruct the applied\nmanipulation with a modified version of the U-NET segmentation network. This is\nobserved to contribute to a better face detection and recognition accuracy.\nFrom a recognition perspective, we employ distance measures and trained machine\nlearning algorithms applied to features extracted using a ResNet-34 network\ntrained to recognize faces. We also evaluate if incorporating filtered images\nto the training set of machine learning approaches are beneficial for identity\nrecognition. Our results show good recognition when filters do not occlude\nimportant landmarks, specially the eyes (identification accuracy >99%, EER<2%).\nThe combined effect of the proposed approaches also allow to mitigate the\neffect produced by filters that occlude parts of the face, achieving an\nidentification accuracy of >92% with the majority of perturbations evaluated,\nand an EER <8%. Although there is room for improvement, when neither U-NET\nreconstruction nor training with filtered images is applied, the accuracy with\nfilters that severely occlude the eye is <72% (identification) and >12% (EER)",
    "descriptor": "",
    "authors": [
      "Pontus Hedman",
      "Vasilios Skepetzis",
      "Kevin Hernandez-Diaz",
      "Josef Bigun",
      "Fernando Alonso-Fernandez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08934"
  },
  {
    "id": "arXiv:2110.08935",
    "title": "InfAnFace: Bridging the infant-adult domain gap in facial landmark  estimation in the wild",
    "abstract": "There is promising potential in the application of algorithmic facial\nlandmark estimation to the early prediction, in infants, of pediatric\ndevelopmental disorders and other conditions. However, the performance of these\ndeep learning algorithms is severely hampered by the scarcity of infant data.\nTo spur the development of facial landmarking systems for infants, we introduce\nInfAnFace, a diverse, richly-annotated dataset of infant faces. We use\nInfAnFace to benchmark the performance of existing facial landmark estimation\nalgorithms that are trained on adult faces and demonstrate there is a\nsignificant domain gap between the representations learned by these algorithms\nwhen applied on infant vs. adult faces. Finally, we put forward the next\npotential steps to bridge that gap.",
    "descriptor": "",
    "authors": [
      "M. Wan",
      "S. Zhu",
      "P. Gulati",
      "L. Luan",
      "X. Huang",
      "R. Schwartz-Mette",
      "M. Hayes",
      "E. Zimmerman",
      "S. Ostadabbas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08935"
  },
  {
    "id": "arXiv:2110.08940",
    "title": "Dynamic Slimmable Denoising Network",
    "abstract": "Recently, tremendous human-designed and automatically searched neural\nnetworks have been applied to image denoising. However, previous works intend\nto handle all noisy images in a pre-defined static network architecture, which\ninevitably leads to high computational complexity for good denoising quality.\nHere, we present dynamic slimmable denoising network (DDS-Net), a general\nmethod to achieve good denoising quality with less computational complexity,\nvia dynamically adjusting the channel configurations of networks at test time\nwith respect to different noisy images. Our DDS-Net is empowered with the\nability of dynamic inference by a dynamic gate, which can predictively adjust\nthe channel configuration of networks with negligible extra computation cost.\nTo ensure the performance of each candidate sub-network and the fairness of the\ndynamic gate, we propose a three-stage optimization scheme. In the first stage,\nwe train a weight-shared slimmable super network. In the second stage, we\nevaluate the trained slimmable super network in an iterative way and\nprogressively tailor the channel numbers of each layer with minimal denoising\nquality drop. By a single pass, we can obtain several sub-networks with good\nperformance under different channel configurations. In the last stage, we\nidentify easy and hard samples in an online way and train a dynamic gate to\npredictively select the corresponding sub-network with respect to different\nnoisy images. Extensive experiments demonstrate our DDS-Net consistently\noutperforms the state-of-the-art individually trained static denoising\nnetworks.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Zutao Jiang",
      "Changlin Li",
      "Xiaojun Chang",
      "Jihua Zhu",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.08940"
  },
  {
    "id": "arXiv:2110.08941",
    "title": "Distributed Optimization using Heterogeneous Compute Systems",
    "abstract": "Hardware compute power has been growing at an unprecedented rate in recent\nyears. The utilization of such advancements plays a key role in producing\nbetter results in less time -- both in academia and industry. However, merging\nthe existing hardware with the latest hardware within the same ecosystem poses\na challenging task. One of the key challenges, in this case, is varying compute\npower. In this paper, we consider the training of deep neural networks on a\ndistributed system of workers with varying compute power. A naive\nimplementation of synchronous distributed training will result in the faster\nworkers waiting for the slowest worker to complete processing. To mitigate this\nissue, we propose to dynamically adjust the data assigned for each worker\nduring the training. We assign each worker a partition of total data\nproportional to its computing power. Our experiments show that dynamically\nadjusting the data partition helps to improve the utilization of the system and\nsignificantly reduces the time taken for training. Code is available at the\nrepository: \\url{https://github.com/vineeths96/Heterogeneous-Systems}.",
    "descriptor": "",
    "authors": [
      "Vineeth S"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.08941"
  },
  {
    "id": "arXiv:2110.08942",
    "title": "Joint SCSP-LROM: A novel approach to detect Cerebrovascular Anomalies  from EEG signals",
    "abstract": "It has always been a big challenge to identify subtle changes in\nElectroencephalogram (EEG) signals. Minor differences often lead to vital\ndecisions, for example, which grade a certain tumour belong to or whether a\nhaemorrhage can result in benign blood clots or cancerous ones. In recent\nstudies on brain computer interfaces (BCIs), one of the biggest challenges is\nrecovering maximum information for realistic predictions. In order to choose\nEEG channels with highest accuracy, a novel notion of including sparsity in a\nmodified common spatial pattern (CSP) algorithm is introduced here. Being\ninfluenced by the existing concept of compressed sensing, an optimization model\nis also developed alongside to recover the cosparse signal and retain maximum\ninformation. The state-of-the-art Joint Sparsity Induced Modified Common\nSpatial Pattern Algorithm and Low Rank Optimization Model (SCSP-LROM) developed\nhere is capable of identifying and describing tumours and lesions in great\ndetail at an overall accuracy of 96.3%.",
    "descriptor": "",
    "authors": [
      "Debojyoti Seth"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.08942"
  },
  {
    "id": "arXiv:2110.08944",
    "title": "Developing a novel fair-loan-predictor through a multi-sensitive  debiasing pipeline: DualFair",
    "abstract": "Machine learning (ML) models are increasingly used for high-stake\napplications that can greatly impact people's lives. Despite their use, these\nmodels have the potential to be biased towards certain social groups on the\nbasis of race, gender, or ethnicity. Many prior works have attempted to\nmitigate this \"model discrimination\" by updating the training data\n(pre-processing), altering the model learning process (in-processing), or\nmanipulating model output (post-processing). However, these works have not yet\nbeen extended to the realm of multi-sensitive parameters and sensitive options\n(MSPSO), where sensitive parameters are attributes that can be discriminated\nagainst (e.g race) and sensitive options are options within sensitive\nparameters (e.g black or white), thus giving them limited real-world usability.\nPrior work in fairness has also suffered from an accuracy-fairness tradeoff\nthat prevents both the accuracy and fairness from being high. Moreover,\nprevious literature has failed to provide holistic fairness metrics that work\nwith MSPSO. In this paper, we solve all three of these problems by (a) creating\na novel bias mitigation technique called DualFair and (b) developing a new\nfairness metric (i.e. AWI) that can handle MSPSO. Lastly, we test our novel\nmitigation method using a comprehensive U.S mortgage lending dataset and show\nthat our classifier, or fair loan predictor, obtains better fairness and\naccuracy metrics than current state-of-the-art models.",
    "descriptor": "\nComments: 10 pages, 2 figures, 3 tables, 1 pseudocode\n",
    "authors": [
      "Arashdeep Singh",
      "Jashandeep Singh",
      "Ariba Khan",
      "Amar Gupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.08944"
  },
  {
    "id": "arXiv:2110.08946",
    "title": "Deep Tactile Experience: Estimating Tactile Sensor Output from Depth  Sensor Data",
    "abstract": "Tactile sensing is inherently contact based. To use tactile data, robots need\nto make contact with the surface of an object. This is inefficient in\napplications where an agent needs to make a decision between multiple\nalternatives that depend the physical properties of the contact location. We\npropose a method to get tactile data in a non-invasive manner. The proposed\nmethod estimates the output of a tactile sensor from the depth data of the\nsurface of the object based on past experiences. An experience dataset is built\nby allowing the robot to interact with various objects, collecting tactile data\nand the corresponding object surface depth data. We use the experience dataset\nto train a neural network to estimate the tactile output from depth data alone.\nWe use GelSight tactile sensors, an image-based sensor, to generate images that\ncapture detailed surface features at the contact location. We train a network\nwith a dataset containing 578 tactile-image to depthmap correspondences. Given\na depth-map of the surface of an object, the network outputs an estimate of the\nresponse of the tactile sensor, should it make a contact with the object. We\nevaluate the method with structural similarity index matrix (SSIM), a\nsimilarity metric between two images commonly used in image processing\ncommunity. We present experimental results that show the proposed method\noutperforms a baseline that uses random images with statistical significance\ngetting an SSIM score of 0.84 +/- 0.0056 and 0.80 +/- 0.0036, respectively.",
    "descriptor": "\nComments: Accepted for publication in the 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2020)\n",
    "authors": [
      "Karankumar Patel",
      "Soshi Iba",
      "Nawid Jamali"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.08946"
  },
  {
    "id": "arXiv:2110.08949",
    "title": "Real-time Mortality Prediction Using MIMIC-IV ICU Data Via Boosted  Nonparametric Hazards",
    "abstract": "Electronic Health Record (EHR) systems provide critical, rich and valuable\ninformation at high frequency. One of the most exciting applications of EHR\ndata is in developing a real-time mortality warning system with tools from\nsurvival analysis. However, most of the survival analysis methods used recently\nare based on (semi)parametric models using static covariates. These models do\nnot take advantage of the information conveyed by the time-varying EHR data. In\nthis work, we present an application of a highly scalable survival analysis\nmethod, BoXHED 2.0 to develop a real-time in-ICU mortality warning indicator\nbased on the MIMIC IV data set. Importantly, BoXHED can incorporate\ntime-dependent covariates in a fully nonparametric manner and is backed by\ntheory. Our in-ICU mortality model achieves an AUC-PRC of 0.41 and AUC-ROC of\n0.83 out of sample, demonstrating the benefit of real-time monitoring.",
    "descriptor": "",
    "authors": [
      "Zhale Nowroozilarki",
      "Arash Pakbin",
      "James Royalty",
      "Donald K.K. Lee",
      "Bobak J. Mortazavi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08949"
  },
  {
    "id": "arXiv:2110.08951",
    "title": "Nonlinear Reduced DNN Models for State Estimation",
    "abstract": "We propose in this paper a data driven state estimation scheme for generating\nnonlinear reduced models for parametric families of PDEs, directly providing\ndata-to-state maps, represented in terms of Deep Neural Networks. A major\nconstituent is a sensor-induced decomposition of a model-compliant Hilbert\nspace warranting approximation in problem relevant metrics. It plays a similar\nrole as in a Parametric Background Data Weak framework for state estimators\nbased on Reduced Basis concepts. Extensive numerical tests shed light on\nseveral optimization strategies that are to improve robustness and performance\nof such estimators.",
    "descriptor": "",
    "authors": [
      "Wolfgang Dahmen",
      "Min Wang",
      "Zhu Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.08951"
  },
  {
    "id": "arXiv:2110.08952",
    "title": "Sim-to-Real Transfer in Multi-agent Reinforcement Networking for  Federated Edge Computing",
    "abstract": "Federated Learning (FL) over wireless multi-hop edge computing networks,\ni.e., multi-hop FL, is a cost-effective distributed on-device deep learning\nparadigm. This paper presents FedEdge simulator, a high-fidelity Linux-based\nsimulator, which enables fast prototyping, sim-to-real code, and knowledge\ntransfer for multi-hop FL systems. FedEdge simulator is built on top of the\nhardware-oriented FedEdge experimental framework with a new extension of the\nrealistic physical layer emulator. This emulator exploits trace-based channel\nmodeling and dynamic link scheduling to minimize the reality gap between the\nsimulator and the physical testbed. Our initial experiments demonstrate the\nhigh fidelity of the FedEdge simulator and its superior performance on\nsim-to-real knowledge transfer in reinforcement learning-optimized multi-hop\nFL.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Pinyarash Pinyoanuntapong",
      "Tagore Pothuneedi",
      "Ravikumar Balakrishnan",
      "Minwoo Lee",
      "Chen Chen",
      "Pu Wang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08952"
  },
  {
    "id": "arXiv:2110.08954",
    "title": "Uncertainty-Aware Semi-Supervised Few Shot Segmentation",
    "abstract": "Few shot segmentation (FSS) aims to learn pixel-level classification of a\ntarget object in a query image using only a few annotated support samples. This\nis challenging as it requires modeling appearance variations of target objects\nand the diverse visual cues between query and support images with limited\ninformation. To address this problem, we propose a semi-supervised FSS strategy\nthat leverages additional prototypes from unlabeled images with uncertainty\nguided pseudo label refinement. To obtain reliable prototypes from unlabeled\nimages, we meta-train a neural network to jointly predict segmentation and\nestimate the uncertainty of predictions. We employ the uncertainty estimates to\nexclude predictions with high degrees of uncertainty for pseudo label\nconstruction to obtain additional prototypes based on the refined pseudo\nlabels. During inference, query segmentation is predicted using prototypes from\nboth support and unlabeled images including low-level features of the query\nimages. Our approach is end-to-end and can easily supplement existing\napproaches without the requirement of additional training to employ unlabeled\nsamples. Extensive experiments on PASCAL-$5^i$ and COCO-$20^i$ demonstrate that\nour model can effectively remove unreliable predictions to refine pseudo labels\nand significantly improve upon state-of-the-art performances.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Soopil Kim",
      "Philip Chikontwe",
      "Sang Hyun Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08954"
  },
  {
    "id": "arXiv:2110.08955",
    "title": "Predicting Rebar Endpoints using Sin Exponential Regression Model",
    "abstract": "Currently, unmanned automation studies are underway to minimize the loss rate\nof rebar production and the time and accuracy of calibration when producing\ndefective products in the cutting process of processing rebar factories. In\nthis paper, we propose a method to detect and track rebar endpoint images\nentering the machine vision camera based on YOLO (You Only Look Once)v3, and to\npredict rebar endpoint in advance with sin exponential regression of acquired\ncoordinates. The proposed method solves the problem of large prediction error\nrates for frame locations where rebar endpoints are far away in OPPDet (Object\nPosition Prediction Detect) models, which prepredict rebar endpoints with\nimproved results showing 0.23 to 0.52% less error rates at sin exponential\nregression prediction points.",
    "descriptor": "",
    "authors": [
      "Jong-Chan Park",
      "Hye-Youn Lim",
      "Dae-Seong Kang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08955"
  },
  {
    "id": "arXiv:2110.08956",
    "title": "Improving Robustness of Reinforcement Learning for Power System Control  with Adversarial Training",
    "abstract": "Due to the proliferation of renewable energy and its intrinsic intermittency\nand stochasticity, current power systems face severe operational challenges.\nData-driven decision-making algorithms from reinforcement learning (RL) offer a\nsolution towards efficiently operating a clean energy system. Although RL\nalgorithms achieve promising performance compared to model-based control\nmodels, there has been limited investigation of RL robustness in\nsafety-critical physical systems. In this work, we first show that several\ncompetition-winning, state-of-the-art RL agents proposed for power system\ncontrol are vulnerable to adversarial attacks. Specifically, we use an\nadversary Markov Decision Process to learn an attack policy, and demonstrate\nthe potency of our attack by successfully attacking multiple winning agents\nfrom the Learning To Run a Power Network (L2RPN) challenge, under both\nwhite-box and black-box attack settings. We then propose to use adversarial\ntraining to increase the robustness of RL agent against attacks and avoid\ninfeasible operational decisions. To the best of our knowledge, our work is the\nfirst to highlight the fragility of grid control RL algorithms, and contribute\nan effective defense scheme towards improving their robustness and security.",
    "descriptor": "\nComments: Published at 2021 ICML RL4RL Workshop Submitted to 2022 PSCC\n",
    "authors": [
      "Alexander Pan",
      "Yongkyun",
      "Huan Zhang",
      "Yize Chen",
      "Yuanyuan Shi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08956"
  },
  {
    "id": "arXiv:2110.08959",
    "title": "Fast and Exact Outlier Detection in Metric Spaces: A Proximity  Graph-based Approach",
    "abstract": "Distance-based outlier detection is widely adopted in many fields, e.g., data\nmining and machine learning, because it is unsupervised, can be employed in a\ngeneric metric space, and does not have any assumptions of data distributions.\nData mining and machine learning applications face a challenge of dealing with\nlarge datasets, which requires efficient distance-based outlier detection\nalgorithms. Due to the popularization of computational environments with large\nmemory, it is possible to build a main-memory index and detect outliers based\non it, which is a promising solution for fast distance-based outlier detection.\nMotivated by this observation, we propose a novel approach that exploits a\nproximity graph. Our approach can employ an arbitrary proximity graph and\nobtains a significant speed-up against state-of-the-art. However, designing an\neffective proximity graph raises a challenge, because existing proximity graphs\ndo not consider efficient traversal for distance-based outlier detection. To\novercome this challenge, we propose a novel proximity graph, MRPG. Our\nempirical study using real datasets demonstrates that MRPG detects outliers\nsignificantly faster than the state-of-the-art algorithms.",
    "descriptor": "\nComments: Accepted to SIGMOD2021\n",
    "authors": [
      "Daichi Amagata",
      "Makoto Onizuka",
      "Takahiro Hara"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.08959"
  },
  {
    "id": "arXiv:2110.08961",
    "title": "Algorithms Using Local Graph Features to Predict Epidemics",
    "abstract": "We study a simple model of epidemics where an infected node transmits the\ninfection to its neighbors independently with probability $p$. This is also\nknown as the independent cascade or Susceptible-Infected-Recovered (SIR) model\nwith fixed recovery time. The size of an outbreak in this model is closely\nrelated to that of the giant connected component in ``edge percolation'', where\neach edge of the graph is kept independently with probability $p$, studied for\na large class of networks including configuration model\n\\cite{molloy2011critical} and preferential attachment\n\\cite{bollobas2003,Riordan2005}. Even though these models capture the effects\nof degree inhomogeneity and the role of super-spreaders in the spread of an\nepidemic, they only consider graphs that are locally tree like i.e. have a few\nor no short cycles. Some generalizations of the configuration model were\nsuggested to capture local communities, known as household models\n\\cite{ball2009threshold}, or hierarchical configuration model\n\\cite{Hofstad2015hierarchical}.\nHere, we ask a different question: what information is needed for general\nnetworks to predict the size of an outbreak? Is it possible to make predictions\nby accessing the distribution of small subgraphs (or motifs)? We answer the\nquestion in the affirmative for large-set expanders with local weak limits\n(also known as Benjamini-Schramm limits). In particular, we show that there is\nan algorithm which gives a $(1-\\epsilon)$ approximation of the probability and\nthe final size of an outbreak by accessing a constant-size neighborhood of a\nconstant number of nodes chosen uniformly at random. We also present\ncorollaries of the theorem for the preferential attachment model, and study\ngeneralizations with household (or motif) structure. The latter was only known\nfor the configuration model.",
    "descriptor": "",
    "authors": [
      "Yeganeh Alimohammadi",
      "Christian Borgs",
      "Amin Saberi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2110.08961"
  },
  {
    "id": "arXiv:2110.08962",
    "title": "Keypoint-Based Bimanual Shaping of Deformable Linear Objects under  Environmental Constraints using Hierarchical Action Planning",
    "abstract": "This paper addresses the problem of contact-based manipulation of deformable\nlinear objects (DLOs) towards desired shapes with a dual-arm robotic system. To\nalleviate the burden of high-dimensional continuous state-action spaces, we\nmodel the DLO as a kinematic multibody system via our proposed keypoint\ndetection network. This new perception network is trained on a synthetic\nlabeled image dataset and transferred to real manipulation scenarios without\nconducting any manual annotations. Our goal-conditioned policy can efficiently\nlearn to rearrange the configuration of the DLO based on the detected\nkeypoints. The proposed hierarchical action framework tackles the manipulation\nproblem in a coarse-to-fine manner (with high-level task planning and low-level\nmotion control) by leveraging on two action primitives. The identification of\ndeformation properties is avoided since the algorithm replans its motion after\neach bimanual execution. The conducted experimental results reveal that our\nmethod achieves high performance in state representation of the DLO, and is\nrobust to uncertain environmental constraints.",
    "descriptor": "",
    "authors": [
      "Shengzeng Huo",
      "Anqing Duan",
      "Chengxi Li",
      "Peng Zhou",
      "Wanyu Ma",
      "David Navarro-Alarcon"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.08962"
  },
  {
    "id": "arXiv:2110.08963",
    "title": "SS-MAIL: Self-Supervised Multi-Agent Imitation Learning",
    "abstract": "The current landscape of multi-agent expert imitation is broadly dominated by\ntwo families of algorithms - Behavioral Cloning (BC) and Adversarial Imitation\nLearning (AIL). BC approaches suffer from compounding errors, as they ignore\nthe sequential decision-making nature of the trajectory generation problem.\nFurthermore, they cannot effectively model multi-modal behaviors. While AIL\nmethods solve the issue of compounding errors and multi-modal policy training,\nthey are plagued with instability in their training dynamics. In this work, we\naddress this issue by introducing a novel self-supervised loss that encourages\nthe discriminator to approximate a richer reward function. We employ our method\nto train a graph-based multi-agent actor-critic architecture that learns a\ncentralized policy, conditioned on a learned latent interaction graph. We show\nthat our method (SS-MAIL) outperforms prior state-of-the-art methods on\nreal-world prediction tasks, as well as on custom-designed synthetic\nexperiments. We prove that SS-MAIL is part of the family of AIL methods by\nproviding a theoretical connection to cost-regularized apprenticeship learning.\nMoreover, we leverage the self-supervised formulation to introduce a novel\nteacher forcing-based curriculum (Trajectory Forcing) that improves sample\nefficiency by progressively increasing the length of the generated trajectory.\nThe SS-MAIL framework improves multi-agent imitation capabilities by\nstabilizing the policy training, improving the reward shaping capabilities, as\nwell as providing the ability for modeling multi-modal trajectories.",
    "descriptor": "\nComments: Pre-Print\n",
    "authors": [
      "Akshay Dharmavaram",
      "Tejus Gupta",
      "Jiachen Li",
      "Katia P. Sycara"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08963"
  },
  {
    "id": "arXiv:2110.08964",
    "title": "Affine Hermitian Grassmann Codes",
    "abstract": "The Grassmannian is an important object in Algebraic Geometry. One of the\nmany techniques used to study the Grassmannian is to build a vector space from\nits points in the projective embedding and study the properties of the\nresulting linear code.\nWe introduce a new class of linear codes, called Affine Hermitian Grassman\nCodes. These codes are the linear codes resulting from an affine part of the\nprojection of the Polar Hermitian Grassmann codes. They combine Polar Hermitian\nGrassmann codes and Affine Grassmann codes. We will determine the parameters of\nthese codes and discuss their minimum distance codewords.",
    "descriptor": "",
    "authors": [
      "Fernando Pi\u00f1ero Gonz\u00e1lez",
      "Doel Rivera Laboy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2110.08964"
  },
  {
    "id": "arXiv:2110.08971",
    "title": "Long Passphrases: Potentials and Limits",
    "abstract": "Passphrases offer an alternative to traditional passwords which aim to be\nstronger and more memorable. However, users tend to choose short passphrases\nwith predictable patterns that may reduce the security they offer. To explore\nthe potential of long passphrases, we formulate a set of passphrase policies\nand guidelines aimed at supporting their creation and use. Through a 39-day\nuser study we analyze the usability and security of passphrases generated using\nour policies and guidelines. Our analysis indicates these policies lead to\nreasonable usability and promising security for some use cases, and that there\nare some common pitfalls in free-form passphrase creation. Our results suggest\nthat our policies can support the use of long passphrases.",
    "descriptor": "",
    "authors": [
      "Christopher Bonk",
      "Zach Parish",
      "Julie Thorpe",
      "Amirali Salehi-Abari"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.08971"
  },
  {
    "id": "arXiv:2110.08975",
    "title": "Deep Transfer Learning & Beyond: Transformer Language Models in  Information Systems Research",
    "abstract": "AI is widely thought to be poised to transform business, yet current\nperceptions of the scope of this transformation may be myopic. Recent progress\nin natural language processing involving transformer language models (TLMs)\noffers a potential avenue for AI-driven business and societal transformation\nthat is beyond the scope of what most currently foresee. We review this recent\nprogress as well as recent literature utilizing text mining in top IS journals\nto develop an outline for how future IS research can benefit from these new\ntechniques. Our review of existing IS literature reveals that suboptimal text\nmining techniques are prevalent and that the more advanced TLMs could be\napplied to enhance and increase IS research involving text data, and to enable\nnew IS research topics, thus creating more value for the research community.\nThis is possible because these techniques make it easier to develop very\npowerful custom systems and their performance is superior to existing methods\nfor a wide range of tasks and applications. Further, multilingual language\nmodels make possible higher quality text analytics for research in multiple\nlanguages. We also identify new avenues for IS research, like language user\ninterfaces, that may offer even greater potential for future IS research.",
    "descriptor": "\nComments: Under review (revised once). Section 2, the literature review on deep transfer learning and transformer language models, is a valuable introduction for a broad audience (not just information systems researchers)\n",
    "authors": [
      "Ross Gruetzemacher",
      "David Paradice"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08975"
  },
  {
    "id": "arXiv:2110.08976",
    "title": "Information Operations in Turkey: Manufacturing Resilience with Free  Twitter Accounts",
    "abstract": "Social media platforms have more recently shifted towards investigating and\nreporting on coordinated state-linked manipulation taking place on their sites.\nFollowing the 2016 US elections, for instance, Twitter opened their Information\nOperations hub where they disclose accounts participating in state-linked\ninformation operations. In June 2020, Twitter released a set of accounts linked\nto Turkey's ruling political party. In this work, we investigate these accounts\nin the aftermath of the takedown and collect still-live accounts that appear to\nbe part of the same network. We create a taxonomy to classify these accounts,\nfind direct sequel accounts between the Turkish takedown and our collected\ndata, and find evidence showing that Turkish actors deliberately construct\ntheir account network to withstand large-scale shutdown.",
    "descriptor": "",
    "authors": [
      "Maya Merhi",
      "Sarah Rajtmajer",
      "Dongwon Lee"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.08976"
  },
  {
    "id": "arXiv:2110.08977",
    "title": "Accurate and Robust Object-oriented SLAM with 3D Quadric Landmark  Construction in Outdoor Environment",
    "abstract": "Object-oriented SLAM is a popular technology in autonomous driving and\nrobotics. In this paper, we propose a stereo visual SLAM with a robust quadric\nlandmark representation method. The system consists of four components,\nincluding deep learning detection, object-oriented data association, dual\nquadric landmark initialization and object-based pose optimization.\nState-of-the-art quadric-based SLAM algorithms always face observation related\nproblems and are sensitive to observation noise, which limits their application\nin outdoor scenes. To solve this problem, we propose a quadric initialization\nmethod based on the decoupling of the quadric parameters method, which improves\nthe robustness to observation noise. The sufficient object data association\nalgorithm and object-oriented optimization with multiple cues enables a highly\naccurate object pose estimation that is robust to local observations.\nExperimental results show that the proposed system is more robust to\nobservation noise and significantly outperforms current state-of-the-art\nmethods in outdoor environments. In addition, the proposed system demonstrates\nreal-time performance.",
    "descriptor": "\nComments: Submitting to RA-L\n",
    "authors": [
      "Rui Tian",
      "Yunzhou Zhang",
      "Yonghui Feng",
      "Linghao Yang",
      "Zhenzhong Cao",
      "Sonya Coleman",
      "Dermot Kerr"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08977"
  },
  {
    "id": "arXiv:2110.08979",
    "title": "Empirical Policy Optimization for $n$-Player Markov Games",
    "abstract": "In single-agent Markov decision processes, an agent can optimize its policy\nbased on the interaction with environment. In multi-player Markov games (MGs),\nhowever, the interaction is non-stationary due to the behaviors of other\nplayers, so the agent has no fixed optimization objective. In this paper, we\ntreat the evolution of player policies as a dynamical process and propose a\nnovel learning scheme for Nash equilibrium. The core is to evolve one's policy\naccording to not just its current in-game performance, but an aggregation of\nits performance over history. We show that for a variety of MGs, players in our\nlearning scheme will provably converge to a point that is an approximation to\nNash equilibrium. Combined with neural networks, we develop the \\emph{empirical\npolicy optimization} algorithm, that is implemented in a reinforcement-learning\nframework and runs in a distributed way, with each player optimizing its policy\nbased on own observations. We use two numerical examples to validate the\nconvergence property on small-scale MGs with $n\\ge 2$ players, and a pong\nexample to show the potential of our algorithm on large games.",
    "descriptor": "",
    "authors": [
      "Yuanheng Zhu",
      "Dongbin Zhao",
      "Mengchen Zhao",
      "Dong Li"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.08979"
  },
  {
    "id": "arXiv:2110.08980",
    "title": "Location Information Assisted Beamforming Design for Reconfigurable  Intelligent Surface Aided Communication Systems",
    "abstract": "In reconfigurable intelligent surface (RIS) aided millimeter-wave (mmWave)\ncommunication systems, in order to overcome the limitation of the conventional\nchannel state information (CSI) acquisition techniques, this paper proposes a\nlocation information assisted beamforming design without the requirement of the\nconventional channel training process. First, we establish the geometrical\nrelation between the channel model and the user location, based on which we\nderive an approximate CSI error bound based on the user location error by means\nof Taylor approximation, triangle and power mean inequalities, and semidefinite\nrelaxation (SDR). Second, for combating the uncertainty of the location error,\nwe formulate a worst-case robust beamforming optimization problem. To solve the\nproblem efficiently, we develop a novel iterative algorithm by utilizing\nvarious optimization tools such as Lagrange multiplier, matrix inversion lemma,\nSDR, as well as branch-and-bound (BnB). Particularly, the BnB algorithm is\nmodified to acquire the phase shift solution under an arbitrary constraint of\npossible phase shift values. Finally, we analyse the algorithm complexity, and\ncarry out simulations to validate the theoretical derivation of the CSI error\nbound and the robustness of the proposed algorithm. Compared with the existing\nnon-robust approach and the robust beamforming techniques based on S-procedure\nand penalty convex-concave procedure (CCP), our method converges faster and\nachieves better performance in terms of the worst-case signal-to-noise ratio\n(SNR) at the receiver.",
    "descriptor": "\nComments: 13 pages, 8 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Zhe Xing",
      "Rui Wang",
      "Xiaojun Yuan",
      "Jun Wu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.08980"
  },
  {
    "id": "arXiv:2110.08983",
    "title": "An Empirical Study of Protocols in Smart Contracts",
    "abstract": "Smart contracts are programs that are executed on a blockhain. They have been\nused for applications in voting, decentralized finance, and supply chain\nmanagement. However, vulnerabilities in smart contracts have been abused by\nhackers, leading to financial losses. Understanding state machine protocols in\nsmart contracts has been identified as important to catching common bugs,\nimproving documentation, and optimizing smart contracts. We analyze Solidity\nsmart contracts deployed on the Ethereum blockchain and study the prevalence of\nprotocols and protocol-based bugs, as well as opportunities for gas\noptimizations.",
    "descriptor": "\nComments: 10 pages. In HATRA 2021\n",
    "authors": [
      "Timothy Mou",
      "Michael Coblenz",
      "Jonathan Aldrich"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.08983"
  },
  {
    "id": "arXiv:2110.08984",
    "title": "Optimistic Policy Optimization is Provably Efficient in Non-stationary  MDPs",
    "abstract": "We study episodic reinforcement learning (RL) in non-stationary linear kernel\nMarkov decision processes (MDPs). In this setting, both the reward function and\nthe transition kernel are linear with respect to the given feature maps and are\nallowed to vary over time, as long as their respective parameter variations do\nnot exceed certain variation budgets. We propose the\n$\\underline{\\text{p}}$eriodically $\\underline{\\text{r}}$estarted\n$\\underline{\\text{o}}$ptimistic $\\underline{\\text{p}}$olicy\n$\\underline{\\text{o}}$ptimization algorithm (PROPO), which is an optimistic\npolicy optimization algorithm with linear function approximation. PROPO\nfeatures two mechanisms: sliding-window-based policy evaluation and\nperiodic-restart-based policy improvement, which are tailored for policy\noptimization in a non-stationary environment. In addition, only utilizing the\ntechnique of sliding window, we propose a value-iteration algorithm. We\nestablish dynamic upper bounds for the proposed methods and a matching minimax\nlower bound which shows the (near-) optimality of the proposed methods. To our\nbest knowledge, PROPO is the first provably efficient policy optimization\nalgorithm that handles non-stationarity.",
    "descriptor": "",
    "authors": [
      "Han Zhong",
      "Zhuoran Yang",
      "Zhaoran Wang Csaba Szepesv\u00e1ri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.08984"
  },
  {
    "id": "arXiv:2110.08985",
    "title": "StyleNeRF: A Style-based 3D-Aware Generator for High-resolution Image  Synthesis",
    "abstract": "We propose StyleNeRF, a 3D-aware generative model for photo-realistic\nhigh-resolution image synthesis with high multi-view consistency, which can be\ntrained on unstructured 2D images. Existing approaches either cannot synthesize\nhigh-resolution images with fine details or yield noticeable 3D-inconsistent\nartifacts. In addition, many of them lack control over style attributes and\nexplicit 3D camera poses. StyleNeRF integrates the neural radiance field (NeRF)\ninto a style-based generator to tackle the aforementioned challenges, i.e.,\nimproving rendering efficiency and 3D consistency for high-resolution image\ngeneration. We perform volume rendering only to produce a low-resolution\nfeature map and progressively apply upsampling in 2D to address the first\nissue. To mitigate the inconsistencies caused by 2D upsampling, we propose\nmultiple designs, including a better upsampler and a new regularization loss.\nWith these designs, StyleNeRF can synthesize high-resolution images at\ninteractive rates while preserving 3D consistency at high quality. StyleNeRF\nalso enables control of camera poses and different levels of styles, which can\ngeneralize to unseen views. It also supports challenging tasks, including\nzoom-in and-out, style mixing, inversion, and semantic editing.",
    "descriptor": "\nComments: 24 pages, 19 figures. Project page: this http URL\n",
    "authors": [
      "Jiatao Gu",
      "Lingjie Liu",
      "Peng Wang",
      "Christian Theobalt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.08985"
  },
  {
    "id": "arXiv:2110.08988",
    "title": "FEANet: Feature-Enhanced Attention Network for RGB-Thermal Real-time  Semantic Segmentation",
    "abstract": "The RGB-Thermal (RGB-T) information for semantic segmentation has been\nextensively explored in recent years. However, most existing RGB-T semantic\nsegmentation usually compromises spatial resolution to achieve real-time\ninference speed, which leads to poor performance. To better extract detail\nspatial information, we propose a two-stage Feature-Enhanced Attention Network\n(FEANet) for the RGB-T semantic segmentation task. Specifically, we introduce a\nFeature-Enhanced Attention Module (FEAM) to excavate and enhance multi-level\nfeatures from both the channel and spatial views. Benefited from the proposed\nFEAM module, our FEANet can preserve the spatial information and shift more\nattention to high-resolution features from the fused RGB-T images. Extensive\nexperiments on the urban scene dataset demonstrate that our FEANet outperforms\nother state-of-the-art (SOTA) RGB-T methods in terms of objective metrics and\nsubjective visual comparison (+2.6% in global mAcc and +0.8% in global mIoU).\nFor the 480 x 640 RGB-T test images, our FEANet can run with a real-time speed\non an NVIDIA GeForce RTX 2080 Ti card.",
    "descriptor": "\nComments: 7 pages, 5 figures\n",
    "authors": [
      "Fuqin Deng",
      "Hua Feng",
      "Mingjian Liang",
      "Hongmin Wang",
      "Yong Yang",
      "Yuan Gao",
      "Junfeng Chen",
      "Junjie Hu",
      "Xiyue Guo",
      "Tin Lun Lam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08988"
  },
  {
    "id": "arXiv:2110.08991",
    "title": "Dimensionality Reduction for Wasserstein Barycenter",
    "abstract": "The Wasserstein barycenter is a geometric construct which captures the notion\nof centrality among probability distributions, and which has found many\napplications in machine learning. However, most algorithms for finding even an\napproximate barycenter suffer an exponential dependence on the dimension $d$ of\nthe underlying space of the distributions. In order to cope with this \"curse of\ndimensionality,\" we study dimensionality reduction techniques for the\nWasserstein barycenter problem. When the barycenter is restricted to support of\nsize $n$, we show that randomized dimensionality reduction can be used to map\nthe problem to a space of dimension $O(\\log n)$ independent of both $d$ and\n$k$, and that \\emph{any} solution found in the reduced dimension will have its\ncost preserved up to arbitrary small error in the original space. We provide\nmatching upper and lower bounds on the size of the reduced dimension, showing\nthat our methods are optimal up to constant factors. We also provide a coreset\nconstruction for the Wasserstein barycenter problem that significantly\ndecreases the number of input distributions. The coresets can be used in\nconjunction with random projections and thus further improve computation time.\nLastly, our experimental results validate the speedup provided by\ndimensionality reduction while maintaining solution quality.",
    "descriptor": "\nComments: Published as a conference paper in NeurIPS 2021\n",
    "authors": [
      "Zachary Izzo",
      "Sandeep Silwal",
      "Samson Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2110.08991"
  },
  {
    "id": "arXiv:2110.08992",
    "title": "SmartGridToolbox: A Library for Simulating Modern and Future Electricity  Networks",
    "abstract": "We present SmartGridToolbox: a C++ library for simulating modern and future\nelectricity networks. SmartGridToolbox is distinguished by the fact that it is\na general purpose library (rather than an application), that emphasizes\nflexibility, extensibility, and ability to interface with a wide range of other\ntools, such as optimization technologies, or existing code for devices. It\nincorporates fully unbalanced network modeling, fast power flow and OPF\nsolvers, a discrete-event simulation engine, and a component library that\nincludes network components like lines, cables, transformers, ZIP loads and\ngenerators, renewable and storage components like PV generation and batteries,\ninverters, tap changers, PV, generic time dependent loads and more. We\nanticipate that SmartGridToolbox will be useful to researchers and developers\nwho require accurate models and simulations of electricity networks that go\nbeyond simple applications of load flow - for example, by incorporating custom\noptimisation algorithms, controllers, devices, or network management\nstrategies. Being a library, it is also perfect for developing a wide range of\nend use applications. We start with a comparison to existing open source\nsoftware, and move on to present its main features and benchmark results. We\nconclude by discussing four applications, most notably, the use of\nSmartGridToolbox in the CONSORT Bruny Island Battery Trial, conducted between\n2016 and 2019.",
    "descriptor": "\nComments: 19 pages, 9 figures\n",
    "authors": [
      "Dan Gordon",
      "Paul Scott",
      "Sylvie Thi\u00e9baux"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2110.08992"
  },
  {
    "id": "arXiv:2110.08993",
    "title": "Typed Image-based Programming with Structure Editing",
    "abstract": "Many beloved programming systems are image-based: self-contained worlds that\npersist both code and data in a single file. Examples include Smalltalk, LISP,\nHyperCard, Flash, and spreadsheets. Image-based programming avoids much of the\ncomplexity of modern programming technology stacks and encourages more casual\nand exploratory programming. However conventional file-based programming has\nbetter support for collaboration and deployment. These problems have been\nblamed for the limited commercial success of Smalltalk. We propose to enable\ncollaboration in image-based programming via types and structure editing.\nWe focus on the problem of schema change on persistent data. We turn to\nstatic types, which paradoxically require more schema change but also provide a\nmechanism to express and execute those changes. To determine those changes we\nturn to structure editing, so that we can capture changes in type definitions\nwith sufficient fidelity to automatically adapt the data to suit. We conjecture\nthat typical schema changes can be handled through structure editing of static\ntypes.\nThat positions us to tackle collaboration with what could be called version\ncontrol for structure editing. We present a theory realizing this idea, which\nis our main technical contribution. While we focus here on editing types, if we\ncan extend the approach to cover the entire programming experience then it\nwould offer a new way to collaborate in image-based programming.",
    "descriptor": "\nComments: Accepted to: Human Aspects of Types and Reasoning Assistants (HATRA'21), Oct 19, 2021, Chicago, US\n",
    "authors": [
      "Jonathan Edwards",
      "Tomas Petricek"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.08993"
  },
  {
    "id": "arXiv:2110.08994",
    "title": "CMTR: Cross-modality Transformer for Visible-infrared Person  Re-identification",
    "abstract": "Visible-infrared cross-modality person re-identification is a challenging\nReID task, which aims to retrieve and match the same identity's images between\nthe heterogeneous visible and infrared modalities. Thus, the core of this task\nis to bridge the huge gap between these two modalities. The existing\nconvolutional neural network-based methods mainly face the problem of\ninsufficient perception of modalities' information, and can not learn good\ndiscriminative modality-invariant embeddings for identities, which limits their\nperformance. To solve these problems, we propose a cross-modality\ntransformer-based method (CMTR) for the visible-infrared person\nre-identification task, which can explicitly mine the information of each\nmodality and generate better discriminative features based on it. Specifically,\nto capture modalities' characteristics, we design the novel modality\nembeddings, which are fused with token embeddings to encode modalities'\ninformation. Furthermore, to enhance representation of modality embeddings and\nadjust matching embeddings' distribution, we propose a modality-aware\nenhancement loss based on the learned modalities' information, reducing\nintra-class distance and enlarging inter-class distance. To our knowledge, this\nis the first work of applying transformer network to the cross-modality\nre-identification task. We implement extensive experiments on the public\nSYSU-MM01 and RegDB datasets, and our proposed CMTR model's performance\nsignificantly surpasses existing outstanding CNN-based methods.",
    "descriptor": "\nComments: 11 pages, 7 figures, 7 tables\n",
    "authors": [
      "Tengfei Liang",
      "Yi Jin",
      "Yajun Gao",
      "Wu Liu",
      "Songhe Feng",
      "Tao Wang",
      "Yidong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08994"
  },
  {
    "id": "arXiv:2110.08996",
    "title": "Finding Everything within Random Binary Networks",
    "abstract": "A recent work by Ramanujan et al. (2020) provides significant empirical\nevidence that sufficiently overparameterized, random neural networks contain\nuntrained subnetworks that achieve state-of-the-art accuracy on several\npredictive tasks. A follow-up line of theoretical work provides justification\nof these findings by proving that slightly overparameterized neural networks,\nwith commonly used continuous-valued random initializations can indeed be\npruned to approximate any target network. In this work, we show that the\namplitude of those random weights does not even matter. We prove that any\ntarget network can be approximated up to arbitrary accuracy by simply pruning a\nrandom network of binary $\\{\\pm1\\}$ weights that is only a polylogarithmic\nfactor wider and deeper than the target network.",
    "descriptor": "",
    "authors": [
      "Kartik Sreenivasan",
      "Shashank Rajput",
      "Jy-yong Sohn",
      "Dimitris Papailiopoulos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08996"
  },
  {
    "id": "arXiv:2110.08998",
    "title": "Using Structure-Behavior Coalescence Method for Systems Definition 2.0",
    "abstract": "Systems definition is an artifact created by humans to describe what a system\nis. A system has been defined, by systems definition 1.0, hopefully to be an\nintegrated whole, embodied in its components, their interrelationships with\neach other and the environment, and the principles and guidelines governing its\ndesign and evolution. This systems definition 1.0 defining the system possesses\none cardinal deficiency. The deficiency comes from that it does not describe\nthe integration of systems structure and systems behavior. Structure-behavior\ncoalescence (SBC) architecture provides an elegant way to integrate the\nstructure and behavior of a system. A system is therefore redefined, by systems\ndefinition 2.0, truly to be an integrated whole, using the SBC architecture,\nembodied in its assembled components, their interactions with each other and\nthe environment, and the principles and guidelines governing its design and\nevolution. Since systems definition 2.0 describes the integration of systems\nstructure and systems behavior, definitely it is able to form an integrated\nwhole of a system. In this situation, systems definition 2.0 is fully capable\nof defining a system.",
    "descriptor": "",
    "authors": [
      "William S. Chao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.08998"
  },
  {
    "id": "arXiv:2110.09001",
    "title": "Deep Learning-Based Power Control for Uplink Cell-Free Massive MIMO  Systems",
    "abstract": "In this paper, a general framework for deep learning-based power control\nmethods for max-min, max-product and max-sum-rate optimization in uplink\ncell-free massive multiple-input multiple-output (CF mMIMO) systems is\nproposed. Instead of using supervised learning, the proposed method relies on\nunsupervised learning, in which optimal power allocations are not required to\nbe known, and thus has low training complexity. More specifically, a deep\nneural network (DNN) is trained to learn the map between fading coefficients\nand power coefficients within short time and with low computational complexity.\nIt is interesting to note that the spectral efficiency of CF mMIMO systems with\nthe proposed method outperforms previous optimization methods for max-min\noptimization and fits well for both max-sum-rate and max-product optimizations.",
    "descriptor": "\nComments: 6 pages, 6 figures, accepted by IEEE Globecom 2021\n",
    "authors": [
      "Yongshun Zhang",
      "Jiayi Zhang",
      "Yu Jin",
      "Stefano Buzzi",
      "Bo Ai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.09001"
  },
  {
    "id": "arXiv:2110.09004",
    "title": "NYU-VPR: Long-Term Visual Place Recognition Benchmark with View  Direction and Data Anonymization Influences",
    "abstract": "Visual place recognition (VPR) is critical in not only localization and\nmapping for autonomous driving vehicles, but also assistive navigation for the\nvisually impaired population. To enable a long-term VPR system on a large\nscale, several challenges need to be addressed. First, different applications\ncould require different image view directions, such as front views for\nself-driving cars while side views for the low vision people. Second, VPR in\nmetropolitan scenes can often cause privacy concerns due to the imaging of\npedestrian and vehicle identity information, calling for the need for data\nanonymization before VPR queries and database construction. Both factors could\nlead to VPR performance variations that are not well understood yet. To study\ntheir influences, we present the NYU-VPR dataset that contains more than\n200,000 images over a 2km by 2km area near the New York University campus,\ntaken within the whole year of 2016. We present benchmark results on several\npopular VPR algorithms showing that side views are significantly more\nchallenging for current VPR methods while the influence of data anonymization\nis almost negligible, together with our hypothetical explanations and in-depth\nanalysis.",
    "descriptor": "\nComments: 7 pages, 10 figures, published in 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2021)\n",
    "authors": [
      "Diwei Sheng",
      "Yuxiang Chai",
      "Xinru Li",
      "Chen Feng",
      "Jianzhe Lin",
      "Claudio Silva",
      "John-Ross Rizzo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09004"
  },
  {
    "id": "arXiv:2110.09006",
    "title": "Natural Image Reconstruction from fMRI using Deep Learning: A Survey",
    "abstract": "With the advent of brain imaging techniques and machine learning tools, much\neffort has been devoted to building computational models to capture the\nencoding of visual information in the human brain. One of the most challenging\nbrain decoding tasks is the accurate reconstruction of the perceived natural\nimages from brain activities measured by functional magnetic resonance imaging\n(fMRI). In this work, we survey the most recent deep learning methods for\nnatural image reconstruction from fMRI. We examine these methods in terms of\narchitectural design, benchmark datasets, and evaluation metrics and present a\nfair performance evaluation across standardized evaluation metrics. Finally, we\ndiscuss the strengths and limitations of existing studies and present potential\nfuture directions.",
    "descriptor": "",
    "authors": [
      "Zarina Rakhimberdina",
      "Quentin Jodelet",
      "Xin Liu",
      "Tsuyoshi Murata"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.09006"
  },
  {
    "id": "arXiv:2110.09007",
    "title": "Online Motion Planning with Soft Timed Temporal Logic in Dynamic and  Unknown Environment",
    "abstract": "Motion planning of an autonomous system with high-level specifications has\nwide applications. However, research of formal languages involving timed\ntemporal logic is still under investigation. Furthermore, many existing results\nrely on a key assumption that user-specified tasks are feasible in the given\nenvironment. Challenges arise when the operating environment is dynamic and\nunknown since the environment can be found prohibitive, leading to potentially\nconflicting tasks where pre-specified LTL tasks cannot be fully satisfied. Such\nissues become even more challenging when considering timed requirements. To\naddress these challenges, this work proposes a control framework that considers\nhard constraints to enforce safety requirements and soft constraints to enable\ntask relaxation. The metric interval temporal logic (MITL) specifications are\nemployed to deal with time constraints. By constructing a relaxed timed product\nautomaton, an online motion planning strategy is synthesized with a receding\nhorizon controller to generate policies, achieving multiple objectives in\ndecreasing order of priority 1) formally guarantee the satisfaction of hard\nsafety constraints; 2) mostly fulfill soft timed tasks; and 3) collect\ntime-varying rewards as much as possible. Another novelty of the relaxed\nstructure is to consider violations of both time and tasks for infeasible\ncases. Simulation results are provided to validate the proposed approach.",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Zhiliang Li",
      "Mingyu Cai",
      "Shaoping Xiao",
      "Zhen Kan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.09007"
  },
  {
    "id": "arXiv:2110.09008",
    "title": "When Are Linear Stochastic Bandits Attackable?",
    "abstract": "We study adversarial attacks on linear stochastic bandits, a sequential\ndecision making problem with many important applications in recommender\nsystems, online advertising, medical treatment, and etc. By manipulating the\nrewards, an adversary aims to control the behaviour of the bandit algorithm.\nPerhaps surprisingly, we first show that some attack goals can never be\nachieved. This is in sharp contrast to context-free stochastic bandits, and is\nintrinsically due to the correlation among arms in linear stochastic bandits.\nMotivated by this observation, this paper studies the attackability of a\n$k$-armed linear bandit environment. We first provide a full necessity and\nsufficiency characterization of attackability based on the geometry of the\ncontext vectors. We then propose a two-stage attack method against LinUCB and\nRobust Phase Elimination. The method first asserts whether the current\nenvironment is attackable, and if Yes, modifies the rewards to force the\nalgorithm to pull a target arm linear times using only a sublinear cost.\nNumerical experiments further validate the effectiveness and cost-efficiency of\nthe proposed method.",
    "descriptor": "",
    "authors": [
      "Huazheng Wang",
      "Haifeng Xu",
      "Hongning Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.09008"
  },
  {
    "id": "arXiv:2110.09012",
    "title": "Navigation of a UAV Equipped with a Reconfigurable Intelligent Surface  for LoS Wireless Communication with a Ground Vehicle",
    "abstract": "Unmanned aerial vehicles (UAVs) have been successfully adopted to enhance the\nflexibility and robustness of wireless communication networks. And recently,\nthe reconfigurable intelligent surface (RIS) technology has been paid\nincreasing attention to improve the throughput of the fifth-generation (5G)\nmillimeter-wave (mmWave) wireless communication. In this work, we propose an\nRIS-outfitted UAV (RISoUAV) to secure an uninterrupted line-of-sight (LoS) link\nwith a ground moving target (MT). The MT can be an emergency ambulance and need\na secure wireless communication link for continuous monitoring and diagnosing\nthe health condition of a patient, which is vital for delivering critical\npatient care. In this light, real-time communication is required for sending\nvarious clinical multimedia data including videos, medical images, and vital\nsigns. This significant target is achievable thanks to the 5G wireless\ncommunication assisted with RISoUAV. A two-stage optimization method is\nproposed to optimize the RISoUAV trajectory limited to UAV motion and LoS\nconstraints. At the first stage, the optimal tube path of the RISoUAV is\ndetermined by taking into account the energy consumption, instant LoS link, and\nUAV speed/acceleration constraints. At the second stage, an accurate RISoUAV\ntrajectory is obtained by considering the communication channel performance and\npassive beamforming. Simulation results show the accuracy and effectiveness of\nthe method.",
    "descriptor": "",
    "authors": [
      "Mohsen Eskandari",
      "Hailong Huang",
      "Andrey V. Savkin",
      "Wei Ni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.09012"
  },
  {
    "id": "arXiv:2110.09018",
    "title": "Reinforcement Learning-Based Coverage Path Planning with Implicit  Cellular Decomposition",
    "abstract": "Coverage path planning in a generic known environment is shown to be NP-hard.\nWhen the environment is unknown, it becomes more challenging as the robot is\nrequired to rely on its online map information built during coverage for\nplanning its path. A significant research effort focuses on designing heuristic\nor approximate algorithms that achieve reasonable performance. Such algorithms\nhave sub-optimal performance in terms of covering the area or the cost of\ncoverage, e.g., coverage time or energy consumption. In this paper, we provide\na systematic analysis of the coverage problem and formulate it as an optimal\nstopping time problem, where the trade-off between coverage performance and its\ncost is explicitly accounted for. Next, we demonstrate that reinforcement\nlearning (RL) techniques can be leveraged to solve the problem computationally.\nTo this end, we provide some technical and practical considerations to\nfacilitate the application of the RL algorithms and improve the efficiency of\nthe solutions. Finally, through experiments in grid world environments and\nGazebo simulator, we show that reinforcement learning-based algorithms\nefficiently cover realistic unknown indoor environments, and outperform the\ncurrent state of the art.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Javad Heydari",
      "Olimpiya Saha",
      "Viswanath Ganapathy"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09018"
  },
  {
    "id": "arXiv:2110.09021",
    "title": "Artificial Neural Network and Its Application Research Progress in  Chemical Process",
    "abstract": "Most chemical processes, such as distillation, absorption, extraction, and\ncatalytic reactions, are extremely complex processes that are affected by\nmultiple factors. The relationships between their input variables and output\nvariables are non-linear, and it is difficult to optimize or control them using\ntraditional methods. Artificial neural network (ANN) is a systematic structure\ncomposed of multiple neuron models. Its main function is to simulate multiple\nbasic functions of the nervous system of living organisms. ANN can achieve\nnonlinear control without relying on mathematical models, and is especially\nsuitable for more complex control objects. This article will introduce the\nbasic principles and development history of artificial neural networks, and\nreview its application research progress in chemical process control, fault\ndiagnosis, and process optimization.",
    "descriptor": "",
    "authors": [
      "Li Sun",
      "Fei Liang",
      "Wutai Cui"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.09021"
  },
  {
    "id": "arXiv:2110.09022",
    "title": "Demystifying How Self-Supervised Features Improve Training from Noisy  Labels",
    "abstract": "The advancement of self-supervised learning (SSL) motivates researchers to\napply SSL on other tasks such as learning with noisy labels. Recent literature\nindicates that methods built on SSL features can substantially improve the\nperformance of learning with noisy labels. Nonetheless, the deeper reasons why\n(and how) SSL features benefit the training from noisy labels are less\nunderstood. In this paper, we study why and how self-supervised features help\nnetworks resist label noise using both theoretical analyses and numerical\nexperiments. Our result shows that, given a quality encoder pre-trained from\nSSL, a simple linear layer trained by the cross-entropy loss is theoretically\nrobust to symmetric label noise. Further, we provide insights for how knowledge\ndistilled from SSL features can alleviate the over-fitting problem. We hope our\nwork provides a better understanding for learning with noisy labels from the\nperspective of self-supervised learning and can potentially serve as a\nguideline for further research. Code is available at\ngithub.com/UCSC-REAL/SelfSup_NoisyLabel.",
    "descriptor": "",
    "authors": [
      "Hao Cheng",
      "Zhaowei Zhu",
      "Xing Sun",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09022"
  },
  {
    "id": "arXiv:2110.09023",
    "title": "Utilizing Active Machine Learning for Quality Assurance: A Case Study of  Virtual Car Renderings in the Automotive Industry",
    "abstract": "Computer-generated imagery of car models has become an indispensable part of\ncar manufacturers' advertisement concepts. They are for instance used in car\nconfigurators to offer customers the possibility to configure their car online\naccording to their personal preferences. However, human-led quality assurance\nfaces the challenge to keep up with high-volume visual inspections due to the\ncar models' increasing complexity. Even though the application of machine\nlearning to many visual inspection tasks has demonstrated great success, its\nneed for large labeled data sets remains a central barrier to using such\nsystems in practice. In this paper, we propose an active machine learning-based\nquality assurance system that requires significantly fewer labeled instances to\nidentify defective virtual car renderings without compromising performance. By\nemploying our system at a German automotive manufacturer, start-up difficulties\ncan be overcome, the inspection process efficiency can be increased, and thus\neconomic advantages can be realized.",
    "descriptor": "\nComments: Hawaii International Conference on System Sciences 2022 (HICSS-55)\n",
    "authors": [
      "Patrick Hemmer",
      "Niklas K\u00fchl",
      "Jakob Sch\u00f6ffer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09023"
  },
  {
    "id": "arXiv:2110.09026",
    "title": "Arjun: An Efficient Independent Support Computation Technique and its  Applications to Counting and Sampling",
    "abstract": "Given a Boolean formula $\\varphi$ over the set of variables $X$ and a\nprojection set $\\mathcal{P} \\subseteq X$, a subset of variables $\\mathcal{I}$\nis independent support of $\\mathcal{P}$ if two solutions agree on\n$\\mathcal{I}$, then they also agree on $\\mathcal{P}$. The notion of independent\nsupport is related to the classical notion of definability dating back to 1901,\nand have been studied over the decades. Recently, the computational problem of\ndetermining independent support for a given formula has attained importance\nowing to the crucial importance of independent support for hashing-based\ncounting and sampling techniques.\nIn this paper, we design an efficient and scalable independent support\ncomputation technique that can handle formulas arising from real-world\nbenchmarks. Our algorithmic framework, called Arjun, employs implicit and\nexplicit definability notions, and is based on a tight integration of\ngate-identification techniques and assumption-based framework. We demonstrate\nthat augmenting the state of the art model counter ApproxMC4 and sampler\nUniGen3 with Arjun leads to significant performance improvements. In\nparticular, ApproxMC4 augmented with Arjun counts 387 more benchmarks out of\n1896 while UniGen3 augmented with Arjun samples 319 more benchmarks within the\nsame time limit.",
    "descriptor": "",
    "authors": [
      "Mate Soos",
      "Kuldeep S. Meel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2110.09026"
  },
  {
    "id": "arXiv:2110.09028",
    "title": "Fast tree skeleton extraction using voxel thinning based on tree point  cloud",
    "abstract": "Tree skeleton plays an important role in tree structure analysis, forest\ninventory and ecosystem monitoring. However, it is a challenge to extract a\nskeleton from a tree point cloud with complex branches. In this paper, an\nautomatic and fast tree skeleton extraction method (FTSEM) based on voxel\nthinning is proposed. In this method, a wood-leaf classification algorithm was\nintroduced to filter leaf points for the reduction of the leaf interference on\ntree skeleton generation, tree voxel thinning was adopted to extract raw tree\nskeleton quickly, and a breakpoint connection algorithm was used to improve the\nskeleton connectivity and completeness. Experiments were carried out in Haidian\nPark, Beijing, in which 24 trees were scanned and processed to obtain tree\nskeletons. The graph search algorithm (GSA) is used to extract tree skeletons\nbased on the same datasets. Compared with GSA method, the FTSEM method obtained\nmore complete tree skeletons. And the time cost of the FTSEM method is\nevaluated using the runtime and time per million points (TPMP). The runtime of\nFTSEM is from 1.0 s to 13.0 s, and the runtime of GSA is from 6.4 s to 309.3 s.\nThe average value of TPMP is 1.8 s for FTSEM, and 22.3 s for GSA respectively.\nThe experimental results demonstrate that the proposed method is feasible,\nrobust, and fast with a good potential on tree skeleton extraction.",
    "descriptor": "",
    "authors": [
      "Jingqian Sun",
      "Pei Wang",
      "Ronghao Li",
      "Mei Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09028"
  },
  {
    "id": "arXiv:2110.09030",
    "title": "An Adaptive-Importance-Sampling-Enhanced Bayesian Approach for Topology  Estimation in an Unbalanced Power Distribution System",
    "abstract": "The reliable operation of a power distribution system relies on a good prior\nknowledge of its topology and its system state. Although crucial, due to the\nlack of direct monitoring devices on the switch statuses, the topology\ninformation is often unavailable or outdated for the distribution system\noperators for real-time applications. Apart from the limited observability of\nthe power distribution system, other challenges are the nonlinearity of the\nmodel, the complicated, unbalanced structure of the distribution system, and\nthe scale of the system. To overcome the above challenges, this paper proposes\na Bayesian-inference framework that allows us to simultaneously estimate the\ntopology and the state of a three-phase, unbalanced power distribution system.\nSpecifically, by using the very limited number of measurements available that\nare associated with the forecast load data, we efficiently recover the full\nBayesian posterior distributions of the system topology under both normal and\noutage operation conditions. This is performed through an adaptive importance\nsampling procedure that greatly alleviates the computational burden of the\ntraditional Monte-Carlo (MC)-sampling-based approach while maintaining a good\nestimation accuracy. The simulations conducted on the IEEE 123-bus test system\nand an unbalanced 1282-bus system reveal the excellent performances of the\nproposed method.",
    "descriptor": "",
    "authors": [
      "Yijun Xu",
      "Jaber Valinejad",
      "Mert Korkali",
      "Lamine Mili",
      "Yajun Wang",
      "Xiao Chen",
      "Zongsheng Zheng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.09030"
  },
  {
    "id": "arXiv:2110.09035",
    "title": "Edge Rewiring Goes Neural: Boosting Network Resilience via Policy  Gradient",
    "abstract": "Improving the resilience of a network protects the system from natural\ndisasters and malicious attacks. This is typically achieved by introducing new\nedges, which however may reach beyond the maximum number of connections a node\ncould sustain. Many studies then resort to the degree-preserving operation of\nrewiring, which swaps existing edges $AC, BD$ to new edges $AB, CD$. A\nsignificant line of studies focuses on this technique for theoretical and\npractical results while leaving three limitations: network utility loss, local\noptimality, and transductivity. In this paper, we propose ResiNet, a\nreinforcement learning (RL)-based framework to discover resilient network\ntopologies against various disasters and attacks. ResiNet is objective agnostic\nwhich allows the utility to be balanced by incorporating it into the objective\nfunction. The local optimality, typically seen in greedy algorithms, is\naddressed by casting the cumulative resilience gain into a sequential decision\nprocess of step-wise rewiring. The transductivity, which refers to the\nnecessity to run a computationally intensive optimization for each input graph,\nis lifted by our variant of RL with auto-regressive permutation-invariant\nvariable action space. ResiNet is armed by our technical innovation, Filtration\nenhanced GNN (FireGNN), which distinguishes graphs with minor differences. It\nis thus possible for ResiNet to capture local structure changes and adapt its\ndecision among consecutive graphs, which is known to be infeasible for GNN.\nExtensive experiments demonstrate that with a small number of rewiring\noperations, ResiNet achieves a near-optimal resilience gain on multiple graphs\nwhile balancing the utility, with a large margin compared to existing\napproaches.",
    "descriptor": "",
    "authors": [
      "Shanchao Yang",
      "Kaili Ma",
      "Baoxiang Wang",
      "Hongyuan Zha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.09035"
  },
  {
    "id": "arXiv:2110.09036",
    "title": "Ranking Facts for Explaining Answers to Elementary Science Questions",
    "abstract": "In multiple-choice exams, students select one answer from among typically\nfour choices and can explain why they made that particular choice. Students are\ngood at understanding natural language questions and based on their domain\nknowledge can easily infer the question's answer by 'connecting the dots'\nacross various pertinent facts.\nConsidering automated reasoning for elementary science question answering, we\naddress the novel task of generating explanations for answers from\nhuman-authored facts. For this, we examine the practically scalable framework\nof feature-rich support vector machines leveraging domain-targeted,\nhand-crafted features. Explanations are created from a human-annotated set of\nnearly 5,000 candidate facts in the WorldTree corpus. Our aim is to obtain\nbetter matches for valid facts of an explanation for the correct answer of a\nquestion over the available fact candidates. To this end, our features offer a\ncomprehensive linguistic and semantic unification paradigm. The machine\nlearning problem is the preference ordering of facts, for which we test\npointwise regression versus pairwise learning-to-rank.\nOur contributions are: (1) a case study in which two preference ordering\napproaches are systematically compared; (2) it is a practically competent\napproach that can outperform some variants of BERT-based reranking models; and\n(3) the human-engineered features make it an interpretable machine learning\nmodel for the task.",
    "descriptor": "\nComments: 25 pages, 5 figures, accepted for publication in NLE\n",
    "authors": [
      "Jennifer D'Souza",
      "Isaiah Onando Mulang'",
      "Soeren Auer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2110.09036"
  },
  {
    "id": "arXiv:2110.09039",
    "title": "Capsule Graph Neural Networks with EM Routing",
    "abstract": "To effectively classify graph instances, graph neural networks need to have\nthe capability to capture the part-whole relationship existing in a graph. A\ncapsule is a group of neurons representing complicated properties of entities,\nwhich has shown its advantages in traditional convolutional neural networks.\nThis paper proposed novel Capsule Graph Neural Networks that use the EM routing\nmechanism (CapsGNNEM) to generate high-quality graph embeddings. Experimental\nresults on a number of real-world graph datasets demonstrate that the proposed\nCapsGNNEM outperforms nine state-of-the-art models in graph classification\ntasks.",
    "descriptor": "",
    "authors": [
      "Yu Lei",
      "Jing Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09039"
  },
  {
    "id": "arXiv:2110.09041",
    "title": "DroneStick: Flying Joystick as a Novel Type of Interface",
    "abstract": "DroneStick is a novel hands-free method for smooth interaction between a\nhuman and a robotic system via one of its agents, without training and any\nadditional handheld or wearable device or infrastructure. A flying joystick\n(DroneStick), being a part of a multi-robot system, is composed of a flying\ndrone and coiled wire with a vibration motor. By pulling on the coiled wire,\nthe operator commands certain motions of the follower robotic system. The\nDroneStick system does not require the user to carry any equipment before or\nafter performing the required interaction. DroneStick provides useful feedback\nto the operator in the form of force transferred through the wire,\ntranslation/rotation of the flying joystick, and motor vibrations at the\nfingertips. Feedback allows users to interact with different forms of robotic\nsystems intuitively. A potential application can enhance an automated `last\nmile' delivery when a recipient needs to guide a delivery drone/robot gently to\na spot where a parcel has to be dropped.",
    "descriptor": "\nComments: 2 pages, 1 figure, to be published in ACM SIGGRAPH Asia 2021 Emerging Technologies\n",
    "authors": [
      "Evgeny Tsykunov",
      "Aleksey Fedoseev",
      "Ekaterina Dorzhieva",
      "Ruslan Agishev",
      "Roman Ibrahimov",
      "Derek Vasquez",
      "Luiza Labazanova",
      "Dzmitry Tsetserukou"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.09041"
  },
  {
    "id": "arXiv:2110.09047",
    "title": "Abnormal Occupancy Grid Map Recognition using Attention Network",
    "abstract": "The occupancy grid map is a critical component of autonomous positioning and\nnavigation in the mobile robotic system, as many other systems' performance\ndepends heavily on it. To guarantee the quality of the occupancy grid maps,\nresearchers previously had to perform tedious manual recognition for a long\ntime. This work focuses on automatic abnormal occupancy grid map recognition\nusing the residual neural networks and a novel attention mechanism module. We\npropose an effective channel and spatial Residual SE(csRSE) attention module,\nwhich contains a residual block for producing hierarchical features, followed\nby both channel SE (cSE) block and spatial SE (sSE) block for the sufficient\ninformation extraction along the channel and spatial pathways. To further\nsummarize the occupancy grid map characteristics and experiment with our csRSE\nattention modules, we constructed a dataset called occupancy grid map dataset\n(OGMD) for our experiments. On this OGMD test dataset, we tested few variants\nof our proposed structure and compared them with other attention mechanisms.\nOur experimental results show that the proposed attention network can infer the\nabnormal map with state-of-the-art (SOTA) accuracy of 96.23% for abnormal\noccupancy grid map recognition.",
    "descriptor": "",
    "authors": [
      "Fuqin Deng",
      "Hua Feng",
      "Mingjian Liang",
      "Qi Feng",
      "Ningbo Yi",
      "Yong Yang",
      "Yuan Gao",
      "Junfeng Chen",
      "Tin Lun Lam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09047"
  },
  {
    "id": "arXiv:2110.09050",
    "title": "Data Driven and Visualization based Strategization for University Rank  Improvement using Decision Trees",
    "abstract": "Annual ranking of higher educational institutes (HEIs) is a global phenomena\nand past research shows that they have significant impact on higher education\nlandscape. In spite of criticisms regarding the goals, methodologies and\noutcomes of such ranking systems, previous studies reveal that most of the\nuniversities pay close attention to ranking results and look forward to\nimproving their ranks. Generally, each ranking framework uses its own set of\nparameters and the data for individual metrics are condensed into a single\nfinal score for determining the rank thereby making it a complex multivariate\nproblem. Maintaining a good rank and ascending in the rankings is a difficult\ntask because it requires considerable resources, efforts and accurate planning.\nIn this work, we show how exploratory data analysis (EDA) using correlation\nheatmaps and box plots can aid in understanding the broad trends in the ranking\ndata, however it is challenging to make institutional decisions for rank\nimprovements completely based on EDA. We present a novel idea of classifying\nthe rankings data using Decision Tree (DT) based algorithms and retrieve\ndecision paths for rank improvement using data visualization techniques. Using\nLaplace correction to the probability estimate, we quantify the amount of\ncertainty attached with different decision paths obtained from interpretable DT\nmodels . The proposed methodology can aid HEIs to quantitatively asses the\nscope of improvement, adumbrate a fine-grained long-term action plan and\nprepare a suitable road-map.",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Nishi Doshi",
      "Samhitha Gundam",
      "Bhaskar Chaudhury"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2110.09050"
  },
  {
    "id": "arXiv:2110.09051",
    "title": "A Tactile-enabled Grasping Method for Robotic Fruit Harvesting",
    "abstract": "In the robotic crop harvesting environment, foreign objects intrusion in the\ngripper workspace is frequently occurring and unignorable, however, rarely\naddressed. This paper presents a novel intelligent robotic grasping method\ncapable of handling obstacle interference, which is the first of its kind in\nthe literature. The proposed method combines deep learning algorithms with\nlow-cost tactile sensing hardware on a multi-DoF soft robotic gripper. Through\nexperimental validations, the proposed method demonstrated promising\nperformance in distinguishing various grasping scenarios. The 4-finger\nindependently controlled gripper presented outstanding adaptability to handle\nvarious picking scenarios. The overall performance of this work indicated great\npotential for solving the robotic fruit harvesting challenges.",
    "descriptor": "\nComments: submit to conference\n",
    "authors": [
      "Hongyu Zhou",
      "Xing Wang",
      "Hanwen Kang",
      "Chao Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.09051"
  },
  {
    "id": "arXiv:2110.09054",
    "title": "A Stable FDTD Subgridding Scheme with SBP-SAT for Transient  Electromagnetic Analysis",
    "abstract": "We proposed a provably stable FDTD subgridding method for accurate and\nefficient transient electromagnetic analysis. In the proposed method, several\nfield components are properly added to the boundaries of Yee's grid to make\nsure that the discrete operators meet the summation-by-parts (SBP) property.\nThen, by incorporating the simultaneous approximation terms (SATs) into the\nfinite-difference time-domain (FDTD) method, the proposed FDTD subgridding\nmethod mimics the energy estimate of the continuous Maxwell's equations at the\nsemi-discrete level to guarantee its stability. Further, to couple multiple\nmesh blocks with different mesh sizes, the interpolation matrices are also\nderived. The proposed FDTD subgridding method is accurate, efficient, easy to\nimplement and be integrated into the existing FDTD codes with only simple\nmodifications. At last, three numerical examples with fine structures are\ncarried out to validate the effectiveness of the proposed method.",
    "descriptor": "",
    "authors": [
      "Yu Cheng",
      "Yuhui Wang",
      "Hanhong Liu",
      "Lilin Li",
      "Xiang-Hua Wang",
      "Shunchuan Yang",
      "Zhizhang",
      "Chen"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2110.09054"
  },
  {
    "id": "arXiv:2110.09057",
    "title": "Training Deep Neural Networks with Adaptive Momentum Inspired by the  Quadratic Optimization",
    "abstract": "Heavy ball momentum is crucial in accelerating (stochastic) gradient-based\noptimization algorithms for machine learning. Existing heavy ball momentum is\nusually weighted by a uniform hyperparameter, which relies on excessive tuning.\nMoreover, the calibrated fixed hyperparameter may not lead to optimal\nperformance. In this paper, to eliminate the effort for tuning the\nmomentum-related hyperparameter, we propose a new adaptive momentum inspired by\nthe optimal choice of the heavy ball momentum for quadratic optimization. Our\nproposed adaptive heavy ball momentum can improve stochastic gradient descent\n(SGD) and Adam. SGD and Adam with the newly designed adaptive momentum are more\nrobust to large learning rates, converge faster, and generalize better than the\nbaselines. We verify the efficiency of SGD and Adam with the new adaptive\nmomentum on extensive machine learning benchmarks, including image\nclassification, language modeling, and machine translation. Finally, we provide\nconvergence guarantees for SGD and Adam with the proposed adaptive momentum.",
    "descriptor": "",
    "authors": [
      "Tao Sun",
      "Huaming Ling",
      "Zuoqiang Shi",
      "Dongsheng Li",
      "Bao Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.09057"
  },
  {
    "id": "arXiv:2110.09059",
    "title": "Context-aware Reranking with Utility Maximization for Recommendation",
    "abstract": "As a critical task for large-scale commercial recommender systems, reranking\nhas shown the potential of improving recommendation results by uncovering\nmutual influence among items. Reranking rearranges items in the initial ranking\nlists from the previous ranking stage to better meet users' demands. However,\nrather than considering the context of initial lists as most existing methods\ndo, an ideal reranking algorithm should consider the counterfactual context --\nthe position and the alignment of the items in the reranked lists. In this\nwork, we propose a novel pairwise reranking framework, Context-aware Reranking\nwith Utility Maximization for recommendation (CRUM), which maximizes the\noverall utility after reranking efficiently. Specifically, we first design a\nutility-oriented evaluator, which applies Bi-LSTM and graph attention mechanism\nto estimate the listwise utility via the counterfactual context modeling. Then,\nunder the guidance of the evaluator, we propose a pairwise reranker model to\nfind the most suitable position for each item by swapping misplaced item pairs.\nExtensive experiments on two benchmark datasets and a proprietary real-world\ndataset demonstrate that CRUM significantly outperforms the state-of-the-art\nmodels in terms of both relevance-based metrics and utility-based metrics.",
    "descriptor": "",
    "authors": [
      "Yunjia Xi",
      "Weiwen Liu",
      "Xinyi Dai",
      "Ruiming Tang",
      "Weinan Zhang",
      "Qing Liu",
      "Xiuqiang He",
      "Yong Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.09059"
  },
  {
    "id": "arXiv:2110.09060",
    "title": "Discovery-and-Selection: Towards Optimal Multiple Instance Learning for  Weakly Supervised Object Detection",
    "abstract": "Weakly supervised object detection (WSOD) is a challenging task that requires\nsimultaneously learn object classifiers and estimate object locations under the\nsupervision of image category labels. A major line of WSOD methods roots in\nmultiple instance learning which regards images as bags of instance and selects\npositive instances from each bag to learn the detector. However, a grand\nchallenge emerges when the detector inclines to converge to discriminative\nparts of objects rather than the whole objects. In this paper, under the\nhypothesis that optimal solutions are included in local minima, we propose a\ndiscoveryand-selection approach fused with multiple instance learning (DS-MIL),\nwhich finds rich local minima and select optimal solutions from multiple local\nminima. To implement DS-MIL, an attention module is designed so that more\ncontext information can be captured by feature maps and more valuable proposals\ncan be collected during training. With proposal candidates, a re-rank module is\ndesigned to select informative instances for object detector training.\nExperimental results on commonly used benchmarks show that our proposed DS-MIL\napproach can consistently improve the baselines, reporting state-of-the-art\nperformance.",
    "descriptor": "",
    "authors": [
      "Shiwei Zhang",
      "Wei Ke",
      "Lin Yang",
      "Qixiang Ye",
      "Xiaopeng Hong",
      "Yihong Gong",
      "Tong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09060"
  },
  {
    "id": "arXiv:2110.09066",
    "title": "Fairness Concepts for Indivisible Items with Externalities",
    "abstract": "We study a fair allocation problem of indivisible items under additive\nexternalities in which each agent also receives values from items that are\nassigned to other agents. We propose several new fairness concepts. We extend\nthe well-studied envy-freeness up to one item (EF1) and envy-freeness up to any\nitem (EFX) to this setting, and we propose a new fairness concept called\ngeneral fair share (GFS). We undertake a detailed study and present algorithms\nfor finding fair allocations.",
    "descriptor": "",
    "authors": [
      "Haris Aziz",
      "Warut Suksompong",
      "Zhaohong Sun",
      "Toby Walsh"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.09066"
  },
  {
    "id": "arXiv:2110.09067",
    "title": "Unsupervised Shot Boundary Detection for Temporal Segmentation of Long  Capsule Endoscopy Videos",
    "abstract": "Physicians use Capsule Endoscopy (CE) as a non-invasive and non-surgical\nprocedure to examine the entire gastrointestinal (GI) tract for diseases and\nabnormalities. A single CE examination could last between 8 to 11 hours\ngenerating up to 80,000 frames which is compiled as a video. Physicians have to\nreview and analyze the entire video to identify abnormalities or diseases\nbefore making diagnosis. This review task can be very tedious, time consuming\nand prone to error. While only as little as a single frame may capture useful\ncontent that is relevant to the physicians' final diagnosis, frames covering\nthe small bowel region alone could be as much as 50,000. To minimize\nphysicians' review time and effort, this paper proposes a novel unsupervised\nand computationally efficient temporal segmentation method to automatically\npartition long CE videos into a homogeneous and identifiable video segments.\nHowever, the search for temporal boundaries in a long video using high\ndimensional frame-feature matrix is computationally prohibitive and\nimpracticable for real clinical application. Therefore, leveraging both spatial\nand temporal information in the video, we first extracted high level frame\nfeatures using a pretrained CNN model and then projected the high-dimensional\nframe-feature matrix to lower 1-dimensional embedding. Using this 1-dimensional\nsequence embedding, we applied the Pruned Exact Linear Time (PELT) algorithm to\nsearched for temporal boundaries that indicates the transition points from\nnormal to abnormal frames and vice-versa. We experimented with multiple real\npatients' CE videos and our model achieved an AUC of 66\\% on multiple test\nvideos against expert provided labels.",
    "descriptor": "",
    "authors": [
      "Sodiq Adewole",
      "Philip Fernandes",
      "James Jablonski",
      "Andrew Copland",
      "Michael Porter",
      "Sana Syed",
      "Donald Brown"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09067"
  },
  {
    "id": "arXiv:2110.09068",
    "title": "Approximate Sampling and Counting of Graphs with Near-Regular Degree  Intervals",
    "abstract": "The approximate uniform sampling of graphs with a given degree sequence is a\nwell-known, extensively studied problem in theoretical computer science and has\nsignificant applications, e.g., in the analysis of social networks. In this\nwork we study an extension of the problem, where degree intervals are specified\nrather than a single degree sequence. We are interested in sampling and\ncounting graphs whose degree sequences satisfy the degree interval constraints.\nA natural scenario where this problem arises is in hypothesis testing on social\nnetworks that are only partially observed.\nIn this work, we provide the first fully polynomial almost uniform sampler\n(FPAUS) as well as the first fully polynomial randomized approximation scheme\n(FPRAS) for sampling and counting, respectively, graphs with near-regular\ndegree intervals, in which every node $i$ has a degree from an interval not too\nfar away from a given $d \\in \\N$. In order to design our FPAUS, we rely on\nvarious state-of-the-art tools from Markov chain theory and combinatorics. In\nparticular, we provide the first non-trivial algorithmic application of a\nbreakthrough result of Liebenau and Wormald (2017) regarding an asymptotic\nformula for the number of graphs with a given near-regular degree sequence.\nFurthermore, we also make use of the recent breakthrough of Anari et al. (2019)\non sampling a base of a matroid under a strongly log-concave probability\ndistribution.\nAs a more direct approach, we also study a natural Markov chain recently\nintroduced by Rechner, Strowick and M\\\"uller-Hannemann (2018), based on three\nsimple local operations: Switches, hinge flips, and additions/deletions of a\nsingle edge. We obtain the first theoretical results for this Markov chain by\nshowing it is rapidly mixing for the case of near-regular degree intervals of\nsize at most one.",
    "descriptor": "",
    "authors": [
      "Georgios Amanatidis",
      "Pieter Kleer"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.09068"
  },
  {
    "id": "arXiv:2110.09069",
    "title": "Diameter constrained Steiner tree and related problems",
    "abstract": "We give a dynamic programming solution to find the minimum cost of a diameter\nconstrained Steiner tree in case of directed graphs. Then we show a simple\nreduction from undirected version to the directed version to realize an\nalgorithm of similar complexity i.e, FPT in number of terminal vertices. Other\nnatural variants of constrained Steiner trees are defined by imposing\nconstraints on the min-degree and size of the Steiner tree and some polynomial\ntime reductions among these problems are proven. To the best of our knowledge,\nthese fairly simple reductions are not present in the literature prior to our\nwork.",
    "descriptor": "\nComments: 13 pages, 4 figures\n",
    "authors": [
      "Prashanth Amireddy",
      "Chetan Sai Digumarthi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.09069"
  },
  {
    "id": "arXiv:2110.09073",
    "title": "Semi-asynchronous Hierarchical Federated Learning for Cooperative  Intelligent Transportation Systems",
    "abstract": "Cooperative Intelligent Transport System (C-ITS) is a promising network to\nprovide safety, efficiency, sustainability, and comfortable services for\nautomated vehicles and road infrastructures by taking advantages from\nparticipants. However, the components of C-ITS usually generate large amounts\nof data, which makes it difficult to explore data science. Currently, federated\nlearning has been proposed as an appealing approach to allow users to\ncooperatively reap the benefits from trained participants. Therefore, in this\npaper, we propose a novel Semi-asynchronous Hierarchical Federated Learning\n(SHFL) framework for C-ITS that enables elastic edge to cloud model aggregation\nfrom data sensing. We further formulate a joint edge node association and\nresource allocation problem under the proposed SHFL framework to prevent\npersonalities of heterogeneous road vehicles and achieve\ncommunication-efficiency. To deal with our proposed Mixed integer nonlinear\nprogramming (MINLP) problem, we introduce a distributed Alternating Direction\nMethod of Multipliers (ADMM)-Block Coordinate Update (BCU) algorithm. With this\nalgorithm, a tradeoff between training accuracy and transmission latency has\nbeen derived. Numerical results demonstrate the advantages of the proposed\nalgorithm in terms of training overhead and model performance.",
    "descriptor": "",
    "authors": [
      "Qimei Chen",
      "Zehua You",
      "Hao Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09073"
  },
  {
    "id": "arXiv:2110.09074",
    "title": "Towards General Deep Leakage in Federated Learning",
    "abstract": "Unlike traditional central training, federated learning (FL) improves the\nperformance of the global model by sharing and aggregating local models rather\nthan local data to protect the users' privacy. Although this training approach\nappears secure, some research has demonstrated that an attacker can still\nrecover private data based on the shared gradient information. This on-the-fly\nreconstruction attack deserves to be studied in depth because it can occur at\nany stage of training, whether at the beginning or at the end of model\ntraining; no relevant dataset is required and no additional models need to be\ntrained. We break through some unrealistic assumptions and limitations to apply\nthis reconstruction attack in a broader range of scenarios. We propose methods\nthat can reconstruct the training data from shared gradients or weights,\ncorresponding to the FedSGD and FedAvg usage scenarios, respectively. We\npropose a zero-shot approach to restore labels even if there are duplicate\nlabels in the batch. We study the relationship between the label and image\nrestoration. We find that image restoration fails even if there is only one\nincorrectly inferred label in the batch; we also find that when batch images\nhave the same label, the corresponding image is restored as a fusion of that\nclass of images. Our approaches are evaluated on classic image benchmarks,\nincluding CIFAR-10 and ImageNet. The batch size, image quality, and the\nadaptability of the label distribution of our approach exceed those of\nGradInversion, the state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Jiahui Geng",
      "Yongli Mou",
      "Feifei Li",
      "Qing Li",
      "Oya Beyan",
      "Stefan Decker",
      "Chunming Rong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09074"
  },
  {
    "id": "arXiv:2110.09075",
    "title": "Boosting the Transferability of Video Adversarial Examples via Temporal  Translation",
    "abstract": "Although deep-learning based video recognition models have achieved\nremarkable success, they are vulnerable to adversarial examples that are\ngenerated by adding human-imperceptible perturbations on clean video samples.\nAs indicated in recent studies, adversarial examples are transferable, which\nmakes it feasible for black-box attacks in real-world applications.\nNevertheless, most existing adversarial attack methods have poor\ntransferability when attacking other video models and transfer-based attacks on\nvideo models are still unexplored. To this end, we propose to boost the\ntransferability of video adversarial examples for black-box attacks on video\nrecognition models. Through extensive analysis, we discover that different\nvideo recognition models rely on different discriminative temporal patterns,\nleading to the poor transferability of video adversarial examples. This\nmotivates us to introduce a temporal translation attack method, which optimizes\nthe adversarial perturbations over a set of temporal translated video clips. By\ngenerating adversarial examples over translated videos, the resulting\nadversarial examples are less sensitive to temporal patterns existed in the\nwhite-box model being attacked and thus can be better transferred. Extensive\nexperiments on the Kinetics-400 dataset and the UCF-101 dataset demonstrate\nthat our method can significantly boost the transferability of video\nadversarial examples. For transfer-based attack against video recognition\nmodels, it achieves a 61.56% average attack success rate on the Kinetics-400\nand 48.60% on the UCF-101.",
    "descriptor": "",
    "authors": [
      "Zhipeng Wei",
      "Jingjing Chen",
      "Zuxuan Wu",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09075"
  },
  {
    "id": "arXiv:2110.09083",
    "title": "Learning to Learn a Cold-start Sequential Recommender",
    "abstract": "The cold-start recommendation is an urgent problem in contemporary online\napplications. It aims to provide users whose behaviors are literally sparse\nwith as accurate recommendations as possible. Many data-driven algorithms, such\nas the widely used matrix factorization, underperform because of data\nsparseness. This work adopts the idea of meta-learning to solve the user's\ncold-start recommendation problem. We propose a meta-learning based cold-start\nsequential recommendation framework called metaCSR, including three main\ncomponents: Diffusion Representer for learning better user/item embedding\nthrough information diffusion on the interaction graph; Sequential Recommender\nfor capturing temporal dependencies of behavior sequences; Meta Learner for\nextracting and propagating transferable knowledge of prior users and learning a\ngood initialization for new users. metaCSR holds the ability to learn the\ncommon patterns from regular users' behaviors and optimize the initialization\nso that the model can quickly adapt to new users after one or a few gradient\nupdates to achieve optimal performance. The extensive quantitative experiments\non three widely-used datasets show the remarkable performance of metaCSR in\ndealing with user cold-start problem. Meanwhile, a series of qualitative\nanalysis demonstrates that the proposed metaCSR has good generalization.",
    "descriptor": "",
    "authors": [
      "Xiaowen Huang",
      "Jitao Sang",
      "Jian Yu",
      "Changsheng Xu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09083"
  },
  {
    "id": "arXiv:2110.09086",
    "title": "ViraPart: A Text Refinement Framework for ASR and NLP Tasks in Persian",
    "abstract": "The Persian language is an inflectional SOV language. This fact makes Persian\na more uncertain language. However, using techniques such as ZWNJ recognition,\npunctuation restoration, and Persian Ezafe construction will lead us to a more\nunderstandable and precise language. In most of the works in Persian, these\ntechniques are addressed individually. Despite that, we believe that for text\nrefinement in Persian, all of these tasks are necessary. In this work, we\nproposed a ViraPart framework that uses embedded ParsBERT in its core for text\nclarifications. First, used the BERT variant for Persian following by a\nclassifier layer for classification procedures. Next, we combined models\noutputs to output cleartext. In the end, the proposed model for ZWNJ\nrecognition, punctuation restoration, and Persian Ezafe construction performs\nthe averaged F1 macro scores of 96.90\\%, 92.13\\%, and 98.50\\%, respectively.\nExperimental results show that our proposed approach is very effective in text\nrefinement for the Persian language.",
    "descriptor": "",
    "authors": [
      "Narges Farokhshad",
      "Milad Molazadeh",
      "Saman Jamalabbasi",
      "Hamed Babaei Giglou",
      "Saeed Bibak"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.09086"
  },
  {
    "id": "arXiv:2110.09089",
    "title": "DNA Codes over the Ring $\\mathbb{Z}_4 + w\\mathbb{Z}_4$",
    "abstract": "In this present work, we generalize the study of construction of DNA codes\nover the rings $\\mathcal{R}_\\theta=\\mathbb{Z}_4+w\\mathbb{Z}_4$, $w^2 = \\theta $\nfor $\\theta \\in \\mathbb{Z}_4+w\\mathbb{Z}_4$. Rigorous study along with\ncharacterization of the ring structures is presented. We extend the Gau map and\nGau distance, defined in \\cite{DKBG}, over all the $16$ rings\n$\\mathcal{R}_\\theta$. Furthermore, an isometry between the codes over the rings\n$\\mathcal{R}_\\theta$ and the analogous DNA codes is established in general.\nBrief study of dual and self dual codes over the rings is given including the\nconstruction of special class of self dual codes that satisfy reverse and\nreverse-complement constraints. The technical contributions of this paper are\ntwofold. Considering the Generalized Gau distance, Sphere Packing-like bound,\nGV-like bound, Singleton like bound and Plotkin-like bound are established over\nthe rings $\\mathcal{R}_\\theta$. In addition to this, optimal class of codes are\nprovided with respect to Singleton-like bound and Plotkin-like bound. Moreover,\nthe construction of family of DNA codes is proposed that satisfies reverse and\nreverse-complement constraints using the Reed-Muller type codes over the rings\n$\\mathcal{R}_\\theta$.",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Adel Alahmadi",
      "Krishna Gopal Benerjee",
      "Sourav Deb",
      "Manish K Gupta"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Emerging Technologies (cs.ET)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2110.09089"
  },
  {
    "id": "arXiv:2110.09094",
    "title": "Using Natural Language Processing to Understand Reasons and Motivators  Behind Customer Calls in Financial Domain",
    "abstract": "In this era of abundant digital information, customer satisfaction has become\none of the prominent factors in the success of any business. Customers want a\none-click solution for almost everything. They tend to get unsatisfied if they\nhave to call about something which they could have done online. Moreover,\nincoming calls are a high-cost component for any business. Thus, it is\nessential to develop a framework capable of mining the reasons and motivators\nbehind customer calls. This paper proposes two models. Firstly, an\nattention-based stacked bidirectional Long Short Term Memory Network followed\nby Hierarchical Clustering for extracting these reasons from transcripts of\ninbound calls. Secondly, a set of ensemble models based on probabilities from\nSupport Vector Machines and Logistic Regression. It is capable of detecting\nfactors that led to these calls. Extensive evaluation proves the effectiveness\nof these models.",
    "descriptor": "\nComments: Accepted at ICCMDE-2021. To be published in Springer - Lecture Notes on Data Engineering and Communications Technologies\n",
    "authors": [
      "Ankit Patil",
      "Ankush Chopra",
      "Sohom Ghosh",
      "Vamshi Vadla"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.09094"
  },
  {
    "id": "arXiv:2110.09096",
    "title": "Semantic network analysis of abstract and concrete word associations",
    "abstract": "In recent years, a new interest for the use of graph-theory based networks\nhas emerged within the field of cognitive science. This has played a key role\nin mining the large amount of data generated by word association norms. In the\npresent work, we applied semantic network analyses to explore norms of French\nword associations for concrete and abstract concepts (Lakhzoum et al., 2021).\nGraph analyses have shown that the network exhibits high clustering\ncoefficient, sparse density, and small average shortest path length for both\nthe concrete and abstract networks. These characteristics are consistent with a\nsmall-world structure. Comparisons between local node statistics and global\nstructural topology showed that abstract and concrete concepts present a\nsimilar local connectivity but different overall patterns of structural\norganisation with concrete concepts presenting an organisation in densely\nconnected communities compared to abstract concepts. These patterns confirm\npreviously acquired knowledge about the dichotomy of abstract and concrete\nconcepts on a larger scale. To the best of our knowledge, this is the first\nattempt to confirm the generalisability of these properties to the French\nlanguage and with an emphasis on abstract and concrete concepts.",
    "descriptor": "",
    "authors": [
      "Dounia Lakhzoum",
      "Marie Izaute",
      "Ludovic Ferrand"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2110.09096"
  },
  {
    "id": "arXiv:2110.09101",
    "title": "Vega: A 10-Core SoC for IoT End-Nodes with DNN Acceleration and  Cognitive Wake-Up From MRAM-Based State-Retentive Sleep Mode",
    "abstract": "The Internet-of-Things requires end-nodes with ultra-low-power always-on\ncapability for a long battery lifetime, as well as high performance, energy\nefficiency, and extreme flexibility to deal with complex and fast-evolving\nnear-sensor analytics algorithms (NSAAs). We present Vega, an IoT end-node SoC\ncapable of scaling from a 1.7 $\\mathrm{\\mu}$W fully retentive cognitive sleep\nmode up to 32.2 GOPS (@ 49.4 mW) peak performance on NSAAs, including mobile\nDNN inference, exploiting 1.6 MB of state-retentive SRAM, and 4 MB of\nnon-volatile MRAM. To meet the performance and flexibility requirements of\nNSAAs, the SoC features 10 RISC-V cores: one core for SoC and IO management and\na 9-cores cluster supporting multi-precision SIMD integer and floating-point\ncomputation. Vega achieves SoA-leading efficiency of 615 GOPS/W on 8-bit INT\ncomputation (boosted to 1.3TOPS/W for 8-bit DNN inference with hardware\nacceleration). On floating-point (FP) compuation, it achieves SoA-leading\nefficiency of 79 and 129 GFLOPS/W on 32- and 16-bit FP, respectively. Two\nprogrammable machine-learning (ML) accelerators boost energy efficiency in\ncognitive sleep and active states, respectively.",
    "descriptor": "\nComments: 13 pages, 11 figures, 8 tables, journal paper\n",
    "authors": [
      "Davide Rossi",
      "Francesco Conti",
      "Manuel Eggimann",
      "Alfio Di Mauro",
      "Giuseppe Tagliavini",
      "Stefan Mach",
      "Marco Guermandi",
      "Antonio Pullini",
      "Igor Loi",
      "Jie Chen",
      "Eric Flamand",
      "Luca Benini"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09101"
  },
  {
    "id": "arXiv:2110.09102",
    "title": "Data structure for node connectivity queries",
    "abstract": "Let $\\kappa(s,t)$ denote the maximum number of internally disjoint paths in\nan undirected graph $G$. We consider designing a data structure that includes a\nlist of cuts, and answers in $O(1)$ time the following query: given $s,t \\in\nV$, determine whether $\\kappa(s,t) \\leq k$, and if so, return a pointer to an\n$st$-cut of size $\\leq k$ in the list. A trivial data structure includes a list\nof $n(n-1)/2$ cuts and requires $\\Theta(kn^2)$ space. We show that $O(kn)$ cuts\nsuffice, thus reducing the space to $O(k^2 n+n^2)$. In the case when $G$ is\n$k$-connected, we show that $O(n)$ cuts suffice, and that these cuts can be\npartitioned into $O(k)$ laminar families; this reduces the space to $O(kn)$.\nThe latter result slightly improves and substantially simplifies a recent\nresult of Pettie and Yin [ICALP 2021].",
    "descriptor": "",
    "authors": [
      "Zeev Nutov"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.09102"
  },
  {
    "id": "arXiv:2110.09103",
    "title": "LDNet: Unified Listener Dependent Modeling in MOS Prediction for  Synthetic Speech",
    "abstract": "An effective approach to automatically predict the subjective rating for\nsynthetic speech is to train on a listening test dataset with human-annotated\nscores. Although each speech sample in the dataset is rated by several\nlisteners, most previous works only used the mean score as the training target.\nIn this work, we present LDNet, a unified framework for mean opinion score\n(MOS) prediction that predicts the listener-wise perceived quality given the\ninput speech and the listener identity. We reflect recent advances in LD\nmodeling, including design choices of the model architecture, and propose two\ninference methods that provide more stable results and efficient computation.\nWe conduct systematic experiments on the voice conversion challenge (VCC) 2018\nbenchmark and a newly collected large-scale MOS dataset, providing an in-depth\nanalysis of the proposed framework. Results show that the mean listener\ninference method is a better way to utilize the mean scores, whose\neffectiveness is more obvious when having more ratings per sample.",
    "descriptor": "\nComments: Submitted to ICASSP 2022. Code available at: this https URL\n",
    "authors": [
      "Wen-Chin Huang",
      "Erica Cooper",
      "Junichi Yamagishi",
      "Tomoki Toda"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.09103"
  },
  {
    "id": "arXiv:2110.09107",
    "title": "Differentiable Rendering with Perturbed Optimizers",
    "abstract": "Reasoning about 3D scenes from their 2D image projections is one of the core\nproblems in computer vision. Solutions to this inverse and ill-posed problem\ntypically involve a search for models that best explain observed image data.\nNotably, images depend both on the properties of observed scenes and on the\nprocess of image formation. Hence, if optimization techniques should be used to\nexplain images, it is crucial to design differentiable functions for the\nprojection of 3D scenes into images, also known as differentiable rendering.\nPrevious approaches to differentiable rendering typically replace\nnon-differentiable operations by smooth approximations, impacting the\nsubsequent 3D estimation. In this paper, we take a more general approach and\nstudy differentiable renderers through the prism of randomized optimization and\nthe related notion of perturbed optimizers. In particular, our work highlights\nthe link between some well-known differentiable renderer formulations and\nrandomly smoothed optimizers, and introduces differentiable perturbed\nrenderers. We also propose a variance reduction mechanism to alleviate the\ncomputational burden inherent to perturbed optimizers and introduce an adaptive\nscheme to automatically adjust the smoothing parameters of the rendering\nprocess. We apply our method to 3D scene reconstruction and demonstrate its\nadvantages on the tasks of 6D pose estimation and 3D mesh reconstruction. By\nproviding informative gradients that can be used as a strong supervisory\nsignal, we demonstrate the benefits of perturbed renderers to obtain more\naccurate solutions when compared to the state-of-the-art alternatives using\nsmooth gradient approximations.",
    "descriptor": "",
    "authors": [
      "Quentin Le Lidec",
      "Ivan Laptev",
      "Cordelia Schmid",
      "Justin Carpentier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09107"
  },
  {
    "id": "arXiv:2110.09108",
    "title": "Asymmetric Modality Translation For Face Presentation Attack Detection",
    "abstract": "Face presentation attack detection (PAD) is an essential measure to protect\nface recognition systems from being spoofed by malicious users and has\nattracted great attention from both academia and industry. Although most of the\nexisting methods can achieve desired performance to some extent, the\ngeneralization issue of face presentation attack detection under cross-domain\nsettings (e.g., the setting of unseen attacks and varying illumination) remains\nto be solved. In this paper, we propose a novel framework based on asymmetric\nmodality translation for face presentation attack detection in bi-modality\nscenarios. Under the framework, we establish connections between two modality\nimages of genuine faces. Specifically, a novel modality fusion scheme is\npresented that the image of one modality is translated to the other one through\nan asymmetric modality translator, then fused with its corresponding paired\nimage. The fusion result is fed as the input to a discriminator for inference.\nThe training of the translator is supervised by an asymmetric modality\ntranslation loss. Besides, an illumination normalization module based on\nPattern of Local Gravitational Force (PLGF) representation is used to reduce\nthe impact of illumination variation. We conduct extensive experiments on three\npublic datasets, which validate that our method is effective in detecting\nvarious types of attacks and achieves state-of-the-art performance under\ndifferent evaluation protocols.",
    "descriptor": "",
    "authors": [
      "Zhi Li",
      "Haoliang Li",
      "Xin Luo",
      "Yongjian Hu",
      "Kwok-Yan Lam",
      "Alex C. Kot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09108"
  },
  {
    "id": "arXiv:2110.09109",
    "title": "Patch-Based Deep Autoencoder for Point Cloud Geometry Compression",
    "abstract": "The ever-increasing 3D application makes the point cloud compression\nunprecedentedly important and needed. In this paper, we propose a patch-based\ncompression process using deep learning, focusing on the lossy point cloud\ngeometry compression. Unlike existing point cloud compression networks, which\napply feature extraction and reconstruction on the entire point cloud, we\ndivide the point cloud into patches and compress each patch independently. In\nthe decoding process, we finally assemble the decompressed patches into a\ncomplete point cloud. In addition, we train our network by a patch-to-patch\ncriterion, i.e., use the local reconstruction loss for optimization, to\napproximate the global reconstruction optimality. Our method outperforms the\nstate-of-the-art in terms of rate-distortion performance, especially at low\nbitrates. Moreover, the compression process we proposed can guarantee to\ngenerate the same number of points as the input. The network model of this\nmethod can be easily applied to other point cloud reconstruction problems, such\nas upsampling.",
    "descriptor": "\nComments: Accepted to ACM Multimedia Asia (MMAsia '21)\n",
    "authors": [
      "Kang You",
      "Pan Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.09109"
  },
  {
    "id": "arXiv:2110.09110",
    "title": "Graph Convolution Neural Network For Weakly Supervised Abnormality  Localization In Long Capsule Endoscopy Videos",
    "abstract": "Temporal activity localization in long videos is an important problem. The\ncost of obtaining frame level label for long Wireless Capsule Endoscopy (WCE)\nvideos is prohibitive. In this paper, we propose an end-to-end temporal\nabnormality localization for long WCE videos using only weak video level\nlabels. Physicians use Capsule Endoscopy (CE) as a non-surgical and\nnon-invasive method to examine the entire digestive tract in order to diagnose\ndiseases or abnormalities. While CE has revolutionized traditional endoscopy\nprocedures, a single CE examination could last up to 8 hours generating as much\nas 100,000 frames. Physicians must review the entire video, frame-by-frame, in\norder to identify the frames capturing relevant abnormality. This, sometimes\ncould be as few as just a single frame. Given this very high level of\nredundancy, analyzing long CE videos can be very tedious, time consuming and\nalso error prone. This paper presents a novel multi-step method for an\nend-to-end localization of target frames capturing abnormalities of interest in\nthe long video using only weak video labels. First we developed an automatic\ntemporal segmentation using change point detection technique to temporally\nsegment the video into uniform, homogeneous and identifiable segments. Then we\nemployed Graph Convolutional Neural Network (GCNN) to learn a representation of\neach video segment. Using weak video segment labels, we trained our GCNN model\nto recognize each video segment as abnormal if it contains at least a single\nabnormal frame. Finally, leveraging the parameters of the trained GCNN model,\nwe replaced the final layer of the network with a temporal pool layer to\nlocalize the relevant abnormal frames within each abnormal video segment. Our\nmethod achieved an accuracy of 89.9\\% on the graph classification task and a\nspecificity of 97.5\\% on the abnormal frames localization task.",
    "descriptor": "",
    "authors": [
      "Sodiq Adewole",
      "Philip Fernandes",
      "James Jablonski",
      "Andrew Copland",
      "Michael Porter",
      "Sana Syed",
      "Donald Brown"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09110"
  },
  {
    "id": "arXiv:2110.09111",
    "title": "Analyzing Wikipedia Membership Dataset and PredictingUnconnected Nodes  in the Signed Networks",
    "abstract": "In the age of digital interaction, person-to-person relationships existing on\nsocial media may be different from the very same interactions that exist\noffline. Examining potential or spurious relationships between members in a\nsocial network is a fertile area of research for computer scientists -- here we\nexamine how relationships can be predicted between two unconnected people in a\nsocial network by using area under Precison-Recall curve and ROC. Modeling the\nsocial network as a signed graph, we compare Triadic model,Latent Information\nmodel and Sentiment model and use them to predict peer to peer interactions,\nfirst using a plain signed network, and second using a signed network with\ncomments as context. We see that our models are much better than random model\nand could complement each other in different cases.",
    "descriptor": "\nComments: The work was done in UCLA CS249 17Spring\n",
    "authors": [
      "Zhihao Wu",
      "Taoran Li",
      "Ray Roman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.09111"
  },
  {
    "id": "arXiv:2110.09114",
    "title": "A Promising Technology for 6G Wireless Networks: Intelligent Reflecting  Surface",
    "abstract": "The intelligent information society, which is highly digitized, intelligence\ninspired and globally data driven, will be deployed in the next decade. The\nnext 6G wireless communication networks are the key to achieve this grand\nblueprint, which is expected to connect everything, provide full dimensional\nwireless coverage and integrate all functions to support full-vertical\napplications. Recent research reveals that intelligent reflecting surface (IRS)\nwith wireless environment control capability is a promising technology for 6G\nnetworks. Specifically, IRS can intelligently control the wavefront, e.g., the\nphase, amplitude, frequency, and even polarization by massive tunable elements,\nthus achieving fine-grained 3-D passive beamforming. In this paper, we first\ngive a blueprint of the next 6G networks including the vision, typical\nscenarios and key performance indicators (KPIs). Then, we provide an overview\nof IRS including the new signal model, hardware architecture and competitive\nadvantages in 6G networks. Besides, we discuss the potential application of IRS\nin the connectivity of 6G networks in detail, including intelligent and\ncontrollable wireless environment, ubiquitous connectivity, deep connectivity\nand holographic connectivity. At last, we summarize the challenges of IRS\napplication and deployment in 6G networks. As a timely review of IRS, our\nsummary will be of interest to both researchers and practitioners engaging in\nIRS for 6G networks.",
    "descriptor": "",
    "authors": [
      "Wen-Xuan Long",
      "Rui Chen",
      "Marco Moretti",
      "Wei Zhang",
      "Jiandong Li"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.09114"
  },
  {
    "id": "arXiv:2110.09116",
    "title": "Real Additive Margin Softmax for Speaker Verification",
    "abstract": "The additive margin softmax (AM-Softmax) loss has delivered remarkable\nperformance in speaker verification. A supposed behavior of AM-Softmax is that\nit can shrink within-class variation by putting emphasis on target logits,\nwhich in turn improves margin between target and non-target classes. In this\npaper, we conduct a careful analysis on the behavior of AM-Softmax loss, and\nshow that this loss does not implement real max-margin training. Based on this\nobservation, we present a Real AM-Softmax loss which involves a true margin\nfunction in the softmax training. Experiments conducted on VoxCeleb1, SITW and\nCNCeleb demonstrated that the corrected AM-Softmax loss consistently\noutperforms the original one. The code has been released at\nhttps://gitlab.com/csltstu/sunine.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Lantian Li",
      "Ruiqian Nai",
      "Dong Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.09116"
  },
  {
    "id": "arXiv:2110.09121",
    "title": "KaraTuner: Towards end to end natural pitch correction for singing voice  in karaoke",
    "abstract": "An automatic pitch correction system typically includes several stages, such\nas pitch extraction, deviation estimation, pitch shift processing, and\ncross-fade smoothing. However, designing these components with strategies often\nrequires domain expertise and they are likely to fail on corner cases. In this\npaper, we present KaraTuner, an end-to-end neural architecture that predicts\npitch curve and resynthesizes the singing voice directly from the tuned pitch\nand vocal spectrum extracted from the original recordings. Several vital\ntechnical points have been introduced in KaraTuner to ensure pitch accuracy,\npitch naturalness, timbre consistency, and sound quality. A feed-forward\nTransformer is employed in the pitch predictor to capture long-term\ndependencies in the vocal spectrum and musical note. We also develop a\npitch-controllable vocoder base on a novel source-filter block and the Fre-GAN\narchitecture. KaraTuner obtains a higher preference than the rule-based pitch\ncorrection approach through A/B tests, and perceptual experiments show that the\nproposed vocoder achieves significant advantages in timbre consistency and\nsound quality compared with the parametric WORLD vocoder and phase vocoder.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Xiaobin Zhuang",
      "Huiran Yu",
      "Weifeng Zhao",
      "Tao Jiang",
      "Peng Hu",
      "Simon Lui",
      "Wenjiang Zhou"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.09121"
  },
  {
    "id": "arXiv:2110.09123",
    "title": "Joint Spatial Division and Coaxial Multiplexing for Downlink Multi-User  OAM Wireless Backhaul",
    "abstract": "Orbital angular momentum (OAM) at radio frequency (RF) provides a novel\napproach of multiplexing a set of orthogonal modes on the same frequency\nchannel to achieve high spectral efficiencies (SEs). However, the existing\nresearch on OAM wireless communications is mainly focused on pointto-point\ntransmission in the line-of-sight (LoS) scenario. In this paper, we propose an\noverall scheme of the downlink multi-user OAM (MU-OAM) wireless backhaul based\non uniform circular arrays (UCAs) for broadcasting networks, which can achieve\nthe joint spatial division and coaxial multiplexing (JSDCM). A salient feature\nof the proposed downlink MU-OAM wireless backhaul systems is that the channel\nmatrices are completely characterized by the position of each small base\nstation (SBS), independent of the numbers of subcarriers and antennas, which\navoids estimating large channel matrices required by the traditional downlink\nmulti-user multiple-input multiple-output (MU-MIMO) wireless backhaul systems.\nThereafter, we propose an OAM-based multiuser distance and angle of arrival\n(AoA) estimation method, which is able to simultaneously estimate the positions\nof multiple SBSs with a flexible number of training symbols. With the estimated\ndistances and AoAs, a MU-OAM preprocessing scheme is applied to eliminate the\nco-mode and inter-mode interferences in the downlink MU-OAM channel. At last,\nthe proposed methods are extended to the downlink MU-OAM-MIMO wireless backhaul\nsystem equipped with uniform concentric circular arrays (UCCAs), for which much\nhigher spectral efficiency (SE) and energy efficiency (EE) than traditional\nMU-MIMO systems can be achieved. Both mathematical analysis and simulation\nresults validate that the proposed scheme can effectively eliminate both\ninterferences of the practical downlink MU-OAM channel and approaches the\nperformance of the ideal MU-OAM channel.",
    "descriptor": "",
    "authors": [
      "Wen-Xuan Long",
      "Rui Chen",
      "Marco Moretti",
      "Jian Xiong",
      "Jiandong Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.09123"
  },
  {
    "id": "arXiv:2110.09127",
    "title": "SpecTNT: a Time-Frequency Transformer for Music Audio",
    "abstract": "Transformers have drawn attention in the MIR field for their remarkable\nperformance shown in natural language processing and computer vision. However,\nprior works in the audio processing domain mostly use Transformer as a temporal\nfeature aggregator that acts similar to RNNs. In this paper, we propose\nSpecTNT, a Transformer-based architecture to model both spectral and temporal\nsequences of an input time-frequency representation. Specifically, we introduce\na novel variant of the Transformer-in-Transformer (TNT) architecture. In each\nSpecTNT block, a spectral Transformer extracts frequency-related features into\nthe frequency class token (FCT) for each frame. Later, the FCTs are linearly\nprojected and added to the temporal embeddings (TEs), which aggregate useful\ninformation from the FCTs. Then, a temporal Transformer processes the TEs to\nexchange information across the time axis. By stacking the SpecTNT blocks, we\nbuild the SpecTNT model to learn the representation for music signals. In\nexperiments, SpecTNT demonstrates state-of-the-art performance in music tagging\nand vocal melody extraction, and shows competitive performance for chord\nrecognition. The effectiveness of SpecTNT and other design choices are further\nexamined through ablation studies.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Wei-Tsung Lu",
      "Ju-Chiang Wang",
      "Minz Won",
      "Keunwoo Choi",
      "Xuchen Song"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.09127"
  },
  {
    "id": "arXiv:2110.09129",
    "title": "Deep Models with Fusion Strategies for MVP Point Cloud Registration",
    "abstract": "The main goal of point cloud registration in Multi-View Partial (MVP)\nChallenge 2021 is to estimate a rigid transformation to align a point cloud\npair. The pairs in this competition have the characteristics of low overlap,\nnon-uniform density, unrestricted rotations and ambiguity, which pose a huge\nchallenge to the registration task. In this report, we introduce our solution\nto the registration task, which fuses two deep learning models: ROPNet and\nPREDATOR, with customized ensemble strategies. Finally, we achieved the second\nplace in the registration track with 2.96546, 0.02632 and 0.07808 under the the\nmetrics of Rot\\_Error, Trans\\_Error and MSE, respectively.",
    "descriptor": "\nComments: Point cloud registration competition, ICCV21 workshop. Substantial text overlap with arXiv:2107.02583\n",
    "authors": [
      "Lifa Zhu",
      "Changwei Lin",
      "Dongrui Liu",
      "Xin Li",
      "Francisco G\u00f3mez-Fern\u00e1ndez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09129"
  },
  {
    "id": "arXiv:2110.09131",
    "title": "Ensembling Graph Predictions for AMR Parsing",
    "abstract": "In many machine learning tasks, models are trained to predict structure data\nsuch as graphs. For example, in natural language processing, it is very common\nto parse texts into dependency trees or abstract meaning representation (AMR)\ngraphs. On the other hand, ensemble methods combine predictions from multiple\nmodels to create a new one that is more robust and accurate than individual\npredictions. In the literature, there are many ensembling techniques proposed\nfor classification or regression problems, however, ensemble graph prediction\nhas not been studied thoroughly. In this work, we formalize this problem as\nmining the largest graph that is the most supported by a collection of graph\npredictions. As the problem is NP-Hard, we propose an efficient heuristic\nalgorithm to approximate the optimal solution. To validate our approach, we\ncarried out experiments in AMR parsing problems. The experimental results\ndemonstrate that the proposed approach can combine the strength of\nstate-of-the-art AMR parsers to create new predictions that are more accurate\nthan any individual models in five standard benchmark datasets.",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Hoang Thanh Lam",
      "Gabriele Picco",
      "Yufang Hou",
      "Young-Suk Lee",
      "Lam M. Nguyen",
      "Dzung T. Phan",
      "Vanessa L\u00f3pez",
      "Ramon Fernandez Astudillo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09131"
  },
  {
    "id": "arXiv:2110.09132",
    "title": "EmbRace: Accelerating Sparse Communication for Distributed Training of  NLP Neural Networks",
    "abstract": "Distributed data-parallel training has been widely used for natural language\nprocessing (NLP) neural network models. However, the embedding tables in NLP\nmodels, holding a large portion of parameters and bringing dramatic sparsity in\ncommunication, make it a big challenge to efficiently scale the distributed\ntraining. Current distributed training frameworks mainly concentrate on dense\nmodels but neglect the sparsity of NLP models, resulting in significant\ncommunication overhead and relatively poor scalability.\nIn this paper, we propose EmbRace, an efficient communication framework\ndesigned to accelerate sparse communication of distributed NLP model training.\nEmbRace introduces Sparsity-aware Hybrid Communication, which combines AlltoAll\nand AllReduce to optimize the communication overhead for sparse and dense data\nin NLP models. EmbRace further introduces a 2D Communication Scheduling\napproach to thoroughly overlap communication with computation by optimizing\nmodel computation procedure, relaxing the dependency of embeddings, and\nscheduling communication with a priority queue.\nWe implement EmbRace based on PyTorch and Horovod, and conduct comprehensive\nevaluations with four representative NLP models on two high-performance GPU\nclusters. Experimental results show that EmbRace achieves up to 30.66X speedup\non 16 GPUs clusters among four popular distributed training baselines.",
    "descriptor": "",
    "authors": [
      "Shengwei Li",
      "Zhiquan Lai",
      "Dongsheng Li",
      "Xiangyu Ye",
      "Yabo Duan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.09132"
  },
  {
    "id": "arXiv:2110.09133",
    "title": "Online Sign Identification: Minimization of the Number of Errors in  Thresholding Bandits",
    "abstract": "In the fixed budget thresholding bandit problem, an algorithm sequentially\nallocates a budgeted number of samples to different distributions. It then\npredicts whether the mean of each distribution is larger or lower than a given\nthreshold. We introduce a large family of algorithms (containing most existing\nrelevant ones), inspired by the Frank-Wolfe algorithm, and provide a thorough\nyet generic analysis of their performance. This allowed us to construct new\nexplicit algorithms, for a broad class of problems, whose losses are within a\nsmall constant factor of the non-adaptive oracle ones. Quite interestingly, we\nobserved that adaptive methods empirically greatly out-perform non-adaptive\noracles, an uncommon behavior in standard online learning settings, such as\nregret minimization. We explain this surprising phenomenon on an insightful toy\nproblem.",
    "descriptor": "\nComments: 10+15 pages. To be published in the proceedings of NeurIPS 2021\n",
    "authors": [
      "Reda Ouhamma",
      "R\u00e9my Degenne",
      "Pierre Gaillard",
      "Vianney Perchet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09133"
  },
  {
    "id": "arXiv:2110.09138",
    "title": "State-Space Constraints Improve the Generalization of the Differentiable  Neural Computer in some Algorithmic Tasks",
    "abstract": "Memory-augmented neural networks (MANNs) can solve algorithmic tasks like\nsorting. However, they often do not generalize to lengths of input sequences\nnot seen in the training phase. Therefore, we introduce two approaches\nconstraining the state-space of the network controller to improve the\ngeneralization to out-of-distribution-sized input sequences: state compression\nand state regularization. We show that both approaches can improve the\ngeneralization capability of a particular type of MANN, the differentiable\nneural computer (DNC), and compare our approaches to a stateful and a stateless\ncontroller on a set of algorithmic tasks. Furthermore, we show that especially\nthe combination of both approaches can enable a pre-trained DNC to be extended\npost hoc with a larger memory. Thus, our introduced approaches allow to train a\nDNC using shorter input sequences and thus save computational resources.\nMoreover, we observed that the capability for generalization is often\naccompanied by loop structures in the state-space, which could correspond to\nlooping constructs in algorithms.",
    "descriptor": "",
    "authors": [
      "Patrick Ofner",
      "Roman Kern"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.09138"
  },
  {
    "id": "arXiv:2110.09140",
    "title": "Learning Prototype-oriented Set Representations for Meta-Learning",
    "abstract": "Learning from set-structured data is a fundamental problem that has recently\nattracted increasing attention, where a series of summary networks are\nintroduced to deal with the set input. In fact, many meta-learning problems can\nbe treated as set-input tasks. Most existing summary networks aim to design\ndifferent architectures for the input set in order to enforce permutation\ninvariance. However, scant attention has been paid to the common cases where\ndifferent sets in a meta-distribution are closely related and share certain\nstatistical properties. Viewing each set as a distribution over a set of global\nprototypes, this paper provides a novel optimal transport (OT) based way to\nimprove existing summary networks. To learn the distribution over the global\nprototypes, we minimize its OT distance to the set empirical distribution over\ndata points, providing a natural unsupervised way to improve the summary\nnetwork. Since our plug-and-play framework can be applied to many meta-learning\nproblems, we further instantiate it to the cases of few-shot classification and\nimplicit meta generative modeling. Extensive experiments demonstrate that our\nframework significantly improves the existing summary networks on learning more\npowerful summary statistics from sets and can be successfully integrated into\nmetric-based few-shot classification and generative modeling applications,\nproviding a promising tool for addressing set-input and meta-learning problems.",
    "descriptor": "",
    "authors": [
      "Dandan Guo",
      "Long Tian",
      "Minghe Zhang",
      "Mingyuan Zhou",
      "Hongyuan Zha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.09140"
  },
  {
    "id": "arXiv:2110.09142",
    "title": "Adaptive Tikhonov strategies for stochastic ensemble Kalman inversion",
    "abstract": "Ensemble Kalman inversion (EKI) is a derivative-free optimizer aimed at\nsolving inverse problems, taking motivation from the celebrated ensemble Kalman\nfilter. The purpose of this article is to consider the introduction of adaptive\nTikhonov strategies for EKI. This work builds upon Tikhonov EKI (TEKI) which\nwas proposed for a fixed regularization constant. By adaptively learning the\nregularization parameter, this procedure is known to improve the recovery of\nthe underlying unknown. For the analysis, we consider a continuous-time setting\nwhere we extend known results such as well-posdeness and convergence of various\nloss functions, but with the addition of noisy observations. Furthermore, we\nallow a time-varying noise and regularization covariance in our presented\nconvergence result which mimic adaptive regularization schemes. In turn we\npresent three adaptive regularization schemes, which are highlighted from both\nthe deterministic and Bayesian approaches for inverse problems, which include\nbilevel optimization, the MAP formulation and covariance learning. We\nnumerically test these schemes and the theory on linear and nonlinear partial\ndifferential equations, where they outperform the non-adaptive TEKI and EKI.",
    "descriptor": "",
    "authors": [
      "Simon Weissmann",
      "Neil K. Chada",
      "Claudia Schillings",
      "Xin T. Tong"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.09142"
  },
  {
    "id": "arXiv:2110.09144",
    "title": "SynCoLFinGer: Synthetic Contactless Fingerprint Generator",
    "abstract": "We present the first method for synthetic generation of contactless\nfingerprint images, referred to as SynCoLFinGer. To this end, the constituent\ncomponents of contactless fingerprint images regarding capturing, subject\ncharacteristics, and environmental influences are modeled and applied to a\nsynthetically generated ridge pattern using the SFinGe algorithm. The proposed\nmethod is able to generate different synthetic samples corresponding to a\nsingle finger and it can be parameterized to generate contactless fingerprint\nimages of various quality levels. The resemblance of the synthetically\ngenerated contactless fingerprints to real fingerprints is confirmed by\nevaluating biometric sample quality using an adapted NFIQ 2.0 algorithm and\nbiometric utility using a state-of-the-art contactless fingerprint recognition\nsystem.",
    "descriptor": "",
    "authors": [
      "Jannis Priesnitz",
      "Christian Rathgeb",
      "Nicolas Buchmann",
      "Christoph Busch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09144"
  },
  {
    "id": "arXiv:2110.09147",
    "title": "BEAMetrics: A Benchmark for Language Generation Evaluation Evaluation",
    "abstract": "Natural language processing (NLP) systems are increasingly trained to\ngenerate open-ended text rather than classifying between responses. This makes\nresearch on evaluation metrics for generated language -- functions that score\nsystem output given the context and/or human reference responses -- of critical\nimportance. However, different metrics have different strengths and biases, and\nreflect human intuitions better on some tasks than others. There is currently\nno simple, unified way to compare, analyse or evaluate metrics across a\nrepresentative set of tasks. Here, we describe the Benchmark to Evaluate\nAutomatic Metrics (BEAMetrics), a resource to make research into new metrics\nitself easier to evaluate. BEAMetrics users can quickly compare existing and\nnew metrics with human judgements across a diverse set of tasks, quality\ndimensions (fluency vs. coherence vs. informativeness etc), and languages. As\ngeneration experts might predict, BEAMetrics reveals stark task-dependent\ndifferences between existing metrics, and consistently poor performance on\ntasks with complex answer spaces or high reliance on general knowledge. While\nthis analysis highlights a critical issue facing current research practice,\nBEAMetrics also contribute to its resolution by facilitating research into\nbetter metrics -- particularly those that can account for the complex\ninteraction between context and general knowledge inherent to many modern NLP\napplications. BEAMetrics is available under the MIT License:\nhttps://github.com/ThomasScialom/BEAMetrics",
    "descriptor": "",
    "authors": [
      "Thomas Scialom",
      "Felix Hill"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09147"
  },
  {
    "id": "arXiv:2110.09151",
    "title": "How to Effectively Identify and Communicate Person-Targeting Media Bias  in Daily News Consumption?",
    "abstract": "Slanted news coverage strongly affects public opinion. This is especially\ntrue for coverage on politics and related issues, where studies have shown that\nbias in the news may influence elections and other collective decisions. Due to\nits viable importance, news coverage has long been studied in the social\nsciences, resulting in comprehensive models to describe it and effective yet\ncostly methods to analyze it, such as content analysis. We present an\nin-progress system for news recommendation that is the first to automate the\nmanual procedure of content analysis to reveal person-targeting biases in news\narticles reporting on policy issues. In a large-scale user study, we find very\npromising results regarding this interdisciplinary research direction. Our\nrecommender detects and reveals substantial frames that are actually present in\nindividual news articles. In contrast, prior work rather only facilitates the\nvisibility of biases, e.g., by distinguishing left- and right-wing outlets.\nFurther, our study shows that recommending news articles that differently frame\nan event significantly improves respondents' awareness of bias.",
    "descriptor": "",
    "authors": [
      "Felix Hamborg",
      "Timo Spinde",
      "Kim Heinser",
      "Karsten Donnay",
      "Bela Gipp"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.09151"
  },
  {
    "id": "arXiv:2110.09152",
    "title": "Lifting DecPOMDPs for Nanoscale Systems -- A Work in Progress",
    "abstract": "DNA-based nanonetworks have a wide range of promising use cases, especially\nin the field of medicine. With a large set of agents, a partially observable\nstochastic environment, and noisy observations, such nanoscale systems can be\nmodelled as a decentralised, partially observable, Markov decision process\n(DecPOMDP). As the agent set is a dominating factor, this paper presents (i)\nlifted DecPOMDPs, partitioning the agent set into sets of indistinguishable\nagents, reducing the worst-case space required, and (ii) a nanoscale medical\nsystem as an application. Future work turns to solving and implementing lifted\nDecPOMDPs.",
    "descriptor": "\nComments: Accepted at the Tenth International Workshop on Statistical Relational AI (StarAI-2021)\n",
    "authors": [
      "Tanya Braun",
      "Stefan Fischer",
      "Florian Lau",
      "Ralf M\u00f6ller"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09152"
  },
  {
    "id": "arXiv:2110.09153",
    "title": "Probabilistic Inference in Planning for Partially Observable Long  Horizon Problems",
    "abstract": "For autonomous service robots to successfully perform long horizon tasks in\nthe real world, they must act intelligently in partially observable\nenvironments. Most Task and Motion Planning approaches assume full\nobservability of their state space, making them ineffective in stochastic and\npartially observable domains that reflect the uncertainties in the real world.\nWe propose an online planning and execution approach for performing long\nhorizon tasks in partially observable domains. Given the robot's belief and a\nplan skeleton composed of symbolic actions, our approach grounds each symbolic\naction by inferring continuous action parameters needed to execute the plan\nsuccessfully. To achieve this, we formulate the problem of joint inference of\naction parameters as a Hybrid Constraint Satisfaction Problem (H-CSP) and solve\nthe H-CSP using Belief Propagation. The robot executes the resulting\nparameterized actions, updates its belief of the world and replans when\nnecessary. Our approach is able to efficiently solve partially observable tasks\nin a realistic kitchen simulation environment. Our approach outperformed an\nadaptation of the state-of-the-art method across our experiments.",
    "descriptor": "\nComments: International Conference on Intelligent Robots and Systems (IROS), 2021\n",
    "authors": [
      "Alphonsus Adu-Bredu",
      "Nikhil Devraj",
      "Pin-Han Lin",
      "Zhen Zeng",
      "Odest Chadwicke Jenkins"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.09153"
  },
  {
    "id": "arXiv:2110.09154",
    "title": "Measuring the influence of beliefs in belief networks",
    "abstract": "Influential beliefs are crucial for our understanding of how people reason\nabout political issues and make political decisions. This research proposes a\nnew method for measuring the influence of political beliefs within larger\ncontext of belief system networks, based on the advances in psychometric\nnetwork methods and network influence research. Using the latest round of the\nEuropean Social Survey data, we demonstrate this approach on a belief network\nexpressing support for the regime in 29 European countries and capturing\nbeliefs related to support for regime performance, principles, institutions,\nand political actors. Our results show that the average influence of beliefs\ncan be related to the consistency and connectivity of the belief network and\nthat the influence of specific beliefs (e.g. Satisfaction with Democracy) on a\ncountry level has a significant negative correlation with external indicators\nfrom the same domain (e.g. Liberal Democracy index), which suggests that highly\ninfluential beliefs are related to pressing political issues. These findings\nsuggest that network-based belief influence metrics estimated from large-scale\nsurvey data can be used a new type of indicator in comparative political\nresearch, which opens new avenues for integrating psychometric network analysis\nmethods into political science methodology.",
    "descriptor": "\nComments: 19 pages, 4 figures. Earlier version of this work was presented at Networks 2021 conference\n",
    "authors": [
      "Aleksandar Toma\u0161evi\u0107"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.09154"
  },
  {
    "id": "arXiv:2110.09155",
    "title": "A dynamic mode decomposition extension for the forecasting of parametric  dynamical systems",
    "abstract": "Dynamic mode decomposition (DMD) has recently become a popular tool for the\nnon-intrusive analysis of dynamical systems. Exploiting the proper orthogonal\ndecomposition as dimensionality reduction technique, DMD is able to approximate\na dynamical system as a sum of (spatial) basis evolving linearly in time,\nallowing for a better understanding of the physical phenomena or for a future\nforecasting.\nWe propose in this contribution an extension of the DMD to parametrized\ndynamical systems, focusing on the future forecasting of the output of interest\nin a parametric context. Initially, all the snapshots -- for different\nparameters and different time instants -- are projected to the reduced space,\nemploying the DMD (or one of its variants) to approximate the reduced snapshots\nfor a future instants. Still exploiting the low dimension of the reduced space,\nthe predicted reduced snapshots are then combined using a regression technique,\nenabling the possibility to approximate any untested parametric configuration\nin any future instant.\nWe are going to present here the algorithmic core of the aforementioned\nmethod, presenting at the end three different test cases with incremental\ncomplexity: a simple dynamical system with a linear parameter dependency, a\nheat problem with nonlinear parameter dependency and a fluid dynamics problem\nwith nonlinear parameter dependency.",
    "descriptor": "",
    "authors": [
      "Francesco Andreuzzi",
      "Nicola Demo",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.09155"
  },
  {
    "id": "arXiv:2110.09156",
    "title": "Enhancing exploration algorithms for navigation with visual SLAM",
    "abstract": "Exploration is an important step in autonomous navigation of robotic systems.\nIn this paper we introduce a series of enhancements for exploration algorithms\nin order to use them with vision-based simultaneous localization and mapping\n(vSLAM) methods. We evaluate developed approaches in photo-realistic simulator\nin two modes: with ground-truth depths and neural network reconstructed depth\nmaps as vSLAM input. We evaluate standard metrics in order to estimate\nexploration coverage.",
    "descriptor": "\nComments: Camera-ready version as submitted to RNCAI 2021 conference\n",
    "authors": [
      "Kirill Muravyev",
      "Andrey Bokovoy",
      "Konstantin Yakovlev"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.09156"
  },
  {
    "id": "arXiv:2110.09157",
    "title": "Disentangled Representation with Dual-stage Feature Learning for Face  Anti-spoofing",
    "abstract": "As face recognition is widely used in diverse security-critical applications,\nthe study of face anti-spoofing (FAS) has attracted more and more attention.\nSeveral FAS methods have achieved promising performances if the attack types in\nthe testing data are the same as training data, while the performance\nsignificantly degrades for unseen attack types. It is essential to learn more\ngeneralized and discriminative features to prevent overfitting to pre-defined\nspoof attack types. This paper proposes a novel dual-stage disentangled\nrepresentation learning method that can efficiently untangle spoof-related\nfeatures from irrelevant ones. Unlike previous FAS disentanglement works with\none-stage architecture, we found that the dual-stage training design can\nimprove the training stability and effectively encode the features to detect\nunseen attack types. Our experiments show that the proposed method provides\nsuperior accuracy than the state-of-the-art methods on several cross-type FAS\nbenchmarks.",
    "descriptor": "\nComments: WACV 2022\n",
    "authors": [
      "Yu-Chun Wang",
      "Chien-Yi Wang",
      "Shang-Hong Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09157"
  },
  {
    "id": "arXiv:2110.09158",
    "title": "Newsalyze: Effective Communication of Person-Targeting Biases in News  Articles",
    "abstract": "Media bias and its extreme form, fake news, can decisively affect public\nopinion. Especially when reporting on policy issues, slanted news coverage may\nstrongly influence societal decisions, e.g., in democratic elections. Our paper\nmakes three contributions to address this issue. First, we present a system for\nbias identification, which combines state-of-the-art methods from natural\nlanguage understanding. Second, we devise bias-sensitive visualizations to\ncommunicate bias in news articles to non-expert news consumers. Third, our main\ncontribution is a large-scale user study that measures bias-awareness in a\nsetting that approximates daily news consumption, e.g., we present respondents\nwith a news overview and individual articles. We not only measure the\nvisualizations' effect on respondents' bias-awareness, but we can also pinpoint\nthe effects on individual components of the visualizations by employing a\nconjoint design. Our bias-sensitive overviews strongly and significantly\nincrease bias-awareness in respondents. Our study further suggests that our\ncontent-driven identification method detects groups of similarly slanted news\narticles due to substantial biases present in individual news articles. In\ncontrast, the reviewed prior work rather only facilitates the visibility of\nbiases, e.g., by distinguishing left- and right-wing outlets.",
    "descriptor": "",
    "authors": [
      "Felix Hamborg",
      "Kim Heinser",
      "Anastasia Zhukova",
      "Karsten Donnay",
      "Bela Gipp"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.09158"
  },
  {
    "id": "arXiv:2110.09160",
    "title": "DE-RSTC: A rational secure two-party computation protocol based on  direction entropy",
    "abstract": "Rational secure multi-party computation (RSMC) means two or more rational\nparties to complete a function on private inputs. In the process, the rational\nparties choose strategies to maximize utility, which will cause players to\nmaliciously execute the protocol and undermine the fairness and correctness of\nthe protocol. To solve this problem, we leverage game theory to propose the\ndirection entropy-based solution. First, we utilize the direction vector of the\ndirection entropy to examine the player's strategy uncertainty and quantify its\nstrategy from different dimensions. Specifically, when parties choose a\ncooperation strategy, the direction vector is positive, and the information\ntransmitted is positive, conversely, it is negative information. Then, we\nprovide mutual information to construct new utility functions for the players.\nWhat's more, we measure the mutual information of players to appraise their\nstrategies. Finally, we prove in detail the protocol we gave, and the result\nshow that the fairness problem in rational secure two-party computation. We\nalso prove that the proposed protocol reaches the Nash equilibrium.\nFurthermore, we conduct experiments using mutual information to construct\nutility, and the results show that the utility obtained when the player is\nhonest will be higher.",
    "descriptor": "",
    "authors": [
      "Juan Ma",
      "Yuling Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.09160"
  },
  {
    "id": "arXiv:2110.09161",
    "title": "Machine Covering in the Random-Order Model",
    "abstract": "In the Online Machine Covering problem jobs, defined by their sizes, arrive\none by one and have to be assigned to $m$ parallel and identical machines, with\nthe goal of maximizing the load of the least-loaded machine. In this work, we\nstudy the Machine Covering problem in the recently popular random-order model.\nHere no extra resources are present, but instead the adversary is weakened in\nthat it can only decide upon the input set while jobs are revealed uniformly at\nrandom. It is particularly relevant to Machine Covering where lower bounds are\nusually associated to highly structured input sequences.\nWe first analyze Graham's Greedy-strategy in this context and establish that\nits competitive ratio decreases slightly to\n$\\Theta\\left(\\frac{m}{\\log(m)}\\right)$ which is asymptotically tight. Then, as\nour main result, we present an improved $\\tilde{O}(\\sqrt[4]{m})$-competitive\nalgorithm for the problem. This result is achieved by exploiting the extra\ninformation coming from the random order of the jobs, using sampling techniques\nto devise an improved mechanism to distinguish jobs that are relatively large\nfrom small ones. We complement this result with a first lower bound showing\nthat no algorithm can have a competitive ratio of\n$O\\left(\\frac{\\log(m)}{\\log\\log(m)}\\right)$ in the random-order model. This\nlower bound is achieved by studying a novel variant of the Secretary problem,\nwhich could be of independent interest.",
    "descriptor": "",
    "authors": [
      "Susanne Albers",
      "Waldo G\u00e1lvez",
      "Maximilian Janke"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.09161"
  },
  {
    "id": "arXiv:2110.09162",
    "title": "Investigating Man-in-the-Middle-based False Data Injection in a Smart  Grid Laboratory Environment",
    "abstract": "With the increasing use of information and communication technology in\nelectrical power grids, the security of energy supply is increasingly\nthreatened by cyber-attacks. Traditional cyber-security measures, such as\nfirewalls or intrusion detection/prevention systems, can be used as mitigation\nand prevention measures, but their effective use requires a deep understanding\nof the potential threat landscape and complex attack processes in energy\ninformation systems. Given the complexity and lack of detailed knowledge of\ncoordinated, timed attacks in smart grid applications, we need information and\ninsight into realistic attack scenarios in an appropriate and practical\nsetting. In this paper, we present a man-in-the-middle-based attack scenario\nthat intercepts process communication between control systems and field\ndevices, employs false data injection techniques, and performs data corruption\nsuch as sending false commands to field devices. We demonstrate the\napplicability of the presented attack scenario in a physical smart grid\nlaboratory environment and analyze the generated data under normal and attack\nconditions to extract domain-specific knowledge for detection mechanisms.",
    "descriptor": "\nComments: To be published in Proceedings of 2021 IEEE PES Innovative Smart Grid Technologies Europe (ISGT-Europe)\n",
    "authors": [
      "\u00d6mer Sen",
      "Dennis van der Velde",
      "Philipp Linnartz",
      "Immanuel Hacker",
      "Martin Henze",
      "Michael Andres",
      "Andreas Ulbig"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.09162"
  },
  {
    "id": "arXiv:2110.09163",
    "title": "A Dimensionality Reduction Approach for Convolutional Neural Networks",
    "abstract": "The focus of this paper is the application of classical model order reduction\ntechniques, such as Active Subspaces and Proper Orthogonal Decomposition, to\nDeep Neural Networks. We propose a generic methodology to reduce the number of\nlayers of a pre-trained network by combining the aforementioned techniques for\ndimensionality reduction with input-output mappings, such as Polynomial Chaos\nExpansion and Feedforward Neural Networks. The necessity of compressing the\narchitecture of an existing Convolutional Neural Network is motivated by its\napplication in embedded systems with specific storage constraints. Our\nexperiment shows that the reduced nets obtained can achieve a level of accuracy\nsimilar to the original Convolutional Neural Network under examination, while\nsaving in memory allocation.",
    "descriptor": "",
    "authors": [
      "Laura Meneghetti",
      "Nicola Demo",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.09163"
  },
  {
    "id": "arXiv:2110.09164",
    "title": "Speeding-Up Back-Propagation in DNN: Approximate Outer Product with  Memory",
    "abstract": "In this paper, an algorithm for approximate evaluation of back-propagation in\nDNN training is considered, which we term Approximate Outer Product Gradient\nDescent with Memory (Mem-AOP-GD). The Mem-AOP-GD algorithm implements an\napproximation of the stochastic gradient descent by considering only a subset\nof the outer products involved in the matrix multiplications that encompass\nbackpropagation. In order to correct for the inherent bias in this\napproximation, the algorithm retains in memory an accumulation of the outer\nproducts that are not used in the approximation. We investigate the performance\nof the proposed algorithm in terms of DNN training loss under two design\nparameters: (i) the number of outer products used for the approximation, and\n(ii) the policy used to select such outer products. We experimentally show that\nsignificant improvements in computational complexity as well as accuracy can\nindeed be obtained through Mem-AOPGD.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Eduin E. Hernandez",
      "Stefano Rini",
      "Tolga M. Duman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09164"
  },
  {
    "id": "arXiv:2110.09166",
    "title": "Branch Predicting with Sparse Distributed Memories",
    "abstract": "Modern processors rely heavily on speculation to keep the pipeline filled and\nconsequently execute and commit instructions as close to maximum capacity as\npossible. To improve instruction-level parallelism, the processor core needs to\nfetch and decode multiple instructions per cycle and has come to rely on\nincredibly accurate branch prediction. However, this comes at cost of the\nincreased area and complexity which is needed for modern high accuracy branch\npredictors.\nThe key idea described in this work is to use hyperdimensional computing and\nsparse distributed memory principles to create a novel branch predictor that\ncan deliver complex predictions for a fraction of the current area. Sparse\ndistributed memories can store vast amounts of data in a compressed manner,\ntheoretically enabling branch histories larger and more precise than the branch\npredictors used today to be stored with equal or smaller area footprint.\nFurthermore, as all the data is in a hashed format and due to the nature of the\nhashing scheme used, it is inherently harder to manipulate with known\nside-channel attacks.\nWe describe our proof-of-concept and evaluate it against a state-of-the-art\nacademic TAGE predictor. Our experiments are conducted on realistic synthetic\nbranch predictor patterns and the Championship Branch Prediction traces and\nshow competitive accuracy. Finally, we describe techniques that can be used to\nsolve some of the challenges of processing with hyperdimensional vectors in\norder to deliver timely predictions.",
    "descriptor": "",
    "authors": [
      "Ilias Vougioukas",
      "Andreas Sandberg",
      "Nikos Nikoleris"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2110.09166"
  },
  {
    "id": "arXiv:2110.09168",
    "title": "Domain Generalisation for Apparent Emotional Facial Expression  Recognition across Age-Groups",
    "abstract": "Apparent emotional facial expression recognition has attracted a lot of\nresearch attention recently. However, the majority of approaches ignore age\ndifferences and train a generic model for all ages. In this work, we study the\neffect of using different age-groups for training apparent emotional facial\nexpression recognition models. To this end, we study Domain Generalisation in\nthe context of apparent emotional facial expression recognition from facial\nimagery across different age groups. We first compare several domain\ngeneralisation algorithms on the basis of out-of-domain-generalisation, and\nobserve that the Class-Conditional Domain-Adversarial Neural Networks (CDANN)\nalgorithm has the best performance. We then study the effect of variety and\nnumber of age-groups used during training on generalisation to unseen\nage-groups and observe that an increase in the number of training age-groups\ntends to increase the apparent emotional facial expression recognition\nperformance on unseen age-groups. We also show that exclusion of an age-group\nduring training tends to affect more the performance of the neighbouring age\ngroups.",
    "descriptor": "",
    "authors": [
      "Rafael Poyiadzi",
      "Jie Shen",
      "Stavros Petridis",
      "Yujiang Wang",
      "Maja Pantic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09168"
  },
  {
    "id": "arXiv:2110.09170",
    "title": "Continuation of Famous Art with AI: A Conditional Adversarial Network  Inpainting Approach",
    "abstract": "Much of the state-of-the-art in image synthesis inspired by real artwork are\neither entirely generative by filtered random noise or inspired by the transfer\nof style. This work explores the application of image inpainting to continue\nfamous artworks and produce generative art with a Conditional GAN. During the\ntraining stage of the process, the borders of images are cropped, leaving only\nthe centre. An inpainting GAN is then tasked with learning to reconstruct the\noriginal image from the centre crop by way of minimising both adversarial and\nabsolute difference losses. Once the network is trained, images are then\nresized rather than cropped and presented as input to the generator. Following\nthe learning process, the generator then creates new images by continuing from\nthe edges of the original piece. Three experiments are performed with datasets\nof 4766 landscape paintings (impressionism and romanticism), 1167 Ukiyo-e works\nfrom the Japanese Edo period, and 4968 abstract artworks. Results show that\ngeometry and texture (including canvas and paint) as well as scenery such as\nsky, clouds, water, land (including hills and mountains), grass, and flowers\nare implemented by the generator when extending real artworks. In the Ukiyo-e\nexperiments, it was observed that features such as written text were generated\neven in cases where the original image did not have any, due to the presence of\nan unpainted border within the input image.",
    "descriptor": "",
    "authors": [
      "Jordan J. Bird"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.09170"
  },
  {
    "id": "arXiv:2110.09171",
    "title": "Projected Model Counting: Beyond Independent Support",
    "abstract": "The past decade has witnessed a surge of interest in practical techniques for\nprojected model counting. Despite significant advancements, however,\nperformance scaling remains the Achilles' heel of this field. A key idea used\nin modern counters is to count models projected on an \\emph{independent\nsupport} that is often a small subset of the projection set, i.e. original set\nof variables on which we wanted to project. While this idea has been effective\nin scaling performance, the question of whether it can benefit to count models\nprojected on variables beyond the projection set, has not been explored. In\nthis paper, we study this question and show that contrary to intuition, it can\nbe beneficial to project on variables beyond the projection set. In\napplications such as verification of binarized neural networks, quantification\nof information flow, reliability of power grids etc., a good upper bound of the\nprojected model count often suffices. We show that in several such cases, we\ncan identify a set of variables, called upper bound support (UBS), that is not\nnecessarily a subset of the projection set, and yet counting models projected\non UBS guarantees an upper bound of the true projected model count.\nTheoretically, a UBS can be exponentially smaller than the smallest independent\nsupport. Our experiments show that even otherwise, UBS-based projected counting\ncan be more efficient than independent support-based projected counting, while\nyielding bounds of very high quality. Based on extensive experiments, we find\nthat UBS-based projected counting can solve many problem instances that are\nbeyond the reach of a state-of-the-art independent support-based projected\nmodel counter.",
    "descriptor": "",
    "authors": [
      "Jiong Yang",
      "Supratik Chakraborty",
      "Kuldeep S. Meel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.09171"
  },
  {
    "id": "arXiv:2110.09172",
    "title": "A unified framework for walking and running of bipedal robots",
    "abstract": "In this paper, we propose a novel framework capable of generating various\nwalking and running gaits for bipedal robots. The main goal is to relax the\nfixed center of mass (CoM) height assumption of the linear inverted pendulum\nmodel (LIPM) and generate a wider range of walking and running motions, without\na considerable increase in complexity. To do so, we use the concept of virtual\nconstraints in the centroidal space which enables generating motions beyond\nwalking while keeping the complexity at a minimum. By a proper choice of these\nvirtual constraints, we show that we can generate different types of walking\nand running motions. More importantly, enforcing the virtual constraints\nthrough feedback renders the dynamics linear and enables us to design a\nfeedback control mechanism which adapts the next step location and timing in\nface of disturbances, through a simple quadratic program (QP). To show the\neffectiveness of this framework, we showcase different walking and running\nsimulations of the biped robot Bolt in the presence of both environmental\nuncertainties and external disturbances.",
    "descriptor": "",
    "authors": [
      "Mahrokh Ghoddousi Boroujeni",
      "Elham Daneshmand",
      "Ludovic Righetti",
      "Majid Khadiv"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.09172"
  },
  {
    "id": "arXiv:2110.09174",
    "title": "A Formalisation of Abstract Argumentation in Higher-Order Logic",
    "abstract": "We present an approach for representing abstract argumentation frameworks\nbased on an encoding into classical higher-order logic. This provides a uniform\nframework for computer-assisted assessment of abstract argumentation frameworks\nusing interactive and automated reasoning tools. This enables the formal\nanalysis and verification of meta-theoretical properties as well as the\nflexible generation of extensions and labellings with respect to well-known\nargumentation semantics.",
    "descriptor": "\nComments: 33 pages, 8 figures; submitted article\n",
    "authors": [
      "Alexander Steen",
      "David Fuenmayor"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.09174"
  },
  {
    "id": "arXiv:2110.09179",
    "title": "Analysis of French Phonetic Idiosyncrasies for Accent Recognition",
    "abstract": "Speech recognition systems have made tremendous progress since the last few\ndecades. They have developed significantly in identifying the speech of the\nspeaker. However, there is a scope of improvement in speech recognition systems\nin identifying the nuances and accents of a speaker. It is known that any\nspecific natural language may possess at least one accent. Despite the\nidentical word phonemic composition, if it is pronounced in different accents,\nwe will have sound waves, which are different from each other. Differences in\npronunciation, in accent and intonation of speech in general, create one of the\nmost common problems of speech recognition. If there are a lot of accents in\nlanguage we should create the acoustic model for each separately. We carry out\na systematic analysis of the problem in the accurate classification of accents.\nWe use traditional machine learning techniques and convolutional neural\nnetworks, and show that the classical techniques are not sufficiently efficient\nto solve this problem. Using spectrograms of speech signals, we propose a\nmulti-class classification framework for accent recognition. In this paper, we\nfocus our attention on the French accent. We also identify its limitation by\nunderstanding the impact of French idiosyncrasies on its spectrograms.",
    "descriptor": "\nComments: Accepted in Soft Computing Letters, 2021\n",
    "authors": [
      "Pierre Berjon",
      "Avishek Nag",
      "Soumyabrata Dev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.09179"
  },
  {
    "id": "arXiv:2110.09181",
    "title": "Derived terms without derivation a shifted perspective on the  derived-term automaton",
    "abstract": "We present here a construction for the derived term automaton (aka partial\nderivative, or Antimirov, automaton) of a rational (or regular) expression\nbased on a sole induction on the depth of the expression and without making\nreference to an operation of derivation of the expression. It is particularly\nwell-suited to the case of weighted rational expressions.",
    "descriptor": "",
    "authors": [
      "Sylvain Lombardy",
      "Jacques Sakarovitch"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.09181"
  },
  {
    "id": "arXiv:2110.09182",
    "title": "Graph Partner Neural Networks for Semi-Supervised Learning on Graphs",
    "abstract": "Graph Convolutional Networks (GCNs) are powerful for processing\ngraph-structured data and have achieved state-of-the-art performance in several\ntasks such as node classification, link prediction, and graph classification.\nHowever, it is inevitable for deep GCNs to suffer from an over-smoothing issue\nthat the representations of nodes will tend to be indistinguishable after\nrepeated graph convolution operations. To address this problem, we propose the\nGraph Partner Neural Network (GPNN) which incorporates a de-parameterized GCN\nand a parameter-sharing MLP. We provide empirical and theoretical evidence to\ndemonstrate the effectiveness of the proposed MLP partner on tackling\nover-smoothing while benefiting from appropriate smoothness. To further tackle\nover-smoothing and regulate the learning process, we introduce a well-designed\nconsistency contrastive loss and KL divergence loss. Besides, we present a\ngraph enhancement technique to improve the overall quality of edges in graphs.\nWhile most GCNs can work with shallow architecture only, GPNN can obtain better\nresults through increasing model depth. Experiments on various node\nclassification tasks have demonstrated the state-of-the-art performance of\nGPNN. Meanwhile, extensive ablation studies are conducted to investigate the\ncontributions of each component in tackling over-smoothing and improving\nperformance.",
    "descriptor": "",
    "authors": [
      "Langzhang Liang",
      "Cuiyun Gao",
      "Shiyi Chen",
      "Shishi Duan",
      "Yu pan",
      "Junjin Zheng",
      "Lei Wang",
      "Zenglin Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09182"
  },
  {
    "id": "arXiv:2110.09183",
    "title": "Building a Smart EM Environment -- AI-Enhanced Aperiodic Micro-Scale  Design of Passive EM Skins",
    "abstract": "An innovative process for the design of static passive smart skins (SPSSs) is\nproposed to take into account, within the synthesis, the electromagnetic (EM)\ninteractions due to their finite (macro-level) size and aperiodic (micro-scale)\nlayouts. Such an approach leverages on the combination of an inverse source\n(IS) formulation, to define the SPSS surface currents, and of an instance of\nthe System-by-Design paradigm, to synthesize the unit cell (UC) descriptors\nsuitable for supporting these currents. As for this latter step, an enhanced\nArtificial Intelligence (IA)-based digital twin (DT) is built to efficiently\nand reliably predict the relationships among the UCs and the non-uniform\ncoupling effects arising when the UCs are irregularly assembled to build the\ncorresponding SPSS. Towards this end and unlike state-of-the-art approaches, an\naperiodic finite small-scale model of the SPSS is derived to generate the\ntraining database for the DT implementation. A set of representative numerical\nexperiments, dealing with different radiation objectives and smart skin\napertures, is reported to assess the reliability of the conceived design\nprocess and to illustrate the radiation features of the resulting layouts,\nvalidated with accurate full-wave simulations, as well.",
    "descriptor": "",
    "authors": [
      "Giacomo Oliveri",
      "Francesco Zardi",
      "Paolo Rocca",
      "Marco Salucci",
      "Andrea Massa"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.09183"
  },
  {
    "id": "arXiv:2110.09188",
    "title": "Ride Sharing & Data Privacy: An Analysis of the State of Practice",
    "abstract": "Digital services like ride sharing rely heavily on personal data as\nindividuals have to disclose personal information in order to gain access to\nthe market and exchange their information with other participants; yet, the\nservice provider usually gives little to no information regarding the privacy\nstatus of the disclosed information though privacy concerns are a decisive\nfactor for individuals to (not) use these services. We analyzed how popular\nride sharing services handle user privacy to assess the current state of\npractice. The results show that services include a varying set of personal data\nand offer limited privacy-related features.",
    "descriptor": "",
    "authors": [
      "Carsten Hesselmann",
      "Jan Gertheiss",
      "J\u00f6rg P. M\u00fcller"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.09188"
  },
  {
    "id": "arXiv:2110.09191",
    "title": "Electric Vehicle Automatic Charging System Based on Vision-force Fusion",
    "abstract": "Electric vehicles are an emerging means of transportation with environmental\nfriendliness. The automatic charging is a hot topic in this field that is full\nof challenges. We introduce a complete automatic charging system based on\nvision-force fusion, which includes perception, planning and control for robot\nmanipulations of the system. We design the whole system in simulation and\ntransfer it to the real world. The experimental results prove the effectiveness\nof our system.",
    "descriptor": "",
    "authors": [
      "Dashun Guo",
      "Liang Xie",
      "Hongxiang Yu",
      "Yue Wang",
      "Rong Xiong"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.09191"
  },
  {
    "id": "arXiv:2110.09192",
    "title": "Learning Optimal Conformal Classifiers",
    "abstract": "Modern deep learning based classifiers show very high accuracy on test data\nbut this does not provide sufficient guarantees for safe deployment, especially\nin high-stake AI applications such as medical diagnosis. Usually, predictions\nare obtained without a reliable uncertainty estimate or a formal guarantee.\nConformal prediction (CP) addresses these issues by using the classifier's\nprobability estimates to predict confidence sets containing the true class with\na user-specified probability. However, using CP as a separate processing step\nafter training prevents the underlying model from adapting to the prediction of\nconfidence sets. Thus, this paper explores strategies to differentiate through\nCP during training with the goal of training model with the conformal wrapper\nend-to-end. In our approach, conformal training (ConfTr), we specifically\n\"simulate\" conformalization on mini-batches during training. We show that CT\noutperforms state-of-the-art CP methods for classification by reducing the\naverage confidence set size (inefficiency). Moreover, it allows to \"shape\" the\nconfidence sets predicted at test time, which is difficult for standard CP. On\nexperiments with several datasets, we show ConfTr can influence how\ninefficiency is distributed across classes, or guide the composition of\nconfidence sets in terms of the included classes, while retaining the\nguarantees offered by CP.",
    "descriptor": "",
    "authors": [
      "David Stutz",
      "Krishnamurthy",
      "Dvijotham",
      "Ali Taylan Cemgil",
      "Arnaud Doucet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.09192"
  },
  {
    "id": "arXiv:2110.09193",
    "title": "Topologically Regularized Data Embeddings",
    "abstract": "Unsupervised feature learning often finds low-dimensional embeddings that\ncapture the structure of complex data. For tasks for which expert prior\ntopological knowledge is available, incorporating this into the learned\nrepresentation may lead to higher quality embeddings. For example, this may\nhelp one to embed the data into a given number of clusters, or to accommodate\nfor noise that prevents one from deriving the distribution of the data over the\nmodel directly, which can then be learned more effectively. However, a general\ntool for integrating different prior topological knowledge into embeddings is\nlacking. Although differentiable topology layers have been recently developed\nthat can (re)shape embeddings into prespecified topological models, they have\ntwo important limitations for representation learning, which we address in this\npaper. First, the currently suggested topological losses fail to represent\nsimple models such as clusters and flares in a natural manner. Second, these\nlosses neglect all original structural (such as neighborhood) information in\nthe data that is useful for learning. We overcome these limitations by\nintroducing a new set of topological losses, and proposing their usage as a way\nfor topologically regularizing data embeddings to naturally represent a\nprespecified model. We include thorough experiments on synthetic and real data\nthat highlight the usefulness and versatility of this approach, with\napplications ranging from modeling high-dimensional single cell data, to graph\nembedding.",
    "descriptor": "",
    "authors": [
      "Robin Vandaele",
      "Bo Kang",
      "Jefrey Lijffijt",
      "Tijl De Bie",
      "Yvan Saeys"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.09193"
  },
  {
    "id": "arXiv:2110.09195",
    "title": "Sub-bit Neural Networks: Learning to Compress and Accelerate Binary  Neural Networks",
    "abstract": "In the low-bit quantization field, training Binary Neural Networks (BNNs) is\nthe extreme solution to ease the deployment of deep models on\nresource-constrained devices, having the lowest storage cost and significantly\ncheaper bit-wise operations compared to 32-bit floating-point counterparts. In\nthis paper, we introduce Sub-bit Neural Networks (SNNs), a new type of binary\nquantization design tailored to compress and accelerate BNNs. SNNs are inspired\nby an empirical observation, showing that binary kernels learnt at\nconvolutional layers of a BNN model are likely to be distributed over kernel\nsubsets. As a result, unlike existing methods that binarize weights one by one,\nSNNs are trained with a kernel-aware optimization framework, which exploits\nbinary quantization in the fine-grained convolutional kernel space.\nSpecifically, our method includes a random sampling step generating\nlayer-specific subsets of the kernel space, and a refinement step learning to\nadjust these subsets of binary kernels via optimization. Experiments on visual\nrecognition benchmarks and the hardware deployment on FPGA validate the great\npotentials of SNNs. For instance, on ImageNet, SNNs of ResNet-18/ResNet-34 with\n0.56-bit weights achieve 3.13/3.33 times runtime speed-up and 1.8 times\ncompression over conventional BNNs with moderate drops in recognition accuracy.\nPromising results are also obtained when applying SNNs to binarize both weights\nand activations. Our code is available at https://github.com/yikaiw/SNN.",
    "descriptor": "\nComments: ICCV 2021. Code and models: this https URL\n",
    "authors": [
      "Yikai Wang",
      "Yi Yang",
      "Fuchun Sun",
      "Anbang Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09195"
  },
  {
    "id": "arXiv:2110.09196",
    "title": "MDP Abstraction with Successor Features",
    "abstract": "Abstraction plays an important role for generalisation of knowledge and\nskills, and is key to sample efficient learning and planning. For many complex\nproblems an abstract plan can be formed first, which is then instantiated by\nfilling in the necessary low-level details. Often, such abstract plans\ngeneralize well to related new problems. We study abstraction in the context of\nreinforcement learning, in which agents may perform state or temporal\nabstractions. Temporal abstractions aka options represent temporally-extended\nactions in the form of option policies. However, typically acquired option\npolicies cannot be directly transferred to new environments due to changes in\nthe state space or transition dynamics. Furthermore, many existing state\nabstraction schemes ignore the correlation between state and temporal\nabstraction. In this work, we propose successor abstraction, a novel\nabstraction scheme building on successor features. This includes an algorithm\nfor encoding and instantiation of abstract options across different\nenvironments, and a state abstraction mechanism based on the abstract options.\nOur successor abstraction allows us to learn abstract environment models with\nsemantics that are transferable across different environments through encoding\nand instantiation of abstract options. Empirically, we achieve better transfer\nand improved performance on a set of benchmark tasks as compared to relevant\nstate of the art baselines.",
    "descriptor": "",
    "authors": [
      "Dongge Han",
      "Michael Wooldridge",
      "Sebastian Tschiatschek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09196"
  },
  {
    "id": "arXiv:2110.09197",
    "title": "On the Completness and Complexity of the Lifted Dynamic Junction Tree  Algorithm",
    "abstract": "Lifted inference allows to perform inference in polynomial time w.r.t. domain\nsizes. For a lifted algorithm, completeness investigates model classes for\nwhich the algorithm is guaranteed to compute a lifted solution. We contribute,\nto the best of our knowledge, the first completeness and complexity analysis\nfor a temporal lifted algorithm, the so-called lifted dynamic junction tree\nalgorithm (LDJT). To treat time as a first class citizen, LDJT introduces some\nconstraints. Given these constraints, we analyse the classes of liftable\nmodels. Further, we show that LDJT has many advantages from a complexity point\nof view compared to a propositional temporal inference algorithm w.r.t. domain\nsizes. Therefore, LDJT advances the number of models for which inference tasks\ncan be solved in reasonable time not only from a practically point of view, but\nalso from a theoretical point of view.",
    "descriptor": "\nComments: StaRAI 2021\n",
    "authors": [
      "Marcel Gehrke"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09197"
  },
  {
    "id": "arXiv:2110.09202",
    "title": "Finding Strong Gravitational Lenses Through Self-Attention",
    "abstract": "The upcoming large scale surveys are expected to find approximately $10^5$\nstrong gravitational systems by analyzing data of many orders of magnitude than\nthe current era. In this scenario, non-automated techniques will be highly\nchallenging and time-consuming. We propose a new automated architecture based\non the principle of self-attention to find strong gravitational lensing. The\nadvantages of self-attention based encoder models over convolution neural\nnetworks are investigated and encoder models are analyzed to optimize\nperformance. We constructed 21 self-attention based encoder models and four\nconvolution neural networks trained to identify gravitational lenses from the\nBologna Lens Challenge. Each model is trained separately using 18,000 simulated\nimages, cross-validated using 2 000 images, and then applied to a test set with\n100 000 images. We used four different metrics for evaluation: classification\naccuracy, the area under the receiver operating characteristic curve (AUROC),\nthe $TPR_0$ score and the $TPR_{10}$ score. The performance of the\nself-attention based encoder models and CNN's participated in the challenge are\ncompared. The encoder models performed better than the CNNs and surpassed the\nCNN models that participated in the bologna lens challenge by a high margin for\nthe $TPR_0$ and $TPR_{10}$. In terms of the AUROC, the encoder models scored\nequivalent to the top CNN model by only using one-sixth parameters to that of\nthe CNN. Self-Attention based models have a clear advantage compared to simpler\nCNNs. A low computational cost and complexity make it a highly competing\narchitecture to currently used residual neural networks. Moreover, introducing\nthe encoder layers can also tackle the over-fitting problem present in the\nCNN's by acting as effective filters.",
    "descriptor": "\nComments: 11 Pages, 4 tables and 10 Figures\n",
    "authors": [
      "Hareesh Thuruthipilly",
      "Adam Zadrozny",
      "Agnieszka Pollo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)"
    ],
    "url": "https://arxiv.org/abs/2110.09202"
  },
  {
    "id": "arXiv:2110.09207",
    "title": "SPON: Enabling Resilient Inter-Ledgers Payments with an  Intrusion-Tolerant Overlay",
    "abstract": "Payment systems are a critical component of everyday life in our society.\nWhile in many situations payments are still slow, opaque, siloed, expensive or\neven fail, users expect them to be fast, transparent, cheap, reliable and\nglobal. Recent technologies such as distributed ledgers create opportunities\nfor near-real-time, cheaper and more transparent payments. However, in order to\nachieve a global payment system, payments should be possible not only within\none ledger, but also across different ledgers and geographies. In this paper we\npropose Secure Payments with Overlay Networks (SPON), a service that enables\nglobal payments across multiple ledgers by combining the transaction exchange\nprovided by the Interledger protocol with an intrusion-tolerant overlay of\nrelay nodes to achieve (1) improved payment latency, (2) fault tolerance to\nbenign failures such as node failures and network partitions, and (3)\nresilience to BGP hijacking attacks. We discuss the design goals and present an\nimplementation based on the Interledger protocol and Spines overlay network. We\nanalyze the resilience of SPON and demonstrate through experimental evaluation\nthat it is able to improve payment latency, recover from path outages,\nwithstand network partition attacks, and disseminate payments fairly across\nmultiple ledgers. We also show how SPON can be deployed to make the\ncommunication between different ledgers resilient to BGP hijacking attacks.",
    "descriptor": "\nComments: 9 pages, 14 figures, IEEE Conference on Communications and Network Security October 2021\n",
    "authors": [
      "Lucian Trestioreanu",
      "Cristina Nita-Rotaru",
      "Aanchal Malhotra",
      "Radu State"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.09207"
  },
  {
    "id": "arXiv:2110.09208",
    "title": "Correlation-based Discovery of Disease Patterns for Syndromic  Surveillance",
    "abstract": "Early outbreak detection is a key aspect in the containment of infectious\ndiseases, as it enables the identification and isolation of infected\nindividuals before the disease can spread to a larger population. Instead of\ndetecting unexpected increases of infections by monitoring confirmed cases,\nsyndromic surveillance aims at the detection of cases with early symptoms,\nwhich allows a more timely disclosure of outbreaks. However, the definition of\nthese disease patterns is often challenging, as early symptoms are usually\nshared among many diseases and a particular disease can have several clinical\npictures in the early phase of an infection. To support epidemiologists in the\nprocess of defining reliable disease patterns, we present a novel, data-driven\napproach to discover such patterns in historic data. The key idea is to take\ninto account the correlation between indicators in a health-related data source\nand the reported number of infections in the respective geographic region. In\nan experimental evaluation, we use data from several emergency departments to\ndiscover disease patterns for three infectious diseases. Our results suggest\nthat the proposed approach is able to find patterns that correlate with the\nreported infections and often identifies indicators that are related to the\nrespective diseases.",
    "descriptor": "",
    "authors": [
      "Michael Rapp",
      "Moritz Kulessa",
      "Eneldo Loza Menc\u00eda",
      "Johannes F\u00fcrnkranz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09208"
  },
  {
    "id": "arXiv:2110.09212",
    "title": "Noise-Resilient Ensemble Learning using Evidence Accumulation Clustering",
    "abstract": "Ensemble Learning methods combine multiple algorithms performing the same\ntask to build a group with superior quality. These systems are well adapted to\nthe distributed setup, where each peer or machine of the network hosts one\nalgorithm and communicate its results to its peers. Ensemble learning methods\nare naturally resilient to the absence of several peers thanks to the ensemble\nredundancy. However, the network can be corrupted, altering the prediction\naccuracy of a peer, which has a deleterious effect on the ensemble quality. In\nthis paper, we propose a noise-resilient ensemble classification method, which\nhelps to improve accuracy and correct random errors. The approach is inspired\nby Evidence Accumulation Clustering , adapted to classification ensembles. We\ncompared it to the naive voter model over four multi-class datasets. Our model\nshowed a greater resilience, allowing us to recover prediction under a very\nhigh noise level. In addition as the method is based on the evidence\naccumulation clustering, our method is highly flexible as it can combines\nclassifiers with different label definitions.",
    "descriptor": "\nComments: 12 pages, submitted and accepted to ANTIC-2021 (International Conference on Advanced Network Technologies and Intelligent Computing)\n",
    "authors": [
      "Ga\u00eblle Candel",
      "David Naccache"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09212"
  },
  {
    "id": "arXiv:2110.09215",
    "title": "A Primer on the Statistical Relation between Wireless Ultra-Reliability  and Location Estimation",
    "abstract": "This letter statistically characterizes the impact of location estimation\nuncertainty in the wireless communication reliability, in which location\ninformation is used as a proxy to choose the rate. First, a Cram\\'er-Rao bound\nfor the localization error is derived. Then, through a simplified setup, we\nshow that the reliability - characterized by how likely the outage probability\nis to be above a target threshold - can be sensitive to location errors,\nespecially when the channel statistics are also sensitive to the location.\nFinally, we highlight the difficulty of choosing a rate that both meets target\nreliability and accounts for the location uncertainty, and that the most direct\nsolutions suffer from being too conservative.",
    "descriptor": "\nComments: 5 pages and 4 figures. Has been submitted in IEEE Wireless Communication Letters\n",
    "authors": [
      "Tobias Kallehauge",
      "Pablo Ram\u00edrez-Espinosa",
      "Kimmo Kansanen",
      "Henk Wymeersch",
      "Petar Popovski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.09215"
  },
  {
    "id": "arXiv:2110.09216",
    "title": "The Arabic Parallel Gender Corpus 2.0: Extensions and Analyses",
    "abstract": "Gender bias in natural language processing (NLP) applications, particularly\nmachine translation, has been receiving increasing attention. Much of the\nresearch on this issue has focused on mitigating gender bias in English NLP\nmodels and systems. Addressing the problem in poorly resourced, and/or\nmorphologically rich languages has lagged behind, largely due to the lack of\ndatasets and resources. In this paper, we introduce a new corpus for gender\nidentification and rewriting in contexts involving one or two target users (I\nand/or You) -- first and second grammatical persons with independent\ngrammatical gender preferences. We focus on Arabic, a gender-marking\nmorphologically rich language. The corpus has multiple parallel components:\nfour combinations of 1st and 2nd person in feminine and masculine grammatical\ngenders, as well as English, and English to Arabic machine translation output.\nThis corpus expands on Habash et al. (2019)'s Arabic Parallel Gender Corpus\n(APGC v1.0) by adding second person targets as well as increasing the total\nnumber of sentences over 6.5 times, reaching over 590K words. Our new dataset\nwill aid the research and development of gender identification, controlled text\ngeneration, and post-editing rewrite systems that could be used to personalize\nNLP applications and provide users with the correct outputs based on their\ngrammatical gender preferences. We make the Arabic Parallel Gender Corpus (APGC\nv2.0) publicly available.",
    "descriptor": "",
    "authors": [
      "Bashar Alhafni",
      "Nizar Habash",
      "Houda Bouamor"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.09216"
  },
  {
    "id": "arXiv:2110.09217",
    "title": "Color Image Segmentation Using Multi-Objective Swarm Optimizer and  Multi-level Histogram Thresholding",
    "abstract": "Rapid developments in swarm intelligence optimizers and computer processing\nabilities make opportunities to design more accurate, stable, and comprehensive\nmethods for color image segmentation. This paper presents a new way for\nunsupervised image segmentation by combining histogram thresholding methods\n(Kapur's entropy and Otsu's method) and different multi-objective swarm\nintelligence algorithms (MOPSO, MOGWO, MSSA, and MOALO) to thresholding 3D\nhistogram of a color image. More precisely, this method first combines the\nobjective function of traditional thresholding algorithms to design\ncomprehensive objective functions then uses multi-objective optimizers to find\nthe best thresholds during the optimization of designed objective functions.\nAlso, our method uses a vector objective function in 3D space that could\nsimultaneously handle the segmentation of entire image color channels with the\nsame thresholds. To optimize this vector objective function, we employ\nmultiobjective swarm optimizers that can optimize multiple objective functions\nat the same time. Therefore, our method considers dependencies between channels\nto find the thresholds that satisfy objective functions of color channels\n(which we name as vector objective function) simultaneously. Segmenting entire\ncolor channels with the same thresholds also benefits from the fact that our\nproposed method needs fewer thresholds to segment the image than other\nthresholding algorithms; thus, it requires less memory space to save\nthresholds. It helps a lot when we want to segment many images to many regions.\nThe subjective and objective results show the superiority of this method to\ntraditional thresholding methods that separately threshold histograms of a\ncolor image.",
    "descriptor": "\nComments: 11 pages, 6 figures\n",
    "authors": [
      "Mohammadreza Naderi Boldaji",
      "Samaneh Hosseini Semnani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.09217"
  },
  {
    "id": "arXiv:2110.09218",
    "title": "Neural-network learning of SPOD latent dynamics",
    "abstract": "We aim to reconstruct the latent space dynamics of high dimensional systems\nusing model order reduction via the spectral proper orthogonal decomposition\n(SPOD). The proposed method is based on three fundamental steps: in the first,\nwe compress the data from a high-dimensional representation to a lower\ndimensional one by constructing the SPOD latent space; in the second, we build\nthe time-dependent coefficients by projecting the realizations (also referred\nto as snapshots) onto the reduced SPOD basis and we learn their evolution in\ntime with the aid of recurrent neural networks; in the third, we reconstruct\nthe high-dimensional data from the learnt lower-dimensional representation. The\nproposed method is demonstrated on two different test cases, namely, a\ncompressible jet flow, and a geophysical problem known as the Madden-Julian\nOscillation. An extensive comparison between SPOD and the equivalent POD-based\ncounterpart is provided and differences between the two approaches are\nhighlighted. The numerical results suggest that the proposed model is able to\nprovide low rank predictions of complex statistically stationary data and to\nprovide insights into the evolution of phenomena characterized by specific\nrange of frequencies. The comparison between POD and SPOD surrogate strategies\nhighlights the need for further work on the characterization of the error\ninterplay between data reduction techniques and neural network forecasts.",
    "descriptor": "\nComments: 25 pages, 17 figures, 4 tables\n",
    "authors": [
      "Andrea Lario",
      "Romit Maulik",
      "Gianluigi Rozza",
      "Gianmarco Mengaldo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.09218"
  },
  {
    "id": "arXiv:2110.09220",
    "title": "Structured vector fitting framework for mechanical systems",
    "abstract": "In this paper, we develop a structure-preserving formulation of the\ndata-driven vector fitting algorithm for the case of modally damped mechanical\nsystems. Using the structured pole-residue form of the transfer function of\nmodally damped second-order systems, we propose two possible structured\nextensions of the barycentric formula of system transfer functions. Integrating\nthese new forms within the classical vector fitting algorithm leads to the\nformulation of two new algorithms that allow the computation of modally damped\nmechanical systems from data in a least squares fashion. Thus, the learned\nmodel is guaranteed to have the desired structure. We test the proposed\nalgorithms on two benchmark models.",
    "descriptor": "\nComments: 8 pages, 2 figures\n",
    "authors": [
      "Steffen W. R. Werner",
      "Ion Victor Gosea",
      "Serkan Gugercin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.09220"
  },
  {
    "id": "arXiv:2110.09221",
    "title": "A Serverless Distributed Ledger for Enterprises",
    "abstract": "Enterprises have been attracted by the capability of blockchains to provide a\nsingle source of truth for workloads that span companies, geographies, and\nclouds while retaining the independence of each party's IT operations. However,\nso far production applications have remained rare, stymied by technical\nlimitations of existing blockchain technologies and challenges with their\nintegration into enterprises' IT systems. In this paper, we collect\nenterprises' requirements on distributed ledgers for data sharing and\nintegration from a technical perspective, argue that they are not sufficiently\naddressed by available blockchain frameworks, and propose a novel distributed\nledger design that is \"serverless\", i.e., built on cloud-native resources. We\nevaluate its qualitative and quantitative properties and give evidence that\nenterprises already heavily reliant on cloud service providers would consider\nsuch an approach acceptable, particularly if it offers ease of deployment, low\ntransactional cost structure, and a combination of latency and scalability\naligned with real-time IT application needs.",
    "descriptor": "\nComments: This paper has been accepted at the 55th Hawaii International Conference on System Sciences (HICSS) and will be published in January 2022\n",
    "authors": [
      "Johannes Sedlmeir",
      "Tim Wagner",
      "Emil Djerekarov",
      "Ryan Green",
      "Johannes Klepsch",
      "Shruthi Rao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.09221"
  },
  {
    "id": "arXiv:2110.09223",
    "title": "Learning Models for Query by Vocal Percussion: A Comparative Study",
    "abstract": "The imitation of percussive sounds via the human voice is a natural and\neffective tool for communicating rhythmic ideas on the fly. Thus, the automatic\nretrieval of drum sounds using vocal percussion can help artists prototype drum\npatterns in a comfortable and quick way, smoothing the creative workflow as a\nresult. Here we explore different strategies to perform this type of query,\nmaking use of both traditional machine learning algorithms and recent deep\nlearning techniques. The main hyperparameters from the models involved are\ncarefully selected by feeding performance metrics to a grid search algorithm.\nWe also look into several audio data augmentation techniques, which can\npotentially regularise deep learning models and improve generalisation. We\ncompare the final performances in terms of effectiveness (classification\naccuracy), efficiency (computational speed), stability (performance\nconsistency), and interpretability (decision patterns), and discuss the\nrelevance of these results when it comes to the design of successful\nquery-by-vocal-percussion systems.",
    "descriptor": "\nComments: Published in proceedings of the International Computer Music Conference (ICMC) 2021\n",
    "authors": [
      "Alejandro Delgado",
      "SkoT McDonald",
      "Ning Xu",
      "Charalampos Saitis",
      "Mark Sandler"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.09223"
  },
  {
    "id": "arXiv:2110.09225",
    "title": "Starlink : A Solution to the Digital Connectivity Divide in Education in  the Global South",
    "abstract": "Digital connectivity gap in the global south hampered the education of\nmillions of school children during the COVID-19 pandemic. If not actions are\ntaken to remedy this problem, future prospects of millions of children around\nwill be bleak. This paper explores the feasibility of using the SpaceX Starlink\nsatellite constellation as a means to alleviate the problem of the digital\nconnectivity divide in the global south. First, the paper discusses the issues\nof digital connectivity in education in rural Sri Lanka and other countries in\nthe global south. Then, the paper gives an introduction to Starlink broadband\ninternet technology and discusses its advantages over traditional technologies.\nAfter that, the paper discusses a possible mechanism of adopting Starlink\ntechnology as a solution to the rural digital connectivity problem in the\nglobal south. Technological, as well as economical aspects of such scheme, are\ndiscussed. Finally, challenges that may arise in deploying a system such as\nStarlink to improve rural digital connectivity in Sri Lanka or any another\ncountry in the global south will be discussed with possible remedies.",
    "descriptor": "\nComments: 11 pages, 3 figures, 1 table\n",
    "authors": [
      "H.M.V.R. Herath"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.09225"
  },
  {
    "id": "arXiv:2110.09226",
    "title": "Governance and Communication of Algorithmic Decision Making: A Case  Study on Public Sector",
    "abstract": "Algorithmic Decision Making (ADM) has permeated all aspects of society.\nGovernment organizations are also affected by this trend. However, the use of\nADM has been getting negative attention from the public, media, and interest\ngroups. There is little to no actionable guidelines for government\norganizations to create positive impact through ADM. In this case study, we\nexamined eight municipal organizations in the Netherlands regarding their\nactual and intended use of ADM. We interviewed key personnel and decision\nmakers. Our results show that municipalities mostly use ADM in an ad hoc\nmanner, and they have not systematically defined or institutionalized a data\nscience process yet. They operate risk averse, and they clearly express the\nneed for cooperation, guidance, and even supervision at the national level.\nThird parties, mostly commercial, are often involved in the ADM development\nlifecycle, without systematic governance. Communication on the use of ADM is\ngenerally responsive to negative attention from the media and public. There are\nstrong indications for the need of an ADM governance framework. In this paper,\nwe present our findings in detail, along with actionable insights on\ngovernance, communication, and performance evaluation of ADM systems.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Erik Jonk",
      "Deniz Iren"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09226"
  },
  {
    "id": "arXiv:2110.09228",
    "title": "Random Formula Generators",
    "abstract": "In this article, we provide three generators of propositional formulae for\narbitrary languages, which uniformly sample three different formulae spaces.\nThey take the same three parameters as input, namely, a desired depth, a set of\natomics and a set of logical constants (with specified arities). The first\ngenerator returns formulae of exactly the given depth, using all or some of the\npropositional letters. The second does the same but samples up-to the given\ndepth. The third generator outputs formulae with exactly the desired depth and\nall the atomics in the set. To make the generators uniform (i.e. to make them\nreturn every formula in their space with the same probability), we will prove\nvarious cardinality results about those spaces.",
    "descriptor": "",
    "authors": [
      "Ariel J. Roffe",
      "Joaquin S. Toranzo Calderon"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.09228"
  },
  {
    "id": "arXiv:2110.09229",
    "title": "Computing eigenfunctions of the multidimensional Ornstein-Uhlenbeck  operator",
    "abstract": "We discuss approaches to computing eigenfunctions of the Ornstein--Uhlenbeck\n(OU) operator in more than two dimensions. While the spectrum of the OU\noperator and theoretical properties of its eigenfunctions have been well\ncharacterized in previous research, the practical computation of general\neigenfunctions has not been resolved. We review special cases for which the\neigenfunctions can be expressed exactly in terms of commonly used orthogonal\npolynomials. Then we present a tractable approach for computing the\neigenfunctions in general cases and comment on its dimension dependence.",
    "descriptor": "",
    "authors": [
      "Benjamin J. Zhang",
      "Tuhin Sahai",
      "Youssef M. Marzouk"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2110.09229"
  },
  {
    "id": "arXiv:2110.09231",
    "title": "Machine Learning Featurizations for AI Hacking of Political Systems",
    "abstract": "What would the inputs be to a machine whose output is the destabilization of\na robust democracy, or whose emanations could disrupt the political power of\nnations? In the recent essay \"The Coming AI Hackers,\" Schneier (2021) proposed\na future application of artificial intelligences to discover, manipulate, and\nexploit vulnerabilities of social, economic, and political systems at speeds\nfar greater than humans' ability to recognize and respond to such threats. This\nwork advances the concept by applying to it theory from machine learning,\nhypothesizing some possible \"featurization\" (input specification and\ntransformation) frameworks for AI hacking. Focusing on the political domain, we\ndevelop graph and sequence data representations that would enable the\napplication of a range of deep learning models to predict attributes and\noutcomes of political systems. We explore possible data models, datasets,\npredictive tasks, and actionable applications associated with each framework.\nWe speculate about the likely practical impact and feasibility of such models,\nand conclude by discussing their ethical implications.",
    "descriptor": "\nComments: 19 pages, 2 figures\n",
    "authors": [
      "Nathan E Sanders",
      "Bruce Schneier"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09231"
  },
  {
    "id": "arXiv:2110.09232",
    "title": "Accountability in AI: From Principles to Industry-specific Accreditation",
    "abstract": "Recent AI-related scandals have shed a spotlight on accountability in AI,\nwith increasing public interest and concern. This paper draws on literature\nfrom public policy and governance to make two contributions. First, we propose\nan AI accountability ecosystem as a useful lens on the system, with different\nstakeholders requiring and contributing to specific accountability mechanisms.\nWe argue that the present ecosystem is unbalanced, with a need for improved\ntransparency via AI explainability and adequate documentation and process\nformalisation to support internal audit, leading up eventually to external\naccreditation processes. Second, we use a case study in the gambling sector to\nillustrate in a subset of the overall ecosystem the need for industry-specific\naccountability principles and processes. We define and evaluate critically the\nimplementation of key accountability principles in the gambling industry,\nnamely addressing algorithmic bias and model explainability, before concluding\nand discussing directions for future work based on our findings. Keywords:\nAccountability, Explainable AI, Algorithmic Bias, Regulation.",
    "descriptor": "\nComments: 24 pages, 2 figures, 2 tables\n",
    "authors": [
      "Chris Percy",
      "Simo Dragicevic",
      "Sanjoy Sarkar",
      "Artur S. d'Avila Garcez"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09232"
  },
  {
    "id": "arXiv:2110.09234",
    "title": "Impact of COVID-19 Policies and Misinformation on Social Unrest",
    "abstract": "The novel coronavirus disease (COVID-19) pandemic has impacted every corner\nof earth, disrupting governments and leading to socioeconomic instability. This\ncrisis has prompted questions surrounding how different sectors of society\ninteract and influence each other during times of change and stress. Given the\nunprecedented economic and societal impacts of this pandemic, many new data\nsources have become available, allowing us to quantitatively explore these\nassociations. Understanding these relationships can help us better prepare for\nfuture disasters and mitigate the impacts. Here, we focus on the interplay\nbetween social unrest (protests), health outcomes, public health orders, and\nmisinformation in eight countries of Western Europe and four regions of the\nUnited States. We created 1-3 week forecasts of both a binary protest metric\nfor identifying times of high protest activity and the overall protest counts\nover time. We found that for all regions, except Belgium, at least one feature\nfrom our various data streams was predictive of protests. However, the accuracy\nof the protest forecasts varied by country, that is, for roughly half of the\ncountries analyzed, our forecasts outperform a na\\\"ive model. These mixed\nresults demonstrate the potential of diverse data streams to predict a topic as\nvolatile as protests as well as the difficulties of predicting a situation that\nis as rapidly evolving as a pandemic.",
    "descriptor": "\nComments: 21 pages, 9 figures\n",
    "authors": [
      "Martha Barnard",
      "Radhika Iyer",
      "Sara Y. Del Valle",
      "Ashlynn R. Daughton"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.09234"
  },
  {
    "id": "arXiv:2110.09236",
    "title": "Model-Based Reinforcement Learning Framework of Online Network Resource  Allocation",
    "abstract": "Online Network Resource Allocation (ONRA) for service provisioning is a\nfundamental problem in communication networks. As a sequential decision-making\nunder uncertainty problem, it is promising to approach ONRA via Reinforcement\nLearning (RL). But, RL solutions suffer from the sample complexity issue; i.e.,\na large number of interactions with the environment needed to find an efficient\npolicy. This is a barrier to utilize RL for ONRA as on one hand, it is not\npractical to train the RL agent offline due to lack of information about future\nrequests, and on the other hand, online training in the real network leads to\nsignificant performance loss because of the sub-optimal policy during the\nprolonged learning time. This performance degradation is even higher in\nnon-stationary ONRA where the agent should continually adapt the policy with\nthe changes in service requests. To deal with this issue, we develop a general\nresource allocation framework, named RADAR, using model-based RL for a class of\nONRA problems with the known immediate reward of each action. RADAR improves\nsample efficiency via exploring the state space in the background and\nexploiting the policy in the decision-time using synthetic samples by the model\nof the environment, which is trained by real interactions. Applying RADAR on\nthe multi-domain service federation problem, to maximize profit via selecting\nproper domains for service requests deployment, shows its continual learning\ncapability and up to 44% performance improvement w.r.t. the standard model-free\nRL solution.",
    "descriptor": "\nComments: This is the version of the paper submitted to ICC 2022\n",
    "authors": [
      "Bahador Bakhshi",
      "Josep Mangues-Bafalluy"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.09236"
  },
  {
    "id": "arXiv:2110.09237",
    "title": "Designing Anonymity",
    "abstract": "Creating anonymity means cutting connections. A common goal in this context\nis to prevent accountability. This prevention of accountability can be\nproblematic, for example, if it leads to delinquents remaining undetected.\nHowever, imputability can also provide protection against discrimination. In\nmedical, religious or legal matters, this is of fundamental importance. Thus,\nwhen individuals actively establish anonymity, they do so mostly because they\nwant to prevent certain information about them, that is, sensitive and/or\ncompromising information, from being associated with their identities. By\nremaining inaccessible as individuals with respect to certain information about\nthem, they can engage in forms of exchange that would otherwise be impossible\nfor them. Examples include practices of exchange in (self-organized) therapy\ngroups, acting out stigmatized sexual preferences, the role of anonymity in the\nperforming arts, or political resistance movements. Given the variety of\nexamples in which personal anonymity is important, it is not surprising that it\nis primarily these personal dimensions that are the focus of current debates\nabout the increasing precariousness of anonymity in the face of new technical\npossibilities of data mining and processing. In this paper, we nevertheless -\nor precisely because of this - want to focus on another aspect of anonymity\nthat has received much less attention so far. Namely, we assume that\nresearching and working with and about anonymity can open up new perspectives\non and for contemporary forms of knowledge production.",
    "descriptor": "\nComments: 4 pages, in German, journal article, Helm, P. 2021. Designing Anonymity. Hamburger Journal fuer Kulturanthropologie, 13. Abgerufen von this https URL\n",
    "authors": [
      "Paula Helm"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.09237"
  },
  {
    "id": "arXiv:2110.09238",
    "title": "Foundations for the Future: Institution building for the purpose of  Artificial Intelligence governance",
    "abstract": "Governance efforts for artificial intelligence (AI) are taking on\nincreasingly more concrete forms, drawing on a variety of approaches and\ninstruments from hard regulation to standardisation efforts, aimed at\nmitigating challenges from high-risk AI systems. To implement these and other\nefforts, new institutions will need to be established on a national and\ninternational level. This paper sketches a blueprint of such institutions, and\nconducts in-depth investigations of three key components of any future AI\ngovernance institutions, exploring benefits and associated drawbacks: (1)\npurpose, relating to the institution's overall goals and scope of work or\nmandate; (2) geography, relating to questions of participation and the reach of\njurisdiction; and (3) capacity, the infrastructural and human make-up of the\ninstitution. Subsequently, the paper highlights noteworthy aspects of various\ninstitutional roles specifically around questions of institutional purpose, and\nframes what these could look like in practice, by placing these debates in a\nEuropean context and proposing different iterations of a European AI Agency.\nFinally, conclusions and future research directions are proposed.",
    "descriptor": "",
    "authors": [
      "Charlotte Stix"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.09238"
  },
  {
    "id": "arXiv:2110.09239",
    "title": "EIHW-MTG: Second DiCOVA Challenge System Report",
    "abstract": "This work presents an outer product-based approach to fuse the embedded\nrepresentations generated from the spectrograms of cough, breath, and speech\nsamples for the automatic detection of COVID-19. To extract deep learnt\nrepresentations from the spectrograms, we compare the performance of a CNN\ntrained from scratch and a ResNet18 architecture fine-tuned for the task at\nhand. Furthermore, we investigate whether the patients' sex and the use of\ncontextual attention mechanisms is beneficial. Our experiments use the dataset\nreleased as part of the Second Diagnosing COVID-19 using Acoustics (DiCOVA)\nChallenge. The results suggest the suitability of fusing breath and speech\ninformation to detect COVID-19. An Area Under the Curve (AUC) of 84.06% is\nobtained on the test partition when using a CNN trained from scratch with\ncontextual attention mechanisms. When using the ResNet18 architecture for\nfeature extraction, the baseline model scores the highest performance with an\nAUC of 84.26%.",
    "descriptor": "",
    "authors": [
      "Adria Mallol-Ragolta",
      "Helena Cuesta",
      "Emilia G\u00f3mez",
      "Bj\u00f6rn W. Schuller"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.09239"
  },
  {
    "id": "arXiv:2110.09240",
    "title": "Value alignment: a formal approach",
    "abstract": "principles that should govern autonomous AI systems. It essentially states\nthat a system's goals and behaviour should be aligned with human values. But\nhow to ensure value alignment? In this paper we first provide a formal model to\nrepresent values through preferences and ways to compute value aggregations;\ni.e. preferences with respect to a group of agents and/or preferences with\nrespect to sets of values. Value alignment is then defined, and computed, for a\ngiven norm with respect to a given value through the increase/decrease that it\nresults in the preferences of future states of the world. We focus on norms as\nit is norms that govern behaviour, and as such, the alignment of a given system\nwith a given value will be dictated by the norms the system follows.",
    "descriptor": "\nComments: accepted paper at the Responsible Artificial Intelligence Agents Workshop, of the 18th International Conference on Autonomous Agents and MultiAgent Systems (AAMAS 2019)\n",
    "authors": [
      "Carles Sierra",
      "Nardine Osman",
      "Pablo Noriega",
      "Jordi Sabater-Mir",
      "Antoni Perell\u00f3"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09240"
  },
  {
    "id": "arXiv:2110.09241",
    "title": "Video Coding for Machine: Compact Visual Representation Compression for  Intelligent Collaborative Analytics",
    "abstract": "Video Coding for Machines (VCM) is committed to bridging to an extent\nseparate research tracks of video/image compression and feature compression,\nand attempts to optimize compactness and efficiency jointly from a unified\nperspective of high accuracy machine vision and full fidelity human vision. In\nthis paper, we summarize VCM methodology and philosophy based on existing\nacademia and industrial efforts. The development of VCM follows a general\nrate-distortion optimization, and the categorization of key modules or\ntechniques is established. From previous works, it is demonstrated that,\nalthough existing works attempt to reveal the nature of scalable representation\nin bits when dealing with machine and human vision tasks, there remains a rare\nstudy in the generality of low bit rate representation, and accordingly how to\nsupport a variety of visual analytic tasks. Therefore, we investigate a novel\nvisual information compression for the analytics taxonomy problem to strengthen\nthe capability of compact visual representations extracted from multiple tasks\nfor visual analytics. A new perspective of task relationships versus\ncompression is revisited. By keeping in mind the transferability among\ndifferent machine vision tasks (e.g. high-level semantic and mid-level\ngeometry-related), we aim to support multiple tasks jointly at low bit rates.\nIn particular, to narrow the dimensionality gap between neural network\ngenerated features extracted from pixels and a variety of machine vision\nfeatures/labels (e.g. scene class, segmentation labels), a codebook hyperprior\nis designed to compress the neural network-generated features. As demonstrated\nin our experiments, this new hyperprior model is expected to improve feature\ncompression efficiency by estimating the signal entropy more accurately, which\nenables further investigation of the granularity of abstracting compact\nfeatures among different tasks.",
    "descriptor": "\nComments: The first three authors had equal contribution. arXiv admin note: text overlap with arXiv:2106.08512\n",
    "authors": [
      "Wenhan Yang",
      "Haofeng Huang",
      "Yueyu Hu",
      "Ling-Yu Duan",
      "Jiaying Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09241"
  },
  {
    "id": "arXiv:2110.09243",
    "title": "Leveraging MoCap Data for Human Mesh Recovery",
    "abstract": "Training state-of-the-art models for human body pose and shape recovery from\nimages or videos requires datasets with corresponding annotations that are\nreally hard and expensive to obtain. Our goal in this paper is to study whether\nposes from 3D Motion Capture (MoCap) data can be used to improve image-based\nand video-based human mesh recovery methods. We find that fine-tune image-based\nmodels with synthetic renderings from MoCap data can increase their\nperformance, by providing them with a wider variety of poses, textures and\nbackgrounds. In fact, we show that simply fine-tuning the batch normalization\nlayers of the model is enough to achieve large gains. We further study the use\nof MoCap data for video, and introduce PoseBERT, a transformer module that\ndirectly regresses the pose parameters and is trained via masked modeling. It\nis simple, generic and can be plugged on top of any state-of-the-art\nimage-based model in order to transform it in a video-based model leveraging\ntemporal information. Our experimental results show that the proposed\napproaches reach state-of-the-art performance on various datasets including\n3DPW, MPI-INF-3DHP, MuPoTS-3D, MCB and AIST. Test code and models will be\navailable soon.",
    "descriptor": "\nComments: 3DV 2021\n",
    "authors": [
      "Fabien Baradel",
      "Thibault Groueix",
      "Philippe Weinzaepfel",
      "Romain Br\u00e9gier",
      "Yannis Kalantidis",
      "Gr\u00e9gory Rogez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09243"
  },
  {
    "id": "arXiv:2110.09244",
    "title": "The search of Type I codes",
    "abstract": "A self-dual binary linear code is called Type I code if it has singly-even\ncodewords, i.e.~it has codewords with weight divisible by $2.$ The purpose of\nthis paper is to investigate interesting properties of Type I codes of\ndifferent lengths. Further, we build up a computer-based code-searching program\nbased on our knowledge about Type I codes. Some computation results achieved by\nthis program are given.",
    "descriptor": "",
    "authors": [
      "Carolin Hannusch",
      "Roland S. Major"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2110.09244"
  },
  {
    "id": "arXiv:2110.09245",
    "title": "Efficient Sequence Training of Attention Models using Approximative  Recombination",
    "abstract": "Sequence discriminative training is a great tool to improve the performance\nof an automatic speech recognition system. It does, however, necessitate a sum\nover all possible word sequences, which is intractable to compute in practice.\nCurrent state-of-the-art systems with unlimited label context circumvent this\nproblem by limiting the summation to an n-best list of relevant competing\nhypotheses obtained from beam search.\nThis work proposes to perform (approximative) recombinations of hypotheses\nduring beam search, if they share a common local history. The error that is\nincurred by the approximation is analyzed and it is shown that using this\ntechnique the effective beam size can be increased by several orders of\nmagnitude without significantly increasing the computational requirements.\nLastly, it is shown that this technique can be used to effectively perform\nsequence discriminative training for attention-based encoder-decoder acoustic\nmodels on the LibriSpeech task.",
    "descriptor": "\nComments: submitted to ICASSP 2022\n",
    "authors": [
      "Nils-Philipp Wynands",
      "Wilfried Michel",
      "Jan Rosendahl",
      "Ralf Schl\u00fcter",
      "Hermann Ney"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.09245"
  },
  {
    "id": "arXiv:2110.09246",
    "title": "Single Layer Predictive Normalized Maximum Likelihood for  Out-of-Distribution Detection",
    "abstract": "Detecting out-of-distribution (OOD) samples is vital for developing machine\nlearning based models for critical safety systems. Common approaches for OOD\ndetection assume access to some OOD samples during training which may not be\navailable in a real-life scenario. Instead, we utilize the {\\em predictive\nnormalized maximum likelihood} (pNML) learner, in which no assumptions are made\non the tested input. We derive an explicit expression of the pNML and its\ngeneralization error, denoted as the {\\em regret}, for a single layer neural\nnetwork (NN). We show that this learner generalizes well when (i) the test\nvector resides in a subspace spanned by the eigenvectors associated with the\nlarge eigenvalues of the empirical correlation matrix of the training data, or\n(ii) the test sample is far from the decision boundary. Furthermore, we\ndescribe how to efficiently apply the derived pNML regret to any pretrained\ndeep NN, by employing the explicit pNML for the last layer, followed by the\nsoftmax function. Applying the derived regret to deep NN requires neither\nadditional tunable parameters nor extra data. We extensively evaluate our\napproach on 74 OOD detection benchmarks using DenseNet-100, ResNet-34, and\nWideResNet-40 models trained with CIFAR-100, CIFAR-10, SVHN, and ImageNet-30\nshowing a significant improvement of up to 15.6\\% over recent leading methods.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Koby Bibas",
      "Meir Feder",
      "Tal Hassner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09246"
  },
  {
    "id": "arXiv:2110.09247",
    "title": "Uncertainty-aware Topic Modeling Visualization",
    "abstract": "Topic modeling is a state-of-the-art technique for analyzing text corpora. It\nuses a statistical model, most commonly Latent Dirichlet Allocation (LDA), to\ndiscover abstract topics that occur in the document collection. However, the\nLDA-based topic modeling procedure is based on a randomly selected initial\nconfiguration as well as a number of parameter values than need to be chosen.\nThis induces uncertainties on the topic modeling results, and visualization\nmethods should convey these uncertainties during the analysis process. We\npropose a visual uncertainty-aware topic modeling analysis. We capture the\nuncertainty by computing topic modeling ensembles and propose measures for\nestimating topic modeling uncertainty from the ensemble. Then, we propose to\nenhance state-of-the-art topic modeling visualization methods to convey the\nuncertainty in the topic modeling process. We visualize the entire ensemble of\ntopic modeling results at different levels for topic and document analysis. We\napply our visualization methods to a text corpus to document the impact of\nuncertainty on the analysis.",
    "descriptor": "",
    "authors": [
      "Valerie M\u00fcller",
      "Christian Sieg",
      "Lars Linsen"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.09247"
  },
  {
    "id": "arXiv:2110.09248",
    "title": "Demographic Biases of Crowd Workers in Key Opinion Leaders Finding",
    "abstract": "Key Opinion Leaders (KOLs) are people that have a strong influence and their\nopinions are listened to by people when making important decisions.\nCrowdsourcing provides an efficient and cost-effective means to gather data for\nthe KOL finding task. However, data collected through crowdsourcing is affected\nby the inherent demographic biases of crowd workers. To avoid such demographic\nbiases, we need to measure how biased each crowd worker is. In this paper, we\npropose a simple yet effective approach based on demographic information of\ncandidate KOLs and their counterfactual value. We argue that it is\neffectiveness because of the extra information that we can consider together\nwith labeled data to curate a less biased dataset.",
    "descriptor": "\nComments: 3 pages, CSCW 2021 Workshop - Investigating and Mitigating Biases in Crowdsourced Data\n",
    "authors": [
      "Hossein A. Rahmani",
      "Jie Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.09248"
  },
  {
    "id": "arXiv:2110.09251",
    "title": "Predicting Indian Supreme Court Judgments, Decisions, Or Appeals",
    "abstract": "Legal predictive models are of enormous interest and value to legal\ncommunity. The stakeholders, specially, the judges and attorneys can take the\nbest advantages of these models to predict the case outcomes to further augment\ntheir future course of actions, for example speeding up the decision making,\nsupport the arguments, strengthening the defense, etc. However, accurately\npredicting the legal decisions and case outcomes is an arduous process, which\ninvolves several complex steps -- finding suitable bulk case documents, data\nextracting, cleansing and engineering, etc. Additionally, the legal complexity\nfurther adds to its intricacies. In this paper, we introduce our newly\ndeveloped ML-enabled legal prediction model and its operational prototype,\neLegPredict; which successfully predicts the Indian supreme court decisions.\nThe eLegPredict is trained and tested over 3072 supreme court cases and has\nachieved ~76% accuracy (F1-score). The eLegPredict is equipped with a mechanism\nto aid end users, where as soon as a document with new case description is\ndropped into a designated directory, the system quickly reads through its\ncontent and generates prediction. To our best understanding, eLegPredict is the\nfirst legal prediction model to predict Indian supreme court decisions.",
    "descriptor": "",
    "authors": [
      "Sugam Sharma",
      "Ritu Shandilya",
      "Swadesh Sharma"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.09251"
  },
  {
    "id": "arXiv:2110.09252",
    "title": "Exploring Individual and Collaborative Storytelling in an Introductory  Creative Coding Class",
    "abstract": "Teaching programming through storytelling is a popular pedagogical approach\nand an active area of research. However, most previous work in this area\nfocused on K-12 students using block-based programming. Little, if any, work\nhas examined the approach with university students using text-based\nprogramming. This experience report fills this gap. Specifically, we report our\nexperience administering three storytelling assignments -- two individual and\none collaborative -- in an introductory computer science class with 49\nundergraduate students using $\\textit{p5.js}$, a text-based programming library\nfor creative coding. Our work contributes an understanding of students'\nexperiences with the three authoring processes and a set of recommendations to\nimprove the administration of and experience with individual and collaborative\nstorytelling with text-based programming.",
    "descriptor": "",
    "authors": [
      "Sangho Suh",
      "Ken Jen Lee",
      "Celine Latulipe",
      "Jian Zhao",
      "Edith Law"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.09252"
  },
  {
    "id": "arXiv:2110.09253",
    "title": "A Sociotechnical View of Algorithmic Fairness",
    "abstract": "Algorithmic fairness has been framed as a newly emerging technology that\nmitigates systemic discrimination in automated decision-making, providing\nopportunities to improve fairness in information systems (IS). However, based\non a state-of-the-art literature review, we argue that fairness is an\ninherently social concept and that technologies for algorithmic fairness should\ntherefore be approached through a sociotechnical lens. We advance the discourse\non algorithmic fairness as a sociotechnical phenomenon. Our research objective\nis to embed AF in the sociotechnical view of IS. Specifically, we elaborate on\nwhy outcomes of a system that uses algorithmic means to assure fairness depends\non mutual influences between technical and social structures. This perspective\ncan generate new insights that integrate knowledge from both technical fields\nand social studies. Further, it spurs new directions for IS debates. We\ncontribute as follows: First, we problematize fundamental assumptions in the\ncurrent discourse on algorithmic fairness based on a systematic analysis of 310\narticles. Second, we respond to these assumptions by theorizing algorithmic\nfairness as a sociotechnical construct. Third, we propose directions for IS\nresearchers to enhance their impacts by pursuing a unique understanding of\nsociotechnical algorithmic fairness. We call for and undertake a holistic\napproach to AF. A sociotechnical perspective on algorithmic fairness can yield\nholistic solutions to systemic biases and discrimination.",
    "descriptor": "\nComments: Accepted at Information Systems Journal\n",
    "authors": [
      "Mateusz Dolata",
      "Stefan Feuerriegel",
      "Gerhard Schwabe"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.09253"
  },
  {
    "id": "arXiv:2110.09255",
    "title": "Towards responsible research in digital technology for health care",
    "abstract": "Digital technology is everywhere for the benefit of our daily and\nprofessional life. It strongly impacts our life and was crucial to maintain\nprofessional and social activities during the COVID19 crisis. Similarly,\ndigital technologies are key within biomedical engineering research topics.\nInnovations have been generated and introduced over the last 40 years,\ndemonstrating how computing and digital technologies have impacted health care.\nAlthough the benefits of digital technology are obvious now, we are at the\nconvergence of several issues which makes us aware about social, societal and\nenvironmental challenges associated with this technology. In the social domain,\ndigital technologies raise concern about exclusion (financial, geographical,\neducational, demographical, racial, gender, language, and disabled related\nexclusion) and physical and mental health. In the societal dimension, digital\ntechnologies raise concern about politics and democracy (sovereignty and\ngovernance, cognitive filters and citizen's engagement), privacy and security\n(data acquisition and usage transparency, level of personal approval, and level\nof anonymization), and economics. In the environmental dimension, digital\ntechnologies raise concern about energy consumption and hardware production.\nThis paper introduces and defines these challenges for digital technology in\ngeneral, as well as when applied to health care. The objective of this paper is\nto make the research community more aware about the challenges of digital\ntechnology and to promote more transparency for innovative and responsible\nresearch.",
    "descriptor": "\nComments: 16 pages, 1 table, 4 figures, 69 references\n",
    "authors": [
      "Pierre Jannin"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.09255"
  },
  {
    "id": "arXiv:2110.09260",
    "title": "A Unified Framework for Generalized Low-Shot Medical Image Segmentation  with Scarce Data",
    "abstract": "Medical image segmentation has achieved remarkable advancements using deep\nneural networks (DNNs). However, DNNs often need big amounts of data and\nannotations for training, both of which can be difficult and costly to obtain.\nIn this work, we propose a unified framework for generalized low-shot (one- and\nfew-shot) medical image segmentation based on distance metric learning (DML).\nUnlike most existing methods which only deal with the lack of annotations while\nassuming abundance of data, our framework works with extreme scarcity of both,\nwhich is ideal for rare diseases. Via DML, the framework learns a multimodal\nmixture representation for each category, and performs dense predictions based\non cosine distances between the pixels' deep embeddings and the category\nrepresentations. The multimodal representations effectively utilize the\ninter-subject similarities and intraclass variations to overcome overfitting\ndue to extremely limited data. In addition, we propose adaptive mixing\ncoefficients for the multimodal mixture distributions to adaptively emphasize\nthe modes better suited to the current input. The representations are\nimplicitly embedded as weights of the fc layer, such that the cosine distances\ncan be computed efficiently via forward propagation. In our experiments on\nbrain MRI and abdominal CT datasets, the proposed framework achieves superior\nperformances for low-shot segmentation towards standard DNN-based (3D U-Net)\nand classical registration-based (ANTs) methods, e.g., achieving mean Dice\ncoefficients of 81%/69% for brain tissue/abdominal multiorgan segmentation\nusing a single training sample, as compared to 52%/31% and 72%/35% by the U-Net\nand ANTs, respectively.",
    "descriptor": "\nComments: Published in IEEE TRANSACTIONS ON MEDICAL IMAGING\n",
    "authors": [
      "Hengji Cui",
      "Dong Wei",
      "Kai Ma",
      "Shi Gu",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09260"
  },
  {
    "id": "arXiv:2110.09264",
    "title": "Intent Classification Using Pre-Trained Embeddings For Low Resource  Languages",
    "abstract": "Building Spoken Language Understanding (SLU) systems that do not rely on\nlanguage specific Automatic Speech Recognition (ASR) is an important yet less\nexplored problem in language processing. In this paper, we present a\ncomparative study aimed at employing a pre-trained acoustic model to perform\nSLU in low resource scenarios. Specifically, we use three different embeddings\nextracted using Allosaurus, a pre-trained universal phone decoder: (1) Phone\n(2) Panphone, and (3) Allo embeddings. These embeddings are then used in\nidentifying the spoken intent. We perform experiments across three different\nlanguages: English, Sinhala, and Tamil each with different data sizes to\nsimulate high, medium, and low resource scenarios. Our system improves on the\nstate-of-the-art (SOTA) intent classification accuracy by approximately 2.11%\nfor Sinhala and 7.00% for Tamil and achieves competitive results on English.\nFurthermore, we present a quantitative analysis of how the performance scales\nwith the number of training examples used per intent.",
    "descriptor": "",
    "authors": [
      "Hemant Yadav",
      "Akshat Gupta",
      "Sai Krishna Rallabandi",
      "Alan W Black",
      "Rajiv Ratn Shah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.09264"
  },
  {
    "id": "arXiv:2110.09267",
    "title": "Boosting Image Outpainting with Semantic Layout Prediction",
    "abstract": "The objective of image outpainting is to extend image current border and\ngenerate new regions based on known ones. Previous methods adopt generative\nadversarial networks (GANs) to synthesize realistic images. However, the lack\nof explicit semantic representation leads to blurry and abnormal image pixels\nwhen the outpainting areas are complex and with various objects. In this work,\nwe decompose the outpainting task into two stages. Firstly, we train a GAN to\nextend regions in semantic segmentation domain instead of image domain.\nSecondly, another GAN model is trained to synthesize real images based on the\nextended semantic layouts. The first model focuses on low frequent context such\nas sizes, classes and other semantic cues while the second model focuses on\nhigh frequent context like color and texture. By this design, our approach can\nhandle semantic clues more easily and hence works better in complex scenarios.\nWe evaluate our framework on various datasets and make quantitative and\nqualitative analysis. Experiments demonstrate that our method generates\nreasonable extended semantic layouts and images, outperforming state-of-the-art\nmodels.",
    "descriptor": "",
    "authors": [
      "Ye Ma",
      "Jin Ma",
      "Min Zhou",
      "Quan Chen",
      "Tiezheng Ge",
      "Yuning Jiang",
      "Tong Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09267"
  },
  {
    "id": "arXiv:2110.09271",
    "title": "Rebuilding Trust: Queer in AI Approach to Artificial Intelligence Risk  Management",
    "abstract": "AI, machine learning, and data science methods are already pervasive in our\nsociety and technology, affecting all of our lives in many subtle ways.\nTrustworthy AI has become an important topic because trust in AI systems and\ntheir creators has been lost, or was never present in the first place.\nResearchers, corporations, and governments have long and painful histories of\nexcluding marginalized groups from technology development, deployment, and\noversight. As a direct result of this exclusion, these technologies have long\nhistories of being less useful or even harmful to minoritized groups. This\ninfuriating history illustrates that industry cannot be trusted to\nself-regulate and why trust in commercial AI systems and development has been\nlost. We argue that any AI development, deployment, and monitoring framework\nthat aspires to trust must incorporate both feminist, non-exploitative\nparticipatory design principles and strong, outside, and continual monitoring\nand testing. We additionally explain the importance of considering aspects of\ntrustworthiness beyond just transparency, fairness, and accountability,\nspecifically, to consider justice and shifting power to the people and\ndisempowered as core values to any trustworthy AI system. Creating trustworthy\nAI starts by funding, supporting, and empowering groups like Queer in AI so the\nfield of AI has the diversity and inclusion to credibly and effectively develop\ntrustworthy AI. Through our years of work and advocacy, we have developed\nexpert knowledge around questions of if and how gender, sexuality, and other\naspects of identity should be used in AI systems and how harms along these\nlines should be mitigated. Based on this, we discuss a gendered approach to AI,\nand further propose a queer epistemology and analyze the benefits it can bring\nto AI.",
    "descriptor": "\nComments: Queer in AI Response to NIST AI Risk Management Framework\n",
    "authors": [
      "Ashwin",
      "William Agnew",
      "Juan Pajaro",
      "Arjun Subramonian"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09271"
  },
  {
    "id": "arXiv:2110.09272",
    "title": "Multi-Objective Allocation of COVID-19 Testing Centers: Improving  Coverage and Equity in Access",
    "abstract": "At the time of this article, COVID-19 has been transmitted to more than 42\nmillion people and resulted in more than 673,000 deaths across the United\nStates. Throughout this pandemic, public health authorities have monitored the\nresults of diagnostic testing to identify hotspots of transmission. Such\ninformation can help reduce or block transmission paths of COVID-19 and help\ninfected patients receive early treatment. However, most current schemes of\ntest site allocation have been based on experience or convenience, often\nresulting in low efficiency and non-optimal allocation. In addition, the\nhistorical sociodemographic patterns of populations within cities can result in\nmeasurable inequities in access to testing between various racial and income\ngroups. To address these pressing issues, we propose a novel test site\nallocation scheme to (a) maximize population coverage, (b) minimize prediction\nuncertainties associated with projections of outbreak trajectories, and (c)\nreduce inequities in access. We illustrate our approach with case studies\ncomparing our allocation scheme with recorded allocation of testing sites in\nGeorgia, revealing increases in both population coverage and improvements in\nequity of access over current practice.",
    "descriptor": "",
    "authors": [
      "Zhen Zhong",
      "Ribhu Sengupta",
      "Kamran Paynabar",
      "Lance A. Waller"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Optimization and Control (math.OC)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.09272"
  },
  {
    "id": "arXiv:2110.09273",
    "title": "SafeAccess+: An Intelligent System to make Smart Home Safer and  Americans with Disability Act Compliant",
    "abstract": "Smart homes are becoming ubiquitous, but they are not Americans with\nDisability Act (ADA) compliant. Smart homes equipped with ADA compliant\nappliances and services are critical for people with disabilities (i.e., visual\nimpairments and limited mobility) to improve independence, safety, and quality\nof life. Despite all advancements in smart home technologies, some fundamental\ndesign and implementation issues remain. For example, people with disabilities\noften feel insecure to respond when someone knocks on the door or rings the\ndoorbell. In this paper, we present an intelligent system called \"SafeAccess+\"\nto build safer and ADA compliant premises (e.g. smart homes, offices). The key\nfunctionalities of the SafeAccess+ are: 1) Monitoring the inside/outside of\npremises and identifying incoming people; 2) Providing users relevant\ninformation to assess incoming threats (e.g., burglary, robbery) and ongoing\ncrimes 3) Allowing users to grant safe access to homes for friends/family\nmembers. We have addressed several technical and research challenges: -\ndeveloping models to detect and recognize person/activity, generating image\ndescriptions, designing ADA compliant end-end system. In addition, we have\ndesigned a prototype smart door showcasing the proof-of-concept. The premises\nare expected to be equipped with cameras placed in strategic locations that\nfacilitate monitoring the premise 24/7 to identify incoming persons and to\ngenerate image descriptions. The system generates a pre-structured message from\nthe image description to assess incoming threats and immediately notify the\nusers. The completeness and generalization of models have been ensured through\na rigorous quantitative evaluation. The users' satisfaction and reliability of\nthe system has been measured using PYTHEIA scale and was rated excellent\n(Internal Consistency-Cronbach's alpha is 0.784, Test-retest reliability is\n0.939 )",
    "descriptor": "",
    "authors": [
      "Shahinur Alam"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.09273"
  },
  {
    "id": "arXiv:2110.09274",
    "title": "pygrank: A Python Package for Graph Node Ranking",
    "abstract": "We introduce pygrank, an open source Python package to define, run and\nevaluate node ranking algorithms. We provide object-oriented and extensively\nunit-tested algorithm components, such as graph filters, post-processors,\nmeasures, benchmarks and online tuning. Computations can be delegated to numpy,\ntensorflow or pytorch backends and fit in back-propagation pipelines. Classes\ncan be combined to define interoperable complex algorithms. Within the context\nof this paper we compare the package with related alternatives and demonstrate\nits flexibility and ease of use with code examples.",
    "descriptor": "\nComments: 6 pages, 1 figure, 2 tables, 3 code snippets\n",
    "authors": [
      "Emmanouil Krasanakis",
      "Symeon Papadopoulos",
      "Ioannis Kompatsiaris",
      "Andreas Symeonidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09274"
  },
  {
    "id": "arXiv:2110.09276",
    "title": "Natural Attribute-based Shift Detection",
    "abstract": "Despite the impressive performance of deep networks in vision, language, and\nhealthcare, unpredictable behaviors on samples from the distribution different\nthan the training distribution cause severe problems in deployment. For better\nreliability of neural-network-based classifiers, we define a new task, natural\nattribute-based shift (NAS) detection, to detect the samples shifted from the\ntraining distribution by some natural attribute such as age of subjects or\nbrightness of images. Using the natural attributes present in existing\ndatasets, we introduce benchmark datasets in vision, language, and medical for\nNAS detection. Further, we conduct an extensive evaluation of prior\nrepresentative out-of-distribution (OOD) detection methods on NAS datasets and\nobserve an inconsistency in their performance. To understand this, we provide\nan analysis on the relationship between the location of NAS samples in the\nfeature space and the performance of distance- and confidence-based OOD\ndetection methods. Based on the analysis, we split NAS samples into three\ncategories and further suggest a simple modification to the training objective\nto obtain an improved OOD detection method that is capable of detecting samples\nfrom all NAS categories.",
    "descriptor": "",
    "authors": [
      "Jeonghoon Park",
      "Jimin Hong",
      "Radhika Dua",
      "Daehoon Gwak",
      "Yixuan Li",
      "Jaegul Choo",
      "Edward Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09276"
  },
  {
    "id": "arXiv:2110.09277",
    "title": "A Methodology for Developing a Verifiable Aircraft Engine Controller  from Formal Requirements",
    "abstract": "Verification of complex, safety-critical systems is a significant challenge.\nManual testing and simulations are often used, but are only capable of\nexploring a subset of the system's reachable states. Formal methods are\nmathematically-based techniques for the specification and development of\nsoftware, which can provide proofs of properties and exhaustive checks over a\nsystem's state space. In this paper, we present a formal requirements-driven\nmethodology, applied to a model of an aircraft engine controller that has been\nprovided by our industrial partner. Our methodology begins by formalising the\ncontroller's natural-language requirements using the (pre-existing) Formal\nRequirements Elicitation Tool (FRET), iteratively, in consultation with our\nindustry partner. Once formalised, FRET can automatically translate the\nrequirements to enable their verification alongside a Simulink model of the\naircraft engine controller; the requirements can also guide formal verification\nusing other approaches. These two parallel streams in our methodology seek to\ncombine the results from formal requirements elicitation, classical\nverification approaches, and runtime verification; to support the verification\nof aerospace systems modelled in Simulink, from the requirements phase through\nto execution. Our methodology harnesses the power of formal methods in a way\nthat complements existing verification techniques, and supports the\ntraceability of requirements throughout the verification process. This\nmethodology streamlines the process of developing verifiable aircraft engine\ncontrollers, by ensuring that the requirements are formalised up-front and\nuseable during development. In this paper we give an overview of (FRET),\ndescribe our methodology and work to-date on the formalisation and verification\nof the requirements, and outline future work using our methodology.",
    "descriptor": "\nComments: Submitted to AeroConf 2022\n",
    "authors": [
      "Matt Luckcuck",
      "Marie Farrell",
      "Ois\u00edn Sheridan",
      "Rosemary Monahan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.09277"
  },
  {
    "id": "arXiv:2110.09278",
    "title": "A Lightweight and Accurate Recognition Framework for Signs of X-ray Weld  Images",
    "abstract": "X-ray images are commonly used to ensure the security of devices in quality\ninspection industry. The recognition of signs printed on X-ray weld images\nplays an essential role in digital traceability system of manufacturing\nindustry. However, the scales of objects vary different greatly in weld images,\nand it hinders us to achieve satisfactory recognition. In this paper, we\npropose a signs recognition framework based on convolutional neural networks\n(CNNs) for weld images. The proposed framework firstly contains a shallow\nclassification network for correcting the pose of images. Moreover, we present\na novel spatial and channel enhancement (SCE) module to address the above scale\nproblem. This module can integrate multi-scale features and adaptively assign\nweights for each feature source. Based on SCE module, a narrow network is\ndesigned for final weld information recognition. To enhance the practicability\nof our framework, we carefully design the architecture of framework with a few\nparameters and computations. Experimental results show that our framework\nachieves 99.7% accuracy with 1.1 giga floating-point of operations (GFLOPs) on\nclassification stage, and 90.0 mean average precision (mAP) with 176.1 frames\nper second (FPS) on recognition stage.",
    "descriptor": "",
    "authors": [
      "Moyun Liu",
      "Jingming Xie",
      "Jing Hao",
      "Yang Zhang",
      "Xuzhan Chen",
      "Youping Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09278"
  },
  {
    "id": "arXiv:2110.09284",
    "title": "Carbon Neutrality in Data Center",
    "abstract": "Data centers are carbon-intensive enterprises due to their massive energy\nconsumption, and it is estimated that data center industry will account for 8\\%\nof global carbon emissions by 2030. However, both technological and policy\ninstruments for reducing or even neutralizing data center carbon emissions have\nnot been thoroughly investigated. To bridge this gap, this survey paper\nproposes a roadmap towards carbon-neutral data centers that takes into account\nboth policy instruments and technological methodologies. We begin by presenting\nthe carbon footprint of data centers, as well as some insights into the major\nsources of carbon emissions. Following that, carbon neutrality plans for major\nglobal cloud providers are discussed to summarize current industrial efforts in\nthis direction. In what follows, we introduce the carbon market as a policy\ninstrument to explain how to offset data center carbon emissions in a\ncost-efficient manner. On the technological front, we propose achieving\ncarbon-neutral data centers by increasing renewable energy penetration,\nimproving energy efficiency, and boosting energy circulation simultaneously. A\ncomprehensive review of existing technologies on these three topics is\nelaborated subsequently. Based on this, a multi-pronged approach towards carbon\nneutrality is envisioned and a digital twin-powered industrial artificial\nintelligence (AI) framework is proposed to make this solution a reality.\nFurthermore, three key scientific challenges for putting such a framework in\nplace are discussed. Finally, several applications for this framework are\npresented to demonstrate its enormous potential.",
    "descriptor": "",
    "authors": [
      "Zhiwei Cao",
      "Xin Zhou",
      "Han Hu",
      "Zhi Wang",
      "Yonggang Wen"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.09284"
  },
  {
    "id": "arXiv:2110.09286",
    "title": "Gait-based Human Identification through Minimum Gait-phases and Sensors",
    "abstract": "Human identification is one of the most common and critical tasks for\ncondition monitoring, human-machine interaction, and providing assistive\nservices in smart environments. Recently, human gait has gained new attention\nas a biometric for identification to achieve contactless identification from a\ndistance robust to physical appearances. However, an important aspect of gait\nidentification through wearables and image-based systems alike is accurate\nidentification when limited information is available, for example, when only a\nfraction of the whole gait cycle or only a part of the subject body is visible.\nIn this paper, we present a gait identification technique based on temporal and\ndescriptive statistic parameters of different gait phases as the features and\nwe investigate the performance of using only single gait phases for the\nidentification task using a minimum number of sensors. It was shown that it is\npossible to achieve high accuracy of over 95.5 percent by monitoring a single\nphase of the whole gait cycle through only a single sensor. It was also shown\nthat the proposed methodology could be used to achieve 100 percent\nidentification accuracy when the whole gait cycle was monitored through pelvis\nand foot sensors combined. The ANN was found to be more robust to fewer data\nfeatures compared to SVM and was concluded as the best machine algorithm for\nthe purpose.",
    "descriptor": "\nComments: Accepted in 43rd Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC 2021)\n",
    "authors": [
      "Muhammad Zeeshan Arshad",
      "Dawoon Jung",
      "Mina Park",
      "Kyung-Ryoul Mun",
      "Jinwook Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.09286"
  },
  {
    "id": "arXiv:2110.09290",
    "title": "The AI Triplet: Computational, Conceptual, and Mathematical  Representations in AI Education",
    "abstract": "Expertise in AI requires integrating computational, conceptual, and\nmathematical knowledge and representations. We propose this trifecta as an \"AI\ntriplet,\" similar in spirit to the \"chemistry triplet\" that has influenced the\npast four decades of chemistry education. We describe a rationale for this\ntriplet and how it maps onto topics commonly taught in AI courses, such as tree\nsearch and gradient descent. Also, similar to impacts of the chemistry triplet\non chemistry education, we suggest an initial example of how considering the AI\ntriplet may help pinpoint obstacles in AI education, i.e., how student learning\nmight be scaffolded to approach expert-level flexibility in moving between the\npoints of the triplet.",
    "descriptor": "",
    "authors": [
      "Maithilee Kunda"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09290"
  },
  {
    "id": "arXiv:2110.09291",
    "title": "Reconfigurable Intelligent Surface-Enhanced OFDM Communications via  Delay Adjustable Metasurface",
    "abstract": "Reconfigurable intelligent surface (RIS) is a promising technology for\nestablishing spectral- and energy-efficient wireless networks. In this paper,\nwe study RIS-enhanced orthogonal frequency division multiplexing (OFDM)\ncommunications, which generalize the existing RIS-driven context focusing only\non frequency-flat channels. Firstly, we introduce the delay adjustable\nmetasurface (DAM) relying on varactor diodes. In contrast to existing\nreflecting elements, each one in DAM is capable of storing and retrieving the\nimpinging electromagnetic waves upon dynamically controlling its\nelectromagnetically induced transparency (EIT) properties, thus additionally\nimposing an extra delay onto the reflected incident signals. Secondly, we\nformulate the rate-maximization problem by jointly optimizing the transmit\npower allocation and the RIS reflection coefficients as well as the RIS delays.\nFurthermore, to address the coupling among optimization variables, we propose\nan efficient algorithm to achieve a high-quality solution for the formulated\nnon-convex design problem by alternately optimizing the transmit power\nallocation and the RIS reflection pattern, including the reflection\ncoefficients and the delays. Thirdly, to circumvent the high complexity for\noptimizing the RIS reflection coefficients, we conceive a low-complexity scheme\nupon aligning the strongest taps of all reflected channels, while ensuring that\nthe maximum delay spread after introducing extra RIS delays does not exceed the\nlength of the cyclic prefix (CP). Finally, simulation results demonstrate that\nthe proposed design significantly improves the OFDM rate performance as well as\nthe RIS's adaptability to wideband signals compared to baseline schemes without\nemploying DAM.",
    "descriptor": "",
    "authors": [
      "Jiancheng An",
      "Chao Xu",
      "Derrick Wing Kwan Ng",
      "Chau Yuen",
      "Lu Gan",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.09291"
  },
  {
    "id": "arXiv:2110.09295",
    "title": "Fair Tree Learning",
    "abstract": "When dealing with sensitive data in automated data-driven decision-making, an\nimportant concern is to learn predictors with high performance towards a class\nlabel, whilst minimising for the discrimination towards some sensitive\nattribute, like gender or race, induced from biased data. Various hybrid\noptimisation criteria exist which combine classification performance with a\nfairness metric. However, while the threshold-free ROC-AUC is the standard for\nmeasuring traditional classification model performance, current fair decision\ntree methods only optimise for a fixed threshold on both the classification\ntask as well as the fairness metric. Moreover, current tree learning frameworks\ndo not allow for fair treatment with respect to multiple categories or multiple\nsensitive attributes. Lastly, the end-users of a fair model should be able to\nbalance fairness and classification performance according to their specific\nethical, legal, and societal needs. In this paper we address these shortcomings\nby proposing a threshold-independent fairness metric termed uniform demographic\nparity, and a derived splitting criterion entitled SCAFF -- Splitting Criterion\nAUC for Fairness -- towards fair decision tree learning, which extends to\nbagged and boosted frameworks. Compared to the state-of-the-art, our method\nprovides three main advantages: (1) classifier performance and fairness are\ndefined continuously instead of relying upon an, often arbitrary, decision\nthreshold; (2) it leverages multiple sensitive attributes simultaneously, of\nwhich the values may be multicategorical; and (3) the unavoidable\nperformance-fairness trade-off is tunable during learning. In our experiments,\nwe demonstrate how SCAFF attains high predictive performance towards the class\nlabel and low discrimination with respect to binary, multicategorical, and\nmultiple sensitive attributes, further substantiating our claims.",
    "descriptor": "",
    "authors": [
      "Ant\u00f3nio Pereira Barata",
      "Cor J. Veenman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09295"
  },
  {
    "id": "arXiv:2110.09296",
    "title": "Spark Deficient Gabor Frames for Inverse Problems",
    "abstract": "In this paper, we apply star-Digital Gabor Transform in analysis Compressed\nSensing and speech denoising. Based on assumptions on the ambient dimension, we\nproduce a window vector that generates a spark deficient Gabor frame with many\nlinear dependencies among its elements. We conduct computational experiments on\nboth synthetic and real-world signals, using as baseline three Gabor transforms\ngenerated by state-of-the-art window vectors and compare their performance to\nstar-Gabor transform. Results show that the proposed star-Gabor transform\noutperforms all others in all signal cases.",
    "descriptor": "\nComments: 2021 Online International Conference on Computational Harmonic Analysis (Online-ICCHA2021)\n",
    "authors": [
      "Vasiliki Kouni",
      "Holger Rauhut"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.09296"
  },
  {
    "id": "arXiv:2110.09297",
    "title": "Analysis of Indian Agricultural Ecosystem using Knowledge-based Tantra  Framework",
    "abstract": "The information systems have been extremely useful in managing businesses,\nenterprises, and public institutions such as government departments. But\ncurrent challenges are increasingly about managing ecosystems. Ecosystem is a\nuseful paradigm to better understand a variety of domains such as biology,\nbusiness, industry, agriculture, and society. In this paper, we look at the\nIndian Agricultural ecosystem. It is a mammoth task to assimilate the\ninformation for the whole ecosystem consisting of consumers, producers,\nworkers, traders, transporters, industry, and Government. There are myriad\ninterventions by the state and the central Governments, whose efficacy is\ndifficult to track and the outcomes hard to assess. A policy intervention that\nhelps one part of the ecosystem can harm the other. In addition, sustainability\nand ecological considerations are also extremely important. In this paper, we\nmake use of the Knowledge-based Tantra Social Information Management Framework\nto analyze the Indian Agricultural Ecosystem and build related Knowledge\nGraphs. Our analysis spans descriptive, normative, and transformative\nviewpoints. Tantra Framework makes use of concepts from Zachman Framework to\nmanage aspects of social information through different perspectives and\nconcepts from Unified Foundational Ontology (UFO) to represent\ninterrelationships between aspects.",
    "descriptor": "\nComments: 16 Tables, 6 Figures, draws heavily on arXiv:2102.04206. Submitted to CSI Transactions on ICT Journal\n",
    "authors": [
      "Shreekanth M Prabhu",
      "Natarajan Subramanyam"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.09297"
  },
  {
    "id": "arXiv:2110.09298",
    "title": "A DCT-based Tensor Completion Approach for Recovering Color Images and  Videos from Highly Undersampled Data",
    "abstract": "Recovering color images and videos from highly undersampled data is a\nfundamental and challenging task in face recognition and computer vision. By\nthe multi-dimensional nature of color images and videos, in this paper, we\npropose a novel tensor completion approach, which is able to efficiently\nexplore the sparsity of tensor data under the discrete cosine transform (DCT).\nSpecifically, we introduce two DCT-based tensor completion models as well as\ntwo implementable algorithms for their solutions. The first one is a DCT-based\nweighted nuclear norm minimization model. The second one is called DCT-based\n$p$-shrinking tensor completion model, which is a nonconvex model utilizing\n$p$-shrinkage mapping for promoting the low-rankness of data. Moreover, we\naccordingly propose two implementable augmented Lagrangian-based algorithms for\nsolving the underlying optimization models. A series of numerical experiments\nincluding color and MRI image inpainting and video data recovery demonstrate\nthat our proposed approach performs better than many existing state-of-the-art\ntensor completion methods, especially for the case when the ratio of missing\ndata is high.",
    "descriptor": "\nComments: 13 pages, 2 tables and 8 figures\n",
    "authors": [
      "Chenjian Pan",
      "Chen Ling",
      "Hongjin He",
      "Liqun Qi",
      "Yanwei Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.09298"
  },
  {
    "id": "arXiv:2110.09299",
    "title": "A Literature Review of 3D Face Reconstruction From a Single Image",
    "abstract": "This paper is a brief survey of the recent literature on 3D face\nreconstruction from a single image. Most articles have been choosen among 2016\nand 2020, in order to provide the most up-to-date view of the single image 3D\nface reconstruction.",
    "descriptor": "",
    "authors": [
      "Hanxin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09299"
  },
  {
    "id": "arXiv:2110.09302",
    "title": "A Prior Guided Adversarial Representation Learning and Hypergraph  Perceptual Network for Predicting Abnormal Connections of Alzheimer's Disease",
    "abstract": "Alzheimer's disease is characterized by alterations of the brain's structural\nand functional connectivity during its progressive degenerative processes.\nExisting auxiliary diagnostic methods have accomplished the classification\ntask, but few of them can accurately evaluate the changing characteristics of\nbrain connectivity. In this work, a prior guided adversarial representation\nlearning and hypergraph perceptual network (PGARL-HPN) is proposed to predict\nabnormal brain connections using triple-modality medical images. Concretely, a\nprior distribution from the anatomical knowledge is estimated to guide\nmultimodal representation learning using an adversarial strategy. Also, the\npairwise collaborative discriminator structure is further utilized to narrow\nthe difference of representation distribution. Moreover, the hypergraph\nperceptual network is developed to effectively fuse the learned representations\nwhile establishing high-order relations within and between multimodal images.\nExperimental results demonstrate that the proposed model outperforms other\nrelated methods in analyzing and predicting Alzheimer's disease progression.\nMore importantly, the identified abnormal connections are partly consistent\nwith the previous neuroscience discoveries. The proposed model can evaluate\ncharacteristics of abnormal brain connections at different stages of\nAlzheimer's disease, which is helpful for cognitive disease study and early\ntreatment.",
    "descriptor": "",
    "authors": [
      "Qiankun Zuo",
      "Baiying Lei",
      "Shuqiang Wang",
      "Yong Liu",
      "Bingchuan Wang",
      "Yanyan Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.09302"
  },
  {
    "id": "arXiv:2110.09303",
    "title": "Roles of Retailers in the Peer-to-Peer Electricity Market: A Single  Retailer Perspective",
    "abstract": "Despite extensive research in the past five years and several successfully\ncompleted and on-going pilot projects, regulators are still reluctant to\nimplement peer-to-peer trading at a large-scale in today's electricity market.\nThe reason could partly be attributed to the perceived disadvantage of current\nmarket participants like retailers due to their exclusion from market\nparticipation - a fundamental property of decentralised peer-to-peer trading.\nAs a consequence, recently, there has been growing pressure from energy service\nproviders in favour of retailers' participation in peer-to-peer trading.\nHowever, the role of retailers in the peer-to-peer market is yet to be\nestablished as no existing study has challenged this fundamental circumspection\nof decentralized trading. In this context, this perspective takes the first\nstep to discuss the feasibility of retailers' involvement in the peer-to-peer\nmarket. In doing so, we identify key characteristics of retail-based and\npeer-to-peer electricity markets and discuss our viewpoint on how to\nincorporate a single retailer in a peer-to-peer market without compromising the\nfundamental decision-making characteristics of both markets. Finally, we give\nan example of a hypothetical business model to demonstrate how a retailer can\nbe a part of a peer-to-peer market with a promise of collective benefits for\nthe participants.",
    "descriptor": "\nComments: 4 figures, 2 tables, accepted for publication in iScience (Cell Press)\n",
    "authors": [
      "Wayes Tushar",
      "Chau Yuen",
      "Tapan Saha",
      "Deb Chattopadhyay",
      "Sohrab Nizami",
      "Sarmad Hanif",
      "Jan E Alam",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.09303"
  },
  {
    "id": "arXiv:2110.09304",
    "title": "Prediction of Occurrence of Extreme Events using Machine Learning",
    "abstract": "Machine learning models play a vital role in the prediction task in several\nfields of study. In this work, we utilize the ability of machine learning\nalgorithms for the prediction of occurrence of extreme events in a nonlinear\nmechanical system. Extreme events are rare events which occur ubiquitously in\nnature. We consider four machine learning models, namely Logistic Regression,\nSupport Vector Machine, Random Forest and Multi-Layer Perceptron in our\nprediction task. We train these four machine learning models using training set\ndata and compute the performance of each model using the test set data. We show\nthat Multi-Layer Perceptron model performs better among the four models in the\nprediction of extreme events in the considered system. The persistent behaviour\nof the considered machine learning models are cross-checked with randomly\nshuffled training set and test set data.",
    "descriptor": "",
    "authors": [
      "J. Meiyazhagan",
      "S. Sudharsan",
      "A. Venkatasen",
      "M. Senthilvelan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2110.09304"
  },
  {
    "id": "arXiv:2110.09306",
    "title": "Two-stage Fourth-order Gas Kinetic Solver-based Compact Subcell Finite  Volume Method for Compressible Flows over Triangular Meshes",
    "abstract": "To meet the demand for complex geometries and high resolutions of small-scale\nflow structures, a two-stage fourth-order subcell finite volume (SCFV) method\ncombining the gas-kinetic solver (GKS) with subcell techniques for compressible\nflows over (unstructured) triangular meshes was developed to improve the\ncompactness and efficiency. Compared to the fourth-order GKS-based traditional\nfinite volume (FV) method, the proposed method realizes compactness effectively\nby subdividing each cell into a set of subcells or control volumes (CVs) and\nselecting only face-neighboring cells for high-order compact reconstruction.\nBecause a set of CVs share a solution polynomial, the reconstruction is more\nefficient than that for traditional FV-GKS, where each CV needs to be\nseparately reconstructed. Unlike in the single-stage third-order SCFV-GKS, both\naccuracy and efficiency are improved significantly by two-stage fourth-order\ntemporal discretization, for which only a second-order gas distribution\nfunction is needed to simplify the construction of the flux function and reduce\ncomputational costs. For viscous flows, it is not necessary to compute the\nviscous term with GKS. Compared to the fourth-stage Runge--Kutta method, one\nhalf of the stage is saved for achieving fourth-order time accuracy, which also\nhelps to improve the efficiency. Therefore, a new high-order method with\ncompactness, efficiency, and robustness is proposed by combining the SCFV\nmethod with the two-stage gas-kinetic flux. Several benchmark cases were tested\nto demonstrate the performance of the method in compressible flow simulations.",
    "descriptor": "",
    "authors": [
      "Chao Zhang",
      "Qibing Li",
      "Peng Song",
      "Jiequan Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2110.09306"
  },
  {
    "id": "arXiv:2110.09308",
    "title": "Power Systems Performance under 5G Radio Access Network in a  Co-Simulation Environment",
    "abstract": "Communication can improve control of important system parameters by allowing\ndifferent grid components to communicate their states with each other. This\ninformation exchange requires a reliable and fast communication infrastructure.\n5G communication can be a viable means to achieve this objective. This paper\ninvestigates the performance of several smart grid applications under a 5G\nradio access network. Different scenarios including set point changes and\ntransients are evaluated, and the results indicate that the system maintains\nstability when a 5Gnetwork is used to communicate system states.",
    "descriptor": "",
    "authors": [
      "Rahul Iyer",
      "Biplav Choudhury",
      "Vijay K. Shah",
      "Ali Mehrizi-Sani"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.09308"
  },
  {
    "id": "arXiv:2110.09309",
    "title": "Toward a multimodal multitask model for neurodegenerative diseases  diagnosis and progression prediction",
    "abstract": "Recent studies on modelling the progression of Alzheimer's disease use a\nsingle modality for their predictions while ignoring the time dimension.\nHowever, the nature of patient data is heterogeneous and time dependent which\nrequires models that value these factors in order to achieve a reliable\ndiagnosis, as well as making it possible to track and detect changes in the\nprogression of patients' condition at an early stage. This article overviews\nvarious categories of models used for Alzheimer's disease prediction with their\nrespective learning methods, by establishing a comparative study of early\nprediction and detection Alzheimer's disease progression. Finally, a robust and\nprecise detection model is proposed.",
    "descriptor": "",
    "authors": [
      "Sofia Lahrichi",
      "Maryem Rhanoui",
      "Mounia Mikram",
      "Bouchra El Asri"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.09309"
  },
  {
    "id": "arXiv:2110.09310",
    "title": "Energon: Towards Efficient Acceleration of Transformers Using Dynamic  Sparse Attention",
    "abstract": "In recent years, transformer models have revolutionized Natural Language\nProcessing (NLP) and also show promising performance on Computer Vision (CV)\ntasks. Despite their effectiveness, transformers' attention operations are hard\nto accelerate due to complicated data movement and quadratic computational\ncomplexity, prohibiting the real-time inference on resource-constrained\nedge-computing platforms.\nTo tackle this challenge, we propose Energon, an algorithm-architecture\nco-design approach that accelerates various transformers using dynamic sparse\nattention. With the observation that attention results only depend on a few\nimportant query-key pairs, we propose a multi-round filtering algorithm to\ndynamically identify such pairs at runtime. We adopt low bitwidth in each\nfiltering round and only use high-precision tensors in the attention stage to\nreduce overall complexity. By this means, we significantly mitigate the\ncomputational cost with negligible accuracy loss. To enable such an algorithm\nwith lower latency and better energy-efficiency, we also propose an Energon\nco-processor architecture. Elaborated pipelines and specialized optimizations\njointly boost the performance and reduce power consumption. Extensive\nexperiments on both NLP and CV benchmarks demonstrate that Energon achieves\n$161\\times$ and $8.4\\times$ geo-mean speedup and up to $10^4\\times$ and\n$10^3\\times$ energy reduction compared with Intel Xeon 5220 CPU and NVIDIA V100\nGPU. Compared to state-of-the-art attention accelerators SpAtten and $A^3$,\nEnergon also achieves $1.7\\times, 1.25\\times$ speedup and $1.6 \\times,\n1.5\\times $ higher energy efficiency.",
    "descriptor": "",
    "authors": [
      "Zhe Zhou",
      "Junlin Liu",
      "Zhenyu Gu",
      "Guangyu Sun"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09310"
  },
  {
    "id": "arXiv:2110.09313",
    "title": "Impact of review valence and perceived uncertainty on purchase of  time-constrained and discounted search goods",
    "abstract": "Increasing online shoppers have generated enormous amount of data in form of\nreviews (text) and sales data. Aggregate reviews in form of rating (stars) have\nbecome noticeable indicators of product quality and vendor performance to\nprospective consumers at first sight. Consumers subjected to product discount\ndeadlines search for ways in which they could evaluate product and vendor\nservice using a comprehensible benchmark. Considering the effect of time\npressure on consumers, aggregate reviews, known as review valence, become a\nviable indicator of product quality. This study investigates how purchase\ndecisions for new products are affected by past customer aggregate ratings when\na soon-to-expire discount is being offered. We examine the role that a\nconsumer's attitude towards review valence (RV) plays as an antecedent to that\nconsumer's reliance on RV in a purchase decision for time-discounted search\ngoods. Considering review credibility, diagnosticity, and effectiveness as\ndeterminants of consumer attitude in a time-constrained search and purchase\nenvironment, we follow the approach-avoidance conflict theory to examine the\nrole of review valence and perceived uncertainty in a time-constrained\nenvironment. The data was collected through an online survey and analyzed using\nstructural equation modelling. This study provides significant implications for\npractitioners as they can better understand how review valence can influence a\npurchase decision. Empirical analysis includes two contributions: 1. It helps\nto understand how consumer attitude toward review valence, when positively\ninfluenced by the determinants, can lead to reliance on review valence, further\ninfluencing purchase decision; 2. Time constrained purchase-related perceived\nuncertainty negatively moderates the relationship between consumer attitude and\nreliance on review valence.",
    "descriptor": "",
    "authors": [
      "Prathamesh Muzumdar"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.09313"
  },
  {
    "id": "arXiv:2110.09318",
    "title": "Mixed Reality using Illumination-aware Gradient Mixing in Surgical  Telepresence: Enhanced Multi-layer Visualization",
    "abstract": "Background and aim: Surgical telepresence using augmented perception has been\napplied, but mixed reality is still being researched and is only theoretical.\nThe aim of this work is to propose a solution to improve the visualization in\nthe final merged video by producing globally consistent videos when the\nintensity of illumination in the input source and target video varies.\nMethodology: The proposed system uses an enhanced multi-layer visualization\nwith illumination-aware gradient mixing using Illumination Aware Video\nComposition algorithm. Particle Swarm Optimization Algorithm is used to find\nthe best sample pair from foreground and background region and image pixel\ncorrelation to estimate the alpha matte. Particle Swarm Optimization algorithm\nhelps to get the original colour and depth of the unknown pixel in the unknown\nregion. Result: Our results showed improved accuracy caused by reducing the\nMean squared Error for selecting the best sample pair for unknown region in 10\neach sample for bowel, jaw and breast. The amount of this reduction is 16.48%\nfrom the state of art system. As a result, the visibility accuracy is improved\nfrom 89.4 to 97.7% which helped to clear the hand vision even in the difference\nof light. Conclusion: Illumination effect and alpha pixel correlation improves\nthe visualization accuracy and produces a globally consistent composition\nresults and maintains the temporal coherency when compositing two videos with\nhigh and inverse illumination effect. In addition, this paper provides a\nsolution for selecting the best sampling pair for the unknown region to obtain\nthe original colour and depth.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Nirakar Puri",
      "Abeer Alsadoon",
      "P.W.C. Prasad",
      "Nada Alsalami",
      "Tarik A. Rashid"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09318"
  },
  {
    "id": "arXiv:2110.09320",
    "title": "Deploying Near-Optimal Delay-Constrained Paths with Segment Routing in  Massive-Scale Networks",
    "abstract": "With a growing demand for quasi-instantaneous communication services such as\nreal-time video streaming, cloud gaming, and industry 4.0 applications,\nmulti-constraint Traffic Engineering (TE) becomes increasingly important. While\nlegacy TE management planes have proven laborious to deploy, Segment Routing\n(SR) drastically eases the deployment of TE paths and is thus increasingly\nadopted by Internet Service Providers (ISP). There is a clear need in computing\nand deploying Delay-Constrained Least-Cost paths (DCLC) with SR for real-time\ninteractive services. However, most current DCLC solutions are not tailored for\nSR. They also often lack efficiency or guarantees. Similarly to approximation\nschemes, we argue that the challenge is to design an algorithm providing both\nperformances and guarantees. However, conversely to most of these schemes, we\nalso consider operational constraints to provide a practical, high-performance\nimplementation.\nWe leverage the inherent limitations of delay measurements and account for\nthe operational constraint added by SR to design a new algorithm, best2cop,\nproviding guarantees and performance in all cases. Best2cop outperforms a\nstate-of-the-art algorithm on both random and real networks of up to 1000\nnodes. Relying on commodity hardware with a single thread, our algorithm\nretrieves all non-superfluous 3-dimensional routes in only 250ms and 100ms\nrespectively. This execution time is further reduced using multiple threads, as\nthe design of best2cop enables a speedup almost linear in the number of cores.\nFinally, we extend best2cop to deal with massive scale ISP by leveraging the\nmulti-area partitioning of these deployments. Thanks to our new topology\ngenerator specifically designed to model the realistic patterns of such massive\nIP networks, we show that best2cop solves DCLC-SR in approximately 1 second\neven for ISP having more than 100000 routers.",
    "descriptor": "",
    "authors": [
      "Jean-Romain Luttringer",
      "Thomas Alfroy",
      "Pascal M\u00e9rindol",
      "Quentin Bramas",
      "Fran\u00e7ois Clad",
      "Cristel Pelsser"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.09320"
  },
  {
    "id": "arXiv:2110.09321",
    "title": "COVIDRead: A Large-scale Question Answering Dataset on COVID-19",
    "abstract": "During this pandemic situation, extracting any relevant information related\nto COVID-19 will be immensely beneficial to the community at large. In this\npaper, we present a very important resource, COVIDRead, a Stanford Question\nAnswering Dataset (SQuAD) like dataset over more than 100k question-answer\npairs. The dataset consists of Context-Answer-Question triples. Primarily the\nquestions from the context are constructed in an automated way. After that, the\nsystem-generated questions are manually checked by hu-mans annotators. This is\na precious resource that could serve many purposes, ranging from common people\nqueries regarding this very uncommon disease to managing articles by\neditors/associate editors of a journal. We establish several end-to-end neural\nnetwork based baseline models that attain the lowest F1 of 32.03% and the\nhighest F1 of 37.19%. To the best of our knowledge, we are the first to provide\nthis kind of QA dataset in such a large volume on COVID-19. This dataset\ncreates a new avenue of carrying out research on COVID-19 by providing a\nbenchmark dataset and a baseline model.",
    "descriptor": "\nComments: 20 pages, 7 figures\n",
    "authors": [
      "Tanik Saikh",
      "Sovan Kumar Sahoo",
      "Asif Ekbal",
      "Pushpak Bhattacharyya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09321"
  },
  {
    "id": "arXiv:2110.09324",
    "title": "Automatic Learning of Subword Dependent Model Scales",
    "abstract": "To improve the performance of state-of-the-art automatic speech recognition\nsystems it is common practice to include external knowledge sources such as\nlanguage models or prior corrections. This is usually done via log-linear model\ncombination using separate scaling parameters for each model. Typically these\nparameters are manually optimized on some held-out data.\nIn this work we propose to optimize these scaling parameters via automatic\ndifferentiation and stochastic gradient decent similar to the neural network\nmodel parameters. We show on the LibriSpeech (LBS) and Switchboard (SWB)\ncorpora that the model scales for a combination of attentionbased\nencoder-decoder acoustic model and language model can be learned as effectively\nas with manual tuning. We further extend this approach to subword dependent\nmodel scales which could not be tuned manually which leads to 7% improvement on\nLBS and 3% on SWB. We also show that joint training of scales and model\nparameters is possible and gives additional 6% improvement on LBS.",
    "descriptor": "\nComments: submitted to ICASSP 2022\n",
    "authors": [
      "Felix Meyer",
      "Wilfried Michel",
      "Mohammad Zeineldeen",
      "Ralf Schl\u00fcter",
      "Hermann Ney"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.09324"
  },
  {
    "id": "arXiv:2110.09327",
    "title": "Self-Supervised Representation Learning: Introduction, Advances and  Challenges",
    "abstract": "Self-supervised representation learning methods aim to provide powerful deep\nfeature learning without the requirement of large annotated datasets, thus\nalleviating the annotation bottleneck that is one of the main barriers to\npractical deployment of deep learning today. These methods have advanced\nrapidly in recent years, with their efficacy approaching and sometimes\nsurpassing fully supervised pre-training alternatives across a variety of data\nmodalities including image, video, sound, text and graphs. This article\nintroduces this vibrant area including key concepts, the four main families of\napproach and associated state of the art, and how self-supervised methods are\napplied to diverse modalities of data. We further discuss practical\nconsiderations including workflows, representation transferability, and compute\ncost. Finally, we survey the major open challenges in the field that provide\nfertile ground for future work.",
    "descriptor": "",
    "authors": [
      "Linus Ericsson",
      "Henry Gouk",
      "Chen Change Loy",
      "Timothy M. Hospedales"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.09327"
  },
  {
    "id": "arXiv:2110.09332",
    "title": "Result Diversification by Multi-objective Evolutionary Algorithms with  Theoretical Guarantees",
    "abstract": "Given a ground set of items, the result diversification problem aims to\nselect a subset with high \"quality\" and \"diversity\" while satisfying some\nconstraints. It arises in various real-world artificial intelligence\napplications, such as web-based search, document summarization and feature\nselection, and also has applications in other areas, e.g., computational\ngeometry, databases, finance and operations research. Previous algorithms are\nmainly based on greedy or local search. In this paper, we propose to\nreformulate the result diversification problem as a bi-objective maximization\nproblem, and solve it by a multi-objective evolutionary algorithm (EA), i.e.,\nthe GSEMO. We theoretically prove that the GSEMO can achieve the\n(asymptotically) optimal theoretical guarantees under both static and dynamic\nenvironments. For cardinality constraints, the GSEMO can achieve the optimal\npolynomial-time approximation ratio, $1/2$. For more general matroid\nconstraints, the GSEMO can achieve the asymptotically optimal polynomial-time\napproximation ratio, $1/2-\\epsilon/(4n)$. Furthermore, when the objective\nfunction (i.e., a linear combination of quality and diversity) changes\ndynamically, the GSEMO can maintain this approximation ratio in polynomial\nrunning time, addressing the open question proposed by Borodin et al. This also\ntheoretically shows the superiority of EAs over local search for solving\ndynamic optimization problems for the first time, and discloses the robustness\nof the mutation operator of EAs against dynamic changes. Experiments on the\napplications of web-based search, multi-label feature selection and document\nsummarization show the superior performance of the GSEMO over the\nstate-of-the-art algorithms (i.e., the greedy algorithm and local search) under\nboth static and dynamic environments.",
    "descriptor": "\nComments: 46 pages, 2 figures\n",
    "authors": [
      "Chao Qian",
      "Dan-Xuan Liu",
      "Zhi-Hua Zhou"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09332"
  },
  {
    "id": "arXiv:2110.09338",
    "title": "Contextual Hate Speech Detection in Code Mixed Text using Transformer  Based Approaches",
    "abstract": "In the recent past, social media platforms have helped people in connecting\nand communicating to a wider audience. But this has also led to a drastic\nincrease in cyberbullying. It is essential to detect and curb hate speech to\nkeep the sanity of social media platforms. Also, code mixed text containing\nmore than one language is frequently used on these platforms. We, therefore,\npropose automated techniques for hate speech detection in code mixed text from\nscraped Twitter. We specifically focus on code mixed English-Hindi text and\ntransformer-based approaches. While regular approaches analyze the text\nindependently, we also make use of content text in the form of parent tweets.\nWe try to evaluate the performances of multilingual BERT and Indic-BERT in\nsingle-encoder and dual-encoder settings. The first approach is to concatenate\nthe target text and context text using a separator token and get a single\nrepresentation from the BERT model. The second approach encodes the two texts\nindependently using a dual BERT encoder and the corresponding representations\nare averaged. We show that the dual-encoder approach using independent\nrepresentations yields better performance. We also employ simple ensemble\nmethods to further improve the performance. Using these methods we were able to\nachieve the best F1 score of 73.07% on the HASOC 2021 ICHCL code mixed data\nset.",
    "descriptor": "\nComments: Accepted at HASOC @Forum for Information Retrieval Evaluation(FIRE) 2021\n",
    "authors": [
      "Ravindra Nayak",
      "Raviraj Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09338"
  },
  {
    "id": "arXiv:2110.09343",
    "title": "Turing Tumble is Turing-Complete",
    "abstract": "It is shown that the toy Turing Tumble, suitably extended with an infinitely\nlong game board and unlimited supply of pieces, is Turing-Complete. This is\nachieved via direct simulation of a Turing machine. Unlike previously\ninformally presented constructions, we do not encode the finite control\ninfinitely many times, we need only one trigger/ball-hopper pair, and we prove\nour construction correct. We believe this is the first natural extension of a\nmarble-based computer that has been shown to be universal.",
    "descriptor": "",
    "authors": [
      "Lenny Pitt"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2110.09343"
  },
  {
    "id": "arXiv:2110.09344",
    "title": "Intrusion-Free Graph Mixup",
    "abstract": "We present a simple and yet effective interpolation-based regularization\ntechnique to improve the generalization of Graph Neural Networks (GNNs). We\nleverage the recent advances in Mixup regularizer for vision and text, where\nrandom sample pairs and their labels are interpolated to create synthetic\nsamples for training. Unlike images or natural sentences, which embrace a grid\nor linear sequence format, graphs have arbitrary structure and topology, which\nplay a vital role on the semantic information of a graph. Consequently, even\nsimply deleting or adding one edge from a graph can dramatically change its\nsemantic meanings. This makes interpolating graph inputs very challenging\nbecause mixing random graph pairs may naturally create graphs with identical\nstructure but with different labels, causing the manifold intrusion issue. To\ncope with this obstacle, we propose the first input mixing schema for Mixup on\ngraph. We theoretically prove that our mixing strategy can recover the source\ngraphs from the mixed graph, and guarantees that the mixed graphs are manifold\nintrusion free. We also empirically show that our method can effectively\nregularize the graph classification learning, resulting in superior predictive\naccuracy over popular graph augmentation baselines.",
    "descriptor": "",
    "authors": [
      "Hongyu Guo",
      "Yongyi Mao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09344"
  },
  {
    "id": "arXiv:2110.09348",
    "title": "Understanding Dimensional Collapse in Contrastive Self-supervised  Learning",
    "abstract": "Self-supervised visual representation learning aims to learn useful\nrepresentations without relying on human annotations. Joint embedding approach\nbases on maximizing the agreement between embedding vectors from different\nviews of the same image. Various methods have been proposed to solve the\ncollapsing problem where all embedding vectors collapse to a trivial constant\nsolution. Among these methods, contrastive learning prevents collapse via\nnegative sample pairs. It has been shown that non-contrastive methods suffer\nfrom a lesser collapse problem of a different nature: dimensional collapse,\nwhereby the embedding vectors end up spanning a lower-dimensional subspace\ninstead of the entire available embedding space. Here, we show that dimensional\ncollapse also happens in contrastive learning. In this paper, we shed light on\nthe dynamics at play in contrastive learning that leads to dimensional\ncollapse. Inspired by our theory, we propose a novel contrastive learning\nmethod, called DirectCLR, which directly optimizes the representation space\nwithout relying on a trainable projector. Experiments show that DirectCLR\noutperforms SimCLR with a trainable linear projector on ImageNet.",
    "descriptor": "\nComments: 15 pages, 10 figures\n",
    "authors": [
      "Li Jing",
      "Pascal Vincent",
      "Yann LeCun",
      "Yuandong Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09348"
  },
  {
    "id": "arXiv:2110.09349",
    "title": "Small Data and Process in Data Visualization: The Radical Translations  Case Study",
    "abstract": "This paper uses the collaborative project Radical Translations as case study\nto examine some of the theoretical perspectives informing the adoption and\ncritique of data visualization in the digital humanities with applied examples\nin context. It showcases how data visualization is used within a King's Digital\nLab project lifecycle to facilitate collaborative data exploration within the\nproject interdisciplinary team - to support data curation and cleaning and/or\nto guide the design process - as well as data analysis by users external to the\nteam. Theoretical issues around bridging the gap between approaches adopted for\nsmall and/or large-scale datasets are addressed from functional perspectives\nwith reference to evolving data modelling and software development lifecycle\napproaches and workflows. While anchored to the specific context of the project\nunder examination, some of the identified trade-offs have epistemological value\nbeyond the specific case study iterations and its design solutions.",
    "descriptor": "",
    "authors": [
      "Arianna Ciula",
      "Miguel Vieira",
      "Ginestra Ferraro",
      "Tiffany Ong",
      "Sanja Perovic",
      "Rosa Mucignat",
      "Niccol\u00f2 Valmori",
      "Brecht Deseure",
      "Erica Joy Mannucci"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.09349"
  },
  {
    "id": "arXiv:2110.09350",
    "title": "On the Design of Modular Reflecting EM Skins for Enhanced Urban Wireless  Coverage",
    "abstract": "The design of modular, passive, and static artificial metasurfaces to be used\nas electromagnetic skins (EMSs) of buildings for improving the coverage in\nurban millimeter-wave communication scenarios is addressed. Towards this end,\nan ad-hoc design strategy is presented to determine optimal trade-off\nimplementative solutions that assure a suitable coverage of the areas of\ninterest, where the signal from the base station is too weak, with the minimum\ncomplexity. More specifically, the admissible surface in the building facade is\nfirst partitioned into tiles, which are the minimum-size elements of the\nartificial coating (i.e., the building block of an EMS). Then, the search for\nthe optimal EMS layout (i.e., the minimum number and the positions of the tiles\nto be installed) is carried out with a binary multi-objective optimization\nmethod. Representative numerical results are reported and discussed to point\nout the features and the potentialities of the EMS solution in the smart\nelectromagnetic environment (SEME) as well as the effectiveness of the proposed\ndesign method.",
    "descriptor": "",
    "authors": [
      "Paolo Rocca",
      "Pietro Da R\u00f9",
      "Nicola Anselmi",
      "Marco Salucci",
      "Giacomo Oliveri",
      "Danilo Erricolo",
      "Andrea Massa"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.09350"
  },
  {
    "id": "arXiv:2110.09355",
    "title": "FAST3D: Flow-Aware Self-Training for 3D Object Detectors",
    "abstract": "In the field of autonomous driving, self-training is widely applied to\nmitigate distribution shifts in LiDAR-based 3D object detectors. This\neliminates the need for expensive, high-quality labels whenever the environment\nchanges (e.g., geographic location, sensor setup, weather condition).\nState-of-the-art self-training approaches, however, mostly ignore the temporal\nnature of autonomous driving data. To address this issue, we propose a\nflow-aware self-training method that enables unsupervised domain adaptation for\n3D object detectors on continuous LiDAR point clouds. In order to get reliable\npseudo-labels, we leverage scene flow to propagate detections through time. In\nparticular, we introduce a flow-based multi-target tracker, that exploits flow\nconsistency to filter and refine resulting tracks. The emerged precise\npseudo-labels then serve as a basis for model re-training. Starting with a\npre-trained KITTI model, we conduct experiments on the challenging Waymo Open\nDataset to demonstrate the effectiveness of our approach. Without any prior\ntarget domain knowledge, our results show a significant improvement over the\nstate-of-the-art.",
    "descriptor": "\nComments: Accepted to BMVC 2021\n",
    "authors": [
      "Christian Fruhwirth-Reisinger",
      "Michael Opitz",
      "Horst Possegger",
      "Horst Bischof"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.09355"
  },
  {
    "id": "arXiv:2110.09356",
    "title": "Towards Federated Bayesian Network Structure Learning with Continuous  Optimization",
    "abstract": "Traditionally, Bayesian network structure learning is often carried out at a\ncentral site, in which all data is gathered. However, in practice, data may be\ndistributed across different parties (e.g., companies, devices) who intend to\ncollectively learn a Bayesian network, but are not willing to disclose\ninformation related to their data owing to privacy or security concerns. In\nthis work, we present a cross-silo federated learning approach to estimate the\nstructure of Bayesian network from data that is horizontally partitioned across\ndifferent parties. We develop a distributed structure learning method based on\ncontinuous optimization, using the alternating direction method of multipliers\n(ADMM), such that only the model parameters have to be exchanged during the\noptimization process. We demonstrate the flexibility of our approach by\nadopting it for both linear and nonlinear cases. Experimental results on\nsynthetic and real datasets show that it achieves an improved performance over\nthe other methods, especially when there is a relatively large number of\nclients and each has a limited sample size.",
    "descriptor": "\nComments: 16 pages; 5 figures\n",
    "authors": [
      "Ignavier Ng",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.09356"
  },
  {
    "id": "arXiv:2110.09359",
    "title": "Does human-robot trust need reciprocity?",
    "abstract": "Trust is one of the hallmarks of human-human and human-robot interaction.\nExtensive evidence has shown that trust among humans requires reciprocity.\nConversely, research in human-robot interaction (HRI) has mostly relied on a\nunidirectional view of trust that focuses on robots' reliability and\nperformance. The current paper argues that reciprocity may also play a key role\nin the emergence of mutual trust and successful collaboration between humans\nand robots. We will gather and discuss works that reveal a reciprocal dimension\nin human-robot trust, paving the way to a bidirectional and dynamic view of\ntrust in HRI.",
    "descriptor": "",
    "authors": [
      "Joshua Zonca",
      "Alessandra Sciutti"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.09359"
  },
  {
    "id": "arXiv:2110.09365",
    "title": "Optical Front/Mid-haul with Open Access-Edge Server Deployment Framework  for Sliced O-RAN",
    "abstract": "The fifth-generation of mobile radio technologies is expected to be agile,\nflexible, and scalable while provisioning ultra-reliable and low-latency\ncommunication (uRLLC), enhanced mobile broadband (eMBB), and massive machine\ntype communication (mMTC) applications. These are implemented by adopting\ncloudification, network function virtualization, and network slicing techniques\nin open-radio access network (O-RAN) architecture where remote radio heads\n(RRHs) are connected to dis-aggregated virtual base-band units (BBUs), i.e.,\nradio unit (RU), distributed unit (DU), and centralized unit (CU) over\nfront/mid-haul interfaces. However, cost-efficient solutions are required for\ndesigning front/mid-haul interfaces and time-wavelength division multiplexed\n(TWDM) passive optical network (PON) appears as a potential candidate.\nTherefore, in this paper, we propose a framework for the optimal placement of\nRUs based on long-term network statistics and connecting them to open\naccess-edge servers for hosting the corresponding DUs and CUs over\nfront/mid-haul interfaces while satisfying the diverse QoS requirements of\nuRLLC, eMBB, and mMTC slices. In turn, we formulate a two-stage integer\nprogramming problem and time-efficient heuristics for users to RU association\nand flexible deployment of the corresponding DUs and CUs. We evaluate the O-RAN\ndeployment cost and latency requirements with our TWDM-PON-based framework\nagainst urban, rural, and industrial areas and show its efficiency over the\noptical next-generation front-haul interface (NGFI)-based framework.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Sourav Mondal",
      "Marco Ruffini"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.09365"
  },
  {
    "id": "arXiv:2110.09366",
    "title": "Use and Misuse of the Term Experiment in Mining Software Repositories  Research",
    "abstract": "The significant momentum and importance of Mining Software Repositories (MSR)\nin Software Engineering (SE) has fostered new opportunities and challenges for\nextensive empirical research. However, MSR researchers seem to struggle to\ncharacterize the empirical methods they use into the existing empirical SE body\nof knowledge. This is especially the case of MSR experiments. To provide\nevidence on the special characteristics of MSR experiments and their\ndifferences with experiments traditionally acknowledged in SE so far, we\nelicited the hallmarks that differentiate an experiment from other types of\nempirical studies and characterized the hallmarks and types of experiments in\nMSR. We analyzed MSR literature obtained from a small-scale systematic mapping\nstudy to assess the use of the term experiment in MSR. We found that 19% of the\npapers claiming to be an experiment are indeed not an experiment at all but\nalso observational studies, so they use the term in a misleading way. From the\nremaining 81% of the papers, only one of them refers to a genuine controlled\nexperiment while the others stand for experiments with limited control. MSR\nresearchers tend to overlook such limitations, compromising the interpretation\nof the results of their studies. We provide recommendations and insights to\nsupport the improvement of MSR experiments.",
    "descriptor": "",
    "authors": [
      "Claudia Ayala",
      "Burak Turhan",
      "Xavier Franch",
      "Natalia Juristo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.09366"
  },
  {
    "id": "arXiv:2110.09369",
    "title": "Anti-Factor is FPT Parameterized by Treewidth and List Size (but  Counting is Hard)",
    "abstract": "In the general AntiFactor problem, a graph $G$ is given with a set\n$X_v\\subseteq \\mathbb{N}$ of forbidden degrees for every vertex $v$ and the\ntask is to find a set $S$ of edges such that the degree of $v$ in $S$ is not in\nthe set $X_v$. Standard techniques (dynamic programming + fast convolution) can\nbe used to show that if $M$ is the largest forbidden degree, then the problem\ncan be solved in time $(M+2)^k\\cdot n^{O(1)}$ if a tree decomposition of width\n$k$ is given. However, significantly faster algorithms are possible if the sets\n$X_v$ are sparse: our main algorithmic result shows that if every vertex has at\nmost $x$ forbidden degrees (we call this special case AntiFactor$_x$), then the\nproblem can be solved in time $(x+1)^{O(k)}\\cdot n^{O(1)}$. That is, the\nAntiFactor$_x$ is fixed-parameter tractable parameterized by treewidth $k$ and\nthe maximum number $x$ of excluded degrees.\nOur algorithm uses the technique of representative sets, which can be\ngeneralized to the optimization version, but (as expected) not to the counting\nversion of the problem. In fact, we show that #AntiFactor$_1$ is already\n#W[1]-hard parameterized by the width of the given decomposition. Moreover, we\nshow that, unlike for the decision version, the standard dynamic programming\nalgorithm is essentially optimal for the counting version. Formally, for a\nfixed nonempty set $X$, we denote by $X$-AntiFactor the special case where\nevery vertex $v$ has the same set $X_v=X$ of forbidden degrees. We show the\nfollowing lower bound for every fixed set $X$: if there is an $\\epsilon>0$ such\nthat #$X$-AntiFactor can be solved in time $(\\max X+2-\\epsilon)^k\\cdot\nn^{O(1)}$ on a tree decomposition of width $k$, then the Counting Strong\nExponential-Time Hypothesis (#SETH) fails.",
    "descriptor": "",
    "authors": [
      "D\u00e1niel Marx",
      "Govind S. Sankar",
      "Philipp Schepper"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.09369"
  },
  {
    "id": "arXiv:2110.09371",
    "title": "Proceedings of the 19th International Overture Workshop",
    "abstract": "This volume contains the papers presented at the 19th International Overture\nWorkshop, which was held in an hybrid format: online and physically at Aarhus,\nDenmark on 22th October 2021. This event was the latest in a series of\nworkshops around the Vienna Development Method (VDM), the open-source project\nOverture, and related tools and formalisms. VDM is one of the longest\nestablished formal methods for systems development. A lively community of\nresearchers and practitioners has grown up in academia and industry around the\nmodelling languages (VDM-SL, VDM++, VDM-RT, CML) and tools (VDMTools, Overture,\nVDM VSCode extension, Crescendo, Symphony, the INTO-CPS chain, and ViennaTalk).\nTogether, these provide a platform for work on modelling and analysis\ntechnology that includes static and dynamic analysis, test generation,\nexecution support, and model checking. This workshop provided updates on the\nemerging technology of VDM/Overture, including collaboration infrastructure,\ncollaborative modelling and co-simulation for Cyber-Physical Systems.",
    "descriptor": "",
    "authors": [
      "Hugo Daniel Macedo",
      "Casper Thule",
      "Ken Pierce"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.09371"
  },
  {
    "id": "arXiv:2110.09374",
    "title": "Ortho-Shot: Low Displacement Rank Regularization with Data Augmentation  for Few-Shot Learning",
    "abstract": "In few-shot classification, the primary goal is to learn representations from\na few samples that generalize well for novel classes. In this paper, we propose\nan efficient low displacement rank (LDR) regularization strategy termed\nOrtho-Shot; a technique that imposes orthogonal regularization on the\nconvolutional layers of a few-shot classifier, which is based on the\ndoubly-block toeplitz (DBT) matrix structure. The regularized convolutional\nlayers of the few-shot classifier enhances model generalization and intra-class\nfeature embeddings that are crucial for few-shot learning. Overfitting is a\ntypical issue for few-shot models, the lack of data diversity inhibits proper\nmodel inference which weakens the classification accuracy of few-shot learners\nto novel classes. In this regard, we broke down the pipeline of the few-shot\nclassifier and established that the support, query and task data augmentation\ncollectively alleviates overfitting in networks. With compelling results, we\ndemonstrated that combining a DBT-based low-rank orthogonal regularizer with\ndata augmentation strategies, significantly boosts the performance of a\nfew-shot classifier. We perform our experiments on the miniImagenet, CIFAR-FS\nand Stanford datasets with performance values of about 5\\% when compared to\nstate-of-the-art",
    "descriptor": "",
    "authors": [
      "Uche Osahor",
      "Nasser M. Nasrabadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.09374"
  },
  {
    "id": "arXiv:2110.09376",
    "title": "Planning of EM Skins for Improved Quality-of-Service in Urban Areas",
    "abstract": "The optimal planning of electromagnetic skins (EMSs) installed on the\nbuilding facades to enhance the received signal strength, thus the wireless\ncoverage and/or the quality-of-service (QoS) in large-scale urban areas, is\naddressed. More specifically, a novel instance of the System-by-Design (SbD)\nparadigm is proposed towards the implementation of a smart electromagnetic\nenvironment (SEME) where low-cost passive static reflective skins are deployed\nto enhance the level of the power received within selected regions-of-interest\n(RoIs). Thanks to the ad-hoc customization of the SbD functional blocks, which\nincludes the exploitation of a digital twin (DT) for the accurate yet fast\nassessment of the wireless coverage condition, effective solutions are yielded.\nNumerical results, dealing with real-world test-beds, are shown to assess the\ncapabilities, the potentialities, and the current limitations of the proposed\nEMSs planning strategy.",
    "descriptor": "",
    "authors": [
      "Arianna Benoni",
      "Marco Salucci",
      "Giacomo Oliveri",
      "Paolo Rocca",
      "Baozhu Li",
      "Andrea Massa"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.09376"
  },
  {
    "id": "arXiv:2110.09378",
    "title": "Forecasting Nonverbal Social Signals during Dyadic Interactions with  Generative Adversarial Neural Networks",
    "abstract": "We are approaching a future where social robots will progressively become\nwidespread in many aspects of our daily lives, including education, healthcare,\nwork, and personal use. All of such practical applications require that humans\nand robots collaborate in human environments, where social interaction is\nunavoidable. Along with verbal communication, successful social interaction is\nclosely coupled with the interplay between nonverbal perception and action\nmechanisms, such as observation of gaze behaviour and following their\nattention, coordinating the form and function of hand gestures. Humans perform\nnonverbal communication in an instinctive and adaptive manner, with no effort.\nFor robots to be successful in our social landscape, they should therefore\nengage in social interactions in a humanlike way, with increasing levels of\nautonomy. In particular, nonverbal gestures are expected to endow social robots\nwith the capability of emphasizing their speech, or showing their intentions.\nMotivated by this, our research sheds a light on modeling human behaviors in\nsocial interactions, specifically, forecasting human nonverbal social signals\nduring dyadic interactions, with an overarching goal of developing robotic\ninterfaces that can learn to imitate human dyadic interactions. Such an\napproach will ensure the messages encoded in the robot gestures could be\nperceived by interacting partners in a facile and transparent manner, which\ncould help improve the interacting partner perception and makes the social\ninteraction outcomes enhanced.",
    "descriptor": "",
    "authors": [
      "Nguyen Tan Viet Tuyen",
      "Oya Celiktutan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09378"
  },
  {
    "id": "arXiv:2110.09380",
    "title": "Learning multiplane images from single views with self-supervision",
    "abstract": "Generating static novel views from an already captured image is a hard task\nin computer vision and graphics, in particular when the single input image has\ndynamic parts such as persons or moving objects. In this paper, we tackle this\nproblem by proposing a new framework, called CycleMPI, that is capable of\nlearning a multiplane image representation from single images through a cyclic\ntraining strategy for self-supervision. Our framework does not require stereo\ndata for training, therefore it can be trained with massive visual data from\nthe Internet, resulting in a better generalization capability even for very\nchallenging cases. Although our method does not require stereo data for\nsupervision, it reaches results on stereo datasets comparable to the state of\nthe art in a zero-shot scenario. We evaluated our method on RealEstate10K and\nMannequin Challenge datasets for view synthesis and presented qualitative\nresults on Places II dataset.",
    "descriptor": "\nComments: To appear on BMVC 2021\n",
    "authors": [
      "Gustavo Sutter P. Carvalho",
      "Diogo C. Luvizon",
      "Antonio Joia",
      "Andre G. C. Pacheco",
      "Otavio A. B. Penatti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09380"
  },
  {
    "id": "arXiv:2110.09383",
    "title": "Neuro-Symbolic Forward Reasoning",
    "abstract": "Reasoning is an essential part of human intelligence and thus has been a\nlong-standing goal in artificial intelligence research. With the recent success\nof deep learning, incorporating reasoning with deep learning systems, i.e.,\nneuro-symbolic AI has become a major field of interest. We propose the\nNeuro-Symbolic Forward Reasoner (NSFR), a new approach for reasoning tasks\ntaking advantage of differentiable forward-chaining using first-order logic.\nThe key idea is to combine differentiable forward-chaining reasoning with\nobject-centric (deep) learning. Differentiable forward-chaining reasoning\ncomputes logical entailments smoothly, i.e., it deduces new facts from given\nfacts and rules in a differentiable manner. The object-centric learning\napproach factorizes raw inputs into representations in terms of objects. Thus,\nit allows us to provide a consistent framework to perform the forward-chaining\ninference from raw inputs. NSFR factorizes the raw inputs into the\nobject-centric representations, converts them into probabilistic ground atoms,\nand finally performs differentiable forward-chaining inference using weighted\nrules for inference. Our comprehensive experimental evaluations on\nobject-centric reasoning data sets, 2D Kandinsky patterns and 3D CLEVR-Hans,\nand a variety of tasks show the effectiveness and advantage of our approach.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Hikaru Shindo",
      "Devendra Singh Dhami",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09383"
  },
  {
    "id": "arXiv:2110.09391",
    "title": "How Far Two UAVs Should Be subject to Communication Uncertainties",
    "abstract": "Unmanned aerial vehicles are now becoming increasingly accessible to amateur\nand commercial users alike. A safety air traffic management system is needed to\nhelp ensure that every newest entrant into the sky does not collide with\nothers. Much research has been done to design various methods to perform\ncollision avoidance with obstacles. However, how to decide the safety radius\nsubject to communication uncertainties is still suspended. Based on assumptions\non communication uncertainties and supposed control performance, a separation\nprinciple of the safety radius design and controller design is proposed. With\nit, the safety radius corresponding to the safety area in the design phase\n(without uncertainties) and flight phase (subject to uncertainties) are\nstudied. Furthermore, the results are extended to multiple obstacles.\nSimulations and experiments are carried out to show the effectiveness of the\nproposed methods.",
    "descriptor": "",
    "authors": [
      "Quan Quan",
      "Rao Fu",
      "Kai-Yuan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.09391"
  },
  {
    "id": "arXiv:2110.09393",
    "title": "Ceasing hate withMoH: Hate Speech Detection in Hindi-English  Code-Switched Language",
    "abstract": "Social media has become a bedrock for people to voice their opinions\nworldwide. Due to the greater sense of freedom with the anonymity feature, it\nis possible to disregard social etiquette online and attack others without\nfacing severe consequences, inevitably propagating hate speech. The current\nmeasures to sift the online content and offset the hatred spread do not go far\nenough. One factor contributing to this is the prevalence of regional languages\nin social media and the paucity of language flexible hate speech detectors. The\nproposed work focuses on analyzing hate speech in Hindi-English code-switched\nlanguage. Our method explores transformation techniques to capture precise text\nrepresentation. To contain the structure of data and yet use it with existing\nalgorithms, we developed MoH or Map Only Hindi, which means \"Love\" in Hindi.\nMoH pipeline consists of language identification, Roman to Devanagari Hindi\ntransliteration using a knowledge base of Roman Hindi words. Finally, it\nemploys the fine-tuned Multilingual Bert and MuRIL language models. We\nconducted several quantitative experiment studies on three datasets and\nevaluated performance using Precision, Recall, and F1 metrics. The first\nexperiment studies MoH mapped text's performance with classical machine\nlearning models and shows an average increase of 13% in F1 scores. The second\ncompares the proposed work's scores with those of the baseline models and\noffers a rise in performance by 6%. Finally, the third reaches the proposed MoH\ntechnique with various data simulations using the existing transliteration\nlibrary. Here, MoH outperforms the rest by 15%. Our results demonstrate a\nsignificant improvement in the state-of-the-art scores on all three datasets.",
    "descriptor": "\nComments: Accepted in Elsevier Journal of Information Processing and Management. Sharma and Kabra made equal contribution\n",
    "authors": [
      "Arushi Sharma",
      "Anubha Kabra",
      "Minni Jain"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09393"
  },
  {
    "id": "arXiv:2110.09395",
    "title": "From river flow to spatial flow: flow map via river flow directions  assignment algorithm",
    "abstract": "Flow map is an effective way to visualize object movements across space over\ntime. It aims to model the paths from destinations to origins with quality\nconstraints satisfied, which is similar to river system extraction in a digital\nelevation model (DEM). In this paper, we present a novel and automated approach\ncalled RFDA-FM for spatial flows from one origin to multiple destinations using\na river flow directions assignment algorithm in DEM. The RFDA-FM first models\nthe mapping space as a flat surface by DEM. An improved maze solving algorithm\n(MSA) is then introduced to assign the flow directions by constraining its\nsearching directions, direction weights and searching range. The paths from the\ndestinations to the origin are obtained iteratively based on the improved MSA\naccording the path importance. Finally, these paths are rendered with varied\nwidths and smoothed according to their volume using the B\\'ezier curves. The\nevaluation results indicate that the flow maps generated by RFDA-FM can have a\nhigher quality on uniform distribution of edge lengths and avoidance of\nself-intersections and acute angles by comparing to the existing approaches.\nThe experiments demonstrate that RFDA-FM is also applicable for heterogeneous\nmapping space or mapping space with obstacle areas.",
    "descriptor": "\nComments: 14 pages and 16 figures\n",
    "authors": [
      "Zhiwei Wei",
      "Su Ding",
      "Yang Wang",
      "Yuanben Zhang",
      "Wenjia Xu"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.09395"
  },
  {
    "id": "arXiv:2110.09396",
    "title": "Streaming Machine Learning and Online Active Learning for Automated  Visual Inspection",
    "abstract": "Quality control is a key activity performed by manufacturing companies to\nverify product conformance to the requirements and specifications. Standardized\nquality control ensures that all the products are evaluated under the same\ncriteria. The decreased cost of sensors and connectivity enabled an increasing\ndigitalization of manufacturing and provided greater data availability. Such\ndata availability has spurred the development of artificial intelligence\nmodels, which allow higher degrees of automation and reduced bias when\ninspecting the products. Furthermore, the increased speed of inspection reduces\noverall costs and time required for defect inspection. In this research, we\ncompare five streaming machine learning algorithms applied to visual defect\ninspection with real-world data provided by Philips Consumer Lifestyle BV.\nFurthermore, we compare them in a streaming active learning context, which\nreduces the data labeling effort in a real-world context. Our results show that\nactive learning reduces the data labeling effort by almost 15% on average for\nthe worst case, while keeping an acceptable classification performance. The use\nof machine learning models for automated visual inspection are expected to\nspeed up the quality inspection up to 40%.",
    "descriptor": "",
    "authors": [
      "Jo\u017ee M. Ro\u017eanec",
      "Elena Trajkova",
      "Paulien Dam",
      "Bla\u017e Fortuna",
      "Dunja Mladeni\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.09396"
  },
  {
    "id": "arXiv:2110.09397",
    "title": "Using Psychological Characteristics of Situations for Social Situation  Comprehension in Support Agents",
    "abstract": "Support agents that help users in their daily lives need to take into account\nnot only the user's characteristics, but also the social situation of the user.\nExisting work on including social context uses some type of situation cue as an\ninput to information processing techniques in order to assess the expected\nbehavior of the user. However, research shows that it is important to also\ndetermine the meaning of a situation, a step which we refer to as social\nsituation comprehension. We propose using psychological characteristics of\nsituations, which have been proposed in social science for ascribing meaning to\nsituations, as the basis for social situation comprehension. Using data from\nuser studies, we evaluate this proposal from two perspectives. First, from a\ntechnical perspective, we show that psychological characteristics of situations\ncan be used as input to predict the priority of social situations, and that\npsychological characteristics of situations can be predicted from the features\nof a social situation. Second, we investigate the role of the comprehension\nstep in human-machine meaning making. We show that psychological\ncharacteristics can be successfully used as a basis for explanations given to\nusers about the decisions of an agenda management personal assistant agent.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Ilir Kola",
      "Catholijn M. Jonker",
      "M. Birna van Riemsdijk"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09397"
  },
  {
    "id": "arXiv:2110.09399",
    "title": "Verifying Compliance in Process Choreographies: Foundations, Algorithms,  and Implementation",
    "abstract": "The current push towards interoperability drives companies to collaborate\nthrough process choreographies. At the same time, they face a jungle of\ncontinuously changing regulations, e.g., due to the pandemic and developments\nsuch as the BREXIT, which strongly affect cross-organizational collaborations.\nThink of, for example, supply chains spanning several countries with different\nand maybe even conflicting COVID19 traveling restrictions. Hence, providing\nautomatic compliance verification in process choreographies is crucial for any\ncross-organizational business process. A particular challenge concerns the\nrestricted visibility of the partner processes at the presence of global\ncompliance rules (GCR), i.e., rules that span across the process of several\npartners. This work deals with the question how to verify global compliance if\naffected tasks are not fully visible. Our idea is to decompose GCRs into so\ncalled assertions that can be checked by each affected partner whereby the\ndecomposition is both correct and lossless. The algorithm exploits transitivity\nproperties of the underlying rule specification, and its correctness and\ncomplexity are proven, considering advanced aspects such as loops. The\nalgorithm is implemented in a proof-of-concept prototype, including a model\nchecker for verifying compliance. The applicability of the approach is further\ndemonstrated on a real-world manufacturing use case.",
    "descriptor": "",
    "authors": [
      "Walid Fdhila",
      "David Knuplesch",
      "Stefanie Rinderle-Ma",
      "Manfred Reichert"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.09399"
  },
  {
    "id": "arXiv:2110.09401",
    "title": "Mesh Convolutional Autoencoder for Semi-Regular Meshes of Different  Sizes",
    "abstract": "The analysis of deforming 3D surface meshes is accelerated by autoencoders\nsince the low-dimensional embeddings can be used to visualize underlying\ndynamics. But, state-of-the-art mesh convolutional autoencoders require a fixed\nconnectivity of all input meshes handled by the autoencoder. This is due to\neither the use of spectral convolutional layers or mesh dependent pooling\noperations. Therefore, the types of datasets that one can study are limited and\nthe learned knowledge cannot be transferred to other datasets that exhibit\nsimilar behavior. To address this, we transform the discretization of the\nsurfaces to semi-regular meshes that have a locally regular connectivity and\nwhose meshing is hierarchical. This allows us to apply the same spatial\nconvolutional filters to the local neighborhoods and to define a pooling\noperator that can be applied to every semi-regular mesh. We apply the same mesh\nautoencoder to different datasets and our reconstruction error is more than 50%\nlower than the error from state-of-the-art models, which have to be trained for\nevery mesh separately. Additionally, we visualize the underlying dynamics of\nunseen mesh sequences with an autoencoder trained on different classes of\nmeshes.",
    "descriptor": "",
    "authors": [
      "Sara Hahner",
      "Jochen Garcle"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09401"
  },
  {
    "id": "arXiv:2110.09405",
    "title": "Capacity Region Bounds for the K user Dispersive Nonlinear Optical WDM  Channel with Peak Power Constraints",
    "abstract": "It is known that fiber nonlinearities induce crosstalk in a wavelength\ndivision multiplexed (WDM) system, which limits the capacity of such systems\nespecially at higher signal powers. Traditionally, the channel capacity of a\nsingle WDM user is analyzed under different assumptions for the transmitted\nsignals of the other users. In this paper, we instead take a multi-user\ninformation theoretic view of an optical WDM channel impaired by cross-phase\nmodulation and dispersion as an interference channel. We characterize, for the\nfirst time, an outer bound on the capacity region of simultaneously achievable\nrate pairs, assuming a general K-user perturbative channel model using\ngenie-aided techniques. Furthermore, an achievable rate region is obtained by\ntime-sharing between certain single-user strategies, and it is shown that the\nlatter can achieve better rate tuples compared to treating nonlinear\ninterference as noise.",
    "descriptor": "",
    "authors": [
      "Viswanathan Ramachandran",
      "Gabriele Liga",
      "Astrid Barreiro",
      "Alex Alvarado"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.09405"
  },
  {
    "id": "arXiv:2110.09408",
    "title": "HRFormer: High-Resolution Transformer for Dense Prediction",
    "abstract": "We present a High-Resolution Transformer (HRT) that learns high-resolution\nrepresentations for dense prediction tasks, in contrast to the original Vision\nTransformer that produces low-resolution representations and has high memory\nand computational cost. We take advantage of the multi-resolution parallel\ndesign introduced in high-resolution convolutional networks (HRNet), along with\nlocal-window self-attention that performs self-attention over small\nnon-overlapping image windows, for improving the memory and computation\nefficiency. In addition, we introduce a convolution into the FFN to exchange\ninformation across the disconnected image windows. We demonstrate the\neffectiveness of the High-Resolution Transformer on both human pose estimation\nand semantic segmentation tasks, e.g., HRT outperforms Swin transformer by\n$1.3$ AP on COCO pose estimation with $50\\%$ fewer parameters and $30\\%$ fewer\nFLOPs. Code is available at: https://github.com/HRNet/HRFormer.",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Yuhui Yuan",
      "Rao Fu",
      "Lang Huang",
      "Weihong Lin",
      "Chao Zhang",
      "Xilin Chen",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09408"
  },
  {
    "id": "arXiv:2110.09410",
    "title": "Exploiting Domain-Specific Features to Enhance Domain Generalization",
    "abstract": "Domain Generalization (DG) aims to train a model, from multiple observed\nsource domains, in order to perform well on unseen target domains. To obtain\nthe generalization capability, prior DG approaches have focused on extracting\ndomain-invariant information across sources to generalize on target domains,\nwhile useful domain-specific information which strongly correlates with labels\nin individual domains and the generalization to target domains is usually\nignored. In this paper, we propose meta-Domain Specific-Domain Invariant\n(mDSDI) - a novel theoretically sound framework that extends beyond the\ninvariance view to further capture the usefulness of domain-specific\ninformation. Our key insight is to disentangle features in the latent space\nwhile jointly learning both domain-invariant and domain-specific features in a\nunified framework. The domain-specific representation is optimized through the\nmeta-learning framework to adapt from source domains, targeting a robust\ngeneralization on unseen domains. We empirically show that mDSDI provides\ncompetitive results with state-of-the-art techniques in DG. A further ablation\nstudy with our generated dataset, Background-Colored-MNIST, confirms the\nhypothesis that domain-specific is essential, leading to better results when\ncompared with only using domain-invariant.",
    "descriptor": "\nComments: 25 pages, 6 tables, 11 figures, published at Advances in Neural Information Processing Systems (NeurIPS), 2021\n",
    "authors": [
      "Manh-Ha Bui",
      "Toan Tran",
      "Anh Tuan Tran",
      "Dinh Phung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09410"
  },
  {
    "id": "arXiv:2110.09414",
    "title": "BPPChecker: An SMT-based Model Checker on Basic Parallel Processes",
    "abstract": "Program verification on concurrent programs is a big challenge due to general\nundecidable results. Petri nets and its extensions are used in most works.\nHowever, existing verifiers based on Petri nets are difficult to be complete\nand efficient. Basic Parallel Process (BPP), as a subclass of Petri nets, can\nbe used as a model for describing and verifying concurrent programs with lower\ncomplexity. We propose and implement BPPChecker, the first model checker for\nverifying CTL on BPP. We propose constraint-based algorithms for the problem of\nmodel checking CTL on BPPs and handle formulas by SMT solver Z3. For EF\noperator, we reduce the model checking of EF-formulas to the satisfiability\nproblem of existential Presburger formula. For EG operator, we provide a\n$k$-step bounded semantics and reduce the model checking of EG-formulas to the\nsatisfiability problem of linear integer arithmetic. Besides, we give Actor\nCommunicating System (ACS) the over-approximation BPP-based semantics and\nevaluate BPPChecker on ACSs generated from real Erlang programs. Experimental\nresults show that BPPChecker performs more efficiently than the existing tools\nfor a series of branching-time property verification problems of Erlang\nprograms.",
    "descriptor": "",
    "authors": [
      "Ying Zhao",
      "Jinhao Tan",
      "Guoqiang Li"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.09414"
  },
  {
    "id": "arXiv:2110.09415",
    "title": "NeuralBlox: Real-Time Neural Representation Fusion for Robust Volumetric  Mapping",
    "abstract": "We present a novel 3D mapping method leveraging the recent progress in neural\nimplicit representation for 3D reconstruction. Most existing state-of-the-art\nneural implicit representation methods are limited to object-level\nreconstructions and can not incrementally perform updates given new data. In\nthis work, we propose a fusion strategy and training pipeline to incrementally\nbuild and update neural implicit representations that enable the reconstruction\nof large scenes from sequential partial observations. By representing an\narbitrarily sized scene as a grid of latent codes and performing updates\ndirectly in latent space, we show that incrementally built occupancy maps can\nbe obtained in real-time even on a CPU. Compared to traditional approaches such\nas Truncated Signed Distance Fields (TSDFs), our map representation is\nsignificantly more robust in yielding a better scene completeness given noisy\ninputs. We demonstrate the performance of our approach in thorough experimental\nvalidation on real-world datasets with varying degrees of added pose noise.",
    "descriptor": "\nComments: 3DV 2021. Equal contribution between the first two authors. Code: this https URL\n",
    "authors": [
      "Stefan Lionar",
      "Lukas Schmid",
      "Cesar Cadena",
      "Roland Siegwart",
      "Andrei Cramariuc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.09415"
  },
  {
    "id": "arXiv:2110.09419",
    "title": "Compositional Attention: Disentangling Search and Retrieval",
    "abstract": "Multi-head, key-value attention is the backbone of the widely successful\nTransformer model and its variants. This attention mechanism uses multiple\nparallel key-value attention blocks (called heads), each performing two\nfundamental computations: (1) search - selection of a relevant entity from a\nset via query-key interactions, and (2) retrieval - extraction of relevant\nfeatures from the selected entity via a value matrix. Importantly, standard\nattention heads learn a rigid mapping between search and retrieval. In this\nwork, we first highlight how this static nature of the pairing can potentially:\n(a) lead to learning of redundant parameters in certain tasks, and (b) hinder\ngeneralization. To alleviate this problem, we propose a novel attention\nmechanism, called Compositional Attention, that replaces the standard head\nstructure. The proposed mechanism disentangles search and retrieval and\ncomposes them in a dynamic, flexible and context-dependent manner through an\nadditional soft competition stage between the query-key combination and value\npairing. Through a series of numerical experiments, we show that it outperforms\nstandard multi-head attention on a variety of tasks, including some\nout-of-distribution settings. Through our qualitative analysis, we demonstrate\nthat Compositional Attention leads to dynamic specialization based on the type\nof retrieval needed. Our proposed mechanism generalizes multi-head attention,\nallows independent scaling of search and retrieval, and can easily be\nimplemented in lieu of standard attention heads in any network architecture.",
    "descriptor": "",
    "authors": [
      "Sarthak Mittal",
      "Sharath Chandra Raparthy",
      "Irina Rish",
      "Yoshua Bengio",
      "Guillaume Lajoie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09419"
  },
  {
    "id": "arXiv:2110.09421",
    "title": "Measuring Cognitive Status from Speech in a Smart Home Environment",
    "abstract": "The population is aging, and becoming more tech-savvy. The United Nations\npredicts that by 2050, one in six people in the world will be over age 65 (up\nfrom one in 11 in 2019), and this increases to one in four in Europe and\nNorthern America. Meanwhile, the proportion of American adults over 65 who own\na smartphone has risen 24 percentage points from 2013-2017, and the majority\nhave Internet in their homes. Smart devices and smart home technology have\nprofound potential to transform how people age, their ability to live\nindependently in later years, and their interactions with their circle of care.\nCognitive health is a key component to independence and well-being in old age,\nand smart homes present many opportunities to measure cognitive status in a\ncontinuous, unobtrusive manner. In this article, we focus on speech as a\nmeasurement instrument for cognitive health. Existing methods of cognitive\nassessment suffer from a number of limitations that could be addressed through\nsmart home speech sensing technologies. We begin with a brief tutorial on\nmeasuring cognitive status from speech, including some pointers to useful\nopen-source software toolboxes for the interested reader. We then present an\noverview of the preliminary results from pilot studies on active and passive\nsmart home speech sensing for the measurement of cognitive health, and conclude\nwith some recommendations and challenge statements for the next wave of work in\nthis area, to help overcome both technical and ethical barriers to success.",
    "descriptor": "",
    "authors": [
      "Kathleen C. Fraser",
      "Majid Komeili"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.09421"
  },
  {
    "id": "arXiv:2110.09424",
    "title": "Don't Judge Me by My Face : An Indirect Adversarial Approach to Remove  Sensitive Information From Multimodal Neural Representation in Asynchronous  Job Video Interviews",
    "abstract": "se of machine learning for automatic analysis of job interview videos has\nrecently seen increased interest. Despite claims of fair output regarding\nsensitive information such as gender or ethnicity of the candidates, the\ncurrent approaches rarely provide proof of unbiased decision-making, or that\nsensitive information is not used. Recently, adversarial methods have been\nproved to effectively remove sensitive information from the latent\nrepresentation of neural networks. However, these methods rely on the use of\nexplicitly labeled protected variables (e.g. gender), which cannot be collected\nin the context of recruiting in some countries (e.g. France). In this article,\nwe propose a new adversarial approach to remove sensitive information from the\nlatent representation of neural networks without the need to collect any\nsensitive variable. Using only a few frames of the interview, we train our\nmodel to not be able to find the face of the candidate related to the job\ninterview in the inner layers of the model. This, in turn, allows us to remove\nrelevant private information from these layers. Comparing our approach to a\nstandard baseline on a public dataset with gender and ethnicity annotations, we\nshow that it effectively removes sensitive information from the main network.\nMoreover, to the best of our knowledge, this is the first application of\nadversarial techniques for obtaining a multimodal fair representation in the\ncontext of video job interviews. In summary, our contributions aim at improving\nfairness of the upcoming automatic systems processing videos of job interviews\nfor equality in job selection.",
    "descriptor": "\nComments: published in ACII 2021\n",
    "authors": [
      "L\u00e9o Hemamou",
      "Arthur Guillon",
      "Jean-Claude Martin",
      "Chlo\u00e9 Clavel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09424"
  },
  {
    "id": "arXiv:2110.09425",
    "title": "FacialGAN: Style Transfer and Attribute Manipulation on Synthetic Faces",
    "abstract": "Facial image manipulation is a generation task where the output face is\nshifted towards an intended target direction in terms of facial attribute and\nstyles. Recent works have achieved great success in various editing techniques\nsuch as style transfer and attribute translation. However, current approaches\nare either focusing on pure style transfer, or on the translation of predefined\nsets of attributes with restricted interactivity. To address this issue, we\npropose FacialGAN, a novel framework enabling simultaneous rich style transfers\nand interactive facial attributes manipulation. While preserving the identity\nof a source image, we transfer the diverse styles of a target image to the\nsource image. We then incorporate the geometry information of a segmentation\nmask to provide a fine-grained manipulation of facial attributes. Finally, a\nmulti-objective learning strategy is introduced to optimize the loss of each\nspecific tasks. Experiments on the CelebA-HQ dataset, with CelebAMask-HQ as\nsemantic mask labels, show our model's capacity in producing visually\ncompelling results in style transfer, attribute manipulation, diversity and\nface verification. For reproducibility, we provide an interactive open-source\ntool to perform facial manipulations, and the Pytorch implementation of the\nmodel.",
    "descriptor": "",
    "authors": [
      "Ricard Durall",
      "Jireh Jam",
      "Dominik Strassel",
      "Moi Hoon Yap",
      "Janis Keuper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09425"
  },
  {
    "id": "arXiv:2110.09428",
    "title": "Distinguishing Natural and Computer-Generated Images using  Multi-Colorspace fused EfficientNet",
    "abstract": "The problem of distinguishing natural images from photo-realistic\ncomputer-generated ones either addresses natural images versus computer\ngraphics or natural images versus GAN images, at a time. But in a real-world\nimage forensic scenario, it is highly essential to consider all categories of\nimage generation, since in most cases image generation is unknown. We, for the\nfirst time, to our best knowledge, approach the problem of distinguishing\nnatural images from photo-realistic computer-generated images as a three-class\nclassification task classifying natural, computer graphics, and GAN images. For\nthe task, we propose a Multi-Colorspace fused EfficientNet model by parallelly\nfusing three EfficientNet networks that follow transfer learning methodology\nwhere each network operates in different colorspaces, RGB, LCH, and HSV, chosen\nafter analyzing the efficacy of various colorspace transformations in this\nimage forensics problem. Our model outperforms the baselines in terms of\naccuracy, robustness towards post-processing, and generalizability towards\nother datasets. We conduct psychophysics experiments to understand how\naccurately humans can distinguish natural, computer graphics, and GAN images\nwhere we could observe that humans find difficulty in classifying these images,\nparticularly the computer-generated images, indicating the necessity of\ncomputational algorithms for the task. We also analyze the behavior of our\nmodel through visual explanations to understand salient regions that contribute\nto the model's decision making and compare with manual explanations provided by\nhuman participants in the form of region markings, where we could observe\nsimilarities in both the explanations indicating the powerful nature of our\nmodel to take the decisions meaningfully.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Manjary P Gangan",
      "Anoop K",
      "Lajish V L"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09428"
  },
  {
    "id": "arXiv:2110.09431",
    "title": "Comparing Deep Neural Nets with UMAP Tour",
    "abstract": "Neural networks should be interpretable to humans. In particular, there is a\ngrowing interest in concepts learned in a layer and similarity between layers.\nIn this work, a tool, UMAP Tour, is built to visually inspect and compare\ninternal behavior of real-world neural network models using well-aligned,\ninstance-level representations. The method used in the visualization also\nimplies a new similarity measure between neural network layers. Using the\nvisual tool and the similarity measure, we find concepts learned in\nstate-of-the-art models and dissimilarities between them, such as GoogLeNet and\nResNet.",
    "descriptor": "",
    "authors": [
      "Mingwei Li",
      "Carlos Scheidegger"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09431"
  },
  {
    "id": "arXiv:2110.09434",
    "title": "Learning Realtime One-Counter Automata",
    "abstract": "We present a new learning algorithm for realtime one-counter automata. Our\nalgorithm uses membership and equivalence queries as in Angluin's L* algorithm,\nas well as counter value queries and partial equivalence queries. In a partial\nequivalence query, we ask the teacher whether the language of a given\nfinite-state automaton coincides with a counter-bounded subset of the target\nlanguage. We evaluate an implementation of our algorithm on a number of random\nbenchmarks and on a use case regarding efficient JSON-stream validation.",
    "descriptor": "\nComments: 55 pages, 9 figures, submitted to TACAS 2022\n",
    "authors": [
      "V\u00e9ronique Bruy\u00e8re",
      "Guillermo A. P\u00e9rez",
      "Ga\u00ebtan Staquet"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.09434"
  },
  {
    "id": "arXiv:2110.09436",
    "title": "Early Diagnostic Prediction of Covid-19 using Gradient-Boosting Machine  Model",
    "abstract": "With the huge spike in the COVID-19 cases across the globe and reverse\ntranscriptase-polymerase chain reaction (RT-PCR) test remains a key component\nfor rapid and accurate detection of severe acute respiratory syndrome\ncoronavirus 2 (SARS-CoV-2). In recent months there has been an acute shortage\nof medical supplies in developing countries, especially a lack of RT-PCR\ntesting resulting in delayed patient care and high infection rates. We present\na gradient-boosting machine model that predicts the diagnostics result of\nSARS-CoV- 2 in an RT-PCR test by utilizing eight binary features. We used the\npublicly available nationwide dataset released by the Israeli Ministry of\nHealth.",
    "descriptor": "\nComments: Presented at the Drexel Society of Artificial Intelligence Research Conference, 2021 (arXiv:2110.05263)\n",
    "authors": [
      "Satvik Tripathi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09436"
  },
  {
    "id": "arXiv:2110.09437",
    "title": "Ctrl-Shift: How Privacy Sentiment Changed from 2019 to 2021",
    "abstract": "People's privacy sentiments drive changes in legislation and may influence\ntheir willingness to use a variety of technologies. While single-point-in-time\ninvestigations of privacy sentiment offer useful insight, longitudinal study of\npeople's privacy sentiments is necessary to better understand and anticipate\nevolving privacy attitudes. In this work, we use longitudinal survey data\n(n=6,676) to model Americans' sentiments toward collection and use of data for\ngovernment- and health-related purposes in 2019, 2020 and 2021. After the onset\nof COVID-19, we observe significant changes in Americans' privacy sentiments\ntoward government- and health-related data uses and find that Americans'\nprivacy attitudes largely converged on these topics. We observe additional\nchanges in the context of other national events such as the U.S. presidential\nelections and Black Lives Matter protests. Our results offer insight into how\nprivacy attitudes may have been impacted by recent events, and these results\nallow us to identify potential predictors of changes in privacy attitudes\nduring times of geopolitical (e.g., global pandemic) or national (e.g.,\npolitical elections, the rise of the Black Lives Matter movement) change.",
    "descriptor": "",
    "authors": [
      "Angelica Goetzen",
      "Samuel Dooley",
      "Elissa M. Redmiles"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.09437"
  },
  {
    "id": "arXiv:2110.09441",
    "title": "FMFCC-A: A Challenging Mandarin Dataset for Synthetic Speech Detection",
    "abstract": "As increasing development of text-to-speech (TTS) and voice conversion (VC)\ntechnologies, the detection of synthetic speech has been suffered dramatically.\nIn order to promote the development of synthetic speech detection model against\nMandarin TTS and VC technologies, we have constructed a challenging Mandarin\ndataset and organized the accompanying audio track of the first fake media\nforensic challenge of China Society of Image and Graphics (FMFCC-A). The\nFMFCC-A dataset is by far the largest publicly-available Mandarin dataset for\nsynthetic speech detection, which contains 40,000 synthesized Mandarin\nutterances that generated by 11 Mandarin TTS systems and two Mandarin VC\nsystems, and 10,000 genuine Mandarin utterances collected from 58 speakers. The\nFMFCC-A dataset is divided into the training, development and evaluation sets,\nwhich are used for the research of detection of synthesized Mandarin speech\nunder various previously unknown speech synthesis systems or audio\npost-processing operations. In addition to describing the construction of the\nFMFCC-A dataset, we provide a detailed analysis of two baseline methods and the\ntop-performing submissions from the FMFCC-A, which illustrates the usefulness\nand challenge of FMFCC-A dataset. We hope that the FMFCC-A dataset can fill the\ngap of lack of Mandarin datasets for synthetic speech detection.",
    "descriptor": "",
    "authors": [
      "Zhenyu Zhang",
      "Yewei Gu",
      "Xiaowei Yi",
      "Xianfeng Zhao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.09441"
  },
  {
    "id": "arXiv:2110.09442",
    "title": "Goal Agnostic Planning using Maximum Likelihood Paths in Hypergraph  World Models",
    "abstract": "In this paper, we present a hypergraph--based machine learning algorithm, a\ndatastructure--driven maintenance method, and a planning algorithm based on a\nprobabilistic application of Dijkstra's algorithm. Together, these form a goal\nagnostic automated planning engine for an autonomous learning agent which\nincorporates beneficial properties of both classical Machine Learning and\ntraditional Artificial Intelligence. We prove that the algorithm determines\noptimal solutions within the problem space, mathematically bound learning\nperformance, and supply a mathematical model analyzing system state progression\nthrough time yielding explicit predictions for learning curves, goal\nachievement rates, and response to abstractions and uncertainty. To validate\nperformance, we exhibit results from applying the agent to three archetypal\nplanning problems, including composite hierarchical domains, and highlight\nempirical findings which illustrate properties elucidated in the analysis.",
    "descriptor": "\nComments: 58 pages, 27 figures, comments\n",
    "authors": [
      "Christopher Robinson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09442"
  },
  {
    "id": "arXiv:2110.09443",
    "title": "Beltrami Flow and Neural Diffusion on Graphs",
    "abstract": "We propose a novel class of graph neural networks based on the discretised\nBeltrami flow, a non-Euclidean diffusion PDE. In our model, node features are\nsupplemented with positional encodings derived from the graph topology and\njointly evolved by the Beltrami flow, producing simultaneously continuous\nfeature learning and topology evolution. The resulting model generalises many\npopular graph neural networks and achieves state-of-the-art results on several\nbenchmarks.",
    "descriptor": "\nComments: 21 pages, 5 figures. Proceedings of the Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS) 2021\n",
    "authors": [
      "Benjamin Paul Chamberlain",
      "James Rowbottom",
      "Davide Eynard",
      "Francesco Di Giovanni",
      "Xiaowen Dong",
      "Michael M Bronstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.09443"
  },
  {
    "id": "arXiv:2110.09446",
    "title": "Squeezing Backbone Feature Distributions to the Max for Efficient  Few-Shot Learning",
    "abstract": "Few-shot classification is a challenging problem due to the uncertainty\ncaused by using few labelled samples. In the past few years, many methods have\nbeen proposed with the common aim of transferring knowledge acquired on a\npreviously solved task, what is often achieved by using a pretrained feature\nextractor. Following this vein, in this paper we propose a novel transfer-based\nmethod which aims at processing the feature vectors so that they become closer\nto Gaussian-like distributions, resulting in increased accuracy. In the case of\ntransductive few-shot learning where unlabelled test samples are available\nduring training, we also introduce an optimal-transport inspired algorithm to\nboost even further the achieved performance. Using standardized vision\nbenchmarks, we show the ability of the proposed methodology to achieve\nstate-of-the-art accuracy with various datasets, backbone architectures and\nfew-shot settings.",
    "descriptor": "\nComments: Init commit. arXiv admin note: text overlap with arXiv:2006.03806\n",
    "authors": [
      "Yuqing Hu",
      "Vincent Gripon",
      "St\u00e9phane Pateux"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09446"
  },
  {
    "id": "arXiv:2110.09452",
    "title": "SPAP: Simultaneous Demand Prediction and Planning for Electric Vehicle  Chargers in a New City",
    "abstract": "For a new city that is committed to promoting Electric Vehicles (EVs), it is\nsignificant to plan the public charging infrastructure where charging demands\nare high. However, it is difficult to predict charging demands before the\nactual deployment of EV chargers for lack of operational data, resulting in a\ndeadlock. A direct idea is to leverage the urban transfer learning paradigm to\nlearn the knowledge from a source city, then exploit it to predict charging\ndemands, and meanwhile determine locations and amounts of slow/fast chargers\nfor charging stations in the target city. However, the demand prediction and\ncharger planning depend on each other, and it is required to re-train the\nprediction model to eliminate the negative transfer between cities for each\nvaried charger plan, leading to the unacceptable time complexity. To this end,\nwe propose the concept and an effective solution of Simultaneous Demand\nPrediction And Planning (SPAP): discriminative features are extracted from\nmulti-source data, and fed into an Attention-based Spatial-Temporal City Domain\nAdaptation Network (AST-CDAN) for cross-city demand prediction; a novel\nTransfer Iterative Optimization (TIO) algorithm is designed for charger\nplanning by iteratively utilizing AST-CDAN and a charger plan fine-tuning\nalgorithm. Extensive experiments on real-world datasets collected from three\ncities in China validate the effectiveness and efficiency of SPAP. Specially,\nSPAP improves at most 72.5% revenue compared with the real-world charger\ndeployment.",
    "descriptor": "",
    "authors": [
      "Yizong Wang",
      "Dong Zhao",
      "Yajie Ren",
      "Desheng Zhang",
      "Huadong Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09452"
  },
  {
    "id": "arXiv:2110.09453",
    "title": "A New Approach to Complex Dynamic Geofencing for Unmanned Aerial  Vehicles",
    "abstract": "The anticipated widespread use of unmanned aerial vehicles (UAVs) raises\nsignificant safety and security concerns, including trespassing in restricted\nareas, colliding with other UAVs, and disrupting high-traffic airspaces. To\nmitigate these risks, geofences have been proposed as one line of defence,\nwhich limit UAVs from flying into the perimeters of other UAVs and restricted\nlocations. In this paper, we address the concern that existing geometric\ngeofencing algorithms lack accuracy during the calculation of complex\ngeofences, particularly in dynamic urban environments. We propose a new\nalgorithm based on alpha shapes and Voronoi diagrams, which we integrate into\nan on-drone framework using an open-source mapping database from OpenStreetMap.\nTo demonstrate its efficacy, we present performance results using Microsoft's\nAirSim and a low-cost commercial UAV platform in a real-world urban\nenvironment.",
    "descriptor": "\nComments: Accepted to the 40th IEEE Digital Avionics Systems Conference\n",
    "authors": [
      "Vihangi Vagal",
      "Konstantinos Markantonakis",
      "Carlton Shepherd"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2110.09453"
  },
  {
    "id": "arXiv:2110.09454",
    "title": "SentimentArcs: A Novel Method for Self-Supervised Sentiment Analysis of  Time Series Shows SOTA Transformers Can Struggle Finding Narrative Arcs",
    "abstract": "SOTA Transformer and DNN short text sentiment classifiers report over 97%\naccuracy on narrow domains like IMDB movie reviews. Real-world performance is\nsignificantly lower because traditional models overfit benchmarks and\ngeneralize poorly to different or more open domain texts. This paper introduces\nSentimentArcs, a new self-supervised time series sentiment analysis methodology\nthat addresses the two main limitations of traditional supervised sentiment\nanalysis: limited labeled training datasets and poor generalization. A large\nensemble of diverse models provides a synthetic ground truth for\nself-supervised learning. Novel metrics jointly optimize an exhaustive search\nacross every possible corpus:model combination. The joint optimization over\nboth the corpus and model solves the generalization problem. Simple\nvisualizations exploit the temporal structure in narratives so domain experts\ncan quickly spot trends, identify key features, and note anomalies over\nhundreds of arcs and millions of data points. To our knowledge, this is the\nfirst self-supervised method for time series sentiment analysis and the largest\nsurvey directly comparing real-world model performance on long-form narratives.",
    "descriptor": "\nComments: 87 pages, 97 figures\n",
    "authors": [
      "Jon Chun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09454"
  },
  {
    "id": "arXiv:2110.09455",
    "title": "TLDR: Twin Learning for Dimensionality Reduction",
    "abstract": "Dimensionality reduction methods are unsupervised approaches which learn\nlow-dimensional spaces where some properties of the initial space, typically\nthe notion of \"neighborhood\", are preserved. They are a crucial component of\ndiverse tasks like visualization, compression, indexing, and retrieval. Aiming\nfor a totally different goal, self-supervised visual representation learning\nhas been shown to produce transferable representation functions by learning\nmodels that encode invariance to artificially created distortions, e.g. a set\nof hand-crafted image transformations. Unlike manifold learning methods that\nusually require propagation on large k-NN graphs or complicated optimization\nsolvers, self-supervised learning approaches rely on simpler and more scalable\nframeworks for learning. In this paper, we unify these two families of\napproaches from the angle of manifold learning and propose TLDR, a\ndimensionality reduction method for generic input spaces that is porting the\nsimple self-supervised learning framework of Barlow Twins to a setting where it\nis hard or impossible to define an appropriate set of distortions by hand. We\npropose to use nearest neighbors to build pairs from a training set and a\nredundancy reduction loss borrowed from the self-supervised literature to learn\nan encoder that produces representations invariant across such pairs. TLDR is a\nmethod that is simple, easy to implement and train, and of broad applicability;\nit consists of an offline nearest neighbor computation step that can be highly\napproximated, and a straightforward learning process that does not require\nmining negative samples to contrast, eigendecompositions, or cumbersome\noptimization solvers. By replacing PCA with TLDR, we are able to increase the\nperformance of GeM-AP by 4% mAP for 128 dimensions, and to retain its\nperformance with 16x fewer dimensions.",
    "descriptor": "\nComments: Code available at: this https URL\n",
    "authors": [
      "Yannis Kalantidis",
      "Carlos Lassance",
      "Jon Almazan",
      "Diane Larlus"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09455"
  },
  {
    "id": "arXiv:2110.09456",
    "title": "NormFormer: Improved Transformer Pretraining with Extra Normalization",
    "abstract": "During pretraining, the Pre-LayerNorm transformer suffers from a gradient\nmagnitude mismatch: gradients at early layers are much larger than at later\nlayers. These issues can be alleviated by our proposed NormFormer architecture,\nwhich adds three normalization operations to each layer: a Layer Norm after\nself attention, head-wise scaling of self-attention outputs, and a Layer Norm\nafter the first fully connected layer. The extra operations incur negligible\ncompute cost (+0.4% parameter increase), but improve pretraining perplexity and\ndownstream task performance for both causal and masked language models ranging\nfrom 125 Million to 2.7 Billion parameters. For example, adding NormFormer on\ntop of our strongest 1.3B parameter baseline can reach equal perplexity 24%\nfaster, or converge 0.27 perplexity better in the same compute budget. This\nmodel reaches GPT3-Large (1.3B) zero shot performance 60% faster. For masked\nlanguage modeling, NormFormer improves fine-tuned GLUE performance by 1.9% on\naverage. Code to train NormFormer models is available in fairseq\nhttps://github.com/pytorch/fairseq/tree/main/examples/normformer .",
    "descriptor": "",
    "authors": [
      "Sam Shleifer",
      "Jason Weston",
      "Myle Ott"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09456"
  },
  {
    "id": "arXiv:2110.09460",
    "title": "FAR Planner: Fast, Attemptable Route Planner using Dynamic Visibility  Update",
    "abstract": "We present our work on a fast route planner based on visibility graph. The\nmethod extracts edge points around obstacles in the environment to form\npolygons, with which, the method dynamically updates a global visibility graph,\nexpanding the visibility graph along with the navigation and removing edges\nthat become occluded by dynamic obstacles. When guiding a vehicle to the goal,\nthe method can deal with both known and unknown environments. In the latter\ncase, the method is attemptable in discovering a way to the goal by picking up\nthe environment layout on the fly. We evaluate the method using both ground and\naerial vehicles, in simulated and real-world settings. In highly convoluted\nunknown or partially known environments, our method is able to reduce travel\ntime by 13-27% compared to RRT*, RRT-Connect, A*, and D* Lite, and finds a path\nwithin 3ms in all of our experiments.",
    "descriptor": "\nComments: This paper has been submitted to ICRA 2022 and is currently under review\n",
    "authors": [
      "Fan Yang",
      "Chao Cao",
      "Hongbiao Zhu",
      "Jean Oh",
      "Ji Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.09460"
  },
  {
    "id": "arXiv:2110.09461",
    "title": "In a Nutshell, the Human Asked for This: Latent Goals for Following  Temporal Specifications",
    "abstract": "We address the problem of building agents whose goal is to satisfy out-of\ndistribution (OOD) multi-task instructions expressed in temporal logic (TL) by\nusing deep reinforcement learning (DRL). Recent works provided evidence that\nthe deep learning architecture is a key feature when teaching a DRL agent to\nsolve OOD tasks in TL. Yet, the studies on their performance are still limited.\nIn this work, we analyse various state-of-the-art (SOTA) architectures that\ninclude generalisation mechanisms such as relational layers, the soft-attention\nmechanism, or hierarchical configurations, when generalising safety-aware tasks\nexpressed in TL. Most importantly, we present a novel deep learning\narchitecture that induces agents to generate latent representations of their\ncurrent goal given both the human instruction and the current observation from\nthe environment. We find that applying our proposed configuration to SOTA\narchitectures yields significantly stronger performance when executing new\ntasks in OOD environments.",
    "descriptor": "",
    "authors": [
      "Borja G. Le\u00f3n",
      "Murray Shanahan",
      "Francesco Belardinelli"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09461"
  },
  {
    "id": "arXiv:2110.09467",
    "title": "On Predictive Explanation of Data Anomalies",
    "abstract": "Numerous algorithms have been proposed for detecting anomalies (outliers,\nnovelties) in an unsupervised manner. Unfortunately, it is not trivial, in\ngeneral, to understand why a given sample (record) is labelled as an anomaly\nand thus diagnose its root causes. We propose the following\nreduced-dimensionality, surrogate model approach to explain detector decisions:\napproximate the detection model with another one that employs only a small\nsubset of features. Subsequently, samples can be visualized in this\nlow-dimensionality space for human understanding. To this end, we develop\nPROTEUS, an AutoML pipeline to produce the surrogate model, specifically\ndesigned for feature selection on imbalanced datasets. The PROTEUS surrogate\nmodel can not only explain the training data, but also the out-of-sample\n(unseen) data. In other words, PROTEUS produces predictive explanations by\napproximating the decision surface of an unsupervised detector. PROTEUS is\ndesigned to return an accurate estimate of out-of-sample predictive performance\nto serve as a metric of the quality of the approximation. Computational\nexperiments confirm the efficacy of PROTEUS to produce predictive explanations\nfor different families of detectors and to reliably estimate their predictive\nperformance in unseen data. Unlike several ad-hoc feature importance methods,\nPROTEUS is robust to high-dimensional data.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Nikolaos Myrtakis",
      "Ioannis Tsamardinos",
      "Vassilis Christophides"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09467"
  },
  {
    "id": "arXiv:2110.09468",
    "title": "Improving Robustness using Generated Data",
    "abstract": "Recent work argues that robust training requires substantially larger\ndatasets than those required for standard classification. On CIFAR-10 and\nCIFAR-100, this translates into a sizable robust-accuracy gap between models\ntrained solely on data from the original training set and those trained with\nadditional data extracted from the \"80 Million Tiny Images\" dataset (TI-80M).\nIn this paper, we explore how generative models trained solely on the original\ntraining set can be leveraged to artificially increase the size of the original\ntraining set and improve adversarial robustness to $\\ell_p$ norm-bounded\nperturbations. We identify the sufficient conditions under which incorporating\nadditional generated data can improve robustness, and demonstrate that it is\npossible to significantly reduce the robust-accuracy gap to models trained with\nadditional real data. Surprisingly, we even show that even the addition of\nnon-realistic random data (generated by Gaussian sampling) can improve\nrobustness. We evaluate our approach on CIFAR-10, CIFAR-100, SVHN and\nTinyImageNet against $\\ell_\\infty$ and $\\ell_2$ norm-bounded perturbations of\nsize $\\epsilon = 8/255$ and $\\epsilon = 128/255$, respectively. We show large\nabsolute improvements in robust accuracy compared to previous state-of-the-art\nmethods. Against $\\ell_\\infty$ norm-bounded perturbations of size $\\epsilon =\n8/255$, our models achieve 66.10% and 33.49% robust accuracy on CIFAR-10 and\nCIFAR-100, respectively (improving upon the state-of-the-art by +8.96% and\n+3.29%). Against $\\ell_2$ norm-bounded perturbations of size $\\epsilon =\n128/255$, our model achieves 78.31% on CIFAR-10 (+3.81%). These results beat\nmost prior works that use external data.",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Sven Gowal",
      "Sylvestre-Alvise Rebuffi",
      "Olivia Wiles",
      "Florian Stimberg",
      "Dan Andrei Calian",
      "Timothy Mann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.09468"
  },
  {
    "id": "arXiv:2110.09470",
    "title": "No RL, No Simulation: Learning to Navigate without Navigating",
    "abstract": "Most prior methods for learning navigation policies require access to\nsimulation environments, as they need online policy interaction and rely on\nground-truth maps for rewards. However, building simulators is expensive\n(requires manual effort for each and every scene) and creates challenges in\ntransferring learned policies to robotic platforms in the real-world, due to\nthe sim-to-real domain gap. In this paper, we pose a simple question: Do we\nreally need active interaction, ground-truth maps or even\nreinforcement-learning (RL) in order to solve the image-goal navigation task?\nWe propose a self-supervised approach to learn to navigate from only passive\nvideos of roaming. Our approach, No RL, No Simulator (NRNS), is simple and\nscalable, yet highly effective. NRNS outperforms RL-based formulations by a\nsignificant margin. We present NRNS as a strong baseline for any future\nimage-based navigation tasks that use RL or Simulation.",
    "descriptor": "",
    "authors": [
      "Meera Hahn",
      "Devendra Chaplot",
      "Shubham Tulsiani",
      "Mustafa Mukadam",
      "James M. Rehg",
      "Abhinav Gupta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09470"
  },
  {
    "id": "arXiv:2110.09471",
    "title": "Scaling and Placing Distributed Services on Vehicle Clusters in Urban  Environments",
    "abstract": "Many vehicles spend a significant amount of time in urban traffic congestion.\nDue to the evolution of autonomous cars, driver assistance systems, and\nin-vehicle entertainment, many vehicles have plentiful computational and\ncommunication capacity. How can we deploy data collection and processing tasks\non these (slowly) moving vehicles to productively use any spare resources? To\nanswer this question, we study the efficient placement of distributed services\non a moving vehicle cluster. We present a macroscopic flow model for an\nintersection in Dublin, Ireland, using real vehicle density data. We show that\nsuch aggregate flows are highly predictable (even though the paths of\nindividual vehicles are not known in advance), making it viable to deploy\nservices harnessing vehicles' sensing capabilities. Our main contribution is a\ndetailed mathematical specification for a task-based, distributed service\nplacement model that scales according to the resource requirements and is\nrobust to the changes caused by the mobility of the cluster. We formulate this\nas a constrained optimization problem, with the objective of minimizing overall\nprocessing and communication costs. Our results show that jointly scaling tasks\nand finding a mobility-aware, optimal placement results in reduced processing\nand communication costs compared to an autonomous vehicular edge\ncomputing-based na\\\"{i}ve solution.",
    "descriptor": "\nComments: 16 pages, 15 Figures\n",
    "authors": [
      "Kanika Sharma",
      "Bernard Butler",
      "Brendan Jennings"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.09471"
  },
  {
    "id": "arXiv:2110.09474",
    "title": "Trajectory Optimization for Thermally-Actuated Soft Planar Robot Limbs",
    "abstract": "Practical use of robotic manipulators made from soft materials will require\nplanning for complex motions. We present the first approach for generating\ntrajectories of a thermally-actuated soft robotic manipulator. Based on\nsimplified approximations of the soft arm and its shape-memory-alloy (SMA)\nwires, we justify a dynamics model of a discretized rigid manipulator with\njoint torques proportional to wire temperature. Then, we propose a method to\ncalibrate this model from hardware data, and demonstrate that the simulation\naligns well with a test trajectory. Finally, we use direct collocation\ntrajectory optimization with the non-linear dynamics to derive open-loop\ncontrols for feasible trajectories that closely align with desired reference\ninputs. Two example trajectories are verified in hardware. The results show\npromise for both open-loop planning as well as for future applications with\nfeedback.",
    "descriptor": "\nComments: 8 pages, 6 figures, submitted to IEEE RA-L & Robosoft conference\n",
    "authors": [
      "Anthony Wertz",
      "Andrew P. Sabelhaus",
      "Carmel Majidi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.09474"
  },
  {
    "id": "arXiv:2110.09476",
    "title": "Recovery Guarantees for Kernel-based Clustering under Non-parametric  Mixture Models",
    "abstract": "Despite the ubiquity of kernel-based clustering, surprisingly few statistical\nguarantees exist beyond settings that consider strong structural assumptions on\nthe data generation process. In this work, we take a step towards bridging this\ngap by studying the statistical performance of kernel-based clustering\nalgorithms under non-parametric mixture models. We provide necessary and\nsufficient separability conditions under which these algorithms can\nconsistently recover the underlying true clustering. Our analysis provides\nguarantees for kernel clustering approaches without structural assumptions on\nthe form of the component distributions. Additionally, we establish a key\nequivalence between kernel-based data-clustering and kernel density-based\nclustering. This enables us to provide consistency guarantees for kernel-based\nestimators of non-parametric mixture models. Along with theoretical\nimplications, this connection could have practical implications, including in\nthe systematic choice of the bandwidth of the Gaussian kernel in the context of\nclustering.",
    "descriptor": "",
    "authors": [
      "Leena Chennuru Vankadara",
      "Sebastian Bordt",
      "Ulrike von Luxburg",
      "Debarghya Ghoshdastidar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.09476"
  },
  {
    "id": "arXiv:2110.09481",
    "title": "MTP: Multi-Hypothesis Tracking and Prediction for Reduced Error  Propagation",
    "abstract": "Recently, there has been tremendous progress in developing each individual\nmodule of the standard perception-planning robot autonomy pipeline, including\ndetection, tracking, prediction of other agents' trajectories, and ego-agent\ntrajectory planning. Nevertheless, there has been less attention given to the\nprincipled integration of these components, particularly in terms of the\ncharacterization and mitigation of cascading errors. This paper addresses the\nproblem of cascading errors by focusing on the coupling between the tracking\nand prediction modules. First, by using state-of-the-art tracking and\nprediction tools, we conduct a comprehensive experimental evaluation of how\nseverely errors stemming from tracking can impact prediction performance. On\nthe KITTI and nuScenes datasets, we find that predictions consuming tracked\ntrajectories as inputs (the typical case in practice) can experience a\nsignificant (even order of magnitude) drop in performance in comparison to the\nidealized setting where ground truth past trajectories are used as inputs. To\naddress this issue, we propose a multi-hypothesis tracking and prediction\nframework. Rather than relying on a single set of tracking results for\nprediction, our framework simultaneously reasons about multiple sets of\ntracking results, thereby increasing the likelihood of including accurate\ntracking results as inputs to prediction. We show that this framework improves\noverall prediction performance over the standard single-hypothesis\ntracking-prediction pipeline by up to 34.2% on the nuScenes dataset, with even\nmore significant improvements (up to ~70%) when restricting the evaluation to\nchallenging scenarios involving identity switches and fragments -- all with an\nacceptable computation overhead.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Xinshuo Weng",
      "Boris Ivanovic",
      "Marco Pavone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.09481"
  },
  {
    "id": "arXiv:2110.09482",
    "title": "Self-Supervised Monocular DepthEstimation with Internal Feature Fusion",
    "abstract": "Self-supervised learning for depth estimation uses geometry in image\nsequences for supervision and shows promising results. Like many computer\nvision tasks, depth network performance is determined by the capability to\nlearn accurate spatial and semantic representations from images. Therefore, it\nis natural to exploit semantic segmentation networks for depth estimation. In\nthis work, based on a well-developed semantic segmentation network HRNet, we\npropose a novel depth estimation networkDIFFNet, which can make use of semantic\ninformation in down and upsampling procedures. By applying feature fusion and\nan attention mechanism, our proposed method outperforms the state-of-the-art\nmonocular depth estimation methods on the KITTI benchmark. Our method also\ndemonstrates greater potential on higher resolution training data. We propose\nan additional extended evaluation strategy by establishing a test set of\nchallenging cases, empirically derived from the standard benchmark.",
    "descriptor": "",
    "authors": [
      "Hang Zhou",
      "David Greenwood",
      "Sarah Taylor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09482"
  },
  {
    "id": "arXiv:2110.09485",
    "title": "Learning in High Dimension Always Amounts to Extrapolation",
    "abstract": "The notion of interpolation and extrapolation is fundamental in various\nfields from deep learning to function approximation. Interpolation occurs for a\nsample $x$ whenever this sample falls inside or on the boundary of the given\ndataset's convex hull. Extrapolation occurs when $x$ falls outside of that\nconvex hull. One fundamental (mis)conception is that state-of-the-art\nalgorithms work so well because of their ability to correctly interpolate\ntraining data. A second (mis)conception is that interpolation happens\nthroughout tasks and datasets, in fact, many intuitions and theories rely on\nthat assumption. We empirically and theoretically argue against those two\npoints and demonstrate that on any high-dimensional ($>$100) dataset,\ninterpolation almost surely never happens. Those results challenge the validity\nof our current interpolation/extrapolation definition as an indicator of\ngeneralization performances.",
    "descriptor": "",
    "authors": [
      "Randall Balestriero",
      "Jerome Pesenti",
      "Yann LeCun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09485"
  },
  {
    "id": "arXiv:2110.09490",
    "title": "Unsupervised Image Fusion Using Deep Image Priors",
    "abstract": "A significant number of researchers have recently applied deep learning\nmethods to image fusion. However, most of these works either require a large\namount of training data or depend on pre-trained models or frameworks. This\ninevitably encounters a shortage of training data or a mismatch between the\nframework and the actual problem. Recently, the publication of Deep Image Prior\n(DIP) method made it possible to do image restoration totally\ntraining-data-free. However, the original design of DIP is hard to be\ngeneralized to multi-image processing problems. This paper introduces a novel\nloss calculation structure, in the framework of DIP, while formulating image\nfusion as an inverse problem. This enables the extension of DIP to general\nmultisensor/multifocus image fusion problems. Secondly, we propose a\nmulti-channel approach to improve the effect of DIP. Finally, an evaluation is\nconducted using several commonly used image fusion assessment metrics. The\nresults are compared with state-of-the-art traditional and deep learning image\nfusion methods. Our method outperforms previous techniques for a range of\nmetrics. In particular, it is shown to provide the best objective results for\nmost metrics when applied to medical images.",
    "descriptor": "",
    "authors": [
      "Xudong Ma",
      "Alin Achim",
      "Paul Hill"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09490"
  },
  {
    "id": "arXiv:2110.09495",
    "title": "Protecting Anonymous Speech: A Generative Adversarial Network  Methodology for Removing Stylistic Indicators in Text",
    "abstract": "With Internet users constantly leaving a trail of text, whether through\nblogs, emails, or social media posts, the ability to write and protest\nanonymously is being eroded because artificial intelligence, when given a\nsample of previous work, can match text with its author out of hundreds of\npossible candidates. Existing approaches to authorship anonymization, also\nknown as authorship obfuscation, often focus on protecting binary demographic\nattributes rather than identity as a whole. Even those that do focus on\nobfuscating identity require manual feedback, lose the coherence of the\noriginal sentence, or only perform well given a limited subset of authors. In\nthis paper, we develop a new approach to authorship anonymization by\nconstructing a generative adversarial network that protects identity and\noptimizes for three different losses corresponding to anonymity, fluency, and\ncontent preservation. Our fully automatic method achieves comparable results to\nother methods in terms of content preservation and fluency, but greatly\noutperforms baselines in regards to anonymization. Moreover, our approach is\nable to generalize well to an open-set context and anonymize sentences from\nauthors it has not encountered before.",
    "descriptor": "",
    "authors": [
      "Rishi Balakrishnan",
      "Stephen Sloan",
      "Anil Aswani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.09495"
  },
  {
    "id": "arXiv:2110.09504",
    "title": "The complexity of the Quantified CSP having the polynomially generated  powers property",
    "abstract": "It is known that if an algebra of polymorphisms of the constraint language\nhas the Polynomially Generated Powers (PGP) Property then the Quantified CSP\ncan be reduced to the CSP over the same constraint language with constants. The\nonly limitation of this reduction is that it is applicable only for the\nconstraint languages with constants. We drastically simplified the reduction\nand generalized it for constraint languages without constants. As a result, we\ncompletely classified the complexity of the QCSP for constraint languages\nhaving the PGP property.",
    "descriptor": "",
    "authors": [
      "Dmitriy Zhuk"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.09504"
  },
  {
    "id": "arXiv:2110.09506",
    "title": "MEMO: Test Time Robustness via Adaptation and Augmentation",
    "abstract": "While deep neural networks can attain good accuracy on in-distribution test\npoints, many applications require robustness even in the face of unexpected\nperturbations in the input, changes in the domain, or other sources of\ndistribution shift. We study the problem of test time robustification, i.e.,\nusing the test input to improve model robustness. Recent prior works have\nproposed methods for test time adaptation, however, they each introduce\nadditional assumptions, such as access to multiple test points, that prevent\nwidespread adoption. In this work, we aim to study and devise methods that make\nno assumptions about the model training process and are broadly applicable at\ntest time. We propose a simple approach that can be used in any test setting\nwhere the model is probabilistic and adaptable: when presented with a test\nexample, perform different data augmentations on the data point, and then adapt\n(all of) the model parameters by minimizing the entropy of the model's average,\nor marginal, output distribution across the augmentations. Intuitively, this\nobjective encourages the model to make the same prediction across different\naugmentations, thus enforcing the invariances encoded in these augmentations,\nwhile also maintaining confidence in its predictions. In our experiments, we\ndemonstrate that this approach consistently improves robust ResNet and vision\ntransformer models, achieving accuracy gains of 1-8% over standard model\nevaluation and also generally outperforming prior augmentation and adaptation\nstrategies. We achieve state-of-the-art results for test shifts caused by image\ncorruptions (ImageNet-C), renditions of common objects (ImageNet-R), and, among\nResNet-50 models, adversarially chosen natural examples (ImageNet-A).",
    "descriptor": "",
    "authors": [
      "Marvin Zhang",
      "Sergey Levine",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09506"
  },
  {
    "id": "arXiv:2110.09507",
    "title": "Provable Hierarchy-Based Meta-Reinforcement Learning",
    "abstract": "Hierarchical reinforcement learning (HRL) has seen widespread interest as an\napproach to tractable learning of complex modular behaviors. However, existing\nwork either assume access to expert-constructed hierarchies, or use\nhierarchy-learning heuristics with no provable guarantees. To address this gap,\nwe analyze HRL in the meta-RL setting, where a learner learns latent\nhierarchical structure during meta-training for use in a downstream task. We\nconsider a tabular setting where natural hierarchical structure is embedded in\nthe transition dynamics. Analogous to supervised meta-learning theory, we\nprovide \"diversity conditions\" which, together with a tractable optimism-based\nalgorithm, guarantee sample-efficient recovery of this natural hierarchy.\nFurthermore, we provide regret bounds on a learner using the recovered\nhierarchy to solve a meta-test task. Our bounds incorporate common notions in\nHRL literature such as temporal and state/action abstractions, suggesting that\nour setting and analysis capture important features of HRL in practice.",
    "descriptor": "",
    "authors": [
      "Kurtland Chua",
      "Qi Lei",
      "Jason D. Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.09507"
  },
  {
    "id": "arXiv:2110.09508",
    "title": "Deep CNNs for Peripheral Blood Cell Classification",
    "abstract": "The application of machine learning techniques to the medical domain is\nespecially challenging due to the required level of precision and the\nincurrence of huge risks of minute errors. Employing these techniques to a more\ncomplex subdomain of hematological diagnosis seems quite promising, with\nautomatic identification of blood cell types, which can help in detection of\nhematologic disorders. In this paper, we benchmark 27 popular deep\nconvolutional neural network architectures on the microscopic peripheral blood\ncell images dataset. The dataset is publicly available, with large number of\nnormal peripheral blood cells acquired using the CellaVision DM96 analyzer and\nidentified by expert pathologists into eight different cell types. We fine-tune\nthe state-of-the-art image classification models pre-trained on the ImageNet\ndataset for blood cell classification. We exploit data augmentation techniques\nduring training to avoid overfitting and achieve generalization. An ensemble of\nthe top performing models obtains significant improvements over past published\nworks, achieving the state-of-the-art results with a classification accuracy of\n99.51%. Our work provides empirical baselines and benchmarks on standard\ndeep-learning architectures for microscopic peripheral blood cell recognition\ntask.",
    "descriptor": "\nComments: 20 pages, 14 figures, Submitted at MIDL 2021\n",
    "authors": [
      "Ekta Gavas",
      "Kaustubh Olpadkar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09508"
  },
  {
    "id": "arXiv:2110.09510",
    "title": "Unsupervised Finetuning",
    "abstract": "This paper studies \"unsupervised finetuning\", the symmetrical problem of the\nwell-known \"supervised finetuning\". Given a pretrained model and small-scale\nunlabeled target data, unsupervised finetuning is to adapt the representation\npretrained from the source domain to the target domain so that better transfer\nperformance can be obtained. This problem is more challenging than the\nsupervised counterpart, as the low data density in the small-scale target data\nis not friendly for unsupervised learning, leading to the damage of the\npretrained representation and poor representation in the target domain. In this\npaper, we find the source data is crucial when shifting the finetuning paradigm\nfrom supervise to unsupervise, and propose two simple and effective strategies\nto combine source and target data into unsupervised finetuning: \"sparse source\ndata replaying\", and \"data mixing\". The motivation of the former strategy is to\nadd a small portion of source data back to occupy their pretrained\nrepresentation space and help push the target data to reside in a smaller\ncompact space; and the motivation of the latter strategy is to increase the\ndata density and help learn more compact representation. To demonstrate the\neffectiveness of our proposed ``unsupervised finetuning'' strategy, we conduct\nextensive experiments on multiple different target datasets, which show better\ntransfer performance than the naive strategy.",
    "descriptor": "",
    "authors": [
      "Suichan Li",
      "Dongdong Chen",
      "Yinpeng Chen",
      "Lu Yuan",
      "Lei Zhang",
      "Qi Chu",
      "Bin Liu",
      "Nenghai Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09510"
  },
  {
    "id": "arXiv:2110.09514",
    "title": "Discovering and Achieving Goals via World Models",
    "abstract": "How can artificial agents learn to solve many diverse tasks in complex visual\nenvironments in the absence of any supervision? We decompose this question into\ntwo problems: discovering new goals and learning to reliably achieve them. We\nintroduce Latent Explorer Achiever (LEXA), a unified solution to these that\nlearns a world model from image inputs and uses it to train an explorer and an\nachiever policy from imagined rollouts. Unlike prior methods that explore by\nreaching previously visited states, the explorer plans to discover unseen\nsurprising states through foresight, which are then used as diverse targets for\nthe achiever to practice. After the unsupervised phase, LEXA solves tasks\nspecified as goal images zero-shot without any additional learning. LEXA\nsubstantially outperforms previous approaches to unsupervised goal-reaching,\nboth on prior benchmarks and on a new challenging benchmark with a total of 40\ntest tasks spanning across four standard robotic manipulation and locomotion\ndomains. LEXA further achieves goals that require interacting with multiple\nobjects in sequence. Finally, to demonstrate the scalability and generality of\nLEXA, we train a single general agent across four distinct environments. Code\nand videos at https://orybkin.github.io/lexa/",
    "descriptor": "\nComments: NeurIPS 2021. First two authors contributed equally. Website at this https URL\n",
    "authors": [
      "Russell Mendonca",
      "Oleh Rybkin",
      "Kostas Daniilidis",
      "Danijar Hafner",
      "Deepak Pathak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.09514"
  },
  {
    "id": "arXiv:2102.10663",
    "title": "MedAug: Contrastive learning leveraging patient metadata improves  representations for chest X-ray interpretation",
    "abstract": "Self-supervised contrastive learning between pairs of multiple views of the\nsame image has been shown to successfully leverage unlabeled data to produce\nmeaningful visual representations for both natural and medical images. However,\nthere has been limited work on determining how to select pairs for medical\nimages, where availability of patient metadata can be leveraged to improve\nrepresentations. In this work, we develop a method to select positive pairs\ncoming from views of possibly different images through the use of patient\nmetadata. We compare strategies for selecting positive pairs for chest X-ray\ninterpretation including requiring them to be from the same patient, imaging\nstudy or laterality. We evaluate downstream task performance by fine-tuning the\nlinear layer on 1% of the labeled dataset for pleural effusion classification.\nOur best performing positive pair selection strategy, which involves using\nimages from the same patient from the same study across all lateralities,\nachieves a performance increase of 14.4% in mean AUC from the ImageNet\npretrained baseline. Our controlled experiments show that the keys to improving\ndownstream performance on disease classification are (1) using patient metadata\nto appropriately create positive pairs from different images with the same\nunderlying pathologies, and (2) maximizing the number of different images used\nin query pairing. In addition, we explore leveraging patient metadata to select\nhard negative pairs for contrastive learning, but do not find improvement over\nbaselines that do not use metadata. Our method is broadly applicable to medical\nimage interpretation and allows flexibility for incorporating medical insights\nin choosing pairs for contrastive learning.",
    "descriptor": "",
    "authors": [
      "Yen Nhi Truong Vu",
      "Richard Wang",
      "Niranjan Balachandar",
      "Can Liu",
      "Andrew Y. Ng",
      "Pranav Rajpurkar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.10663"
  },
  {
    "id": "arXiv:2110.05925",
    "title": "Fast A Posteriori State Error Estimation for Reliable Frequency Sweeping  in Microwave Circuits via the Reduced-Basis Method",
    "abstract": "We develop a compact, reliable model order reduction approach for fast\nfrequency sweeps in microwave circuits by means of the reduced-basis method.\nContrary to what has been previously done, special emphasis is placed on\ncertifying the accuracy of the reduced-order model with respect to the original\nfull-order model in an effective and efficient way. Previous works on model\norder reduction accuracy certification rely on costly $\\textit{a posteriori}$\nerror estimators, which typically require expensive $\\textit{inf-sup}$ constant\nevaluations of the underlying full-order model. This scenario is often too\ntime-consuming and unaffordable in electromagnetic applications. As a result,\nless expensive and heuristic error estimators are commonly used instead. Very\noften, one is interested in knowing about the full state vector, instead of\njust some output quantities derived from the full state. Therefore, error\nestimators for the full state vector become relevant. In this work, we detail\nthe frequency behavior of both the electric field and the state error when an\napproximation to the electric field solution is carried out. Both field\nquantities share the same frequency behavior. Based on this observation, we\nfocus on the efficient estimation of the electric field state error and propose\na fast evaluation of the reduced-order model state error in the frequency band\nof analysis, minimizing the number of full-order model evaluations. This\nmethodology is of paramount importance to carry out a reliable fast frequency\nsweep in microwave circuits. Finally, real-life applications will illustrate\nthe capabilities and efficiency of the proposed approach.",
    "descriptor": "\nComments: 24 pages, 13 Figures, 6 Tables\n",
    "authors": [
      "Valentin de la Rubia",
      "Sridhar Chellappa",
      "Lihong Feng",
      "Peter Benner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2110.05925"
  },
  {
    "id": "arXiv:2110.06909",
    "title": "Reinforcement Learning for Standards Design",
    "abstract": "Communications standards are designed via committees of humans holding\nrepeated meetings over months or even years until consensus is achieved. This\nincludes decisions regarding the modulation and coding schemes to be supported\nover an air interface. We propose a way to \"automate\" the selection of the set\nof modulation and coding schemes to be supported over a given air interface and\nthereby streamline both the standards design process and the ease of extending\nthe standard to support new modulation schemes applicable to new higher-level\napplications and services. Our scheme involves machine learning, whereby a\nconstructor entity submits proposals to an evaluator entity, which returns a\nscore for the proposal. The constructor employs reinforcement learning to\niterate on its submitted proposals until a score is achieved that was\npreviously agreed upon by both constructor and evaluator to be indicative of\nsatisfying the required design criteria (including performance metrics for\ntransmissions over the interface).",
    "descriptor": "",
    "authors": [
      "Shahrukh Khan Kasi",
      "Sayandev Mukherjee",
      "Lin Cheng",
      "Bernardo A. Huberman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.06909"
  },
  {
    "id": "arXiv:2110.08295",
    "title": "Nonlinear proper orthogonal decomposition for convection-dominated flows",
    "abstract": "Autoencoder techniques find increasingly common use in reduced order modeling\nas a means to create a latent space. This reduced order representation offers a\nmodular data-driven modeling approach for nonlinear dynamical systems when\nintegrated with a time series predictive model. In this letter, we put forth a\nnonlinear proper orthogonal decomposition (POD) framework, which is an\nend-to-end Galerkin-free model combining autoencoders with long short-term\nmemory networks for dynamics. By eliminating the projection error due to the\ntruncation of Galerkin models, a key enabler of the proposed nonintrusive\napproach is the kinematic construction of a nonlinear mapping between the\nfull-rank expansion of the POD coefficients and the latent space where the\ndynamics evolve. We test our framework for model reduction of a\nconvection-dominated system, which is generally challenging for reduced order\nmodels. Our approach not only improves the accuracy, but also significantly\nreduces the computational cost of training and testing.",
    "descriptor": "",
    "authors": [
      "Shady E. Ahmed",
      "Omer San",
      "Adil Rasheed",
      "Traian Iliescu"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.08295"
  },
  {
    "id": "arXiv:2110.08298",
    "title": "Non-Euclidean Contractivity of Recurrent Neural Networks",
    "abstract": "Critical questions in neuroscience and machine learning can be addressed by\nestablishing strong stability, robustness, entrainment, and computational\nefficiency properties of neural network models. The usefulness of such strong\nproperties motivates the development of a comprehensive contractivity theory\nfor neural networks. This paper makes two sets of contributions. First, we\ndevelop novel general results on non-Euclidean matrix measures and nonsmooth\ncontraction theory. Regarding $\\ell_1/\\ell_\\infty$ matrix measures, we show\ntheir quasiconvexity with respect to positive diagonal weights, their\nmonotonicity with respect to principal submatrices, and provide closed form\nexpressions for certain matrix polytopes. These results motivate the\nintroduction of M-Hurwitz matrices, i.e., matrices whose Metzler majorant is\nHurwitz. Regarding nonsmooth contraction theory, we show that the one-sided\nLipschitz constant of a Lipschitz vector field is equal to the essential\nsupremum of the matrix measure of its Jacobian. Second, we apply these general\nresults to classes of recurrent neural circuits, including Hopfield, firing\nrate, Persidskii, Lur'e and other models. For each model, we compute the\noptimal contraction rate and weighted non-Euclidean norm via a linear program\nor, in some special cases, via an $M$-Hurwitz condition on the synaptic matrix.\nOur analysis establishes also absolute contraction and total contraction.",
    "descriptor": "",
    "authors": [
      "Alexander Davydov",
      "Anton V. Proskurnikov",
      "Francesco Bullo"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.08298"
  },
  {
    "id": "arXiv:2110.08311",
    "title": "Non-existing and ill-behaved coequalizers of locally ordered spaces",
    "abstract": "Categories of locally ordered spaces are especially well-adapted to the\nrealization of most precubical sets, though their colimits are not so easy to\ndetermine (in comparison with colimits in the category of d-spaces for\nexample). We use the plural here, as the notion of a locally ordered space vary\nfrom an author to another, only differing according to seemingly anodyne\ntechnical details. As we explain in this article, these differences have\ndramatic consequences on colimits. In particular, we show that most categories\nof locally ordered spaces are not cocomplete, thus answering a question that\nwas neglected so far. The strategy is the following: given a directed loop\n{\\gamma} on a locally ordered space X, we try to identify the image of {\\gamma}\nwith a single point. If it were taken in the category of d-spaces, such an\nidentification would be likely to create a vortex, while locally ordered spaces\nhave no vortices. Concretely, the antisymmetry of local orders gets more points\nto be identified than in a mere topological quotient. However, the effect of\nthis phenomenon is in some sense limited to the neighbourhood of (the image of)\n{\\gamma}. So the existence and the nature of the corresponding coequalizer\nstrongly depends on the topology around the image of {\\gamma}. As an extreme\nexample, if the latter forms a connected component, the coequalizer exists and\nits underlying space matches with the topological coequalizer.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Pierre-Yves Coursolle",
      "Emmanuel Haucourt"
    ],
    "subjectives": [
      "General Topology (math.GN)",
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2110.08311"
  },
  {
    "id": "arXiv:2110.08325",
    "title": "Minor Embedding in Broken Chimera and Pegasus Graphs is NP-complete",
    "abstract": "The embedding is an essential step when calculating on the D-Wave machine. In\nthis work we show the hardness of the embedding problem for both types of\nexisting hardware, represented by the Chimera and the Pegasus graphs,\ncontaining unavailable qubits. We construct certain broken Chimera graphs,\nwhere it is hard to find a Hamiltonian cycle. As the Hamiltonian cycle problem\nis a special case of the embedding problem, this proves the general complexity\nresult for the Chimera graphs. By exploiting the subgraph relation between the\nChimera and the Pegasus graphs, the proof is then further extended to the\nPegasus graphs.",
    "descriptor": "\nComments: 36 pages, 21 figures\n",
    "authors": [
      "Elisabeth Lobe",
      "Annette Lutz"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2110.08325"
  },
  {
    "id": "arXiv:2110.08341",
    "title": "Regional Stability Analysis of Transitional Fluid Flows",
    "abstract": "A method to bound the maximum energy perturbation for which regional\nstability of transitional fluid flow models can be guaranteed is introduced.\nThe proposed method exploits the fact that the fluid model's nonlinearities are\nboth lossless and locally bounded and uses the axes lengths of the ellipsoids\nfor the trajectory set containment as variables in the stability conditions.\nCompared to existing approaches, the proposed method leads to an average\nincrease in the maximum allowable energy perturbation of 29% for the\nWaleffe-KimHamilton (WKH) shear flow model and of 38% for the 9-state reduced\nmodel of Couette flow.",
    "descriptor": "\nComments: The paper is composed of 6 pages with 4 figures. It will be submitted to the IEEE Control Systems Letters (L-CSS)\n",
    "authors": [
      "Leonardo F. Toso",
      "Ross Drummond",
      "Stephen R. Duncan"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.08341"
  },
  {
    "id": "arXiv:2110.08342",
    "title": "Simple Periodic Boundary Conditions for Molecular Simulation of Uniaxial  Flow",
    "abstract": "We present rotating periodic boundary conditions (PBCs) for the simulation of\nnonequilibrium molecular dynamics (NEMD) under uniaxial stretching flow (USF)\nor biaxial stretching flow (BSF). Such nonequilibrium flows need specialized\nPBCs since the simulation box deforms with the background flow. The technique\nbuilds on previous models using one or lattice remappings, and is simpler than\nthe PBCs developed for the general three dimensional flow. For general three\ndimensional flows, Dobson \\cite{Dobson} and Hunt \\cite{Hunt} proposed schemes\nwhich are not time-periodic since they use more than one automorphism\nremapping. This paper presents a single automorphism remapping PBCs for USF and\nBSF which is time periodic up to a rotation matrix and has a better minimum\nlattice spacing properties.",
    "descriptor": "",
    "authors": [
      "Matthew Dobson",
      "Abdel Kader Geraldo"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.08342"
  },
  {
    "id": "arXiv:2110.08367",
    "title": "Dropping diversity of products of large US firms: Models and measures",
    "abstract": "It is widely assumed that in our lifetimes the products available in the\nglobal economy have become more diverse. This assumption is difficult to\ninvestigate directly, however, because it is difficult to collect the necessary\ndata about every product in an economy each year. We solve this problem by\nmining publicly available textual descriptions of the products of every large\nUS firms each year from 1997 to 2017. Although many aspects of economic\nproductivity have been steadily rising during this period, our text-based\nmeasurements show that the diversity of the products of at least large US firms\nhas steadily declined. This downward trend is visible using a variety of\nproduct diversity metrics, including some that depend on a measurement of the\nsimilarity of the products of every single pair of firms. The current state of\nthe art in comprehensive and detailed firm-similarity measurements is a Boolean\nword vector model due to Hoberg and Phillips. We measure diversity using\nfirm-similarities from this Boolean model and two more sophisticated variants,\nand we consistently observe a significant dropping trend in product diversity.\nThese results make it possible to frame and start to test specific hypotheses\nfor explaining the dropping product diversity trend.",
    "descriptor": "",
    "authors": [
      "Ananthan Nambiar",
      "Tobias Rubel",
      "James McCaull",
      "Jon deVries",
      "Mark Bedau"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08367"
  },
  {
    "id": "arXiv:2110.08407",
    "title": "Bridging the gap between paired and unpaired medical image translation",
    "abstract": "Medical image translation has the potential to reduce the imaging workload,\nby removing the need to capture some sequences, and to reduce the annotation\nburden for developing machine learning methods. GANs have been used\nsuccessfully to translate images from one domain to another, such as MR to CT.\nAt present, paired data (registered MR and CT images) or extra supervision\n(e.g. segmentation masks) is needed to learn good translation models.\nRegistering multiple modalities or annotating structures within each of them is\na tedious and laborious task. Thus, there is a need to develop improved\ntranslation methods for unpaired data. Here, we introduce modified pix2pix\nmodels for tasks CT$\\rightarrow$MR and MR$\\rightarrow$CT, trained with unpaired\nCT and MR data, and MRCAT pairs generated from the MR scans. The proposed\nmodifications utilize the paired MR and MRCAT images to ensure good alignment\nbetween input and translated images, and unpaired CT images ensure the\nMR$\\rightarrow$CT model produces realistic-looking CT and CT$\\rightarrow$MR\nmodel works well with real CT as input. The proposed pix2pix variants\noutperform baseline pix2pix, pix2pixHD and CycleGAN in terms of FID and KID,\nand generate more realistic looking CT and MR translations.",
    "descriptor": "\nComments: Deep Generative Models for MICCAI (DGM4MICCAI) workshop 2021\n",
    "authors": [
      "Pauliina Paavilainen",
      "Saad Ullah Akram",
      "Juho Kannala"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08407"
  },
  {
    "id": "arXiv:2110.08414",
    "title": "Quantum Error Correction with Reflexive Stabilizer Codes and Cayley  Graphs",
    "abstract": "Long distance communication of digital data, whether through a physical\nmedium or a broadcast signal, is often subjected to noise. To deliver data\nreliably through noisy communication channels, one must use codes that can\ndetect and correct the particular noise of the channel. For transmission of\nclassical data, error correcting schemes can be as simple as the sending of\nreplicates. For quantum data, and in tandem the development of machines that\ncan process quantum data, quantum error correcting codes must be developed. In\naddition to a larger set of possible errors, quantum error correcting schemes\nmust contend with other peculiarities of quantum mechanics, such as the\nno-cloning theorem which can prevent the sending of replicate messages.\nStabilizer codes are one family of quantum error correcting codes which can\nprotect and correct errors expressed in terms of the Pauli group, exploiting\nits group structure and utilizing classical codes and the corresponding duals.\nWe develop and examine a family of quantum stabilizer codes which arise from\nreflexive stabilizers. Moreover, we provide a mapping from our reflexive\nstabilizer codes to the well-known CSS codes developed by Calderbank, Shor, and\nSteane. For the case of a 4-state system we show that these codes can obtain\nthe minimal embedding for code which can correct any flip or phase error. We\nalso provide heuristic algorithms for creating reflexive stabilizer codes\nstarting from the noise of a quantum channel. Furthermore, we show that the\nproblem can be posed in terms of finding maximal Cayley subgraphs with\nrestrictions imposed by the set of potential errors.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Robert Vandermolen",
      "Duncan Wright"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.08414"
  },
  {
    "id": "arXiv:2110.08418",
    "title": "Nuances in Margin Conditions Determine Gains in Active Learning",
    "abstract": "We consider nonparametric classification with smooth regression functions,\nwhere it is well known that notions of margin in $E[Y|X]$ determine fast or\nslow rates in both active and passive learning. Here we elucidate a striking\ndistinction between the two settings. Namely, we show that some seemingly\nbenign nuances in notions of margin -- involving the uniqueness of the Bayes\nclassifier, and which have no apparent effect on rates in passive learning --\ndetermine whether or not any active learner can outperform passive learning\nrates. In particular, for Audibert-Tsybakov's margin condition (allowing\ngeneral situations with non-unique Bayes classifiers), no active learner can\ngain over passive learning in commonly studied settings where the marginal on\n$X$ is near uniform. Our results thus negate the usual intuition from past\nliterature that active rates should improve over passive rates in nonparametric\nsettings.",
    "descriptor": "",
    "authors": [
      "Samory Kpotufe",
      "Gan Yuan",
      "Yunfan Zhao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08418"
  },
  {
    "id": "arXiv:2110.08424",
    "title": "Deep learning-based detection of intravenous contrast in computed  tomography scans",
    "abstract": "Purpose: Identifying intravenous (IV) contrast use within CT scans is a key\ncomponent of data curation for model development and testing. Currently, IV\ncontrast is poorly documented in imaging metadata and necessitates manual\ncorrection and annotation by clinician experts, presenting a major barrier to\nimaging analyses and algorithm deployment. We sought to develop and validate a\nconvolutional neural network (CNN)-based deep learning (DL) platform to\nidentify IV contrast within CT scans. Methods: For model development and\nevaluation, we used independent datasets of CT scans of head, neck (HN) and\nlung cancer patients, totaling 133,480 axial 2D scan slices from 1,979 CT scans\nmanually annotated for contrast presence by clinical experts. Five different DL\nmodels were adopted and trained in HN training datasets for slice-level\ncontrast detection. Model performances were evaluated on a hold-out set and on\nan independent validation set from another institution. DL models was then\nfine-tuned on chest CT data and externally validated on a separate chest CT\ndataset. Results: Initial DICOM metadata tags for IV contrast were missing or\nerroneous in 1,496 scans (75.6%). The EfficientNetB4-based model showed the\nbest overall detection performance. For HN scans, AUC was 0.996 in the internal\nvalidation set (n = 216) and 1.0 in the external validation set (n = 595). The\nfine-tuned model on chest CTs yielded an AUC: 1.0 for the internal validation\nset (n = 53), and AUC: 0.980 for the external validation set (n = 402).\nConclusion: The DL model could accurately detect IV contrast in both HN and\nchest CT scans with near-perfect performance.",
    "descriptor": "",
    "authors": [
      "Zezhong Ye",
      "Jack M. Qian",
      "Ahmed Hosny",
      "Roman Zeleznik",
      "Deborah Plana",
      "Jirapat Likitlersuang",
      "Zhongyi Zhang",
      "Raymond H. Mak",
      "Hugo J. W. L. Aerts",
      "Benjamin H. Kann"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08424"
  },
  {
    "id": "arXiv:2110.08427",
    "title": "COVID-19 Detection in Chest X-ray Images Using Swin-Transformer and  Transformer in Transformer",
    "abstract": "The Coronavirus Disease 2019 (COVID-19) has spread globally and caused\nserious damages. Chest X-ray images are widely used for COVID-19 diagnosis and\nArtificial Intelligence method can assist to increase the efficiency and\naccuracy. In the Challenge of Chest XR COVID-19 detection in Ethics and\nExplainability for Responsible Data Science (EE-RDS) conference 2021, we\nproposed a method which combined Swin Transformer and Transformer in\nTransformer to classify chest X-ray images as three classes: COVID-19,\nPneumonia and Normal (healthy) and achieved 0.9475 accuracy on test set.",
    "descriptor": "\nComments: COVID-19, Chest X-ray Images, Swin-Transformer, Transformer in Transformer, Model Ensembling, Image Classification\n",
    "authors": [
      "Juntao Jiang",
      "Shuyi Lin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08427"
  },
  {
    "id": "arXiv:2110.08442",
    "title": "Koopman Operator Theory for Nonlinear Dynamic Modeling using Dynamic  Mode Decomposition",
    "abstract": "The Koopman operator is a linear operator that describes the evolution of\nscalar observables (i.e., measurement functions of the states) in an\ninfinitedimensional Hilbert space. This operator theoretic point of view lifts\nthe dynamics of a finite-dimensional nonlinear system to an\ninfinite-dimensional function space where the evolution of the original system\nbecomes linear. In this paper, we provide a brief summary of the Koopman\noperator theorem for nonlinear dynamics modeling and focus on analyzing several\ndata-driven implementations using dynamical mode decomposition (DMD) for\nautonomous and controlled canonical problems. We apply the extended dynamic\nmode decomposition (EDMD) to identify the leading Koopman eigenfunctions and\napproximate a finite-dimensional representation of the discovered linear\ndynamics. This allows us to apply linear control approaches towards nonlinear\nsystems without linearization approximations around fixed points. We can then\nexamine the fidelity of using a linear controller based on a Koopman operator\napproximated system on under-actuated systems with basic maneuvers. We\ndemonstrate the effectiveness of this theory through numerical simulation on\ntwo classic dynamical systems are used to show DMD methods of evaluating and\napproximating the Koopman operator and its effectiveness at linearizing these\nsystems.",
    "descriptor": "\nComments: 8 pages, 16 figures\n",
    "authors": [
      "Gregory Snyder",
      "Zhuoyuan Song"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.08442"
  },
  {
    "id": "arXiv:2110.08449",
    "title": "Adversarial Attacks on Gaussian Process Bandits",
    "abstract": "Gaussian processes (GP) are a widely-adopted tool used to sequentially\noptimize black-box functions, where evaluations are costly and potentially\nnoisy. Recent works on GP bandits have proposed to move beyond random noise and\ndevise algorithms robust to adversarial attacks. In this paper, we study this\nproblem from the attacker's perspective, proposing various adversarial attack\nmethods with differing assumptions on the attacker's strength and prior\ninformation. Our goal is to understand adversarial attacks on GP bandits from\nboth a theoretical and practical perspective. We focus primarily on targeted\nattacks on the popular GP-UCB algorithm and a related elimination-based\nalgorithm, based on adversarially perturbing the function $f$ to produce\nanother function $\\tilde{f}$ whose optima are in some region $\\mathcal{R}_{\\rm\ntarget}$. Based on our theoretical analysis, we devise both white-box attacks\n(known $f$) and black-box attacks (unknown $f$), with the former including a\nSubtraction attack and Clipping attack, and the latter including an Aggressive\nsubtraction attack. We demonstrate that adversarial attacks on GP bandits can\nsucceed in forcing the algorithm towards $\\mathcal{R}_{\\rm target}$ even with a\nlow attack budget, and we compare our attacks' performance and efficiency on\nseveral real and synthetic functions.",
    "descriptor": "",
    "authors": [
      "Eric Han",
      "Jonathan Scarlett"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08449"
  },
  {
    "id": "arXiv:2110.08471",
    "title": "Fast Projection onto the Capped Simplex withApplications to Sparse  Regression in Bioinformatics",
    "abstract": "We consider the problem of projecting a vector onto the so-called k-capped\nsimplex, which is a hyper-cube cut by a hyperplane. For an n-dimensional input\nvector with bounded elements, we found that a simple algorithm based on\nNewton's method is able to solve the projection problem to high precision with\na complexity roughly about O(n), which has a much lower computational cost\ncompared with the existing sorting-based methods proposed in the literature. We\nprovide a theory for partial explanation and justification of the method.\nWe demonstrate that the proposed algorithm can produce a solution of the\nprojection problem with high precision on large scale datasets, and the\nalgorithm is able to significantly outperform the state-of-the-art methods in\nterms of runtime (about 6-8 times faster than a commercial software with\nrespect to CPU time for input vector with 1 million variables or more).\nWe further illustrate the effectiveness of the proposed algorithm on solving\nsparse regression in a bioinformatics problem. Empirical results on the GWAS\ndataset (with 1,500,000 single-nucleotide polymorphisms) show that, when using\nthe proposed method to accelerate the Projected Quasi-Newton (PQN) method, the\naccelerated PQN algorithm is able to handle huge-scale regression problem and\nit is more efficient (about 3-6 times faster) than the current state-of-the-art\nmethods.",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Andersen Ang",
      "Jianzhu Ma",
      "Nianjun Liu",
      "Kun Huang",
      "Yijie Wang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2110.08471"
  },
  {
    "id": "arXiv:2110.08500",
    "title": "On Model Selection Consistency of Lasso for High-Dimensional Ising  Models on Tree-like Graphs",
    "abstract": "We consider the problem of high-dimensional Ising model selection using\nneighborhood-based least absolute shrinkage and selection operator (Lasso). It\nis rigorously proved that under some mild coherence conditions on the\npopulation covariance matrix of the Ising model, consistent model selection can\nbe achieved with sample sizes $n=\\Omega{(d^3\\log{p})}$ for any tree-like graph\nin the paramagnetic phase, where $p$ is the number of variables and $d$ is the\nmaximum node degree. When the same conditions are imposed directly on the\nsample covariance matrices, it is shown that a reduced sample size\n$n=\\Omega{(d^2\\log{p})}$ suffices. The obtained sufficient conditions for\nconsistent model selection with Lasso are the same in the scaling of the sample\ncomplexity as that of $\\ell_1$-regularized logistic regression. Given the\npopularity and efficiency of Lasso, our rigorous analysis provides a\ntheoretical backing for its practical use in Ising model selection.",
    "descriptor": "\nComments: 30 pages, 4 figures\n",
    "authors": [
      "Xiangming Meng",
      "Tomoyuki Obuchi",
      "Yoshiyuki Kabashima"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.08500"
  },
  {
    "id": "arXiv:2110.08505",
    "title": "Mode and Ridge Estimation in Euclidean and Directional Product Spaces: A  Mean Shift Approach",
    "abstract": "The set of local modes and the ridge lines estimated from a dataset are\nimportant summary characteristics of the data-generating distribution. In this\nwork, we consider estimating the local modes and ridges from point cloud data\nin a product space with two or more Euclidean/directional metric spaces.\nSpecifically, we generalize the well-known (subspace constrained) mean shift\nalgorithm to the product space setting and illuminate some pitfalls in such\ngeneralization. We derive the algorithmic convergence of the proposed method,\nprovide practical guidelines on the implementation, and demonstrate its\neffectiveness on both simulated and real datasets.",
    "descriptor": "\nComments: 51 pages, 10 figures\n",
    "authors": [
      "Yikun Zhang",
      "Yen-Chi Chen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.08505"
  },
  {
    "id": "arXiv:2110.08509",
    "title": "BAPGAN: GAN-based Bone Age Progression of Femur and Phalange X-ray  Images",
    "abstract": "Convolutional Neural Networks play a key role in bone age assessment for\ninvestigating endocrinology, genetic, and growth disorders under various\nmodalities and body regions. However, no researcher has tackled bone age\nprogression/regression despite its valuable potential applications:\nbone-related disease diagnosis, clinical knowledge acquisition, and museum\neducation. Therefore, we propose Bone Age Progression Generative Adversarial\nNetwork (BAPGAN) to progress/regress both femur/phalange X-ray images while\npreserving identity and realism. We exhaustively confirm the BAPGAN's clinical\npotential via Frechet Inception Distance, Visual Turing Test by two expert\northopedists, and t-Distributed Stochastic Neighbor Embedding.",
    "descriptor": "\nComments: 6 pages, 5 figures, accepted to SPIE Medical Imaging 2022\n",
    "authors": [
      "Shinji Nakazawa",
      "Changhee Han",
      "Joe Hasei",
      "Ryuichi Nakahara",
      "Toshifumi Ozaki"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08509"
  },
  {
    "id": "arXiv:2110.08521",
    "title": "Locally Adaptive Structure and Texture Similarity for Image Quality  Assessment",
    "abstract": "The latest advances in full-reference image quality assessment (IQA) involve\nunifying structure and texture similarity based on deep representations. The\nresulting Deep Image Structure and Texture Similarity (DISTS) metric, however,\nmakes rather global quality measurements, ignoring the fact that natural\nphotographic images are locally structured and textured across space and scale.\nIn this paper, we describe a locally adaptive structure and texture similarity\nindex for full-reference IQA, which we term A-DISTS. Specifically, we rely on a\nsingle statistical feature, namely the dispersion index, to localize texture\nregions at different scales. The estimated probability (of one patch being\ntexture) is in turn used to adaptively pool local structure and texture\nmeasurements. The resulting A-DISTS is adapted to local image content, and is\nfree of expensive human perceptual scores for supervised training. We\ndemonstrate the advantages of A-DISTS in terms of correlation with human data\non ten IQA databases and optimization of single image super-resolution methods.",
    "descriptor": "",
    "authors": [
      "Keyan Ding",
      "Yi Liu",
      "Xueyi Zou",
      "Shiqi Wang",
      "Kede Ma"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08521"
  },
  {
    "id": "arXiv:2110.08531",
    "title": "A theoretical and empirical study of new adaptive algorithms with  additional momentum steps and shifted updates for stochastic non-convex  optimization",
    "abstract": "In the following paper we introduce new adaptive algorithms endowed with\nmomentum terms for stochastic non-convex optimization problems. We investigate\nthe almost sure convergence to stationary points, along with a finite-time\nhorizon analysis with respect to a chosen final iteration, and we also inspect\nthe worst-case iteration complexity. An estimate for the expectation of the\nsquared Euclidean norm of the gradient is given and the theoretical analysis\nthat we perform is assisted by various computational simulations for neural\nnetwork training.",
    "descriptor": "\nComments: 36 pages, 5 figures, 6 tables, 35 references\n",
    "authors": [
      "Cristian Daniel Alecsa"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08531"
  },
  {
    "id": "arXiv:2110.08545",
    "title": "A Unified Speaker Adaptation Approach for ASR",
    "abstract": "Transformer models have been used in automatic speech recognition (ASR)\nsuccessfully and yields state-of-the-art results. However, its performance is\nstill affected by speaker mismatch between training and test data. Further\nfinetuning a trained model with target speaker data is the most natural\napproach for adaptation, but it takes a lot of compute and may cause\ncatastrophic forgetting to the existing speakers. In this work, we propose a\nunified speaker adaptation approach consisting of feature adaptation and model\nadaptation. For feature adaptation, we employ a speaker-aware persistent memory\nmodel which generalizes better to unseen test speakers by making use of speaker\ni-vectors to form a persistent memory. For model adaptation, we use a novel\ngradual pruning method to adapt to target speakers without changing the model\narchitecture, which to the best of our knowledge, has never been explored in\nASR. Specifically, we gradually prune less contributing parameters on model\nencoder to a certain sparsity level, and use the pruned parameters for\nadaptation, while freezing the unpruned parameters to keep the original model\nperformance. We conduct experiments on the Librispeech dataset. Our proposed\napproach brings relative 2.74-6.52% word error rate (WER) reduction on general\nspeaker adaptation. On target speaker adaptation, our method outperforms the\nbaseline with up to 20.58% relative WER reduction, and surpasses the finetuning\nmethod by up to relative 2.54%. Besides, with extremely low-resource adaptation\ndata (e.g., 1 utterance), our method could improve the WER by relative 6.53%\nwith only a few epochs of training.",
    "descriptor": "\nComments: Accepted by EMNLP 2021\n",
    "authors": [
      "Yingzhu Zhao",
      "Chongjia Ni",
      "Cheung-Chi Leung",
      "Shafiq Joty",
      "Eng Siong Chng",
      "Bin Ma"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.08545"
  },
  {
    "id": "arXiv:2110.08569",
    "title": "Deep Image Debanding",
    "abstract": "Banding or false contour is an annoying visual artifact whose impact is even\nmore pronounced in ultra high definition, high dynamic range, and wide colour\ngamut visual content, which is becoming increasingly popular. Since users\nassociate a heightened expectation of quality with such content and banding\nleads to deteriorated visual quality-of-experience, the area of banding removal\nor debanding has taken paramount importance. Existing debanding approaches are\nmostly knowledge-driven. Despite the widespread success of deep learning in\nother areas of image processing and computer vision, data-driven debanding\napproaches remain surprisingly missing. In this work, we make one of the first\nattempts to develop a deep learning based banding artifact removal method for\nimages and name it deep debanding network (deepDeband). For its training, we\nconstruct a large-scale dataset of 51,490 pairs of corresponding pristine and\nbanded image patches. Performance evaluation shows that deepDeband is\nsuccessful at greatly reducing banding artifacts in images, outperforming\nexisting methods both quantitatively and visually.",
    "descriptor": "\nComments: 5 pages, 4 figures, 5 tables\n",
    "authors": [
      "Raymond Zhou",
      "Shahrukh Athar",
      "Zhongling Wang",
      "Zhou Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08569"
  },
  {
    "id": "arXiv:2110.08577",
    "title": "Nys-Curve: Nystr\u00f6m-Approximated Curvature for Stochastic Optimization",
    "abstract": "The quasi-Newton methods generally provide curvature information by\napproximating the Hessian using the secant equation. However, the secant\nequation becomes insipid in approximating the Newton step owing to its use of\nthe first-order derivatives. In this study, we propose an approximate Newton\nstep-based stochastic optimization algorithm for large-scale empirical risk\nminimization of convex functions with linear convergence rates. Specifically,\nwe compute a partial column Hessian of size ($d\\times k$) with $k\\ll d$\nrandomly selected variables, then use the \\textit{Nystr\\\"om method} to better\napproximate the full Hessian matrix. To further reduce the computational\ncomplexity per iteration, we directly compute the update step\n($\\Delta\\boldsymbol{w}$) without computing and storing the full Hessian or its\ninverse. Furthermore, to address large-scale scenarios in which even computing\na partial Hessian may require significant time, we used distribution-preserving\n(DP) sub-sampling to compute a partial Hessian. The DP sub-sampling generates\n$p$ sub-samples with similar first and second-order distribution statistics and\nselects a single sub-sample at each epoch in a round-robin manner to compute\nthe partial Hessian. We integrate our approximated Hessian with stochastic\ngradient descent and stochastic variance-reduced gradients to solve the\nlogistic regression problem. The numerical experiments show that the proposed\napproach was able to obtain a better approximation of Newton\\textquotesingle s\nmethod with performance competitive with the state-of-the-art first-order and\nthe stochastic quasi-Newton methods.",
    "descriptor": "",
    "authors": [
      "Hardik Tankaria",
      "Dinesh Singh",
      "Makoto Yamada"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.08577"
  },
  {
    "id": "arXiv:2110.08583",
    "title": "ASR4REAL: An extended benchmark for speech models",
    "abstract": "Popular ASR benchmarks such as Librispeech and Switchboard are limited in the\ndiversity of settings and speakers they represent. We introduce a set of\nbenchmarks matching real-life conditions, aimed at spotting possible biases and\nweaknesses in models. We have found out that even though recent models do not\nseem to exhibit a gender bias, they usually show important performance\ndiscrepancies by accent, and even more important ones depending on the\nsocio-economic status of the speakers. Finally, all tested models show a strong\nperformance drop when tested on conversational speech, and in this precise\ncontext even a language model trained on a dataset as big as Common Crawl does\nnot seem to have significant positive effect which reiterates the importance of\ndeveloping conversational language models",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Morgane Riviere",
      "Jade Copet",
      "Gabriel Synnaeve"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.08583"
  },
  {
    "id": "arXiv:2110.08595",
    "title": "A MIMO Radar-based Few-Shot Learning Approach for Human-ID",
    "abstract": "Radar for deep learning-based human identification has become a research area\nof increasing interest. It has been shown that micro-Doppler (\\(\\upmu\\)-D) can\nreflect the walking behavior through capturing the periodic limbs'\nmicro-motions. One of the main aspects is maximizing the number of included\nclasses while considering the real-time and training dataset size constraints.\nIn this paper, a multiple-input-multiple-output (MIMO) radar is used to\nformulate micro-motion spectrograms of the elevation angular velocity\n(\\(\\upmu\\)-\\(\\omega\\)). The effectiveness of concatenating this\nnewly-formulated spectrogram with the commonly used \\(\\upmu\\)-D is\ninvestigated. To accommodate for non-constrained real walking motion, an\nadaptive cycle segmentation framework is utilized and a metric learning network\nis trained on half gait cycles (\\(\\approx\\) 0.5 s). Studies on the effects of\nvarious numbers of classes (5--20), different dataset sizes, and varying\nobservation time windows 1--2 s are conducted. A non-constrained walking\ndataset of 22 subjects is collected with different aspect angles with respect\nto the radar. The proposed few-shot learning (FSL) approach achieves a\nclassification error of 11.3 % with only 2 min of training data per subject.",
    "descriptor": "\nComments: 5 pages, 6 figures, 2 tables\n",
    "authors": [
      "Pascal Weller",
      "Fady Aziz",
      "Sherif Abdulatif",
      "Urs Schneider",
      "Marco F. Huber"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08595"
  },
  {
    "id": "arXiv:2110.08598",
    "title": "A Variational Bayesian Approach to Learning Latent Variables for  Acoustic Knowledge Transfer",
    "abstract": "We propose a variational Bayesian (VB) approach to learning distributions of\nlatent variables in deep neural network (DNN) models for cross-domain knowledge\ntransfer, to address acoustic mismatches between training and testing\nconditions. Instead of carrying out point estimation in conventional maximum a\nposteriori estimation with a risk of having a curse of dimensionality in\nestimating a huge number of model parameters, we focus our attention on\nestimating a manageable number of latent variables of DNNs via a VB inference\nframework. To accomplish model transfer, knowledge learnt from a source domain\nis encoded in prior distributions of latent variables and optimally combined,\nin a Bayesian sense, with a small set of adaptation data from a target domain\nto approximate the corresponding posterior distributions. Experimental results\non device adaptation in acoustic scene classification show that our proposed VB\napproach can obtain good improvements on target devices, and consistently\noutperforms 13 state-of-the-art knowledge transfer algorithms.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Hu Hu",
      "Sabato Marco Siniscalchi",
      "Chao-Han Huck Yang",
      "Chin-Hui Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.08598"
  },
  {
    "id": "arXiv:2110.08618",
    "title": "Convolutional Deep Denoising Autoencoders for Radio Astronomical Images",
    "abstract": "We apply a Machine Learning technique known as Convolutional Denoising\nAutoencoder to denoise synthetic images of state-of-the-art radio telescopes,\nwith the goal of detecting the faint, diffused radio sources predicted to\ncharacterise the radio cosmic web. In our application, denoising is intended to\naddress both the reduction of random instrumental noise and the minimisation of\nadditional spurious artefacts like the sidelobes, resulting from the aperture\nsynthesis technique. The effectiveness and the accuracy of the method are\nanalysed for different kinds of corrupted input images, together with its\ncomputational performance. Specific attention has been devoted to create\nrealistic mock observations for the training, exploiting the outcomes of\ncosmological numerical simulations, to generate images corresponding to LOFAR\nHBA 8 hours observations at 150 MHz. Our autoencoder can effectively denoise\ncomplex images identifying and extracting faint objects at the limits of the\ninstrumental sensitivity. The method can efficiently scale on large datasets,\nexploiting high performance computing solutions, in a fully automated way (i.e.\nno human supervision is required after training). It can accurately perform\nimage segmentation, identifying low brightness outskirts of diffused sources,\nproving to be a viable solution for detecting challenging extended objects\nhidden in noisy radio observations.",
    "descriptor": "\nComments: 21 pages, 14 figures, Accepted for publication by MNRAS\n",
    "authors": [
      "Claudio Gheller",
      "Franco Vazza"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08618"
  },
  {
    "id": "arXiv:2110.08619",
    "title": "SAGAN: Adversarial Spatial-asymmetric Attention for Noisy Nona-Bayer  Reconstruction",
    "abstract": "Nona-Bayer colour filter array (CFA) pattern is considered one of the most\nviable alternatives to traditional Bayer patterns. Despite the substantial\nadvantages, such non-Bayer CFA patterns are susceptible to produce visual\nartefacts while reconstructing RGB images from noisy sensor data. This study\naddresses the challenges of learning RGB image reconstruction from noisy\nNona-Bayer CFA comprehensively. We propose a novel spatial-asymmetric attention\nmodule to jointly learn bi-direction transformation and large-kernel global\nattention to reduce the visual artefacts. We combine our proposed module with\nadversarial learning to produce plausible images from Nona-Bayer CFA. The\nfeasibility of the proposed method has been verified and compared with the\nstate-of-the-art image reconstruction method. The experiments reveal that the\nproposed method can reconstruct RGB images from noisy Nona-Bayer CFA without\nproducing any visually disturbing artefacts. Also, it can outperform the\nstate-of-the-art image reconstruction method in both qualitative and\nquantitative comparison. Code available:\nhttps://github.com/sharif-apu/SAGAN_BMVC21.",
    "descriptor": "",
    "authors": [
      "S M A Sharif",
      "Rizwan Ali Naqvi",
      "Mithun Biswas"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08619"
  },
  {
    "id": "arXiv:2110.08668",
    "title": "Fast Strain Estimation and Frame Selection in Ultrasound Elastography  using Machine Learning",
    "abstract": "Ultrasound Elastography aims to determine the mechanical properties of the\ntissue by monitoring tissue deformation due to internal or external forces.\nTissue deformations are estimated from ultrasound radio frequency (RF) signals\nand are often referred to as time delay estimation (TDE). Given two RF frames\nI1 and I2, we can compute a displacement image which shows the change in the\nposition of each sample in I1 to a new position in I2. Two important challenges\nin TDE include high computational complexity and the difficulty in choosing\nsuitable RF frames. Selecting suitable frames is of high importance because\nmany pairs of RF frames either do not have acceptable deformation for\nextracting informative strain images or are decorrelated and deformation cannot\nbe reliably estimated. Herein, we introduce a method that learns 12\ndisplacement modes in quasi-static elastography by performing Principal\nComponent Analysis (PCA) on displacement fields of a large training database.\nIn the inference stage, we use dynamic programming (DP) to compute an initial\ndisplacement estimate of around 1% of the samples, and then decompose this\nsparse displacement into a linear combination of the 12 displacement modes. Our\nmethod assumes that the displacement of the whole image could also be described\nby this linear combination of principal components. We then use the GLobal\nUltrasound Elastography (GLUE) method to fine-tune the result yielding the\nexact displacement image. Our method, which we call PCA-GLUE, is more than 10\ntimes faster than DP in calculating the initial displacement map while giving\nthe same result. Our second contribution in this paper is determining the\nsuitability of the frame pair I1 and I2 for strain estimation, which we achieve\nby using the weight vector that we calculated for PCA-GLUE as an input to a\nmulti-layer perceptron (MLP) classifier.",
    "descriptor": "",
    "authors": [
      "Abdelrahman Zayed",
      "Hassan Rivaz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.08668"
  },
  {
    "id": "arXiv:2110.08676",
    "title": "Noise-Augmented Privacy-Preserving Empirical Risk Minimization with  Dual-purpose Regularizer and Privacy Budget Retrieval and Recycling",
    "abstract": "We propose Noise-Augmented Privacy-Preserving Empirical Risk Minimization\n(NAPP-ERM) that solves ERM with differential privacy guarantees. Existing\nprivacy-preserving ERM approaches may be subject to over-regularization with\nthe employment of an l2 term to achieve strong convexity on top of the target\nregularization. NAPP-ERM improves over the current approaches and mitigates\nover-regularization by iteratively realizing target regularization through\nappropriately designed augmented data and delivering strong convexity via a\nsingle adaptively weighted dual-purpose l2 regularizer. When the target\nregularization is for variable selection, we propose a new regularizer that\nachieves both privacy and sparsity guarantees simultaneously. Finally, we\npropose a strategy to retrieve privacy budget when the strong convexity\nrequirement is met, which can be returned to users such that the DP of ERM is\nguaranteed at a lower privacy cost than originally planned, or be recycled to\nthe ERM optimization procedure to reduce the injected DP noise and improve the\nutility of DP-ERM. From an implementation perspective, NAPP-ERM can be achieved\nby optimizing a non-perturbed object function given noise-augmented data and\ncan thus leverage existing tools for non-private ERM optimization. We\nillustrate through extensive experiments the mitigation effect of the\nover-regularization and private budget retrieval by NAPP-ERM on variable\nselection and prediction.",
    "descriptor": "",
    "authors": [
      "Yinan Li",
      "Fang Liu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08676"
  },
  {
    "id": "arXiv:2110.08701",
    "title": "Measuring Total Transverse Reference-free Displacements of Railroad  Bridges using 2 Degrees of Freedom (2DOF): Experimental Validation",
    "abstract": "Railroad bridge engineers are interested in the displacement of railroad\nbridges when the train is crossing the bridge for engineering decision making\nof their assets. Measuring displacements under train crossing events is\ndifficult. If simplified reference-free methods would be accurate and\nvalidated, owners would conduct objective performance assessment of their\nbridge inventories under trains. Researchers have developed new sensing\ntechnologies (reference-free) to overcome the limitations of reference\npoint-based displacement sensors. Reference-free methods use accelerometers to\nestimate displacements, by decomposing the total displacement in two parts: a\nhigh-frequency dynamic displacement component, and a low-frequency\npseudo-static displacement component. In the past, researchers have used the\nEuler-Bernoulli beam theory formula to estimate the pseudo-static displacement\nassuming railroad bridge piles and columns can be simplified as cantilever\nbeams. However, according to railroad bridge managers, railroad bridges have a\ndifferent degree of fixity for each pile of each bent. Displacements can be\nestimated assuming a similar degree of fixity for deep foundations, but\ninherent errors will affect the accuracy of displacement estimation. This paper\nsolves this problem expanding the 1 Degree of Freedom (1DOF) solution to a new\n2 Degrees of Freedom (2DOF), to collect displacements under trains and enable\ncost-effective condition-based information related to bridge safety.\nResearchers developed a simplified beam to demonstrate the total displacement\nestimation using 2DOF and further conducted experimental results in the\nlaboratory. The estimated displacement of the 2DOF model is more accurate than\nthat of the 1DOF model for ten train crossing events. With only one sensor\nadded to the ground of the pile, this method provides owners with approximately\n40% more accurate displacements.",
    "descriptor": "\nComments: 28 pages, 11 figures, 2 tables\n",
    "authors": [
      "Lingkun Chen",
      "Can Zhu",
      "Zeyu Wu",
      "Xinxing Yuan",
      "Fernando Moreu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.08701"
  },
  {
    "id": "arXiv:2110.08713",
    "title": "Pareto Navigation Gradient Descent: a First-Order Algorithm for  Optimization in Pareto Set",
    "abstract": "Many modern machine learning applications, such as multi-task learning,\nrequire finding optimal model parameters to trade-off multiple objective\nfunctions that may conflict with each other. The notion of the Pareto set\nallows us to focus on the set of (often infinite number of) models that cannot\nbe strictly improved. But it does not provide an actionable procedure for\npicking one or a few special models to return to practical users. In this\npaper, we consider \\emph{optimization in Pareto set (OPT-in-Pareto)}, the\nproblem of finding Pareto models that optimize an extra reference criterion\nfunction within the Pareto set. This function can either encode a specific\npreference from the users, or represent a generic diversity measure for\nobtaining a set of diversified Pareto models that are representative of the\nwhole Pareto set. Unfortunately, despite being a highly useful framework,\nefficient algorithms for OPT-in-Pareto have been largely missing, especially\nfor large-scale, non-convex, and non-linear objectives in deep learning. A\nnaive approach is to apply Riemannian manifold gradient descent on the Pareto\nset, which yields a high computational cost due to the need for\neigen-calculation of Hessian matrices. We propose a first-order algorithm that\napproximately solves OPT-in-Pareto using only gradient information, with both\nhigh practical efficiency and theoretically guaranteed convergence property.\nEmpirically, we demonstrate that our method works efficiently for a variety of\nchallenging multi-task-related problems.",
    "descriptor": "",
    "authors": [
      "Mao Ye",
      "Qiang Liu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08713"
  },
  {
    "id": "arXiv:2110.08721",
    "title": "CAE-Transformer: Transformer-based Model to Predict Invasiveness of Lung  Adenocarcinoma Subsolid Nodules from Non-thin Section 3D CT Scans",
    "abstract": "Lung cancer is the leading cause of mortality from cancer worldwide and has\nvarious histologic types, among which Lung Adenocarcinoma (LAUC) has recently\nbeen the most prevalent. Lung adenocarcinomas are classified as pre-invasive,\nminimally invasive, and invasive adenocarcinomas. Timely and accurate knowledge\nof the invasiveness of lung nodules leads to a proper treatment plan and\nreduces the risk of unnecessary or late surgeries. Currently, the primary\nimaging modality to assess and predict the invasiveness of LAUCs is the chest\nCT. The results based on CT images, however, are subjective and suffer from a\nlow accuracy compared to the ground truth pathological reviews provided after\nsurgical resections. In this paper, a predictive transformer-based framework,\nreferred to as the \"CAE-Transformer\", is developed to classify LAUCs. The\nCAE-Transformer utilizes a Convolutional Auto-Encoder (CAE) to automatically\nextract informative features from CT slices, which are then fed to a modified\ntransformer model to capture global inter-slice relations. Experimental results\non our in-house dataset of 114 pathologically proven Sub-Solid Nodules (SSNs)\ndemonstrate the superiority of the CAE-Transformer over the\nhistogram/radiomics-based models and its deep learning-based counterparts,\nachieving an accuracy of 87.73%, sensitivity of 88.67%, specificity of 86.33%,\nand AUC of 0.913, using a 10-fold cross-validation.",
    "descriptor": "",
    "authors": [
      "Shahin Heidarian",
      "Parnian Afshar",
      "Anastasia Oikonomou",
      "Konstantinos N. Plataniotis",
      "Arash Mohammadi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08721"
  },
  {
    "id": "arXiv:2110.08726",
    "title": "Data Shapley Value for Handling Noisy Labels: An application in  Screening COVID-19 Pneumonia from Chest CT Scans",
    "abstract": "A long-standing challenge of deep learning models involves how to handle\nnoisy labels, especially in applications where human lives are at stake.\nAdoption of the data Shapley Value (SV), a cooperative game theoretical\napproach, is an intelligent valuation solution to tackle the issue of noisy\nlabels. Data SV can be used together with a learning model and an evaluation\nmetric to validate each training point's contribution to the model's\nperformance. The SV of a data point, however, is not unique and depends on the\nlearning model, the evaluation metric, and other data points collaborating in\nthe training game. However, effects of utilizing different evaluation metrics\nfor computation of the SV, detecting the noisy labels, and measuring the data\npoints' importance has not yet been thoroughly investigated. In this context,\nwe performed a series of comparative analyses to assess SV's capabilities to\ndetect noisy input labels when measured by different evaluation metrics. Our\nexperiments on COVID-19-infected of CT images illustrate that although the data\nSV can effectively identify noisy labels, adoption of different evaluation\nmetric can significantly influence its ability to identify noisy labels from\ndifferent data classes. Specifically, we demonstrate that the SV greatly\ndepends on the associated evaluation metric.",
    "descriptor": "",
    "authors": [
      "Nastaran Enshaei",
      "Moezedin Javad Rafiee",
      "Arash Mohammadi",
      "Farnoosh Naderkhani"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08726"
  },
  {
    "id": "arXiv:2110.08775",
    "title": "Perturbative construction of mean-field equations in extensive-rank  matrix factorization and denoising",
    "abstract": "Factorization of matrices where the rank of the two factors diverges linearly\nwith their sizes has many applications in diverse areas such as unsupervised\nrepresentation learning, dictionary learning or sparse coding. We consider a\nsetting where the two factors are generated from known component-wise\nindependent prior distributions, and the statistician observes a (possibly\nnoisy) component-wise function of their matrix product. In the limit where the\ndimensions of the matrices tend to infinity, but their ratios remain fixed, we\nexpect to be able to derive closed form expressions for the optimal mean\nsquared error on the estimation of the two factors. However, this remains a\nvery involved mathematical and algorithmic problem. A related, but simpler,\nproblem is extensive-rank matrix denoising, where one aims to reconstruct a\nmatrix with extensive but usually small rank from noisy measurements. In this\npaper, we approach both these problems using high-temperature expansions at\nfixed order parameters. This allows to clarify how previous attempts at solving\nthese problems failed at finding an asymptotically exact solution. We provide a\nsystematic way to derive the corrections to these existing approximations,\ntaking into account the structure of correlations particular to the problem.\nFinally, we illustrate our approach in detail on the case of extensive-rank\nmatrix denoising. We compare our results with known optimal\nrotationally-invariant estimators, and show how exact asymptotic calculations\nof the minimal error can be performed using extensive-rank matrix integrals.",
    "descriptor": "\nComments: 28 pages (main text), 24 pages of references and appendices\n",
    "authors": [
      "Antoine Maillard",
      "Florent Krzakala",
      "Marc M\u00e9zard",
      "Lenka Zdeborov\u00e1"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2110.08775"
  },
  {
    "id": "arXiv:2110.08776",
    "title": "Self-Supervised U-Net for Segmenting Flat and Sessile Polyps",
    "abstract": "Colorectal Cancer(CRC) poses a great risk to public health. It is the third\nmost common cause of cancer in the US. Development of colorectal polyps is one\nof the earliest signs of cancer. Early detection and resection of polyps can\ngreatly increase survival rate to 90%. Manual inspection can cause\nmisdetections because polyps vary in color, shape, size and appearance. To this\nend, Computer-Aided Diagnosis systems(CADx) has been proposed that detect\npolyps by processing the colonoscopic videos. The system acts a secondary check\nto help clinicians reduce misdetections so that polyps may be resected before\nthey transform to cancer. Polyps vary in color, shape, size, texture and\nappearance. As a result, the miss rate of polyps is between 6% and 27% despite\nthe prominence of CADx solutions. Furthermore, sessile and flat polyps which\nhave diameter less than 10 mm are more likely to be undetected. Convolutional\nNeural Networks(CNN) have shown promising results in polyp segmentation.\nHowever, all of these works have a supervised approach and are limited by the\nsize of the dataset. It was observed that smaller datasets reduce the\nsegmentation accuracy of ResUNet++. We train a U-Net to inpaint randomly\ndropped out pixels in the image as a proxy task. The dataset we use for\npre-training is Kvasir-SEG dataset. This is followed by a supervised training\non the limited Kvasir-Sessile dataset. Our experimental results demonstrate\nthat with limited annotated dataset and a larger unlabeled dataset,\nself-supervised approach is a better alternative than fully supervised\napproach. Specifically, our self-supervised U-Net performs better than five\nsegmentation models which were trained in supervised manner on the\nKvasir-Sessile dataset.",
    "descriptor": "",
    "authors": [
      "Debayan Bhattacharya",
      "Christian Betz",
      "Dennis Eggert",
      "Alexander Schlaefer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08776"
  },
  {
    "id": "arXiv:2110.08811",
    "title": "Attention W-Net: Improved Skip Connections for better Representations",
    "abstract": "Segmentation of macro and microvascular structures in fundoscopic retinal\nimages plays a crucial role in detection of multiple retinal and systemic\ndiseases, yet it is a difficult problem to solve. Most deep learning approaches\nfor this task involve an autoencoder based architecture, but they face several\nissues such as lack of enough parameters, overfitting when there are enough\nparameters and incompatibility between internal feature-spaces. Due to such\nissues, these techniques are hence not able to extract the best semantic\ninformation from the limited data present for such tasks. We propose Attention\nW-Net, a new U-Net based architecture for retinal vessel segmentation to\naddress these problems. In this architecture with a LadderNet backbone, we have\ntwo main contributions: Attention Block and regularisation measures. Our\nAttention Block uses decoder features to attend over the encoder features from\nskip-connections during upsampling, resulting in higher compatibility when the\nencoder and decoder features are added. Our regularisation measures include\nimage augmentation and modifications to the ResNet Block used, which prevent\noverfitting. With these additions, we observe an AUC and F1-Score of 0.8407 and\n0.9833 - a sizeable improvement over its LadderNet backbone as well as\ncompetitive performance among the contemporary state-of-the-art methods.",
    "descriptor": "\nComments: Under review at ICASSP 2022, Singapore\n",
    "authors": [
      "Shikhar Mohan",
      "Saumik Bhattacharya",
      "Sayantari Ghosh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08811"
  },
  {
    "id": "arXiv:2110.08812",
    "title": "Rheumatoid Arthritis: Automated Scoring of Radiographic Joint Damage",
    "abstract": "Rheumatoid arthritis is an autoimmune disease that causes joint damage due to\ninflammation in the soft tissue lining the joints known as the synovium. It is\nvital to identify joint damage as soon as possible to provide necessary\ntreatment early and prevent further damage to the bone structures. Radiographs\nare often used to assess the extent of the joint damage. Currently, the scoring\nof joint damage from the radiograph takes expertise, effort, and time. Joint\ndamage associated with rheumatoid arthritis is also not quantitated in clinical\npractice and subjective descriptors are used. In this work, we describe a\npipeline of deep learning models to automatically identify and score rheumatoid\narthritic joint damage from a radiographic image. Our automatic tool was shown\nto produce scores with extremely high balanced accuracy within a couple of\nminutes and utilizing this would remove the subjectivity of the scores between\nhuman reviewers.",
    "descriptor": "",
    "authors": [
      "Yan Ming Tan",
      "Raphael Quek Hao Chong",
      "Carol Anne Hargreaves"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08812"
  },
  {
    "id": "arXiv:2110.08813",
    "title": "VISinger: Variational Inference with Adversarial Learning for End-to-End  Singing Voice Synthesis",
    "abstract": "In this paper, we propose VISinger, a complete end-to-end high-quality\nsinging voice synthesis (SVS) system that directly generates audio waveform\nfrom lyrics and musical score. Our approach is inspired by VITS, which adopts\nVAE-based posterior encoder augmented with normalizing flow-based prior encoder\nand adversarial decoder to realize complete end-to-end speech generation.\nVISinger follows the main architecture of VITS, but makes substantial\nimprovements to the prior encoder based on the characteristics of singing.\nFirst, instead of using phoneme-level mean and variance of acoustic features,\nwe introduce a length regulator and a frame prior network to get the\nframe-level mean and variance on acoustic features, modeling the rich acoustic\nvariation in singing. Second, we further introduce an F0 predictor to guide the\nframe prior network, leading to stabler singing performance. Finally, to\nimprove the singing rhythm, we modify the duration predictor to specifically\npredict the phoneme to note duration ratio, helped with singing note\nnormalization. Experiments on a professional Mandarin singing corpus show that\nVISinger significantly outperforms FastSpeech+Neural-Vocoder two-stage approach\nand the oracle VITS; ablation study demonstrates the effectiveness of different\ncontributions.",
    "descriptor": "\nComments: 5 pages, submitted to ICASSP 2022\n",
    "authors": [
      "Yongmao Zhang",
      "Jian Cong",
      "Heyang Xue",
      "Lei Xie",
      "Pengcheng Zhu",
      "Mengxiao Bi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.08813"
  },
  {
    "id": "arXiv:2110.08817",
    "title": "A deep learning pipeline for localization, differentiation, and  uncertainty estimation of liver lesions using multi-phasic and multi-sequence  MRI",
    "abstract": "Objectives: to propose a fully-automatic computer-aided diagnosis (CAD)\nsolution for liver lesion characterization, with uncertainty estimation.\nMethods: we enrolled 400 patients who had either liver resection or a biopsy\nand was diagnosed with either hepatocellular carcinoma (HCC), intrahepatic\ncholangiocarcinoma, or secondary metastasis, from 2006 to 2019. Each patient\nwas scanned with T1WI, T2WI, T1WI venous phase (T2WI-V), T1WI arterial phase\n(T1WI-A), and DWI MRI sequences. We propose a fully-automatic deep CAD pipeline\nthat localizes lesions from 3D MRI studies using key-slice parsing and provides\na confidence measure for its diagnoses. We evaluate using five-fold cross\nvalidation and compare performance against three radiologists, including a\nsenior hepatology radiologist, a junior hepatology radiologist and an abdominal\nradiologist.\nResults: the proposed CAD solution achieves a mean F1 score of 0.62,\noutperforming the abdominal radiologist (0.47), matching the junior hepatology\nradiologist (0.61), and underperforming the senior hepatology radiologist\n(0.68). The CAD system can informatively assess its diagnostic confidence,\ni.e., when only evaluating on the 70% most confident cases the mean f1 score\nand sensitivity at 80% specificity for HCC vs. others are boosted from 0.62 to\n0.71 and 0.84 to 0.92, respectively.\nConclusion: the proposed fully-automatic CAD solution can provide good\ndiagnostic performance with informative confidence assessments in finding and\ndiscriminating liver lesions from MRI studies.",
    "descriptor": "\nComments: 18 pages, 6 figures\n",
    "authors": [
      "Peng Wang",
      "Yuhsuan Wu",
      "Bolin Lai",
      "Xiao-Yun Zhou",
      "Le Lu",
      "Wendi Liu",
      "Huabang Zhou",
      "Lingyun Huang",
      "Jing Xiao",
      "Adam P. Harrison",
      "Ningyang Jia",
      "Heping Hu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08817"
  },
  {
    "id": "arXiv:2110.08843",
    "title": "Graph Wedgelets: Adaptive Data Compression on Graphs based on Binary  Wedge Partitioning Trees and Geometric Wavelets",
    "abstract": "We introduce graph wegdelets - a tool for data compression on graphs based on\nthe representation of signals by piecewise constant functions on adaptively\ngenerated binary wedge partitionings of a graph. For this, we transfer\npartitioning and compression techniques known for 2D images to general graph\nstructures and develop discrete variants of continuous wedgelets and binary\nspace partitionings. We prove that continuous results on best $m$-term\napproximation with geometric wavelets can be transferred to the discrete graph\nsetting, and show that our wedgelet representation of graph signals can be\nencoded and implemented in a simple way. Finally, we illustrate that this graph\nbased method can be applied for the compression of images as well.",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Wolfgang Erb"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.08843"
  },
  {
    "id": "arXiv:2110.08850",
    "title": "Understanding the network formation pattern for better link prediction",
    "abstract": "As a classical problem in the field of complex networks, link prediction has\nattracted much attention from researchers, which is of great significance to\nhelp us understand the evolution and dynamic development mechanisms of\nnetworks. Although various network type-specific algorithms have been proposed\nto tackle the link prediction problem, most of them suppose that the network\nstructure is dominated by the Triadic Closure Principle. We still lack an\nadaptive and comprehensive understanding of network formation patterns for\npredicting potential links. In addition, it is valuable to investigate how\nnetwork local information can be better utilized. To this end, we proposed a\nnovel method named Link prediction using Multiple Order Local Information\n(MOLI) that exploits the local information from the neighbors of different\ndistances, with parameters that can be a prior-driven based on prior knowledge,\nor data-driven by solving an optimization problem on observed networks. MOLI\ndefined a local network diffusion process via random walks on the graph,\nresulting in better use of network information. We show that MOLI outperforms\nthe other 11 widely used link prediction algorithms on 11 different types of\nsimulated and real-world networks. We also conclude that there are different\npatterns of local information utilization for different networks, including\nsocial networks, communication networks, biological networks, etc. In\nparticular, the classical common neighbor-based algorithm is not as adaptable\nto all social networks as it is perceived to be; instead, some of the social\nnetworks obey the Quadrilateral Closure Principle which preferentially connects\npaths of length three.",
    "descriptor": "\nComments: 21 pages, 3 figures, 18 tables, and 29 references\n",
    "authors": [
      "Jiating Yu",
      "Ling-Yun Wu"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Molecular Networks (q-bio.MN)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.08850"
  },
  {
    "id": "arXiv:2110.08862",
    "title": "Deep Learning Based EDM Subgenre Classification using Mel-Spectrogram  and Tempogram Features",
    "abstract": "Along with the evolution of music technology, a large number of styles, or\n\"subgenres,\" of Electronic Dance Music(EDM) have emerged in recent years. While\nthe classification task of distinguishing between EDM and non-EDM has been\noften studied in the context of music genre classification, little work has\nbeen done on the more challenging EDM subgenre classification. The state-of-art\nmodel is based on extremely randomized trees and could be improved by deep\nlearning methods. In this paper, we extend the state-of-art music auto-tagging\nmodel \"short-chunkCNN+Resnet\" to EDM subgenre classification, with the addition\nof two mid-level tempo-related feature representations, called the Fourier\ntempogram and autocorrelation tempogram. And, we explore two fusion strategies,\nearly fusion and late fusion, to aggregate the two types of tempograms. We\nevaluate the proposed models using a large dataset consisting of 75,000 songs\nfor 30 different EDM subgenres, and show that the adoption of deep learning\nmodels and tempo features indeed leads to higher classification accuracy.",
    "descriptor": "",
    "authors": [
      "Wei-Han Hsu",
      "Bo-Yu Chen",
      "Yi-Hsuan Yang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.08862"
  },
  {
    "id": "arXiv:2110.08868",
    "title": "Accurate Baryon Acoustic Oscillations reconstruction via semi-discrete  optimal transport",
    "abstract": "Optimal transport theory has recently reemerged as a vastly resourceful field\nof mathematics with elegant applications across physics and computer science.\nHarnessing methods from geometry processing, we report on the efficient\nimplementation for a specific problem in cosmology -- the reconstruction of the\nlinear density field from low redshifts, in particular the recovery of the\nBaryonic Acoustic Oscillation (BAO) scale. We demonstrate our algorithm's\naccuracy by retrieving the BAO scale in noise-less cosmological simulations\nthat are dedicated to cancel cosmic variance; we find uncertainties to be\nreduced by factor of 4.3 compared with performing no reconstruction, and a\nfactor of 3.1 compared with standard reconstruction.",
    "descriptor": "\nComments: Comments welcome! 5 pages excluding references, 2 figures, 1 table\n",
    "authors": [
      "Sebastian von Hausegger",
      "Bruno L\u00e9vy",
      "Roya Mohayaee"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.08868"
  },
  {
    "id": "arXiv:2110.08884",
    "title": "Persuasion by Dimension Reduction",
    "abstract": "How should an agent (the sender) observing multi-dimensional data (the state\nvector) persuade another agent to take the desired action? We show that it is\nalways optimal for the sender to perform a (non-linear) dimension reduction by\nprojecting the state vector onto a lower-dimensional object that we call the\n\"optimal information manifold.\" We characterize geometric properties of this\nmanifold and link them to the sender's preferences. Optimal policy splits\ninformation into \"good\" and \"bad\" components. When the sender's marginal\nutility is linear, revealing the full magnitude of good information is always\noptimal. In contrast, with concave marginal utility, optimal information design\nconceals the extreme realizations of good information and only reveals its\ndirection (sign). We illustrate these effects by explicitly solving several\nmulti-dimensional Bayesian persuasion problems.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2102.10909\n",
    "authors": [
      "Semyon Malamud",
      "Andreas Schrimpf"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "General Economics (econ.GN)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.08884"
  },
  {
    "id": "arXiv:2110.08901",
    "title": "Gravitational wave surrogates through automated machine learning",
    "abstract": "We analyze a prospect for predicting gravitational waveforms from compact\nbinaries based on automated machine learning (AutoML) from around a hundred\ndifferent possible regression models, without having to resort to tedious and\nmanual case-by-case analyses and fine-tuning. The particular study of this\narticle is within the context of the gravitational waves emitted by the\ncollision of two spinless black holes in initial quasi-circular orbit. We find,\nfor example, that approaches such as Gaussian process regression with radial\nbases as kernels do provide a sufficiently accurate solution, an approach which\nis generalizable to multiple dimensions with low computational evaluation cost.\nThe results here presented suggest that AutoML might provide a framework for\nregression in the field of surrogates for gravitational waveforms. Our study is\nwithin the context of surrogates of numerical relativity simulations based on\nReduced Basis and the Empirical Interpolation Method, where we find that for\nthe particular case analyzed AutoML can produce surrogates which are\nessentially indistinguishable from the NR simulations themselves.",
    "descriptor": "\nComments: 15 pages, 7 figures\n",
    "authors": [
      "Dami\u00e1n Barsotti",
      "Franco Cerino",
      "Manuel Tiglio",
      "Aar\u00f3n Villanueva"
    ],
    "subjectives": [
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08901"
  },
  {
    "id": "arXiv:2110.08936",
    "title": "Rejoinder: Learning Optimal Distributionally Robust Individualized  Treatment Rules",
    "abstract": "We thank the opportunity offered by editors for this discussion and the\ndiscussants for their insightful comments and thoughtful contributions. We also\nwant to congratulate Kallus (2020) for his inspiring work in improving the\nefficiency of policy learning by retargeting. Motivated from the discussion in\nDukes and Vansteelandt (2020), we first point out interesting connections and\ndistinctions between our work and Kallus (2020) in Section 1. In particular,\nthe assumptions and sources of variation for consideration in these two papers\nlead to different research problems with different scopes and focuses. In\nSection 2, following the discussions in Li et al. (2020); Liang and Zhao\n(2020), we also consider the efficient policy evaluation problem when we have\nsome data from the testing distribution available at the training stage. We\nshow that under the assumption that the sample sizes from training and testing\nare growing in the same order, efficient value function estimates can deliver\ncompetitive performance. We further show some connections of these estimates\nwith existing literature. However, when the growth of testing sample size\navailable for training is in a slower order, efficient value function estimates\nmay not perform well anymore. In contrast, the requirement of the testing\nsample size for DRITR is not as strong as that of efficient policy evaluation\nusing the combined data. Finally, we highlight the general applicability and\nusefulness of DRITR in Section 3.",
    "descriptor": "",
    "authors": [
      "Weibin Mo",
      "Zhengling Qi",
      "Yufeng Liu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08936"
  },
  {
    "id": "arXiv:2110.08966",
    "title": "Computing Semilinear Sparse Models for Approximately Eventually Periodic  Signals",
    "abstract": "Some elements of the theory and algorithmics corresponding to the computation\nof semilinear sparse models for discrete-time signals are presented. In this\nstudy, we will focus on approximately eventually periodic discrete-time\nsignals, that is, signals that can exhibit an aperiodic behavior for an initial\namount of time, and then become approximately periodic afterwards. The\nsemilinear models considered in this study are obtained by combining sparse\nrepresentation methods, linear autoregressive models and GRU neural network\nmodels, initially fitting each block model independently using some reference\ndata corresponding to some signal under consideration, and then fitting some\nmixing parameters that are used to obtain a signal model consisting of a linear\ncombination of the previously fitted blocks using the aforementioned reference\ndata, computing sparse representations of some of the matrix parameters of the\nresulting model along the process. Some prototypical computational\nimplementations are presented as well.",
    "descriptor": "",
    "authors": [
      "Fredy Vides"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.08966"
  },
  {
    "id": "arXiv:2110.08973",
    "title": "The Spooky Pebble Game",
    "abstract": "Pebble games are commonly used to study space-time trade-offs in computation.\nWe present a pebble game that explores this trade-off in quantum simulation of\narbitrary classical circuits on non-classical inputs. Many quantum algorithms,\nsuch as Shor's algorithm and Grover's search, include subroutines that require\nsimulation of classical functions on inputs in superposition. The current state\nof the art uses generic reversible simulation through Bennett's pebble game and\nuniversal reversible gate sets such as the Toffoli. Using measurement-based\nuncomputation, we replace many of the ancilla qubits used by existing\nconstructions with classical control bits, which are cheaper. Our pebble game\nforms a natural framework for reasoning about measurement-based uncomputation,\nand we prove tight bounds on the time complexity of all algorithms that use our\npebble game. For any $\\epsilon \\in (0,1)$, we present an algorithm that can\nsimulate irreversible classical computation that uses $\\mathcal{T}$ time and\n$\\mathcal{S}$ space in\n$O(\\frac{1}{\\epsilon}\\frac{\\mathcal{T}^{1+\\epsilon}}{\\mathcal{S}^\\epsilon})$\ntime with $O(\\frac{1}{\\epsilon}\\mathcal{S})$ qubits. With access to more qubits\nwe present algorithms that run in $O(\\frac{1}{\\epsilon}\\mathcal{T})$ time with\n$O(\\mathcal{S}^{1-\\epsilon}\\mathcal{T}^\\epsilon)$ qubits. Both of these results\nshow an improvement over Bennett's construction, which requires\n$O(\\frac{\\mathcal{T}^{1+\\epsilon}}{\\mathcal{S}^\\epsilon})$ time when using\n$O(\\epsilon2^{1/\\epsilon} \\mathcal{S} (1+\\log\n\\frac{\\mathcal{T}}{\\mathcal{S}}))$ qubits. Additionally the results in our\npaper combine with Barrington's theorem to provide a general method to\nefficiently compute any log-depth circuit on quantum inputs using a constant\nnumber of ancilla qubits. We also explore a connection between the optimal\nstructure of our pebbling algorithms and backtracking from dynamic programming.",
    "descriptor": "",
    "authors": [
      "Niels Kornerup",
      "Jonathan Sadun",
      "David Soloveichik"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2110.08973"
  },
  {
    "id": "arXiv:2110.08989",
    "title": "Valid and Exact Statistical Inference for Multi-dimensional Multiple  Change-Points by Selective Inference",
    "abstract": "In this paper, we study statistical inference of change-points (CPs) in\nmulti-dimensional sequence. In CP detection from a multi-dimensional sequence,\nit is often desirable not only to detect the location, but also to identify the\nsubset of the components in which the change occurs. Several algorithms have\nbeen proposed for such problems, but no valid exact inference method has been\nestablished to evaluate the statistical reliability of the detected locations\nand components. In this study, we propose a method that can guarantee the\nstatistical reliability of both the location and the components of the detected\nchanges. We demonstrate the effectiveness of the proposed method by applying it\nto the problems of genomic abnormality identification and human behavior\nanalysis.",
    "descriptor": "",
    "authors": [
      "Ryota Sugiyama",
      "Hiroki Toda",
      "Vo Nguyen Le Duy",
      "Yu Inatsu",
      "Ichiro Takeuchi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08989"
  },
  {
    "id": "arXiv:2110.09000",
    "title": "Supervised Metric Learning for Music Structure Feature",
    "abstract": "Music structure analysis (MSA) methods traditionally search for musically\nmeaningful patterns in audio: homogeneity, repetition, novelty, and\nsegment-length regularity. Hand-crafted audio features such as MFCCs or\nchromagrams are often used to elicit these patterns. However, with more\nannotations of section labels (e.g., verse, chorus, and bridge) becoming\navailable, one can use supervised feature learning to make these patterns even\nclearer and improve MSA performance. To this end, we take a supervised metric\nlearning approach: we train a deep neural network to output embeddings that are\nnear each other for two spectrogram inputs if both have the same section type\n(according to an annotation), and otherwise far apart. We propose a batch\nsampling scheme to ensure the labels in a training pair are interpreted\nmeaningfully. The trained model extracts features that can be used in existing\nMSA algorithms. In evaluations with three datasets (HarmonixSet, SALAMI, and\nRWC), we demonstrate that using the proposed features can improve a traditional\nMSA algorithm significantly in both intra- and cross-dataset scenarios.",
    "descriptor": "\nComments: Pre-print for an accepted paper by ISMIR 2021\n",
    "authors": [
      "Ju-Chiang Wang",
      "Jordan B. L. Smith",
      "Wei-Tsung Lu",
      "Xuchen Song"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.09000"
  },
  {
    "id": "arXiv:2110.09005",
    "title": "Unsupervised Learned Kalman Filtering",
    "abstract": "In this paper we adapt KalmanNet, which is a recently pro-posed deep neural\nnetwork (DNN)-aided system whose architecture follows the operation of the\nmodel-based Kalman filter (KF), to learn its mapping in an unsupervised manner,\ni.e., without requiring ground-truth states. The unsupervised adaptation is\nachieved by exploiting the hybrid model-based/data-driven architecture of\nKalmanNet, which internally predicts the next observation as the KF does. These\ninternal features are then used to compute the loss rather than the state\nestimate at the output of the system. With the capability of unsupervised\nlearning, one can use KalmanNet not only to track the hidden state, but also to\nadapt to variations in the state space (SS) model. We numerically demonstrate\nthat when the noise statistics are unknown, unsupervised KalmanNet achieves a\nsimilar performance to KalmanNet with supervised learning. We also show that we\ncan adapt a pre-trained KalmanNet to changing SS models without providing\nadditional data thanks to the unsupervised capabilities.",
    "descriptor": "\nComments: 5 Pages, 5 Figures, Submitted to ICASSP 2022\n",
    "authors": [
      "Guy Revach",
      "Nir Shlezinger",
      "Timur Locher",
      "Xiaoyong Ni",
      "Ruud J. G. van Sloun",
      "Yonina C. Eldar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09005"
  },
  {
    "id": "arXiv:2110.09019",
    "title": "Similarity-and-Independence-Aware Beamformer with Iterative Casting and  Boost Start for Target Source Extraction Using Reference",
    "abstract": "Target source extraction is significant for improving human speech\nintelligibility and the speech recognition performance of computers. This study\ndescribes a method for target source extraction, called the\nsimilarity-and-independence-aware beamformer (SIBF). The SIBF extracts the\ntarget source using a rough magnitude spectrogram as the reference signal. The\nadvantage of the SIBF is that it can obtain a more accurate signal than the\nspectrogram generated by target-enhancing methods such as speech enhancement\nbased on deep neural networks. For the extraction, we extend the framework of\ndeflationary independent component analysis (ICA) by considering the\nsimilarities between the reference and extracted target sources, in addition to\nthe mutual independence of all the potential sources. To solve the extraction\nproblem by maximum-likelihood estimation, we introduce three source models that\ncan reflect the similarities. The major contributions of this study are as\nfollows. First, the extraction performance is improved using two methods,\nnamely boost start for faster convergence and iterative casting for generating\na more accurate reference. The effectiveness of these methods is verified\nthrough experiments using the CHiME3 dataset. Second, a concept of a fixed\npoint pertaining to accuracy is developed. This concept facilitates\nunderstanding the relationship between the reference and SIBF output in terms\nof accuracy. Third, a unified formulation of the SIBF and mask-based beamformer\nis realized to apply the expertise of conventional BFs to the SIBF. The\nfindings of this study can also improve the performance of the SIBF and promote\nresearch on ICA and conventional beamformers.\nIndex Terms: beamformer, independent component analysis, source separation,\nspeech enhancement, target source extraction",
    "descriptor": "\nComments: Accepted for publication as a regular paper in the IEEE Open Journal of Signal Processing\n",
    "authors": [
      "Atsuo Hiroe"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.09019"
  },
  {
    "id": "arXiv:2110.09040",
    "title": "A Bayesian approach to multi-task learning with network lasso",
    "abstract": "Network lasso is a method for solving a multi-task learning problem through\nthe regularized maximum likelihood method. A characteristic of network lasso is\nsetting a different model for each sample. The relationships among the models\nare represented by relational coefficients. A crucial issue in network lasso is\nto provide appropriate values for these relational coefficients. In this paper,\nwe propose a Bayesian approach to solve multi-task learning problems by network\nlasso. This approach allows us to objectively determine the relational\ncoefficients by Bayesian estimation. The effectiveness of the proposed method\nis shown in a simulation study and a real data analysis.",
    "descriptor": "",
    "authors": [
      "Kaito Shimamura",
      "Shuichi Kawano"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.09040"
  },
  {
    "id": "arXiv:2110.09076",
    "title": "An actor-critic algorithm with deep double recurrent agents to solve the  job shop scheduling problem",
    "abstract": "There is a growing interest in integrating machine learning techniques and\noptimization to solve challenging optimization problems. In this work, we\npropose a deep reinforcement learning methodology for the job shop scheduling\nproblem (JSSP). The aim is to build up a greedy-like heuristic able to learn on\nsome distribution of JSSP instances, different in the number of jobs and\nmachines. The need for fast scheduling methods is well known, and it arises in\nmany areas, from transportation to healthcare. We model the JSSP as a Markov\nDecision Process and then we exploit the efficacy of reinforcement learning to\nsolve the problem. We adopt an actor-critic scheme, where the action taken by\nthe agent is influenced by policy considerations on the state-value function.\nThe procedures are adapted to take into account the challenging nature of JSSP,\nwhere the state and the action space change not only for every instance but\nalso after each decision. To tackle the variability in the number of jobs and\noperations in the input, we modeled the agent using two incident LSTM models, a\nspecial type of deep neural network. Experiments show the algorithm reaches\ngood solutions in a short time, proving that is possible to generate new greedy\nheuristics just from learning-based methodologies. Benchmarks have been\ngenerated in comparison with the commercial solver CPLEX. As expected, the\nmodel can generalize, to some extent, to larger problems or instances\noriginated by a different distribution from the one used in training.",
    "descriptor": "",
    "authors": [
      "Marta Monaci",
      "Valerio Agasucci",
      "Giorgio Grani"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09076"
  },
  {
    "id": "arXiv:2110.09113",
    "title": "Salt and pepper noise removal method based on stationary Framelet  transform with non-convex sparsity regularization",
    "abstract": "Salt and pepper noise removal is a common inverse problem in image\nprocessing, and it aims to restore image information with high quality.\nTraditional salt and pepper denoising methods have two limitations. First,\nnoise characteristics are often not described accurately. For example, the\nnoise location information is often ignored and the sparsity of the salt and\npepper noise is often described by L1 norm, which cannot illustrate the sparse\nvariables clearly. Second, conventional methods separate the contaminated image\ninto a recovered image and a noise part, thus resulting in recovering an image\nwith unsatisfied smooth parts and detail parts. In this study, we introduce a\nnoise detection strategy to determine the position of the noise, and a\nnon-convex sparsity regularization depicted by Lp quasi-norm is employed to\ndescribe the sparsity of the noise, thereby addressing the first limitation.\nThe morphological component analysis framework with stationary Framelet\ntransform is adopted to decompose the processed image into cartoon, texture,\nand noise parts to resolve the second limitation. In this framework, the\nstationary Framelet regularizations with different parameters control the\nrestoration of the cartoon and texture parts. In this way, the two parts are\nrecovered separately to avoid mutual interference. Then, the alternating\ndirection method of multipliers (ADMM) is employed to solve the proposed model.\nFinally, experiments are conducted to verify the proposed method and compare it\nwith some current state-of-the-art denoising methods. The experimental results\nshow that the proposed method can remove salt and pepper noise while preserving\nthe details of the processed image.",
    "descriptor": "",
    "authors": [
      "Yingpin Chen",
      "Lingzhi Wang",
      "Huiying Huang",
      "Jianhua Song",
      "Chaoqun Yu",
      "Yanping Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09113"
  },
  {
    "id": "arXiv:2110.09134",
    "title": "GAN-based disentanglement learning for chest X-ray rib suppression",
    "abstract": "Clinical evidence has shown that rib-suppressed chest X-rays (CXRs) can\nimprove the reliability of pulmonary disease diagnosis. However, previous\napproaches on generating rib-suppressed CXR face challenges in preserving\ndetails and eliminating rib residues. We hereby propose a GAN-based\ndisentanglement learning framework called Rib Suppression GAN, or RSGAN, to\nperform rib suppression by utilizing the anatomical knowledge embedded in\nunpaired computed tomography (CT) images. In this approach, we employ a\nresidual map to characterize the intensity difference between CXR and the\ncorresponding rib-suppressed result. To predict the residual map in CXR domain,\nwe disentangle the image into structure- and contrast-specific features and\ntransfer the rib structural priors from digitally reconstructed radiographs\n(DRRs) computed by CT. Furthermore, we employ additional adaptive loss to\nsuppress rib residue and preserve more details. We conduct extensive\nexperiments based on 1,673 CT volumes, and four benchmarking CXR datasets,\ntotaling over 120K images, to demonstrate that (i) our proposed RSGAN achieves\nsuperior image quality compared to the state-of-the-art rib suppression\nmethods; (ii) combining CXR with our rib-suppressed result leads to better\nperformance in lung disease classification and tuberculosis area detection.",
    "descriptor": "",
    "authors": [
      "Luyi Han",
      "Yuanyuan Lyu",
      "Cheng Peng",
      "S.Kevin Zhou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09134"
  },
  {
    "id": "arXiv:2110.09143",
    "title": "Variance Reduction in Stochastic Reaction Networks using Control  Variates",
    "abstract": "Monte Carlo estimation in plays a crucial role in stochastic reaction\nnetworks. However, reducing the statistical uncertainty of the corresponding\nestimators requires sampling a large number of trajectories. We propose control\nvariates based on the statistical moments of the process to reduce the\nestimators' variances. We develop an algorithm that selects an efficient subset\nof infinitely many control variates. To this end, the algorithm uses resampling\nand a redundancy-aware greedy selection. We demonstrate the efficiency of our\napproach in several case studies.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1905.00854\n",
    "authors": [
      "Michael Backenk\u00f6hler",
      "Luca Bortolussi",
      "Verena Wolf"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Systems and Control (eess.SY)",
      "Molecular Networks (q-bio.MN)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2110.09143"
  },
  {
    "id": "arXiv:2110.09148",
    "title": "Body Part Regression for CT Images",
    "abstract": "One of the greatest challenges in the medical imaging domain is to\nsuccessfully transfer deep learning models into clinical practice. Since models\nare often trained on a specific body region, a robust transfer into the clinic\nnecessitates the selection of images with body regions that fit the algorithm\nto avoid false-positive predictions in unknown regions. Due to the insufficient\nand inaccurate nature of manually-defined imaging meta-data, automated body\npart recognition is a key ingredient towards the broad and reliable adoption of\nmedical deep learning models. While some approaches to this task have been\npresented in the past, building and evaluating robust algorithms for\nfine-grained body part recognition remains challenging. So far, no easy-to-use\nmethod exists to determine the scanned body range of medical Computed\nTomography (CT) volumes. In this thesis, a self-supervised body part regression\nmodel for CT volumes is developed and trained on a heterogeneous collection of\nCT studies. Furthermore, it is demonstrated how the algorithm can contribute to\nthe robust and reliable transfer of medical models into the clinic. Finally,\neasy application of the developed method is ensured by integrating it into the\nmedical platform toolkit Kaapana and providing it as a python package at\nhttps://github.com/MIC-DKFZ/BodyPartRegression .",
    "descriptor": "",
    "authors": [
      "Sarah Schuhegger"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09148"
  },
  {
    "id": "arXiv:2110.09150",
    "title": "Tackling the Score Shift in Cross-Lingual Speaker Verification by  Exploiting Language Information",
    "abstract": "This paper contains a post-challenge performance analysis on cross-lingual\nspeaker verification of the IDLab submission to the VoxCeleb Speaker\nRecognition Challenge 2021 (VoxSRC-21). We show that current speaker embedding\nextractors consistently underestimate speaker similarity in within-speaker\ncross-lingual trials. Consequently, the typical training and scoring protocols\ndo not put enough emphasis on the compensation of intra-speaker language\nvariability. We propose two techniques to increase cross-lingual speaker\nverification robustness. First, we enhance our previously proposed Large-Margin\nFine-Tuning (LM-FT) training stage with a mini-batch sampling strategy which\nincreases the amount of intra-speaker cross-lingual samples within the\nmini-batch. Second, we incorporate language information in the logistic\nregression calibration stage. We integrate quality metrics based on soft and\nhard decisions of a VoxLingua107 language identification model. The proposed\ntechniques result in a 11.7% relative improvement over the baseline model on\nthe VoxSRC-21 test set and contributed to our third place finish in the\ncorresponding challenge.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Jenthe Thienpondt",
      "Brecht Desplanques",
      "Kris Demuynck"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.09150"
  },
  {
    "id": "arXiv:2110.09167",
    "title": "RKHS-SHAP: Shapley Values for Kernel Methods",
    "abstract": "Feature attribution for kernel methods is often heuristic and not\nindividualised for each prediction. To address this, we turn to the concept of\nShapley values, a coalition game theoretical framework that has previously been\napplied to different machine learning model interpretation tasks, such as\nlinear models, tree ensembles and deep networks. By analysing Shapley values\nfrom a functional perspective, we propose \\textsc{RKHS-SHAP}, an attribution\nmethod for kernel machines that can efficiently compute both\n\\emph{Interventional} and \\emph{Observational Shapley values} using kernel mean\nembeddings of distributions. We show theoretically that our method is robust\nwith respect to local perturbations - a key yet often overlooked desideratum\nfor interpretability. Further, we propose \\emph{Shapley regulariser},\napplicable to a general empirical risk minimisation framework, allowing\nlearning while controlling the level of specific feature's contributions to the\nmodel. We demonstrate that the Shapley regulariser enables learning which is\nrobust to covariate shift of a given feature and fair learning which controls\nthe Shapley values of sensitive features.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Siu Lun Chau",
      "Javier Gonzalez",
      "Dino Sejdinovic"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09167"
  },
  {
    "id": "arXiv:2110.09209",
    "title": "Graph-based Local Climate Classification in Iran",
    "abstract": "In this paper, we introduce a novel graph-based method to classify the\nregions with similar climate in a local area. We refer our proposed method as\nGraph Partition Based Method (GPBM). Our proposed method attempts to overcome\nthe shortcomings of the current state-of-the-art methods in the literature. It\nhas no limit on the number of variables that can be used and also preserves the\nnature of climate data. To illustrate the capability of our proposed algorithm,\nwe benchmark its performance with other state-of-the-art climate classification\ntechniques. The climate data is collected from 24 synoptic stations in Fars\nprovince in southern Iran. The data includes seven climate variables stored as\ntime series from 1951 to 2017. Our results exhibit that our proposed method\nperforms a more realistic climate classification with less computational time.\nIt can save more information during the climate classification process and is\ntherefore efficient in further data analysis. Furthermore, using our method, we\ncan introduce seasonal graphs to better investigate seasonal climate changes.\nTo the best of our knowledge, our proposed method is the first graph-based\nclimate classification system.",
    "descriptor": "\nComments: Accepted in International Journal of Climatology, 2021\n",
    "authors": [
      "Neda Akrami",
      "Koorush Ziarati",
      "Soumyabrata Dev"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09209"
  },
  {
    "id": "arXiv:2110.09211",
    "title": "Mode I and Mode II stress intensity factors and dislocation density  behaviour in strain gradient plasticity",
    "abstract": "In this study, we use the mechanism-based strain gradient plasticity theory\nto evaluate both crack tip dislocation density behaviour and the coupled effect\nof the material plastic properties and the intrinsic material length on\nnon-linear amplitude factors. The two planar classical stress-strain states are\nexamined, namely, plane strain and plane stress, both under pure mode I and\npure mode II loading conditions. The constitutive relations are based on\nTaylor's dislocation model, which enables gaining insights into the role of the\nincreased dislocation density associated with large gradients in plastic strain\nnear cracks. The material model is implemented in a commercial finite element\n(FE) software package using a user subroutine, and the nonlinear stress\nintensity factors (SIF) are evaluated as a function of the intrinsic material\nlength, characterising the scale at which gradient effects become significant.\nAs a result of the FE calculations of dislocation density distributions, the\neffects of both the fracture mode and the stress-strain state are determined.\nIn pure mode I, the geometrically necessary dislocation (GND) density is\nlocated symmetrically with respect to the blunted crack tip. On the contrary,\nunder pure mode II, the GND density becomes concentrated in the blunted and\nsharp parts of the crack tip. In this case, fracture initiation is shown to be\nlikely to occur near the blunted region of the crack tip, where both the stress\ntriaxiality and the GND density are at their maximum. The relation between the\nequilibrium state of dislocation densities and the intrinsic material length as\nwell as the plastic SIF as a function of the work hardening exponent is\ndiscussed.",
    "descriptor": "",
    "authors": [
      "V. Shlyannikov",
      "E. Mart\u00ednez-Pa\u00f1eda",
      "A. Tumanov",
      "R. Khamidullin"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2110.09211"
  },
  {
    "id": "arXiv:2110.09288",
    "title": "CT-SGAN: Computed Tomography Synthesis GAN",
    "abstract": "Diversity in data is critical for the successful training of deep learning\nmodels. Leveraged by a recurrent generative adversarial network, we propose the\nCT-SGAN model that generates large-scale 3D synthetic CT-scan volumes ($\\geq\n224\\times224\\times224$) when trained on a small dataset of chest CT-scans.\nCT-SGAN offers an attractive solution to two major challenges facing machine\nlearning in medical imaging: a small number of given i.i.d. training data, and\nthe restrictions around the sharing of patient data preventing to rapidly\nobtain larger and more diverse datasets. We evaluate the fidelity of the\ngenerated images qualitatively and quantitatively using various metrics\nincluding Fr\\'echet Inception Distance and Inception Score. We further show\nthat CT-SGAN can significantly improve lung nodule detection accuracy by\npre-training a classifier on a vast amount of synthetic data.",
    "descriptor": "\nComments: In Proceedings of MICCAI Deep Generative Models workshop, October 2021\n",
    "authors": [
      "Ahmad Pesaranghader",
      "Yiping Wang",
      "Mohammad Havaei"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09288"
  },
  {
    "id": "arXiv:2110.09294",
    "title": "Comparative Analysis of Deep Learning Algorithms for Classification of  COVID-19 X-Ray Images",
    "abstract": "The Coronavirus was first emerged in December, in the city of China named\nWuhan in 2019 and spread quickly all over the world. It has very harmful\neffects all over the global economy, education, social, daily living and\ngeneral health of humans. To restrict the quick expansion of the disease\ninitially, main difficulty is to explore the positive corona patients as\nquickly as possible. As there are no automatic tool kits accessible the\nrequirement for supplementary diagnostic tools has risen up. Previous studies\nhave findings acquired from radiological techniques proposed that this kind of\nimages have important details related to the coronavirus. The usage of modified\nArtificial Intelligence (AI) system in combination with radio-graphical images\ncan be fruitful for the precise and exact solution of this virus and can also\nbe helpful to conquer the issue of deficiency of professional physicians in\ndistant villages. In our research, we analyze the different techniques for the\ndetection of COVID-19 using X-Ray radiographic images of the chest, we examined\nthe different pre-trained CNN models AlexNet, VGG-16, MobileNet-V2, SqeezeNet,\nResNet-34, ResNet-50 and COVIDX-Net to correct analytics for classification\nsystem of COVID-19. Our study shows that the pre trained CNN Model with\nResNet-34 technique gives the higher accuracy rate of 98.33, 96.77% precision,\nand 98.36 F1-score, which is better than other CNN techniques. Our model may be\nhelpful for the researchers to fine train the CNN model for the the quick\nscreening of COVID patients.",
    "descriptor": "",
    "authors": [
      "Unsa Maheen",
      "Khawar Iqbal Malik",
      "Gohar Ali"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09294"
  },
  {
    "id": "arXiv:2110.09305",
    "title": "Vit-GAN: Image-to-image Translation with Vision Transformes and  Conditional GANS",
    "abstract": "In this paper, we have developed a general-purpose architecture, Vit-Gan,\ncapable of performing most of the image-to-image translation tasks from\nsemantic image segmentation to single image depth perception. This paper is a\nfollow-up paper, an extension of generator-based model [1] in which the\nobtained results were very promising. This opened the possibility of further\nimprovements with adversarial architecture. We used a unique vision\ntransformers-based generator architecture and Conditional GANs(cGANs) with a\nMarkovian Discriminator (PatchGAN) (https://github.com/YigitGunduc/vit-gan). In\nthe present work, we use images as conditioning arguments. It is observed that\nthe obtained results are more realistic than the commonly used architectures.",
    "descriptor": "",
    "authors": [
      "Yi\u011fit G\u00fcnd\u00fc\u00e7"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09305"
  },
  {
    "id": "arXiv:2110.09307",
    "title": "Stochastic Constitutive Model of Isotropic Thin Fiber Networks Based on  Stochastic Volume Elements",
    "abstract": "Thin fiber networks are widely represented in nature and can be found in\nman-made materials such as paper and packaging. The strength of such materials\nis an intricate subject due to inherited randomness and size-dependencies.\nDirect fiber-level numerical simulations can provide insights into the role of\nthe constitutive components of such networks, their morphology, and\narrangements on the strength of the products made of them. However, direct\nmechanical simulation of randomly generated large and thin fiber networks is\ncharacterized by overwhelming computational costs. Herein, a stochastic\nconstitutive model for predicting the random mechanical response of isotropic\nthin fiber networks of arbitrary size is presented. The model is based on\nstochastic volume elements (SVEs) with SVE size-specific deterministic and\nstochastic constitutive law parameters. The randomness in the network is\ndescribed by the spatial fields of the uniaxial strain and strength to failure,\nformulated using multivariate kernel functions and approximate univariate\nprobability density functions. The proposed stochastic continuum approach shows\ngood agreement when compared to direct numerical simulation with respect to\nmechanical response. Furthermore, strain localization patterns matched the one\nobserved in direct simulations, which suggests an accurate prediction of the\nfailure location. This work demonstrates that the proposed stochastic\nconstitutive model can be used to predict the response of random isotropic\nfiber networks of arbitrary size.",
    "descriptor": "\nComments: 28 pages, 19 figures\n",
    "authors": [
      "Rami Mansour",
      "Artem Kulachenko",
      "Wei Chen",
      "M\u00e5rten Olsson"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.09307"
  },
  {
    "id": "arXiv:2110.09315",
    "title": "Predicting Status of Pre and Post M&A Deals Using Machine Learning and  Deep Learning Techniques",
    "abstract": "Risk arbitrage or merger arbitrage is a well-known investment strategy that\nspeculates on the success of M&A deals. Prediction of the deal status in\nadvance is of great importance for risk arbitrageurs. If a deal is mistakenly\nclassified as a completed deal, then enormous cost can be incurred as a result\nof investing in target company shares. On the contrary, risk arbitrageurs may\nlose the opportunity of making profit. In this paper, we present an ML and DL\nbased methodology for takeover success prediction problem. We initially apply\nvarious ML techniques for data preprocessing such as kNN for data imputation,\nPCA for lower dimensional representation of numerical variables, MCA for\ncategorical variables, and LSTM autoencoder for sentiment scores. We experiment\nwith different cost functions, different evaluation metrics, and oversampling\ntechniques to address class imbalance in our dataset. We then implement\nfeedforward neural networks to predict the success of the deal status. Our\npreliminary results indicate that our methodology outperforms the benchmark\nmodels such as logit and weighted logit models. We also integrate sentiment\nscores into our methodology using different model architectures, but our\npreliminary results show that the performance is not changing much compared to\nthe simple FFNN framework. We will explore different architectures and employ a\nthorough hyperparameter tuning for sentiment scores as a future work.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Tugce Karatas",
      "Ali Hirsa"
    ],
    "subjectives": [
      "General Finance (q-fin.GN)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09315"
  },
  {
    "id": "arXiv:2110.09319",
    "title": "Incremental Cross-Domain Adaptation for Robust Retinopathy Screening via  Bayesian Deep Learning",
    "abstract": "Retinopathy represents a group of retinal diseases that, if not treated\ntimely, can cause severe visual impairments or even blindness. Many researchers\nhave developed autonomous systems to recognize retinopathy via fundus and\noptical coherence tomography (OCT) imagery. However, most of these frameworks\nemploy conventional transfer learning and fine-tuning approaches, requiring a\ndecent amount of well-annotated training data to produce accurate diagnostic\nperformance. This paper presents a novel incremental cross-domain adaptation\ninstrument that allows any deep classification model to progressively learn\nabnormal retinal pathologies in OCT and fundus imagery via few-shot training.\nFurthermore, unlike its competitors, the proposed instrument is driven via a\nBayesian multi-objective function that not only enforces the candidate\nclassification network to retain its prior learned knowledge during incremental\ntraining but also ensures that the network understands the structural and\nsemantic relationships between previously learned pathologies and newly added\ndisease categories to effectively recognize them at the inference stage. The\nproposed framework, evaluated on six public datasets acquired with three\ndifferent scanners to screen thirteen retinal pathologies, outperforms the\nstate-of-the-art competitors by achieving an overall accuracy and F1 score of\n0.9826 and 0.9846, respectively.",
    "descriptor": "\nComments: Accepted in IEEE Transactions on Instrumentation and Measurement. Source code is available at this https URL\n",
    "authors": [
      "Taimur Hassan",
      "Bilal Hassan",
      "Muhammad Usman Akram",
      "Shahrukh Hashmi",
      "Abdel Hakim Taguri",
      "Naoufel Werghi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09319"
  },
  {
    "id": "arXiv:2110.09326",
    "title": "Neural message passing for predicting abnormal grain growth in Monte  Carlo simulations of microstructural evolution",
    "abstract": "Abnormal grain growth can significantly alter the properties of materials\nduring processing. This can cause significant variation in the properties and\nperformance of in-spec feedstock components subjected to identical processing\npaths. Understanding and controlling abnormal grain growth has proved to be\nelusive due to the stochastic nature of this phenomenon. However, recent\nadvances in deep learning provide a promising alternative to traditional\nexperimental and physics-based methods for understanding this phenomenon.\nNeural message passing allows deep learning to be applied to irregular inputs\nincluding graph representations of grain structures in a material. In this\nstudy we generate a large database of Monte Carlo simulations of abnormal grain\ngrowth in an idealized system. We apply message passing neural networks to\npredict the occurrence of abnormal grain growth in these simulations using only\nthe initial state of the system as input. A computer vision model is also\ntrained for the same task for comparison. The preliminary results indicate that\nthe message passing approach outperforms the computer vision method and\nachieved 75% prediction accuracy, significantly better than random guessing.\nAnalysis of the uncertainty in the Monte Carlo simulations provides a road map\nfor ongoing work on this project.",
    "descriptor": "\nComments: 17 pages, 11 figures\n",
    "authors": [
      "Ryan Cohn",
      "Elizabeth Holm"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09326"
  },
  {
    "id": "arXiv:2110.09339",
    "title": "Finite Sections of Periodic Schr\u00f6dinger Operators",
    "abstract": "We study discrete Schr\\\"odinger operators $H$ with periodic potentials as\nthey are typically used to approximate aperiodic Schr\\\"odinger operators like\nthe Fibonacci Hamiltonian. We prove an efficient test for applicability of the\nfinite section method, a procedure that approximates $H$ by growing finite\nsquare submatrices $H_n$. For integer-valued potentials, we show that the\nfinite section method is applicable as soon as H is invertible. This statement\nremains true for $\\{0, \\lambda\\}$-valued potentials with fixed rational\n$\\lambda$ and period less than nine as well as for arbitrary real-valued\npotentials of period two.",
    "descriptor": "\nComments: Based on arXiv:2104.00711\n",
    "authors": [
      "Fabian Gabel",
      "Dennis Gallaun",
      "Julian Gro\u00dfmann",
      "Marko Lindner",
      "Riko Ukena"
    ],
    "subjectives": [
      "Spectral Theory (math.SP)",
      "Mathematical Physics (math-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.09339"
  },
  {
    "id": "arXiv:2110.09346",
    "title": "Planar Median Graphs and Cubesquare-Graphs",
    "abstract": "Median graphs are connected graphs in which for all three vertices there is a\nunique vertex that belongs to shortest paths between each pair of these three\nvertices. In this paper we provide several novel characterizations of planar\nmedian graphs. More specifically, we characterize when a planar graph $G$ is a\nmedian graph in terms of forbidden subgraphs and the structure of isometric\ncycles in $G$, and also in terms of subgraphs of $G$ that are contained inside\nand outside of 4-cycles with respect to an arbitrary planar embedding of $G$.\nThese results lead us to a new characterization of planar median graphs in\nterms of cubesquare-graphs that is, graphs that can be obtained by starting\nwith cubes and square graphs, and iteratively replacing 4-cycle boundaries\n(relative to some embedding) by cubes or square-graphs. As a corollary we also\nshow that a graph is planar median if and only if it can be obtained from cubes\nand square-graphs by a sequence of ``square-boundary'' amalgamations. These\nconsiderations also lead to an $\\mathcal{O}(n\\log n)$-time recognition\nalgorithm to compute a decomposition of a planar median graph with $n$ vertices\ninto cubes and square-graphs.",
    "descriptor": "",
    "authors": [
      "Carsten R. Seemann",
      "Vincent Moulton",
      "Peter F. Stadler",
      "Marc Hellmuth"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.09346"
  },
  {
    "id": "arXiv:2110.09354",
    "title": "An Analysis and Implementation of the HDR+ Burst Denoising Method",
    "abstract": "HDR+ is an image processing pipeline presented by Google in 2016. At its core\nlies a denoising algorithm that uses a burst of raw images to produce a single\nhigher quality image. Since it is designed as a versatile solution for\nsmartphone cameras, it does not necessarily aim for the maximization of\nstandard denoising metrics, but rather for the production of natural, visually\npleasing images. In this article, we specifically discuss and analyze the HDR+\nburst denoising algorithm architecture and the impact of its various\nparameters. With this publication, we provide an open source Python\nimplementation of the algorithm, along with an interactive demo.",
    "descriptor": "\nComments: 28 pages, 15 figures, published at this https URL, code on this https URL\n",
    "authors": [
      "Antoine Monod",
      "Julie Delon",
      "Thomas Veit"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09354"
  },
  {
    "id": "arXiv:2110.09360",
    "title": "Prediction of liquid fuel properties using machine learning models with  Gaussian processes and probabilistic conditional generative learning",
    "abstract": "Accurate determination of fuel properties of complex mixtures over a wide\nrange of pressure and temperature conditions is essential to utilizing\nalternative fuels. The present work aims to construct cheap-to-compute machine\nlearning (ML) models to act as closure equations for predicting the physical\nproperties of alternative fuels. Those models can be trained using the database\nfrom MD simulations and/or experimental measurements in a data-fusion-fidelity\napproach. Here, Gaussian Process (GP) and probabilistic generative models are\nadopted. GP is a popular non-parametric Bayesian approach to build surrogate\nmodels mainly due to its capacity to handle the aleatory and epistemic\nuncertainties. Generative models have shown the ability of deep neural networks\nemployed with the same intent. In this work, ML analysis is focused on a\nparticular property, the fuel density, but it can also be extended to other\nphysicochemical properties. This study explores the versatility of the ML\nmodels to handle multi-fidelity data. The results show that ML models can\npredict accurately the fuel properties of a wide range of pressure and\ntemperature conditions.",
    "descriptor": "\nComments: 22 pages, 13 figures\n",
    "authors": [
      "Rodolfo S. M. Freitas",
      "\u00c1gatha P. F. Lima",
      "Cheng Chen",
      "Fernando A. Rochinha",
      "Daniel Mira",
      "Xi Jiang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09360"
  },
  {
    "id": "arXiv:2110.09361",
    "title": "Efficient Exploration in Binary and Preferential Bayesian Optimization",
    "abstract": "Bayesian optimization (BO) is an effective approach to optimize expensive\nblack-box functions, that seeks to trade-off between exploitation (selecting\nparameters where the maximum is likely) and exploration (selecting parameters\nwhere we are uncertain about the objective function). In many real-world\nsituations, direct measurements of the objective function are not possible, and\nonly binary measurements such as success/failure or pairwise comparisons are\navailable. To perform efficient exploration in this setting, we show that it is\nimportant for BO algorithms to distinguish between different types of\nuncertainty: epistemic uncertainty, about the unknown objective function, and\naleatoric uncertainty, which comes from noisy observations and cannot be\nreduced. In effect, only the former is important for efficient exploration.\nBased on this, we propose several new acquisition functions that outperform\nstate-of-the-art heuristics in binary and preferential BO, while being fast to\ncompute and easy to implement. We then generalize these acquisition rules to\nbatch learning, where multiple queries are performed simultaneously.",
    "descriptor": "",
    "authors": [
      "Tristan Fauvel",
      "Matthew Chalk"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.09361"
  },
  {
    "id": "arXiv:2110.09384",
    "title": "Automatic Detection of COVID-19 and Pneumonia from Chest X-Ray using  Deep Learning",
    "abstract": "In this study, a dataset of X-ray images from patients with common viral\npneumonia, bacterial pneumonia, confirmed Covid-19 disease was utilized for the\nautomatic detection of the Coronavirus disease. The point of the investigation\nis to assess the exhibition of cutting edge convolutional neural system\nstructures proposed over the ongoing years for clinical picture order. In\nparticular, the system called Transfer Learning was received. With transfer\nlearning, the location of different variations from the norm in little clinical\npicture datasets is a reachable objective, regularly yielding amazing outcomes.\nThe datasets used in this trial. Firstly, a collection of 24000 X-ray images\nincludes 6000 images for confirmed Covid-19 disease,6000 confirmed common\nbacterial pneumonia and 6000 images of normal conditions. The information was\ngathered and expanded from the accessible X-Ray pictures on open clinical\nstores. The outcomes recommend that Deep Learning with X-Ray imaging may\nseparate noteworthy biological markers identified with the Covid-19 sickness,\nwhile the best precision, affectability, and particularity acquired is 97.83%,\n96.81%, and 98.56% individually.",
    "descriptor": "",
    "authors": [
      "Sarath Pathari"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09384"
  },
  {
    "id": "arXiv:2110.09413",
    "title": "SGEN: Single-cell Sequencing Graph Self-supervised Embedding Network",
    "abstract": "Single-cell sequencing has a significant role to explore biological processes\nsuch as embryonic development, cancer evolution, and cell differentiation.\nThese biological properties can be presented by a two-dimensional scatter plot.\nHowever, single-cell sequencing data generally has very high dimensionality.\nTherefore, dimensionality reduction should be used to process the high\ndimensional sequencing data for 2D visualization and subsequent biological\nanalysis. The traditional dimensionality reduction methods, which do not\nconsider the structure characteristics of single-cell sequencing data, are\ndifficult to reveal the data structure in the 2D representation. In this paper,\nwe develop a 2D feature representation method based on graph convolutional\nnetworks (GCN) for the visualization of single-cell data, termed single-cell\nsequencing graph embedding networks (SGEN). This method constructs the graph by\nthe similarity relationship between cells and adopts GCN to analyze the\nneighbor embedding information of samples, which makes the similar cell closer\nto each other on the 2D scatter plot. The results show SGEN achieves obvious 2D\ndistribution and preserves the high-dimensional relationship of different\ncells. Meanwhile, similar cell clusters have spatial continuity rather than\nrelying heavily on random initialization, which can reflect the trajectory of\ncell development in this scatter plot.",
    "descriptor": "\nComments: 6 pages body + 2 pages reference\n",
    "authors": [
      "Ziyi Liu",
      "Minghui Liao",
      "Fulin luo",
      "Bo Du"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09413"
  },
  {
    "id": "arXiv:2110.09469",
    "title": "Hybrid PUF: A Novel Way to Enhance the Security of Classical PUFs",
    "abstract": "Physical unclonable functions provide a unique 'fingerprint' to a physical\nentity by exploiting the inherent physical randomness. With the help of quantum\ninformation theory, this paper proposes solutions to protect PUFs against\nmachine learning-based attacks. Here, based on the querying capability, we\nfirst divide the adversaries into two classes, namely adaptive and weak\nadversaries. We also modify an existing security notion, universal\nunforgeability, to capture the power of those two classes of adversaries. We\nthen introduce the notion of a hybrid PUF, using a classical PUF and quantum\nconjugate coding. This construction encodes the output of a classical PUF in\nnon-orthogonal quantum states. We show that the indistinguishability of those\nstates can significantly enhance the security of the classical PUFs against\nweak adversaries. Moreover, we show that learning the underlying classical PUF\nfrom the outputs of our HPUF construction is at least as hard as learning the\nclassical PUF from its random noisy outputs. To prevent the adversaries from\nquerying the PUFs adaptively, we borrow ideas from a classical lockdown\ntechnique and apply them to our hybrid PUF. We show that the hybrid PUFs,\ntogether with the lockdown technique, termed as hybrid locked PUF, can provide\na secure client authentication protocol against adaptive adversaries and are\nimplementable with the current day quantum communication technology. Moreover,\nwe show that HLPUF allows the server to reuse the challenges for further client\nauthentication, providing an efficient solution for running a PUF-based client\nauthentication protocol for a longer period while maintaining a small-sized\nchallenge-response pairs database on the server-side. Finally, we explore the\nlockdown technique with quantum PUF and show that the direct adaptation of the\nclassical lockdown technique will not work with the fully quantum PUFs.",
    "descriptor": "",
    "authors": [
      "Kaushik Chakraborty",
      "Mina Doosti",
      "Yao Ma",
      "Myrto Arapinis",
      "Elham Kashefi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.09469"
  },
  {
    "id": "arXiv:2110.09473",
    "title": "DBSegment: Fast and robust segmentation of deep brain structures --  Evaluation of transportability across acquisition domains",
    "abstract": "Segmenting deep brain structures from magnetic resonance images is important\nfor patient diagnosis, surgical planning, and research. Most current\nstate-of-the-art solutions follow a segmentation-by-registration approach,\nwhere subject MRIs are mapped to a template with well-defined segmentations.\nHowever, registration-based pipelines are time-consuming, thus, limiting their\nclinical use. This paper uses deep learning to provide a robust and efficient\ndeep brain segmentation solution. The method consists of a pre-processing step\nto conform all MRI images to the same orientation, followed by a convolutional\nneural network using the nnU-Net framework. We use a total of 14 datasets from\nboth research and clinical collections. Of these, seven were used for training\nand validation and seven were retained for independent testing. We trained the\nnetwork to segment 30 deep brain structures, as well as a brain mask, using\nlabels generated from a registration-based approach. We evaluated the\ngeneralizability of the network by performing a leave-one-dataset-out\ncross-validation, and extensive testing on external datasets. Furthermore, we\nassessed cross-domain transportability by evaluating the results separately on\ndifferent domains. We achieved an average DSC of 0.89 $\\pm$ 0.04 on the\nindependent testing datasets when compared to the registration-based gold\nstandard. On our test system, the computation time decreased from 42 minutes\nfor a reference registration-based pipeline to 1 minute. Our proposed method is\nfast, robust, and generalizes with high reliability. It can be extended to the\nsegmentation of other brain structures. The method is publicly available on\nGitHub, as well as a pip package for convenient usage.",
    "descriptor": "",
    "authors": [
      "Mehri Baniasadi",
      "Mikkel V. Petersen",
      "Jorge Goncalves",
      "Andreas Horn",
      "Vanja Vlasov",
      "Frank Hertel",
      "Andreas Husch"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2110.09473"
  },
  {
    "id": "arXiv:2110.09483",
    "title": "Evaluating NISQ Devices with Quadratic Nonresidues",
    "abstract": "Comparing the relative quality of NISQ devices is difficult. Algorithms\nshowing a quantum advantage are often tailored precisely to what a particular\nNISQ does well. We present a new algorithm for evaluating NISQs using quadratic\nnonresidues. We prove quantum computers can find quadratic nonresidues in\ndeterministic polynomial time, whereas the classical version of this problem\nremains unsolved after hundreds of years. Using a restrictive computational\nrule set for finding quadratic nonresidues, we can compare the NISQ success\nrate with what is possible for a classical computer to accomplish under the\nsame rules. A success rate greater than 75% provides evidence of quantum\nadvantage. We present the results of current NISQ devices running this test.",
    "descriptor": "\nComments: 20 pages, 14 figures, 2 tables. arXiv admin note: text overlap with arXiv:2106.03991\n",
    "authors": [
      "Thomas G. Draper"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2110.09483"
  },
  {
    "id": "arXiv:2110.09489",
    "title": "Sector Volatility Prediction Performance Using GARCH Models and  Artificial Neural Networks",
    "abstract": "Recently artificial neural networks (ANNs) have seen success in volatility\nprediction, but the literature is divided on where an ANN should be used rather\nthan the common GARCH model. The purpose of this study is to compare the\nvolatility prediction performance of ANN and GARCH models when applied to\nstocks with low, medium, and high volatility profiles. This approach intends to\nidentify which model should be used for each case. The volatility profiles\ncomprise of five sectors that cover all stocks in the U.S stock market from\n2005 to 2020. Three GARCH specifications and three ANN architectures are\nexamined for each sector, where the most adequate model is chosen to move on to\nforecasting. The results indicate that the ANN model should be used for\npredicting volatility of assets with low volatility profiles, and GARCH models\nshould be used when predicting volatility of medium and high volatility assets.",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Curtis Nybo"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09489"
  },
  {
    "id": "arXiv:2110.09502",
    "title": "Minimum $\\ell_{1}$-norm interpolators: Precise asymptotics and multiple  descent",
    "abstract": "An evolving line of machine learning works observe empirical evidence that\nsuggests interpolating estimators -- the ones that achieve zero training error\n-- may not necessarily be harmful. This paper pursues theoretical understanding\nfor an important type of interpolators: the minimum $\\ell_{1}$-norm\ninterpolator, which is motivated by the observation that several learning\nalgorithms favor low $\\ell_1$-norm solutions in the over-parameterized regime.\nConcretely, we consider the noisy sparse regression model under Gaussian\ndesign, focusing on linear sparsity and high-dimensional asymptotics (so that\nboth the number of features and the sparsity level scale proportionally with\nthe sample size).\nWe observe, and provide rigorous theoretical justification for, a curious\nmulti-descent phenomenon; that is, the generalization risk of the minimum\n$\\ell_1$-norm interpolator undergoes multiple (and possibly more than two)\nphases of descent and ascent as one increases the model capacity. This\nphenomenon stems from the special structure of the minimum $\\ell_1$-norm\ninterpolator as well as the delicate interplay between the over-parameterized\nratio and the sparsity, thus unveiling a fundamental distinction in geometry\nfrom the minimum $\\ell_2$-norm interpolator. Our finding is built upon an exact\ncharacterization of the risk behavior, which is governed by a system of two\nnon-linear equations with two unknowns.",
    "descriptor": "",
    "authors": [
      "Yue Li",
      "Yuting Wei"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.09502"
  },
  {
    "id": "arXiv:1712.01145",
    "title": "Learning Fast and Slow: PROPEDEUTICA for Real-time Malware Detection",
    "abstract": "Comments: 12 pages, 4 figures. This paper has been accepted to IEEE Transactions on Neural Networks and Learning Systems (TNNLS)",
    "descriptor": "\nComments: 12 pages, 4 figures. This paper has been accepted to IEEE Transactions on Neural Networks and Learning Systems (TNNLS)\n",
    "authors": [
      "Ruimin Sun",
      "Xiaoyong Yuan",
      "Pan He",
      "Qile Zhu",
      "Aokun Chen",
      "Andre Gregio",
      "Daniela Oliveira",
      "Xiaolin Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1712.01145"
  },
  {
    "id": "arXiv:1802.05904",
    "title": "Error and Stability Estimates of the Least-Squares Variational  Kernel-Based Methods for Second Order PDEs",
    "abstract": "Comments: This paper includes 29 pages, 1 figure and 2 tables",
    "descriptor": "\nComments: This paper includes 29 pages, 1 figure and 2 tables\n",
    "authors": [
      "Salar Seyednazari",
      "Mehdi Tatari",
      "Davoud Mirzaei"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1802.05904"
  },
  {
    "id": "arXiv:1811.01060",
    "title": "A two-step symmetric method for charged-particle dynamics in a normal or  strong magnetic feld",
    "abstract": "A two-step symmetric method for charged-particle dynamics in a normal or  strong magnetic feld",
    "descriptor": "",
    "authors": [
      "Bin Wang",
      "Xinyuan Wu",
      "Yonglei Fang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1811.01060"
  },
  {
    "id": "arXiv:1901.08057",
    "title": "Large dimensional analysis of general margin based classification  methods",
    "abstract": "Comments: 33 pages, 5 figures",
    "descriptor": "\nComments: 33 pages, 5 figures\n",
    "authors": [
      "Hanwen Huang",
      "Qinglong Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/1901.08057"
  },
  {
    "id": "arXiv:1902.04742",
    "title": "Uniform convergence may be unable to explain generalization in deep  learning",
    "abstract": "Uniform convergence may be unable to explain generalization in deep  learning",
    "descriptor": "",
    "authors": [
      "Vaishnavh Nagarajan",
      "J. Zico Kolter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1902.04742"
  },
  {
    "id": "arXiv:1903.12278",
    "title": "Numerical preservation of multiple local conservation laws",
    "abstract": "Numerical preservation of multiple local conservation laws",
    "descriptor": "",
    "authors": [
      "Gianluca Frasca-Caccia",
      "Peter E. Hydon"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1903.12278"
  },
  {
    "id": "arXiv:1904.02422",
    "title": "Resource Efficient 3D Convolutional Neural Networks",
    "abstract": "Comments: Accepted to ICCV 2019 workshop - Neural Architects",
    "descriptor": "\nComments: Accepted to ICCV 2019 workshop - Neural Architects\n",
    "authors": [
      "Okan K\u00f6p\u00fckl\u00fc",
      "Neslihan Kose",
      "Ahmet Gunduz",
      "Gerhard Rigoll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1904.02422"
  },
  {
    "id": "arXiv:1904.06942",
    "title": "Non-Sequential Theory of Distributed Systems",
    "abstract": "Comments: lecture notes, 82 pages; this version: minor revisions, extended ICPDL to EQ-ICPDL",
    "descriptor": "\nComments: lecture notes, 82 pages; this version: minor revisions, extended ICPDL to EQ-ICPDL\n",
    "authors": [
      "Benedikt Bollig",
      "Paul Gastin"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/1904.06942"
  },
  {
    "id": "arXiv:1906.10747",
    "title": "Intention Detection of Gait Adaptation in Natural Settings",
    "abstract": "Intention Detection of Gait Adaptation in Natural Settings",
    "descriptor": "",
    "authors": [
      "Ines Domingos",
      "Guang-Zhong Yang",
      "Fani Deligianni"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/1906.10747"
  },
  {
    "id": "arXiv:1908.09128",
    "title": "Position-Aware Self-Attention based Neural Sequence Labeling",
    "abstract": "Comments: 12 pages, 6 figures",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Wei Wei",
      "Zanbo Wang",
      "Xianling Mao",
      "Guangyou Zhou",
      "Pan Zhou",
      "Sheng Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1908.09128"
  },
  {
    "id": "arXiv:1910.09714",
    "title": "Smoothness-Adaptive Contextual Bandits",
    "abstract": "Smoothness-Adaptive Contextual Bandits",
    "descriptor": "",
    "authors": [
      "Yonatan Gur",
      "Ahmadreza Momeni",
      "Stefan Wager"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1910.09714"
  },
  {
    "id": "arXiv:1910.11588",
    "title": "On the Decidability of Termination for Polynomial Loops",
    "abstract": "On the Decidability of Termination for Polynomial Loops",
    "descriptor": "",
    "authors": [
      "Florian Frohn",
      "Marcel Hark",
      "J\u00fcrgen Giesl"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1910.11588"
  },
  {
    "id": "arXiv:1911.02319",
    "title": "Improving reinforcement learning algorithms: towards optimal learning  rate policies",
    "abstract": "Improving reinforcement learning algorithms: towards optimal learning  rate policies",
    "descriptor": "",
    "authors": [
      "Othmane Mounjid",
      "Charles-Albert Lehalle"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.02319"
  },
  {
    "id": "arXiv:1911.02424",
    "title": "Convergence Acceleration of Ensemble Kalman Inversion in Nonlinear  Settings",
    "abstract": "Convergence Acceleration of Ensemble Kalman Inversion in Nonlinear  Settings",
    "descriptor": "",
    "authors": [
      "Neil K. Chada",
      "Xin T. Tong"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/1911.02424"
  },
  {
    "id": "arXiv:1911.06644",
    "title": "You Only Watch Once: A Unified CNN Architecture for Real-Time  Spatiotemporal Action Localization",
    "abstract": "You Only Watch Once: A Unified CNN Architecture for Real-Time  Spatiotemporal Action Localization",
    "descriptor": "",
    "authors": [
      "Okan K\u00f6p\u00fckl\u00fc",
      "Xiangyu Wei",
      "Gerhard Rigoll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1911.06644"
  },
  {
    "id": "arXiv:1912.09552",
    "title": "Robust Product-line Pricing under Generalized Extreme Value Models",
    "abstract": "Robust Product-line Pricing under Generalized Extreme Value Models",
    "descriptor": "",
    "authors": [
      "Tien Mai",
      "Patrick Jaillet"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/1912.09552"
  },
  {
    "id": "arXiv:2001.04286",
    "title": "Nonparametric Continuous Sensor Registration",
    "abstract": "Comments: 50 pages. Accepted for Journal of Machine Learning Research. arXiv admin note: text overlap with arXiv:1904.02266",
    "descriptor": "\nComments: 50 pages. Accepted for Journal of Machine Learning Research. arXiv admin note: text overlap with arXiv:1904.02266\n",
    "authors": [
      "William Clark",
      "Maani Ghaffari",
      "Anthony Bloch"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2001.04286"
  },
  {
    "id": "arXiv:2002.00223",
    "title": "Dialogue-Based Simulation For Cultural Awareness Training",
    "abstract": "Dialogue-Based Simulation For Cultural Awareness Training",
    "descriptor": "",
    "authors": [
      "Sodiq Adewole",
      "Erfaneh Gharavi",
      "Benjamin Shpringer",
      "Martin Bolger",
      "Vaibhav Sharma",
      "Sung Ming Yang",
      "Donald E. Brown"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2002.00223"
  },
  {
    "id": "arXiv:2002.07336",
    "title": "The power of adaptivity in source location on the path",
    "abstract": "The power of adaptivity in source location on the path",
    "descriptor": "",
    "authors": [
      "Victor Lecomte",
      "Gergely \u00d3dor",
      "Patrick Thiran"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2002.07336"
  },
  {
    "id": "arXiv:2002.07955",
    "title": "Improved Classical and Quantum Algorithms for the Shortest Vector  Problem via Bounded Distance Decoding",
    "abstract": "Comments: Faster Quantum Algorithm for SVP in QRAM, 43 pages, 4 figures",
    "descriptor": "\nComments: Faster Quantum Algorithm for SVP in QRAM, 43 pages, 4 figures\n",
    "authors": [
      "Divesh Aggarwal",
      "Yanlin Chen",
      "Rajendra Kumar",
      "Yixin Shen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2002.07955"
  },
  {
    "id": "arXiv:2003.00660",
    "title": "Upper Confidence Primal-Dual Reinforcement Learning for CMDP with  Adversarial Loss",
    "abstract": "Upper Confidence Primal-Dual Reinforcement Learning for CMDP with  Adversarial Loss",
    "descriptor": "",
    "authors": [
      "Shuang Qiu",
      "Xiaohan Wei",
      "Zhuoran Yang",
      "Jieping Ye",
      "Zhaoran Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.00660"
  },
  {
    "id": "arXiv:2003.06566",
    "title": "On the benefits of defining vicinal distributions in latent space",
    "abstract": "Comments: Accepted at Elsevier Pattern Recognition Letters (2021), Best Paper Award at CVPR 2021 Workshop on Adversarial Machine Learning in Real-World Computer Vision (AML-CV), Also accepted at ICLR 2021 Workshops on Robust-Reliable Machine Learning (Oral) and Generalization beyond the training distribution (Abstract)",
    "descriptor": "\nComments: Accepted at Elsevier Pattern Recognition Letters (2021), Best Paper Award at CVPR 2021 Workshop on Adversarial Machine Learning in Real-World Computer Vision (AML-CV), Also accepted at ICLR 2021 Workshops on Robust-Reliable Machine Learning (Oral) and Generalization beyond the training distribution (Abstract)\n",
    "authors": [
      "Puneet Mangla",
      "Vedant Singh",
      "Shreyas Jayant Havaldar",
      "Vineeth N Balasubramanian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.06566"
  },
  {
    "id": "arXiv:2003.10323",
    "title": "Monte Carlo integration of non-differentiable functions on  $[0,1]^\u03b9$, $\u03b9=1,\\dots,d$, using a single determinantal point pattern  defined on $[0,1]^d$",
    "abstract": "Monte Carlo integration of non-differentiable functions on  $[0,1]^\u03b9$, $\u03b9=1,\\dots,d$, using a single determinantal point pattern  defined on $[0,1]^d$",
    "descriptor": "",
    "authors": [
      "Jean-Fran\u00e7ois Coeurjolly",
      "Adrien Mazoyer",
      "Pierre-Olivier Amblard"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Classical Analysis and ODEs (math.CA)",
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2003.10323"
  },
  {
    "id": "arXiv:2003.12739",
    "title": "Modulating Bottom-Up and Top-Down Visual Processing via  Language-Conditional Filters",
    "abstract": "Comments: 13 pages, 6 figures, currently under review for IEEE Transactions on Multimedia",
    "descriptor": "\nComments: 13 pages, 6 figures, currently under review for IEEE Transactions on Multimedia\n",
    "authors": [
      "\u0130lker Kesen",
      "Ozan Arkan Can",
      "Erkut Erdem",
      "Aykut Erdem",
      "Deniz Yuret"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2003.12739"
  },
  {
    "id": "arXiv:2003.13883",
    "title": "Autonomous Cave Surveying with an Aerial Robot",
    "abstract": "Comments: 17 pages, 14 figures; accepted for publication in IEEE Transactions on Robotics (TRO 2021) and adds additional experimental results",
    "descriptor": "\nComments: 17 pages, 14 figures; accepted for publication in IEEE Transactions on Robotics (TRO 2021) and adds additional experimental results\n",
    "authors": [
      "Wennie Tabib",
      "Kshitij Goel",
      "John Yao",
      "Curtis Boirum",
      "Nathan Michael"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2003.13883"
  },
  {
    "id": "arXiv:2004.05973",
    "title": "Speak2Label: Using Domain Knowledge for Creating a Large Scale Driver  Gaze Zone Estimation Dataset",
    "abstract": "Speak2Label: Using Domain Knowledge for Creating a Large Scale Driver  Gaze Zone Estimation Dataset",
    "descriptor": "",
    "authors": [
      "Shreya Ghosh",
      "Abhinav Dhall",
      "Garima Sharma",
      "Sarthak Gupta",
      "Nicu Sebe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2004.05973"
  },
  {
    "id": "arXiv:2004.08646",
    "title": "Macro-Action-Based Deep Multi-Agent Reinforcement Learning",
    "abstract": "Macro-Action-Based Deep Multi-Agent Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Yuchen Xiao",
      "Joshua Hoffman",
      "Christopher Amato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2004.08646"
  },
  {
    "id": "arXiv:2004.14810",
    "title": "Some Relativistic and Gravitational Properties of the Wolfram Model",
    "abstract": "Comments: 59 pages, 19 figures, submitted to Journal of Complex Systems",
    "descriptor": "\nComments: 59 pages, 19 figures, submitted to Journal of Complex Systems\n",
    "authors": [
      "Jonathan Gorard"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "General Relativity and Quantum Cosmology (gr-qc)"
    ],
    "url": "https://arxiv.org/abs/2004.14810"
  },
  {
    "id": "arXiv:2005.01071",
    "title": "Revisiting Synthesis for One-Counter Automata",
    "abstract": "Revisiting Synthesis for One-Counter Automata",
    "descriptor": "",
    "authors": [
      "Guillermo A. P\u00e9rez",
      "Ritam Raha"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2005.01071"
  },
  {
    "id": "arXiv:2005.03566",
    "title": "Noisy Differentiable Architecture Search",
    "abstract": "Comments: BMVC 2021",
    "descriptor": "\nComments: BMVC 2021\n",
    "authors": [
      "Xiangxiang Chu",
      "Bo Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.03566"
  },
  {
    "id": "arXiv:2005.07087",
    "title": "A new technique for preserving conservation laws",
    "abstract": "A new technique for preserving conservation laws",
    "descriptor": "",
    "authors": [
      "G. Frasca-Caccia",
      "P.E. Hydon"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2005.07087"
  },
  {
    "id": "arXiv:2005.14674",
    "title": "Maximal Spaces for Approximation Rates in $\\ell^1$-regularization",
    "abstract": "Maximal Spaces for Approximation Rates in $\\ell^1$-regularization",
    "descriptor": "",
    "authors": [
      "Philip Miller",
      "Thorsten Hohage"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2005.14674"
  },
  {
    "id": "arXiv:2006.05842",
    "title": "The Emergence of Individuality",
    "abstract": "Comments: The extended version of ICML 2021 paper",
    "descriptor": "\nComments: The extended version of ICML 2021 paper\n",
    "authors": [
      "Jiechuan Jiang",
      "Zongqing Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.05842"
  },
  {
    "id": "arXiv:2007.00202",
    "title": "Sparse Approximate Multifrontal Factorization with Butterfly Compression  for High Frequency Wave Equations",
    "abstract": "Sparse Approximate Multifrontal Factorization with Butterfly Compression  for High Frequency Wave Equations",
    "descriptor": "",
    "authors": [
      "Yang Liu",
      "Pieter Ghysels",
      "Lisa Claus",
      "Xiaoye Sherry Li"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2007.00202"
  },
  {
    "id": "arXiv:2007.00823",
    "title": "Dropout as a Regularizer of Interaction Effects",
    "abstract": "Dropout as a Regularizer of Interaction Effects",
    "descriptor": "",
    "authors": [
      "Benjamin Lengerich",
      "Eric P. Xing",
      "Rich Caruana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.00823"
  },
  {
    "id": "arXiv:2007.02794",
    "title": "Efficient Connected and Automated Driving Systemwith Multi-agent Graph  Reinforcement Learning",
    "abstract": "Comments: the paper is not even ready",
    "descriptor": "\nComments: the paper is not even ready\n",
    "authors": [
      "Tianyu Shi",
      "Jiawei Wang",
      "Yuankai Wu",
      "Luis Miranda-Moreno",
      "Lijun Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.02794"
  },
  {
    "id": "arXiv:2007.03408",
    "title": "A Generative Model for Texture Synthesis based on Optimal Transport  between Feature Distributions",
    "abstract": "A Generative Model for Texture Synthesis based on Optimal Transport  between Feature Distributions",
    "descriptor": "",
    "authors": [
      "Antoine Houdard",
      "Arthur Leclaire",
      "Nicolas Papadakis",
      "Julien Rabin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.03408"
  },
  {
    "id": "arXiv:2007.08057",
    "title": "A Tight Approximation Algorithm for the Cluster Vertex Deletion Problem",
    "abstract": "Comments: 23 pages, 3 figures",
    "descriptor": "\nComments: 23 pages, 3 figures\n",
    "authors": [
      "Manuel Aprile",
      "Matthew Drescher",
      "Samuel Fiorini",
      "Tony Huynh"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2007.08057"
  },
  {
    "id": "arXiv:2007.08596",
    "title": "OptChain: Optimal Transactions Placement for Scalable Blockchain  Sharding",
    "abstract": "OptChain: Optimal Transactions Placement for Scalable Blockchain  Sharding",
    "descriptor": "",
    "authors": [
      "Lan N. Nguyen",
      "Truc Nguyen",
      "Thang N. Dinh",
      "My T. Thai"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2007.08596"
  },
  {
    "id": "arXiv:2007.09248",
    "title": "Fine Timing and Frequency Synchronization for MIMO-OFDM: An Extreme  Learning Approach",
    "abstract": "Comments: 13 pages, 12 figures, has been accepted for publication in IEEE Transactions on Cognitive Communications and Networking",
    "descriptor": "\nComments: 13 pages, 12 figures, has been accepted for publication in IEEE Transactions on Cognitive Communications and Networking\n",
    "authors": [
      "Jun Liu",
      "Kai Mei",
      "Xiaochen Zhang",
      "Des McLernon",
      "Dongtang Ma",
      "Jibo Wei",
      "Syed Ali Raza Zaidi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.09248"
  },
  {
    "id": "arXiv:2007.12123",
    "title": "Receding Horizon Control Based Online Motion Planning with Partially  Infeasible LTL Specifications",
    "abstract": "Receding Horizon Control Based Online Motion Planning with Partially  Infeasible LTL Specifications",
    "descriptor": "",
    "authors": [
      "Mingyu Cai",
      "Hao Peng",
      "Zhijun Li",
      "Hongbo Gao",
      "Zhen Kan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Logic (math.LO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2007.12123"
  },
  {
    "id": "arXiv:2007.14052",
    "title": "Multioutput Gaussian Processes with Functional Data: A Study on Coastal  Flood Hazard Assessment",
    "abstract": "Multioutput Gaussian Processes with Functional Data: A Study on Coastal  Flood Hazard Assessment",
    "descriptor": "",
    "authors": [
      "A. F. L\u00f3pez-Lopera",
      "D. Idier",
      "J. Rohmer",
      "F. Bachoc"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2007.14052"
  },
  {
    "id": "arXiv:2007.14861",
    "title": "Efficient Sparse Secure Aggregation for Federated Learning",
    "abstract": "Efficient Sparse Secure Aggregation for Federated Learning",
    "descriptor": "",
    "authors": [
      "Constance Beguier",
      "Mathieu Andreux",
      "Eric W. Tramel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.14861"
  },
  {
    "id": "arXiv:2008.00152",
    "title": "Transactive Energy System Deployment over Insecure Communication Links",
    "abstract": "Comments: 10 pages, 6 figures, journal submission",
    "descriptor": "\nComments: 10 pages, 6 figures, journal submission\n",
    "authors": [
      "Yang Lu",
      "Jianming Lian",
      "Minghui Zhu",
      "Ke Ma"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2008.00152"
  },
  {
    "id": "arXiv:2008.11348",
    "title": "Variance-Reduced Splitting Schemes for Monotone Stochastic Generalized  Equations",
    "abstract": "Variance-Reduced Splitting Schemes for Monotone Stochastic Generalized  Equations",
    "descriptor": "",
    "authors": [
      "Shisheng Cui",
      "Uday V. Shanbhag"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.11348"
  },
  {
    "id": "arXiv:2008.11753",
    "title": "Countdown games, and simulation on (succinct) one-counter nets",
    "abstract": "Comments: A part of this paper elaborates arxiv-paper 1801.01073 and the related paper presented at Reachability Problems 2018",
    "descriptor": "\nComments: A part of this paper elaborates arxiv-paper 1801.01073 and the related paper presented at Reachability Problems 2018\n",
    "authors": [
      "Petr Jancar",
      "Petr Osicka",
      "Zdenek Sawa"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2008.11753"
  },
  {
    "id": "arXiv:2008.13443",
    "title": "On the Quality Requirements of Demand Prediction for Dynamic Public  Transport",
    "abstract": "Comments: 26 pages, 9 tables, 6 figures",
    "descriptor": "\nComments: 26 pages, 9 tables, 6 figures\n",
    "authors": [
      "Inon Peled",
      "Kelvin Lee",
      "Yu Jiang",
      "Justin Dauwels",
      "Francisco C. Pereira"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2008.13443"
  },
  {
    "id": "arXiv:2009.00664",
    "title": "VeRNAl: Mining RNA Structures for Fuzzy Base Pairing Network Motifs",
    "abstract": "VeRNAl: Mining RNA Structures for Fuzzy Base Pairing Network Motifs",
    "descriptor": "",
    "authors": [
      "Carlos Oliver",
      "Vincent Mallet",
      "Pericles Philippopoulos",
      "William L. Hamilton",
      "Jerome Waldispuhl"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2009.00664"
  },
  {
    "id": "arXiv:2009.02327",
    "title": "OnsagerNet: Learning Stable and Interpretable Dynamics using a  Generalized Onsager Principle",
    "abstract": "Comments: 29 pages, 19 figures",
    "descriptor": "\nComments: 29 pages, 19 figures\n",
    "authors": [
      "Haijun Yu",
      "Xinyuan Tian",
      "Weinan E",
      "Qianxiao Li"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2009.02327"
  },
  {
    "id": "arXiv:2009.06087",
    "title": "Neural Networks Enhancement with Logical Knowledge",
    "abstract": "Neural Networks Enhancement with Logical Knowledge",
    "descriptor": "",
    "authors": [
      "Alessandro Daniele",
      "Luciano Serafini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.06087"
  },
  {
    "id": "arXiv:2009.14639",
    "title": "Dissected 3D CNNs: Temporal Skip Connections for Efficient Online Video  Processing",
    "abstract": "Dissected 3D CNNs: Temporal Skip Connections for Efficient Online Video  Processing",
    "descriptor": "",
    "authors": [
      "Okan K\u00f6p\u00fckl\u00fc",
      "Stefan H\u00f6rmann",
      "Fabian Herzog",
      "Hakan Cevikalp",
      "Gerhard Rigoll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2009.14639"
  },
  {
    "id": "arXiv:2010.00373",
    "title": "Task Agnostic Continual Learning Using Online Variational Bayes with  Fixed-Point Updates",
    "abstract": "Comments: The arXiv paper \"Task Agnostic Continual Learning Using Online Variational Bayes\" is a preliminary pre-print of this paper. The main differences between the versions are: 1. We develop new algorithmic framework (FOO-VB). 2. We add multivariate Gaussian and matrix variate Gaussian versions of the algorithm. 3. We demonstrate the new algorithm performance in task agnostic scenarios",
    "descriptor": "\nComments: The arXiv paper \"Task Agnostic Continual Learning Using Online Variational Bayes\" is a preliminary pre-print of this paper. The main differences between the versions are: 1. We develop new algorithmic framework (FOO-VB). 2. We add multivariate Gaussian and matrix variate Gaussian versions of the algorithm. 3. We demonstrate the new algorithm performance in task agnostic scenarios\n",
    "authors": [
      "Chen Zeno",
      "Itay Golan",
      "Elad Hoffer",
      "Daniel Soudry"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.00373"
  },
  {
    "id": "arXiv:2010.01777",
    "title": "A Unified View on Graph Neural Networks as Graph Signal Denoising",
    "abstract": "A Unified View on Graph Neural Networks as Graph Signal Denoising",
    "descriptor": "",
    "authors": [
      "Yao Ma",
      "Xiaorui Liu",
      "Tong Zhao",
      "Yozen Liu",
      "Jiliang Tang",
      "Neil Shah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.01777"
  },
  {
    "id": "arXiv:2010.02398",
    "title": "A Recursive Logit Model with Choice Aversion and Its Application to  Transportation Networks",
    "abstract": "Comments: 58 pages, 12 figures, 6 tables; forthcoming at Transportation Research Part B: Methodological",
    "descriptor": "\nComments: 58 pages, 12 figures, 6 tables; forthcoming at Transportation Research Part B: Methodological\n",
    "authors": [
      "Austin Knies",
      "Jorge Lorca",
      "Emerson Melo"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2010.02398"
  },
  {
    "id": "arXiv:2010.02471",
    "title": "Determination for minimum symbol-pair and RT weights via torsional  degrees of repeated-root cyclic codes",
    "abstract": "Determination for minimum symbol-pair and RT weights via torsional  degrees of repeated-root cyclic codes",
    "descriptor": "",
    "authors": [
      "Boran Kim"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2010.02471"
  },
  {
    "id": "arXiv:2010.07217",
    "title": "Back to the Future: Cycle Encoding Prediction for Self-supervised  Contrastive Video Representation Learning",
    "abstract": "Comments: accepted at BMVC",
    "descriptor": "\nComments: accepted at BMVC\n",
    "authors": [
      "Xinyu Yang",
      "Majid Mirmehdi",
      "Tilo Burghardt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.07217"
  },
  {
    "id": "arXiv:2010.09429",
    "title": "Neural Additive Vector Autoregression Models for Causal Discovery in  Time Series",
    "abstract": "Comments: 11 pages, 5 figures",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Bart Bussmann",
      "Jannes Nys",
      "Steven Latr\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.09429"
  },
  {
    "id": "arXiv:2010.10216",
    "title": "Simulated Chats for Building Dialog Systems: Learning to Generate  Conversations from Instructions",
    "abstract": "Simulated Chats for Building Dialog Systems: Learning to Generate  Conversations from Instructions",
    "descriptor": "",
    "authors": [
      "Biswesh Mohapatra",
      "Gaurav Pandey",
      "Danish Contractor",
      "Sachindra Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.10216"
  },
  {
    "id": "arXiv:2011.02697",
    "title": "Center-wise Local Image Mixture For Contrastive Representation Learning",
    "abstract": "Comments: Accepted by BMVC2021",
    "descriptor": "\nComments: Accepted by BMVC2021\n",
    "authors": [
      "Hao Li",
      "Xiaopeng Zhang",
      "Hongkai Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.02697"
  },
  {
    "id": "arXiv:2011.03180",
    "title": "FedSL: Federated Split Learning on Distributed Sequential Data in  Recurrent Neural Networks",
    "abstract": "FedSL: Federated Split Learning on Distributed Sequential Data in  Recurrent Neural Networks",
    "descriptor": "",
    "authors": [
      "Ali Abedi",
      "Shehroz S. Khan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2011.03180"
  },
  {
    "id": "arXiv:2011.03185",
    "title": "Efficient quantum algorithm for dissipative nonlinear differential  equations",
    "abstract": "Comments: 36 pages, 1 figure. Published in PNAS",
    "descriptor": "\nComments: 36 pages, 1 figure. Published in PNAS\n",
    "authors": [
      "Jin-Peng Liu",
      "Herman \u00d8ie Kolden",
      "Hari K. Krovi",
      "Nuno F. Loureiro",
      "Konstantina Trivisa",
      "Andrew M. Childs"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Numerical Analysis (math.NA)",
      "Plasma Physics (physics.plasm-ph)"
    ],
    "url": "https://arxiv.org/abs/2011.03185"
  },
  {
    "id": "arXiv:2011.03525",
    "title": "SigNet: A Novel Deep Learning Framework for Radio Signal Classification",
    "abstract": "Comments: 13 pages, 8 figures",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Zhuangzhi Chen",
      "Hui Cui",
      "Jingyang Xiang",
      "Kunfeng Qiu",
      "Liang Huang",
      "Shilian Zheng",
      "Shichuan Chen",
      "Qi Xuan",
      "Xiaoniu Yang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.03525"
  },
  {
    "id": "arXiv:2011.04569",
    "title": "Signal-Guided Source Separation",
    "abstract": "Comments: Published at ITG 2021",
    "descriptor": "\nComments: Published at ITG 2021\n",
    "authors": [
      "Mohamed Elminshawi",
      "Wolfgang Mack",
      "Emanu\u00ebl A. P. Habets"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2011.04569"
  },
  {
    "id": "arXiv:2011.05348",
    "title": "SALR: Sharpness-aware Learning Rate Scheduler for Improved  Generalization",
    "abstract": "SALR: Sharpness-aware Learning Rate Scheduler for Improved  Generalization",
    "descriptor": "",
    "authors": [
      "Xubo Yue",
      "Maher Nouiehed",
      "Raed Al Kontar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.05348"
  },
  {
    "id": "arXiv:2011.07010",
    "title": "Monitoring and Diagnosability of Perception Systems",
    "abstract": "Comments: Updated version of arXiv:2005.11816",
    "descriptor": "\nComments: Updated version of arXiv:2005.11816\n",
    "authors": [
      "Pasquale Antonante",
      "David I. Spivak",
      "Luca Carlone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.07010"
  },
  {
    "id": "arXiv:2011.07097",
    "title": "Some remarks on hypergraph matching and the F\u00fcredi-Kahn-Seymour  conjecture",
    "abstract": "Some remarks on hypergraph matching and the F\u00fcredi-Kahn-Seymour  conjecture",
    "descriptor": "",
    "authors": [
      "Nikhil Bansal",
      "David G. Harris"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2011.07097"
  },
  {
    "id": "arXiv:2011.08946",
    "title": "A Unified Seeding Framework",
    "abstract": "A Unified Seeding Framework",
    "descriptor": "",
    "authors": [
      "Ya-Wen Teng",
      "Hsi-Wen Chen",
      "De-Nian Yang",
      "Yvonne-Anne Pignolet",
      "Ting-Wei Li",
      "Lydia Chen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2011.08946"
  },
  {
    "id": "arXiv:2011.09105",
    "title": "Elephants Don't Pack Groceries: Robot Task Planning for Low Entropy  Belief States",
    "abstract": "Elephants Don't Pack Groceries: Robot Task Planning for Low Entropy  Belief States",
    "descriptor": "",
    "authors": [
      "Alphonsus Adu-Bredu",
      "Zhen Zeng",
      "Neha Pusalkar",
      "Odest Chadwicke Jenkins"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2011.09105"
  },
  {
    "id": "arXiv:2011.09315",
    "title": "End-to-End Object Detection with Adaptive Clustering Transformer",
    "abstract": "Comments: BMVC 2021 Oral",
    "descriptor": "\nComments: BMVC 2021 Oral\n",
    "authors": [
      "Minghang Zheng",
      "Peng Gao",
      "Renrui Zhang",
      "Kunchang Li",
      "Xiaogang Wang",
      "Hongsheng Li",
      "Hao Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.09315"
  },
  {
    "id": "arXiv:2011.10932",
    "title": "Copernicus: Characterizing the Performance Implications of Compression  Formats Used in Sparse Workloads",
    "abstract": "Comments: 11 pages, 14 figures, 2 tables",
    "descriptor": "\nComments: 11 pages, 14 figures, 2 tables\n",
    "authors": [
      "Bahar Asgari",
      "Ramyad Hadidi",
      "Joshua Dierberger",
      "Charlotte Steinichen",
      "Amaan Marfatia",
      "Hyesoon Kim"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2011.10932"
  },
  {
    "id": "arXiv:2011.12174",
    "title": "Algorithmic Causal Sets and the Wolfram Model",
    "abstract": "Comments: 100 pages, 72 figures",
    "descriptor": "\nComments: 100 pages, 72 figures\n",
    "authors": [
      "Jonathan Gorard"
    ],
    "subjectives": [
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2011.12174"
  },
  {
    "id": "arXiv:2011.12979",
    "title": "mask-Net: Learning Context Aware Invariant Features using Adversarial  Forgetting (Student Abstract)",
    "abstract": "mask-Net: Learning Context Aware Invariant Features using Adversarial  Forgetting (Student Abstract)",
    "descriptor": "",
    "authors": [
      "Hemant Yadav",
      "Atul Anshuman Singh",
      "Rachit Mittal",
      "Sunayana Sitaram",
      "Yi Yu",
      "Rajiv Ratn Shah"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2011.12979"
  },
  {
    "id": "arXiv:2011.13120",
    "title": "Evaluation of Out-of-Distribution Detection Performance of  Self-Supervised Learning in a Controllable Environment",
    "abstract": "Comments: Accepted to NeurIPS 2020 Workshop: Self-Supervised Learning - Theory and Practice",
    "descriptor": "\nComments: Accepted to NeurIPS 2020 Workshop: Self-Supervised Learning - Theory and Practice\n",
    "authors": [
      "Jeonghoon Park",
      "Kyungmin Jo",
      "Daehoon Gwak",
      "Jimin Hong",
      "Jaegul Choo",
      "Edward Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.13120"
  },
  {
    "id": "arXiv:2011.13341",
    "title": "4D Human Body Capture from Egocentric Video via 3D Scene Grounding",
    "abstract": "4D Human Body Capture from Egocentric Video via 3D Scene Grounding",
    "descriptor": "",
    "authors": [
      "Miao Liu",
      "Dexin Yang",
      "Yan Zhang",
      "Zhaopeng Cui",
      "James M. Rehg",
      "Siyu Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.13341"
  },
  {
    "id": "arXiv:2012.01230",
    "title": "Curiosity-driven 3D Object Detection Without Labels",
    "abstract": "Comments: 19 pages, 17 figures",
    "descriptor": "\nComments: 19 pages, 17 figures\n",
    "authors": [
      "David Griffiths",
      "Jan Boehm",
      "Tobias Ritschel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.01230"
  },
  {
    "id": "arXiv:2012.01415",
    "title": "Prototype-based Incremental Few-Shot Semantic Segmentation",
    "abstract": "Comments: Accepted at BMVC 2021 (Poster)",
    "descriptor": "\nComments: Accepted at BMVC 2021 (Poster)\n",
    "authors": [
      "Fabio Cermelli",
      "Massimiliano Mancini",
      "Yongqin Xian",
      "Zeynep Akata",
      "Barbara Caputo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.01415"
  },
  {
    "id": "arXiv:2012.01788",
    "title": "Object SLAM-Based Active Mapping and Robotic Grasping",
    "abstract": "Comments: Accepted for IEEE International Conference on 3D Vision (3DV), 2021. Project page: this https URL",
    "descriptor": "\nComments: Accepted for IEEE International Conference on 3D Vision (3DV), 2021. Project page: this https URL\n",
    "authors": [
      "Yanmin Wu",
      "Yunzhou Zhang",
      "Delong Zhu",
      "Xin Chen",
      "Sonya Coleman",
      "Wenkai Sun",
      "Xinggang Hu",
      "Zhiqiang Deng"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.01788"
  },
  {
    "id": "arXiv:2012.01988",
    "title": "Wisdom of Committees: An Overlooked Approach To Faster and More Accurate  Models",
    "abstract": "Wisdom of Committees: An Overlooked Approach To Faster and More Accurate  Models",
    "descriptor": "",
    "authors": [
      "Xiaofang Wang",
      "Dan Kondratyuk",
      "Eric Christiansen",
      "Kris M. Kitani",
      "Yair Alon",
      "Elad Eban"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.01988"
  },
  {
    "id": "arXiv:2012.03581",
    "title": "DIPPAS: A Deep Image Prior PRNU Anonymization Scheme",
    "abstract": "DIPPAS: A Deep Image Prior PRNU Anonymization Scheme",
    "descriptor": "",
    "authors": [
      "Francesco Picetti",
      "Sara Mandelli",
      "Paolo Bestagini",
      "Vincenzo Lipari",
      "Stefano Tubaro"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.03581"
  },
  {
    "id": "arXiv:2012.05590",
    "title": "An Asynchronous Kalman Filter for Hybrid Event Cameras",
    "abstract": "Comments: 12 pages, 6 figures, published in International Conference on Computer Vision (ICCV) 2021",
    "descriptor": "\nComments: 12 pages, 6 figures, published in International Conference on Computer Vision (ICCV) 2021\n",
    "authors": [
      "Ziwei Wang",
      "Yonhon Ng",
      "Cedric Scheerlinck",
      "Robert Mahony"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2012.05590"
  },
  {
    "id": "arXiv:2012.05657",
    "title": "Geometric Adversarial Attacks and Defenses on 3D Point Clouds",
    "abstract": "Comments: 3DV 2021",
    "descriptor": "\nComments: 3DV 2021\n",
    "authors": [
      "Itai Lang",
      "Uriel Kotlicki",
      "Shai Avidan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.05657"
  },
  {
    "id": "arXiv:2012.08105",
    "title": "Schema Extraction on Semi-structured Data",
    "abstract": "Comments: More schema extraction methods will be investigated to enrich the content of the paper, so the manuscript is temporarily retracted",
    "descriptor": "\nComments: More schema extraction methods will be investigated to enrich the content of the paper, so the manuscript is temporarily retracted\n",
    "authors": [
      "Panpan Li",
      "Yikun Gong",
      "Chen Wang"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.08105"
  },
  {
    "id": "arXiv:2012.08418",
    "title": "Pedestrian Behavior Prediction for Automated Driving: Requirements,  Metrics, and Relevant Features",
    "abstract": "Comments: This work has been submitted to the IEEE Transactions on Intelligent Transportation Systems for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. Revision: Extended requirement analysis and evaluation. 16 pages",
    "descriptor": "\nComments: This work has been submitted to the IEEE Transactions on Intelligent Transportation Systems for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. Revision: Extended requirement analysis and evaluation. 16 pages\n",
    "authors": [
      "Michael Herman",
      "J\u00f6rg Wagner",
      "Vishnu Prabhakaran",
      "Nicolas M\u00f6ser",
      "Hanna Ziesche",
      "Waleed Ahmed",
      "Lutz B\u00fcrkle",
      "Ernst Kloppenburg",
      "Claudius Gl\u00e4ser"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.08418"
  },
  {
    "id": "arXiv:2012.09036",
    "title": "Improved StyleGAN Embedding: Where are the Good Latents?",
    "abstract": "Improved StyleGAN Embedding: Where are the Good Latents?",
    "descriptor": "",
    "authors": [
      "Peihao Zhu",
      "Rameen Abdal",
      "Yipeng Qin",
      "John Femiani",
      "Peter Wonka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2012.09036"
  },
  {
    "id": "arXiv:2012.11026",
    "title": "Independent Approximates enable closed-form parameter estimation of  heavy-tailed distributions",
    "abstract": "Comments: 30 pages, 8 figures, 7 tables",
    "descriptor": "\nComments: 30 pages, 8 figures, 7 tables\n",
    "authors": [
      "Kenric P. Nelson"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Information Theory (cs.IT)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2012.11026"
  },
  {
    "id": "arXiv:2012.11772",
    "title": "Power-SLIC: Fast Superpixel Segmentations by Diagrams",
    "abstract": "Power-SLIC: Fast Superpixel Segmentations by Diagrams",
    "descriptor": "",
    "authors": [
      "Maximilian Fiedler",
      "Andreas Alpers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.11772"
  },
  {
    "id": "arXiv:2012.12881",
    "title": "Lifespan Functors and Natural Dualities in Persistent Homology",
    "abstract": "Comments: 32 pages, 1 figure",
    "descriptor": "\nComments: 32 pages, 1 figure\n",
    "authors": [
      "Ulrich Bauer",
      "Maximilian Schmahl"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2012.12881"
  },
  {
    "id": "arXiv:2101.01076",
    "title": "Understanding Health Video Engagement: An Interpretable Deep Learning  Approach",
    "abstract": "Understanding Health Video Engagement: An Interpretable Deep Learning  Approach",
    "descriptor": "",
    "authors": [
      "Jiaheng Xie",
      "Yidong Chai",
      "Xiao Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.01076"
  },
  {
    "id": "arXiv:2101.02733",
    "title": "Layer reconstruction and missing link prediction of multilayer network  with a Maximum A Posteriori estimation",
    "abstract": "Layer reconstruction and missing link prediction of multilayer network  with a Maximum A Posteriori estimation",
    "descriptor": "",
    "authors": [
      "Junyao Kuang",
      "Caterina Scoglio"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2101.02733"
  },
  {
    "id": "arXiv:2101.04407",
    "title": "FaceX-Zoo: A PyTorch Toolbox for Face Recognition",
    "abstract": "Comments: add more backbone comparisons",
    "descriptor": "\nComments: add more backbone comparisons\n",
    "authors": [
      "Jun Wang",
      "Yinglu Liu",
      "Yibo Hu",
      "Hailin Shi",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.04407"
  },
  {
    "id": "arXiv:2101.05592",
    "title": "Dynamic network analysis of a target defense differential game with  limited observations",
    "abstract": "Comments: 8 figures",
    "descriptor": "\nComments: 8 figures\n",
    "authors": [
      "Sharad Kumar Singh",
      "Puduru Viswanadha Reddy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.05592"
  },
  {
    "id": "arXiv:2101.06722",
    "title": "Almost Optimal Construction of Functional Batch Codes Using Hadamard  Codes",
    "abstract": "Almost Optimal Construction of Functional Batch Codes Using Hadamard  Codes",
    "descriptor": "",
    "authors": [
      "Lev Yohananov",
      "Eitan Yaakobi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2101.06722"
  },
  {
    "id": "arXiv:2101.07338",
    "title": "Improving Makeup Face Verification by Exploring Part-Based  Representations",
    "abstract": "Improving Makeup Face Verification by Exploring Part-Based  Representations",
    "descriptor": "",
    "authors": [
      "Marcus de Assis Angeloni",
      "Helio Pedrini"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.07338"
  },
  {
    "id": "arXiv:2101.10961",
    "title": "The Wireless Control Bus: Enabling Efficient Multi-hop Event-Triggered  Control with Concurrent Transmissions",
    "abstract": "Comments: To appear in ACM Transactions on Cyber-Physical Systems (TCPS), 28 pages",
    "descriptor": "\nComments: To appear in ACM Transactions on Cyber-Physical Systems (TCPS), 28 pages\n",
    "authors": [
      "Matteo Trobinger",
      "Gabriel de Albuquerque Gleizer",
      "Timofei Istomin",
      "Manuel Mazo Jr.",
      "Amy L. Murphy",
      "Gian Pietro Picco"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2101.10961"
  },
  {
    "id": "arXiv:2101.12146",
    "title": "Online Tensor Completion Based Prediction For Wireless Edge Caching",
    "abstract": "Online Tensor Completion Based Prediction For Wireless Edge Caching",
    "descriptor": "",
    "authors": [
      "Navneet Garg",
      "Tharmalingam Ratnarajah"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2101.12146"
  },
  {
    "id": "arXiv:2101.12161",
    "title": "Improved Rate-Energy Trade-off For SWIPT Using Chordal Distance  Decomposition In Interference Alignment Networks",
    "abstract": "Improved Rate-Energy Trade-off For SWIPT Using Chordal Distance  Decomposition In Interference Alignment Networks",
    "descriptor": "",
    "authors": [
      "Navneet Garg",
      "Avinash Rudraksh",
      "Govind Sharma",
      "Tharmalingam Ratnarajah"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2101.12161"
  },
  {
    "id": "arXiv:2101.12353",
    "title": "On the capacity of deep generative networks for approximating  distributions",
    "abstract": "On the capacity of deep generative networks for approximating  distributions",
    "descriptor": "",
    "authors": [
      "Yunfei Yang",
      "Zhen Li",
      "Yang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2101.12353"
  },
  {
    "id": "arXiv:2101.12677",
    "title": "Diminishing Domain Bias by Leveraging Domain Labels in Object Detection  on UAVs",
    "abstract": "Comments: Accepted for publication at ICAR 2021",
    "descriptor": "\nComments: Accepted for publication at ICAR 2021\n",
    "authors": [
      "Benjamin Kiefer",
      "Martin Messmer",
      "Andreas Zell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.12677"
  },
  {
    "id": "arXiv:2102.01009",
    "title": "Infrastructure Resilience Curves: Performance Measures and Summary  Metrics",
    "abstract": "Comments: 32 pages, 4 figures. Submitted to Reliability Engineering & System Safety",
    "descriptor": "\nComments: 32 pages, 4 figures. Submitted to Reliability Engineering & System Safety\n",
    "authors": [
      "Craig Poulin",
      "Michael Kane"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2102.01009"
  },
  {
    "id": "arXiv:2102.02611",
    "title": "CKConv: Continuous Kernel Convolution For Sequential Data",
    "abstract": "CKConv: Continuous Kernel Convolution For Sequential Data",
    "descriptor": "",
    "authors": [
      "David W. Romero",
      "Anna Kuzina",
      "Erik J. Bekkers",
      "Jakub M. Tomczak",
      "Mark Hoogendoorn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.02611"
  },
  {
    "id": "arXiv:2102.02926",
    "title": "Alchemy: A structured task distribution for meta-reinforcement learning",
    "abstract": "Comments: Published in Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 2021",
    "descriptor": "\nComments: Published in Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 2021\n",
    "authors": [
      "Jane X. Wang",
      "Michael King",
      "Nicolas Porcel",
      "Zeb Kurth-Nelson",
      "Tina Zhu",
      "Charlie Deck",
      "Peter Choy",
      "Mary Cassin",
      "Malcolm Reynolds",
      "Francis Song",
      "Gavin Buttimore",
      "David P. Reichert",
      "Neil Rabinowitz",
      "Loic Matthey",
      "Demis Hassabis",
      "Alexander Lerchner",
      "Matthew Botvinick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.02926"
  },
  {
    "id": "arXiv:2102.03988",
    "title": "Ising Model Selection Using $\\ell_{1}$-Regularized Linear Regression: A  Statistical Mechanics Analysis",
    "abstract": "Comments: Accepted by NeurIPS 2021",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Xiangming Meng",
      "Tomoyuki Obuchi",
      "Yoshiyuki Kabashima"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.03988"
  },
  {
    "id": "arXiv:2102.04036",
    "title": "Simultaneous Localization and Mapping Related Datasets: A Comprehensive  Survey",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Yuanzhi Liu",
      "Yujia Fu",
      "Fengdong Chen",
      "Bart Goossens",
      "Wei Tao",
      "Hui Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2102.04036"
  },
  {
    "id": "arXiv:2102.07318",
    "title": "A Global to Local Double Embedding Method for Multi-person Pose  Estimation",
    "abstract": "A Global to Local Double Embedding Method for Multi-person Pose  Estimation",
    "descriptor": "",
    "authors": [
      "Yiming Xu",
      "Jiaxin Li",
      "Yiheng Peng",
      "Yan Ding",
      "Hua-Liang Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.07318"
  },
  {
    "id": "arXiv:2102.08864",
    "title": "Automated Test-Case Generation for Solidity Smart Contracts: the AGSolT  Approach and its Evaluation",
    "abstract": "Comments: Currently under review at Journal of Software Testing, Verification and Reliability",
    "descriptor": "\nComments: Currently under review at Journal of Software Testing, Verification and Reliability\n",
    "authors": [
      "Stefan Driessen",
      "Dario Di Nucci",
      "Geert Monsieur",
      "Willem-Jan van den Heuvel"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2102.08864"
  },
  {
    "id": "arXiv:2102.09332",
    "title": "HVAQ: A High-Resolution Vision-Based Air Quality Dataset",
    "abstract": "HVAQ: A High-Resolution Vision-Based Air Quality Dataset",
    "descriptor": "",
    "authors": [
      "Zuohui Chen",
      "Tony Zhang",
      "Zhuangzhi Chen",
      "Yun Xiang",
      "Qi Xuan",
      "Robert P. Dick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.09332"
  },
  {
    "id": "arXiv:2102.09738",
    "title": "A Sequential Learning Algorithm for Probabilistically Robust Controller  Tuning",
    "abstract": "Comments: 17 pages including appendices and references",
    "descriptor": "\nComments: 17 pages including appendices and references\n",
    "authors": [
      "Robert Chin",
      "Chris Manzie",
      "Iman Shames",
      "Dragan Ne\u0161i\u0107",
      "Jonathan E. Rowe"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.09738"
  },
  {
    "id": "arXiv:2102.10663",
    "title": "MedAug: Contrastive learning leveraging patient metadata improves  representations for chest X-ray interpretation",
    "abstract": "MedAug: Contrastive learning leveraging patient metadata improves  representations for chest X-ray interpretation",
    "descriptor": "",
    "authors": [
      "Yen Nhi Truong Vu",
      "Richard Wang",
      "Niranjan Balachandar",
      "Can Liu",
      "Andrew Y. Ng",
      "Pranav Rajpurkar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.10663"
  },
  {
    "id": "arXiv:2102.12142",
    "title": "Gaussian boson sampling and multi-particle event optimization by machine  learning in the quantum phase space",
    "abstract": "Comments: Extended version, with correct figure 4, code available in github",
    "descriptor": "\nComments: Extended version, with correct figure 4, code available in github\n",
    "authors": [
      "Claudio Conti"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2102.12142"
  },
  {
    "id": "arXiv:2103.00075",
    "title": "Noisy Truncated SGD: Optimization and Generalization",
    "abstract": "Noisy Truncated SGD: Optimization and Generalization",
    "descriptor": "",
    "authors": [
      "Yingxue Zhou",
      "Xinyan Li",
      "Arindam Banerjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.00075"
  },
  {
    "id": "arXiv:2103.01946",
    "title": "Fixing Data Augmentation to Improve Adversarial Robustness",
    "abstract": "Comments: Since its original publication (2 Mar 2021), this paper has been accepted to NeurIPS 2021 as two separate and updated papers (Rebuffi et al., 2021; Gowal et al., 2021). The new papers improve results and clarity",
    "descriptor": "\nComments: Since its original publication (2 Mar 2021), this paper has been accepted to NeurIPS 2021 as two separate and updated papers (Rebuffi et al., 2021; Gowal et al., 2021). The new papers improve results and clarity\n",
    "authors": [
      "Sylvestre-Alvise Rebuffi",
      "Sven Gowal",
      "Dan A. Calian",
      "Florian Stimberg",
      "Olivia Wiles",
      "Timothy Mann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.01946"
  },
  {
    "id": "arXiv:2103.09052",
    "title": "Selective Intervention Planning using Restless Multi-Armed Bandits to  Improve Maternal and Child Health Outcomes",
    "abstract": "Comments: 7 pages. Camera-ready version for AASG 2021 Workshop",
    "descriptor": "\nComments: 7 pages. Camera-ready version for AASG 2021 Workshop\n",
    "authors": [
      "Siddharth Nishtala",
      "Lovish Madaan",
      "Aditya Mate",
      "Harshavardhan Kamarthi",
      "Anirudh Grama",
      "Divy Thakkar",
      "Dhyanesh Narayanan",
      "Suresh Chaudhary",
      "Neha Madhiwalla",
      "Ramesh Padmanabhan",
      "Aparna Hegde",
      "Pradeep Varakantham",
      "Balaraman Ravindran",
      "Milind Tambe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.09052"
  },
  {
    "id": "arXiv:2103.09743",
    "title": "Deep Learning-based Extreme Heatwave Forecast",
    "abstract": "Comments: 20 pages, 5 figures",
    "descriptor": "\nComments: 20 pages, 5 figures\n",
    "authors": [
      "Val\u00e9rian Jacques-Dumas",
      "Francesco Ragone",
      "Pierre Borgnat",
      "Patrice Abry",
      "Freddy Bouchet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2103.09743"
  },
  {
    "id": "arXiv:2103.10245",
    "title": "Building Safer Autonomous Agents by Leveraging Risky Driving Behavior  Knowledge",
    "abstract": "Comments: Published in CCCI 2021, Best Paper Award in Informatics",
    "descriptor": "\nComments: Published in CCCI 2021, Best Paper Award in Informatics\n",
    "authors": [
      "Ashish Rana",
      "Avleen Malhi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.10245"
  },
  {
    "id": "arXiv:2103.11099",
    "title": "Local Patch AutoAugment with Multi-Agent Collaboration",
    "abstract": "Local Patch AutoAugment with Multi-Agent Collaboration",
    "descriptor": "",
    "authors": [
      "Shiqi Lin",
      "Tao Yu",
      "Ruoyu Feng",
      "Xin Li",
      "Xin Jin",
      "Zhibo Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.11099"
  },
  {
    "id": "arXiv:2103.11470",
    "title": "NeBula: Quest for Robotic Autonomy in Challenging Environments; TEAM  CoSTAR at the DARPA Subterranean Challenge",
    "abstract": "Comments: For team website, see this https URL Accepted for publication in the Journal of Field Robotics, 2021",
    "descriptor": "\nComments: For team website, see this https URL Accepted for publication in the Journal of Field Robotics, 2021\n",
    "authors": [
      "Ali Agha",
      "Kyohei Otsu",
      "Benjamin Morrell",
      "David D. Fan",
      "Rohan Thakker",
      "Angel Santamaria-Navarro",
      "Sung-Kyun Kim",
      "Amanda Bouman",
      "Xianmei Lei",
      "Jeffrey Edlund",
      "Muhammad Fadhil Ginting",
      "Kamak Ebadi",
      "Matthew Anderson",
      "Torkom Pailevanian",
      "Edward Terry",
      "Michael Wolf",
      "Andrea Tagliabue",
      "Tiago Stegun Vaquero",
      "Matteo Palieri",
      "Scott Tepsuporn",
      "Yun Chang",
      "Arash Kalantari",
      "Fernando Chavez",
      "Brett Lopez",
      "Nobuhiro Funabiki",
      "Gregory Miles",
      "Thomas Touma",
      "Alessandro Buscicchio",
      "Jesus Tordesillas",
      "Nikhilesh Alatur",
      "Jeremy Nash",
      "William Walsh",
      "Sunggoo Jung",
      "Hanseob Lee",
      "Christoforos Kanellakis",
      "John Mayo",
      "Scott Harper",
      "Marcel Kaufmann",
      "Anushri Dixit",
      "Gustavo Correa",
      "Carlyn Lee",
      "Jay Gao",
      "Gene Merewether",
      "Jairo Maldonado-Contreras",
      "Gautam Salhotra",
      "Maira Saboia Da Silva",
      "Benjamin Ramtoula",
      "Yuki Kubo",
      "Seyed Fakoorian"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.11470"
  },
  {
    "id": "arXiv:2103.11933",
    "title": "PatentSBERTa: A Deep NLP based Hybrid Model for Patent Distance and  Classification using Augmented SBERT",
    "abstract": "Comments: 18 pages, 7 figures and 4 Tables",
    "descriptor": "\nComments: 18 pages, 7 figures and 4 Tables\n",
    "authors": [
      "Hamid Bekamiri",
      "Daniel S. Hain",
      "Roman Jurowetzki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2103.11933"
  },
  {
    "id": "arXiv:2103.12459",
    "title": "Dual Mesh Convolutional Networks for Human Shape Correspondence",
    "abstract": "Dual Mesh Convolutional Networks for Human Shape Correspondence",
    "descriptor": "",
    "authors": [
      "Nitika Verma",
      "Adnane Boukhayma",
      "Jakob Verbeek",
      "Edmond Boyer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.12459"
  },
  {
    "id": "arXiv:2103.12488",
    "title": "The Digital Agricultural Revolution: a Bibliometric Analysis Literature  Review",
    "abstract": "The Digital Agricultural Revolution: a Bibliometric Analysis Literature  Review",
    "descriptor": "",
    "authors": [
      "Riccardo Bertoglio",
      "Chiara Corbo",
      "Filippo M. Renga",
      "Matteo Matteucci"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2103.12488"
  },
  {
    "id": "arXiv:2103.13020",
    "title": "deGraphCS: Embedding Variable-based Flow Graph for Neural Code Search",
    "abstract": "Comments: 32 pages",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Chen Zeng",
      "Yue Yu",
      "Shanshan Li",
      "Xin Xia",
      "Zhiming Wang",
      "Mingyang Geng",
      "Bailin Xiao",
      "Wei Dong",
      "Xiangke Liao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.13020"
  },
  {
    "id": "arXiv:2103.13300",
    "title": "Automatic Cough Classification for Tuberculosis Screening in a  Real-World Environment",
    "abstract": "Comments: This paper has been accepted in Physiological Measurement (2021)",
    "descriptor": "\nComments: This paper has been accepted in Physiological Measurement (2021)\n",
    "authors": [
      "Madhurananda Pahar",
      "Marisa Klopper",
      "Byron Reeve",
      "Grant Theron",
      "Rob Warren",
      "Thomas Niesler"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2103.13300"
  },
  {
    "id": "arXiv:2103.13538",
    "title": "Hierarchical Proxy-based Loss for Deep Metric Learning",
    "abstract": "Comments: Accepted to WACV2022",
    "descriptor": "\nComments: Accepted to WACV2022\n",
    "authors": [
      "Zhibo Yang",
      "Muhammet Bastan",
      "Xinliang Zhu",
      "Doug Gray",
      "Dimitris Samaras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.13538"
  },
  {
    "id": "arXiv:2103.14616",
    "title": "Training a Task-Specific Image Reconstruction Loss",
    "abstract": "Comments: Accepted at WACV 2022",
    "descriptor": "\nComments: Accepted at WACV 2022\n",
    "authors": [
      "Aamir Mustafa",
      "Aliaksei Mikhailiuk",
      "Dan Andrei Iliescu",
      "Varun Babbar",
      "Rafal K. Mantiuk"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.14616"
  },
  {
    "id": "arXiv:2103.14804",
    "title": "LSTM Based Sentiment Analysis for Cryptocurrency Prediction",
    "abstract": "LSTM Based Sentiment Analysis for Cryptocurrency Prediction",
    "descriptor": "",
    "authors": [
      "Xin Huang",
      "Wenbin Zhang",
      "Xuejiao Tang",
      "Mingli Zhang",
      "Jayachander Surbiryala",
      "Vasileios Iosifidis",
      "Zhen Liu",
      "Ji Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.14804"
  },
  {
    "id": "arXiv:2103.15776",
    "title": "CHAD: Combinatory Homomorphic Automatic Differentiation",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2007.05283",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2007.05283\n",
    "authors": [
      "Matthijs V\u00e1k\u00e1r",
      "Tom Smeding"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2103.15776"
  },
  {
    "id": "arXiv:2104.02145",
    "title": "What Will it Take to Fix Benchmarking in Natural Language Understanding?",
    "abstract": "Comments: Proceedings of NAACL 2020. This revision adds a missing acknowledgment",
    "descriptor": "\nComments: Proceedings of NAACL 2020. This revision adds a missing acknowledgment\n",
    "authors": [
      "Samuel R. Bowman",
      "George E. Dahl"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.02145"
  },
  {
    "id": "arXiv:2104.03133",
    "title": "Image Composition Assessment with Saliency-augmented Multi-pattern  Pooling",
    "abstract": "Image Composition Assessment with Saliency-augmented Multi-pattern  Pooling",
    "descriptor": "",
    "authors": [
      "Bo Zhang",
      "Li Niu",
      "Liqing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.03133"
  },
  {
    "id": "arXiv:2104.03187",
    "title": "A Preliminary Proposal for an Analytical Model for Evaluating the Impact  on Performance of Data Access Patterns in Transaction Execution",
    "abstract": "A Preliminary Proposal for an Analytical Model for Evaluating the Impact  on Performance of Data Access Patterns in Transaction Execution",
    "descriptor": "",
    "authors": [
      "Pierangelo Di Sanzo"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2104.03187"
  },
  {
    "id": "arXiv:2104.04724",
    "title": "Occlusion Guided Self-supervised Scene Flow Estimation on 3D Point  Clouds",
    "abstract": "Comments: Accepted at 3DV 2021 (Poster)",
    "descriptor": "\nComments: Accepted at 3DV 2021 (Poster)\n",
    "authors": [
      "Bojun Ouyang",
      "Dan Raviv"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.04724"
  },
  {
    "id": "arXiv:2104.04902",
    "title": "Sublinear Time Nearest Neighbor Search over Generalized Weighted  Manhattan Distance",
    "abstract": "Comments: The proposed schemes($d_w^{l_1},l_2$)-ALSH and ($d_w^{l_1},\\theta$)-ALSH will be compared as soon as possible",
    "descriptor": "\nComments: The proposed schemes($d_w^{l_1},l_2$)-ALSH and ($d_w^{l_1},\\theta$)-ALSH will be compared as soon as possible\n",
    "authors": [
      "Huan Hu",
      "Jianzhong Li"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2104.04902"
  },
  {
    "id": "arXiv:2104.04968",
    "title": "Knowledge-Augmented Contrastive Learning for Abnormality Classification  and Localization in Chest X-rays with Radiomics using a Feedback Loop",
    "abstract": "Comments: Accepted by WACV 2022",
    "descriptor": "\nComments: Accepted by WACV 2022\n",
    "authors": [
      "Yan Han",
      "Chongyan Chen",
      "Ahmed Tewfik",
      "Benjamin Glicksberg",
      "Ying Ding",
      "Yifan Peng",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.04968"
  },
  {
    "id": "arXiv:2104.05914",
    "title": "GSA-Forecaster: Forecasting Graph-Based Time-Dependent Data with Graph  Sequence Attention",
    "abstract": "GSA-Forecaster: Forecasting Graph-Based Time-Dependent Data with Graph  Sequence Attention",
    "descriptor": "",
    "authors": [
      "Yang Li",
      "Di Wang",
      "Jos\u00e9 M. F. Moura"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.05914"
  },
  {
    "id": "arXiv:2104.06084",
    "title": "On the efficiency of polar-like decoding for symmetric codes",
    "abstract": "Comments: Accepted to IEEE Transactions on Communications. This work was partially presented at the International Symposium on Information Theory and Applications'2020",
    "descriptor": "\nComments: Accepted to IEEE Transactions on Communications. This work was partially presented at the International Symposium on Information Theory and Applications'2020\n",
    "authors": [
      "Kirill Ivanov",
      "R\u00fcdiger Urbanke"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2104.06084"
  },
  {
    "id": "arXiv:2104.07084",
    "title": "Grouped Variable Selection with Discrete Optimization: Computational and  Statistical Perspectives",
    "abstract": "Grouped Variable Selection with Discrete Optimization: Computational and  Statistical Perspectives",
    "descriptor": "",
    "authors": [
      "Hussein Hazimeh",
      "Rahul Mazumder",
      "Peter Radchenko"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.07084"
  },
  {
    "id": "arXiv:2104.07644",
    "title": "ExplaGraphs: An Explanation Graph Generation Task for Structured  Commonsense Reasoning",
    "abstract": "Comments: EMNLP 2021 (25 pages)",
    "descriptor": "\nComments: EMNLP 2021 (25 pages)\n",
    "authors": [
      "Swarnadeep Saha",
      "Prateek Yadav",
      "Lisa Bauer",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.07644"
  },
  {
    "id": "arXiv:2104.08050",
    "title": "Age of information without service preemption",
    "abstract": "Age of information without service preemption",
    "descriptor": "",
    "authors": [
      "George Kesidis",
      "Takis Konstantopoulos",
      "Michael A. Zazanis"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2104.08050"
  },
  {
    "id": "arXiv:2104.08773",
    "title": "Cross-Task Generalization via Natural Language Crowdsourcing  Instructions",
    "abstract": "Comments: 20 pages",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Swaroop Mishra",
      "Daniel Khashabi",
      "Chitta Baral",
      "Hannaneh Hajishirzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.08773"
  },
  {
    "id": "arXiv:2104.08790",
    "title": "Misinfo Reaction Frames: Reasoning about Readers' Reactions to News  Headlines",
    "abstract": "Misinfo Reaction Frames: Reasoning about Readers' Reactions to News  Headlines",
    "descriptor": "",
    "authors": [
      "Saadia Gabriel",
      "Skyler Hallinan",
      "Maarten Sap",
      "Pemi Nguyen",
      "Franziska Roesner",
      "Eunsol Choi",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08790"
  },
  {
    "id": "arXiv:2104.10122",
    "title": "Improving state-of-the-art in Detecting Student Engagement with Resnet  and TCN Hybrid Network",
    "abstract": "Comments: 7 pages, 3 figures, 1 table",
    "descriptor": "\nComments: 7 pages, 3 figures, 1 table\n",
    "authors": [
      "Ali Abedi",
      "Shehroz S. Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2104.10122"
  },
  {
    "id": "arXiv:2104.10236",
    "title": "A Game Theoretic Approach to a Problem in Polymatroid Maximization",
    "abstract": "A Game Theoretic Approach to a Problem in Polymatroid Maximization",
    "descriptor": "",
    "authors": [
      "Lisa Hellerstein",
      "Thomas Lidbetter"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2104.10236"
  },
  {
    "id": "arXiv:2104.10490",
    "title": "FIERY: Future Instance Prediction in Bird's-Eye View from Surround  Monocular Cameras",
    "abstract": "Comments: ICCV 2021",
    "descriptor": "\nComments: ICCV 2021\n",
    "authors": [
      "Anthony Hu",
      "Zak Murez",
      "Nikhil Mohan",
      "Sof\u00eda Dudas",
      "Jeffrey Hawke",
      "Vijay Badrinarayanan",
      "Roberto Cipolla",
      "Alex Kendall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2104.10490"
  },
  {
    "id": "arXiv:2104.11393",
    "title": "Age of information distribution under dynamic service preemption",
    "abstract": "Age of information distribution under dynamic service preemption",
    "descriptor": "",
    "authors": [
      "George Kesidis",
      "Takis Konstantopoulos",
      "Michael A. Zazanis"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2104.11393"
  },
  {
    "id": "arXiv:2104.11510",
    "title": "Time Series Forecasting via Learning Convolutionally Low-Rank Models",
    "abstract": "Time Series Forecasting via Learning Convolutionally Low-Rank Models",
    "descriptor": "",
    "authors": [
      "Guangcan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.11510"
  },
  {
    "id": "arXiv:2104.11734",
    "title": "Exact marginal prior distributions of finite Bayesian neural networks",
    "abstract": "Comments: 12+9 pages, 4 figures; v3: Accepted as NeurIPS 2021 Spotlight",
    "descriptor": "\nComments: 12+9 pages, 4 figures; v3: Accepted as NeurIPS 2021 Spotlight\n",
    "authors": [
      "Jacob A. Zavatone-Veth",
      "Cengiz Pehlevan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.11734"
  },
  {
    "id": "arXiv:2104.11746",
    "title": "VidTr: Video Transformer Without Convolutions",
    "abstract": "Comments: ICCV 2021 Accepted",
    "descriptor": "\nComments: ICCV 2021 Accepted\n",
    "authors": [
      "Yanyi Zhang",
      "Xinyu Li",
      "Chunhui Liu",
      "Bing Shuai",
      "Yi Zhu",
      "Biagio Brattoli",
      "Hao Chen",
      "Ivan Marsic",
      "Joseph Tighe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.11746"
  },
  {
    "id": "arXiv:2104.12761",
    "title": "Adaptive Learning in Continuous Games: Optimal Regret Bounds and  Convergence to Nash Equilibrium",
    "abstract": "Comments: In the 34th Annual Conference on Learning Theory (COLT 2021); 35 pages, 2 figures",
    "descriptor": "\nComments: In the 34th Annual Conference on Learning Theory (COLT 2021); 35 pages, 2 figures\n",
    "authors": [
      "Yu-Guan Hsieh",
      "Kimon Antonakopoulos",
      "Panayotis Mertikopoulos"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2104.12761"
  },
  {
    "id": "arXiv:2104.13362",
    "title": "There is no APTAS for 2-dimensional vector bin packing: Revisited",
    "abstract": "Comments: 15 pages, LIPIcs format, changes: fixed typos, added vector bin covering result",
    "descriptor": "\nComments: 15 pages, LIPIcs format, changes: fixed typos, added vector bin covering result\n",
    "authors": [
      "Arka Ray"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2104.13362"
  },
  {
    "id": "arXiv:2105.01051",
    "title": "SUPERB: Speech processing Universal PERformance Benchmark",
    "abstract": "Comments: To appear in Interspeech 2021",
    "descriptor": "\nComments: To appear in Interspeech 2021\n",
    "authors": [
      "Shu-wen Yang",
      "Po-Han Chi",
      "Yung-Sung Chuang",
      "Cheng-I Jeff Lai",
      "Kushal Lakhotia",
      "Yist Y. Lin",
      "Andy T. Liu",
      "Jiatong Shi",
      "Xuankai Chang",
      "Guan-Ting Lin",
      "Tzu-Hsien Huang",
      "Wei-Cheng Tseng",
      "Ko-tik Lee",
      "Da-Rong Liu",
      "Zili Huang",
      "Shuyan Dong",
      "Shang-Wen Li",
      "Shinji Watanabe",
      "Abdelrahman Mohamed",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.01051"
  },
  {
    "id": "arXiv:2105.01099",
    "title": "Reinforcement Learning for Ridesharing: A Survey",
    "abstract": "Comments: This survey has been significantly expanded and refined over the conference version presented at IEEE ITSC 2021",
    "descriptor": "\nComments: This survey has been significantly expanded and refined over the conference version presented at IEEE ITSC 2021\n",
    "authors": [
      "Zhiwei Qin",
      "Hongtu Zhu",
      "Jieping Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.01099"
  },
  {
    "id": "arXiv:2105.02345",
    "title": "A Multi-Chamber Smart Suction Cup for Adaptive Gripping and Haptic  Exploration",
    "abstract": "A Multi-Chamber Smart Suction Cup for Adaptive Gripping and Haptic  Exploration",
    "descriptor": "",
    "authors": [
      "Tae Myung Huh",
      "Kate Sanders",
      "Michael Danielczuk",
      "Monica Li",
      "Yunliang Chen",
      "Ken Goldberg",
      "Hannah S. Stuart"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.02345"
  },
  {
    "id": "arXiv:2105.02857",
    "title": "Visual Foresight Tree for Object Retrieval from Clutter with  Nonprehensile Rearrangement",
    "abstract": "Comments: Accepted by RA-L",
    "descriptor": "\nComments: Accepted by RA-L\n",
    "authors": [
      "Baichuan Huang",
      "Shuai D. Han",
      "Jingjin Yu",
      "Abdeslam Boularias"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.02857"
  },
  {
    "id": "arXiv:2105.03425",
    "title": "Kernel Two-Sample Tests for Manifold Data",
    "abstract": "Kernel Two-Sample Tests for Manifold Data",
    "descriptor": "",
    "authors": [
      "Xiuyuan Cheng",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2105.03425"
  },
  {
    "id": "arXiv:2105.05301",
    "title": "Collaborative Regression of Expressive Bodies using Moderation",
    "abstract": "Comments: 21 pages. The first two authors contributed equally to this work",
    "descriptor": "\nComments: 21 pages. The first two authors contributed equally to this work\n",
    "authors": [
      "Yao Feng",
      "Vasileios Choutas",
      "Timo Bolkart",
      "Dimitrios Tzionas",
      "Michael J. Black"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.05301"
  },
  {
    "id": "arXiv:2105.06451",
    "title": "Outage Common Randomness Capacity Characterization of Multiple-Antenna  Slow Fading Channels",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2102.01197",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2102.01197\n",
    "authors": [
      "Rami Ezzine",
      "Moritz Wiese",
      "Christian Deppe",
      "Holger Boche"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.06451"
  },
  {
    "id": "arXiv:2105.06744",
    "title": "A Separator Theorem for Hypergraphs and a CSP-SAT Algorithm",
    "abstract": "A Separator Theorem for Hypergraphs and a CSP-SAT Algorithm",
    "descriptor": "",
    "authors": [
      "Michal Kouck\u00fd",
      "Vojt\u011bch R\u00f6dl",
      "Navid Talebanfard"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2105.06744"
  },
  {
    "id": "arXiv:2105.07025",
    "title": "Minimal Cycle Representatives in Persistent Homology using Linear  Programming: an Empirical Study with User's Guide",
    "abstract": "Minimal Cycle Representatives in Persistent Homology using Linear  Programming: an Empirical Study with User's Guide",
    "descriptor": "",
    "authors": [
      "Lu Li",
      "Connor Thompson",
      "Gregory Henselman-Petrusek",
      "Chad Giusti",
      "Lori Ziegelmeier"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.07025"
  },
  {
    "id": "arXiv:2105.07123",
    "title": "Byzantine-Resilient Population Protocols",
    "abstract": "Byzantine-Resilient Population Protocols",
    "descriptor": "",
    "authors": [
      "Costas Busch",
      "Dariusz R. Kowalski"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.07123"
  },
  {
    "id": "arXiv:2105.08024",
    "title": "Sample-Efficient Reinforcement Learning Is Feasible for Linearly  Realizable MDPs with Limited Revisiting",
    "abstract": "Sample-Efficient Reinforcement Learning Is Feasible for Linearly  Realizable MDPs with Limited Revisiting",
    "descriptor": "",
    "authors": [
      "Gen Li",
      "Yuxin Chen",
      "Yuejie Chi",
      "Yuantao Gu",
      "Yuting Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.08024"
  },
  {
    "id": "arXiv:2105.08532",
    "title": "Robust Learning in Heterogeneous Contexts",
    "abstract": "Robust Learning in Heterogeneous Contexts",
    "descriptor": "",
    "authors": [
      "Muhammad Osama",
      "Dave Zachariah",
      "Petre Stoica"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.08532"
  },
  {
    "id": "arXiv:2105.09152",
    "title": "Preconditioning for a pressure-robust HDG discretization of the Stokes  equations",
    "abstract": "Preconditioning for a pressure-robust HDG discretization of the Stokes  equations",
    "descriptor": "",
    "authors": [
      "Sander Rhebergen",
      "Garth N. Wells"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2105.09152"
  },
  {
    "id": "arXiv:2105.10266",
    "title": "Ensemble Quantile Networks: Uncertainty-Aware Reinforcement Learning  with Applications in Autonomous Driving",
    "abstract": "Ensemble Quantile Networks: Uncertainty-Aware Reinforcement Learning  with Applications in Autonomous Driving",
    "descriptor": "",
    "authors": [
      "Carl-Johan Hoel",
      "Krister Wolff",
      "Leo Laine"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.10266"
  },
  {
    "id": "arXiv:2105.10466",
    "title": "Setting Out a Software Stack Capable of Hosting a Virtual ROS-based  Competition",
    "abstract": "Comments: 6 pages, 4 figures",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Nishesh Singh"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.10466"
  },
  {
    "id": "arXiv:2105.11705",
    "title": "SBEVNet: End-to-End Deep Stereo Layout Estimation",
    "abstract": "Comments: WACV 2022",
    "descriptor": "\nComments: WACV 2022\n",
    "authors": [
      "Divam Gupta",
      "Wei Pu",
      "Trenton Tabor",
      "Jeff Schneider"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.11705"
  },
  {
    "id": "arXiv:2105.13348",
    "title": "Optimization in Open Networks via Dual Averaging",
    "abstract": "Comments: In 60th IEEE Conference on Decision and Control (CDC 2021); 7 pages, 1 figure",
    "descriptor": "\nComments: In 60th IEEE Conference on Decision and Control (CDC 2021); 7 pages, 1 figure\n",
    "authors": [
      "Yu-Guan Hsieh",
      "Franck Iutzeler",
      "J\u00e9r\u00f4me Malick",
      "Panayotis Mertikopoulos"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2105.13348"
  },
  {
    "id": "arXiv:2105.13967",
    "title": "Bridge Data Center AI Systems with Edge Computing for Actionable  Information Retrieval",
    "abstract": "Bridge Data Center AI Systems with Edge Computing for Actionable  Information Retrieval",
    "descriptor": "",
    "authors": [
      "Zhengchun Liu",
      "Ahsan Ali",
      "Peter Kenesei",
      "Antonino Miceli",
      "Hemant Sharma",
      "Nicholas Schwarz",
      "Dennis Trujillo",
      "Hyunseung Yoo",
      "Ryan Coffee",
      "Naoufal Layad",
      "Jana Thayer",
      "Ryan Herbst",
      "Chun Hong Yoon",
      "Ian Foster"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13967"
  },
  {
    "id": "arXiv:2105.14461",
    "title": "A Hybrid SIE-PDE Formulation Without Boundary Condition Requirement for  Transverse Magnetic Electromagnetic Analysis",
    "abstract": "A Hybrid SIE-PDE Formulation Without Boundary Condition Requirement for  Transverse Magnetic Electromagnetic Analysis",
    "descriptor": "",
    "authors": [
      "Aipeng Sun",
      "Zekun Zhu",
      "Shunchuan Yang",
      "Zhizhang",
      "Chen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2105.14461"
  },
  {
    "id": "arXiv:2105.15089",
    "title": "Analogous to Evolutionary Algorithm: Designing a Unified Sequence Model",
    "abstract": "Analogous to Evolutionary Algorithm: Designing a Unified Sequence Model",
    "descriptor": "",
    "authors": [
      "Jiangning Zhang",
      "Chao Xu",
      "Jian Li",
      "Wenzhou Chen",
      "Yabiao Wang",
      "Ying Tai",
      "Shuo Chen",
      "Chengjie Wang",
      "Feiyue Huang",
      "Yong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.15089"
  },
  {
    "id": "arXiv:2106.00198",
    "title": "Gradient play in stochastic games: stationary points, convergence, and  sample complexity",
    "abstract": "Gradient play in stochastic games: stationary points, convergence, and  sample complexity",
    "descriptor": "",
    "authors": [
      "Runyu Zhang",
      "Zhaolin Ren",
      "Na Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.00198"
  },
  {
    "id": "arXiv:2106.00847",
    "title": "Sparse, Efficient, and Semantic Mixture Invariant Training: Taming  In-the-Wild Unsupervised Sound Separation",
    "abstract": "Comments: 5 pages, 1 figure. WASPAA 2021",
    "descriptor": "\nComments: 5 pages, 1 figure. WASPAA 2021\n",
    "authors": [
      "Scott Wisdom",
      "Aren Jansen",
      "Ron J. Weiss",
      "Hakan Erdogan",
      "John R. Hershey"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.00847"
  },
  {
    "id": "arXiv:2106.01401",
    "title": "Container: Context Aggregation Network",
    "abstract": "Comments: NeuIPS 2021",
    "descriptor": "\nComments: NeuIPS 2021\n",
    "authors": [
      "Peng Gao",
      "Jiasen Lu",
      "Hongsheng Li",
      "Roozbeh Mottaghi",
      "Aniruddha Kembhavi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01401"
  },
  {
    "id": "arXiv:2106.01505",
    "title": "Barbershop: GAN-based Image Compositing using Segmentation Masks",
    "abstract": "Comments: Project page: this https URL Video: this https URL",
    "descriptor": "\nComments: Project page: this https URL Video: this https URL\n",
    "authors": [
      "Peihao Zhu",
      "Rameen Abdal",
      "John Femiani",
      "Peter Wonka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.01505"
  },
  {
    "id": "arXiv:2106.01917",
    "title": "SpecAttack: Specification-Based Adversarial Training for Deep Neural  Networks",
    "abstract": "SpecAttack: Specification-Based Adversarial Training for Deep Neural  Networks",
    "descriptor": "",
    "authors": [
      "Fabian Bauer-Marquart",
      "David Boetius",
      "Stefan Leue",
      "Christian Schilling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.01917"
  },
  {
    "id": "arXiv:2106.02016",
    "title": "Semantic-WER: A Unified Metric for the Evaluation of ASR Transcript for  End Usability",
    "abstract": "Semantic-WER: A Unified Metric for the Evaluation of ASR Transcript for  End Usability",
    "descriptor": "",
    "authors": [
      "Somnath Roy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.02016"
  },
  {
    "id": "arXiv:2106.02185",
    "title": "Functional observers with linear error dynamics for discrete-time  nonlinear systems, with application to fault diagnosis",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2101.11148",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2101.11148\n",
    "authors": [
      "Sunjeev Venkateswaran",
      "Benjamin A. Wilhite",
      "Costas Kravaris"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.02185"
  },
  {
    "id": "arXiv:2106.02514",
    "title": "The Image Local Autoregressive Transformer",
    "abstract": "Comments: Accepted by NeurIPS2021",
    "descriptor": "\nComments: Accepted by NeurIPS2021\n",
    "authors": [
      "Chenjie Cao",
      "Yuxin Hong",
      "Xiang Li",
      "Chengrong Wang",
      "Chengming Xu",
      "XiangYang Xue",
      "Yanwei Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.02514"
  },
  {
    "id": "arXiv:2106.02898",
    "title": "Dynamic Resolution Network",
    "abstract": "Comments: Accepted by NeurIPS 2021",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Mingjian Zhu",
      "Kai Han",
      "Enhua Wu",
      "Qiulin Zhang",
      "Ying Nie",
      "Zhenzhong Lan",
      "Yunhe Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02898"
  },
  {
    "id": "arXiv:2106.03215",
    "title": "PreferenceNet: Encoding Human Preferences in Auction Design with Deep  Learning",
    "abstract": "Comments: This work has been accepted to Neural Information Processing Systems (NeurIPS) 2021. First two authors contributed equally",
    "descriptor": "\nComments: This work has been accepted to Neural Information Processing Systems (NeurIPS) 2021. First two authors contributed equally\n",
    "authors": [
      "Neehar Peri",
      "Michael J. Curry",
      "Samuel Dooley",
      "John P. Dickerson"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.03215"
  },
  {
    "id": "arXiv:2106.03227",
    "title": "Neural Tangent Kernel Maximum Mean Discrepancy",
    "abstract": "Neural Tangent Kernel Maximum Mean Discrepancy",
    "descriptor": "",
    "authors": [
      "Xiuyuan Cheng",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2106.03227"
  },
  {
    "id": "arXiv:2106.03373",
    "title": "Pre-trained Language Model for Web-scale Retrieval in Baidu Search",
    "abstract": "Comments: Accepted by KDD 2021",
    "descriptor": "\nComments: Accepted by KDD 2021\n",
    "authors": [
      "Yiding Liu",
      "Guan Huang",
      "Jiaxiang Liu",
      "Weixue Lu",
      "Suqi Cheng",
      "Yukun Li",
      "Daiting Shi",
      "Shuaiqiang Wang",
      "Zhicong Cheng",
      "Dawei Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.03373"
  },
  {
    "id": "arXiv:2106.03762",
    "title": "Frustratingly Easy Uncertainty Estimation for Distribution Shift",
    "abstract": "Comments: 17 pages, 4 Tables, 9 Figures",
    "descriptor": "\nComments: 17 pages, 4 Tables, 9 Figures\n",
    "authors": [
      "Tiago Salvador",
      "Vikram Voleti",
      "Alexander Iannantuono",
      "Adam Oberman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03762"
  },
  {
    "id": "arXiv:2106.04117",
    "title": "The best of both worlds: stochastic and adversarial episodic MDPs with  unknown transition",
    "abstract": "Comments: The camera-ready version for NeurIPS 2021",
    "descriptor": "\nComments: The camera-ready version for NeurIPS 2021\n",
    "authors": [
      "Tiancheng Jin",
      "Longbo Huang",
      "Haipeng Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.04117"
  },
  {
    "id": "arXiv:2106.04427",
    "title": "On the relation between statistical learning and perceptual distances",
    "abstract": "On the relation between statistical learning and perceptual distances",
    "descriptor": "",
    "authors": [
      "Alexander Hepburn",
      "Valero Laparra",
      "Raul Santos-Rodriguez",
      "Johannes Ball\u00e9",
      "Jes\u00fas Malo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2106.04427"
  },
  {
    "id": "arXiv:2106.05232",
    "title": "Realizing GANs via a Tunable Loss Function",
    "abstract": "Comments: Extended version of a paper accepted to ITW 2021. 8 pages, 2 figures",
    "descriptor": "\nComments: Extended version of a paper accepted to ITW 2021. 8 pages, 2 figures\n",
    "authors": [
      "Gowtham R. Kurri",
      "Tyler Sypherd",
      "Lalitha Sankar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.05232"
  },
  {
    "id": "arXiv:2106.05565",
    "title": "Identifiability of interaction kernels in mean-field equations of  interacting particles",
    "abstract": "Identifiability of interaction kernels in mean-field equations of  interacting particles",
    "descriptor": "",
    "authors": [
      "Quanjun Lang",
      "Fei Lu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2106.05565"
  },
  {
    "id": "arXiv:2106.05854",
    "title": "Do you feel safe with your robot? Factors Influencing Perceived Safety  in Human-Robot Interaction based on Subjective and Objective Measures",
    "abstract": "Do you feel safe with your robot? Factors Influencing Perceived Safety  in Human-Robot Interaction based on Subjective and Objective Measures",
    "descriptor": "",
    "authors": [
      "Neziha Akalin",
      "Annica Kristoffersson",
      "Amy Loutfi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2106.05854"
  },
  {
    "id": "arXiv:2106.06134",
    "title": "Is Homophily a Necessity for Graph Neural Networks?",
    "abstract": "Is Homophily a Necessity for Graph Neural Networks?",
    "descriptor": "",
    "authors": [
      "Yao Ma",
      "Xiaorui Liu",
      "Neil Shah",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.06134"
  },
  {
    "id": "arXiv:2106.06797",
    "title": "Machine Translation into Low-resource Language Varieties",
    "abstract": "Comments: The Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL-IJCNLP 2021)",
    "descriptor": "\nComments: The Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL-IJCNLP 2021)\n",
    "authors": [
      "Sachin Kumar",
      "Antonios Anastasopoulos",
      "Shuly Wintner",
      "Yulia Tsvetkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.06797"
  },
  {
    "id": "arXiv:2106.07827",
    "title": "Improving the compromise between accuracy, interpretability and  personalization of rule-based machine learning in medical problems",
    "abstract": "Comments: Accepted for the IEEE Engineering in Medicine and Biology Society Conference (EMBC 2021)",
    "descriptor": "\nComments: Accepted for the IEEE Engineering in Medicine and Biology Society Conference (EMBC 2021)\n",
    "authors": [
      "Francisco Valente",
      "Jorge Henriques",
      "Sim\u00e3o Paredes",
      "Teresa Rocha",
      "Paulo de Carvalho",
      "Jo\u00e3o Morais"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07827"
  },
  {
    "id": "arXiv:2106.07976",
    "title": "Federated Learning for Internet of Things: A Federated Learning  Framework for On-device Anomaly Data Detection",
    "abstract": "Federated Learning for Internet of Things: A Federated Learning  Framework for On-device Anomaly Data Detection",
    "descriptor": "",
    "authors": [
      "Tuo Zhang",
      "Chaoyang He",
      "Tianhao Ma",
      "Lei Gao",
      "Mark Ma",
      "Salman Avestimehr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.07976"
  },
  {
    "id": "arXiv:2106.09215",
    "title": "Optimum-statistical Collaboration Towards General and Efficient  Black-box Optimization",
    "abstract": "Optimum-statistical Collaboration Towards General and Efficient  Black-box Optimization",
    "descriptor": "",
    "authors": [
      "Wenjie Li",
      "Chi-Hua Wang",
      "Guang Cheng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09215"
  },
  {
    "id": "arXiv:2106.09685",
    "title": "LoRA: Low-Rank Adaptation of Large Language Models",
    "abstract": "Comments: Draft V2 includes better baselines, experiments on GLUE, and more on adapter latency",
    "descriptor": "\nComments: Draft V2 includes better baselines, experiments on GLUE, and more on adapter latency\n",
    "authors": [
      "Edward J. Hu",
      "Yelong Shen",
      "Phillip Wallis",
      "Zeyuan Allen-Zhu",
      "Yuanzhi Li",
      "Shean Wang",
      "Lu Wang",
      "Weizhu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09685"
  },
  {
    "id": "arXiv:2106.10065",
    "title": "Being a Bit Frequentist Improves Bayesian Neural Networks",
    "abstract": "Being a Bit Frequentist Improves Bayesian Neural Networks",
    "descriptor": "",
    "authors": [
      "Agustinus Kristiadi",
      "Matthias Hein",
      "Philipp Hennig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10065"
  },
  {
    "id": "arXiv:2106.10404",
    "title": "Sparse Training via Boosting Pruning Plasticity with Neuroregeneration",
    "abstract": "Comments: Published on the thirty-fifth Conference on Neural Information Processing Systems (NeurIPS 2021). Code can be found this https URL",
    "descriptor": "\nComments: Published on the thirty-fifth Conference on Neural Information Processing Systems (NeurIPS 2021). Code can be found this https URL\n",
    "authors": [
      "Shiwei Liu",
      "Tianlong Chen",
      "Xiaohan Chen",
      "Zahra Atashgahi",
      "Lu Yin",
      "Huanyu Kou",
      "Li Shen",
      "Mykola Pechenizkiy",
      "Zhangyang Wang",
      "Decebal Constantin Mocanu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10404"
  },
  {
    "id": "arXiv:2106.10578",
    "title": "Optimal adaptive control of a knee joint exoskeleton for lower limb  functional rehabilitation",
    "abstract": "Optimal adaptive control of a knee joint exoskeleton for lower limb  functional rehabilitation",
    "descriptor": "",
    "authors": [
      "Maria-Sara-Nour Sadoun",
      "Fouad Yacef"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.10578"
  },
  {
    "id": "arXiv:2106.11655",
    "title": "DARTS-PRIME: Regularization and Scheduling Improve Constrained  Optimization in Differentiable NAS",
    "abstract": "DARTS-PRIME: Regularization and Scheduling Improve Constrained  Optimization in Differentiable NAS",
    "descriptor": "",
    "authors": [
      "Kaitlin Maile",
      "Erwan Lecarpentier",
      "Herv\u00e9 Luga",
      "Dennis G. Wilson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11655"
  },
  {
    "id": "arXiv:2106.12423",
    "title": "Alias-Free Generative Adversarial Networks",
    "abstract": "Alias-Free Generative Adversarial Networks",
    "descriptor": "",
    "authors": [
      "Tero Karras",
      "Miika Aittala",
      "Samuli Laine",
      "Erik H\u00e4rk\u00f6nen",
      "Janne Hellsten",
      "Jaakko Lehtinen",
      "Timo Aila"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.12423"
  },
  {
    "id": "arXiv:2106.13423",
    "title": "Federated Graph Classification over Non-IID Graphs",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Han Xie",
      "Jing Ma",
      "Li Xiong",
      "Carl Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.13423"
  },
  {
    "id": "arXiv:2106.13430",
    "title": "Subgraph Federated Learning with Missing Neighbor Generation",
    "abstract": "Comments: Accepted to NeurIPS 2021 (spotlight presentation)",
    "descriptor": "\nComments: Accepted to NeurIPS 2021 (spotlight presentation)\n",
    "authors": [
      "Ke Zhang",
      "Carl Yang",
      "Xiaoxiao Li",
      "Lichao Sun",
      "Siu Ming Yiu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.13430"
  },
  {
    "id": "arXiv:2106.14118",
    "title": "Hear Me Out: Fusional Approaches for Audio Augmented Temporal Action  Localization",
    "abstract": "Hear Me Out: Fusional Approaches for Audio Augmented Temporal Action  Localization",
    "descriptor": "",
    "authors": [
      "Anurag Bagchi",
      "Jazib Mahmood",
      "Dolton Fernandes",
      "Ravi Kiran Sarvadevabhatla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2106.14118"
  },
  {
    "id": "arXiv:2106.14229",
    "title": "Over-the-Air Federated Multi-Task Learning",
    "abstract": "Over-the-Air Federated Multi-Task Learning",
    "descriptor": "",
    "authors": [
      "Haoming Ma",
      "Xiaojun Yuan",
      "Dian Fan",
      "Zhi Ding",
      "Xin Wang",
      "Jun Fang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.14229"
  },
  {
    "id": "arXiv:2106.15358",
    "title": "Towards Sample-Optimal Compressive Phase Retrieval with Sparse and  Generative Priors",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Zhaoqiang Liu",
      "Subhroshekhar Ghosh",
      "Jonathan Scarlett"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15358"
  },
  {
    "id": "arXiv:2107.00384",
    "title": "A variational non-linear constrained model for the inversion of FDEM  data",
    "abstract": "A variational non-linear constrained model for the inversion of FDEM  data",
    "descriptor": "",
    "authors": [
      "Alessandro Buccini",
      "Patricia D\u00edaz de Alba"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.00384"
  },
  {
    "id": "arXiv:2107.00520",
    "title": "Predictive Modeling in the Presence of Nuisance-Induced Spurious  Correlations",
    "abstract": "Predictive Modeling in the Presence of Nuisance-Induced Spurious  Correlations",
    "descriptor": "",
    "authors": [
      "Aahlad Puli",
      "Lily H. Zhang",
      "Eric K. Oermann",
      "Rajesh Ranganath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.00520"
  },
  {
    "id": "arXiv:2107.00753",
    "title": "An Investigation of the (In)effectiveness of Counterfactually Augmented  Data",
    "abstract": "Comments: (v2) Toy theoretical example updated",
    "descriptor": "\nComments: (v2) Toy theoretical example updated\n",
    "authors": [
      "Nitish Joshi",
      "He He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00753"
  },
  {
    "id": "arXiv:2107.00758",
    "title": "The Spotlight: A General Method for Discovering Systematic Errors in  Deep Learning Models",
    "abstract": "The Spotlight: A General Method for Discovering Systematic Errors in  Deep Learning Models",
    "descriptor": "",
    "authors": [
      "Greg d'Eon",
      "Jason d'Eon",
      "James R. Wright",
      "Kevin Leyton-Brown"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.00758"
  },
  {
    "id": "arXiv:2107.01510",
    "title": "Directed Percolation in Temporal Networks",
    "abstract": "Comments: Implementation available at this https URL",
    "descriptor": "\nComments: Implementation available at this https URL\n",
    "authors": [
      "Arash Badie-Modiri",
      "Abbas K. Rizi",
      "M\u00e1rton Karsai",
      "Mikko Kivel\u00e4"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.01510"
  },
  {
    "id": "arXiv:2107.03813",
    "title": "Heterogeneous Global Graph Neural Networks for Personalized  Session-based Recommendation",
    "abstract": "Comments: 10 pages, 4 figures",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Yitong Pang",
      "Lingfei Wu",
      "Qi Shen",
      "Yiming Zhang",
      "Zhihua Wei",
      "Fangli Xu",
      "Ethan Chang",
      "Bo Long",
      "Jian Pei"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.03813"
  },
  {
    "id": "arXiv:2107.04082",
    "title": "Improved Language Identification Through Cross-Lingual Self-Supervised  Learning",
    "abstract": "Improved Language Identification Through Cross-Lingual Self-Supervised  Learning",
    "descriptor": "",
    "authors": [
      "Andros Tjandra",
      "Diptanu Gon Choudhury",
      "Frank Zhang",
      "Kritika Singh",
      "Alexis Conneau",
      "Alexei Baevski",
      "Assaf Sela",
      "Yatharth Saraf",
      "Michael Auli"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.04082"
  },
  {
    "id": "arXiv:2107.04117",
    "title": "Crowd Sensing and Living Lab Outdoor Experimentation Made Easy",
    "abstract": "Crowd Sensing and Living Lab Outdoor Experimentation Made Easy",
    "descriptor": "",
    "authors": [
      "Evangelos Pournaras",
      "Atif Nabi Ghulam",
      "Renato Kunz",
      "Regula H\u00e4nggli"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2107.04117"
  },
  {
    "id": "arXiv:2107.04281",
    "title": "JPGNet: Joint Predictive Filtering and Generative Network for Image  Inpainting",
    "abstract": "Comments: This work has been accepted to ACM-MM 2021",
    "descriptor": "\nComments: This work has been accepted to ACM-MM 2021\n",
    "authors": [
      "Qing Guo",
      "Xiaoguang Li",
      "Felix Juefei-Xu",
      "Hongkai Yu",
      "Yang Liu",
      "Song wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.04281"
  },
  {
    "id": "arXiv:2107.05348",
    "title": "Zero-shot Visual Question Answering using Knowledge Graph",
    "abstract": "Comments: accepted at the International Semantic Web Conference '21 (ISWC 2021)",
    "descriptor": "\nComments: accepted at the International Semantic Web Conference '21 (ISWC 2021)\n",
    "authors": [
      "Zhuo Chen",
      "Jiaoyan Chen",
      "Yuxia Geng",
      "Jeff Z. Pan",
      "Zonggang Yuan",
      "Huajun Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.05348"
  },
  {
    "id": "arXiv:2107.05686",
    "title": "The Role of Pretrained Representations for the OOD Generalization of RL  Agents",
    "abstract": "The Role of Pretrained Representations for the OOD Generalization of RL  Agents",
    "descriptor": "",
    "authors": [
      "Andrea Dittadi",
      "Frederik Tr\u00e4uble",
      "Manuel W\u00fcthrich",
      "Felix Widmaier",
      "Peter Gehler",
      "Ole Winther",
      "Francesco Locatello",
      "Olivier Bachem",
      "Bernhard Sch\u00f6lkopf",
      "Stefan Bauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.05686"
  },
  {
    "id": "arXiv:2107.06501",
    "title": "AdvFilter: Predictive Perturbation-aware Filtering against Adversarial  Attack via Multi-domain Learning",
    "abstract": "Comments: This work has been accepted to ACM-MM 2021",
    "descriptor": "\nComments: This work has been accepted to ACM-MM 2021\n",
    "authors": [
      "Yihao Huang",
      "Qing Guo",
      "Felix Juefei-Xu",
      "Lei Ma",
      "Weikai Miao",
      "Yang Liu",
      "Geguang Pu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.06501"
  },
  {
    "id": "arXiv:2107.07030",
    "title": "Diff-Net: Image Feature Difference based High-Definition Map Change  Detection for Autonomous Driving",
    "abstract": "Comments: 13 pages, 4 figures. Fixed typos, added more explanations to figures",
    "descriptor": "\nComments: 13 pages, 4 figures. Fixed typos, added more explanations to figures\n",
    "authors": [
      "Lei He",
      "Shengjie Jiang",
      "Xiaoqing Liang",
      "Ning Wang",
      "Shiyu Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.07030"
  },
  {
    "id": "arXiv:2107.08688",
    "title": "Structural Watermarking to Deep Neural Networks via Network Channel  Pruning",
    "abstract": "Comments: Accepted by IEEE International Workshop on Information Forensics and Security 2021",
    "descriptor": "\nComments: Accepted by IEEE International Workshop on Information Forensics and Security 2021\n",
    "authors": [
      "Xiangyu Zhao",
      "Yinzhe Yao",
      "Hanzhou Wu",
      "Xinpeng Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2107.08688"
  },
  {
    "id": "arXiv:2107.09280",
    "title": "Global Winning Conditions in Synthesis of Distributed Systems with  Causal Memory (Full Version)",
    "abstract": "Global Winning Conditions in Synthesis of Distributed Systems with  Causal Memory (Full Version)",
    "descriptor": "",
    "authors": [
      "Bernd Finkbeiner",
      "Manuel Gieseking",
      "Jesko Hecking-Harbusch",
      "Ernst-R\u00fcdiger Olderog"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.09280"
  },
  {
    "id": "arXiv:2107.09472",
    "title": "Verified Functional Programming of an Abstract Interpreter",
    "abstract": "Comments: Published in SAS21",
    "descriptor": "\nComments: Published in SAS21\n",
    "authors": [
      "Lucas Franceschino",
      "David Pichardie",
      "Jean-Pierre Talpin"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2107.09472"
  },
  {
    "id": "arXiv:2107.10370",
    "title": "Analytic Study of Families of Spurious Minima in Two-Layer ReLU Neural  Networks: A Tale of Symmetry II",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2008.01805",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2008.01805\n",
    "authors": [
      "Yossi Arjevani",
      "Michael Field"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.10370"
  },
  {
    "id": "arXiv:2107.10406",
    "title": "Distributed Asynchronous Policy Iteration for Sequential Zero-Sum Games  and Minimax Control",
    "abstract": "Distributed Asynchronous Policy Iteration for Sequential Zero-Sum Games  and Minimax Control",
    "descriptor": "",
    "authors": [
      "Dimitri Bertsekas"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.10406"
  },
  {
    "id": "arXiv:2107.10880",
    "title": "Using UMAP to Inspect Audio Data for Unsupervised Anomaly Detection  under Domain-Shift Conditions",
    "abstract": "Comments: Accepted at the DCASE2021 Workshop",
    "descriptor": "\nComments: Accepted at the DCASE2021 Workshop\n",
    "authors": [
      "Andres Fernandez",
      "Mark D. Plumbley"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2107.10880"
  },
  {
    "id": "arXiv:2107.10884",
    "title": "Structured second-order methods via natural gradient descent",
    "abstract": "Comments: Fixed some typos. ICML workshop paper. A short version of arXiv:2102.07405 with a focus on optimization tasks",
    "descriptor": "\nComments: Fixed some typos. ICML workshop paper. A short version of arXiv:2102.07405 with a focus on optimization tasks\n",
    "authors": [
      "Wu Lin",
      "Frank Nielsen",
      "Mohammad Emtiyaz Khan",
      "Mark Schmidt"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.10884"
  },
  {
    "id": "arXiv:2107.11413",
    "title": "An Instance-Dependent Simulation Framework for Learning with Label Noise",
    "abstract": "Comments: Datasets released at this https URL",
    "descriptor": "\nComments: Datasets released at this https URL\n",
    "authors": [
      "Keren Gu",
      "Xander Masotto",
      "Vandana Bachani",
      "Balaji Lakshminarayanan",
      "Jack Nikodem",
      "Dong Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.11413"
  },
  {
    "id": "arXiv:2107.12085",
    "title": "Learning to Adversarially Blur Visual Object Tracking",
    "abstract": "Comments: This work has been accepted to ICCV 2021",
    "descriptor": "\nComments: This work has been accepted to ICCV 2021\n",
    "authors": [
      "Qing Guo",
      "Ziyi Cheng",
      "Felix Juefei-Xu",
      "Lei Ma",
      "Xiaofei Xie",
      "Yang Liu",
      "Jianjun Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.12085"
  },
  {
    "id": "arXiv:2107.13921",
    "title": "Bellamy: Reusing Performance Models for Distributed Dataflow Jobs Across  Contexts",
    "abstract": "Comments: 10 pages, 8 figures, 2 tables",
    "descriptor": "\nComments: 10 pages, 8 figures, 2 tables\n",
    "authors": [
      "Dominik Scheinert",
      "Lauritz Thamsen",
      "Houkun Zhu",
      "Jonathan Will",
      "Alexander Acker",
      "Thorsten Wittkopp",
      "Odej Kao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.13921"
  },
  {
    "id": "arXiv:2108.00573",
    "title": "MuSiQue: Multi-hop Questions via Single-hop Question Composition",
    "abstract": "MuSiQue: Multi-hop Questions via Single-hop Question Composition",
    "descriptor": "",
    "authors": [
      "Harsh Trivedi",
      "Niranjan Balasubramanian",
      "Tushar Khot",
      "Ashish Sabharwal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.00573"
  },
  {
    "id": "arXiv:2108.03873",
    "title": "Rain Removal and Illumination Enhancement Done in One Go",
    "abstract": "Comments: In section 5.2 of the paper, the comparison results are unfair due to different calculation methods of model speed. Please allow us to correct the unfair result",
    "descriptor": "\nComments: In section 5.2 of the paper, the comparison results are unfair due to different calculation methods of model speed. Please allow us to correct the unfair result\n",
    "authors": [
      "Yecong Wan",
      "Yuanshuo Cheng",
      "Mingwen Shao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.03873"
  },
  {
    "id": "arXiv:2108.03874",
    "title": "Zero-Error Feedback Capacity of Finite-State Additive Noise Channels for  Stabilization of Linear Systems",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2006.00892",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2006.00892\n",
    "authors": [
      "Amir Saberi",
      "Farhad Farokhi",
      "Girish Nair"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2108.03874"
  },
  {
    "id": "arXiv:2108.04228",
    "title": "Iterative Distillation for Better Uncertainty Estimates in Multitask  Emotion Recognition",
    "abstract": "Comments: Accepted as a Workshop paper in ICCV2021 proceeding",
    "descriptor": "\nComments: Accepted as a Workshop paper in ICCV2021 proceeding\n",
    "authors": [
      "Didan Deng",
      "Liang Wu",
      "Bertram E. Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.04228"
  },
  {
    "id": "arXiv:2108.06249",
    "title": "MINT -- Mainstream and Independent News Text Corpus",
    "abstract": "MINT -- Mainstream and Independent News Text Corpus",
    "descriptor": "",
    "authors": [
      "Danielle Caled",
      "Paula Carvalho",
      "M\u00e1rio J. Silva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.06249"
  },
  {
    "id": "arXiv:2108.07406",
    "title": "From the Greene--Wu Convolution to Gradient Estimation over Riemannian  Manifolds",
    "abstract": "From the Greene--Wu Convolution to Gradient Estimation over Riemannian  Manifolds",
    "descriptor": "",
    "authors": [
      "Tianyu Wang",
      "Yifeng Huang",
      "Didong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2108.07406"
  },
  {
    "id": "arXiv:2108.07472",
    "title": "PAC Learnability of Approximate Nash Equilibrium in Bimatrix Games",
    "abstract": "PAC Learnability of Approximate Nash Equilibrium in Bimatrix Games",
    "descriptor": "",
    "authors": [
      "Zhijian Duan",
      "Dinghuai Zhang",
      "Wenhan Huang",
      "Yali Du",
      "Yaodong Yang",
      "Jun Wang",
      "Xiaotie Deng"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2108.07472"
  },
  {
    "id": "arXiv:2108.07917",
    "title": "Classification of Abnormal Hand Movement for Aiding in Autism Detection:  Machine Learning Study",
    "abstract": "Classification of Abnormal Hand Movement for Aiding in Autism Detection:  Machine Learning Study",
    "descriptor": "",
    "authors": [
      "Anish Lakkapragada",
      "Aaron Kline",
      "Onur Cezmi Mutlu",
      "Kelley Paskov",
      "Brianna Chrisman",
      "Nate Stockham",
      "Peter Washington",
      "Dennis Wall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.07917"
  },
  {
    "id": "arXiv:2108.08050",
    "title": "Worst-Case Efficient Dynamic Geometric Independent Set",
    "abstract": "Comments: Full version of ESA 2021 paper. Correction on the update time bounds for squares, hypercubes and unions of fat hyperrectangles (in the initial version, polylogarithmic update time was erroneously claimed, which is replaced here by polynomial sublinear update time)",
    "descriptor": "\nComments: Full version of ESA 2021 paper. Correction on the update time bounds for squares, hypercubes and unions of fat hyperrectangles (in the initial version, polylogarithmic update time was erroneously claimed, which is replaced here by polynomial sublinear update time)\n",
    "authors": [
      "Jean Cardinal",
      "John Iacono",
      "Grigorios Koumoutsos"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2108.08050"
  },
  {
    "id": "arXiv:2108.08255",
    "title": "Combating Informational Denial-of-Service (IDoS) Attacks: Modeling and  Mitigation of Attentional Human Vulnerability",
    "abstract": "Combating Informational Denial-of-Service (IDoS) Attacks: Modeling and  Mitigation of Attentional Human Vulnerability",
    "descriptor": "",
    "authors": [
      "Linan Huang",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.08255"
  },
  {
    "id": "arXiv:2108.08355",
    "title": "An EMA-conserving, pressure-robust and Re-semi-robust reconstruction  method for the unsteady incompressible Navier-Stokes equations",
    "abstract": "An EMA-conserving, pressure-robust and Re-semi-robust reconstruction  method for the unsteady incompressible Navier-Stokes equations",
    "descriptor": "",
    "authors": [
      "Xu Li",
      "Hongxing Rui"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.08355"
  },
  {
    "id": "arXiv:2108.08435",
    "title": "Addressing Algorithmic Disparity and Performance Inconsistency in  Federated Learning",
    "abstract": "Comments: This work is accepted by NeurIPS2021",
    "descriptor": "\nComments: This work is accepted by NeurIPS2021\n",
    "authors": [
      "Sen Cui",
      "Weishen Pan",
      "Jian Liang",
      "Changshui Zhang",
      "Fei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.08435"
  },
  {
    "id": "arXiv:2108.08987",
    "title": "Uniformity Testing in the Shuffle Model: Simpler, Better, Faster",
    "abstract": "Comments: Accepted to the SIAM Symposium on Simplicity in Algorithms (SOSA 2022). Added some details and discussions",
    "descriptor": "\nComments: Accepted to the SIAM Symposium on Simplicity in Algorithms (SOSA 2022). Added some details and discussions\n",
    "authors": [
      "Cl\u00e9ment L. Canonne",
      "Hongyi Lyu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.08987"
  },
  {
    "id": "arXiv:2108.09455",
    "title": "Natural Evolution Strategy for Unconstrained and Implicitly Constrained  Problems with Ridge Structure",
    "abstract": "Comments: accepted at IEEE Symposium Series on Computational Intelligence (IEEE SSCI 2021)",
    "descriptor": "\nComments: accepted at IEEE Symposium Series on Computational Intelligence (IEEE SSCI 2021)\n",
    "authors": [
      "Masahiro Nomura",
      "Isao Ono"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2108.09455"
  },
  {
    "id": "arXiv:2108.09676",
    "title": "Efficient Gaussian Neural Processes for Regression",
    "abstract": "Comments: 6 pages",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Stratis Markou",
      "James Requeima",
      "Wessel Bruinsma",
      "Richard Turner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.09676"
  },
  {
    "id": "arXiv:2108.10566",
    "title": "sigmoidF1: A Smooth F1 Score Surrogate Loss for Multilabel  Classification",
    "abstract": "sigmoidF1: A Smooth F1 Score Surrogate Loss for Multilabel  Classification",
    "descriptor": "",
    "authors": [
      "Gabriel B\u00e9n\u00e9dict",
      "Vincent Koops",
      "Daan Odijk",
      "Maarten de Rijke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.10566"
  },
  {
    "id": "arXiv:2108.10831",
    "title": "LLVIP: A Visible-infrared Paired Dataset for Low-light Vision",
    "abstract": "Comments: 9 pages, 9 figures, ICCV workshop",
    "descriptor": "\nComments: 9 pages, 9 figures, ICCV workshop\n",
    "authors": [
      "Xinyu Jia",
      "Chuang Zhu",
      "Minzhen Li",
      "Wenqi Tang",
      "Wenli Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.10831"
  },
  {
    "id": "arXiv:2108.13512",
    "title": "Energy-Efficient Massive MIMO for Serving Multiple Federated Learning  Groups",
    "abstract": "Comments: Accepted to appear in Proc. IEEE Global Communications Conference (GLOBECOM), Madrid, Spain, Dec. 2021. (v2). arXiv admin note: text overlap with arXiv:2107.09577",
    "descriptor": "\nComments: Accepted to appear in Proc. IEEE Global Communications Conference (GLOBECOM), Madrid, Spain, Dec. 2021. (v2). arXiv admin note: text overlap with arXiv:2107.09577\n",
    "authors": [
      "Tung T. Vu",
      "Hien Quoc Ngo",
      "Duy T. Ngo",
      "Minh N Dao",
      "Erik G. Larsson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2108.13512"
  },
  {
    "id": "arXiv:2108.13562",
    "title": "Adversarial Example Devastation and Detection on Speech Recognition  System by Adding Random Noise",
    "abstract": "Comments: 20 pages, 5 figures, Submitted to Computer Speech and Language",
    "descriptor": "\nComments: 20 pages, 5 figures, Submitted to Computer Speech and Language\n",
    "authors": [
      "Mingyu Dong",
      "Diqun Yan",
      "Yongkang Gong",
      "Rangding Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2108.13562"
  },
  {
    "id": "arXiv:2108.13741",
    "title": "Monolingual versus Multilingual BERTology for Vietnamese Extractive  Multi-Document Summarization",
    "abstract": "Monolingual versus Multilingual BERTology for Vietnamese Extractive  Multi-Document Summarization",
    "descriptor": "",
    "authors": [
      "Huy Quoc To",
      "Kiet Van Nguyen",
      "Ngan Luu-Thuy Nguyen",
      "Anh Gia-Tuan Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13741"
  },
  {
    "id": "arXiv:2109.01135",
    "title": "Sequence-to-Sequence Learning with Latent Neural Grammars",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Yoon Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.01135"
  },
  {
    "id": "arXiv:2109.01745",
    "title": "A realistic approach to generate masked faces applied on two novel  masked face recognition data sets",
    "abstract": "Comments: Accepted at NeurIPS 2021",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Tudor Mare",
      "Georgian Duta",
      "Mariana-Iuliana Georgescu",
      "Adrian Sandru",
      "Bogdan Alexe",
      "Marius Popescu",
      "Radu Tudor Ionescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.01745"
  },
  {
    "id": "arXiv:2109.02418",
    "title": "Multitask Balanced and Recalibrated Network for Medical Code Prediction",
    "abstract": "Multitask Balanced and Recalibrated Network for Medical Code Prediction",
    "descriptor": "",
    "authors": [
      "Wei Sun",
      "Shaoxiong Ji",
      "Erik Cambria",
      "Pekka Marttinen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.02418"
  },
  {
    "id": "arXiv:2109.02934",
    "title": "Fishr: Invariant Gradient Variances for Out-of-distribution  Generalization",
    "abstract": "Comments: 32 pages, 13 tables, 6 figures",
    "descriptor": "\nComments: 32 pages, 13 tables, 6 figures\n",
    "authors": [
      "Alexandre Rame",
      "Corentin Dancette",
      "Matthieu Cord"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.02934"
  },
  {
    "id": "arXiv:2109.04256",
    "title": "Cataloging Dependency Injection Anti-Patterns in Software Systems",
    "abstract": "Comments: Version accepted at The Journal of Systems & Software",
    "descriptor": "\nComments: Version accepted at The Journal of Systems & Software\n",
    "authors": [
      "Rodrigo Laigner",
      "Diogo Mendon\u00e7a",
      "Alessandro Garcia",
      "Marcos Kalinowski"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.04256"
  },
  {
    "id": "arXiv:2109.04525",
    "title": "Sharper bounds on the Fourier concentration of DNFs",
    "abstract": "Comments: 19 pages; to appear at FOCS 2021",
    "descriptor": "\nComments: 19 pages; to appear at FOCS 2021\n",
    "authors": [
      "Victor Lecomte",
      "Li-Yang Tan"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2109.04525"
  },
  {
    "id": "arXiv:2109.04712",
    "title": "Balancing Methods for Multi-label Text Classification with Long-Tailed  Class Distribution",
    "abstract": "Comments: EMNLP 2021",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Yi Huang",
      "Buse Giledereli",
      "Abdullatif K\u00f6ksal",
      "Arzucan \u00d6zg\u00fcr",
      "Elif Ozkirimli"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04712"
  },
  {
    "id": "arXiv:2109.05211",
    "title": "RobustART: Benchmarking Robustness on Architecture Design and Training  Techniques",
    "abstract": "RobustART: Benchmarking Robustness on Architecture Design and Training  Techniques",
    "descriptor": "",
    "authors": [
      "Shiyu Tang",
      "Ruihao Gong",
      "Yan Wang",
      "Aishan Liu",
      "Jiakai Wang",
      "Xinyun Chen",
      "Fengwei Yu",
      "Xianglong Liu",
      "Dawn Song",
      "Alan Yuille",
      "Philip H.S. Torr",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.05211"
  },
  {
    "id": "arXiv:2109.05578",
    "title": "Kernel PCA with the Nystr\u00f6m method",
    "abstract": "Comments: 44 pages, 6 figures",
    "descriptor": "\nComments: 44 pages, 6 figures\n",
    "authors": [
      "Fredrik Hallgren"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2109.05578"
  },
  {
    "id": "arXiv:2109.05583",
    "title": "Automatic Componentwise Boosting: An Interpretable AutoML System",
    "abstract": "Comments: 6 pages, 4 figures, ECML-PKDD Workshop on Automating Data Science 2021",
    "descriptor": "\nComments: 6 pages, 4 figures, ECML-PKDD Workshop on Automating Data Science 2021\n",
    "authors": [
      "Stefan Coors",
      "Daniel Schalk",
      "Bernd Bischl",
      "David R\u00fcgamer"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.05583"
  },
  {
    "id": "arXiv:2109.05675",
    "title": "Online Unsupervised Learning of Visual Representations and Categories",
    "abstract": "Comments: Technical report, 28 pages",
    "descriptor": "\nComments: Technical report, 28 pages\n",
    "authors": [
      "Mengye Ren",
      "Tyler R. Scott",
      "Michael L. Iuzzolino",
      "Michael C. Mozer",
      "Richard Zemel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.05675"
  },
  {
    "id": "arXiv:2109.05710",
    "title": "Robust Stability of Neural-Network Controlled Nonlinear Systems with  Parametric Variability",
    "abstract": "Comments: 15 pages, 7 figures",
    "descriptor": "\nComments: 15 pages, 7 figures\n",
    "authors": [
      "Soumyabrata Talukder",
      "Ratnesh Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.05710"
  },
  {
    "id": "arXiv:2109.05941",
    "title": "Efficient Contrastive Learning via Novel Data Augmentation and  Curriculum Learning",
    "abstract": "Comments: EMNLP 2021",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Seonghyeon Ye",
      "Jiseon Kim",
      "Alice Oh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.05941"
  },
  {
    "id": "arXiv:2109.06721",
    "title": "Linear block and convolutional MDS codes to required rate, distance and  type",
    "abstract": "Linear block and convolutional MDS codes to required rate, distance and  type",
    "descriptor": "",
    "authors": [
      "Ted Hurley"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.06721"
  },
  {
    "id": "arXiv:2109.06992",
    "title": "ML-aided power allocation for Tactical MIMO",
    "abstract": "Comments: Accepted at MILCOM 2021",
    "descriptor": "\nComments: Accepted at MILCOM 2021\n",
    "authors": [
      "Arindam Chowdhury",
      "Gunjan Verma",
      "Chirag Rao",
      "Ananthram Swami",
      "Santiago Segarra"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2109.06992"
  },
  {
    "id": "arXiv:2109.07282",
    "title": "Universality for Sets of Three-Valued Qubit Gates",
    "abstract": "Comments: 18 pages, 26 figures, as presented on the GOL2021 conferece (this https URL)",
    "descriptor": "\nComments: 18 pages, 26 figures, as presented on the GOL2021 conferece (this https URL)\n",
    "authors": [
      "Carlos Efrain Quintero Narvaez"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2109.07282"
  },
  {
    "id": "arXiv:2109.07680",
    "title": "Jointly Modeling Aspect and Polarity for Aspect-based Sentiment Analysis  in Persian Reviews",
    "abstract": "Comments: 20 pages, 9 figures",
    "descriptor": "\nComments: 20 pages, 9 figures\n",
    "authors": [
      "Milad Vazan",
      "Jafar Razmara"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.07680"
  },
  {
    "id": "arXiv:2109.07830",
    "title": "Reframing Instructional Prompts to GPTk's Language",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Swaroop Mishra",
      "Daniel Khashabi",
      "Chitta Baral",
      "Yejin Choi",
      "Hannaneh Hajishirzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07830"
  },
  {
    "id": "arXiv:2109.07960",
    "title": "Efficient and Effective Generation of Test Cases for Pedestrian  Detection -- Search-based Software Testing of Baidu Apollo in SVL",
    "abstract": "Comments: 8 pages, 2021 IEEE Conference on Artificial Intelligence Testing (AITest 2021)",
    "descriptor": "\nComments: 8 pages, 2021 IEEE Conference on Artificial Intelligence Testing (AITest 2021)\n",
    "authors": [
      "Hamid Ebadi",
      "Mahshid Helali Moghadam",
      "Markus Borg",
      "Gregory Gay",
      "Afonso Fontes",
      "Kasper Socha"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.07960"
  },
  {
    "id": "arXiv:2109.08125",
    "title": "NORESQA: A Framework for Speech Quality Assessment using Non-Matching  References",
    "abstract": "NORESQA: A Framework for Speech Quality Assessment using Non-Matching  References",
    "descriptor": "",
    "authors": [
      "Pranay Manocha",
      "Buye Xu",
      "Anurag Kumar"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2109.08125"
  },
  {
    "id": "arXiv:2109.08989",
    "title": "Passive Optical Networking for 5G and Beyond 5G Low-Latency Mobile  Fronthauling Services",
    "abstract": "Passive Optical Networking for 5G and Beyond 5G Low-Latency Mobile  Fronthauling Services",
    "descriptor": "",
    "authors": [
      "Oscar J. Ciceri",
      "Carlos A. Astudillo",
      "Gustavo B. Figueiredo",
      "Zuqing Zhu",
      "Nelson L.S. da Fonseca"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Emerging Technologies (cs.ET)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2109.08989"
  },
  {
    "id": "arXiv:2109.09390",
    "title": "Learning to Improve Representations by Communicating About Perspectives",
    "abstract": "Learning to Improve Representations by Communicating About Perspectives",
    "descriptor": "",
    "authors": [
      "Julius Taylor",
      "Eleni Nisioti",
      "Cl\u00e9ment Moulin-Frier"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.09390"
  },
  {
    "id": "arXiv:2109.09704",
    "title": "BabelCalib: A Universal Approach to Calibrating Central Cameras",
    "abstract": "BabelCalib: A Universal Approach to Calibrating Central Cameras",
    "descriptor": "",
    "authors": [
      "Yaroslava Lochman",
      "Kostiantyn Liepieshov",
      "Jianhui Chen",
      "Michal Perdoch",
      "Christopher Zach",
      "James Pritts"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.09704"
  },
  {
    "id": "arXiv:2109.10000",
    "title": "Automated segmentation and extraction of posterior eye segment using OCT  scans",
    "abstract": "Comments: Accepted in 2021 IEEE International Conference on Robotics and Automation in Industry (ICRAI)",
    "descriptor": "\nComments: Accepted in 2021 IEEE International Conference on Robotics and Automation in Industry (ICRAI)\n",
    "authors": [
      "Bilal Hassan",
      "Taimur Hassan",
      "Ramsha Ahmed",
      "Shiyin Qin",
      "Naoufel Werghi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.10000"
  },
  {
    "id": "arXiv:2109.10817",
    "title": "Causal Inference in Non-linear Time-series using Deep Networks and  Knockoff Counterfactuals",
    "abstract": "Causal Inference in Non-linear Time-series using Deep Networks and  Knockoff Counterfactuals",
    "descriptor": "",
    "authors": [
      "Wasim Ahmad",
      "Maha Shadaydeh",
      "Joachim Denzler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.10817"
  },
  {
    "id": "arXiv:2109.13216",
    "title": "Extending Lattice linearity for Self-Stabilizing Algorithms",
    "abstract": "Extending Lattice linearity for Self-Stabilizing Algorithms",
    "descriptor": "",
    "authors": [
      "Arya Tanmay Gupta",
      "Sandeep S Kulkarni"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.13216"
  },
  {
    "id": "arXiv:2109.13376",
    "title": "Counting colorings of triangle-free graphs",
    "abstract": "Comments: 16 pp",
    "descriptor": "\nComments: 16 pp\n",
    "authors": [
      "Anton Bernshteyn",
      "Tyler Brazelton",
      "Ruijia Cao",
      "Akum Kang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2109.13376"
  },
  {
    "id": "arXiv:2109.14420",
    "title": "FastCorrect 2: Fast Error Correction on Multiple Candidates for  Automatic Speech Recognition",
    "abstract": "Comments: Findings of EMNLP 2021",
    "descriptor": "\nComments: Findings of EMNLP 2021\n",
    "authors": [
      "Yichong Leng",
      "Xu Tan",
      "Rui Wang",
      "Linchen Zhu",
      "Jin Xu",
      "Wenjie Liu",
      "Linquan Liu",
      "Tao Qin",
      "Xiang-Yang Li",
      "Edward Lin",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2109.14420"
  },
  {
    "id": "arXiv:2109.14920",
    "title": "On the Kullback-Leibler divergence between discrete normal distributions",
    "abstract": "Comments: 26 pages",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Frank Nielsen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.14920"
  },
  {
    "id": "arXiv:2110.00137",
    "title": "Iterative Teacher-Aware Learning",
    "abstract": "Iterative Teacher-Aware Learning",
    "descriptor": "",
    "authors": [
      "Luyao Yuan",
      "Dongruo Zhou",
      "Junhong Shen",
      "Jingdong Gao",
      "Jeffrey L. Chen",
      "Quanquan Gu",
      "Ying Nian Wu",
      "Song-Chun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.00137"
  },
  {
    "id": "arXiv:2110.00629",
    "title": "Factored couplings in multi-marginal optimal transport via difference of  convex programming",
    "abstract": "Comments: Fix typo and correct the corollary 3.3",
    "descriptor": "\nComments: Fix typo and correct the corollary 3.3\n",
    "authors": [
      "Quang Huy Tran",
      "Hicham Janati",
      "Ievgen Redko",
      "R\u00e9mi Flamary",
      "Nicolas Courty"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.00629"
  },
  {
    "id": "arXiv:2110.00634",
    "title": "Terminal Adaptive Guidance for Autonomous Hypersonic Strike Weapons via  Reinforcement Learning",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2107.14764; text overlap with arXiv:2109.03880",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2107.14764; text overlap with arXiv:2109.03880\n",
    "authors": [
      "Brian Gaudet",
      "Roberto Furfaro"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.00634"
  },
  {
    "id": "arXiv:2110.00804",
    "title": "ProTo: Program-Guided Transformer for Program-Guided Tasks",
    "abstract": "Comments: Accepted in NeurIPS 2021",
    "descriptor": "\nComments: Accepted in NeurIPS 2021\n",
    "authors": [
      "Zelin Zhao",
      "Karan Samel",
      "Binghong Chen",
      "Le Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.00804"
  },
  {
    "id": "arXiv:2110.00970",
    "title": "Semantic-Guided Zero-Shot Learning for Low-Light Image/Video Enhancement",
    "abstract": "Semantic-Guided Zero-Shot Learning for Low-Light Image/Video Enhancement",
    "descriptor": "",
    "authors": [
      "Shen Zheng",
      "Gaurav Gupta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.00970"
  },
  {
    "id": "arXiv:2110.00987",
    "title": "Motif-based Graph Self-Supervised Learning for Molecular Property  Prediction",
    "abstract": "Comments: Accepted by NeurIPS'21",
    "descriptor": "\nComments: Accepted by NeurIPS'21\n",
    "authors": [
      "Zaixi Zhang",
      "Qi Liu",
      "Hao Wang",
      "Chengqiang Lu",
      "Chee-Kong Lee"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.00987"
  },
  {
    "id": "arXiv:2110.01303",
    "title": "Incremental Class Learning using Variational Autoencoders with  Similarity Learning",
    "abstract": "Incremental Class Learning using Variational Autoencoders with  Similarity Learning",
    "descriptor": "",
    "authors": [
      "Jiahao Huo",
      "Terence L. van Zyl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.01303"
  },
  {
    "id": "arXiv:2110.01500",
    "title": "Factorized Neural Transducer for Efficient Language Model Adaptation",
    "abstract": "Factorized Neural Transducer for Efficient Language Model Adaptation",
    "descriptor": "",
    "authors": [
      "Xie Chen",
      "Zhong Meng",
      "Sarangarajan Parthasarathy",
      "Jinyu Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.01500"
  },
  {
    "id": "arXiv:2110.01571",
    "title": "Learning Causal Representation for Face Transfer across Large Appearance  Gap",
    "abstract": "Learning Causal Representation for Face Transfer across Large Appearance  Gap",
    "descriptor": "",
    "authors": [
      "Gege Gao",
      "Huaibo Huang",
      "Chaoyou Fu",
      "Ran He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.01571"
  },
  {
    "id": "arXiv:2110.01593",
    "title": "Generalized Kernel Thinning",
    "abstract": "Generalized Kernel Thinning",
    "descriptor": "",
    "authors": [
      "Raaz Dwivedi",
      "Lester Mackey"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.01593"
  },
  {
    "id": "arXiv:2110.01773",
    "title": "Differentiable Equilibrium Computation with Decision Diagrams for  Stackelberg Models of Combinatorial Congestion Games",
    "abstract": "Differentiable Equilibrium Computation with Decision Diagrams for  Stackelberg Models of Combinatorial Congestion Games",
    "descriptor": "",
    "authors": [
      "Shinsaku Sakaue",
      "Kengo Nakamura"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.01773"
  },
  {
    "id": "arXiv:2110.01798",
    "title": "Enabling Cell-Free Massive MIMO Systems with Wireless Millimeter Wave  Fronthaul",
    "abstract": "Comments: Submitted, 30 pages, 7 figures",
    "descriptor": "\nComments: Submitted, 30 pages, 7 figures\n",
    "authors": [
      "Umut Demirhan",
      "Ahmed Alkhateeb"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.01798"
  },
  {
    "id": "arXiv:2110.02011",
    "title": "Sound Event Detection Transformer: An Event-based End-to-End Model for  Sound Event Detection",
    "abstract": "Sound Event Detection Transformer: An Event-based End-to-End Model for  Sound Event Detection",
    "descriptor": "",
    "authors": [
      "Zhirong Ye",
      "Xiangdong Wang",
      "Hong Liu",
      "Yueliang Qian",
      "Rui Tao",
      "Long Yan",
      "Kazushige Ouchi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.02011"
  },
  {
    "id": "arXiv:2110.02628",
    "title": "Characterizing Learning Dynamics of Deep Neural Networks via Complex  Networks",
    "abstract": "Comments: IEEE/ICTAI2021 (full paper)",
    "descriptor": "\nComments: IEEE/ICTAI2021 (full paper)\n",
    "authors": [
      "Emanuele La Malfa",
      "Gabriele La Malfa",
      "Giuseppe Nicosia",
      "Vito Latora"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.02628"
  },
  {
    "id": "arXiv:2110.02651",
    "title": "Weak Novel Categories without Tears: A Survey on Weak-Shot Learning",
    "abstract": "Weak Novel Categories without Tears: A Survey on Weak-Shot Learning",
    "descriptor": "",
    "authors": [
      "Li Niu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02651"
  },
  {
    "id": "arXiv:2110.03016",
    "title": "DeepBBS: Deep Best Buddies for Point Cloud Registration",
    "abstract": "Comments: Accepted to 3DV 2021",
    "descriptor": "\nComments: Accepted to 3DV 2021\n",
    "authors": [
      "Itan Hezroni",
      "Amnon Drory",
      "Raja Giryes",
      "Shai Avidan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03016"
  },
  {
    "id": "arXiv:2110.03251",
    "title": "A Cough-based deep learning framework for detecting COVID-19",
    "abstract": "Comments: COVID-19, ICASSP-2022, DiCOVA, top 2nd",
    "descriptor": "\nComments: COVID-19, ICASSP-2022, DiCOVA, top 2nd\n",
    "authors": [
      "Hoang Van Truong",
      "Lam Pham"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.03251"
  },
  {
    "id": "arXiv:2110.03267",
    "title": "Propagating State Uncertainty Through Trajectory Forecasting",
    "abstract": "Comments: 8 pages, 6 figures, 4 tables. Fixed section name typo",
    "descriptor": "\nComments: 8 pages, 6 figures, 4 tables. Fixed section name typo\n",
    "authors": [
      "Boris Ivanovic",
      "Yifeng Lin",
      "Shubham Shrivastava",
      "Punarjay Chakravarty",
      "Marco Pavone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03267"
  },
  {
    "id": "arXiv:2110.03370",
    "title": "WenetSpeech: A 10000+ Hours Multi-domain Mandarin Corpus for Speech  Recognition",
    "abstract": "WenetSpeech: A 10000+ Hours Multi-domain Mandarin Corpus for Speech  Recognition",
    "descriptor": "",
    "authors": [
      "Binbin Zhang",
      "Hang Lv",
      "Pengcheng Guo",
      "Qijie Shao",
      "Chao Yang",
      "Lei Xie",
      "Xin Xu",
      "Hui Bu",
      "Xiaoyu Chen",
      "Chenchen Zeng",
      "Di Wu",
      "Zhendong Peng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.03370"
  },
  {
    "id": "arXiv:2110.03762",
    "title": "Group-based Delivery of Critical Traffic in Cellular IoT Networks",
    "abstract": "Group-based Delivery of Critical Traffic in Cellular IoT Networks",
    "descriptor": "",
    "authors": [
      "O. Vikhrova",
      "S. Pizzi",
      "A. Molinaro",
      "A. Iera",
      "K. Samuylov",
      "G. Araniti"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.03762"
  },
  {
    "id": "arXiv:2110.03909",
    "title": "Meta-Learning with Task-Adaptive Loss Function for Few-Shot Learning",
    "abstract": "Comments: ICCV 2021 (Oral). Code at this https URL",
    "descriptor": "\nComments: ICCV 2021 (Oral). Code at this https URL\n",
    "authors": [
      "Sungyong Baik",
      "Janghoon Choi",
      "Heewon Kim",
      "Dohee Cho",
      "Jaesik Min",
      "Kyoung Mu Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03909"
  },
  {
    "id": "arXiv:2110.04076",
    "title": "Self-supervised Point Cloud Prediction Using 3D Spatio-temporal  Convolutional Networks",
    "abstract": "Comments: Accepted for CoRL 2021",
    "descriptor": "\nComments: Accepted for CoRL 2021\n",
    "authors": [
      "Benedikt Mersch",
      "Xieyuanli Chen",
      "Jens Behley",
      "Cyrill Stachniss"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.04076"
  },
  {
    "id": "arXiv:2110.04160",
    "title": "Federated Learning for Big Data: A Survey on Opportunities,  Applications, and Future Directions",
    "abstract": "Comments: Submitted for peer review in a journal",
    "descriptor": "\nComments: Submitted for peer review in a journal\n",
    "authors": [
      "Thippa Reddy Gadekallu",
      "Quoc-Viet Pham",
      "Thien Huynh-The",
      "Sweta Bhattacharya",
      "Praveen Kumar Reddy Maddikunta",
      "Madhusanka Liyanage"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04160"
  },
  {
    "id": "arXiv:2110.04200",
    "title": "On tolerance of discrete systems with respect to transition  perturbations",
    "abstract": "Comments: Full version of TACAS'22 submission",
    "descriptor": "\nComments: Full version of TACAS'22 submission\n",
    "authors": [
      "R\u00f4mulo Meira-G\u00f3es",
      "Eunsuk Kang",
      "St\u00e9phane Lafortune",
      "Stavros Tripakis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.04200"
  },
  {
    "id": "arXiv:2110.04203",
    "title": "Toward a Human-Level Video Understanding Intelligence",
    "abstract": "Comments: Presented at AI-HRI symposium as part of AAAI-FSS 2021 (arXiv:2109.10836). The first two authors have equal contribution",
    "descriptor": "\nComments: Presented at AI-HRI symposium as part of AAAI-FSS 2021 (arXiv:2109.10836). The first two authors have equal contribution\n",
    "authors": [
      "Yu-Jung Heo",
      "Minsu Lee",
      "Seongho Choi",
      "Woo Suk Choi",
      "Minjung Shin",
      "Minjoon Jung",
      "Jeh-Kwang Ryu",
      "Byoung-Tak Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.04203"
  },
  {
    "id": "arXiv:2110.04402",
    "title": "Walking into the complex plane to 'order' better time integrators",
    "abstract": "Comments: 30 pages, 15 figures",
    "descriptor": "\nComments: 30 pages, 15 figures\n",
    "authors": [
      "Jithin D. George",
      "Samuel Y. Jung",
      "Niall M. Mangan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Complex Variables (math.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04402"
  },
  {
    "id": "arXiv:2110.04439",
    "title": "A Generic Knowledge Based Medical Diagnosis Expert System",
    "abstract": "A Generic Knowledge Based Medical Diagnosis Expert System",
    "descriptor": "",
    "authors": [
      "Xin Huang",
      "Xuejiao Tang",
      "Wenbin Zhang",
      "Shichao Pei",
      "Ji Zhang",
      "Wensheng Gan",
      "Mingli Zhang",
      "Zhen Liu",
      "Ruijun Chen",
      "Yiyi Huang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04439"
  },
  {
    "id": "arXiv:2110.04507",
    "title": "TiKick: Toward Playing Multi-agent Football Full Games from Single-agent  Demonstrations",
    "abstract": "TiKick: Toward Playing Multi-agent Football Full Games from Single-agent  Demonstrations",
    "descriptor": "",
    "authors": [
      "Shiyu Huang",
      "Wenze Chen",
      "Longfei Zhang",
      "Ziyang Li",
      "Fengming Zhu",
      "Deheng Ye",
      "Ting Chen",
      "Jun Zhu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04507"
  },
  {
    "id": "arXiv:2110.04624",
    "title": "Iterative Refinement Graph Neural Network for Antibody  Sequence-Structure Co-design",
    "abstract": "Iterative Refinement Graph Neural Network for Antibody  Sequence-Structure Co-design",
    "descriptor": "",
    "authors": [
      "Wengong Jin",
      "Jeremy Wohlwend",
      "Regina Barzilay",
      "Tommi Jaakkola"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04624"
  },
  {
    "id": "arXiv:2110.04764",
    "title": "Deep learning-based person re-identification methods: A survey and  outlook of recent works",
    "abstract": "Comments: 21 pages, 13 figures",
    "descriptor": "\nComments: 21 pages, 13 figures\n",
    "authors": [
      "Zhangqiang Ming",
      "Min Zhu",
      "Xiaoyong Wei",
      "Xiangkun Wang",
      "Jiamin Zhu",
      "Junlong Cheng",
      "Yong Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04764"
  },
  {
    "id": "arXiv:2110.04933",
    "title": "A Faster Algorithm for Maximum Independent Set on Interval Filament  Graphs",
    "abstract": "A Faster Algorithm for Maximum Independent Set on Interval Filament  Graphs",
    "descriptor": "",
    "authors": [
      "Darcy Best",
      "Max Ward"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.04933"
  },
  {
    "id": "arXiv:2110.05279",
    "title": "Sliced Mutual Information: A Scalable Measure of Statistical Dependence",
    "abstract": "Sliced Mutual Information: A Scalable Measure of Statistical Dependence",
    "descriptor": "",
    "authors": [
      "Ziv Goldfeld",
      "Kristjan Greenewald"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.05279"
  },
  {
    "id": "arXiv:2110.05319",
    "title": "Efficient Training of 3D Seismic Image Fault Segmentation Network under  Sparse Labels by Weakening Anomaly Annotation",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Yimin Dou",
      "Kewen Li",
      "Jianbing Zhu",
      "Timing Li",
      "Shaoquan Tan",
      "Zongchao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.05319"
  },
  {
    "id": "arXiv:2110.05430",
    "title": "Density-based interpretable hypercube region partitioning for mixed  numeric and categorical data",
    "abstract": "Density-based interpretable hypercube region partitioning for mixed  numeric and categorical data",
    "descriptor": "",
    "authors": [
      "Samuel Ackerman",
      "Eitan Farchi",
      "Orna Raz",
      "Marcel Zalmanovici",
      "Maya Zohar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.05430"
  },
  {
    "id": "arXiv:2110.05454",
    "title": "Momentum Centering and Asynchronous Update for Adaptive Gradient Methods",
    "abstract": "Momentum Centering and Asynchronous Update for Adaptive Gradient Methods",
    "descriptor": "",
    "authors": [
      "Juntang Zhuang",
      "Yifan Ding",
      "Tommy Tang",
      "Nicha Dvornek",
      "Sekhar Tatikonda",
      "James S. Duncan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.05454"
  },
  {
    "id": "arXiv:2110.05668",
    "title": "NAS-Bench-360: Benchmarking Diverse Tasks for Neural Architecture Search",
    "abstract": "NAS-Bench-360: Benchmarking Diverse Tasks for Neural Architecture Search",
    "descriptor": "",
    "authors": [
      "Renbo Tu",
      "Mikhail Khodak",
      "Nicholas Roberts",
      "Ameet Talwalkar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05668"
  },
  {
    "id": "arXiv:2110.05717",
    "title": "Relation-aware Video Reading Comprehension for Temporal Language  Grounding",
    "abstract": "Comments: Accepted by EMNLP-21",
    "descriptor": "\nComments: Accepted by EMNLP-21\n",
    "authors": [
      "Jialin Gao",
      "Xin Sun",
      "Mengmeng Xu",
      "Xi Zhou",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05717"
  },
  {
    "id": "arXiv:2110.05910",
    "title": "Bridging the Band Gap: What Device Physicists Need to Know About Machine  Learning",
    "abstract": "Bridging the Band Gap: What Device Physicists Need to Know About Machine  Learning",
    "descriptor": "",
    "authors": [
      "Nathaniel Tye",
      "Stephan Hofmann",
      "Phillip Stanley-Marbell"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.05910"
  },
  {
    "id": "arXiv:2110.06021",
    "title": "Embedded-model flows: Combining the inductive biases of model-free deep  learning and explicit probabilistic modeling",
    "abstract": "Embedded-model flows: Combining the inductive biases of model-free deep  learning and explicit probabilistic modeling",
    "descriptor": "",
    "authors": [
      "Gianluigi Silvestri",
      "Emily Fertig",
      "Dave Moore",
      "Luca Ambrogioni"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06021"
  },
  {
    "id": "arXiv:2110.06060",
    "title": "Downtime-Aware O-RAN VNF Deployment Strategy for Optimized Self-Healing  in the O-Cloud",
    "abstract": "Comments: 6 pages, 4 figures, IEEE Global Communications Conference 2021",
    "descriptor": "\nComments: 6 pages, 4 figures, IEEE Global Communications Conference 2021\n",
    "authors": [
      "Ibrahim Tamim",
      "Anas Saci",
      "Manar Jammal",
      "Abdallah Shami"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.06060"
  },
  {
    "id": "arXiv:2110.06172",
    "title": "Complexity of optimizing over the integers",
    "abstract": "Complexity of optimizing over the integers",
    "descriptor": "",
    "authors": [
      "Amitabh Basu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.06172"
  },
  {
    "id": "arXiv:2110.06304",
    "title": "Generalized Time Domain Velocity Vector",
    "abstract": "Comments: Submitted",
    "descriptor": "\nComments: Submitted\n",
    "authors": [
      "Sr\u0111an Kiti\u0107",
      "J\u00e9r\u00f4me Daniel"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.06304"
  },
  {
    "id": "arXiv:2110.06382",
    "title": "A Survey of Open Source User Activity Traces with Applications to User  Mobility Characterization and Modeling",
    "abstract": "Comments: 23 pages, 6 pages references",
    "descriptor": "\nComments: 23 pages, 6 pages references\n",
    "authors": [
      "Sinjoni Mukhopadhyay King",
      "Faisal Nawab",
      "Katia Obraczka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.06382"
  },
  {
    "id": "arXiv:2110.06532",
    "title": "SMS: An Efficient Source Model Selection Framework for Model Reuse",
    "abstract": "SMS: An Efficient Source Model Selection Framework for Model Reuse",
    "descriptor": "",
    "authors": [
      "Minjun Zhao",
      "Lu Chen",
      "Keyu Yang",
      "Yuntao Du",
      "Yunjun Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.06532"
  },
  {
    "id": "arXiv:2110.06559",
    "title": "Infinitely Divisible Noise in the Low Privacy Regime",
    "abstract": "Comments: Updated figure 3, which was misleading in the previous version",
    "descriptor": "\nComments: Updated figure 3, which was misleading in the previous version\n",
    "authors": [
      "Rasmus Pagh",
      "Nina Mesing Stausholm"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.06559"
  },
  {
    "id": "arXiv:2110.06607",
    "title": "THOMAS: Trajectory Heatmap Output with learned Multi-Agent Sampling",
    "abstract": "THOMAS: Trajectory Heatmap Output with learned Multi-Agent Sampling",
    "descriptor": "",
    "authors": [
      "Thomas Gilles",
      "Stefano Sabatini",
      "Dzmitry Tsishkou",
      "Bogdan Stanciulescu",
      "Fabien Moutarde"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.06607"
  },
  {
    "id": "arXiv:2110.06635",
    "title": "ADOP: Approximate Differentiable One-Pixel Point Rendering",
    "abstract": "ADOP: Approximate Differentiable One-Pixel Point Rendering",
    "descriptor": "",
    "authors": [
      "Darius R\u00fcckert",
      "Linus Franke",
      "Marc Stamminger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.06635"
  },
  {
    "id": "arXiv:2110.06636",
    "title": "Unique on Facebook: Formulation and Evidence of (Nano)targeting  Individual Users with non-PII Data",
    "abstract": "Comments: 16 pages, 12 figures, 4 tables",
    "descriptor": "\nComments: 16 pages, 12 figures, 4 tables\n",
    "authors": [
      "Jos\u00e9 Gonz\u00e1lez-Caba\u00f1as",
      "\u00c1ngel Cuevas",
      "Rub\u00e9n Cuevas",
      "Juan L\u00f3pez-Fern\u00e1ndez",
      "David Garc\u00eda"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.06636"
  },
  {
    "id": "arXiv:2110.06863",
    "title": "Improving Users' Mental Model with Attention-directed Counterfactual  Edits",
    "abstract": "Comments: Accepted for publication in Applied AI Letters",
    "descriptor": "\nComments: Accepted for publication in Applied AI Letters\n",
    "authors": [
      "Kamran Alipour",
      "Arijit Ray",
      "Xiao Lin",
      "Michael Cogswell",
      "Jurgen P. Schulze",
      "Yi Yao",
      "Giedrius T. Burachas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.06863"
  },
  {
    "id": "arXiv:2110.06976",
    "title": "Rethinking the Representational Continuity: Towards Unsupervised  Continual Learning",
    "abstract": "Rethinking the Representational Continuity: Towards Unsupervised  Continual Learning",
    "descriptor": "",
    "authors": [
      "Divyam Madaan",
      "Jaehong Yoon",
      "Yuanchun Li",
      "Yunxin Liu",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06976"
  },
  {
    "id": "arXiv:2110.07187",
    "title": "Revisiting IPA-based Cross-lingual Text-to-speech",
    "abstract": "Comments: Submitted to ICASSP2022",
    "descriptor": "\nComments: Submitted to ICASSP2022\n",
    "authors": [
      "Haitong Zhang",
      "Haoyue Zhan",
      "Yang Zhang",
      "Xinyuan Yu",
      "Yue Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.07187"
  },
  {
    "id": "arXiv:2110.07217",
    "title": "Alpine Permafrost Modeling: On the influence of topography driven  lateral fluxes",
    "abstract": "Comments: 20 pages (without appendix), 9 figures",
    "descriptor": "\nComments: 20 pages (without appendix), 9 figures\n",
    "authors": [
      "Jonas Beddrich",
      "Shubhangi Gupta",
      "Barbara Wohlmuth",
      "Gabriele Chiogna"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.07217"
  },
  {
    "id": "arXiv:2110.07233",
    "title": "Optimal Update in Energy Harvesting Aided Terahertz Communications with  Random Blocking",
    "abstract": "Comments: 9 pages, 4 Postscript figures",
    "descriptor": "\nComments: 9 pages, 4 Postscript figures\n",
    "authors": [
      "Lixin Wang",
      "Fuzhou Peng",
      "Xiang Chen",
      "Shidong Zhou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.07233"
  },
  {
    "id": "arXiv:2110.07239",
    "title": "Solving Large Break Minimization Problems in a Mirrored Double  Round-robin Tournament Using Quantum Annealing",
    "abstract": "Comments: 12pages, 2 figures",
    "descriptor": "\nComments: 12pages, 2 figures\n",
    "authors": [
      "Michiya Kuramata",
      "Ryota Katsuki",
      "Kazuhide Nakata"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.07239"
  },
  {
    "id": "arXiv:2110.07511",
    "title": "Contrastive Proposal Extension with LSTM Network for Weakly Supervised  Object Detection",
    "abstract": "Contrastive Proposal Extension with LSTM Network for Weakly Supervised  Object Detection",
    "descriptor": "",
    "authors": [
      "Pei Lv",
      "Suqi Hu",
      "Tianran Hao",
      "Haohan Ji",
      "Lisha Cui",
      "Haoyi Fan",
      "Mingliang Xu",
      "Changsheng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.07511"
  },
  {
    "id": "arXiv:2110.07602",
    "title": "P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally  Across Scales and Tasks",
    "abstract": "P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally  Across Scales and Tasks",
    "descriptor": "",
    "authors": [
      "Xiao Liu",
      "Kaixuan Ji",
      "Yicheng Fu",
      "Zhengxiao Du",
      "Zhilin Yang",
      "Jie Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.07602"
  },
  {
    "id": "arXiv:2110.07604",
    "title": "NeRS: Neural Reflectance Surfaces for Sparse-view 3D Reconstruction in  the Wild",
    "abstract": "Comments: In NeurIPS 2021. v2-3: Fixed minor typos",
    "descriptor": "\nComments: In NeurIPS 2021. v2-3: Fixed minor typos\n",
    "authors": [
      "Jason Y. Zhang",
      "Gengshan Yang",
      "Shubham Tulsiani",
      "Deva Ramanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.07604"
  },
  {
    "id": "arXiv:2110.07698",
    "title": "Directed Percolation in Random Temporal Network Models with  Heterogeneities",
    "abstract": "Comments: Implementation available at this https URL",
    "descriptor": "\nComments: Implementation available at this https URL\n",
    "authors": [
      "Arash Badie-Modiri",
      "Abbas K. Rizi",
      "M\u00e1rton Karsai",
      "Mikko Kivel\u00e4"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.07698"
  },
  {
    "id": "arXiv:2110.07723",
    "title": "EMDS-7: Environmental Microorganism Image Dataset Seventh Version for  Multiple Object Detection Evaluation",
    "abstract": "EMDS-7: Environmental Microorganism Image Dataset Seventh Version for  Multiple Object Detection Evaluation",
    "descriptor": "",
    "authors": [
      "Hechen Yang",
      "Chen Li",
      "Xin Zhao",
      "Bencheng Cai",
      "Jiawei Zhang",
      "Pingli Ma",
      "Peng Zhao",
      "Ao Chen",
      "Tao Jiang",
      "Hongzan Sun",
      "Yueyang Teng",
      "Shouliang Qi",
      "Tao Jiang",
      "Marcin Grzegorzek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.07723"
  },
  {
    "id": "arXiv:2110.07749",
    "title": "Attention-Free Keyword Spotting",
    "abstract": "Comments: Submitted to ICASSP-2022 (5 pages)",
    "descriptor": "\nComments: Submitted to ICASSP-2022 (5 pages)\n",
    "authors": [
      "Mashrur M. Morshed",
      "Ahmad Omar Ahsan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.07749"
  },
  {
    "id": "arXiv:2110.07809",
    "title": "PTQ-SL: Exploring the Sub-layerwise Post-training Quantization",
    "abstract": "PTQ-SL: Exploring the Sub-layerwise Post-training Quantization",
    "descriptor": "",
    "authors": [
      "Zhihang Yuan",
      "Yiqi Chen",
      "Chenhao Xue",
      "Chenguang Zhang",
      "Qiankun Wang",
      "Guangyu Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.07809"
  },
  {
    "id": "arXiv:2110.07959",
    "title": "Low-rank Matrix Recovery With Unknown Correspondence",
    "abstract": "Low-rank Matrix Recovery With Unknown Correspondence",
    "descriptor": "",
    "authors": [
      "Zhiwei Tang",
      "Tsung-Hui Chang",
      "Xiaojing Ye",
      "Hongyuan Zha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.07959"
  },
  {
    "id": "arXiv:2110.08009",
    "title": "MaGNET: Uniform Sampling from Deep Generative Network Manifolds Without  Retraining",
    "abstract": "Comments: 13 pages, 14 pages Appendix, 23 figures",
    "descriptor": "\nComments: 13 pages, 14 pages Appendix, 23 figures\n",
    "authors": [
      "Ahmed Imtiaz Humayun",
      "Randall Balestriero",
      "Richard Baraniuk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08009"
  },
  {
    "id": "arXiv:2110.08059",
    "title": "FlexConv: Continuous Kernel Convolutions with Differentiable Kernel  Sizes",
    "abstract": "Comments: First two authors contributed equally to this work",
    "descriptor": "\nComments: First two authors contributed equally to this work\n",
    "authors": [
      "David W. Romero",
      "Robert-Jan Bruintjes",
      "Jakub M. Tomczak",
      "Erik J. Bekkers",
      "Mark Hoogendoorn",
      "Jan C. van Gemert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08059"
  },
  {
    "id": "arXiv:2110.08172",
    "title": "MLFC: From 10 to 50 Planners in the Multi-Agent Programming Contest",
    "abstract": "Comments: Published in The Multi-Agent Programming Contest 2021: One-and-a-Half Decades of Exploring Multi-Agent Systems",
    "descriptor": "\nComments: Published in The Multi-Agent Programming Contest 2021: One-and-a-Half Decades of Exploring Multi-Agent Systems\n",
    "authors": [
      "Rafael C. Cardoso",
      "Angelo Ferrando",
      "Fabio Papacchini",
      "Matt Luckcuck",
      "Sven Linker",
      "Terry R. Payne"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.08172"
  }
]
[
  {
    "id": "arXiv:2110.10150",
    "title": "Summ^N: A Multi-Stage Summarization Framework for Long Input Dialogues  and Documents",
    "abstract": "Text summarization is an essential task to help readers capture salient\ninformation from documents, news, interviews, and meetings. However, most\nstate-of-the-art pretrained language models are unable to efficiently process\nlong text commonly seen in the summarization problem domain. In this paper, we\npropose Summ^N, a simple, flexible, and effective multi-stage framework for\ninput texts that are longer than the maximum context lengths of typical\npretrained LMs. Summ^N first generates the coarse summary in multiple stages\nand then produces the final fine-grained summary based on them. The framework\ncan process input text of arbitrary length by adjusting the number of stages\nwhile keeping the LM context size fixed. Moreover, it can deal with both\ndocuments and dialogues and can be used on top of any underlying backbone\nabstractive summarization model. Our experiments demonstrate that Summ^N\nsignificantly outperforms previous state-of-the-art methods by improving ROUGE\nscores on three long meeting summarization datasets AMI, ICSI, and QMSum, two\nlong TV series datasets from SummScreen, and a newly proposed long document\nsummarization dataset GovReport. Our data and code are available at\nhttps://github.com/chatc/Summ-N.",
    "descriptor": "",
    "authors": [
      "Yusen Zhang",
      "Ansong Ni",
      "Ziming Mao",
      "Chen Henry Wu",
      "Chenguang Zhu",
      "Budhaditya Deb",
      "Ahmed H. Awadallah",
      "Dragomir Radev",
      "Rui Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.10150"
  },
  {
    "id": "arXiv:2110.10151",
    "title": "Can Fortran's 'do concurrent' replace directives for accelerated  computing?",
    "abstract": "Recently, there has been growing interest in using standard language\nconstructs (e.g. C++'s Parallel Algorithms and Fortran's do concurrent) for\naccelerated computing as an alternative to directive-based APIs (e.g. OpenMP\nand OpenACC). These constructs have the potential to be more portable, and some\ncompilers already (or have plans to) support such standards. Here, we look at\nthe current capabilities, portability, and performance of replacing directives\nwith Fortran's do concurrent using a mini-app that currently implements OpenACC\nfor GPU-acceleration and OpenMP for multi-core CPU parallelism. We replace as\nmany directives as possible with do concurrent, testing various configurations\nand compiler options within three major compilers: GNU's gfortran, NVIDIA's\nnvfortran, and Intel's ifort. We find that with the right compiler versions and\nflags, many directives can be replaced without loss of performance or\nportability, and, in the case of nvfortran, they can all be replaced. We\ndiscuss limitations that may apply to more complicated codes and future\nlanguage additions that may mitigate them. The software and Singularity\ncontainers are publicly provided to allow the results to be reproduced.",
    "descriptor": "\nComments: 18 pages, 2 figures, Accepted for publication at WACCPD 2021\n",
    "authors": [
      "Miko M. Stulajter",
      "Ronald M. Caplan",
      "Jon A. Linker"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2110.10151"
  },
  {
    "id": "arXiv:2110.10152",
    "title": "Identifying Stroke Indicators Using Rough Sets",
    "abstract": "Stroke is widely considered as the second most common cause of mortality. The\nadverse consequences of stroke have led to global interest and work for\nimproving the management and diagnosis of stroke. Various techniques for data\nmining have been used globally for accurate prediction of occurrence of stroke\nbased on the risk factors that are associated with the electronic health care\nrecords (EHRs) of the patients. In particular, EHRs routinely contain several\nthousands of features and most of them are redundant and irrelevant that need\nto be discarded to enhance the prediction accuracy. The choice of\nfeature-selection methods can help in improving the prediction accuracy of the\nmodel and efficient data management of the archived input features. In this\npaper, we systematically analyze the various features in EHR records for the\ndetection of stroke. We propose a novel rough-set based technique for ranking\nthe importance of the various EHR records in detecting stroke. Unlike the\nconventional rough-set techniques, our proposed technique can be applied on any\ndataset that comprises binary feature sets. We evaluated our proposed method in\na publicly available dataset of EHR, and concluded that age, average glucose\nlevel, heart disease, and hypertension were the most essential attributes for\ndetecting stroke in patients. Furthermore, we benchmarked the proposed\ntechnique with other popular feature-selection techniques. We obtained the best\nperformance in ranking the importance of individual features in detecting\nstroke.",
    "descriptor": "\nComments: Accepted in IEEE Access, 2020\n",
    "authors": [
      "Muhammad Salman Pathan",
      "Jianbiao Zhang",
      "Deepu John",
      "Avishek Nag",
      "Soumyabrata Dev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10152"
  },
  {
    "id": "arXiv:2110.10153",
    "title": "Towards Puffin: The Creation of an Uncertainty Compiler",
    "abstract": "An uncertainty compiler is a tool that automatically translates original\ncomputer source code lacking explicit uncertainty analysis into code containing\nappropriate uncertainty representations and uncertainty propagation algorithms.\nWe have developed an prototype uncertainty compiler along with an associated\nobject-oriented uncertainty language in the form of a stand-alone Python\nlibrary. It handles the specifications of input uncertainties and inserts calls\nto intrusive uncertainty quantification algorithms in the library. The\nuncertainty compiler can apply intrusive uncertainty propagation methods to\ncodes or parts of codes and therefore more comprehensively and flexibly address\nboth epistemic and aleatory uncertainties.",
    "descriptor": "\nComments: 21 Pages, 10 Figures\n",
    "authors": [
      "Nicholas Gray",
      "Marco De Angelis",
      "Scott Ferson"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.10153"
  },
  {
    "id": "arXiv:2110.10165",
    "title": "NAS-HPO-Bench-II: A Benchmark Dataset on Joint Optimization of  Convolutional Neural Network Architecture and Training Hyperparameters",
    "abstract": "The benchmark datasets for neural architecture search (NAS) have been\ndeveloped to alleviate the computationally expensive evaluation process and\nensure a fair comparison. Recent NAS benchmarks only focus on architecture\noptimization, although the training hyperparameters affect the obtained model\nperformances. Building the benchmark dataset for joint optimization of\narchitecture and training hyperparameters is essential to further NAS research.\nThe existing NAS-HPO-Bench is a benchmark for joint optimization, but it does\nnot consider the network connectivity design as done in modern NAS algorithms.\nThis paper introduces the first benchmark dataset for joint optimization of\nnetwork connections and training hyperparameters, which we call\nNAS-HPO-Bench-II. We collect the performance data of 4K cell-based\nconvolutional neural network architectures trained on the CIFAR-10 dataset with\ndifferent learning rate and batch size settings, resulting in the data of 192K\nconfigurations. The dataset includes the exact data for 12 epoch training. We\nfurther build the surrogate model predicting the accuracies after 200 epoch\ntraining to provide the performance data of longer training epoch. By analyzing\nNAS-HPO-Bench-II, we confirm the dependency between architecture and training\nhyperparameters and the necessity of joint optimization. Finally, we\ndemonstrate the benchmarking of the baseline optimization algorithms using\nNAS-HPO-Bench-II.",
    "descriptor": "\nComments: 16 pages, 6 figures. Accepted at ACML2021 (long oral). API is available at this https URL\n",
    "authors": [
      "Yoichi Hirose",
      "Nozomu Yoshinari",
      "Shinichi Shirakawa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10165"
  },
  {
    "id": "arXiv:2110.10174",
    "title": "Hand-Object Contact Prediction via Motion-Based Pseudo-Labeling and  Guided Progressive Label Correction",
    "abstract": "Every hand-object interaction begins with contact. Despite predicting the\ncontact state between hands and objects is useful in understanding hand-object\ninteractions, prior methods on hand-object analysis have assumed that the\ninteracting hands and objects are known, and were not studied in detail. In\nthis study, we introduce a video-based method for predicting contact between a\nhand and an object. Specifically, given a video and a pair of hand and object\ntracks, we predict a binary contact state (contact or no-contact) for each\nframe. However, annotating a large number of hand-object tracks and contact\nlabels is costly. To overcome the difficulty, we propose a semi-supervised\nframework consisting of (i) automatic collection of training data with\nmotion-based pseudo-labels and (ii) guided progressive label correction (gPLC),\nwhich corrects noisy pseudo-labels with a small amount of trusted data. We\nvalidated our framework's effectiveness on a newly built benchmark dataset for\nhand-object contact prediction and showed superior performance against existing\nbaseline methods. Code and data are available at\nhttps://github.com/takumayagi/hand_object_contact_prediction.",
    "descriptor": "\nComments: BMVC 2021\n",
    "authors": [
      "Takuma Yagi",
      "Md Tasnimul Hasan",
      "Yoichi Sato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10174"
  },
  {
    "id": "arXiv:2110.10183",
    "title": "Cascaded Cross MLP-Mixer GANs for Cross-View Image Translation",
    "abstract": "It is hard to generate an image at target view well for previous cross-view\nimage translation methods that directly adopt a simple encoder-decoder or U-Net\nstructure, especially for drastically different views and severe deformation\ncases. To ease this problem, we propose a novel two-stage framework with a new\nCascaded Cross MLP-Mixer (CrossMLP) sub-network in the first stage and one\nrefined pixel-level loss in the second stage. In the first stage, the CrossMLP\nsub-network learns the latent transformation cues between image code and\nsemantic map code via our novel CrossMLP blocks. Then the coarse results are\ngenerated progressively under the guidance of those cues. Moreover, in the\nsecond stage, we design a refined pixel-level loss that eases the noisy\nsemantic label problem with more reasonable regularization in a more compact\nfashion for better optimization. Extensive experimental results on\nDayton~\\cite{vo2016localizing} and CVUSA~\\cite{workman2015wide} datasets show\nthat our method can generate significantly better results than state-of-the-art\nmethods. The source code and trained models are available at\nhttps://github.com/Amazingren/CrossMLP.",
    "descriptor": "\nComments: 16 pages, 5 figures\n",
    "authors": [
      "Bin Ren",
      "Hao Tang",
      "Nicu Sebe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10183"
  },
  {
    "id": "arXiv:2110.10185",
    "title": "GenNI: Human-AI Collaboration for Data-Backed Text Generation",
    "abstract": "Table2Text systems generate textual output based on structured data utilizing\nmachine learning. These systems are essential for fluent natural language\ninterfaces in tools such as virtual assistants; however, left to generate\nfreely these ML systems often produce misleading or unexpected outputs. GenNI\n(Generation Negotiation Interface) is an interactive visual system for\nhigh-level human-AI collaboration in producing descriptive text. The tool\nutilizes a deep learning model designed with explicit control states. These\ncontrols allow users to globally constrain model generations, without\nsacrificing the representation power of the deep learning models. The visual\ninterface makes it possible for users to interact with AI systems following a\nRefine-Forecast paradigm to ensure that the generation system acts in a manner\nhuman users find suitable. We report multiple use cases on two experiments that\nimprove over uncontrolled generation approaches, while at the same time\nproviding fine-grained control. A demo and source code are available at\nhttps://genni.vizhub.ai .",
    "descriptor": "\nComments: IEEE VIS 2021\n",
    "authors": [
      "Hendrik Strobelt",
      "Jambay Kinley",
      "Robert Krueger",
      "Johanna Beyer",
      "Hanspeter Pfister",
      "Alexander M. Rush"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.10185"
  },
  {
    "id": "arXiv:2110.10187",
    "title": "Sky Is Not the Limit: Tighter Rank Bounds for Elevator Automata in  B\u00fcchi Automata Complementation (Technical Report)",
    "abstract": "We propose several heuristics for mitigating one of the main causes of\ncombinatorial explosion in rank-based complementation of B\\\"{u}chi automata\n(BAs): unnecessarily high bounds on the ranks of states. First, we identify\nelevator automata, which is a large class of BAs (generalizing\nsemi-deterministic BAs), occurring often in practice, where ranks of states are\nbounded according to the structure of strongly connected components. The bounds\nfor elevator automata also carry over to general BAs that contain elevator\nautomata as a sub-structure. Second, we introduce two techniques for refining\nbounds on the ranks of BA states using data-flow analysis of the automaton. We\nimplement out techniques as an extension of the tool Ranker for BA\ncomplementation and show that they indeed greatly prune the generated state\nspace, obtaining significantly better results and outperforming other\nstate-of-the-art tools on a large set of benchmarks.",
    "descriptor": "",
    "authors": [
      "Vojt\u011bch Havlena",
      "Ond\u0159ej Leng\u00e1l",
      "Barbora \u0160mahl\u00edkov\u00e1"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.10187"
  },
  {
    "id": "arXiv:2110.10189",
    "title": "StructFormer: Learning Spatial Structure for Language-Guided Semantic  Rearrangement of Novel Objects",
    "abstract": "Geometric organization of objects into semantically meaningful arrangements\npervades the built world. As such, assistive robots operating in warehouses,\noffices, and homes would greatly benefit from the ability to recognize and\nrearrange objects into these semantically meaningful structures. To be useful,\nthese robots must contend with previously unseen objects and receive\ninstructions without significant programming. While previous works have\nexamined recognizing pairwise semantic relations and sequential manipulation to\nchange these simple relations none have shown the ability to arrange objects\ninto complex structures such as circles or table settings. To address this\nproblem we propose a novel transformer-based neural network, StructFormer,\nwhich takes as input a partial-view point cloud of the current object\narrangement and a structured language command encoding the desired object\nconfiguration. We show through rigorous experiments that StructFormer enables a\nphysical robot to rearrange novel objects into semantically meaningful\nstructures with multi-object relational constraints inferred from the language\ncommand.",
    "descriptor": "",
    "authors": [
      "Weiyu Liu",
      "Chris Paxton",
      "Tucker Hermans",
      "Dieter Fox"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10189"
  },
  {
    "id": "arXiv:2110.10194",
    "title": "CoFi: Coarse-to-Fine ICP for LiDAR Localization in an Efficient  Long-lasting Point Cloud Map",
    "abstract": "LiDAR odometry and localization has attracted increasing research interest in\nrecent years. In the existing works, iterative closest point (ICP) is widely\nused since it is precise and efficient. Due to its non-convexity and its local\niterative strategy, however, ICP-based method easily falls into local optima,\nwhich in turn calls for a precise initialization. In this paper, we propose\nCoFi, a Coarse-to-Fine ICP algorithm for LiDAR localization. Specifically, the\nproposed algorithm down-samples the input point sets under multiple voxel\nresolution, and gradually refines the transformation from the coarse point sets\nto the fine-grained point sets. In addition, we propose a map based LiDAR\nlocalization algorithm that extracts semantic feature points from the LiDAR\nframes and apply CoFi to estimate the pose on an efficient point cloud map.\nWith the help of the Cylinder3D algorithm for LiDAR scan semantic segmentation,\nthe proposed CoFi localization algorithm demonstrates the state-of-the-art\nperformance on the KITTI odometry benchmark, with significant improvement over\nthe literature.",
    "descriptor": "\nComments: 8 pages, submitted to ICRA 2022\n",
    "authors": [
      "Yecheng Lyu",
      "Xinming Huang",
      "Ziming Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.10194"
  },
  {
    "id": "arXiv:2110.10200",
    "title": "fairadapt: Causal Reasoning for Fair Data Pre-processing",
    "abstract": "Machine learning algorithms are useful for various predictions tasks, but\nthey can also learn how to discriminate, based on gender, race or other\nsensitive attributes. This realization gave rise to the field of fair machine\nlearning, which aims to measure and mitigate such algorithmic bias. This\nmanuscript describes the R-package fairadapt, which implements a causal\ninference pre-processing method. By making use of a causal graphical model and\nthe observed data, the method can be used to address hypothetical questions of\nthe form \"What would my salary have been, had I been of a different\ngender/race?\". Such individual level counterfactual reasoning can help\neliminate discrimination and help justify fair decisions. We also discuss\nappropriate relaxations which assume certain causal pathways from the sensitive\nattribute to the outcome are not discriminatory.",
    "descriptor": "\nComments: Keywords: algorithmic fairness, causal inference, machine learning\n",
    "authors": [
      "Drago Ple\u010dko",
      "Nicolas Bennett",
      "Nicolai Meinshausen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.10200"
  },
  {
    "id": "arXiv:2110.10205",
    "title": "MultiHead MultiModal Deep Interest Recommendation Network",
    "abstract": "With the development of information technology, human beings are constantly\nproducing a large amount of information at all times. How to obtain the\ninformation that users are interested in from the large amount of information\nhas become an issue of great concern to users and even business managers. In\norder to solve this problem, from traditional machine learning to deep learning\nrecommendation systems, researchers continue to improve optimization models and\nexplore solutions. Because researchers have optimized more on the\nrecommendation model network structure, they have less research on enriching\nrecommendation model features, and there is still room for in-depth\nrecommendation model optimization. Based on the DIN\\cite{Authors01} model, this\npaper adds multi-head and multi-modal modules, which enriches the feature sets\nthat the model can use, and at the same time strengthens the cross-combination\nand fitting capabilities of the model. Experiments show that the multi-head\nmulti-modal DIN improves the recommendation prediction effect, and outperforms\ncurrent state-of-the-art methods on various comprehensive indicators.",
    "descriptor": "",
    "authors": [
      "Mingbao Yang",
      "ShaoBo Li",
      "Zhou Peng",
      "Ansi Zhang",
      "Yuanmeng Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10205"
  },
  {
    "id": "arXiv:2110.10206",
    "title": "Come Again? Re-Query in Referring Expression Comprehension",
    "abstract": "To build a shared perception of the world, humans rely on the ability to\nresolve misunderstandings by requesting and accepting clarifications. However,\nwhen evaluating visiolinguistic models, metrics such as accuracy enforce the\nassumption that a decision must be made based on a single piece of evidence. In\nthis work, we relax this assumption for the task of referring expression\ncomprehension by allowing the model to request help when its confidence is low.\nWe consider two ways in which this help can be provided: multimodal re-query,\nwhere the user is allowed to point or click to provide additional information\nto the model, and rephrase re-query, where the user is only allowed to provide\nanother referring expression. We demonstrate the importance of re-query by\nshowing that providing the best referring expression for all objects can\nincrease accuracy by up to 21.9% and that this accuracy can be matched by\nre-querying only 12% of initial referring expressions. We further evaluate\nre-query functions for both multimodal and rephrase re-query across three\nmodern approaches and demonstrate combined replacement for rephrase re-query,\nwhich improves average single-query performance by up to 6.5% and converges to\nas close as 1.6% of the upper bound of single-query performance.",
    "descriptor": "\nComments: 17 pages, 3 figures\n",
    "authors": [
      "Stephan J. Lemmer",
      "Jason J. Corso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10206"
  },
  {
    "id": "arXiv:2110.10211",
    "title": "Learning Equivariances and Partial Equivariances from Data",
    "abstract": "Group equivariant Convolutional Neural Networks (G-CNNs) constrain features\nto respect the chosen symmetries, and lead to better generalization when these\nsymmetries appear in the data. However, if the chosen symmetries are not\npresent, group equivariant architectures lead to overly constrained models and\nworse performance. Frequently, the distribution of the data can be better\nrepresented by a subset of a group than by the group as a whole, e.g.,\nrotations in $[-90^{\\circ}, 90^{\\circ}]$. In such cases, a model that respects\nequivariance partially is better suited to represent the data. Moreover,\nrelevant symmetries may differ for low and high-level features, e.g., edge\norientations in a face, and face poses relative to the camera. As a result, the\noptimal level of equivariance may differ per layer. In this work, we introduce\nPartial G-CNNs: a family of equivariant networks able to learn partial and full\nequivariances from data at every layer end-to-end. Partial G-CNNs retain full\nequivariance whenever beneficial, e.g., for rotated MNIST, but are able to\nrestrict it whenever it becomes harmful, e.g., for 6~/~9 or natural image\nclassification. Partial G-CNNs perform on par with G-CNNs when full\nequivariance is necessary, and outperform them otherwise. Our method is\napplicable to discrete groups, continuous groups and combinations thereof.",
    "descriptor": "",
    "authors": [
      "David W. Romero",
      "Suhas Lohit"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10211"
  },
  {
    "id": "arXiv:2110.10213",
    "title": "Neural Medication Extraction: A Comparison of Recent Models in  Supervised and Semi-supervised Learning Settings",
    "abstract": "Drug prescriptions are essential information that must be encoded in\nelectronic medical records. However, much of this information is hidden within\nfree-text reports. This is why the medication extraction task has emerged. To\ndate, most of the research effort has focused on small amount of data and has\nonly recently considered deep learning methods. In this paper, we present an\nindependent and comprehensive evaluation of state-of-the-art neural\narchitectures on the I2B2 medical prescription extraction task both in the\nsupervised and semi-supervised settings. The study shows the very competitive\nperformance of simple DNN models on the task as well as the high interest of\npre-trained models. Adapting the latter models on the I2B2 dataset enables to\npush medication extraction performances above the state-of-the-art. Finally,\nthe study also confirms that semi-supervised techniques are promising to\nleverage large amounts of unlabeled data in particular in low resource setting\nwhen labeled data is too costly to acquire.",
    "descriptor": "\nComments: IEEE International Conference on Healthcare Informatics (ICHI 2021)\n",
    "authors": [
      "Ali Can Kocabiyikoglu",
      "Fran\u00e7ois Portet",
      "Raheel Qader",
      "Jean-Marc Babouchkine"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.10213"
  },
  {
    "id": "arXiv:2110.10217",
    "title": "An Adaptive Sampling and Edge Detection Approach for Encoding Static  Images for Spiking Neural Networks",
    "abstract": "Current state-of-the-art methods of image classification using convolutional\nneural networks are often constrained by both latency and power consumption.\nThis places a limit on the devices, particularly low-power edge devices, that\ncan employ these methods. Spiking neural networks (SNNs) are considered to be\nthe third generation of artificial neural networks which aim to address these\nlatency and power constraints by taking inspiration from biological neuronal\ncommunication processes. Before data such as images can be input into an SNN,\nhowever, they must be first encoded into spike trains. Herein, we propose a\nmethod for encoding static images into temporal spike trains using edge\ndetection and an adaptive signal sampling method for use in SNNs. The edge\ndetection process consists of first performing Canny edge detection on the 2D\nstatic images and then converting the edge detected images into two X and Y\nsignals using an image-to-signal conversion method. The adaptive signaling\napproach consists of sampling the signals such that the signals maintain enough\ndetail and are sensitive to abrupt changes in the signal. Temporal encoding\nmechanisms such as threshold-based representation (TBR) and step-forward (SF)\nare then able to be used to convert the sampled signals into spike trains. We\nuse various error and indicator metrics to optimize and evaluate the efficiency\nand precision of the proposed image encoding approach. Comparison results\nbetween the original and reconstructed signals from spike trains generated\nusing edge-detection and adaptive temporal encoding mechanism exhibit 18x and\n7x reduction in average root mean square error (RMSE) compared to the\nconventional SF and TBR encoding, respectively, while used for encoding MNIST\ndataset.",
    "descriptor": "",
    "authors": [
      "Peyton Chandarana",
      "Junlin Ou",
      "Ramtin Zand"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10217"
  },
  {
    "id": "arXiv:2110.10221",
    "title": "The CoRa Tensor Compiler: Compilation for Ragged Tensors with Minimal  Padding",
    "abstract": "There is often variation in the shape and size of input data used for deep\nlearning. In many cases, such data can be represented using tensors with\nnon-uniform shapes, or ragged tensors. Due to limited and non-portable support\nfor efficient execution on ragged tensors, current deep learning frameworks\ngenerally use techniques such as padding and masking to make the data shapes\nuniform and then offload the computations to optimized kernels for dense tensor\nalgebra. Such techniques can, however, lead to a lot of wasted computation and\ntherefore, a loss in performance. This paper presents CoRa, a tensor compiler\nthat allows users to easily generate efficient code for ragged tensor operators\ntargeting a wide range of CPUs and GPUs. Evaluating CoRa on a variety of\noperators on ragged tensors as well as on an encoder layer of the transformer\nmodel, we find that CoRa (i)performs competitively with hand-optimized\nimplementations of the operators and the transformer encoder and (ii) achieves,\nover PyTorch, a 1.6X geomean speedup for the encoder on an Nvidia GPU and a\n1.86X geomean speedup for the multi-head attention module used in transformers\non an ARM CPU.",
    "descriptor": "\nComments: 23 pages, 25 figures and 10 tables\n",
    "authors": [
      "Pratik Fegade",
      "Tianqi Chen",
      "Phillip B. Gibbons",
      "Todd C. Mowry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10221"
  },
  {
    "id": "arXiv:2110.10223",
    "title": "A Federated Learning Aggregation Algorithm for Pervasive Computing:  Evaluation and Comparison",
    "abstract": "Pervasive computing promotes the installation of connected devices in our\nliving spaces in order to provide services. Two major developments have gained\nsignificant momentum recently: an advanced use of edge resources and the\nintegration of machine learning techniques for engineering applications. This\nevolution raises major challenges, in particular related to the appropriate\ndistribution of computing elements along an edge-to-cloud continuum. About\nthis, Federated Learning has been recently proposed for distributed model\ntraining in the edge. The principle of this approach is to aggregate models\nlearned on distributed clients in order to obtain a new, more general model.\nThe resulting model is then redistributed to clients for further training. To\ndate, the most popular federated learning algorithm uses coordinate-wise\naveraging of the model parameters for aggregation. However, it has been shown\nthat this method is not adapted in heterogeneous environments where data is not\nidentically and independently distributed (non-iid). This corresponds directly\nto some pervasive computing scenarios where heterogeneity of devices and users\nchallenges machine learning with the double objective of generalization and\npersonalization. In this paper, we propose a novel aggregation algorithm,\ntermed FedDist, which is able to modify its model architecture (here, deep\nneural network) by identifying dissimilarities between specific neurons amongst\nthe clients. This permits to account for clients' specificity without impairing\ngeneralization. Furthermore, we define a complete method to evaluate federated\nlearning in a realistic way taking generalization and personalization into\naccount.\nUsing this method, FedDist is extensively tested and compared with three\nstate-of-the-art federated learning algorithms on the pervasive domain of Human\nActivity Recognition with smartphones.",
    "descriptor": "\nComments: 9th IEEE International Conference on Pervasive Computing and Communications (PerCom 2021)\n",
    "authors": [
      "Sannara Ek",
      "Fran\u00e7ois Portet",
      "Philippe Lalanda",
      "German Vega"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.10223"
  },
  {
    "id": "arXiv:2110.10225",
    "title": "What Averages Do Not Tell -- Predicting Real Life Processes with  Sequential Deep Learning",
    "abstract": "Deep Learning is proven to be an effective tool for modeling sequential data\nas shown by the success in Natural Language, Computer Vision and Signal\nProcessing. Process Mining concerns discovering insights on business processes\nfrom their execution data that are logged by supporting information systems.\nThe logged data (event log) is formed of event sequences (traces) that\ncorrespond to executions of a process. Many Deep Learning techniques have been\nsuccessfully adapted for predictive Process Mining that aims to predict process\noutcomes, remaining time, the next event, or even the suffix of running traces.\nTraces in Process Mining are multimodal sequences and very differently\nstructured than natural language sentences or images. This may require a\ndifferent approach to processing. So far, there has been little focus on these\ndifferences and the challenges introduced. Looking at suffix prediction as the\nmost challenging of these tasks, the performance of Deep Learning models was\nevaluated only on average measures and for a small number of real-life event\nlogs. Comparing the results between papers is difficult due to different\npre-processing and evaluation strategies. Challenges that may be relevant are\nthe skewness of trace-length distribution and the skewness of the activity\ndistribution in real-life event logs. We provide an end-to-end framework which\nenables to compare the performance of seven state-of-the-art sequential\narchitectures in common settings. Results show that sequence modeling still has\na lot of room for improvement for majority of the more complex datasets.\nFurther research and insights are required to get consistent performance not\njust in average measures but additionally over all the prefixes.",
    "descriptor": "",
    "authors": [
      "Istv\u00e1n Ketyk\u00f3",
      "Felix Mannhardt",
      "Marwan Hassani",
      "Boudewijn van Dongen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10225"
  },
  {
    "id": "arXiv:2110.10232",
    "title": "Test time Adaptation through Perturbation Robustness",
    "abstract": "Data samples generated by several real world processes are dynamic in nature\n\\textit{i.e.}, their characteristics vary with time. Thus it is not possible to\ntrain and tackle all possible distributional shifts between training and\ninference, using the host of transfer learning methods in literature. In this\npaper, we tackle this problem of adapting to domain shift at inference time\n\\textit{i.e.}, we do not change the training process, but quickly adapt the\nmodel at test-time to handle any domain shift. For this, we propose to enforce\nconsistency of predictions of data sampled in the vicinity of test sample on\nthe image manifold. On a host of test scenarios like dealing with corruptions\n(CIFAR-10-C and CIFAR-100-C), and domain adaptation (VisDA-C), our method is at\npar or significantly outperforms previous methods.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Prabhu Teja Sivaprasad",
      "Fran\u00e7ois Fleuret"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10232"
  },
  {
    "id": "arXiv:2110.10233",
    "title": "Forecasting Market Prices using DL with Data Augmentation and  Meta-learning: ARIMA still wins!",
    "abstract": "Deep-learning techniques have been successfully used for time-series\nforecasting and have often shown superior performance on many standard\nbenchmark datasets as compared to traditional techniques. Here we present a\ncomprehensive and comparative study of performance of deep-learning techniques\nfor forecasting prices in financial markets. We benchmark state-of-the-art\ndeep-learning baselines, such as NBeats, etc., on data from currency as well as\nstock markets. We also generate synthetic data using a fuzzy-logic based model\nof demand driven by technical rules such as moving averages, which are often\nused by traders. We benchmark the baseline techniques on this synthetic data as\nwell as use it for data augmentation. We also apply gradient-based\nmeta-learning to account for non-stationarity of financial time-series. Our\nextensive experiments notwithstanding, the surprising result is that the\nstandard ARIMA models outperforms deep-learning even using data augmentation or\nmeta-learning. We conclude by speculating as to why this might be the case.",
    "descriptor": "\nComments: Accepted at the ICBINB Workshop @ NeurIPS, 2021\n",
    "authors": [
      "Vedant Shah",
      "Gautam Shroff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10233"
  },
  {
    "id": "arXiv:2110.10234",
    "title": "More Engineering, No Silos: Rethinking Processes and Interfaces in  Collaboration between Interdisciplinary Teams for Machine Learning Projects",
    "abstract": "The introduction of machine learning (ML) components in software projects has\ncreated the need for software engineers to collaborate with data scientists and\nother specialists. While collaboration can always be challenging, ML introduces\nadditional challenges with its exploratory model development process,\nadditional skills and knowledge needed, difficulties testing ML systems, need\nfor continuous evolution and monitoring, and non-traditional quality\nrequirements such as fairness and explainability. Through interviews with 45\npractitioners from 28 organizations, we identified key collaboration challenges\nthat teams face when building and deploying ML systems into production. We\nreport on common collaboration points in the development of production ML\nsystems for requirements, data, and integration, as well as corresponding team\npatterns and challenges. We find that most of these challenges center around\ncommunication, documentation, engineering, and process and collect\nrecommendations to address these challenges.",
    "descriptor": "\nComments: 22 pages, 10 figures, 5 tables\n",
    "authors": [
      "Nadia Nahar",
      "Shurui Zhou",
      "Grace Lewis",
      "Christian K\u00e4stner"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10234"
  },
  {
    "id": "arXiv:2110.10236",
    "title": "Optimal Sequential Stochastic Deployment of Multiple Passenger Robots",
    "abstract": "We present a new algorithm for deploying passenger robots in marsupial robot\nsystems. A marsupial robot system consists of a carrier robot (e.g., a ground\nvehicle), which is highly capable and has a long mission duration, and at least\none passenger robot (e.g., a short-duration aerial vehicle) transported by the\ncarrier. We optimize the performance of passenger robot deployment by proposing\nan algorithm that reasons over uncertainty by exploiting information about the\nprior probability distribution of features of interest in the environment. Our\nalgorithm is formulated as a solution to a sequential stochastic assignment\nproblem (SSAP). The key feature of the algorithm is a recurrence relationship\nthat defines a set of observation thresholds that are used to decide when to\ndeploy passenger robots. Our algorithm computes the optimal policy in $O(NR)$\ntime, where $N$ is the number of deployment decision points and $R$ is the\nnumber of passenger robots to be deployed. We conducted drone deployment\nexploration experiments on real-world data from the DARPA Subterranean\nchallenge to test the SSAP algorithm. Our results show that our deployment\nalgorithm outperforms other competing algorithms, such as the classic secretary\napproach and baseline partitioning methods, and is comparable to an offline\noracle algorithm.",
    "descriptor": "",
    "authors": [
      "Chris",
      "Graeme Best",
      "Geoffrey A. Hollinger"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.10236"
  },
  {
    "id": "arXiv:2110.10237",
    "title": "Stochastic Assignment for Deploying Multiple Marsupial Robots",
    "abstract": "Marsupial robot teams consist of carrier robots that transport and deploy\nmultiple passenger robots, such as a team of ground robots that carry and\ndeploy multiple aerial robots, to rapidly explore complex environments. We\nspecifically address the problem of planning the deployment times and locations\nof the carrier robots to best meet the objectives of a mission while reasoning\nover uncertain future observations and rewards. While prior work proposed\noptimal, polynomial-time solutions to single-carrier robot systems, the\nmultiple-carrier robot deployment problem is fundamentally harder as it\nrequires addressing conflicts and dependencies between deployments of multiple\npassenger robots. We propose a centralized heuristic search algorithm for the\nmultiple-carrier robot deployment problem that combines Monte Carlo Tree Search\nwith a dynamic programming-based solution to the Sequential Stochastic\nAssignment Problem as a rollout action-selection policy. Our results with both\nprocedurally-generated data and data drawn from the DARPA Subterranean\nChallenge Urban Circuit show the viability of our approach and substantial\nexploration performance improvements over alternative algorithms.",
    "descriptor": "",
    "authors": [
      "Chris",
      "Graeme Best",
      "Geoffrey A. Hollinger"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.10237"
  },
  {
    "id": "arXiv:2110.10239",
    "title": "1st Place Solution for the UVO Challenge on Image-based Open-World  Segmentation 2021",
    "abstract": "We describe our two-stage instance segmentation framework we use to compete\nin the challenge. The first stage of our framework consists of an object\ndetector, which generates object proposals in the format of bounding boxes.\nThen, the images and the detected bounding boxes are fed to the second stage,\nwhere a segmentation network is applied to segment the objects in the bounding\nboxes. We train all our networks in a class-agnostic way. Our approach achieves\nthe first place in the UVO 2021 Image-based Open-World Segmentation Challenge.",
    "descriptor": "\nComments: Code:this https URL\n",
    "authors": [
      "Yuming Du",
      "Wen Guo",
      "Yang Xiao",
      "Vincent Lepetit"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10239"
  },
  {
    "id": "arXiv:2110.10246",
    "title": "2020 State of the Octoverse: Securing the World's Software",
    "abstract": "Open source is the connective tissue for much of the information economy. You\nwould be hard-pressed to find a scenario where your data does not pass through\nat least one open source component. Many of the services and technology we all\nrely on, from banking to healthcare, also rely on open source software. The\nartifacts of open source code serve as critical i infrastructure for much of\nthe global economy, making the security of open source software\nmission-critical to the world.",
    "descriptor": "\nComments: published by GitHub\n",
    "authors": [
      "Nicole Forsgren",
      "Bas Alberts",
      "Kevin Backhouse",
      "Grey Baker",
      "Greg Cecarelli",
      "Derek Jedamski",
      "Scot Kelly",
      "Clair Sullivan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.10246"
  },
  {
    "id": "arXiv:2110.10248",
    "title": "2020 State of the Octoverse: Finding Balance Between Work and Play",
    "abstract": "Over the past year, many developers and other technology professionals have\ntransitioned to a remote-first world, as COVID-19 pressed organizations to\nsupport working from home whenever possible. This shift quickly changed the\nroutines and environments where we work and learn, redrawing the lines between\npersonal and professional lives. How does this affect the ways we develop and\ndeliver software, both at work and in our open source projects?",
    "descriptor": "\nComments: GitHub\n",
    "authors": [
      "Nicole Forsgren",
      "Greg Ceccarelli",
      "Derek Jedamski",
      "Scot Kelly",
      "Clair Sullivan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.10248"
  },
  {
    "id": "arXiv:2110.10249",
    "title": "Neural Stochastic Partial Differential Equations",
    "abstract": "Stochastic partial differential equations (SPDEs) are the mathematical tool\nof choice to model complex spatio-temporal dynamics of systems subject to the\ninfluence of randomness. We introduce the Neural SPDE model providing an\nextension to two important classes of physics-inspired neural architectures. On\nthe one hand, it extends all the popular neural -- ordinary, controlled,\nstochastic, rough -- differential equation models in that it is capable of\nprocessing incoming information even when the latter evolves in an infinite\ndimensional state space. On the other hand, it extends Neural Operators --\nrecent generalizations of neural networks modelling mappings between functional\nspaces -- in that it can be used to learn complex SPDE solution operators\n$(u_0,\\xi) \\mapsto u$ depending simultaneously on an initial condition $u_0$\nand on a stochastic forcing term $\\xi$, while remaining resolution-invariant\nand equation-agnostic. A Neural SPDE is constrained to respect real physical\ndynamics and consequently requires only a modest amount of data to train,\ndepends on a significantly smaller amount of parameters and has better\ngeneralization properties compared to Neural Operators. Through various\nexperiments on semilinear SPDEs with additive and multiplicative noise\n(including the stochastic Navier-Stokes equations) we demonstrate how Neural\nSPDEs can flexibly be used in a supervised learning setting as well as\nconditional generative models to sample solutions of SPDEs conditioned on prior\nknowledge, systematically achieving in both cases better performance than all\nalternative models.",
    "descriptor": "",
    "authors": [
      "Cristopher Salvi",
      "Maud Lemercier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10249"
  },
  {
    "id": "arXiv:2110.10255",
    "title": "A Simple Approach to Continual Learning by Transferring Skill Parameters",
    "abstract": "In order to be effective general purpose machines in real world environments,\nrobots not only will need to adapt their existing manipulation skills to new\ncircumstances, they will need to acquire entirely new skills on-the-fly. A\ngreat promise of continual learning is to endow robots with this ability, by\nusing their accumulated knowledge and experience from prior skills. We take a\nfresh look at this problem, by considering a setting in which the robot is\nlimited to storing that knowledge and experience only in the form of learned\nskill policies. We show that storing skill policies, careful pre-training, and\nappropriately choosing when to transfer those skill policies is sufficient to\nbuild a continual learner in the context of robotic manipulation. We analyze\nwhich conditions are needed to transfer skills in the challenging Meta-World\nsimulation benchmark. Using this analysis, we introduce a pair-wise metric\nrelating skills that allows us to predict the effectiveness of skill transfer\nbetween tasks, and use it to reduce the problem of continual learning to\ncurriculum selection. Given an appropriate curriculum, we show how to\ncontinually acquire robotic manipulation skills without forgetting, and using\nfar fewer samples than needed to train them from scratch.",
    "descriptor": "\nComments: Submitted to ICRA 2022\n",
    "authors": [
      "K.R. Zentner",
      "Ryan Julian",
      "Ujjwal Puri",
      "Yulun Zhang",
      "Gaurav S. Sukhatme"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.10255"
  },
  {
    "id": "arXiv:2110.10261",
    "title": "Learning Domain Specific Language Models for Automatic Speech  Recognition through Machine Translation",
    "abstract": "Automatic Speech Recognition (ASR) systems have been gaining popularity in\nthe recent years for their widespread usage in smart phones and speakers.\nBuilding ASR systems for task-specific scenarios is subject to the availability\nof utterances that adhere to the style of the task as well as the language in\nquestion. In our work, we target such a scenario wherein task-specific text\ndata is available in a language that is different from the target language in\nwhich an ASR Language Model (LM) is expected. We use Neural Machine Translation\n(NMT) as an intermediate step to first obtain translations of the task-specific\ntext data. We then train LMs on the 1-best and N-best translations and study\nways to improve on such a baseline LM. We develop a procedure to derive word\nconfusion networks from NMT beam search graphs and evaluate LMs trained on\nthese confusion networks. With experiments on the WMT20 chat translation task\ndataset, we demonstrate that NMT confusion networks can help to reduce the\nperplexity of both n-gram and recurrent neural network LMs compared to those\ntrained only on N-best translations.",
    "descriptor": "\nComments: Master's thesis work from July 2021, 22 pages including references\n",
    "authors": [
      "Saurav Jha"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.10261"
  },
  {
    "id": "arXiv:2110.10275",
    "title": "Early- and in-season crop type mapping without current-year ground  truth: generating labels from historical information via a topology-based  approach",
    "abstract": "Land cover classification in remote sensing is often faced with the challenge\nof limited ground truth. Incorporating historical information has the potential\nto significantly lower the expensive cost associated with collecting ground\ntruth and, more importantly, enable early- and in-season mapping that is\nhelpful to many pre-harvest decisions. In this study, we propose a new approach\nthat can effectively transfer knowledge about the topology (i.e. relative\nposition) of different crop types in the spectral feature space (e.g. the\nhistogram of SWIR1 vs RDEG1 bands) to generate labels, thereby support crop\nclassification in a different year. Importantly, our approach does not attempt\nto transfer classification decision boundaries that are susceptible to\ninter-annual variations of weather and management, but relies on the more\nrobust and shift-invariant topology information. We tested this approach for\nmapping corn/soybeans in the US Midwest and paddy rice/corn/soybeans in\nNortheast China using Landsat-8 and Sentinel-2 data. Results show that our\napproach automatically generates high-quality labels for crops in the target\nyear immediately after each image becomes available. Based on these generated\nlabels from our approach, the subsequent crop type mapping using a random\nforest classifier reach the F1 score as high as 0.887 for corn as early as the\nsilking stage and 0.851 for soybean as early as the flowering stage and the\noverall accuracy of 0.873 in Iowa. In Northeast China, F1 scores of paddy rice,\ncorn and soybeans and the overall accuracy can exceed 0.85 two and half months\nahead of harvest. Overall, these results highlight unique advantages of our\napproach in transferring historical knowledge and maximizing the timeliness of\ncrop maps. Our approach supports a general paradigm shift towards learning\ntransferrable and generalizable knowledge to facilitate land cover\nclassification.",
    "descriptor": "",
    "authors": [
      "Chenxi Lin",
      "Liheng Zhong",
      "Xiao-Peng Song",
      "Jinwei Dong",
      "David B.Lobell",
      "Zhenong Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10275"
  },
  {
    "id": "arXiv:2110.10278",
    "title": "Fine-Grained Control of Artistic Styles in Image Generation",
    "abstract": "Recent advances in generative models and adversarial training have enabled\nartificially generating artworks in various artistic styles. It is highly\ndesirable to gain more control over the generated style in practice. However,\nartistic styles are unlike object categories -- there are a continuous spectrum\nof styles distinguished by subtle differences. Few works have been explored to\ncapture the continuous spectrum of styles and apply it to a style generation\ntask. In this paper, we propose to achieve this by embedding original artwork\nexamples into a continuous style space. The style vectors are fed to the\ngenerator and discriminator to achieve fine-grained control. Our method can be\nused with common generative adversarial networks (such as StyleGAN).\nExperiments show that our method not only precisely controls the fine-grained\nartistic style but also improves image quality over vanilla StyleGAN as\nmeasured by FID.",
    "descriptor": "",
    "authors": [
      "Xin Miao",
      "Huayan Wang",
      "Jun Fu",
      "Jiayi Liu",
      "Shen Wang",
      "Zhenyu Liao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10278"
  },
  {
    "id": "arXiv:2110.10283",
    "title": "Fine-Grained Complexity Theory: Conditional Lower Bounds for  Computational Geometry",
    "abstract": "Fine-grained complexity theory is the area of theoretical computer science\nthat proves conditional lower bounds based on the Strong Exponential Time\nHypothesis and similar conjectures. This area has been thriving in the last\ndecade, leading to conditionally best-possible algorithms for a wide variety of\nproblems on graphs, strings, numbers etc. This article is an introduction to\nfine-grained lower bounds in computational geometry, with a focus on lower\nbounds for polynomial-time problems based on the Orthogonal Vectors Hypothesis.\nSpecifically, we discuss conditional lower bounds for nearest neighbor search\nunder the Euclidean distance and Fr\\'echet distance.",
    "descriptor": "\nComments: Written version of a tutorial talk given at a special session of CiE'21\n",
    "authors": [
      "Karl Bringmann"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.10283"
  },
  {
    "id": "arXiv:2110.10284",
    "title": "flip-hoisting: Exploiting Repeated Parameters in Discrete Probabilistic  Programs",
    "abstract": "Probabilistic programming is emerging as a popular and effective means of\nprobabilistic modeling and an alternative to probabilistic graphical models.\nProbabilistic programs provide greater expressivity and flexibility in modeling\nprobabilistic systems than graphical models, but this flexibility comes at a\ncost: there remains a significant disparity in performance between specialized\nBayesian network solvers and probabilistic program inference algorithms. In\nthis work we present a program analysis and associated optimization,\nflip-hoisting, that collapses repetitious parameters in discrete probabilistic\nprograms to improve inference performance. flip-hoisting generalizes parameter\nsharing - a well-known important optimization from discrete graphical models -\nto probabilistic programs. We implement flip-hoisting in an existing\nprobabilistic programming language and show empirically that it significantly\nimproves inference performance, narrowing the gap between the performances of\nprobabilistic programs and probabilistic graphical models.",
    "descriptor": "",
    "authors": [
      "Yu-Hsi Cheng",
      "Todd Millstein",
      "Guy Van den Broeck",
      "Steven Holtzen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10284"
  },
  {
    "id": "arXiv:2110.10285",
    "title": "CUI @ Auto-UI: Exploring the Fortunate and Unfortunate Futures of  Conversational Automotive User Interfaces",
    "abstract": "This work aims to connect the Automotive User Interfaces (Auto-UI) and\nConversational User Interfaces (CUI) communities through discussion of their\nshared view of the future of automotive conversational user interfaces. The\nworkshop aims to encourage creative consideration of optimistic and pessimistic\nfutures, encouraging attendees to explore the opportunities and barriers that\nlie ahead through a game. Considerations of the future will be mapped out in\ngreater detail through the drafting of research agendas, by which attendees\nwill get to know each other's expertise and networks of resources. The two day\nworkshop, consisting of two 90-minute sessions, will facilitate greater\ncommunication and collaboration between these communities, connecting\nresearchers to work together to influence the futures they imagine in the\nworkshop.",
    "descriptor": "\nComments: Workshop published and presented at Automotive User Interfaces 2021 (AutoUI 21)\n",
    "authors": [
      "Justin Edwards",
      "Philipp Wintersberger",
      "Leigh Clark",
      "Daniel Rough",
      "Philip R Doyle",
      "Victoria Banks",
      "Adam Wyner",
      "Christian P. Janssen",
      "Benjamin R. Cowan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.10285"
  },
  {
    "id": "arXiv:2110.10286",
    "title": "Robust Semi-Supervised Classification using GANs with Self-Organizing  Maps",
    "abstract": "Generative adversarial networks (GANs) have shown tremendous promise in\nlearning to generate data and effective at aiding semi-supervised\nclassification. However, to this point, semi-supervised GAN methods make the\nassumption that the unlabeled data set contains only samples of the joint\ndistribution of the classes of interest, referred to as inliers. Consequently,\nwhen presented with a sample from other distributions, referred to as outliers,\nGANs perform poorly at determining that it is not qualified to make a decision\non the sample. The problem of discriminating outliers from inliers while\nmaintaining classification accuracy is referred to here as the DOIC problem. In\nthis work, we describe an architecture that combines self-organizing maps\n(SOMs) with SS-GANS with the goal of mitigating the DOIC problem and\nexperimental results indicating that the architecture achieves the goal.\nMultiple experiments were conducted on hyperspectral image data sets. The\nSS-GANS performed slightly better than supervised GANS on classification\nproblems with and without the SOM. Incorporating the SOMs into the SS-GANs and\nthe supervised GANS led to substantially mitigation of the DOIC problem when\ncompared to SS-GANS and GANs without the SOMs. Furthermore, the SS-GANS\nperformed much better than GANS on the DOIC problem, even without the SOMs.",
    "descriptor": "\nComments: 9 pages, 13 figures This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Ronald Fick",
      "Paul Gader",
      "Alina Zare"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10286"
  },
  {
    "id": "arXiv:2110.10287",
    "title": "Multi-concept adversarial attacks",
    "abstract": "As machine learning (ML) techniques are being increasingly used in many\napplications, their vulnerability to adversarial attacks becomes well-known.\nTest time attacks, usually launched by adding adversarial noise to test\ninstances, have been shown effective against the deployed ML models. In\npractice, one test input may be leveraged by different ML models. Test time\nattacks targeting a single ML model often neglect their impact on other ML\nmodels. In this work, we empirically demonstrate that naively attacking the\nclassifier learning one concept may negatively impact classifiers trained to\nlearn other concepts. For example, for the online image classification\nscenario, when the Gender classifier is under attack, the (wearing) Glasses\nclassifier is simultaneously attacked with the accuracy dropped from 98.69 to\n88.42. This raises an interesting question: is it possible to attack one set of\nclassifiers without impacting the other set that uses the same test instance?\nAnswers to the above research question have interesting implications for\nprotecting privacy against ML model misuse. Attacking ML models that pose\nunnecessary risks of privacy invasion can be an important tool for protecting\nindividuals from harmful privacy exploitation. In this paper, we address the\nabove research question by developing novel attack techniques that can\nsimultaneously attack one set of ML models while preserving the accuracy of the\nother. In the case of linear classifiers, we provide a theoretical framework\nfor finding an optimal solution to generate such adversarial examples. Using\nthis theoretical framework, we develop a multi-concept attack strategy in the\ncontext of deep learning. Our results demonstrate that our techniques can\nsuccessfully attack the target classes while protecting the protected classes\nin many different settings, which is not possible with the existing test-time\nattack-single strategies.",
    "descriptor": "\nComments: 20 pages, 28 figures, 9 tables\n",
    "authors": [
      "Vibha Belavadi",
      "Yan Zhou",
      "Murat Kantarcioglu",
      "Bhavani M. Thuraisingham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.10287"
  },
  {
    "id": "arXiv:2110.10289",
    "title": "On Coordinate Decoding for Keypoint Estimation Tasks",
    "abstract": "A series of 2D (and 3D) keypoint estimation tasks are built upon heatmap\ncoordinate representation, i.e. a probability map that allows for learnable and\nspatially aware encoding and decoding of keypoint coordinates on grids, even\nallowing for sub-pixel coordinate accuracy. In this report, we aim to reproduce\nthe findings of DARK that investigated the 2D heatmap representation by\nhighlighting the importance of the encoding of the ground truth heatmap and the\ndecoding of the predicted heatmap to keypoint coordinates. The authors claim\nthat a) a more principled distribution-aware coordinate decoding method\novercomes the limitations of the standard techniques widely used in the\nliterature, and b), that the reconstruction of heatmaps from ground-truth\ncoordinates by generating accurate and continuous heatmap distributions lead to\nunbiased model training, contrary to the standard coordinate encoding process\nthat quantizes the keypoint coordinates on the resolution of the input image\ngrid.",
    "descriptor": "",
    "authors": [
      "Anargyros Chatzitofis",
      "Nikolaos Zioulis",
      "Georgios Nikolaos Albanis",
      "Dimitrios Zarpalas",
      "Petros Daras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10289"
  },
  {
    "id": "arXiv:2110.10291",
    "title": "A Deeper Look into RowHammer`s Sensitivities: Experimental Analysis of  Real DRAM Chips and Implications on Future Attacks and Defenses",
    "abstract": "RowHammer is a circuit-level DRAM vulnerability where repeatedly accessing\n(i.e., hammering) a DRAM row can cause bit flips in physically nearby rows. The\nRowHammer vulnerability worsens as DRAM cell size and cell-to-cell spacing\nshrink. Recent studies demonstrate that modern DRAM chips, including chips\npreviously marketed as RowHammer-safe, are even more vulnerable to RowHammer\nthan older chips such that the required hammer count to cause a bit flip has\nreduced by more than 10X in the last decade. Therefore, it is essential to\ndevelop a better understanding and in-depth insights into the RowHammer\nvulnerability of modern DRAM chips to more effectively secure current and\nfuture systems.\nOur goal in this paper is to provide insights into fundamental properties of\nthe RowHammer vulnerability that are not yet rigorously studied by prior works,\nbut can potentially be $i$) exploited to develop more effective RowHammer\nattacks or $ii$) leveraged to design more effective and efficient defense\nmechanisms. To this end, we present an experimental characterization using\n248~DDR4 and 24~DDR3 modern DRAM chips from four major DRAM manufacturers\ndemonstrating how the RowHammer effects vary with three fundamental properties:\n1)~DRAM chip temperature, 2)~aggressor row active time, and 3)~victim DRAM\ncell's physical location. Among our 16 new observations, we highlight that a\nRowHammer bit flip 1)~is very likely to occur in a bounded range, specific to\neach DRAM cell (e.g., 5.4% of the vulnerable DRAM cells exhibit errors in the\nrange 70C to 90C), 2)~is more likely to occur if the aggressor row is active\nfor longer time (e.g., RowHammer vulnerability increases by 36% if we keep a\nDRAM row active for 15 column accesses), and 3)~is more likely to occur in\ncertain physical regions of the DRAM module under attack (e.g., 5% of the rows\nare 2x more vulnerable than the remaining 95% of the rows).",
    "descriptor": "\nComments: A shorter version of this work is to appear at the 54th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO-54), 2021\n",
    "authors": [
      "Lois Orosa",
      "Abdullah Giray Ya\u011fl\u0131k\u00e7\u0131",
      "Haocong Luo",
      "Ataberk Olgun",
      "Jisung Park",
      "Hasan Hassan",
      "Minesh Patel",
      "Jeremie S. Kim",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2110.10291"
  },
  {
    "id": "arXiv:2110.10293",
    "title": "Learning Rich Nearest Neighbor Representations from Self-supervised  Ensembles",
    "abstract": "Pretraining convolutional neural networks via self-supervision, and applying\nthem in transfer learning, is an incredibly fast-growing field that is rapidly\nand iteratively improving performance across practically all image domains.\nMeanwhile, model ensembling is one of the most universally applicable\ntechniques in supervised learning literature and practice, offering a simple\nsolution to reliably improve performance. But how to optimally combine\nself-supervised models to maximize representation quality has largely remained\nunaddressed. In this work, we provide a framework to perform self-supervised\nmodel ensembling via a novel method of learning representations directly\nthrough gradient descent at inference time. This technique improves\nrepresentation quality, as measured by k-nearest neighbors, both on the\nin-domain dataset and in the transfer setting, with models transferable from\nthe former setting to the latter. Additionally, this direct learning of feature\nthrough backpropagation improves representations from even a single model,\nechoing the improvements found in self-distillation.",
    "descriptor": "",
    "authors": [
      "Bram Wallace",
      "Devansh Arpit",
      "Huan Wang",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10293"
  },
  {
    "id": "arXiv:2110.10295",
    "title": "Expressivity of Neural Networks via Chaotic Itineraries beyond  Sharkovsky's Theorem",
    "abstract": "Given a target function $f$, how large must a neural network be in order to\napproximate $f$? Recent works examine this basic question on neural network\n\\textit{expressivity} from the lens of dynamical systems and provide novel\n``depth-vs-width'' tradeoffs for a large family of functions $f$. They suggest\nthat such tradeoffs are governed by the existence of \\textit{periodic} points\nor \\emph{cycles} in $f$. Our work, by further deploying dynamical systems\nconcepts, illuminates a more subtle connection between periodicity and\nexpressivity: we prove that periodic points alone lead to suboptimal\ndepth-width tradeoffs and we improve upon them by demonstrating that certain\n``chaotic itineraries'' give stronger exponential tradeoffs, even in regimes\nwhere previous analyses only imply polynomial gaps. Contrary to prior works,\nour bounds are nearly-optimal, tighten as the period increases, and handle\nstrong notions of inapproximability (e.g., constant $L_1$ error). More broadly,\nwe identify a phase transition to the \\textit{chaotic regime} that exactly\ncoincides with an abrupt shift in other notions of function complexity,\nincluding VC-dimension and topological entropy.",
    "descriptor": "\nComments: 47 pages, 19 figures\n",
    "authors": [
      "Clayton Sanford",
      "Vaggos Chatziafratis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2110.10295"
  },
  {
    "id": "arXiv:2110.10298",
    "title": "Incorporating Rich Social Interactions Into MDPs",
    "abstract": "Much of what we do as humans is engage socially with other agents, a skill\nthat robots must also eventually possess. We demonstrate that a rich theory of\nsocial interactions originating from microsociology and economics can be\nformalized by extending a nested MDP where agents reason about arbitrary\nfunctions of each other's hidden rewards. This extended Social MDP allows us to\nencode the five basic interactions that underlie microsociology: cooperation,\nconflict, coercion, competition, and exchange. The result is a robotic agent\ncapable of executing social interactions zero-shot in new environments; like\nhumans it can engage socially in novel ways even without a single example of\nthat social interaction. Moreover, the judgments of these Social MDPs align\nclosely with those of humans when considering which social interaction is\ntaking place in an environment. This method both sheds light on the nature of\nsocial interactions, by providing concrete mathematical definitions, and brings\nrich social interactions into a mathematical framework that has proven to be\nnatural for robotics, MDPs.",
    "descriptor": "\nComments: Submitted to the 39th IEEE Conference on Robotics and Automation (ICRA 2022). Do not distribute\n",
    "authors": [
      "Ravi Tejwani",
      "Yen-Ling Kuo",
      "Tianmin Shu",
      "Bennett Stankovits",
      "Dan Gutfreund",
      "Joshua B. Tenenbaum",
      "Boris Katz",
      "Andrei Barbu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.10298"
  },
  {
    "id": "arXiv:2110.10302",
    "title": "Layer-wise Adaptive Model Aggregation for Scalable Federated Learning",
    "abstract": "In Federated Learning, a common approach for aggregating local models across\nclients is periodic averaging of the full model parameters. It is, however,\nknown that different layers of neural networks can have a different degree of\nmodel discrepancy across the clients. The conventional full aggregation scheme\ndoes not consider such a difference and synchronizes the whole model parameters\nat once, resulting in inefficient network bandwidth consumption. Aggregating\nthe parameters that are similar across the clients does not make meaningful\ntraining progress while increasing the communication cost. We propose FedLAMA,\na layer-wise model aggregation scheme for scalable Federated Learning. FedLAMA\nadaptively adjusts the aggregation interval in a layer-wise manner, jointly\nconsidering the model discrepancy and the communication cost. The layer-wise\naggregation method enables to finely control the aggregation interval to relax\nthe aggregation frequency without a significant impact on the model accuracy.\nOur empirical study shows that FedLAMA reduces the communication cost by up to\n60% for IID data and 70% for non-IID data while achieving a comparable accuracy\nto FedAvg.",
    "descriptor": "",
    "authors": [
      "Sunwoo Lee",
      "Tuo Zhang",
      "Chaoyang He",
      "Salman Avestimehr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10302"
  },
  {
    "id": "arXiv:2110.10303",
    "title": "Momentum Contrastive Autoencoder: Using Contrastive Learning for Latent  Space Distribution Matching in WAE",
    "abstract": "Wasserstein autoencoder (WAE) shows that matching two distributions is\nequivalent to minimizing a simple autoencoder (AE) loss under the constraint\nthat the latent space of this AE matches a pre-specified prior distribution.\nThis latent space distribution matching is a core component of WAE, and a\nchallenging task. In this paper, we propose to use the contrastive learning\nframework that has been shown to be effective for self-supervised\nrepresentation learning, as a means to resolve this problem. We do so by\nexploiting the fact that contrastive learning objectives optimize the latent\nspace distribution to be uniform over the unit hyper-sphere, which can be\neasily sampled from. We show that using the contrastive learning framework to\noptimize the WAE loss achieves faster convergence and more stable optimization\ncompared with existing popular algorithms for WAE. This is also reflected in\nthe FID scores on CelebA and CIFAR-10 datasets, and the realistic generated\nimage quality on the CelebA-HQ dataset.",
    "descriptor": "",
    "authors": [
      "Devansh Arpit",
      "Aadyot",
      "Bhatnagar",
      "Huan Wang",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10303"
  },
  {
    "id": "arXiv:2110.10305",
    "title": "When in Doubt, Summon the Titans: Efficient Inference with Large Models",
    "abstract": "Scaling neural networks to \"large\" sizes, with billions of parameters, has\nbeen shown to yield impressive results on many challenging problems. However,\nthe inference cost incurred by such large models often prevents their\napplication in most real-world settings. In this paper, we propose a two-stage\nframework based on distillation that realizes the modelling benefits of the\nlarge models, while largely preserving the computational benefits of inference\nwith more lightweight models. In a nutshell, we use the large teacher models to\nguide the lightweight student models to only make correct predictions on a\nsubset of \"easy\" examples; for the \"hard\" examples, we fall-back to the\nteacher. Such an approach allows us to efficiently employ large models in\npractical scenarios where easy examples are much more frequent than rare hard\nexamples. Our proposed use of distillation to only handle easy instances allows\nfor a more aggressive trade-off in the student size, thereby reducing the\namortized cost of inference and achieving better accuracy than standard\ndistillation. Empirically, we demonstrate the benefits of our approach on both\nimage classification and natural language processing benchmarks.",
    "descriptor": "",
    "authors": [
      "Ankit Singh Rawat",
      "Manzil Zaheer",
      "Aditya Krishna Menon",
      "Amr Ahmed",
      "Sanjiv Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10305"
  },
  {
    "id": "arXiv:2110.10307",
    "title": "Distributed Secret Sharing over a Public Channel from Correlated Random  Variables",
    "abstract": "We consider a secret-sharing model where a dealer distributes the shares of a\nsecret among a set of participants with the constraint that only predetermined\nsubsets of participants must be able to reconstruct the secret by pooling their\nshares. Our study generalizes Shamir's secret-sharing model in three\ndirections. First, we allow a joint design of the protocols for the creation of\nthe shares and the distribution of the shares, instead of constraining the\nmodel to independent designs. Second, instead of assuming that the participants\nand the dealer have access to information-theoretically secure channels at no\ncost, we assume that they have access to a public channel and correlated\nrandomness. Third, motivated by a wireless network setting where the correlated\nrandomness is obtained from channel gain measurements, we explore a setting\nwhere the dealer is an entity made of multiple sub-dealers. Our main results\nare inner and outer regions for the achievable secret rates that the dealer and\nthe participants can obtain in this model. To this end, we develop two new\nachievability techniques, a first one to successively handle reliability and\nsecurity constraints in a distributed setting, and a second one to reduce a\nmulti-dealer setting to multiple single-user dealer settings. Our results yield\nthe capacity region for threshold access structures when the correlated\nrandomness corresponds to pairwise secret keys shared between each sub-dealer\nand each participant, and the capacity for the all-or-nothing access structure\nin the presence of a single dealer and arbitrarily correlated randomness.",
    "descriptor": "\nComments: 38 pages, 1 figure\n",
    "authors": [
      "Remi A. Chou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.10307"
  },
  {
    "id": "arXiv:2110.10309",
    "title": "Constrained Mean Shift for Representation Learning",
    "abstract": "We are interested in representation learning from labeled or unlabeled data.\nInspired by recent success of self-supervised learning (SSL), we develop a\nnon-contrastive representation learning method that can exploit additional\nknowledge. This additional knowledge may come from annotated labels in the\nsupervised setting or an SSL model from another modality in the SSL setting.\nOur main idea is to generalize the mean-shift algorithm by constraining the\nsearch space of nearest neighbors, resulting in semantically purer\nrepresentations. Our method simply pulls the embedding of an instance closer to\nits nearest neighbors in a search space that is constrained using the\nadditional knowledge. By leveraging this non-contrastive loss, we show that the\nsupervised ImageNet-1k pretraining with our method results in better transfer\nperformance as compared to the baselines. Further, we demonstrate that our\nmethod is relatively robust to label noise. Finally, we show that it is\npossible to use the noisy constraint across modalities to train self-supervised\nvideo models.",
    "descriptor": "",
    "authors": [
      "Ajinkya Tejankar",
      "Soroush Abbasi Koohpayegani",
      "Hamed Pirsiavash"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10309"
  },
  {
    "id": "arXiv:2110.10311",
    "title": "EMF-Aware Cellular Networks in RIS-Assisted Environments",
    "abstract": "The deployment of the 5th-generation cellular networks (5G) and beyond has\ntriggered health concerns due to the electric and magnetic fields (EMF)\nexposure. In this paper, we propose a novel architecture to minimize the\npopulation exposure to EMF by considering a smart radio environment with a\nreconfigurable intelligent surface (RIS). Then, we optimize the RIS phases to\nminimize the exposure in terms of the exposure index (EI) while maintaining a\nminimum target quality of service. The proposed scheme achieves up to 20%\nreduction in EI compared to schemes without RISs.",
    "descriptor": "",
    "authors": [
      "Hussam Ibraiwish",
      "Ahmed Elzanaty",
      "Yazan H. Al-Badarneh",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.10311"
  },
  {
    "id": "arXiv:2110.10316",
    "title": "Beamforming Design for Intelligent Reflecting Surface-Enhanced Symbiotic  Radio Systems",
    "abstract": "This paper investigates multiuser multi-input single-output downlink\nsymbiotic radio communication systems assisted by an intelligent reflecting\nsurface (IRS). Different from existing methods ideally assuming the secondary\nuser (SU) can jointly decode information symbols from both the access point\n(AP) and the IRS via multiuser detection, we consider a more practical SU that\nonly non-coherent detection is available. To characterize the non-coherent\ndecoding performance, a practical upper bound of the average symbol error rate\n(SER) is derived. Subsequently, we jointly optimize the beamformer at the AP\nand the phase shifts at the IRS to maximize the average sum-rate of the primary\nsystem taking into account the maximum tolerable SER constraint for the SU. To\ncircumvent the couplings of variables, we exploit the Schur complement that\nfacilitates the design of a suboptimal beamforming algorithm based on\nsuccessive convex approximation. Our simulation results show that compared with\nvarious benchmark algorithms, the proposed scheme significantly improves the\naverage sum-rate of the primary system, while guaranteeing the decoding\nperformance of the secondary system.",
    "descriptor": "\nComments: This paper is submitted to ICC 2022\n",
    "authors": [
      "Shaokang Hu",
      "Chang Liu",
      "Zhiqiang Wei",
      "Yuanxin Cai",
      "Derrick Wing Kwan Ng",
      "Jinhong Yuan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.10316"
  },
  {
    "id": "arXiv:2110.10318",
    "title": "Improved Multilingual Language Model Pretraining for Social Media Text  via Translation Pair Prediction",
    "abstract": "We evaluate a simple approach to improving zero-shot multilingual transfer of\nmBERT on social media corpus by adding a pretraining task called translation\npair prediction (TPP), which predicts whether a pair of cross-lingual texts are\na valid translation. Our approach assumes access to translations (exact or\napproximate) between source-target language pairs, where we fine-tune a model\non source language task data and evaluate the model in the target language. In\nparticular, we focus on language pairs where transfer learning is difficult for\nmBERT: those where source and target languages are different in script,\nvocabulary, and linguistic typology. We show improvements from TPP pretraining\nover mBERT alone in zero-shot transfer from English to Hindi, Arabic, and\nJapanese on two social media tasks: NER (a 37% average relative improvement in\nF1 across target languages) and sentiment classification (12% relative\nimprovement in F1) on social media text, while also benchmarking on a\nnon-social media task of Universal Dependency POS tagging (6.7% relative\nimprovement in accuracy). Our results are promising given the lack of social\nmedia bitext corpus. Our code can be found at:\nhttps://github.com/twitter-research/multilingual-alignment-tpp.",
    "descriptor": "\nComments: Camera ready version. Accepted to WNUT 2021. Code for reproducing the experiments can be found at: this https URL\n",
    "authors": [
      "Shubhanshu Mishra",
      "Aria Haghighi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10318"
  },
  {
    "id": "arXiv:2110.10319",
    "title": "LMSOC: An Approach for Socially Sensitive Pretraining",
    "abstract": "While large-scale pretrained language models have been shown to learn\neffective linguistic representations for many NLP tasks, there remain many\nreal-world contextual aspects of language that current approaches do not\ncapture. For instance, consider a cloze-test \"I enjoyed the ____ game this\nweekend\": the correct answer depends heavily on where the speaker is from, when\nthe utterance occurred, and the speaker's broader social milieu and\npreferences. Although language depends heavily on the geographical, temporal,\nand other social contexts of the speaker, these elements have not been\nincorporated into modern transformer-based language models. We propose a simple\nbut effective approach to incorporate speaker social context into the learned\nrepresentations of large-scale language models. Our method first learns dense\nrepresentations of social contexts using graph representation learning\nalgorithms and then primes language model pretraining with these social context\nrepresentations. We evaluate our approach on geographically-sensitive\nlanguage-modeling tasks and show a substantial improvement (more than 100%\nrelative lift on MRR) compared to baselines.",
    "descriptor": "\nComments: Camera ready version. Accepted to EMNLP 2021 Findings. Code for reproducing the experiments can be found at: this https URL\n",
    "authors": [
      "Vivek Kulkarni",
      "Shubhanshu Mishra",
      "Aria Haghighi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10319"
  },
  {
    "id": "arXiv:2110.10320",
    "title": "Frontiers in Evolutionary Computation: A Workshop Report",
    "abstract": "In July of 2021, the Santa Fe Institute hosted a workshop on evolutionary\ncomputation as part of its Foundations of Intelligence in Natural and\nArtificial Systems project. This project seeks to advance the field of\nartificial intelligence by promoting interdisciplinary research on the nature\nof intelligence. The workshop brought together computer scientists and\nbiologists to share their insights about the nature of evolution and the future\nof evolutionary computation. In this report, we summarize each of the talks and\nthe subsequent discussions. We also draw out a number of key themes and\nidentify important frontiers for future research.",
    "descriptor": "",
    "authors": [
      "Tyler Millhouse",
      "Melanie Moses",
      "Melanie Mitchell"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10320"
  },
  {
    "id": "arXiv:2110.10324",
    "title": "Semantic Sensing and Planning for Human-Robot Collaboration in Uncertain  Environments",
    "abstract": "Autonomous robots can benefit greatly from human-provided semantic\ncharacterizations of uncertain task environments and states. However, the\ndevelopment of integrated strategies which let robots model, communicate, and\nact on such soft data remains challenging. Here, a framework is presented for\nactive semantic sensing and planning in human-robot teams which addresses these\ngaps by formally combining the benefits of online sampling-based POMDP\npolicies, multi-modal semantic interaction, and Bayesian data fusion. This\napproach lets humans opportunistically impose model structure and extend the\nrange of semantic soft data in uncertain environments by sketching and labeling\narbitrary landmarks across the environment. Dynamic updating of the environment\nwhile searching for a mobile target allows robotic agents to actively query\nhumans for novel and relevant semantic data, thereby improving beliefs of\nunknown environments and target states for improved online planning. Target\nsearch simulations show significant improvements in time and belief state\nestimates required for interception versus conventional planning based solely\non robotic sensing. Human subject studies demonstrate a average doubling in\ndynamic target capture rate compared to the lone robot case, employing\nreasoning over a range of user characteristics and interaction modalities.\nVideo of interaction can be found at https://youtu.be/Eh-82ZJ1o4I.",
    "descriptor": "",
    "authors": [
      "Luke Burks",
      "Hunter M. Ray",
      "Jamison McGinley",
      "Sousheel Vunnam",
      "Nisar Ahmed"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.10324"
  },
  {
    "id": "arXiv:2110.10325",
    "title": "One-Step Abductive Multi-Target Learning with Diverse Noisy Samples",
    "abstract": "One-step abductive multi-target learning (OSAMTL) was proposed to handle\ncomplex noisy labels. In this paper, giving definition of diverse noisy samples\n(DNS), we propose one-step abductive multi-target learning with DNS\n(OSAMTL-DNS) to expand the original OSAMTL to a wider range of tasks that\nhandle complex noisy labels.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Yongquan Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10325"
  },
  {
    "id": "arXiv:2110.10328",
    "title": "R$^3$Net:Relation-embedded Representation Reconstruction Network for  Change Captioning",
    "abstract": "Change captioning is to use a natural language sentence to describe the\nfine-grained disagreement between two similar images. Viewpoint change is the\nmost typical distractor in this task, because it changes the scale and location\nof the objects and overwhelms the representation of real change. In this paper,\nwe propose a Relation-embedded Representation Reconstruction Network (R$^3$Net)\nto explicitly distinguish the real change from the large amount of clutter and\nirrelevant changes. Specifically, a relation-embedded module is first devised\nto explore potential changed objects in the large amount of clutter. Then,\nbased on the semantic similarities of corresponding locations in the two\nimages, a representation reconstruction module (RRM) is designed to learn the\nreconstruction representation and further model the difference representation.\nBesides, we introduce a syntactic skeleton predictor (SSP) to enhance the\nsemantic interaction between change localization and caption generation.\nExtensive experiments show that the proposed method achieves the\nstate-of-the-art results on two public datasets.",
    "descriptor": "\nComments: Accepted by EMNLP 2021\n",
    "authors": [
      "Yunbin Tu",
      "Liang Li",
      "Chenggang Yan",
      "Shengxiang Gao",
      "Zhengtao Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10328"
  },
  {
    "id": "arXiv:2110.10329",
    "title": "SLAM: A Unified Encoder for Speech and Language Modeling via Speech-Text  Joint Pre-Training",
    "abstract": "Unsupervised pre-training is now the predominant approach for both text and\nspeech understanding. Self-attention models pre-trained on large amounts of\nunannotated data have been hugely successful when fine-tuned on downstream\ntasks from a variety of domains and languages. This paper takes the\nuniversality of unsupervised language pre-training one step further, by\nunifying speech and text pre-training within a single model. We build a single\nencoder with the BERT objective on unlabeled text together with the w2v-BERT\nobjective on unlabeled speech. To further align our model representations\nacross modalities, we leverage alignment losses, specifically Translation\nLanguage Modeling (TLM) and Speech Text Matching (STM) that make use of\nsupervised speech-text recognition data. We demonstrate that incorporating both\nspeech and text data during pre-training can significantly improve downstream\nquality on CoVoST~2 speech translation, by around 1 BLEU compared to\nsingle-modality pre-trained models, while retaining close to SotA performance\non LibriSpeech and SpeechStew ASR tasks. On four GLUE tasks and\ntext-normalization, we observe evidence of capacity limitations and\ninterference between the two modalities, leading to degraded performance\ncompared to an equivalent text-only model, while still being competitive with\nBERT. Through extensive empirical analysis we also demonstrate the importance\nof the choice of objective function for speech pre-training, and the beneficial\neffect of adding additional supervised signals on the quality of the learned\nrepresentations.",
    "descriptor": "",
    "authors": [
      "Ankur Bapna",
      "Yu-an Chung",
      "Nan Wu",
      "Anmol Gulati",
      "Ye Jia",
      "Jonathan H. Clark",
      "Melvin Johnson",
      "Jason Riesa",
      "Alexis Conneau",
      "Yu Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10329"
  },
  {
    "id": "arXiv:2110.10333",
    "title": "Computationally Efficient Safe Reinforcement Learning for Power Systems",
    "abstract": "We propose a computationally efficient approach to safe reinforcement\nlearning (RL) for frequency regulation in power systems with high levels of\nvariable renewable energy resources. The approach draws on set-theoretic\ncontrol techniques to craft a neural network-based control policy that is\nguaranteed to satisfy safety-critical state constraints, without needing to\nsolve a model predictive control or projection problem in real time. By\nexploiting the properties of robust controlled-invariant polytopes, we\nconstruct a novel, closed-form \"safety-filter\" that enables end-to-end safe\nlearning using any policy gradient-based RL algorithm. We then apply the safety\nfilter in conjunction with the deep deterministic policy gradient (DDPG)\nalgorithm to regulate frequency in a modified 9-bus power system, and show that\nthe learned policy is more cost-effective than robust linear feedback control\ntechniques while maintaining the same safety guarantee. We also show that the\nproposed paradigm outperforms DDPG augmented with constraint violation\npenalties.",
    "descriptor": "\nComments: Submitted to the 2022 American Control Conference. 8 pages, 7 figures\n",
    "authors": [
      "Daniel Tabas",
      "Baosen Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.10333"
  },
  {
    "id": "arXiv:2110.10334",
    "title": "Toward Accurate and Reliable Iris Segmentation Using Uncertainty  Learning",
    "abstract": "As an upstream task of iris recognition, iris segmentation plays a vital role\nin multiple subsequent tasks, including localization and matching. A slight\nbias in iris segmentation often results in obvious performance degradation of\nthe iris recognition system. In the paper, we propose an Iris U-transformer\n(IrisUsformer) for accurate and reliable iris segmentation. For better\naccuracy, we elaborately design IrisUsformer by adopting position-sensitive\noperation and re-packaging transformer block to raise the spatial perception\nability of the model. For better reliability, IrisUsformer utilizes an\nauxiliary head to distinguishes the high- and low-uncertainty regions of\nsegmentation predictions and then adopts a weighting scheme to guide model\noptimization. Experimental results on three publicly available databases\ndemonstrate that IrisUsformer achieves better segmentation accuracy using 35%\nMACs of the SOTA IrisParseNet. More importantly, our method estimates the\nuncertainty map corresponding to the segmentation prediction for subsequent\nprocessing in iris recognition systems.",
    "descriptor": "",
    "authors": [
      "Jianze Wei",
      "Huaibo Huang",
      "Muyi Sun",
      "Ran He",
      "Zhenan Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10334"
  },
  {
    "id": "arXiv:2110.10335",
    "title": "Simpler Does It: Generating Semantic Labels with Objectness Guidance",
    "abstract": "Existing weakly or semi-supervised semantic segmentation methods utilize\nimage or box-level supervision to generate pseudo-labels for weakly labeled\nimages. However, due to the lack of strong supervision, the generated\npseudo-labels are often noisy near the object boundaries, which severely\nimpacts the network's ability to learn strong representations. To address this\nproblem, we present a novel framework that generates pseudo-labels for training\nimages, which are then used to train a segmentation model. To generate\npseudo-labels, we combine information from: (i) a class agnostic objectness\nnetwork that learns to recognize object-like regions, and (ii) either\nimage-level or bounding box annotations. We show the efficacy of our approach\nby demonstrating how the objectness network can naturally be leveraged to\ngenerate object-like regions for unseen categories. We then propose an\nend-to-end multi-task learning strategy, that jointly learns to segment\nsemantics and objectness using the generated pseudo-labels. Extensive\nexperiments demonstrate the high quality of our generated pseudo-labels and\neffectiveness of the proposed framework in a variety of domains. Our approach\nachieves better or competitive performance compared to existing\nweakly-supervised and semi-supervised methods.",
    "descriptor": "\nComments: BMVC 2021\n",
    "authors": [
      "Md Amirul Islam",
      "Matthew Kowal",
      "Sen Jia",
      "Konstantinos G. Derpanis",
      "Neil D. B. Bruce"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10335"
  },
  {
    "id": "arXiv:2110.10340",
    "title": "News-based Business Sentiment and its Properties as an Economic Index",
    "abstract": "This paper presents an approach to measuring business sentiment based on\ntextual data. Business sentiment has been measured by traditional surveys,\nwhich are costly and time-consuming to conduct. To address the issues, we take\nadvantage of daily newspaper articles and adopt a self-attention-based model to\ndefine a business sentiment index, named S-APIR, where outlier detection models\nare investigated to properly handle various genres of news articles. Moreover,\nwe propose a simple approach to temporally analyzing how much any given event\ncontributed to the predicted business sentiment index. To demonstrate the\nvalidity of the proposed approach, an extensive analysis is carried out on 12\nyears' worth of newspaper articles. The analysis shows that the S-APIR index is\nstrongly and positively correlated with established survey-based index (up to\ncorrelation coefficient r=0.937) and that the outlier detection is effective\nespecially for a general newspaper. Also, S-APIR is compared with a variety of\neconomic indices, revealing the properties of S-APIR that it reflects the trend\nof the macroeconomy as well as the economic outlook and sentiment of economic\nagents. Moreover, to illustrate how S-APIR could benefit economists and\npolicymakers, several events are analyzed with respect to their impacts on\nbusiness sentiment over time.",
    "descriptor": "\nComments: 40 pages, to be published in Information Processing and Management\n",
    "authors": [
      "Kazuhiro Seki",
      "Yusuke Ikuta",
      "Yoichi Matsubayashi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.10340"
  },
  {
    "id": "arXiv:2110.10341",
    "title": "Quadrotor Trajectory Tracking with Learned Dynamics: Joint Koopman-based  Learning of System Models and Function Dictionaries",
    "abstract": "Nonlinear dynamical effects are crucial to the operation of many agile\nrobotic systems. Koopman-based model learning methods can capture these\nnonlinear dynamical system effects in higher dimensional lifted bilinear models\nthat are amenable to optimal control. However, standard methods that lift the\nsystem state using a fixed function dictionary before model learning result in\nhigh dimensional models that are intractable for real time control. This paper\npresents a novel method that jointly learns a function dictionary and lifted\nbilinear model purely from data by incorporating the Koopman model in a neural\nnetwork architecture. Nonlinear MPC design utilizing the learned model can be\nperformed readily. We experimentally realized this method on a multirotor drone\nfor agile trajectory tracking at low altitudes where the aerodynamic ground\neffect influences the system's behavior. Experimental results demonstrate that\nthe learning-based controller achieves similar performance as a nonlinear MPC\nbased on a nominal dynamics model in medium altitude. However, our\nlearning-based system can reliably track trajectories in near-ground flight\nregimes while the nominal controller crashes due to unmodeled dynamical effects\nthat are captured by our method.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2105.08036\n",
    "authors": [
      "Carl Folkestad",
      "Skylar X. Wei",
      "Joel W. Burdick"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.10341"
  },
  {
    "id": "arXiv:2110.10342",
    "title": "Minibatch vs Local SGD with Shuffling: Tight Convergence Bounds and  Beyond",
    "abstract": "In distributed learning, local SGD (also known as federated averaging) and\nits simple baseline minibatch SGD are widely studied optimization methods. Most\nexisting analyses of these methods assume independent and unbiased gradient\nestimates obtained via with-replacement sampling. In contrast, we study\nshuffling-based variants: minibatch and local Random Reshuffling, which draw\nstochastic gradients without replacement and are thus closer to practice. For\nsmooth functions satisfying the Polyak-{\\L}ojasiewicz condition, we obtain\nconvergence bounds (in the large epoch regime) which show that these\nshuffling-based variants converge faster than their with-replacement\ncounterparts. Moreover, we prove matching lower bounds showing that our\nconvergence analysis is tight. Finally, we propose an algorithmic modification\ncalled synchronized shuffling that leads to convergence rates faster than our\nlower bounds in near-homogeneous settings.",
    "descriptor": "\nComments: 72 pages\n",
    "authors": [
      "Chulhee Yun",
      "Shashank Rajput",
      "Suvrit Sra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.10342"
  },
  {
    "id": "arXiv:2110.10343",
    "title": "EBJR: Energy-Based Joint Reasoning for Adaptive Inference",
    "abstract": "State-of-the-art deep learning models have achieved significant performance\nlevels on various benchmarks. However, the excellent performance comes at a\ncost of inefficient computational cost. Light-weight architectures, on the\nother hand, achieve moderate accuracies, but at a much more desirable latency.\nThis paper presents a new method of jointly using the large accurate models\ntogether with the small fast ones. To this end, we propose an Energy-Based\nJoint Reasoning (EBJR) framework that adaptively distributes the samples\nbetween shallow and deep models to achieve an accuracy close to the deep model,\nbut latency close to the shallow one. Our method is applicable to\nout-of-the-box pre-trained models as it does not require an architecture change\nnor re-training. Moreover, it is easy to use and deploy, especially for cloud\nservices. Through a comprehensive set of experiments on different down-stream\ntasks, we show that our method outperforms strong state-of-the-art approaches\nwith a considerable margin. In addition, we propose specialized EBJR, an\nextension of our method where we create a smaller specialized side model that\nperforms the target task only partially, but yields an even higher accuracy and\nfaster inference. We verify the strengths of our methods with both theoretical\nand experimental evaluations.",
    "descriptor": "\nComments: BMVC 2021\n",
    "authors": [
      "Mohammad Akbari",
      "Amin Banitalebi-Dehkordi",
      "Yong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10343"
  },
  {
    "id": "arXiv:2110.10347",
    "title": "Multi-Stage Network Embedding for Exploring Heterogeneous Edges",
    "abstract": "The relationships between objects in a network are typically diverse and\ncomplex, leading to the heterogeneous edges with different semantic\ninformation. In this paper, we focus on exploring the heterogeneous edges for\nnetwork representation learning. By considering each relationship as a view\nthat depicts a specific type of proximity between nodes, we propose a\nmulti-stage non-negative matrix factorization (MNMF) model, committed to\nutilizing abundant information in multiple views to learn robust network\nrepresentations. In fact, most existing network embedding methods are closely\nrelated to implicitly factorizing the complex proximity matrix. However, the\napproximation error is usually quite large, since a single low-rank matrix is\ninsufficient to capture the original information. Through a multi-stage matrix\nfactorization process motivated by gradient boosting, our MNMF model achieves\nlower approximation error. Meanwhile, the multi-stage structure of MNMF gives\nthe feasibility of designing two kinds of non-negative matrix factorization\n(NMF) manners to preserve network information better. The united NMF aims to\npreserve the consensus information between different views, and the independent\nNMF aims to preserve unique information of each view. Concrete experimental\nresults on realistic datasets indicate that our model outperforms three types\nof baselines in practical applications.",
    "descriptor": "\nComments: ACM Transactions on Knowledge Discovery from Data\n",
    "authors": [
      "Hong Huang",
      "Yu Song",
      "Fanghua Ye",
      "Xing Xie",
      "Xuanhua Shi",
      "Hai Jin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.10347"
  },
  {
    "id": "arXiv:2110.10348",
    "title": "GTM: Gray Temporal Model for Video Recognition",
    "abstract": "Data input modality plays an important role in video action recognition.\nNormally, there are three types of input: RGB, flow stream and compressed data.\nIn this paper, we proposed a new input modality: gray stream. Specifically,\ntaken the stacked consecutive 3 gray images as input, which is the same size of\nRGB, can not only skip the conversion process from video decoding data to RGB,\nbut also improve the spatio-temporal modeling ability at zero computation and\nzero parameters. Meanwhile, we proposed a 1D Identity Channel-wise\nSpatio-temporal Convolution(1D-ICSC) which captures the temporal relationship\nat channel-feature level within a controllable computation budget(by parameters\nG & R). Finally, we confirm its effectiveness and efficiency on several action\nrecognition benchmarks, such as Kinetics, Something-Something, HMDB-51 and\nUCF-101, and achieve impressive results.",
    "descriptor": "",
    "authors": [
      "Yanping Zhang",
      "Yongxin Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10348"
  },
  {
    "id": "arXiv:2110.10349",
    "title": "Distributed Reinforcement Learning for Privacy-Preserving Dynamic Edge  Caching",
    "abstract": "Mobile edge computing (MEC) is a prominent computing paradigm which expands\nthe application fields of wireless communication. Due to the limitation of the\ncapacities of user equipments and MEC servers, edge caching (EC) optimization\nis crucial to the effective utilization of the caching resources in MEC-enabled\nwireless networks. However, the dynamics and complexities of content\npopularities over space and time as well as the privacy preservation of users\npose significant challenges to EC optimization. In this paper, a\nprivacy-preserving distributed deep deterministic policy gradient (P2D3PG)\nalgorithm is proposed to maximize the cache hit rates of devices in the MEC\nnetworks. Specifically, we consider the fact that content popularities are\ndynamic, complicated and unobservable, and formulate the maximization of cache\nhit rates on devices as distributed problems under the constraints of privacy\npreservation. In particular, we convert the distributed optimizations into\ndistributed model-free Markov decision process problems and then introduce a\nprivacy-preserving federated learning method for popularity prediction.\nSubsequently, a P2D3PG algorithm is developed based on distributed\nreinforcement learning to solve the distributed problems. Simulation results\ndemonstrate the superiority of the proposed approach in improving EC hit rate\nover the baseline methods while preserving user privacy.",
    "descriptor": "\nComments: 12 pages, 6 figures, under review with the IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS\n",
    "authors": [
      "Shengheng Liu",
      "Chong Zheng",
      "Yongming Huang",
      "Tony Q. S. Quek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.10349"
  },
  {
    "id": "arXiv:2110.10353",
    "title": "Contextual Gradient Scaling for Few-Shot Learning",
    "abstract": "Model-agnostic meta-learning (MAML) is a well-known optimization-based\nmeta-learning algorithm that works well in various computer vision tasks, e.g.,\nfew-shot classification. MAML is to learn an initialization so that a model can\nadapt to a new task in a few steps. However, since the gradient norm of a\nclassifier (head) is much bigger than those of backbone layers, the model\nfocuses on learning the decision boundary of the classifier with similar\nrepresentations. Furthermore, gradient norms of high-level layers are small\nthan those of the other layers. So, the backbone of MAML usually learns\ntask-generic features, which results in deteriorated adaptation performance in\nthe inner-loop. To resolve or mitigate this problem, we propose contextual\ngradient scaling (CxGrad), which scales gradient norms of the backbone to\nfacilitate learning task-specific knowledge in the inner-loop. Since the\nscaling factors are generated from task-conditioned parameters, gradient norms\nof the backbone can be scaled in a task-wise fashion. Experimental results show\nthat CxGrad effectively encourages the backbone to learn task-specific\nknowledge in the inner-loop and improves the performance of MAML up to a\nsignificant margin in both same- and cross-domain few-shot classification.",
    "descriptor": "\nComments: Accepted to WACV2022\n",
    "authors": [
      "Sanghyuk Lee",
      "Seunghyun Lee",
      "Byung Cheol Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10353"
  },
  {
    "id": "arXiv:2110.10354",
    "title": "Detecting Backdoor Attacks Against Point Cloud Classifiers",
    "abstract": "Backdoor attacks (BA) are an emerging threat to deep neural network\nclassifiers. A classifier being attacked will predict to the attacker's target\nclass when a test sample from a source class is embedded with the backdoor\npattern (BP). Recently, the first BA against point cloud (PC) classifiers was\nproposed, creating new threats to many important applications including\nautonomous driving. Such PC BAs are not detectable by existing BA defenses due\nto their special BP embedding mechanism. In this paper, we propose a\nreverse-engineering defense that infers whether a PC classifier is backdoor\nattacked, without access to its training set or to any clean classifiers for\nreference. The effectiveness of our defense is demonstrated on the benchmark\nModeNet40 dataset for PCs.",
    "descriptor": "",
    "authors": [
      "Zhen Xiang",
      "David J. Miller",
      "Siheng Chen",
      "Xi Li",
      "George Kesidis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10354"
  },
  {
    "id": "arXiv:2110.10355",
    "title": "Dynamic Multi-Person Mesh Recovery From Uncalibrated Multi-View Cameras",
    "abstract": "Dynamic multi-person mesh recovery has been a hot topic in 3D vision\nrecently. However, few works focus on the multi-person motion capture from\nuncalibrated cameras, which mainly faces two challenges: the one is that\ninter-person interactions and occlusions introduce inherent ambiguities for\nboth camera calibration and motion capture; The other is that a lack of dense\ncorrespondences can be used to constrain sparse camera geometries in a dynamic\nmulti-person scene. Our key idea is incorporating motion prior knowledge into\nsimultaneous optimization of extrinsic camera parameters and human meshes from\nnoisy human semantics. First, we introduce a physics-geometry consistency to\nreduce the low and high frequency noises of the detected human semantics. Then\na novel latent motion prior is proposed to simultaneously optimize extrinsic\ncamera parameters and coherent human motions from slightly noisy inputs.\nExperimental results show that accurate camera parameters and human motions can\nbe obtained through one-stage optimization. The codes will be publicly\navailable at~\\url{https://www.yangangwang.com}.",
    "descriptor": "\nComments: 3DV 2021\n",
    "authors": [
      "Buzhen Huang",
      "Yuan Shu",
      "Tianshu Zhang",
      "Yangang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10355"
  },
  {
    "id": "arXiv:2110.10357",
    "title": "Fast Bitmap Fit: A CPU Cache Line friendly memory allocator for single  object allocations",
    "abstract": "Applications making excessive use of single-object based data structures\n(such as linked lists, trees, etc...) can see a drop in efficiency over a\nperiod of time due to the randomization of nodes in memory. This slow down is\ndue to the ineffective use of the CPU's L1/L2 cache. We present a novel\napproach for mitigating this by presenting the design of a single-object memory\nallocator that preserves memory locality across randomly ordered memory\nallocations and deallocations.",
    "descriptor": "",
    "authors": [
      "Dhruv Matani",
      "Gaurav Menghani"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Operating Systems (cs.OS)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2110.10357"
  },
  {
    "id": "arXiv:2110.10358",
    "title": "Hierarchical Aspect-guided Explanation Generation for Explainable  Recommendation",
    "abstract": "Explainable recommendation systems provide explanations for recommendation\nresults to improve their transparency and persuasiveness. The existing\nexplainable recommendation methods generate textual explanations without\nexplicitly considering the user's preferences on different aspects of the item.\nIn this paper, we propose a novel explanation generation framework, named\nHierarchical Aspect-guided explanation Generation (HAG), for explainable\nrecommendation. Specifically, HAG employs a review-based syntax graph to\nprovide a unified view of the user/item details. An aspect-guided graph pooling\noperator is proposed to extract the aspect-relevant information from the\nreview-based syntax graphs to model the user's preferences on an item at the\naspect level. Then, a hierarchical explanation decoder is developed to generate\naspects and aspect-relevant explanations based on the attention mechanism. The\nexperimental results on three real datasets indicate that HAG outperforms\nstate-of-the-art explanation generation methods in both single-aspect and\nmulti-aspect explanation generation tasks, and also achieves comparable or even\nbetter preference prediction accuracy than strong baseline methods.",
    "descriptor": "",
    "authors": [
      "Yidan Hu",
      "Yong Liu",
      "Chunyan Miao",
      "Gongqi Lin",
      "Yuan Miao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.10358"
  },
  {
    "id": "arXiv:2110.10360",
    "title": "Real-time Identification and Simultaneous Avoidance of Static and  Dynamic Obstacles on Point Cloud for UAVs Navigation",
    "abstract": "Avoiding hybrid obstacles in unknown scenarios with an efficient flight\nstrategy is a key challenge for unmanned aerial vehicle applications. In this\npaper, we introduce a more robust technique to distinguish and track dynamic\nobstacles from static ones with only point cloud input. Then, to achieve\ndynamic avoidance, we propose the forbidden pyramids method to solve the\ndesired vehicle velocity with an efficient sampling-based method in iteration.\nThe motion primitives are generated by solving a nonlinear optimization problem\nwith the constraint of desired velocity and the waypoint. Furthermore, we\npresent several techniques to deal with the position estimation error for close\nobjects, the error for deformable objects, and the time gap between different\nsubmodules. The proposed approach is implemented to run onboard in real-time\nand validated extensively in simulation and hardware tests, demonstrating our\nsuperiority in tracking robustness, energy cost, and calculating time.",
    "descriptor": "\nComments: 12 pages. arXiv admin note: text overlap with arXiv:2105.06622\n",
    "authors": [
      "Han Chen",
      "Peng Lu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.10360"
  },
  {
    "id": "arXiv:2110.10364",
    "title": "NOD: Taking a Closer Look at Detection under Extreme Low-Light  Conditions with Night Object Detection Dataset",
    "abstract": "Recent work indicates that, besides being a challenge in producing\nperceptually pleasing images, low light proves more difficult for machine\ncognition than previously thought. In our work, we take a closer look at object\ndetection in low light. First, to support the development and evaluation of new\nmethods in this domain, we present a high-quality large-scale Night Object\nDetection (NOD) dataset showing dynamic scenes captured on the streets at\nnight. Next, we directly link the lighting conditions to perceptual difficulty\nand identify what makes low light problematic for machine cognition.\nAccordingly, we provide instance-level annotation for a subset of the dataset\nfor an in-depth evaluation of future methods. We also present an analysis of\nthe baseline model performance to highlight opportunities for future research\nand show that low light is a non-trivial problem that requires special\nattention from the researchers. Further, to address the issues caused by low\nlight, we propose to incorporate an image enhancement module into the object\ndetection framework and two novel data augmentation techniques. Our image\nenhancement module is trained under the guidance of the object detector to\nlearn image representation optimal for machine cognition rather than for the\nhuman visual system. Finally, experimental results confirm that the proposed\nmethod shows consistent improvement of the performance on low-light datasets.",
    "descriptor": "\nComments: 13 pages, 6 figures, to be published in BMVC 2021\n",
    "authors": [
      "Igor Morawski",
      "Yu-An Chen",
      "Yu-Sheng Lin",
      "Winston H. Hsu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10364"
  },
  {
    "id": "arXiv:2110.10366",
    "title": "Repaint: Improving the Generalization of Down-Stream Visual Tasks by  Generating Multiple Instances of Training Examples",
    "abstract": "Convolutional Neural Networks (CNNs) for visual tasks are believed to learn\nboth the low-level textures and high-level object attributes, throughout the\nnetwork depth. This paper further investigates the `texture bias' in CNNs. To\nthis end, we regenerate multiple instances of training examples from each\noriginal image, through a process we call `repainting'. The repainted examples\npreserve the shape and structure of the regions and objects within the scenes,\nbut diversify their texture and color. Our method can regenerate a same image\nat different daylight, season, or weather conditions, can have colorization or\nde-colorization effects, or even bring back some texture information from\nblacked-out areas. The in-place repaint allows us to further use these\nrepainted examples for improving the generalization of CNNs. Through an\nextensive set of experiments, we demonstrate the usefulness of the repainted\nexamples in training, for the tasks of image classification (ImageNet) and\nobject detection (COCO), over several state-of-the-art network architectures at\ndifferent capacities, and across different data availability regimes.",
    "descriptor": "\nComments: BMVC 2021\n",
    "authors": [
      "Amin Banitalebi-Dehkordi",
      "Yong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10366"
  },
  {
    "id": "arXiv:2110.10367",
    "title": "Constructions and Applications of Perfect Difference Matrices and  Perfect Difference Families",
    "abstract": "Perfect difference families (PDFs for short) are important both in\ntheoretical and in applications. Perfect difference matrices (PDMs for short)\nand the equivalent structure had been extensively studied and used to construct\nperfect difference families, radar array and related codes. The necessary\ncondition for the existence of a PDM$(n,m)$ is $m\\equiv 1\\pmod2$ and $m\\geq\nn+1$. So far, PDM$(3,m)$s exist for odd $5\\leq m\\leq 201$ with two definite\nexceptions of $m=9,11$. In this paper, new recursive constructions on\nPDM$(3,m)$s are investigated, and it is proved that there exist PDM$(3,m)$s for\nany odd $5\\leq m<1000$ with two definite exceptions of $m=9,11$ and $33$\npossible exceptions. A complete result of $(g,\\{3,4\\},1)$-PDFs with the ratio\nof block size $4$ no less than $\\frac{1}{14}$ is obtained. As an application, a\ncomplete class of perfect strict optical orthogonal codes with weights $3$ and\n$4$ is obtained.",
    "descriptor": "",
    "authors": [
      "Xianwei Sun",
      "Huangsheng Yu",
      "Dianhua Wu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.10367"
  },
  {
    "id": "arXiv:2110.10368",
    "title": "ABC: Auxiliary Balanced Classifier for Class-imbalanced Semi-supervised  Learning",
    "abstract": "Existing semi-supervised learning (SSL) algorithms typically assume\nclass-balanced datasets, although the class distributions of many real-world\ndatasets are imbalanced. In general, classifiers trained on a class-imbalanced\ndataset are biased toward the majority classes. This issue becomes more\nproblematic for SSL algorithms because they utilize the biased prediction of\nunlabeled data for training. However, traditional class-imbalanced learning\ntechniques, which are designed for labeled data, cannot be readily combined\nwith SSL algorithms. We propose a scalable class-imbalanced SSL algorithm that\ncan effectively use unlabeled data, while mitigating class imbalance by\nintroducing an auxiliary balanced classifier (ABC) of a single layer, which is\nattached to a representation layer of an existing SSL algorithm. The ABC is\ntrained with a class-balanced loss of a minibatch, while using high-quality\nrepresentations learned from all data points in the minibatch using the\nbackbone SSL algorithm to avoid overfitting and information loss.Moreover, we\nuse consistency regularization, a recent SSL technique for utilizing unlabeled\ndata in a modified way, to train the ABC to be balanced among the classes by\nselecting unlabeled data with the same probability for each class. The proposed\nalgorithm achieves state-of-the-art performance in various class-imbalanced SSL\nexperiments using four benchmark datasets.",
    "descriptor": "",
    "authors": [
      "Hyuck Lee",
      "Seungjae Shin",
      "Heeyoung Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10368"
  },
  {
    "id": "arXiv:2110.10369",
    "title": "Model Composition: Can Multiple Neural Networks Be Combined into a  Single Network Using Only Unlabeled Data?",
    "abstract": "The diversity of deep learning applications, datasets, and neural network\narchitectures necessitates a careful selection of the architecture and data\nthat match best to a target application. As an attempt to mitigate this\ndilemma, this paper investigates the idea of combining multiple trained neural\nnetworks using unlabeled data. In addition, combining multiple models into one\ncan speed up the inference, result in stronger, more capable models, and allows\nus to select efficient device-friendly target network architectures. To this\nend, the proposed method makes use of generation, filtering, and aggregation of\nreliable pseudo-labels collected from unlabeled data. Our method supports using\nan arbitrary number of input models with arbitrary architectures and\ncategories. Extensive performance evaluations demonstrated that our method is\nvery effective. For example, for the task of object detection and without using\nany ground-truth labels, an EfficientDet-D0 trained on Pascal-VOC and an\nEfficientDet-D1 trained on COCO, can be combined to a RetinaNet-ResNet50 model,\nwith a similar mAP as the supervised training. If fine-tuned in a\nsemi-supervised setting, the combined model achieves +18.6%, +12.6%, and +8.1%\nmAP improvements over supervised training with 1%, 5%, and 10% of labels.",
    "descriptor": "\nComments: BMVC 2021\n",
    "authors": [
      "Amin Banitalebi-Dehkordi",
      "Xinyu Kang",
      "Yong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10369"
  },
  {
    "id": "arXiv:2110.10372",
    "title": "Distributionally Robust Classifiers in Sentiment Analysis",
    "abstract": "In this paper, we propose sentiment classification models based on BERT\nintegrated with DRO (Distributionally Robust Classifiers) to improve model\nperformance on datasets with distributional shifts. We added 2-Layer Bi-LSTM,\nprojection layer (onto simplex or Lp ball), and linear layer on top of BERT to\nachieve distributionally robustness. We considered one form of distributional\nshift (from IMDb dataset to Rotten Tomatoes dataset). We have confirmed through\nexperiments that our DRO model does improve performance on our test set with\ndistributional shift from the training set.",
    "descriptor": "",
    "authors": [
      "Shilun Li",
      "Renee Li",
      "Carina Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10372"
  },
  {
    "id": "arXiv:2110.10374",
    "title": "Playing 2048 With Reinforcement Learning",
    "abstract": "The game of 2048 is a highly addictive game. It is easy to learn the game,\nbut hard to master as the created game revealed that only about 1% games out of\nhundreds million ever played have been won. In this paper, we would like to\nexplore reinforcement learning techniques to win 2048. The approaches we have\ntook include deep Q-learning and beam search, with beam search reaching 2048\n28.5 of time.",
    "descriptor": "",
    "authors": [
      "Shilun Li",
      "Veronica Peng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10374"
  },
  {
    "id": "arXiv:2110.10376",
    "title": "A Fast Planning Approach for 3D Short Trajectory with a Parallel  Framework",
    "abstract": "For real applications of unmanned aerial vehicles, the capability of\nnavigating with full autonomy in unknown environments is a crucial requirement.\nHowever, planning a shorter path with less computing time is contradictory. To\naddress this problem, we present a framework with the map planner and point\ncloud planner running in parallel in this paper. The map planner determines the\ninitial path using the improved jump point search method on the 2D map, and\nthen it tries to optimize the path by considering a possible shorter 3D path.\nThe point cloud planner is executed at a high frequency to generate the motion\nprimitives. It makes the drone follow the solved path and avoid the suddenly\nappearing obstacles nearby. Thus, vehicles can achieve a short trajectory while\nreacting quickly to the intruding obstacles. We demonstrate fully autonomous\nquadrotor flight tests in unknown and complex environments with static and\ndynamic obstacles to validate the proposed method. In simulation and hardware\nexperiments, the proposed framework shows satisfactorily comprehensive\nperformance.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Han Chen",
      "Shengyang Chen",
      "Peng Lu",
      "Chih-Yung Wen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.10376"
  },
  {
    "id": "arXiv:2110.10379",
    "title": "Cascaded Compressed Sensing Networks: A Reversible Architecture for  Layerwise Learning",
    "abstract": "Recently, the method that learns networks layer by layer has attracted\nincreasing interest for its ease of analysis. For the method, the main\nchallenge lies in deriving an optimization target for each layer by inversely\npropagating the global target of the network. The propagation problem is ill\nposed, due to involving the inversion of nonlinear activations from\nlowdimensional to high-dimensional spaces. To address the problem, the existing\nsolution is to learn an auxiliary network to specially propagate the target.\nHowever, the network lacks stability, and moreover, it results in higher\ncomplexity for network learning. In the letter, we show that target propagation\ncould be achieved by modeling the network s each layer with compressed sensing,\nwithout the need of auxiliary networks. Experiments show that the proposed\nmethod could achieve better performance than the auxiliary network-based\nmethod.",
    "descriptor": "",
    "authors": [
      "Weizhi Lu",
      "Mingrui Chen",
      "Kai Guo",
      "Weiyu Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10379"
  },
  {
    "id": "arXiv:2110.10380",
    "title": "Learning to Remember Patterns: Pattern Matching Memory Networks for  Traffic Forecasting",
    "abstract": "Traffic forecasting is a challenging problem due to complex road networks and\nsudden speed changes caused by various events on roads. A number of models have\nbeen proposed to solve this challenging problem with a focus on learning\nspatio-temporal dependencies of roads. In this work, we propose a new\nperspective of converting the forecasting problem into a pattern matching task,\nassuming that large data can be represented by a set of patterns. To evaluate\nthe validness of the new perspective, we design a novel traffic forecasting\nmodel, called Pattern-Matching Memory Networks (PM-MemNet), which learns to\nmatch input data to the representative patterns with a key-value memory\nstructure. We first extract and cluster representative traffic patterns, which\nserve as keys in the memory. Then via matching the extracted keys and inputs,\nPM-MemNet acquires necessary information of existing traffic patterns from the\nmemory and uses it for forecasting. To model spatio-temporal correlation of\ntraffic, we proposed novel memory architecture GCMem, which integrates\nattention and graph convolution for memory enhancement. The experiment results\nindicate that PM-MemNet is more accurate than state-of-the-art models, such as\nGraph WaveNet with higher responsiveness. We also present a qualitative\nanalysis result, describing how PM-MemNet works and achieves its higher\naccuracy when road speed rapidly changes.",
    "descriptor": "\nComments: 12 pages, Submitted as conference paper to ICLR 2022\n",
    "authors": [
      "Hyunwook Lee",
      "Seungmin Jin",
      "Hyeshin Chu",
      "Hongkyu Lim",
      "Sungahn Ko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.10380"
  },
  {
    "id": "arXiv:2110.10389",
    "title": "Does Data Repair Lead to Fair Models? Curating Contextually Fair Data To  Reduce Model Bias",
    "abstract": "Contextual information is a valuable cue for Deep Neural Networks (DNNs) to\nlearn better representations and improve accuracy. However, co-occurrence bias\nin the training dataset may hamper a DNN model's generalizability to unseen\nscenarios in the real world. For example, in COCO, many object categories have\na much higher co-occurrence with men compared to women, which can bias a DNN's\nprediction in favor of men. Recent works have focused on task-specific training\nstrategies to handle bias in such scenarios, but fixing the available data is\noften ignored. In this paper, we propose a novel and more generic solution to\naddress the contextual bias in the datasets by selecting a subset of the\nsamples, which is fair in terms of the co-occurrence with various classes for a\nprotected attribute. We introduce a data repair algorithm using the coefficient\nof variation, which can curate fair and contextually balanced data for a\nprotected class(es). This helps in training a fair model irrespective of the\ntask, architecture or training methodology. Our proposed solution is simple,\neffective, and can even be used in an active learning setting where the data\nlabels are not present or being generated incrementally. We demonstrate the\neffectiveness of our algorithm for the task of object detection and multi-label\nimage classification across different datasets. Through a series of\nexperiments, we validate that curating contextually fair data helps make model\npredictions fair by balancing the true positive rate for the protected class\nacross groups without compromising on the model's overall performance.",
    "descriptor": "\nComments: A variant of this report is accepted in WACV 2022\n",
    "authors": [
      "Sharat Agarwal",
      "Sumanyu Muku",
      "Saket Anand",
      "Chetan Arora"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10389"
  },
  {
    "id": "arXiv:2110.10391",
    "title": "Robust lEarned Shrinkage-Thresholding (REST): Robust unrolling for  sparse recover",
    "abstract": "In this paper, we consider deep neural networks for solving inverse problems\nthat are robust to forward model mis-specifications. Specifically, we treat\nsensing problems with model mismatch where one wishes to recover a sparse\nhigh-dimensional vector from low-dimensional observations subject to\nuncertainty in the measurement operator. We then design a new robust deep\nneural network architecture by applying algorithm unfolding techniques to a\nrobust version of the underlying recovery problem. Our proposed network - named\nRobust lEarned Shrinkage-Thresholding (REST) - exhibits an additional\nnormalization processing compared to Learned Iterative Shrinkage-Thresholding\nAlgorithm (LISTA), leading to reliable recovery of the signal under sample-wise\nvarying model mismatch. The proposed REST network is shown to outperform\nstate-of-the-art model-based and data-driven algorithms in both compressive\nsensing and radar imaging problems wherein model mismatch is taken into\nconsideration.",
    "descriptor": "",
    "authors": [
      "Wei Pu",
      "Chao Zhou",
      "Yonina C. Eldar",
      "Miguel R.D. Rodrigues"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.10391"
  },
  {
    "id": "arXiv:2110.10395",
    "title": "3DFaceFill: An Analysis-By-Synthesis Approach to Face Completion",
    "abstract": "Existing face completion solutions are primarily driven by end-to-end models\nthat directly generate 2D completions of 2D masked faces. By having to\nimplicitly account for geometric and photometric variations in facial shape and\nappearance, such approaches result in unrealistic completions, especially under\nlarge variations in pose, shape, illumination and mask sizes. To alleviate\nthese limitations, we introduce 3DFaceFill, an analysis-by-synthesis approach\nfor face completion that explicitly considers the image formation process. It\ncomprises three components, (1) an encoder that disentangles the face into its\nconstituent 3D mesh, 3D pose, illumination and albedo factors, (2) an\nautoencoder that inpaints the UV representation of facial albedo, and (3) a\nrenderer that resynthesizes the completed face. By operating on the UV\nrepresentation, 3DFaceFill affords the power of correspondence and allows us to\nnaturally enforce geometrical priors (e.g. facial symmetry) more effectively.\nQuantitatively, 3DFaceFill improves the state-of-the-art by up to 4dB higher\nPSNR and 25% better LPIPS for large masks. And, qualitatively, it leads to\ndemonstrably more photorealistic face completions over a range of masks and\nocclusions while preserving consistency in global and component-wise shape,\npose, illumination and eye-gaze.",
    "descriptor": "\nComments: Winter Conference on Applications of Computer Vision, WACV 2022\n",
    "authors": [
      "Rahul Dey",
      "Vishnu Boddeti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10395"
  },
  {
    "id": "arXiv:2110.10396",
    "title": "UPPRESSO: Untraceable and Unlinkable Privacy-PREserving Single Sign-On  Services",
    "abstract": "Single sign-on (SSO) allows a user to maintain only the credential at the\nidentity provider (IdP), instead of one credential for each relying party (RP),\nto login to numerous RPs. However, SSO introduces extra privacy leakage\nthreats, as (a) the IdP could track all the RPs which a user is visiting, and\n(b) collusive RPs could learn a user's online profile by linking his identities\nacross these RPs. Several privacy-preserving SSO solutions have been proposed\nto defend against either the curious IdP or collusive RPs, but none of them\naddresses both of these privacy leakage threats at the same time. In this\npaper, we propose a privacy-preserving SSO system, called UPPRESSO, to protect\na user's login traces against both the curious IdP and collusive RPs\nsimultaneously. We analyze the identity dilemma between the SSO security\nrequirements and these privacy concerns, and convert the SSO privacy problems\ninto an identity-transformation challenge. To the best of our knowledge, this\nis the first practical SSO solution which solves the privacy problems caused by\nboth the curious IdP and collusive RPs. We build the UPPRESSO prototype system\nfor web applications, with standard functions of OpenID Connect, while the\nfunction of Core Sign-On is slightly modified to calculate the transformed\nidentities. The prototype system is implemented on top of open-source MITREid\nConnect, and the extensive evaluation shows that UPPRESSO introduces reasonable\noverheads and fulfills the requirements of both security and privacy.",
    "descriptor": "",
    "authors": [
      "Chengqian Guo",
      "Jingqiang Lin",
      "Quanwei Cai",
      "Fengjun Li",
      "Qiongxiao Wang",
      "Jiwu Jing",
      "Bin Zhao",
      "Wei Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.10396"
  },
  {
    "id": "arXiv:2110.10401",
    "title": "Monitoring Collective Communication Among GPUs",
    "abstract": "Communication among devices in multi-GPU systems plays an important role in\nterms of performance and scalability. In order to optimize an application,\nprogrammers need to know the type and amount of the communication happening\namong GPUs. Although there are prior works to gather this information in MPI\napplications on distributed systems and multi-threaded applications on shared\nmemory systems, there is no tool that identifies communication among GPUs. Our\nprior work, ComScribe, presents a point-to-point (P2P) communication detection\ntool for GPUs sharing a common host. In this work, we extend ComScribe to\nidentify communication among GPUs for collective and P2P communication\nprimitives in NVIDIA's NCCL library. In addition to P2P communications,\ncollective communications are commonly used in HPC and AI workloads thus it is\nimportant to monitor the induced data movement due to collectives. Our tool\nextracts the size and the frequency of data transfers in an application and\nvisualizes them as a communication matrix. To demonstrate the tool in action,\nwe present communication matrices and some statistics for two applications\ncoming from machine translation and image classification domains.",
    "descriptor": "\nComments: 12 pages, 3 figures, 3 tables\n",
    "authors": [
      "Muhammet Abdullah Soyturk",
      "Palwisha Akhtar",
      "Erhan Tezcan",
      "Didem Unat"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2110.10401"
  },
  {
    "id": "arXiv:2110.10402",
    "title": "An Investigation of Enhancing CTC Model for Triggered Attention-based  Streaming ASR",
    "abstract": "In the present paper, an attempt is made to combine Mask-CTC and the\ntriggered attention mechanism to construct a streaming end-to-end automatic\nspeech recognition (ASR) system that provides high performance with low\nlatency. The triggered attention mechanism, which performs autoregressive\ndecoding triggered by the CTC spike, has shown to be effective in streaming\nASR. However, in order to maintain high accuracy of alignment estimation based\non CTC outputs, which is the key to its performance, it is inevitable that\ndecoding should be performed with some future information input (i.e., with\nhigher latency). It should be noted that in streaming ASR, it is desirable to\nbe able to achieve high recognition accuracy while keeping the latency low.\nTherefore, the present study aims to achieve highly accurate streaming ASR with\nlow latency by introducing Mask-CTC, which is capable of learning feature\nrepresentations that anticipate future information (i.e., that can consider\nlong-term contexts), to the encoder pre-training. Experimental comparisons\nconducted using WSJ data demonstrate that the proposed method achieves higher\naccuracy with lower latency than the conventional triggered attention-based\nstreaming ASR system.",
    "descriptor": "\nComments: Accepted to APSIPA 2021\n",
    "authors": [
      "Huaibo Zhao",
      "Yosuke Higuchi",
      "Tetsuji Ogawa",
      "Tetsunori Kobayashi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.10402"
  },
  {
    "id": "arXiv:2110.10404",
    "title": "JavaBERT: Training a transformer-based model for the Java programming  language",
    "abstract": "Code quality is and will be a crucial factor while developing new software\ncode, requiring appropriate tools to ensure functional and reliable code.\nMachine learning techniques are still rarely used for software engineering\ntools, missing out the potential benefits of its application. Natural language\nprocessing has shown the potential to process text data regarding a variety of\ntasks. We argue, that such models can also show similar benefits for software\ncode processing. In this paper, we investigate how models used for natural\nlanguage processing can be trained upon software code. We introduce a data\nretrieval pipeline for software code and train a model upon Java software code.\nThe resulting model, JavaBERT, shows a high accuracy on the masked language\nmodeling task showing its potential for software engineering tools.",
    "descriptor": "\nComments: 6 pages, to appear in the Proceedings of the 9th International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering (RAISE'2021)\n",
    "authors": [
      "Nelson Tavares de Sousa",
      "Wilhelm Hasselbring"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10404"
  },
  {
    "id": "arXiv:2110.10405",
    "title": "ARTS: Eliminating Inconsistency between Text Detection and Recognition  with Auto-Rectification Text Spotter",
    "abstract": "Recent approaches for end-to-end text spotting have achieved promising\nresults. However, most of the current spotters were plagued by the\ninconsistency problem between text detection and recognition. In this work, we\nintroduce and prove the existence of the inconsistency problem and analyze it\nfrom two aspects: (1) inconsistency of text recognition features between\ntraining and testing, and (2) inconsistency of optimization targets between\ntext detection and recognition. To solve the aforementioned issues, we propose\na differentiable Auto-Rectification Module (ARM) together with a new training\nstrategy to enable propagating recognition loss back into detection branch, so\nthat our detection branch can be jointly optimized by detection and recognition\ntargets, which largely alleviates the inconsistency problem between text\ndetection and recognition. Based on these designs, we present a simple yet\nrobust end-to-end text spotting framework, termed Auto-Rectification Text\nSpotter (ARTS), to detect and recognize arbitrarily-shaped text in natural\nscenes. Extensive experiments demonstrate the superiority of our method. In\nparticular, our ARTS-S achieves 77.1% end-to-end text spotting F-measure on\nTotal-Text at a competitive speed of 10.5 FPS, which significantly outperforms\nprevious methods in both accuracy and inference speed.",
    "descriptor": "",
    "authors": [
      "Humen Zhong",
      "Jun Tang",
      "Wenhai Wang",
      "Zhibo Yang",
      "Cong Yao",
      "Tong Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10405"
  },
  {
    "id": "arXiv:2110.10407",
    "title": "Development of an Ontology for an Integrated Image Analysis Platform to  enable Global Sharing of Microscopy Imaging Data",
    "abstract": "Imaging data is one of the most important fundamentals in the current life\nsciences. We aimed to construct an ontology to describe imaging metadata as a\ndata schema of the integrated database for optical and electron microscopy\nimages combined with various bio-entities. To realise this, we applied Resource\nDescription Framework (RDF) to an Open Microscopy Environment (OME) data model,\nwhich is the de facto standard to describe optical microscopy images and\nexperimental data. We translated the XML-based OME metadata into the base\nconcept of RDF schema as a trial of developing microscopy ontology. In this\nontology, we propose 18 upper-level concepts including missing concepts in OME\nsuch as electron microscopy, phenotype data, biosample, and imaging conditions.",
    "descriptor": "",
    "authors": [
      "Satoshi Kume",
      "Hiroshi Masuya",
      "Yosky Kataoka",
      "Norio Kobayashi"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Image and Video Processing (eess.IV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2110.10407"
  },
  {
    "id": "arXiv:2110.10412",
    "title": "A Row-Wise Update Algorithm for Sparse Stochastic Matrix Factorization",
    "abstract": "Nonnegative matrix factorization arises widely in machine learning and data\nanalysis. In this paper, for a given factorization of rank r, we consider the\nsparse stochastic matrix factorization (SSMF) of decomposing a prescribed\nm-by-n stochastic matrix V into a product of an m-by-r stochastic matrix W and\na sparse r-by-n stochastic matrix H. With the prescribed sparsity level, we\nreformulate the SSMF as an unconstrained nonvonvex-nonsmooth minimization\nproblem and introduce a row-wise update algorithm for solving the minimization\nproblem. We show that the proposed algorithm converges globally and the\ngenerated sequence converges to a special critical point of the cost function,\nwhich is a global minimizer over the W-factor as a whole and is nearly a global\nminimizer over each row vector of the H-factor. Numerical experiments on both\nsynthetic and real data sets are given to demonstrate the effectiveness of our\nproposed algorithm.",
    "descriptor": "\nComments: 27 pages,6 figures\n",
    "authors": [
      "Guiyun Xiao",
      "Zheng-Jian Bai",
      "Wai-Ki Ching"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.10412"
  },
  {
    "id": "arXiv:2110.10413",
    "title": "Newtonian Mechanics Based Transient Stability PART I: Machine Paradigms",
    "abstract": "Individual-machine, superimposed-machine and equivalent-machine can be seen\nas the three major perspectives of the power system transient stability. In\nthis paper, the machine paradigms are established according to the common\nthinking among the three different machines. The machine paradigms comprise of\nthe three components, i.e., trajectory paradigm, modeling paradigm and energy\nparadigm. The trajectory paradigm is the reflection of the trajectory\nstability; the modeling paradigm is the two-machine-system modeling of the\ntrajectory stability; and the energy paradigm is the stability evaluation of\nthe two-machine system. Based on this, it is clarified that the machine\nparadigms can be expressed into the individual machine form or the equivalent\nmachine form. Then, the relationship between the machine stability and the\nsystem stability are analyzed. Simulation results show that the effectiveness\nof both the individual-machine and the equivalent machine is fully based on the\nstrict followings of the machine paradigms.",
    "descriptor": "\nComments: This paper contains 15 pages and 25 figures\n",
    "authors": [
      "Songyan Wang",
      "Jilai Yu",
      "Aoife Foley",
      "Jingrui Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.10413"
  },
  {
    "id": "arXiv:2110.10415",
    "title": "Depth360: Monocular Depth Estimation using Learnable Axisymmetric Camera  Model for Spherical Camera Image",
    "abstract": "Self-supervised monocular depth estimation has been widely investigated to\nestimate depth images and relative poses from RGB images. This framework is\nattractive for researchers because the depth and pose networks can be trained\nfrom just time sequence images without the need for the ground truth depth and\nposes.\nIn this work, we estimate the depth around a robot (360 degree view) using\ntime sequence spherical camera images, from a camera whose parameters are\nunknown. We propose a learnable axisymmetric camera model which accepts\ndistorted spherical camera images with two fisheye camera images. In addition,\nwe trained our models with a photo-realistic simulator to generate ground truth\ndepth images to provide supervision. Moreover, we introduced loss functions to\nprovide floor constraints to reduce artifacts that can result from reflective\nfloor surfaces. We demonstrate the efficacy of our method using the spherical\ncamera images from the GO Stanford dataset and pinhole camera images from the\nKITTI dataset to compare our method's performance with that of baseline method\nin learning the camera parameters.",
    "descriptor": "\nComments: 8 pages, 6 figures, 2 tables\n",
    "authors": [
      "Noriaki Hirose",
      "Kosuke Tahara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.10415"
  },
  {
    "id": "arXiv:2110.10417",
    "title": "FoV Privacy-aware VR Streaming",
    "abstract": "Proactive tile-based virtual reality (VR) video streaming can use the trace\nof FoV and eye movement to predict future requested tiles, then renders and\ndelivers the predicted tiles before playback. The quality of experience (QoE)\ndepends on the combined effect of tile prediction and consumed resources.\nRecently, it has been found that with the FoV and eye movement data collected\nfor a user, one can infer the identity and preference of the user. Existing\nworks investigate the privacy protection for eye movement, but never address\nhow to protect the privacy in terms of FoV and how the privacy protection\naffects the QoE. In this paper, we strive to characterize and satisfy the FoV\nprivacy requirement. We consider \"trading resources for privacy\". We first add\ncamouflaged tile requests around the real FoV and define spatial degree of\nprivacy (SDoP) as a normalized number of camouflaged tile requests. By\nconsuming more resources to ensure SDoP, the real FoVs can be hidden. Then, we\nproceed to analyze the impacts of SDoP on the QoE by jointly optimizing the\ndurations for prediction, computing, and transmission that maximizes the QoE\ngiven arbitrary predictor, configured resources, and SDoP. We find that a\nlarger SDoP requires more resources but degrades the performance of tile\nprediction. Simulation with state-of-the-art predictors on a real dataset\nverifies the analysis and shows that a user requiring a larger SDoP can be\nserved with better QoE.",
    "descriptor": "\nComments: 6 pages, 4 figures, 2 tables. arXiv admin note: substantial text overlap with arXiv:2104.14170, arXiv:2104.09779\n",
    "authors": [
      "Xing Wei",
      "Chenyang Yang"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.10417"
  },
  {
    "id": "arXiv:2110.10418",
    "title": "Steganography of Complex Networks",
    "abstract": "Steganography is one of the information hiding techniques, which conceals\nsecret messages in cover media. Digital image and audio are the most studied\ncover media for steganography. However, so far, there is no research on\nsteganography to utilize complex networks as cover media. To investigate the\npossibility and feasibility of complex networks as cover media for\nsteganography, we introduce steganography of complex networks through three\nalgorithms: BIND, BYMOND, and BYNIS. BIND hides two bits of a secret message in\nan edge, while BYMOND encodes a byte in an edge, without changing the original\nnetwork structures. Encoding simulation experiments for the networks of Open\nGraph Benchmark demonstrated BIND and BYMOND can successfully hide random\nmessages in the edge lists. BYNIS synthesizes edges by generating node\nidentifiers from a given message. The degree distribution of stego network\nsynthesized by BYNIS was mostly close to a power-law. Steganography of complex\nnetworks is expected to have applications such as watermarking to protect\nproprietary datasets, or sensitive information hiding for privacy preservation.",
    "descriptor": "\nComments: 16 pages, 6 figures, 3 tables\n",
    "authors": [
      "Daewon Lee"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.10418"
  },
  {
    "id": "arXiv:2110.10422",
    "title": "Encoding spatiotemporal priors with VAEs for small-area estimation",
    "abstract": "Gaussian processes (GPs), implemented through multivariate Gaussian\ndistributions for a finite collection of data, are the most popular approach in\nsmall-area spatiotemporal statistical modelling. In this context they are used\nto encode correlation structures over space and time and can generalise well in\ninterpolation tasks. Despite their flexibility, off-the-shelf GPs present\nserious computational challenges which limit their scalability and practical\nusefulness in applied settings. Here, we propose a novel, deep generative\nmodelling approach to tackle this challenge: for a particular spatiotemporal\nsetting, we approximate a class of GP priors through prior sampling and\nsubsequent fitting of a variational autoencoder (VAE). Given a trained VAE, the\nresultant decoder allows spatiotemporal inference to become incredibly\nefficient due to the low dimensional, independently distributed latent Gaussian\nspace representation of the VAE. Once trained, inference using the VAE decoder\nreplaces the GP within a Bayesian sampling framework. This approach provides\ntractable and easy-to-implement means of approximately encoding spatiotemporal\npriors and facilitates efficient statistical inference. We demonstrate the\nutility of our VAE two stage approach on Bayesian, small-area estimation tasks.",
    "descriptor": "",
    "authors": [
      "Elizaveta Semenova",
      "Yidan Xu",
      "Adam Howes",
      "Theo Rashid",
      "Samir Bhatt",
      "Swapnil Mishra",
      "Seth Flaxman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.10422"
  },
  {
    "id": "arXiv:2110.10423",
    "title": "ProxyBO: Accelerating Neural Architecture Search via Bayesian  Optimization with Zero-cost Proxies",
    "abstract": "Designing neural architectures requires immense manual efforts. This has\npromoted the development of neural architecture search (NAS) to automate this\ndesign. While previous NAS methods achieve promising results but run slowly and\nzero-cost proxies run extremely fast but are less promising, recent work\nconsiders utilizing zero-cost proxies via a simple warm-up. The existing method\nhas two limitations, which are unforeseeable reliability and one-shot usage. To\naddress the limitations, we present ProxyBO, an efficient Bayesian optimization\nframework that utilizes the zero-cost proxies to accelerate neural architecture\nsearch. We propose the generalization ability measurement to estimate the\nfitness of proxies on the task during each iteration and then combine BO with\nzero-cost proxies via dynamic influence combination. Extensive empirical\nstudies show that ProxyBO consistently outperforms competitive baselines on\nfive tasks from three public benchmarks. Concretely, ProxyBO achieves up to\n5.41x and 3.83x speedups over the state-of-the-art approach REA and BRP-NAS,\nrespectively.",
    "descriptor": "",
    "authors": [
      "Yu Shen",
      "Yang Li",
      "Jian Zheng",
      "Wentao Zhang",
      "Peng Yao",
      "Jixiang Li",
      "Sen Yang",
      "Ji Liu",
      "Cui Bin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10423"
  },
  {
    "id": "arXiv:2110.10425",
    "title": "A generalised phase field model for fatigue crack growth in  elastic-plastic solids with an efficient monolithic solver",
    "abstract": "We present a generalised phase field-based formulation for predicting fatigue\ncrack growth in metals. The theoretical framework aims at covering a wide range\nof material behaviour. Different fatigue degradation functions are considered\nand their influence is benchmarked against experiments. The phase field\nconstitutive theory accommodates the so-called AT1, AT2 and phase\nfield-cohesive zone (PF-CZM) models. In regards to material deformation, both\nnon-linear kinematic and isotropic hardening are considered, as well as the\ncombination of the two. Moreover, a monolithic solution scheme based on\nquasi-Newton algorithms is presented and shown to significantly outperform\nstaggered approaches. The potential of the computational framework is\ndemonstrated by investigating several 2D and 3D boundary value problems of\nparticular interest. Constitutive and numerical choices are compared and\ninsight is gained into their differences and similarities. The framework\nenables predicting fatigue crack growth in arbitrary geometries and for\nmaterials exhibiting complex (cyclic) deformation and damage responses. The\nfinite element code developed is made freely available at\nwww.empaneda.com/codes.",
    "descriptor": "",
    "authors": [
      "Z. Khalil",
      "A.Y. Elghazouli",
      "E. Mart\u00ednez-Pa\u00f1eda"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2110.10425"
  },
  {
    "id": "arXiv:2110.10428",
    "title": "Reconstruction of Fragmented Trajectories of Collective Motion using  Hadamard Deep Autoencoders",
    "abstract": "Learning dynamics of collectively moving agents such as fish or humans is an\nactive field in research. Due to natural phenomena such as occlusion and change\nof illumination, the multi-object methods tracking such dynamics might lose\ntrack of the agents where that might result fragmentation in the constructed\ntrajectories. Here, we present an extended deep autoencoder (DA) that we train\nonly on fully observed segments of the trajectories by defining its loss\nfunction as the Hadamard product of a binary indicator matrix with the absolute\ndifference between the outputs and the labels. The trajectories of the agents\npracticing collective motion is low-rank due to mutual interactions and\ndependencies between the agents that we utilize as the underlying pattern that\nour Hadamard deep autoencoder (HDA) codes during its training. The performance\nof our HDA is compared with that of a low-rank matrix completion scheme in the\ncontext of fragmented trajectory reconstruction.",
    "descriptor": "\nComments: 21 Pages, 5 figures, submitted into Pattern Recognition\n",
    "authors": [
      "Kelum Gajamannage",
      "Yonggi Park",
      "Randy Paffenroth",
      "Anura P. Jayasumana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.10428"
  },
  {
    "id": "arXiv:2110.10429",
    "title": "Knowledge distillation from language model to acoustic model: a  hierarchical multi-task learning approach",
    "abstract": "The remarkable performance of the pre-trained language model (LM) using\nself-supervised learning has led to a major paradigm shift in the study of\nnatural language processing. In line with these changes, leveraging the\nperformance of speech recognition systems with massive deep learning-based LMs\nis a major topic of speech recognition research. Among the various methods of\napplying LMs to speech recognition systems, in this paper, we focus on a\ncross-modal knowledge distillation method that transfers knowledge between two\ntypes of deep neural networks with different modalities. We propose an acoustic\nmodel structure with multiple auxiliary output layers for cross-modal\ndistillation and demonstrate that the proposed method effectively compensates\nfor the shortcomings of the existing label-interpolation-based distillation\nmethod. In addition, we extend the proposed method to a hierarchical\ndistillation method using LMs trained in different units (senones, monophones,\nand subwords) and reveal the effectiveness of the hierarchical distillation\nmethod through an ablation study.",
    "descriptor": "\nComments: 4page + 1page for citation + 2 pages for appendix\n",
    "authors": [
      "Mun-Hak Lee",
      "Joon-Hyuk Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.10429"
  },
  {
    "id": "arXiv:2110.10431",
    "title": "Discontinuous Grammar as a Foreign Language",
    "abstract": "In order to achieve deep natural language understanding, syntactic\nconstituent parsing is a vital step, highly demanded by many artificial\nintelligence systems to process both text and speech. One of the most recent\nproposals is the use of standard sequence-to-sequence models to perform\nconstituent parsing as a machine translation task, instead of applying\ntask-specific parsers. While they show a competitive performance, these\ntext-to-parse transducers are still lagging behind classic techniques in terms\nof accuracy, coverage and speed. To close the gap, we here extend the framework\nof sequence-to-sequence models for constituent parsing, not only by providing a\nmore powerful neural architecture for improving their performance, but also by\nenlarging their coverage to handle the most complex syntactic phenomena:\ndiscontinuous structures. To that end, we design several novel linearizations\nthat can fully produce discontinuities and, for the first time, we test a\nsequence-to-sequence model on the main discontinuous benchmarks, obtaining\ncompetitive results on par with task-specific discontinuous constituent parsers\nand achieving state-of-the-art scores on the (discontinuous) English Penn\nTreebank.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Daniel Fern\u00e1ndez-Gonz\u00e1lez",
      "Carlos G\u00f3mez-Rodr\u00edguez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.10431"
  },
  {
    "id": "arXiv:2110.10433",
    "title": "New Result on Interception of Stationary Targets at Arbitrary  Time-Varying Velocity",
    "abstract": "In this paper, some new results on time-varying missile against a stationary\ntarget using pure proportional navigation (PPN) are developed in the planar\ninterception problem. First, the relative motion equation is established in\narc-length domain based on the differential geometry theory, which eliminates\nthe influence of time-varying missile speed. Then, the closed-form solution of\ntime-varying speed missile intercepting stationary target with PPN is deduced,\nand the interception performance is analyzed. Additionally, considering the\nmissile maneuvering acceleration limit, the capture region of time-varying\nspeed missile is analyzed. Finally, the results derived in this paper are\nverified by numerical simulation analysis for various scenarios.",
    "descriptor": "",
    "authors": [
      "Liu Yuanhe",
      "Li Kebo",
      "Liang Yangang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.10433"
  },
  {
    "id": "arXiv:2110.10436",
    "title": "A Survey on Deep-Learning Approaches for Vehicle Trajectory Prediction  in Autonomous Driving",
    "abstract": "With the rapid development of machine learning, autonomous driving has become\na hot issue, making urgent demands for more intelligent perception and planning\nsystems. Self-driving cars can avoid traffic crashes with precisely predicted\nfuture trajectories of surrounding vehicles. In this work, we review and\ncategorize existing learning-based trajectory forecasting methods from\nperspectives of representation, modeling, and learning. Moreover, we make our\nimplementation of Target-driveN Trajectory Prediction publicly available at\nhttps://github.com/Henry1iu/TNT-Trajectory-Predition, demonstrating its\noutstanding performance whereas its original codes are withheld. Enlightenment\nis expected for researchers seeking to improve trajectory prediction\nperformance based on the achievement we have made.",
    "descriptor": "\nComments: Accepted by ROBIO2021\n",
    "authors": [
      "Jianbang Liu",
      "Xinyu Mao",
      "Yuqi Fang",
      "Delong Zhu",
      "Max Q.-H. Meng"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.10436"
  },
  {
    "id": "arXiv:2110.10437",
    "title": "A unifying framework for $n$-dimensional quasi-conformal mappings",
    "abstract": "With the advancement of computer technology, there is a surge of interest in\neffective mapping methods for objects in higher-dimensional spaces. To\nestablish a one-to-one correspondence between objects, higher-dimensional\nquasi-conformal theory can be utilized for ensuring the bijectivity of the\nmappings. In addition, it is often desirable for the mappings to satisfy\ncertain prescribed geometric constraints and possess low distortion in\nconformality or volume. In this work, we develop a unifying framework for\ncomputing $n$-dimensional quasi-conformal mappings. More specifically, we\npropose a variational model that integrates quasi-conformal distortion,\nvolumetric distortion, landmark correspondence, intensity mismatch and volume\nprior information to handle a large variety of deformation problems. We further\nprove the existence of a minimizer for the proposed model and devise efficient\nnumerical methods to solve the optimization problem. We demonstrate the\neffectiveness of the proposed framework using various experiments in two- and\nthree-dimensions, with applications to medical image registration, adaptive\nremeshing and shape modeling.",
    "descriptor": "",
    "authors": [
      "Daoping Zhang",
      "Gary P. T. Choi",
      "Jianping Zhang",
      "Lok Ming Lui"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Differential Geometry (math.DG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.10437"
  },
  {
    "id": "arXiv:2110.10444",
    "title": "Moir\u00e9 Attack (MA): A New Potential Risk of Screen Photos",
    "abstract": "Images, captured by a camera, play a critical role in training Deep Neural\nNetworks (DNNs). Usually, we assume the images acquired by cameras are\nconsistent with the ones perceived by human eyes. However, due to the different\nphysical mechanisms between human-vision and computer-vision systems, the final\nperceived images could be very different in some cases, for example shooting on\ndigital monitors. In this paper, we find a special phenomenon in digital image\nprocessing, the moir\\'e effect, that could cause unnoticed security threats to\nDNNs. Based on it, we propose a Moir\\'e Attack (MA) that generates the\nphysical-world moir\\'e pattern adding to the images by mimicking the shooting\nprocess of digital devices. Extensive experiments demonstrate that our proposed\ndigital Moir\\'e Attack (MA) is a perfect camouflage for attackers to tamper\nwith DNNs with a high success rate ($100.0\\%$ for untargeted and $97.0\\%$ for\ntargeted attack with the noise budget $\\epsilon=4$), high transferability rate\nacross different models, and high robustness under various defenses.\nFurthermore, MA owns great stealthiness because the moir\\'e effect is\nunavoidable due to the camera's inner physical structure, which therefore\nhardly attracts the awareness of humans. Our code is available at\nhttps://github.com/Dantong88/Moire_Attack.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Dantong Niu",
      "Ruohao Guo",
      "Yisen Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.10444"
  },
  {
    "id": "arXiv:2110.10446",
    "title": "Interactive simulation for easy decision-making in fluid dynamics",
    "abstract": "A conventional study of fluid simulation involves different stages including\nconception, simulation, visualization, and analysis tasks. It is, therefore,\nnecessary to switch between different software and interactive contexts which\nimplies costly data manipulation and increases the time needed for decision\nmaking. Our interactive simulation approach was designed to shorten this loop,\nallowing users to visualize and steer a simulation in progress without waiting\nfor the end of the simulation. The methodology allows the users to control,\nstart, pause, or stop a simulation in progress, to change global physical\nparameters, to interact with its 3D environment by editing boundary conditions\nsuch as walls or obstacles. This approach is made possible by using a\nmethodology such as the Lattice Boltzmann Method (LBM) to achieve interactive\ntime while remaining physically relevant. In this work, we present our platform\ndedicated to interactive fluid simulation based on LBM. The contribution of our\ninteractive simulation approach to decision making will be evaluated in a study\nbased on a simple but realistic use case.",
    "descriptor": "",
    "authors": [
      "Mengchen Wang",
      "Nicolas F\u00e9rey",
      "Fr\u00e9d\u00e9ric Magoul\u00e8s",
      "Patrick Bourdot"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2110.10446"
  },
  {
    "id": "arXiv:2110.10447",
    "title": "Easy and structured approach for software and firmware co-simulation for  bus centric designs",
    "abstract": "Although software and firmware co-simulation is gaining popularity, it is\nstill not widely used in the FPGA designs. This work presents easy and\nstructured approach for software and firmware co-simulation for bus centric\ndesigns. The proposed approach is very modular and software language agnostic.\nThe only requirement is that the firmware design is accessible via some kind of\nsystem bus. The concept has been used for testing DAQ system being developed\nfor high energy physics experiment.",
    "descriptor": "",
    "authors": [
      "Micha\u0142 Kruszewski"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/2110.10447"
  },
  {
    "id": "arXiv:2110.10450",
    "title": "KabOOM: Unsupervised Crash Categorization through Timeseries  Fingerprinting",
    "abstract": "Modern mobile applications include instrumentation that sample internal\napplication metrics at regular intervals. Following a crash, sample metrics are\ncollected and can potentially be valuable for root-causing difficult to\ndiagnose crashes. However, the fine-grained nature and overwhelming wealth of\navailable application metrics, coupled with frequent application updates,\nrenders their use for root-causing crashes extremely difficult.\nWe propose KabOOM, a method to automatically cluster telemetry reports in\nintuitive, distinct crash categories. Uniquely, KabOOM relies on multivariate\ntimeseries fingerprinting; an auto-encoder coupled with a cluster centroid\noptimization technique learns embeddings of each crash report, which are then\nused to cluster metric timeseries based crash reports. We demonstrate the\neffectiveness of KabOOM on both reducing the dimensionality of the incoming\ncrash reports and producing crash categories that are intuitive to developers.",
    "descriptor": "\nComments: Submitted to ICSE-SEIP 2022\n",
    "authors": [
      "Edward Yao",
      "Wes Dyer",
      "Georgios Gousios"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.10450"
  },
  {
    "id": "arXiv:2110.10452",
    "title": "Different Applications and Technologies of Internet of Things (IoT)",
    "abstract": "Internet of things (IoT) has significantly altered the traditional lifestyle\nto a highly technologically advanced society. Some of the significant\ntransformations that have been achieved through IoT are smart homes, smart\ntransportation, smart city, and control of pollution. A considerable number of\nstudies have been conducted and continue to be done to increase the use of\ntechnology through IoT. Furthermore, the research about IoT has not been done\nfully in improving the application of technology through IoT. Besides, IoT\nexperiences several problems that need to be considered in order to get the\nfull capability of IoT in changing society. This research paper addresses the\nkey applications of IoT, the architecture of IoT, and the key issues affecting\nIoT. In addition, the paper highlights how big data analytics is essential in\nimproving the effectiveness of IoT in various applications within society.",
    "descriptor": "\nComments: Paper is submitted to ICICT 2022 Conference for its acceptance\n",
    "authors": [
      "Feisal Masmali",
      "Shah J. Miah"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.10452"
  },
  {
    "id": "arXiv:2110.10456",
    "title": "Noisy Annotation Refinement for Object Detection",
    "abstract": "Supervised training of object detectors requires well-annotated large-scale\ndatasets, whose production is costly. Therefore, some efforts have been made to\nobtain annotations in economical ways, such as cloud sourcing. However,\ndatasets obtained by these methods tend to contain noisy annotations such as\ninaccurate bounding boxes and incorrect class labels. In this study, we propose\na new problem setting of training object detectors on datasets with entangled\nnoises of annotations of class labels and bounding boxes. Our proposed method\nefficiently decouples the entangled noises, corrects the noisy annotations, and\nsubsequently trains the detector using the corrected annotations. We verified\nthe effectiveness of our proposed method and compared it with the baseline on\nnoisy datasets with different noise levels. The experimental results show that\nour proposed method significantly outperforms the baseline.",
    "descriptor": "",
    "authors": [
      "Jiafeng Mao",
      "Qing Yu",
      "Yoko Yamakata",
      "Kiyoharu Aizawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10456"
  },
  {
    "id": "arXiv:2110.10457",
    "title": "Knowledge Graph informed Fake News Classification via Heterogeneous  Representation Ensembles",
    "abstract": "Increasing amounts of freely available data both in textual and relational\nform offers exploration of richer document representations, potentially\nimproving the model performance and robustness. An emerging problem in the\nmodern era is fake news detection -- many easily available pieces of\ninformation are not necessarily factually correct, and can lead to wrong\nconclusions or are used for manipulation. In this work we explore how different\ndocument representations, ranging from simple symbolic bag-of-words, to\ncontextual, neural language model-based ones can be used for efficient fake\nnews identification. One of the key contributions is a set of novel document\nrepresentation learning methods based solely on knowledge graphs, i.e.\nextensive collections of (grounded) subject-predicate-object triplets. We\ndemonstrate that knowledge graph-based representations already achieve\ncompetitive performance to conventionally accepted representation learners.\nFurthermore, when combined with existing, contextual representations, knowledge\ngraph-based document representations can achieve state-of-the-art performance.\nTo our knowledge this is the first larger-scale evaluation of how knowledge\ngraph-based representations can be systematically incorporated into the process\nof fake news classification.",
    "descriptor": "",
    "authors": [
      "Boshko Koloski",
      "Timen Stepi\u0161nik-Perdih",
      "Marko Robnik-\u0160ikonja",
      "Senja Pollak",
      "Bla\u017e \u0160krlj"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.10457"
  },
  {
    "id": "arXiv:2110.10460",
    "title": "Zeros of quasi-paraorthogonal polynomials and positive quadrature",
    "abstract": "In this paper we illustrate that paraorthogonality on the unit circle\n$\\mathbb{T}$ is the counterpart to orthogonality on $\\mathbb{R}$ when we are\ninterested in the spectral properties. We characterize quasi-paraorthogonal\npolynomials on the unit circle as the analogues of the quasi-orthogonal\npolynomials on $\\mathbb{R}$. We analyze the possibilities of preselecting some\nof its zeros, in order to build positive quadrature formulas with prefixed\nnodes and maximal domain of validity. These quadrature formulas on the unit\ncircle are illustrated numerically.",
    "descriptor": "",
    "authors": [
      "Adhemar Bultheel",
      "Ruym\u00e1n Cruz-Barroso",
      "Carlos D\u00edaz Mendoza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.10460"
  },
  {
    "id": "arXiv:2110.10461",
    "title": "Scalable One-Pass Optimisation of High-Dimensional Weight-Update  Hyperparameters by Implicit Differentiation",
    "abstract": "Machine learning training methods depend plentifully and intricately on\nhyperparameters, motivating automated strategies for their optimisation. Many\nexisting algorithms restart training for each new hyperparameter choice, at\nconsiderable computational cost. Some hypergradient-based one-pass methods\nexist, but these either cannot be applied to arbitrary optimiser\nhyperparameters (such as learning rates and momenta) or take several times\nlonger to train than their base models. We extend these existing methods to\ndevelop an approximate hypergradient-based hyperparameter optimiser which is\napplicable to any continuous hyperparameter appearing in a differentiable model\nweight update, yet requires only one training episode, with no restarts. We\nalso provide a motivating argument for convergence to the true hypergradient,\nand perform tractable gradient-based optimisation of independent learning rates\nfor each model parameter. Our method performs competitively from varied random\nhyperparameter initialisations on several UCI datasets and Fashion-MNIST (using\na one-layer MLP), Penn Treebank (using an LSTM) and CIFAR-10 (using a\nResNet-18), in time only 2-3x greater than vanilla training.",
    "descriptor": "\nComments: 34 pages, 18 figures, 13 tables\n",
    "authors": [
      "Ross M. Clarke",
      "Elre T. Oldewage",
      "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.10461"
  },
  {
    "id": "arXiv:2110.10470",
    "title": "Interpreting Deep Learning Models in Natural Language Processing: A  Review",
    "abstract": "Neural network models have achieved state-of-the-art performances in a wide\nrange of natural language processing (NLP) tasks. However, a long-standing\ncriticism against neural network models is the lack of interpretability, which\nnot only reduces the reliability of neural NLP systems but also limits the\nscope of their applications in areas where interpretability is essential (e.g.,\nhealth care applications). In response, the increasing interest in interpreting\nneural NLP models has spurred a diverse array of interpretation methods over\nrecent years. In this survey, we provide a comprehensive review of various\ninterpretation methods for neural models in NLP. We first stretch out a\nhigh-level taxonomy for interpretation methods in NLP, i.e., training-based\napproaches, test-based approaches, and hybrid approaches. Next, we describe\nsub-categories in each category in detail, e.g., influence-function based\nmethods, KNN-based methods, attention-based models, saliency-based methods,\nperturbation-based methods, etc. We point out deficiencies of current methods\nand suggest some avenues for future research.",
    "descriptor": "",
    "authors": [
      "Xiaofei Sun",
      "Diyi Yang",
      "Xiaoya Li",
      "Tianwei Zhang",
      "Yuxian Meng",
      "Qiu Han",
      "Guoyin Wang",
      "Eduard Hovy",
      "Jiwei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.10470"
  },
  {
    "id": "arXiv:2110.10472",
    "title": "Multilingual Unsupervised Neural Machine Translation with Denoising  Adapters",
    "abstract": "We consider the problem of multilingual unsupervised machine translation,\ntranslating to and from languages that only have monolingual data by using\nauxiliary parallel language pairs. For this problem the standard procedure so\nfar to leverage the monolingual data is back-translation, which is\ncomputationally costly and hard to tune.\nIn this paper we propose instead to use denoising adapters, adapter layers\nwith a denoising objective, on top of pre-trained mBART-50. In addition to the\nmodularity and flexibility of such an approach we show that the resulting\ntranslations are on-par with back-translating as measured by BLEU, and\nfurthermore it allows adding unseen languages incrementally.",
    "descriptor": "\nComments: Accepted as a long paper to EMNLP 2021\n",
    "authors": [
      "Ahmet \u00dcst\u00fcn",
      "Alexandre B\u00e9rard",
      "Laurent Besacier",
      "Matthias Gall\u00e9"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.10472"
  },
  {
    "id": "arXiv:2110.10474",
    "title": "R4: A Framework for Route Representation and Route Recommendation",
    "abstract": "Route recommendation is significant in navigation service. Two major\nchallenges for route recommendation are route representation and user\nrepresentation. Different from items that can be identified by unique IDs in\ntraditional recommendation, routes are combinations of links (i.e., a road\nsegment and its following action like turning left) and the number of\ncombinations could be close to infinite. Besides, the representation of a route\nchanges under different scenarios. These facts result in severe sparsity of\nroutes, which increases the difficulty of route representation. Moreover, link\nattribute deficiencies and errors affect preciseness of route representation.\nBecause of the sparsity of routes, the interaction data between users and\nroutes are also sparse. This makes it not easy to acquire user representation\nfrom historical user-item interactions as traditional recommendations do. To\naddress these issues, we propose a novel learning framework R4. In R4, we\ndesign a sparse & dense network to obtain representations of routes. The sparse\nunit learns link ID embeddings and aggregates them to represent a route, which\ncaptures implicit route characteristics and subsequently alleviates problems\ncaused by link attribute deficiencies and errors. The dense unit extracts\nimplicit local features of routes from link attributes. For user\nrepresentation, we utilize a series of historical navigation to extract user\npreference. R4 achieves remarkable performance in both offline and online\nexperiments.",
    "descriptor": "",
    "authors": [
      "Ran Cheng",
      "Chao Chen",
      "Longfei Xu",
      "Shen Li",
      "Lei Wang",
      "Hengbin Cui",
      "Kaikui Liu",
      "Xiaolong Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10474"
  },
  {
    "id": "arXiv:2110.10478",
    "title": "Continual Learning in Multilingual NMT via Language-Specific Embeddings",
    "abstract": "This paper proposes a technique for adding a new source or target language to\nan existing multilingual NMT model without re-training it on the initial set of\nlanguages. It consists in replacing the shared vocabulary with a small\nlanguage-specific vocabulary and fine-tuning the new embeddings on the new\nlanguage's parallel data. Some additional language-specific components may be\ntrained to improve performance (e.g., Transformer layers or adapter modules).\nBecause the parameters of the original model are not modified, its performance\non the initial languages does not degrade. We show on two sets of experiments\n(small-scale on TED Talks, and large-scale on ParaCrawl) that this approach\nperforms as well or better as the more costly alternatives; and that it has\nexcellent zero-shot performance: training on English-centric data is enough to\ntranslate between the new language and any of the initial languages.",
    "descriptor": "\nComments: Accepted as a research paper to WMT 2021\n",
    "authors": [
      "Alexandre Berard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.10478"
  },
  {
    "id": "arXiv:2110.10481",
    "title": "Unified Style Transfer",
    "abstract": "Currently, it is hard to compare and evaluate different style transfer\nalgorithms due to chaotic definitions of style and the absence of agreed\nobjective validation methods in the study of style transfer. In this paper, a\nnovel approach, the Unified Style Transfer (UST) model, is proposed. With the\nintroduction of a generative model for internal style representation, UST can\ntransfer images in two approaches, i.e., Domain-based and Image-based,\nsimultaneously. At the same time, a new philosophy based on the human sense of\nart and style distributions for evaluating the transfer model is presented and\ndemonstrated, called Statistical Style Analysis. It provides a new path to\nvalidate style transfer models' feasibility by validating the general\nconsistency between internal style representation and art facts. Besides, the\ntranslation-invariance of AdaIN features is also discussed.",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Guanjie Huang",
      "Hongjian He",
      "Xiang Li",
      "Xingchen Li",
      "Ziang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10481"
  },
  {
    "id": "arXiv:2110.10482",
    "title": "Surrogate Representation Learning with Isometric Mapping for Gray-box  Graph Adversarial Attacks",
    "abstract": "Gray-box graph attacks aim at disrupting the performance of the victim model\nby using inconspicuous attacks with limited knowledge of the victim model. The\nparameters of the victim model and the labels of the test nodes are invisible\nto the attacker. To obtain the gradient on the node attributes or graph\nstructure, the attacker constructs an imaginary surrogate model trained under\nsupervision. However, there is a lack of discussion on the training of\nsurrogate models and the robustness of provided gradient information. The\ngeneral node classification model loses the topology of the nodes on the graph,\nwhich is, in fact, an exploitable prior for the attacker. This paper\ninvestigates the effect of representation learning of surrogate models on the\ntransferability of gray-box graph adversarial attacks. To reserve the topology\nin the surrogate embedding, we propose Surrogate Representation Learning with\nIsometric Mapping (SRLIM). By using Isometric mapping method, our proposed\nSRLIM can constrain the topological structure of nodes from the input layer to\nthe embedding space, that is, to maintain the similarity of nodes in the\npropagation process. Experiments prove the effectiveness of our approach\nthrough the improvement in the performance of the adversarial attacks generated\nby the gradient-based attacker in untargeted poisoning gray-box setups.",
    "descriptor": "",
    "authors": [
      "Zihan Liul",
      "Yun Luo",
      "Zelin Zang",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10482"
  },
  {
    "id": "arXiv:2110.10486",
    "title": "A TinyML Platform for On-Device Continual Learning with Quantized Latent  Replays",
    "abstract": "In the last few years, research and development on Deep Learning models and\ntechniques for ultra-low-power devices in a word, TinyML has mainly focused on\na train-then-deploy assumption, with static models that cannot be adapted to\nnewly collected data without cloud-based data collection and fine-tuning.\nLatent Replay-based Continual Learning (CL) techniques[1] enable online,\nserverless adaptation in principle, but so farthey have still been too\ncomputation and memory-hungry for ultra-low-power TinyML devices, which are\ntypically based on microcontrollers. In this work, we introduce a HW/SW\nplatform for end-to-end CL based on a 10-core FP32-enabled parallel\nultra-low-power (PULP) processor. We rethink the baseline Latent Replay CL\nalgorithm, leveraging quantization of the frozen stage of the model and Latent\nReplays (LRs) to reduce their memory cost with minimal impact on accuracy. In\nparticular, 8-bit compression of the LR memory proves to be almost lossless\n(-0.26% with 3000LR) compared to the full-precision baseline implementation,\nbut requires 4x less memory, while 7-bit can also be used with an additional\nminimal accuracy degradation (up to 5%). We also introduce optimized primitives\nfor forward and backward propagation on the PULP processor. Our results show\nthat by combining these techniques, continual learning can be achieved in\npractice using less than 64MB of memory an amount compatible with embedding in\nTinyML devices. On an advanced 22nm prototype of our platform, called VEGA, the\nproposed solution performs onaverage 65x faster than a low-power STM32 L4\nmicrocontroller, being 37x more energy efficient enough for a lifetime of 535h\nwhen learning a new mini-batch of data once every minute.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Leonardo Ravaglia",
      "Manuele Rusci",
      "Davide Nadalini",
      "Alessandro Capotondi",
      "Francesco Conti",
      "Luca Benini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10486"
  },
  {
    "id": "arXiv:2110.10490",
    "title": "Transferring Reinforcement Learning for DC-DC Buck Converter Control via  Duty Ratio Mapping: From Simulation to Implementation",
    "abstract": "Reinforcement learning (RL) control approach with application into power\nelectronics systems has become an emerging topic whilst the sim-to-real issue\nremains a challenging problem as very few results can be referred to in the\nliterature. Indeed, due to the inevitable mismatch between simulation models\nand real-life systems, offline trained RL control strategies may sustain\nunexpected hurdles in practical implementation during transferring procedure.\nAs the main contribution of this paper, a transferring methodology via a\ndelicately designed duty ratio mapping (DRM) is proposed for a DC-DC buck\nconverter. Then, a detailed sim-to-real process is presented to enable the\nimplementation of a model-free deep reinforcement learning (DRL) controller.\nThe feasibility and effectiveness of the proposed methodology are demonstrated\nby comparative experimental studies.",
    "descriptor": "",
    "authors": [
      "Chenggang Cui",
      "Tianxiao Yang",
      "Yuxuan Dai",
      "Chuanlin Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10490"
  },
  {
    "id": "arXiv:2110.10491",
    "title": "A Study On Data Augmentation In Voice Anti-Spoofing",
    "abstract": "In this paper, we perform an in-depth study of how data augmentation\ntechniques improve synthetic or spoofed audio detection. Specifically, we\npropose methods to deal with channel variability, different audio compressions,\ndifferent band-widths, and unseen spoofing attacks, which have all been shown\nto significantly degrade the performance of audio-based systems and\nAnti-Spoofing systems. Our results are based on the ASVspoof 2021 challenge, in\nthe Logical Access (LA) and Deep Fake (DF) categories. Our study is\nData-Centric, meaning that the models are fixed and we significantly improve\nthe results by making changes in the data. We introduce two forms of data\naugmentation - compression augmentation for the DF part, compression & channel\naugmentation for the LA part. In addition, a new type of online data\naugmentation, SpecAverage, is introduced in which the audio features are masked\nwith their average value in order to improve generalization. Furthermore, we\nintroduce a Log spectrogram feature design that improved the results. Our best\nsingle system and fusion scheme both achieve state-of-the-art performance in\nthe DF category, with an EER of 15.46% and 14.46% respectively. Our best system\nfor the LA task reduced the best baseline EER by 50% and the min t-DCF by 16%.\nOur techniques to deal with spoofed data from a wide variety of distributions\ncan be replicated and can help anti-spoofing and speech-based systems enhance\ntheir results.",
    "descriptor": "",
    "authors": [
      "Ariel Cohen",
      "Inbal Rimon",
      "Eran Aflalo",
      "Haim Permuter"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.10491"
  },
  {
    "id": "arXiv:2110.10493",
    "title": "On the Effectiveness of Clone Detection for Detecting IoT-related  Vulnerable Clones",
    "abstract": "Since IoT systems provide services over the Internet, they must continue to\noperate safely even if malicious users attack them. Since the computational\nresources of edge devices connected to the IoT are limited, lightweight\nplatforms and network protocols are often used. Lightweight platforms and\nnetwork protocols are less resistant to attacks, increasing the risk that\ndevelopers will embed vulnerabilities. The code clone research community has\nbeen developing approaches to fix buggy (e.g., vulnerable) clones\nsimultaneously. However, there has been little research on IoT-related\nvulnerable clones. It is unclear whether existing code clone detection\ntechniques can perform simultaneous fixes of the vulnerable clones. In this\nstudy, we first created two datasets of IoT-related vulnerable code. We then\nconducted a preliminary investigation to show whether existing code clone\ndetection tools (e.g., NiCaD, CCFinderSW) are capable of detecting IoT-related\nvulnerable clones by applying them to the created datasets. The preliminary\nresult shows that the existing tools can detect them partially.",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Kentaro Ohno",
      "Norihiro Yoshida",
      "Wenqing Zhu",
      "Hiroaki Takada"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.10493"
  },
  {
    "id": "arXiv:2110.10494",
    "title": "Deep Point Cloud Normal Estimation via Triplet Learning",
    "abstract": "Normal estimation on 3D point clouds is a fundamental problem in 3D vision\nand graphics. Current methods often show limited accuracy in predicting normals\nat sharp features (e.g., edges and corners) and less robustness to noise. In\nthis paper, we propose a novel normal estimation method for point clouds. It\nconsists of two phases: (a) feature encoding which learns representations of\nlocal patches, and (b) normal estimation that takes the learned representation\nas input and regresses the normal vector. We are motivated that local patches\non isotropic and anisotropic surfaces have similar or distinct normals, and\nthat separable features or representations can be learned to facilitate normal\nestimation. To realise this, we first construct triplets of local patches on 3D\npoint cloud data, and design a triplet network with a triplet loss for feature\nencoding. We then design a simple network with several MLPs and a loss function\nto regress the normal vector. Despite having a smaller network size compared to\nmost other methods, experimental results show that our method preserves sharp\nfeatures and achieves better normal estimation results on CAD-like shapes.",
    "descriptor": "",
    "authors": [
      "Weijia Wang",
      "Xuequan Lu",
      "Dasith de Silva Edirimuni",
      "Xiao Liu",
      "Antonio Robles-Kelly"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.10494"
  },
  {
    "id": "arXiv:2110.10501",
    "title": "STALP: Style Transfer with Auxiliary Limited Pairing",
    "abstract": "We present an approach to example-based stylization of images that uses a\nsingle pair of a source image and its stylized counterpart. We demonstrate how\nto train an image translation network that can perform real-time semantically\nmeaningful style transfer to a set of target images with similar content as the\nsource image. A key added value of our approach is that it considers also\nconsistency of target images during training. Although those have no stylized\ncounterparts, we constrain the translation to keep the statistics of neural\nresponses compatible with those extracted from the stylized source. In contrast\nto concurrent techniques that use a similar input, our approach better\npreserves important visual characteristics of the source style and can deliver\ntemporally stable results without the need to explicitly handle temporal\nconsistency. We demonstrate its practical utility on various applications\nincluding video stylization, style transfer to panoramas, faces, and 3D models.",
    "descriptor": "\nComments: Eurographics 2021\n",
    "authors": [
      "David Futschik",
      "Michal Ku\u010dera",
      "Michal Luk\u00e1\u010d",
      "Zhaowen Wang",
      "Eli Shechtman",
      "Daniel S\u00fdkora"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.10501"
  },
  {
    "id": "arXiv:2110.10505",
    "title": "Event Guided Depth Sensing",
    "abstract": "Active depth sensors like structured light, lidar, and time-of-flight systems\nsample the depth of the entire scene uniformly at a fixed scan rate. This leads\nto limited spatio-temporal resolution where redundant static information is\nover-sampled and precious motion information might be under-sampled. In this\npaper, we present an efficient bio-inspired event-camera-driven depth\nestimation algorithm. In our approach, we dynamically illuminate areas of\ninterest densely, depending on the scene activity detected by the event camera,\nand sparsely illuminate areas in the field of view with no motion. The depth\nestimation is achieved by an event-based structured light system consisting of\na laser point projector coupled with a second event-based sensor tuned to\ndetect the reflection of the laser from the scene. We show the feasibility of\nour approach in a simulated autonomous driving scenario and real indoor\nsequences using our prototype. We show that, in natural scenes like autonomous\ndriving and indoor environments, moving edges correspond to less than 10% of\nthe scene on average. Thus our setup requires the sensor to scan only 10% of\nthe scene, which could lead to almost 90% less power consumption by the\nillumination source. While we present the evaluation and proof-of-concept for\nan event-based structured-light system, the ideas presented here are applicable\nfor a wide range of depth-sensing modalities like LIDAR, time-of-flight, and\nstandard stereo.",
    "descriptor": "",
    "authors": [
      "Manasi Muglikar",
      "Diederik Paul Moeys",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10505"
  },
  {
    "id": "arXiv:2110.10507",
    "title": "Development and analysis of entropy stable no-slip wall boundary  conditions for the Eulerian model for viscous and heat conducting  compressible flows",
    "abstract": "Nonlinear entropy stability analysis is used to derive entropy stable no-slip\nwall boundary conditions for the Eulerian model proposed by Sv\\\"{a}rd (Physica\nA: Statistical Mechanics and its Applications, 2018). and its spatial\ndiscretization based on entropy stable collocated discontinuous Galerkin\noperators with the summation-by-parts property for unstructured grids. A set of\nviscous test cases of increasing complexity are simulated using both the\nEulerian and the classic compressible Navier-Stokes models. The numerical\nresults obtained with the two models are compared, and differences and\nsimilarities are then highlighted.",
    "descriptor": "\nComments: The datasets generated during and/or analysed during the current study are available in the Zenodo repository, this http URL\n",
    "authors": [
      "Mohammed Sayyari",
      "Matteo Parsani",
      "Lisandro Dalcin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.10507"
  },
  {
    "id": "arXiv:2110.10510",
    "title": "Periodic DMP formulation for Quaternion Trajectories",
    "abstract": "Imitation learning techniques have been used as a way to transfer skills to\nrobots. Among them, dynamic movement primitives (DMPs) have been widely\nexploited as an effective and an efficient technique to learn and reproduce\ncomplex discrete and periodic skills. While DMPs have been properly formulated\nfor learning point-to-point movements for both translation and orientation,\nperiodic ones are missing a formulation to learn the orientation. To address\nthis gap, we propose a novel DMP formulation that enables encoding of periodic\norientation trajectories. Within this formulation we develop two approaches:\nRiemannian metric-based projection approach and unit quaternion based periodic\nDMP. Both formulations exploit unit quaternions to represent the orientation.\nHowever, the first exploits the properties of Riemannian manifolds to work in\nthe tangent space of the unit sphere. The second encodes directly the unit\nquaternion trajectory while guaranteeing the unitary norm of the generated\nquaternions. We validated the technical aspects of the proposed methods in\nsimulation. Then we performed experiments on a real robot to execute daily\ntasks that involve periodic orientation changes (i.e., surface polishing/wiping\nand liquid mixing by shaking).",
    "descriptor": "\nComments: 2021 20th International Conference on Advanced Robotics (ICAR)\n",
    "authors": [
      "Fares J. Abu-Dakka",
      "Matteo Saveriano",
      "Luka Peternel"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10510"
  },
  {
    "id": "arXiv:2110.10517",
    "title": "A $C^{0}$ interior penalty method for $m$th-Laplace equation",
    "abstract": "In this paper, we propose a $C^{0}$ interior penalty method for $m$th-Laplace\nequation on bounded Lipschitz polyhedral domain in $\\mathbb{R}^{d}$, where $m$\nand $d$ can be any positive integers. The standard $H^{1}$-conforming piecewise\n$r$-th order polynomial space is used to approximate the exact solution $u$,\nwhere $r$ can be any integer greater than or equal to $m$. Unlike the interior\npenalty method in [T.~Gudi and M.~Neilan, {\\em An interior penalty method for a\nsixth-order elliptic equation}, IMA J. Numer. Anal., \\textbf{31(4)} (2011), pp.\n1734--1753], we avoid computing $D^{m}$ of numerical solution on each element\nand high order normal derivatives of numerical solution along mesh interfaces.\nTherefore our method can be easily implemented. After proving discrete\n$H^{m}$-norm bounded by the natural energy semi-norm associated with our\nmethod, we manage to obtain stability and optimal convergence with respect to\ndiscrete $H^{m}$-norm. Numerical experiments validate our theoretical estimate.",
    "descriptor": "",
    "authors": [
      "Huangxin Chen",
      "Jingzhi Li",
      "Weifeng Qiu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.10517"
  },
  {
    "id": "arXiv:2110.10522",
    "title": "CIM-PPO:Proximal Policy Optimization with Liu-Correntropy Induced Metric",
    "abstract": "As an algorithm based on deep reinforcement learning, Proximal Policy\nOptimization (PPO) performs well in many complex tasks and has become one of\nthe most popular RL algorithms in recent years. According to the mechanism of\npenalty in surrogate objective, PPO can be divided into PPO with KL Divergence\n(KL-PPO) and PPO with Clip function(Clip-PPO). Clip-PPO is widely used in a\nvariety of practical scenarios and has attracted the attention of many\nresearchers. Therefore, many variations have also been created, making the\nalgorithm better and better. However, as a more theoretical algorithm, KL-PPO\nwas neglected because its performance was not as good as CliP-PPO. In this\narticle, we analyze the asymmetry effect of KL divergence on PPO's objective\nfunction , and give the inequality that can indicate when the asymmetry will\naffect the efficiency of KL-PPO. Proposed PPO with Correntropy Induced Metric\nalgorithm(CIM-PPO) that use the theory of correntropy(a symmetry metric method\nthat was widely used in M-estimation to evaluate two distributions'\ndifference)and applied it in PPO. Then, we designed experiments based on\nOpenAIgym to test the effectiveness of the new algorithm and compare it with\nKL-PPO and CliP-PPO.",
    "descriptor": "",
    "authors": [
      "Yunxiao Guo",
      "Han Long",
      "Xiaojun Duan",
      "Kaiyuan Feng",
      "Maochu Li",
      "Xiaying Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10522"
  },
  {
    "id": "arXiv:2110.10523",
    "title": "Detecting and Identifying Optical Signal Attacks on Autonomous Driving  Systems",
    "abstract": "For autonomous driving, an essential task is to detect surrounding objects\naccurately. To this end, most existing systems use optical devices, including\ncameras and light detection and ranging (LiDAR) sensors, to collect environment\ndata in real time. In recent years, many researchers have developed advanced\nmachine learning models to detect surrounding objects. Nevertheless, the\naforementioned optical devices are vulnerable to optical signal attacks, which\ncould compromise the accuracy of object detection. To address this critical\nissue, we propose a framework to detect and identify sensors that are under\nattack. Specifically, we first develop a new technique to detect attacks on a\nsystem that consists of three sensors. Our main idea is to: 1) use data from\nthree sensors to obtain two versions of depth maps (i.e., disparity) and 2)\ndetect attacks by analyzing the distribution of disparity errors. In our study,\nwe use real data sets and the state-of-the-art machine learning model to\nevaluate our attack detection scheme and the results confirm the effectiveness\nof our detection method. Based on the detection scheme, we further develop an\nidentification model that is capable of identifying up to n-2 attacked sensors\nin a system with one LiDAR and n cameras. We prove the correctness of our\nidentification scheme and conduct experiments to show the accuracy of our\nidentification method. Finally, we investigate the overall sensitivity of our\nframework.",
    "descriptor": "",
    "authors": [
      "Jindi Zhang",
      "Yifan Zhang",
      "Kejie Lu",
      "Jianping Wang",
      "Kui Wu",
      "Xiaohua Jia",
      "Bin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10523"
  },
  {
    "id": "arXiv:2110.10524",
    "title": "Statistical and Topological Properties of Gaussian Smoothed Sliced  Probability Divergences",
    "abstract": "Gaussian smoothed sliced Wasserstein distance has been recently introduced\nfor comparing probability distributions, while preserving privacy on the data.\nIt has been shown, in applications such as domain adaptation, to provide\nperformances similar to its non-private (non-smoothed) counterpart. However,\nthe computational and statistical properties of such a metric is not yet been\nwell-established. In this paper, we analyze the theoretical properties of this\ndistance as well as those of generalized versions denoted as Gaussian smoothed\nsliced divergences. We show that smoothing and slicing preserve the metric\nproperty and the weak topology. We also provide results on the sample\ncomplexity of such divergences. Since, the privacy level depends on the amount\nof Gaussian smoothing, we analyze the impact of this parameter on the\ndivergence. We support our theoretical findings with empirical studies of\nGaussian smoothed and sliced version of Wassertein distance, Sinkhorn\ndivergence and maximum mean discrepancy (MMD). In the context of\nprivacy-preserving domain adaptation, we confirm that those Gaussian smoothed\nsliced Wasserstein and MMD divergences perform very well while ensuring data\nprivacy.",
    "descriptor": "",
    "authors": [
      "Alain Rakotomamonjy",
      "Mokhtar Z. Alaya",
      "Maxime Berar",
      "Gilles Gasso"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.10524"
  },
  {
    "id": "arXiv:2110.10527",
    "title": "Sampling from Arbitrary Functions via PSD Models",
    "abstract": "In many areas of applied statistics and machine learning, generating an\narbitrary number of independent and identically distributed (i.i.d.) samples\nfrom a given distribution is a key task. When the distribution is known only\nthrough evaluations of the density, current methods either scale badly with the\ndimension or require very involved implementations. Instead, we take a two-step\napproach by first modeling the probability distribution and then sampling from\nthat model. We use the recently introduced class of positive semi-definite\n(PSD) models, which have been shown to be efficient for approximating\nprobability densities. We show that these models can approximate a large class\nof densities concisely using few evaluations, and present a simple algorithm to\neffectively sample from these models. We also present preliminary empirical\nresults to illustrate our assertions.",
    "descriptor": "",
    "authors": [
      "Ulysse Marteau-Ferey",
      "Alessandro Rudi",
      "Francis Bach"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.10527"
  },
  {
    "id": "arXiv:2110.10533",
    "title": "AniFormer: Data-driven 3D Animation with Transformer",
    "abstract": "We present a novel task, i.e., animating a target 3D object through the\nmotion of a raw driving sequence. In previous works, extra auxiliary\ncorrelations between source and target meshes or intermedia factors are\ninevitable to capture the motions in the driving sequences. Instead, we\nintroduce AniFormer, a novel Transformer-based architecture, that generates\nanimated 3D sequences by directly taking the raw driving sequences and\narbitrary same-type target meshes as inputs. Specifically, we customize the\nTransformer architecture for 3D animation that generates mesh sequences by\nintegrating styles from target meshes and motions from the driving meshes.\nBesides, instead of the conventional single regression head in the vanilla\nTransformer, AniFormer generates multiple frames as outputs to preserve the\nsequential consistency of the generated meshes. To achieve this, we carefully\ndesign a pair of regression constraints, i.e., motion and appearance\nconstraints, that can provide strong regularization on the generated mesh\nsequences. Our AniFormer achieves high-fidelity, realistic, temporally coherent\nanimated results and outperforms compared start-of-the-art methods on\nbenchmarks of diverse categories. Code is available:\nhttps://github.com/mikecheninoulu/AniFormer.",
    "descriptor": "\nComments: BMVC 2021\n",
    "authors": [
      "Haoyu Chen",
      "Hao Tang",
      "Nicu Sebe",
      "Guoying Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10533"
  },
  {
    "id": "arXiv:2110.10534",
    "title": "FairNet: A Measurement Framework for Traffic Discrimination Detection on  the Internet",
    "abstract": "Network neutrality is related to the non-discriminatory treatment of packets\non the Internet. Any deliberate discrimination of traffic of one application\nwhile favoring others violates the principle of neutrality. Many countries have\nenforced laws against such discrimination. To enforce such laws, one requires\ntools to detect any net neutrality violations. However, detecting such\nviolations is challenging as it is hard to separate any degradation in quality\ndue to natural network effects and selective degradation. Also, legitimate\ntraffic management and deliberate discrimination methods can be technically the\nsame, making it further challenging to distinguish them.\nWe developed an end-to-end measurement framework named FairNet to detect\ndiscrimination of traffic. It compares the performance of similar services. Our\nfocus is on HTTPS streaming services which constitute a predominant portion of\nthe Internet traffic. The effect of confounding factors (congestion, traffic\nmanagement policy, dynamic rate adaptation) is made `similar' on the test\nservices to ensure a fair comparison. FairNet framework uses a ``replay\nserver'' and user-client that exchanges correctly identifiable traffic streams\nover the Internet. The Server Name Indication (SNI) field in the TLS handshake,\nwhich goes in plaintext, ensures that the traffic from the replay server\nappears to network middle-boxes as that coming from its actual server. We\nvalidated that appropriate SNIs results in the correct classification of\nservices using a commercial traffic shaper. FairNet uses two novel algorithms\nbased on application-level throughput and connection status to detect traffic\ndiscrimination. We also validated the methodology's effectiveness by collecting\nnetwork logs through mobile apps over the live Internet and analyzing them.",
    "descriptor": "",
    "authors": [
      "Vinod S. Khandkar",
      "Manjesh K. Hanawal"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.10534"
  },
  {
    "id": "arXiv:2110.10535",
    "title": "Investigating Reversibility of Steps in Petri Nets",
    "abstract": "In reversible computations one is interested in the development of mechanisms\nallowing to undo the effects of executed actions. The past research has been\nconcerned mainly with reversing single actions. In this paper, we consider the\nproblem of reversing the effect of the execution of groups of actions (steps).\nUsing Petri nets as a system model, we introduce concepts related to this new\nscenario, generalising notions used in the single action case. We then present\nproperties arising when reverse actions are allowed in place/transition nets\n(pt-nets). We obtain both positive and negative results, showing that allowing\nsteps makes reversibility more problematic than in the interleaving/sequential\ncase. In particular, we demonstrate that there is a crucial difference between\nreversing steps which are sets and those which are true multisets. Moreover, in\ncontrast to sequential semantics, splitting reverses does not lead to a general\nmethod for reversing bounded pt-nets. We then show that a suitable solution can\nbe obtained by combining split reverses with weighted read arcs.",
    "descriptor": "\nComments: special issue of PN 2019\n",
    "authors": [
      "David de Frutos Escrig",
      "Maciej Koutny",
      "\u0141ukasz Mikulski"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.10535"
  },
  {
    "id": "arXiv:2110.10536",
    "title": "Improving Model Generalization by Agreement of Learned Representations  from Data Augmentation",
    "abstract": "Data augmentation reduces the generalization error by forcing a model to\nlearn invariant representations given different transformations of the input\nimage. In computer vision, on top of the standard image processing functions,\ndata augmentation techniques based on regional dropout such as CutOut, MixUp,\nand CutMix and policy-based selection such as AutoAugment demonstrated\nstate-of-the-art (SOTA) results. With an increasing number of data augmentation\nalgorithms being proposed, the focus is always on optimizing the input-output\nmapping while not realizing that there might be an untapped value in the\ntransformed images with the same label. We hypothesize that by forcing the\nrepresentations of two transformations to agree, we can further reduce the\nmodel generalization error. We call our proposed method Agreement Maximization\nor simply AgMax. With this simple constraint applied during training, empirical\nresults show that data augmentation algorithms can further improve the\nclassification accuracy of ResNet50 on ImageNet by up to 1.5%, WideResNet40-2\non CIFAR10 by up to 0.7%, WideResNet40-2 on CIFAR100 by up to 1.6%, and LeNet5\non Speech Commands Dataset by up to 1.4%. Experimental results further show\nthat unlike other regularization terms such as label smoothing, AgMax can take\nadvantage of the data augmentation to consistently improve model generalization\nby a significant margin. On downstream tasks such as object detection and\nsegmentation on PascalVOC and COCO, AgMax pre-trained models outperforms other\ndata augmentation methods by as much as 1.0mAP (box) and 0.5mAP (mask). Code is\navailable at https://github.com/roatienza/agmax.",
    "descriptor": "\nComments: Accepted at WACV2022\n",
    "authors": [
      "Rowel Atienza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10536"
  },
  {
    "id": "arXiv:2110.10538",
    "title": "Anisotropic Separable Set Abstraction for Efficient Point Cloud  Representation Learning",
    "abstract": "Access to 3D point cloud representations has been widely facilitated by LiDAR\nsensors embedded in various mobile devices. This has led to an emerging need\nfor fast and accurate point cloud processing techniques. In this paper, we\nrevisit and dive deeper into PointNet++, one of the most influential yet\nunder-explored networks, and develop faster and more accurate variants of the\nmodel. We first present a novel Separable Set Abstraction (SA) module that\ndisentangles the vanilla SA module used in PointNet++ into two separate\nlearning stages: (1) learning channel correlation and (2) learning spatial\ncorrelation. The Separable SA module is significantly faster than the vanilla\nversion, yet it achieves comparable performance. We then introduce a new\nAnisotropic Reduction function into our Separable SA module and propose an\nAnisotropic Separable SA (ASSA) module that substantially increases the\nnetwork's accuracy. We later replace the vanilla SA modules in PointNet++ with\nthe proposed ASSA module, and denote the modified network as ASSANet. Extensive\nexperiments on point cloud classification, semantic segmentation, and part\nsegmentation show that ASSANet outperforms PointNet++ and other methods,\nachieving much higher accuracy and faster speeds. In particular, ASSANet\noutperforms PointNet++ by $7.4$ mIoU on S3DIS Area 5, while maintaining $1.6\n\\times $ faster inference speed on a single NVIDIA 2080Ti GPU. Our scaled\nASSANet variant achieves $66.8$ mIoU and outperforms KPConv, while being more\nthan $54 \\times$ faster.",
    "descriptor": "\nComments: NeurIPS'21 Spotlight paper. code available at this https URL\n",
    "authors": [
      "Guocheng Qian",
      "Hasan Abed Al Kader Hammoud",
      "Guohao Li",
      "Ali Thabet",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10538"
  },
  {
    "id": "arXiv:2110.10540",
    "title": "On the Integration of Course of Action Playbooks into Shareable Cyber  Threat Intelligence",
    "abstract": "Motivated by the introduction of CACAO, the first open standard that\nharmonizes the way we document course of action playbooks in a machine-readable\nformat for interoperability, and the benefits for cybersecurity operations\nderived from utilizing, and coupling and sharing security playbooks as part of\ncyber threat intelligence, we introduce a uniform metadata template that\nsupports the management and integration of security playbooks into knowledge\nrepresentation and knowledge management systems. To demonstrate the\napplicability of our approach, we provide two use-case implementations where\nour uniform non-proprietary metadata template is used to introduce security\nplaybooks like CACAO into the MISP threat intelligence platform and the Threat\nActor Context ontology.",
    "descriptor": "",
    "authors": [
      "Vasileios Mavroeidis",
      "Pavel Eis",
      "Martin Zadnik",
      "Marco Caseli",
      "Bret Jordan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.10540"
  },
  {
    "id": "arXiv:2110.10545",
    "title": "Ranking and Tuning Pre-trained Models: A New Paradigm of Exploiting  Model Hubs",
    "abstract": "Pre-trained model hubs with many pre-trained models (PTMs) have been a\ncornerstone in deep learning. Although built at a high cost, they are in fact\n\\emph{under-exploited}: practitioners usually pick one PTM from the provided\nmodel hub by popularity, and then fine-tune the PTM to solve the target task.\nThis na\\\"ve but common practice poses two obstacles to sufficiently exploiting\npre-trained model hubs: (1) the PTM selection procedure has no optimality\nguarantee; (2) only one PTM is used while the rest PTMs are overlooked.\nIdeally, to maximally exploit pre-trained model hubs, trying all combinations\nof PTMs and extensively fine-tuning each combination of PTMs are required,\nwhich incurs exponential combinations and unaffordable computational budget. In\nthis paper, we propose a new paradigm of exploiting model hubs by ranking and\ntuning pre-trained models: (1) Our conference work~\\citep{you_logme:_2021}\nproposed LogME to estimate the maximum value of label evidence given features\nextracted by pre-trained models, which can rank all the PTMs in a model hub for\nvarious types of PTMs and tasks \\emph{before fine-tuning}. (2) the best ranked\nPTM can be fine-tuned and deployed if we have no preference for the model's\narchitecture, or the target PTM can be tuned by top-K ranked PTMs via the\nproposed B-Tuning algorithm. The ranking part is based on the conference paper,\nand we complete its theoretical analysis (convergence proof of the heuristic\nevidence maximization procedure, and the influence of feature dimension) in\nthis paper. The tuning part introduces a novel Bayesian Tuning (B-Tuning)\nmethod for multiple PTMs tuning, which surpasses dedicated methods designed for\nhomogeneous PTMs tuning and sets up new state of the art for heterogeneous PTMs\ntuning. We believe the new paradigm of exploiting PTM hubs can interest a large\naudience of the community.",
    "descriptor": "\nComments: 45 pages\n",
    "authors": [
      "Kaichao You",
      "Yong Liu",
      "Jianmin Wang",
      "Michael I. Jordan",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10545"
  },
  {
    "id": "arXiv:2110.10546",
    "title": "Trash or Treasure? An Interactive Dual-Stream Strategy for Single Image  Reflection Separation",
    "abstract": "Single image reflection separation (SIRS), as a representative blind source\nseparation task, aims to recover two layers, $\\textit{i.e.}$, transmission and\nreflection, from one mixed observation, which is challenging due to the highly\nill-posed nature. Existing deep learning based solutions typically restore the\ntarget layers individually, or with some concerns at the end of the output,\nbarely taking into account the interaction across the two streams/branches. In\norder to utilize information more efficiently, this work presents a general yet\nsimple interactive strategy, namely $\\textit{your trash is my treasure}$\n(YTMT), for constructing dual-stream decomposition networks. To be specific, we\nexplicitly enforce the two streams to communicate with each other block-wisely.\nInspired by the additive property between the two components, the interactive\npath can be easily built via transferring, instead of discarding, deactivated\ninformation by the ReLU rectifier from one stream to the other. Both ablation\nstudies and experimental results on widely-used SIRS datasets are conducted to\ndemonstrate the efficacy of YTMT, and reveal its superiority over other\nstate-of-the-art alternatives. The implementation is quite simple and our code\nis publicly available at\n$\\href{https://github.com/mingcv/YTMT-Strategy}{\\textit{https://github.com/mingcv/YTMT-Strategy}}$.",
    "descriptor": "\nComments: Accepted to NeurIPS2021\n",
    "authors": [
      "Qiming Hu",
      "Xiaojie Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10546"
  },
  {
    "id": "arXiv:2110.10548",
    "title": "Synthesizing Optimal Parallelism Placement and Reduction Strategies on  Hierarchical Systems for Deep Learning",
    "abstract": "We present a novel characterization of the mapping of multiple parallelism\nforms (e.g. data and model parallelism) onto hierarchical accelerator systems\nthat is hierarchy-aware and greatly reduces the space of software-to-hardware\nmapping. We experimentally verify the substantial effect of these mappings on\nall-reduce performance (up to 448x). We offer a novel syntax-guided program\nsynthesis framework that is able to decompose reductions over one or more\nparallelism axes to sequences of collectives in a hierarchy- and mapping-aware\nway. For 69% of parallelism placements and user requested reductions, our\nframework synthesizes programs that outperform the default all-reduce\nimplementation when evaluated on different GPU hierarchies (max 2.04x, average\n1.27x). We complement our synthesis tool with a simulator exceeding 90% top-10\naccuracy, which therefore reduces the need for massive evaluations of synthesis\nresults to determine a small set of optimal programs and mappings.",
    "descriptor": "\nComments: Submitted to the 5th MLSys Conference\n",
    "authors": [
      "Ningning Xie",
      "Tamara Norman",
      "Dominik Grewe",
      "Dimitrios Vytiniotis"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10548"
  },
  {
    "id": "arXiv:2110.10549",
    "title": "Statistical Physics Meets Wireless Communications: A Resource Allocation  Solution for Large Networks",
    "abstract": "The ever-increasing number of nodes in current and future wireless\ncommunication networks brings unprecedented challenges for the allocation of\nthe available communication resources. This is caused by the combinatorial\nnature of the resource allocation problems, which limits the performance of\nstate-of-the-art techniques when the network size increases. In this paper, we\ntake a new direction and investigate how methods from statistical physics can\nbe used to address resource allocation problems in large networks. To this aim,\nwe propose a novel model of the wireless network based on a type of disordered\nphysical systems called spin glasses, and on the contributions of the recently\nNobel laureate G. Parisi. We show that resource allocation problems, e.g.,\ntime, code or frequency assignment, have the same structure as the problem of\nfinding specific configurations in spin glasses. Based on this parallel, we\ninvestigate the use of the Survey Propagation method from statistical physics\nin the solution of resource allocation problems in wireless networks. Through\nnumerical simulations we show that the proposed statistical-physics-based\nresource allocation algorithm is a promising tool for the efficient allocation\nof communication resources in large wireless communications networks. Given a\nfixed number of resources, we are able to serve a larger number of nodes,\ncompared to state-of-the-art reference schemes, without introducing more\ninterference into the system",
    "descriptor": "",
    "authors": [
      "Andrea Ortiz",
      "Daniel Barragan-Yani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.10549"
  },
  {
    "id": "arXiv:2110.10551",
    "title": "Hosting Capacity Approach Implications",
    "abstract": "This paper revisits the generation hosting capacity (HC) calculation approach\nto account for grid operational flexibility--the ability to reconfigure the\nsystem safely. In essence, the generation hosting capacity is determined\nagainst the set of limiting factors--voltage, thermal (conductor loading),\nreverse flow (at the feeder head, station transformer, or substation), and\nchange in the voltage (due to sudden change in generation output)). Not that\nlong ago, California Investor-Owned Utilities (IOUs) added a new criterion that\ndoes not allow reverse flow at the supervisory control and data acquisition\n(SCADA) points that can change the system configuration, aiming to prevent the\npotential transfer of reverse flow to an adjacent feeder. This new criterion\nintended to capture operational constraints as part of hosting capacity-known\nas hosting capacity with operational flexibility (OpFlex). This paper explores\nthe shortfalls of such an approach and proposes performing actual transfer\nanalysis when determining hosting capacity rather than implementing the OpFlex\napproach. Furthermore, we discuss the need for transition to determining\nhosting capacity profile (all intervals) rather than a flat line (one, worst\nperforming interval) hosting capacity. A hosting capacity profile would inform\nthe developers of interval-by-interval limits and opportunities, creating new\nopportunities to reach higher penetration of DERs at a lower cost. With\ntechnological and computational advancements, such an approach is neither out\nof implementation reach nor that computationally expensive. In return, far more\nDER can be interconnected once programmed not to violate certain generation\nprofiles as part of the interconnection requirement, and utilities would be\nbetter informed of their actual operational flexibility, benefiting society\noverall.",
    "descriptor": "",
    "authors": [
      "Narayan Bhusal",
      "Andrija Sadikovic",
      "Mohammed Ben-Idris"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.10551"
  },
  {
    "id": "arXiv:2110.10552",
    "title": "Few-Shot Temporal Action Localization with Query Adaptive Transformer",
    "abstract": "Existing temporal action localization (TAL) works rely on a large number of\ntraining videos with exhaustive segment-level annotation, preventing them from\nscaling to new classes. As a solution to this problem, few-shot TAL (FS-TAL)\naims to adapt a model to a new class represented by as few as a single video.\nExiting FS-TAL methods assume trimmed training videos for new classes. However,\nthis setting is not only unnatural actions are typically captured in untrimmed\nvideos, but also ignores background video segments containing vital contextual\ncues for foreground action segmentation. In this work, we first propose a new\nFS-TAL setting by proposing to use untrimmed training videos. Further, a novel\nFS-TAL model is proposed which maximizes the knowledge transfer from training\nclasses whilst enabling the model to be dynamically adapted to both the new\nclass and each video of that class simultaneously. This is achieved by\nintroducing a query adaptive Transformer in the model. Extensive experiments on\ntwo action localization benchmarks demonstrate that our method can outperform\nall the state of the art alternatives significantly in both single-domain and\ncross-domain scenarios. The source code can be found in\nhttps://github.com/sauradip/fewshotQAT",
    "descriptor": "\nComments: BMVC 2021\n",
    "authors": [
      "Sauradip Nag",
      "Xiatian Zhu",
      "Tao Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.10552"
  },
  {
    "id": "arXiv:2110.10554",
    "title": "Receding Horizon Control in Deep Structured Teams: A Provably Tractable  Large-Scale Approach with Application to Swarm Robotics",
    "abstract": "In this paper, a deep structured tracking problem is introduced for a large\nnumber of decision-makers. The problem is formulated as a linear quadratic deep\nstructured team, where the decision-makers wish to track a global target\ncooperatively while considering their local targets. For the unconstrained\nsetup, the gauge transformation technique is used to decompose the resultant\noptimization problem in order to obtain a low-dimensional optimal control\nstrategy in terms of the local and global Riccati equations. For the\nconstrained case, however, the feasible set is not necessarily decomposable by\nthe gauge transformation. To overcome this hurdle, we propose a family of local\nand global receding horizon control problems, where a carefully constructed\nlinear combination of their solutions provides a feasible solution for the\noriginal constrained problem. The salient property of the above solutions is\nthat they are tractable with respect to the number of decision-makers and can\nbe implemented in a distributed manner. In addition, the main results are\ngeneralized to cases with multiple sub-populations and multiple features,\nincluding leader-follower setup, cohesive cost function and soft structural\nconstraint. Furthermore, a class of cyber-physical attacks is proposed in terms\nof perturbed influence factors. A numerical example is presented to demonstrate\nthe efficacy of the results.",
    "descriptor": "",
    "authors": [
      "Jalal Arabneydi",
      "Amir G. Aghdam"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.10554"
  },
  {
    "id": "arXiv:2110.10555",
    "title": "Why Settle for Just One? Extending EL++ Ontology Embeddings with  Many-to-Many Relationships",
    "abstract": "Knowledge Graph (KG) embeddings provide a low-dimensional representation of\nentities and relations of a Knowledge Graph and are used successfully for\nvarious applications such as question answering and search, reasoning,\ninference, and missing link prediction. However, most of the existing KG\nembeddings only consider the network structure of the graph and ignore the\nsemantics and the characteristics of the underlying ontology that provides\ncrucial information about relationships between entities in the KG. Recent\nefforts in this direction involve learning embeddings for a Description Logic\n(logical underpinning for ontologies) named EL++. However, such methods\nconsider all the relations defined in the ontology to be one-to-one which\nseverely limits their performance and applications. We provide a simple and\neffective solution to overcome this shortcoming that allows such methods to\nconsider many-to-many relationships while learning embedding representations.\nExperiments conducted using three different EL++ ontologies show substantial\nperformance improvement over five baselines. Our proposed solution also paves\nthe way for learning embedding representations for even more expressive\ndescription logics such as SROIQ.",
    "descriptor": "\nComments: The paper got accepted in SemrRec challenge in ISWC 2021\n",
    "authors": [
      "Biswesh Mohapatra",
      "Sumit Bhatia",
      "Raghava Mutharaju",
      "G. Srinivasaraghavan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10555"
  },
  {
    "id": "arXiv:2110.10563",
    "title": "Robust Monocular Localization in Sparse HD Maps Leveraging Multi-Task  Uncertainty Estimation",
    "abstract": "Robust localization in dense urban scenarios using a low-cost sensor setup\nand sparse HD maps is highly relevant for the current advances in autonomous\ndriving, but remains a challenging topic in research. We present a novel\nmonocular localization approach based on a sliding-window pose graph that\nleverages predicted uncertainties for increased precision and robustness\nagainst challenging scenarios and per frame failures. To this end, we propose\nan efficient multi-task uncertainty-aware perception module, which covers\nsemantic segmentation, as well as bounding box detection, to enable the\nlocalization of vehicles in sparse maps, containing only lane borders and\ntraffic lights. Further, we design differentiable cost maps that are directly\ngenerated from the estimated uncertainties. This opens up the possibility to\nminimize the reprojection loss of amorphous map elements in an association free\nand uncertainty-aware manner. Extensive evaluation on the Lyft 5 dataset shows\nthat, despite the sparsity of the map, our approach enables robust and accurate\n6D localization in challenging urban scenarios",
    "descriptor": "",
    "authors": [
      "K\u00fcrsat Petek",
      "Kshitij Sirohi",
      "Daniel B\u00fcscher",
      "Wolfram Burgard"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10563"
  },
  {
    "id": "arXiv:2110.10566",
    "title": "Exploring the Relationship Between \"Positive Risk Balance\" and \"Absence  of Unreasonable Risk\"",
    "abstract": "International discussions on the overarching topic of how to define and\nquantify what a \"safe enough\" Automated Driving System (ADS) is are currently\nhinged on the question of determining the relationship between \"positive risk\nbalance\" (PRB) and \"absence of unreasonable risk\" (AUR). In order to advance\nthe conversation on these important safety topics at the international level,\nit is first important to start from a shared common understanding, grounded in\nclear definitions and terminology. To that end, this paper will start with an\noverview of the notions of PRB and AUR; it will then summarize different\npositions of the present debate; finally, it will conclude that two possible\ninterpretations exist for PRB, and that failure to distinguish them can lead to\nmisunderstanding different parties' positions. The argumentation in this paper\nis aimed at showing that the two interpretations for PRB can actually\ncomplement each other, but can be considered independently, and can both be\nsubsumed within non-prescriptive guidelines toward ADS safety assurance.",
    "descriptor": "",
    "authors": [
      "Francesca Favaro"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.10566"
  },
  {
    "id": "arXiv:2110.10567",
    "title": "Fingerprint recognition with embedded presentation attacks detection:  are we ready?",
    "abstract": "The diffusion of fingerprint verification systems for security applications\nmakes it urgent to investigate the embedding of software-based presentation\nattack detection algorithms (PAD) into such systems. Companies and institutions\nneed to know whether such integration would make the system more \"secure\" and\nwhether the technology available is ready, and, if so, at what operational\nworking conditions. Despite significant improvements, especially by adopting\ndeep learning approaches to fingerprint PAD, current research did not state\nmuch about their effectiveness when embedded in fingerprint verification\nsystems. We believe that the lack of works is explained by the lack of\ninstruments to investigate the problem, that is, modeling the cause-effect\nrelationships when two non-zero error-free systems work together. Accordingly,\nthis paper explores the fusion of PAD into verification systems by proposing a\nnovel investigation instrument: a performance simulator based on the\nprobabilistic modeling of the relationships among the Receiver Operating\nCharacteristics (ROC) of the two individual systems when PAD and verification\nstages are implemented sequentially. As a matter of fact, this is the most\nstraightforward, flexible, and widespread approach. We carry out simulations on\nthe PAD algorithms' ROCs submitted to the most recent editions of LivDet\n(2017-2019), the state-of-the-art NIST Bozorth3, and the top-level Veryfinger\n12 matchers. Reported experiments explore significant scenarios to get the\nconditions under which fingerprint matching with embedded PAD can improve,\nrather than degrade, the overall personal verification performance.",
    "descriptor": "",
    "authors": [
      "Marco Micheletto",
      "Gian Luca Marcialis",
      "Giulia Orr\u00f9",
      "Fabio Roli"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10567"
  },
  {
    "id": "arXiv:2110.10568",
    "title": "Inference Graphs for CNN Interpretation",
    "abstract": "Convolutional neural networks (CNNs) have achieved superior accuracy in many\nvisual related tasks. However, the inference process through intermediate\nlayers is opaque, making it difficult to interpret such networks or develop\ntrust in their operation. We propose to model the network hidden layers\nactivity using probabilistic models. The activity patterns in layers of\ninterest are modeled as Gaussian mixture models, and transition probabilities\nbetween clusters in consecutive modeled layers are estimated. Based on\nmaximum-likelihood considerations, nodes and paths relevant for network\nprediction are chosen, connected, and visualized as an inference graph. We show\nthat such graphs are useful for understanding the general inference process of\na class, as well as explaining decisions the network makes regarding specific\nimages.",
    "descriptor": "",
    "authors": [
      "Yael Konforti",
      "Alon Shpigler",
      "Boaz Lernerand Aharon Bar-Hillel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10568"
  },
  {
    "id": "arXiv:2110.10570",
    "title": "Behavioral Experiments for Understanding Catastrophic Forgetting",
    "abstract": "In this paper we explore whether the fundamental tool of experimental\npsychology, the behavioral experiment, has the power to generate insight not\nonly into humans and animals, but artificial systems too. We apply the\ntechniques of experimental psychology to investigating catastrophic forgetting\nin neural networks. We present a series of controlled experiments with\ntwo-layer ReLU networks, and exploratory results revealing a new understanding\nof the behavior of catastrophic forgetting. Alongside our empirical findings,\nwe demonstrate an alternative, behavior-first approach to investigating neural\nnetwork phenomena.",
    "descriptor": "",
    "authors": [
      "Samuel J. Bell",
      "Neil D. Lawrence"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10570"
  },
  {
    "id": "arXiv:2110.10571",
    "title": "CobotAR: Interaction with Robots using Omnidirectionally Projected Image  and DNN-based Gesture Recognition",
    "abstract": "Several technological solutions supported the creation of interfaces for\nAugmented Reality (AR) multi-user collaboration in the last years. However,\nthese technologies require the use of wearable devices. We present CobotAR - a\nnew AR technology to achieve the Human-Robot Interaction (HRI) by gesture\nrecognition based on Deep Neural Network (DNN) - without an extra wearable\ndevice for the user. The system allows users to have a more intuitive\nexperience with robotic applications using just their hands. The CobotAR system\nassumes the AR spatial display created by a mobile projector mounted on a 6 DoF\nrobot. The proposed technology suggests a novel way of interaction with\nmachines to achieve safe, intuitive, and immersive control mediated by a\nrobotic projection system and DNN-based algorithm. We conducted the experiment\nwith several parameters assessment during this research, which allows the users\nto define the positives and negatives of the new approach. The mental demand of\nCobotAR system is twice less than Wireless Gamepad and by 16\\% less than Teach\nPendant.",
    "descriptor": "\nComments: Accepted paper in SMC conference 2021, IEEE copyright\n",
    "authors": [
      "Nazarova Elena",
      "Sautenkov Oleg",
      "Altamirano Cabrera Miguel",
      "Tirado Jonathan",
      "Serpiva Valerii",
      "Rakhmatulin Viktor",
      "Tsetserukou Dzmitry"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.10571"
  },
  {
    "id": "arXiv:2110.10572",
    "title": "Random-Fuzzy Dual Interpretation of Unknown Quantity for Estimation &  Recognition: with Demonstration of IMM Filter",
    "abstract": "This paper is to consider the problems of estimation and recognition from the\nperspective of sigma-max inference (probability-possibility inference), with a\nfocus on discovering whether some of the unknown quantities involved could be\nmore faithfully modeled as fuzzy uncertainty. Two related key issues are\naddressed: 1) the random-fuzzy dual interpretation of unknown quantity being\nestimated; 2) the principle of selecting sigma-max operator for practical\nproblems, such as estimation and recognition. Our perspective, conceived from\ndefinitions of randomness and fuzziness, is that continuous unknown quantity\ninvolved in estimation with inaccurate prior should be more appropriately\nmodeled as randomness and handled by sigma inference; whereas discrete unknown\nquantity involved in recognition with insufficient (and inaccurate) prior could\nbe better modeled as fuzziness and handled by max inference. The philosophy was\ndemonstrated by an updated version of the well-known interacting multiple model\n(IMM) filter, for which the jump Markovian System is reformulated as a hybrid\nuncertainty system, with continuous state evolution modeled as usual as\nmodel-conditioned stochastic system and discrete mode transitions modeled as\nfuzzy system by a possibility (instead of probability) transition matrix, and\nhypotheses mixing is conducted by using the operation of \"max\" instead of\n\"sigma\". For our example of maneuvering target tracking using simulated data\nfrom both a short-range fire control radar and a long-range surveillance radar,\nthe updated IMM filter shows significant improvement over the classic IMM\nfilter, due to its peculiarity of hard decision of system model and a faster\nresponse to the transition of discrete mode.",
    "descriptor": "\nComments: 15 pages, 11 figures, code available\n",
    "authors": [
      "Wei Mei"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.10572"
  },
  {
    "id": "arXiv:2110.10575",
    "title": "SocialVisTUM: An Interactive Visualization Toolkit for Correlated Neural  Topic Models on Social Media Opinion Mining",
    "abstract": "Recent research in opinion mining proposed word embedding-based topic\nmodeling methods that provide superior coherence compared to traditional topic\nmodeling. In this paper, we demonstrate how these methods can be used to\ndisplay correlated topic models on social media texts using SocialVisTUM, our\nproposed interactive visualization toolkit. It displays a graph with topics as\nnodes and their correlations as edges. Further details are displayed\ninteractively to support the exploration of large text collections, e.g.,\nrepresentative words and sentences of topics, topic and sentiment\ndistributions, hierarchical topic clustering, and customizable, predefined\ntopic labels. The toolkit optimizes automatically on custom data for optimal\ncoherence. We show a working instance of the toolkit on data crawled from\nEnglish social media discussions about organic food consumption. The\nvisualization confirms findings of a qualitative consumer research study.\nSocialVisTUM and its training procedures are accessible online.",
    "descriptor": "\nComments: Demo paper accepted for publication on RANLP 2021; 8 pages, 5 figures, 1 table\n",
    "authors": [
      "Gerhard Hagerer",
      "Martin Kirchhoff",
      "Hannah Danner",
      "Robert Pesch",
      "Mainak Ghosh",
      "Archishman Roy",
      "Jiaxi Zhao",
      "Georg Groh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.10575"
  },
  {
    "id": "arXiv:2110.10577",
    "title": "Overview of the 2021 Key Point Analysis Shared Task",
    "abstract": "We describe the 2021 Key Point Analysis (KPA-2021) shared task on key point\nanalysis that we organized as a part of the 8th Workshop on Argument Mining\n(ArgMining 2021) at EMNLP 2021. We outline various approaches and discuss the\nresults of the shared task. We expect the task and the findings reported in\nthis paper to be relevant for researchers working on text summarization and\nargument mining.",
    "descriptor": "",
    "authors": [
      "Roni Friedman",
      "Lena Dankin",
      "Yufang Hou",
      "Ranit Aharonov",
      "Yoav Katz",
      "Noam Slonim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.10577"
  },
  {
    "id": "arXiv:2110.10580",
    "title": "A Learning Framework for Diffeomorphic Image Registration based on  Quasi-conformal Geometry",
    "abstract": "Image registration, the process of defining meaningful correspondences\nbetween images, is essential for various image analysis tasks, especially\nmedical imaging. Numerous learning-based methods, notably convolutional neural\nnetworks (CNNs), for deformable image registration proposed in recent years\nhave demonstrated the feasibility and superiority of deep learning techniques\nfor registration problems. Besides, compared to traditional algorithms'\noptimization scheme of the objective function for each image pair,\nlearning-based algorithms are several orders of magnitude faster. However,\nthese data-driven methods without proper constraint on the deformation field\nwill easily lead to topological foldings.\nTo tackle this problem, We propose the quasi-conformal registration network\n(QCRegNet), an unsupervised learning framework, to obtain diffeomorphic 2D\nimage registrations with large deformations based on quasi-conformal (QC) map,\nan orientation-preserving homeomorphism between two manifolds.\nThe basic idea is to design a CNN mapping image pairs to deformation fields.\nQCRegNet consists of the estimator network and the Beltrami solver network\n(BSNet). The estimator network takes image pair as input and outputs the\nBeltrami coefficient (BC). The BC, which captures conformal distortion of a QC\nmap and guarantees the bijectivity, will then be input to the BSNet, a\ntask-independent network which reconstructs the desired QC map.\nFurthermore, we reduce the number of network parameters and computational\ncomplexity by utilizing Fourier approximation to compress BC. Experiments have\nbeen carried out on different data such as underwater and medical images.\nRegistration results show that the registration accuracy is comparable to\nstate-of-the-art methods and diffeomorphism is to a great extent guaranteed\ncompared to other diffeomorphic registration algorithms.",
    "descriptor": "",
    "authors": [
      "Qiguang Chen",
      "Zhiwen Li",
      "Lok Ming Lui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10580"
  },
  {
    "id": "arXiv:2110.10582",
    "title": "Distributionally Robust Semi-Supervised Learning Over Graphs",
    "abstract": "Semi-supervised learning (SSL) over graph-structured data emerges in many\nnetwork science applications. To efficiently manage learning over graphs,\nvariants of graph neural networks (GNNs) have been developed recently. By\nsuccinctly encoding local graph structures and features of nodes,\nstate-of-the-art GNNs can scale linearly with the size of graph. Despite their\nsuccess in practice, most of existing methods are unable to handle graphs with\nuncertain nodal attributes. Specifically whenever mismatches between training\nand testing data distribution exists, these models fail in practice. Challenges\nalso arise due to distributional uncertainties associated with data acquired by\nnoisy measurements. In this context, a distributionally robust learning\nframework is developed, where the objective is to train models that exhibit\nquantifiable robustness against perturbations. The data distribution is\nconsidered unknown, but lies within a Wasserstein ball centered around\nempirical data distribution. A robust model is obtained by minimizing the worst\nexpected loss over this ball. However, solving the emerging functional\noptimization problem is challenging, if not impossible. Advocating a strong\nduality condition, we develop a principled method that renders the problem\ntractable and efficiently solvable. Experiments assess the performance of the\nproposed method.",
    "descriptor": "",
    "authors": [
      "Alireza Sadeghi",
      "Meng Ma",
      "Bingcong Li",
      "Georgios B. Giannakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10582"
  },
  {
    "id": "arXiv:2110.10583",
    "title": "Rapid computation of special values of Dirichlet $L$-functions",
    "abstract": "We consider computing the Riemann zeta function $\\zeta(s)$ and Dirichlet\n$L$-functions $L(s,\\chi)$ to $p$-bit accuracy for large $p$. Using the\napproximate functional equation together with asymptotically fast computation\nof the incomplete gamma function, we observe that $p^{3/2+o(1)}$ bit complexity\ncan be achieved if $s$ is an algebraic number of fixed degree and with\nalgebraic height bounded by $O(p)$. This is an improvement over the\n$p^{2+o(1)}$ complexity of previously published algorithms and yields, among\nother things, $p^{3/2+o(1)}$ complexity algorithms for Stieltjes constants and\n$n^{3/2+o(1)}$ complexity algorithms for computing the $n$th Bernoulli number\nor the $n$th Euler number exactly.",
    "descriptor": "",
    "authors": [
      "Fredrik Johansson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Classical Analysis and ODEs (math.CA)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2110.10583"
  },
  {
    "id": "arXiv:2110.10586",
    "title": "Pattern Division Random Access (PDRA) for M2M Communications with  Massive MIMO Systems",
    "abstract": "In this work, we introduce the pattern-domain pilot design paradigm based on\na \"superposition of orthogonal-building-blocks\" with significantly larger\ncontention space to enhance the massive machine-type communications (mMTC)\nrandom access (RA) performance in massive multiple-input multiple-output (MIMO)\nsystems.Specifically, the pattern-domain pilot is constructed based on the\nsuperposition of $L$ cyclically-shifted Zadoff-Chu (ZC) sequences. The\npattern-domain pilots exhibit zero correlation values between non-colliding\npatterns from the same root and low correlation values between patterns from\ndifferent roots. The increased contention space, i.e., from N to\n$\\binom{N}{L}$, where $\\binom{N}{L}$ denotes the number of all L-combinations\nof a set N, and low correlation valueslead to a significantly lower pilot\ncollision probability without compromising excessively on channel estimation\nperformance for mMTC RA in massive MIMO systems.We present the framework and\nanalysis of the RA success probability of the pattern-domain based scheme with\nmassive MIMO systems.Numerical results demonstrate that the proposed pattern\ndivision random access (PDRA) scheme achieves an appreciable performance gain\nover the conventional one,while preserving the existing physical layer\nvirtually unchanged. The extension of the \"superposition of\northogonal-building-blocks\" scheme to \"superposition of\nquasi-orthogonal-building-blocks\" is straightforward.",
    "descriptor": "",
    "authors": [
      "Xiaoming Dai",
      "Tiantian Yan",
      "Qianqian Li",
      "Hua Li",
      "Xiyuan Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2110.10586"
  },
  {
    "id": "arXiv:2110.10593",
    "title": "Time-Domain Mapping Based Single-Channel Speech Separation With  Hierarchical Constraint Training",
    "abstract": "Single-channel speech separation is required for multi-speaker speech\nrecognition. Recent deep learning-based approaches focused on time-domain audio\nseparation net (TasNet) because it has superior performance and lower latency\ncompared to the conventional time-frequency-based (T-F-based) approaches. Most\nof these works rely on the masking-based method that estimates a linear mapping\nfunction (mask) for each speaker. However, the other commonly used method, the\nmapping-based method that is less sensitive to SNR variations, is inadequately\nstudied in the time domain. We explore the potential of the mapping-based\nmethod by introducing attention augmented DPRNN (AttnAugDPRNN) which directly\napproximates the clean sources from the mixture for speech separation.\nPermutation Invariant Training (PIT) has been a paradigm to solve the label\nambiguity problem for speech separation but usually leads to suboptimal\nperformance. To solve this problem, we propose an efficient training strategy\ncalled Hierarchical Constraint Training (HCT) to regularize the training, which\ncould effectively improve the model performance. When using PIT, our results\nshowed that mapping-based AttnAugDPRNN outperformed masking-based AttnAugDPRNN\nwhen the training corpus is large. Mapping-based AttnAugDPRNN with HCT\nsignificantly improved the SI-SDR by 10.1% compared to the masking-based\nAttnAugDPRNN without HCT.",
    "descriptor": "",
    "authors": [
      "Chenyang Gao",
      "Yue Gu",
      "Ivan Marsic"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.10593"
  },
  {
    "id": "arXiv:2110.10596",
    "title": "Look at What I'm Doing: Self-Supervised Spatial Grounding of Narrations  in Instructional Videos",
    "abstract": "We introduce the task of spatially localizing narrated interactions in\nvideos. Key to our approach is the ability to learn to spatially localize\ninteractions with self-supervision on a large corpus of videos with\naccompanying transcribed narrations. To achieve this goal, we propose a\nmultilayer cross-modal attention network that enables effective optimization of\na contrastive loss during training. We introduce a divided strategy that\nalternates between computing inter- and intra-modal attention across the visual\nand natural language modalities, which allows effective training via directly\ncontrasting the two modalities' representations. We demonstrate the\neffectiveness of our approach by self-training on the HowTo100M instructional\nvideo dataset and evaluating on a newly collected dataset of localized\ndescribed interactions in the YouCook2 dataset. We show that our approach\noutperforms alternative baselines, including shallow co-attention and full\ncross-modal attention. We also apply our approach to grounding phrases in\nimages with weak supervision on Flickr30K and show that stacking multiple\nattention layers is effective and, when combined with a word-to-region loss,\nachieves state of the art on recall-at-one and pointing hand accuracies.",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Reuben Tan",
      "Bryan A. Plummer",
      "Kate Saenko",
      "Hailin Jin",
      "Bryan Russell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10596"
  },
  {
    "id": "arXiv:2110.10599",
    "title": "Video Instance Segmentation by Instance Flow Assembly",
    "abstract": "Instance segmentation is a challenging task aiming at classifying and\nsegmenting all object instances of specific classes. While two-stage box-based\nmethods achieve top performances in the image domain, they cannot easily extend\ntheir superiority into the video domain. This is because they usually deal with\nfeatures or images cropped from the detected bounding boxes without alignment,\nfailing to capture pixel-level temporal consistency. We embrace the observation\nthat bottom-up methods dealing with box-free features could offer accurate\nspacial correlations across frames, which can be fully utilized for object and\npixel level tracking. We first propose our bottom-up framework equipped with a\ntemporal context fusion module to better encode inter-frame correlations.\nIntra-frame cues for semantic segmentation and object localization are\nsimultaneously extracted and reconstructed by corresponding decoders after a\nshared backbone. For efficient and robust tracking among instances, we\nintroduce an instance-level correspondence across adjacent frames, which is\nrepresented by a center-to-center flow, termed as instance flow, to assemble\nmessy dense temporal correspondences. Experiments demonstrate that the proposed\nmethod outperforms the state-of-the-art online methods (taking image-level\ninput) on the challenging Youtube-VIS dataset.",
    "descriptor": "",
    "authors": [
      "Xiang Li",
      "Jinglu Wang",
      "Xiao Li",
      "Yan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10599"
  },
  {
    "id": "arXiv:2110.10601",
    "title": "Color Teams for Machine Learning Development",
    "abstract": "Machine learning and software development share processes and methodologies\nfor reliably delivering products to customers. This work proposes the use of a\nnew teaming construct for forming machine learning teams for better combatting\nadversarial attackers. In cybersecurity, infrastructure uses these teams to\nprotect their systems by using system builders and programmers to also offer\nmore robustness to their platforms. Color teams provide clear responsibility to\nthe individuals on each team for which part of the baseline (Yellow), attack\n(Red), and defense (Blue) breakout of the pipeline. Combining colors leads to\nadditional knowledge shared across the team and more robust models built during\ndevelopment. The responsibilities of the new teams Orange, Green, and Purple\nwill be outlined during this paper along with an overview of the necessary\nresources for these teams to be successful.",
    "descriptor": "\nComments: 8 Pages, 6 Figures\n",
    "authors": [
      "Josh Kalin",
      "David Noever",
      "Matthew Ciolino"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.10601"
  },
  {
    "id": "arXiv:2110.10602",
    "title": "Transductive Robust Learning Guarantees",
    "abstract": "We study the problem of adversarially robust learning in the transductive\nsetting. For classes $\\mathcal{H}$ of bounded VC dimension, we propose a simple\ntransductive learner that when presented with a set of labeled training\nexamples and a set of unlabeled test examples (both sets possibly adversarially\nperturbed), it correctly labels the test examples with a robust error rate that\nis linear in the VC dimension and is adaptive to the complexity of the\nperturbation set. This result provides an exponential improvement in dependence\non VC dimension over the best known upper bound on the robust error in the\ninductive setting, at the expense of competing with a more restrictive notion\nof optimal robust error.",
    "descriptor": "",
    "authors": [
      "Omar Montasser",
      "Steve Hanneke",
      "Nathan Srebro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.10602"
  },
  {
    "id": "arXiv:2110.10603",
    "title": "Uncovering In-DRAM RowHammer Protection Mechanisms: A New Methodology,  Custom RowHammer Patterns, and Implications",
    "abstract": "The RowHammer vulnerability in DRAM is a critical threat to system security.\nTo protect against RowHammer, vendors commit to security-through-obscurity:\nmodern DRAM chips rely on undocumented, proprietary, on-die mitigations,\ncommonly known as Target Row Refresh (TRR). At a high level, TRR detects and\nrefreshes potential RowHammer-victim rows, but its exact implementations are\nnot openly disclosed. Security guarantees of TRR mechanisms cannot be easily\nstudied due to their proprietary nature.\nTo assess the security guarantees of recent DRAM chips, we present Uncovering\nTRR (U-TRR), an experimental methodology to analyze in-DRAM TRR\nimplementations. U-TRR is based on the new observation that data retention\nfailures in DRAM enable a side channel that leaks information on how TRR\nrefreshes potential victim rows. U-TRR allows us to (i) understand how logical\nDRAM rows are laid out physically in silicon; (ii) study undocumented on-die\nTRR mechanisms; and (iii) combine (i) and (ii) to evaluate the RowHammer\nsecurity guarantees of modern DRAM chips. We show how U-TRR allows us to craft\nRowHammer access patterns that successfully circumvent the TRR mechanisms\nemployed in 45 DRAM modules of the three major DRAM vendors. We find that the\nDRAM modules we analyze are vulnerable to RowHammer, having bit flips in up to\n99.9% of all DRAM rows.",
    "descriptor": "\nComments: This work is to appear at the 54th IEEE/ACM International Symposium on Microarchitecture (MICRO 2021)\n",
    "authors": [
      "Hasan Hassan",
      "Yahya Can Tugrul",
      "Jeremie S. Kim",
      "Victor van der Veen",
      "Kaveh Razavi",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2110.10603"
  },
  {
    "id": "arXiv:2110.10606",
    "title": "Maximal Information Propagation via Lotteries",
    "abstract": "Propagating information to more people through their friends is becoming an\nincreasingly important technology used in domains such as blockchain,\nadvertising, and social media. To incentivize people to broadcast the\ninformation, the designer may use a monetary rewarding scheme, which specifies\nwho gets how much, to compensate for the propagation. Several properties are\ndesirable for the rewarding scheme, such as budget feasible, individually\nrational, incentive compatible, and Sybil-proof. In this work, we design a free\nmarket with lotteries, where every participant can decide by herself how much\nof the reward she wants to withhold before propagating to others. We show that\nin the free market, the participants have a strong incentive to maximally\npropagate the information and all the above properties are satisfied\nautomatically.",
    "descriptor": "",
    "authors": [
      "Jing Chen",
      "Bo Li"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.10606"
  },
  {
    "id": "arXiv:2110.10611",
    "title": "Analysis of pressure-robust embedded-hybridized discontinuous Galerkin  methods for the Stokes problem under minimal regularity",
    "abstract": "We present analysis of two lowest-order hybridizable discontinuous Galerkin\nmethods for the Stokes problem, while making only minimal regularity\nassumptions on the exact solution. The methods under consideration have\npreviously been shown to produce $H(\\textrm{div})$-conforming and\ndivergence-free approximate velocities. Using these properties, we derive a\npriori error estimates for the velocity that are independent of the pressure.\nThese error estimates, which assume only $H^{1+s}$-regularity of the exact\nvelocity fields for any $s \\in [0, 1]$, are optimal in a discrete energy norm.\nError estimates for the velocity and pressure in the $L^2$-norm are also\nderived in this minimal regularity setting. Our theoretical findings are\nsupported by numerical computations.",
    "descriptor": "",
    "authors": [
      "Aaron Baier-Reinio",
      "Sander Rhebergen",
      "Garth N. Wells"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.10611"
  },
  {
    "id": "arXiv:2110.10614",
    "title": "Independent Natural Policy Gradient Always Converges in Markov Potential  Games",
    "abstract": "Multi-agent reinforcement learning has been successfully applied to\nfully-cooperative and fully-competitive environments, but little is currently\nknown about mixed cooperative/competitive environments. In this paper, we focus\non a particular class of multi-agent mixed cooperative/competitive stochastic\ngames called Markov Potential Games (MPGs), which include cooperative games as\na special case. Recent results have shown that independent policy gradient\nconverges in MPGs but it was not known whether Independent Natural Policy\nGradient converges in MPGs as well. We prove that Independent Natural Policy\nGradient always converges in the last iterate using constant learning rates.\nThe proof deviates from the existing approaches and the main challenge lies in\nthe fact that Markov Potential Games do not have unique optimal values (as\nsingle-agent settings exhibit) so different initializations can lead to\ndifferent limit point values. We complement our theoretical results with\nexperiments that indicate that Natural Policy Gradient outperforms Policy\nGradient in routing games and congestion games.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Roy Fox",
      "Stephen McAleer",
      "Will Overman",
      "Ioannis Panageas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.10614"
  },
  {
    "id": "arXiv:2110.10617",
    "title": "Colosseum: Large-Scale Wireless Experimentation Through  Hardware-in-the-Loop Network Emulation",
    "abstract": "Colosseum is an open-access and publicly-available large-scale wireless\ntestbed for experimental research via virtualized and softwarized waveforms and\nprotocol stacks on a fully programmable, \"white-box\" platform. Through 256\nstate-of-the-art Software-defined Radios and a Massive Channel Emulator core,\nColosseum can model virtually any scenario, enabling the design, development\nand testing of solutions at scale in a variety of deployments and channel\nconditions. These Colosseum radio-frequency scenarios are reproduced through\nhigh-fidelity FPGA-based emulation with finite-impulse response filters.\nFilters model the taps of desired wireless channels and apply them to the\nsignals generated by the radio nodes, faithfully mimicking the conditions of\nreal-world wireless environments. In this paper we describe the architecture of\nColosseum and its experimentation and emulation capabilities. We then\ndemonstrate the effectiveness of Colosseum for experimental research at scale\nthrough exemplary use cases including prevailing wireless technologies (e.g.,\ncellular and Wi-Fi) in spectrum sharing and unmanned aerial vehicle scenarios.\nA roadmap for Colosseum future updates concludes the paper.",
    "descriptor": "",
    "authors": [
      "Leonardo Bonati",
      "Pedram Johari",
      "Michele Polese",
      "Salvatore D'Oro",
      "Subhramoy Mohanti",
      "Miead Tehrani-Moayyed",
      "Davide Villa",
      "Shweta Shrivastava",
      "Chinenye Tassie",
      "Kurt Yoder",
      "Ajeet Bagga",
      "Paresh Patel",
      "Ventz Petkov",
      "Michael Seltser",
      "Francesco Restuccia",
      "Abhimanyu Gosain",
      "Kaushik R. Chowdhury",
      "Stefano Basagni",
      "Tommaso Melodia"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.10617"
  },
  {
    "id": "arXiv:2110.10623",
    "title": "Chaos inspired Particle Swarm Optimization with Levy Flight for Genome  Sequence Assembly",
    "abstract": "With the advent of Genome Sequencing, the field of Personalized Medicine has\nbeen revolutionized. From drug testing and studying diseases and mutations to\nclan genomics, studying the genome is required. However, genome sequence\nassembly is a very complex combinatorial optimization problem of computational\nbiology. PSO is a popular meta-heuristic swarm intelligence optimization\nalgorithm, used to solve combinatorial optimization problems. In this paper, we\npropose a new variant of PSO to address this permutation-optimization problem.\nPSO is integrated with the Chaos and Levy Flight (A random walk algorithm) to\neffectively balance the exploration and exploitation capability of the\nalgorithm. Empirical experiments are conducted to evaluate the performance of\nthe proposed method in comparison to the other variants of the PSO proposed in\nthe literature. The analysis is conducted on four DNA coverage datasets. The\nconducted analysis demonstrates that the proposed model attain a better\nperformance with better reliability and consistency in comparison to other\ncompetitive methods in all cases.",
    "descriptor": "\nComments: 18 pages, 10 figures, 3 tables\n",
    "authors": [
      "Sehej Jain",
      "Kusum Kumari Bharti"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.10623"
  },
  {
    "id": "arXiv:2110.10628",
    "title": "PyPSA meets Africa: Developing an open source electricity network model  of the African continent",
    "abstract": "Electricity network modelling and grid simulations form a key enabling\nelement for the integration of newer and cleaner technologies such as renewable\nenergy generation and electric vehicles into the existing grid and energy\nsystem infrastructure. This paper reviews the models of the African electricity\nsystems and highlights the gaps in the open model landscape. Using PyPSA (an\nopen Power System Analysis package), the paper outlines the pathway to a fully\nopen model and data to increase the transparency in the African electricity\nsystem planning. Optimisation and modelling can reveal viable pathways to a\nsustainable energy system, aiding strategic planning for upgrades and\npolicy-making for accelerated integration of renewable energy generation and\nsmart grid technologies such as battery storage in Africa.",
    "descriptor": "",
    "authors": [
      "Desen Kirli",
      "Johannes Hampp",
      "Koen van Greevenboek",
      "Rebecca Grant",
      "Matin Mahmood",
      "Maximilian Parzen",
      "Aristides Kiprakis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.10628"
  },
  {
    "id": "arXiv:2110.10632",
    "title": "More Efficient Exploration with Symbolic Priors on Action Sequence  Equivalences",
    "abstract": "Incorporating prior knowledge in reinforcement learning algorithms is mainly\nan open question. Even when insights about the environment dynamics are\navailable, reinforcement learning is traditionally used in a tabula rasa\nsetting and must explore and learn everything from scratch. In this paper, we\nconsider the problem of exploiting priors about action sequence equivalence:\nthat is, when different sequences of actions produce the same effect. We\npropose a new local exploration strategy calibrated to minimize collisions and\nmaximize new state visitations. We show that this strategy can be computed at\nlittle cost, by solving a convex optimization problem. By replacing the usual\nepsilon-greedy strategy in a DQN, we demonstrate its potential in several\nenvironments with various dynamic structures.",
    "descriptor": "",
    "authors": [
      "Toby Johnstone",
      "Nathan Grinsztajn",
      "Johan Ferret",
      "Philippe Preux"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10632"
  },
  {
    "id": "arXiv:2110.10639",
    "title": "Semi-supervised Domain Adaptation for Semantic Segmentation",
    "abstract": "Deep learning approaches for semantic segmentation rely primarily on\nsupervised learning approaches and require substantial efforts in producing\npixel-level annotations. Further, such approaches may perform poorly when\napplied to unseen image domains. To cope with these limitations, both\nunsupervised domain adaptation (UDA) with full source supervision but without\ntarget supervision and semi-supervised learning (SSL) with partial supervision\nhave been proposed. While such methods are effective at aligning different\nfeature distributions, there is still a need to efficiently exploit unlabeled\ndata to address the performance gap with respect to fully-supervised methods.\nIn this paper we address semi-supervised domain adaptation (SSDA) for semantic\nsegmentation, where a large amount of labeled source data as well as a small\namount of labeled target data are available. We propose a novel and effective\ntwo-step semi-supervised dual-domain adaptation (SSDDA) approach to address\nboth cross- and intra-domain gaps in semantic segmentation. The proposed\nframework is comprised of two mixing modules. First, we conduct a cross-domain\nadaptation via an image-level mixing strategy, which learns to align the\ndistribution shift of features between the source data and target data. Second,\nintra-domain adaptation is achieved using a separate student-teacher network\nwhich is built to generate category-level data augmentation by mixing unlabeled\ntarget data in a way that respects predicted object boundaries. We demonstrate\nthat the proposed approach outperforms state-of-the-art methods on two common\nsynthetic-to-real semantic segmentation benchmarks. An extensive ablation study\nis provided to further validate the effectiveness of our approach.",
    "descriptor": "",
    "authors": [
      "Ying Chen",
      "Xu Ouyang",
      "Kaiyue Zhu",
      "Gady Agam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10639"
  },
  {
    "id": "arXiv:2110.10641",
    "title": "Anaphora and Ellipsis in Lambek Calculus with a Relevant Modality:  Syntax and Semantics",
    "abstract": "Lambek calculus with a relevant modality $!\\mathbf{L^*}$ of arXiv:1601.06303\nsyntactically resolves parasitic gaps in natural language. It resembles the\nLambek calculus with anaphora $\\mathbf{LA}$ of (J\\\"ager, 1998) and the Lambek\ncalculus with controlled contraction, $\\mathbf{L}_{\\Diamond}$, of\narXiv:1905.01647v1 which deal with anaphora and ellipsis. What all these\ncalculi add to Lambek calculus is a copying and moving behaviour.\nDistributional semantics is a subfield of Natural Language Processing that uses\nvector space semantics for words via co-occurrence statistics in large corpora\nof data. Compositional vector space semantics for Lambek Calculi are obtained\nvia the DisCoCat models arXiv:1003.4394v1. $\\mathbf{LA}$ does not have a vector\nspace semantics and the semantics of $\\mathbf{L}_{\\Diamond}$ is not\ncompositional. Previously, we developed a DisCoCat semantics for\n$!\\mathbf{L^*}$ and focused on the parasitic gap applications. In this paper,\nwe use the vector space instance of that general semantics and show how one can\nalso interpret anaphora, ellipsis, and for the first time derive the sloppy vs\nstrict vector readings of ambiguous anaphora with ellipsis cases. The base of\nour semantics is tensor algebras and their finite dimensional variants: the\nFermionic Fock spaces of Quantum Mechanics. We implement our model and\nexperiment with the ellipsis disambiguation task of arXiv:1905.01647.",
    "descriptor": "",
    "authors": [
      "Lachlan McPheat",
      "Gijs Wijnholds",
      "Mehrnoosh Sadrzadeh",
      "Adriana Correia",
      "Alexis Toumi"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.10641"
  },
  {
    "id": "arXiv:2110.10655",
    "title": "Adversarial Socialbot Learning via Multi-Agent Deep Hierarchical  Reinforcement Learning",
    "abstract": "Socialbots are software-driven user accounts on social platforms, acting\nautonomously (mimicking human behavior), with the aims to influence the\nopinions of other users or spread targeted misinformation for particular goals.\nAs socialbots undermine the ecosystem of social platforms, they are often\nconsidered harmful. As such, there have been several computational efforts to\nauto-detect the socialbots. However, to our best knowledge, the adversarial\nnature of these socialbots has not yet been studied. This begs a question \"can\nadversaries, controlling socialbots, exploit AI techniques to their advantage?\"\nTo this question, we successfully demonstrate that indeed it is possible for\nadversaries to exploit computational learning mechanism such as reinforcement\nlearning (RL) to maximize the influence of socialbots while avoiding being\ndetected. We first formulate the adversarial socialbot learning as a\ncooperative game between two functional hierarchical RL agents. While one agent\ncurates a sequence of activities that can avoid the detection, the other agent\naims to maximize network influence by selectively connecting with right users.\nOur proposed policy networks train with a vast amount of synthetic graphs and\ngeneralize better than baselines on unseen real-life graphs both in terms of\nmaximizing network influence (up to +18%) and sustainable stealthiness (up to\n+40% undetectability) under a strong bot detector (with 90% detection\naccuracy). During inference, the complexity of our approach scales linearly,\nindependent of a network's structure and the virality of news. This makes our\napproach a practical adversarial attack when deployed in a real-life setting.",
    "descriptor": "",
    "authors": [
      "Thai Le",
      "Long Tran-Thanh",
      "Dongwon Lee"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.10655"
  },
  {
    "id": "arXiv:2110.10659",
    "title": "OMB-Py: Python Micro-Benchmarks for Evaluating Performance of MPI  Libraries on HPC Systems",
    "abstract": "Python has become a dominant programming language for emerging areas like\nMachine Learning (ML), Deep Learning (DL), and Data Science (DS). An attractive\nfeature of Python is that it provides easy-to-use programming interface while\nallowing library developers to enhance performance of their applications by\nharnessing the computing power offered by High Performance Computing (HPC)\nplatforms. Efficient communication is key to scaling applications on parallel\nsystems, which is typically enabled by the Message Passing Interface (MPI)\nstandard and compliant libraries on HPC hardware. mpi4py is a Python-based\ncommunication library that provides an MPI-like interface for Python\napplications allowing application developers to utilize parallel processing\nelements including GPUs. However, there is currently no benchmark suite to\nevaluate communication performance of mpi4py -- and Python MPI codes in general\n-- on modern HPC systems. In order to bridge this gap, we propose OMB-Py --\nPython extensions to the open-source OSU Micro-Benchmark (OMB) suite -- aimed\nto evaluate communication performance of MPI-based parallel applications in\nPython. To the best of our knowledge, OMB-Py is the first communication\nbenchmark suite for parallel Python applications. OMB-Py consists of a variety\nof point-to-point and collective communication benchmark tests that are\nimplemented for a range of popular Python libraries including NumPy, CuPy,\nNumba, and PyCUDA. We also provide Python implementation for several\ndistributed ML algorithms as benchmarks to understand the potential gain in\nperformance for ML/DL workloads. Our evaluation reveals that mpi4py introduces\na small overhead when compared to native MPI libraries. We also evaluate the\nML/DL workloads and report up to 106x speedup on 224 CPU cores compared to\nsequential execution. We plan to publicly release OMB-Py to benefit Python HPC\ncommunity.",
    "descriptor": "",
    "authors": [
      "Nawras Alnaasan",
      "Arpan Jain",
      "Aamir Shafi",
      "Hari Subramoni",
      "Dhabaleswar K Panda"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10659"
  },
  {
    "id": "arXiv:2110.10660",
    "title": "Event-triggered Control for Nonlinear Systems with Center Manifolds",
    "abstract": "In this work, we consider the problem of event-triggered implementation of\ncontrol laws designed for the local stabilization of nonlinear systems with\ncenter manifolds. We propose event-triggering conditions which are derived from\na local input-to-state stability characterization of such systems. The\ntriggering conditions ensure local ultimate boundedness of the trajectories and\nthe existence of a uniform positive lower bound for the inter-event times. The\nultimate bound can be made arbitrarily small, but by allowing for smaller\ninter-event times. Under certain assumptions on the controller structure, local\nasymptotic stability of the origin is also guaranteed. Two sets of triggering\nconditions are proposed, that cater to the cases where the exact center\nmanifold and only an approximation of the center manifold is computable. The\nclosed-loop system exhibits some desirable properties when the exact knowledge\nof the center manifold is employed in checking the triggering conditions. Three\nillustrative examples that explore different scenarios are presented and the\napplicability of the proposed methods is demonstrated. The third example\nconcerns the event-triggered implementation of a position stabilizing\ncontroller for the open-loop unstable Mobile Inverted Pendulum (MIP) robot.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Automatic Control as a Full paper (Under review). 16 Pages, 4 Figures\n",
    "authors": [
      "Akshit Saradagi",
      "Vijay Muralidharan",
      "Arun D. Mahindrakar",
      "Pavankumar Tallapragada"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.10660"
  },
  {
    "id": "arXiv:2110.10661",
    "title": "SILG: The Multi-environment Symbolic Interactive Language Grounding  Benchmark",
    "abstract": "Existing work in language grounding typically study single environments. How\ndo we build unified models that apply across multiple environments? We propose\nthe multi-environment Symbolic Interactive Language Grounding benchmark (SILG),\nwhich unifies a collection of diverse grounded language learning environments\nunder a common interface. SILG consists of grid-world environments that require\ngeneralization to new dynamics, entities, and partially observed worlds (RTFM,\nMessenger, NetHack), as well as symbolic counterparts of visual worlds that\nrequire interpreting rich natural language with respect to complex scenes\n(ALFWorld, Touchdown). Together, these environments provide diverse grounding\nchallenges in richness of observation space, action space, language\nspecification, and plan complexity. In addition, we propose the first shared\nmodel architecture for RL on these environments, and evaluate recent advances\nsuch as egocentric local convolution, recurrent state-tracking, entity-centric\nattention, and pretrained LM using SILG. Our shared architecture achieves\ncomparable performance to environment-specific architectures. Moreover, we find\nthat many recent modelling advances do not result in significant gains on\nenvironments other than the one they were designed for. This highlights the\nneed for a multi-environment benchmark. Finally, the best models significantly\nunderperform humans on SILG, which suggests ample room for future work. We hope\nSILG enables the community to quickly identify new methodologies for language\ngrounding that generalize to a diverse set of environments and their associated\nchallenges.",
    "descriptor": "\nComments: NeurIPS 2021. 14 pages, 8 figures\n",
    "authors": [
      "Victor Zhong",
      "Austin W. Hanjie",
      "Sida I. Wang",
      "Karthik Narasimhan",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10661"
  },
  {
    "id": "arXiv:2110.10666",
    "title": "Efficient Consensus-Free Weight Reassignment for Atomic Storage",
    "abstract": "Weighted voting is a conventional approach to improving the performance of\nreplicated systems based on commonly-used majority quorum systems in\nheterogeneous environments. In long-lived systems, a weight reassignment\nprotocol is required to reassign weights over time in order to accommodate\nperformance variations accordingly. The weight reassignment protocol should be\nconsensus-free in asynchronous failure-prone systems because of the\nimpossibility of solving consensus in such systems. This paper presents an\nefficient consensus-free weight reassignment protocol for atomic storage\nsystems in heterogeneous, dynamic, and asynchronous message-passing systems. An\nexperimental evaluation shows that the proposed protocol improves the\nperformance of atomic read/write storage implemented by majority quorum systems\ncompared with previous solutions.",
    "descriptor": "",
    "authors": [
      "Hasan Heydari",
      "Guthemberg Silvestre",
      "Luciana Arantes"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.10666"
  },
  {
    "id": "arXiv:2110.10668",
    "title": "Evaluating the Evaluation Metrics for Style Transfer: A Case Study in  Multilingual Formality Transfer",
    "abstract": "While the field of style transfer (ST) has been growing rapidly, it has been\nhampered by a lack of standardized practices for automatic evaluation. In this\npaper, we evaluate leading ST automatic metrics on the oft-researched task of\nformality style transfer. Unlike previous evaluations, which focus solely on\nEnglish, we expand our focus to Brazilian-Portuguese, French, and Italian,\nmaking this work the first multilingual evaluation of metrics in ST. We outline\nbest practices for automatic evaluation in (formality) style transfer and\nidentify several models that correlate well with human judgments and are robust\nacross languages. We hope that this work will help accelerate development in\nST, where human evaluation is often challenging to collect.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Eleftheria Briakou",
      "Sweta Agrawal",
      "Joel Tetreault",
      "Marine Carpuat"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.10668"
  },
  {
    "id": "arXiv:2110.10674",
    "title": "SEA: Graph Shell Attention in Graph Neural Networks",
    "abstract": "A common issue in Graph Neural Networks (GNNs) is known as over-smoothing. By\nincreasing the number of iterations within the message-passing of GNNs, the\nnodes' representations of the input graph align with each other and become\nindiscernible. Recently, it has been shown that increasing a model's complexity\nby integrating an attention mechanism yields more expressive architectures.\nThis is majorly contributed to steering the nodes' representations only towards\nnodes that are more informative than others. Transformer models in combination\nwith GNNs result in architectures including Graph Transformer Layers (GTL),\nwhere layers are entirely based on the attention operation. However, the\ncalculation of a node's representation is still restricted to the computational\nworking flow of a GNN. In our work, we relax the GNN architecture by means of\nimplementing a routing heuristic. Specifically, the nodes' representations are\nrouted to dedicated experts. Each expert calculates the representations\naccording to their respective GNN workflow. The definitions of distinguishable\nGNNs result from k-localized views starting from the central node. We call this\nprocedure Graph Shell Attention (SEA), where experts process different\nsubgraphs in a transformer-motivated fashion. Intuitively, by increasing the\nnumber of experts, the models gain in expressiveness such that a node's\nrepresentation is solely based on nodes that are located within the receptive\nfield of an expert. We evaluate our architecture on various benchmark datasets\nshowing competitive results compared to state-of-the-art models.",
    "descriptor": "",
    "authors": [
      "Christian M.M. Frey",
      "Yunpu Ma",
      "Matthias Schubert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10674"
  },
  {
    "id": "arXiv:2110.10678",
    "title": "Resilient Time-Varying Formation Tracking for Mobile Robot Networks  under Deception Attacks on Positioning",
    "abstract": "This paper investigates the resilient control, analysis, recovery, and\noperation of mobile robot networks in time-varying formation tracking under\ndeception attacks on global positioning. Local and global tracking control\nalgorithms are presented to ensure redundancy of the mobile robot network and\nto retain the desired functionality for better resilience. Lyapunov stability\nanalysis is utilized to show the boundedness of the formation tracking error\nand the stability of the network under various attack modes. A performance\nindex is designed to compare the efficiency of the proposed formation tracking\nalgorithms in situations with or without positioning attacks. Subsequently, a\ncommunication-free decentralized cooperative localization approach based on\nextended information filters is presented for positioning estimate recovery\nwhere the identification of the positioning attacks is based on\nKullback-Leibler divergence. A gain-tuning resilient operation is proposed to\nstrategically synthesize the formation control and cooperative localization for\naccurate and rapid system recovery from positioning attacks. The proposed\nmethods are tested using both numerical simulation and experimental validation\nwith a team of quadrotors.",
    "descriptor": "\nComments: 12 pages, 13 figures\n",
    "authors": [
      "Yen-Chen Liu",
      "Kai-Yuan Liu",
      "Zhuoyuan Song"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.10678"
  },
  {
    "id": "arXiv:2110.10679",
    "title": "Using a market basket analysis in tourism studies",
    "abstract": "Understanding tourist visitation patterns is crucial for decision makers in\norder to create smart tourism industry. A growing body of tourism research uses\ngeo-location data in order to better understand tourism demand. In this paper,\nwe present a new approach based on a market basket analysis. This approach uses\ngeo-location data shared by tourists on tourism platforms in order to bundle\nthe range of available tourism services and understand which experiences are\nconsumed together. The approach was tested on the case of Vienna, Austria.\nBased on our analyses we argue that the proposed approach has potential for use\nat the destination level and provides relevant information on tourism demand\npatterns important for smart tourism decision-making.",
    "descriptor": "\nComments: 36 pages, 8 figures\n",
    "authors": [
      "Damjan Vavpoti\u010d",
      "Karmen Knavs",
      "Ljubica Kne\u017eevi\u0107 Cvelbar"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.10679"
  },
  {
    "id": "arXiv:2110.10704",
    "title": "A Self-Explainable Stylish Image Captioning Framework via  Multi-References",
    "abstract": "In this paper, we propose to build a stylish image captioning model through a\nMulti-style Multi modality mechanism (2M). We demonstrate that with 2M, we can\nbuild an effective stylish captioner and that multi-references produced by the\nmodel can also support explaining the model through identifying erroneous input\nfeatures on faulty examples. We show how this 2M mechanism can be used to build\nstylish captioning models and show how these models can be utilized to provide\nexplanations of likely errors in the models.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2103.11186\n",
    "authors": [
      "Chengxi Li",
      "Brent Harrison"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.10704"
  },
  {
    "id": "arXiv:2110.10713",
    "title": "PPFS: Predictive Permutation Feature Selection",
    "abstract": "We propose Predictive Permutation Feature Selection (PPFS), a novel\nwrapper-based feature selection method based on the concept of Markov Blanket\n(MB). Unlike previous MB methods, PPFS is a universal feature selection\ntechnique as it can work for both classification as well as regression tasks on\ndatasets containing categorical and/or continuous features. We propose\nPredictive Permutation Independence (PPI), a new Conditional Independence (CI)\ntest, which enables PPFS to be categorised as a wrapper feature selection\nmethod. This is in contrast to current filter based MB feature selection\ntechniques that are unable to harness the advancements in supervised algorithms\nsuch as Gradient Boosting Machines (GBM). The PPI test is based on the knockoff\nframework and utilizes supervised algorithms to measure the association between\nan individual or a set of features and the target variable. We also propose a\nnovel MB aggregation step that addresses the issue of sample inefficiency.\nEmpirical evaluations and comparisons on a large number of datasets demonstrate\nthat PPFS outperforms state-of-the-art Markov blanket discovery algorithms as\nwell as, well-known wrapper methods. We also provide a sketch of the proof of\ncorrectness of our method. Implementation of this work is available at\n\\url{https://github.com/atif-hassan/PyImpetus}",
    "descriptor": "\nComments: 7 pages. For the implementation of this work, see this https URL\n",
    "authors": [
      "Atif Hassan",
      "Jiaul H. Paik",
      "Swanand Khare",
      "Syed Asif Hassan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10713"
  },
  {
    "id": "arXiv:2110.10714",
    "title": "Auction Design through Multi-Agent Learning in Peer-to-Peer Energy  Trading",
    "abstract": "Distributed energy resources (DERs), such as rooftop solar panels, are\ngrowing rapidly and are reshaping power systems. To promote DERs,\nfeed-in-tariff (FIT) is usually adopted by utilities to pay DER owners certain\nfixed rates for supplying energy to the grid. An alternative to FIT is a\nmarket-based approach; that is, consumers and DER owners trade energy in an\nauction-based peer-to-peer (P2P) market, and the rates are determined based on\nsupply and demand. However, the auction complexity and market participants'\nbounded rationality may invalidate many well-established theories on auction\ndesign and hinder market development. To address the challenges, we propose an\nautomated bidding framework based on multi-agent, multi-armed bandit learning\nfor repeated auctions, which aims to minimize each bidder's cumulative regret.\nNumerical results indicate convergence of such a multi-agent learning game to a\nsteady-state. Being particularly interested in auction designs, we have applied\nthe framework to four different implementations of repeated double-side\nauctions to compare their market outcomes. While it is difficult to pick a\nclear winner, $k$-double auction (a variant of uniform pricing auction) and\nMcAfee auction (a variant of Vickrey double-auction) appear to perform well in\ngeneral, with their respective strengths and weaknesses.",
    "descriptor": "",
    "authors": [
      "Zibo Zhao",
      "Chen Feng",
      "Andrew L. Lu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.10714"
  },
  {
    "id": "arXiv:2110.10718",
    "title": "Bootstrapping confidence in future safety based on past safe operation",
    "abstract": "With autonomous vehicles (AVs), a major concern is the inability to give\nmeaningful quantitative assurance of safety, to the extent required by society\n- e.g. that an AV must be at least as safe as a good human driver - before that\nAV is in extensive use. We demonstrate an approach to achieving more moderate,\nbut useful, confidence, e.g., confidence of low enough probability of causing\naccidents in the early phases of operation. This formalises mathematically the\ncommon approach of operating a system on a limited basis in the hope that\nmishap-free operation will confirm one's confidence in its safety and allow\nprogressively more extensive operation: a process of \"bootstrapping\" of\nconfidence. Translating that intuitive approach into theorems shows: (1) that\nit is substantially sound in the right circumstances, and could be a good\nmethod for deciding about the early deployment phase for an AV; (2) how much\nconfidence can be rightly derived from such a \"cautious deployment\" approach,\nso that we can avoid over-optimism; (3) under which conditions our sound\nformulas for future confidence are applicable; (4) thus, which analyses of the\nconcrete situations, and/or constraints on practice, are needed in order to\nenjoy the advantages of provably correct confidence in adequate future safety.",
    "descriptor": "\nComments: 15 pages, 3 figures\n",
    "authors": [
      "Peter Bishop",
      "Andrey Povyakalo",
      "Lorenzo Strigini"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.10718"
  },
  {
    "id": "arXiv:2110.10720",
    "title": "Privacy in Open Search: A Review of Challenges and Solutions",
    "abstract": "Privacy is of worldwide concern regarding activities and processes that\ninclude sensitive data. For this reason, many countries and territories have\nbeen recently approving regulations controlling the extent to which\norganizations may exploit data provided by people. Artificial intelligence\nareas, such as machine learning and natural language processing, have already\nsuccessfully employed privacy-preserving mechanisms in order to safeguard data\nprivacy in a vast number of applications. Information retrieval (IR) is\nlikewise prone to privacy threats, such as attacks and unintended disclosures\nof documents and search history, which may cripple the security of users and be\npenalized by data protection laws. This work aims at highlighting and\ndiscussing open challenges for privacy in the recent literature of IR, focusing\non tasks featuring user-generated text data. Our contribution is threefold:\nfirstly, we present an overview of privacy threats to IR tasks; secondly, we\ndiscuss applicable privacy-preserving mechanisms which may be employed in\nsolutions to restrain privacy hazards; finally, we bring insights on the\ntradeoffs between privacy preservation and utility performance for IR tasks.",
    "descriptor": "\nComments: Paper accepted at OSSYM 2021 - Third International Open Search Symposium\n",
    "authors": [
      "Samuel Sousa",
      "Roman Kern",
      "Christian Guetl"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.10720"
  },
  {
    "id": "arXiv:2110.10725",
    "title": "An Invariance Principle for the Multi-slice, with Applications",
    "abstract": "Given an alphabet size $m\\in\\mathbb{N}$ thought of as a constant, and\n$\\vec{k} = (k_1,\\ldots,k_m)$ whose entries sum of up $n$, the\n$\\vec{k}$-multi-slice is the set of vectors $x\\in [m]^n$ in which each symbol\n$i\\in [m]$ appears precisely $k_i$ times. We show an invariance principle for\nlow-degree functions over the multi-slice, to functions over the product space\n$([m]^n,\\mu^n)$ in which $\\mu(i) = k_i/n$. This answers a question raised by\nFilmus et al.\nAs applications of the invariance principle, we show:\n1. An analogue of the \"dictatorship test implies computational hardness\"\nparadigm for problems with perfect completeness, for a certain class of\ndictatorship tests. Our computational hardness is proved assuming a recent\nstrengthening of the Unique-Games Conjecture, called the Rich $2$-to-$1$ Games\nConjecture. Using this analogue, we show that assuming the Rich $2$-to-$1$\nGames Conjecture, (a) there is an $r$-ary CSP $\\mathcal{P}_r$ for which it is\nNP-hard to distinguish satisfiable instances of the CSP and instances that are\nat most $\\frac{2r+1}{2^r} + o(1)$ satisfiable, and (b) hardness of\ndistinguishing $3$-colorable graphs, and graphs that do not contain an\nindependent set of size $o(1)$.\n2. A reduction of the problem of studying expectations of products of\nfunctions on the multi-slice to studying expectations of products of functions\non correlated, product spaces. In particular, we are able to deduce analogues\nof the Gaussian bounds from \\cite{MosselGaussian} for the multi-slice.\n3. In a companion paper, we show further applications of our invariance\nprinciple in extremal combinatorics, and more specifically to proving removal\nlemmas of a wide family of hypergraphs $H$ called $\\zeta$-forests, which is a\nnatural extension of the well-studied case of matchings.",
    "descriptor": "",
    "authors": [
      "Mark Braverman",
      "Subhash Khot",
      "Noam Lifshitz",
      "Dor Minzer"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.10725"
  },
  {
    "id": "arXiv:2110.10729",
    "title": "Part-X: A Family of Stochastic Algorithms for Search-Based Test  Generation with Probabilistic Guarantees",
    "abstract": "Requirements driven search-based testing (also known as falsification) has\nproven to be a practical and effective method for discovering erroneous\nbehaviors in Cyber-Physical Systems. Despite the constant improvements on the\nperformance and applicability of falsification methods, they all share a common\ncharacteristic. Namely, they are best-effort methods which do not provide any\nguarantees on the absence of erroneous behaviors (falsifiers) when the testing\nbudget is exhausted. The absence of finite time guarantees is a major\nlimitation which prevents falsification methods from being utilized in\ncertification procedures. In this paper, we address the finite-time guarantees\nproblem by developing a new stochastic algorithm. Our proposed algorithm not\nonly estimates (bounds) the probability that falsifying behaviors exist, but\nalso it identifies the regions where these falsifying behaviors may occur. We\ndemonstrate the applicability of our approach on standard benchmark functions\nfrom the optimization literature and on the F16 benchmark problem.",
    "descriptor": "\nComments: 25 pages, 7 Figures\n",
    "authors": [
      "Giulia Pedrielli",
      "Tanmay Kandhait",
      "Surdeep Chotaliya",
      "Quinn Thibeault",
      "Hao Huang",
      "Mauricio Castillo-Effen",
      "Georgios Fainekos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.10729"
  },
  {
    "id": "arXiv:2110.10734",
    "title": "Self-Supervision and Spatial-Sequential Attention Based Loss for  Multi-Person Pose Estimation",
    "abstract": "Bottom-up based multi-person pose estimation approaches use heatmaps with\nauxiliary predictions to estimate joint positions and belonging at one time.\nRecently, various combinations between auxiliary predictions and heatmaps have\nbeen proposed for higher performance, these predictions are supervised by the\ncorresponding L2 loss function directly. However, the lack of more explicit\nsupervision results in low features utilization and contradictions between\npredictions in one model. To solve these problems, this paper proposes (i) a\nnew loss organization method which uses self-supervised heatmaps to reduce\nprediction contradictions and spatial-sequential attention to enhance networks'\nfeatures extraction; (ii) a new combination of predictions composed by\nheatmaps, Part Affinity Fields (PAFs) and our block-inside offsets to fix\npixel-level joints positions and further demonstrates the effectiveness of\nproposed loss function. Experiments are conducted on the MS COCO keypoint\ndataset and adopting OpenPose as the baseline model. Our method outperforms the\nbaseline overall. On the COCO verification dataset, the mAP of OpenPose trained\nwith our proposals outperforms the OpenPose baseline by over 5.5%.",
    "descriptor": "",
    "authors": [
      "Haiyang Liu",
      "Dingli Luo",
      "Songlin Du",
      "Takeshi Ikenaga"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10734"
  },
  {
    "id": "arXiv:2110.10735",
    "title": "Dynamic Bottleneck for Robust Self-Supervised Exploration",
    "abstract": "Exploration methods based on pseudo-count of transitions or curiosity of\ndynamics have achieved promising results in solving reinforcement learning with\nsparse rewards. However, such methods are usually sensitive to environmental\ndynamics-irrelevant information, e.g., white-noise. To handle such\ndynamics-irrelevant information, we propose a Dynamic Bottleneck (DB) model,\nwhich attains a dynamics-relevant representation based on the\ninformation-bottleneck principle. Based on the DB model, we further propose\nDB-bonus, which encourages the agent to explore state-action pairs with high\ninformation gain. We establish theoretical connections between the proposed\nDB-bonus, the upper confidence bound (UCB) for linear case, and the visiting\ncount for tabular case. We evaluate the proposed method on Atari suits with\ndynamics-irrelevant noises. Our experiments show that exploration with DB bonus\noutperforms several state-of-the-art exploration methods in noisy environments.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Chenjia Bai",
      "Lingxiao Wang",
      "Lei Han",
      "Animesh Garg",
      "Jianye Hao",
      "Peng Liu",
      "Zhaoran Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10735"
  },
  {
    "id": "arXiv:2110.10739",
    "title": "Adapting Speech Separation to Real-World Meetings Using Mixture  Invariant Training",
    "abstract": "The recently-proposed mixture invariant training (MixIT) is an unsupervised\nmethod for training single-channel sound separation models in the sense that it\ndoes not require ground-truth isolated reference sources. In this paper, we\ninvestigate using MixIT to adapt a separation model on real far-field\noverlapping reverberant and noisy speech data from the AMI Corpus. The models\nare tested on real AMI recordings containing overlapping speech, and are\nevaluated subjectively by human listeners. To objectively evaluate our models,\nwe also devise a synthetic AMI test set. For human evaluations on real\nrecordings, we also propose a modification of the standard MUSHRA protocol to\nhandle imperfect reference signals, which we call MUSHIRA. Holding network\narchitectures constant, we find that a fine-tuned semi-supervised model yields\nthe largest SI-SNR improvement, PESQ scores, and human listening ratings across\nsynthetic and real datasets, outperforming unadapted generalist models trained\non orders of magnitude more data. Our results show that unsupervised learning\nthrough MixIT enables model adaptation on real-world unlabeled spontaneous\nspeech recordings.",
    "descriptor": "",
    "authors": [
      "Aswin Sivaraman",
      "Scott Wisdom",
      "Hakan Erdogan",
      "John R. Hershey"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.10739"
  },
  {
    "id": "arXiv:2110.10741",
    "title": "Class Incremental Online Streaming Learning",
    "abstract": "A wide variety of methods have been developed to enable lifelong learning in\nconventional deep neural networks. However, to succeed, these methods require a\n`batch' of samples to be available and visited multiple times during training.\nWhile this works well in a static setting, these methods continue to suffer in\na more realistic situation where data arrives in \\emph{online streaming\nmanner}. We empirically demonstrate that the performance of current approaches\ndegrades if the input is obtained as a stream of data with the following\nrestrictions: $(i)$ each instance comes one at a time and can be seen only\nonce, and $(ii)$ the input data violates the i.i.d assumption, i.e., there can\nbe a class-based correlation. We propose a novel approach (CIOSL) for the\nclass-incremental learning in an \\emph{online streaming setting} to address\nthese challenges. The proposed approach leverages implicit and explicit dual\nweight regularization and experience replay. The implicit regularization is\nleveraged via the knowledge distillation, while the explicit regularization\nincorporates a novel approach for parameter regularization by learning the\njoint distribution of the buffer replay and the current sample. Also, we\npropose an efficient online memory replay and replacement buffer strategy that\nsignificantly boosts the model's performance. Extensive experiments and\nablation on challenging datasets show the efficacy of the proposed method.",
    "descriptor": "",
    "authors": [
      "Soumya Banerjee",
      "Vinay Kumar Verma",
      "Toufiq Parag",
      "Maneesh Singh",
      "Vinay P. Namboodiri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10741"
  },
  {
    "id": "arXiv:2110.10746",
    "title": "Better than Average: Paired Evaluation of NLP Systems",
    "abstract": "Evaluation in NLP is usually done by comparing the scores of competing\nsystems independently averaged over a common set of test instances. In this\nwork, we question the use of averages for aggregating evaluation scores into a\nfinal number used to decide which system is best, since the average, as well as\nalternatives such as the median, ignores the pairing arising from the fact that\nsystems are evaluated on the same test instances. We illustrate the importance\nof taking the instance-level pairing of evaluation scores into account and\ndemonstrate, both theoretically and empirically, the advantages of aggregation\nmethods based on pairwise comparisons, such as the Bradley-Terry (BT) model, a\nmechanism based on the estimated probability that a given system scores better\nthan another on the test set. By re-evaluating 296 real NLP evaluation setups\nacross four tasks and 18 evaluation metrics, we show that the choice of\naggregation mechanism matters and yields different conclusions as to which\nsystems are state of the art in about 30% of the setups. To facilitate the\nadoption of pairwise evaluation, we release a practical tool for performing the\nfull analysis of evaluation scores with the mean, median, BT, and two variants\nof BT (Elo and TrueSkill), alongside functionality for appropriate statistical\ntesting.",
    "descriptor": "\nComments: Published in ACL 2021 (long paper)\n",
    "authors": [
      "Maxime Peyrard",
      "Wei Zhao",
      "Steffen Eger",
      "Robert West"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10746"
  },
  {
    "id": "arXiv:2110.10749",
    "title": "A domain decomposition solution of the Stokes-Darcy system in 3D based  on boundary integrals",
    "abstract": "A framework is developed for a robust and highly accurate numerical solution\nof the coupled Stokes-Darcy system in three dimensions. The domain\ndecomposition method is based on a Dirichlet-Neumann type splitting of the\ninterface conditions and solving separate Stokes and Darcy problems\niteratively. Second kind boundary integral equations are formulated for each\nproblem. The integral equations use a smoothing of the kernels that achieves\nhigh accuracy on the boundary, and a straightforward quadrature to discretize\nthe integrals. Numerical results demonstrate the convergence, accuracy, and\ndependence on parameter values of the iterative solution for a problem of\nviscous flow around a porous sphere with a known analytical solution, as well\nas more general surfaces.",
    "descriptor": "",
    "authors": [
      "Svetlana Tlupova"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.10749"
  },
  {
    "id": "arXiv:2110.10757",
    "title": "TPARN: Triple-path Attentive Recurrent Network for Time-domain  Multichannel Speech Enhancement",
    "abstract": "In this work, we propose a new model called triple-path attentive recurrent\nnetwork (TPARN) for multichannel speech enhancement in the time domain. TPARN\nextends a single-channel dual-path network to a multichannel network by adding\na third path along the spatial dimension. First, TPARN processes speech signals\nfrom all channels independently using a dual-path attentive recurrent network\n(ARN), which is a recurrent neural network (RNN) augmented with self-attention.\nNext, an ARN is introduced along the spatial dimension for spatial context\naggregation. TPARN is designed as a multiple-input and multiple-output\narchitecture to enhance all input channels simultaneously. Experimental results\ndemonstrate the superiority of TPARN over existing state-of-the-art approaches.",
    "descriptor": "\nComments: submitted to ICASSP 2022\n",
    "authors": [
      "Ashutosh Pandey",
      "Buye Xu",
      "Anurag Kumar",
      "Jacob Donley",
      "Paul Calamia",
      "DeLiang Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.10757"
  },
  {
    "id": "arXiv:2110.10759",
    "title": "Balanced Allocations: Caching and Packing, Twinning and Thinning",
    "abstract": "We consider the sequential allocation of $m$ balls (jobs) into $n$ bins\n(servers) by allowing each ball to choose from some bins sampled uniformly at\nrandom. The goal is to maintain a small gap between the maximum load and the\naverage load. In this paper, we present a general framework that allows us to\nanalyze various allocation processes that slightly prefer allocating into\nunderloaded, as opposed to overloaded bins. Our analysis covers several natural\ninstances of processes, including:\nThe Caching process (a.k.a. memory protocol) as studied by Mitzenmacher,\nPrabhakar and Shah (2002): At each round we only take one bin sample, but we\nalso have access to a cache in which the most recently used bin is stored. We\nplace the ball into the least loaded of the two.\nThe Packing process: At each round we only take one bin sample. If the load\nis below some threshold (e.g., the average load), then we place as many balls\nuntil the threshold is reached; otherwise, we place only one ball.\nThe Twinning process: At each round, we only take one bin sample. If the load\nis below some threshold, then we place two balls; otherwise, we place only one\nball.\nThe Thinning process as recently studied by Feldheim and Gurel-Gurevich\n(2021): At each round, we first take one bin sample. If its load is below some\nthreshold, we place one ball; otherwise, we place one ball into a\n$\\textit{second}$ bin sample.\nAs we demonstrate, our general framework implies for all these processes a\ngap of $\\mathcal{O}(\\log n)$ between the maximum load and average load, even\nwhen an arbitrary number of balls $m \\geq n$ are allocated (heavily loaded\ncase). Our analysis is inspired by a previous work of Peres, Talwar and Wieder\n(2010) for the $(1+\\beta)$-process, however here we rely on the interplay\nbetween different potential functions to prove stabilization.",
    "descriptor": "\nComments: 76 pages, 7 figures, 2 tables\n",
    "authors": [
      "Dimitrios Los",
      "Thomas Sauerwald",
      "John Sylvester"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2110.10759"
  },
  {
    "id": "arXiv:2110.10762",
    "title": "Asynchronous parareal time discretization for partial differential  equations",
    "abstract": "Asynchronous iterations are more and more investigated for both scaling and\nfault-resilience purpose on high performance computing platforms. While so far,\nthey have been exclusively applied within space domain decomposition\nframeworks, this paper advocates a novel application direction targeting\ntime-decomposed time-parallel approaches. Specifically, an asynchronous\niterative model is derived from the Parareal scheme, for which convergence and\nspeedup analysis are then conducted. It turned out that Parareal and\nasync-Parareal feature very close convergence conditions, asymptotically\nequivalent, including the finite-time termination property. Based on a\ncomputational cost model aware of unsteady communication delays, our speedup\nanalysis shows the potential performance gain from asynchronous iterations,\nwhich is confirmed by some experimental case of heat evolution on a homogeneous\nsupercomputer. This primary work clearly suggests possible further benefits\nfrom asynchronous iterations.",
    "descriptor": "",
    "authors": [
      "Frederic Magoules",
      "Guillaume Gbikpi-Benissan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.10762"
  },
  {
    "id": "arXiv:2110.10765",
    "title": "Accelerating quantum many-body configuration interaction with directives",
    "abstract": "Many-Fermion Dynamics-nuclear, or MFDn, is a configuration interaction (CI)\ncode for nuclear structure calculations. It is a platform-independent Fortran\n90 code using a hybrid MPI+X programming model. For CPU platforms the\napplication has a robust and optimized OpenMP implementation for shared memory\nparallelism. As part of the NESAP application readiness program for NERSC's\nlatest Perlmutter system, MFDn has been updated to take advantage of\naccelerators. The current mainline GPU port is based on OpenACC. In this work\nwe describe some of the key challenges of creating an efficient GPU\nimplementation. Additionally, we compare the support of OpenMP and OpenACC on\nAMD and NVIDIA GPUs.",
    "descriptor": "\nComments: 22 pages, 7 figures, 11 code listings, WACCPD@SC21\n",
    "authors": [
      "Brandon Cook",
      "Patrick J. Fasano",
      "Pieter Maris",
      "Chao Yang",
      "Dossay Oryspayev"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Mathematical Software (cs.MS)",
      "Performance (cs.PF)",
      "Nuclear Theory (nucl-th)"
    ],
    "url": "https://arxiv.org/abs/2110.10765"
  },
  {
    "id": "arXiv:2110.10769",
    "title": "RegGuard: Leveraging CPU Registers for Mitigation of Control- and  Data-Oriented Attacks",
    "abstract": "CPU registers are small discrete storage units, used to hold temporary data\nand instructions within the CPU. Registers are not addressable in the same way\nmemory is, which makes them immune from memory attacks and manipulation by\nother means. In this paper, we take advantage of this to provide a protection\nmechanism for critical program data; both active local variables and control\nobjects on the stack. This protection effectively eliminates the threat of\ncontrol- and data-oriented attacks, even by adversaries with full knowledge of\nthe active stack. Our solution RegGuard, is a compiler register allocation\nstrategy that utilises the available CPU registers to hold critical variables\nduring execution. Unlike conventional allocations schemes, RegGuard prioritises\nthe security significance of a program variable over its expected performance\ngain. Our scheme can deal effectively with saved registers to the stack, i.e.,\nwhen the compiler needs to free up registers to make room for the variables of\na new function call. With RegGuard, critical data objects anywhere on the\nentire stack are effectively protected from corruption, even by adversaries\nwith arbitrary read and write access. While our primary design focus is on\nsecurity, performance is very important for a scheme to be adopted in practice.\nRegGuard is still benefiting from the performance gain normally associated with\nregister allocations, and the overhead is within a few percent of other\nunsecured register allocation schemes for most cases. We present detailed\nexperiments that showcase the performance of RegGuard using different benchmark\nprograms and the C library on ARM64 platform.",
    "descriptor": "\nComments: 15 pages with 8 figures\n",
    "authors": [
      "Munir Geden",
      "Kasper Rasmussen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.10769"
  },
  {
    "id": "arXiv:2110.10772",
    "title": "Closed-loop Feedback Registration for Consecutive Images of Moving  Flexible Targets",
    "abstract": "Advancement of imaging techniques enables consecutive image sequences to be\nacquired for quality monitoring of manufacturing production lines. Registration\nfor these image sequences is essential for in-line pattern inspection and\nmetrology, e.g., in the printing process of flexible electronics. However,\nconventional image registration algorithms cannot produce accurate results when\nthe images contain many similar and deformable patterns in the manufacturing\nprocess. Such a failure originates from a fact that the conventional algorithms\nonly use the spatial and pixel intensity information for registration.\nConsidering the nature of temporal continuity and consecution of the product\nimages, in this paper, we propose a closed-loop feedback registration algorithm\nfor matching and stitching the deformable printed patterns on a moving flexible\nsubstrate. The algorithm leverages the temporal and spatial relationships of\nthe consecutive images and the continuity of the image sequence for fast,\naccurate, and robust point matching. Our experimental results show that our\nalgorithm can find more matching point pairs with a lower root mean squared\nerror (RMSE) compared to other state-of-the-art algorithms while offering\nsignificant improvements to running time.",
    "descriptor": "",
    "authors": [
      "Rui Ma",
      "Xian Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10772"
  },
  {
    "id": "arXiv:2110.10774",
    "title": "SciXGen: A Scientific Paper Dataset for Context-Aware Text Generation",
    "abstract": "Generating texts in scientific papers requires not only capturing the content\ncontained within the given input but also frequently acquiring the external\ninformation called \\textit{context}. We push forward the scientific text\ngeneration by proposing a new task, namely \\textbf{context-aware text\ngeneration} in the scientific domain, aiming at exploiting the contributions of\ncontext in generated texts. To this end, we present a novel challenging\nlarge-scale \\textbf{Sci}entific Paper Dataset for Conte\\textbf{X}t-Aware Text\n\\textbf{Gen}eration (SciXGen), consisting of well-annotated 205,304 papers with\nfull references to widely-used objects (e.g., tables, figures, algorithms) in a\npaper. We comprehensively benchmark, using state-of-the-arts, the efficacy of\nour newly constructed SciXGen dataset in generating description and paragraph.\nOur dataset and benchmarks will be made publicly available to hopefully\nfacilitate the scientific text generation research.",
    "descriptor": "\nComments: this paper was accepted by EMNLP2021-findings\n",
    "authors": [
      "Hong Chen",
      "Hiroya Takamura",
      "Hideki Nakayama"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.10774"
  },
  {
    "id": "arXiv:2110.10775",
    "title": "Reduced Basis Approximations of Parameterized Dynamical Partial  Differential Equations via Neural Networks",
    "abstract": "Projection-based reduced order models are effective at approximating\nparameter-dependent differential equations that are parametrically separable.\nWhen parametric separability is not satisfied, which occurs in both linear and\nnonlinear problems, projection-based methods fail to adequately reduce the\ncomputational complexity. Devising alternative reduced order models is crucial\nfor obtaining efficient and accurate approximations to expensive high-fidelity\nmodels. In this work, we develop a time-stepping procedure for dynamical\nparameter-dependent problems, in which a neural-network is trained to propagate\nthe coefficients of a reduced basis expansion. This results in an online stage\nwith a computational cost independent of the size of the underlying problem. We\ndemonstrate our method on several parabolic partial differential equations,\nincluding a problem that is not parametrically separable.",
    "descriptor": "\nComments: 21 pages, 10 figures\n",
    "authors": [
      "Peter Sentz",
      "Kristian Beckwith",
      "Eric C. Cyr",
      "Luke N. Olson",
      "Ravi Patel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.10775"
  },
  {
    "id": "arXiv:2110.10777",
    "title": "Learning controllers for performance through LMI regions",
    "abstract": "In an open-loop experiment, an input sequence is applied to an unknown linear\ntime-invariant system (in continuous or discrete time) affected also by an\nunknown-but-bounded disturbance sequence (with an energy or instantaneous\nbound); the corresponding state sequence is measured. The goal is to design\ndirectly from the input and state sequences a controller that enforces a\ncertain performance specification on the transient behaviour of the unknown\nsystem. The performance specification is expressed through a subset of the\ncomplex plane where closed-loop eigenvalues need to belong, a so called LMI\nregion. For this control design problem, we provide here convex programs to\nenforce the performance specification from data in the form of linear matrix\ninequalities (LMI). For generic LMI regions, these are sufficient conditions to\nassign the eigenvalues within the LMI region for all possible dynamics\nconsistent with data, and become necessary and sufficient conditions for\nspecial LMI regions. In this way, we extend classical model-based conditions\nfrom a seminal work in the literature to the setting of data-driven control\nfrom noisy data. Through two numerical examples, we investigate how these\ndata-based conditions compare with each other.",
    "descriptor": "",
    "authors": [
      "Andrea Bisoffi",
      "Claudio De Persis",
      "Pietro Tesi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.10777"
  },
  {
    "id": "arXiv:2110.10778",
    "title": "Contrastive Document Representation Learning with Graph Attention  Networks",
    "abstract": "Recent progress in pretrained Transformer-based language models has shown\ngreat success in learning contextual representation of text. However, due to\nthe quadratic self-attention complexity, most of the pretrained Transformers\nmodels can only handle relatively short text. It is still a challenge when it\ncomes to modeling very long documents. In this work, we propose to use a graph\nattention network on top of the available pretrained Transformers model to\nlearn document embeddings. This graph attention network allows us to leverage\nthe high-level semantic structure of the document. In addition, based on our\ngraph document model, we design a simple contrastive learning strategy to\npretrain our models on a large amount of unlabeled corpus. Empirically, we\ndemonstrate the effectiveness of our approaches in document classification and\ndocument retrieval tasks.",
    "descriptor": "\nComments: Findings of EMNLP 2021\n",
    "authors": [
      "Peng Xu",
      "Xinchi Chen",
      "Xiaofei Ma",
      "Zhiheng Huang",
      "Bing Xiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.10778"
  },
  {
    "id": "arXiv:2110.10780",
    "title": "An Open Natural Language Processing Development Framework for EHR-based  Clinical Research: A case demonstration using the National COVID Cohort  Collaborative (N3C)",
    "abstract": "While we pay attention to the latest advances in clinical natural language\nprocessing (NLP), we can notice some resistance in the clinical and\ntranslational research community to adopt NLP models due to limited\ntransparency, Interpretability and usability. Built upon our previous work, in\nthis study, we proposed an open natural language processing development\nframework and evaluated it through the implementation of NLP algorithms for the\nNational COVID Cohort Collaborative (N3C). Based on the interests in\ninformation extraction from COVID-19 related clinical notes, our work includes\n1) an open data annotation process using COVID-19 signs and symptoms as the use\ncase, 2) a community-driven ruleset composing platform, and 3) a synthetic text\ndata generation workflow to generate texts for information extraction tasks\nwithout involving human subjects. The generated corpora derived out of the\ntexts from multiple intuitions and gold standard annotation are tested on a\nsingle institution's rule set has the performances in F1 score of 0.876, 0.706\nand 0.694, respectively. The study as a consortium effort of the N3C NLP\nsubgroup demonstrates the feasibility of creating a federated NLP algorithm\ndevelopment and benchmarking platform to enhance multi-institution clinical NLP\nstudy.",
    "descriptor": "",
    "authors": [
      "Sijia Liu",
      "Andrew Wen",
      "Liwei Wang",
      "Huan He",
      "Sunyang Fu",
      "Robert Miller",
      "Andrew Williams",
      "Daniel Harris",
      "Ramakanth Kavuluru",
      "Mei Liu",
      "Noor Abu-el-rub",
      "Rui Zhang",
      "John D. Osborne",
      "Masoud Rouhizadeh",
      "Yongqun He",
      "Emily Pfaff",
      "Christopher G. Chute",
      "Tim Duong",
      "Melissa A. Haendel",
      "Rafael Fuentes",
      "Peter Szolovits",
      "Hua Xu",
      "Hongfang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.10780"
  },
  {
    "id": "arXiv:2110.10784",
    "title": "Style Agnostic 3D Reconstruction via Adversarial Style Transfer",
    "abstract": "Reconstructing the 3D geometry of an object from an image is a major\nchallenge in computer vision. Recently introduced differentiable renderers can\nbe leveraged to learn the 3D geometry of objects from 2D images, but those\napproaches require additional supervision to enable the renderer to produce an\noutput that can be compared to the input image. This can be scene information\nor constraints such as object silhouettes, uniform backgrounds, material,\ntexture, and lighting. In this paper, we propose an approach that enables a\ndifferentiable rendering-based learning of 3D objects from images with\nbackgrounds without the need for silhouette supervision. Instead of trying to\nrender an image close to the input, we propose an adversarial style-transfer\nand domain adaptation pipeline that allows to translate the input image domain\nto the rendered image domain. This allows us to directly compare between a\ntranslated image and the differentiable rendering of a 3D object reconstruction\nin order to train the 3D object reconstruction network. We show that the\napproach learns 3D geometry from images with backgrounds and provides a better\nperformance than constrained methods for single-view 3D object reconstruction\non this task.",
    "descriptor": "\nComments: To be published at WACV 2022, Code @ this https URL\n",
    "authors": [
      "Felix Petersen",
      "Bastian Goldluecke",
      "Oliver Deussen",
      "Hilde Kuehne"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10784"
  },
  {
    "id": "arXiv:2110.10790",
    "title": "Human-Centered Explainable AI (XAI): From Algorithms to User Experiences",
    "abstract": "As a technical sub-field of artificial intelligence (AI), explainable AI\n(XAI) has produced a vast collection of algorithms in recent years. However,\nexplainability is an inherently human-centric property and the field is\nstarting to embrace inter-disciplinary perspectives and human-centered\napproaches. As researchers and practitioners begin to leverage XAI algorithms\nto build XAI applications, explainability has moved beyond a demand by data\nscientists or researchers to comprehend the models they are developing, to\nbecome an essential requirement for people to trust and adopt AI deployed in\nnumerous domains. Human-computer interaction (HCI) research and user experience\n(UX) design in this area are therefore increasingly important. In this chapter,\nwe begin with a high-level overview of the technical landscape of XAI\nalgorithms, then selectively survey recent HCI work that takes human-centered\napproaches to design, evaluate, provide conceptual and methodological tools for\nXAI. We ask the question \"what are human-centered approaches doing for XAI\" and\nhighlight three roles that they should play in shaping XAI technologies: to\ndrive technical choices by understanding users' explainability needs, to\nuncover pitfalls of existing XAI methods through empirical studies and inform\nnew methods, and to provide conceptual frameworks for human-compatible XAI.",
    "descriptor": "\nComments: draft for a book chapter\n",
    "authors": [
      "Q. Vera Liao",
      "Kush R. Varshney"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.10790"
  },
  {
    "id": "arXiv:2110.10791",
    "title": "Modeling Human-Human Collaboration: A Connection Between Inter-Personal  Motor Synergy and Consensus Algorithms",
    "abstract": "Many day-to-day activities involve people working collaboratively toward\nreaching a desired outcome. Previous research in motor control and neuroscience\nhave proposed inter-personal motor synergy (IPMS) as a mechanism of\ncollaboration between people, referring to the idea of how two or more people\nmay work together \"as if they were one\" to coordinate their motion. In motor\ncontrol literature, uncontrolled manifold (UCM) is used for quantifying IPMS.\nAccording to this approach, coordinated motion is achieved through\nstabilization of a performance variable (e.g., an output in a collaborative\noutput tracking task). We show that the UCM approach is closely related to the\nwell-studied consensus approach in multi-agent systems that concerns processes\nby which a set of interacting agents agree on a shared objective. To explore\nthe connection between these two approaches, in this paper, we provide a\ncontrol-theoretic model that represents the systems-level behaviors in a\ncollaborative task. In particular, we utilize the consensus protocol and show\nhow the model can be systematically tuned to reproduce the behavior exhibited\nby human-human collaboration experiments. We discuss the association between\nthe proposed control law and the UCM approach and validate our model using\nexperimental results previously collected from an inter-personal finger force\nproduction task.",
    "descriptor": "",
    "authors": [
      "Sara Honarvar",
      "Jin-OH Hahn",
      "Tim Kiemel",
      "Jae Kun Shim",
      "Yancy Diaz-Mercado"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.10791"
  },
  {
    "id": "arXiv:2110.10797",
    "title": "Scheduling of Graph Queries: Controlling Intra- and Inter-query  Parallelism for a High System Throughput",
    "abstract": "The vast amounts of data used in social, business or traffic networks,\nbiology and other natural sciences are often managed in graph-based data sets,\nconsisting of a few thousand up to billions and trillions of vertices and\nedges, respectively. Typical applications utilizing such data either execute\none or a few complex queries or many small queries at the same time\ninteractively or as batch jobs. Furthermore, graph processing is inherently\ncomplex, as data sets can substantially differ (scale free vs. constant\ndegree), and algorithms exhibit diverse behavior (computational intensity,\nlocal or global, push- or pull-based).\nThis work is concerned with multi-query execution by automatically\ncontrolling the degree of parallelization, with overall objectives including\nhigh system utilization, low synchronization cost, and highly efficient\nconcurrent execution. The underlying concept is three-fold: (1) sampling is\nused to determine graph statistics, (2) parallelization constraints are derived\nfrom algorithm and system properties, and (3) suitable work packages are\ngenerated based on the previous two aspects. We evaluate the proposed concept\nusing different algorithms on synthetic and real world data sets, with up to 16\nconcurrent sessions (queries). The results demonstrate a robust performance in\nspite of these various configurations, and in particular that the performance\nis always close to or even slightly ahead of the performance of manually\noptimized implementations. Furthermore, the similar performance to manually\noptimized implementations under extreme configurations, which require either a\nfull parallelization (few large queries) or complete sequential execution (many\nsmall queries), shows that the proposed concept exhibits a particularly low\noverhead.",
    "descriptor": "",
    "authors": [
      "Matthias Hauck",
      "Ismail Oukid",
      "Holger Fr\u00f6ning"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.10797"
  },
  {
    "id": "arXiv:2110.10802",
    "title": "A Data-Centric Optimization Framework for Machine Learning",
    "abstract": "Rapid progress in deep learning is leading to a diverse set of quickly\nchanging models, with a dramatically growing demand for compute. However, as\nframeworks specialize optimization to patterns in popular networks, they\nimplicitly constrain novel and diverse models that drive progress in research.\nWe empower deep learning researchers by defining a flexible and\nuser-customizable pipeline for optimizing training of arbitrary deep neural\nnetworks, based on data movement minimization. The pipeline begins with\nstandard networks in PyTorch or ONNX and transforms computation through\nprogressive lowering. We define four levels of general-purpose transformations,\nfrom local intra-operator optimizations to global data movement reduction.\nThese operate on a data-centric graph intermediate representation that\nexpresses computation and data movement at all levels of abstraction, including\nexpanding basic operators such as convolutions to their underlying\ncomputations. Central to the design is the interactive and introspectable\nnature of the pipeline. Every part is extensible through a Python API, and can\nbe tuned interactively using a GUI. We demonstrate competitive performance or\nspeedups on ten different networks, with interactive optimizations discovering\nnew opportunities in EfficientNet.",
    "descriptor": "",
    "authors": [
      "Oliver Rausch",
      "Tal Ben-Nun",
      "Nikoli Dryden",
      "Andrei Ivanov",
      "Shigang Li",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2110.10802"
  },
  {
    "id": "arXiv:2110.10803",
    "title": "Propensity-scored Probabilistic Label Trees",
    "abstract": "Extreme multi-label classification (XMLC) refers to the task of tagging\ninstances with small subsets of relevant labels coming from an extremely large\nset of all possible labels. Recently, XMLC has been widely applied to diverse\nweb applications such as automatic content labeling, online advertising, or\nrecommendation systems. In such environments, label distribution is often\nhighly imbalanced, consisting mostly of very rare tail labels, and relevant\nlabels can be missing. As a remedy to these problems, the propensity model has\nbeen introduced and applied within several XMLC algorithms. In this work, we\nfocus on the problem of optimal predictions under this model for probabilistic\nlabel trees, a popular approach for XMLC problems. We introduce an inference\nprocedure, based on the $A^*$-search algorithm, that efficiently finds the\noptimal solution, assuming that all probabilities and propensities are known.\nWe demonstrate the attractiveness of this approach in a wide empirical study on\npopular XMLC benchmark datasets.",
    "descriptor": "\nComments: The extended version of SIGIR '21 Short Research Paper\n",
    "authors": [
      "Marek Wydmuch",
      "Kalina Jasinska-Kobus",
      "Rohit Babbar",
      "Krzysztof Dembczy\u0144ski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.10803"
  },
  {
    "id": "arXiv:2110.10805",
    "title": "DVIO: Depth aided visual inertial odometry for RGBD sensors",
    "abstract": "In past few years we have observed an increase in the usage of RGBD sensors\nin mobile devices. These sensors provide a good estimate of the depth map for\nthe camera frame, which can be used in numerous augmented reality applications.\nThis paper presents a new visual inertial odometry (VIO) system, which uses\nmeasurements from a RGBD sensor and an inertial measurement unit (IMU) sensor\nfor estimating the motion state of the mobile device. The resulting system is\ncalled the depth-aided VIO (DVIO) system. In this system we add the depth\nmeasurement as part of the nonlinear optimization process. Specifically, we\npropose methods to use the depth measurement using one-dimensional (1D) feature\nparameterization as well as three-dimensional (3D) feature parameterization. In\naddition, we propose to utilize the depth measurement for estimating time\noffset between the unsynchronized IMU and the RGBD sensors. Last but not least,\nwe propose a novel block-based marginalization approach to speed up the\nmarginalization processes and maintain the real-time performance of the overall\nsystem. Experimental results validate that the proposed DVIO system outperforms\nthe other state-of-the-art VIO systems in terms of trajectory accuracy as well\nas processing time.",
    "descriptor": "",
    "authors": [
      "Abhishek Tyagi",
      "Yangwen Liang",
      "Shuangquan Wang",
      "Dongwoon Bai"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10805"
  },
  {
    "id": "arXiv:2110.10807",
    "title": "Text-Based Person Search with Limited Data",
    "abstract": "Text-based person search (TBPS) aims at retrieving a target person from an\nimage gallery with a descriptive text query. Solving such a fine-grained\ncross-modal retrieval task is challenging, which is further hampered by the\nlack of large-scale datasets. In this paper, we present a framework with two\nnovel components to handle the problems brought by limited data. Firstly, to\nfully utilize the existing small-scale benchmarking datasets for more\ndiscriminative feature learning, we introduce a cross-modal momentum\ncontrastive learning framework to enrich the training data for a given\nmini-batch. Secondly, we propose to transfer knowledge learned from existing\ncoarse-grained large-scale datasets containing image-text pairs from\ndrastically different problem domains to compensate for the lack of TBPS\ntraining data. A transfer learning method is designed so that useful\ninformation can be transferred despite the large domain gap. Armed with these\ncomponents, our method achieves new state of the art on the CUHK-PEDES dataset\nwith significant improvements over the prior art in terms of Rank-1 and mAP.\nOur code is available at https://github.com/BrandonHanx/TextReID.",
    "descriptor": "\nComments: 20 pages, 7 figures, 6 tables, to appear in BMVC2021\n",
    "authors": [
      "Xiao Han",
      "Sen He",
      "Li Zhang",
      "Tao Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10807"
  },
  {
    "id": "arXiv:2110.10809",
    "title": "Hierarchical Skills for Efficient Exploration",
    "abstract": "In reinforcement learning, pre-trained low-level skills have the potential to\ngreatly facilitate exploration. However, prior knowledge of the downstream task\nis required to strike the right balance between generality (fine-grained\ncontrol) and specificity (faster learning) in skill design. In previous work on\ncontinuous control, the sensitivity of methods to this trade-off has not been\naddressed explicitly, as locomotion provides a suitable prior for navigation\ntasks, which have been of foremost interest. In this work, we analyze this\ntrade-off for low-level policy pre-training with a new benchmark suite of\ndiverse, sparse-reward tasks for bipedal robots. We alleviate the need for\nprior knowledge by proposing a hierarchical skill learning framework that\nacquires skills of varying complexity in an unsupervised manner. For\nutilization on downstream tasks, we present a three-layered hierarchical\nlearning algorithm to automatically trade off between general and specific\nskills as required by the respective task. In our experiments, we show that our\napproach performs this trade-off effectively and achieves better results than\ncurrent state-of-the-art methods for end- to-end hierarchical reinforcement\nlearning and unsupervised skill discovery. Code and videos are available at\nhttps://facebookresearch.github.io/hsd3 .",
    "descriptor": "\nComments: To appear in 35th Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Jonas Gehring",
      "Gabriel Synnaeve",
      "Andreas Krause",
      "Nicolas Usunier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.10809"
  },
  {
    "id": "arXiv:2110.10811",
    "title": "HALP: Hardware-Aware Latency Pruning",
    "abstract": "Structural pruning can simplify network architecture and improve inference\nspeed. We propose Hardware-Aware Latency Pruning (HALP) that formulates\nstructural pruning as a global resource allocation optimization problem, aiming\nat maximizing the accuracy while constraining latency under a predefined\nbudget. For filter importance ranking, HALP leverages latency lookup table to\ntrack latency reduction potential and global saliency score to gauge accuracy\ndrop. Both metrics can be evaluated very efficiently during pruning, allowing\nus to reformulate global structural pruning under a reward maximization problem\ngiven target constraint. This makes the problem solvable via our augmented\nknapsack solver, enabling HALP to surpass prior work in pruning efficacy and\naccuracy-efficiency trade-off. We examine HALP on both classification and\ndetection tasks, over varying networks, on ImageNet and VOC datasets. In\nparticular, for ResNet-50/-101 pruning on ImageNet, HALP improves network\nthroughput by $1.60\\times$/$1.90\\times$ with $+0.3\\%$/$-0.2\\%$ top-1 accuracy\nchanges, respectively. For SSD pruning on VOC, HALP improves throughput by\n$1.94\\times$ with only a $0.56$ mAP drop. HALP consistently outperforms prior\nart, sometimes by large margins.",
    "descriptor": "",
    "authors": [
      "Maying Shen",
      "Hongxu Yin",
      "Pavlo Molchanov",
      "Lei Mao",
      "Jianna Liu",
      "Jose M. Alvarez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10811"
  },
  {
    "id": "arXiv:2110.10815",
    "title": "Convergence Analysis and Implicit Regularization of Feedback Alignment  for Deep Linear Networks",
    "abstract": "We theoretically analyze the Feedback Alignment (FA) algorithm, an efficient\nalternative to backpropagation for training neural networks. We provide\nconvergence guarantees with rates for deep linear networks for both continuous\nand discrete dynamics. Additionally, we study incremental learning phenomena\nfor shallow linear networks. Interestingly, certain specific initializations\nimply that negligible components are learned before the principal ones, thus\npotentially negatively affecting the effectiveness of such a learning\nalgorithm; a phenomenon we classify as implicit anti-regularization. We also\nprovide initialization schemes where the components of the problem are\napproximately learned by decreasing order of importance, thus providing a form\nof implicit regularization.",
    "descriptor": "\nComments: 10 pages (Main) + 19 pages (Appendix), 6 figures\n",
    "authors": [
      "Manuela Girotti",
      "Ioannis Mitliagkas",
      "Gauthier Gidel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.10815"
  },
  {
    "id": "arXiv:2110.10819",
    "title": "Shaking the foundations: delusions in sequence models for interaction  and control",
    "abstract": "The recent phenomenal success of language models has reinvigorated machine\nlearning research, and large sequence models such as transformers are being\napplied to a variety of domains. One important problem class that has remained\nrelatively elusive however is purposeful adaptive behavior. Currently there is\na common perception that sequence models \"lack the understanding of the cause\nand effect of their actions\" leading them to draw incorrect inferences due to\nauto-suggestive delusions. In this report we explain where this mismatch\noriginates, and show that it can be resolved by treating actions as causal\ninterventions. Finally, we show that in supervised learning, one can teach a\nsystem to condition or intervene on data by training with factual and\ncounterfactual error signals respectively.",
    "descriptor": "\nComments: DeepMind Tech Report, 16 pages, 4 figures\n",
    "authors": [
      "Pedro A. Ortega",
      "Markus Kunesch",
      "Gr\u00e9goire Del\u00e9tang",
      "Tim Genewein",
      "Jordi Grau-Moya",
      "Joel Veness",
      "Jonas Buchli",
      "Jonas Degrave",
      "Bilal Piot",
      "Julien Perolat",
      "Tom Everitt",
      "Corentin Tallec",
      "Emilio Parisotto",
      "Tom Erez",
      "Yutian Chen",
      "Scott Reed",
      "Marcus Hutter",
      "Nando de Freitas",
      "Shane Legg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10819"
  },
  {
    "id": "arXiv:2110.10824",
    "title": "Dynamic Bipartite Matching Market with Arrivals and Departures",
    "abstract": "In this paper, we study a matching market model on a bipartite network where\nagents on each side arrive and depart stochastically by a Poisson process. For\nsuch a dynamic model, we design a mechanism that decides not only which agents\nto match, but also when to match them, to minimize the expected number of\nunmatched agents. The main contribution of this paper is to achieve theoretical\nbounds on the performance of local mechanisms with different timing properties.\nWe show that an algorithm that waits to thicken the market, called the\n$\\textit{Patient}$ algorithm, is exponentially better than the\n$\\textit{Greedy}$ algorithm, i.e., an algorithm that matches agents greedily.\nThis means that waiting has substantial benefits on maximizing a matching over\na bipartite network. We remark that the Patient algorithm requires the planner\nto identify agents who are about to leave the market, and, under the\nrequirement, the Patient algorithm is shown to be an optimal algorithm. We also\nshow that, without the requirement, the Greedy algorithm is almost optimal. In\naddition, we consider the $\\textit{1-sided algorithms}$ where only an agent on\none side can attempt to match. This models a practical matching market such as\na freight exchange market and a labor market where only agents on one side can\nmake a decision. For this setting, we prove that the Greedy and Patient\nalgorithms admit the same performance, that is, waiting to thicken the market\nis not valuable. This conclusion is in contrast to the case where agents on\nboth sides can make a decision and the non-bipartite case by [Akbarpour et\nal.,$~\\textit{Journal of Political Economy}$, 2020].",
    "descriptor": "\nComments: An extended abstract is to appear in ACM WINE 2021\n",
    "authors": [
      "Naonori Kakimura",
      "Donghao Zhu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2110.10824"
  },
  {
    "id": "arXiv:2110.10827",
    "title": "How to pose material design problems for flow through porous media  applications?: Sensitivity of dissipation rate to medium's permeability holds  the key",
    "abstract": "Recent studies have advocated using the total dissipation rate under topology\noptimization to realize material designs involving the flow of fluids through\nporous media. However, these studies decided how to pose the design problem,\nsuch as maximizing the total dissipation rate for some situations while\nminimizing for others, by solving one-dimensional problems and justifying their\nchoices using numerical experiments. The rigor is lacking -- a bottleneck for\nfurther scientific advancements to computational material design. This paper\nprovides the missing theoretical justification. We identify four classes of\nboundary value problems using the adjoint state method and analytically\ncalculate the sensitivity of the total dissipation rate to the permeability\nfield. For two of those classes in which the flow of fluids is pressure-driven,\nthe sensitivity is positive -- the total dissipation rate increases if the\nmedium's permeability increases. While for the other two classes, in which the\nflow is velocity-driven, the trend is the opposite. These sensitivities provide\nrigorous answers to the central question: how to pose a material design problem\nfor flow through porous media applications. The impact of our work is\nmulti-fold. First, this study further elevates the role of the dissipation rate\nin posing well-posed material design problems using topology optimization.\nSecond, besides the theoretical significance, the results benefit computational\nscientists and practitioners to realize optimal designs. Third, given their\nsimplicity yet far-reaching impact, both the approach and results possess\nimmense pedagogical value.",
    "descriptor": "",
    "authors": [
      "K. B. Nakshatrala"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.10827"
  },
  {
    "id": "arXiv:2110.10828",
    "title": "AdamD: Improved bias-correction in Adam",
    "abstract": "Here I present a small update to the bias correction term in the Adam\noptimizer that has the advantage of behaving well in the first several steps.\nThe default implementation of Adam may be as sensitive as it is to\nhyperparameters partially due to the originally proposed bias correction\nprocedure, and its behavior in early steps of training.",
    "descriptor": "\nComments: 6 pages, 1 figure\n",
    "authors": [
      "John St John"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10828"
  },
  {
    "id": "arXiv:2110.10829",
    "title": "ReachBot: A Small Robot for Large Mobile Manipulation Tasks",
    "abstract": "Robots are widely deployed in space environments because of their versatility\nand robustness. However, adverse gravity conditions and challenging terrain\ngeometry expose the limitations of traditional robot designs, which are often\nforced to sacrifice one of mobility or manipulation capabilities to attain the\nother. Prospective climbing operations in these environments reveals a need for\nsmall, compact robots capable of versatile mobility and manipulation. We\npropose a novel robotic concept called ReachBot that fills this need by\ncombining two existing technologies: extendable booms and mobile manipulation.\nReachBot leverages the reach and tensile strength of extendable booms to\nachieve an outsized reachable workspace and wrench capability. Through their\nlightweight, compactable structure, these booms also reduce mass and complexity\ncompared to traditional rigid-link articulated-arm designs. Using these\nadvantages, ReachBot excels in mobile manipulation missions in low gravity or\nthat require climbing, particularly when anchor points are sparse. After\nintroducing the ReachBot concept, we discuss modeling approaches and strategies\nfor increasing stability and robustness. We then develop a 2D analytical model\nfor ReachBot's dynamics inspired by grasp models for dexterous manipulators.\nNext, we introduce a waypoint-tracking controller for a planar ReachBot in\nmicrogravity. Our simulation results demonstrate the controller's robustness to\ndisturbances and modeling error. Finally, we briefly discuss next steps that\nbuild on these initially promising results to realize the full potential of\nReachBot.",
    "descriptor": "\nComments: 12 pages, 13 figures\n",
    "authors": [
      "Stephanie Schneider",
      "Andrew Bylard",
      "Tony G. Chen",
      "Preston Wang",
      "Mark Cutkosky",
      "Marco Pavone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.10829"
  },
  {
    "id": "arXiv:2110.10832",
    "title": "Ensemble of Averages: Improving Model Selection and Boosting Performance  in Domain Generalization",
    "abstract": "In Domain Generalization (DG) settings, models trained on a given set of\ntraining domains have notoriously chaotic performance on distribution shifted\ntest domains, and stochasticity in optimization (e.g. seed) plays a big role.\nThis makes deep learning models unreliable in real world settings. We first\nshow that a simple protocol for averaging model parameters along the\noptimization path, starting early during training, both significantly boosts\ndomain generalization and diminishes the impact of stochasticity by improving\nthe rank correlation between the in-domain validation accuracy and out-domain\ntest accuracy, which is crucial for reliable model selection. Next, we show\nthat an ensemble of independently trained models also has a chaotic behavior in\nthe DG setting. Taking advantage of our observation, we show that instead of\nensembling unaveraged models, ensembling moving average models (EoA) from\ndifferent runs does increase stability and further boosts performance. On the\nDomainBed benchmark, when using a ResNet-50 pre-trained on ImageNet, this\nensemble of averages achieves $88.6\\%$ on PACS, $79.1\\%$ on VLCS, $72.5\\%$ on\nOfficeHome, $52.3\\%$ on TerraIncognita, and $47.4\\%$ on DomainNet, an average\nof $68.0\\%$, beating ERM (w/o model averaging) by $\\sim 4\\%$. We also evaluate\na model that is pre-trained on a larger dataset, where we show EoA achieves an\naverage accuracy of $72.7\\%$, beating its corresponding ERM baseline by $5\\%$.",
    "descriptor": "",
    "authors": [
      "Devansh Arpit",
      "Huan Wang",
      "Yingbo Zhou",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10832"
  },
  {
    "id": "arXiv:2110.10833",
    "title": "High-resolution rainfall-runoff modeling using graph neural network",
    "abstract": "Time-series modeling has shown great promise in recent studies using the\nlatest deep learning algorithms such as LSTM (Long Short-Term Memory). These\nstudies primarily focused on watershed-scale rainfall-runoff modeling or\nstreamflow forecasting, but the majority of them only considered a single\nwatershed as a unit. Although this simplification is very effective, it does\nnot take into account spatial information, which could result in significant\nerrors in large watersheds. Several studies investigated the use of GNN (Graph\nNeural Networks) for data integration by decomposing a large watershed into\nmultiple sub-watersheds, but each sub-watershed is still treated as a whole,\nand the geoinformation contained within the watershed is not fully utilized. In\nthis paper, we propose the GNRRM (Graph Neural Rainfall-Runoff Model), a novel\ndeep learning model that makes full use of spatial information from\nhigh-resolution precipitation data, including flow direction and geographic\ninformation. When compared to baseline models, GNRRM has less over-fitting and\nsignificantly improves model performance. Our findings support the importance\nof hydrological data in deep learning-based rainfall-runoff modeling, and we\nencourage researchers to include more domain knowledge in their models.",
    "descriptor": "",
    "authors": [
      "Zhongrun Xiang",
      "Ibrahim Demir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.10833"
  },
  {
    "id": "arXiv:2110.10834",
    "title": "Integrating Visuospatial, Linguistic and Commonsense Structure into  Story Visualization",
    "abstract": "While much research has been done in text-to-image synthesis, little work has\nbeen done to explore the usage of linguistic structure of the input text. Such\ninformation is even more important for story visualization since its inputs\nhave an explicit narrative structure that needs to be translated into an image\nsequence (or visual story). Prior work in this domain has shown that there is\nample room for improvement in the generated image sequence in terms of visual\nquality, consistency and relevance. In this paper, we first explore the use of\nconstituency parse trees using a Transformer-based recurrent architecture for\nencoding structured input. Second, we augment the structured input with\ncommonsense information and study the impact of this external knowledge on the\ngeneration of visual story. Third, we also incorporate visual structure via\nbounding boxes and dense captioning to provide feedback about the\ncharacters/objects in generated images within a dual learning setup. We show\nthat off-the-shelf dense-captioning models trained on Visual Genome can improve\nthe spatial structure of images from a different target domain without needing\nfine-tuning. We train the model end-to-end using intra-story contrastive loss\n(between words and image sub-regions) and show significant improvements in\nseveral metrics (and human evaluation) for multiple datasets. Finally, we\nprovide an analysis of the linguistic and visuo-spatial information. Code and\ndata: https://github.com/adymaharana/VLCStoryGan.",
    "descriptor": "\nComments: EMNLP 2021 (16 pages)\n",
    "authors": [
      "Adyasha Maharana",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10834"
  },
  {
    "id": "arXiv:2110.10836",
    "title": "Application of E-Commerce Technologies in accelerating the Success of  SME Operation",
    "abstract": "Electronic commerce (e-Commerce) technologies have been increased over the\npast two decades in different business sectors. In particular, the technologies\nof B2C operations have significantly improved the productivity of online small\nbusinesses such as SMEs. Systematic literature review in this domain\ncategorized different benefits but a limited number of studies on SME success\nfrom a view of an information systems (IS) research exists, which needs to be\ntaken for further attention. Informing through a comprehensive analysis this\nstudy introduces a conceptual framework of the application of e-Commerce\ntechnologies in accelerating the SME operation. Content analysis methodology\nwas adopted for generating the outcome associated with the success of the\ntechnologies in SMEs.",
    "descriptor": "\nComments: Submitted to ICICT Conf 2022\n",
    "authors": [
      "Ziad Hmwd A Almtiri",
      "Shah J Miah",
      "Nasimul Noman"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.10836"
  },
  {
    "id": "arXiv:2110.10837",
    "title": "A Domain Gap Aware Generative Adversarial Network for Multi-domain Image  Translation",
    "abstract": "Recent image-to-image translation models have shown great success in mapping\nlocal textures between two domains. Existing approaches rely on a\ncycle-consistency constraint that supervises the generators to learn an inverse\nmapping. However, learning the inverse mapping introduces extra trainable\nparameters and it is unable to learn the inverse mapping for some domains. As a\nresult, they are ineffective in the scenarios where (i) multiple visual image\ndomains are involved; (ii) both structure and texture transformations are\nrequired; and (iii) semantic consistency is preserved. To solve these\nchallenges, the paper proposes a unified model to translate images across\nmultiple domains with significant domain gaps. Unlike previous models that\nconstrain the generators with the ubiquitous cycle-consistency constraint to\nachieve the content similarity, the proposed model employs a perceptual\nself-regularization constraint. With a single unified generator, the model can\nmaintain consistency over the global shapes as well as the local texture\ninformation across multiple domains. Extensive qualitative and quantitative\nevaluations demonstrate the effectiveness and superior performance over\nstate-of-the-art models. It is more effective in representing shape deformation\nin challenging mappings with significant dataset variation across multiple\ndomains.",
    "descriptor": "",
    "authors": [
      "Wenju Xu",
      "Guanghui Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10837"
  },
  {
    "id": "arXiv:2110.10842",
    "title": "SMOF: Squeezing More Out of Filters Yields Hardware-Friendly CNN Pruning",
    "abstract": "For many years, the family of convolutional neural networks (CNNs) has been a\nworkhorse in deep learning. Recently, many novel CNN structures have been\ndesigned to address increasingly challenging tasks. To make them work\nefficiently on edge devices, researchers have proposed various structured\nnetwork pruning strategies to reduce their memory and computational cost.\nHowever, most of them only focus on reducing the number of filter channels per\nlayer without considering the redundancy within individual filter channels. In\nthis work, we explore pruning from another dimension, the kernel size. We\ndevelop a CNN pruning framework called SMOF, which Squeezes More Out of Filters\nby reducing both kernel size and the number of filter channels. Notably, SMOF\nis friendly to standard hardware devices without any customized low-level\nimplementations, and the pruning effort by kernel size reduction does not\nsuffer from the fixed-size width constraint in SIMD units of general-purpose\nprocessors. The pruned networks can be deployed effortlessly with significant\nrunning time reduction. We also support these claims via extensive experiments\non various CNN structures and general-purpose processors for mobile devices.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Yanli Liu",
      "Bochen Guan",
      "Qinwen Xu",
      "Weiyi Li",
      "Shuxue Quan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.10842"
  },
  {
    "id": "arXiv:2110.10849",
    "title": "Using NASA Satellite Data Sources and Geometric Deep Learning to Uncover  Hidden Patterns in COVID-19 Clinical Severity",
    "abstract": "As multiple adverse events in 2021 illustrated, virtually all aspects of our\nsocietal functioning -- from water and food security to energy supply to\nhealthcare -- more than ever depend on the dynamics of environmental factors.\nNevertheless, the social dimensions of weather and climate are noticeably less\nexplored by the machine learning community, largely, due to the lack of\nreliable and easy access to use data. Here we present a unique not yet broadly\navailable NASA's satellite dataset on aerosol optical depth (AOD), temperature\nand relative humidity and discuss the utility of these new data for COVID-19\nbiosurveillance. In particular, using the geometric deep learning models for\nsemi-supervised classification on a county-level basis over the contiguous\nUnited States, we investigate the pressing societal question whether\natmospheric variables have considerable impact on COVID-19 clinical severity.",
    "descriptor": "\nComments: Main Paper and Appendix\n",
    "authors": [
      "Ignacio Segovia-Dominguez",
      "Huikyo Lee",
      "Zhiwei Zhen",
      "Yuzhou Chen",
      "Michael Garay",
      "Daniel Crichton",
      "Rishabh Wagh",
      "Yulia R. Gel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.10849"
  },
  {
    "id": "arXiv:2110.10850",
    "title": "Locality-Sensitive Experience Replay for Online Recommendation",
    "abstract": "Online recommendation requires handling rapidly changing user preferences.\nDeep reinforcement learning (DRL) is gaining interest as an effective means of\ncapturing users' dynamic interest during interactions with recommender systems.\nHowever, it is challenging to train a DRL agent, due to large state space\n(e.g., user-item rating matrix and user profiles), action space (e.g.,\ncandidate items), and sparse rewards. Existing studies encourage the agent to\nlearn from past experience via experience replay (ER). They adapt poorly to the\ncomplex environment of online recommender systems and are inefficient in\ndetermining an optimal strategy from past experience. To address these issues,\nwe design a novel state-aware experience replay model, which uses\nlocality-sensitive hashing to map high dimensional data into low-dimensional\nrepresentations and a prioritized reward-driven strategy to replay more\nvaluable experience at a higher chance. Our model can selectively pick the most\nrelevant and salient experiences and recommend the agent with the optimal\npolicy. Experiments on three online simulation platforms demonstrate our model'\nfeasibility and superiority toseveral existing experience replay methods.",
    "descriptor": "",
    "authors": [
      "Xiaocong Chen",
      "Lina Yao",
      "Xianzhi Wang",
      "Julian McAuley"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.10850"
  },
  {
    "id": "arXiv:2110.10854",
    "title": "Performance Analysis for Covert Communications Under Faster-than-Nyquist  Signaling",
    "abstract": "In this letter, we analyze the performance of covert communications under\nfaster-than-Nyquist (FTN) signaling in an additive white Gaussian noise\nchannel. Both Neyman-Pearson criterion- and Kullback-Leibler (KL)\ndivergence-based covertness constraints are considered. Especially, for KL\ndivergence-based one, we prove that both the maximum transmit power and covert\nrate under FTN signaling are higher than those under Nyquist signaling.\nNumerical results coincide with our analysis and validate the advantages of FTN\nsignaling to realize covert data transmission.",
    "descriptor": "\nComments: 5 pages, 4 figures. The paper has been submitted to IEEE Communications Letters on 20-Oct-2021\n",
    "authors": [
      "Yuan Li",
      "Yuchen Zhang",
      "Wanyu Xiang",
      "Jianquan Wang",
      "Sa Xiao",
      "Liang Chang",
      "Wanbin Tang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.10854"
  },
  {
    "id": "arXiv:2110.10857",
    "title": "Vortex: Extending the RISC-V ISA for GPGPU and 3D-GraphicsResearch",
    "abstract": "The importance of open-source hardware and software has been increasing.\nHowever, despite GPUs being one of the more popular accelerators across various\napplications, there is very little open-source GPU infrastructure in the public\ndomain. We argue that one of the reasons for the lack of open-source\ninfrastructure for GPUs is rooted in the complexity of their ISA and software\nstacks.In this work, we first propose an ISA extension to RISC-V that supports\nGPGPUs and graphics. The main goal of the ISA extension proposal is to minimize\nthe ISA changes so that the corresponding changes to the open-source ecosystem\nare also minimal, which makes for a sustainable development ecosystem. To\ndemonstrate the feasibility of the minimally extended RISC-V ISA, we\nimplemented the complete software and hardware stacks of Vortex on FPGA. Vortex\nis a PCIe-based soft GPU that supports OpenCL and OpenGL.Vortex can be used in\na variety of applications, including machine learning, graph analytics, and\ngraphics rendering. Vortex can scale up to 32 cores on an Altera Stratix 10\nFPGA, delivering a peak performance of 25.6 GFlops at 200 Mhz.",
    "descriptor": "",
    "authors": [
      "Blaise Tine",
      "Fares Elsabbagh",
      "Krishna Yalamarthy",
      "Hyesoon Kim"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2110.10857"
  },
  {
    "id": "arXiv:2110.10858",
    "title": "Utilizing Redundancy in Cost Functions for Resilience in Distributed  Optimization and Learning",
    "abstract": "This paper considers the problem of resilient distributed optimization and\nstochastic machine learning in a server-based architecture. The system\ncomprises a server and multiple agents, where each agent has a local cost\nfunction. The agents collaborate with the server to find a minimum of their\naggregate cost functions. We consider the case when some of the agents may be\nasynchronous and/or Byzantine faulty. In this case, the classical algorithm of\ndistributed gradient descent (DGD) is rendered ineffective. Our goal is to\ndesign techniques improving the efficacy of DGD with asynchrony and Byzantine\nfailures. To do so, we start by proposing a way to model the agents' cost\nfunctions by the generic notion of $(f, \\,r; \\epsilon)$-redundancy where $f$\nand $r$ are the parameters of Byzantine failures and asynchrony, respectively,\nand $\\epsilon$ characterizes the closeness between agents' cost functions. This\nallows us to quantify the level of redundancy present amongst the agents' cost\nfunctions, for any given distributed optimization problem. We demonstrate, both\ntheoretically and empirically, the merits of our proposed redundancy model in\nimproving the robustness of DGD against asynchronous and Byzantine agents, and\ntheir extensions to distributed stochastic gradient descent (D-SGD) for robust\ndistributed machine learning with asynchronous and Byzantine agents.",
    "descriptor": "\nComments: 66 pages, 1 figure, and 1 table. Supersede our previous report arXiv:2106.03998 in asynchronous distributed optimization by containing the most of its results\n",
    "authors": [
      "Shuo Liu",
      "Nirupam Gupta",
      "Nitin Vaidya"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10858"
  },
  {
    "id": "arXiv:2110.10863",
    "title": "Deep Generative Models in Engineering Design: A Review",
    "abstract": "Automated design synthesis has the potential to revolutionize the modern\nhuman design process and improve access to highly optimized and customized\nproducts across countless industries. Successfully adapting generative Machine\nLearning to design engineering may be the key to such automated design\nsynthesis and is a research subject of great importance. We present a review\nand analysis of Deep Generative Learning models in engineering design. Deep\nGenerative Models (DGMs) typically leverage deep networks to learn from an\ninput dataset and learn to synthesize new designs. Recently, DGMs such as\nGenerative Adversarial Networks (GANs), Variational Autoencoders (VAEs),\nfeedforward Neural Networks (NNs) and certain Deep Reinforcement Learning (DRL)\nframeworks have shown promising results in design applications like structural\noptimization, materials design, and shape synthesis. The prevalence of DGMs in\nEngineering Design has skyrocketed since 2016. Anticipating continued growth,\nwe conduct a review of recent advances with the hope of benefitting researchers\ninterested in DGMs for design. We structure our review as an exposition of the\nalgorithms, datasets, representation methods, and applications commonly used in\nthe current literature. In particular, we discuss key works that have\nintroduced new techniques and methods in DGMs, successfully applied DGMs to a\ndesign-related domain, or directly supported development of DGMs through\ndatasets or auxiliary methods. We further identify key challenges and\nlimitations currently seen in DGMs across design fields, such as design\ncreativity, handling complex constraints and objectives, and modeling both form\nand functional performance simultaneously. In our discussion we identify\npossible solution pathways as key areas on which to target future work.",
    "descriptor": "",
    "authors": [
      "Lyle Regenwetter",
      "Amin Heyrani Nobari",
      "Faez Ahmed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.10863"
  },
  {
    "id": "arXiv:2110.10864",
    "title": "Class-Discriminative CNN Compression",
    "abstract": "Compressing convolutional neural networks (CNNs) by pruning and distillation\nhas received ever-increasing focus in the community. In particular, designing a\nclass-discrimination based approach would be desired as it fits seamlessly with\nthe CNNs training objective. In this paper, we propose class-discriminative\ncompression (CDC), which injects class discrimination in both pruning and\ndistillation to facilitate the CNNs training goal. We first study the\neffectiveness of a group of discriminant functions for channel pruning, where\nwe include well-known single-variate binary-class statistics like Student's\nT-Test in our study via an intuitive generalization. We then propose a novel\nlayer-adaptive hierarchical pruning approach, where we use a coarse class\ndiscrimination scheme for early layers and a fine one for later layers. This\nmethod naturally accords with the fact that CNNs process coarse semantics in\nthe early layers and extract fine concepts at the later. Moreover, we leverage\ndiscriminant component analysis (DCA) to distill knowledge of intermediate\nrepresentations in a subspace with rich discriminative information, which\nenhances hidden layers' linear separability and classification accuracy of the\nstudent. Combining pruning and distillation, CDC is evaluated on CIFAR and\nILSVRC 2012, where we consistently outperform the state-of-the-art results.",
    "descriptor": "",
    "authors": [
      "Yuchen Liu",
      "David Wentzlaff",
      "S.Y. Kung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10864"
  },
  {
    "id": "arXiv:2110.10869",
    "title": "LC3Net: Ladder context correlation complementary network for salient  object detection",
    "abstract": "Currently, existing salient object detection methods based on convolutional\nneural networks commonly resort to constructing discriminative networks to\naggregate high level and low level features. However, contextual information is\nalways not fully and reasonably utilized, which usually causes either the\nabsence of useful features or contamination of redundant features. To address\nthese issues, we propose a novel ladder context correlation complementary\nnetwork (LC3Net) in this paper, which is equipped with three crucial\ncomponents. At the beginning, we propose a filterable convolution block (FCB)\nto assist the automatic collection of information on the diversity of initial\nfeatures, and it is simple yet practical. Besides, we propose a dense cross\nmodule (DCM) to facilitate the intimate aggregation of different levels of\nfeatures by validly integrating semantic information and detailed information\nof both adjacent and non-adjacent layers. Furthermore, we propose a\nbidirectional compression decoder (BCD) to help the progressive shrinkage of\nmulti-scale features from coarse to fine by leveraging multiple pairs of\nalternating top-down and bottom-up feature interaction flows. Extensive\nexperiments demonstrate the superiority of our method against 16\nstate-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Xian Fang",
      "Jinchao Zhu",
      "Xiuli Shao",
      "Hongpeng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10869"
  },
  {
    "id": "arXiv:2110.10871",
    "title": "Principled Representation Learning for Entity Alignment",
    "abstract": "Embedding-based entity alignment (EEA) has recently received great attention.\nDespite significant performance improvement, few efforts have been paid to\nfacilitate understanding of EEA methods. Most existing studies rest on the\nassumption that a small number of pre-aligned entities can serve as anchors\nconnecting the embedding spaces of two KGs. Nevertheless, no one investigates\nthe rationality of such an assumption. To fill the research gap, we define a\ntypical paradigm abstracted from existing EEA methods and analyze how the\nembedding discrepancy between two potentially aligned entities is implicitly\nbounded by a predefined margin in the scoring function. Further, we find that\nsuch a bound cannot guarantee to be tight enough for alignment learning. We\nmitigate this problem by proposing a new approach, named NeoEA, to explicitly\nlearn KG-invariant and principled entity embeddings. In this sense, an EEA\nmodel not only pursues the closeness of aligned entities based on geometric\ndistance, but also aligns the neural ontologies of two KGs by eliminating the\ndiscrepancy in embedding distribution and underlying ontology knowledge. Our\nexperiments demonstrate consistent and significant improvement in performance\nagainst the best-performing EEA methods.",
    "descriptor": "",
    "authors": [
      "Lingbing Guo",
      "Zequn Sun",
      "Mingyang Chen",
      "Wei Hu",
      "Qiang Zhang",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10871"
  },
  {
    "id": "arXiv:2110.10872",
    "title": "HENet: Forcing a Network to Think More for Font Recognition",
    "abstract": "Although lots of progress were made in Text Recognition/OCR in recent years,\nthe task of font recognition is remaining challenging. The main challenge lies\nin the subtle difference between these similar fonts, which is hard to\ndistinguish. This paper proposes a novel font recognizer with a pluggable\nmodule solving the font recognition task. The pluggable module hides the most\ndiscriminative accessible features and forces the network to consider other\ncomplicated features to solve the hard examples of similar fonts, called HE\nBlock. Compared with the available public font recognition systems, our\nproposed method does not require any interactions at the inference stage.\nExtensive experiments demonstrate that HENet achieves encouraging performance,\nincluding on character-level dataset Explor_all and word-level dataset AdobeVFR",
    "descriptor": "\nComments: 8 pages, 2021 3rd International Conference on Advanced Information Science and System (AISS 2021)\n",
    "authors": [
      "Jingchao Chen",
      "Shiyi Mu",
      "Shugong Xu",
      "Youdong Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10872"
  },
  {
    "id": "arXiv:2110.10873",
    "title": "Controllable and Compositional Generation with Latent-Space Energy-Based  Models",
    "abstract": "Controllable generation is one of the key requirements for successful\nadoption of deep generative models in real-world applications, but it still\nremains as a great challenge. In particular, the compositional ability to\ngenerate novel concept combinations is out of reach for most current models. In\nthis work, we use energy-based models (EBMs) to handle compositional generation\nover a set of attributes. To make them scalable to high-resolution image\ngeneration, we introduce an EBM in the latent space of a pre-trained generative\nmodel such as StyleGAN. We propose a novel EBM formulation representing the\njoint distribution of data and attributes together, and we show how sampling\nfrom it is formulated as solving an ordinary differential equation (ODE). Given\na pre-trained generator, all we need for controllable generation is to train an\nattribute classifier. Sampling with ODEs is done efficiently in the latent\nspace and is robust to hyperparameters. Thus, our method is simple, fast to\ntrain, and efficient to sample. Experimental results show that our method\noutperforms the state-of-the-art in both conditional sampling and sequential\nediting. In compositional generation, our method excels at zero-shot generation\nof unseen attribute combinations. Also, by composing energy functions with\nlogical operators, this work is the first to achieve such compositionality in\ngenerating photo-realistic images of resolution 1024x1024.",
    "descriptor": "\nComments: 32 pages, NeurIPS 2021\n",
    "authors": [
      "Weili Nie",
      "Arash Vahdat",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10873"
  },
  {
    "id": "arXiv:2110.10874",
    "title": "CNewSum: A Large-scale Chinese News Summarization Dataset with  Human-annotated Adequacy and Deducibility Level",
    "abstract": "Automatic text summarization aims to produce a brief but crucial summary for\nthe input documents. Both extractive and abstractive methods have witnessed\ngreat success in English datasets in recent years. However, there has been a\nminimal exploration of text summarization in Chinese, limited by the lack of\nlarge-scale datasets. In this paper, we present a large-scale Chinese news\nsummarization dataset CNewSum, which consists of 304,307 documents and\nhuman-written summaries for the news feed. It has long documents with\nhigh-abstractive summaries, which can encourage document-level understanding\nand generation for current summarization models. An additional distinguishing\nfeature of CNewSum is that its test set contains adequacy and deducibility\nannotations for the summaries. The adequacy level measures the degree of\nsummary information covered by the document, and the deducibility indicates the\nreasoning ability the model needs to generate the summary. These annotations\ncan help researchers analyze and target their model performance bottleneck. We\nexamine recent methods on CNewSum and release our dataset to provide a solid\ntestbed for automatic Chinese summarization research.",
    "descriptor": "",
    "authors": [
      "Danqing Wang",
      "Jiaze Chen",
      "Xianze Wu",
      "Hao Zhou",
      "Lei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.10874"
  },
  {
    "id": "arXiv:2110.10876",
    "title": "Evolving Transferable Pruning Functions",
    "abstract": "Channel pruning has made major headway in the design of efficient deep\nlearning models. Conventional approaches adopt human-made pruning functions to\nscore channels' importance for channel pruning, which requires domain knowledge\nand could be sub-optimal. In this work, we propose an end-to-end framework to\nautomatically discover strong pruning metrics. Specifically, we craft a novel\ndesign space for expressing pruning functions and leverage an evolution\nstrategy, genetic programming, to evolve high-quality and transferable pruning\nfunctions. Unlike prior methods, our approach can not only provide compact\npruned networks for efficient inference, but also novel closed-form pruning\nmetrics that are mathematically explainable and thus generalizable to different\npruning tasks. The evolution is conducted on small datasets while the learned\nfunctions are transferable to larger datasets without any manual modification.\nCompared to direct evolution on a large dataset, our strategy shows better\ncost-effectiveness. When applied to more challenging datasets, different from\nthose used in the evolution process, e.g., ILSVRC-2012, an evolved function\nachieves state-of-the-art pruning results.",
    "descriptor": "",
    "authors": [
      "Yuchen Liu",
      "S.Y. Kung",
      "David Wentzlaff"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10876"
  },
  {
    "id": "arXiv:2110.10877",
    "title": "Decision Theoretic Cutoff and ROC Analysis for Bayesian Optimal Group  Testing",
    "abstract": "We study the inference problem in the group testing to identify defective\nitems from the perspective of the decision theory. We introduce Bayesian\ninference and consider the Bayesian optimal setting in which the true\ngenerative process of the test results is known. We demonstrate the adequacy of\nthe posterior marginal probability in the Bayesian optimal setting as a\ndiagnostic variable based on the area under the curve (AUC). Using the\nposterior marginal probability, we derive the general expression of the optimal\ncutoff value that yields the minimum expected risk function. Furthermore, we\nevaluate the performance of the Bayesian group testing without knowing the true\nstates of the items: defective or non-defective. By introducing an analytical\nmethod from statistical physics, we derive the receiver operating\ncharacteristics curve, and quantify the corresponding AUC under the Bayesian\noptimal setting. The obtained analytical results precisely describes the actual\nperformance of the belief propagation algorithm defined for single samples when\nthe number of items is sufficiently large.",
    "descriptor": "\nComments: 17 pages, 8 figures\n",
    "authors": [
      "Ayaka Sakata",
      "Yoshiyuki Kabashima"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)"
    ],
    "url": "https://arxiv.org/abs/2110.10877"
  },
  {
    "id": "arXiv:2110.10881",
    "title": "Threshold Tests as Quality Signals: Optimal Strategies, Equilibria, and  Price of Anarchy",
    "abstract": "We study a signaling game between two firms competing to have their product\nchosen by a principal. The products have qualities drawn i.i.d. from a common\nprior. The principal aims to choose the better product, but the quality of a\nproduct can only be estimated via a coarse-grained threshold test: for chosen\n$\\theta$, the principal learns whether a product's quality exceeds $\\theta$ or\nnot.\nWe study this problem under two types of interactions. In the first, the\nprincipal does the testing herself, and can choose tests from a class of\nallowable tests. We show that the optimum strategy for the principal is to\nadminister different tests to the two products: one which is passed with\nprobability $\\frac{1}{3}$ and the other with probability $\\frac{2}{3}$. If,\nhowever, the principal is required to choose the tests in a symmetric manner\n(i.e., via an i.i.d.~distribution), then the optimal strategy is to choose\ntests whose probability of passing is drawn uniformly from $[\\frac{1}{4},\n\\frac{3}{4}]$.\nIn our second model, test difficulties are selected endogenously by the\nfirms. This corresponds to a setting in which the firms must commit to their\ntesting procedures before knowing the quality of their products. This\ninteraction naturally gives rise to a signaling game; we characterize the\nunique Bayes-Nash Equilibrium of this game, which happens to be symmetric. We\nthen calculate its Price of Anarchy in terms of the principal's probability of\nchoosing the worse product. Finally, we show that by restricting both firms'\nset of available thresholds to choose from, the principal can lower the Price\nof Anarchy of the resulting equilibrium; however, there is a limit, in that for\nevery (common) restricted set of tests, the equilibrium failure probability is\nstrictly larger than under the optimal i.i.d. distribution.",
    "descriptor": "\nComments: 43 pages, 3 figures, to appear at WINE 2021\n",
    "authors": [
      "Siddhartha Banerjee",
      "David Kempe",
      "Robert Kleinberg"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.10881"
  },
  {
    "id": "arXiv:2110.10887",
    "title": "A Real-Time Energy and Cost Efficient Vehicle Route Assignment Neural  Recommender System",
    "abstract": "This paper presents a neural network recommender system algorithm for\nassigning vehicles to routes based on energy and cost criteria. In this work,\nwe applied this new approach to efficiently identify the most cost-effective\nmedium and heavy duty truck (MDHDT) powertrain technology, from a total cost of\nownership (TCO) perspective, for given trips. We employ a machine learning\nbased approach to efficiently estimate the energy consumption of various\ncandidate vehicles over given routes, defined as sequences of links (road\nsegments), with little information known about internal dynamics, i.e using\nhigh level macroscopic route information. A complete recommendation logic is\nthen developed to allow for real-time optimum assignment for each route,\nsubject to the operational constraints of the fleet. We show how this framework\ncan be used to (1) efficiently provide a single trip recommendation with a\ntop-$k$ vehicles star ranking system, and (2) engage in more general assignment\nproblems where $n$ vehicles need to be deployed over $m \\leq n$ trips. This new\nassignment system has been deployed and integrated into the POLARIS\nTransportation System Simulation Tool for use in research conducted by the\nDepartment of Energy's Systems and Modeling for Accelerated Research in\nTransportation (SMART) Mobility Consortium",
    "descriptor": "\nComments: 14 pages, 11 figures\n",
    "authors": [
      "Ayman Moawad",
      "Zhijian Li",
      "Ines Pancorbo",
      "Krishna Murthy Gurumurthy",
      "Vincent Freyermuth",
      "Ehsan Islam",
      "Ram Vijayagopal",
      "Monique Stinson",
      "Aymeric Rousseau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.10887"
  },
  {
    "id": "arXiv:2110.10895",
    "title": "Finite Volume Least-Squares Neural Network (FV-LSNN) Method for Scalar  Nonlinear Hyperbolic Conservation Laws",
    "abstract": "In [4], we introduced the least-squares ReLU neural network (LSNN) method for\nsolving the linear advection-reaction problem with discontinuous solution and\nshowed that the number of degrees of freedom for the LSNN method is\nsignificantly less than that of traditional mesh-based methods. The LSNN method\nis a discretization of an equivalent least-squares (LS) formulation in the\nclass of neural network functions with the ReLU activation function; and\nevaluation of the LS functional is done by using numerical integration and\nproper numerical differentiation.\nBy developing a novel finite volume approximation (FVA) to the divergence\noperator, this paper studies the LSNN method for scalar nonlinear hyperbolic\nconservation laws. The FVA introduced in this paper is tailored to the LSNN\nmethod and is more accurate than traditional, well-studied FV schemes used in\nmesh-based numerical methods. Numerical results of some benchmark test problems\nwith both convex and non-convex fluxes show that the finite volume LSNN\n(FV-LSNN) method is capable of computing the physical solution for problems\nwith rarefaction waves and capturing the shock of the underlying problem\nautomatically through the free hyper-planes of the ReLU neural network.\nMoreover, the method does not exhibit the common Gibbs phenomena along the\ndiscontinuous interface.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2105.11627\n",
    "authors": [
      "Zhiqiang Cai",
      "Jingshuang Chen",
      "Min Liu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10895"
  },
  {
    "id": "arXiv:2110.10897",
    "title": "Privacy-Aware Identity Cloning Detection based on Deep Forest",
    "abstract": "We propose a novel method to detect identity cloning of social-sensor cloud\nservice providers to prevent the detrimental outcomes caused by identity\ndeception. This approach leverages non-privacy-sensitive user profile data\ngathered from social networks and a powerful deep learning model to perform\ncloned identity detection. We evaluated the proposed method against the\nstate-of-the-art identity cloning detection techniques and the other popular\nidentity deception detection models atop a real-world dataset. The results show\nthat our method significantly outperforms these techniques/models in terms of\nPrecision and F1-score.",
    "descriptor": "\nComments: The 19th International Conference on Service Oriented Computing (ICSOC 2021). arXiv admin note: text overlap with arXiv:2109.15179\n",
    "authors": [
      "Ahmed Alharbi",
      "Hai Dong",
      "Xun Yi",
      "Prabath Abeysekara"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10897"
  },
  {
    "id": "arXiv:2110.10898",
    "title": "Deep Image Matting with Flexible Guidance Input",
    "abstract": "Image matting is an important computer vision problem. Many existing matting\nmethods require a hand-made trimap to provide auxiliary information, which is\nvery expensive and limits the real world usage. Recently, some trimap-free\nmethods have been proposed, which completely get rid of any user input.\nHowever, their performance lag far behind trimap-based methods due to the lack\nof guidance information. In this paper, we propose a matting method that use\nFlexible Guidance Input as user hint, which means our method can use trimap,\nscribblemap or clickmap as guidance information or even work without any\nguidance input. To achieve this, we propose Progressive Trimap Deformation(PTD)\nscheme that gradually shrink the area of the foreground and background of the\ntrimap with the training step increases and finally become a scribblemap. To\nmake our network robust to any user scribble and click, we randomly sample\npoints on foreground and background and perform curve fitting. Moreover, we\npropose Semantic Fusion Module(SFM) which utilize the Feature Pyramid\nEnhancement Module(FPEM) and Joint Pyramid Upsampling(JPU) in matting task for\nthe first time. The experiments show that our method can achieve\nstate-of-the-art results comparing with existing trimap-based and trimap-free\nmethods.",
    "descriptor": "\nComments: Accepted to BMVC2021\n",
    "authors": [
      "Hang Cheng",
      "Shugong Xu",
      "Xiufeng Jiang",
      "Rongrong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10898"
  },
  {
    "id": "arXiv:2110.10899",
    "title": "LARNet: Latent Action Representation for Human Action Synthesis",
    "abstract": "We present LARNet, a novel end-to-end approach for generating human action\nvideos. A joint generative modeling of appearance and dynamics to synthesize a\nvideo is very challenging and therefore recent works in video synthesis have\nproposed to decompose these two factors. However, these methods require a\ndriving video to model the video dynamics. In this work, we propose a\ngenerative approach instead, which explicitly learns action dynamics in latent\nspace avoiding the need of a driving video during inference. The generated\naction dynamics is integrated with the appearance using a recurrent\nhierarchical structure which induces motion at different scales to focus on\nboth coarse as well as fine level action details. In addition, we propose a\nnovel mix-adversarial loss function which aims at improving the temporal\ncoherency of synthesized videos. We evaluate the proposed approach on four\nreal-world human action datasets demonstrating the effectiveness of the\nproposed approach in generating human actions. The code and models will be made\npublicly available.",
    "descriptor": "\nComments: British Machine Vision Conference (BMVC) 2021\n",
    "authors": [
      "Naman Biyani",
      "Aayush J Rana",
      "Shruti Vyas",
      "Yogesh S Rawat"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10899"
  },
  {
    "id": "arXiv:2110.10901",
    "title": "A Fast Location Algorithm for Very Sparse Point Clouds Based on Object  Detection",
    "abstract": "Limited by the performance factor, it is arduous to recognize target object\nand locate it in Augmented Reality (AR) scenes on low-end mobile devices,\nespecially which using monocular cameras. In this paper, we proposed an\nalgorithm which can quickly locate the target object through image object\ndetection in the circumstances of having very sparse feature points. We\nintroduce YOLOv3-Tiny to our algorithm as the object detection module to filter\nthe possible points and using Principal Component Analysis (PCA) to determine\nthe location. We conduct the experiment in a manually designed scene by holding\na smartphone and the results represent high positioning speed and accuracy of\nour method.",
    "descriptor": "",
    "authors": [
      "Shiyu Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10901"
  },
  {
    "id": "arXiv:2110.10905",
    "title": "Efficient Robotic Manipulation Through Offline-to-Online Reinforcement  Learning and Goal-Aware State Information",
    "abstract": "End-to-end learning robotic manipulation with high data efficiency is one of\nthe key challenges in robotics. The latest methods that utilize human\ndemonstration data and unsupervised representation learning has proven to be a\npromising direction to improve RL learning efficiency. The use of demonstration\ndata also allows \"warming-up\" the RL policies using offline data with imitation\nlearning or the recently emerged offline reinforcement learning algorithms.\nHowever, existing works often treat offline policy learning and online\nexploration as two separate processes, which are often accompanied by severe\nperformance drop during the offline-to-online transition. Furthermore, many\nrobotic manipulation tasks involve complex sub-task structures, which are very\nchallenging to be solved in RL with sparse reward. In this work, we propose a\nunified offline-to-online RL framework that resolves the transition performance\ndrop issue. Additionally, we introduce goal-aware state information to the RL\nagent, which can greatly reduce task complexity and accelerate policy learning.\nCombined with an advanced unsupervised representation learning module, our\nframework achieves great training efficiency and performance compared with the\nstate-of-the-art methods in multiple robotic manipulation tasks.",
    "descriptor": "",
    "authors": [
      "Jin Li",
      "Xianyuan Zhan",
      "Zixu Xiao",
      "Guyue Zhou"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10905"
  },
  {
    "id": "arXiv:2110.10906",
    "title": "Single-Modal Entropy based Active Learning for Visual Question Answering",
    "abstract": "Constructing a large-scale labeled dataset in the real world, especially for\nhigh-level tasks (eg, Visual Question Answering), can be expensive and\ntime-consuming. In addition, with the ever-growing amounts of data and\narchitecture complexity, Active Learning has become an important aspect of\ncomputer vision research. In this work, we address Active Learning in the\nmulti-modal setting of Visual Question Answering (VQA). In light of the\nmulti-modal inputs, image and question, we propose a novel method for effective\nsample acquisition through the use of ad hoc single-modal branches for each\ninput to leverage its information. Our mutual information based sample\nacquisition strategy Single-Modal Entropic Measure (SMEM) in addition to our\nself-distillation technique enables the sample acquisitor to exploit all\npresent modalities and find the most informative samples. Our novel idea is\nsimple to implement, cost-efficient, and readily adaptable to other multi-modal\ntasks. We confirm our findings on various VQA datasets through state-of-the-art\nperformance by comparing to existing Active Learning baselines.",
    "descriptor": "\nComments: Accepted to BMVC 2021\n",
    "authors": [
      "Dong-Jin Kim",
      "Jae Won Cho",
      "Jinsoo Choi",
      "Yunjae Jung",
      "In So Kweon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10906"
  },
  {
    "id": "arXiv:2110.10909",
    "title": "On the benefits of being constrained when receiving signals",
    "abstract": "We study a Bayesian persuasion setting in which the receiver is trying to\nmatch the (binary) state of the world. The sender's utility is partially\naligned with the receiver's, in that conditioned on the receiver's action, the\nsender derives higher utility when the state of the world matches the action.\nOur focus is on whether, in such a setting, being constrained helps a\nreceiver. Intuitively, if the receiver can only take the sender's preferred\naction with a smaller probability, the sender might have to reveal more\ninformation, so that the receiver can take the action more specifically when\nthe sender prefers it. We show that with a binary state of the world, this\nintuition indeed carries through: under very mild non-degeneracy conditions, a\nmore constrained receiver will always obtain (weakly) higher utility than a\nless constrained one. Unfortunately, without additional assumptions, the result\ndoes not hold when there are more than two states in the world, which we show\nwith an explicit example.",
    "descriptor": "",
    "authors": [
      "Shih-Tang Su",
      "David Kempe",
      "Vijay G. Subramanian"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.10909"
  },
  {
    "id": "arXiv:2110.10913",
    "title": "WENO interpolations and reconstructions using data bounded polynomial  approximation",
    "abstract": "This work characterizes the structure of third and forth order WENO weights\nby deducing data bounded condition on third order polynomial approximations.\nUsing these conditions, non-linear weights are defined for third and fourth\norder data bounded weighted essentially non-oscillatory (WENO) approximations.\nComputational results show that data bounded WENO approximations for smooth\nfunctions achieve required accuracy and do not exhibit overshoot or undershoot\nfor functions with discontinuities and extrema. Further with suitable weights,\nhigh order data-bounded WENO approximations are proposed for WENO schemes.",
    "descriptor": "\nComments: 21 pages, 7 figures, 2 Tables\n",
    "authors": [
      "Sabana Parvin",
      "Ritesh Kumar Dubey"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.10913"
  },
  {
    "id": "arXiv:2110.10914",
    "title": "An Empirical Evaluation of Time-Series Feature Sets",
    "abstract": "Solving time-series problems with features has been rising in popularity due\nto the availability of software for feature extraction. Feature-based\ntime-series analysis can now be performed using many different feature sets,\nincluding hctsa (7730 features: Matlab), feasts (42 features: R), tsfeatures\n(63 features: R), Kats (40 features: Python), tsfresh (up to 1558 features:\nPython), TSFEL (390 features: Python), and the C-coded catch22 (22 features:\nMatlab, R, Python, and Julia). There is substantial overlap in the types of\nmethods included in these sets (e.g., properties of the autocorrelation\nfunction and Fourier power spectrum), but they are yet to be systematically\ncompared. Here we compare these seven sets on computational speed, assess the\nredundancy of features contained in each, and evaluate the overlap and\nredundancy between them. We take an empirical approach to feature similarity\nbased on outputs across a diverse set of real-world and simulated time series.\nWe find that feature sets vary across three orders of magnitude in their\ncomputation time per feature on a laptop for a 1000-sample series, from the\nfastest sets catch22 and TSFEL (~0.1ms per feature) to tsfeatures (~3s per\nfeature). Using PCA to evaluate feature redundancy within each set, we find the\nhighest within-set redundancy for TSFEL and tsfresh. For example, in TSFEL, 90%\nof the variance across 390 features can be captured with just four PCs.\nFinally, we introduce a metric for quantifying overlap between pairs of feature\nsets, which indicates substantial overlap. We found that the largest feature\nset, hctsa, is the most comprehensive, and that tsfresh is the most\ndistinctive, due to its incorporation of many low-level Fourier coefficients.\nOur results provide empirical understanding of the differences between existing\nfeature sets, information that can be used to better tailor feature sets to\ntheir applications.",
    "descriptor": "\nComments: Submitted to and accepted for publication in SFE-TSDM Workshop at 21st IEEE International Conference on Data Mining (IEEE ICDM 2021)\n",
    "authors": [
      "Trent Henderson",
      "Ben D. Fulcher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10914"
  },
  {
    "id": "arXiv:2110.10915",
    "title": "On some theoretical limitations of Generative Adversarial Networks",
    "abstract": "Generative Adversarial Networks have become a core technique in Machine\nLearning to generate unknown distributions from data samples. They have been\nused in a wide range of context without paying much attention to the possible\ntheoretical limitations of those models. Indeed, because of the universal\napproximation properties of Neural Networks, it is a general assumption that\nGANs can generate any probability distribution. Recently, people began to\nquestion this assumption and this article is in line with this thinking. We\nprovide a new result based on Extreme Value Theory showing that GANs can't\ngenerate heavy tailed distributions. The full proof of this result is given.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Beno\u00eet Oriol",
      "Alexandre Miot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10915"
  },
  {
    "id": "arXiv:2110.10916",
    "title": "Exploiting Inter-pixel Correlations in Unsupervised Domain Adaptation  for Semantic Segmentation",
    "abstract": "\"Self-training\" has become a dominant method for semantic segmentation via\nunsupervised domain adaptation (UDA). It creates a set of pseudo labels for the\ntarget domain to give explicit supervision. However, the pseudo labels are\nnoisy, sparse and do not provide any information about inter-pixel\ncorrelations. We regard inter-pixel correlation quite important because\nsemantic segmentation is a task of predicting highly structured pixel-level\noutputs. Therefore, in this paper, we propose a method of transferring the\ninter-pixel correlations from the source domain to the target domain via a\nself-attention module. The module takes the prediction of the segmentation\nnetwork as an input and creates a self-attended prediction that correlates\nsimilar pixels. The module is trained only on the source domain to learn the\ndomain-invariant inter-pixel correlations, then later, it is used to train the\nsegmentation network on the target domain. The network learns not only from the\npseudo labels but also by following the output of the self-attention module\nwhich provides additional knowledge about the inter-pixel correlations. Through\nextensive experiments, we show that our method significantly improves the\nperformance on two standard UDA benchmarks and also can be combined with recent\nstate-of-the-art method to achieve better performance.",
    "descriptor": "",
    "authors": [
      "Inseop Chung",
      "Jayeon Yoo",
      "Nojun Kwak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10916"
  },
  {
    "id": "arXiv:2110.10919",
    "title": "FlexTOE: Flexible TCP Offload with Fine-Grained Parallelism",
    "abstract": "FlexTOE is a flexible, yet high-performance TCP offload engine (TOE) to\nSmartNICs. FlexTOE eliminates almost all host data-path TCP processing and is\nfully customizable. FlexTOE interoperates well with other TCP stacks, is robust\nunder adverse network conditions, and supports POSIX sockets.\nFlexTOE focuses on data-path offload of established connections, avoiding\ncomplex control logic and packet buffering in the NIC. FlexTOE leverages\nfine-grained parallelization of the TCP data-path and segment reordering for\nhigh performance on wimpy SmartNIC architecture, while remaining flexible via a\nmodular design. We compare FlexTOE to Linux, the TAS software TCP accelerator,\nand the Chelsio Terminator TOE. We find that Memcached scales up to 38% better\non FlexTOE versus TAS, while saving up to 81% host CPU cycles versus Chelsio.\nFlexTOE provides competitive performance for RPCs, even with wimpy SmartNICs.\nFlexTOE cuts 99.99th-percentile RPC RTT by 3.2$\\times$ and 50% versus Chelsio\nand TAS, respectively. FlexTOE's API supports Micro-C and XDP programs written\nin eBPF. It allows us to implement popular data center transport features, such\nas TCP tracing, packet filtering and capture, VLAN stripping, flow\nclassification, firewalling, and connection splicing.",
    "descriptor": "\nComments: 17 pages, 16 figures\n",
    "authors": [
      "Rajath Shashidhara",
      "Timothy Stamler",
      "Antoine Kaufmann",
      "Simon Peter"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2110.10919"
  },
  {
    "id": "arXiv:2110.10921",
    "title": "CATRO: Channel Pruning via Class-Aware Trace Ratio Optimization",
    "abstract": "Deep convolutional neural networks are shown to be overkill with high\nparametric and computational redundancy in many application scenarios, and an\nincreasing number of works have explored model pruning to obtain lightweight\nand efficient networks. However, most existing pruning approaches are driven by\nempirical heuristics and rarely consider the joint impact of channels, leading\nto unguaranteed and suboptimal performance. In this paper, we propose a novel\nchannel pruning method via class-aware trace ratio optimization (CATRO) to\nreduce the computational burden and accelerate the model inference. Utilizing\nclass information from a few samples, CATRO measures the joint impact of\nmultiple channels by feature space discriminations and consolidates the\nlayer-wise impact of preserved channels. By formulating channel pruning as a\nsubmodular set function maximization problem, CATRO solves it efficiently via a\ntwo-stage greedy iterative optimization procedure. More importantly, we present\ntheoretical justifications on convergence and performance of CATRO.\nExperimental results demonstrate that CATRO achieves higher accuracy with\nsimilar computation cost or lower computation cost with similar accuracy than\nother state-of-the-art channel pruning algorithms. In addition, because of its\nclass-aware property, CATRO is suitable to prune efficient networks adaptively\nfor various classification subtasks, enhancing handy deployment and usage of\ndeep networks in real-world applications.",
    "descriptor": "",
    "authors": [
      "Wenzheng Hu",
      "Ning Liu",
      "Zhengping Che",
      "Mingyang Li",
      "Jian Tang",
      "Changshui Zhang",
      "Jianqiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10921"
  },
  {
    "id": "arXiv:2110.10924",
    "title": "Fuzzy-Depth Objects Grasping Based on FSG Algorithm and a Soft Robotic  Hand",
    "abstract": "Autonomous grasping is an important factor for robots physically interacting\nwith the environment and executing versatile tasks. However, a universally\napplicable, cost-effective, and rapidly deployable autonomous grasping approach\nis still limited by those target objects with fuzzy-depth information. Examples\nare transparent, specular, flat, and small objects whose depth is difficult to\nbe accurately sensed. In this work, we present a solution to those fuzzy-depth\nobjects. The framework of our approach includes two major components: one is a\nsoft robotic hand and the other one is a Fuzzy-depth Soft Grasping (FSG)\nalgorithm. The soft hand is replaceable for most existing soft hands/grippers\nwith body compliance. FSG algorithm exploits both RGB and depth images to\npredict grasps while not trying to reconstruct the whole scene. Two grasping\nprimitives are designed to further increase robustness. The proposed method\noutperforms reference baselines in unseen fuzzy-depth objects grasping\nexperiments (84% success rate).",
    "descriptor": "\nComments: accepted by IROS 2021\n",
    "authors": [
      "Hanwen Cao",
      "Junda Huang",
      "Yichuan Li",
      "Jianshu Zhou",
      "Yunhui Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.10924"
  },
  {
    "id": "arXiv:2110.10926",
    "title": "PipAttack: Poisoning Federated Recommender Systems forManipulating Item  Promotion",
    "abstract": "Due to the growing privacy concerns, decentralization emerges rapidly in\npersonalized services, especially recommendation. Also, recent studies have\nshown that centralized models are vulnerable to poisoning attacks, compromising\ntheir integrity. In the context of recommender systems, a typical goal of such\npoisoning attacks is to promote the adversary's target items by interfering\nwith the training dataset and/or process. Hence, a common practice is to\nsubsume recommender systems under the decentralized federated learning\nparadigm, which enables all user devices to collaboratively learn a global\nrecommender while retaining all the sensitive data locally. Without exposing\nthe full knowledge of the recommender and entire dataset to end-users, such\nfederated recommendation is widely regarded `safe' towards poisoning attacks.\nIn this paper, we present a systematic approach to backdooring federated\nrecommender systems for targeted item promotion. The core tactic is to take\nadvantage of the inherent popularity bias that commonly exists in data-driven\nrecommenders. As popular items are more likely to appear in the recommendation\nlist, our innovatively designed attack model enables the target item to have\nthe characteristics of popular items in the embedding space. Then, by uploading\ncarefully crafted gradients via a small number of malicious users during the\nmodel update, we can effectively increase the exposure rate of a target\n(unpopular) item in the resulted federated recommender. Evaluations on two\nreal-world datasets show that 1) our attack model significantly boosts the\nexposure rate of the target item in a stealthy way, without harming the\naccuracy of the poisoned recommender; and 2) existing defenses are not\neffective enough, highlighting the need for new defenses against our local\nmodel poisoning attacks to federated recommender systems.",
    "descriptor": "\nComments: Proceedings of the 15th ACM International Conference on Web Search and Data Mining (WSDM '22)\n",
    "authors": [
      "Shijie Zhang",
      "Hongzhi Yin",
      "Tong Chen",
      "Zi Huang",
      "Quoc Viet Hung Nguyen",
      "Lizhen Cui"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10926"
  },
  {
    "id": "arXiv:2110.10927",
    "title": "SecureBoost+ : A High Performance Gradient Boosting Tree Framework for  Large Scale Vertical Federated Learning",
    "abstract": "Gradient boosting decision tree (GBDT) is a widely used ensemble algorithm in\nthe industry. Its vertical federated learning version, SecureBoost, is one of\nthe most popular algorithms used in cross-silo privacy-preserving modeling. As\nthe area of privacy computation thrives in recent years, demands for\nlarge-scale and high-performance federated learning have grown dramatically in\nreal-world applications. In this paper, to fulfill these requirements, we\npropose SecureBoost+ that is both novel and improved from the prior work\nSecureBoost. SecureBoost+ integrates several ciphertext calculation\noptimizations and engineering optimizations. The experimental results\ndemonstrate that Secureboost+ has significant performance improvements on large\nand high dimensional data sets compared to SecureBoost. It makes effective and\nefficient large-scale vertical federated learning possible.",
    "descriptor": "",
    "authors": [
      "Weijing Chen",
      "Guoqiang Ma",
      "Tao Fan",
      "Yan Kang",
      "Qian Xu",
      "Qiang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10927"
  },
  {
    "id": "arXiv:2110.10928",
    "title": "Quantum field theories, Markov random fields and machine learning",
    "abstract": "The transition to Euclidean space and the discretization of quantum field\ntheories on spatial or space-time lattices opens up the opportunity to\ninvestigate probabilistic machine learning from the perspective of quantum\nfield theory. Here, we will discuss how discretized Euclidean field theories\ncan be recast within the mathematical framework of Markov random fields, which\nis a notable class of probabilistic graphical models with applications in a\nvariety of research areas, including machine learning. Specifically, we will\ndemonstrate that the $\\phi^{4}$ scalar field theory on a square lattice\nsatisfies the Hammersley-Clifford theorem, therefore recasting it as a Markov\nrandom field from which neural networks are additionally derived. We will then\ndiscuss applications pertinent to the minimization of an asymmetric distance\nbetween the probability distribution of the $\\phi^{4}$ machine learning\nalgorithms and that of target probability distributions.",
    "descriptor": "\nComments: Contribution submitted to the CCP2021: XXXII IUPAP Conference on Computational Physics, Coventry University, United Kingdom. arXiv admin note: substantial text overlap with arXiv:2109.07730\n",
    "authors": [
      "Dimitrios Bachtis",
      "Gert Aarts",
      "Biagio Lucini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "High Energy Physics - Lattice (hep-lat)"
    ],
    "url": "https://arxiv.org/abs/2110.10928"
  },
  {
    "id": "arXiv:2110.10932",
    "title": "Subspace Detours Meet Gromov-Wasserstein",
    "abstract": "In the context of optimal transport methods, the subspace detour approach was\nrecently presented by Muzellec and Cuturi (2019). It consists in building a\nnearly optimal transport plan in the measures space from an optimal transport\nplan in a wisely chosen subspace, onto which the original measures are\nprojected. The contribution of this paper is to extend this category of methods\nto the Gromov-Wasserstein problem, which is a particular type of transport\ndistance involving the inner geometry of the compared distributions. After\nderiving the associated formalism and properties, we also discuss a specific\ncost for which we can show connections with the Knothe-Rosenblatt\nrearrangement. We finally give an experimental illustration on a shape matching\nproblem.",
    "descriptor": "",
    "authors": [
      "Cl\u00e9ment Bonet",
      "Nicolas Courty",
      "Fran\u00e7ois Septier",
      "Lucas Drumetz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.10932"
  },
  {
    "id": "arXiv:2110.10934",
    "title": "Can Q-learning solve Multi Armed Bantids?",
    "abstract": "When a reinforcement learning (RL) method has to decide between several\noptional policies by solely looking at the received reward, it has to\nimplicitly optimize a Multi-Armed-Bandit (MAB) problem. This arises the\nquestion: are current RL algorithms capable of solving MAB problems? We claim\nthat the surprising answer is no. In our experiments we show that in some\nsituations they fail to solve a basic MAB problem, and in many common\nsituations they have a hard time: They suffer from regression in results during\ntraining, sensitivity to initialization and high sample complexity. We claim\nthat this stems from variance differences between policies, which causes two\nproblems: The first problem is the \"Boring Policy Trap\" where each policy have\na different implicit exploration depends on its rewards variance, and leaving a\nboring, or low variance, policy is less likely due to its low implicit\nexploration. The second problem is the \"Manipulative Consultant\" problem, where\nvalue-estimation functions used in deep RL algorithms such as DQN or deep Actor\nCritic methods, maximize estimation precision rather than mean rewards, and\nhave a better loss in low-variance policies, which cause the network to\nconverge to a sub-optimal policy. Cognitive experiments on humans showed that\nnoised reward signals may paradoxically improve performance. We explain this\nusing the aforementioned problems, claiming that both humans and algorithms may\nshare similar challenges in decision making.\nInspired by this result, we propose the Adaptive Symmetric Reward Noising\n(ASRN) method, by which we mean equalizing the rewards variance across\ndifferent policies, thus avoiding the two problems without affecting the\nenvironment's mean rewards behavior. We demonstrate that the ASRN scheme can\ndramatically improve the results.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1905.10144\n",
    "authors": [
      "Refael Vivanti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10934"
  },
  {
    "id": "arXiv:2110.10938",
    "title": "Autonomous Dimension Reduction by Flattening Deformation of Data  Manifold under an Intrinsic Deforming Field",
    "abstract": "A new dimension reduction (DR) method for data sets is proposed by autonomous\ndeforming of data manifolds. The deformation is guided by the proposed\ndeforming vector field, which is defined by two kinds of virtual interactions\nbetween data points. The flattening of data manifold is achieved as an emergent\nbehavior under the elastic and repelling interactions between data points,\nmeanwhile the topological structure of the manifold is preserved. To overcome\nthe uneven sampling (or \"short-cut edge\") problem, the soft neighborhood is\nproposed, in which the neighbor degree is defined and adaptive interactions\nbetween neighbor points is implemented. The proposed method provides a novel\ngeometric viewpoint on dimension reduction. Experimental results prove the\neffectiveness of the proposed method in dimension reduction, and implicit\nfeature of data sets may also be revealed.",
    "descriptor": "\nComments: 18 pages, 23 figures\n",
    "authors": [
      "Xiaodong Zhuang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10938"
  },
  {
    "id": "arXiv:2110.10939",
    "title": "A channel attention based MLP-Mixer network for motor imagery decoding  with EEG",
    "abstract": "Convolutional neural networks (CNNs) and their variants have been\nsuccessfully applied to the electroencephalogram (EEG) based motor imagery (MI)\ndecoding task. However, these CNN-based algorithms generally have limitations\nin perceiving global temporal dependencies of EEG signals. Besides, they also\nignore the diverse contributions of different EEG channels to the\nclassification task. To address such issues, a novel channel attention based\nMLP-Mixer network (CAMLP-Net) is proposed for EEG-based MI decoding.\nSpecifically, the MLP-based architecture is applied in this network to capture\nthe temporal and spatial information. The attention mechanism is further\nembedded into MLP-Mixer to adaptively exploit the importance of different EEG\nchannels. Therefore, the proposed CAMLP-Net can effectively learn more global\ntemporal and spatial information. The experimental results on the newly built\nMI-2 dataset indicate that our proposed CAMLP-Net achieves superior\nclassification performance over all the compared algorithms.",
    "descriptor": "",
    "authors": [
      "Yanbin He",
      "Zhiyang Lu",
      "Jun Wang",
      "Jun Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10939"
  },
  {
    "id": "arXiv:2110.10942",
    "title": "Generalization of Neural Combinatorial Solvers Through the Lens of  Adversarial Robustness",
    "abstract": "End-to-end (geometric) deep learning has seen first successes in\napproximating the solution of combinatorial optimization problems. However,\ngenerating data in the realm of NP-hard/-complete tasks brings practical and\ntheoretical challenges, resulting in evaluation protocols that are too\noptimistic. Specifically, most datasets only capture a simpler subproblem and\nlikely suffer from spurious features. We investigate these effects by studying\nadversarial robustness - a local generalization property - to reveal hard,\nmodel-specific instances and spurious features. For this purpose, we derive\nperturbation models for SAT and TSP. Unlike in other applications, where\nperturbation models are designed around subjective notions of imperceptibility,\nour perturbation models are efficient and sound, allowing us to determine the\ntrue label of perturbed samples without a solver. Surprisingly, with such\nperturbations, a sufficiently expressive neural solver does not suffer from the\nlimitations of the accuracy-robustness trade-off common in supervised learning.\nAlthough such robust solvers exist, we show empirically that the assessed\nneural solvers do not generalize well w.r.t. small perturbations of the problem\ninstance.",
    "descriptor": "",
    "authors": [
      "Simon Geisler",
      "Johanna Sommer",
      "Jan Schuchardt",
      "Aleksandar Bojchevski",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10942"
  },
  {
    "id": "arXiv:2110.10949",
    "title": "Multimodal Learning using Optimal Transport for Sarcasm and Humor  Detection",
    "abstract": "Multimodal learning is an emerging yet challenging research area. In this\npaper, we deal with multimodal sarcasm and humor detection from conversational\nvideos and image-text pairs. Being a fleeting action, which is reflected across\nthe modalities, sarcasm detection is challenging since large datasets are not\navailable for this task in the literature. Therefore, we primarily focus on\nresource-constrained training, where the number of training samples is limited.\nTo this end, we propose a novel multimodal learning system, MuLOT (Multimodal\nLearning using Optimal Transport), which utilizes self-attention to exploit\nintra-modal correspondence and optimal transport for cross-modal\ncorrespondence. Finally, the modalities are combined with multimodal attention\nfusion to capture the inter-dependencies across modalities. We test our\napproach for multimodal sarcasm and humor detection on three benchmark datasets\n- MUStARD (video, audio, text), UR-FUNNY (video, audio, text), MST (image,\ntext) and obtain 2.1%, 1.54%, and 2.34% accuracy improvements over\nstate-of-the-art.",
    "descriptor": "\nComments: Accepted to WACV 2022\n",
    "authors": [
      "Shraman Pramanick",
      "Aniket Roy",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10949"
  },
  {
    "id": "arXiv:2110.10952",
    "title": "Estimation of Covariance Matrix of Interference for Secure Spatial  Modulation against a Malicious Full-duplex Attacker",
    "abstract": "In a secure spatial modulation with a malicious full-duplex attacker, how to\nobtain the interference space or channel state information (CSI) is very\nimportant for Bob to cancel or reduce the interference from Mallory. In this\npaper, different from existing work with a perfect CSI, the covariance matrix\nof malicious interference (CMMI) from Mallory is estimated and is used to\nconstruct the null-space of interference (NSI). Finally, the receive beamformer\nat Bob is designed to remove the malicious interference using the NSI. To\nimprove the estimation accuracy, a rank detector relying on Akaike information\ncriterion (AIC) is derived. To achieve a high-precision CMMI estimation, two\nmethods are proposed as follows: principal component analysis-eigenvalue\ndecomposition (PCA-EVD), and joint diagonalization (JD). The proposed PCA-EVD\nis a rank deduction method whereas the JD method is a joint optimization method\nwith improved performance in low signal to interference plus noise ratio (SINR)\nregion at the expense of increased complexities. Simulation results show that\nthe proposed PCA-EVD performs much better than the existing method like sample\nestimated covariance matrix (SCM) and EVD in terms of normalized mean square\nerror (NMSE) and secrecy rate (SR). Additionally, the proposed JD method has an\nexcellent NMSE performance better than PCA-EVD in the low SINR region (SINR <\n0dB) while in the high SINR region PCA-EVD performs better than JD.",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Lili Yang",
      "Xinyi Jiang",
      "Feng Shu",
      "Weibin Zhang",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.10952"
  },
  {
    "id": "arXiv:2110.10953",
    "title": "MOS: A Low Latency and Lightweight Framework for Face Detection,  Landmark Localization, and Head Pose Estimation",
    "abstract": "With the emergence of service robots and surveillance cameras, dynamic face\nrecognition (DFR) in wild has received much attention in recent years. Face\ndetection and head pose estimation are two important steps for DFR. Very often,\nthe pose is estimated after the face detection. However, such sequential\ncomputations lead to higher latency. In this paper, we propose a low latency\nand lightweight network for simultaneous face detection, landmark localization\nand head pose estimation. Inspired by the observation that it is more\nchallenging to locate the facial landmarks for faces with large angles, a pose\nloss is proposed to constrain the learning. Moreover, we also propose an\nuncertainty multi-task loss to learn the weights of individual tasks\nautomatically. Another challenge is that robots often use low computational\nunits like ARM based computing core and we often need to use lightweight\nnetworks instead of the heavy ones, which lead to performance drop especially\nfor small and hard faces. In this paper, we propose online feedback sampling to\naugment the training samples across different scales, which increases the\ndiversity of training data automatically. Through validation in commonly used\nWIDER FACE, AFLW and AFLW2000 datasets, the results show that the proposed\nmethod achieves the state-of-the-art performance in low computational\nresources.",
    "descriptor": "",
    "authors": [
      "Yepeng Liu",
      "Zaiwang Gu",
      "Shenghua Gao",
      "Dong Wang",
      "Yusheng Zeng",
      "Jun Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10953"
  },
  {
    "id": "arXiv:2110.10955",
    "title": "Multi-label Classification with Partial Annotations using Class-aware  Selective Loss",
    "abstract": "Large-scale multi-label classification datasets are commonly, and perhaps\ninevitably, partially annotated. That is, only a small subset of labels are\nannotated per sample. Different methods for handling the missing labels induce\ndifferent properties on the model and impact its accuracy. In this work, we\nanalyze the partial labeling problem, then propose a solution based on two key\nideas. First, un-annotated labels should be treated selectively according to\ntwo probability quantities: the class distribution in the overall dataset and\nthe specific label likelihood for a given data sample. We propose to estimate\nthe class distribution using a dedicated temporary model, and we show its\nimproved efficiency over a naive estimation computed using the dataset's\npartial annotations. Second, during the training of the target model, we\nemphasize the contribution of annotated labels over originally un-annotated\nlabels by using a dedicated asymmetric loss. With our novel approach, we\nachieve state-of-the-art results on OpenImages dataset (e.g. reaching 87.3 mAP\non V6). In addition, experiments conducted on LVIS and simulated-COCO\ndemonstrate the effectiveness of our approach. Code is available at\nhttps://github.com/Alibaba-MIIL/PartialLabelingCSL.",
    "descriptor": "",
    "authors": [
      "Emanuel Ben-Baruch",
      "Tal Ridnik",
      "Itamar Friedman",
      "Avi Ben-Cohen",
      "Nadav Zamir",
      "Asaf Noy",
      "Lihi Zelnik-Manor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10955"
  },
  {
    "id": "arXiv:2110.10957",
    "title": "Vis-TOP: Visual Transformer Overlay Processor",
    "abstract": "In recent years, Transformer has achieved good results in Natural Language\nProcessing (NLP) and has also started to expand into Computer Vision (CV).\nExcellent models such as the Vision Transformer and Swin Transformer have\nemerged. At the same time, the platform for Transformer models was extended to\nembedded devices to meet some resource-sensitive application scenarios.\nHowever, due to the large number of parameters, the complex computational flow\nand the many different structural variants of Transformer models, there are a\nnumber of issues that need to be addressed in its hardware design. This is both\nan opportunity and a challenge. We propose Vis-TOP (Visual Transformer Overlay\nProcessor), an overlay processor for various visual Transformer models. It\ndiffers from coarse-grained overlay processors such as CPU, GPU, NPE, and from\nfine-grained customized designs for a specific model. Vis-TOP summarizes the\ncharacteristics of all visual Transformer models and implements a three-layer\nand two-level transformation structure that allows the model to be switched or\nchanged freely without changing the hardware architecture. At the same time,\nthe corresponding instruction bundle and hardware architecture are designed in\nthree-layer and two-level transformation structure. After quantization of Swin\nTransformer tiny model using 8-bit fixed points (fix_8), we implemented an\noverlay processor on the ZCU102. Compared to GPU, the TOP throughput is 1.5x\nhigher. Compared to the existing Transformer accelerators, our throughput per\nDSP is between 2.2x and 11.7x higher than others. In a word, the approach in\nthis paper meets the requirements of real-time AI in terms of both resource\nconsumption and inference speed. Vis-TOP provides a cost-effective and\npower-effective solution based on reconfigurable devices for computer vision at\nthe edge.",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "Wei Hu",
      "Dian Xu",
      "Zimeng Fan",
      "Fang Liu",
      "Yanxiang He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2110.10957"
  },
  {
    "id": "arXiv:2110.10963",
    "title": "Neuro-Symbolic Reinforcement Learning with First-Order Logic",
    "abstract": "Deep reinforcement learning (RL) methods often require many trials before\nconvergence, and no direct interpretability of trained policies is provided. In\norder to achieve fast convergence and interpretability for the policy in RL, we\npropose a novel RL method for text-based games with a recent neuro-symbolic\nframework called Logical Neural Network, which can learn symbolic and\ninterpretable rules in their differentiable network. The method is first to\nextract first-order logical facts from text observation and external word\nmeaning network (ConceptNet), then train a policy in the network with directly\ninterpretable logical operators. Our experimental results show RL training with\nthe proposed method converges significantly faster than other state-of-the-art\nneuro-symbolic methods in a TextWorld benchmark.",
    "descriptor": "\nComments: EMNLP 2021 (main conference)\n",
    "authors": [
      "Daiki Kimura",
      "Masaki Ono",
      "Subhajit Chaudhury",
      "Ryosuke Kohita",
      "Akifumi Wachi",
      "Don Joven Agravante",
      "Michiaki Tatsubori",
      "Asim Munawar",
      "Alexander Gray"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.10963"
  },
  {
    "id": "arXiv:2110.10966",
    "title": "Weakly Supervised Training of Monocular 3D Object Detectors Using Wide  Baseline Multi-view Traffic Camera Data",
    "abstract": "Accurate 7DoF prediction of vehicles at an intersection is an important task\nfor assessing potential conflicts between road users. In principle, this could\nbe achieved by a single camera system that is capable of detecting the pose of\neach vehicle but this would require a large, accurately labelled dataset from\nwhich to train the detector. Although large vehicle pose datasets exist\n(ostensibly developed for autonomous vehicles), we find training on these\ndatasets inadequate. These datasets contain images from a ground level\nviewpoint, whereas an ideal view for intersection observation would be elevated\nhigher above the road surface. We develop an alternative approach using a\nweakly supervised method of fine tuning 3D object detectors for traffic\nobservation cameras; showing in the process that large existing autonomous\nvehicle datasets can be leveraged for pre-training. To fine-tune the monocular\n3D object detector, our method utilises multiple 2D detections from\noverlapping, wide-baseline views and a loss that encodes the subjacent\ngeometric consistency. Our method achieves vehicle 7DoF pose prediction\naccuracy on our dataset comparable to the top performing monocular 3D object\ndetectors on autonomous vehicle datasets. We present our training methodology,\nmulti-view reprojection loss, and dataset.",
    "descriptor": "\nComments: Paper accepted at The 32nd British Machine Vision Conference, BMVC 2021\n",
    "authors": [
      "Matthew Howe",
      "Ian Reid",
      "Jamie Mackenzie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10966"
  },
  {
    "id": "arXiv:2110.10969",
    "title": "Memory Efficient Adaptive Attention For Multiple Domain Learning",
    "abstract": "Training CNNs from scratch on new domains typically demands large numbers of\nlabeled images and computations, which is not suitable for low-power hardware.\nOne way to reduce these requirements is to modularize the CNN architecture and\nfreeze the weights of the heavier modules, that is, the lower layers after\npre-training. Recent studies have proposed alternative modular architectures\nand schemes that lead to a reduction in the number of trainable parameters\nneeded to match the accuracy of fully fine-tuned CNNs on new domains. Our work\nsuggests that a further reduction in the number of trainable parameters by an\norder of magnitude is possible. Furthermore, we propose that new modularization\ntechniques for multiple domain learning should also be compared on other\nrealistic metrics, such as the number of interconnections needed between the\nfixed and trainable modules, the number of training samples needed, the order\nof computations required and the robustness to partial mislabeling of the\ntraining data. On all of these criteria, the proposed architecture demonstrates\nadvantages over or matches the current state-of-the-art.",
    "descriptor": "\nComments: 13 pages, 3 figures, 4 graphs, 3 tables\n",
    "authors": [
      "Himanshu Pradeep Aswani",
      "Abhiraj Sunil Kanse",
      "Shubhang Bhatnagar",
      "Amit Sethi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.10969"
  },
  {
    "id": "arXiv:2110.10970",
    "title": "Fuzzy Algebraic Theories",
    "abstract": "In this work we propose a formal system for fuzzy algebraic reasoning. The\nsequent calculus we define is based on two kinds of propositions, capturing\nequality and existence of terms as members of a fuzzy set. We provide a sound\nsemantics for this calculus and show that there is a notion of free model for\nany theory in this system, allowing us (with some restrictions) to recover\nmodels as Eilenberg-Moore algebras for some monad. We will also prove a\ncompleteness result: a formula is derivable from a given theory if and only if\nit is satisfied by all models of the theory. Finally, leveraging results by\nMilius and Urbat, we give HSP-like characterizations of subcategories of\nalgebras which are categories of models of particular kinds of theories.",
    "descriptor": "",
    "authors": [
      "Davide Castelnovo",
      "Marino Miculan"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.10970"
  },
  {
    "id": "arXiv:2110.10972",
    "title": "Sliced-Wasserstein Gradient Flows",
    "abstract": "Minimizing functionals in the space of probability distributions can be done\nwith Wasserstein gradient flows. To solve them numerically, a possible approach\nis to rely on the Jordan-Kinderlehrer-Otto (JKO) scheme which is analogous to\nthe proximal scheme in Euclidean spaces. However, this bilevel optimization\nproblem is known for its computational challenges, especially in high\ndimension. To alleviate it, very recent works propose to approximate the JKO\nscheme leveraging Brenier's theorem, and using gradients of Input Convex Neural\nNetworks to parameterize the density (JKO-ICNN). However, this method comes\nwith a high computational cost and stability issues. Instead, this work\nproposes to use gradient flows in the space of probability measures endowed\nwith the sliced-Wasserstein (SW) distance. We argue that this method is more\nflexible than JKO-ICNN, since SW enjoys a closed-form differentiable\napproximation. Thus, the density at each step can be parameterized by any\ngenerative model which alleviates the computational burden and makes it\ntractable in higher dimensions. Interestingly, we also show empirically that\nthese gradient flows are strongly related to the usual Wasserstein gradient\nflows, and that they can be used to minimize efficiently diverse machine\nlearning functionals.",
    "descriptor": "",
    "authors": [
      "Cl\u00e9ment Bonet",
      "Nicolas Courty",
      "Fran\u00e7ois Septier",
      "Lucas Drumetz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.10972"
  },
  {
    "id": "arXiv:2110.10973",
    "title": "LOA: Logical Optimal Actions for Text-based Interaction Games",
    "abstract": "We present Logical Optimal Actions (LOA), an action decision architecture of\nreinforcement learning applications with a neuro-symbolic framework which is a\ncombination of neural network and symbolic knowledge acquisition approach for\nnatural language interaction games. The demonstration for LOA experiments\nconsists of a web-based interactive platform for text-based games and\nvisualization for acquired knowledge for improving interpretability for trained\nrules. This demonstration also provides a comparison module with other\nneuro-symbolic approaches as well as non-symbolic state-of-the-art agent models\non the same text-based games. Our LOA also provides open-sourced implementation\nin Python for the reinforcement learning environment to facilitate an\nexperiment for studying neuro-symbolic agents. Code: https://github.com/ibm/loa",
    "descriptor": "\nComments: ACL-IJCNLP 2021 (demo paper)\n",
    "authors": [
      "Daiki Kimura",
      "Subhajit Chaudhury",
      "Masaki Ono",
      "Michiaki Tatsubori",
      "Don Joven Agravante",
      "Asim Munawar",
      "Akifumi Wachi",
      "Ryosuke Kohita",
      "Alexander Gray"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.10973"
  },
  {
    "id": "arXiv:2110.10974",
    "title": "A Decentralized Framework for Serverless Edge Computing in the Internet  of Things",
    "abstract": "Serverless computing is becoming widely adopted among cloud providers, thus\nmaking increasingly popular the Function-as-a-Service (FaaS) programming model,\nwhere the developers realize services by packaging sequences of stateless\nfunction calls.\nThe current technologies are very well suited to data centers, but cannot\nprovide equally good performance in decentralized environments, such as edge\ncomputing systems, which are expected to be typical for Internet of Things\n(IoT) applications.\nIn this paper, we fill this gap by proposing a framework for efficient\ndispatching of stateless tasks to in-network executors so as to minimize the\nresponse times while exhibiting short- and long-term fairness, also leveraging\ninformation from a virtualized network infrastructure when available.\nOur solution is shown to be simple enough to be installed on devices with\nlimited computational capabilities, such as IoT gateways, especially when using\na hierarchical forwarding extension.\nWe evaluate the proposed platform by means of extensive emulation experiments\nwith a prototype implementation in realistic conditions.\nThe results show that it is able to smoothly adapt to the mobility of clients\nand to the variations of their service request patterns, while coping promptly\nwith network congestion.",
    "descriptor": "",
    "authors": [
      "Claudio Cicconetti",
      "Marco Conti",
      "Andrea Passarella"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.10974"
  },
  {
    "id": "arXiv:2110.10978",
    "title": "Multiobjective Dijkstra A*",
    "abstract": "We introduce the Multiobjective Dijkstra A* (MDA*) algorithm, a label setting\nalgorithm for the One-to-One Multiobjective Shortest Path Problem that guides\nthe search toward the target node. For the design of our new algorithm, we\ncombine the recently published Biobjective and Multiobjective Dijkstra\nalgorithms (B/MDA) with the ideas used to design the classical A* algorithm for\nShortest Path problems. Thus, our algorithm requires a monotone node heuristic\nas part of its input. For any node, the heuristic underestimates the costs of a\npath from this node to the target node of the search. Paths in the priority\nqueue are then sorted according to the sum of their costs and the value of the\nheuristic at their final node. The direct implication is that paths that are\ncloser to the target are processed earlier. Together with some pruning\ntechniques, the number of iterations needed to solve the given One-to-One MOSP\ninstances can be drastically reduced. In our computational experiments, we use\ndifferent types of three dimensional instances to show that the MDA* algorithm\nclearly outperforms the MDA.",
    "descriptor": "\nComments: 14 pages, 12 figures, 4 tables\n",
    "authors": [
      "Pedro Maristany de las Casas",
      "Luitgard Kraus",
      "Antonio Sede\u00f1o-Noda",
      "Ralf Bornd\u00f6rfer"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.10978"
  },
  {
    "id": "arXiv:2110.10980",
    "title": "Ethics-Based Auditing of Automated Decision-Making Systems: Nature,  Scope, and Limitations",
    "abstract": "Important decisions that impact human lives, livelihoods, and the natural\nenvironment are increasingly being automated. Delegating tasks to so-called\nautomated decision-making systems (ADMS) can improve efficiency and enable new\nsolutions. However, these benefits are coupled with ethical challenges. For\nexample, ADMS may produce discriminatory outcomes, violate individual privacy,\nand undermine human self-determination. New governance mechanisms are thus\nneeded that help organisations design and deploy ADMS in ways that are ethical,\nwhile enabling society to reap the full economic and social benefits of\nautomation. In this article, we consider the feasibility and efficacy of\nethics-based auditing (EBA) as a governance mechanism that allows organisations\nto validate claims made about their ADMS. Building on previous work, we define\nEBA as a structured process whereby an entity's present or past behaviour is\nassessed for consistency with relevant principles or norms. We then offer three\ncontributions to the existing literature. First, we provide a theoretical\nexplanation of how EBA can contribute to good governance by promoting\nprocedural regularity and transparency. Second, we propose seven criteria for\nhow to design and implement EBA procedures successfully. Third, we identify and\ndiscuss the conceptual, technical, social, economic, organisational, and\ninstitutional constraints associated with EBA. We conclude that EBA should be\nconsidered an integral component of multifaced approaches to managing the\nethical risks posed by ADMS.",
    "descriptor": "\nComments: Artificial Intelligence, Auditing, Automated Decision-Making, Ethics, Governance\n",
    "authors": [
      "Jakob Mokander",
      "Jessica Morley",
      "Mariarosaria Taddeo",
      "Luciano Floridi"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.10980"
  },
  {
    "id": "arXiv:2110.10983",
    "title": "Optimizing Multi-Taper Features for Deep Speaker Verification",
    "abstract": "Multi-taper estimators provide low-variance power spectrum estimates that can\nbe used in place of the windowed discrete Fourier transform (DFT) to extract\nspeech features such as mel-frequency cepstral coefficients (MFCCs). Even if\npast work has reported promising automatic speaker verification (ASV) results\nwith Gaussian mixture model-based classifiers, the performance of multi-taper\nMFCCs with deep ASV systems remains an open question. Instead of a static-taper\ndesign, we propose to optimize the multi-taper estimator jointly with a deep\nneural network trained for ASV tasks. With a maximum improvement on the SITW\ncorpus of 25.8% in terms of equal error rate over the static-taper, our method\nhelps preserve a balanced level of leakage and variance, providing more\nrobustness.",
    "descriptor": "\nComments: To appear in IEEE Signal Processing Letters\n",
    "authors": [
      "Xuechen Liu",
      "Md Sahidullah",
      "Tomi Kinnunen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.10983"
  },
  {
    "id": "arXiv:2110.10984",
    "title": "The popular assignment problem: when cardinality is more important than  popularity",
    "abstract": "We consider a matching problem in a bipartite graph $G=(A\\cup B,E)$ where\neach node in $A$ is an agent having preferences in partial order over her\nneighbors, while nodes in $B$ are objects with no preferences. The size of our\nmatching is more important than node preferences; thus, we are interested in\nmaximum matchings only. Any pair of maximum matchings in $G$ (equivalently,\nperfect matchings or assignments) can be compared by holding a head-to-head\nelection between them where agents are voters. The goal is to compute an\nassignment $M$ such that there is no better or \"more popular\" assignment. This\nis the popular assignment problem and it generalizes the well-studied popular\nmatching problem.\nPopular assignments need not always exist. We show a polynomial-time\nalgorithm that decides if the given instance admits one or not, and computes\none, if so. In instances with no popular assignment, we consider the problem of\nfinding an almost popular assignment, i.e., an assignment with minimum\nunpopularity margin. We show an $O^*(|E|^k)$ time algorithm for deciding if\nthere exists an assignment with unpopularity margin at most $k$. We show that\nthis algorithm is essentially optimal by proving that the problem is\n$\\mathsf{W}_l[1]$-hard with parameter $k$.\nWe also consider the minimum-cost popular assignment problem when there are\nedge costs, and show its $\\mathsf{NP}$-hardness even when all edge costs are in\n$\\{0,1\\}$ and agents have strict preferences. By contrast, we propose a\npolynomial-time algorithm to the problem of deciding if there exists a popular\nassignment with a given set of forced/forbidden edges (this tractability holds\neven for partially ordered preferences). Our algorithms are combinatorial and\nbased on LP duality. They search for an appropriate witness or dual\ncertificate, and when a certificate cannot be found, we prove that the desired\nassignment does not exist in $G$.",
    "descriptor": "\nComments: 28 pages, 7 figures\n",
    "authors": [
      "Telikepalli Kavitha",
      "Tam\u00e1s Kir\u00e1ly",
      "Jannik Matuschke",
      "Ildik\u00f3 Schlotter",
      "Ulrike Schmidt-Kraepelin"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.10984"
  },
  {
    "id": "arXiv:2110.10986",
    "title": "Multi-stable design of triangulated origami structures on cones of  revolution",
    "abstract": "It is well-known that the Kresling pattern of congruent triangles can be\narranged either circularly on a cylinder of revolution or in a helical way. In\nboth cases the resulting cylindrical structures are multi-stable. We generalize\nthese arrangements with respect to cones of revolution, where our approach\nallows to construct structures, which snap between conical realizations whose\napex angles serve as design parameters. In this context we also figure out\nshaky realizations, intervals for self-intersection free realizations and an\ninteresting property related to the cross sectional area. Finally, we analyze\nthese origami structures with respect to their capability to snap by means of\nthe so-called snappability index.",
    "descriptor": "\nComments: 31 pages, 16 figures\n",
    "authors": [
      "Georg Nawratil"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2110.10986"
  },
  {
    "id": "arXiv:2110.10987",
    "title": "Learning OFDM Waveforms with PAPR and ACLR Constraints",
    "abstract": "An attractive research direction for future communication systems is the\ndesign of new waveforms that can both support high throughputs and present\nadvantageous signal characteristics. Although most modern systems use\northogonal frequency-division multiplexing (OFDM) for its efficient\nequalization, this waveform suffers from multiple limitations such as a high\nadjacent channel leakage ratio (ACLR) and high peak-to-average power ratio\n(PAPR). In this paper, we propose a learning-based method to design OFDM-based\nwaveforms that satisfy selected constraints while maximizing an achievable\ninformation rate. To that aim, we model the transmitter and the receiver as\nconvolutional neural networks (CNNs) that respectively implement a\nhigh-dimensional modulation scheme and perform the detection of the transmitted\nbits. This leads to an optimization problem that is solved using the augmented\nLagrangian method. Evaluation results show that the end-to-end system is able\nto satisfy target PAPR and ACLR constraints and allows significant throughput\ngains compared to a tone reservation (TR) baseline. An additional advantage is\nthat no dedicated pilots are needed.",
    "descriptor": "",
    "authors": [
      "Mathieu Goutay",
      "Fay\u00e7al Ait Aoudia",
      "Jakob Hoydis",
      "Jean-Marie Gorce"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.10987"
  },
  {
    "id": "arXiv:2110.10992",
    "title": "Scheduling Algorithms for Age of Information Differentiation with Random  Arrivals",
    "abstract": "We study age-agnostic scheduling in a non-preemptive status update system\nwith two sources sending time-stamped information packets at random instances\nto a common monitor through a single server. The server is equipped with a\nwaiting room holding the freshest packet from each source called \"single-buffer\nper-source queueing\". The server is assumed to be work-conserving and when the\nwaiting room has two waiting packets (one from each source), a probabilistic\nscheduling policy is applied so as to provide Age of Information (AoI)\ndifferentiation for the two sources of interest. Assuming Poisson packet\narrivals and exponentially distributed service times, the exact distributions\nof AoI and also Peak AoI (PAoI) for each source are first obtained.\nSubsequently, this analytical tool is used to numerically obtain the optimum\nprobabilistic scheduling policy so as to minimize the weighted average AoI/PAoI\nby means of which differentiation can be achieved between the two sources. In\naddition, a pair of heuristic age-agnostic schedulers are proposed on the basis\nof heavy-traffic analysis and comparatively evaluated in a wide variety of\nscenarios, and guidelines are provided for scheduling and AoI differentiation\nin status update systems with two sources.",
    "descriptor": "\nComments: 14 pages, 7 figures, 2 tables\n",
    "authors": [
      "Nail Akar",
      "Ezhan Karasan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Performance (cs.PF)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2110.10992"
  },
  {
    "id": "arXiv:2110.10994",
    "title": "Interpretable Machine Learning for Resource Allocation with Application  to Ventilator Triage",
    "abstract": "Rationing of healthcare resources is a challenging decision that policy\nmakers and providers may be forced to make during a pandemic, natural disaster,\nor mass casualty event. Well-defined guidelines to triage scarce life-saving\nresources must be designed to promote transparency, trust, and consistency. To\nfacilitate buy-in and use during high-stress situations, these guidelines need\nto be interpretable and operational. We propose a novel data-driven model to\ncompute interpretable triage guidelines based on policies for Markov Decision\nProcess that can be represented as simple sequences of decision trees (\"tree\npolicies\"). In particular, we characterize the properties of optimal tree\npolicies and present an algorithm based on dynamic programming recursions to\ncompute good tree policies. We utilize this methodology to obtain simple, novel\ntriage guidelines for ventilator allocations for COVID-19 patients, based on\nreal patient data from Montefiore hospitals. We also compare the performance of\nour guidelines to the official New York State guidelines that were developed in\n2015 (well before the COVID-19 pandemic). Our empirical study shows that the\nnumber of excess deaths associated with ventilator shortages could be reduced\nsignificantly using our policy. Our work highlights the limitations of the\nexisting official triage guidelines, which need to be adapted specifically to\nCOVID-19 before being successfully deployed.",
    "descriptor": "",
    "authors": [
      "Julien Grand-Cl\u00e9ment",
      "Carri Chan",
      "Vineet Goyal",
      "Elizabeth Chuang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.10994"
  },
  {
    "id": "arXiv:2110.11001",
    "title": "Pixel-Level Face Image Quality Assessment for Explainable Face  Recognition",
    "abstract": "An essential factor to achieve high performance in face recognition systems\nis the quality of its samples. Since these systems are involved in various\ndaily life there is a strong need of making face recognition processes\nunderstandable for humans. In this work, we introduce the concept of\npixel-level face image quality that determines the utility of pixels in a face\nimage for recognition. Given an arbitrary face recognition network, in this\nwork, we propose a training-free approach to assess the pixel-level qualities\nof a face image. To achieve this, a model-specific quality value of the input\nimage is estimated and used to build a sample-specific quality regression\nmodel. Based on this model, quality-based gradients are back-propagated and\nconverted into pixel-level quality estimates. In the experiments, we\nqualitatively and quantitatively investigated the meaningfulness of the\npixel-level qualities based on real and artificial disturbances and by\ncomparing the explanation maps on ICAO-incompliant faces. In all scenarios, the\nresults demonstrate that the proposed solution produces meaningful pixel-level\nqualities. The code is publicly available.",
    "descriptor": "\nComments: Submitted to CVPR 2022, Code will be made publicly-available in November 2021\n",
    "authors": [
      "Philipp Terh\u00f6rst",
      "Marco Huber",
      "Naser Damer",
      "Florian Kirchbuchner",
      "Kiran Raja",
      "Arjan Kuijper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11001"
  },
  {
    "id": "arXiv:2110.11006",
    "title": "Bristle: Decentralized Federated Learning in Byzantine, Non-i.i.d.  Environments",
    "abstract": "Federated learning (FL) is a privacy-friendly type of machine learning where\ndevices locally train a model on their private data and typically communicate\nmodel updates with a server. In decentralized FL (DFL), peers communicate model\nupdates with each other instead. However, DFL is challenging since (1) the\ntraining data possessed by different peers is often non-i.i.d. (i.e.,\ndistributed differently between the peers) and (2) malicious, or Byzantine,\nattackers can share arbitrary model updates with other peers to subvert the\ntraining process.\nWe address these two challenges and present Bristle, middleware between the\nlearning application and the decentralized network layer. Bristle leverages\ntransfer learning to predetermine and freeze the non-output layers of a neural\nnetwork, significantly speeding up model training and lowering communication\ncosts. To securely update the output layer with model updates from other peers,\nwe design a fast distance-based prioritizer and a novel performance-based\nintegrator. Their combined effect results in high resilience to Byzantine\nattackers and the ability to handle non-i.i.d. classes.\nWe empirically show that Bristle converges to a consistent 95% accuracy in\nByzantine environments, outperforming all evaluated baselines. In non-Byzantine\nenvironments, Bristle requires 83% fewer iterations to achieve 90% accuracy\ncompared to state-of-the-art methods. We show that when the training classes\nare non-i.i.d., Bristle significantly outperforms the accuracy of the most\nByzantine-resilient baselines by 2.3x while reducing communication costs by\n90%.",
    "descriptor": "",
    "authors": [
      "Joost Verbraeken",
      "Martijn de Vos",
      "Johan Pouwelse"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11006"
  },
  {
    "id": "arXiv:2110.11007",
    "title": "Attack Detection and Localization in Smart Grid with Image-based Deep  Learning",
    "abstract": "Smart grid's objective is to enable electricity and information to flow\ntwo-way while providing effective, robust, computerized, and decentralized\nenergy delivery. This necessitates the use of state estimation-based techniques\nand real-time analysis to ensure that effective controls are deployed properly.\nHowever, the reliance on communication technologies makes such systems\nsusceptible to sophisticated data integrity attacks imposing serious threats to\nthe overall reliability of smart grid. To detect such attacks, advanced and\nefficient anomaly detection solutions are needed. In this paper, a two-stage\ndeep learning-based framework is carefully designed by embedding power system's\ncharacteristics enabling precise attack detection and localization. First, we\nencode temporal correlations of the multivariate power system time-series\nmeasurements as 2D images using image-based representation approaches such as\nGramian Angular Field (GAF) and Recurrence Plot (RP) to obtain the latent data\ncharacteristics. These images are then utilized to build a highly reliable and\nresilient deep Convolutional Neural Network (CNN)-based multi-label classifier\ncapable of learning both low and high level characteristics in the images to\ndetect and discover the exact attack locations without leveraging any prior\nstatistical assumptions. The proposed method is evaluated on the IEEE 57-bus\nsystem using real-world load data. Also, a comparative study is carried out.\nNumerical results indicate that the proposed multi-class cyber-intrusion\ndetection framework outperforms the current conventional and deep\nlearning-based attack detection methods.",
    "descriptor": "",
    "authors": [
      "Mostafa Mohammadpourfard",
      "Istemihan Genc",
      "Subhash Lakshminarayana",
      "Charalambos Konstantinou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.11007"
  },
  {
    "id": "arXiv:2110.11010",
    "title": "Algorithmic Amplification of Politics on Twitter",
    "abstract": "Content on Twitter's home timeline is selected and ordered by personalization\nalgorithms. By consistently ranking certain content higher, these algorithms\nmay amplify some messages while reducing the visibility of others. There's been\nintense public and scholarly debate about the possibility that some political\ngroups benefit more from algorithmic amplification than others. We provide\nquantitative evidence from a long-running, massive-scale randomized experiment\non the Twitter platform that committed a randomized control group including\nnearly 2M daily active accounts to a reverse-chronological content feed free of\nalgorithmic personalization. We present two sets of findings. First, we studied\nTweets by elected legislators from major political parties in 7 countries. Our\nresults reveal a remarkably consistent trend: In 6 out of 7 countries studied,\nthe mainstream political right enjoys higher algorithmic amplification than the\nmainstream political left. Consistent with this overall trend, our second set\nof findings studying the U.S. media landscape revealed that algorithmic\namplification favours right-leaning news sources. We further looked at whether\nalgorithms amplify far-left and far-right political groups more than moderate\nones: contrary to prevailing public belief, we did not find evidence to support\nthis hypothesis. We hope our findings will contribute to an evidence-based\ndebate on the role personalization algorithms play in shaping political content\nconsumption.",
    "descriptor": "",
    "authors": [
      "Ferenc Husz\u00e1r",
      "Sofia Ira Ktena",
      "Conor O'Brien",
      "Luca Belli",
      "Andrew Schlaikjer",
      "Moritz Hardt"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.11010"
  },
  {
    "id": "arXiv:2110.11013",
    "title": "Spatial Location Constraint Prototype Loss for Open Set Recognition",
    "abstract": "One of the challenges in pattern recognition is open set recognition.\nCompared with closed set recognition, open set recognition needs to reduce not\nonly the empirical risk, but also the open space risk, and the reduction of\nthese two risks corresponds to classifying the known classes and identifying\nthe unknown classes respectively. How to reduce the open space risk is the key\nof open set recognition. This paper explores the origin of the open space risk\nby analyzing the distribution of known and unknown classes features. On this\nbasis, the spatial location constraint prototype loss function is proposed to\nreduce the two risks simultaneously. Extensive experiments on multiple\nbenchmark datasets and many visualization results indicate that our methods is\nsignificantly superior to other existing approaches.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Ziheng Xia",
      "Ganggang Dong",
      "Penghui Wang",
      "Hongwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11013"
  },
  {
    "id": "arXiv:2110.11015",
    "title": "A Utility Maximization Model of Pedestrian and Driver Interactions",
    "abstract": "Many models account for the traffic flow of road users but few take the\ndetails of local interactions into consideration and how they could deteriorate\ninto safety-critical situations. Building on the concept of sensorimotor\ncontrol, we develop a modeling framework applying the principles of utility\nmaximization, motor primitives, and intermittent action decisions to account\nfor the details of interactive behaviors among road users. The framework\nconnects these principles to the decision theory and is applied to determine\nwhether such an approach can reproduce the following phenomena: When two\npedestrians travel on crossing paths, (a) their interaction is sensitive to\ninitial asymmetries, and (b) based on which, they rapidly resolve collision\nconflict by adapting their behaviors. When a pedestrian crosses the road while\nfacing an approaching car, (c) either road user yields to the other to resolve\ntheir conflict, akin to the pedestrian interaction, and (d) the outcome reveals\na specific situational kinematics, associated with the nature of vehicle\nacceleration. We show that these phenomena emerge naturally from our modeling\nframework when the model can evolve its parameters as a consequence of the\nsituations. We believe that the modeling framework and phenomenon-centered\nanalysis offer promising tools to understand road user interactions. We\nconclude with a discussion on how the model can be instrumental in studying the\nsafety-critical situations when including other variables in road-user\ninteractions.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Yi-Shin Lin",
      "Aravinda Ramakrishnan Srinivasan",
      "Matteo Leonetti",
      "Jac Billington",
      "Gustav Markkula"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11015"
  },
  {
    "id": "arXiv:2110.11017",
    "title": "Learning Time-Varying Graphs from Online Data",
    "abstract": "This work proposes an algorithmic framework to learn time-varying graphs from\nonline data. The generality offered by the framework renders it\nmodel-independent, i.e., it can be theoretically analyzed in its abstract\nformulation and then instantiated under a variety of model-dependent graph\nlearning problems. This is possible by phrasing (time-varying) graph learning\nas a composite optimization problem, where different functions regulate\ndifferent desiderata, e.g., data fidelity, sparsity or smoothness. Instrumental\nfor the findings is recognizing that the dependence of the majority (if not\nall) data-driven graph learning algorithms on the data is exerted through the\nempirical covariance matrix, representing a sufficient statistic for the\nestimation problem. Its user-defined recursive update enables the framework to\nwork in non-stationary environments, while iterative algorithms building on\nnovel time-varying optimization tools explicitly take into account the temporal\ndynamics, speeding up convergence and implicitly including a\ntemporal-regularization of the solution. We specialize the framework to three\nwell-known graph learning models, namely, the Gaussian graphical model (GGM),\nthe structural equation model (SEM), and the smoothness-based model (SBM),\nwhere we also introduce ad-hoc vectorization schemes for structured matrices\n(symmetric, hollows, etc.) which are crucial to perform correct gradient\ncomputations, other than enabling to work in low-dimensional vector spaces and\nhence easing storage requirements. After discussing the theoretical guarantees\nof the proposed framework, we corroborate it with extensive numerical tests in\nsynthetic and real data.",
    "descriptor": "",
    "authors": [
      "Alberto Natali",
      "Elvin Isufi",
      "Mario Coutino",
      "Geert Leus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.11017"
  },
  {
    "id": "arXiv:2110.11018",
    "title": "Newtonian Mechanics Based Transient Stability PART II: Individual  Machine",
    "abstract": "The paper analyzes the mechanisms of the individual-machine and also its\nadvantages in TSA. Based on the critical-machine monitoring of the original\nsystem trajectory, it is clarified that the individual-machine strictly follows\nthe machine paradigms. These strict followings of the paradigms bring the two\nadvantages of the individual-machine method in TSA: (i) the individual-machine\ntrajectory stability is characterized precisely, and (ii) the\nindividual-machine trajectory variance is depicted clearly at IMPP. The two\nadvantages are fully reflected in the precise definitions of individual-machine\nbased transient stability concepts. In particular, the critical machine swing\nis clearly depicted through the IDSP or IDLP of the machine, the critical\nstability of the system is strictly defined as the critical stability of the\nmost-severely disturbed machine, and the individual-machine potential energy\nsurface is also precisely modeled through the IMPE of the machine. Simulation\nresults show the effectiveness of the individual-machine in TSA.",
    "descriptor": "\nComments: This paper contains 9 pages and 23 figures\n",
    "authors": [
      "Songyan Wang",
      "Jilai Yu",
      "Aoife Foley",
      "Jingrui Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.11018"
  },
  {
    "id": "arXiv:2110.11023",
    "title": "Augmenting Knowledge Distillation With Peer-To-Peer Mutual Learning For  Model Compression",
    "abstract": "Knowledge distillation (KD) is an effective model compression technique where\na compact student network is taught to mimic the behavior of a complex and\nhighly trained teacher network. In contrast, Mutual Learning (ML) provides an\nalternative strategy where multiple simple student networks benefit from\nsharing knowledge, even in the absence of a powerful but static teacher\nnetwork. Motivated by these findings, we propose a single-teacher,\nmulti-student framework that leverages both KD and ML to achieve better\nperformance. Furthermore, an online distillation strategy is utilized to train\nthe teacher and students simultaneously. To evaluate the performance of the\nproposed approach, extensive experiments were conducted using three different\nversions of teacher-student networks on benchmark biomedical classification\n(MSI vs. MSS) and object detection (Polyp Detection) tasks. Ensemble of student\nnetworks trained in the proposed manner achieved better results than the\nensemble of students trained using KD or ML individually, establishing the\nbenefit of augmenting knowledge transfer from teacher to students with\npeer-to-peer learning between students.",
    "descriptor": "",
    "authors": [
      "Usma Niyaz",
      "Deepti R. Bathula"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11023"
  },
  {
    "id": "arXiv:2110.11024",
    "title": "Watermarking Graph Neural Networks based on Backdoor Attacks",
    "abstract": "Graph Neural Networks (GNNs) have achieved promising performance in various\nreal-world applications. Building a powerful GNN model is not a trivial task,\nas it requires a large amount of training data, powerful computing resources,\nand human expertise on fine-tuning the model. What is more, with the\ndevelopment of adversarial attacks, e.g., model stealing attacks, GNNs raise\nchallenges to model authentication. To avoid copyright infringement on GNNs, it\nis necessary to verify the ownership of the GNN models.\nIn this paper, we present a watermarking framework for GNNs for both graph\nand node classification tasks. We 1) design two strategies to generate\nwatermarked data for the graph classification and one for the node\nclassification task, 2) embed the watermark into the host model through\ntraining to obtain the watermarked GNN model, and 3) verify the ownership of\nthe suspicious model in a black-box setting. The experiments show that our\nframework can verify the ownership of GNN models with a very high probability\n(around $100\\%$) for both tasks. In addition, we experimentally show that our\nwatermarking approach is still effective even when considering suspicious\nmodels obtained from different architectures than the owner's.",
    "descriptor": "",
    "authors": [
      "Jing Xu",
      "Stjepan Picek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.11024"
  },
  {
    "id": "arXiv:2110.11027",
    "title": "FedGEMS: Federated Learning of Larger Server Models via Selective  Knowledge Fusion",
    "abstract": "Today data is often scattered among billions of resource-constrained edge\ndevices with security and privacy constraints. Federated Learning (FL) has\nemerged as a viable solution to learn a global model while keeping data\nprivate, but the model complexity of FL is impeded by the computation resources\nof edge nodes. In this work, we investigate a novel paradigm to take advantage\nof a powerful server model to break through model capacity in FL. By\nselectively learning from multiple teacher clients and itself, a server model\ndevelops in-depth knowledge and transfers its knowledge back to clients in\nreturn to boost their respective performance. Our proposed framework achieves\nsuperior performance on both server and client models and provides several\nadvantages in a unified framework, including flexibility for heterogeneous\nclient architectures, robustness to poisoning attacks, and communication\nefficiency between clients and server. By bridging FL effectively with larger\nserver model training, our proposed paradigm paves ways for robust and\ncontinual knowledge accumulation from distributed and private data.",
    "descriptor": "\nComments: Under review as a conference paper at ICLR 2022\n",
    "authors": [
      "Sijie Cheng",
      "Jingwen Wu",
      "Yanghua Xiao",
      "Yang Liu",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11027"
  },
  {
    "id": "arXiv:2110.11033",
    "title": "Fundamental Wireless Performance of a Building",
    "abstract": "Over 80% of wireless traffic already takes place in buildings. Like water,\ngas, and electricity, wireless communication is becoming one of the most\nfundamental utilities of a building. It is well known that building structures\nhave a significant impact on in-building wireless networks. If we seek to\nachieve the optimal network performance indoors, the buildings should be\ndesigned with the objective of maximizing wireless performance. So far,\nwireless performance has not yet been considered when designing a building. In\nthis paper, we introduce a novel and interdisciplinary concept of building\nwireless performance (BWP) to a wide audience in both wireless communications\nand building design, emphasizing its broad impacts on wireless network\ndevelopment and deployment, and on building layout/material design. We first\ngive an overview of the BWP evaluation framework proposed in our\nstate-of-the-art works and explain their interconnections. Then, we outline the\npotential research directions in this exciting research area to encourage\nfurther interdisciplinary research.",
    "descriptor": "\nComments: Accepted at IEEE Wireless Communications\n",
    "authors": [
      "Jiliang Zhang",
      "Andr\u00e9s Alay\u00f3n Glazunov",
      "Wenfei Yang",
      "Jie Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.11033"
  },
  {
    "id": "arXiv:2110.11034",
    "title": "Certifying C program correctness with respect to CompCert with VeriFast",
    "abstract": "VeriFast is a powerful tool for verification of various correctness\nproperties of C programs using symbolic execution. However, VeriFast itself has\nnot been verified. We present a proof-of-concept extension which generates a\ncorrectness certificate for each successful verification run individually. This\ncertificate takes the form of a Coq script containing two proofs which, when\nsuccessfully checked by Coq, together remove the need for trusting in the\ncorrectness of VeriFast itself.\nThe first proves a lemma expressing the correctness of the program with\nrespect to a big step operational semantics developed by ourselves, intended to\nreflect VeriFast's interpretation of C. We have formalized this semantics in\nCoq as cbsem. This lemma is proven by symbolic execution in Coq, which in turn\nis implemented by transforming the exported AST of the program into a Coq\nproposition representing the symbolic execution performed by VeriFast itself.\nThe second proves the correctness of the same C program with respect to\nCompCert's Clight big step semantics. This proof simply applies our proof of\nthe soundness of cbsem with respect to CompCert Clight to the first proof.",
    "descriptor": "",
    "authors": [
      "Stefan Wils",
      "Bart Jacobs"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2110.11034"
  },
  {
    "id": "arXiv:2110.11036",
    "title": "RefRec: Pseudo-labels Refinement via Shape Reconstruction for  Unsupervised 3D Domain Adaptation",
    "abstract": "Unsupervised Domain Adaptation (UDA) for point cloud classification is an\nemerging research problem with relevant practical motivations. Reliance on\nmulti-task learning to align features across domains has been the standard way\nto tackle it. In this paper, we take a different path and propose RefRec, the\nfirst approach to investigate pseudo-labels and self-training in UDA for point\nclouds. We present two main innovations to make self-training effective on 3D\ndata: i) refinement of noisy pseudo-labels by matching shape descriptors that\nare learned by the unsupervised task of shape reconstruction on both domains;\nii) a novel self-training protocol that learns domain-specific decision\nboundaries and reduces the negative impact of mislabelled target samples and\nin-domain intra-class variability. RefRec sets the new state of the art in both\nstandard benchmarks used to test UDA for point cloud classification, showcasing\nthe effectiveness of self-training for this important problem.",
    "descriptor": "\nComments: 3DV 2021 (Oral) Code: this https URL\n",
    "authors": [
      "Adriano Cardace",
      "Riccardo Spezialetti",
      "Pierluigi Zama Ramirez",
      "Samuele Salti",
      "Luigi Di Stefano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11036"
  },
  {
    "id": "arXiv:2110.11037",
    "title": "\"Computer Says No\": Algorithmic Decision Support and Organisational  Responsibility",
    "abstract": "Algorithmic decision support is increasingly used in a whole array of\ndifferent contexts and structures in various areas of society, influencing many\npeople's lives. Its use raises questions, among others, about accountability,\ntransparency and responsibility. While there is substantial research on the\nissue of algorithmic systems and responsibility in general, there is little to\nno prior research on organisational responsibility and its attribution. Our\narticle aims to fill that gap; we give a brief overview of the central issues\nconnected to ADS, responsibility and decision-making in organisational contexts\nand identify open questions and research gaps. Furthermore, we describe a set\nof guidelines and a complementary digital tool to assist practitioners in\nmapping responsibility when introducing ADS within their organisational\ncontext.",
    "descriptor": "\nComments: 24 pages, 2 figures\n",
    "authors": [
      "Angelika Adensamer",
      "Rita Gsenger",
      "Lukas Daniel Klausner"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.11037"
  },
  {
    "id": "arXiv:2110.11039",
    "title": "Automated Climate Analyses Using Knowledge Graph",
    "abstract": "The FAIR (Findable, Accessible, Interoperable, Reusable) data principles are\nfundamental for climate researchers and all stakeholders in the current digital\necosystem. In this paper, we demonstrate how relational climate data can be\n\"FAIR\" and modeled using RDF, in line with Semantic Web technologies and our\nClimate Analysis ontology. Thus, heterogeneous climate data can be stored in\ngraph databases and offered as Linked Data on the Web. As a result, climate\nresearchers will be able to use the standard SPARQL query language to query\nthese sources directly on the Web. In this paper, we demonstrate the usefulness\nof our SPARQL endpoint for automated climate analytics. We illustrate two\nsample use cases that establish the advantage of representing climate data as\nknowledge graphs.",
    "descriptor": "\nComments: Accepted in Proc. IEEE AP-S Symposium on Antennas and Propagation and USNC-URSI Radio Science Meeting, 2021\n",
    "authors": [
      "Jiantao Wu",
      "Huan Chen",
      "Fabrizio Orlandi",
      "Yee Hui Lee",
      "Declan O'Sullivan",
      "Soumyabrata Dev"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.11039"
  },
  {
    "id": "arXiv:2110.11040",
    "title": "InterpolationSLAM: A Novel Robust Visual SLAM System in Rotational  Motion",
    "abstract": "In recent years, visual SLAM has achieved great progress and development in\ndifferent scenes, however, there are still many problems to be solved. The SLAM\nsystem is not only restricted by the external scenes but is also affected by\nits movement mode, such as movement speed, rotational motion, etc. As the\nrepresentatives of the most excellent networks for frame interpolation,\nSepconv-slomo and EDSC can predict high-quality intermediate frame between the\nprevious frame and the current frame. Intuitively, frame interpolation\ntechnology can enrich the information of images sequences, the number of which\nis limited by the camera's frame rate, and thus decreasing the probability of\nSLAM system's failure rate. In this article, we propose an InterpolationSLAM\nframework. InterpolationSLAM is robust in rotational movement for Monocular and\nRGB-D configurations. By detecting the rotation and performing interpolation\nprocessing at the rotated position, pose of the system can be estimated more\naccurately, thereby improving the accuracy and robustness of the SLAM system in\nthe rotational movement.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2110.02593\n",
    "authors": [
      "Zhenkun Zhu",
      "Jikai Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.11040"
  },
  {
    "id": "arXiv:2110.11043",
    "title": "Improving the Deployment of Recycling Classification through Efficient  Hyper-Parameter Analysis",
    "abstract": "The paradigm of automated waste classification has recently seen a shift in\nthe domain of interest from conventional image processing techniques to\npowerful computer vision algorithms known as convolutional neural networks\n(CNN). Historically, CNNs have demonstrated a strong dependency on powerful\nhardware for real-time classification, yet the need for deployment on weaker\nembedded devices is greater than ever. The work in this paper proposes a\nmethodology for reconstructing and tuning conventional image classification\nmodels, using EfficientNets, to decrease their parameterisation with no\ntrade-off in model accuracy and develops a pipeline through TensorRT for\naccelerating such models to run at real-time on an NVIDIA Jetson Nano embedded\ndevice. The train-deployment discrepancy, relating how poor data augmentation\nleads to a discrepancy in model accuracy between training and deployment, is\noften neglected in many papers and thus the work is extended by analysing and\nevaluating the impact real word perturbations had on model accuracy once\ndeployed. The scope of the work concerns developing a more efficient variant of\nWasteNet, a collaborative recycling classification model. The newly developed\nmodel scores a test-set accuracy of 95.8\\% with a real word accuracy of 95%, a\n14% increase over the original. Our acceleration pipeline boosted model\nthroughput by 750% to 24 inferences per second on the Jetson Nano and real-time\nlatency of the system was verified through servomotor latency analysis.",
    "descriptor": "",
    "authors": [
      "Mazin Abdulmahmood",
      "Ryan Grammenos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11043"
  },
  {
    "id": "arXiv:2110.11044",
    "title": "Bayesian Meta-Learning Through Variational Gaussian Processes",
    "abstract": "Recent advances in the field of meta-learning have tackled domains consisting\nof large numbers of small (\"few-shot\") supervised learning tasks. Meta-learning\nalgorithms must be able to rapidly adapt to any individual few-shot task,\nfitting to a small support set within a task and using it to predict the labels\nof the task's query set. This problem setting can be extended to the Bayesian\ncontext, wherein rather than predicting a single label for each query data\npoint, a model predicts a distribution of labels capturing its uncertainty.\nSuccessful methods in this domain include Bayesian ensembling of MAML-based\nmodels, Bayesian neural networks, and Gaussian processes with learned deep\nkernel and mean functions. While Gaussian processes have a robust Bayesian\ninterpretation in the meta-learning context, they do not naturally model\nnon-Gaussian predictive posteriors for expressing uncertainty. In this paper,\nwe design a theoretically principled method, VMGP, extending\nGaussian-process-based meta-learning to allow for high-quality, arbitrary\nnon-Gaussian uncertainty predictions. On benchmark environments with complex\nnon-smooth or discontinuous structure, we find our VMGP method performs\nsignificantly better than existing Bayesian meta-learning baselines.",
    "descriptor": "",
    "authors": [
      "Vivek Myers",
      "Nikhil Sardana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.11044"
  },
  {
    "id": "arXiv:2110.11048",
    "title": "Mixer-based lidar lane detection network and dataset for urban roads",
    "abstract": "Accurate lane detection under various road conditions is a critical function\nfor autonomous driving. Generally, when detected lane lines from a front camera\nimage are projected into a birds-eye view (BEV) for motion planning, the\nresulting lane lines are often distorted. And convolutional neural network\n(CNN)-based feature extractors often lose resolution when increasing the\nreceptive field to detect global features such as lane lines. However, Lidar\npoint cloud has little image distortion in the BEV-projection. Since lane lines\nare thin and stretch over entire BEV image while occupying only a small\nportion, lane lines should be detected as a global feature with high\nresolution. In this paper, we propose Lane Mixer Network (LMN) that extracts\nlocal features from Lidar point cloud, recognizes global features, and detects\nlane lines using a BEV encoder, a Mixer-based global feature extractor, and a\ndetection head, respectively. In addition, we provide a world-first large urban\nlane dataset for Lidar, K-Lane, which has maximum 6 lanes under various urban\nroad conditions. We demonstrate that the proposed LMN achieves the\nstate-of-the-art performance, an F1 score of 91.67%, with K-Lane. The K-Lane,\nLMN training code, pre-trained models, and total dataset development platform\nare available at github.",
    "descriptor": "\nComments: 15 pages, 12 figures, 8 tables\n",
    "authors": [
      "Donghee Paek",
      "Seung-Hyun Kong",
      "Kevin Tirta Wijaya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.11048"
  },
  {
    "id": "arXiv:2110.11052",
    "title": "WareVR: Virtual Reality Interface for Supervision of Autonomous Robotic  System Aimed at Warehouse Stocktaking",
    "abstract": "WareVR is a novel human-robot interface based on a virtual reality (VR)\napplication to interact with a heterogeneous robotic system for automated\ninventory management. We have created an interface to supervise an autonomous\nrobot remotely from a secluded workstation in a warehouse that could benefit\nduring the current pandemic COVID-19 since the stocktaking is a necessary and\nregular process in warehouses, which involves a group of people. The proposed\ninterface allows regular warehouse workers without experience in robotics to\ncontrol the heterogeneous robotic system consisting of an unmanned ground\nvehicle (UGV) and unmanned aerial vehicle (UAV). WareVR provides visualization\nof the robotic system in a digital twin of the warehouse, which is accompanied\nby a real-time video stream from the real environment through an on-board UAV\ncamera. Using the WareVR interface, the operator can conduct different levels\nof stocktaking, monitor the inventory process remotely, and teleoperate the\ndrone for a more detailed inspection. Besides, the developed interface includes\nremote control of the UAV for intuitive and straightforward human interaction\nwith the autonomous robot for stocktaking. The effectiveness of the VR-based\ninterface was evaluated through the user study in a \"visual inspection\"\nscenario.",
    "descriptor": "\nComments: Accepted to 2021 IEEE International Conference on Systems, Man, and Cybernetics, 7 pages, 8 figures\n",
    "authors": [
      "Ivan Kalinov",
      "Daria Trinitatova",
      "Dzmitry Tsetserukou"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.11052"
  },
  {
    "id": "arXiv:2110.11053",
    "title": "$Q$-tensor gradient flow with quasi-entropy and discretizations  preserving physical constraints",
    "abstract": "We propose and analyze numerical schemes for the gradient flow of $Q$-tensor\nwith the quasi-entropy. The quasi-entropy is a strictly convex, rotationally\ninvariant elementary function, giving a singular potential constraining the\neigenvalues of $Q$ within the physical range $(-1/3,2/3)$. Compared with the\npotential derived from the Bingham distribution, the quasi-entropy has the same\nasymptotic behavior and underlying physics. Meanwhile, it is very easy to\nevaluate because of its simple expression. For the elastic energy, we include\nall the rotationally invariant terms. The numerical schemes for the gradient\nflow are built on the nice properties of the quasi-entropy. The first-order\ntime discretization is uniquely solvable, keeping the physical constraints and\nenergy dissipation, which are all independent of the time step. The\nsecond-order time discretization keeps the first two properties\nunconditionally, and the third with an $O(1)$ restriction on the time step.\nThese results also hold when we further incorporate a second-order\ndiscretization in space. Error estimates are also established for time\ndiscretization and full discretization. Numerical examples about defect\npatterns are presented to validate the theoretical results.",
    "descriptor": "\nComments: 25 pages, 7 figures\n",
    "authors": [
      "Yanli Wang",
      "Jie Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.11053"
  },
  {
    "id": "arXiv:2110.11054",
    "title": "A Geometric Approach for Computing the Kernelof a Polyhedron",
    "abstract": "We present a geometric algorithm to compute the geometric kernel of a generic\npolyhedron. The geometric kernel (or simply kernel) is definedas the set of\npoints from which the whole polyhedron is visible. Whilst the computation of\nthe kernel for a polygon has already been largely addressed in the literature,\nless has been done for polyhedra. Currently, the principal implementation of\nthe kernel estimation is based on the solution of a linear programming problem.\nWe compare against it on several examples, showing that our method is more\nefficient in analysing the elements of a generic tessellation. Details on the\ntechnical implementation and discussions on pros and cons of the method are\nalso provided.",
    "descriptor": "",
    "authors": [
      "Tommaso Sorgente",
      "Silvia Biasotti",
      "Michela Spagnuolo"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.11054"
  },
  {
    "id": "arXiv:2110.11062",
    "title": "Transfer beyond the Field of View: Dense Panoramic Semantic Segmentation  via Unsupervised Domain Adaptation",
    "abstract": "Autonomous vehicles clearly benefit from the expanded Field of View (FoV) of\n360-degree sensors, but modern semantic segmentation approaches rely heavily on\nannotated training data which is rarely available for panoramic images. We look\nat this problem from the perspective of domain adaptation and bring panoramic\nsemantic segmentation to a setting, where labelled training data originates\nfrom a different distribution of conventional pinhole camera images. To achieve\nthis, we formalize the task of unsupervised domain adaptation for panoramic\nsemantic segmentation and collect DensePASS - a novel densely annotated dataset\nfor panoramic segmentation under cross-domain conditions, specifically built to\nstudy the Pinhole-to-Panoramic domain shift and accompanied with pinhole camera\ntraining examples obtained from Cityscapes. DensePASS covers both, labelled-\nand unlabelled 360-degree images, with the labelled data comprising 19 classes\nwhich explicitly fit the categories available in the source (i.e. pinhole)\ndomain. Since data-driven models are especially susceptible to changes in data\ndistribution, we introduce P2PDA - a generic framework for Pinhole-to-Panoramic\nsemantic segmentation which addresses the challenge of domain divergence with\ndifferent variants of attention-augmented domain adaptation modules, enabling\nthe transfer in output-, feature-, and feature confidence spaces. P2PDA\nintertwines uncertainty-aware adaptation using confidence values regulated\non-the-fly through attention heads with discrepant predictions. Our framework\nfacilitates context exchange when learning domain correspondences and\ndramatically improves the adaptation performance of accuracy- and\nefficiency-focused models. Comprehensive experiments verify that our framework\nclearly surpasses unsupervised domain adaptation- and specialized panoramic\nsegmentation approaches.",
    "descriptor": "\nComments: Accepted to IEEE Transactions on Intelligent Transportation Systems (IEEE T-ITS). Dataset and code will be made publicly available at this https URL arXiv admin note: substantial text overlap with arXiv:2108.06383\n",
    "authors": [
      "Jiaming Zhang",
      "Chaoxiang Ma",
      "Kailun Yang",
      "Alina Roitberg",
      "Kunyu Peng",
      "Rainer Stiefelhagen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.11062"
  },
  {
    "id": "arXiv:2110.11064",
    "title": "Robust Edge-Direct Visual Odometry based on CNN edge detection and  Shi-Tomasi corner optimization",
    "abstract": "In this paper, we propose a robust edge-direct visual odometry (VO) based on\nCNN edge detection and Shi-Tomasi corner optimization. Four layers of pyramids\nwere extracted from the image in the proposed method to reduce the motion error\nbetween frames. This solution used CNN edge detection and Shi-Tomasi corner\noptimization to extract information from the image. Then, the pose estimation\nis performed using the Levenberg-Marquardt (LM) algorithm and updating the\nkeyframes. Our method was compared with the dense direct method, the improved\ndirect method of Canny edge detection, and ORB-SLAM2 system on the RGB-D TUM\nbenchmark. The experimental results indicate that our method achieves better\nrobustness and accuracy.",
    "descriptor": "",
    "authors": [
      "Kengdong Lu",
      "Jintao Cheng",
      "Yubin Zhou",
      "Juncan Deng",
      "Rui Fan",
      "Kaiqing Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.11064"
  },
  {
    "id": "arXiv:2110.11069",
    "title": "Pacta sunt servanda: legal contracts in Stipula",
    "abstract": "There is a growing interest in running legal contracts on digital systems, at\nthe same time, it is important to understand to what extent software contracts\nmay capture legal content. We then undertake a foundational study of legal\ncontracts and we distill four main features: agreement, permissions, violations\nand obligations. We therefore design Stipula, a domain specific language that\nassists lawyers in programming legal contracts through specific patterns. The\nlanguage is based on a small set of abstractions that correspond to common\npatterns in legal contracts, and that are amenable to be executed either on\ncentralized or on distributed systems. Stipula comes with a formal semantics\nand an observational equivalence, that provide for a clear account of the\ncontracts' behaviour. The expressive power of the language is illustrated by a\nset of examples that correspond to template contracts that are often used in\npractice.",
    "descriptor": "",
    "authors": [
      "Silvia Crafa",
      "Cosimo Laneve",
      "Giovanni Sartor"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2110.11069"
  },
  {
    "id": "arXiv:2110.11070",
    "title": "A Nested Weighted Tchebycheff Multi-Objective Bayesian Optimization  Approach for Flexibility of Unknown Utopia Estimation in Expensive Black-box  Design Problems",
    "abstract": "We propose a nested weighted Tchebycheff Multi-objective Bayesian\noptimization framework where we build a regression model selection procedure\nfrom an ensemble of models, towards better estimation of the uncertain\nparameters of the weighted-Tchebycheff expensive black-box multi-objective\nfunction. In existing work, a weighted Tchebycheff MOBO approach has been\ndemonstrated which attempts to estimate the unknown utopia in formulating\nacquisition function, through calibration using a priori selected regression\nmodel. However, the existing MOBO model lacks flexibility in selecting the\nappropriate regression models given the guided sampled data and therefore, can\nunder-fit or over-fit as the iterations of the MOBO progress, reducing the\noverall MOBO performance. As it is too complex to a priori guarantee a best\nmodel in general, this motivates us to consider a portfolio of different\nfamilies of predictive models fitted with current training data, guided by the\nWTB MOBO; the best model is selected following a user-defined prediction root\nmean-square-error-based approach. The proposed approach is implemented in\noptimizing a multi-modal benchmark problem and a thin tube design under\nconstant loading of temperature-pressure, with minimizing the risk of\ncreep-fatigue failure and design cost. Finally, the nested weighted Tchebycheff\nMOBO model performance is compared with different MOBO frameworks with respect\nto accuracy in parameter estimation, Pareto-optimal solutions and function\nevaluation cost. This method is generalized enough to consider different\nfamilies of predictive models in the portfolio for best model selection, where\nthe overall design architecture allows for solving any high-dimensional\n(multiple functions) complex black-box problems and can be extended to any\nother global criterion multi-objective optimization methods where prior\nknowledge of utopia is required.",
    "descriptor": "\nComments: 35 pages, 8 figures in main text and 2 figures in supplementary\n",
    "authors": [
      "Arpan Biswas",
      "Claudio Fuentes",
      "Christopher Hoyle"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.11070"
  },
  {
    "id": "arXiv:2110.11072",
    "title": "Sequential Modeling with Multiple Attributes for Watchlist  Recommendation in E-Commerce",
    "abstract": "In e-commerce, the watchlist enables users to track items over time and has\nemerged as a primary feature, playing an important role in users' shopping\njourney. Watchlist items typically have multiple attributes whose values may\nchange over time (e.g., price, quantity). Since many users accumulate dozens of\nitems on their watchlist, and since shopping intents change over time,\nrecommending the top watchlist items in a given context can be valuable. In\nthis work, we study the watchlist functionality in e-commerce and introduce a\nnovel watchlist recommendation task. Our goal is to prioritize which watchlist\nitems the user should pay attention to next by predicting the next items the\nuser will click. We cast this task as a specialized sequential recommendation\ntask and discuss its characteristics. Our proposed recommendation model,\nTrans2D, is built on top of the Transformer architecture, where we further\nsuggest a novel extended attention mechanism (Attention2D) that allows to learn\ncomplex item-item, attribute-attribute and item-attribute patterns from\nsequential-data with multiple item attributes. Using a large-scale watchlist\ndataset from eBay, we evaluate our proposed model, where we demonstrate its\nsuperiority compared to multiple state-of-the-art baselines, many of which are\nadapted for this task.",
    "descriptor": "",
    "authors": [
      "Uriel Singer",
      "Haggai Roitman",
      "Yotam Eshel",
      "Alexander Nus",
      "Ido Guy",
      "Or Levi",
      "Idan Hasson",
      "Eliyahu Kiperwasser"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11072"
  },
  {
    "id": "arXiv:2110.11073",
    "title": "RL4RS: A Real-World Benchmark for Reinforcement Learning based  Recommender System",
    "abstract": "Reinforcement learning based recommender systems (RL-based RS) aims at\nlearning a good policy from a batch of collected data, with casting sequential\nrecommendation to multi-step decision-making tasks. However, current RL-based\nRS benchmarks commonly have a large reality gap, because they involve\nartificial RL datasets or semi-simulated RS datasets, and the trained policy is\ndirectly evaluated in the simulation environment. In real-world situations, not\nall recommendation problems are suitable to be transformed into reinforcement\nlearning problems. Unlike previous academic RL researches, RL-based RS suffer\nfrom extrapolation error and the difficulties of being well validated before\ndeployment. In this paper, we introduce the RL4RS (Reinforcement Learning for\nRecommender Systems) benchmark - a new resource fully collected from industrial\napplications to train and evaluate RL algorithms with special concerns on the\nabove issues. It contains two datasets, tuned simulation environments, related\nadvanced RL baselines, data understanding tools, and counterfactual policy\nevaluation algorithms. The RL4RS suit can be found at\nhttps://github.com/fuxiAIlab/RL4RS. In addition to the RL-based recommender\nsystems, we expect the resource to contribute to research in reinforcement\nlearning and neural combinatorial optimization.",
    "descriptor": "\nComments: First version\n",
    "authors": [
      "Kai Wang",
      "Zhene Zou",
      "Qilin Deng",
      "Yue Shang",
      "Minghao Zhao",
      "Runze Wu",
      "Xudong Shen",
      "Tangjie Lyu",
      "Changjie Fan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11073"
  },
  {
    "id": "arXiv:2110.11075",
    "title": "Enabling a Social Robot to Process Social Cues to Detect when to Help a  User",
    "abstract": "It is important for socially assistive robots to be able to recognize when a\nuser needs and wants help. Such robots need to be able to recognize human needs\nin a real-time manner so that they can provide timely assistance. We propose an\narchitecture that uses social cues to determine when a robot should provide\nassistance. Based on a multimodal fusion approach upon eye gaze and language\nmodalities, our architecture is trained and evaluated on data collected in a\nrobot-assisted Lego building task. By focusing on social cues, our architecture\nhas minimal dependencies on the specifics of a given task, enabling it to be\napplied in many different contexts. Enabling a social robot to recognize a\nuser's needs through social cues can help it to adapt to user behaviors and\npreferences, which in turn will lead to improved user experiences.",
    "descriptor": "\nComments: Presented at AI-HRI symposium as part of AAAI-FSS 2021 (arXiv:2109.10836)\n",
    "authors": [
      "Jason R. Wilson",
      "Phyo Thuta Aung",
      "Isabelle Boucher"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.11075"
  },
  {
    "id": "arXiv:2110.11079",
    "title": "Tagged Documents Co-Clustering",
    "abstract": "Tags are short sequences of words allowing to describe textual and non-texual\nresources such as as music, image or book. Tags could be used by machine\ninformation retrieval systems to access quickly a document. These tags can be\nused to build recommender systems to suggest similar items to a user. However,\nthe number of tags per document is limited, and often distributed according to\na Zipf law. In this paper, we propose a methodology to cluster tags into\nconceptual groups. Data are preprocessed to remove power-law effects and\nenhance the context of low-frequency words. Then, a hierarchical agglomerative\nco-clustering algorithm is proposed to group together the most related tags\ninto clusters. The capabilities were evaluated on a sparse synthetic dataset\nand a real-world tag collection associated with scientific papers. The task\nbeing unsupervised, we propose some stopping criterion for selectecting an\noptimal partitioning.",
    "descriptor": "\nComments: 15 pages, submitted and accepted to the 2021 World Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE'21) - track ICAI21\n",
    "authors": [
      "Ga\u00eblle Candel",
      "David Naccache"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.11079"
  },
  {
    "id": "arXiv:2110.11080",
    "title": "Continuous Authentication Using Mouse Movements, Machine Learning, and  Minecraft",
    "abstract": "Mouse dynamics has grown in popularity as a novel irreproducible behavioral\nbiometric. Datasets which contain general unrestricted mouse movements from\nusers are sparse in the current literature. The Balabit mouse dynamics dataset\nproduced in 2016 was made for a data science competition and despite some of\nits shortcomings, is considered to be the first publicly available mouse\ndynamics dataset. Collecting mouse movements in a dull administrative manner as\nBalabit does may unintentionally homogenize data and is also not representative\nof realworld application scenarios. This paper presents a novel mouse dynamics\ndataset that has been collected while 10 users play the video game Minecraft on\na desktop computer. Binary Random Forest (RF) classifiers are created for each\nuser to detect differences between a specific users movements and an imposters\nmovements. Two evaluation scenarios are proposed to evaluate the performance of\nthese classifiers; one scenario outperformed previous works in all evaluation\nmetrics, reaching average accuracy rates of 92%, while the other scenario\nsuccessfully reported reduced instances of false authentications of imposters.",
    "descriptor": "",
    "authors": [
      "Nyle Siddiqui",
      "Rushit Dave",
      "Naeem Seliya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.11080"
  },
  {
    "id": "arXiv:2110.11084",
    "title": "3D-ANAS v2: Grafting Transformer Module on Automatically Designed  ConvNet for Hyperspectral Image Classification",
    "abstract": "Hyperspectral image (HSI) classification has been a hot topic for decides, as\nHyperspectral image has rich spatial and spectral information, providing strong\nbasis for distinguishing different land-cover objects. Benefiting from the\ndevelopment of deep learning technologies, deep learning based HSI\nclassification methods have achieved promising performance. Recently, several\nneural architecture search (NAS) algorithms are proposed for HSI\nclassification, which further improve the accuracy of HSI classification to a\nnew level. In this paper, we revisit the search space designed in previous HSI\nclassification NAS methods and propose a novel hybrid search space, where 3D\nconvolution, 2D spatial convolution and 2D spectral convolution are employed.\nCompared search space proposed in previous works, the serach space proposed in\nthis paper is more aligned with characteristic of HSI data that is HSIs have a\nrelatively low spatial resolution and an extremely high spectral resolution. In\naddition, to further improve the classification accuracy, we attempt to graft\nthe emerging transformer module on the automatically designed ConvNet to adding\nglobal information to local region focused features learned by ConvNet. We\ncarry out comparison experiments on three public HSI datasets which have\ndifferent spectral characteristics to evaluate the proposed method.\nExperimental results show that the proposed method achieves much better\nperformance than comparison approaches, and both adopting the proposed hybrid\nsearch space and grafting transformer module improves classification accuracy.\nEspecially on the most recently captured dataset Houston University, overall\naccuracy is improved by up to nearly 6 percentage points. Code will be\navailable at: https://github.com/xmm/3D-ANAS-V2.",
    "descriptor": "\nComments: 15 pages, 10 figures\n",
    "authors": [
      "Xizhe Xue",
      "Haokui Zhang",
      "Zongwen Bai",
      "Ying Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11084"
  },
  {
    "id": "arXiv:2110.11088",
    "title": "RoMA: a Method for Neural Network Robustness Measurement and Assessment",
    "abstract": "Neural network models have become the leading solution for a large variety of\ntasks, such as classification, language processing, protein folding, and\nothers. However, their reliability is heavily plagued by adversarial inputs:\nsmall input perturbations that cause the model to produce erroneous outputs.\nAdversarial inputs can occur naturally when the system's environment behaves\nrandomly, even in the absence of a malicious adversary, and are a severe cause\nfor concern when attempting to deploy neural networks within critical systems.\nIn this paper, we present a new statistical method, called Robustness\nMeasurement and Assessment (RoMA), which can measure the expected robustness of\na neural network model. Specifically, RoMA determines the probability that a\nrandom input perturbation might cause misclassification. The method allows us\nto provide formal guarantees regarding the expected frequency of errors that a\ntrained model will encounter after deployment. Our approach can be applied to\nlarge-scale, black-box neural networks, which is a significant advantage\ncompared to recently proposed verification methods. We apply our approach in\ntwo ways: comparing the robustness of different models, and measuring how a\nmodel's robustness is affected by the magnitude of input perturbation. One\ninteresting insight obtained through this work is that, in a classification\nnetwork, different output labels can exhibit very different robustness levels.\nWe term this phenomenon categorial robustness. Our ability to perform risk and\nrobustness assessments on a categorial basis opens the door to risk mitigation,\nwhich may prove to be a significant step towards neural network certification\nin safety-critical applications.",
    "descriptor": "",
    "authors": [
      "Natan Levy",
      "Guy Katz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11088"
  },
  {
    "id": "arXiv:2110.11090",
    "title": "Blockchain-based Result Verification for Computation Offloading",
    "abstract": "Offloading of computation, e.g., to the cloud, is today a major task in\ndistributed systems. Usually, consumers which apply offloading have to trust\nthat a particular functionality offered by a service provider is delivering\ncorrect results. While redundancy (i.e., offloading a task to more than one\nservice provider) or (partial) reprocessing help to identify correct results,\nthey also lead to significantly higher cost.\nHence, within this paper, we present an approach to verify the results of\noffchain computations via the blockchain. For this, we apply zero-knowledge\nproofs to provide evidence that results are correct. Using our approach, it is\npossible to establish trust between a service consumer and arbitrary service\nproviders. We evaluate our approach using a very well-known example task, i.e.,\nthe Traveling Salesman Problem.",
    "descriptor": "",
    "authors": [
      "Benjamin K\u00f6rbel",
      "Marten Sigwart",
      "Philip Frauenthaler",
      "Michael Sober",
      "Stefan Schulte"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.11090"
  },
  {
    "id": "arXiv:2110.11091",
    "title": "E-DPNCT: An Enhanced Attack Resilient Differential Privacy Model For  Smart Grids Using Split Noise Cancellation",
    "abstract": "High frequency reporting of energy utilization data in smart grid can leads\nto leaking sensitive information regarding end users life style. We propose A\nDifferential Private Noise Cancellation Model for Load Monitoring and Billing\nfor Smart Meters (DPNCT) to protect the privacy of the smart grid data using\nnoise cancellation protocol with a master smart meter to provide accurate\nbilling and load monitoring. Next, we evaluate the performance of DPNCT under\nvarious privacy attacks such as filtering attack, negative noise cancellation\nattack and collusion attack. The DPNCT model relies on trusted master smart\nmeters and is vulnerable to collusion attack where adversary collude with\nmalicious smart meters in order to get private information of other smart\nmeters. In this paper, we propose an Enhanced DPNCT (E-DPNCT) where we use\nmultiple master smart meters for split noise at each instant in time t for\nbetter protection against collusion attack. We did extensive comparison of our\nE-DPNCT model with state of the art attack resistant privacy preserving models\nsuch as EPIC for collision attack and with Barbosa Differentialy Private (BDP)\nmodel for filtering attack. We evaluate our E-DPNCT model with real time data\nwhich shows significant improvement in privacy attack scenarios without any\ncompute intensive operations.",
    "descriptor": "\nComments: 10 pages, 12 figues, 4 tables\n",
    "authors": [
      "Khadija Hafeez",
      "Donna OShea",
      "Mubashir Husain Rehmani"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.11091"
  },
  {
    "id": "arXiv:2110.11098",
    "title": "Index Coded - NOMA in Vehicular Ad Hoc Networks",
    "abstract": "The demand for multimedia services is growing day by day in vehicular ad-hoc\nnetworks (VANETs), resulting in high spectral usage and network congestion.\nNon-orthogonal multiple access (NOMA) is a promising wireless communication\ntechnique to solve the problems related to spectral efficiency effectively. The\nindex coding (IC) is a powerful method to improve spectral utilization, where a\nsender aims to satisfy the needs of multiple receivers with a minimum number of\ntransmissions. By combining these two approaches, in this work, we propose a\nnovel technique called index coded NOMA (IC-NOMA), where we apply NOMA\ntechniques on index coded data to reduce the number of transmissions further.\nThis work shows that the IC-NOMA system demands a specific design for index\ncodes to reap the advantages of NOMA. We have done the feasibility analysis of\nthe proposed method in a general scenario and proposed an index code design to\nintegrate IC over NOMA for the best efficiency. Through detailed analytical\nstudies it is validated that the proposed transmission system provides improved\nspectral efficiency and power saving compared to conventional IC systems.",
    "descriptor": "\nComments: 13 pages, 5 figures and 9 tables\n",
    "authors": [
      "Sreelakshmi P.",
      "Jesy Pachat",
      "Anjana A. Mahesh",
      "Deepthi P. P.",
      "B. Sundar Rajan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.11098"
  },
  {
    "id": "arXiv:2110.11102",
    "title": "Physical Layer Security in Relay Networks with Outdated Relay Selection",
    "abstract": "In this paper, the secrecy performance of a cooperative relay network with\noutdated relay selection is investigated where an eavesdropper intercepts the\nchannels between the source and the destination. The best relay is chosen among\nN relays based on the opportunistic relay selection algorithm, which may not be\nthe best relay at the time of transmission because of the outdated channel\nstate information. We derive closed-form analytical expressions for the\nnon-zero secrecy capacity, the secrecy outage probability, and the ergodic\nsecrecy capacity. Finally, our theoretical analysis is validated by the\nnumerical results, and detailed discussions and insights are given.",
    "descriptor": "",
    "authors": [
      "Shahla Mohsenifard"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.11102"
  },
  {
    "id": "arXiv:2110.11104",
    "title": "Intelligent Reflecting Surface for Multi-Path Beam Routing with  Active/Passive Beam Splitting and Combining",
    "abstract": "Intelligent reflecting surface (IRS) can be densely deployed in wireless\nnetworks to significantly enhance the communication channels. In this letter,\nwe consider the downlink transmission from a multi-antenna base station (BS) to\na single-antenna user, by exploiting the cooperative passive beamforming (CPB)\nand line-of-sight (LoS) path diversity gains of multi-IRS signal reflection.\nUnlike existing works where only one single multi-IRS reflection path from the\nBS to user is selected, we propose a new and more general {\\it\n\\textbf{multi-path beam routing}} scheme. Specifically, the BS sends the user's\ninformation signal via multiple orthogonal active beams (termed as {\\it\n\\textbf{active beam splitting}}), which point towards different IRSs. Then,\nthese beamed signals are subsequently reflected by selected IRSs via their CPB\nin different paths, and finally coherently combined at the user's receiver\n(thus named {\\it \\textbf{passive beam combining}}). For this scheme, we\nformulate a new multi-path beam routing design problem to jointly optimize the\nnumber of IRS reflection paths, the selected IRSs for each of the reflection\npaths, the active/passive beamforming at the BS/each selected IRS, as well as\nthe BS's power allocation over different active beams, so as to maximize the\nreceived signal power at the user. To solve this challenging problem, we first\nderive the optimal BS/IRS beamforming and BS power allocation for a given set\nof reflection paths. The clique-based approach in graph theory is then applied\nto solve the remaining multi-path selection problem efficiently. Simulation\nresults show that our proposed multi-path beam routing scheme significantly\noutperforms its conventional single-path beam routing special case.",
    "descriptor": "\nComments: 5 pages, 4 figures (9 subfigures)\n",
    "authors": [
      "Weidong Mei",
      "Rui Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.11104"
  },
  {
    "id": "arXiv:2110.11106",
    "title": "Reinforcement Learning Based Optimal Camera Placement for Depth  Observation of Indoor Scenes",
    "abstract": "Exploring the most task-friendly camera setting -- optimal camera placement\n(OCP) problem -- in tasks that use multiple cameras is of great importance.\nHowever, few existing OCP solutions specialize in depth observation of indoor\nscenes, and most versatile solutions work offline. To this problem, an OCP\nonline solution to depth observation of indoor scenes based on reinforcement\nlearning is proposed in this paper. The proposed solution comprises a\nsimulation environment that implements scene observation and reward estimation\nusing shadow maps and an agent network containing a soft actor-critic\n(SAC)-based reinforcement learning backbone and a feature extractor to extract\nfeatures from the observed point cloud layer-by-layer. Comparative experiments\nwith two state-of-the-art optimization-based offline methods are conducted. The\nexperimental results indicate that the proposed system outperforms seven out of\nten test scenes in obtaining lower depth observation error. The total error in\nall test scenes is also less than 90% of the baseline ones. Therefore, the\nproposed system is more competent for depth camera placement in scenarios where\nthere is no prior knowledge of the scenes or where a lower depth observation\nerror is the main objective.",
    "descriptor": "\nComments: Accepted to IEEE International Conference on Networking, Sensing and Control (ICNSC) 2021\n",
    "authors": [
      "Yichuan Chen",
      "Manabu Tsukada",
      "Hiroshi Esaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11106"
  },
  {
    "id": "arXiv:2110.11107",
    "title": "Extraction of Positional Player Data from Broadcast Soccer Videos",
    "abstract": "Computer-aided support and analysis are becoming increasingly important in\nthe modern world of sports. The scouting of potential prospective players,\nperformance as well as match analysis, and the monitoring of training programs\nrely more and more on data-driven technologies to ensure success. Therefore,\nmany approaches require large amounts of data, which are, however, not easy to\nobtain in general. In this paper, we propose a pipeline for the fully-automated\nextraction of positional data from broadcast video recordings of soccer\nmatches. In contrast to previous work, the system integrates all necessary\nsub-tasks like sports field registration, player detection, or team assignment\nthat are crucial for player position estimation. The quality of the modules and\nthe entire system is interdependent. A comprehensive experimental evaluation is\npresented for the individual modules as well as the entire pipeline to identify\nthe influence of errors to subsequent modules and the overall result. In this\ncontext, we propose novel evaluation metrics to compare the output with\nground-truth positional data.",
    "descriptor": "\nComments: Accepted for publication at WACV'22; Preprint\n",
    "authors": [
      "Jonas Theiner",
      "Wolfgang Gritz",
      "Eric M\u00fcller-Budack",
      "Robert Rein",
      "Daniel Memmert",
      "Ralph Ewerth"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11107"
  },
  {
    "id": "arXiv:2110.11108",
    "title": "Applying Second-Order Quantifier Elimination in Inspecting G\u00f6del's  Ontological Proof",
    "abstract": "In recent years, G\\\"odel's ontological proof and variations of it were\nformalized and analyzed with automated tools in various ways. We supplement\nthese analyses with a modeling in an automated environment based on first-order\nlogic extended by predicate quantification. Formula macros are used to\nstructure complex formulas and tasks. The analysis is presented as a generated\ntype-set document where informal explanations are interspersed with\npretty-printed formulas and outputs of reasoners for first-order theorem\nproving and second-order quantifier elimination. Previously unnoticed or\nobscured aspects and details of G\\\"odel's proof become apparent. Practical\napplication possibilities of second-order quantifier elimination are shown and\nthe encountered elimination tasks may serve as benchmarks.",
    "descriptor": "",
    "authors": [
      "Christoph Wernhard"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11108"
  },
  {
    "id": "arXiv:2110.11109",
    "title": "On the Expressive Power of TeamLTL and First-Order Team Logic over  Hyperproperties",
    "abstract": "In this article we study linear temporal logics with team semantics (TeamLTL)\nthat are novel logics for defining hyperproperties. We define Kamp-type\ntranslations of these logics into fragments of first-order team logic and\nsecond-order logic. We also characterize the expressive power and the\ncomplexity of model-checking and satisfiability of team logic and second-order\nlogic by relating them to second- and third-order arithmetic. Our results set\nin a larger context the recent results of L\\\"uck showing that the extension of\nTeamLTL by the Boolean negation is highly undecidable under the so-called\nsynchronous semantics. We also study stutter-invariant fragments of extensions\nof TeamLTL.",
    "descriptor": "",
    "authors": [
      "Juha Kontinen",
      "Max Sandstr\u00f6m"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.11109"
  },
  {
    "id": "arXiv:2110.11110",
    "title": "A Secretive Coded Caching for Shared Cache Systems using PDAs",
    "abstract": "This paper considers the secretive coded caching problem with shared caches\nin which no user must have access to the files that it did not demand. In a\nshared cache network, the users are served by a smaller number of helper caches\nand each user is connected to exactly one helper cache. To ensure the secrecy\nconstraint in shared cache networks, each user is required to have an\nindividual cache of at least unit file size. For this setting, a secretive\ncoded caching scheme was proposed recently in the literature\n(\\enquote{Secretive Coded Caching with Shared Caches}, in \\textit{IEEE\nCommunications Letters}, 2021), and it requires a subpacketization level which\nis in the exponential order of the number of helper caches. By utilizing the\nPDA constructions, we propose a procedure to obtain new secretive coded caching\nschemes for shared caches with reduced subpacketization levels. We also show\nthat the existing secretive coded caching scheme for shared caches can be\nrecovered using our procedure. Furthermore, we derive a lower bound on the\nsecretive transmission rate using cut-set arguments and demonstrate the\norder-optimality of the proposed secretive coded caching scheme.",
    "descriptor": "\nComments: 10 pages and 4 figures\n",
    "authors": [
      "Elizabath Peter",
      "K. K. Krishnan Namboodiri",
      "B. Sundar Rajan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.11110"
  },
  {
    "id": "arXiv:2110.11111",
    "title": "A Deep Insight into Measuring Face Image Utility with General and  Face-specific Image Quality Metrics",
    "abstract": "Quality scores provide a measure to evaluate the utility of biometric samples\nfor biometric recognition. Biometric recognition systems require high-quality\nsamples to achieve optimal performance. This paper focuses on face images and\nthe measurement of face image utility with general and face-specific image\nquality metrics. While face-specific metrics rely on features of aligned face\nimages, general image quality metrics can be used on the global image and\nrelate to human perceptions. In this paper, we analyze the gap between the\ngeneral image quality metrics and the face image quality metrics. Our\ncontribution lies in a thorough examination of how different the image quality\nassessment algorithms relate to the utility for the face recognition task. The\nresults of image quality assessment algorithms are further compared with those\nof dedicated face image quality assessment algorithms. In total, 25 different\nquality metrics are evaluated on three face image databases, BioSecure, LFW,\nand VGGFace2 using three open-source face recognition solutions, SphereFace,\nArcFace, and FaceNet. Our results reveal a clear correlation between learned\nimage metrics to face image utility even without being specifically trained as\na face utility measure. Individual handcrafted features lack general stability\nand perform significantly worse than general face-specific quality metrics. We\nadditionally provide a visual insight into the image areas contributing to the\nquality score of a selected set of quality assessment methods.",
    "descriptor": "\nComments: 8 pages, 5 figures, IEEE Winter Conf. on Applications of Computer Vision\n",
    "authors": [
      "Biying Fu",
      "Cong Chen",
      "Olaf Henniger",
      "Naser Damer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11111"
  },
  {
    "id": "arXiv:2110.11115",
    "title": "Improving Non-autoregressive Generation with Mixup Training",
    "abstract": "While pre-trained language models have achieved great success on various\nnatural language understanding tasks, how to effectively leverage them into\nnon-autoregressive generation tasks remains a challenge. To solve this problem,\nwe present a non-autoregressive generation model based on pre-trained\ntransformer models. To bridge the gap between autoregressive and\nnon-autoregressive models, we propose a simple and effective iterative training\nmethod called MIx Source and pseudo Target (MIST). Unlike other iterative\ndecoding methods, which sacrifice the inference speed to achieve better\nperformance based on multiple decoding iterations, MIST works in the training\nstage and has no effect on inference time. Our experiments on three generation\nbenchmarks including question generation, summarization and paraphrase\ngeneration, show that the proposed framework achieves the new state-of-the-art\nresults for fully non-autoregressive models. We also demonstrate that our\nmethod can be used to a variety of pre-trained models. For instance, MIST based\non the small pre-trained model also obtains comparable performance with seq2seq\nmodels.",
    "descriptor": "",
    "authors": [
      "Ting Jiang",
      "Shaohan Huang",
      "Zihan Zhang",
      "Deqing Wang",
      "Fuzhen Zhuang",
      "Furu Wei",
      "Haizhen Huang",
      "Liangjie Zhang",
      "Qi Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.11115"
  },
  {
    "id": "arXiv:2110.11121",
    "title": "Joint Power Control, Channel Assignment and Cell Association in  Heterogeneous Cellular Networks",
    "abstract": "Heterogeneous network (HetNet) is a promising concept for increasing capacity\nand alleviating spectrum scarcity. In HetNets, however, channel assignment and\ntransmit power control affect the distribution of users among base stations. We\npresent a novel scheme to maximize the uplink sum rate in two-tier HetNets with\none macrocell and several femtocells, where the transmit power of each user is\nbounded and at least one channel is assigned to each user. We divide the\nproblem into two sub-problems: one for channel assignment and one for transmit\npower control and solve them by iteratively alternating between the two. Our\nscheme is convergent and yields a transmission rate above 6 bps/Hz for almost\n50% of users as compared to the same for 10% of users in SINR-based schemes.\nWhen users are in cell boundaries, the average transmission rate for fractional\nfrequency reuse is up to 20% more compared to the conventional full frequency\nreuse. This is due to reduced transmit power resulting in less interference.",
    "descriptor": "",
    "authors": [
      "Shahla Mohsenifard",
      "Ahmad R. Sharafat",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.11121"
  },
  {
    "id": "arXiv:2110.11128",
    "title": "A Strong Baseline for Semi-Supervised Incremental Few-Shot Learning",
    "abstract": "Few-shot learning (FSL) aims to learn models that generalize to novel classes\nwith limited training samples. Recent works advance FSL towards a scenario\nwhere unlabeled examples are also available and propose semi-supervised FSL\nmethods. Another line of methods also cares about the performance of base\nclasses in addition to the novel ones and thus establishes the incremental FSL\nscenario. In this paper, we generalize the above two under a more realistic yet\ncomplex setting, named by Semi-Supervised Incremental Few-Shot Learning (S2\nI-FSL). To tackle the task, we propose a novel paradigm containing two parts:\n(1) a well-designed meta-training algorithm for mitigating ambiguity between\nbase and novel classes caused by unreliable pseudo labels and (2) a model\nadaptation mechanism to learn discriminative features for novel classes while\npreserving base knowledge using few labeled and all the unlabeled data.\nExtensive experiments on standard FSL, semi-supervised FSL, incremental FSL,\nand the firstly built S2 I-FSL benchmarks demonstrate the effectiveness of our\nproposed method.",
    "descriptor": "\nComments: Accepted by BMVC2021\n",
    "authors": [
      "Linlan Zhao",
      "Dashan Guo",
      "Yunlu Xu",
      "Liang Qiao",
      "Zhanzhan Cheng",
      "Shiliang Pu",
      "Yi Niu",
      "Xiangzhong Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11128"
  },
  {
    "id": "arXiv:2110.11129",
    "title": "Data-driven finite element method with RVE generated foam data",
    "abstract": "The data-driven finite element method proposed by Kirchdoerfer and Ortiz [1]\nallows to elude the material modeling step. Instead, a previously obtained data\nset is used directly in the algorithm to describe the material behavior under\ndeformation. Usually, this data set is expected to be gained experimentally.\nThe following empirical treatment is skipped in the data-driven framework and\nthe data is implemented in the algorithm directly. The data-driven problem is\nrewritten as a minimization problem of a distance function subject to the\nconservation laws. This paper presents a computational approach to deduce a\ndata set prior to the finite element computation. Representative volume element\ncomputations are conducted to deduce a macroscopic material behavior of a\npolyurethane foam structure. The typical linear load regime of the foam allows\nus to generate a large material database which can be used as an input for the\ndata-driven finite element computation. Furthermore, we also work out how to\nproceed in the case of (non-)linear and (an-)isotropic material behavior in\norder to obtain suitable material data sets. The numerical example which is\nconducted with the foam data is a typical rubber sealing profile. In the\ndata-driven computation itself, we use a numerical method proposed in [2] to\ndecrease the computing and storage demands.",
    "descriptor": "",
    "authors": [
      "Tim Fabian Korzeniowski",
      "Kerstin Weinberg"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2110.11129"
  },
  {
    "id": "arXiv:2110.11130",
    "title": "Inverse Optimal Control Adapted to the Noise Characteristics of the  Human Sensorimotor System",
    "abstract": "Computational level explanations based on optimal feedback control with\nsignal-dependent noise have been able to account for a vast array of phenomena\nin human sensorimotor behavior. However, commonly a cost function needs to be\nassumed for a task and the optimality of human behavior is evaluated by\ncomparing observed and predicted trajectories. Here, we introduce inverse\noptimal control with signal-dependent noise, which allows inferring the cost\nfunction from observed behavior. To do so, we formalize the problem as a\npartially observable Markov decision process and distinguish between the\nagent's and the experimenter's inference problems. Specifically, we derive a\nprobabilistic formulation of the evolution of states and belief states and an\napproximation to the propagation equation in the linear-quadratic Gaussian\nproblem with signal-dependent noise. We extend the model to the case of partial\nobservability of state variables from the point of view of the experimenter. We\nshow the feasibility of the approach through validation on synthetic data and\napplication to experimental data. Our approach enables recovering the costs and\nbenefits implicit in human sequential sensorimotor behavior, thereby\nreconciling normative and descriptive approaches in a computational framework.",
    "descriptor": "\nComments: 24 pages, 11 figures, to be published at NeurIPS 2021\n",
    "authors": [
      "Matthias Schultheis",
      "Dominik Straub",
      "Constantin A. Rothkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.11130"
  },
  {
    "id": "arXiv:2110.11133",
    "title": "Newton-Type Methods For Simultaneous Matrix Diagonalization",
    "abstract": "This paper proposes a Newton type method to solve numerically the\neigenproblem of several diagonalizable matrices, which pairwise commute. A\nclassical result states that these matrices are simultaneously diagonalizable.\nFrom a suitable system of equations associated to this problem, we construct a\nsequence which converges quadratically towards the solution. This construction\nis not based on the resolution of linear system as it is the case in the\nclassical Newton method. Moreover, we provide a theoretical analysis of this\nconstruction to exhibit a condition to get a quadratic convergence. We also\npropose numerical experiments, which illustrate the theoretical results. This\nshows that classical QR method would gain in efficiency incorporating the tests\ngiven by the theory.",
    "descriptor": "",
    "authors": [
      "Rima Khouja",
      "Bernard Mourrain",
      "Jean-Claude Yakoubsohn"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.11133"
  },
  {
    "id": "arXiv:2110.11137",
    "title": "Control of Humanoid in Multiple Fixed and Moving Unilateral Contacts",
    "abstract": "Enforcing balance of multi-limbed robots in multiple non-coplanar unilateral\ncontact settings is challenging when a subset of such contacts are also induced\nin motion tasks. The first contribution of this paper is in enhancing the\ncomputational performance of state-of-the-art geometric center-of-mass\ninclusion-based balance method to be integrated online as part of a task-space\nwhole-body control framework. As a consequence, our second contribution lies in\nintegrating such a balance region with relevant contact force distribution\nwithout pre-computing a target center-of-mass. This last feature is essential\nto leave the latter with freedom to better comply with other existing tasks\nthat are not captured in classical twolevel approaches. We assess the\nperformance of our proposed method through experiments using the HRP-4 humanoid\nrobot.",
    "descriptor": "",
    "authors": [
      "Julien Roux",
      "Saeid Samadi",
      "Eisoku Kuroiwa",
      "Takahide Yoshiike",
      "Abderrahmane Kheddar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.11137"
  },
  {
    "id": "arXiv:2110.11140",
    "title": "Dual Encoding U-Net for Spatio-Temporal Domain Shift Frame Prediction",
    "abstract": "The landscape of city-wide mobility behaviour has altered significantly over\nthe past 18 months. The ability to make accurate and reliable predictions on\nsuch behaviour has likewise changed drastically with COVID-19 measures\nimpacting how populations across the world interact with the different facets\nof mobility. This raises the question: \"How does one use an abundance of\npre-covid mobility data to make predictions on future behaviour in a\npresent/post-covid environment?\" This paper seeks to address this question by\nintroducing an approach for traffic frame prediction using a lightweight\nDual-Encoding U-Net built using only 12 Convolutional layers that incorporates\na novel approach to skip-connections between Convolutional LSTM layers. This\napproach combined with an intuitive handling of training data can model both a\ntemporal and spatio-temporal domain shift\n(gitlab.com/alchera/alchera-traffic4cast-2021).",
    "descriptor": "\nComments: 8 pages, 4 figures, 5 tables\n",
    "authors": [
      "Jay Santokhi",
      "Dylan Hillier",
      "Yiming Yang",
      "Joned Sarwar",
      "Anna Jordan",
      "Emil Hewage"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11140"
  },
  {
    "id": "arXiv:2110.11141",
    "title": "DeepBND: a Machine Learning approach to enhance Multiscale Solid  Mechanics",
    "abstract": "Effective properties of materials with random heterogeneous structures are\ntypically determined by homogenising the mechanical quantity of interest in a\nwindow of observation. The entire problem setting encompasses the solution of a\nlocal PDE and some averaging formula for the quantity of interest in such\ndomain. There are relatively standard methods in the literature to completely\ndetermine the formulation except for two choices: i) the local domain itself\nand the ii) boundary conditions. Hence, the modelling errors are governed by\nthe quality of these two choices. The choice i) relates to the degree of\nrepresentativeness of a microscale sample, i.e., it is essentially a\nstatistical characteristic. Naturally, its reliability is higher as the size of\nthe observation window becomes larger and/or the number of samples increases.\nOn the other hand, excepting few special cases there is no automatic guideline\nto handle ii). Although it is known that the overall effect of boundary\ncondition becomes less important with the size of the microscale domain, the\ncomputational cost to simulate such large problem several times might be\nprohibitive even for relatively small accuracy requirements. Here we introduce\na machine learning procedure to select most suitable boundary conditions for\nmultiscale problems, particularly those arising in solid mechanics. We propose\nthe combination Reduced-Order Models and Deep Neural Networks in an offline\nphase, whilst the online phase consists in the very same homogenisation\nprocedure plus one (cheap) evaluation of the trained model for boundary\nconditions. Hence, the method allows an implementation with minimal changes in\nexisting codes and the use of relatively small domains without losing accuracy,\nwhich reduces the computational cost by several orders of magnitude.",
    "descriptor": "\nComments: It has been submitted to Journal of Computational Physics\n",
    "authors": [
      "Felipe Rocha",
      "Simone Deparis",
      "Pablo Antolin",
      "Annalisa Buffa"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.11141"
  },
  {
    "id": "arXiv:2110.11147",
    "title": "Unique Continuation on Quadratic Curves for Harmonic Functions",
    "abstract": "The unique continuation on quadratic curves for harmonic functions is\ndiscussed in this paper. By using complex extension method, the conditional\nstability of unique continuation along quadratic curves for harmonic functions\nis illustrated. The numerical algorithm is provided based on collocation method\nand Tikhonov regularization. The stability estimates on parabolic and\nhyperbolic curves for harmonic functions are demonstrated by numerical examples\nrespectively.",
    "descriptor": "",
    "authors": [
      "Yufei Ke",
      "Yu Chen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.11147"
  },
  {
    "id": "arXiv:2110.11148",
    "title": "HCV: Hierarchy-Consistency Verification for Incremental  Implicitly-Refined Classification",
    "abstract": "Human beings learn and accumulate hierarchical knowledge over their lifetime.\nThis knowledge is associated with previous concepts for consolidation and\nhierarchical construction. However, current incremental learning methods lack\nthe ability to build a concept hierarchy by associating new concepts to old\nones. A more realistic setting tackling this problem is referred to as\nIncremental Implicitly-Refined Classification (IIRC), which simulates the\nrecognition process from coarse-grained categories to fine-grained categories.\nTo overcome forgetting in this benchmark, we propose Hierarchy-Consistency\nVerification (HCV) as an enhancement to existing continual learning methods.\nOur method incrementally discovers the hierarchical relations between classes.\nWe then show how this knowledge can be exploited during both training and\ninference. Experiments on three setups of varying difficulty demonstrate that\nour HCV module improves performance of existing continual learning methods\nunder this IIRC setting by a large margin. Code is available in\nhttps://github.com/wangkai930418/HCV_IIRC.",
    "descriptor": "\nComments: accepted in BMVC 2021\n",
    "authors": [
      "Kai Wang",
      "Xialei Liu",
      "Luis Herranz",
      "Joost van de Weijer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11148"
  },
  {
    "id": "arXiv:2110.11150",
    "title": "Towards strong pruning for lottery tickets with non-zero biases",
    "abstract": "The strong lottery ticket hypothesis holds the promise that pruning randomly\ninitialized deep neural networks could offer a computationally efficient\nalternative to deep learning with stochastic gradient descent. Common parameter\ninitialization schemes and existence proofs, however, are focused on networks\nwith zero biases, thus foregoing the potential universal approximation property\nof pruning. To fill this gap, we extend multiple initialization schemes and\nexistence proofs to non-zero biases, including explicit 'looks-linear'\napproaches for ReLU activation functions. These do not only enable truly\northogonal parameter initialization but also reduce potential pruning errors.\nIn experiments on standard benchmark data sets, we further highlight the\npractical benefits of non-zero bias initialization schemes, and present\ntheoretically inspired extensions for state-of-the-art strong lottery ticket\npruning.",
    "descriptor": "",
    "authors": [
      "Jonas Fischer",
      "Rebekka Burkholz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11150"
  },
  {
    "id": "arXiv:2110.11154",
    "title": "Personalized Transfer of User Preferences for Cross-domain  Recommendation",
    "abstract": "Cold-start problem is still a very challenging problem in recommender\nsystems. Fortunately, the interactions of the cold-start users in the auxiliary\nsource domain can help cold-start recommendations in the target domain. How to\ntransfer user's preferences from the source domain to the target domain, is the\nkey issue in Cross-domain Recommendation (CDR) which is a promising solution to\ndeal with the cold-start problem. Most existing methods model a common\npreference bridge to transfer preferences for all users. Intuitively, since\npreferences vary from user to user, the preference bridges of different users\nshould be different. Along this line, we propose a novel framework named\nPersonalized Transfer of User Preferences for Cross-domain Recommendation\n(PTUPCDR). Specifically, a meta network fed with users' characteristic\nembeddings is learned to generate personalized bridge functions to achieve\npersonalized transfer of preferences for each user. To learn the meta network\nstably, we employ a task-oriented optimization procedure. With the\nmeta-generated personalized bridge function, the user's preference embedding in\nthe source domain can be transformed into the target domain, and the\ntransformed user preference embedding can be utilized as the initial embedding\nfor the cold-start user in the target domain. Using large real-world datasets,\nwe conduct extensive experiments to evaluate the effectiveness of PTUPCDR on\nboth cold-start and warm-start stages. The code has been available at\n\\url{https://github.com/easezyc/WSDM2022-PTUPCDR}.",
    "descriptor": "\nComments: Accepted by WSDM 2022\n",
    "authors": [
      "Yongchun Zhu",
      "Zhenwei Tang",
      "Yudan Liu",
      "Fuzhen Zhuang",
      "Ruobing Xie",
      "Xu Zhang",
      "Leyu Lin",
      "Qing He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11154"
  },
  {
    "id": "arXiv:2110.11155",
    "title": "DeLag: Detecting Latency Degradation Patterns in Service-based Systems",
    "abstract": "Performance debugging in production is a fundamental activity in modern\nservice-based systems. The diagnosis of performance issues is often\ntime-consuming, since it requires thorough inspection of large volumes of\ntraces and performance indices. In this paper we present DeLag, a novel\nautomated search-based approach for diagnosing performance issues in\nservice-based systems. DeLag identifies subsets of requests that show, in the\ncombination of their Remote Procedure Call execution times, symptoms of\npotentially relevant performance issues. We call such symptoms Latency\nDegradation Patterns. DeLag simultaneously search for multiple latency\ndegradation patterns while optimizing precision, recall and latency\ndissimilarity. Experimentation on 700 datasets of requests generated from two\nmicroservice-based systems shows that our approach provide better and more\nstable effectiveness than three state-of-the-art approaches and general purpose\nmachine learning clustering algorithms. Moreover, DeLag outperforms in terms of\nefficiency the second and the third most effective baseline techniques on the\nlargest datasets used in our evaluation.",
    "descriptor": "",
    "authors": [
      "Luca Traini",
      "Vittorio Cortellessa"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2110.11155"
  },
  {
    "id": "arXiv:2110.11159",
    "title": "Each Attribute Matters: Contrastive Attention for Sentence-based Image  Editing",
    "abstract": "Sentence-based Image Editing (SIE) aims to deploy natural language to edit an\nimage. Offering potentials to reduce expensive manual editing, SIE has\nattracted much interest recently. However, existing methods can hardly produce\naccurate editing and even lead to failures in attribute editing when the query\nsentence is with multiple editable attributes. To cope with this problem, by\nfocusing on enhancing the difference between attributes, this paper proposes a\nnovel model called Contrastive Attention Generative Adversarial Network\n(CA-GAN), which is inspired from contrastive training. Specifically, we first\ndesign a novel contrastive attention module to enlarge the editing difference\nbetween random combinations of attributes which are formed during training. We\nthen construct an attribute discriminator to ensure effective editing on each\nattribute. A series of experiments show that our method can generate very\nencouraging results in sentence-based image editing with multiple attributes on\nCUB and COCO dataset. Our code is available at\nhttps://github.com/Zlq2021/CA-GAN",
    "descriptor": "\nComments: Accepted by BMVC 2021\n",
    "authors": [
      "Liuqing Zhao",
      "Fan Lyu",
      "Fuyuan Hu",
      "Kaizhu Huang",
      "Fenglei Xu",
      "Linyan Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.11159"
  },
  {
    "id": "arXiv:2110.11160",
    "title": "Self-Supervised Visual Representation Learning Using Lightweight  Architectures",
    "abstract": "In self-supervised learning, a model is trained to solve a pretext task,\nusing a data set whose annotations are created by a machine. The objective is\nto transfer the trained weights to perform a downstream task in the target\ndomain. We critically examine the most notable pretext tasks to extract\nfeatures from image data and further go on to conduct experiments on resource\nconstrained networks, which aid faster experimentation and deployment. We study\nthe performance of various self-supervised techniques keeping all other\nparameters uniform. We study the patterns that emerge by varying model type,\nsize and amount of pre-training done for the backbone as well as establish a\nstandard to compare against for future research. We also conduct comprehensive\nstudies to understand the quality of representations learned by different\narchitectures.",
    "descriptor": "\nComments: 8 pages, 4 figures, 1 table, submitted to Artificial Intelligence and Statistics 2022 (AISTATS 2022)\n",
    "authors": [
      "Prathamesh Sonawane",
      "Sparsh Drolia",
      "Saqib Shamsi",
      "Bhargav Jain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11160"
  },
  {
    "id": "arXiv:2110.11162",
    "title": "Hierarchical Multi-robot Strategies Synthesis and Optimization under  Individual and Collaborative Temporal Logic Specifications",
    "abstract": "This paper presents a hierarchical framework to solve the multi-robot\ntemporal task planning problem. We assume that each robot has its individual\ntask specification and the robots have to jointly satisfy a global\ncollaborative task specification, both described in linear temporal logic.\nSpecifically, a central server firstly extracts and decomposes a collaborative\ntask sequence from the automaton corresponding to the collaborative task\nspecification, and allocates the subtasks in the sequence to robots. The robots\ncan then synthesize their initial execution strategies based on locally\nconstructed product automatons, combining the assigned collaborative tasks and\ntheir individual task specifications. Furthermore, we propose a distributed\nexecution strategy adjusting mechanism to iteratively improve the time\nefficiency, by reducing wait time in collaborations caused by potential\nsynchronization constraints. We prove the completeness of the proposed\nframework under assumptions, and analyze its time complexity and optimality.\nExtensive simulation results verify the scalability and optimization efficiency\nof the proposed method.",
    "descriptor": "\nComments: 14 pages, 6 figures. arXiv admin note: text overlap with arXiv:2108.11597\n",
    "authors": [
      "Ruofei Bai",
      "Ronghao Zheng",
      "Yang Xu",
      "Meiqin Liu",
      "Senlin Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.11162"
  },
  {
    "id": "arXiv:2110.11164",
    "title": "Modeling Performance in Open-Domain Dialogue with PARADISE",
    "abstract": "There has recently been an explosion of work on spoken dialogue systems,\nalong with an increased interest in open-domain systems that engage in casual\nconversations on popular topics such as movies, books and music. These systems\naim to socially engage, entertain, and even empathize with their users. Since\nthe achievement of such social goals is hard to measure, recent research has\nused dialogue length or human ratings as evaluation metrics, and developed\nmethods for automatically calculating novel metrics, such as coherence,\nconsistency, relevance and engagement. Here we develop a PARADISE model for\npredicting the performance of Athena, a dialogue system that has participated\nin thousands of conversations with real users, while competing as a finalist in\nthe Alexa Prize. We use both user ratings and dialogue length as metrics for\ndialogue quality, and experiment with predicting these metrics using automatic\nfeatures that are both system dependent and independent. Our goal is to learn a\ngeneral objective function that can be used to optimize the dialogue choices of\nany Alexa Prize system in real time and evaluate its performance. Our best\nmodel for predicting user ratings gets an R$^2$ of .136 with a DistilBert\nmodel, and the best model for predicting length with system independent\nfeatures gets an R$^2$ of .865, suggesting that conversation length may be a\nmore reliable measure for automatic training of dialogue systems.",
    "descriptor": "\nComments: The 12th International Workshop on Spoken Dialog System Technology, November 2021\n",
    "authors": [
      "Marilyn Walker",
      "Colin Harmon",
      "James Graupera",
      "Davan Harrison",
      "Steve Whittaker"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11164"
  },
  {
    "id": "arXiv:2110.11166",
    "title": "Driving the Herd: Search Engines as Content Influencers",
    "abstract": "In competitive search settings such as the Web, many documents' authors\n(publishers) opt to have their documents highly ranked for some queries. To\nthis end, they modify the documents - specifically, their content - in response\nto induced rankings. Thus, the search engine affects the content in the corpus\nvia its ranking decisions. We present a first study of the ability of search\nengines to drive pre-defined, targeted, content effects in the corpus using\nsimple techniques. The first is based on the herding phenomenon - a celebrated\nresult from the economics literature - and the second is based on biasing the\nrelevance ranking function. The types of content effects we study are either\ntopical or touch on specific document properties - length and inclusion of\nquery terms. Analysis of ranking competitions we organized between incentivized\npublishers shows that the types of content effects we target can indeed be\nattained by applying our suggested techniques. These findings have important\nimplications with regard to the role of search engines in shaping the corpus.",
    "descriptor": "",
    "authors": [
      "Gregory Goren",
      "Oren Kurland",
      "Moshe Tennenholtz",
      "Fiana Raiber"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.11166"
  },
  {
    "id": "arXiv:2110.11167",
    "title": "A guided journey through non-interactive automatic story generation",
    "abstract": "We present a literature survey on non-interactive computational story\ngeneration. The article starts with the presentation of requirements for\ncreative systems, three types of models of creativity (computational,\nsocio-cultural, and individual), and models of human creative writing. Then it\nreviews each class of story generation approach depending on the used\ntechnology: story-schemas, analogy, rules, planning, evolutionary algorithms,\nimplicit knowledge learning, and explicit knowledge learning. Before the\nconcluding section, the article analyses the contributions of the reviewed work\nto improve the quality of the generated stories. This analysis addresses the\ndescription of the story characters, the use of narrative knowledge including\nabout character believability, and the possible lack of more comprehensive or\nmore detailed knowledge or creativity models. Finally, the article presents\nconcluding remarks in the form of suggestions of research topics that might\nhave a significant impact on the advancement of the state of the art on\nautonomous non-interactive story generation systems. The article concludes that\nthe autonomous generation and adoption of the main idea to be conveyed and the\nautonomous design of the creativity ensuring criteria are possibly two of most\nimportant topics for future research.",
    "descriptor": "",
    "authors": [
      "Luis Miguel Botelho"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11167"
  },
  {
    "id": "arXiv:2110.11168",
    "title": "A Survey on Methods and Metrics for the Assessment of Explainability  under the Proposed AI Act",
    "abstract": "This study discusses the interplay between metrics used to measure the\nexplainability of the AI systems and the proposed EU Artificial Intelligence\nAct. A standardisation process is ongoing: several entities (e.g. ISO) and\nscholars are discussing how to design systems that are compliant with the\nforthcoming Act and explainability metrics play a significant role. This study\nidentifies the requirements that such a metric should possess to ease\ncompliance with the AI Act. It does so according to an interdisciplinary\napproach, i.e. by departing from the philosophical concept of explainability\nand discussing some metrics proposed by scholars and standardisation entities\nthrough the lenses of the explainability obligations set by the proposed AI\nAct. Our analysis proposes that metrics to measure the kind of explainability\nendorsed by the proposed AI Act shall be risk-focused, model-agnostic,\ngoal-aware, intelligible & accessible. This is why we discuss the extent to\nwhich these requirements are met by the metrics currently under discussion.",
    "descriptor": "\nComments: Accepted paper at JURIX 2021\n",
    "authors": [
      "Francesco Sovrano",
      "Salvatore Sapienza",
      "Monica Palmirani",
      "Fabio Vitali"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.11168"
  },
  {
    "id": "arXiv:2110.11177",
    "title": "Decentralised Trustworthy Collaborative Intrusion Detection System for  IoT",
    "abstract": "Intrusion Detection Systems (IDS) have been the industry standard for\nsecuring IoT networks against known attacks. To increase the capability of an\nIDS, researchers proposed the concept of blockchain-based Collaborative-IDS\n(CIDS), wherein blockchain acts as a decentralised platform allowing\ncollaboration between CIDS nodes to share intrusion related information, such\nas intrusion alarms and detection rules. However, proposals in blockchain-based\nCIDS overlook the importance of continuous evaluation of the trustworthiness of\neach node and generally work based on the assumption that the nodes are always\nhonest. In this paper, we propose a decentralised CIDS that emphasises the\nimportance of building trust between CIDS nodes. In our proposed solution, each\nCIDS node exchanges detection rules to help other nodes detect new types of\nintrusion. Our architecture offloads the trust computation to the blockchain\nand utilises a decentralised storage to host the shared trustworthy detection\nrules, ensuring scalability. Our implementation in a lab-scale testbed shows\nthat the our solution is feasible and performs within the expected benchmarks\nof the Ethereum platform.",
    "descriptor": "\nComments: 8 pages, 7 figures, accepted to IEEE Blockchain 2021\n",
    "authors": [
      "Guntur Dharma Putra",
      "Volkan Dedeoglu",
      "Abhinav Pathak",
      "Salil S. Kanhere",
      "Raja Jurdak"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.11177"
  },
  {
    "id": "arXiv:2110.11179",
    "title": "A hyper-reduced MAC scheme for the parametric Stokes and Navier-Stokes  equations",
    "abstract": "The need for accelerating the repeated solving of certain parametrized\nsystems motivates the development of more efficient reduced order methods. The\nclassical reduced basis method is popular due to an offline-online\ndecomposition and a mathematically rigorous {\\em a posterior} error estimator\nwhich guides a greedy algorithm offline. For nonlinear and nonaffine problems,\nhyper reduction techniques have been introduced to make this decomposition\nefficient. However, they may be tricky to implement and often degrade the\nonline computation efficiency.\nTo avoid this degradation, reduced residual reduced over-collocation (R2-ROC)\nwas invented integrating empirical interpolation techniques on the solution\nsnapshots and well-chosen residuals, the collocation philosophy, and the\nsimplicity of evaluating the hyper-reduced well-chosen residuals. In this\npaper, we introduce an adaptive enrichment strategy for R2-ROC rendering it\ncapable of handling parametric fluid flow problems. Built on top of an\nunderlying Marker and Cell (MAC) scheme, a novel hyper-reduced MAC scheme is\ntherefore presented and tested on Stokes and Navier-Stokes equations\ndemonstrating its high efficiency, stability and accuracy.",
    "descriptor": "",
    "authors": [
      "Yanlai Chen",
      "Lijie Ji",
      "Zhu Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.11179"
  },
  {
    "id": "arXiv:2110.11181",
    "title": "Sensing Cox Processes via Posterior Sampling and Positive Bases",
    "abstract": "We study adaptive sensing of Cox point processes, a widely used model from\nspatial statistics. We introduce three tasks: maximization of captured events,\nsearch for the maximum of the intensity function and learning level sets of the\nintensity function. We model the intensity function as a sample from a\ntruncated Gaussian process, represented in a specially constructed positive\nbasis. In this basis, the positivity constraint on the intensity function has a\nsimple form. We show how an minimal description positive basis can be adapted\nto the covariance kernel, non-stationarity and make connections to common\npositive bases from prior works. Our adaptive sensing algorithms use Langevin\ndynamics and are based on posterior sampling (\\textsc{Cox-Thompson}) and\ntop-two posterior sampling (\\textsc{Top2}) principles. With latter, the\ndifference between samples serves as a surrogate to the uncertainty. We\ndemonstrate the approach using examples from environmental monitoring and crime\nrate modeling, and compare it to the classical Bayesian experimental design\napproach.",
    "descriptor": "",
    "authors": [
      "Mojm\u00edr Mutn\u00fd",
      "Andreas Krause"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.11181"
  },
  {
    "id": "arXiv:2110.11182",
    "title": "SLURP: Side Learning Uncertainty for Regression Problems",
    "abstract": "It has become critical for deep learning algorithms to quantify their output\nuncertainties to satisfy reliability constraints and provide accurate results.\nUncertainty estimation for regression has received less attention than\nclassification due to the more straightforward standardized output of the\nlatter class of tasks and their high importance. However, regression problems\nare encountered in a wide range of applications in computer vision. We propose\nSLURP, a generic approach for regression uncertainty estimation via a side\nlearner that exploits the output and the intermediate representations generated\nby the main task model. We test SLURP on two critical regression tasks in\ncomputer vision: monocular depth and optical flow estimation. In addition, we\nconduct exhaustive benchmarks comprising transfer to different datasets and the\naddition of aleatoric noise. The results show that our proposal is generic and\nreadily applicable to various regression problems and has a low computational\ncost with respect to existing solutions.",
    "descriptor": "",
    "authors": [
      "Xuanlong Yu",
      "Gianni Franchi",
      "Emanuel Aldea"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11182"
  },
  {
    "id": "arXiv:2110.11187",
    "title": "Heritability in Morphological Robot Evolution",
    "abstract": "In the field of evolutionary robotics, choosing the correct encoding is very\ncomplicated, especially when robots evolve both behaviours and morphologies at\nthe same time. With the objective of improving our understanding of the mapping\nprocess from encodings to functional robots, we introduce the biological notion\nof heritability, which captures the amount of phenotypic variation caused by\ngenotypic variation. In our analysis we measure the heritability on the first\ngeneration of robots evolved from two different encodings, a direct encoding\nand an indirect encoding. In addition we investigate the interplay between\nheritability and phenotypic diversity through the course of an entire\nevolutionary process. In particular, we investigate how direct and indirect\ngenotypes can exhibit preferences for exploration or exploitation throughout\nthe course of evolution. We observe how an exploration or exploitation tradeoff\ncan be more easily understood by examining patterns in heritability and\nphenotypic diversity. In conclusion, we show how heritability can be a useful\ntool to better understand the relationship between genotypes and phenotypes,\nespecially helpful when designing more complicated systems where complex\nindividuals and environments can adapt and influence each other.",
    "descriptor": "",
    "authors": [
      "Matteo De Carlo",
      "Eliseo Ferrante",
      "Daan Zeeuwe",
      "Jacintha Ellers",
      "Gerben Meynen",
      "A. E. Eiben"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.11187"
  },
  {
    "id": "arXiv:2110.11188",
    "title": "Classification of Encrypted IoT Traffic Despite Padding and Shaping",
    "abstract": "It is well known that when IoT traffic is unencrypted it is possible to\nidentify the active devices based on their TCP/IP headers. And when traffic is\nencrypted, packet-sizes and timings can still be used to do so. To defend\nagainst such fingerprinting, traffic padding and shaping were introduced. In\nthis paper we demonstrate that the packet-sizes distribution can still be used\nto successfully fingerprint the active IoT devices when shaping and padding are\nused, as long as the adversary is aware that these mitigations are deployed,\nand even if the values of the padding and shaping parameters are unknown. The\nmain tool we use in our analysis is the full distribution of packet-sizes, as\nopposed to commonly used statistics such as mean and variance. We further show\nhow an external adversary who only sees the padded and shaped traffic as\naggregated and hidden behind a NAT middlebox can accurately identify the subset\nof active devices with Recall and Precision of at least 96%. We also show that\nthe adversary can distinguish time windows containing only bogus cover packets\nfrom windows with real device activity, at a granularity of $1sec$ time\nwindows, with 81% accuracy. Using similar methodology, but now on the\ndefender's side, we are also able to detect anomalous activities in IoT traffic\ndue to the Mirai worm.",
    "descriptor": "\nComments: 13 pages, 11 figures, 7 tables\n",
    "authors": [
      "Aviv Engelberg",
      "Avishai Wool"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.11188"
  },
  {
    "id": "arXiv:2110.11190",
    "title": "On Hard Episodes in Meta-Learning",
    "abstract": "Existing meta-learners primarily focus on improving the average task accuracy\nacross multiple episodes. Different episodes, however, may vary in hardness and\nquality leading to a wide gap in the meta-learner's performance across\nepisodes. Understanding this issue is particularly critical in industrial\nfew-shot settings, where there is limited control over test episodes as they\nare typically uploaded by end-users. In this paper, we empirically analyse the\nbehaviour of meta-learners on episodes of varying hardness across three\nstandard benchmark datasets: CIFAR-FS, mini-ImageNet, and tiered-ImageNet.\nSurprisingly, we observe a wide gap in accuracy of around 50% between the\nhardest and easiest episodes across all the standard benchmarks and\nmeta-learners. We additionally investigate various properties of hard episodes\nand highlight their connection to catastrophic forgetting during meta-training.\nTo address the issue of sub-par performance on hard episodes, we investigate\nand benchmark different meta-training strategies based on adversarial training\nand curriculum learning. We find that adversarial training strategies are much\nmore powerful than curriculum learning in improving the prediction performance\non hard episodes.",
    "descriptor": "",
    "authors": [
      "Samyadeep Basu",
      "Amr Sharaf",
      "Nicolo Fusi",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11190"
  },
  {
    "id": "arXiv:2110.11191",
    "title": "Generative Adversarial Graph Convolutional Networks for Human Action  Synthesis",
    "abstract": "Synthesising the spatial and temporal dynamics of the human body skeleton\nremains a challenging task, not only in terms of the quality of the generated\nshapes, but also of their diversity, particularly to synthesise realistic body\nmovements of a specific action (action conditioning). In this paper, we propose\nKinetic-GAN, a novel architecture that leverages the benefits of Generative\nAdversarial Networks and Graph Convolutional Networks to synthesise the\nkinetics of the human body. The proposed adversarial architecture can condition\nup to 120 different actions over local and global body movements while\nimproving sample quality and diversity through latent space disentanglement and\nstochastic variations. Our experiments were carried out in three well-known\ndatasets, where Kinetic-GAN notably surpasses the state-of-the-art methods in\nterms of distribution quality metrics while having the ability to synthesise\nmore than one order of magnitude regarding the number of different actions. Our\ncode and models are publicly available at\nhttps://github.com/DegardinBruno/Kinetic-GAN.",
    "descriptor": "\nComments: Published as a conference paper at WACV 2022. Code and pretrained models available at this https URL\n",
    "authors": [
      "Bruno Degardin",
      "Jo\u00e3o Neves",
      "Vasco Lopes",
      "Jo\u00e3o Brito",
      "Ehsan Yaghoubi",
      "Hugo Proen\u00e7a"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11191"
  },
  {
    "id": "arXiv:2110.11198",
    "title": "Temporal Motifs in Patent Opposition and Collaboration Networks",
    "abstract": "Patents are intellectual properties that reflect innovative activities of\ncompanies and organizations. The literature is rich with the studies that\nanalyze the citations among the patents and the collaboration relations among\ncompanies that own the patents. However, the adversarial relations between the\npatent owners are not as well investigated. One proxy to model such relations\nis the patent opposition, which is a legal activity in which a company\nchallenges the validity of a patent. Characterizing the patent oppositions,\ncollaborations, and the interplay between them can help better understand the\ncompanies' business strategies. Temporality matters in this context as the\norder and frequency of oppositions and collaborations characterize their\ninterplay. In this study, we construct a two-layer temporal network to model\nthe patent oppositions and collaborations among the companies. We utilize\ntemporal motifs to analyze the oppositions and collaborations from structural\nand temporal perspectives. We first characterize the frequent motifs in patent\noppositions and investigate how often the companies of different sizes attack\nother companies. We show that large companies tend to engage in opposition with\nmultiple companies. Then we analyze the temporal interplay between\ncollaborations and oppositions. We find that two adversarial companies are more\nlikely to collaborate in the future than two collaborating companies oppose\neach other in the future.",
    "descriptor": "",
    "authors": [
      "Penghang Liu",
      "Naoki Masuda",
      "Tomomi Kito",
      "A. Erdem Sar\u0131y\u00fcce"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.11198"
  },
  {
    "id": "arXiv:2110.11199",
    "title": "Asynchronous Decentralized Distributed Training of Acoustic Models",
    "abstract": "Large-scale distributed training of deep acoustic models plays an important\nrole in today's high-performance automatic speech recognition (ASR). In this\npaper we investigate a variety of asynchronous decentralized distributed\ntraining strategies based on data parallel stochastic gradient descent (SGD) to\nshow their superior performance over the commonly-used synchronous distributed\ntraining via allreduce, especially when dealing with large batch sizes.\nSpecifically, we study three variants of asynchronous decentralized parallel\nSGD (ADPSGD), namely, fixed and randomized communication patterns on a ring as\nwell as a delay-by-one scheme. We introduce a mathematical model of ADPSGD,\ngive its theoretical convergence rate, and compare the empirical convergence\nbehavior and straggler resilience properties of the three variants. Experiments\nare carried out on an IBM supercomputer for training deep long short-term\nmemory (LSTM) acoustic models on the 2000-hour Switchboard dataset. Recognition\nand speedup performance of the proposed strategies are evaluated under various\ntraining configurations. We show that ADPSGD with fixed and randomized\ncommunication patterns cope well with slow learners. When learners are equally\nfast, ADPSGD with the delay-by-one strategy has the fastest convergence with\nlarge batches. In particular, using the delay-by-one strategy, we can train the\nacoustic model in less than 2 hours using 128 V100 GPUs with competitive word\nerror rates.",
    "descriptor": "\nComments: Accepted by IEEE/ACM Transactions on Audio, Speech and Language Processing\n",
    "authors": [
      "Xiaodong Cui",
      "Wei Zhang",
      "Abdullah Kayi",
      "Mingrui Liu",
      "Ulrich Finkler",
      "Brian Kingsbury",
      "George Saon",
      "David Kung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.11199"
  },
  {
    "id": "arXiv:2110.11202",
    "title": "Anti-Concentrated Confidence Bonuses for Scalable Exploration",
    "abstract": "Intrinsic rewards play a central role in handling the\nexploration-exploitation trade-off when designing sequential decision-making\nalgorithms, in both foundational theory and state-of-the-art deep reinforcement\nlearning. The LinUCB algorithm, a centerpiece of the stochastic linear bandits\nliterature, prescribes an elliptical bonus which addresses the challenge of\nleveraging shared information in large action spaces. This bonus scheme cannot\nbe directly transferred to high-dimensional exploration problems, however, due\nto the computational cost of maintaining the inverse covariance matrix of\naction features. We introduce \\emph{anti-concentrated confidence bounds} for\nefficiently approximating the elliptical bonus, using an ensemble of regressors\ntrained to predict random noise from policy network-derived features. Using\nthis approximation, we obtain stochastic linear bandit algorithms which obtain\n$\\tilde O(d \\sqrt{T})$ regret bounds for $\\mathrm{poly}(d)$ fixed actions. We\ndevelop a practical variant for deep reinforcement learning that is competitive\nwith contemporary intrinsic reward heuristics on Atari benchmarks.",
    "descriptor": "",
    "authors": [
      "Jordan T. Ash",
      "Cyril Zhang",
      "Surbhi Goel",
      "Akshay Krishnamurthy",
      "Sham Kakade"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11202"
  },
  {
    "id": "arXiv:2110.11205",
    "title": "DAIR: Data Augmented Invariant Regularization",
    "abstract": "While deep learning through empirical risk minimization (ERM) has succeeded\nat achieving human-level performance at a variety of complex tasks, ERM\ngeneralizes poorly to distribution shift. This is partly explained by\noverfitting to spurious features such as background in images or named entities\nin natural language. Synthetic data augmentation followed by empirical risk\nminimization (DA-ERM) is a simple yet powerful solution to remedy this problem.\nIn this paper, we propose data augmented invariant regularization (DAIR). The\nidea of DAIR is based on the observation that the model performance (loss) is\ndesired to be consistent on the augmented sample and the original one. DAIR\nintroduces a regularizer on DA-ERM to penalize such loss inconsistency. Both\ntheoretically and through empirical experiments, we show that a particular form\nof the DAIR regularizer consistently performs well in a variety of settings. We\napply it to multiple real-world learning problems involving domain shift,\nnamely robust regression, visual question answering, robust deep neural network\ntraining, and task-oriented dialog modeling. Our experiments show that DAIR\nconsistently outperforms ERM and DA-ERM with little marginal cost and setting\nnew state-of-the-art results in several benchmarks.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Tianjian Huang",
      "Shaunak Halbe",
      "Chinnadhurai Sankar",
      "Pooyan Amini",
      "Satwik Kottur",
      "Alborz Geramifard",
      "Meisam Razaviyayn",
      "Ahmad Beirami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11205"
  },
  {
    "id": "arXiv:2110.11207",
    "title": "Topic-Guided Abstractive Multi-Document Summarization",
    "abstract": "A critical point of multi-document summarization (MDS) is to learn the\nrelations among various documents. In this paper, we propose a novel\nabstractive MDS model, in which we represent multiple documents as a\nheterogeneous graph, taking semantic nodes of different granularities into\naccount, and then apply a graph-to-sequence framework to generate summaries.\nMoreover, we employ a neural topic model to jointly discover latent topics that\ncan act as cross-document semantic units to bridge different documents and\nprovide global information to guide the summary generation. Since topic\nextraction can be viewed as a special type of summarization that \"summarizes\"\ntexts into a more abstract format, i.e., a topic distribution, we adopt a\nmulti-task learning strategy to jointly train the topic and summarization\nmodule, allowing the promotion of each other. Experimental results on the\nMulti-News dataset demonstrate that our model outperforms previous\nstate-of-the-art MDS models on both Rouge metrics and human evaluation,\nmeanwhile learns high-quality topics.",
    "descriptor": "\nComments: accepted at findings of EMNLP 2021\n",
    "authors": [
      "Peng Cui",
      "Le Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11207"
  },
  {
    "id": "arXiv:2110.11208",
    "title": "User-Level Private Learning via Correlated Sampling",
    "abstract": "Most works in learning with differential privacy (DP) have focused on the\nsetting where each user has a single sample. In this work, we consider the\nsetting where each user holds $m$ samples and the privacy protection is\nenforced at the level of each user's data. We show that, in this setting, we\nmay learn with a much fewer number of users. Specifically, we show that, as\nlong as each user receives sufficiently many samples, we can learn any\nprivately learnable class via an $(\\epsilon, \\delta)$-DP algorithm using only\n$O(\\log(1/\\delta)/\\epsilon)$ users. For $\\epsilon$-DP algorithms, we show that\nwe can learn using only $O_{\\epsilon}(d)$ users even in the local model, where\n$d$ is the probabilistic representation dimension. In both cases, we show a\nnearly-matching lower bound on the number of users required.\nA crucial component of our results is a generalization of global stability\n[Bun et al., FOCS 2020] that allows the use of public randomness. Under this\nrelaxed notion, we employ a correlated sampling strategy to show that the\nglobal stability can be boosted to be arbitrarily close to one, at a polynomial\nexpense in the number of samples.",
    "descriptor": "\nComments: To appear in NeurIPS 2021\n",
    "authors": [
      "Badih Ghazi",
      "Ravi Kumar",
      "Pasin Manurangsi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.11208"
  },
  {
    "id": "arXiv:2110.11211",
    "title": "A dimension-oblivious domain decomposition method based on space-filling  curves",
    "abstract": "In this paper we present an algebraic dimension-oblivious two-level domain\ndecomposition solver for discretizations of elliptic partial differential\nequations. The proposed parallel solver is based on a space-filling curve\npartitioning approach that is applicable to any discretization, i.e. it\ndirectly operates on the assembled matrix equations. Moreover, it allows for\nthe effective use of arbitrary processor numbers independent of the dimension\nof the underlying partial differential equation while maintaining optimal\nconvergence behavior. This is the core property required to attain a sparse\ngrid based combination method with extreme scalability which can utilize\nexascale parallel systems efficiently. Moreover, this approach provides a basis\nfor the development of a fault-tolerant solver for the numerical treatment of\nhigh-dimensional problems. To achieve the required data redundancy we are\ntherefore concerned with large overlaps of our domain decomposition which we\nconstruct via space-filling curves. In this paper, we propose our space-filling\ncurve based domain decomposition solver and present its convergence properties\nand scaling behavior. The results of numerical experiments clearly show that\nour approach provides optimal convergence and scaling behavior in arbitrary\ndimension utilizing arbitrary processor numbers.",
    "descriptor": "\nComments: 24 pages, 9 figures, 1 table. arXiv admin note: substantial text overlap with arXiv:2103.03315\n",
    "authors": [
      "Michael Griebel",
      "Marc Alexander Schweitzer",
      "Lukas Troska"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.11211"
  },
  {
    "id": "arXiv:2110.11219",
    "title": "PlaneRecNet: Multi-Task Learning with Cross-Task Consistency for  Piece-Wise Plane Detection and Reconstruction from a Single RGB Image",
    "abstract": "Piece-wise 3D planar reconstruction provides holistic scene understanding of\nman-made environments, especially for indoor scenarios. Most recent approaches\nfocused on improving the segmentation and reconstruction results by introducing\nadvanced network architectures but overlooked the dual characteristics of\npiece-wise planes as objects and geometric models. Different from other\nexisting approaches, we start from enforcing cross-task consistency for our\nmulti-task convolutional neural network, PlaneRecNet, which integrates a\nsingle-stage instance segmentation network for piece-wise planar segmentation\nand a depth decoder to reconstruct the scene from a single RGB image. To\nachieve this, we introduce several novel loss functions (geometric constraint)\nthat jointly improve the accuracy of piece-wise planar segmentation and depth\nestimation. Meanwhile, a novel Plane Prior Attention module is used to guide\ndepth estimation with the awareness of plane instances. Exhaustive experiments\nare conducted in this work to validate the effectiveness and efficiency of our\nmethod.",
    "descriptor": "\nComments: accepted to BMVC 2021, code opensource: this https URL\n",
    "authors": [
      "Yaxu Xie",
      "Fangwen Shu",
      "Jason Rambach",
      "Alain Pagani",
      "Didier Stricker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11219"
  },
  {
    "id": "arXiv:2110.11222",
    "title": "Is High Variance Unavoidable in RL? A Case Study in Continuous Control",
    "abstract": "Reinforcement learning (RL) experiments have notoriously high variance, and\nminor details can have disproportionately large effects on measured outcomes.\nThis is problematic for creating reproducible research and also serves as an\nobstacle for real-world applications, where safety and predictability are\nparamount. In this paper, we investigate causes for this perceived instability.\nTo allow for an in-depth analysis, we focus on a specifically popular setup\nwith high variance -- continuous control from pixels with an actor-critic\nagent. In this setting, we demonstrate that variance mostly arises early in\ntraining as a result of poor \"outlier\" runs, but that weight initialization and\ninitial exploration are not to blame. We show that one cause for early variance\nis numerical instability which leads to saturating nonlinearities. We\ninvestigate several fixes to this issue and find that one particular method is\nsurprisingly effective and simple -- normalizing penultimate features.\nAddressing the learning instability allows for larger learning rates, and\nsignificantly decreases the variance of outcomes. This demonstrates that the\nperceived variance in RL is not necessarily inherent to the problem definition\nand may be addressed through simple architectural modifications.",
    "descriptor": "",
    "authors": [
      "Johan Bjorck",
      "Carla P. Gomes",
      "Kilian Q. Weinberger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11222"
  },
  {
    "id": "arXiv:2110.11223",
    "title": "Detection of Driver Drowsiness by Calculating the Speed of Eye Blinking",
    "abstract": "Many road accidents are caused by drowsiness of the driver. While there are\nmethods to detect closed eyes, it is a non-trivial task to detect the gradual\nprocess of a driver becoming drowsy. We consider a simple real-time detection\nsystem for drowsiness merely based on the eye blinking rate derived from the\neye aspect ratio. For the eye detection we use HOG and a linear SVM. If the\nspeed of the eye blinking drops below some empirically determined threshold,\nthe system triggers an alarm, hence preventing the driver from falling into\nmicrosleep. In this paper, we extensively evaluate the minimal requirements for\nthe proposed system. We find that this system works well if the face is\ndirected to the camera, but it becomes less reliable once the head is tilted\nsignificantly. The results of our evaluations provide the foundation for\nfurther developments of our drowsiness detection system.",
    "descriptor": "\nComments: This paper has been accepted at the Upper-Rhine Artificial Intelligence Symposium 2021\n",
    "authors": [
      "Muhammad Fawwaz Yusri",
      "Patrick Mangat",
      "Oliver Wasenm\u00fcller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11223"
  },
  {
    "id": "arXiv:2110.11225",
    "title": "Player Dominance Adjustment in Games",
    "abstract": "Video Games are boring when they are too easy, and frustrating when they are\ntoo hard. In terms of providing game experience such as enjoyment to the player\nby match players with different levels of ability to player ability, We assume\nthat implementing DDA for providing matches between player ability and overall\ngame difficulty to the game, especially the modern game, has limitations in\nterms of increasing computational cost and complexities in the design of\nmodeling the difficulty in modern games. To overcome limitations underlying the\nmethod of providing static difficulty changes to player, and DDA, we proposed a\nnovel idea, Player Domination adjustment (PDA). The proposed idea is that to\ncontrol the AI's actions based on the player's inputs so as to adjust the\nplayer's dominant power (e.g. the AI recognizes the player's attack actions but\ndefends it in a wrong side to let the player incur damage to itself), which was\nproved as it leads to promotion of game-related self-efficacy in our work.\nSeveral pieces of research on were conducted on a social deduction game and a\nfighting game respectively, show our proposed idea has its potential of\npromoting User Experience(UX). As in an another study, outperforms DDA in two\nconducted experiments in terms of health promotion.",
    "descriptor": "\nComments: 65 pages\n",
    "authors": [
      "Junjie Xu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.11225"
  },
  {
    "id": "arXiv:2110.11226",
    "title": "Accelerating Genetic Programming using GPUs",
    "abstract": "Genetic Programming (GP), an evolutionary learning technique, has multiple\napplications in machine learning such as curve fitting, data modelling, feature\nselection, classification etc. GP has several inherent parallel steps, making\nit an ideal candidate for GPU based parallelization. This paper describes a GPU\naccelerated stack-based variant of the generational GP algorithm which can be\nused for symbolic regression and binary classification. The selection and\nevaluation steps of the generational GP algorithm are parallelized using CUDA.\nWe introduce representing candidate solution expressions as prefix lists, which\nenables evaluation using a fixed-length stack in GPU memory. CUDA based matrix\nvector operations are also used for computation of the fitness of population\nprograms. We evaluate our algorithm on synthetic datasets for the Pagie\nPolynomial (ranging in size from $4096$ to $16$ million points), profiling\ntraining times of our algorithm with other standard symbolic regression\nlibraries viz. gplearn, TensorGP and KarooGP. In addition, using $6$\nlarge-scale regression and classification datasets usually used for comparing\ngradient boosting algorithms, we run performance benchmarks on our algorithm\nand gplearn, profiling the training time, test accuracy, and loss. On an NVIDIA\nDGX-A100 GPU, our algorithm outperforms all the previously listed frameworks,\nand in particular, achieves average speedups of $119\\times$ and $40\\times$\nagainst gplearn on the synthetic and large scale datasets respectively.",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Vimarsh Sathia",
      "Venkataramana Ganesh",
      "Shankara Rao Thejaswi Nanditale"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11226"
  },
  {
    "id": "arXiv:2110.11227",
    "title": "Towards Automatic Grading of D3.js Visualizations",
    "abstract": "Manually grading D3 data visualizations is a challenging endeavor, and is\nespecially difficult for large classes with hundreds of students. Grading an\ninteractive visualization requires a combination of interactive, quantitative,\nand qualitative evaluation that are conventionally done manually and are\ndifficult to scale up as the visualization complexity, data size, and number of\nstudents increase. We present a first-of-its kind automatic grading method for\nD3 visualizations that scalably and precisely evaluates the data bindings,\nvisual encodings, interactions, and design specifications used in a\nvisualization. Our method has shown potential to enhance students' learning\nexperience, enabling them to submit their code frequently and receive rapid\nfeedback to better inform iteration and improvement to their code and\nvisualization design. Our method promotes consistent grading and enables\ninstructors to dedicate more focus to assist students in gaining visualization\nknowledge and experience. We have successfully deployed our method and\nauto-graded D3 submissions from more than 1000 undergraduate and graduate\nstudents in Georgia Tech's CSE6242 Data and Visual Analytics course, and\nreceived positive feedback and encouragement for expanding its adoption.",
    "descriptor": "\nComments: Accepted to IEEE VIS'21. For a demo video, see this https URL\n",
    "authors": [
      "Matthew Hull",
      "Connor Guerin",
      "Justin Chen",
      "Susanta Routray",
      "Duen Horng Chau"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.11227"
  },
  {
    "id": "arXiv:2110.11236",
    "title": "Variational Predictive Routing with Nested Subjective Timescales",
    "abstract": "Discovery and learning of an underlying spatiotemporal hierarchy in\nsequential data is an important topic for machine learning. Despite this,\nlittle work has been done to explore hierarchical generative models that can\nflexibly adapt their layerwise representations in response to datasets with\ndifferent temporal dynamics. Here, we present Variational Predictive Routing\n(VPR) - a neural probabilistic inference system that organizes latent\nrepresentations of video features in a temporal hierarchy, based on their rates\nof change, thus modeling continuous data as a hierarchical renewal process. By\nemploying an event detection mechanism that relies solely on the system's\nlatent representations (without the need of a separate model), VPR is able to\ndynamically adjust its internal state following changes in the observed\nfeatures, promoting an optimal organisation of representations across the\nlevels of the model's latent hierarchy. Using several video datasets, we show\nthat VPR is able to detect event boundaries, disentangle spatiotemporal\nfeatures across its hierarchy, adapt to the dynamics of the data, and produce\naccurate time-agnostic rollouts of the future. Our approach integrates insights\nfrom neuroscience and introduces a framework with high potential for\napplications in model-based reinforcement learning, where flexible and\ninformative state-space rollouts are of particular interest.",
    "descriptor": "\nComments: 18 pages, 13 figures\n",
    "authors": [
      "Alexey Zakharov",
      "Qinghai Guo",
      "Zafeirios Fountas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2110.11236"
  },
  {
    "id": "arXiv:2110.11238",
    "title": "One Representative-Shot Learning Using a Population-Driven Template with  Application to Brain Connectivity Classification and Evolution Prediction",
    "abstract": "Few-shot learning presents a challenging paradigm for training discriminative\nmodels on a few training samples representing the target classes to\ndiscriminate. However, classification methods based on deep learning are\nill-suited for such learning as they need large amounts of training data --let\nalone one-shot learning. Recently, graph neural networks (GNNs) have been\nintroduced to the field of network neuroscience, where the brain connectivity\nis encoded in a graph. However, with scarce neuroimaging datasets particularly\nfor rare diseases and low-resource clinical facilities, such data-devouring\narchitectures might fail in learning the target task. In this paper, we take a\nvery different approach in training GNNs, where we aim to learn with one sample\nand achieve the best performance --a formidable challenge to tackle.\nSpecifically, we present the first one-shot paradigm where a GNN is trained on\na single population-driven template --namely a connectional brain template\n(CBT). A CBT is a compact representation of a population of brain graphs\ncapturing the unique connectivity patterns shared across individuals. It is\nanalogous to brain image atlases for neuroimaging datasets. Using a\none-representative CBT as a training sample, we alleviate the training load of\nGNN models while boosting their performance across a variety of classification\nand regression tasks. We demonstrate that our method significantly outperformed\nbenchmark one-shot learning methods with downstream classification and\ntime-dependent brain graph data forecasting tasks while competing with the\ntrain-on-all conventional training strategy. Our source code can be found at\nhttps://github.com/basiralab/one-representative-shot-learning.",
    "descriptor": "",
    "authors": [
      "Umut Guvercin",
      "Mohammed Amine Gharsallaoui",
      "Islem Rekik"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11238"
  },
  {
    "id": "arXiv:2110.11239",
    "title": "Improving the Search by Encoding Multiple Solutions in a Chromosome",
    "abstract": "We investigate the possibility of encoding multiple solutions of a problem in\na single chromosome. The best solution encoded in an individual will represent\n(will provide the fitness of) that individual. In order to obtain some benefits\nthe chromosome decoding process must have the same complexity as in the case of\na single solution in a chromosome. Three Genetic Programming techniques are\nanalyzed for this purpose: Multi Expression Programming, Linear Genetic\nProgramming, and Infix Form Genetic Programming. Numerical experiments show\nthat encoding multiple solutions in a chromosome greatly improves the search\nprocess.",
    "descriptor": "\nComments: 7 figures\n",
    "authors": [
      "Mihai Oltean"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11239"
  },
  {
    "id": "arXiv:2110.11240",
    "title": "A Systematic Review on the Detection of Fake News Articles",
    "abstract": "It has been argued that fake news and the spread of false information pose a\nthreat to societies throughout the world, from influencing the results of\nelections to hindering the efforts to manage the COVID-19 pandemic. To combat\nthis threat, a number of Natural Language Processing (NLP) approaches have been\ndeveloped. These leverage a number of datasets, feature extraction/selection\ntechniques and machine learning (ML) algorithms to detect fake news before it\nspreads. While these methods are well-documented, there is less evidence\nregarding their efficacy in this domain. By systematically reviewing the\nliterature, this paper aims to delineate the approaches for fake news detection\nthat are most performant, identify limitations with existing approaches, and\nsuggest ways these can be mitigated. The analysis of the results indicates that\nEnsemble Methods using a combination of news content and socially-based\nfeatures are currently the most effective. Finally, it is proposed that future\nresearch should focus on developing approaches that address generalisability\nissues (which, in part, arise from limitations with current datasets),\nexplainability and bias.",
    "descriptor": "\nComments: 22 Pages, 16 Figures, Currently submitted to ACM TIST - Awaiting Peer-Review\n",
    "authors": [
      "Nathaniel Hoy",
      "Theodora Koulouri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11240"
  },
  {
    "id": "arXiv:2110.11241",
    "title": "Be Daring to Push your Ads Forward: Measuring the (Over)use of Service  Workers for Advertising Purposes",
    "abstract": "Rich offline experience, periodic background sync, push notification\nfunctionality, network requests control, improved performance via requests\ncaching are only a few of the functionalities provided by the Service Workers\nAPI. This new technology, supported by all major browsers, can significantly\nimprove users' experience by providing the publisher with the technical\nfoundations that would normally require anative application. Albeit the\ncapabilities of this new technique and its important role in the ecosystem of\nProgressive Web Apps (PWAs), it is still unclear what is their actual purpose\non the web, and how publishers leverage the provided functionality in their web\napplications. In this study, we shed light in the real world deployment of\nService Workers, by conducting the first large scale analysis of the prevalence\nof Service Workers in the wild. We see that Service Workers are becoming more\nand more popular, with the adoption increased by 26% only within the last 5\nmonths. Surprisingly, besides their fruitful capabilities, we see that Service\nWorkers are being mostly used for Push Advertising, in 65.08% of the Service\nWorkers that connect with 3rd parties. We Highlight that this is a relatively\nnew way for advertisers to bypass ad-blockers and render ads on the user's\ndisplays natively.",
    "descriptor": "",
    "authors": [
      "George Pantelakis",
      "Panagiotis Papadopoulos",
      "Nicolas Kourtellis",
      "Evangelos P. Markatos"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.11241"
  },
  {
    "id": "arXiv:2110.11242",
    "title": "Analysis of the first Genetic Engineering Attribution Challenge",
    "abstract": "The ability to identify the designer of engineered biological sequences --\ntermed genetic engineering attribution (GEA) -- would help ensure due credit\nfor biotechnological innovation, while holding designers accountable to the\ncommunities they affect. Here, we present the results of the first Genetic\nEngineering Attribution Challenge, a public data-science competition to advance\nGEA. Top-scoring teams dramatically outperformed previous models at identifying\nthe true lab-of-origin of engineered sequences, including an increase in top-1\nand top-10 accuracy of 10 percentage points. A simple ensemble of prizewinning\nmodels further increased performance. New metrics, designed to assess a model's\nability to confidently exclude candidate labs, also showed major improvements,\nespecially for the ensemble. Most winning teams adopted CNN-based\nmachine-learning approaches; however, one team achieved very high accuracy with\nan extremely fast neural-network-free approach. Future work, including future\ncompetitions, should further explore a wide diversity of approaches for\nbringing GEA technology into practical use.",
    "descriptor": "\nComments: Main text: 11 pages, 4 figures, 37 references. Supplementary materials: 29 pages, 2 supplementary tables, 21 supplementary figures\n",
    "authors": [
      "Oliver M. Crook",
      "Kelsey Lane Warmbrod",
      "Greg Lipstein",
      "Christine Chung",
      "Christopher W. Bakerlee",
      "T. Greg McKelvey Jr.",
      "Shelly R. Holland",
      "Jacob L. Swett",
      "Kevin M. Esvelt",
      "Ethan C. Alley",
      "William J. Bradshaw"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.11242"
  },
  {
    "id": "arXiv:2110.11246",
    "title": "Motion Planning for Connected Automated Vehicles at Occluded  Intersections With Infrastructure Sensors",
    "abstract": "Motion planning at urban intersections that accounts for the situation\ncontext, handles occlusions, and deals with measurement and prediction\nuncertainty is a major challenge on the way to urban automated driving. In this\nwork, we address this challenge with a sampling-based optimization approach.\nFor this, we formulate an optimal control problem that optimizes for low risk\nand high passenger comfort. The risk is calculated on the basis of the\nperception information and the respective uncertainty using a risk model. The\nrisk model combines set-based methods and probabilistic approaches. Thus, the\napproach provides safety guarantees in a probabilistic sense, while for a\nvanishing risk, the formal safety guarantees of the set-based methods are\ninherited. By exploring all available behavior options, our approach solves\ndecision making and longitudinal trajectory planning in one step. The available\nbehavior options are provided by a formal representation of the situation\ncontext, which is also used to reduce calculation efforts. Occlusions are\nresolved using the external perception of infrastructure-mounted sensors. Yet,\ninstead of merging external and ego perception with track-to-track fusion, the\ninformation is used in parallel. The motion planning scheme is validated\nthrough real-world experiments.",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Johannes M\u00fcller",
      "Jan Strohbeck",
      "Martin Herrmann",
      "Michael Buchholz"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.11246"
  },
  {
    "id": "arXiv:2110.11248",
    "title": "Learning to Recommend Using Non-Uniform Data",
    "abstract": "Learning user preferences for products based on their past purchases or\nreviews is at the cornerstone of modern recommendation engines. One\ncomplication in this learning task is that some users are more likely to\npurchase products or review them, and some products are more likely to be\npurchased or reviewed by the users. This non-uniform pattern degrades the power\nof many existing recommendation algorithms, as they assume that the observed\ndata is sampled uniformly at random among user-product pairs. In addition,\nexisting literature on modeling non-uniformity either assume user interests are\nindependent of the products, or lack theoretical understanding. In this paper,\nwe first model the user-product preferences as a partially observed matrix with\nnon-uniform observation pattern. Next, building on the literature about\nlow-rank matrix estimation, we introduce a new weighted trace-norm penalized\nregression to predict unobserved values of the matrix. We then prove an upper\nbound for the prediction error of our proposed approach. Our upper bound is a\nfunction of a number of parameters that are based on a certain weight matrix\nthat depends on the joint distribution of users and products. Utilizing this\nobservation, we introduce a new optimization problem to select a weight matrix\nthat minimizes the upper bound on the prediction error. The final product is a\nnew estimator, NU-Recommend, that outperforms existing methods in both\nsynthetic and real datasets.",
    "descriptor": "",
    "authors": [
      "Wanning Chen",
      "Mohsen Bayati"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11248"
  },
  {
    "id": "arXiv:2110.11253",
    "title": "Multimode Diagnosis for Switched Affine Systems with Noisy Measurement",
    "abstract": "We study a diagnosis scheme to reliably detect the active mode of\ndiscrete-time, switched affine systems in the presence of measurement noise and\nasynchronous switching. The proposed scheme consists of two parts: (i) the\nconstruction of a bank of filters, and (ii) the introduction of a\nresidual/threshold-based diagnosis rule. We develop an exact finite\noptimization-based framework to numerically solve an optimal bank of filters in\nwhich the contribution of the measurement noise to the residual is minimized.\nThe design problem is safely approximated through linear matrix inequalities\nand thus becomes tractable. We further propose a thresholding policy along with\nprobabilistic false-alarm guarantees to estimate the active system mode in\nreal-time. In comparison with the existing results, the guarantees improve from\na polynomial dependency in the probability of false-alarm to a logarithmic\nform. This improvement is achieved under the additional assumption of\nsub-Gaussianity, which is expected in many applications. The performance of the\nproposed diagnosis filters is validated through a synthesis numerical example\nand an application of the building radiant system.",
    "descriptor": "\nComments: 24 pages, 8 figures\n",
    "authors": [
      "Jingwei Dong",
      "Arman Sharifi Kolarijani",
      "Peyman Mohajerin Esfahani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.11253"
  },
  {
    "id": "arXiv:2110.11255",
    "title": "On the properties of some low-parameter models for color reproduction in  terms of spectrum transformations and coverage of a color triangle",
    "abstract": "One of the classical approaches to solving color reproduction problems, such\nas color adaptation or color space transform, is the use of low-parameter\nspectral models. The strength of this approach is the ability to choose a set\nof properties that the model should have, be it a large coverage area of a\ncolor triangle, an accurate description of the addition or multiplication of\nspectra, knowing only the tristimulus corresponding to them. The disadvantage\nis that some of the properties of the mentioned spectral models are confirmed\nonly experimentally. This work is devoted to the theoretical substantiation of\nvarious properties of spectral models. In particular, we prove that the banded\nmodel is the only model that simultaneously possesses the properties of closure\nunder addition and multiplication. We also show that the Gaussian model is the\nlimiting case of the von Mises model and prove that the set of protomers of the\nvon Mises model unambiguously covers the color triangle in both the case of\nconvex and non-convex spectral locus.",
    "descriptor": "\nComments: 23 pages, 2 figures\n",
    "authors": [
      "Alexey Kroshnin",
      "Viacheslav Vasilev",
      "Egor Ershov",
      "Denis Shepelev",
      "Dmitry Nikolaev",
      "Mikhail Tchobanou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.11255"
  },
  {
    "id": "arXiv:2110.11256",
    "title": "Multi-Category Mesh Reconstruction From Image Collections",
    "abstract": "Recently, learning frameworks have shown the capability of inferring the\naccurate shape, pose, and texture of an object from a single RGB image.\nHowever, current methods are trained on image collections of a single category\nin order to exploit specific priors, and they often make use of\ncategory-specific 3D templates. In this paper, we present an alternative\napproach that infers the textured mesh of objects combining a series of\ndeformable 3D models and a set of instance-specific deformation, pose, and\ntexture. Differently from previous works, our method is trained with images of\nmultiple object categories using only foreground masks and rough camera poses\nas supervision. Without specific 3D templates, the framework learns\ncategory-level models which are deformed to recover the 3D shape of the\ndepicted object. The instance-specific deformations are predicted independently\nfor each vertex of the learned 3D mesh, enabling the dynamic subdivision of the\nmesh during the training process. Experiments show that the proposed framework\ncan distinguish between different object categories and learn category-specific\nshape priors in an unsupervised manner. Predicted shapes are smooth and can\nleverage from multiple steps of subdivision during the training process,\nobtaining comparable or state-of-the-art results on two public datasets. Models\nand code are publicly released.",
    "descriptor": "\nComments: Accepted at 3DV 2021\n",
    "authors": [
      "Alessandro Simoni",
      "Stefano Pini",
      "Roberto Vezzani",
      "Rita Cucchiara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11256"
  },
  {
    "id": "arXiv:2110.11259",
    "title": "A scale invariant ranking function for learning-to-rank: a real-world  use case",
    "abstract": "Nowadays, Online Travel Agencies provide the main service for booking\nholidays, business trips, accommodations, etc. As in many e-commerce services\nwhere users, items, and preferences are involved, the use of a Recommender\nSystem facilitates the navigation of the marketplaces. One of the main\nchallenges when productizing machine learning models (and in this case,\nLearning-to-Rank models) is the need of, not only consistent pre-processing\ntransformations, but also input features maintaining a similar scale both at\ntraining and prediction time. However, the features' scale does not necessarily\nstay the same in the real-world production environment, which could lead to\nunexpected ranking order. Normalization techniques such as feature\nstandardization, batch normalization and layer normalization are commonly used\nto tackle the scaling issue. However, these techniques. To address this issue,\nin this paper we propose a novel scale-invariant ranking function (dubbed as\nSIR) which is accomplished by combining a deep and a wide neural network. We\nincorporate SIR with five state-of-the-art Learning-to-Rank models and compare\nthe performance of the combined models with the classic algorithms on a large\ndata set containing 56 million booked searches from the Hotels.com website.\nBesides, we simulate four real-world scenarios where the features' scale at the\ntest set is inconsistent with that at the training set. The results reveal that\nwhen the features' scale is inconsistent at prediction time, Learning-To-Rank\nmethods incorporating SIR outperform their original counterpart in all\nscenarios (with performance difference up to 14.7%), while when the features'\nscale at the training and test set are consistent our proposal achieves\ncomparable accuracy to the classic algorithms.",
    "descriptor": "\nComments: 14 pages, 1 figure, 1 table\n",
    "authors": [
      "Alessio Petrozziello",
      "Xiaoke Liu",
      "Christian Sommeregger"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.11259"
  },
  {
    "id": "arXiv:2110.11261",
    "title": "Principal Component Analysis versus Factor Analysis",
    "abstract": "The article discusses selected problems related to both principal component\nanalysis (PCA) and factor analysis (FA). In particular, both types of analysis\nwere compared. A vector interpretation for both PCA and FA has also been\nproposed. The problem of determining the number of principal components in PCA\nand factors in FA was discussed in detail. A new criterion for determining the\nnumber of factors and principal components is discussed, which will allow to\npresent most of the variance of each of the analyzed primary variables. An\nefficient algorithm for determining the number of factors in FA, which complies\nwith this criterion, was also proposed. This algorithm was adapted to find the\nnumber of principal components in PCA. It was also proposed to modify the PCA\nalgorithm using a new method of determining the number of principal components.\nThe obtained results were discussed.",
    "descriptor": "\nComments: 54 pages, 13 figures, 35 tables\n",
    "authors": [
      "Zenon Gniazdowski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.11261"
  },
  {
    "id": "arXiv:2110.11262",
    "title": "Detecting Important Patterns Using Conceptual Relevance Interestingness  Measure",
    "abstract": "Discovering meaningful conceptual structures is a substantial task in data\nmining and knowledge discovery applications. While off-the-shelf\ninterestingness indices defined in Formal Concept Analysis may provide an\neffective relevance evaluation in several situations, they frequently give\ninadequate results when faced with massive formal contexts (and concept\nlattices), and in the presence of irrelevant concepts. In this paper, we\nintroduce the Conceptual Relevance (CR) score, a new scalable interestingness\nmeasurement for the identification of actionable concepts. From a conceptual\nperspective, the minimal generators provide key information about their\nassociated concept intent. Furthermore, the relevant attributes of a concept\nare those that maintain the satisfaction of its closure condition. Thus, the\nguiding idea of CR exploits the fact that minimal generators and relevant\nattributes can be efficiently used to assess concept relevance. As such, the CR\nindex quantifies both the amount of conceptually relevant attributes and the\nnumber of the minimal generators per concept intent. Our experiments on\nsynthetic and real-world datasets show the efficiency of this measure over the\nwell-known stability index.",
    "descriptor": "",
    "authors": [
      "Mohamed-Hamza Ibrahim",
      "Rokia Missaoui",
      "Jean Vaillancourt"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.11262"
  },
  {
    "id": "arXiv:2110.11264",
    "title": "MSO: Multi-Feature Space Joint Optimization Network for RGB-Infrared  Person Re-Identification",
    "abstract": "The RGB-infrared cross-modality person re-identification (ReID) task aims to\nrecognize the images of the same identity between the visible modality and the\ninfrared modality. Existing methods mainly use a two-stream architecture to\neliminate the discrepancy between the two modalities in the final common\nfeature space, which ignore the single space of each modality in the shallow\nlayers. To solve it, in this paper, we present a novel multi-feature space\njoint optimization (MSO) network, which can learn modality-sharable features in\nboth the single-modality space and the common space. Firstly, based on the\nobservation that edge information is modality-invariant, we propose an edge\nfeatures enhancement module to enhance the modality-sharable features in each\nsingle-modality space. Specifically, we design a perceptual edge features (PEF)\nloss after the edge fusion strategy analysis. According to our knowledge, this\nis the first work that proposes explicit optimization in the single-modality\nfeature space on cross-modality ReID task. Moreover, to increase the difference\nbetween cross-modality distance and class distance, we introduce a novel\ncross-modality contrastive-center (CMCC) loss into the modality-joint\nconstraints in the common feature space. The PEF loss and CMCC loss jointly\noptimize the model in an end-to-end manner, which markedly improves the\nnetwork's performance. Extensive experiments demonstrate that the proposed\nmodel significantly outperforms state-of-the-art methods on both the SYSU-MM01\nand RegDB datasets.",
    "descriptor": "",
    "authors": [
      "Yajun Gao",
      "Tengfei Liang",
      "Yi Jin",
      "Xiaoyan Gu",
      "Wu Liu",
      "Yidong Li",
      "Congyan Lang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11264"
  },
  {
    "id": "arXiv:2110.11265",
    "title": "Deep Reinforcement Learning for Online Control of Stochastic Partial  Differential Equations",
    "abstract": "In many areas, such as the physical sciences, life sciences, and finance,\ncontrol approaches are used to achieve a desired goal in complex dynamical\nsystems governed by differential equations. In this work we formulate the\nproblem of controlling stochastic partial differential equations (SPDE) as a\nreinforcement learning problem. We present a learning-based, distributed\ncontrol approach for online control of a system of SPDEs with high dimensional\nstate-action space using deep deterministic policy gradient method. We tested\nthe performance of our method on the problem of controlling the stochastic\nBurgers' equation, describing a turbulent fluid flow in an infinitely large\ndomain.",
    "descriptor": "",
    "authors": [
      "Erfan Pirmorad",
      "Faraz Khoshbakhtian",
      "Farnam Mansouri",
      "Amir-massoud Farahmand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.11265"
  },
  {
    "id": "arXiv:2110.11269",
    "title": "Modeling the AC Power Flow Equations with Optimally Compact Neural  Networks: Application to Unit Commitment",
    "abstract": "Nonlinear power flow constraints render a variety of power system\noptimization problems computationally intractable. Emerging research shows,\nhowever, that the nonlinear AC power flow equations can be successfully modeled\nusing Neural Networks (NNs). These NNs can be exactly transformed into Mixed\nInteger Linear Programs (MILPs) and embedded inside challenging optimization\nproblems, thus replacing nonlinearities that are intractable for many\napplications with tractable piecewise linear approximations. Such approaches,\nthough, suffer from an explosion of the number of binary variables needed to\nrepresent the NN. Accordingly, this paper develops a technique for training an\n\"optimally compact\" NN, i.e., one that can represent the power flow equations\nwith a sufficiently high degree of accuracy while still maintaining a tractable\nnumber of binary variables. We show that the resulting NN model is more\nexpressive than both the DC and linearized power flow approximations when\nembedded inside of a challenging optimization problem (i.e., the AC unit\ncommitment problem).",
    "descriptor": "\nComments: first two authors equally contributed, 8 pages, 3 figures, 1 table\n",
    "authors": [
      "Alyssa Kody",
      "Samuel Chevalier",
      "Spyros Chatzivasileiadis",
      "Daniel Molzahn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.11269"
  },
  {
    "id": "arXiv:2110.11271",
    "title": "Analyzing and Improving the Optimization Landscape of Noise-Contrastive  Estimation",
    "abstract": "Noise-contrastive estimation (NCE) is a statistically consistent method for\nlearning unnormalized probabilistic models. It has been empirically observed\nthat the choice of the noise distribution is crucial for NCE's performance.\nHowever, such observations have never been made formal or quantitative. In\nfact, it is not even clear whether the difficulties arising from a poorly\nchosen noise distribution are statistical or algorithmic in nature. In this\nwork, we formally pinpoint reasons for NCE's poor performance when an\ninappropriate noise distribution is used. Namely, we prove these challenges\narise due to an ill-behaved (more precisely, flat) loss landscape. To address\nthis, we introduce a variant of NCE called \"eNCE\" which uses an exponential\nloss and for which normalized gradient descent addresses the landscape issues\nprovably when the target and noise distributions are in a given exponential\nfamily.",
    "descriptor": "",
    "authors": [
      "Bingbin Liu",
      "Elan Rosenfeld",
      "Pradeep Ravikumar",
      "Andrej Risteski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.11271"
  },
  {
    "id": "arXiv:2110.11275",
    "title": "Self-Supervised Monocular Scene Decomposition and Depth Estimation",
    "abstract": "Self-supervised monocular depth estimation approaches either ignore\nindependently moving objects in the scene or need a separate segmentation step\nto identify them. We propose MonoDepthSeg to jointly estimate depth and segment\nmoving objects from monocular video without using any ground-truth labels. We\ndecompose the scene into a fixed number of components where each component\ncorresponds to a region on the image with its own transformation matrix\nrepresenting its motion. We estimate both the mask and the motion of each\ncomponent efficiently with a shared encoder. We evaluate our method on three\ndriving datasets and show that our model clearly improves depth estimation\nwhile decomposing the scene into separately moving components.",
    "descriptor": "\nComments: 3DV 2021\n",
    "authors": [
      "Sadra Safadoust",
      "Fatma G\u00fcney"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11275"
  },
  {
    "id": "arXiv:2110.11280",
    "title": "Actor-critic is implicitly biased towards high entropy optimal policies",
    "abstract": "We show that the simplest actor-critic method -- a linear softmax policy\nupdated with TD through interaction with a linear MDP, but featuring no\nexplicit regularization or exploration -- does not merely find an optimal\npolicy, but moreover prefers high entropy optimal policies. To demonstrate the\nstrength of this bias, the algorithm not only has no regularization, no\nprojections, and no exploration like $\\epsilon$-greedy, but is moreover trained\non a single trajectory with no resets. The key consequence of the high entropy\nbias is that uniform mixing assumptions on the MDP, which exist in some form in\nall prior work, can be dropped: the implicit regularization of the high entropy\nbias is enough to ensure that all chains mix and an optimal policy is reached\nwith high probability. As auxiliary contributions, this work decouples concerns\nbetween the actor and critic by writing the actor update as an explicit mirror\ndescent, provides tools to uniformly bound mixing times within KL balls of\npolicy space, and provides a projection-free TD analysis with its own implicit\nbias which can be run from an unmixed starting distribution.",
    "descriptor": "",
    "authors": [
      "Yuzheng Hu",
      "Ziwei Ji",
      "Matus Telgarsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11280"
  },
  {
    "id": "arXiv:2110.11281",
    "title": "Super-resolution of multiphase materials by combining complementary 2D  and 3D image data using generative adversarial networks",
    "abstract": "Modelling the impact of a material's mesostructure on device level\nperformance typically requires access to 3D image data containing all the\nrelevant information to define the geometry of the simulation domain. This\nimage data must include sufficient contrast between phases to distinguish each\nmaterial, be of high enough resolution to capture the key details, but also\nhave a large enough field-of-view to be representative of the material in\ngeneral. It is rarely possible to obtain data with all of these properties from\na single imaging technique. In this paper, we present a method for combining\ninformation from pairs of distinct but complementary imaging techniques in\norder to accurately reconstruct the desired multi-phase, high resolution,\nrepresentative, 3D images. Specifically, we use deep convolutional generative\nadversarial networks to implement super-resolution, style transfer and\ndimensionality expansion. To demonstrate the widespread applicability of this\ntool, two pairs of datasets are used to validate the quality of the volumes\ngenerated by fusing the information from paired imaging techniques. Three key\nmesostructural metrics are calculated in each case to show the accuracy of this\nmethod. Having confidence in the accuracy of our method, we then demonstrate\nits power by applying to a real data pair from a lithium ion battery electrode,\nwhere the required 3D high resolution image data is not available anywhere in\nthe literature. We believe this approach is superior to previously reported\nstatistical material reconstruction methods both in terms of its fidelity and\nease of use. Furthermore, much of the data required to train this algorithm\nalready exists in the literature, waiting to be combined. As such, our\nopen-access code could precipitate a step change by generating the hard to\nobtain high quality image volumes necessary to simulate behaviour at the\nmesoscale.",
    "descriptor": "",
    "authors": [
      "Amir Dahari",
      "Steve Kench",
      "Isaac Squires",
      "Samuel J. Cooper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11281"
  },
  {
    "id": "arXiv:2110.11283",
    "title": "The Effect of Wearing a Face Mask on Face Image Quality",
    "abstract": "Due to the COVID-19 situation, face masks have become a main part of our\ndaily life. Wearing mouth-and-nose protection has been made a mandate in many\npublic places, to prevent the spread of the COVID-19 virus. However, face masks\naffect the performance of face recognition, since a large area of the face is\ncovered. The effect of wearing a face mask on the different components of the\nface recognition system in a collaborative environment is a problem that is\nstill to be fully studied. This work studies, for the first time, the effect of\nwearing a face mask on face image quality by utilising state-of-the-art face\nimage quality assessment methods of different natures. This aims at providing\nbetter understanding on the effect of face masks on the operation of face\nrecognition as a whole system. In addition, we further studied the effect of\nsimulated masks on face image utility in comparison to real face masks. We\ndiscuss the correlation between the mask effect on face image quality and that\non the face verification performance by automatic systems and human experts,\nindicating a consistent trend between both factors. The evaluation is conducted\non the database containing (1) no-masked faces, (2) real face masks, and (3)\nsimulated face masks, by synthetically generating digital facial masks on\nno-masked faces according to the NIST protocols [1, 23]. Finally, a visual\ninterpretation of the face areas contributing to the quality score of a\nselected set of quality assessment methods is provided to give a deeper insight\ninto the difference of network decisions in masked and non-masked faces, among\nother variations.",
    "descriptor": "\nComments: 8 pages, 6 figures, 16th {IEEE} International Conference on Automatic Face and Gesture Recognition, {FG} 2021\n",
    "authors": [
      "Biying Fu",
      "Florian Kirchbuchner",
      "Naser Damer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.11283"
  },
  {
    "id": "arXiv:2110.11284",
    "title": "Multi-Object Tracking and Segmentation with a Space-Time Memory Network",
    "abstract": "We propose a method for multi-object tracking and segmentation that does not\nrequire fine-tuning or per benchmark hyper-parameter selection. The proposed\ntracker, MeNToS, addresses particularly the data association problem. Indeed,\nthe recently introduced HOTA metric, which has a better alignment with the\nhuman visual assessment by evenly balancing detections and associations\nquality, has shown that improvements are still needed for data association.\nAfter creating tracklets using instance segmentation and optical flow, the\nproposed method relies on a space-time memory network developed for one-shot\nvideo object segmentation to improve the association of tracklets with temporal\ngaps. We evaluated our tracker on KITTIMOTS and MOTSChallenge and show the\nbenefit of our data association strategy with the HOTA metric. The project page\nis \\url{www.mehdimiah.com/mentos+}.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2107.07067\n",
    "authors": [
      "Mehdi Miah",
      "Guillaume-Alexandre Bilodeau",
      "Nicolas Saunier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11284"
  },
  {
    "id": "arXiv:2110.11285",
    "title": "How to Fairly Allocate Easy and Difficult Chores",
    "abstract": "A major open question in fair allocation of indivisible items is whether\nthere always exists an allocation of chores that is Pareto optimal (PO) and\nenvy-free up to one item (EF1). We answer this question affirmatively for the\nnatural class of bivalued utilities, where each agent partitions the chores\ninto easy and difficult ones, and has cost $p > 1$ for chores that are\ndifficult for her and cost $1$ for chores that are easy for her. Such an\nallocation can be found in polynomial time using an algorithm based on the\nFisher market.\nWe also show that for a slightly broader class of utilities, where each agent\n$i$ can have a potentially different integer $p_i$, an allocation that is\nmaximin share fair (MMS) always exists and one that is both PO and MMS can be\ncomputed in polynomial time, provided that each $p_i$ is an integer. Our MMS\narguments also hold when allocating goods instead of chores, and extend to\nanother natural class of utilities, namely weakly lexicographic utilities.",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Soroush Ebadian",
      "Dominik Peters",
      "Nisarg Shah"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.11285"
  },
  {
    "id": "arXiv:2110.11286",
    "title": "One-Shot Transfer Learning of Physics-Informed Neural Networks",
    "abstract": "Solving differential equations efficiently and accurately sits at the heart\nof progress in many areas of scientific research, from classical dynamical\nsystems to quantum mechanics. There is a surge of interest in using\nPhysics-Informed Neural Networks (PINNs) to tackle such problems as they\nprovide numerous benefits over traditional numerical approaches. Despite their\npotential benefits for solving differential equations, transfer learning has\nbeen under explored. In this study, we present a general framework for transfer\nlearning PINNs that results in one-shot inference for linear systems of both\nordinary and partial differential equations. This means that highly accurate\nsolutions to many unknown differential equations can be obtained\ninstantaneously without retraining an entire network. We demonstrate the\nefficacy of the proposed deep learning approach by solving several real-world\nproblems, such as first- and second-order linear ordinary equations, the\nPoisson equation, and the time-dependent Schrodinger complex-value partial\ndifferential equation.",
    "descriptor": "\nComments: [under review]\n",
    "authors": [
      "Shaan Desai",
      "Marios Mattheakis",
      "Hayden Joy",
      "Pavlos Protopapas",
      "Stephen Roberts"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.11286"
  },
  {
    "id": "arXiv:2110.11290",
    "title": "Physical Side-Channel Attacks on Embedded Neural Networks: A Survey",
    "abstract": "During the last decade, Deep Neural Networks (DNN) have progressively been\nintegrated on all types of platforms, from data centers to embedded systems\nincluding low-power processors and, recently, FPGAs. Neural Networks (NN) are\nexpected to become ubiquitous in IoT systems by transforming all sorts of\nreal-world applications, including applications in the safety-critical and\nsecurity-sensitive domains. However, the underlying hardware security\nvulnerabilities of embedded NN implementations remain unaddressed. In\nparticular, embedded DNN implementations are vulnerable to Side-Channel\nAnalysis (SCA) attacks, which are especially important in the IoT and edge\ncomputing contexts where an attacker can usually gain physical access to the\ntargeted device. A research field has therefore emerged and is rapidly growing\nin terms of the use of SCA including timing, electromagnetic attacks and power\nattacks to target NN embedded implementations. Since 2018, research papers have\nshown that SCA enables an attacker to recover inference models architectures\nand parameters, to expose industrial IP and endangers data confidentiality and\nprivacy. Without a complete review of this emerging field in the literature so\nfar, this paper surveys state-of-the-art physical SCA attacks relative to the\nimplementation of embedded DNNs on micro-controllers and FPGAs in order to\nprovide a thorough analysis on the current landscape. It provides a taxonomy\nand a detailed classification of current attacks. It first discusses mitigation\ntechniques and then provides insights for future research leads.",
    "descriptor": "\nComments: 25 pages, 7 figures\n",
    "authors": [
      "Maria M\u00e9ndez Real",
      "Rub\u00e9n Salvador"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.11290"
  },
  {
    "id": "arXiv:2110.11292",
    "title": "OpenABC-D: A Large-Scale Dataset For Machine Learning Guided Integrated  Circuit Synthesis",
    "abstract": "Logic synthesis is a challenging and widely-researched combinatorial\noptimization problem during integrated circuit (IC) design. It transforms a\nhigh-level description of hardware in a programming language like Verilog into\nan optimized digital circuit netlist, a network of interconnected Boolean logic\ngates, that implements the function. Spurred by the success of ML in solving\ncombinatorial and graph problems in other domains, there is growing interest in\nthe design of ML-guided logic synthesis tools. Yet, there are no standard\ndatasets or prototypical learning tasks defined for this problem domain. Here,\nwe describe OpenABC-D,a large-scale, labeled dataset produced by synthesizing\nopen source designs with a leading open-source logic synthesis tool and\nillustrate its use in developing, evaluating and benchmarking ML-guided logic\nsynthesis. OpenABC-D has intermediate and final outputs in the form of 870,000\nAnd-Inverter-Graphs (AIGs) produced from 1500 synthesis runs plus labels such\nas the optimized node counts, and de-lay. We define a generic learning problem\non this dataset and benchmark existing solutions for it. The codes related to\ndataset creation and benchmark models are available\nathttps://github.com/NYU-MLDA/OpenABC.git. The dataset generated is available\nathttps://archive.nyu.edu/handle/2451/63311",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Animesh Basak Chowdhury",
      "Benjamin Tan",
      "Ramesh Karri",
      "Siddharth Garg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.11292"
  },
  {
    "id": "arXiv:2110.11293",
    "title": "An Empirical Study on GANs with Margin Cosine Loss and Relativistic  Discriminator",
    "abstract": "Generative Adversarial Networks (GANs) have emerged as useful generative\nmodels, which are capable of implicitly learning data distributions of\narbitrarily complex dimensions. However, the training of GANs is empirically\nwell-known for being highly unstable and sensitive. The loss functions of both\nthe discriminator and generator concerning their parameters tend to oscillate\nwildly during training. Different loss functions have been proposed to\nstabilize the training and improve the quality of images generated. In this\npaper, we perform an empirical study on the impact of several loss functions on\nthe performance of standard GAN models, Deep Convolutional Generative\nAdversarial Networks (DCGANs). We introduce a new improvement that employs a\nrelativistic discriminator to replace the classical deterministic discriminator\nin DCGANs and implement a margin cosine loss function for both the generator\nand discriminator. This results in a novel loss function, namely\n\\textit{Relativistic Margin Cosine Loss} (RMCosGAN). We carry out extensive\nexperiments with four datasets: CIFAR-$10$, MNIST, STL-$10$, and CAT. We\ncompare RMCosGAN performance with existing loss functions based on two metrics:\nFrechet inception distance and inception score. The experimental results show\nthat RMCosGAN outperforms the existing ones and significantly improves the\nquality of images generated.",
    "descriptor": "\nComments: 16 pages, 5 figures\n",
    "authors": [
      "Cuong V. Nguyen",
      "Tien-Dung Cao",
      "Tram Truong-Huu",
      "Khanh N. Pham",
      "Binh T. Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11293"
  },
  {
    "id": "arXiv:2110.11298",
    "title": "Video and Text Matching with Conditioned Embeddings",
    "abstract": "We present a method for matching a text sentence from a given corpus to a\ngiven video clip and vice versa. Traditionally video and text matching is done\nby learning a shared embedding space and the encoding of one modality is\nindependent of the other. In this work, we encode the dataset data in a way\nthat takes into account the query's relevant information. The power of the\nmethod is demonstrated to arise from pooling the interaction data between words\nand frames. Since the encoding of the video clip depends on the sentence\ncompared to it, the representation needs to be recomputed for each potential\nmatch. To this end, we propose an efficient shallow neural network. Its\ntraining employs a hierarchical triplet loss that is extendable to\nparagraph/video matching. The method is simple, provides explainability, and\nachieves state-of-the-art results for both sentence-clip and video-text by a\nsizable margin across five different datasets: ActivityNet, DiDeMo, YouCook2,\nMSR-VTT, and LSMDC. We also show that our conditioned representation can be\ntransferred to video-guided machine translation, where we improved the current\nresults on VATEX. Source code is available at\nhttps://github.com/AmeenAli/VideoMatch.",
    "descriptor": "",
    "authors": [
      "Ameen Ali",
      "Idan Schwartz",
      "Tamir Hazan",
      "Lior Wolf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.11298"
  },
  {
    "id": "arXiv:2110.11299",
    "title": "Transformer Acceleration with Dynamic Sparse Attention",
    "abstract": "Transformers are the mainstream of NLP applications and are becoming\nincreasingly popular in other domains such as Computer Vision. Despite the\nimprovements in model quality, the enormous computation costs make Transformers\ndifficult at deployment, especially when the sequence length is large in\nemerging applications. Processing attention mechanism as the essential\ncomponent of Transformer is the bottleneck of execution due to the quadratic\ncomplexity. Prior art explores sparse patterns in attention to support long\nsequence modeling, but those pieces of work are on static or fixed patterns. We\ndemonstrate that the sparse patterns are dynamic, depending on input sequences.\nThus, we propose the Dynamic Sparse Attention (DSA) that can efficiently\nexploit the dynamic sparsity in the attention of Transformers. Compared with\nother methods, our approach can achieve better trade-offs between accuracy and\nmodel complexity. Moving forward, we identify challenges and provide solutions\nto implement DSA on existing hardware (GPUs) and specialized hardware in order\nto achieve practical speedup and efficiency improvements for Transformer\nexecution.",
    "descriptor": "",
    "authors": [
      "Liu Liu",
      "Zheng Qu",
      "Zhaodong Chen",
      "Yufei Ding",
      "Yuan Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11299"
  },
  {
    "id": "arXiv:2110.11303",
    "title": "Survival-oriented embeddings for improving accessibility to complex data  structures",
    "abstract": "Deep learning excels in the analysis of unstructured data and recent\nadvancements allow to extend these techniques to survival analysis. In the\ncontext of clinical radiology, this enables, e.g., to relate unstructured\nvolumetric images to a risk score or a prognosis of life expectancy and support\nclinical decision making. Medical applications are, however, associated with\nhigh criticality and consequently, neither medical personnel nor patients do\nusually accept black box models as reason or basis for decisions. Apart from\naverseness to new technologies, this is due to missing interpretability,\ntransparency and accountability of many machine learning methods. We propose a\nhazard-regularized variational autoencoder that supports straightforward\ninterpretation of deep neural architectures in the context of survival\nanalysis, a field highly relevant in healthcare. We apply the proposed approach\nto abdominal CT scans of patients with liver tumors and their corresponding\nsurvival times.",
    "descriptor": "\nComments: NeurIPS 2021 Workshop, Bridging the Gap: From Machine Learning Research to Clinical Practice\n",
    "authors": [
      "Tobias Weber",
      "Michael Ingrisch",
      "Matthias Fabritius",
      "Bernd Bischl",
      "David R\u00fcgamer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11303"
  },
  {
    "id": "arXiv:2110.11305",
    "title": "On games and simulators as a platform for development of artificial  intelligence for command and control",
    "abstract": "Games and simulators can be a valuable platform to execute complex\nmulti-agent, multiplayer, imperfect information scenarios with significant\nparallels to military applications: multiple participants manage resources and\nmake decisions that command assets to secure specific areas of a map or\nneutralize opposing forces. These characteristics have attracted the artificial\nintelligence (AI) community by supporting development of algorithms with\ncomplex benchmarks and the capability to rapidly iterate over new ideas. The\nsuccess of artificial intelligence algorithms in real-time strategy games such\nas StarCraft II have also attracted the attention of the military research\ncommunity aiming to explore similar techniques in military counterpart\nscenarios. Aiming to bridge the connection between games and military\napplications, this work discusses past and current efforts on how games and\nsimulators, together with the artificial intelligence algorithms, have been\nadapted to simulate certain aspects of military missions and how they might\nimpact the future battlefield. This paper also investigates how advances in\nvirtual reality and visual augmentation systems open new possibilities in human\ninterfaces with gaming platforms and their military parallels.",
    "descriptor": "\nComments: Preprint submitted to the Journal of Defense Modeling and Simulation (JDMS) for peer review\n",
    "authors": [
      "Vinicius G. Goecks",
      "Nicholas Waytowich",
      "Derrik E. Asher",
      "Song Jun Park",
      "Mark Mittrick",
      "John Richardson",
      "Manuel Vindiola",
      "Anne Logie",
      "Mark Dennison",
      "Theron Trout",
      "Priya Narayanan",
      "Alexander Kott"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.11305"
  },
  {
    "id": "arXiv:2110.11309",
    "title": "Fast Model Editing at Scale",
    "abstract": "While large pre-trained models have enabled impressive results on a variety\nof downstream tasks, the largest existing models still make errors, and even\naccurate predictions may become outdated over time. Because detecting all such\nfailures at training time is impossible, enabling both developers and end users\nof such models to correct inaccurate outputs while leaving the model otherwise\nintact is desirable. However, the distributed, black-box nature of the\nrepresentations learned by large neural networks makes producing such targeted\nedits difficult. If presented with only a single problematic input and new\ndesired output, fine-tuning approaches tend to overfit; other editing\nalgorithms are either computationally infeasible or simply ineffective when\napplied to very large models. To enable easy post-hoc editing at scale, we\npropose Model Editor Networks with Gradient Decomposition (MEND), a collection\nof small auxiliary editing networks that use a single desired input-output pair\nto make fast, local edits to a pre-trained model. MEND learns to transform the\ngradient obtained by standard fine-tuning, using a low-rank decomposition of\nthe gradient to make the parameterization of this transformation tractable.\nMEND can be trained on a single GPU in less than a day even for 10 billion+\nparameter models; once trained MEND enables rapid application of new edits to\nthe pre-trained model. Our experiments with T5, GPT, BERT, and BART models show\nthat MEND is the only approach to model editing that produces effective edits\nfor models with tens of millions to over 10 billion parameters. Implementation\navailable at https://sites.google.com/view/mend-editing.",
    "descriptor": "\nComments: View implementation and additional project info at this https URL\n",
    "authors": [
      "Eric Mitchell",
      "Charles Lin",
      "Antoine Bosselut",
      "Chelsea Finn",
      "Christopher D. Manning"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.11309"
  },
  {
    "id": "arXiv:2110.11312",
    "title": "Towards modelling hazard factors in unstructured data spaces using  gradient-based latent interpolation",
    "abstract": "The application of deep learning in survival analysis (SA) gives the\nopportunity to utilize unstructured and high-dimensional data types uncommon in\ntraditional survival methods. This allows to advance methods in fields such as\ndigital health, predictive maintenance and churn analysis, but often yields\nless interpretable and intuitively understandable models due to the black-box\ncharacter of deep learning-based approaches. We close this gap by proposing 1)\na multi-task variational autoencoder (VAE) with survival objective, yielding\nsurvival-oriented embeddings, and 2) a novel method HazardWalk that allows to\nmodel hazard factors in the original data space. HazardWalk transforms the\nlatent distribution of our autoencoder into areas of maximized/minimized hazard\nand then uses the decoder to project changes to the original domain. Our\nprocedure is evaluated on a simulated dataset as well as on a dataset of CT\nimaging data of patients with liver metastases.",
    "descriptor": "\nComments: NeurIPS 2021 Workshop, Deep Generative Models and Downstream Applications\n",
    "authors": [
      "Tobias Weber",
      "Michael Ingrisch",
      "Bernd Bischl",
      "David R\u00fcgamer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11312"
  },
  {
    "id": "arXiv:2110.11314",
    "title": "Center Loss Regularization for Continual Learning",
    "abstract": "The ability to learn different tasks sequentially is essential to the\ndevelopment of artificial intelligence. In general, neural networks lack this\ncapability, the major obstacle being catastrophic forgetting. It occurs when\nthe incrementally available information from non-stationary data distributions\nis continually acquired, disrupting what the model has already learned. Our\napproach remembers old tasks by projecting the representations of new tasks\nclose to that of old tasks while keeping the decision boundaries unchanged. We\nemploy the center loss as a regularization penalty that enforces new tasks'\nfeatures to have the same class centers as old tasks and makes the features\nhighly discriminative. This, in turn, leads to the least forgetting of already\nlearned information. This method is easy to implement, requires minimal\ncomputational and memory overhead, and allows the neural network to maintain\nhigh performance across many sequentially encountered tasks. We also\ndemonstrate that using the center loss in conjunction with the memory replay\noutperforms other replay-based strategies. Along with standard MNIST variants\nfor continual learning, we apply our method to continual domain adaptation\nscenarios with the Digits and PACS datasets. We demonstrate that our approach\nis scalable, effective, and gives competitive performance compared to\nstate-of-the-art continual learning methods.",
    "descriptor": "\nComments: 16 pages, 9 figures, Submitted to the ICLR 2022 conference\n",
    "authors": [
      "Kaustubh Olpadkar",
      "Ekta Gavas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11314"
  },
  {
    "id": "arXiv:2110.11316",
    "title": "CLOOB: Modern Hopfield Networks with InfoLOOB Outperform CLIP",
    "abstract": "Contrastive learning with the InfoNCE objective is exceptionally successful\nin various self-supervised learning tasks. Recently, the CLIP model yielded\nimpressive results on zero-shot transfer learning when using InfoNCE for\nlearning visual representations from natural language supervision. However,\nInfoNCE as a lower bound on the mutual information has been shown to perform\npoorly for high mutual information. In contrast, the InfoLOOB upper bound\n(leave one out bound) works well for high mutual information but suffers from\nlarge variance and instabilities. We introduce \"Contrastive Leave One Out\nBoost\" (CLOOB), where modern Hopfield networks boost learning with the InfoLOOB\nobjective. Modern Hopfield networks replace the original embeddings by\nretrieved embeddings in the InfoLOOB objective. The retrieved embeddings give\nInfoLOOB two assets. Firstly, the retrieved embeddings stabilize InfoLOOB,\nsince they are less noisy and more similar to one another than the original\nembeddings. Secondly, they are enriched by correlations, since the covariance\nstructure of embeddings is reinforced through retrievals. We compare CLOOB to\nCLIP after learning on the Conceptual Captions and the YFCC dataset with\nrespect to their zero-shot transfer learning performance on other datasets.\nCLOOB consistently outperforms CLIP at zero-shot transfer learning across all\nconsidered architectures and datasets.",
    "descriptor": "\nComments: 14 pages (+ appendix); Blog: this https URL GitHub: this https URL\n",
    "authors": [
      "Andreas F\u00fcrst",
      "Elisabeth Rumetshofer",
      "Viet Tran",
      "Hubert Ramsauer",
      "Fei Tang",
      "Johannes Lehner",
      "David Kreil",
      "Michael Kopp",
      "G\u00fcnter Klambauer",
      "Angela Bitto-Nemling",
      "Sepp Hochreiter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11316"
  },
  {
    "id": "arXiv:2110.11320",
    "title": "Deep Curriculum Learning in Task Space for Multi-Class Based Mammography  Diagnosis",
    "abstract": "Mammography is used as a standard screening procedure for the potential\npatients of breast cancer. Over the past decade, it has been shown that deep\nlearning techniques have succeeded in reaching near-human performance in a\nnumber of tasks, and its application in mammography is one of the topics that\nmedical researchers most concentrate on. In this work, we propose an end-to-end\nCurriculum Learning (CL) strategy in task space for classifying the three\ncategories of Full-Field Digital Mammography (FFDM), namely Malignant,\nNegative, and False recall. Specifically, our method treats this three-class\nclassification as a \"harder\" task in terms of CL, and create an \"easier\"\nsub-task of classifying False recall against the combined group of Negative and\nMalignant. We introduce a loss scheduler to dynamically weight the contribution\nof the losses from the two tasks throughout the entire training process. We\nconduct experiments on an FFDM datasets of 1,709 images using 5-fold cross\nvalidation. The results show that our curriculum learning strategy can boost\nthe performance for classifying the three categories of FFDM compared to the\nbaseline strategies for model training.",
    "descriptor": "\nComments: 4-page abstract. Full paper to appear at SPIE Medical Imaging 2022\n",
    "authors": [
      "Jun Luo",
      "Dooman Arefan",
      "Margarita Zuley",
      "Jules Sumkin",
      "Shandong Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11320"
  },
  {
    "id": "arXiv:2110.11323",
    "title": "StyleAlign: Analysis and Applications of Aligned StyleGAN Models",
    "abstract": "In this paper, we perform an in-depth study of the properties and\napplications of aligned generative models. We refer to two models as aligned if\nthey share the same architecture, and one of them (the child) is obtained from\nthe other (the parent) via fine-tuning to another domain, a common practice in\ntransfer learning. Several works already utilize some basic properties of\naligned StyleGAN models to perform image-to-image translation. Here, we perform\nthe first detailed exploration of model alignment, also focusing on StyleGAN.\nFirst, we empirically analyze aligned models and provide answers to important\nquestions regarding their nature. In particular, we find that the child model's\nlatent spaces are semantically aligned with those of the parent, inheriting\nincredibly rich semantics, even for distant data domains such as human faces\nand churches. Second, equipped with this better understanding, we leverage\naligned models to solve a diverse set of tasks. In addition to image\ntranslation, we demonstrate fully automatic cross-domain image morphing. We\nfurther show that zero-shot vision tasks may be performed in the child domain,\nwhile relying exclusively on supervision in the parent domain. We demonstrate\nqualitatively and quantitatively that our approach yields state-of-the-art\nresults, while requiring only simple fine-tuning and inversion.",
    "descriptor": "\nComments: 39 pages, 33 figures\n",
    "authors": [
      "Zongze Wu",
      "Yotam Nitzan",
      "Eli Shechtman",
      "Dani Lischinski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11323"
  },
  {
    "id": "arXiv:2110.11325",
    "title": "Learning 3D Semantic Segmentation with only 2D Image Supervision",
    "abstract": "With the recent growth of urban mapping and autonomous driving efforts, there\nhas been an explosion of raw 3D data collected from terrestrial platforms with\nlidar scanners and color cameras. However, due to high labeling costs,\nground-truth 3D semantic segmentation annotations are limited in both quantity\nand geographic diversity, while also being difficult to transfer across\nsensors. In contrast, large image collections with ground-truth semantic\nsegmentations are readily available for diverse sets of scenes. In this paper,\nwe investigate how to use only those labeled 2D image collections to supervise\ntraining 3D semantic segmentation models. Our approach is to train a 3D model\nfrom pseudo-labels derived from 2D semantic image segmentations using multiview\nfusion. We address several novel issues with this approach, including how to\nselect trusted pseudo-labels, how to sample 3D scenes with rare object\ncategories, and how to decouple input features from 2D images from\npseudo-labels during training. The proposed network architecture, 2D3DNet,\nachieves significantly better performance (+6.2-11.4 mIoU) than baselines\nduring experiments on a new urban dataset with lidar and images captured in 20\ncities across 5 continents.",
    "descriptor": "\nComments: Accepted to 3DV 2021 (Oral)\n",
    "authors": [
      "Kyle Genova",
      "Xiaoqi Yin",
      "Abhijit Kundu",
      "Caroline Pantofaru",
      "Forrester Cole",
      "Avneesh Sud",
      "Brian Brewington",
      "Brian Shucker",
      "Thomas Funkhouser"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11325"
  },
  {
    "id": "arXiv:2110.11328",
    "title": "A Fine-Grained Analysis on Distribution Shift",
    "abstract": "Robustness to distribution shifts is critical for deploying machine learning\nmodels in the real world. Despite this necessity, there has been little work in\ndefining the underlying mechanisms that cause these shifts and evaluating the\nrobustness of algorithms across multiple, different distribution shifts. To\nthis end, we introduce a framework that enables fine-grained analysis of\nvarious distribution shifts. We provide a holistic analysis of current\nstate-of-the-art methods by evaluating 19 distinct methods grouped into five\ncategories across both synthetic and real-world datasets. Overall, we train\nmore than 85K models. Our experimental framework can be easily extended to\ninclude new methods, shifts, and datasets. We find, unlike previous\nwork~\\citep{Gulrajani20}, that progress has been made over a standard ERM\nbaseline; in particular, pretraining and augmentations (learned or heuristic)\noffer large gains in many cases. However, the best methods are not consistent\nover different datasets and shifts.",
    "descriptor": "",
    "authors": [
      "Olivia Wiles",
      "Sven Gowal",
      "Florian Stimberg",
      "Sylvestre Alvise-Rebuffi",
      "Ira Ktena",
      "Krishnamurthy",
      "Dvijotham",
      "Taylan Cemgil"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11328"
  },
  {
    "id": "arXiv:2110.11331",
    "title": "RoQNN: Noise-Aware Training for Robust Quantum Neural Networks",
    "abstract": "Quantum Neural Network (QNN) is a promising application towards quantum\nadvantage on near-term quantum hardware. However, due to the large quantum\nnoises (errors), the performance of QNN models has a severe degradation on real\nquantum devices. For example, the accuracy gap between noise-free simulation\nand noisy results on IBMQ-Yorktown for MNIST-4 classification is over 60%.\nExisting noise mitigation methods are general ones without leveraging unique\ncharacteristics of QNN and are only applicable to inference; on the other hand,\nexisting QNN work does not consider noise effect. To this end, we present\nRoQNN, a QNN-specific framework to perform noise-aware optimizations in both\ntraining and inference stages to improve robustness. We analytically deduct and\nexperimentally observe that the effect of quantum noise to QNN measurement\noutcome is a linear map from noise-free outcome with a scaling and a shift\nfactor. Motivated by that, we propose post-measurement normalization to\nmitigate the feature distribution differences between noise-free and noisy\nscenarios. Furthermore, to improve the robustness against noise, we propose\nnoise injection to the training process by inserting quantum error gates to QNN\naccording to realistic noise models of quantum hardware. Finally,\npost-measurement quantization is introduced to quantize the measurement\noutcomes to discrete values, achieving the denoising effect. Extensive\nexperiments on 8 classification tasks using 6 quantum devices demonstrate that\nRoQNN improves accuracy by up to 43%, and achieves over 94% 2-class, 80%\n4-class, and 34% 10-class MNIST classification accuracy measured on real\nquantum computers. We also open-source our PyTorch library for construction and\nnoise-aware training of QNN at https://github.com/mit-han-lab/pytorch-quantum .",
    "descriptor": "\nComments: 19 pages, 10 figures, open-source at this https URL\n",
    "authors": [
      "Hanrui Wang",
      "Jiaqi Gu",
      "Yongshan Ding",
      "Zirui Li",
      "Frederic T. Chong",
      "David Z. Pan",
      "Song Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.11331"
  },
  {
    "id": "arXiv:2110.11333",
    "title": "A Python Package to Detect Anti-Vaccine Users on Twitter",
    "abstract": "Vaccine hesitancy has a long history but has been recently driven by the\nanti-vaccine narratives shared online, which significantly degrades the\nefficacy of vaccination strategies, such as those for COVID-19. Despite broad\nagreement in the medical community about the safety and efficacy of available\nvaccines, a large number of social media users continue to be inundated with\nfalse information about vaccines and, partly because of this, became indecisive\nor unwilling to be vaccinated. The goal of this study is to better understand\nanti-vaccine sentiment, and work to reduce its impact, by developing a system\ncapable of automatically identifying the users responsible for spreading\nanti-vaccine narratives. We introduce a publicly available Python package\ncapable of analyzing Twitter profiles to assess how likely that profile is to\nspread anti-vaccine sentiment in the future. The software package is built\nusing text embedding methods, neural networks, and automated dataset\ngeneration. It is trained on over one hundred thousand accounts and several\nmillion tweets. This model will help researchers and policy-makers understand\nanti-vaccine discussion and misinformation strategies, which can further help\ntailor targeted campaigns seeking to inform and debunk the harmful\nanti-vaccination myths currently being spread. Additionally, we leverage the\ndata on such users to understand what are the moral and emotional\ncharacteristics of anti-vaccine spreaders.",
    "descriptor": "",
    "authors": [
      "Matheus Schmitz",
      "Goran Muri\u0107",
      "Keith Burghardt"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.11333"
  },
  {
    "id": "arXiv:2110.11334",
    "title": "Generalized Out-of-Distribution Detection: A Survey",
    "abstract": "Out-of-distribution (OOD) detection is critical to ensuring the reliability\nand safety of machine learning systems. For instance, in autonomous driving, we\nwould like the driving system to issue an alert and hand over the control to\nhumans when it detects unusual scenes or objects that it has never seen before\nand cannot make a safe decision. This problem first emerged in 2017 and since\nthen has received increasing attention from the research community, leading to\na plethora of methods developed, ranging from classification-based to\ndensity-based to distance-based ones. Meanwhile, several other problems are\nclosely related to OOD detection in terms of motivation and methodology. These\ninclude anomaly detection (AD), novelty detection (ND), open set recognition\n(OSR), and outlier detection (OD). Despite having different definitions and\nproblem settings, these problems often confuse readers and practitioners, and\nas a result, some existing studies misuse terms. In this survey, we first\npresent a generic framework called generalized OOD detection, which encompasses\nthe five aforementioned problems, i.e., AD, ND, OSR, OOD detection, and OD.\nUnder our framework, these five problems can be seen as special cases or\nsub-tasks, and are easier to distinguish. Then, we conduct a thorough review of\neach of the five areas by summarizing their recent technical developments. We\nconclude this survey with open challenges and potential research directions.",
    "descriptor": "\nComments: Issues, comments, and questions are all welcomed in this https URL\n",
    "authors": [
      "Jingkang Yang",
      "Kaiyang Zhou",
      "Yixuan Li",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11334"
  },
  {
    "id": "arXiv:2110.11335",
    "title": "Convex Joint Graph Matching and Clustering via Semidefinite Relaxations",
    "abstract": "This paper proposes a new algorithm for simultaneous graph matching and\nclustering. For the first time in the literature, these two problems are solved\njointly and synergetically without relying on any training data, which brings\nadvantages for identifying similar arbitrary objects in compound 3D scenes and\nmatching them. For joint reasoning, we first rephrase graph matching as a rigid\npoint set registration problem operating on spectral graph embeddings.\nConsequently, we utilise efficient convex semidefinite program relaxations for\naligning points in Hilbert spaces and add coupling constraints to model the\nmutual dependency and exploit synergies between both tasks. We outperform state\nof the art in challenging cases with non-perfectly matching and noisy graphs,\nand we show successful applications on real compound scenes with multiple 3D\nelements. Our source code and data are publicly available.",
    "descriptor": "\nComments: 12 pages, 8 figures; source code available; project webpage: this https URL\n",
    "authors": [
      "Maximilian Krahn",
      "Florian Bernard",
      "Vladislav Golyanik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11335"
  },
  {
    "id": "arXiv:1610.06631",
    "title": "Inverse Power Flow Problem",
    "abstract": "This paper formulates the inverse power flow problem which is to infer the\nnodal admittance matrix (hence the network structure of the power system) from\nvoltage and current phasors measured at a number of buses. We show that the\nadmittance matrix can be uniquely identified from a sequence of measurements\ncorresponding to different steady states when every node in the system is\nequipped with a measurement device, and a Kron-reduced admittance matrix can be\ndetermined even if some nodes in the system are not monitored (hidden nodes).\nFurthermore, we propose effective algorithms based on graph theory to uncover\nthe actual admittance matrix of radial systems with hidden nodes. We provide\ntheoretical guarantees for the recovered admittance matrix and demonstrate that\nthe actual admittance matrix can be fully recovered even from the Kron-reduced\nadmittance matrix under some mild assumptions. Simulations on standard test\nsystems confirm that these algorithms are capable of providing accurate\nestimates of the admittance matrix from noisy sensor data.",
    "descriptor": "\nComments: working paper\n",
    "authors": [
      "Ye Yuan",
      "Steven Low",
      "Omid Ardakanian",
      "Claire Tomlin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/1610.06631"
  },
  {
    "id": "arXiv:2107.06013",
    "title": "Barriers and Dynamical Paths in Alternating Gibbs Sampling of Restricted  Boltzmann Machines",
    "abstract": "Restricted Boltzmann Machines (RBM) are bi-layer neural networks used for the\nunsupervised learning of model distributions from data. The bipartite\narchitecture of RBM naturally defines an elegant sampling procedure, called\nAlternating Gibbs Sampling (AGS), where the configurations of the\nlatent-variable layer are sampled conditional to the data-variable layer, and\nvice versa. We study here the performance of AGS on several analytically\ntractable models borrowed from statistical mechanics. We show that standard AGS\nis not more efficient than classical Metropolis-Hastings (MH) sampling of the\neffective energy landscape defined on the data layer. However, RBM can identify\nmeaningful representations of training data in their latent space. Furthermore,\nusing these representations and combining Gibbs sampling with the MH algorithm\nin the latent space can enhance the sampling performance of the RBM when the\nhidden units encode weakly dependent features of the data. We illustrate our\nfindings on three datasets: Bars and Stripes and MNIST, well known in machine\nlearning, and the so-called Lattice Proteins, introduced in theoretical biology\nto study the sequence-to-structure mapping in proteins.",
    "descriptor": "",
    "authors": [
      "Cl\u00e9ment Roussel",
      "Simona Cocco",
      "R\u00e9mi Monasson"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06013"
  },
  {
    "id": "arXiv:2110.10156",
    "title": "Cross-Sim-NGF: FFT-Based Global Rigid Multimodal Alignment of Image  Volumes using Normalized Gradient Fields",
    "abstract": "Multimodal image alignment involves finding spatial correspondences between\nvolumes varying in appearance and structure. Automated alignment methods are\noften based on local optimization that can be highly sensitive to their\ninitialization. We propose a global optimization method for rigid multimodal 3D\nimage alignment, based on a novel efficient algorithm for computing similarity\nof normalized gradient fields (NGF) in the frequency domain. We validate the\nmethod experimentally on a dataset comprised of 20 brain volumes acquired in\nfour modalities (T1w, Flair, CT, [18F] FDG PET), synthetically displaced with\nknown transformations. The proposed method exhibits excellent performance on\nall six possible modality combinations, and outperforms all four reference\nmethods by a large margin. The method is fast; a 3.4Mvoxel global rigid\nalignment requires approximately 40 seconds of computation, and the proposed\nalgorithm outperforms a direct algorithm for the same task by more than three\norders of magnitude. Open-source implementation is provided.",
    "descriptor": "\nComments: 5 pages, 3 figures, 3 tables. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Johan \u00d6fverstedt",
      "Joakim Lindblad",
      "Nata\u0161a Sladoje"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10156"
  },
  {
    "id": "arXiv:2110.10199",
    "title": "Theoretical Advances in Current Estimation and Navigation from a  Glider-Based Acoustic Doppler Current Profiler (ADCP)",
    "abstract": "We examine acoustic Doppler current profiler (ADCP) measurements from\nunderwater gliders to determine glider position, glider velocity, and\nsubsurface current. ADCPs, however, do not directly observe the quantities of\ninterest; instead, they measure the relative motion of the vehicle and the\nwater column. We examine the lineage of mathematical innovations that have\npreviously been applied to this problem, discovering an unstated but incorrect\nassumption of independence. We reframe a recent method to form a joint\nprobability model of current and vehicle navigation, which allows us to correct\nthis assumption and extend the classic Kalman smoothing method. Detailed\nsimulations affirm the efficacy of our approach for computing estimates and\ntheir uncertainty. The joint model developed here sets the stage for future\nwork to incorporate constraints, range measurements, and robust statistical\nmodeling.",
    "descriptor": "\nComments: Submitted to Journal of Atmospheric and Oceanic Technology. 15 pages main text. 10 pages figures, tables, bibliography, appendices\n",
    "authors": [
      "Jacob Stevens-Haas",
      "Sarah E. Webster",
      "Aleksandr Aravkin"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.10199"
  },
  {
    "id": "arXiv:2110.10210",
    "title": "Long Random Matrices and Tensor Unfolding",
    "abstract": "In this paper, we consider the singular values and singular vectors of low\nrank perturbations of large rectangular random matrices, in the regime the\nmatrix is \"long\": we allow the number of rows (columns) to grow polynomially in\nthe number of columns (rows). We prove there exists a critical signal-to-noise\nratio (depending on the dimensions of the matrix), and the extreme singular\nvalues and singular vectors exhibit a BBP type phase transition. As a main\napplication, we investigate the tensor unfolding algorithm for the asymmetric\nrank-one spiked tensor model, and obtain an exact threshold, which is\nindependent of the procedure of tensor unfolding. If the signal-to-noise ratio\nis above the threshold, tensor unfolding detects the signals; otherwise, it\nfails to capture the signals.",
    "descriptor": "\nComments: 29 pages, 4 figures\n",
    "authors": [
      "G\u00e9rard Ben Arous",
      "Daniel Zhengyu Huang",
      "Jiaoyang Huang"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.10210"
  },
  {
    "id": "arXiv:2110.10219",
    "title": "Power Line Communication Based Smart Grid Asset Monitoring Using Time  Series Forecasting",
    "abstract": "Monitoring grid assets continuously is critical in ensuring the reliable\noperation of the electricity grid system and improving its resilience in case\nof a defect. In light of several asset monitoring techniques in use, power line\ncommunication (PLC) enables a low-cost cable diagnostics solution by re-using\nsmart grid data communication modems to also infer the cable health using the\ninherently estimated communication channel state information. Traditional\nPLC-based cable diagnostics solutions are dependent on prior knowledge of the\ncable type, network topology, and/or characteristics of the anomalies. In\ncontrast, we develop an asset monitoring technique in this paper that can\ndetect various types of anomalies in the grid without any prior domain\nknowledge. To this end, we design a solution that first uses time-series\nforecasting to predict the PLC channel state information at any given point in\ntime based on its historical data. Under the assumption that the prediction\nerror follows a Gaussian distribution, we then perform chi-squared statistical\ntest to determine the significance level of the resultant Mahalanobis distance\nto build our anomaly detector. We demonstrate the effectiveness and\nuniversality of our solution via evaluations conducted using both synthetic and\nreal-world data extracted from low- and medium-voltage distribution networks.",
    "descriptor": "",
    "authors": [
      "Yinjia Huo",
      "Gautham Prasad",
      "Lutz Lampe",
      "Victor C. M. Leung"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.10219"
  },
  {
    "id": "arXiv:2110.10220",
    "title": "Patch Based Transformation for Minimum Variance Beamformer Image  Approximation Using Delay and Sum Pipeline",
    "abstract": "In the recent past, there have been several efforts in accelerating\ncomputationally heavy beamforming algorithms such as minimum variance\ndistortionless response (MVDR) beamforming to achieve real-time performance\ncomparable to the popular delay and sum (DAS) beamforming. This has been\nachieved using a variety of neural network architectures ranging from fully\nconnected neural networks (FCNNs), convolutional neural networks (CNNs) and\ngeneral adversarial networks (GANs). However most of these approaches are\nworking with optimizations considering image level losses and hence require a\nsignificant amount of dataset to ensure that the process of beamforming is\nlearned. In this work, a patch level U-Net based neural network is proposed,\nwhere the delay compensated radio frequency (RF) patch for a fixed region in\nspace (e.g. 32x32) is transformed through a U-Net architecture and multiplied\nwith DAS apodization weights and optimized for similarity with MVDR image of\nthe patch. Instead of framing the beamforming problem as a regression problem\nto estimate the apodization weights, the proposed approach treats the\nnon-linear transformation of the RF data space that can account for the data\ndriven weight adaptation done by the MVDR approach in the parameters of the\nnetwork. In this way, it is also observed that by restricting the input to a\npatch the model will learn the beamforming pipeline as an image non-linear\ntransformation problem.",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Sairoop Bodepudi",
      "A N Madhavanunni",
      "Mahesh Raveendranatha Panicker"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10220"
  },
  {
    "id": "arXiv:2110.10242",
    "title": "A New Automatic Change Detection Frame-work Based on Region Growing and  Weighted Local Mutual Information: Analysis of Breast Tumor Response to  Chemotherapy in Serial MR Images",
    "abstract": "The automatic analysis of subtle changes between longitudinal MR images is an\nimportant task as it is still a challenging issue in scope of the breast\nmedical image processing. In this paper we propose an effective automatic\nchange detection framework composed of two phases since previously used methods\nhave features with low distinctive power. First, in the preprocessing phase an\nintensity normalization method is suggested based on Hierarchical Histogram\nMatching (HHM) that is more robust to noise than previous methods. To eliminate\nundesirable changes and extract the regions containing significant changes the\nproposed Extraction Region of Changes (EROC) method is applied based on\nintensity distribution and Hill-Climbing algorithm. Second, in the detection\nphase a region growing-based approach is suggested to differentiate significant\nchanges from unreal ones. Due to using proposed Weighted Local Mutual\nInformation (WLMI) method to extract high level features and also utilizing the\nprinciple of the local consistency of changes, the proposed approach enjoys\nreasonable performance. The experimental results on both simulated and real\nlongitudinal Breast MR Images confirm the effectiveness of the proposed\nframework. Also, this framework outperforms the human expert in some cases\nwhich can detect many lesion evolutions that are missed by expert.",
    "descriptor": "\nComments: 18 pages, 16 figures, 14 tables\n",
    "authors": [
      "Narges Norouzi",
      "Reza Azmi",
      "Nooshin Noshiri",
      "Robab Anbiaee"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10242"
  },
  {
    "id": "arXiv:2110.10267",
    "title": "Recognizability of morphisms",
    "abstract": "We investigate several questions related to the notion of recognizable\nmorphism. The main result is a new proof of Mosse's theorem and actually of a\ngeneralization to non primitive morphisms due to Berth\\'e et al. We actually\nprove the result of Berth\\'e et al. for the most general class of morphisms,\nincluding ones with erasable letters. It is derived from a result concerning\nelementary morphisms for which we also provide a new proof. We also show how to\ndecide whether an injective morphism is recognizable on the full shift for\naperiodic points.",
    "descriptor": "",
    "authors": [
      "Marie-Pierre B\u00e9al",
      "Dominique Perrin",
      "Antonio Restivo"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.10267"
  },
  {
    "id": "arXiv:2110.10279",
    "title": "Factorization Approach for Low-complexity Matrix Completion Problems:  Exponential Number of Spurious Solutions and Failure of Gradient Methods",
    "abstract": "It is well-known that the Burer-Monteiro (B-M) factorization approach can\nefficiently solve low-rank matrix optimization problems under the RIP\ncondition. It is natural to ask whether B-M factorization-based methods can\nsucceed on any low-rank matrix optimization problems with a low\ninformation-theoretic complexity, i.e., polynomial-time solvable problems that\nhave a unique solution. In this work, we provide a negative answer to the above\nquestion. We investigate the landscape of B-M factorized polynomial-time\nsolvable matrix completion (MC) problems, which are the most popular subclass\nof low-rank matrix optimization problems without the RIP condition. We\nconstruct an instance of polynomial-time solvable MC problems with\nexponentially many spurious local minima, which leads to the failure of most\ngradient-based methods. Based on those results, we define a new complexity\nmetric that potentially measures the solvability of low-rank matrix\noptimization problems based on the B-M factorization approach. In addition, we\nshow that more measurements of the ground truth matrix can deteriorate the\nlandscape, which further reveals the unfavorable behavior of the B-M\nfactorization on general low-rank matrix optimization problems.",
    "descriptor": "\nComments: 21 pages, 1 figure\n",
    "authors": [
      "Baturalp Yalcin",
      "Haixiang Zhang",
      "Javad Lavaei",
      "Somayeh Sojoudi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10279"
  },
  {
    "id": "arXiv:2110.10281",
    "title": "Joint Gaussian Graphical Model Estimation: A Survey",
    "abstract": "Graphs from complex systems often share a partial underlying structure across\ndomains while retaining individual features. Thus, identifying common\nstructures can shed light on the underlying signal, for instance, when applied\nto scientific discoveries or clinical diagnoses. Furthermore, growing evidence\nshows that the shared structure across domains boosts the estimation power of\ngraphs, particularly for high-dimensional data. However, building a joint\nestimator to extract the common structure may be more complicated than it\nseems, most often due to data heterogeneity across sources. This manuscript\nsurveys recent work on statistical inference of joint Gaussian graphical\nmodels, identifying model structures that fit various data generation\nprocesses. Simulations under different data generation processes are\nimplemented with detailed discussions on the choice of models.",
    "descriptor": "",
    "authors": [
      "Katherine Tsai",
      "Oluwasanmi Koyejo",
      "Mladen Kolar"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.10281"
  },
  {
    "id": "arXiv:2110.10323",
    "title": "Computational Graph Completion",
    "abstract": "We introduce a framework for generating, organizing, and reasoning with\ncomputational knowledge. It is motivated by the observation that most problems\nin Computational Sciences and Engineering (CSE) can be described as that of\ncompleting (from data) a computational graph representing dependencies between\nfunctions and variables. Functions and variables may be known, unknown, or\nrandom. Data comes in the form of observations of distinct values of a finite\nnumber of subsets of the variables of the graph. The underlying problem\ncombines a regression problem (approximating unknown functions) with a matrix\ncompletion problem (recovering unobserved variables in the data). Replacing\nunknown functions by Gaussian Processes (GPs) and conditioning on observed data\nprovides a simple but efficient approach to completing such graphs. Since the\nproposed framework is highly expressive, it has a vast potential application\nscope. Since the completion process can be automatized, as one solves\n$\\sqrt{\\sqrt{2}+\\sqrt{3}}$ on a pocket calculator without thinking about it,\none could, with the proposed framework, solve a complex CSE problem by drawing\na diagram. Compared to traditional kriging, the proposed framework can be used\nto recover unknown functions with much scarcer data by exploiting\ninterdependencies between multiple functions and variables. The Computational\nGraph Completion (CGC) problem addressed by the proposed framework could\ntherefore also be interpreted as a generalization of that of solving linear\nsystems of equations to that of approximating unknown variables and functions\nwith noisy, incomplete, and nonlinear dependencies. Numerous examples\nillustrate the flexibility, scope, efficacy, and robustness of the CGC\nframework and show how it can be used as a pathway to identifying simple\nsolutions to classical CSE problems (digital twin modeling, dimension\nreduction, mode decomposition, etc.).",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Houman Owhadi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.10323"
  },
  {
    "id": "arXiv:2110.10326",
    "title": "Identity Conversion for Emotional Speakers: A Study for Disentanglement  of Emotion Style and Speaker Identity",
    "abstract": "Expressive voice conversion performs identity conversion for emotional\nspeakers by jointly converting speaker identity and speaker-dependent emotion\nstyle. Due to the hierarchical structure of speech emotion, it is challenging\nto disentangle the speaker-dependent emotional style for expressive voice\nconversion. Motivated by the recent success on speaker disentanglement with\nvariational autoencoder (VAE), we propose an expressive voice conversion\nframework which can effectively disentangle linguistic content, speaker\nidentity, pitch, and emotional style information. We study the use of emotion\nencoder to model emotional style explicitly, and introduce mutual information\n(MI) losses to reduce the irrelevant information from the disentangled emotion\nrepresentations. At run-time, our proposed framework can convert both speaker\nidentity and speaker-dependent emotional style without the need for parallel\ndata. Experimental results validate the effectiveness of our proposed framework\nin both objective and subjective evaluations.",
    "descriptor": "\nComments: Submitted to ICASSP2022\n",
    "authors": [
      "Zongyang Du",
      "Berrak Sisman",
      "Kun Zhou",
      "Haizhou Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.10326"
  },
  {
    "id": "arXiv:2110.10330",
    "title": "One model to enhance them all: array geometry agnostic multi-channel  personalized speech enhancement",
    "abstract": "With the recent surge of video conferencing tools usage, providing\nhigh-quality speech signals and accurate captions have become essential to\nconduct day-to-day business or connect with friends and families.\nSingle-channel personalized speech enhancement (PSE) methods show promising\nresults compared with the unconditional speech enhancement (SE) methods in\nthese scenarios due to their ability to remove interfering speech in addition\nto the environmental noise. In this work, we leverage spatial information\nafforded by microphone arrays to improve such systems' performance further. We\ninvestigate the relative importance of speaker embeddings and spatial features.\nMoreover, we propose a new causal array-geometry-agnostic multi-channel PSE\nmodel, which can generate a high-quality enhanced signal from arbitrary\nmicrophone geometry. Experimental results show that the proposed geometry\nagnostic model outperforms the model trained on a specific microphone array\ngeometry in both speech quality and automatic speech recognition accuracy. We\nalso demonstrate the effectiveness of the proposed approach for unseen array\ngeometries.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Hassan Taherian",
      "Sefik Emre Eskimez",
      "Takuya Yoshioka",
      "Huaming Wang",
      "Zhuo Chen",
      "Xuedong Huang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.10330"
  },
  {
    "id": "arXiv:2110.10332",
    "title": "Artificial Intelligence-Based Detection, Classification and  Prediction/Prognosis in PET Imaging: Towards Radiophenomics",
    "abstract": "Artificial intelligence (AI) techniques have significant potential to enable\neffective, robust, and automated image phenotyping including identification of\nsubtle patterns. AI-based detection searches the image space to find the\nregions of interest based on patterns and features. There is a spectrum of\ntumor histologies from benign to malignant that can be identified by AI-based\nclassification approaches using image features. The extraction of minable\ninformation from images gives way to the field of radiomics and can be explored\nvia explicit (handcrafted/engineered) and deep radiomics frameworks. Radiomics\nanalysis has the potential to be utilized as a noninvasive technique for the\naccurate characterization of tumors to improve diagnosis and treatment\nmonitoring. This work reviews AI-based techniques, with a special focus on\noncological PET and PET/CT imaging, for different detection, classification,\nand prediction/prognosis tasks. We also discuss needed efforts to enable the\ntranslation of AI techniques to routine clinical workflows, and potential\nimprovements and complementary techniques such as the use of natural language\nprocessing on electronic health records and neuro-symbolic AI techniques.",
    "descriptor": "",
    "authors": [
      "Fereshteh Yousefirizi",
      "Pierre Decasez",
      "Amine Amyar",
      "Su Ruan",
      "Babak Saboury",
      "Arman Rahmim"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.10332"
  },
  {
    "id": "arXiv:2110.10351",
    "title": "Faster Algorithm and Sharper Analysis for Constrained Markov Decision  Process",
    "abstract": "The problem of constrained Markov decision process (CMDP) is investigated,\nwhere an agent aims to maximize the expected accumulated discounted reward\nsubject to multiple constraints on its utilities/costs. A new primal-dual\napproach is proposed with a novel integration of three ingredients: entropy\nregularized policy optimizer, dual variable regularizer, and Nesterov's\naccelerated gradient descent dual optimizer, all of which are critical to\nachieve a faster convergence. The finite-time error bound of the proposed\napproach is characterized. Despite the challenge of the nonconcave objective\nsubject to nonconcave constraints, the proposed approach is shown to converge\nto the global optimum with a complexity of $\\tilde{\\mathcal O}(1/\\epsilon)$ in\nterms of the optimality gap and the constraint violation, which improves the\ncomplexity of the existing primal-dual approach by a factor of $\\mathcal\nO(1/\\epsilon)$ \\citep{ding2020natural,paternain2019constrained}. This is the\nfirst demonstration that nonconcave CMDP problems can attain the complexity\nlower bound of $\\mathcal O(1/\\epsilon)$ for convex optimization subject to\nconvex constraints. Our primal-dual approach and non-asymptotic analysis are\nagnostic to the RL optimizer used, and thus are more flexible for practical\napplications. More generally, our approach also serves as the first algorithm\nthat provably accelerates constrained nonconvex optimization with zero duality\ngap by exploiting the geometries such as the gradient dominance condition, for\nwhich the existing acceleration methods for constrained convex optimization are\nnot applicable.",
    "descriptor": "\nComments: The paper was initially submitted for publication in January 2021\n",
    "authors": [
      "Tianjiao Li",
      "Ziwei Guan",
      "Shaofeng Zou",
      "Tengyu Xu",
      "Yingbin Liang",
      "Guanghui Lan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10351"
  },
  {
    "id": "arXiv:2110.10362",
    "title": "The Bleeps, the Sweeps, and the Creeps: Convergence Rates for Dynamic  Observer Patterns via Data Assimilation for the 2D Navier-Stokes Equations",
    "abstract": "We adapt a continuous data assimilation scheme, known as the\nAzouani-Olson-Titi (AOT) algorithm, to the case of moving observers for the 2D\nincompressible Navier-Stokes equations. We propose and test computationally\nseveral movement patterns (which we refer to as \"the bleeps, the sweeps and the\ncreeps\"), as well as Lagrangian motion and combinations of these patterns, in\ncomparison with static (i.e. non-moving) observers. In several cases,\norder-of-magnitude improvements in terms of the time-to-convergence are\nobserved. We end with a discussion of possible applications to real-world data\ncollection strategies that may lead to substantial improvements in predictive\ncapabilities.",
    "descriptor": "",
    "authors": [
      "Trenton Franz",
      "Adam Larios",
      "Collin Victor"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.10362"
  },
  {
    "id": "arXiv:2110.10381",
    "title": "Medical Knowledge-Guided Deep Curriculum Learning for Elbow Fracture  Diagnosis from X-Ray Images",
    "abstract": "Elbow fractures are one of the most common fracture types. Diagnoses on elbow\nfractures often need the help of radiographic imaging to be read and analyzed\nby a specialized radiologist with years of training. Thanks to the recent\nadvances of deep learning, a model that can classify and detect different types\nof bone fractures needs only hours of training and has shown promising results.\nHowever, most existing deep learning models are purely data-driven, lacking\nincorporation of known domain knowledge from human experts. In this work, we\npropose a novel deep learning method to diagnose elbow fracture from elbow\nX-ray images by integrating domain-specific medical knowledge into a curriculum\nlearning framework. In our method, the training data are permutated by sampling\nwithout replacement at the beginning of each training epoch. The sampling\nprobability of each training sample is guided by a scoring criterion\nconstructed based on clinically known knowledge from human experts, where the\nscoring indicates the diagnosis difficultness of different elbow fracture\nsubtypes. We also propose an algorithm that updates the sampling probabilities\nat each epoch, which is applicable to other sampling-based curriculum learning\nframeworks. We design an experiment with 1865 elbow X-ray images for a\nfracture/normal binary classification task and compare our proposed method to a\nbaseline method and a previous method using multiple metrics. Our results show\nthat the proposed method achieves the highest classification performance. Also,\nour proposed probability update algorithm boosts the performance of the\nprevious method.",
    "descriptor": "\nComments: SPIE Medical Imaging 2021. DOI: this https URL URL: this https URL\n",
    "authors": [
      "Jun Luo",
      "Gene Kitamura",
      "Emine Doganay",
      "Dooman Arefan",
      "Shandong Wu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10381"
  },
  {
    "id": "arXiv:2110.10383",
    "title": "Knowledge-Guided Multiview Deep Curriculum Learning for Elbow Fracture  Classification",
    "abstract": "Elbow fracture diagnosis often requires patients to take both frontal and\nlateral views of elbow X-ray radiographs. In this paper, we propose a multiview\ndeep learning method for an elbow fracture subtype classification task. Our\nstrategy leverages transfer learning by first training two single-view models,\none for frontal view and the other for lateral view, and then transferring the\nweights to the corresponding layers in the proposed multiview network\narchitecture. Meanwhile, quantitative medical knowledge was integrated into the\ntraining process through a curriculum learning framework, which enables the\nmodel to first learn from \"easier\" samples and then transition to \"harder\"\nsamples to reach better performance. In addition, our multiview network can\nwork both in a dual-view setting and with a single view as input. We evaluate\nour method through extensive experiments on a classification task of elbow\nfracture with a dataset of 1,964 images. Results show that our method\noutperforms two related methods on bone fracture study in multiple settings,\nand our technique is able to boost the performance of the compared methods. The\ncode is available at https://github.com/ljaiverson/multiview-curriculum.",
    "descriptor": "\nComments: MICCAI 2021 workshop. DOI: this https URL URL: this https URL\n",
    "authors": [
      "Jun Luo",
      "Gene Kitamura",
      "Dooman Arefan",
      "Emine Doganay",
      "Ashok Panigrahy",
      "Shandong Wu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10383"
  },
  {
    "id": "arXiv:2110.10394",
    "title": "Deep Learning for HDR Imaging: State-of-the-Art and Future Trends",
    "abstract": "High dynamic range (HDR) imaging is a technique that allows an extensive\ndynamic range of exposures, which is important in image processing, computer\ngraphics, and computer vision. In recent years, there has been a significant\nadvancement in HDR imaging using deep learning (DL). This study conducts a\ncomprehensive and insightful survey and analysis of recent developments in deep\nHDR imaging methodologies. We hierarchically and structurally group existing\ndeep HDR imaging methods into five categories based on (1) number/domain of\ninput exposures, (2) number of learning tasks, (3) novel sensor data, (4) novel\nlearning strategies, and (5) applications. Importantly, we provide a\nconstructive discussion on each category regarding its potential and\nchallenges. Moreover, we review some crucial aspects of deep HDR imaging, such\nas datasets and evaluation metrics. Finally, we highlight some open problems\nand point out future research directions.",
    "descriptor": "\nComments: Accepted to IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)\n",
    "authors": [
      "Lin Wang",
      "Kuk-Jin Yoon"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10394"
  },
  {
    "id": "arXiv:2110.10398",
    "title": "Modelling of microstructures during in-situ alloying in additive  manufacturing for efficient material qualification processes",
    "abstract": "In this work, a numerical simulation framework is presented based on the\nPhase Field Method that is able to capture the evolution of heterogeneous\nmetallic microstructures during solidification. The involved physics can prove\nespecially useful when studying not only systems undergoing thermal gradients,\nsuch as in homogeneous systems, but also in conditions that exhibit stark\nspatial gradients, i.e. when these inhomogeneities are present even on a\nmesoscopic scale. To illustrate the capabilities of the model, in-situ alloying\nof a High Entropy Alloy during Laser Powder Bed Fusion is investigated as an\nexemplary use case. The resulting digital twin is expected to shorten\ndevelopment times of new materials as well as cut down on experimental resource\nneeds considerably, therefore contributing to efficient material qualification\nprocesses.",
    "descriptor": "\nComments: 12 pages, 4 figures, submitted to ASIM Simulation in Produktion und Logistik 2021, Erlangen\n",
    "authors": [
      "Patrick Zimbrod",
      "Johannes Schilp"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.10398"
  },
  {
    "id": "arXiv:2110.10403",
    "title": "AFTer-UNet: Axial Fusion Transformer UNet for Medical Image Segmentation",
    "abstract": "Recent advances in transformer-based models have drawn attention to exploring\nthese techniques in medical image segmentation, especially in conjunction with\nthe U-Net model (or its variants), which has shown great success in medical\nimage segmentation, under both 2D and 3D settings. Current 2D based methods\neither directly replace convolutional layers with pure transformers or consider\na transformer as an additional intermediate encoder between the encoder and\ndecoder of U-Net. However, these approaches only consider the attention\nencoding within one single slice and do not utilize the axial-axis information\nnaturally provided by a 3D volume. In the 3D setting, convolution on volumetric\ndata and transformers both consume large GPU memory. One has to either\ndownsample the image or use cropped local patches to reduce GPU memory usage,\nwhich limits its performance. In this paper, we propose Axial Fusion\nTransformer UNet (AFTer-UNet), which takes both advantages of convolutional\nlayers' capability of extracting detailed features and transformers' strength\non long sequence modeling. It considers both intra-slice and inter-slice\nlong-range cues to guide the segmentation. Meanwhile, it has fewer parameters\nand takes less GPU memory to train than the previous transformer-based models.\nExtensive experiments on three multi-organ segmentation datasets demonstrate\nthat our method outperforms current state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Xiangyi Yan",
      "Hao Tang",
      "Shanlin Sun",
      "Haoyu Ma",
      "Deying Kong",
      "Xiaohui Xie"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10403"
  },
  {
    "id": "arXiv:2110.10411",
    "title": "Hyperspherical Dirac Mixture Reapproximation",
    "abstract": "We propose a novel scheme for efficient Dirac mixture modeling of\ndistributions on unit hyperspheres. A so-called hyperspherical localized\ncumulative distribution (HLCD) is introduced as a local and smooth\ncharacterization of the underlying continuous density in hyperspherical\ndomains. Based on HLCD, a manifold-adapted modification of the Cram\\'er-von\nMises distance (HCvMD) is established to measure the statistical divergence\nbetween two Dirac mixtures of arbitrary dimensions. Given a (source) Dirac\nmixture with many components representing an unknown hyperspherical\ndistribution, a (target) Dirac mixture with fewer components is obtained via\nmatching the source in the sense of least HCvMD. As the number of target Dirac\ncomponents is configurable, the underlying distributions is represented in a\nmore efficient and informative way. Based upon this hyperspherical Dirac\nmixture reapproximation (HDMR), we derive a density estimation method and a\nrecursive filter. For density estimation, a maximum likelihood method is\nprovided to reconstruct the underlying continuous distribution in the form of a\nvon Mises-Fisher mixture. For recursive filtering, we introduce the\nhyperspherical reapproximation discrete filter (HRDF) for nonlinear\nhyperspherical estimation of dynamic systems under unknown system noise of\narbitrary form. Simulations show that the HRDF delivers superior tracking\nperformance over filters using sequential Monte Carlo and parametric modeling.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Kailai Li",
      "Florian Pfaff",
      "Uwe D. Hanebeck"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.10411"
  },
  {
    "id": "arXiv:2110.10441",
    "title": "Feedback Linearization of Car Dynamics for Racing via Reinforcement  Learning",
    "abstract": "Through the method of Learning Feedback Linearization, we seek to learn a\nlinearizing controller to simplify the process of controlling a car to race\nautonomously. A soft actor-critic approach is used to learn a decoupling matrix\nand drift vector that effectively correct for errors in a hand-designed\nlinearizing controller. The result is an exactly linearizing controller that\ncan be used to enable the well-developed theory of linear systems to design\npath planning and tracking schemes that are easy to implement and significantly\nless computationally demanding. To demonstrate the method of feedback\nlinearization, it is first used to learn a simulated model whose exact\nstructure is known, but varied from the initial controller, so as to introduce\nerror. We further seek to apply this method to a system that introduces even\nmore error in the form of a gym environment specifically designed for modeling\nthe dynamics of car racing. To do so, we posit an extension to the method of\nlearning feedback linearization; a neural network that is trained using\nsupervised learning to convert the output of our linearizing controller to the\nrequired input for the racing environment. Our progress towards these goals is\nreported and the next steps in their accomplishment are discussed.",
    "descriptor": "\nComments: Final research paper for Berkeley's CS 285 (Deep Reinforcement Learning) in Fall 2020\n",
    "authors": [
      "Michael Estrada",
      "Sida Li",
      "Xiangyu Cai"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.10441"
  },
  {
    "id": "arXiv:2110.10489",
    "title": "Evaluation of augmentation methods in classifying autism spectrum  disorders from fMRI data with 3D convolutional neural networks",
    "abstract": "Classifying subjects as healthy or diseased using neuroimaging data has\ngained a lot of attention during the last 10 years. Here we apply deep learning\nto derivatives from resting state fMRI data, and investigate how different 3D\naugmentation techniques affect the test accuracy. Specifically, we use resting\nstate derivatives from 1,112 subjects in ABIDE preprocessed to train a 3D\nconvolutional neural network (CNN) to perform the classification. Our results\nshow that augmentation only provide minor improvements to the test accuracy.",
    "descriptor": "",
    "authors": [
      "Johan J\u00f6nemo",
      "David Abramian",
      "Anders Eklund"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2110.10489"
  },
  {
    "id": "arXiv:2110.10498",
    "title": "Differential Privacy in Multi-Party Resource Sharing",
    "abstract": "This study examines a resource-sharing problem involving multiple parties\nthat agree to use a set of capacities together. We start with modeling the\nwhole problem as a mathematical program, where all parties are required to\nexchange information to obtain the optimal objective function value. This\ninformation bears private data from each party in terms of coefficients used in\nthe mathematical program. Moreover, the parties also consider the individual\noptimal solutions as private. In this setting, the concern for the parties is\nthe privacy of their data and their optimal allocations. We propose a two-step\napproach to meet the privacy requirements of the parties. In the first step, we\nobtain a reformulated model that is amenable to a decomposition scheme.\nAlthough this scheme eliminates almost all data exchange, it does not provide a\nformal privacy guarantee. In the second step, we provide this guarantee with a\ndifferentially private algorithm at the expense of deviating slightly from the\noptimality. We provide bounds on this deviation and discuss the consequences of\nthese theoretical results. The study ends with a simulation study on a planning\nproblem that demonstrates an application of the proposed approach. Our work\nprovides a new optimization model and a solution approach for optimal\nallocation of a set of shared resources among multiple parties who expect\nprivacy of their data. The proposed approach is based on the decomposition of\nthe shared resources and the randomization of the optimization iterations. With\nour analysis, we show that the resulting randomized algorithm does give a\nguarantee for the privacy of each party's data. As we work with a general\noptimization model, our analysis and discussion can be used in different\napplication areas including production planning, logistics, and network revenue\nmanagement.",
    "descriptor": "",
    "authors": [
      "Utku Karaca",
      "S. Ilker Birbil",
      "Nursen Aydin",
      "Gizem Mullaoglu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.10498"
  },
  {
    "id": "arXiv:2110.10518",
    "title": "Online non-parametric change-point detection for heterogeneous data  streams observed over graph nodes",
    "abstract": "Consider a heterogeneous data stream being generated by the nodes of a graph.\nThe data stream is in essence composed by multiple streams, possibly of\ndifferent nature that depends on each node. At a given moment $\\tau$, a\nchange-point occurs for a subset of nodes $C$, signifying the change in the\nprobability distribution of their associated streams. In this paper we propose\nan online non-parametric method to infer $\\tau$ based on the direct estimation\nof the likelihood-ratio between the post-change and the pre-change distribution\nassociated with the data stream of each node. We propose a kernel-based method,\nunder the hypothesis that connected nodes of the graph are expected to have\nsimilar likelihood-ratio estimates when there is no change-point. We\ndemonstrate the quality of our method on synthetic experiments and real-world\napplications.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Alejandro de la Concha",
      "Argyris Kalogeratos",
      "Nicolas Vayatis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10518"
  },
  {
    "id": "arXiv:2110.10520",
    "title": "Development and accuracy evaluation of Coded Phase-shift 3D scanner",
    "abstract": "In this paper, we provide an overview of development of a structured light\n3D-scanner based on combination of binary-coded patterns and sinusoidal\nphase-shifted fringe patterns called Coded Phase-shift technique. Further, we\ndescribe the experiments performed to evaluate measurement accuracy and\nprecision of the developed system. A study of this kind is expected to be\nhelpful in understanding the basic working of current structured-light 3D\nscanners and the approaches followed for their performance assessment.",
    "descriptor": "",
    "authors": [
      "Pranav Kant Gaur",
      "D.M.Sarode",
      "S.K.Bose"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10520"
  },
  {
    "id": "arXiv:2110.10530",
    "title": "Improved pyrotechnics : Closer to the burning graph conjecture",
    "abstract": "Can every connected graph burn in $\\lceil \\sqrt{n} \\rceil $ steps? While this\nconjecture remains open, we prove that it is asymptotically true when the graph\nis much larger than its \\emph{growth}, which is the maximal distance of a\nvertex to a well-chosen path in the graph. In fact, we prove that the\nconjecture for graphs of bounded growth boils down to a finite number of cases.\nThrough an improved (but still weaker) bound for all trees, we argue that the\nconjecture almost holds for all graphs with minimum degree at least $3$ and\nholds for all large enough graphs with minimum degree at least $4$. The\nprevious best lower bound was $23$.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Paul Bastide",
      "Marthe Bonamy",
      "Pierre Charbit",
      "Th\u00e9o Pierron",
      "Mika\u00ebl Rabie"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.10530"
  },
  {
    "id": "arXiv:2110.10557",
    "title": "Analytic Correlation of Inflationary Potential to Power Spectrum Shape:  Limits of Validity, and `No-Go' for Small Field Model Analytics",
    "abstract": "The primordial power spectrum informs the possible inflationary histories of\nour universe. Given a power spectrum, the ensuing cosmic microwave background\nis calculated and compared to the observed one. Thus, one focus of modern\ncosmology is building well-motivated inflationary models that predict the\nprimordial power spectrum observables. The common practice uses analytic terms\nfor the scalar spectral index $n_s$ and the index running $\\alpha$, forgoing\nthe effort required to evaluate the model numerically. However, the validity of\nthese terms has never been rigorously probed and relies on perturbative\nmethods, which may lose their efficacy for large perturbations. The requirement\nfor more accurate theoretical predictions becomes crucial with the advent of\nhighly sensitive measuring instruments. This paper probes the limits of the\nperturbative treatment that connects inflationary potential parameters to\nprimordial power spectrum observables. We show that the validity of analytic\napproximations of the scalar index roughly respects the large-field/small-field\ndichotomy. We supply an easily calculated measure for relative perturbation\namplitude and show that, for large field models, the validity of analytical\nterms extends to $\\sim 3\\%$ perturbation relative to a power-law inflation\nmodel. Conversely, the analytical treatment loses its validity for small-field\nmodels with as little as $0.1\\%$ perturbation relative to the small-field\ntest-case. By employing the most general artificial neural networks and\nmultinomial functions up to the twentieth degree and demonstrating their\nshortcomings, we show that no reasonable analytic expressions correlating small\nfield models to the observables the yield exists. Finally, we discuss the\npossible implications of this work and supply the validity heuristic for large\nand small field models.",
    "descriptor": "\nComments: 20 pages, 13 figures, 2 tables. COde package INSANE will be made public shortly\n",
    "authors": [
      "Ira Wolfson"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.10557"
  },
  {
    "id": "arXiv:2110.10587",
    "title": "Quantum networks theory",
    "abstract": "The formalism of quantum theory over discrete systems is extended in two\nsignificant ways. First, tensors and traceouts are generalized, so that systems\ncan be partitioned according to almost arbitrary logical predicates. Second,\nquantum evolutions are generalized to act over network configurations, in such\na way that nodes be allowed to merge, split and reconnect coherently in a\nsuperposition. The hereby presented mathematical framework is anchored on solid\ngrounds through numerous lemmas. Indeed, one might have feared that the\nfamiliar interrelations between the notions of unitarity, complete positivity,\ntrace-preservation, non-signalling causality, locality and localizability that\nare standard in quantum theory be jeopardized as the partitioning of systems\nbecomes both logical and dynamical. Such interrelations in fact carry through,\nalbeit two new notions become instrumental: consistency and comprehension.",
    "descriptor": "\nComments: 41 pages, 10 figures\n",
    "authors": [
      "Pablo Arrighi",
      "Am\u00e9lia Durbec",
      "Matt Wilson"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Mathematical Physics (math-ph)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.10587"
  },
  {
    "id": "arXiv:2110.10640",
    "title": "OSS-Net: Memory Efficient High Resolution Semantic Segmentation of 3D  Medical Data",
    "abstract": "Convolutional neural networks (CNNs) are the current state-of-the-art\nmeta-algorithm for volumetric segmentation of medical data, for example, to\nlocalize COVID-19 infected tissue on computer tomography scans or the detection\nof tumour volumes in magnetic resonance imaging. A key limitation of 3D CNNs on\nvoxelised data is that the memory consumption grows cubically with the training\ndata resolution. Occupancy networks (O-Nets) are an alternative for which the\ndata is represented continuously in a function space and 3D shapes are learned\nas a continuous decision boundary. While O-Nets are significantly more memory\nefficient than 3D CNNs, they are limited to simple shapes, are relatively slow\nat inference, and have not yet been adapted for 3D semantic segmentation of\nmedical data. Here, we propose Occupancy Networks for Semantic Segmentation\n(OSS-Nets) to accurately and memory-efficiently segment 3D medical data. We\nbuild upon the original O-Net with modifications for increased expressiveness\nleading to improved segmentation performance comparable to 3D CNNs, as well as\nmodifications for faster inference. We leverage local observations to represent\ncomplex shapes and prior encoder predictions to expedite inference. We showcase\nOSS-Net's performance on 3D brain tumour and liver segmentation against a\nfunction space baseline (O-Net), a performance baseline (3D residual U-Net),\nand an efficiency baseline (2D residual U-Net). OSS-Net yields segmentation\nresults similar to the performance baseline and superior to the function space\nand efficiency baselines. In terms of memory efficiency, OSS-Net consumes\ncomparable amounts of memory as the function space baseline, somewhat more\nmemory than the efficiency baseline and significantly less than the performance\nbaseline. As such, OSS-Net enables memory-efficient and accurate 3D semantic\nsegmentation that can scale to high resolutions.",
    "descriptor": "\nComments: BMVC 2021 (accepted), this https URL (code)\n",
    "authors": [
      "Christoph Reich",
      "Tim Prangemeier",
      "\u00d6zdemir Cetin",
      "Heinz Koeppl"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10640"
  },
  {
    "id": "arXiv:2110.10645",
    "title": "Combining Different V1 Brain Model Variants to Improve Robustness to  Image Corruptions in CNNs",
    "abstract": "While some convolutional neural networks (CNNs) have surpassed human visual\nabilities in object classification, they often struggle to recognize objects in\nimages corrupted with different types of common noise patterns, highlighting a\nmajor limitation of this family of models. Recently, it has been shown that\nsimulating a primary visual cortex (V1) at the front of CNNs leads to small\nimprovements in robustness to these image perturbations. In this study, we\nstart with the observation that different variants of the V1 model show gains\nfor specific corruption types. We then build a new model using an ensembling\ntechnique, which combines multiple individual models with different V1\nfront-end variants. The model ensemble leverages the strengths of each\nindividual model, leading to significant improvements in robustness across all\ncorruption categories and outperforming the base model by 38% on average.\nFinally, we show that using distillation, it is possible to partially compress\nthe knowledge in the ensemble model into a single model with a V1 front-end.\nWhile the ensembling and distillation techniques used here are hardly\nbiologically-plausible, the results presented here demonstrate that by\ncombining the specific strengths of different neuronal circuits in V1 it is\npossible to improve the robustness of CNNs for a wide range of perturbations.",
    "descriptor": "\nComments: 15 pages with supplementary material, 3 main figures, 2 supplementary figures, 4 supplementary tables\n",
    "authors": [
      "Avinash Baidya",
      "Joel Dapello",
      "James J. DiCarlo",
      "Tiago Marques"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2110.10645"
  },
  {
    "id": "arXiv:2110.10671",
    "title": "Adaptive Gradient Descent for Optimal Control of Parabolic Equations  with Random Parameters",
    "abstract": "In this paper we extend the adaptive gradient descent (AdaGrad) algorithm to\nthe optimal distributed control of parabolic partial differential equations\nwith uncertain parameters. This stochastic optimization method achieves an\nimproved convergence rate through adaptive scaling of the gradient step size.\nWe prove the convergence of the algorithm for this infinite dimensional problem\nunder suitable regularity, convexity, and finite variance conditions, and\nrelate these to verifiable properties of the underlying system parameters.\nFinally, we apply our algorithm to the optimal thermal regulation of lithium\nbattery systems under uncertain loads.",
    "descriptor": "",
    "authors": [
      "Yanzhao Cao",
      "Somak Das",
      "Hans-Werner van Wyk"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.10671"
  },
  {
    "id": "arXiv:2110.10685",
    "title": "Predicting parameters for the Quantum Approximate Optimization Algorithm  for MAX-CUT from the infinite-size limit",
    "abstract": "Combinatorial optimization is regarded as a potentially promising application\nof near and long-term quantum computers. The best-known heuristic quantum\nalgorithm for combinatorial optimization on gate-based devices, the Quantum\nApproximate Optimization Algorithm (QAOA), has been the subject of many\ntheoretical and empirical studies. Unfortunately, its application to specific\ncombinatorial optimization problems poses several difficulties: among these,\nfew performance guarantees are known, and the variational nature of the\nalgorithm makes it necessary to classically optimize a number of parameters. In\nthis work, we partially address these issues for a specific combinatorial\noptimization problem: diluted spin models, with MAX-CUT as a notable special\ncase. Specifically, generalizing the analysis of the Sherrington-Kirkpatrick\nmodel by Farhi et al., we establish an explicit algorithm to evaluate the\nperformance of QAOA on MAX-CUT applied to random Erdos-Renyi graphs of expected\ndegree $d$ for an arbitrary constant number of layers $p$ and as the problem\nsize tends to infinity. This analysis yields an explicit mapping between QAOA\nparameters for MAX-CUT on Erdos-Renyi graphs of expected degree $d$, in the\nlimit $d \\to \\infty$, and the Sherrington-Kirkpatrick model, and gives good\nQAOA variational parameters for MAX-CUT applied to Erdos-Renyi graphs. We then\npartially generalize the latter analysis to graphs with a degree distribution\nrather than a single degree $d$, and finally to diluted spin-models with\n$D$-body interactions ($D \\geq 3$). We validate our results with numerical\nexperiments suggesting they may have a larger reach than rigorously\nestablished; among other things, our algorithms provided good initial, if not\nnearly optimal, variational parameters for very small problem instances where\nthe infinite-size limit assumption is clearly violated.",
    "descriptor": "\nComments: 59 pages, 8 figures\n",
    "authors": [
      "Sami Boulebnane",
      "Ashley Montanaro"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.10685"
  },
  {
    "id": "arXiv:2110.10701",
    "title": "Optimizing Strongly Interacting Fermionic Hamiltonians",
    "abstract": "The fundamental problem in much of physics and quantum chemistry is to\noptimize a low-degree polynomial in certain anticommuting variables. Being a\nquantum mechanical problem, in many cases we do not know an efficient classical\nwitness to the optimum, or even to an approximation of the optimum. One\nprominent exception is when the optimum is described by a so-called \"Gaussian\nstate\", also called a free fermion state. In this work we are interested in the\ncomplexity of this optimization problem when no good Gaussian state exists. Our\nprimary testbed is the Sachdev--Ye--Kitaev (SYK) model of random degree-$q$\npolynomials, a model of great current interest in condensed matter physics and\nstring theory, and one which has remarkable properties from a computational\ncomplexity standpoint. Among other results, we give an efficient classical\ncertification algorithm for upper-bounding the largest eigenvalue in the $q=4$\nSYK model, and an efficient quantum certification algorithm for lower-bounding\nthis largest eigenvalue; both algorithms achieve constant-factor approximations\nwith high probability.",
    "descriptor": "\nComments: 48 pages, 0 figures\n",
    "authors": [
      "Matthew B. Hastings",
      "Ryan O'Donnell"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Computational Complexity (cs.CC)",
      "High Energy Physics - Theory (hep-th)"
    ],
    "url": "https://arxiv.org/abs/2110.10701"
  },
  {
    "id": "arXiv:2110.10709",
    "title": "Predicting Tau Accumulation in Cerebral Cortex with Multivariate MRI  Morphometry Measurements, Sparse Coding, and Correntropy",
    "abstract": "Biomarker-assisted diagnosis and intervention in Alzheimer's disease (AD) may\nbe the key to prevention breakthroughs. One of the hallmarks of AD is the\naccumulation of tau plaques in the human brain. However, current methods to\ndetect tau pathology are either invasive (lumbar puncture) or quite costly and\nnot widely available (Tau PET). In our previous work, structural MRI-based\nhippocampal multivariate morphometry statistics (MMS) showed superior\nperformance as an effective neurodegenerative biomarker for preclinical AD and\nPatch Analysis-based Surface Correntropy-induced Sparse coding and max-pooling\n(PASCS-MP) has excellent ability to generate low-dimensional representations\nwith strong statistical power for brain amyloid prediction. In this work, we\napply this framework together with ridge regression models to predict Tau\ndeposition in Braak12 and Braak34 brain regions separately. We evaluate our\nframework on 925 subjects from the Alzheimer's Disease Neuroimaging Initiative\n(ADNI). Each subject has one pair consisting of a PET image and MRI scan which\nwere collected at about the same times. Experimental results suggest that the\nrepresentations from our MMS and PASCS-MP have stronger predictive power and\ntheir predicted Braak12 and Braak34 are closer to the real values compared to\nthe measures derived from other approaches such as hippocampal surface area and\nvolume, and shape morphometry features based on spherical harmonics (SPHARM).",
    "descriptor": "\nComments: 10 pages, 5 figures, 17th International Symposium on Medical Information Processing and Analysis\n",
    "authors": [
      "Jianfeng Wu",
      "Wenhui Zhu",
      "Yi Su",
      "Jie Gui",
      "Natasha Lepore",
      "Eric M. Reiman",
      "Richard J. Caselli",
      "Paul M. Thompson",
      "Kewei Chen",
      "Yalin Wang"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.10709"
  },
  {
    "id": "arXiv:2110.10710",
    "title": "Stochastic Learning Rate Optimization in the Stochastic Approximation  and Online Learning Settings",
    "abstract": "In this work, multiplicative stochasticity is applied to the learning rate of\nstochastic optimization algorithms, giving rise to stochastic learning-rate\nschemes. In-expectation theoretical convergence results of Stochastic Gradient\nDescent equipped with this novel stochastic learning rate scheme under the\nstochastic setting, as well as convergence results under the online\noptimization settings are provided. Empirical results consider the case of an\nadaptively uniformly distributed multiplicative stochasticity and include not\nonly Stochastic Gradient Descent, but also other popular algorithms equipped\nwith a stochastic learning rate. They demonstrate noticeable optimization\nperformance gains, with respect to their deterministic-learning-rate versions.",
    "descriptor": "",
    "authors": [
      "Theodoros Mamalis",
      "Dusan Stipanovic",
      "Petros Voulgaris"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10710"
  },
  {
    "id": "arXiv:2110.10721",
    "title": "Learning quantum dynamics with latent neural ODEs",
    "abstract": "The core objective of machine-assisted scientific discovery is to learn\nphysical laws from experimental data without prior knowledge of the systems in\nquestion. In the area of quantum physics, making progress towards these goals\nis significantly more challenging due to the curse of dimensionality as well as\nthe counter-intuitive nature of quantum mechanics. Here, we present the QNODE,\na latent neural ODE trained on dynamics from closed and open quantum systems.\nThe QNODE can learn to generate quantum dynamics and extrapolate outside of its\ntraining region that satisfy the von Neumann and time-local Lindblad master\nequations for closed and open quantum systems. Furthermore the QNODE\nrediscovers quantum mechanical laws such as Heisenberg's uncertainty principle\nin a totally data-driven way, without constraints or guidance. Additionally, we\nshow that trajectories that are generated from the QNODE and are close in its\nlatent space have similar quantum dynamics while preserving the physics of the\ntraining system.",
    "descriptor": "",
    "authors": [
      "Matthew Choi",
      "Daniel Flam-Shepherd",
      "Thi Ha Kyaw",
      "Al\u00e1n Aspuru-Guzik"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10721"
  },
  {
    "id": "arXiv:2110.10724",
    "title": "Semi-supervised physics guided DL framework for predicting the I-V  characteristics of GAN HEMT",
    "abstract": "This letter proposes a novel deep learning framework (DLF) that addresses two\nmajor hurdles in the adoption of deep learning techniques for solving\nphysics-based problems: 1) requirement of the large dataset for training the DL\nmodel, 2) consistency of the DL model with the physics of the phenomenon. The\nframework is generic in nature and can be applied to model a phenomenon from\nother fields of research too as long as its behaviour is known. To demonstrate\nthe technique, a semi-supervised physics guided neural network (SPGNN) has been\ndeveloped that predicts I-V characteristics of a gallium nitride-based high\nelectron mobility transistor (GaN HEMT). A two-stage training method is\nproposed, where in the first stage, the DL model is trained via the\nunsupervised learning method using the I-V equations of a field-effect\ntransistor as a loss function of the model that incorporates physical behaviors\nin the DL model and in the second stage, the DL model has been fine-tuned with\na very small set of experimental data. The SPGNN significantly reduces the\nrequirement of the training data by more than 80% for achieving similar or\nbetter performance than a traditional neural network (TNN) even for unseen\nconditions. The SPGNN predicts 32.4% of the unseen test data with less than 1%\nof error and only 0.4% of the unseen test data with more than 10% of error.",
    "descriptor": "",
    "authors": [
      "Shivanshu Mishra",
      "Bipin Gaikwad",
      "Nidhi Chaturvedi"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10724"
  },
  {
    "id": "arXiv:2110.10740",
    "title": "Log-concave poset inequalities",
    "abstract": "We study combinatorial inequalities for various classes of set systems:\nmatroids, polymatroids, poset antimatroids, and interval greedoids. We prove\nlog-concavity inequalities for counting certain weighted feasible words, which\ngeneralize and extend several previous results establishing Mason conjectures\nfor the numbers of independent sets of matroids. Notably, we prove matching\nequality conditions for both earlier inequalities and our extensions.\nIn contrast with much of the previous work, our proofs are combinatorial and\nemploy nothing but linear algebra. We use the language formulation of greedoids\nwhich allows a linear algebraic setup, which in turn can be analyzed\nrecursively. The underlying non-commutative nature of matrices associated with\ngreedoids allows us to proceed beyond polymatroids and prove the equality\nconditions. As further application of our tools, we rederive both Stanley's\ninequality on the number of certain linear extensions, and its equality\nconditions, which we then also extend to the weighted case.",
    "descriptor": "\nComments: 71 pages, 4 figures\n",
    "authors": [
      "Swee Hong Chan",
      "Igor Pak"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.10740"
  },
  {
    "id": "arXiv:2110.10745",
    "title": "Iterated Block Particle Filter for High-dimensional Parameter Learning:  Beating the Curse of Dimensionality",
    "abstract": "Parameter learning for high-dimensional, partially observed, and nonlinear\nstochastic processes is a methodological challenge. Spatiotemporal disease\ntransmission systems provide examples of such processes giving rise to open\ninference problems. We propose the iterated block particle filter (IBPF)\nalgorithm for learning high-dimensional parameters over graphical state space\nmodels with general state spaces, measures, transition densities and graph\nstructure. Theoretical performance guarantees are obtained on beating the curse\nof dimensionality (COD), algorithm convergence, and likelihood maximization.\nExperiments on a highly nonlinear and non-Gaussian spatiotemporal model for\nmeasles transmission reveal that the iterated ensemble Kalman filter algorithm\n(Li et al. (2020)) is ineffective and the iterated filtering algorithm (Ionides\net al. (2015)) suffers from the COD, while our IBPF algorithm beats COD\nconsistently across various experiments with different metrics.",
    "descriptor": "",
    "authors": [
      "Ning Ning",
      "Edward L. Ionides"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Applications (stat.AP)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.10745"
  },
  {
    "id": "arXiv:2110.10755",
    "title": "Toward Real-world Image Super-resolution via Hardware-based Adaptive  Degradation Models",
    "abstract": "Most single image super-resolution (SR) methods are developed on synthetic\nlow-resolution (LR) and high-resolution (HR) image pairs, which are simulated\nby a predetermined degradation operation, e.g., bicubic downsampling. However,\nthese methods only learn the inverse process of the predetermined operation, so\nthey fail to super resolve the real-world LR images; the true formulation\ndeviates from the predetermined operation. To address this problem, we propose\na novel supervised method to simulate an unknown degradation process with the\ninclusion of the prior hardware knowledge of the imaging system. We design an\nadaptive blurring layer (ABL) in the supervised learning framework to estimate\nthe target LR images. The hyperparameters of the ABL can be adjusted for\ndifferent imaging hardware. The experiments on the real-world datasets validate\nthat our degradation model can estimate LR images more accurately than the\npredetermined degradation operation, as well as facilitate existing SR methods\nto perform reconstructions on real-world LR images more accurately than the\nconventional approaches.",
    "descriptor": "",
    "authors": [
      "Rui Ma",
      "Johnathan Czernik",
      "Xian Du"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10755"
  },
  {
    "id": "arXiv:2110.10756",
    "title": "Ambiguities in Direction-of-Arrival Estimation with Linear Arrays",
    "abstract": "In this paper, we present a novel approach to compute ambiguities in thinned\nuniform linear arrays, i.e., sparse non-uniform linear arrays, via a\nmixed-integer program. Ambiguities arise when there exists a set of distinct\ndirections-of-arrival, for which the corresponding steering matrix is\nrank-deficient and are associated with nonunique parameter estimation. Our\napproach uses Young tableaux for which a submatrix of the steering matrix has a\nvanishing determinant, which can be expressed through vanishing sums of unit\nroots. Each of these vanishing sums then corresponds to an ambiguous set of\ndirections-of-arrival. We derive a method to enumerate such ambiguous sets\nusing a mixed-integer program and present results on several examples.",
    "descriptor": "",
    "authors": [
      "Frederic Matter",
      "Tobias Fischer",
      "Marius Pesavento",
      "Marc E. Pfetsch"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.10756"
  },
  {
    "id": "arXiv:2110.10770",
    "title": "Pick-and-Mix Information Operators for Probabilistic ODE Solvers",
    "abstract": "Probabilistic numerical solvers for ordinary differential equations compute\nposterior distributions over the solution of an initial value problem via\nBayesian inference. In this paper, we leverage their probabilistic formulation\nto seamlessly include additional information as general likelihood terms. We\nshow that second-order differential equations should be directly provided to\nthe solver, instead of transforming the problem to first order. Additionally,\nby including higher-order information or physical conservation laws in the\nmodel, solutions become more accurate and more physically meaningful. Lastly,\nwe demonstrate the utility of flexible information operators by solving\ndifferential-algebraic equations. In conclusion, the probabilistic formulation\nof numerical solvers offers a flexible way to incorporate various types of\ninformation, thus improving the resulting solutions.",
    "descriptor": "\nComments: 13 pages, 7 figures\n",
    "authors": [
      "Nathanael Bosch",
      "Filip Tronarp",
      "Philipp Hennig"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.10770"
  },
  {
    "id": "arXiv:2110.10783",
    "title": "Adversarial attacks against Bayesian forecasting dynamic models",
    "abstract": "The last decade has seen the rise of Adversarial Machine Learning (AML). This\ndiscipline studies how to manipulate data to fool inference engines, and how to\nprotect those systems against such manipulation attacks. Extensive work on\nattacks against regression and classification systems is available, while\nlittle attention has been paid to attacks against time series forecasting\nsystems. In this paper, we propose a decision analysis based attacking strategy\nthat could be utilized against Bayesian forecasting dynamic models.",
    "descriptor": "",
    "authors": [
      "Roi Naveiro"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10783"
  },
  {
    "id": "arXiv:2110.10804",
    "title": "Identifiable Variational Autoencoders via Sparse Decoding",
    "abstract": "We develop the Sparse VAE, a deep generative model for unsupervised\nrepresentation learning on high-dimensional data. Given a dataset of\nobservations, the Sparse VAE learns a set of latent factors that captures its\ndistribution. The model is sparse in the sense that each feature of the dataset\n(i.e., each dimension) depends on a small subset of the latent factors. As\nexamples, in ratings data each movie is only described by a few genres; in text\ndata each word is only applicable to a few topics; in genomics, each gene is\nactive in only a few biological processes. We first show that the Sparse VAE is\nidentifiable: given data drawn from the model, there exists a uniquely optimal\nset of factors. (In contrast, most VAE-based models are not identifiable.) The\nkey assumption behind Sparse-VAE identifiability is the existence of \"anchor\nfeatures\", where for each factor there exists a feature that depends only on\nthat factor. Importantly, the anchor features do not need to be known in\nadvance. We then show how to fit the Sparse VAE with variational EM. Finally,\nwe empirically study the Sparse VAE with both simulated and real data. We find\nthat it recovers meaningful latent factors and has smaller heldout\nreconstruction error than related methods.",
    "descriptor": "",
    "authors": [
      "Gemma E. Moran",
      "Dhanya Sridhar",
      "Yixin Wang",
      "David M. Blei"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.10804"
  },
  {
    "id": "arXiv:2110.10812",
    "title": "REAL-M: Towards Speech Separation on Real Mixtures",
    "abstract": "In recent years, deep learning based source separation has achieved\nimpressive results. Most studies, however, still evaluate separation models on\nsynthetic datasets, while the performance of state-of-the-art techniques on\nin-the-wild speech data remains an open question. This paper contributes to\nfill this gap in two ways. First, we release the REAL-M dataset, a\ncrowd-sourced corpus of real-life mixtures. Secondly, we address the problem of\nperformance evaluation of real-life mixtures, where the ground truth is not\navailable. We bypass this issue by carefully designing a blind Scale-Invariant\nSignal-to-Noise Ratio (SI-SNR) neural estimator. Through a user study, we show\nthat our estimator reliably evaluates the separation performance on real\nmixtures. The performance predictions of the SI-SNR estimator indeed correlate\nwell with human opinions. Moreover, we observe that the performance trends\npredicted by our estimator on the REAL-M dataset closely follow those achieved\non synthetic benchmarks when evaluating popular speech separation models.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Cem Subakan",
      "Mirco Ravanelli",
      "Samuele Cornell",
      "Fran\u00e7ois Grondin"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.10812"
  },
  {
    "id": "arXiv:2110.10813",
    "title": "CXR-Net: An Encoder-Decoder-Encoder Multitask Deep Neural Network for  Explainable and Accurate Diagnosis of COVID-19 pneumonia with Chest X-ray  Images",
    "abstract": "Accurate and rapid detection of COVID-19 pneumonia is crucial for optimal\npatient treatment. Chest X-Ray (CXR) is the first line imaging test for\nCOVID-19 pneumonia diagnosis as it is fast, cheap and easily accessible.\nInspired by the success of deep learning (DL) in computer vision, many\nDL-models have been proposed to detect COVID-19 pneumonia using CXR images.\nUnfortunately, these deep classifiers lack the transparency in interpreting\nfindings, which may limit their applications in clinical practice. The existing\ncommonly used visual explanation methods are either too noisy or imprecise,\nwith low resolution, and hence are unsuitable for diagnostic purposes. In this\nwork, we propose a novel explainable deep learning framework (CXRNet) for\naccurate COVID-19 pneumonia detection with an enhanced pixel-level visual\nexplanation from CXR images. The proposed framework is based on a new\nEncoder-Decoder-Encoder multitask architecture, allowing for both disease\nclassification and visual explanation. The method has been evaluated on real\nworld CXR datasets from both public and private data sources, including:\nhealthy, bacterial pneumonia, viral pneumonia and COVID-19 pneumonia cases The\nexperimental results demonstrate that the proposed method can achieve a\nsatisfactory level of accuracy and provide fine-resolution classification\nactivation maps for visual explanation in lung disease detection. The Average\nAccuracy, the Precision, Recall and F1-score of COVID-19 pneumonia reached\n0.879, 0.985, 0.992 and 0.989, respectively. We have also found that using lung\nsegmented (CXR) images can help improve the performance of the model. The\nproposed method can provide more detailed high resolution visual explanation\nfor the classification decision, compared to current state-of-the-art visual\nexplanation methods and has a great potential to be used in clinical practice\nfor COVID-19 pneumonia diagnosis.",
    "descriptor": "",
    "authors": [
      "Xin Zhang",
      "Liangxiu Han",
      "Tam Sobeih",
      "Lianghao Han",
      "Nina Dempsey",
      "Symeon Lechareas",
      "Ascanio Tridente",
      "Haoming Chen",
      "Stephen White"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10813"
  },
  {
    "id": "arXiv:2110.10817",
    "title": "The R package sentometrics to compute, aggregate and predict with  textual sentiment",
    "abstract": "We provide a hands-on introduction to optimized textual sentiment indexation\nusing the R package sentometrics. Textual sentiment analysis is increasingly\nused to unlock the potential information value of textual data. The\nsentometrics package implements an intuitive framework to efficiently compute\nsentiment scores of numerous texts, to aggregate the scores into multiple time\nseries, and to use these time series to predict other variables. The workflow\nof the package is illustrated with a built-in corpus of news articles from two\nmajor U.S. journals to forecast the CBOE Volatility Index.",
    "descriptor": "",
    "authors": [
      "David Ardia",
      "Keven Bluteau",
      "Samuel Borms",
      "Kris Boudt"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.10817"
  },
  {
    "id": "arXiv:2110.10888",
    "title": "Evaluation of Various Open-Set Medical Imaging Tasks with Deep Neural  Networks",
    "abstract": "The current generation of deep neural networks has achieved close-to-human\nresults on \"closed-set\" image recognition; that is, the classes being evaluated\noverlap with the training classes. Many recent methods attempt to address the\nimportance of the unknown, which are termed \"open-set\" recognition algorithms,\ntry to reject unknown classes as well as maintain high recognition accuracy on\nknown classes. However, it is still unclear how different general\ndomain-trained open-set methods from ImageNet would perform on a different but\nmore specific domain, such as the medical domain. Without principled and formal\nevaluations to measure the effectiveness of those general open-set methods,\nartificial intelligence (AI)-based medical diagnostics would experience\nineffective adoption and increased risks of bad decision making. In this paper,\nwe conduct rigorous evaluations amongst state-of-the-art open-set methods,\nexploring different open-set scenarios from \"similar-domain\" to\n\"different-domain\" scenarios and comparing them on various general and medical\ndomain datasets. We summarise the results and core ideas and explain how the\nmodels react to various degrees of openness and different distributions of open\nclasses. We show the main difference between general domain-trained and medical\ndomain-trained open-set models with our quantitative and qualitative analysis\nof the results. We also identify aspects of model robustness in real clinical\nworkflow usage according to confidence calibration and the inference\nefficiency.",
    "descriptor": "",
    "authors": [
      "Zongyuan Ge",
      "Xin Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10888"
  },
  {
    "id": "arXiv:2110.10890",
    "title": "Physics-Based Models for Magneto-Electric Spin-Orbit Logic Circuits",
    "abstract": "Spintronic devices are a promising beyond-CMOS device option thanks to their\nenergy efficiency and compatibility with CMOS. To accurately capture their\nmulti-physics dynamics, a rigorous treatment of both spin and charge and their\ninter-conversion is required. Here we present physics-based device models based\non 4x4 matrices for the spin-orbit coupling part of the magneto-electric\nspin-orbit (MESO) device. Also, a more rigorous physics model of ferroelectric\nand magnetoelectric switching of ferromagnets, based on Landau-Lifshitz-Gilbert\n(LLG) and Landau-Khalatnikov (LK) equations, is presented. With the combined\nmodel implemented in a SPICE circuit simulator environment, simulation results\nwere obtained which show feasibility of MESO implementation and functional\noperation of buffers, oscillators, and majority gates.",
    "descriptor": "\nComments: 11 pages, 21 figures\n",
    "authors": [
      "Hai Li",
      "Dmitri E. Nikonov",
      "Chia-Ching Lin",
      "Kerem Camsari",
      "Yu-Ching Liao",
      "Chia-Sheng Hsu",
      "Azad Naeemi",
      "Ian A. Young"
    ],
    "subjectives": [
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Emerging Technologies (cs.ET)",
      "Applied Physics (physics.app-ph)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.10890"
  },
  {
    "id": "arXiv:2110.10956",
    "title": "Data splitting improves statistical performance in overparametrized  regimes",
    "abstract": "While large training datasets generally offer improvement in model\nperformance, the training process becomes computationally expensive and time\nconsuming. Distributed learning is a common strategy to reduce the overall\ntraining time by exploiting multiple computing devices. Recently, it has been\nobserved in the single machine setting that overparametrization is essential\nfor benign overfitting in ridgeless regression in Hilbert spaces. We show that\nin this regime, data splitting has a regularizing effect, hence improving\nstatistical performance and computational complexity at the same time. We\nfurther provide a unified framework that allows to analyze both the finite and\ninfinite dimensional setting. We numerically demonstrate the effect of\ndifferent model parameters.",
    "descriptor": "",
    "authors": [
      "Nicole M\u00fccke",
      "Enrico Reiss",
      "Jonas Rungenhagen",
      "Markus Klein"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10956"
  },
  {
    "id": "arXiv:2110.10965",
    "title": "2020 CATARACTS Semantic Segmentation Challenge",
    "abstract": "Surgical scene segmentation is essential for anatomy and instrument\nlocalization which can be further used to assess tissue-instrument interactions\nduring a surgical procedure. In 2017, the Challenge on Automatic Tool\nAnnotation for cataRACT Surgery (CATARACTS) released 50 cataract surgery videos\naccompanied by instrument usage annotations. These annotations included\nframe-level instrument presence information. In 2020, we released pixel-wise\nsemantic annotations for anatomy and instruments for 4670 images sampled from\n25 videos of the CATARACTS training set. The 2020 CATARACTS Semantic\nSegmentation Challenge, which was a sub-challenge of the 2020 MICCAI Endoscopic\nVision (EndoVis) Challenge, presented three sub-tasks to assess participating\nsolutions on anatomical structure and instrument segmentation. Their\nperformance was assessed on a hidden test set of 531 images from 10 videos of\nthe CATARACTS test set.",
    "descriptor": "",
    "authors": [
      "Imanol Luengo",
      "Maria Grammatikopoulou",
      "Rahim Mohammadi",
      "Chris Walsh",
      "Chinedu Innocent Nwoye",
      "Deepak Alapatt",
      "Nicolas Padoy",
      "Zhen-Liang Ni",
      "Chen-Chen Fan",
      "Gui-Bin Bian",
      "Zeng-Guang Hou",
      "Heonjin Ha",
      "Jiacheng Wang",
      "Haojie Wang",
      "Dong Guo",
      "Lu Wang",
      "Guotai Wang",
      "Mobarakol Islam",
      "Bharat Giddwani",
      "Ren Hongliang",
      "Theodoros Pissas",
      "Claudio Ravasio Martin Huber",
      "Jeremy Birch",
      "Joan M.Nunez Do Rio",
      "Lyndon da Cruz",
      "Christos Bergeles",
      "Hongyu Chen",
      "Fucang Jia",
      "Nikhil KumarTomar",
      "Debesh Jha",
      "Michael A. Riegler",
      "Pal Halvorsen",
      "Sophia Bano",
      "Uddhav Vaghela",
      "Jianyuan Hong",
      "Haili Ye",
      "Feihong Huang",
      "Da-Han Wang",
      "Danail Stoyanov"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10965"
  },
  {
    "id": "arXiv:2110.10996",
    "title": "Mean Nystr\u00f6m Embeddings for Adaptive Compressive Learning",
    "abstract": "Compressive learning is an approach to efficient large scale learning based\non sketching an entire dataset to a single mean embedding (the sketch), i.e. a\nvector of generalized moments. The learning task is then approximately solved\nas an inverse problem using an adapted parametric model. Previous works in this\ncontext have focused on sketches obtained by averaging random features, that\nwhile universal can be poorly adapted to the problem at hand. In this paper, we\npropose and study the idea of performing sketching based on data-dependent\nNystr\\\"om approximation. From a theoretical perspective we prove that the\nexcess risk can be controlled under a geometric assumption relating the\nparametric model used to learn from the sketch and the covariance operator\nassociated to the task at hand. Empirically, we show for k-means clustering and\nGaussian modeling that for a fixed sketch size, Nystr\\\"om sketches indeed\noutperform those built with random features.",
    "descriptor": "\nComments: 22 pages, 4 figures\n",
    "authors": [
      "Antoine Chatalic",
      "Luigi Carratino",
      "Ernesto De Vito",
      "Lorenzo Rosasco"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10996"
  },
  {
    "id": "arXiv:2110.11004",
    "title": "Space-time formulation and time discretization of phase-field fracture  optimal control problems",
    "abstract": "The purpose of this work is the development of space-time discretization\nschemes for phase-field optimal control problems. First, a time discretization\nof the forward problem is derived using a discontinuous Galerkin formulation.\nHere, a challenge is to include regularization terms and the crack\nirreversibility constraint. The optimal control setting is formulated by means\nof the Lagrangian approach from which the primal part, adjoint, tangent and\nadjoint Hessian are derived. Herein the overall Newton algorithm is based on a\nreduced approach by eliminating the state constraint. From the low-order\ndiscontinuous Galerkin discretization, adjoint time-stepping schemes are\nfinally obtained.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Denis Khimin",
      "Marc C. Steinbach",
      "Thomas Wick"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.11004"
  },
  {
    "id": "arXiv:2110.11012",
    "title": "Towards Reducing Aleatoric Uncertainty for Medical Imaging Tasks",
    "abstract": "In safety-critical applications like medical diagnosis, certainty associated\nwith a model's prediction is just as important as its accuracy. Consequently,\nuncertainty estimation and reduction play a crucial role. Uncertainty in\npredictions can be attributed to noise or randomness in data (aleatoric) and\nincorrect model inferences (epistemic). While model uncertainty can be reduced\nwith more data or bigger models, aleatoric uncertainty is more intricate. This\nwork proposes a novel approach that interprets data uncertainty estimated from\na self-supervised task as noise inherent to the data and utilizes it to reduce\naleatoric uncertainty in another task related to the same dataset via data\naugmentation. The proposed method was evaluated on a benchmark medical imaging\ndataset with image reconstruction as the self-supervised task and segmentation\nas the image analysis task. Our findings demonstrate the effectiveness of the\nproposed approach in significantly reducing the aleatoric uncertainty in the\nimage segmentation task while achieving better or on-par performance compared\nto the standard augmentation techniques.",
    "descriptor": "",
    "authors": [
      "Abhishek Singh Sambyal",
      "Narayanan C. Krishnan",
      "Deepti R. Bathula"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11012"
  },
  {
    "id": "arXiv:2110.11021",
    "title": "Stability and performance analysis of NMPC: Detectable stage costs and  general terminal costs",
    "abstract": "We provide a stability and performance analysis for nonlinear model\npredictive control (NMPC) schemes. Given an exponential stabilizability and\ndetectability condition w.r.t. the employed state cost, we provide a\nsufficiently long prediction horizon to ensure asymptotic stability and a\ndesired performance bound w.r.t. the infinite-horizon optimal controller.\nCompared to existing results, the provided analysis is applicable to positive\nsemi-definite (detectable) cost functions, provides tight bounds using a linear\nprogramming analysis, and allows for a seamless integration of general\npositive-definite terminal cost functions in the analysis. The practical\napplicability of the derived theoretical results are demonstrated in a\nnumerical example.",
    "descriptor": "",
    "authors": [
      "Johannes K\u00f6hler",
      "Melanie Zeilinger",
      "Lars Gr\u00fcne"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.11021"
  },
  {
    "id": "arXiv:2110.11061",
    "title": "Polyadic Sets and Homomorphism Counting",
    "abstract": "A classical result due to Lovasz (1967) shows that the isomorphism type of a\ngraph is determined by homomorphism counts. That is, graphs G and H are\nisomorphic whenever the number of homomorphisms from K to G is the same as the\nnumber of homomorphisms from K to H for all graphs K. Variants of this result,\nfor various classes of finite structures, have been exploited in a wide range\nof research fields, including graph theory and finite model theory.\nWe provide a categorical approach to homomorphism counting based on the\nconcept of polyadic (finite) set. The latter is a special case of the notion of\npolyadic space introduced by Joyal (1971) and related, via duality, to Boolean\nhyperdoctrines in categorical logic. We also obtain new homomorphism counting\nresults applicable to a number of infinite structures, such as finitely\nbranching trees and profinite algebras.",
    "descriptor": "\nComments: 40 pages\n",
    "authors": [
      "Luca Reggio"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Logic in Computer Science (cs.LO)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2110.11061"
  },
  {
    "id": "arXiv:2110.11131",
    "title": "Statistical Finite Elements via Langevin Dynamics",
    "abstract": "The recent statistical finite element method (statFEM) provides a coherent\nstatistical framework to synthesise finite element models with observed data.\nThrough embedding uncertainty inside of the governing equations, finite element\nsolutions are updated to give a posterior distribution which quantifies all\nsources of uncertainty associated with the model. However to incorporate all\nsources of uncertainty, one must integrate over the uncertainty associated with\nthe model parameters, the known forward problem of uncertainty quantification.\nIn this paper, we make use of Langevin dynamics to solve the statFEM forward\nproblem, studying the utility of the unadjusted Langevin algorithm (ULA), a\nMetropolis-free Markov chain Monte Carlo sampler, to build a sample-based\ncharacterisation of this otherwise intractable measure. Due to the structure of\nthe statFEM problem, these methods are able to solve the forward problem\nwithout explicit full PDE solves, requiring only sparse matrix-vector products.\nULA is also gradient-based, and hence provides a scalable approach up to high\ndegrees-of-freedom. Leveraging the theory behind Langevin-based samplers, we\nprovide theoretical guarantees on sampler performance, demonstrating\nconvergence, for both the prior and posterior, in the Kullback-Leibler\ndivergence, and, in Wasserstein-2, with further results on the effect of\npreconditioning. Numerical experiments are also provided, for both the prior\nand posterior, to demonstrate the efficacy of the sampler, with a Python\npackage also included.",
    "descriptor": "",
    "authors": [
      "\u00d6mer Deniz Akyildiz",
      "Connor Duffin",
      "Sotirios Sabanis",
      "Mark Girolami"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.11131"
  },
  {
    "id": "arXiv:2110.11144",
    "title": "rct: random consistency training for semi-supervised sound event  detection",
    "abstract": "Sound event detection (SED), as a core module of acoustic environmental\nanalysis, suffers from the problem of data deficiency. The integration of\nsemi-supervised learning (SSL) largely mitigates such problem while bringing no\nextra annotation budget. This paper researches on several core modules of SSL,\nand introduces a random consistency training (RCT) strategy. First, a\nself-consistency loss is proposed to fuse with the teacher-student model to\nstabilize the training. Second, a hard mixup data augmentation is proposed to\naccount for the additive property of sounds. Third, a random augmentation\nscheme is applied to flexibly combine different types of data augmentations.\nExperiments show that the proposed strategy outperform other widely-used\nstrategies.",
    "descriptor": "\nComments: 5 pages, 2 figures, ICASSP2021\n",
    "authors": [
      "Nian Shao",
      "Erfan Loweimi",
      "Xiaofei Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.11144"
  },
  {
    "id": "arXiv:2110.11216",
    "title": "User-friendly introduction to PAC-Bayes bounds",
    "abstract": "Aggregated predictors are obtained by making a set of basic predictors vote\naccording to some weights, that is, to some probability distribution.\nRandomized predictors are obtained by sampling in a set of basic predictors,\naccording to some prescribed probability distribution.\nThus, aggregated and randomized predictors have in common that they are not\ndefined by a minimization problem, but by a probability distribution on the set\nof predictors. In statistical learning theory, there is a set of tools designed\nto understand the generalization ability of such procedures: PAC-Bayesian or\nPAC-Bayes bounds.\nSince the original PAC-Bayes bounds of McAllester, these tools have been\nconsiderably improved in many directions (we will for example describe a\nsimplified version of the localization technique of Catoni that was missed by\nthe community, and later rediscovered as \"mutual information bounds\"). Very\nrecently, PAC-Bayes bounds received a considerable attention: for example there\nwas workshop on PAC-Bayes at NIPS 2017, \"(Almost) 50 Shades of Bayesian\nLearning: PAC-Bayesian trends and insights\", organized by B. Guedj, F. Bach and\nP. Germain. One of the reason of this recent success is the successful\napplication of these bounds to neural networks by Dziugaite and Roy.\nAn elementary introduction to PAC-Bayes theory is still missing. This is an\nattempt to provide such an introduction.",
    "descriptor": "",
    "authors": [
      "Pierre Alquier"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.11216"
  },
  {
    "id": "arXiv:2110.11237",
    "title": "Recurrent Brain Graph Mapper for Predicting Time-Dependent Brain Graph  Evaluation Trajectory",
    "abstract": "Several brain disorders can be detected by observing alterations in the\nbrain's structural and functional connectivities. Neurological findings suggest\nthat early diagnosis of brain disorders, such as mild cognitive impairment\n(MCI), can prevent and even reverse its development into Alzheimer's disease\n(AD). In this context, recent studies aimed to predict the evolution of brain\nconnectivities over time by proposing machine learning models that work on\nbrain images. However, such an approach is costly and time-consuming. Here, we\npropose to use brain connectivities as a more efficient alternative for\ntime-dependent brain disorder diagnosis by regarding the brain as instead a\nlarge interconnected graph characterizing the interconnectivity scheme between\nseveral brain regions. We term our proposed method Recurrent Brain Graph Mapper\n(RBGM), a novel efficient edge-based recurrent graph neural network that\npredicts the time-dependent evaluation trajectory of a brain graph from a\nsingle baseline. Our RBGM contains a set of recurrent neural network-inspired\nmappers for each time point, where each mapper aims to project the ground-truth\nbrain graph onto its next time point. We leverage the teacher forcing method to\nboost training and improve the evolved brain graph quality. To maintain the\ntopological consistency between the predicted brain graphs and their\ncorresponding ground-truth brain graphs at each time point, we further\nintegrate a topological loss. We also use l1 loss to capture time-dependency\nand minimize the distance between the brain graph at consecutive time points\nfor regularization. Benchmarks against several variants of RBGM and\nstate-of-the-art methods prove that we can achieve the same accuracy in\npredicting brain graph evolution more efficiently, paving the way for novel\ngraph neural network architecture and a highly efficient training scheme.",
    "descriptor": "",
    "authors": [
      "Alpay Tekin",
      "Ahmed Nebli",
      "Islem Rekik"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11237"
  },
  {
    "id": "arXiv:2110.11245",
    "title": "Evolutionary Foundation for Heterogeneity in Risk Aversion",
    "abstract": "We examine the evolutionary basis for risk aversion with respect to aggregate\nrisk. We study populations in which agents face choices between aggregate risk\nand idiosyncratic risk. We show that the choices that maximize the long-run\ngrowth rate are induced by a heterogeneous population in which the least and\nmost risk averse agents are indifferent between aggregate risk and obtaining\nits linear and harmonic mean for sure, respectively. Moreover, approximately\noptimal behavior can be induced by a simple distribution according to which all\nagents have constant relative risk aversion, and the coefficient of relative\nrisk aversion is uniformly distributed between zero and two.",
    "descriptor": "",
    "authors": [
      "Yuval Heller",
      "Ilan Nehama"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.11245"
  },
  {
    "id": "arXiv:2110.11258",
    "title": "On Optimal Interpolation In Linear Regression",
    "abstract": "Understanding when and why interpolating methods generalize well has recently\nbeen a topic of interest in statistical learning theory. However,\nsystematically connecting interpolating methods to achievable notions of\noptimality has only received partial attention. In this paper, we investigate\nthe question of what is the optimal way to interpolate in linear regression\nusing functions that are linear in the response variable (as the case for the\nBayes optimal estimator in ridge regression) and depend on the data, the\npopulation covariance of the data, the signal-to-noise ratio and the covariance\nof the prior for the signal, but do not depend on the value of the signal\nitself nor the noise vector in the training data. We provide a closed-form\nexpression for the interpolator that achieves this notion of optimality and\nshow that it can be derived as the limit of preconditioned gradient descent\nwith a specific initialization. We identify a regime where the minimum-norm\ninterpolator provably generalizes arbitrarily worse than the optimal\nresponse-linear achievable interpolator that we introduce, and validate with\nnumerical experiments that the notion of optimality we consider can be achieved\nby interpolating methods that only use the training data as input in the case\nof an isotropic prior. Finally, we extend the notion of optimal response-linear\ninterpolation to random features regression under a linear data-generating\nmodel that has been previously studied in the literature.",
    "descriptor": "\nComments: 25 pages, 7 figures, to appear in NeurIPS 2021\n",
    "authors": [
      "Eduard Oravkin",
      "Patrick Rebeschini"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.11258"
  },
  {
    "id": "arXiv:2110.11279",
    "title": "Improving Channel Charting using a Split Triplet Loss and an Inertial  Regularizer",
    "abstract": "Channel charting is an emerging technology that enables self-supervised\npseudo-localization of user equipments by performing dimensionality reduction\non large channel-state information (CSI) databases that are passively collected\nat infrastructure base stations or access points. In this paper, we introduce a\nnew dimensionality reduction method specifically designed for channel charting\nusing a novel split triplet loss, which utilizes physical information available\nduring the CSI acquisition process. In addition, we propose a novel regularizer\nthat exploits the physical concept of inertia, which significantly improves the\nquality of the learned channel charts. We provide an experimental verification\nof our methods using synthetic and real-world measured CSI datasets, and we\ndemonstrate that our methods are able to outperform the state-of-the-art in\nchannel charting based on the triplet loss.",
    "descriptor": "\nComments: 6 pages, 2 figures\n",
    "authors": [
      "Brian Rappaport",
      "Emre G\u00f6n\u00fclta\u015f",
      "Jakob Hoydis",
      "Maximilian Arnold",
      "Pavan Koteshwar Srinath",
      "Christoph Studer"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.11279"
  },
  {
    "id": "arXiv:2110.11282",
    "title": "How arithmetic and geometry make error correcting codes better",
    "abstract": "This note completes a talk given at the conference Curves over Finite Fields:\npast, present and future celebrating the publication the book {\\em Rational\nPoints on Curves over Finite Fields by J.-P. Serre and organised at Centro de\nciencias de Benasque in june 2021. It discusses a part of the history of\nalgebraic geometry codes together with some of their recent applications. A\nparticular focus is done on the \"multiplicative\" structure of these codes, i.e.\ntheir behaviour with respect to the component wise product. Some open questions\nare raised and discussed.",
    "descriptor": "",
    "authors": [
      "Alain Couvreur"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Information Theory (cs.IT)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2110.11282"
  },
  {
    "id": "arXiv:2110.11291",
    "title": "Likelihood Training of Schr\u00f6dinger Bridge using Forward-Backward SDEs  Theory",
    "abstract": "Schr\\\"odinger Bridge (SB) is an optimal transport problem that has received\nincreasing attention in deep generative modeling for its mathematical\nflexibility compared to the Scored-based Generative Model (SGM). However, it\nremains unclear whether the optimization principle of SB relates to the modern\ntraining of deep generative models, which often rely on constructing\nparameterized log-likelihood objectives.This raises questions on the\nsuitability of SB models as a principled alternative for generative\napplications. In this work, we present a novel computational framework for\nlikelihood training of SB models grounded on Forward-Backward Stochastic\nDifferential Equations Theory -- a mathematical methodology appeared in\nstochastic optimal control that transforms the optimality condition of SB into\na set of SDEs. Crucially, these SDEs can be used to construct the likelihood\nobjectives for SB that, surprisingly, generalizes the ones for SGM as special\ncases. This leads to a new optimization principle that inherits the same SB\noptimality yet without losing applications of modern generative training\ntechniques, and we show that the resulting training algorithm achieves\ncomparable results on generating realistic images on MNIST, CelebA, and\nCIFAR10.",
    "descriptor": "",
    "authors": [
      "Tianrong Chen",
      "Guan-Horng Liu",
      "Evangelos A. Theodorou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.11291"
  },
  {
    "id": "arXiv:1610.06631",
    "title": "Inverse Power Flow Problem",
    "abstract": "Comments: working paper",
    "descriptor": "\nComments: working paper\n",
    "authors": [
      "Ye Yuan",
      "Steven Low",
      "Omid Ardakanian",
      "Claire Tomlin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/1610.06631"
  },
  {
    "id": "arXiv:1704.03443",
    "title": "Solving the L1 regularized least square problem via a box-constrained  smooth minimization",
    "abstract": "Comments: I stoped working on the paper and cannot guarantee its scientific correctness",
    "descriptor": "\nComments: I stoped working on the paper and cannot guarantee its scientific correctness\n",
    "authors": [
      "Majid Mohammadi",
      "Wout Hofman",
      "Yaohua Tan",
      "S. Hamid Mousavi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1704.03443"
  },
  {
    "id": "arXiv:1708.02511",
    "title": "Parametric Adversarial Divergences are Good Losses for Generative  Modeling",
    "abstract": "Parametric Adversarial Divergences are Good Losses for Generative  Modeling",
    "descriptor": "",
    "authors": [
      "Gabriel Huang",
      "Hugo Berard",
      "Ahmed Touati",
      "Gauthier Gidel",
      "Pascal Vincent",
      "Simon Lacoste-Julien"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1708.02511"
  },
  {
    "id": "arXiv:1802.01815",
    "title": "Effects of Jamming Attacks on Wireless Networked Control Systems Under  Disturbance",
    "abstract": "Comments: Change title; Add new remarks in Sections II and III; Add new simulation results and figures in Section IV",
    "descriptor": "\nComments: Change title; Add new remarks in Sections II and III; Add new simulation results and figures in Section IV\n",
    "authors": [
      "Ahmet Cetinkaya",
      "Hideaki Ishii",
      "Tomohisa Hayakawa"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1802.01815"
  },
  {
    "id": "arXiv:1812.06896",
    "title": "Merging Multigrid Optimization with SESOP",
    "abstract": "Comments: 8 figures, 1 table",
    "descriptor": "\nComments: 8 figures, 1 table\n",
    "authors": [
      "Tao Hong",
      "Irad Yavneh",
      "Michael Zibulevsky"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1812.06896"
  },
  {
    "id": "arXiv:1901.07186",
    "title": "Towards Learning to Imitate from a Single Video Demonstration",
    "abstract": "Comments: PrePrint",
    "descriptor": "\nComments: PrePrint\n",
    "authors": [
      "Glen Berseth",
      "Florian Golemo",
      "Christopher Pal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1901.07186"
  },
  {
    "id": "arXiv:1901.10860",
    "title": "Learning Context-Dependent Choice Functions",
    "abstract": "Comments: 45 pages, 21 figures",
    "descriptor": "\nComments: 45 pages, 21 figures\n",
    "authors": [
      "Karlson Pfannschmidt",
      "Pritha Gupta",
      "Bj\u00f6rn Haddenhorst",
      "Eyke H\u00fcllermeier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "General Economics (econ.GN)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1901.10860"
  },
  {
    "id": "arXiv:1903.00982",
    "title": "Oxide: The Essence of Rust",
    "abstract": "Comments: Latest draft",
    "descriptor": "\nComments: Latest draft\n",
    "authors": [
      "Aaron Weiss",
      "Olek Gierczak",
      "Daniel Patterson",
      "Amal Ahmed"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/1903.00982"
  },
  {
    "id": "arXiv:1903.02240",
    "title": "Efficient Deep Neural Network for Photo-realistic Image Super-Resolution",
    "abstract": "Efficient Deep Neural Network for Photo-realistic Image Super-Resolution",
    "descriptor": "",
    "authors": [
      "Namhyuk Ahn",
      "Byungkon Kang",
      "Kyung-Ah Sohn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1903.02240"
  },
  {
    "id": "arXiv:1905.10201",
    "title": "Model Validation Using Mutated Training Labels: An Exploratory Study",
    "abstract": "Model Validation Using Mutated Training Labels: An Exploratory Study",
    "descriptor": "",
    "authors": [
      "Jie M. Zhang",
      "Mark Harman",
      "Benjamin Guedj",
      "Earl T. Barr",
      "John Shawe-Taylor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1905.10201"
  },
  {
    "id": "arXiv:1907.07758",
    "title": "HITS hits art",
    "abstract": "HITS hits art",
    "descriptor": "",
    "authors": [
      "Massimo Franceschet"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/1907.07758"
  },
  {
    "id": "arXiv:1907.08410",
    "title": "On Linear Convergence of Weighted Kernel Herding",
    "abstract": "Comments: Accepted to UAI 2021",
    "descriptor": "\nComments: Accepted to UAI 2021\n",
    "authors": [
      "Rajiv Khanna",
      "Liam Hodgkinson",
      "Michael W. Mahoney"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1907.08410"
  },
  {
    "id": "arXiv:1908.00089",
    "title": "A Model of Random Industrial SAT",
    "abstract": "Comments: 32 pages",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Dina Barak-Pelleg",
      "Daniel Berend",
      "J.C. Saunders"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/1908.00089"
  },
  {
    "id": "arXiv:1908.08313",
    "title": "Auditing Radicalization Pathways on YouTube",
    "abstract": "Comments: 10 pages plus appendices",
    "descriptor": "\nComments: 10 pages plus appendices\n",
    "authors": [
      "Manoel Horta Ribeiro",
      "Raphael Ottoni",
      "Robert West",
      "Virg\u00edlio A. F. Almeida",
      "Wagner Meira"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/1908.08313"
  },
  {
    "id": "arXiv:1908.09881",
    "title": "Consistently estimating graph statistics using Aggregated Relational  Data",
    "abstract": "Consistently estimating graph statistics using Aggregated Relational  Data",
    "descriptor": "",
    "authors": [
      "Emily Breza",
      "Arun G. Chandrasekhar",
      "Shane Lubold",
      "Tyler H. McCormick",
      "Mengjie Pan"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/1908.09881"
  },
  {
    "id": "arXiv:1908.11017",
    "title": "A Joint Model for Aspect-Category Sentiment Analysis with Shared  Sentiment Prediction Layer",
    "abstract": "Comments: CCL 2020(this https URL)",
    "descriptor": "\nComments: CCL 2020(this https URL)\n",
    "authors": [
      "Yuncong Li",
      "Zhe Yang",
      "Cunxiang Yin",
      "Xu Pan",
      "Lunan Cui",
      "Qiang Huang",
      "Ting Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/1908.11017"
  },
  {
    "id": "arXiv:1909.08065",
    "title": "Deterministic algorithms for the Lovasz Local Lemma: simpler, more  general, and more parallel",
    "abstract": "Comments: This superseded arxiv:1807.06672",
    "descriptor": "\nComments: This superseded arxiv:1807.06672\n",
    "authors": [
      "David G. Harris"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1909.08065"
  },
  {
    "id": "arXiv:1912.03616",
    "title": "Data-Driven Linear Quadratic Optimization for Controller Synthesis with  Structural Constraints",
    "abstract": "Comments: 10 pages, 6 figures",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Jun Ma",
      "Zilong Cheng",
      "Xiaocong Li",
      "Masayoshi Tomizuka",
      "Tong Heng Lee"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1912.03616"
  },
  {
    "id": "arXiv:1912.07640",
    "title": "Indirect NRDF for Partially Observable Gauss-Markov Processes with MSE  Distortion: Complete Characterizations and Optimal Solutions",
    "abstract": "Comments: 17 double column pages, 4 figures, 1 Table",
    "descriptor": "\nComments: 17 double column pages, 4 figures, 1 Table\n",
    "authors": [
      "Photios A. Stavrou",
      "Mikael Skoglund"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/1912.07640"
  },
  {
    "id": "arXiv:2002.08569",
    "title": "Byzantine-resilient Decentralized Stochastic Gradient Descent",
    "abstract": "Byzantine-resilient Decentralized Stochastic Gradient Descent",
    "descriptor": "",
    "authors": [
      "Shangwei Guo",
      "Tianwei Zhang",
      "Han Yu",
      "Xiaofei Xie",
      "Lei Ma",
      "Tao Xiang",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2002.08569"
  },
  {
    "id": "arXiv:2002.12850",
    "title": "Convergence analysis of adaptive DIIS algorithms with application to  electronic ground state calculations",
    "abstract": "Comments: Final version to appear in ESAIM:M2AN",
    "descriptor": "\nComments: Final version to appear in ESAIM:M2AN\n",
    "authors": [
      "Maxime Chupin",
      "Mi-Song Dupuy",
      "Guillaume Legendre",
      "Eric S\u00e9r\u00e9"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2002.12850"
  },
  {
    "id": "arXiv:2004.00679",
    "title": "LQG Graphon Mean Field Games: Analysis via Graphon Invariant Subspaces",
    "abstract": "LQG Graphon Mean Field Games: Analysis via Graphon Invariant Subspaces",
    "descriptor": "",
    "authors": [
      "Shuang Gao",
      "Peter E. Caines",
      "Minyi Huang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2004.00679"
  },
  {
    "id": "arXiv:2005.03304",
    "title": "Data-Driven Distributed Intersection Management for Connected and  Automated Vehicles",
    "abstract": "Comments: 11 pages, 5 figures, 2 tables",
    "descriptor": "\nComments: 11 pages, 5 figures, 2 tables\n",
    "authors": [
      "Darshan Gadginmath",
      "Pavankumar Tallapragada"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2005.03304"
  },
  {
    "id": "arXiv:2005.09147",
    "title": "Increasing-Margin Adversarial (IMA) Training to Improve Adversarial  Robustness of Neural Networks",
    "abstract": "Comments: 9 pages, 12 figures",
    "descriptor": "\nComments: 9 pages, 12 figures\n",
    "authors": [
      "Linhai Ma",
      "Liang Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2005.09147"
  },
  {
    "id": "arXiv:2005.09743",
    "title": "On Evaluating Weakly Supervised Action Segmentation Methods",
    "abstract": "Comments: Technical Report",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Yaser Souri",
      "Alexander Richard",
      "Luca Minciullo",
      "Juergen Gall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2005.09743"
  },
  {
    "id": "arXiv:2005.13499",
    "title": "Asynchronous Reconfiguration with Byzantine Failures",
    "abstract": "Asynchronous Reconfiguration with Byzantine Failures",
    "descriptor": "",
    "authors": [
      "Petr Kuznetsov",
      "Andrei Tonkikh"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2005.13499"
  },
  {
    "id": "arXiv:2005.14681",
    "title": "Improved torsion point attacks on SIDH variants",
    "abstract": "Comments: 37 pages including 3 appendices",
    "descriptor": "\nComments: 37 pages including 3 appendices\n",
    "authors": [
      "Victoria de Quehen",
      "P\u00e9ter Kutas",
      "Chris Leonardi",
      "Chloe Martindale",
      "Lorenz Panny",
      "Christophe Petit",
      "Katherine E. Stange"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2005.14681"
  },
  {
    "id": "arXiv:2006.03696",
    "title": "High-Dimensional Non-Parametric Density Estimation in Mixed Smooth  Sobolev Spaces",
    "abstract": "High-Dimensional Non-Parametric Density Estimation in Mixed Smooth  Sobolev Spaces",
    "descriptor": "",
    "authors": [
      "Liang Ding",
      "Lu Zou",
      "Wenjia Wang",
      "Shahin Shahrampour",
      "Rui Tuo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.03696"
  },
  {
    "id": "arXiv:2006.05659",
    "title": "Optimal Participation of Price-maker Battery Energy Storage Systems in  Energy and Ancillary Services Markets Considering Degradation Cost",
    "abstract": "Optimal Participation of Price-maker Battery Energy Storage Systems in  Energy and Ancillary Services Markets Considering Degradation Cost",
    "descriptor": "",
    "authors": [
      "Reza Khalilisenobari",
      "Meng Wu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2006.05659"
  },
  {
    "id": "arXiv:2006.07559",
    "title": "Enabling Joint Communication and Radar Sensing in Mobile Networks -- A  Survey",
    "abstract": "Comments: 41 pages, 15 figures, 17 tables, journal paper. IEEE Communications Surveys and Tutorials (Accepted for publication, Oct. 2021)",
    "descriptor": "\nComments: 41 pages, 15 figures, 17 tables, journal paper. IEEE Communications Surveys and Tutorials (Accepted for publication, Oct. 2021)\n",
    "authors": [
      "J. Andrew Zhang",
      "Md Lushanur Rahman",
      "Kai Wu",
      "Xiaojing Huang",
      "Y. Jay Guo",
      "Shanzhi Chen",
      "Jinhong Yuan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2006.07559"
  },
  {
    "id": "arXiv:2006.10875",
    "title": "Provably adaptive reinforcement learning in metric spaces",
    "abstract": "Comments: Published in NeurIPS 2020. This version fixes a bug in the published version",
    "descriptor": "\nComments: Published in NeurIPS 2020. This version fixes a bug in the published version\n",
    "authors": [
      "Tongyi Cao",
      "Akshay Krishnamurthy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.10875"
  },
  {
    "id": "arXiv:2006.13201",
    "title": "A stabilized finite element method for inverse problems subject to the  convection-diffusion equation. II: convection-dominated regime",
    "abstract": "Comments: 25 pages, 16 figures; in v2 we made some minor corrections and updated the first 3 figures",
    "descriptor": "\nComments: 25 pages, 16 figures; in v2 we made some minor corrections and updated the first 3 figures\n",
    "authors": [
      "Erik Burman",
      "Mihai Nechita",
      "Lauri Oksanen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2006.13201"
  },
  {
    "id": "arXiv:2006.13533",
    "title": "Provably Convergent Working Set Algorithm for Non-Convex Regularized  Regression",
    "abstract": "Provably Convergent Working Set Algorithm for Non-Convex Regularized  Regression",
    "descriptor": "",
    "authors": [
      "Alain Rakotomamonjy",
      "R\u00e9mi Flamary",
      "Gilles Gasso",
      "Joseph Salmon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.13533"
  },
  {
    "id": "arXiv:2006.15590",
    "title": "VPNet: Variable Projection Networks",
    "abstract": "Comments: The codes and the experiments are available at: this https URL",
    "descriptor": "\nComments: The codes and the experiments are available at: this https URL\n",
    "authors": [
      "P\u00e9ter Kov\u00e1cs",
      "Gerg\u0151 Bogn\u00e1r",
      "Christian Huber",
      "Mario Huemer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.15590"
  },
  {
    "id": "arXiv:2007.06679",
    "title": "Lipschitz regularity of graph Laplacians on random data clouds",
    "abstract": "Lipschitz regularity of graph Laplacians on random data clouds",
    "descriptor": "",
    "authors": [
      "Jeff Calder",
      "Nicolas Garcia Trillos",
      "Marta Lewicka"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.06679"
  },
  {
    "id": "arXiv:2007.10626",
    "title": "Sparse Nonnegative Tensor Factorization and Completion with Noisy  Observations",
    "abstract": "Sparse Nonnegative Tensor Factorization and Completion with Noisy  Observations",
    "descriptor": "",
    "authors": [
      "Xiongjun Zhang",
      "Michael K. Ng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2007.10626"
  },
  {
    "id": "arXiv:2008.00745",
    "title": "Community membership consistency applied to corporate board interlock  networks",
    "abstract": "Comments: This manuscript has been accepted for publication in the Journal of Computational Social Science",
    "descriptor": "\nComments: This manuscript has been accepted for publication in the Journal of Computational Social Science\n",
    "authors": [
      "Dafne E. van Kuppevelt",
      "Rena Bakhshi",
      "Eelke M. Heemskerk",
      "Frank W. Takes"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2008.00745"
  },
  {
    "id": "arXiv:2008.01128",
    "title": "Shifting paths to avoidable ones",
    "abstract": "Comments: 14 pages, 7 figures, accepted for publication in Journal of Graph Theory",
    "descriptor": "\nComments: 14 pages, 7 figures, accepted for publication in Journal of Graph Theory\n",
    "authors": [
      "Vladimir Gurvich",
      "Matja\u017e Krnc",
      "Martin Milani\u010d",
      "Mikhail Vyalyi"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2008.01128"
  },
  {
    "id": "arXiv:2008.02724",
    "title": "Zeroing Neural Networks, an Introduction to, a Survey of, and Predictive  Computations for Discretized Time-varying Matrix Problems",
    "abstract": "Comments: 30 pages, 2 images",
    "descriptor": "\nComments: 30 pages, 2 images\n",
    "authors": [
      "Frank Uhlig"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "History and Overview (math.HO)"
    ],
    "url": "https://arxiv.org/abs/2008.02724"
  },
  {
    "id": "arXiv:2008.03229",
    "title": "Towards Sample Efficient Agents through Algorithmic Alignment",
    "abstract": "Towards Sample Efficient Agents through Algorithmic Alignment",
    "descriptor": "",
    "authors": [
      "Mingxuan Li",
      "Michael L. Littman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.03229"
  },
  {
    "id": "arXiv:2008.05382",
    "title": "Social Companion Robots to Reduce Isolation: A Perception Change Due to  COVID-19",
    "abstract": "Social Companion Robots to Reduce Isolation: A Perception Change Due to  COVID-19",
    "descriptor": "",
    "authors": [
      "Moojan Ghafurian",
      "Colin Ellard",
      "Kerstin Dautenhahn"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2008.05382"
  },
  {
    "id": "arXiv:2008.06255",
    "title": "WAN: Watermarking Attack Network",
    "abstract": "Comments: Accepted to BMVC 2021",
    "descriptor": "\nComments: Accepted to BMVC 2021\n",
    "authors": [
      "Seung-Hun Nam",
      "In-Jae Yu",
      "Seung-Min Mun",
      "Daesik Kim",
      "Wonhyuk Ahn"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2008.06255"
  },
  {
    "id": "arXiv:2008.09150",
    "title": "VisualSem: A High-quality Knowledge Graph for Vision and Language",
    "abstract": "Comments: Accepted for publication at the 1st Multilingual Representation Learning workshop (MRL 2021) co-located with EMNLP 2021. 15 pages, 8 figures, 6 tables",
    "descriptor": "\nComments: Accepted for publication at the 1st Multilingual Representation Learning workshop (MRL 2021) co-located with EMNLP 2021. 15 pages, 8 figures, 6 tables\n",
    "authors": [
      "Houda Alberts",
      "Teresa Huang",
      "Yash Deshpande",
      "Yibo Liu",
      "Kyunghyun Cho",
      "Clara Vania",
      "Iacer Calixto"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2008.09150"
  },
  {
    "id": "arXiv:2008.12050",
    "title": "Hybrid quantum-classical optimization for financial index tracking",
    "abstract": "Comments: 24 pages, 12 figures. A few changes in structure implemented in version 2",
    "descriptor": "\nComments: 24 pages, 12 figures. A few changes in structure implemented in version 2\n",
    "authors": [
      "Samuel Fern\u00e1ndez-Lorenzo",
      "Diego Porras",
      "Juan Jos\u00e9 Garc\u00eda-Ripoll"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)",
      "Portfolio Management (q-fin.PM)"
    ],
    "url": "https://arxiv.org/abs/2008.12050"
  },
  {
    "id": "arXiv:2009.01485",
    "title": "SAC: Semantic Attention Composition for Text-Conditioned Image Retrieval",
    "abstract": "Comments: Surgan Jandial, Pinkesh Badjatiya, Pranit Chawla, and Ayush Chopra contributed equally to this work. Work accepted at WACV 2022",
    "descriptor": "\nComments: Surgan Jandial, Pinkesh Badjatiya, Pranit Chawla, and Ayush Chopra contributed equally to this work. Work accepted at WACV 2022\n",
    "authors": [
      "Surgan Jandial",
      "Pinkesh Badjatiya",
      "Pranit Chawla",
      "Ayush Chopra",
      "Mausoom Sarkar",
      "Balaji Krishnamurthy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2009.01485"
  },
  {
    "id": "arXiv:2009.04003",
    "title": "Bayesian Inverse Reinforcement Learning for Collective Animal Movement",
    "abstract": "Bayesian Inverse Reinforcement Learning for Collective Animal Movement",
    "descriptor": "",
    "authors": [
      "Toryn L. J. Schafer",
      "Christopher K. Wikle",
      "Mevin B. Hooten"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.04003"
  },
  {
    "id": "arXiv:2009.13087",
    "title": "PERF-Net: Pose Empowered RGB-Flow Net",
    "abstract": "Comments: 10 pages, 5 figures, 7 tables",
    "descriptor": "\nComments: 10 pages, 5 figures, 7 tables\n",
    "authors": [
      "Yinxiao Li",
      "Zhichao Lu",
      "Xuehan Xiong",
      "Jonathan Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.13087"
  },
  {
    "id": "arXiv:2009.14474",
    "title": "User-item matching for recommendation fairness",
    "abstract": "User-item matching for recommendation fairness",
    "descriptor": "",
    "authors": [
      "Qiang Dong",
      "Shuang-Shuang Xie",
      "Wen-Jun Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2009.14474"
  },
  {
    "id": "arXiv:2010.04600",
    "title": "Robust Adaptive Control of Linear Parameter-Varying Systems with  Unmatched Uncertainties",
    "abstract": "Comments: 16 pages, 2 figures, submitted to IEEE Transactions on Automatic Control",
    "descriptor": "\nComments: 16 pages, 2 figures, submitted to IEEE Transactions on Automatic Control\n",
    "authors": [
      "Pan Zhao",
      "Steven Snyder",
      "Naira Hovakimyana",
      "Chengyu Cao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2010.04600"
  },
  {
    "id": "arXiv:2010.05005",
    "title": "Generalizations of Length Limited Huffman Coding for Hierarchical Memory  Settings",
    "abstract": "Comments: 19 pages, 5 figures",
    "descriptor": "\nComments: 19 pages, 5 figures\n",
    "authors": [
      "Shashwat Banchhor",
      "Rishikesh Gajjala",
      "Yogish Sabharwal",
      "Sandeep Sen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2010.05005"
  },
  {
    "id": "arXiv:2010.06828",
    "title": "Polynomial Approximation of Value Functions and Nonlinear Controller  Design with Performance Bounds",
    "abstract": "Polynomial Approximation of Value Functions and Nonlinear Controller  Design with Performance Bounds",
    "descriptor": "",
    "authors": [
      "Morgan Jones",
      "Matthew M. Peet"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Analysis of PDEs (math.AP)",
      "Classical Analysis and ODEs (math.CA)"
    ],
    "url": "https://arxiv.org/abs/2010.06828"
  },
  {
    "id": "arXiv:2010.06917",
    "title": "UAV Path Planning using Global and Local Map Information with Deep  Reinforcement Learning",
    "abstract": "Comments: ICAR 2021, code available at this https URL",
    "descriptor": "\nComments: ICAR 2021, code available at this https URL\n",
    "authors": [
      "Mirco Theile",
      "Harald Bayerlein",
      "Richard Nai",
      "David Gesbert",
      "Marco Caccamo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.06917"
  },
  {
    "id": "arXiv:2010.07668",
    "title": "Inducing Alignment Structure with Gated Graph Attention Networks for  Sentence Matching",
    "abstract": "Inducing Alignment Structure with Gated Graph Attention Networks for  Sentence Matching",
    "descriptor": "",
    "authors": [
      "Peng Cui",
      "Le Hu",
      "Yuanchao Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.07668"
  },
  {
    "id": "arXiv:2010.08993",
    "title": "Planning with Learned Dynamics: Probabilistic Guarantees on Safety and  Reachability via Lipschitz Constants",
    "abstract": "Comments: Accepted at RA-L and ICRA 2021. Craig Knuth and Glen Chou contributed equally to this work",
    "descriptor": "\nComments: Accepted at RA-L and ICRA 2021. Craig Knuth and Glen Chou contributed equally to this work\n",
    "authors": [
      "Craig Knuth",
      "Glen Chou",
      "Necmiye Ozay",
      "Dmitry Berenson"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2010.08993"
  },
  {
    "id": "arXiv:2010.09170",
    "title": "Belief-Grounded Networks for Accelerated Robot Learning under Partial  Observability",
    "abstract": "Comments: Accepted at Conference on Robot Learning (CoRL) 2020",
    "descriptor": "\nComments: Accepted at Conference on Robot Learning (CoRL) 2020\n",
    "authors": [
      "Hai Nguyen",
      "Brett Daley",
      "Xinchao Song",
      "Christopher Amato",
      "Robert Platt"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.09170"
  },
  {
    "id": "arXiv:2010.10216",
    "title": "Simulated Chats for Building Dialog Systems: Learning to Generate  Conversations from Instructions",
    "abstract": "Comments: Accepted in the Findings of EMNLP 2021",
    "descriptor": "\nComments: Accepted in the Findings of EMNLP 2021\n",
    "authors": [
      "Biswesh Mohapatra",
      "Gaurav Pandey",
      "Danish Contractor",
      "Sachindra Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.10216"
  },
  {
    "id": "arXiv:2010.10797",
    "title": "Tensor Train Random Projection",
    "abstract": "Tensor Train Random Projection",
    "descriptor": "",
    "authors": [
      "Yani Feng",
      "Kejun Tang",
      "Lianxing He",
      "Pingqiang Zhou",
      "Qifeng Liao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.10797"
  },
  {
    "id": "arXiv:2010.14649",
    "title": "Learning Contextualised Cross-lingual Word Embeddings and Alignments for  Extremely Low-Resource Languages Using Parallel Corpora",
    "abstract": "Comments: 16 pages, accepted at the 1st Workshop on Multilingual Representation Learning",
    "descriptor": "\nComments: 16 pages, accepted at the 1st Workshop on Multilingual Representation Learning\n",
    "authors": [
      "Takashi Wada",
      "Tomoharu Iwata",
      "Yuji Matsumoto",
      "Timothy Baldwin",
      "Jey Han Lau"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.14649"
  },
  {
    "id": "arXiv:2010.15030",
    "title": "Actris 2.0: Asynchronous Session-Type Based Reasoning in Separation  Logic",
    "abstract": "Comments: 60 pages, 24 figures",
    "descriptor": "\nComments: 60 pages, 24 figures\n",
    "authors": [
      "Jonas Kastberg Hinrichsen",
      "Jesper Bengtson",
      "Robbert Krebbers"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2010.15030"
  },
  {
    "id": "arXiv:2011.04461",
    "title": "MoboTSP: Solving the Task Sequencing Problem for Mobile Manipulators",
    "abstract": "Comments: Revised version of arXiv:2011.04461. The edit includes reorganizing and rewriting for better clarity without any changes to the methodology",
    "descriptor": "\nComments: Revised version of arXiv:2011.04461. The edit includes reorganizing and rewriting for better clarity without any changes to the methodology\n",
    "authors": [
      "Nicholas Adrian",
      "Quang-Cuong Pham"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2011.04461"
  },
  {
    "id": "arXiv:2011.06023",
    "title": "Discovering alignment relations with Graph Convolutional Networks: a  biomedical case study",
    "abstract": "Discovering alignment relations with Graph Convolutional Networks: a  biomedical case study",
    "descriptor": "",
    "authors": [
      "Pierre Monnin",
      "Chedy Ra\u00efssi",
      "Amedeo Napoli",
      "Adrien Coulet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2011.06023"
  },
  {
    "id": "arXiv:2011.10353",
    "title": "Pseudoinverse-free randomized block iterative algorithms for consistent  and inconsistent linear systems",
    "abstract": "Comments: 23 pages, 2 figures",
    "descriptor": "\nComments: 23 pages, 2 figures\n",
    "authors": [
      "Kui Du",
      "Xiao-Hui Sun"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2011.10353"
  },
  {
    "id": "arXiv:2011.10480",
    "title": "On the coercivity condition in the learning of interacting particle  systems",
    "abstract": "On the coercivity condition in the learning of interacting particle  systems",
    "descriptor": "",
    "authors": [
      "Zhongyang Li",
      "Fei Lu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.10480"
  },
  {
    "id": "arXiv:2011.10725",
    "title": "Impact of signal-to-noise ratio and bandwidth on graph Laplacian  spectrum from high-dimensional noisy point cloud",
    "abstract": "Impact of signal-to-noise ratio and bandwidth on graph Laplacian  spectrum from high-dimensional noisy point cloud",
    "descriptor": "",
    "authors": [
      "Xiucai Ding",
      "Hau-Tieng Wu"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2011.10725"
  },
  {
    "id": "arXiv:2011.11477",
    "title": "Dimensionality reduction, regularization, and generalization in  overparameterized regressions",
    "abstract": "Dimensionality reduction, regularization, and generalization in  overparameterized regressions",
    "descriptor": "",
    "authors": [
      "Ningyuan Huang",
      "David W. Hogg",
      "Soledad Villar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.11477"
  },
  {
    "id": "arXiv:2011.13147",
    "title": "Generalized Mutual Information-Maximizing Quantized Decoding of LDPC  Codes with Layered Scheduling",
    "abstract": "Comments: 13 pages, 8 figures, journal manuscript",
    "descriptor": "\nComments: 13 pages, 8 figures, journal manuscript\n",
    "authors": [
      "Peng Kang",
      "Kui Cai",
      "Xuan He",
      "Shuangyang Li",
      "Jinhong Yuan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2011.13147"
  },
  {
    "id": "arXiv:2011.14482",
    "title": "A Near-Optimal Parallel Algorithm for Joining Binary Relations",
    "abstract": "Comments: Short versions of this article appeared in PODS'17 and ICDT'20. The article is under submission to a journal. The red sentences are highlighted for the journal's reviewers",
    "descriptor": "\nComments: Short versions of this article appeared in PODS'17 and ICDT'20. The article is under submission to a journal. The red sentences are highlighted for the journal's reviewers\n",
    "authors": [
      "Bas Ketsman",
      "Dan Suciu",
      "Yufei Tao"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2011.14482"
  },
  {
    "id": "arXiv:2012.01296",
    "title": "A Safe Reinforcement Learning Architecture for Antenna Tilt Optimisation",
    "abstract": "Comments: 6 pages, 3 figures, added copyright note",
    "descriptor": "\nComments: 6 pages, 3 figures, added copyright note\n",
    "authors": [
      "Erik Aumayr",
      "Saman Feghhi",
      "Filippo Vannella",
      "Ezeddin Al Hakim",
      "Grigorios Iakovidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.01296"
  },
  {
    "id": "arXiv:2012.02267",
    "title": "Hybrid CMOS/Memristor Circuit Design Methodology",
    "abstract": "Comments: This work has been accepted to the IEEE TCAS-I for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been accepted to the IEEE TCAS-I for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Sachin Maheshwari",
      "Spyros Stathopoulos",
      "Jiaqi Wang",
      "Alexander Serb",
      "Yihan Pan",
      "Andrea Mifsud",
      "Lieuwe B. Leene",
      "Jiawei Shen",
      "Christos Papavassiliou",
      "Timothy G. Constandinou",
      "Themistoklis Prodromakis"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2012.02267"
  },
  {
    "id": "arXiv:2012.04859",
    "title": "Enhanced Recurrent Neural Tangent Kernels for Non-Time-Series Data",
    "abstract": "Enhanced Recurrent Neural Tangent Kernels for Non-Time-Series Data",
    "descriptor": "",
    "authors": [
      "Sina Alemohammad",
      "Randall Balestriero",
      "Zichao Wang",
      "Richard Baraniuk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.04859"
  },
  {
    "id": "arXiv:2012.04905",
    "title": "ESAD: End-to-end Deep Semi-supervised Anomaly Detection",
    "abstract": "Comments: Accepted by BMVC 2021",
    "descriptor": "\nComments: Accepted by BMVC 2021\n",
    "authors": [
      "Chaoqin Huang",
      "Fei Ye",
      "Peisen Zhao",
      "Ya Zhang",
      "Yan-Feng Wang",
      "Qi Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.04905"
  },
  {
    "id": "arXiv:2012.06774",
    "title": "A network analysis on cloud gaming: Stadia, GeForce Now and PSNow",
    "abstract": "A network analysis on cloud gaming: Stadia, GeForce Now and PSNow",
    "descriptor": "",
    "authors": [
      "Andrea Di Domenico",
      "Gianluca Perna",
      "Martino Trevisan",
      "Luca Vassio",
      "Danilo Giordano"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2012.06774"
  },
  {
    "id": "arXiv:2012.08610",
    "title": "Distributed Wasserstein Barycenters via Displacement Interpolation",
    "abstract": "Comments: 25 pages, 4 figures",
    "descriptor": "\nComments: 25 pages, 4 figures\n",
    "authors": [
      "Pedro Cisneros-Velarde",
      "Francesco Bullo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2012.08610"
  },
  {
    "id": "arXiv:2012.10644",
    "title": "A Game-Theoretic Framework for Coexistence of WiFi and Cellular Networks  in the 6-GHz Unlicensed Spectrum",
    "abstract": "Comments: 28 pages, 16 figures, 1 table. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: 28 pages, 16 figures, 1 table. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Aniq Ur Rahman",
      "Mustafa A. Kishk",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Science and Game Theory (cs.GT)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2012.10644"
  },
  {
    "id": "arXiv:2012.11982",
    "title": "Direct Quantum Communications in the Presence of Realistic Noisy  Entanglement",
    "abstract": "Comments: Accepted for publication in IEEE Transactions on Communications",
    "descriptor": "\nComments: Accepted for publication in IEEE Transactions on Communications\n",
    "authors": [
      "Daryus Chandra",
      "Angela Sara Cacciapuoti",
      "Marcello Caleffi",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2012.11982"
  },
  {
    "id": "arXiv:2012.13720",
    "title": "Learning Inter- and Intraframe Representations for Non-Lambertian  Photometric Stereo",
    "abstract": "Comments: 9 pages,8 figures",
    "descriptor": "\nComments: 9 pages,8 figures\n",
    "authors": [
      "Yanlong Cao",
      "Binjie Ding",
      "Zewei He",
      "Jiangxin Yang",
      "Jingxi Chen",
      "Yanpeng Cao",
      "Xin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.13720"
  },
  {
    "id": "arXiv:2101.02118",
    "title": "Do We Really Need Deep Learning Models for Time Series Forecasting?",
    "abstract": "Comments: 14 pages with appendix, 1 figure",
    "descriptor": "\nComments: 14 pages with appendix, 1 figure\n",
    "authors": [
      "Shereen Elsayed",
      "Daniela Thyssens",
      "Ahmed Rashed",
      "Hadi Samer Jomaa",
      "Lars Schmidt-Thieme"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2101.02118"
  },
  {
    "id": "arXiv:2101.02763",
    "title": "Quasi-static crack propagation with a Griffith criterion using a  variational discrete element method",
    "abstract": "Comments: 19 pages, 20 figures",
    "descriptor": "\nComments: 19 pages, 20 figures\n",
    "authors": [
      "Fr\u00e9d\u00e9ric Marazzato",
      "Alexandre Ern",
      "Laurent Monasse"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2101.02763"
  },
  {
    "id": "arXiv:2101.04281",
    "title": "Temporally Guided Articulated Hand Pose Tracking in Surgical Videos",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Nathan Louis",
      "Luowei Zhou",
      "Steven J. Yule",
      "Roger D. Dias",
      "Milisa Manojlovich",
      "Francis D. Pagani",
      "Donald S. Likosky",
      "Jason J. Corso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.04281"
  },
  {
    "id": "arXiv:2101.04516",
    "title": "Machine learning based automated identification of thunderstorms from  anemometric records using shapelet transform",
    "abstract": "Machine learning based automated identification of thunderstorms from  anemometric records using shapelet transform",
    "descriptor": "",
    "authors": [
      "Monica Arul",
      "Ahsan Kareem"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.04516"
  },
  {
    "id": "arXiv:2101.06053",
    "title": "The Multimodal Sentiment Analysis in Car Reviews (MuSe-CaR) Dataset:  Collection, Insights and Improvements",
    "abstract": "Comments: accepted version",
    "descriptor": "\nComments: accepted version\n",
    "authors": [
      "Lukas Stappen",
      "Alice Baird",
      "Lea Schumann",
      "Bj\u00f6rn Schuller"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2101.06053"
  },
  {
    "id": "arXiv:2101.06894",
    "title": "Kimera: from SLAM to Spatial Perception with 3D Dynamic Scene Graphs",
    "abstract": "Comments: 34 pages, 25 figures, 9 tables. arXiv admin note: text overlap with arXiv:2002.06289",
    "descriptor": "\nComments: 34 pages, 25 figures, 9 tables. arXiv admin note: text overlap with arXiv:2002.06289\n",
    "authors": [
      "Antoni Rosinol",
      "Andrew Violette",
      "Marcus Abate",
      "Nathan Hughes",
      "Yun Chang",
      "Jingnan Shi",
      "Arjun Gupta",
      "Luca Carlone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.06894"
  },
  {
    "id": "arXiv:2101.07536",
    "title": "Multisymplectic Hamiltonian Variational Integrators",
    "abstract": "Comments: 45 pages, 9 figures",
    "descriptor": "\nComments: 45 pages, 9 figures\n",
    "authors": [
      "Brian Tran",
      "Melvin Leok"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2101.07536"
  },
  {
    "id": "arXiv:2101.09258",
    "title": "Maximum Likelihood Training of Score-Based Diffusion Models",
    "abstract": "Comments: NeurIPS 2021 (Spotlight)",
    "descriptor": "\nComments: NeurIPS 2021 (Spotlight)\n",
    "authors": [
      "Yang Song",
      "Conor Durkan",
      "Iain Murray",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.09258"
  },
  {
    "id": "arXiv:2101.09563",
    "title": "Pr\u00e4zi: From Package-based to Call-based Dependency Networks",
    "abstract": "Comments: 42 pages, 14 figures, journal",
    "descriptor": "\nComments: 42 pages, 14 figures, journal\n",
    "authors": [
      "Joseph Hejderup",
      "Moritz Beller",
      "Konstantinos Triantafyllou",
      "Georgios Gousios"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2101.09563"
  },
  {
    "id": "arXiv:2101.11898",
    "title": "HEMVIP: Human Evaluation of Multiple Videos in Parallel",
    "abstract": "Comments: 6 pages, 1 figures. Proceedings of the 22th ACM International Conference on Multimodal Interaction. 2021. Montreal, Canada",
    "descriptor": "\nComments: 6 pages, 1 figures. Proceedings of the 22th ACM International Conference on Multimodal Interaction. 2021. Montreal, Canada\n",
    "authors": [
      "Patrik Jonell",
      "Youngwoo Yoon",
      "Pieter Wolfert",
      "Taras Kucherenko",
      "Gustav Eje Henter"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2101.11898"
  },
  {
    "id": "arXiv:2102.02400",
    "title": "Provably End-to-end Label-Noise Learning without Anchor Points",
    "abstract": "Provably End-to-end Label-Noise Learning without Anchor Points",
    "descriptor": "",
    "authors": [
      "Xuefeng Li",
      "Tongliang Liu",
      "Bo Han",
      "Gang Niu",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.02400"
  },
  {
    "id": "arXiv:2102.02926",
    "title": "Alchemy: A benchmark and analysis toolkit for meta-reinforcement  learning agents",
    "abstract": "Comments: Published in Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 2021",
    "descriptor": "\nComments: Published in Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 2021\n",
    "authors": [
      "Jane X. Wang",
      "Michael King",
      "Nicolas Porcel",
      "Zeb Kurth-Nelson",
      "Tina Zhu",
      "Charlie Deck",
      "Peter Choy",
      "Mary Cassin",
      "Malcolm Reynolds",
      "Francis Song",
      "Gavin Buttimore",
      "David P. Reichert",
      "Neil Rabinowitz",
      "Loic Matthey",
      "Demis Hassabis",
      "Alexander Lerchner",
      "Matthew Botvinick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.02926"
  },
  {
    "id": "arXiv:2102.03316",
    "title": "Randomized Controlled Trials without Data Retention",
    "abstract": "Comments: 6 pages, 1 figure, version presented at 2021 Conference on Digital Experimentation (CODE@MIT)",
    "descriptor": "\nComments: 6 pages, 1 figure, version presented at 2021 Conference on Digital Experimentation (CODE@MIT)\n",
    "authors": [
      "Winston Chou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2102.03316"
  },
  {
    "id": "arXiv:2102.04373",
    "title": "Partition-based formulations for mixed-integer optimization of trained  ReLU neural networks",
    "abstract": "Comments: Conference on Neural Information Processing Systems (NeurIPS) 2021",
    "descriptor": "\nComments: Conference on Neural Information Processing Systems (NeurIPS) 2021\n",
    "authors": [
      "Calvin Tsay",
      "Jan Kronqvist",
      "Alexander Thebelt",
      "Ruth Misener"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.04373"
  },
  {
    "id": "arXiv:2102.05502",
    "title": "On the Suboptimality of Thompson Sampling in High Dimensions",
    "abstract": "Comments: Neurips 2021 - 34 pages",
    "descriptor": "\nComments: Neurips 2021 - 34 pages\n",
    "authors": [
      "Raymond Zhang",
      "Richard Combes"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.05502"
  },
  {
    "id": "arXiv:2102.05872",
    "title": "Onoma-to-wave: Environmental sound synthesis from onomatopoeic words",
    "abstract": "Comments: Submitted to APSIPA Transactions on Signal and Information Processing",
    "descriptor": "\nComments: Submitted to APSIPA Transactions on Signal and Information Processing\n",
    "authors": [
      "Yuki Okamoto",
      "Keisuke Imoto",
      "Shinnosuke Takamichi",
      "Ryosuke Yamanishi",
      "Takahiro Fukumori",
      "Yoichi Yamashita"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2102.05872"
  },
  {
    "id": "arXiv:2102.06024",
    "title": "Feature Selection for Multivariate Time Series via Network Pruning",
    "abstract": "Comments: In ICDM 2021 Workshop on Systematic Feature Engineering for Time-Series Data Mining (SFE-TSDM)",
    "descriptor": "\nComments: In ICDM 2021 Workshop on Systematic Feature Engineering for Time-Series Data Mining (SFE-TSDM)\n",
    "authors": [
      "Kang Gu",
      "Soroush Vosoughi",
      "Temiloluwa Prioleau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.06024"
  },
  {
    "id": "arXiv:2102.06406",
    "title": "A Too-Good-to-be-True Prior to Reduce Shortcut Reliance",
    "abstract": "Comments: 10 pages, 8 figures",
    "descriptor": "\nComments: 10 pages, 8 figures\n",
    "authors": [
      "Nikolay Dagaev",
      "Brett D. Roads",
      "Xiaoliang Luo",
      "Daniel N. Barry",
      "Kaustubh R. Patil",
      "Bradley C. Love"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.06406"
  },
  {
    "id": "arXiv:2102.06440",
    "title": "Interview Hoarding",
    "abstract": "Interview Hoarding",
    "descriptor": "",
    "authors": [
      "Vikram Manjunath",
      "Thayer Morrill"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2102.06440"
  },
  {
    "id": "arXiv:2102.06985",
    "title": "Discounting the Past",
    "abstract": "Discounting the Past",
    "descriptor": "",
    "authors": [
      "Taylor Dohmen",
      "Ashutosh Trivedi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2102.06985"
  },
  {
    "id": "arXiv:2102.07937",
    "title": "Inverse Reinforcement Learning in a Continuous State Space with Formal  Guarantees",
    "abstract": "Inverse Reinforcement Learning in a Continuous State Space with Formal  Guarantees",
    "descriptor": "",
    "authors": [
      "Gregory Dexter",
      "Kevin Bello",
      "Jean Honorio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.07937"
  },
  {
    "id": "arXiv:2102.08124",
    "title": "Accelerated Sparse Neural Training: A Provable and Efficient Method to  Find N:M Transposable Masks",
    "abstract": "Accelerated Sparse Neural Training: A Provable and Efficient Method to  Find N:M Transposable Masks",
    "descriptor": "",
    "authors": [
      "Itay Hubara",
      "Brian Chmiel",
      "Moshe Island",
      "Ron Banner",
      "Seffi Naor",
      "Daniel Soudry"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.08124"
  },
  {
    "id": "arXiv:2102.08866",
    "title": "IoTDevID: A Behavior-Based Device Identification Method for the IoT",
    "abstract": "IoTDevID: A Behavior-Based Device Identification Method for the IoT",
    "descriptor": "",
    "authors": [
      "Kahraman Kostas",
      "Mike Just",
      "Michael A. Lones"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2102.08866"
  },
  {
    "id": "arXiv:2102.08880",
    "title": "Fast Approximate Dynamic Programming for Infinite-Horizon Markov  Decision Processes",
    "abstract": "Fast Approximate Dynamic Programming for Infinite-Horizon Markov  Decision Processes",
    "descriptor": "",
    "authors": [
      "M. A. S. Kolarijani",
      "G. F. Max",
      "P. Mohajerin Esfahani"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.08880"
  },
  {
    "id": "arXiv:2102.09030",
    "title": "Bringing Differential Private SGD to Practice: On the Independence of  Gaussian Noise and the Number of Training Rounds",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2007.09208",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2007.09208\n",
    "authors": [
      "Marten van Dijk",
      "Nhuong V. Nguyen",
      "Toan N. Nguyen",
      "Lam M. Nguyen",
      "Phuong Ha Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.09030"
  },
  {
    "id": "arXiv:2102.09671",
    "title": "When Are Solutions Connected in Deep Networks?",
    "abstract": "Comments: Accepted at NeurIPS 2021",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Quynh Nguyen",
      "Pierre Brechet",
      "Marco Mondelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.09671"
  },
  {
    "id": "arXiv:2102.10131",
    "title": "Scaling up DNA digital data storage by efficiently predicting DNA  hybridisation using deep learning",
    "abstract": "Comments: 30 pages, 6 figures (including 13 pages of supplementary information and 2 supplementary figures)",
    "descriptor": "\nComments: 30 pages, 6 figures (including 13 pages of supplementary information and 2 supplementary figures)\n",
    "authors": [
      "David Buterez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2102.10131"
  },
  {
    "id": "arXiv:2102.10745",
    "title": "Feature-level Attentive ICF for Recommendation",
    "abstract": "Comments: Accepted by ACM TOIS; 24 pages, 6 figures",
    "descriptor": "\nComments: Accepted by ACM TOIS; 24 pages, 6 figures\n",
    "authors": [
      "Zhiyong Cheng",
      "Fan Liu",
      "Shenghan Mei",
      "Yangyang Guo",
      "Lei Zhu",
      "Liqiang Nie"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2102.10745"
  },
  {
    "id": "arXiv:2102.10873",
    "title": "Non-linear, Sparse Dimensionality Reduction via Path Lasso Penalized  Autoencoders",
    "abstract": "Non-linear, Sparse Dimensionality Reduction via Path Lasso Penalized  Autoencoders",
    "descriptor": "",
    "authors": [
      "Oskar Allerbo",
      "Rebecka J\u00f6rnsten"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2102.10873"
  },
  {
    "id": "arXiv:2102.12919",
    "title": "Distribution-Free Robust Linear Regression",
    "abstract": "Comments: 29 pages, to appear in Mathematical Statistics and Learning",
    "descriptor": "\nComments: 29 pages, to appear in Mathematical Statistics and Learning\n",
    "authors": [
      "Jaouad Mourtada",
      "Tomas Va\u0161kevi\u010dius",
      "Nikita Zhivotovskiy"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.12919"
  },
  {
    "id": "arXiv:2102.13519",
    "title": "PredDiff: Explanations and Interactions from Conditional Expectations",
    "abstract": "Comments: 28 pages, 13 Figures, major revision (completeness relation, new experiments, comparison to Shapley values), code available at this https URL",
    "descriptor": "\nComments: 28 pages, 13 Figures, major revision (completeness relation, new experiments, comparison to Shapley values), code available at this https URL\n",
    "authors": [
      "Stefan Bl\u00fccher",
      "Johanna Vielhaben",
      "Nils Strodthoff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.13519"
  },
  {
    "id": "arXiv:2103.01133",
    "title": "Posterior Meta-Replay for Continual Learning",
    "abstract": "Comments: Published at NeurIPS 2021",
    "descriptor": "\nComments: Published at NeurIPS 2021\n",
    "authors": [
      "Christian Henning",
      "Maria R. Cervera",
      "Francesco D'Angelo",
      "Johannes von Oswald",
      "Regina Traber",
      "Benjamin Ehret",
      "Seijin Kobayashi",
      "Benjamin F. Grewe",
      "Jo\u00e3o Sacramento"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.01133"
  },
  {
    "id": "arXiv:2103.01148",
    "title": "Class Means as an Early Exit Decision Mechanism",
    "abstract": "Class Means as an Early Exit Decision Mechanism",
    "descriptor": "",
    "authors": [
      "Alperen Gormez",
      "Erdem Koyuncu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.01148"
  },
  {
    "id": "arXiv:2103.01203",
    "title": "Generating Probabilistic Safety Guarantees for Neural Network  Controllers",
    "abstract": "Comments: 31 pages, 19 figures",
    "descriptor": "\nComments: 31 pages, 19 figures\n",
    "authors": [
      "Sydney M. Katz",
      "Kyle D. Julian",
      "Christopher A. Strong",
      "Mykel J. Kochenderfer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.01203"
  },
  {
    "id": "arXiv:2103.02517",
    "title": "EllipsoidNet: Ellipsoid Representation for Point Cloud Classification  and Segmentation",
    "abstract": "Comments: 11 pages, accepted by WACV 2022",
    "descriptor": "\nComments: 11 pages, accepted by WACV 2022\n",
    "authors": [
      "Yecheng Lyu",
      "Xinming Huang",
      "Ziming Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.02517"
  },
  {
    "id": "arXiv:2103.03104",
    "title": "Learning to run a Power Network Challenge: a Retrospective Analysis",
    "abstract": "Learning to run a Power Network Challenge: a Retrospective Analysis",
    "descriptor": "",
    "authors": [
      "Antoine Marot",
      "Benjamin Donnot",
      "Gabriel Dulac-Arnold",
      "Adrian Kelly",
      "A\u00efdan O'Sullivan",
      "Jan Viebahn",
      "Mariette Awad",
      "Isabelle Guyon",
      "Patrick Panciatici",
      "Camilo Romero"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.03104"
  },
  {
    "id": "arXiv:2103.04027",
    "title": "Learning to Predict Vehicle Trajectories with Model-based Planning",
    "abstract": "Comments: Accepted by The Conference on Robot Learning (CoRL) 2021. Project page at this http URL",
    "descriptor": "\nComments: Accepted by The Conference on Robot Learning (CoRL) 2021. Project page at this http URL\n",
    "authors": [
      "Haoran Song",
      "Di Luan",
      "Wenchao Ding",
      "Michael Yu Wang",
      "Qifeng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.04027"
  },
  {
    "id": "arXiv:2103.07601",
    "title": "Approximating How Single Head Attention Learns",
    "abstract": "Approximating How Single Head Attention Learns",
    "descriptor": "",
    "authors": [
      "Charlie Snell",
      "Ruiqi Zhong",
      "Dan Klein",
      "Jacob Steinhardt"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.07601"
  },
  {
    "id": "arXiv:2103.09430",
    "title": "OGB-LSC: A Large-Scale Challenge for Machine Learning on Graphs",
    "abstract": "Comments: KDD Cup 2021. NeurIPS Datasets and Benchmarks Track 2021",
    "descriptor": "\nComments: KDD Cup 2021. NeurIPS Datasets and Benchmarks Track 2021\n",
    "authors": [
      "Weihua Hu",
      "Matthias Fey",
      "Hongyu Ren",
      "Maho Nakata",
      "Yuxiao Dong",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.09430"
  },
  {
    "id": "arXiv:2103.11790",
    "title": "Language Models have a Moral Dimension",
    "abstract": "Language Models have a Moral Dimension",
    "descriptor": "",
    "authors": [
      "Patrick Schramowski",
      "Cigdem Turan",
      "Nico Andersen",
      "Constantin Rothkopf",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2103.11790"
  },
  {
    "id": "arXiv:2103.12690",
    "title": "An Exponential Lower Bound for Linearly-Realizable MDPs with Constant  Suboptimality Gap",
    "abstract": "An Exponential Lower Bound for Linearly-Realizable MDPs with Constant  Suboptimality Gap",
    "descriptor": "",
    "authors": [
      "Yuanhao Wang",
      "Ruosong Wang",
      "Sham M. Kakade"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.12690"
  },
  {
    "id": "arXiv:2103.13338",
    "title": "Incremental Nonlinear Stability Analysis of Stochastic Systems Perturbed  by L\u00e9vy Noise",
    "abstract": "Incremental Nonlinear Stability Analysis of Stochastic Systems Perturbed  by L\u00e9vy Noise",
    "descriptor": "",
    "authors": [
      "SooJean Han",
      "Soon-Jo Chung"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2103.13338"
  },
  {
    "id": "arXiv:2103.13646",
    "title": "Contrast to Divide: Self-Supervised Pre-Training for Learning with Noisy  Labels",
    "abstract": "Contrast to Divide: Self-Supervised Pre-Training for Learning with Noisy  Labels",
    "descriptor": "",
    "authors": [
      "Evgenii Zheltonozhskii",
      "Chaim Baskin",
      "Avi Mendelson",
      "Alex M. Bronstein",
      "Or Litany"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.13646"
  },
  {
    "id": "arXiv:2104.03437",
    "title": "CAPTRA: CAtegory-level Pose Tracking for Rigid and Articulated Objects  from Point Clouds",
    "abstract": "Comments: ICCV 2021 (Oral). Project page: this https URL",
    "descriptor": "\nComments: ICCV 2021 (Oral). Project page: this https URL\n",
    "authors": [
      "Yijia Weng",
      "He Wang",
      "Qiang Zhou",
      "Yuzhe Qin",
      "Yueqi Duan",
      "Qingnan Fan",
      "Baoquan Chen",
      "Hao Su",
      "Leonidas J. Guibas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.03437"
  },
  {
    "id": "arXiv:2104.04580",
    "title": "Predicting the Reproducibility of Social and Behavioral Science Papers  Using Supervised Learning Models",
    "abstract": "Comments: 17 pages, 8 figures",
    "descriptor": "\nComments: 17 pages, 8 figures\n",
    "authors": [
      "Jian Wu",
      "Rajal Nivargi",
      "Sree Sai Teja Lanka",
      "Arjun Manoj Menon",
      "Sai Ajay Modukuri",
      "Nishanth Nakshatri",
      "Xin Wei",
      "Zhuoer Wang",
      "James Caverlee",
      "Sarah M. Rajtmajer",
      "C. Lee Giles"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.04580"
  },
  {
    "id": "arXiv:2104.06714",
    "title": "Lazy Parameter Tuning and Control: Choosing All Parameters Randomly From  a Power-Law Distribution",
    "abstract": "Comments: Extended version of the paper accepted to GECCO 2021, including all the proofs omitted in the conference version",
    "descriptor": "\nComments: Extended version of the paper accepted to GECCO 2021, including all the proofs omitted in the conference version\n",
    "authors": [
      "Denis Antipov",
      "Maxim Buzdalov",
      "Benjamin Doerr"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2104.06714"
  },
  {
    "id": "arXiv:2104.06926",
    "title": "Optimizing Response Time in SDN-Edge Environments for Time-Strict IoT  Applications",
    "abstract": "Comments: Submitted to IEEE Internet of Things Journal",
    "descriptor": "\nComments: Submitted to IEEE Internet of Things Journal\n",
    "authors": [
      "Juan Luis Herrera",
      "Jaime Gal\u00e1n-Jim\u00e9nez",
      "Javier Berrocal",
      "Juan Manuel Murillo"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2104.06926"
  },
  {
    "id": "arXiv:2104.07961",
    "title": "Advanced Deep Networks for 3D Mitochondria Instance Segmentation",
    "abstract": "Advanced Deep Networks for 3D Mitochondria Instance Segmentation",
    "descriptor": "",
    "authors": [
      "Mingxing Li",
      "Chang Chen",
      "Xiaoyu Liu",
      "Wei Huang",
      "Yueyi Zhang",
      "Zhiwei Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.07961"
  },
  {
    "id": "arXiv:2104.08663",
    "title": "BEIR: A Heterogenous Benchmark for Zero-shot Evaluation of Information  Retrieval Models",
    "abstract": "Comments: Accepted at NeurIPS 2021 Dataset and Benchmark Track",
    "descriptor": "\nComments: Accepted at NeurIPS 2021 Dataset and Benchmark Track\n",
    "authors": [
      "Nandan Thakur",
      "Nils Reimers",
      "Andreas R\u00fcckl\u00e9",
      "Abhishek Srivastava",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08663"
  },
  {
    "id": "arXiv:2104.08667",
    "title": "SIMMC 2.0: A Task-oriented Dialog Dataset for Immersive Multimodal  Conversations",
    "abstract": "Comments: 10 pages, 7 figures, 5 tables",
    "descriptor": "\nComments: 10 pages, 7 figures, 5 tables\n",
    "authors": [
      "Satwik Kottur",
      "Seungwhan Moon",
      "Alborz Geramifard",
      "Babak Damavandi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.08667"
  },
  {
    "id": "arXiv:2104.08690",
    "title": "Rethinking Image-Scaling Attacks: The Interplay Between Vulnerabilities  in Machine Learning Systems",
    "abstract": "Comments: 29 pages, 16 figures, 1 table",
    "descriptor": "\nComments: 29 pages, 16 figures, 1 table\n",
    "authors": [
      "Yue Gao",
      "Ilia Shumailov",
      "Kassem Fawaz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2104.08690"
  },
  {
    "id": "arXiv:2104.08760",
    "title": "Solving Inefficiency of Self-supervised Representation Learning",
    "abstract": "Comments: ICCV 2021 paper, oral presentation",
    "descriptor": "\nComments: ICCV 2021 paper, oral presentation\n",
    "authors": [
      "Guangrun Wang",
      "Keze Wang",
      "Guangcong Wang",
      "Philip H.S. Torr",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.08760"
  },
  {
    "id": "arXiv:2104.11120",
    "title": "PyArmadillo: a streamlined linear algebra library for Python",
    "abstract": "PyArmadillo: a streamlined linear algebra library for Python",
    "descriptor": "",
    "authors": [
      "Jason Rumengan",
      "Terry Yue Zhuo",
      "Conrad Sanderson"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2104.11120"
  },
  {
    "id": "arXiv:2104.11537",
    "title": "Practical Hybrid Beamforming for Millimeter Wave Massive MIMO Full  Duplex with Limited Dynamic Range",
    "abstract": "Practical Hybrid Beamforming for Millimeter Wave Massive MIMO Full  Duplex with Limited Dynamic Range",
    "descriptor": "",
    "authors": [
      "Chandan Kumar Sheemar",
      "Christo Kurisummoottil Thomas Dirk Slock"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2104.11537"
  },
  {
    "id": "arXiv:2104.11783",
    "title": "Form 10-Q Itemization",
    "abstract": "Comments: 6 pages, 3 figures, 3 tables, this http URL",
    "descriptor": "\nComments: 6 pages, 3 figures, 3 tables, this http URL\n",
    "authors": [
      "Yanci Zhang",
      "Tianming Du",
      "Yujie Sun",
      "Lawrence Donohue",
      "Rui Dai"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "General Economics (econ.GN)",
      "General Finance (q-fin.GN)"
    ],
    "url": "https://arxiv.org/abs/2104.11783"
  },
  {
    "id": "arXiv:2104.13130",
    "title": "Secure and Efficient Federated Learning Through Layering and Sharding  Blockchain",
    "abstract": "Secure and Efficient Federated Learning Through Layering and Sharding  Blockchain",
    "descriptor": "",
    "authors": [
      "Shuo Yuan",
      "Bin Cao",
      "Yao Sun",
      "Mugen Peng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2104.13130"
  },
  {
    "id": "arXiv:2104.14553",
    "title": "MarioNette: Self-Supervised Sprite Learning",
    "abstract": "Comments: Accepted to NeurIPS 2021",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Dmitriy Smirnov",
      "Michael Gharbi",
      "Matthew Fisher",
      "Vitor Guizilini",
      "Alexei A. Efros",
      "Justin Solomon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.14553"
  },
  {
    "id": "arXiv:2104.14995",
    "title": "Interpretable Semantic Photo Geolocation",
    "abstract": "Comments: Accepted for publication at WACV'22",
    "descriptor": "\nComments: Accepted for publication at WACV'22\n",
    "authors": [
      "Jonas Theiner",
      "Eric Mueller-Budack",
      "Ralph Ewerth"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.14995"
  },
  {
    "id": "arXiv:2105.00278",
    "title": "A Perceptual Distortion Reduction Framework: Towards Generating  Adversarial Examples with High Perceptual Quality and Attack Success Rate",
    "abstract": "Comments: 8 pages, 4 figures",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Ruijie Yang",
      "Yunhong Wang",
      "Ruikui Wang",
      "Yuanfang Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.00278"
  },
  {
    "id": "arXiv:2105.00287",
    "title": "The complexity of approximating the complex-valued Ising model on  bounded degree graphs",
    "abstract": "Comments: 49 pages, 9 figures On last update: minor changes, references have been updated and some definitions have been moved from the appendix to the main text",
    "descriptor": "\nComments: 49 pages, 9 figures On last update: minor changes, references have been updated and some definitions have been moved from the appendix to the main text\n",
    "authors": [
      "Andreas Galanis",
      "Leslie Ann Goldberg",
      "Andr\u00e9s Herrera-Poyatos"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2105.00287"
  },
  {
    "id": "arXiv:2105.01882",
    "title": "A Robotic Approach towards Quantifying Epipelagic Bound Plastic Using  Deep Visual Models",
    "abstract": "Comments: 8 Pages, 6 Figures, 2 Tables - Added Paragraph for Code Availability - Submitted preprint to Elsevier",
    "descriptor": "\nComments: 8 Pages, 6 Figures, 2 Tables - Added Paragraph for Code Availability - Submitted preprint to Elsevier\n",
    "authors": [
      "Gautam Tata",
      "Sarah-Jeanne Royer",
      "Olivier Poirion",
      "Jay Lowe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.01882"
  },
  {
    "id": "arXiv:2105.02186",
    "title": "RandCrowns: A Quantitative Metric for Imprecisely Labeled Tree Crown  Delineation",
    "abstract": "RandCrowns: A Quantitative Metric for Imprecisely Labeled Tree Crown  Delineation",
    "descriptor": "",
    "authors": [
      "Dylan Stewart",
      "Alina Zare",
      "Sergio Marconi",
      "Ben G. Weinstein",
      "Ethan P. White",
      "Sarah J. Graves",
      "Stephanie A. Bohlman",
      "Aditya Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.02186"
  },
  {
    "id": "arXiv:2105.03492",
    "title": "Human-Aided Saliency Maps Improve Generalization of Deep Learning",
    "abstract": "Comments: To appear at WACV 2022",
    "descriptor": "\nComments: To appear at WACV 2022\n",
    "authors": [
      "Aidan Boyd",
      "Kevin Bowyer",
      "Adam Czajka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03492"
  },
  {
    "id": "arXiv:2105.04040",
    "title": "Truly shift-equivariant convolutional neural networks with adaptive  polyphase upsampling",
    "abstract": "Truly shift-equivariant convolutional neural networks with adaptive  polyphase upsampling",
    "descriptor": "",
    "authors": [
      "Anadi Chaman",
      "Ivan Dokmani\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.04040"
  },
  {
    "id": "arXiv:2105.05956",
    "title": "2022 Roadmap on Neuromorphic Computing and Engineering",
    "abstract": "2022 Roadmap on Neuromorphic Computing and Engineering",
    "descriptor": "",
    "authors": [
      "Dennis V. Christensen",
      "Regina Dittmann",
      "Bernab\u00e9 Linares-Barranco",
      "Abu Sebastian",
      "Manuel Le Gallo",
      "Andrea Redaelli",
      "Stefan Slesazeck",
      "Thomas Mikolajick",
      "Sabina Spiga",
      "Stephan Menzel",
      "Ilia Valov",
      "Gianluca Milano",
      "Carlo Ricciardi",
      "Shi-Jun Liang",
      "Feng Miao",
      "Mario Lanza",
      "Tyler J. Quill",
      "Scott T. Keene",
      "Alberto Salleo",
      "Julie Grollier",
      "Danijela Markovi\u0107",
      "Alice Mizrahi",
      "Peng Yao",
      "J. Joshua Yang",
      "Giacomo Indiveri",
      "John Paul Strachan",
      "Suman Datta",
      "Elisa Vianello",
      "Alexandre Valentian",
      "Johannes Feldmann",
      "Xuan Li",
      "Wolfram H.P. Pernice",
      "Harish Bhaskaran",
      "Steve Furber",
      "Emre Neftci",
      "Franz Scherr",
      "Wolfgang Maass",
      "Srikanth Ramaswamy",
      "Jonathan Tapson",
      "Priyadarshini Panda",
      "Youngeun Kim",
      "Gouhei Tanaka",
      "Simon Thorpe",
      "Chiara Bartolozzi",
      "Thomas A. Cleland",
      "Christoph Posch",
      "Shih-Chii Liu",
      "Gabriella Panuccio"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Materials Science (cond-mat.mtrl-sci)"
    ],
    "url": "https://arxiv.org/abs/2105.05956"
  },
  {
    "id": "arXiv:2105.06347",
    "title": "Identity testing of reversible Markov chains",
    "abstract": "Identity testing of reversible Markov chains",
    "descriptor": "",
    "authors": [
      "Sela Fried",
      "Geoffrey Wolfer"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.06347"
  },
  {
    "id": "arXiv:2105.09513",
    "title": "Deep Kronecker neural networks: A general framework for neural networks  with adaptive activation functions",
    "abstract": "Comments: 24 pages, 16 figures",
    "descriptor": "\nComments: 24 pages, 16 figures\n",
    "authors": [
      "Ameya D. Jagtap",
      "Yeonjong Shin",
      "Kenji Kawaguchi",
      "George Em Karniadakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.09513"
  },
  {
    "id": "arXiv:2105.09821",
    "title": "DEHB: Evolutionary Hyperband for Scalable, Robust and Efficient  Hyperparameter Optimization",
    "abstract": "DEHB: Evolutionary Hyperband for Scalable, Robust and Efficient  Hyperparameter Optimization",
    "descriptor": "",
    "authors": [
      "Noor Awad",
      "Neeratyoy Mallik",
      "Frank Hutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2105.09821"
  },
  {
    "id": "arXiv:2105.10347",
    "title": "Removing the mini-batching error in Bayesian inference using Adaptive  Langevin dynamics",
    "abstract": "Removing the mini-batching error in Bayesian inference using Adaptive  Langevin dynamics",
    "descriptor": "",
    "authors": [
      "Inass Sekkat",
      "Gabriel Stoltz"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.10347"
  },
  {
    "id": "arXiv:2105.10620",
    "title": "HPNet: Deep Primitive Segmentation Using Hybrid Representations",
    "abstract": "Comments: ICCV 2021",
    "descriptor": "\nComments: ICCV 2021\n",
    "authors": [
      "Siming Yan",
      "Zhenpei Yang",
      "Chongyang Ma",
      "Haibin Huang",
      "Etienne Vouga",
      "Qixing Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.10620"
  },
  {
    "id": "arXiv:2105.11901",
    "title": "An efficient iterative method for solving parameter-dependent and random  convention-diffusion problems",
    "abstract": "Comments: 25 pages, 10 tables, 20 figures",
    "descriptor": "\nComments: 25 pages, 10 tables, 20 figures\n",
    "authors": [
      "Xiaobing Feng",
      "Yan Luo",
      "Liet Vo",
      "Zhu Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.11901"
  },
  {
    "id": "arXiv:2105.12894",
    "title": "MAGI-X: Manifold-Constrained Gaussian Process Inference for Unknown  System Dynamics",
    "abstract": "MAGI-X: Manifold-Constrained Gaussian Process Inference for Unknown  System Dynamics",
    "descriptor": "",
    "authors": [
      "Chaofan Huang",
      "Simin Ma",
      "Shihao Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2105.12894"
  },
  {
    "id": "arXiv:2105.13495",
    "title": "Learning Dynamic Graph Representation of Brain Connectome with  Spatio-Temporal Attention",
    "abstract": "Comments: Accepted for NeurIPS 2021",
    "descriptor": "\nComments: Accepted for NeurIPS 2021\n",
    "authors": [
      "Byung-Hoon Kim",
      "Jong Chul Ye",
      "Jae-Jin Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2105.13495"
  },
  {
    "id": "arXiv:2105.13913",
    "title": "Simple steps are all you need: Frank-Wolfe and generalized  self-concordant functions",
    "abstract": "Simple steps are all you need: Frank-Wolfe and generalized  self-concordant functions",
    "descriptor": "",
    "authors": [
      "Alejandro Carderera",
      "Mathieu Besan\u00e7on",
      "Sebastian Pokutta"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.13913"
  },
  {
    "id": "arXiv:2105.14203",
    "title": "Understanding Instance-based Interpretability of Variational  Auto-Encoders",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Zhifeng Kong",
      "Kamalika Chaudhuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14203"
  },
  {
    "id": "arXiv:2105.14586",
    "title": "Kolmogorov-Smirnov Test-Based Actively-Adaptive Thompson Sampling for  Non-Stationary Bandits",
    "abstract": "Comments: 9 pages, 6 figures, 2 tables, 2 algorithms. Accepted at IEEE Transactions on Artificial Intelligence",
    "descriptor": "\nComments: 9 pages, 6 figures, 2 tables, 2 algorithms. Accepted at IEEE Transactions on Artificial Intelligence\n",
    "authors": [
      "Gourab Ghatak",
      "Hardhik Mohanty",
      "Aniq Ur Rahman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2105.14586"
  },
  {
    "id": "arXiv:2106.00252",
    "title": "Information-Theoretic Analysis of Epistemic Uncertainty in Bayesian  Meta-learning",
    "abstract": "Comments: Under review",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Sharu Theresa Jose",
      "Sangwoo Park",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.00252"
  },
  {
    "id": "arXiv:2106.01528",
    "title": "Normalizing Flows for Knockoff-free Controlled Feature Selection",
    "abstract": "Comments: 20 pages, 9 figures, 3 tables",
    "descriptor": "\nComments: 20 pages, 9 figures, 3 tables\n",
    "authors": [
      "Derek Hansen",
      "Brian Manzo",
      "Jeffrey Regier"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01528"
  },
  {
    "id": "arXiv:2106.02320",
    "title": "Few-Shot Segmentation via Cycle-Consistent Transformer",
    "abstract": "Comments: Accepted by NeurIPS 2021",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Gengwei Zhang",
      "Guoliang Kang",
      "Yunchao Wei",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02320"
  },
  {
    "id": "arXiv:2106.02496",
    "title": "Quantum Perceptron Revisited: Computational-Statistical Tradeoffs",
    "abstract": "Comments: 12 pages, 4 figures",
    "descriptor": "\nComments: 12 pages, 4 figures\n",
    "authors": [
      "Mathieu Roget",
      "Giuseppe Di Molfetta",
      "Hachem Kadri"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02496"
  },
  {
    "id": "arXiv:2106.02594",
    "title": "Self-Supervised Learning of Domain Invariant Features for Depth  Estimation",
    "abstract": "Comments: 14 pages: 8 main pages with supplementary materials, accepted to WACV2022",
    "descriptor": "\nComments: 14 pages: 8 main pages with supplementary materials, accepted to WACV2022\n",
    "authors": [
      "Hiroyasu Akada",
      "Shariq Farooq Bhat",
      "Ibraheem Alhashim",
      "Peter Wonka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02594"
  },
  {
    "id": "arXiv:2106.04193",
    "title": "Targeted Active Learning for Bayesian Decision-Making",
    "abstract": "Targeted Active Learning for Bayesian Decision-Making",
    "descriptor": "",
    "authors": [
      "Louis Filstroff",
      "Iiris Sundin",
      "Petrus Mikkola",
      "Aleksei Tiulpin",
      "Juuso Kylm\u00e4oja",
      "Samuel Kaski"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.04193"
  },
  {
    "id": "arXiv:2106.04911",
    "title": "Memory-based Optimization Methods for Model-Agnostic Meta-Learning",
    "abstract": "Comments: v2 adds a new variant that has the similar convergence rate without the bounded gradient assumption and includes more baselines in the experiments",
    "descriptor": "\nComments: v2 adds a new variant that has the similar convergence rate without the bounded gradient assumption and includes more baselines in the experiments\n",
    "authors": [
      "Bokun Wang",
      "Zhuoning Yuan",
      "Yiming Ying",
      "Tianbao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.04911"
  },
  {
    "id": "arXiv:2106.04927",
    "title": "A Bi-Level Framework for Learning to Solve Combinatorial Optimization on  Graphs",
    "abstract": "Comments: NeurIPS 2021. Code at this https URL",
    "descriptor": "\nComments: NeurIPS 2021. Code at this https URL\n",
    "authors": [
      "Runzhong Wang",
      "Zhigang Hua",
      "Gan Liu",
      "Jiayi Zhang",
      "Junchi Yan",
      "Feng Qi",
      "Shuang Yang",
      "Jun Zhou",
      "Xiaokang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.04927"
  },
  {
    "id": "arXiv:2106.05669",
    "title": "Information Geometry of Reversible Markov Chains",
    "abstract": "Information Geometry of Reversible Markov Chains",
    "descriptor": "",
    "authors": [
      "Geoffrey Wolfer",
      "Shun Watanabe"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.05669"
  },
  {
    "id": "arXiv:2106.05967",
    "title": "Revisiting Contrastive Methods for Unsupervised Learning of Visual  Representations",
    "abstract": "Comments: NeurIPS 2021. Code: this https URL",
    "descriptor": "\nComments: NeurIPS 2021. Code: this https URL\n",
    "authors": [
      "Wouter Van Gansbeke",
      "Simon Vandenhende",
      "Stamatios Georgoulis",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05967"
  },
  {
    "id": "arXiv:2106.07226",
    "title": "More Real than Real: A Study on Human Visual Perception of Synthetic  Faces",
    "abstract": "More Real than Real: A Study on Human Visual Perception of Synthetic  Faces",
    "descriptor": "",
    "authors": [
      "Federica Lago",
      "Cecilia Pasquini",
      "Rainer B\u00f6hme",
      "H\u00e9l\u00e8ne Dumont",
      "Val\u00e9rie Goffaux",
      "Giulia Boato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.07226"
  },
  {
    "id": "arXiv:2106.07767",
    "title": "On the Relationship between Heterophily and Robustness of Graph Neural  Networks",
    "abstract": "Comments: preprint with appendix; 31 pages, 1 figure",
    "descriptor": "\nComments: preprint with appendix; 31 pages, 1 figure\n",
    "authors": [
      "Jiong Zhu",
      "Junchen Jin",
      "Donald Loveland",
      "Michael T. Schaub",
      "Danai Koutra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07767"
  },
  {
    "id": "arXiv:2106.08229",
    "title": "MICo: Improved representations via sampling-based state similarity for  Markov decision processes",
    "abstract": "Comments: Published at NeurIPS 2021",
    "descriptor": "\nComments: Published at NeurIPS 2021\n",
    "authors": [
      "Pablo Samuel Castro",
      "Tyler Kastner",
      "Prakash Panangaden",
      "Mark Rowland"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08229"
  },
  {
    "id": "arXiv:2106.08601",
    "title": "Self-Supervised GANs with Label Augmentation",
    "abstract": "Comments: Accepted at NeurIPS 2021",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Liang Hou",
      "Huawei Shen",
      "Qi Cao",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08601"
  },
  {
    "id": "arXiv:2106.09608",
    "title": "Learning Knowledge Graph-based World Models of Textual Environments",
    "abstract": "Comments: Camera read, in Proceedings of NeurIPS 2021 Main Conference",
    "descriptor": "\nComments: Camera read, in Proceedings of NeurIPS 2021 Main Conference\n",
    "authors": [
      "Prithviraj Ammanabrolu",
      "Mark O. Riedl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.09608"
  },
  {
    "id": "arXiv:2106.09992",
    "title": "Exploring Counterfactual Explanations Through the Lens of Adversarial  Examples: A Theoretical and Empirical Analysis",
    "abstract": "Exploring Counterfactual Explanations Through the Lens of Adversarial  Examples: A Theoretical and Empirical Analysis",
    "descriptor": "",
    "authors": [
      "Martin Pawelczyk",
      "Chirag Agarwal",
      "Shalmali Joshi",
      "Sohini Upadhyay",
      "Himabindu Lakkaraju"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09992"
  },
  {
    "id": "arXiv:2106.09996",
    "title": "Equivariance-bridged SO(2)-Invariant Representation Learning using Graph  Convolutional Network",
    "abstract": "Comments: BMVC 2021",
    "descriptor": "\nComments: BMVC 2021\n",
    "authors": [
      "Sungwon Hwang",
      "Hyungtae Lim",
      "Hyun Myung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09996"
  },
  {
    "id": "arXiv:2106.10137",
    "title": "Self-supervised Video Representation Learning with Cross-Stream  Prototypical Contrasting",
    "abstract": "Comments: WACV2022",
    "descriptor": "\nComments: WACV2022\n",
    "authors": [
      "Martine Toering",
      "Ioannis Gatopoulos",
      "Maarten Stol",
      "Vincent Tao Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10137"
  },
  {
    "id": "arXiv:2106.11215",
    "title": "Machine Learning based optimization for interval uncertainty propagation",
    "abstract": "Comments: V2 - Preprint submitted to Mechanical Systems and Signal Processing",
    "descriptor": "\nComments: V2 - Preprint submitted to Mechanical Systems and Signal Processing\n",
    "authors": [
      "Alice Cicirello",
      "Filippo Giunta"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.11215"
  },
  {
    "id": "arXiv:2106.11483",
    "title": "A Comprehensive Exploration of Pre-training Language Models",
    "abstract": "Comments: working in progress",
    "descriptor": "\nComments: working in progress\n",
    "authors": [
      "Tong Guo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.11483"
  },
  {
    "id": "arXiv:2106.14771",
    "title": "HALF: Holistic Auto Machine Learning for FPGAs",
    "abstract": "Comments: 2021 31st International Conference on Field-Programmable Logic and Applications (FPL). IEEE, 2021",
    "descriptor": "\nComments: 2021 31st International Conference on Field-Programmable Logic and Applications (FPL). IEEE, 2021\n",
    "authors": [
      "Jonas Ney",
      "Dominik Loroch",
      "Vladimir Rybalkin",
      "Nico Weber",
      "Jens Kr\u00fcger",
      "Norbert Wehn"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.14771"
  },
  {
    "id": "arXiv:2106.15893",
    "title": "Fast whole-slide cartography in colon cancer histology using superpixels  and CNN classification",
    "abstract": "Comments: 26 pages, 17 figures, 5 tables, submitted to SPIE Journal of Medical Imaging",
    "descriptor": "\nComments: 26 pages, 17 figures, 5 tables, submitted to SPIE Journal of Medical Imaging\n",
    "authors": [
      "Frauke Wilm",
      "Michaela Benz",
      "Volker Bruns",
      "Serop Baghdadlian",
      "Jakob Dexl",
      "David Hartmann",
      "Petr Kuritcyn",
      "Martin Weidenfeller",
      "Thomas Wittenberg",
      "Susanne Merkel",
      "Arndt Hartmann",
      "Markus Eckstein",
      "Carol I. Geppert"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15893"
  },
  {
    "id": "arXiv:2107.00090",
    "title": "Mesh-based graph convolutional neural networks for modeling materials  with microstructure",
    "abstract": "Comments: 45 pages, 19 figures",
    "descriptor": "\nComments: 45 pages, 19 figures\n",
    "authors": [
      "Ari Frankel",
      "Cosmin Safta",
      "Coleman Alleman",
      "Reese Jones"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00090"
  },
  {
    "id": "arXiv:2107.00164",
    "title": "MIND: In-Network Memory Management for Disaggregated Data Centers",
    "abstract": "Comments: 18 pages, 9 figures, 2 tables",
    "descriptor": "\nComments: 18 pages, 9 figures, 2 tables\n",
    "authors": [
      "Seung-seob Lee",
      "Yanpeng Yu",
      "Yupeng Tang",
      "Anurag Khandelwal",
      "Lin Zhong",
      "Abhishek Bhattacharjee"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.00164"
  },
  {
    "id": "arXiv:2107.00341",
    "title": "Anti-unification of Unordered Goals",
    "abstract": "Comments: CSL 2022 paper with appendices",
    "descriptor": "\nComments: CSL 2022 paper with appendices\n",
    "authors": [
      "Gonzague Yernaux",
      "Wim Vanhoof"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.00341"
  },
  {
    "id": "arXiv:2107.00436",
    "title": "Overhead-MNIST: Machine Learning Baselines for Image Classification",
    "abstract": "Comments: 6 pages; 8 figures, 2 tables",
    "descriptor": "\nComments: 6 pages; 8 figures, 2 tables\n",
    "authors": [
      "Erik Larsen",
      "David Noever",
      "Korey MacVittie",
      "John Lilly"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00436"
  },
  {
    "id": "arXiv:2107.00729",
    "title": "Essence of Factual Knowledge",
    "abstract": "Comments: 4 pages, 1 figure",
    "descriptor": "\nComments: 4 pages, 1 figure\n",
    "authors": [
      "Ruoyu Wang",
      "Daniel Sun",
      "Guoqiang Li",
      "Raymond Wong",
      "Shiping Chen"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2107.00729"
  },
  {
    "id": "arXiv:2107.01091",
    "title": "CrowdSpeech and VoxDIY: Benchmark Datasets for Crowdsourced Audio  Transcription",
    "abstract": "CrowdSpeech and VoxDIY: Benchmark Datasets for Crowdsourced Audio  Transcription",
    "descriptor": "",
    "authors": [
      "Nikita Pavlichenko",
      "Ivan Stelmakh",
      "Dmitry Ustalov"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.01091"
  },
  {
    "id": "arXiv:2107.01724",
    "title": "Scalable Zonotopic Under-approximation of Backward Reachable Sets for  Uncertain Linear Systems",
    "abstract": "Scalable Zonotopic Under-approximation of Backward Reachable Sets for  Uncertain Linear Systems",
    "descriptor": "",
    "authors": [
      "Liren Yang",
      "Necmiye Ozay"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.01724"
  },
  {
    "id": "arXiv:2107.01850",
    "title": "Matching a Desired Causal State via Shift Interventions",
    "abstract": "Matching a Desired Causal State via Shift Interventions",
    "descriptor": "",
    "authors": [
      "Jiaqi Zhang",
      "Chandler Squires",
      "Caroline Uhler"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.01850"
  },
  {
    "id": "arXiv:2107.02067",
    "title": "Distance-based Hyperspherical Classification for Multi-source Open-Set  Domain Adaptation",
    "abstract": "Comments: accepted at WACV 2022",
    "descriptor": "\nComments: accepted at WACV 2022\n",
    "authors": [
      "Silvia Bucci",
      "Francesco Cappio Borlino",
      "Barbara Caputo",
      "Tatiana Tommasi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.02067"
  },
  {
    "id": "arXiv:2107.03748",
    "title": "Expressive Voice Conversion: A Joint Framework for Speaker Identity and  Emotional Style Transfer",
    "abstract": "Comments: Accepted to ASRU 2021",
    "descriptor": "\nComments: Accepted to ASRU 2021\n",
    "authors": [
      "Zongyang Du",
      "Berrak Sisman",
      "Kun Zhou",
      "Haizhou Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.03748"
  },
  {
    "id": "arXiv:2107.03996",
    "title": "Learning Vision-Guided Quadrupedal Locomotion End-to-End with  Cross-Modal Transformers",
    "abstract": "Comments: Our project page with videos is at this https URL",
    "descriptor": "\nComments: Our project page with videos is at this https URL\n",
    "authors": [
      "Ruihan Yang",
      "Minghao Zhang",
      "Nicklas Hansen",
      "Huazhe Xu",
      "Xiaolong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.03996"
  },
  {
    "id": "arXiv:2107.04422",
    "title": "Likelihood ratio-based policy gradient methods for distorted risk  measures: A non-asymptotic analysis",
    "abstract": "Likelihood ratio-based policy gradient methods for distorted risk  measures: A non-asymptotic analysis",
    "descriptor": "",
    "authors": [
      "Nithia Vijayan",
      "Prashanth L.A"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.04422"
  },
  {
    "id": "arXiv:2107.05328",
    "title": "Structured Directional Pruning via Perturbation Orthogonal Projection",
    "abstract": "Structured Directional Pruning via Perturbation Orthogonal Projection",
    "descriptor": "",
    "authors": [
      "Yinchuan Li",
      "Xiaofeng Liu",
      "Yunfeng Shao",
      "Qing Wang",
      "Yanhui Geng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.05328"
  },
  {
    "id": "arXiv:2107.05916",
    "title": "Towards Automatic Instrumentation by Learning to Separate Parts in  Symbolic Multitrack Music",
    "abstract": "Comments: ISMIR 2021 camera ready",
    "descriptor": "\nComments: ISMIR 2021 camera ready\n",
    "authors": [
      "Hao-Wen Dong",
      "Chris Donahue",
      "Taylor Berg-Kirkpatrick",
      "Julian McAuley"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.05916"
  },
  {
    "id": "arXiv:2107.06015",
    "title": "A Classification of Artificial Intelligence Systems for Mathematics  Education",
    "abstract": "Comments: Chapter in the upcoming book \"Mathematics Education in the Age of Artificial Intelligence: How Artificial Intelligence can serve Mathematical Human Learning\", Springer Nature, edited by P. R. Richard, P. V\\'elez, and S. Van Vaerenbergh",
    "descriptor": "\nComments: Chapter in the upcoming book \"Mathematics Education in the Age of Artificial Intelligence: How Artificial Intelligence can serve Mathematical Human Learning\", Springer Nature, edited by P. R. Richard, P. V\\'elez, and S. Van Vaerenbergh\n",
    "authors": [
      "Steven Van Vaerenbergh",
      "Adri\u00e1n P\u00e9rez-Suay"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "History and Overview (math.HO)"
    ],
    "url": "https://arxiv.org/abs/2107.06015"
  },
  {
    "id": "arXiv:2107.06617",
    "title": "Nowcasting transmission and suppression of the Delta variant of  SARS-CoV-2 in Australia",
    "abstract": "Comments: 30 pages, 13 figures",
    "descriptor": "\nComments: 30 pages, 13 figures\n",
    "authors": [
      "Sheryl L. Chang",
      "Oliver M. Cliff",
      "Cameron Zachreson",
      "Mikhail Prokopenko"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2107.06617"
  },
  {
    "id": "arXiv:2107.08319",
    "title": "Characterizing Online Engagement with Disinformation and Conspiracies in  the 2020 U.S. Presidential Election",
    "abstract": "Comments: Accepted at ICWSM'22",
    "descriptor": "\nComments: Accepted at ICWSM'22\n",
    "authors": [
      "Karishma Sharma",
      "Emilio Ferrara",
      "Yan Liu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.08319"
  },
  {
    "id": "arXiv:2107.10060",
    "title": "Conditional GANs with Auxiliary Discriminative Classifier",
    "abstract": "Conditional GANs with Auxiliary Discriminative Classifier",
    "descriptor": "",
    "authors": [
      "Liang Hou",
      "Qi Cao",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.10060"
  },
  {
    "id": "arXiv:2107.10168",
    "title": "Towards Using Package Centrality Trend to Identify Packages in Decline",
    "abstract": "Comments: Accepted in the Special Issue on Collaboration and Innovation Dynamics in Software Ecosystems",
    "descriptor": "\nComments: Accepted in the Special Issue on Collaboration and Innovation Dynamics in Software Ecosystems\n",
    "authors": [
      "Suhaib Mujahid",
      "Diego Elias Costa",
      "Rabe Abdalkareem",
      "Emad Shihab",
      "Mohamed Aymen Saied",
      "Bram Adams"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.10168"
  },
  {
    "id": "arXiv:2107.10406",
    "title": "Distributed Asynchronous Policy Iteration for Sequential Zero-Sum Games  and Minimax Control",
    "abstract": "Distributed Asynchronous Policy Iteration for Sequential Zero-Sum Games  and Minimax Control",
    "descriptor": "",
    "authors": [
      "Dimitri Bertsekas"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.10406"
  },
  {
    "id": "arXiv:2107.11629",
    "title": "ASOD60K: An Audio-Induced Salient Object Detection Dataset for Panoramic  Videos",
    "abstract": "Comments: 22 pages, 17 figures, 7 tables (Project Page: this https URL) [new revision]",
    "descriptor": "\nComments: 22 pages, 17 figures, 7 tables (Project Page: this https URL) [new revision]\n",
    "authors": [
      "Yi Zhang",
      "Fang-Yi Chao",
      "Lu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.11629"
  },
  {
    "id": "arXiv:2107.11757",
    "title": "MuSe-Toolbox: The Multimodal Sentiment Analysis Continuous Annotation  Fusion and Discrete Class Transformation Toolbox",
    "abstract": "Comments: (1) this https URL (2) docker pull musetoolbox/musetoolbox",
    "descriptor": "\nComments: (1) this https URL (2) docker pull musetoolbox/musetoolbox\n",
    "authors": [
      "Lukas Stappen",
      "Lea Schumann",
      "Benjamin Sertolli",
      "Alice Baird",
      "Benjamin Weigel",
      "Erik Cambria",
      "Bj\u00f6rn W. Schuller"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.11757"
  },
  {
    "id": "arXiv:2107.12020",
    "title": "Adiabatic quantum-flux-parametron with delay-line clocking: logic gate  demonstration and phase skipping operation",
    "abstract": "Adiabatic quantum-flux-parametron with delay-line clocking: logic gate  demonstration and phase skipping operation",
    "descriptor": "",
    "authors": [
      "Taiki Yamae",
      "Naoki Takeuchi",
      "Nobuyuki Yoshikawa"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.12020"
  },
  {
    "id": "arXiv:2107.12085",
    "title": "Learning to Adversarially Blur Visual Object Tracking",
    "abstract": "Comments: This work has been accepted to ICCV 2021",
    "descriptor": "\nComments: This work has been accepted to ICCV 2021\n",
    "authors": [
      "Qing Guo",
      "Ziyi Cheng",
      "Felix Juefei-Xu",
      "Lei Ma",
      "Xiaofei Xie",
      "Yang Liu",
      "Jianjun Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.12085"
  },
  {
    "id": "arXiv:2108.00968",
    "title": "Robust Semantic Segmentation with Superpixel-Mix",
    "abstract": "Comments: Accepted to BMVC2021",
    "descriptor": "\nComments: Accepted to BMVC2021\n",
    "authors": [
      "Gianni Franchi",
      "Nacim Belkhir",
      "Mai Lan Ha",
      "Yufei Hu",
      "Andrei Bursuc",
      "Volker Blanz",
      "Angela Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.00968"
  },
  {
    "id": "arXiv:2108.01598",
    "title": "Secure and Efficient Blockchain based Knowledge Sharing for Intelligent  Connected Vehicles",
    "abstract": "Comments: 13 pages, 11 figures",
    "descriptor": "\nComments: 13 pages, 11 figures\n",
    "authors": [
      "Haoye Chai",
      "Supeng Leng",
      "Fan Wu",
      "Jianhua He"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2108.01598"
  },
  {
    "id": "arXiv:2108.01819",
    "title": "Transfer Learning for Pose Estimation of Illustrated Characters",
    "abstract": "Comments: published at WACV2022",
    "descriptor": "\nComments: published at WACV2022\n",
    "authors": [
      "Shuhong Chen",
      "Matthias Zwicker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.01819"
  },
  {
    "id": "arXiv:2108.02999",
    "title": "Fast Algorithms and Error Analysis of Caputo Derivatives with Small  Factional Orders",
    "abstract": "Comments: 42 pages, 5 figures, submitted to Journal of Scientific Computing",
    "descriptor": "\nComments: 42 pages, 5 figures, submitted to Journal of Scientific Computing\n",
    "authors": [
      "Zihang Zhang",
      "Qiwei Zhan",
      "Zhennan Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.02999"
  },
  {
    "id": "arXiv:2108.03541",
    "title": "OSCAR-Net: Object-centric Scene Graph Attention for Image Attribution",
    "abstract": "Comments: Accepted at the International Conference on Computer Vision (ICCV), 2021. Project site: this https URL",
    "descriptor": "\nComments: Accepted at the International Conference on Computer Vision (ICCV), 2021. Project site: this https URL\n",
    "authors": [
      "Eric Nguyen",
      "Tu Bui",
      "Vishy Swaminathan",
      "John Collomosse"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.03541"
  },
  {
    "id": "arXiv:2108.04614",
    "title": "White blood cell subtype detection and classification",
    "abstract": "White blood cell subtype detection and classification",
    "descriptor": "",
    "authors": [
      "Nalla Praveen",
      "Narinder Singh Punn",
      "Sanjay Kumar Sonbhadra",
      "Sonali Agarwal",
      "M. Syafrullah",
      "Krisna Adiyarta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.04614"
  },
  {
    "id": "arXiv:2108.04725",
    "title": "PRECODE - A Generic Model Extension to Prevent Deep Gradient Leakage",
    "abstract": "Comments: 16 pages, 16 figures, 5 tables (supplementary material included). Accepted at WACV 2022. Code available at this https URL",
    "descriptor": "\nComments: 16 pages, 16 figures, 5 tables (supplementary material included). Accepted at WACV 2022. Code available at this https URL\n",
    "authors": [
      "Daniel Scheliga",
      "Patrick M\u00e4der",
      "Marco Seeland"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.04725"
  },
  {
    "id": "arXiv:2108.05062",
    "title": "Multi-objective Scheduling of Electric Vehicle Charging/Discharging with  Time of Use Tariff",
    "abstract": "Multi-objective Scheduling of Electric Vehicle Charging/Discharging with  Time of Use Tariff",
    "descriptor": "",
    "authors": [
      "Hui Song",
      "Chen Liu",
      "Mahdi Jalili",
      "Xinghuo Yu",
      "Peter McTaggart"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.05062"
  },
  {
    "id": "arXiv:2108.05433",
    "title": "Learning to Hash Robustly, with Guarantees",
    "abstract": "Learning to Hash Robustly, with Guarantees",
    "descriptor": "",
    "authors": [
      "Alexandr Andoni",
      "Daniel Beaglehole"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.05433"
  },
  {
    "id": "arXiv:2108.05566",
    "title": "Matrix pencils with coefficients that have positive semidefinite  Hermitian part",
    "abstract": "Matrix pencils with coefficients that have positive semidefinite  Hermitian part",
    "descriptor": "",
    "authors": [
      "Christian Mehl",
      "Volker Mehrmann",
      "Michal Wojtylak"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2108.05566"
  },
  {
    "id": "arXiv:2108.06130",
    "title": "Semantic Answer Similarity for Evaluating Question Answering Models",
    "abstract": "Comments: Trained model: this https URL",
    "descriptor": "\nComments: Trained model: this https URL\n",
    "authors": [
      "Julian Risch",
      "Timo M\u00f6ller",
      "Julian Gutsch",
      "Malte Pietsch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2108.06130"
  },
  {
    "id": "arXiv:2108.06711",
    "title": "Towards Understanding Theoretical Advantages of Complex-Reaction  Networks",
    "abstract": "Towards Understanding Theoretical Advantages of Complex-Reaction  Networks",
    "descriptor": "",
    "authors": [
      "Shao-Qun Zhang",
      "Wei Gao",
      "Zhi-Hua Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.06711"
  },
  {
    "id": "arXiv:2108.08435",
    "title": "Addressing Algorithmic Disparity and Performance Inconsistency in  Federated Learning",
    "abstract": "Comments: This work is accepted by NeurIPS2021",
    "descriptor": "\nComments: This work is accepted by NeurIPS2021\n",
    "authors": [
      "Sen Cui",
      "Weishen Pan",
      "Jian Liang",
      "Changshui Zhang",
      "Fei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.08435"
  },
  {
    "id": "arXiv:2108.08597",
    "title": "Beyond NED: Fast and Effective Search Space Reduction for Complex  Question Answering over Knowledge Bases",
    "abstract": "Comments: WSDM 2022 Research Track Long Paper (Extended version)",
    "descriptor": "\nComments: WSDM 2022 Research Track Long Paper (Extended version)\n",
    "authors": [
      "Philipp Christmann",
      "Rishiraj Saha Roy",
      "Gerhard Weikum"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.08597"
  },
  {
    "id": "arXiv:2108.08687",
    "title": "Clustering dynamics on graphs: from spectral clustering to mean shift  through Fokker-Planck interpolation",
    "abstract": "Clustering dynamics on graphs: from spectral clustering to mean shift  through Fokker-Planck interpolation",
    "descriptor": "",
    "authors": [
      "Katy Craig",
      "Nicol\u00e1s Garc\u00eda Trillos",
      "Dejan Slep\u010dev"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2108.08687"
  },
  {
    "id": "arXiv:2108.08922",
    "title": "Controlled GAN-Based Creature Synthesis via a Challenging Game Art  Dataset -- Addressing the Noise-Latent Trade-Off",
    "abstract": "Comments: 10 pages, 10 figures",
    "descriptor": "\nComments: 10 pages, 10 figures\n",
    "authors": [
      "Vaibhav Vavilala",
      "David Forsyth"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.08922"
  },
  {
    "id": "arXiv:2108.09717",
    "title": "External Knowledge enabled Text Visual Question Answering",
    "abstract": "Comments: Submitted to Neurocomputing",
    "descriptor": "\nComments: Submitted to Neurocomputing\n",
    "authors": [
      "Arka Ujjal Dey",
      "Ernest Valveny",
      "Gaurav Harit"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2108.09717"
  },
  {
    "id": "arXiv:2108.09789",
    "title": "An Exploration of Factors Influencing the Adoption of ICT Enabled  Entrepreneurship Applications in Namibian Rural Communities",
    "abstract": "Comments: In proceedings of the 1st Virtual Conference on Implications of Information and Digital Technologies for Development, 2021",
    "descriptor": "\nComments: In proceedings of the 1st Virtual Conference on Implications of Information and Digital Technologies for Development, 2021\n",
    "authors": [
      "Elizabeth Ujarura Kamutuezu",
      "Heike Winschiers-Theophilus",
      "Anicia Peters"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2108.09789"
  },
  {
    "id": "arXiv:2108.10132",
    "title": "TRAPDOOR: Repurposing backdoors to detect dataset bias in machine  learning-based genomic analysis",
    "abstract": "TRAPDOOR: Repurposing backdoors to detect dataset bias in machine  learning-based genomic analysis",
    "descriptor": "",
    "authors": [
      "Esha Sarkar",
      "Michail Maniatakos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.10132"
  },
  {
    "id": "arXiv:2108.10520",
    "title": "Improving Object Detection by Label Assignment Distillation",
    "abstract": "Comments: To appear in WACV 2022",
    "descriptor": "\nComments: To appear in WACV 2022\n",
    "authors": [
      "Chuong H. Nguyen",
      "Thuy C. Nguyen",
      "Tuan N. Tang",
      "Nam L.H. Phan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.10520"
  },
  {
    "id": "arXiv:2108.10552",
    "title": "E-RAFT: Dense Optical Flow from Event Cameras",
    "abstract": "Comments: International Conference on 3D Vision (3DV)",
    "descriptor": "\nComments: International Conference on 3D Vision (3DV)\n",
    "authors": [
      "Mathias Gehrig",
      "Mario Millh\u00e4usler",
      "Daniel Gehrig",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.10552"
  },
  {
    "id": "arXiv:2108.10961",
    "title": "Entropic Gromov-Wasserstein between Gaussian Distributions",
    "abstract": "Comments: 42 pages. Khang Le, Dung Le, and Huy Nguyen contributed equally to this work",
    "descriptor": "\nComments: 42 pages. Khang Le, Dung Le, and Huy Nguyen contributed equally to this work\n",
    "authors": [
      "Khang Le",
      "Dung Le",
      "Huy Nguyen",
      "Dat Do",
      "Tung Pham",
      "Nhat Ho"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.10961"
  },
  {
    "id": "arXiv:2108.11765",
    "title": "Physical Adversarial Attacks on an Aerial Imagery Object Detector",
    "abstract": "Physical Adversarial Attacks on an Aerial Imagery Object Detector",
    "descriptor": "",
    "authors": [
      "Andrew Du",
      "Bo Chen",
      "Tat-Jun Chin",
      "Yee Wei Law",
      "Michele Sasdelli",
      "Ramesh Rajasegaran",
      "Dillon Campbell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.11765"
  },
  {
    "id": "arXiv:2108.11898",
    "title": "Supervised Compression for Resource-Constrained Edge Computing Systems",
    "abstract": "Comments: Accepted to WACV 2022. Code and models are available at this https URL",
    "descriptor": "\nComments: Accepted to WACV 2022. Code and models are available at this https URL\n",
    "authors": [
      "Yoshitomo Matsubara",
      "Ruihan Yang",
      "Marco Levorato",
      "Stephan Mandt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.11898"
  },
  {
    "id": "arXiv:2109.02065",
    "title": "The local-global property for G-invariant terms",
    "abstract": "Comments: 22 pages",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Alexandr Kazda",
      "Michael Kompatscher"
    ],
    "subjectives": [
      "Rings and Algebras (math.RA)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2109.02065"
  },
  {
    "id": "arXiv:2109.02639",
    "title": "On the Out-of-distribution Generalization of Probabilistic Image  Modelling",
    "abstract": "On the Out-of-distribution Generalization of Probabilistic Image  Modelling",
    "descriptor": "",
    "authors": [
      "Mingtian Zhang",
      "Andi Zhang",
      "Steven McDonagh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2109.02639"
  },
  {
    "id": "arXiv:2109.04270",
    "title": "Toward a Perspectivist Turn in Ground Truthing for Predictive Computing",
    "abstract": "Comments: 17 pages",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Valerio Basile",
      "Federico Cabitza",
      "Andrea Campagner",
      "Michael Fell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04270"
  },
  {
    "id": "arXiv:2109.04353",
    "title": "Cross DQN: Cross Deep Q Network for Ads Allocation in Feed",
    "abstract": "Cross DQN: Cross Deep Q Network for Ads Allocation in Feed",
    "descriptor": "",
    "authors": [
      "Guogang Liao",
      "Ze Wang",
      "Xiaoxu Wu",
      "Xiaowen Shi",
      "Chuheng Zhang",
      "Yongkang Wang",
      "Xingxing Wang",
      "Dong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04353"
  },
  {
    "id": "arXiv:2109.06061",
    "title": "Learning Indoor Inverse Rendering with 3D Spatially-Varying Lighting",
    "abstract": "Comments: ICCV 2021 (Oral Presentation)",
    "descriptor": "\nComments: ICCV 2021 (Oral Presentation)\n",
    "authors": [
      "Zian Wang",
      "Jonah Philion",
      "Sanja Fidler",
      "Jan Kautz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.06061"
  },
  {
    "id": "arXiv:2109.06238",
    "title": "Extended Version of GTGraffiti: Spray Painting Graffiti Art from Human  Painting Motions with a Cable Driven Parallel Robot",
    "abstract": "Comments: Accompanying Details to ICRA 2022 Submission Number 2016",
    "descriptor": "\nComments: Accompanying Details to ICRA 2022 Submission Number 2016\n",
    "authors": [
      "Gerry Chen",
      "Sereym Baek",
      "Juan-Diego Florez",
      "Wanli Qian",
      "Sang-won Leigh",
      "Seth Hutchinson",
      "Frank Dellaert"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06238"
  },
  {
    "id": "arXiv:2109.06638",
    "title": "Learnable Discrete Wavelet Pooling (LDW-Pooling) For Convolutional  Networks",
    "abstract": "Comments: Accepted by BMVC 2021",
    "descriptor": "\nComments: Accepted by BMVC 2021\n",
    "authors": [
      "Bor-Shiun Wang",
      "Jun-Wei Hsieh",
      "Ming-Ching Chang",
      "Ping-Yang Chen",
      "Lipeng Ke",
      "Siwei Lyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2109.06638"
  },
  {
    "id": "arXiv:2109.06828",
    "title": "A Multi-scale Visual Analytics Approach for Exploring Biomedical  Knowledge",
    "abstract": "A Multi-scale Visual Analytics Approach for Exploring Biomedical  Knowledge",
    "descriptor": "",
    "authors": [
      "Fahd Husain",
      "Rosa Romero-Gomez",
      "Emily Kuang",
      "Dario Segura",
      "Adamo Carolli",
      "Lai Chung Liu",
      "Manfred Cheung",
      "Yohann Paris"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.06828"
  },
  {
    "id": "arXiv:2109.07069",
    "title": "F-CAM: Full Resolution Class Activation Maps via Guided Parametric  Upscaling",
    "abstract": "Comments: 23pages, WACV 2022",
    "descriptor": "\nComments: 23pages, WACV 2022\n",
    "authors": [
      "Soufiane Belharbi",
      "Aydin Sarraf",
      "Marco Pedersoli",
      "Ismail Ben Ayed",
      "Luke McCaffrey",
      "Eric Granger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07069"
  },
  {
    "id": "arXiv:2109.08229",
    "title": "Policy Choice and Best Arm Identification: Asymptotic Analysis of  Exploration Sampling under Posterior Weighted Policy Regret",
    "abstract": "Policy Choice and Best Arm Identification: Asymptotic Analysis of  Exploration Sampling under Posterior Weighted Policy Regret",
    "descriptor": "",
    "authors": [
      "Kaito Ariu",
      "Masahiro Kato",
      "Junpei Komiyama",
      "Kenichiro McAlinn",
      "Chao Qin"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2109.08229"
  },
  {
    "id": "arXiv:2109.09152",
    "title": "On the Dynamics of Political Discussions on Instagram: A Network  Perspective",
    "abstract": "On the Dynamics of Political Discussions on Instagram: A Network  Perspective",
    "descriptor": "",
    "authors": [
      "Carlos H.G. Ferreira",
      "Fabricio Murai",
      "Ana P.C. Silva",
      "Jussara M. Almeida",
      "Martino Trevisan",
      "Luca Vassio",
      "Marco Mellia",
      "Idilio Drago"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2109.09152"
  },
  {
    "id": "arXiv:2109.09228",
    "title": "Rethnicity: Predicting Ethnicity from Names",
    "abstract": "Rethnicity: Predicting Ethnicity from Names",
    "descriptor": "",
    "authors": [
      "Fangzhou Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.09228"
  },
  {
    "id": "arXiv:2109.09654",
    "title": "Can We Leverage Predictive Uncertainty to Detect Dataset Shift and  Adversarial Examples in Android Malware Detection?",
    "abstract": "Comments: Accepted by ACSAC'2021",
    "descriptor": "\nComments: Accepted by ACSAC'2021\n",
    "authors": [
      "Deqiang Li",
      "Tian Qiu",
      "Shuo Chen",
      "Qianmu Li",
      "Shouhuai Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.09654"
  },
  {
    "id": "arXiv:2109.09692",
    "title": "Modeling Regime Shifts in Multiple Time Series",
    "abstract": "Modeling Regime Shifts in Multiple Time Series",
    "descriptor": "",
    "authors": [
      "Etienne Gael Tajeuna",
      "Mohamed Bouguessa",
      "Shengrui Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.09692"
  },
  {
    "id": "arXiv:2109.09948",
    "title": "Neural networks with trainable matrix activation functions",
    "abstract": "Neural networks with trainable matrix activation functions",
    "descriptor": "",
    "authors": [
      "Yuwen Li",
      "Zhengqi Liu",
      "Ludmil Zikatanov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.09948"
  },
  {
    "id": "arXiv:2109.11034",
    "title": "Conditional Poisson Stochastic Beam Search",
    "abstract": "Conditional Poisson Stochastic Beam Search",
    "descriptor": "",
    "authors": [
      "Clara Meister",
      "Afra Amini",
      "Tim Viera",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.11034"
  },
  {
    "id": "arXiv:2109.11887",
    "title": "Distributionally Robust Joint Chance-Constrained Optimization for  Networked Microgrids Considering Contingencies and Renewable Uncertainty",
    "abstract": "Comments: Submitted to IEEE Transactions on Smart Grid on Dec 2020, Revised on May 2021",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Smart Grid on Dec 2020, Revised on May 2021\n",
    "authors": [
      "Yifu Ding",
      "Thomas Morstyn",
      "Malcolm D. McCulloch"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.11887"
  },
  {
    "id": "arXiv:2109.12021",
    "title": "Pythia: A Customizable Hardware Prefetching Framework Using Online  Reinforcement Learning",
    "abstract": "Pythia: A Customizable Hardware Prefetching Framework Using Online  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Rahul Bera",
      "Konstantinos Kanellopoulos",
      "Anant V. Nori",
      "Taha Shahroodi",
      "Sreenivas Subramoney",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.12021"
  },
  {
    "id": "arXiv:2109.12068",
    "title": "AraT5: Text-to-Text Transformers for Arabic Language Understanding and  Generation",
    "abstract": "Comments: All authors contributed equally",
    "descriptor": "\nComments: All authors contributed equally\n",
    "authors": [
      "El Moatez Billah Nagoudi",
      "Muhammad Abdul-Mageed",
      "AbdelRahim Elmadany"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.12068"
  },
  {
    "id": "arXiv:2109.12989",
    "title": "HyperQube: A QBF-Based Bounded Model Checker for Hyperproperties",
    "abstract": "HyperQube: A QBF-Based Bounded Model Checker for Hyperproperties",
    "descriptor": "",
    "authors": [
      "Tzu-Han Hsu",
      "Borzoo Bonakdarpour",
      "C\u00e9sar S\u00e1nchez"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.12989"
  },
  {
    "id": "arXiv:2109.13732",
    "title": "IRMAC: Interpretable Refined Motifs and Binary Classification for  Rooftops PV Owners",
    "abstract": "Comments: 9 pages, 9 figures, refined version of the 8 pages conference",
    "descriptor": "\nComments: 9 pages, 9 figures, refined version of the 8 pages conference\n",
    "authors": [
      "Rui Yuan",
      "S. Ali Pourmousavi",
      "Wen L. Soong",
      "Giang Nguyen",
      "Jon A. R. Liisberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.13732"
  },
  {
    "id": "arXiv:2109.14950",
    "title": "A useful criterion on studying consistent estimation in community  detection",
    "abstract": "A useful criterion on studying consistent estimation in community  detection",
    "descriptor": "",
    "authors": [
      "Huan Qing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.14950"
  },
  {
    "id": "arXiv:2109.15233",
    "title": "Solving the Real Robot Challenge using Deep Reinforcement Learning",
    "abstract": "Comments: This work has been submitted to the AICS 2021 conference for possible publication. Reformatted to match AICS requirements. Added a 'Related Work' section. Minor improvements throughout document",
    "descriptor": "\nComments: This work has been submitted to the AICS 2021 conference for possible publication. Reformatted to match AICS requirements. Added a 'Related Work' section. Minor improvements throughout document\n",
    "authors": [
      "Robert McCarthy",
      "Francisco Roldan Sanchez",
      "Qiang Wang",
      "David Cordova Bulens",
      "Kevin McGuinness",
      "Noel O'Connor",
      "Stephen J. Redmond"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.15233"
  },
  {
    "id": "arXiv:2110.00460",
    "title": "A general isogeometric finite element formulation for rotation-free  shells with embedded fibers and in-plane bending",
    "abstract": "Comments: This version updates the paper format and adjust the units in figure axes, results unchanged",
    "descriptor": "\nComments: This version updates the paper format and adjust the units in figure axes, results unchanged\n",
    "authors": [
      "Thang Xuan Duong",
      "Mikhail Itskov",
      "Roger Andrew Sauer"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2110.00460"
  },
  {
    "id": "arXiv:2110.00628",
    "title": "Permutation Entropy for Graph Signals",
    "abstract": "Comments: 11 pares, 12 figures, 2 tables",
    "descriptor": "\nComments: 11 pares, 12 figures, 2 tables\n",
    "authors": [
      "John Stewart Fabila-Carrasco",
      "Chao Tan",
      "Javier Escudero"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.00628"
  },
  {
    "id": "arXiv:2110.01402",
    "title": "Illustrating quantum information with quantum candies",
    "abstract": "Comments: This is the journal version of: Lin, J. and Mor, T., 2020, December. Quantum Candies and Quantum Cryptography. In International Conference on the Theory and Practice of Natural Computing (pp. 69-81). Springer, Cham., arXiv preprint arXiv:2011.02837. Changes in this version: corrected typos, added references and author affiliations",
    "descriptor": "\nComments: This is the journal version of: Lin, J. and Mor, T., 2020, December. Quantum Candies and Quantum Cryptography. In International Conference on the Theory and Practice of Natural Computing (pp. 69-81). Springer, Cham., arXiv preprint arXiv:2011.02837. Changes in this version: corrected typos, added references and author affiliations\n",
    "authors": [
      "Junan Lin",
      "Tal Mor",
      "Roman Shapira"
    ],
    "subjectives": [
      "Physics Education (physics.ed-ph)",
      "Cryptography and Security (cs.CR)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.01402"
  },
  {
    "id": "arXiv:2110.02642",
    "title": "Anomaly Transformer: Time Series Anomaly Detection with Association  Discrepancy",
    "abstract": "Anomaly Transformer: Time Series Anomaly Detection with Association  Discrepancy",
    "descriptor": "",
    "authors": [
      "Jiehui Xu",
      "Haixu Wu",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02642"
  },
  {
    "id": "arXiv:2110.02852",
    "title": "PSG@Dravidian-CodeMix-HASOC2021: Pretrained Transformers for Offensive  Language Identification in Tanglish",
    "abstract": "Comments: Under review for FIRE 2021",
    "descriptor": "\nComments: Under review for FIRE 2021\n",
    "authors": [
      "Sean Benhur",
      "Kanchana Sivanraju"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.02852"
  },
  {
    "id": "arXiv:2110.03625",
    "title": "Time Series Forecasting Using Manifold Learning",
    "abstract": "Time Series Forecasting Using Manifold Learning",
    "descriptor": "",
    "authors": [
      "Panagiotis Papaioannou",
      "Ronen Talmon",
      "Daniela di Serafino",
      "Ioannis Kevrekidis",
      "Constantinos Siettos"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.03625"
  },
  {
    "id": "arXiv:2110.03825",
    "title": "Exploring Architectural Ingredients of Adversarially Robust Deep Neural  Networks",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Hanxun Huang",
      "Yisen Wang",
      "Sarah Monazam Erfani",
      "Quanquan Gu",
      "James Bailey",
      "Xingjun Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.03825"
  },
  {
    "id": "arXiv:2110.03991",
    "title": "Combining Differential Privacy and Byzantine Resilience in Distributed  SGD",
    "abstract": "Combining Differential Privacy and Byzantine Resilience in Distributed  SGD",
    "descriptor": "",
    "authors": [
      "Rachid Guerraoui",
      "Nirupam Gupta",
      "Rafael Pinot",
      "Sebastien Rouault",
      "John Stephan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.03991"
  },
  {
    "id": "arXiv:2110.04402",
    "title": "Walking into the complex plane to 'order' better time integrators",
    "abstract": "Comments: 30 pages, 15 figures",
    "descriptor": "\nComments: 30 pages, 15 figures\n",
    "authors": [
      "Jithin D. George",
      "Samuel Y. Jung",
      "Niall M. Mangan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Complex Variables (math.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04402"
  },
  {
    "id": "arXiv:2110.05029",
    "title": "Internal Feedback in Biological Control: Constraints and Layered  Architectures",
    "abstract": "Comments: This paper is a companion to arXiv:2109.11752 and arXiv:2109.11757",
    "descriptor": "\nComments: This paper is a companion to arXiv:2109.11752 and arXiv:2109.11757\n",
    "authors": [
      "Anish A. Sarma",
      "Jing-Shuang Li",
      "Josefin Stenberg",
      "Gwyneth Card",
      "Elizabeth S. Heckscher",
      "Narayanan Kasthuri",
      "Terrence Sejnowski",
      "John C. Doyle"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Molecular Networks (q-bio.MN)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2110.05029"
  },
  {
    "id": "arXiv:2110.05682",
    "title": "Provably Efficient Reinforcement Learning in Decentralized General-Sum  Markov Games",
    "abstract": "Provably Efficient Reinforcement Learning in Decentralized General-Sum  Markov Games",
    "descriptor": "",
    "authors": [
      "Weichao Mao",
      "Tamer Ba\u015far"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.05682"
  },
  {
    "id": "arXiv:2110.05856",
    "title": "text2sdg: An open-source solution to monitoring sustainable development  goals from text",
    "abstract": "text2sdg: An open-source solution to monitoring sustainable development  goals from text",
    "descriptor": "",
    "authors": [
      "Dominik S. Meier",
      "Rui Mata",
      "Dirk U. Wulff"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05856"
  },
  {
    "id": "arXiv:2110.05942",
    "title": "Resolution $of$ The Linear-Bounded Automata Question",
    "abstract": "Comments: Minor changes. Feedbacks are welcome. arXiv admin note: text overlap with arXiv:2110.06211",
    "descriptor": "\nComments: Minor changes. Feedbacks are welcome. arXiv admin note: text overlap with arXiv:2110.06211\n",
    "authors": [
      "Tianrong Lin"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.05942"
  },
  {
    "id": "arXiv:2110.06043",
    "title": "Topic Model Supervised by Understanding Map",
    "abstract": "Topic Model Supervised by Understanding Map",
    "descriptor": "",
    "authors": [
      "Gangli Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06043"
  },
  {
    "id": "arXiv:2110.06211",
    "title": "Diagonalization $of$ Polynomial-Time Turing Machines Via  Nondeterministic Turing Machine",
    "abstract": "Comments: Deletion of Cantor pairing function, and presenting a more simpler way to encode a polynomial-time DTM which is easy to enumerate; Some typos corrected; Minor changes. Feedbacks are welcome. arXiv admin note: text overlap with arXiv:2110.05942",
    "descriptor": "\nComments: Deletion of Cantor pairing function, and presenting a more simpler way to encode a polynomial-time DTM which is easy to enumerate; Some typos corrected; Minor changes. Feedbacks are welcome. arXiv admin note: text overlap with arXiv:2110.05942\n",
    "authors": [
      "Tianrong Lin"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.06211"
  },
  {
    "id": "arXiv:2110.06303",
    "title": "NetRep: Automatic Repair for Network Programs",
    "abstract": "Comments: 24 pages, 9 figures",
    "descriptor": "\nComments: 24 pages, 9 figures\n",
    "authors": [
      "Lei Shi",
      "Yuepeng Wang",
      "Rajeev Alur",
      "Boon Thau Loo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2110.06303"
  },
  {
    "id": "arXiv:2110.06388",
    "title": "HETFORMER: Heterogeneous Transformer with Sparse Attention for Long-Text  Extractive Summarization",
    "abstract": "Comments: EMNLP 2021 (short paper)",
    "descriptor": "\nComments: EMNLP 2021 (short paper)\n",
    "authors": [
      "Ye Liu",
      "Jian-Guo Zhang",
      "Yao Wan",
      "Congying Xia",
      "Lifang He",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06388"
  },
  {
    "id": "arXiv:2110.06400",
    "title": "CyTran: Cycle-Consistent Transformers for Non-Contrast to Contrast CT  Translation",
    "abstract": "Comments: 10 pages, 5 figures",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Nicolae-Catalin Ristea",
      "Andreea-Iuliana Miron",
      "Olivian Savencu",
      "Mariana-Iuliana Georgescu",
      "Nicolae Verga",
      "Fahad Shahbaz Khan",
      "Radu Tudor Ionescu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06400"
  },
  {
    "id": "arXiv:2110.06467",
    "title": "Dual-branch Attention-In-Attention Transformer for single-channel speech  enhancement",
    "abstract": "Comments: Submitted to ICASSP 2022",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Guochen Yu",
      "Andong Li",
      "Yutian Wang",
      "Yinuo Guo",
      "Hui Wang",
      "Chengshi Zheng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.06467"
  },
  {
    "id": "arXiv:2110.06541",
    "title": "Collaborative Radio SLAM for Multiple Robots based on WiFi Fingerprint  Similarity",
    "abstract": "Comments: Accepted by 2021 IEEE International Conference on Robotics and Biomimetics, Sanya, China",
    "descriptor": "\nComments: Accepted by 2021 IEEE International Conference on Robotics and Biomimetics, Sanya, China\n",
    "authors": [
      "Ran Liu",
      "Zhenghong Qin",
      "Hua Zhang",
      "Billy Pik Lik Lau",
      "Khairuldanial Ismail",
      "Achala Athukorala",
      "Chau Yuen",
      "Yong Liang Guan",
      "U-Xuan Tan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.06541"
  },
  {
    "id": "arXiv:2110.06700",
    "title": "iRiSC: Iterative Risk Sensitive Control for Nonlinear Systems with  Imperfect Observations",
    "abstract": "Comments: 8 pages, 5 figures, 3 tables",
    "descriptor": "\nComments: 8 pages, 5 figures, 3 tables\n",
    "authors": [
      "Bilal Hammoud",
      "Armand Jordana",
      "Ludovic Righetti"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.06700"
  },
  {
    "id": "arXiv:2110.06804",
    "title": "A comprehensive review of Binary Neural Network",
    "abstract": "A comprehensive review of Binary Neural Network",
    "descriptor": "",
    "authors": [
      "Chunyu Yuan",
      "Sos S. Agaian"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2110.06804"
  },
  {
    "id": "arXiv:2110.07052",
    "title": "6G: Connectivity in the Era of Distributed Intelligence",
    "abstract": "6G: Connectivity in the Era of Distributed Intelligence",
    "descriptor": "",
    "authors": [
      "Shilpa Talwar",
      "Nageen Himayat",
      "Hosein Nikopour",
      "Feng Xue",
      "Geng Wu",
      "Vida Ilderem"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.07052"
  },
  {
    "id": "arXiv:2110.07186",
    "title": "An FPGA-Based Fully Pipelined Bilateral Grid for Real-Time Image  Denoising",
    "abstract": "Comments: 7 pages, 12 figures, 2 tables, FPL 2021 (Full paper) Program and Abstract: this https URL Slides: this https URL Movie: this https URL Profile: this https URL",
    "descriptor": "\nComments: 7 pages, 12 figures, 2 tables, FPL 2021 (Full paper) Program and Abstract: this https URL Slides: this https URL Movie: this https URL Profile: this https URL\n",
    "authors": [
      "Nobuho Hashimoto",
      "Shinya Takamaeda-Yamazaki"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2110.07186"
  },
  {
    "id": "arXiv:2110.07235",
    "title": "HUMAN4D: A Human-Centric Multimodal Dataset for Motions and Immersive  Media",
    "abstract": "HUMAN4D: A Human-Centric Multimodal Dataset for Motions and Immersive  Media",
    "descriptor": "",
    "authors": [
      "Anargyros Chatzitofis",
      "Leonidas Saroglou",
      "Prodromos Boutis",
      "Petros Drakoulis",
      "Nikolaos Zioulis",
      "Shishir Subramanyam",
      "Bart Kevelham",
      "Caecilia Charbonnier",
      "Pablo Cesar",
      "Dimitrios Zarpalas",
      "Stefanos Kollias",
      "Petros Daras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.07235"
  },
  {
    "id": "arXiv:2110.07359",
    "title": "Energy Cooperative Transmission Policy for Energy Harvesting Tags",
    "abstract": "Comments: 6 pages, 5 figures, 2 tables, conference",
    "descriptor": "\nComments: 6 pages, 5 figures, 2 tables, conference\n",
    "authors": [
      "Mengistu Abera Mulatu",
      "Thembelihle Dlamini",
      "Thokozani Shongwe",
      "Mzabalazo Lupupa"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.07359"
  },
  {
    "id": "arXiv:2110.07421",
    "title": "On some batch code properties of the simplex code",
    "abstract": "On some batch code properties of the simplex code",
    "descriptor": "",
    "authors": [
      "Henk D.L. Hollmann",
      "Karan Khathuria",
      "Ago-Erik Riet",
      "Vitaly Skachek"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.07421"
  },
  {
    "id": "arXiv:2110.07525",
    "title": "Connection Management xAPP for O-RAN RIC: A Graph Neural Network and  Reinforcement Learning Approach",
    "abstract": "Comments: paper accepted to the IEEE International Conference on Machine Learning and Applications (ICMLA 2021)",
    "descriptor": "\nComments: paper accepted to the IEEE International Conference on Machine Learning and Applications (ICMLA 2021)\n",
    "authors": [
      "Oner Orhan",
      "Vasuki Narasimha Swamy",
      "Thomas Tetzlaff",
      "Marcel Nassar",
      "Hosein Nikopour",
      "Shilpa Talwar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.07525"
  },
  {
    "id": "arXiv:2110.07752",
    "title": "Hindsight: Posterior-guided training of retrievers for improved  open-ended generation",
    "abstract": "Hindsight: Posterior-guided training of retrievers for improved  open-ended generation",
    "descriptor": "",
    "authors": [
      "Ashwin Paranjape",
      "Omar Khattab",
      "Christopher Potts",
      "Matei Zaharia",
      "Christopher D. Manning"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.07752"
  },
  {
    "id": "arXiv:2110.07807",
    "title": "Provable Regret Bounds for Deep Online Learning and Control",
    "abstract": "Provable Regret Bounds for Deep Online Learning and Control",
    "descriptor": "",
    "authors": [
      "Xinyi Chen",
      "Edgar Minasyan",
      "Jason D. Lee",
      "Elad Hazan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.07807"
  },
  {
    "id": "arXiv:2110.07902",
    "title": "Zipping Strategies and Attribute Grammars",
    "abstract": "Zipping Strategies and Attribute Grammars",
    "descriptor": "",
    "authors": [
      "Jos\u00e9 Nuno Macedo",
      "Marcos Viera",
      "Jo\u00e3o Saraiva"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.07902"
  },
  {
    "id": "arXiv:2110.08016",
    "title": "Efficiently Solve the Max-cut Problem via a Quantum Qubit Rotation  Algorithm",
    "abstract": "Comments: This work doesn't need a quantum computer, and the proof of this work is incomplete. Besides, this work has been done in arXiv:2105.01114 and arXiv:2101.07267",
    "descriptor": "\nComments: This work doesn't need a quantum computer, and the proof of this work is incomplete. Besides, this work has been done in arXiv:2105.01114 and arXiv:2101.07267\n",
    "authors": [
      "Xin Wang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08016"
  },
  {
    "id": "arXiv:2110.08078",
    "title": "The Entanglement-Assisted Communication Capacity over Quantum  Trajectories",
    "abstract": "Comments: Accepted for publication in IEEE Transactions on Wireless Communications",
    "descriptor": "\nComments: Accepted for publication in IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Daryus Chandra",
      "Marcello Caleffi",
      "Angela Sara Cacciapuoti"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.08078"
  },
  {
    "id": "arXiv:2110.08080",
    "title": "Multi-modal Aggregation Network for Fast MR Imaging",
    "abstract": "Multi-modal Aggregation Network for Fast MR Imaging",
    "descriptor": "",
    "authors": [
      "Chun-Mei Feng",
      "Huazhu Fu",
      "Tianfei Zhou",
      "Yong Xu",
      "Ling Shao",
      "David Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08080"
  },
  {
    "id": "arXiv:2110.08113",
    "title": "Hand Me Your PIN! Inferring ATM PINs of Users Typing with a Covered Hand",
    "abstract": "Hand Me Your PIN! Inferring ATM PINs of Users Typing with a Covered Hand",
    "descriptor": "",
    "authors": [
      "Matteo Cardaioli",
      "Stefano Cecconello",
      "Mauro Conti",
      "Simone Milani",
      "Stjepan Picek",
      "Eugen Saraci"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08113"
  },
  {
    "id": "arXiv:2110.08122",
    "title": "Effects of Different Optimization Formulations in Evolutionary  Reinforcement Learning on Diverse Behavior Generation",
    "abstract": "Comments: This paper has been accepted for the presentation in IEEE SSCI 2021",
    "descriptor": "\nComments: This paper has been accepted for the presentation in IEEE SSCI 2021\n",
    "authors": [
      "Victor Villin",
      "Naoki Masuyama",
      "Yusuke Nojima"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08122"
  },
  {
    "id": "arXiv:2110.08202",
    "title": "Evaluation of Hyperparameter-Optimization Approaches in an Industrial  Federated Learning System",
    "abstract": "Comments: This paper is accepted at the IDSC this https URL and will be published by Springer. The Version uploaded is before the peer review process. The link to the final version will be updated as soon as the paper is published. Figure one was corrected on 2021/10/20",
    "descriptor": "\nComments: This paper is accepted at the IDSC this https URL and will be published by Springer. The Version uploaded is before the peer review process. The link to the final version will be updated as soon as the paper is published. Figure one was corrected on 2021/10/20\n",
    "authors": [
      "Stephanie Holly",
      "Thomas Hiessl",
      "Safoura Rezapour Lakani",
      "Daniel Schall",
      "Clemens Heitzinger",
      "Jana Kemnitz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08202"
  },
  {
    "id": "arXiv:2110.08403",
    "title": "Nalanda: A Socio-Technical Graph for Building Software Analytics Tools  at Enterprise Scale",
    "abstract": "Nalanda: A Socio-Technical Graph for Building Software Analytics Tools  at Enterprise Scale",
    "descriptor": "",
    "authors": [
      "Chandra Maddila",
      "Apoorva Agrawal",
      "Thomas Zimmermann",
      "Nicole Forsgren",
      "Kim Herzig",
      "Arie van Deursen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.08403"
  },
  {
    "id": "arXiv:2110.08424",
    "title": "Deep learning-based detection of intravenous contrast in computed  tomography scans",
    "abstract": "Deep learning-based detection of intravenous contrast in computed  tomography scans",
    "descriptor": "",
    "authors": [
      "Zezhong Ye",
      "Jack M. Qian",
      "Ahmed Hosny",
      "Roman Zeleznik",
      "Deborah Plana",
      "Jirapat Likitlersuang",
      "Zhongyi Zhang",
      "Raymond H. Mak",
      "Hugo J. W. L. Aerts",
      "Benjamin H. Kann"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08424"
  },
  {
    "id": "arXiv:2110.08591",
    "title": "n-stage Latent Dirichlet Allocation: A Novel Approach for LDA",
    "abstract": "Comments: Published in: 2019 4th International Conference on Computer Science and Engineering (UBMK). This study is extension version of \"Comparison of Topic Modeling Methods for Type Detection of Turkish News\" this http URL . Please citation this IEEE paper",
    "descriptor": "\nComments: Published in: 2019 4th International Conference on Computer Science and Engineering (UBMK). This study is extension version of \"Comparison of Topic Modeling Methods for Type Detection of Turkish News\" this http URL . Please citation this IEEE paper\n",
    "authors": [
      "Zekeriya Anil Guven",
      "Banu Diri",
      "Tolgahan Cakaloglu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.08591"
  },
  {
    "id": "arXiv:2110.08733",
    "title": "LoveDA: A Remote Sensing Land-Cover Dataset for Domain Adaptive Semantic  Segmentation",
    "abstract": "Comments: Accepted by NeurIPS 2021 Datasets and Benchmarks Track",
    "descriptor": "\nComments: Accepted by NeurIPS 2021 Datasets and Benchmarks Track\n",
    "authors": [
      "Junjue Wang",
      "Zhuo Zheng",
      "Ailong Ma",
      "Xiaoyan Lu",
      "Yanfei Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08733"
  },
  {
    "id": "arXiv:2110.08826",
    "title": "Exploring Deep Neural Networks on Edge TPU",
    "abstract": "Comments: 12 pages, 16 figures",
    "descriptor": "\nComments: 12 pages, 16 figures\n",
    "authors": [
      "Seyedehfaezeh Hosseininoorbin",
      "Siamak Layeghy",
      "Brano Kusy",
      "Raja Jurdak",
      "Marius Portmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08826"
  },
  {
    "id": "arXiv:2110.08843",
    "title": "Graph Wedgelets: Adaptive Data Compression on Graphs based on Binary  Wedge Partitioning Trees and Geometric Wavelets",
    "abstract": "Comments: 11 pages, 8 figures",
    "descriptor": "\nComments: 11 pages, 8 figures\n",
    "authors": [
      "Wolfgang Erb"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.08843"
  },
  {
    "id": "arXiv:2110.08871",
    "title": "Noise-robust Clustering",
    "abstract": "Noise-robust Clustering",
    "descriptor": "",
    "authors": [
      "Rahmat Adesunkanmi",
      "Ratnesh Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.08871"
  },
  {
    "id": "arXiv:2110.08896",
    "title": "Damped Anderson Mixing for Deep Reinforcement Learning: Acceleration,  Convergence, and Stabilization",
    "abstract": "Damped Anderson Mixing for Deep Reinforcement Learning: Acceleration,  Convergence, and Stabilization",
    "descriptor": "",
    "authors": [
      "Ke Sun",
      "Yafei Wang",
      "Yi Liu",
      "Yingnan Zhao",
      "Bo Pan",
      "Shangling Jui",
      "Bei Jiang",
      "Linglong Kong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.08896"
  },
  {
    "id": "arXiv:2110.08934",
    "title": "On the Effect of Selfie Beautification Filters on Face Detection and  Recognition",
    "abstract": "On the Effect of Selfie Beautification Filters on Face Detection and  Recognition",
    "descriptor": "",
    "authors": [
      "Pontus Hedman",
      "Vasilios Skepetzis",
      "Kevin Hernandez-Diaz",
      "Josef Bigun",
      "Fernando Alonso-Fernandez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08934"
  },
  {
    "id": "arXiv:2110.08959",
    "title": "Fast and Exact Outlier Detection in Metric Spaces: A Proximity  Graph-based Approach",
    "abstract": "Comments: Accepted to SIGMOD2021",
    "descriptor": "\nComments: Accepted to SIGMOD2021\n",
    "authors": [
      "Daichi Amagata",
      "Makoto Onizuka",
      "Takahiro Hara"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.08959"
  },
  {
    "id": "arXiv:2110.08964",
    "title": "Affine Hermitian Grassmann Codes",
    "abstract": "Affine Hermitian Grassmann Codes",
    "descriptor": "",
    "authors": [
      "Fernando Pi\u00f1ero Gonz\u00e1lez",
      "Doel Rivera Laboy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2110.08964"
  },
  {
    "id": "arXiv:2110.08966",
    "title": "Computing Semilinear Sparse Models for Approximately Eventually Periodic  Signals",
    "abstract": "Computing Semilinear Sparse Models for Approximately Eventually Periodic  Signals",
    "descriptor": "",
    "authors": [
      "Fredy Vides"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.08966"
  },
  {
    "id": "arXiv:2110.09007",
    "title": "Online Motion Planning with Soft Timed Temporal Logic in Dynamic and  Unknown Environment",
    "abstract": "Comments: under review",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Zhiliang Li",
      "Mingyu Cai",
      "Shaoping Xiao",
      "Zhen Kan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.09007"
  },
  {
    "id": "arXiv:2110.09108",
    "title": "Asymmetric Modality Translation For Face Presentation Attack Detection",
    "abstract": "Asymmetric Modality Translation For Face Presentation Attack Detection",
    "descriptor": "",
    "authors": [
      "Zhi Li",
      "Haoliang Li",
      "Xin Luo",
      "Yongjian Hu",
      "Kwok-Yan Lam",
      "Alex C. Kot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09108"
  },
  {
    "id": "arXiv:2110.09255",
    "title": "Towards responsible research in digital technology for health care",
    "abstract": "Comments: 16 pages, 1 table, 4 figures, 69 references",
    "descriptor": "\nComments: 16 pages, 1 table, 4 figures, 69 references\n",
    "authors": [
      "Pierre Jannin"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.09255"
  },
  {
    "id": "arXiv:2110.09401",
    "title": "Mesh Convolutional Autoencoder for Semi-Regular Meshes of Different  Sizes",
    "abstract": "Comments: Accepted at 2022 IEEE Winter Conference on Applications of Computer Vision (WACV)",
    "descriptor": "\nComments: Accepted at 2022 IEEE Winter Conference on Applications of Computer Vision (WACV)\n",
    "authors": [
      "Sara Hahner",
      "Jochen Garcke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09401"
  },
  {
    "id": "arXiv:2110.09408",
    "title": "HRFormer: High-Resolution Transformer for Dense Prediction",
    "abstract": "Comments: Accepted at NeurIPS 2021",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Yuhui Yuan",
      "Rao Fu",
      "Lang Huang",
      "Weihong Lin",
      "Chao Zhang",
      "Xilin Chen",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09408"
  },
  {
    "id": "arXiv:2110.09482",
    "title": "Self-Supervised Monocular Depth Estimation with Internal Feature Fusion",
    "abstract": "Comments: Accepted at BMVC2021",
    "descriptor": "\nComments: Accepted at BMVC2021\n",
    "authors": [
      "Hang Zhou",
      "David Greenwood",
      "Sarah Taylor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09482"
  },
  {
    "id": "arXiv:2110.09619",
    "title": "Further Generalizations of the Jaccard Index",
    "abstract": "Comments: 12 pages, 11 figures, a working manuscript",
    "descriptor": "\nComments: 12 pages, 11 figures, a working manuscript\n",
    "authors": [
      "Luciano da F. Costa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09619"
  },
  {
    "id": "arXiv:2110.09696",
    "title": "Near-Optimal Quantum Algorithms for String Problems",
    "abstract": "Comments: To appear in SODA 2022. Fixed cleveref issues",
    "descriptor": "\nComments: To appear in SODA 2022. Fixed cleveref issues\n",
    "authors": [
      "Shyan Akmal",
      "Ce Jin"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.09696"
  },
  {
    "id": "arXiv:2110.09702",
    "title": "A non-hierarchical attention network with modality dropout for textual  response generation in multimodal dialogue systems",
    "abstract": "Comments: Submitted to ICASSP2022 (currently under review)",
    "descriptor": "\nComments: Submitted to ICASSP2022 (currently under review)\n",
    "authors": [
      "Rongyi Sun",
      "Borun Chen",
      "Qingyu Zhou",
      "Yinghui Li",
      "YunBo Cao",
      "Hai-Tao Zheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.09702"
  },
  {
    "id": "arXiv:2110.09712",
    "title": "Balancing Value Underestimation and Overestimation with Realistic  Actor-Critic",
    "abstract": "Balancing Value Underestimation and Overestimation with Realistic  Actor-Critic",
    "descriptor": "",
    "authors": [
      "Sicen Li",
      "Gang Wang",
      "Qinyun Tang",
      "Liquan Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09712"
  },
  {
    "id": "arXiv:2110.09744",
    "title": "Spectral Variability Augmented Sparse Unmixing of Hyperspectral Images",
    "abstract": "Spectral Variability Augmented Sparse Unmixing of Hyperspectral Images",
    "descriptor": "",
    "authors": [
      "Ge Zhang",
      "Shaohui Mei",
      "Mingyang Ma",
      "Yan Feng",
      "Qian Du"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.09744"
  },
  {
    "id": "arXiv:2110.09772",
    "title": "Synergy between 3DMM and 3D Landmarks for Accurate 3D Facial Geometry",
    "abstract": "Comments: Accepted at 3DV 2021. This conference version supersedes arXiv:2104.08403",
    "descriptor": "\nComments: Accepted at 3DV 2021. This conference version supersedes arXiv:2104.08403\n",
    "authors": [
      "Cho-Ying Wu",
      "Qiangeng Xu",
      "Ulrich Neumann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.09772"
  },
  {
    "id": "arXiv:2110.09823",
    "title": "An Empirical Study: Extensive Deep Temporal Point Process",
    "abstract": "Comments: 22 pages, 8 figures",
    "descriptor": "\nComments: 22 pages, 8 figures\n",
    "authors": [
      "Haitao Lin",
      "Cheng Tan",
      "Lirong Wu",
      "Zhangyang Gao",
      "Stan. Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.09823"
  },
  {
    "id": "arXiv:2110.09829",
    "title": "Towards Social Situation Awareness in Support Agents",
    "abstract": "Comments: 9 pages, 2 figures",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Ilir Kola",
      "Pradeep K. Murukannaiah",
      "Catholijn M. Jonker",
      "M. Birna van Riemsdijk"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09829"
  },
  {
    "id": "arXiv:2110.09899",
    "title": "POLE: Polarized Embedding for Signed Networks",
    "abstract": "Comments: Accepted to WSDM 2022",
    "descriptor": "\nComments: Accepted to WSDM 2022\n",
    "authors": [
      "Zexi Huang",
      "Arlei Silva",
      "Ambuj Singh"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09899"
  },
  {
    "id": "arXiv:2110.09904",
    "title": "Learning Robotic Manipulation Skills Using an Adaptive Force-Impedance  Action Space",
    "abstract": "Learning Robotic Manipulation Skills Using an Adaptive Force-Impedance  Action Space",
    "descriptor": "",
    "authors": [
      "Maximilian Ulmer",
      "Elie Aljalbout",
      "Sascha Schwarz",
      "Sami Haddadin"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09904"
  },
  {
    "id": "arXiv:2110.09928",
    "title": "CycleFlow: Purify Information Factors by Cycle Loss",
    "abstract": "Comments: Submitted to ICASSP 2022",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Haoran Sun",
      "Chen Chen",
      "Lantian Li",
      "Dong Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.09928"
  },
  {
    "id": "arXiv:2110.09929",
    "title": "Minimal Multi-Layer Modifications of Deep Neural Networks",
    "abstract": "Minimal Multi-Layer Modifications of Deep Neural Networks",
    "descriptor": "",
    "authors": [
      "Idan Refaeli",
      "Guy Katz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.09929"
  },
  {
    "id": "arXiv:2110.10022",
    "title": "Robust Control of a Multi-Axis Shape Memory Alloy-Driven Soft  Manipulator",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Zach J. Patterson",
      "Andrew P. Sabelhaus",
      "Carmel Majidi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.10022"
  },
  {
    "id": "arXiv:2110.10124",
    "title": "A Numerical Scheme for Wave Turbulence: 3-Wave Kinetic Equations",
    "abstract": "A Numerical Scheme for Wave Turbulence: 3-Wave Kinetic Equations",
    "descriptor": "",
    "authors": [
      "Steven Walton",
      "Minh-Binh Tran"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.10124"
  }
]
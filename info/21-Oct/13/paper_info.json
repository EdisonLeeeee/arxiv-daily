[
  {
    "id": "arXiv:2110.05477",
    "title": "Predicting the spread of COVID-19 in Delhi, India using Deep Residual  Recurrent Neural Networks",
    "abstract": "Detecting the spread of coronavirus will go a long way toward reducing human\nand economic loss. Unfortunately, existing Epidemiological models used for\nCOVID 19 prediction models are too slow and fail to capture the COVID-19\ndevelopment in detail. This research uses Partial Differential Equations to\nimprove the processing speed and accuracy of forecasting of COVID 19 governed\nby SEIRD model equations. The dynamics of COVID 19 were extracted using\nConvolutional Neural Networks and Deep Residual Recurrent Neural Networks from\ndata simulated using PDEs. The DRRNNs accuracy is measured using Mean Squared\nError. The DRRNNs COVID-19 prediction model has been shown to have accurate\nCOVID-19 predictions. In addition, we concluded that DR-RNNs can significantly\nadvance the ability to support decision-making in real time COVID-19\nprediction.",
    "descriptor": "\nComments: 10 pages,3 figures. arXiv admin note: text overlap with arXiv:2104.14034 by other authors\n",
    "authors": [
      "Shashank Reddy Vadyala",
      "Sai Nethra Betgeri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05477"
  },
  {
    "id": "arXiv:2110.05481",
    "title": "Which Samples Should be Learned First: Easy or Hard?",
    "abstract": "An effective weighting scheme for training samples is essential for learning\ntasks. Numerous weighting schemes have been proposed. Some schemes take the\neasy-first mode on samples, whereas some others take the hard-first mode.\nNaturally, an interesting yet realistic question is raised. Which samples\nshould be learned first given a new learning task, easy or hard? To answer this\nquestion, three aspects of research are carried out. First, a high-level\nunified weighted loss is proposed, providing a more comprehensive view for\nexisting schemes. Theoretical analysis is subsequently conducted and\npreliminary conclusions are obtained. Second, a flexible weighting scheme is\nproposed to overcome the defects of existing schemes. The three modes, namely,\neasy/medium/hard-first, can be flexibly switched in the proposed scheme. Third,\na wide range of experiments are conducted to further compare the weighting\nschemes in different modes. On the basis of these works, reasonable answers are\nobtained. Factors including prior knowledge and data characteristics determine\nwhich samples should be learned first in a learning task.",
    "descriptor": "\nComments: 32 pages,21 figures\n",
    "authors": [
      "Xiaoling Zhou",
      "Ou Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.05481"
  },
  {
    "id": "arXiv:2110.05518",
    "title": "Global Optimality Beyond Two Layers: Training Deep ReLU Networks via  Convex Programs",
    "abstract": "Understanding the fundamental mechanism behind the success of deep neural\nnetworks is one of the key challenges in the modern machine learning\nliterature. Despite numerous attempts, a solid theoretical analysis is yet to\nbe developed. In this paper, we develop a novel unified framework to reveal a\nhidden regularization mechanism through the lens of convex optimization. We\nfirst show that the training of multiple three-layer ReLU sub-networks with\nweight decay regularization can be equivalently cast as a convex optimization\nproblem in a higher dimensional space, where sparsity is enforced via a group\n$\\ell_1$-norm regularization. Consequently, ReLU networks can be interpreted as\nhigh dimensional feature selection methods. More importantly, we then prove\nthat the equivalent convex problem can be globally optimized by a standard\nconvex optimization solver with a polynomial-time complexity with respect to\nthe number of samples and data dimension when the width of the network is\nfixed. Finally, we numerically validate our theoretical results via experiments\ninvolving both synthetic and real datasets.",
    "descriptor": "\nComments: Accepted to ICML 2021\n",
    "authors": [
      "Tolga Ergen",
      "Mert Pilanci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2110.05518"
  },
  {
    "id": "arXiv:2110.05523",
    "title": "UnfairGAN: An Enhanced Generative Adversarial Network for Raindrop  Removal from A Single Image",
    "abstract": "Image deraining is a new challenging problem in real-world applications, such\nas autonomous vehicles. In a bad weather condition of heavy rainfall,\nraindrops, mainly hitting glasses or windshields, can significantly reduce\nobservation ability. Moreover, raindrops spreading over the glass can yield\nrefraction's physical effect, which seriously impedes the sightline or\nundermine machine learning systems. In this paper, we propose an enhanced\ngenerative adversarial network to deal with the challenging problems of\nraindrops. UnfairGAN is an enhanced generative adversarial network that can\nutilize prior high-level information, such as edges and rain estimation, to\nboost deraining performance. To demonstrate UnfairGAN, we introduce a large\ndataset for training deep learning models of rain removal. The experimental\nresults show that our proposed method is superior to other state-of-the-art\napproaches of deraining raindrops regarding quantitative metrics and visual\nquality.",
    "descriptor": "",
    "authors": [
      "Duc Manh Nguyen",
      "Sang-Woong Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.05523"
  },
  {
    "id": "arXiv:2110.05524",
    "title": "Generalization Techniques Empirically Outperform Differential Privacy  against Membership Inference",
    "abstract": "Differentially private training algorithms provide protection against one of\nthe most popular attacks in machine learning: the membership inference attack.\nHowever, these privacy algorithms incur a loss of the model's classification\naccuracy, therefore creating a privacy-utility trade-off. The amount of noise\nthat differential privacy requires to provide strong theoretical protection\nguarantees in deep learning typically renders the models unusable, but authors\nhave observed that even lower noise levels provide acceptable empirical\nprotection against existing membership inference attacks.\nIn this work, we look for alternatives to differential privacy towards\nempirically protecting against membership inference attacks. We study the\nprotection that simply following good machine learning practices (not designed\nwith privacy in mind) offers against membership inference. We evaluate the\nperformance of state-of-the-art techniques, such as pre-training and\nsharpness-aware minimization, alone and with differentially private training\nalgorithms, and find that, when using early stopping, the algorithms without\ndifferential privacy can provide both higher utility and higher privacy than\ntheir differentially private counterparts. These findings challenge the belief\nthat differential privacy is a good defense to protect against existing\nmembership inference attacks",
    "descriptor": "",
    "authors": [
      "Jiaxiang Liu",
      "Simon Oya",
      "Florian Kerschbaum"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.05524"
  },
  {
    "id": "arXiv:2110.05525",
    "title": "Synergistic Offline-Online Control Synthesis via Local Gaussian Process  Regression",
    "abstract": "Autonomous systems often have complex and possibly unknown dynamics due to,\ne.g., black-box components. This leads to unpredictable behaviors and makes\ncontrol design with performance guarantees a major challenge. This paper\npresents a data-driven control synthesis framework for such systems subject to\nlinear temporal logic on finite traces (LTLf) specifications. The framework\ncombines a baseline (offline) controller with a novel online controller and\nrefinement procedure that improves the baseline guarantees as new data is\ncollected. The baseline controller is computed offline on an uncertain\nabstraction constructed using Gaussian process (GP) regression on a given\ndataset. The offline controller provides a lower bound on the probability of\nsatisfying the LTLf specification, which may be far from optimal due to both\ndiscretization and regression errors. The synergy arises from the online\ncontroller using the offline abstraction along with the current state and new\ndata to choose the next best action. The online controller may improve the\nbaseline guarantees since it avoids the discretization error and reduces\nregression error as new data is collected. The new data are also used to refine\nthe abstraction and offline controller using local GP regression, which\nsignificantly reduces the computation overhead. Evaluations show the efficacy\nof the proposed offline-online framework, especially when compared against the\noffline controller.",
    "descriptor": "\nComments: To appear in the 60th IEEE Conf on Decision and Control\n",
    "authors": [
      "John Jackson",
      "Luca Laurenti",
      "Eric Frew",
      "Morteza Lahijanian"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.05525"
  },
  {
    "id": "arXiv:2110.05529",
    "title": "HUNTER: AI based Holistic Resource Management for Sustainable Cloud  Computing",
    "abstract": "The worldwide adoption of cloud data centers (CDCs) has given rise to the\nubiquitous demand for hosting application services on the cloud. Further,\ncontemporary data-intensive industries have seen a sharp upsurge in the\nresource requirements of modern applications. This has led to the provisioning\nof an increased number of cloud servers, giving rise to higher energy\nconsumption and, consequently, sustainability concerns. Traditional heuristics\nand reinforcement learning based algorithms for energy-efficient cloud resource\nmanagement address the scalability and adaptability related challenges to a\nlimited extent. Existing work often fails to capture dependencies across\nthermal characteristics of hosts, resource consumption of tasks and the\ncorresponding scheduling decisions. This leads to poor scalability and an\nincrease in the compute resource requirements, particularly in environments\nwith non-stationary resource demands. To address these limitations, we propose\nan artificial intelligence (AI) based holistic resource management technique\nfor sustainable cloud computing called HUNTER. The proposed model formulates\nthe goal of optimizing energy efficiency in data centers as a multi-objective\nscheduling problem, considering three important models: energy, thermal and\ncooling. HUNTER utilizes a Gated Graph Convolution Network as a surrogate model\nfor approximating the Quality of Service (QoS) for a system state and\ngenerating optimal scheduling decisions. Experiments on simulated and physical\ncloud environments using the CloudSim toolkit and the COSCO framework show that\nHUNTER outperforms state-of-the-art baselines in terms of energy consumption,\nSLA violation, scheduling time, cost and temperature by up to 12, 35, 43, 54\nand 3 percent respectively.",
    "descriptor": "\nComments: Accepted in Elsevier Journal of Systems and Software, 2021\n",
    "authors": [
      "Shreshth Tuli",
      "Sukhpal Singh Gill",
      "Minxian Xu",
      "Peter Garraghan",
      "Rami Bahsoon",
      "Scharam Dustdar",
      "Rizos Sakellariou",
      "Omer Rana",
      "Rajkumar Buyya",
      "Giuliano Casale",
      "Nicholas R. Jennings"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2110.05529"
  },
  {
    "id": "arXiv:2110.05532",
    "title": "Urban traffic dynamic rerouting framework: A DRL-based model with  fog-cloud architecture",
    "abstract": "Past research and practice have demonstrated that dynamic rerouting framework\nis effective in mitigating urban traffic congestion and thereby improve urban\ntravel efficiency. It has been suggested that dynamic rerouting could be\nfacilitated using emerging technologies such as fog-computing which offer\nadvantages of low-latency capabilities and information exchange between\nvehicles and roadway infrastructure. To address this question, this study\nproposes a two-stage model that combines GAQ (Graph Attention Network - Deep Q\nLearning) and EBkSP (Entropy Based k Shortest Path) using a fog-cloud\narchitecture, to reroute vehicles in a dynamic urban environment and therefore\nto improve travel efficiency in terms of travel speed. First, GAQ analyzes the\ntraffic conditions on each road and for each fog area, and then assigns a road\nindex based on the information attention from both local and neighboring areas.\nSecond, EBkSP assigns the route for each vehicle based on the vehicle priority\nand route popularity. A case study experiment is carried out to investigate the\nefficacy of the proposed model. At the model training stage, different methods\nare used to establish the vehicle priorities, and their impact on the results\nis assessed. Also, the proposed model is tested under various scenarios with\ndifferent ratios of rerouting and background (non-rerouting) vehicles. The\nresults demonstrate that vehicle rerouting using the proposed model can help\nattain higher speed and reduces possibility of severe congestion. This result\nsuggests that the proposed model can be deployed by urban transportation\nagencies for dynamic rerouting and ultimately, to reduce urban traffic\ncongestion.",
    "descriptor": "\nComments: Under review for presentation at TRB 2022 Annual Meeting\n",
    "authors": [
      "Runjia Du",
      "Sikai Chen",
      "Jiqian Dong",
      "Tiantian Chen",
      "Xiaowen Fu",
      "Samuel Labi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05532"
  },
  {
    "id": "arXiv:2110.05540",
    "title": "Parallel Batched Interpolation Search Tree",
    "abstract": "Ordered set (and map) is one of the most used data type. In addition to\nstandard set operations, like insert, delete and contains, it can provide\nset-set operations such as union, intersection, and difference. Each of these\nset-set operations is equivalent to batched operations: the data structure\nshould process a set of operations insert, delete, and contains. It is obvious\nthat we want these \"large\" operations to be parallelized. Typically, these sets\nare implemented with the trees of logarithmic height, such as 2-3 tree, Treap,\nAVL tree, Red-Black tree, etc. Until now, little attention was devoted to data\nstructures that work better but under several restrictions on the data. In this\nwork, we parallelize Interpolation Search Tree which serves each request from a\nsmooth distribution in doubly-logarithmic time. Our data structure of size $n$\nperforms a batch of $m$ operations in $O(m \\log\\log n)$ work and poly-log span.",
    "descriptor": "",
    "authors": [
      "Vitaly Aksenov",
      "Ilya Kokorin",
      "Alena Martsenyuk"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.05540"
  },
  {
    "id": "arXiv:2110.05543",
    "title": "Fallout: Distributed Systems Testing as a Service",
    "abstract": "All modern distributed systems list performance and scalability as their core\nstrengths. Given that optimal performance requires carefully selecting\nconfiguration options, and typical cluster sizes can range anywhere from 2 to\n300 nodes, it is rare for any two clusters to be exactly the same. Validating\nthe behavior and performance of distributed systems in this large configuration\nspace is challenging without automation that stretches across the software\nstack. In this paper we present Fallout, an open-source distributed systems\ntesting service that automatically provisions and configures distributed\nsystems and clients, supports running a variety of workloads and benchmarks,\nand generates performance reports based on collected metrics for visual\nanalysis. We have been running the Fallout service internally at DataStax for\nover 5 years and have recently open sourced it to support our work with Apache\nCassandra, Pulsar, and other open source projects. We describe the architecture\nof Fallout along with the evolution of its design and the lessons we learned\noperating this service in a dynamic environment where teams work on different\nproducts and favor different benchmarking tools.",
    "descriptor": "\nComments: Submitted to 2021 BenchCouncil International Symposium on Benchmarking, Measuring and Optimizing (Bench'21)\n",
    "authors": [
      "Guy Bolton King",
      "Sean McCarthy",
      "Pushkala Pattabhiraman",
      "Jake Luciani",
      "Matt Fleming"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.05543"
  },
  {
    "id": "arXiv:2110.05545",
    "title": "Peformance Prediction for Coarse-Grained Locking: MCS Case",
    "abstract": "A standard design pattern found in many concurrent data structures, such as\nhash tables or ordered containers, is alternation of parallelizable sections\nthat incur no data conflicts and critical sections that must run sequentially\nand are protected with locks. It was already shown that simple stochastic\nanalysis can predict the throughput of coarse-grained lock-based algorithms\nusing CLH lock. In this short paper, we extend this analysis to algorithms\nbased on the popular MCS lock.",
    "descriptor": "",
    "authors": [
      "Vitaly Aksenov",
      "Daniil Bolotov",
      "Petr Kuznetsov"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.05545"
  },
  {
    "id": "arXiv:2110.05554",
    "title": "Towards a Cost vs. Quality Sweet Spot for Monitoring Networks",
    "abstract": "Continuously monitoring a wide variety of performance and fault metrics has\nbecome a crucial part of operating large-scale datacenter networks. In this\nwork, we ask whether we can reduce the costs to monitor -- in terms of\ncollection, storage and analysis -- by judiciously controlling how much and\nwhich measurements we collect. By positing that we can treat almost all\nmeasured signals as sampled time-series, we show that we can use signal\nprocessing techniques such as the Nyquist-Shannon theorem to avoid wasteful\ndata collection. We show that large savings appear possible by analyzing tens\nof popular measurements from a production datacenter network. We also discuss\nthe technical challenges that must be solved when applying these techniques in\npractice.",
    "descriptor": "",
    "authors": [
      "Nofel Yaseen",
      "Behnaz Arzani",
      "Krishna Chintalapudi",
      "Vaishnavi Ranganathan",
      "Felipe Frujeri",
      "Kevin Hsieh",
      "Daniel Berger",
      "Vincent Liu",
      "Srikanth Kandula"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.05554"
  },
  {
    "id": "arXiv:2110.05556",
    "title": "Addressing crash-imminent situations caused by human driven vehicle  errors in a mixed traffic stream: a model-based reinforcement learning  approach for CAV",
    "abstract": "It is anticipated that the era of fully autonomous vehicle operations will be\npreceded by a lengthy \"Transition Period\" where the traffic stream will be\nmixed, that is, consisting of connected autonomous vehicles (CAVs),\nhuman-driven vehicles (HDVs) and connected human-driven vehicles (CHDVs). In\nrecognition of the fact that public acceptance of CAVs will hinge on safety\nperformance of automated driving systems, and that there will likely be safety\nchallenges in the early part of the transition period, significant research\nefforts have been expended in the development of safety-conscious automated\ndriving systems. Yet still, there appears to be a lacuna in the literature\nregarding the handling of the crash-imminent situations that are caused by\nerrant human driven vehicles (HDVs) in the vicinity of the CAV during\noperations on the roadway. In this paper, we develop a simple model-based\nReinforcement Learning (RL) based system that can be deployed in the CAV to\ngenerate trajectories that anticipate and avoid potential collisions caused by\ndrivers of the HDVs. The model involves an end-to-end data-driven approach that\ncontains a motion prediction model based on deep learning, and a fast\ntrajectory planning algorithm based on model predictive control (MPC). The\nproposed system requires no prior knowledge or assumption about the physical\nenvironment including the vehicle dynamics, and therefore represents a general\napproach that can be deployed on any type of vehicle (e.g., truck, buse,\nmotorcycle, etc.). The framework is trained and tested in the CARLA simulator\nwith multiple collision imminent scenarios, and the results indicate the\nproposed model can avoid the collision at high successful rate (>85%) even in\nhighly compact and dangerous situations.",
    "descriptor": "\nComments: Under review for presentation at TRB 2022 Annual Meeting\n",
    "authors": [
      "Jiqian Dong",
      "Sikai Chen",
      "Samuel Labi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.05556"
  },
  {
    "id": "arXiv:2110.05559",
    "title": "Development and testing of an image transformer for explainable  autonomous driving systems",
    "abstract": "In the last decade, deep learning (DL) approaches have been used successfully\nin computer vision (CV) applications. However, DL-based CV models are generally\nconsidered to be black boxes due to their lack of interpretability. This black\nbox behavior has exacerbated user distrust and therefore has prevented\nwidespread deployment DLCV models in autonomous driving tasks even though some\nof these models exhibit superiority over human performance. For this reason, it\nis essential to develop explainable DL models for autonomous driving task.\nExplainable DL models can not only boost user trust in autonomy but also serve\nas a diagnostic approach to identify anydefects and weaknesses of the model\nduring the system development phase. In this paper, we propose an explainable\nend-to-end autonomous driving system based on \"Transformer\", a state-of-the-art\n(SOTA) self-attention based model, to map visual features from images collected\nby onboard cameras to guide potential driving actions with corresponding\nexplanations. The model achieves a soft attention over the global features of\nthe image. The results demonstrate the efficacy of our proposed model as it\nexhibits superior performance (in terms of correct prediction of actions and\nexplanations) compared to the benchmark model by a significant margin with\nlower computational cost.",
    "descriptor": "\nComments: Under review for presentation at TRB 2022 Annual Meeting\n",
    "authors": [
      "Jiqian Dong",
      "Sikai Chen",
      "Shuya Zong",
      "Tiantian Chen",
      "Mohammad Miralinaghi",
      "Samuel Labi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05559"
  },
  {
    "id": "arXiv:2110.05560",
    "title": "Training Computing Educators to Become Computing Education Researchers",
    "abstract": "The computing education community endeavors to consistently move forward,\nimproving the educational experience of our students. As new innovations in\ncomputing education practice are learned and shared, however, these papers may\nnot exhibit the desired qualities that move simple experience reports to true\nScholarship of Teaching and Learning (SoTL). We report on our six years of\nexperience in running professional development for computing educators in\nempirical research methods for social and behavioral studies in the classroom.\nOur goal is to have a direct impact on instructors who are in the beginning\nstages of transitioning their educational innovations from anecdotal to\nempirical results that can be replicated by instructors at other institutions.\nTo achieve this, we created a year-long mentoring experience, beginning with a\nmulti-day workshop on empirical research methods during the summer, followed by\nregular mentoring sessions with participants, and culminating in a follow-up\nsession at the following year's SIGCSE Technical Symposium. From survey results\nand as evidenced by eventual research results and publications from\nparticipants, we believe that our method of structuring empirical research\nprofessional development was successful and could be a model for similar\nprograms in other areas.",
    "descriptor": "\nComments: Accepted to SIGCSE TS 2022\n",
    "authors": [
      "Jeffrey C. Carver",
      "Sarah Heckman",
      "Mark Sherriff"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.05560"
  },
  {
    "id": "arXiv:2110.05561",
    "title": "UrbanNet: Leveraging Urban Maps for Long Range 3D Object Detection",
    "abstract": "Relying on monocular image data for precise 3D object detection remains an\nopen problem, whose solution has broad implications for cost-sensitive\napplications such as traffic monitoring. We present UrbanNet, a modular\narchitecture for long range monocular 3D object detection with static cameras.\nOur proposed system combines commonly available urban maps along with a mature\n2D object detector and an efficient 3D object descriptor to accomplish accurate\ndetection at long range even when objects are rotated along any of their three\naxes. We evaluate UrbanNet on a novel challenging synthetic dataset and\nhighlight the advantages of its design for traffic detection in roads with\nchanging slope, where the flat ground approximation does not hold. Data and\ncode are available at https://github.com/TRAILab/UrbanNet",
    "descriptor": "\nComments: To be published in the 24th IEEE International Conference on Intelligent Transportation Systems - ITSC2021\n",
    "authors": [
      "Juan Carrillo",
      "Steven Waslander"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.05561"
  },
  {
    "id": "arXiv:2110.05562",
    "title": "A Mutation Framework for Evaluating Security Analysis tools in IoT  Applications",
    "abstract": "With the growing and widespread use of Internet of Things (IoT) in our daily\nlife, its security is becoming more crucial. To ensure information security, we\nrequire better security analysis tools for IoT applications. Hence, this paper\npresents an automated framework to evaluate taint-flow analysis tools in the\ndomain of IoT applications. First, we propose a set of mutational operators\ntailored to evaluate three types of sensitivity analysis, flow, path and\ncontext sensitivity. Then we developed mutators to automatically generate\nmutants for those types. We demonstrated the framework on a subset of\nmutational operators to evaluate three taint-flow analyzers, SaINT,\nTaint-Things and FlowsMiner. Our framework and experiments ranked the taint\nanalysis tools according to precision and recall as follows: Taint-Things (99%\nRecall, 100% Precision), FlowsMiner (100% Recall, 87.6% Precision), and SaINT\n(100% Recall, 56.8% Precision). To the best of our knowledge, our framework is\nthe first framework to address the need for evaluating taint-flow analysis\ntools and specifically those developed for IoT SmartThings applications.",
    "descriptor": "",
    "authors": [
      "Manar H. Alalfi",
      "Sajeda Parveen",
      "Bara Nazzal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.05562"
  },
  {
    "id": "arXiv:2110.05564",
    "title": "Scalable Traffic Signal Controls using Fog-Cloud Based Multiagent  Reinforcement Learning",
    "abstract": "Optimizing traffic signal control (TSC) at intersections continues to pose a\nchallenging problem, particularly for large-scale traffic networks. It has been\nshown in past research that it is feasible to optimize the operations of\nindividual TSC systems or a small number of such systems. However, it has been\ncomputationally difficult to scale these solution approaches to large networks\npartly due to the curse of dimensionality that is encountered as the number of\nintersections increases. Fortunately, recent studies have recognized the\npotential of exploiting advancements in deep and reinforcement learning to\naddress this problem, and some preliminary successes have been achieved in this\nregard. However, facilitating such intelligent solution approaches may require\nlarge amounts of infrastructural investments such as roadside units (RSUs) and\ndrones in order to ensure thorough connectivity across all intersections in\nlarge networks, an investment that may be burdensome for agencies to undertake.\nAs such, this study builds on recent work to present a scalable TSC model that\nmay reduce the number of required enabling infrastructure. This is achieved\nusing graph attention networks (GATs) to serve as the neural network for deep\nreinforcement learning, which aids in maintaining the graph topology of the\ntraffic network while disregarding any irrelevant or unnecessary information. A\ncase study is carried out to demonstrate the effectiveness of the proposed\nmodel, and the results show much promise. The overall research outcome suggests\nthat by decomposing large networks using fog-nodes, the proposed fog-based\ngraphic RL (FG-RL) model can be easily applied to scale into larger traffic\nnetworks.",
    "descriptor": "\nComments: Under review for presentation at TRB 2022 Annual Meeting\n",
    "authors": [
      "Paul",
      "Sikai Chen",
      "Runjia Du",
      "Samuel Labi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05564"
  },
  {
    "id": "arXiv:2110.05568",
    "title": "Improving Frequency Stability of Low-Inertia Systems using Virtual  Induction Machine",
    "abstract": "This paper presents a novel strategy for synchronization of grid-connected\nVoltage Source Converters (VSCs) in power systems with low rotational inertia.\nThe proposed model is based on emulating the physical properties of an\ninduction machine and capitalizes on its inherent grid-friendly properties such\nas self-synchronization, oscillation damping and standalone capabilities. A\ndetailed mathematical model of an induction machine is derived, which includes\nthe possibility of obtaining the unknown grid frequency by processing the\nvoltage and current measurements at the converter output. This eliminates the\nneed for the phase-locked loop unit, traditionally employed in grid-following\nVSC control schemes, while simultaneously preserving the applied system-level\nand device-level control. Furthermore, the appropriate steps for obtaining an\nindex-1 DAE representation of the induction-machine-based synchronization unit\nwithin the VSC control scheme are provided. The EMT simulations validate the\nmathematical principles of the proposed model, whereas a small-signal analysis\nprovides guidelines for appropriate control tuning and reveals interesting\nproperties pertaining to the nature of the underlying operation mode.",
    "descriptor": "",
    "authors": [
      "Ognjen Stanojev",
      "Uros Markovic",
      "Petros Aristidou",
      "Gabriela Hug"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.05568"
  },
  {
    "id": "arXiv:2110.05572",
    "title": "EchoVPR: Echo State Networks for Visual Place Recognition",
    "abstract": "Recognising previously visited locations is an important, but unsolved, task\nin autonomous navigation. Current visual place recognition (VPR) benchmarks\ntypically challenge models to recover the position of a query image (or images)\nfrom sequential datasets that include both spatial and temporal components.\nRecently, Echo State Network (ESN) varieties have proven particularly powerful\nat solving machine learning tasks that require spatio-temporal modelling. These\nnetworks are simple, yet powerful neural architectures that -- exhibiting\nmemory over multiple time-scales and non-linear high-dimensional\nrepresentations -- can discover temporal relations in the data while still\nmaintaining linearity in the learning. In this paper, we present a series of\nESNs and analyse their applicability to the VPR problem. We report that the\naddition of ESNs to pre-processed convolutional neural networks led to a\ndramatic boost in performance in comparison to non-recurrent networks in four\nstandard benchmarks (GardensPoint, SPEDTest, ESSEX3IN1, Nordland) demonstrating\nthat ESNs are able to capture the temporal structure inherent in VPR problems.\nMoreover, we show that ESNs can outperform class-leading VPR models which also\nexploit the sequential dynamics of the data. Finally, our results demonstrate\nthat ESNs also improve generalisation abilities, robustness, and accuracy\nfurther supporting their suitability to VPR applications.",
    "descriptor": "\nComments: 8 pages, 7 figures, submitted to ICRA 2022 (under review)\n",
    "authors": [
      "Anil Ozdemir",
      "Andrew B. Barron",
      "Andrew Philippides",
      "Michael Mangan",
      "Eleni Vasilaki",
      "Luca Manneschi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.05572"
  },
  {
    "id": "arXiv:2110.05573",
    "title": "Spatial Data Mining of Public Transport Incidents reported in Social  Media",
    "abstract": "Public transport agencies use social media as an essential tool for\ncommunicating mobility incidents to passengers. However, while the short term,\nday-to-day information about transport phenomena is usually posted in social\nmedia with low latency, its availability is short term as the content is rarely\nmade an aggregated form. Social media communication of transport phenomena\nusually lacks GIS annotations as most social media platforms do not allow\nattaching non-POI GPS coordinates to posts. As a result, the analysis of\ntransport phenomena information is minimal. We collected three years of social\nmedia posts of a polish public transport company with user comments. Through\nexploration, we infer a six-class transport information typology. We\nsuccessfully build an information type classifier for social media posts,\ndetect stop names in posts, and relate them to GPS coordinates, obtaining a\nspatial understanding of long-term aggregated phenomena. We show that our\napproach enables citizen science and use it to analyze the impact of three\nyears of infrastructure incidents on passenger mobility, and the sentiment and\nreaction scale towards each of the events. All these results are achieved for\nPolish, an under-resourced language when it comes to spatial language\nunderstanding, especially in social media contexts. To improve the situation,\nwe released two of our annotated data sets: social media posts with incident\ntype labels and matched stop names and social media comments with the annotated\nsentiment. We also opensource the experimental codebase.",
    "descriptor": "\nComments: Preprint, accepted to IWCTS at SIGSPATIAL'21\n",
    "authors": [
      "Kamil Raczycki",
      "Marcin Szyma\u0144ski",
      "Yahor Yeliseyenka",
      "Piotr Szyma\u0144ski",
      "Tomasz Kajdanowicz"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05573"
  },
  {
    "id": "arXiv:2110.05576",
    "title": "Mutual cooperation and tolerance to defection in the context of  socialization: the theoretical model and experimental evidence",
    "abstract": "The study of the nature of human cooperation still contains gaps needing\ninvestigation. Previous findings reveal that socialization effectively promotes\ncooperation in the well-known Prisoner's dilemma (PD) game. However,\ntheoretical concepts fail to describe high levels of cooperation (probability\nhigher than 50%) that were observed empirically. In this paper, we derive a\nsymmetrical quantal response equilibrium (QRE) in PD in Markov strategies and\ntest it against experimental data. Our results indicate that for low levels of\nrationality, QRE manages to describe high cooperation. In contrast, for high\nrationality QRE converges to the Nash equilibrium and describes low-cooperation\nbehavior of participants. In the area of middle rationality, QRE matches the\ncurve that represents the set of Nash equilibrium in Markov strategies.\nFurther, we find that QRE serves as a dividing line between behavior before and\nafter socialization, according to the experimental data. Finally, we\nsuccessfully highlight the theoretically-predicted intersection of the set of\nNash equilibrium in Markov strategies and the QRE curve.",
    "descriptor": "",
    "authors": [
      "Tatiana Kozitsina",
      "Ivan Kozitsin",
      "Ivan Menshikov"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.05576"
  },
  {
    "id": "arXiv:2110.05580",
    "title": "vocadito: A dataset of solo vocals with $f_0$, note, and lyric  annotations",
    "abstract": "To compliment the existing set of datasets, we present a small dataset\nentitled vocadito, consisting of 40 short excerpts of monophonic singing, sung\nin 7 different languages by singers with varying of levels of training, and\nrecorded on a variety of devices. We provide several types of annotations,\nincluding $f_0$, lyrics, and two different note annotations. All annotations\nwere created by musicians. We provide an analysis of the differences between\nthe two note annotations, and see that the agreement level is low, which has\nimplications for evaluating vocal note estimation algorithms. We also analyze\nthe relation between the $f_0$ and note annotations, and show that quantizing\n$f_0$ values in frequency does not provide a reasonable note estimate,\nreinforcing the difficulty of the note estimation task for singing voice.\nFinally, we provide baseline results from recent algorithms on vocadito for\nnote and $f_0$ transcription. Vocadito is made freely available for public use.",
    "descriptor": "",
    "authors": [
      "Rachel M. Bittner",
      "Katherine Pasalo",
      "Juan Jos\u00e9 Bosch",
      "Gabriel Meseguer-Brocal",
      "David Rubinstein"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05580"
  },
  {
    "id": "arXiv:2110.05587",
    "title": "Evaluation of Latent Space Disentanglement in the Presence of  Interdependent Attributes",
    "abstract": "Controllable music generation with deep generative models has become\nincreasingly reliant on disentanglement learning techniques. However, current\ndisentanglement metrics, such as mutual information gap (MIG), are often\ninadequate and misleading when used for evaluating latent representations in\nthe presence of interdependent semantic attributes often encountered in\nreal-world music datasets. In this work, we propose a dependency-aware\ninformation metric as a drop-in replacement for MIG that accounts for the\ninherent relationship between semantic attributes.",
    "descriptor": "\nComments: Submitted to the Late-Breaking Demo Session of the 22nd International Society for Music Information Retrieval Conference\n",
    "authors": [
      "Karn N. Watcharasupat",
      "Alexander Lerch"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Information Retrieval (cs.IR)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05587"
  },
  {
    "id": "arXiv:2110.05589",
    "title": "TTRS: Tinkoff Transactions Recommender System benchmark",
    "abstract": "Over the past decade, tremendous progress has been made in inventing new\nRecSys methods. However, one of the fundamental problems of the RecSys research\ncommunity remains the lack of applied datasets and benchmarks with well-defined\nevaluation rules and metrics to test these novel approaches. In this article,\nwe present the TTRS - Tinkoff Transactions Recommender System benchmark. This\nfinancial transaction benchmark contains over 2 million interactions between\nalmost 10,000 users and more than 1,000 merchant brands over 14 months. To the\nbest of our knowledge, this is the first publicly available financial\ntransactions dataset. To make it more suitable for possible applications, we\nprovide a complete description of the data collection pipeline, its\npreprocessing, and the resulting dataset statistics. We also present a\ncomprehensive comparison of the current popular RecSys methods on the\nnext-period recommendation task and conduct a detailed analysis of their\nperformance against various metrics and recommendation goals. Last but not\nleast, we also introduce Personalized Item-Frequencies-based Model (Re)Ranker -\nPIFMR, a simple yet powerful approach that has proven to be the most effective\nfor the benchmarked tasks.",
    "descriptor": "",
    "authors": [
      "Sergey Kolesnikov",
      "Oleg Lashinin",
      "Michail Pechatov",
      "Alexander Kosov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05589"
  },
  {
    "id": "arXiv:2110.05594",
    "title": "Neural Radiance Fields Approach to Deep Multi-View Photometric Stereo",
    "abstract": "We present a modern solution to the multi-view photometric stereo problem\n(MVPS). Our work suitably exploits the image formation model in a MVPS\nexperimental setup to recover the dense 3D reconstruction of an object from\nimages. We procure the surface orientation using a photometric stereo (PS)\nimage formation model and blend it with a multi-view neural radiance field\nrepresentation to recover the object's surface geometry. Contrary to the\nprevious multi-staged framework to MVPS, where the position, iso-depth\ncontours, or orientation measurements are estimated independently and then\nfused later, our method is simple to implement and realize. Our method performs\nneural rendering of multi-view images while utilizing surface normals estimated\nby a deep photometric stereo network. We render the MVPS images by considering\nthe object's surface normals for each 3D sample point along the viewing\ndirection rather than explicitly using the density gradient in the volume space\nvia 3D occupancy information. We optimize the proposed neural radiance field\nrepresentation for the MVPS setup efficiently using a fully connected deep\nnetwork to recover the 3D geometry of an object. Extensive evaluation on the\nDiLiGenT-MV benchmark dataset shows that our method performs better than the\napproaches that perform only PS or only multi-view stereo (MVS) and provides\ncomparable results against the state-of-the-art multi-stage fusion methods.",
    "descriptor": "\nComments: Accepted for publication at IEEE/CVF WACV 2022. 18 pages\n",
    "authors": [
      "Berk Kaya",
      "Suryansh Kumar",
      "Francesco Sarno",
      "Vittorio Ferrari",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05594"
  },
  {
    "id": "arXiv:2110.05596",
    "title": "Perspective-taking to Reduce Affective Polarization on Social Media",
    "abstract": "The intensification of affective polarization worldwide has raised new\nquestions about how social media platforms might be further fracturing an\nalready-divided public sphere. As opposed to ideological polarization,\naffective polarization is defined less by divergent policy preferences and more\nby strong negative emotions towards opposing political groups, and thus\narguably poses a formidable threat to rational democratic discourse. We explore\nif prompting perspective-taking on social media platforms can help enhance\nempathy between opposing groups as a first step towards reducing affective\npolarization. Specifically, we deploy a randomized field experiment through a\nbrowser extension to 1,611 participants on Twitter, which enables participants\nto randomly replace their feeds with those belonging to accounts whose\npolitical views either agree with or diverge from their own. We find that\nsimply exposing participants to \"outgroup\" feeds enhances engagement, but not\nan understanding of why others hold their political views. On the other hand,\nframing the experience in familiar, empathic terms by prompting participants to\nrecall a disagreement with a friend does not affect engagement, but does\nincrease their ability to understand opposing views. Our findings illustrate\nhow social media platforms might take simple steps that align with business\nobjectives to reduce affective polarization.",
    "descriptor": "\nComments: To appear in ICWSM'22 (International AAAI Conference on Web and Social Media)\n",
    "authors": [
      "Martin Saveski",
      "Nabeel Gillani",
      "Ann Yuan",
      "Prashanth Vijayaraghavan",
      "Deb Roy"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.05596"
  },
  {
    "id": "arXiv:2110.05597",
    "title": "Learning to Coordinate in Multi-Agent Systems: A Coordinated  Actor-Critic Algorithm and Finite-Time Guarantees",
    "abstract": "Multi-agent reinforcement learning (MARL) has attracted much research\nattention recently. However, unlike its single-agent counterpart, many\ntheoretical and algorithmic aspects of MARL have not been well-understood. In\nthis paper, we study the emergence of coordinated behavior by autonomous agents\nusing an actor-critic (AC) algorithm. Specifically, we propose and analyze a\nclass of coordinated actor-critic algorithms (CAC) in which individually\nparametrized policies have a {\\it shared} part (which is jointly optimized\namong all agents) and a {\\it personalized} part (which is only locally\noptimized). Such kind of {\\it partially personalized} policy allows agents to\nlearn to coordinate by leveraging peers' past experience and adapt to\nindividual tasks. The flexibility in our design allows the proposed MARL-CAC\nalgorithm to be used in a {\\it fully decentralized} setting, where the agents\ncan only communicate with their neighbors, as well as a {\\it federated}\nsetting, where the agents occasionally communicate with a server while\noptimizing their (partially personalized) local models. Theoretically, we show\nthat under some standard regularity assumptions, the proposed MARL-CAC\nalgorithm requires $\\mathcal{O}(\\epsilon^{-\\frac{5}{2}})$ samples to achieve an\n$\\epsilon$-stationary solution (defined as the solution whose squared norm of\nthe gradient of the objective function is less than $\\epsilon$). To the best of\nour knowledge, this work provides the first finite-sample guarantee for\ndecentralized AC algorithm with partially personalized policies.",
    "descriptor": "",
    "authors": [
      "Siliang Zeng",
      "Tianyi Chen",
      "Alfredo Garcia",
      "Mingyi Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.05597"
  },
  {
    "id": "arXiv:2110.05598",
    "title": "GCN-SE: Attention as Explainability for Node Classification in Dynamic  Graphs",
    "abstract": "Graph Convolutional Networks (GCNs) are a popular method from graph\nrepresentation learning that have proved effective for tasks like node\nclassification tasks. Although typical GCN models focus on classifying nodes\nwithin a static graph, several recent variants propose node classification in\ndynamic graphs whose topologies and node attributes change over time, e.g.,\nsocial networks with dynamic relationships, or literature citation networks\nwith changing co-authorships. These works, however, do not fully address the\nchallenge of flexibly assigning different importance to snapshots of the graph\nat different times, which depending on the graph dynamics may have more or less\npredictive power on the labels. We address this challenge by proposing a new\nmethod, GCN-SE, that attaches a set of learnable attention weights to graph\nsnapshots at different times, inspired by Squeeze and Excitation Net (SE-Net).\nWe show that GCN-SE outperforms previously proposed node classification methods\non a variety of graph datasets. To verify the effectiveness of the attention\nweight in determining the importance of different graph snapshots, we adapt\nperturbation-based methods from the field of explainable machine learning to\ngraphical settings and evaluate the correlation between the attention weights\nlearned by GCN-SE and the importance of different snapshots over time. These\nexperiments demonstrate that GCN-SE can in fact identify different snapshots'\npredictive power for dynamic node classification.",
    "descriptor": "\nComments: Accepted by ICDM 2021\n",
    "authors": [
      "Yucai Fan",
      "Yuhang Yao",
      "Carlee Joe-Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.05598"
  },
  {
    "id": "arXiv:2110.05601",
    "title": "A Time-Optimized Content Creation Workflow for Remote Teaching",
    "abstract": "We describe our workflow to create an engaging remote learning experience for\na university course, while minimizing the post-production time of the\neducators. We make use of ubiquitous and commonly free services and platforms,\nso that our workflow is inclusive for all educators and provides polished\nexperiences for students. Our learning materials provide for each lecture: 1) a\nrecorded video, uploaded on YouTube, with exact slide timestamp indices, which\nenables an enhanced navigation UI; and 2) a high-quality flow-text automated\ntranscript of the narration with proper punctuation and capitalization,\nimproved with a student participation workflow on GitHub. All these results\ncould be created by hand in a time consuming and costly way. However, this\nwould generally exceed the time available for creating course materials. Our\nmain contribution is to automate the transformation and post-production between\nraw narrated slides and our published materials with a custom toolchain.\nFurthermore, we describe our complete workflow: from content creation to\ntransformation and distribution. Our students gave us overwhelmingly positive\nfeedback and especially liked our use of ubiquitous platforms. The most used\nfeature was YouTube's chapter UI enabled through our automatically generated\ntimestamps. The majority of students, who started using the transcripts,\ncontinued to do so. Every single transcript was corrected by students, with an\naverage word-change of 6%. We conclude with the positive feedback that our\nenhanced content formats are much appreciated and utilized. Important for\neducators is how our low overhead production workflow was sustainable\nthroughout a busy semester.",
    "descriptor": "\nComments: Accepted at SIGSCE-TS 2022\n",
    "authors": [
      "Sebastian Hofst\u00e4tter",
      "Sophia Althammer",
      "Mete Sertkan",
      "Allan Hanbury"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.05601"
  },
  {
    "id": "arXiv:2110.05603",
    "title": "Generalizing to New Domains by Mapping Natural Language to Lifted LTL",
    "abstract": "Recent work on using natural language to specify commands to robots has\ngrounded that language to LTL. However, mapping natural language task\nspecifications to LTL task specifications using language models require\nprobability distributions over finite vocabulary. Existing state-of-the-art\nmethods have extended this finite vocabulary to include unseen terms from the\ninput sequence to improve output generalization. However, novel\nout-of-vocabulary atomic propositions cannot be generated using these methods.\nTo overcome this, we introduce an intermediate contextual query representation\nwhich can be learned from single positive task specification examples,\nassociating a contextual query with an LTL template. We demonstrate that this\nintermediate representation allows for generalization over unseen object\nreferences, assuming accurate groundings are available. We compare our method\nof mapping natural language task specifications to intermediate contextual\nqueries against state-of-the-art CopyNet models capable of translating natural\nlanguage to LTL, by evaluating whether correct LTL for manipulation and\nnavigation task specifications can be output, and show that our method\noutperforms the CopyNet model on unseen object references. We demonstrate that\nthe grounded LTL our method outputs can be used for planning in a simulated\nOO-MDP environment. Finally, we discuss some common failure modes encountered\nwhen translating natural language task specifications to grounded LTL.",
    "descriptor": "\nComments: 7 pages (6 + 1 references page), 3 figures, 2 tables. Submitted to ICRA 2022\n",
    "authors": [
      "Eric Hsiung",
      "Hiloni Mehta",
      "Junchi Chu",
      "Xinyu Liu",
      "Roma Patel",
      "Stefanie Tellex",
      "George Konidaris"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.05603"
  },
  {
    "id": "arXiv:2110.05604",
    "title": "A caster-wheel-aware MPC-based motion planner for mobile robotics",
    "abstract": "Differential drive mobile robots often use one or more caster wheels for\nbalance. Caster wheels are appreciated for their ability to turn in any\ndirection almost on the spot, allowing the robot to do the same and thereby\ngreatly simplifying the motion planning and control. However, in aligning the\ncaster wheels to the intended direction of motion they produce a so-called bore\ntorque. As a result, additional motor torque is required to move the robot,\nwhich may in some cases exceed the motor capacity or compromise the motion\nplanner's accuracy. Instead of taking a decoupled approach, where the\nnavigation and disturbance rejection algorithms are separated, we propose to\nembed the caster wheel awareness into the motion planner. To do so, we present\na caster-wheel-aware term that is compatible with MPC-based control methods,\nleveraging the existence of caster wheels in the motion planning stage. As a\nproof of concept, this term is combined with a a model-predictive trajectory\ntracking controller. Since this method requires knowledge of the caster wheel\nangle and rolling speed, an observer that estimates these states is also\npresented. The efficacy of the approach is shown in experiments on an\nintralogistics robot and compared against a decoupled bore-torque reduction\napproach and a caster-wheel agnostic controller. Moreover, the experiments show\nthat the presented caster wheel estimator performs sufficiently well and\ntherefore avoids the need for additional sensors.",
    "descriptor": "",
    "authors": [
      "Jon Arrizabalaga",
      "Niels van Duijkeren",
      "Markus Ryll",
      "Ralph Lange"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.05604"
  },
  {
    "id": "arXiv:2110.05605",
    "title": "Randomized Extended Kaczmarz is a Limit Point of Sketch-and-Project",
    "abstract": "The sketch-and-project (SAP) framework for solving systems of linear\nequations has unified the theory behind popular projective iterative methods\nsuch as randomized Kaczmarz, randomized coordinate descent, and variants\nthereof. We show that the randomized extended Kaczmarz (REK) method - so far\nnot shown to lie within this framework - cannot be formulated as a SAP method,\na surprising result as it is of a very similar flavor. We show, in fact, that\nREK may instead be recovered as a limit point of a particular family of SAP\nmethods. We provide an extensive theoretical analysis of said family, including\nconvergence guarantees and further connections to REK. We follow this with an\narray of experiments demonstrating these methods and their connections in\npractice.",
    "descriptor": "\nComments: 18 pages, 12 figures\n",
    "authors": [
      "Benjamin Jarman",
      "Nathan Mankovich",
      "Jacob D. Moorman"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05605"
  },
  {
    "id": "arXiv:2110.05607",
    "title": "Partial Variable Training for Efficient On-Device Federated Learning",
    "abstract": "This paper aims to address the major challenges of Federated Learning (FL) on\nedge devices: limited memory and expensive communication. We propose a novel\nmethod, called Partial Variable Training (PVT), that only trains a small subset\nof variables on edge devices to reduce memory usage and communication cost.\nWith PVT, we show that network accuracy can be maintained by utilizing more\nlocal training steps and devices, which is favorable for FL involving a large\npopulation of devices. According to our experiments on two state-of-the-art\nneural networks for speech recognition and two different datasets, PVT can\nreduce memory usage by up to 1.9$\\times$ and communication cost by up to\n593$\\times$ while attaining comparable accuracy when compared with full network\ntraining.",
    "descriptor": "",
    "authors": [
      "Tien-Ju Yang",
      "Dhruv Guliani",
      "Fran\u00e7oise Beaufays",
      "Giovanni Motta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05607"
  },
  {
    "id": "arXiv:2110.05610",
    "title": "TSK Fuzzy System Towards Few Labeled Incomplete Multi-View Data  Classification",
    "abstract": "Data collected by multiple methods or from multiple sources is called\nmulti-view data. To make full use of the multi-view data, multi-view learning\nplays an increasingly important role. Traditional multi-view learning methods\nrely on a large number of labeled and completed multi-view data. However, it is\nexpensive and time-consuming to obtain a large number of labeled multi-view\ndata in real-world applications. Moreover, multi-view data is often incomplete\nbecause of data collection failures, self-deficiency, or other reasons.\nTherefore, we may have to face the problem of fewer labeled and incomplete\nmulti-view data in real application scenarios. In this paper, a transductive\nsemi-supervised incomplete multi-view TSK fuzzy system modeling method\n(SSIMV_TSK) is proposed to address these challenges. First, in order to\nalleviate the dependency on labeled data and keep the model interpretable, the\nproposed method integrates missing view imputation, pseudo label learning of\nunlabeled data, and fuzzy system modeling into a single process to yield a\nmodel with interpretable fuzzy rules. Then, two new mechanisms, i.e. the\nbidirectional structural preservation of instance and label, as well as the\nadaptive multiple alignment collaborative learning, are proposed to improve the\nrobustness of the model. The proposed method has the following distinctive\ncharacteristics: 1) it can deal with the incomplete and few labeled multi-view\ndata simultaneously; 2) it integrates the missing view imputation and model\nlearning as a single process, which is more efficient than the traditional\ntwo-step strategy; 3) attributed to the interpretable fuzzy inference rules,\nthis method is more interpretable. Experimental results on real datasets show\nthat the proposed method significantly outperforms the state-of-the-art\nmethods.",
    "descriptor": "\nComments: This paper has been submitted to Journal\n",
    "authors": [
      "Wei Zhang",
      "Zhaohong Deng",
      "Qiongdan Lou",
      "Te Zhang",
      "Kup-Sze Choi",
      "Shitong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05610"
  },
  {
    "id": "arXiv:2110.05614",
    "title": "Signal Processing on Cell Complexes",
    "abstract": "The processing of signals supported on non-Euclidean domains has attracted\nlarge interest in the last years. Thus far, such non-Euclidean domains have\nbeen abstracted primarily as graphs with signals supported on the nodes, though\nrecently the processing of signals on more general structures such as\nsimplicial complexes has also been considered. In this paper, we give an\nintroduction to signal processing on (abstract) regular cell complexes, which\nprovide a unifying framework encompassing graphs, simplicial complexes, cubical\ncomplexes and various meshes as special cases. We discuss how appropriate Hodge\nLaplacians for these cell complexes can be derived. These Hodge Laplacians\nenable the construction of convolutional filters, which can be employed in\nlinear filtering and non-linear filtering via neural networks defined on cell\ncomplexes.",
    "descriptor": "",
    "authors": [
      "T. Mitchell Roddenberry",
      "Michael T. Schaub",
      "Mustafa Hajij"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Algebraic Topology (math.AT)",
      "Geometric Topology (math.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.05614"
  },
  {
    "id": "arXiv:2110.05619",
    "title": "Towards a Principled Approach for Dynamic Analysis of Android's  Middleware",
    "abstract": "The Android middleware, in particular the so-called systemserver, is a\ncrucial and central component to Android's security and robustness. To\nunderstand whether the systemserver provides the demanded security properties,\nit has to be thoroughly tested and analyzed. A dedicated line of research\nfocuses exclusively on this task. While static analysis builds on established\ntools, dynamic testing approaches lack a common foundation, which prevents the\ncommunity from comparing, reproducing, or even re-using existing results from\nrelated work. This raises questions about whether the underlying approach of\nany proposed solution is the only possible or optimal one, if it can be re-used\nas a building block for future analyses, or whether results generalize. In this\nwork, we argue that in order to steer away from incompatible custom toolchains\nand towards having comparable analyses with reproducible results, a more\nprincipled approach to dynamically analyzing the Android system is required. As\nan important first step in this direction, we propose a unified dynamic\nanalysis platform that provides re-usable solutions for common challenges as\nthe building blocks for future analyses and allows to compare different\napproaches under the same assumptions.",
    "descriptor": "\nComments: Version submitted to USENIX OSDI'20\n",
    "authors": [
      "Oliver Schranz",
      "Sebastian Weisgerber",
      "Erik Derr",
      "Michael Backes",
      "Sven Bugiel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.05619"
  },
  {
    "id": "arXiv:2110.05621",
    "title": "Neural Architecture Search for Efficient Uncalibrated Deep Photometric  Stereo",
    "abstract": "We present an automated machine learning approach for uncalibrated\nphotometric stereo (PS). Our work aims at discovering lightweight and\ncomputationally efficient PS neural networks with excellent surface normal\naccuracy. Unlike previous uncalibrated deep PS networks, which are handcrafted\nand carefully tuned, we leverage differentiable neural architecture search\n(NAS) strategy to find uncalibrated PS architecture automatically. We begin by\ndefining a discrete search space for a light calibration network and a normal\nestimation network, respectively. We then perform a continuous relaxation of\nthis search space and present a gradient-based optimization strategy to find an\nefficient light calibration and normal estimation network. Directly applying\nthe NAS methodology to uncalibrated PS is not straightforward as certain\ntask-specific constraints must be satisfied, which we impose explicitly.\nMoreover, we search for and train the two networks separately to account for\nthe Generalized Bas-Relief (GBR) ambiguity. Extensive experiments on the\nDiLiGenT dataset show that the automatically searched neural architectures\nperformance compares favorably with the state-of-the-art uncalibrated PS\nmethods while having a lower memory footprint.",
    "descriptor": "\nComments: Accepted for publication at IEEE/CVF, WACV 2022. (11 pages)\n",
    "authors": [
      "Francesco Sarno",
      "Suryansh Kumar",
      "Berk Kaya",
      "Zhiwu Huang",
      "Vittorio Ferrari",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05621"
  },
  {
    "id": "arXiv:2110.05622",
    "title": "Review of Kernel Learning for Intra-Hour Solar Forecasting with Infrared  Sky Images and Cloud Dynamic Feature Extraction",
    "abstract": "The uncertainty of the energy generated by photovoltaic systems incurs an\nadditional cost for a guaranteed, reliable supply of energy (i.e., energy\nstorage). This investigation aims to decrease the additional cost by\nintroducing probabilistic multi-task intra-hour solar forecasting (feasible in\nreal time applications) to increase the penetration of photovoltaic systems in\npower grids. The direction of moving clouds is estimated in consecutive\nsequences of sky images by extracting features of cloud dynamics with the\nobjective of forecasting the global solar irradiance that reaches photovoltaic\nsystems. The sky images are acquired using a low-cost infrared sky imager\nmounted on a solar tracker. The solar forecasting algorithm is based on kernel\nlearning methods, and uses the clear sky index as predictor and features\nextracted from clouds as feature vectors. The proposed solar forecasting\nalgorithm achieved 16.45\\% forecasting skill 8 minutes ahead with a resolution\nof 15 seconds. In contrast, previous work reached 15.4\\% forecasting skill with\nthe resolution of 1 minute. Therefore, this solar forecasting algorithm\nincreases the performances with respect to the state-of-the-art, providing grid\noperators with the capability of managing the inherent uncertainties of power\ngrids with a high penetration of photovoltaic systems.",
    "descriptor": "",
    "authors": [
      "Guillermo Terr\u00e9n-Serrano",
      "Manel Mart\u00ednez-Ram\u00f3n"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.05622"
  },
  {
    "id": "arXiv:2110.05626",
    "title": "Parameterizing Activation Functions for Adversarial Robustness",
    "abstract": "Deep neural networks are known to be vulnerable to adversarially perturbed\ninputs. A commonly used defense is adversarial training, whose performance is\ninfluenced by model capacity. While previous works have studied the impact of\nvarying model width and depth on robustness, the impact of increasing capacity\nby using learnable parametric activation functions (PAFs) has not been studied.\nWe study how using learnable PAFs can improve robustness in conjunction with\nadversarial training. We first ask the question: how should we incorporate\nparameters into activation functions to improve robustness? To address this, we\nanalyze the direct impact of activation shape on robustness through PAFs and\nobserve that activation shapes with positive outputs on negative inputs and\nwith high finite curvature can increase robustness. We combine these properties\nto create a new PAF, which we call Parametric Shifted Sigmoidal Linear Unit\n(PSSiLU). We then combine PAFs (including PReLU, PSoftplus and PSSiLU) with\nadversarial training and analyze robust performance. We find that PAFs optimize\ntowards activation shape properties found to directly affect robustness.\nAdditionally, we find that while introducing only 1-2 learnable parameters into\nthe network, smooth PAFs can significantly increase robustness over ReLU. For\ninstance, when trained on CIFAR-10 with additional synthetic data, PSSiLU\nimproves robust accuracy by 4.54% over ReLU on ResNet-18 and 2.69% over ReLU on\nWRN-28-10 in the $\\ell_{\\infty}$ threat model while adding only 2 additional\nparameters into the network architecture. The PSSiLU WRN-28-10 model achieves\n61.96% AutoAttack accuracy, improving over the state-of-the-art robust accuracy\non RobustBench (Croce et al., 2020).",
    "descriptor": "",
    "authors": [
      "Sihui Dai",
      "Saeed Mahloujifar",
      "Prateek Mittal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05626"
  },
  {
    "id": "arXiv:2110.05627",
    "title": "Subnetwork Constraints for Tighter Upper Bounds and Exact Solution of  the Clique Partitioning Problem",
    "abstract": "We consider a variant of the clustering problem for a complete weighted\ngraph. The aim is to partition the nodes into clusters maximizing the sum of\nthe edge weights within the clusters. This problem is known as the clique\npartitioning problem, being NP-hard in the general case of having edge weights\nof different signs. We propose a new method of estimating an upper bound of the\nobjective function that we combine with the classical branch-and-bound\ntechnique to find the exact solution. We evaluate our approach on a broad range\nof random graphs and real-world networks. The proposed approach provided\ntighter upper bounds and achieved significant convergence speed improvements\ncompared to known alternative methods.",
    "descriptor": "\nComments: 20 pages, 3 figures\n",
    "authors": [
      "Alexander Belyi",
      "Stanislav Sobolevsky",
      "Alexander Kurbatski",
      "Carlo Ratti"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2110.05627"
  },
  {
    "id": "arXiv:2110.05630",
    "title": "Notes on kAExp(pol) problems for deterministic machines",
    "abstract": "The complexity of several logics, such as Presburger arithmetic, dependence\nlogics and ambient logics, can only be characterised in terms of alternating\nTuring machines. Despite quite natural, the presence of alternation can\nsometimes cause neat ideas to be obfuscated inside heavy technical machinery.\nIn these notes, we propose two problems on deterministic machines that can be\nused to prove lower bounds with respect to the computational class\n$k$AExp$_{\\text{pol}}$, that is the class of all problems solvable by an\nalternating Turing machine running in $k$ exponential time and performing a\npolynomial amount of alternations, with respect to the input size. The first\nproblem, called $k$AExp$_{\\text{pol}}$-prenex TM problem, is a problem about\ndeterministic Turing machines. The second problem, called the $k$-exp\nalternating multi-tiling problem, is analogous to the first one, but on tiling\nsystems.\nBoth problems are natural extensions of the TM alternation problem and the\nalternating multi-tiling problem proved AExp$_{\\text{pol}}$-complete by L.\nBozzelli, A. Molinari, A. Montanari and A. Peron in [GandALF, pp. 31-45, 2017].\nThe proofs presented in these notes follow the elegant exposition in A.\nMolinari's PhD thesis to extend these results from the case $k = 1$ to the case\nof arbitrary $k$.",
    "descriptor": "",
    "authors": [
      "Alessio Mansutti"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2110.05630"
  },
  {
    "id": "arXiv:2110.05631",
    "title": "Reeb Graph Metrics from the Ground Up",
    "abstract": "The Reeb graph has been utilized in various applications including the\nanalysis of scalar fields. Recently, research has been focused on using\ntopological signatures such as the Reeb graph to compare multiple scalar fields\nby defining distance metrics on the topological signatures themselves. Here we\nsurvey five existing metrics that have been defined on Reeb graphs: the\nbottleneck distance, the interleaving distance, functional distortion distance,\nthe Reeb graph edit distance, and the universal edit distance. Our goal is to\n(1) provide definitions and concrete examples of these distances in order to\ndevelop the intuition of the reader, (2) visit previously proven results of\nstability, universality, and discriminativity, (3) identify and complete any\nremaining properties which have only been proven (or disproven) for a subset of\nthese metrics, (4) expand the taxonomy of the bottleneck distance to better\ndistinguish between variations which have been commonly miscited, and (5)\nreconcile the various definitions and requirements on the underlying spaces for\nthese metrics to be defined and properties to be proven.",
    "descriptor": "\nComments: 71 pages, 35 figures\n",
    "authors": [
      "Brian Bollen",
      "Erin Chambers",
      "Joshua A. Levine",
      "Elizabeth Munch"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2110.05631"
  },
  {
    "id": "arXiv:2110.05633",
    "title": "TCube: Domain-Agnostic Neural Time-series Narration",
    "abstract": "The task of generating rich and fluent narratives that aptly describe the\ncharacteristics, trends, and anomalies of time-series data is invaluable to the\nsciences (geology, meteorology, epidemiology) or finance (trades, stocks, or\nsales and inventory). The efforts for time-series narration hitherto are\ndomain-specific and use predefined templates that offer consistency but lead to\nmechanical narratives. We present TCube (Time-series-to-text), a\ndomain-agnostic neural framework for time-series narration, that couples the\nrepresentation of essential time-series elements in the form of a dense\nknowledge graph and the translation of said knowledge graph into rich and\nfluent narratives through the transfer-learning capabilities of PLMs\n(Pre-trained Language Models). TCube's design primarily addresses the challenge\nthat lies in building a neural framework in the complete paucity of annotated\ntraining data for time-series. The design incorporates knowledge graphs as an\nintermediary for the representation of essential time-series elements which can\nbe linearized for textual translation. To the best of our knowledge, TCube is\nthe first investigation of the use of neural strategies for time-series\nnarration. Through extensive evaluations, we show that TCube can improve the\nlexical diversity of the generated narratives by up to 65.38% while still\nmaintaining grammatical integrity. The practicality and deployability of TCube\nis further validated through an expert review (n=21) where 76.2% of\nparticipating experts wary of auto-generated narratives favored TCube as a\ndeployable system for time-series narration due to its richer narratives. Our\ncode-base, models, and datasets, with detailed instructions for reproducibility\nis publicly hosted at https://github.com/Mandar-Sharma/TCube.",
    "descriptor": "\nComments: To be published in IEEE ICDM 2021\n",
    "authors": [
      "Mandar Sharma",
      "John S. Brownstein",
      "Naren Ramakrishnan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05633"
  },
  {
    "id": "arXiv:2110.05635",
    "title": "Real-time EEG-based Emotion Recognition using Discrete Wavelet  Transforms on Full and Reduced Channel Signals",
    "abstract": "Real-time EEG-based Emotion Recognition (EEG-ER) with consumer-grade EEG\ndevices involves classification of emotions using a reduced number of channels.\nThese devices typically provide only four or five channels, unlike the high\nnumber of channels (32 or more) typically used in most current state-of-the-art\nresearch. In this work we propose to use Discrete Wavelet Transforms (DWT) to\nextract time-frequency domain features, and we use time-windows of a few\nseconds to perform EEG-ER classification. This technique can be used in\nreal-time, as opposed to post-hoc on the full session data. We also apply\nbaseline removal preprocessing, developed in prior research, to our proposed\nDWT Entropy and Energy features, which improves classification accuracy\nsignificantly. We consider two different classifier architectures, a 3D\nConvolutional Neural Network (3D CNN) and a Support Vector Machine (SVM). We\nevaluate both models on subject-independent and subject dependent setups to\nclassify the Valence and Arousal dimensions of an individual's emotional state.\nWe test them on both the full 32-channel data provided by the DEAP dataset, and\nalso a reduced 5-channel extract of the same dataset. The SVM model performs\nbest on all the presented scenarios, achieving an accuracy of 95.32% on Valence\nand 95.68% on Arousal for the full 32-channel subject-dependent case, beating\nprior real-time EEG-ER subject-dependent benchmarks. On the subject-independent\ncase an accuracy of 80.70% on Valence and 81.41% on Arousal was also obtained.\nReducing the input data to 5 channels only degrades the accuracy by an average\nof 3.54% across all scenarios, making this model appropriate for use with more\naccessible low-end EEG devices.",
    "descriptor": "\nComments: Submitted to the Journal of Biomedical Signal Processing and Control\n",
    "authors": [
      "Josef Bajada",
      "Francesco Borg Bonello"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05635"
  },
  {
    "id": "arXiv:2110.05638",
    "title": "Searching for Replacement Classes",
    "abstract": "Software developers must often replace existing components in their systems\nto adapt to evolving environments or tooling. While traditional code search\nsystems are effective at retrieving components with related functionality, it\nis much more challenging to retrieve components that can be used to directly\nreplace existing functionality, as replacements must account for more\nfundamental program properties such as type compatibility. To address this\nproblem, we introduce ClassFinder, a system which given a query class Q, and a\nsearch corpus S, returns a ranked subset of classes that can replace Q and its\nfunctionality. ClassFinder produces afield and method mapping between the\nclasses that can provide useful hints to a developer and can be used to\neffectively refine the ranking of candidate replacement classes. Our technique\nleverages the complementary strengths of a distributed embeddings-based search\nand type-based analysis, using the former to prune down candidates for an\noptimization-based approach based on the latter. ClassFinder retrieves\nreplacement classes, along with a type-aware field/method mapping between\nclasses. We evaluate ClassFinder on a search space of ~600thousand open\nsourceJava classes. Querying ClassFinder with 24 known Java classes provided\nmeaningful replacement classes and mappings, in many cases producing complete\nmappings with functionally identical replacement classes.",
    "descriptor": "\nComments: 11 pages, 3 figures\n",
    "authors": [
      "Malavika Samak",
      "Jose Pablo Cambronero",
      "Martin C. Rinard"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2110.05638"
  },
  {
    "id": "arXiv:2110.05644",
    "title": "On the computational equivalence of co-NP refutations of a matrix being  a P-matrix",
    "abstract": "A P-matrix is a square matrix $X$ such that all principal submatrices of $X$\nhave positive determinant.\nSuch matrices appear naturally in instances of the linear complementarity\nproblem, where these are precisely the matrices for which the corresponding\nlinear complementarity problem has a unique solution for any input vector.\nTesting whether or not a square matrix is a P-matrix is co-NP complete, so\nwhile it is possible to exhibit polynomially-sized witnesses for the fact that\na matrix is not a P-matrix, it is believed that there is no efficient way to\nprove that a given matrix is a P-matrix.\nWe will show that several well known witnesses for the fact that a matrix is\nnot a P-matrix are computationally equivalent, so that we are able to convert\nbetween them in polynomial time, answering a question raised in\narXiv:1811.03841 .",
    "descriptor": "",
    "authors": [
      "Spencer Gordon",
      "Kevin Shu"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.05644"
  },
  {
    "id": "arXiv:2110.05645",
    "title": "A global convergence theory for deep ReLU implicit networks via  over-parameterization",
    "abstract": "Implicit deep learning has received increasing attention recently due to the\nfact that it generalizes the recursive prediction rules of many commonly used\nneural network architectures. Its prediction rule is provided implicitly based\non the solution of an equilibrium equation. Although a line of recent empirical\nstudies has demonstrated its superior performances, the theoretical\nunderstanding of implicit neural networks is limited. In general, the\nequilibrium equation may not be well-posed during the training. As a result,\nthere is no guarantee that a vanilla (stochastic) gradient descent (SGD)\ntraining nonlinear implicit neural networks can converge. This paper fills the\ngap by analyzing the gradient flow of Rectified Linear Unit (ReLU) activated\nimplicit neural networks. For an $m$-width implicit neural network with ReLU\nactivation and $n$ training samples, we show that a randomly initialized\ngradient descent converges to a global minimum at a linear rate for the square\nloss function if the implicit neural network is \\textit{over-parameterized}. It\nis worth noting that, unlike existing works on the convergence of (S)GD on\nfinite-layer over-parameterized neural networks, our convergence results hold\nfor implicit neural networks, where the number of layers is \\textit{infinite}.",
    "descriptor": "",
    "authors": [
      "Tianxiang Gao",
      "Hailiang Liu",
      "Jia Liu",
      "Hridesh Rajan",
      "Hongyang Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.05645"
  },
  {
    "id": "arXiv:2110.05649",
    "title": "Learned Robust PCA: A Scalable Deep Unfolding Approach for  High-Dimensional Outlier Detection",
    "abstract": "Robust principal component analysis (RPCA) is a critical tool in modern\nmachine learning, which detects outliers in the task of low-rank matrix\nreconstruction. In this paper, we propose a scalable and learnable non-convex\napproach for high-dimensional RPCA problems, which we call Learned Robust PCA\n(LRPCA). LRPCA is highly efficient, and its free parameters can be effectively\nlearned to optimize via deep unfolding. Moreover, we extend deep unfolding from\nfinite iterations to infinite iterations via a novel\nfeedforward-recurrent-mixed neural network model. We establish the recovery\nguarantee of LRPCA under mild assumptions for RPCA. Numerical experiments show\nthat LRPCA outperforms the state-of-the-art RPCA algorithms, such as ScaledGD\nand AltProj, on both synthetic datasets and real-world applications.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "HanQin Cai",
      "Jialin Liu",
      "Wotao Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05649"
  },
  {
    "id": "arXiv:2110.05650",
    "title": "GM-Livox: An Integrated Framework for Large-Scale Map Construction with  Multiple Non-repetitive Scanning LiDARs",
    "abstract": "With the ability of providing direct and accurate enough range measurements,\nlight detection and ranging (LiDAR) is playing an essential role in\nlocalization and detection for autonomous vehicles. Since single LiDAR suffers\nfrom hardware failure and performance degradation intermittently, we present a\nmulti-LiDAR integration scheme in this article. Our framework tightly couples\nmultiple non-repetitive scanning LiDARs with inertial, encoder, and global\nnavigation satellite system (GNSS) into pose estimation and simultaneous global\nmap generation. Primarily, we formulate a precise synchronization strategy to\nintegrate isolated sensors, and the extracted feature points from separate\nLiDARs are merged into a single sweep. The fused scans are introduced to\ncompute the scan-matching correspondences, which can be further refined by\nadditional real-time kinematic (RTK) measurements. Based thereupon, we\nconstruct a factor graph along with the inertial preintegration result,\nestimated ground constraints, and RTK data. For the purpose of maintaining a\nrestricted number of poses for estimation, we deploy a keyframe based\nsliding-window optimization strategy in our system. The real-time performance\nis guaranteed with multi-threaded computation, and extensive experiments are\nconducted in challenging scenarios. Experimental results show that the\nutilization of multiple LiDARs boosts the system performance in both robustness\nand accuracy.",
    "descriptor": "",
    "authors": [
      "Yusheng Wang",
      "Yidong Lou",
      "Weiwei Song",
      "Huan Yu",
      "Zhiyong Tu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.05650"
  },
  {
    "id": "arXiv:2110.05651",
    "title": "Learning with Algorithmic Supervision via Continuous Relaxations",
    "abstract": "The integration of algorithmic components into neural architectures has\ngained increased attention recently, as it allows training neural networks with\nnew forms of supervision such as ordering constraints or silhouettes instead of\nusing ground truth labels. Many approaches in the field focus on the continuous\nrelaxation of a specific task and show promising results in this context. But\nthe focus on single tasks also limits the applicability of the proposed\nconcepts to a narrow range of applications. In this work, we build on those\nideas to propose an approach that allows to integrate algorithms into\nend-to-end trainable neural network architectures based on a general\napproximation of discrete conditions. To this end, we relax these conditions in\ncontrol structures such as conditional statements, loops, and indexing, so that\nresulting algorithms are smoothly differentiable. To obtain meaningful\ngradients, each relevant variable is perturbed via logistic distributions and\nthe expectation value under this perturbation is approximated. We evaluate the\nproposed continuous relaxation model on four challenging tasks and show that it\ncan keep up with relaxations specifically designed for each individual task.",
    "descriptor": "\nComments: Published at NeurIPS 2021\n",
    "authors": [
      "Felix Petersen",
      "Christian Borgelt",
      "Hilde Kuehne",
      "Oliver Deussen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.05651"
  },
  {
    "id": "arXiv:2110.05655",
    "title": "Defocus Map Estimation and Deblurring from a Single Dual-Pixel Image",
    "abstract": "We present a method that takes as input a single dual-pixel image, and\nsimultaneously estimates the image's defocus map -- the amount of defocus blur\nat each pixel -- and recovers an all-in-focus image. Our method is inspired\nfrom recent works that leverage the dual-pixel sensors available in many\nconsumer cameras to assist with autofocus, and use them for recovery of defocus\nmaps or all-in-focus images. These prior works have solved the two recovery\nproblems independently of each other, and often require large labeled datasets\nfor supervised training. By contrast, we show that it is beneficial to treat\nthese two closely-connected problems simultaneously. To this end, we set up an\noptimization problem that, by carefully modeling the optics of dual-pixel\nimages, jointly solves both problems. We use data captured with a consumer\nsmartphone camera to demonstrate that, after a one-time calibration step, our\napproach improves upon prior works for both defocus map estimation and blur\nremoval, despite being entirely unsupervised.",
    "descriptor": "\nComments: ICCV 2021 (Oral)\n",
    "authors": [
      "Shumian Xin",
      "Neal Wadhwa",
      "Tianfan Xue",
      "Jonathan T. Barron",
      "Pratul P. Srinivasan",
      "Jiawen Chen",
      "Ioannis Gkioulekas",
      "Rahul Garg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05655"
  },
  {
    "id": "arXiv:2110.05661",
    "title": "BotNet Detection On Social Media",
    "abstract": "Given the popularity of social media and the notion of it being a platform\nencouraging free speech, it has become an open playground for user (bot)\naccounts trying to manipulate other users using these platforms. Social bots\nnot only learn human conversations, manners, and presence but also manipulate\npublic opinion, act as scammers, manipulate stock markets, etc. There has been\nevidence of bots manipulating the election results which can be a great threat\nto the whole nation and hence the whole world. So identification and prevention\nof such campaigns that release or create the bots have become critical to\ntackling it at its source of origin. Our goal is to leverage semantic web\nmining techniques to identify fake bots or accounts involved in these\nactivities.",
    "descriptor": "",
    "authors": [
      "Aniket Chandrakant Devle",
      "Julia Ann Jose",
      "Abhay Shrinivas Saraswathula",
      "Shubham Mehta",
      "Siddhant Srivastava",
      "Sirisha Kona",
      "Sudheera Daggumalli"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05661"
  },
  {
    "id": "arXiv:2110.05663",
    "title": "Learned Construction Grammars Converge Across Registers Given Increased  Exposure",
    "abstract": "This paper measures the impact of increased exposure on whether learned\nconstruction grammars converge onto shared representations when trained on data\nfrom different registers. Register influences the frequency of constructions,\nwith some structures common in formal but not informal usage. We expect that a\ngrammar induction algorithm exposed to different registers will acquire\ndifferent constructions. To what degree does increased exposure lead to the\nconvergence of register-specific grammars? The experiments in this paper\nsimulate language learning in 12 languages (half Germanic and half Romance)\nwith corpora representing three registers (Twitter, Wikipedia, Web). These\nsimulations are repeated with increasing amounts of exposure, from 100k to 2\nmillion words, to measure the impact of exposure on the convergence of\ngrammars. The results show that increased exposure does lead to converging\ngrammars across all languages. In addition, a shared core of register-universal\nconstructions remains constant across increasing amounts of exposure.",
    "descriptor": "",
    "authors": [
      "Jonathan Dunn",
      "Harish Tayyar Madabushi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05663"
  },
  {
    "id": "arXiv:2110.05665",
    "title": "Are you doing what I say? On modalities alignment in ALFRED",
    "abstract": "ALFRED is a recently proposed benchmark that requires a model to complete\ntasks in simulated house environments specified by instructions in natural\nlanguage. We hypothesize that key to success is accurately aligning the text\nmodality with visual inputs. Motivated by this, we inspect how well existing\nmodels can align these modalities using our proposed intrinsic metric, boundary\nadherence score (BAS). The results show the previous models are indeed failing\nto perform proper alignment. To address this issue, we introduce approaches\naimed at improving model alignment and demonstrate how improved alignment,\nimproves end task performance.",
    "descriptor": "\nComments: Accepted by Novel Ideas in Learning-to-Learn through Interaction at EMNLP 2021\n",
    "authors": [
      "Ting-Rui Chiang",
      "Yi-Ting Yeh",
      "Ta-Chung Chi",
      "Yau-Shian Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05665"
  },
  {
    "id": "arXiv:2110.05667",
    "title": "Why Lottery Ticket Wins? A Theoretical Perspective of Sample Complexity  on Pruned Neural Networks",
    "abstract": "The \\textit{lottery ticket hypothesis} (LTH) states that learning on a\nproperly pruned network (the \\textit{winning ticket}) improves test accuracy\nover the original unpruned network. Although LTH has been justified empirically\nin a broad range of deep neural network (DNN) involved applications like\ncomputer vision and natural language processing, the theoretical validation of\nthe improved generalization of a winning ticket remains elusive. To the best of\nour knowledge, our work, for the first time, characterizes the performance of\ntraining a pruned neural network by analyzing the geometric structure of the\nobjective function and the sample complexity to achieve zero generalization\nerror. We show that the convex region near a desirable model with guaranteed\ngeneralization enlarges as the neural network model is pruned, indicating the\nstructural importance of a winning ticket. Moreover, when the algorithm for\ntraining a pruned neural network is specified as an (accelerated) stochastic\ngradient descent algorithm, we theoretically show that the number of samples\nrequired for achieving zero generalization error is proportional to the number\nof the non-pruned weights in the hidden layer. With a fixed number of samples,\ntraining a pruned neural network enjoys a faster convergence rate to the\ndesired model than training the original unpruned one, providing a formal\njustification of the improved generalization of the winning ticket. Our\ntheoretical results are acquired from learning a pruned neural network of one\nhidden layer, while experimental results are further provided to justify the\nimplications in pruning multi-layer neural networks.",
    "descriptor": "",
    "authors": [
      "Shuai Zhang",
      "Meng Wang",
      "Sijia Liu",
      "Pin-Yu Chen",
      "Jinjun Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.05667"
  },
  {
    "id": "arXiv:2110.05668",
    "title": "NAS-Bench-360: Benchmarking Diverse Tasks for Neural Architecture Search",
    "abstract": "Most existing neural architecture search (NAS) benchmarks and algorithms\nprioritize performance on well-studied tasks, e.g., image classification on\nCIFAR and ImageNet. This makes the applicability of NAS approaches in more\ndiverse areas inadequately understood. In this paper, we present NAS-Bench-360,\na benchmark suite for evaluating state-of-the-art NAS methods for convolutional\nneural networks (CNNs). To construct it, we curate a collection of ten tasks\nspanning a diverse array of application domains, dataset sizes, problem\ndimensionalities, and learning objectives. By carefully selecting tasks that\ncan both interoperate with modern CNN-based search methods but that are also\nfar-afield from their original development domain, we can use NAS-Bench-360 to\ninvestigate the following central question: do existing state-of-the-art NAS\nmethods perform well on diverse tasks? Our experiments show that a modern NAS\nprocedure designed for image classification can indeed find good architectures\nfor tasks with other dimensionalities and learning objectives; however, the\nsame method struggles against more task-specific methods and performs\ncatastrophically poorly on classification in non-vision domains. The case for\nNAS robustness becomes even more dire in a resource-constrained setting, where\na recent NAS method provides little-to-no benefit over much simpler baselines.\nThese results demonstrate the need for a benchmark such as NAS-Bench-360 to\nhelp develop NAS approaches that work well on a variety of tasks, a crucial\ncomponent of a truly robust and automated pipeline. We conclude with a\ndemonstration of the kind of future research our suite of tasks will enable.\nAll data and code is made publicly available.",
    "descriptor": "",
    "authors": [
      "Renbo Tu",
      "Mikhail Khodak",
      "Nicholas Roberts",
      "Ameet Talwalkar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05668"
  },
  {
    "id": "arXiv:2110.05669",
    "title": "Adaptive Feedforward Reference Design for Active Vibration Rejection in  Multi-Actuator Hard Disk Drives",
    "abstract": "In December 2017, Seagate unveiled the Multi Actuator Technology to double\nthe data performance of the future generation hard disk drives (HDD). This\ntechnology will equip drives with two dual stage actuators (DSA) each\ncomprising of a voice coil motor (VCM) actuator and a piezoelectric micro\nactuator (MA) operating on the same pivot point. Each DSA is responsible for\ncontrolling half of the drive's arms. As both the DSAs operate independently on\nthe same pivot timber, the control forces and torques generated by one can\naffect the operation of the other and thereby worsening the performance\ndrastically. In this paper, a robust adaptive feedforward controller is\ndesigned as an add-on controller to an existing stabilizing feedback controller\nto reject the disturbances transferred through the common pivot timber by\nshaping the references to the VCM actuator and the total output of the dual\nstage system.",
    "descriptor": "",
    "authors": [
      "Zhi Chen",
      "Nikhil Potu Surya Prakash",
      "Roberto Horowitz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.05669"
  },
  {
    "id": "arXiv:2110.05671",
    "title": "Predicting the Stereoselectivity of Chemical Transformations by Machine  Learning",
    "abstract": "Stereoselective reactions (both chemical and enzymatic reactions) have been\nessential for origin of life, evolution, human biology and medicine. Since late\n1960s, there have been numerous successes in the exciting new frontier of\nasymmetric catalysis. However, most industrial and academic asymmetric\ncatalysis nowadays do follow the trial-and-error model, since the energetic\ndifference for success or failure in asymmetric catalysis is incredibly small.\nOur current understanding about stereoselective reactions is mostly qualitative\nthat stereoselectivity arises from differences in steric effects and electronic\neffects in multiple competing mechanistic pathways. Quantitatively\nunderstanding and modulating the stereoselectivity of for a given chemical\nreaction still remains extremely difficult. As a proof of principle, we herein\npresent a novel machine learning technique, which combines a LASSO model and\ntwo Random Forest model via two Gaussian Mixture models, for quantitatively\npredicting stereoselectivity of chemical reactions. Compared to the recent\nground-breaking approach [1], our approach is able to capture interactions\nbetween features and exploit complex data distributions, which are important\nfor predicting stereoselectivity. Experimental results on a recently published\ndataset demonstrate that our approach significantly outperform [1]. The insight\nobtained from our results provide a solid foundation for further exploration of\nother synthetically valuable yet mechanistically intriguing stereoselective\nreactions.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Justin Li",
      "Dakang Zhang",
      "Yifei Wang",
      "Christopher Ye",
      "Hao Xu",
      "Pengyu Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.05671"
  },
  {
    "id": "arXiv:2110.05672",
    "title": "Data-Driven Strictly Positive Real System Identification with prior  System Knowledge",
    "abstract": "Strictly Positive Real (SPR) transfer functions arise in many areas of\nengineering like passivity theory in circuit analysis and adaptive control to\nname a few. In many physical systems, it is possible to conclude that the\nsystem is Positive Real (PR) or SPR but system identification algorithms might\nproduce estimates which are not SPR. In this paper, an algorithm to approximate\nfrequency response data with SPR transfer functions using Generalized\nOrthonormal Basis Functions (GOBFs) is presented. Prior knowledge of the system\nhelps us to get approximate pole locations, which can then be used to construct\nGOBFs. Next, a convex optimization problem will be formulated to obtain an\nestimate of the SPR transfer function.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2109.12460\n",
    "authors": [
      "Nikhil Potu Surya Prakash",
      "Zhi Chen",
      "Roberto Horowitz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.05672"
  },
  {
    "id": "arXiv:2110.05675",
    "title": "Strong convergence rates of a fully discrete scheme for nonlinear  stochastic partial differential equations with non-globally Lipschitz  coefficients driven by multiplicative noise",
    "abstract": "We consider a fully discrete scheme for nonlinear stochastic partial\ndifferential equations with non-globally Lipschitz coefficients driven by\nmultiplicative noise in a multi-dimensional setting. Our method uses a\npolynomial based spectral method in space, so it does not require the elliptic\noperator $A$ and the covariance operator $Q$ of noise in the equation commute,\nand thus successfully alleviates a restriction of Fourier spectral method for\nSPDEs pointed out by Jentzen, Kloeden and Winkel.\nThe discretization in time is a tamed semi-implicit scheme which treats the\nnonlinear term explicitly while being unconditionally stable. Under regular\nassumptions which are usually made for SPDEs with additive noise, we establish\noptimal strong convergence rates in both space and time for our fully discrete\nscheme. We also present numerical experiments which are consistent with our\ntheoretical results.",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Can Huang",
      "Jie Shen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05675"
  },
  {
    "id": "arXiv:2110.05676",
    "title": "Improved Heatmap-based Landmark Detection",
    "abstract": "Mitral valve repair is a very difficult operation, often requiring\nexperienced surgeons. The doctor will insert a prosthetic ring to aid in the\nrestoration of heart function. The location of the prosthesis' sutures is\ncritical. Obtaining and studying them during the procedure is a valuable\nlearning experience for new surgeons. This paper proposes a landmark detection\nnetwork for detecting sutures in endoscopic pictures, which solves the problem\nof a variable number of suture points in the images. Because there are two\ndatasets, one from the simulated domain and the other from real intraoperative\ndata, this work uses cycleGAN to interconvert the images from the two domains\nto obtain a larger dataset and a better score on real intraoperative data. This\npaper performed the tests using a simulated dataset of 2708 photos and a real\ndataset of 2376 images. The mean sensitivity on the simulated dataset is about\n75.64% and the precision is about 73.62%. The mean sensitivity on the real\ndataset is about 50.23% and the precision is about 62.76%. The data is from the\nAdaptOR MICCAI Challenge 2021, which can be found at\nhttps://zenodo.org/record/4646979\\#.YO1zLUxCQ2x.",
    "descriptor": "\nComments: Accepted by MICCAI2021 workshop\n",
    "authors": [
      "Huifeng Yao",
      "Ziyu Guo",
      "Yatao Zhang",
      "Xiaomeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05676"
  },
  {
    "id": "arXiv:2110.05678",
    "title": "Development of A Load Control Algorithm to Enhance Energy Sustainability  for the International Space Station",
    "abstract": "This paper presents a load control algorithm for control of energy sources\nand loads to enhance energy sustainability and reliability of the International\nSpace Station (ISS), which is a large spacecraft in orbit around Earth. In this\npaper, the ISS electric power system was simulated in MATLAB/Simulink to be\nable to evaluate the performance of the developed algorithm in a simulated\nenvironment. This study also aims to emphasize the importance of load control\nalgorithms on energy sustainability for critical systems, like ISS, having\nlimited energy sources.",
    "descriptor": "\nComments: 5 pages, 7 figures, 1 table, 2021 International Conference & Exposition on Modern Energy and Power Systems (ICMEPS2021)\n",
    "authors": [
      "E. Herwald",
      "G. Holliday",
      "M. Kuzlu",
      "U. Cali",
      "O. Elma"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.05678"
  },
  {
    "id": "arXiv:2110.05679",
    "title": "Large Language Models Can Be Strong Differentially Private Learners",
    "abstract": "Differentially Private (DP) learning has seen limited success for building\nlarge deep learning models of text, and attempts at straightforwardly applying\nDifferentially Private Stochastic Gradient Descent (DP-SGD) to NLP tasks have\nresulted in large performance drops and high computational overhead. We show\nthat this performance drop can be mitigated with (1) the use of large\npretrained models; (2) hyperparameters that suit DP optimization; and (3)\nfine-tuning objectives aligned with the pretraining procedure. With these\nfactors set right, we obtain private NLP models that outperform\nstate-of-the-art private training approaches and strong non-private baselines\n-- by directly fine-tuning pretrained models with DP optimization on\nmoderately-sized corpora. To address the computational challenge of running\nDP-SGD with large Transformers, we propose a memory saving technique that\nallows clipping in DP-SGD to run without instantiating per-example gradients\nfor any layer in the model. The technique enables privately training\nTransformers with almost the same memory cost as non-private training at a\nmodest run-time overhead. Contrary to conventional wisdom that DP optimization\nfails at learning high-dimensional models (due to noise that scales with\ndimension) empirical results reveal that private learning with pretrained\nmodels tends to not suffer from dimension-dependent performance degradation.",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Xuechen Li",
      "Florian Tram\u00e8r",
      "Percy Liang",
      "Tatsunori Hashimoto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05679"
  },
  {
    "id": "arXiv:2110.05682",
    "title": "Provably Efficient Reinforcement Learning in Decentralized General-Sum  Markov Games",
    "abstract": "This paper addresses the problem of learning an equilibrium efficiently in\ngeneral-sum Markov games through decentralized multi-agent reinforcement\nlearning. Given the fundamental difficulty of calculating a Nash equilibrium\n(NE), we instead aim at finding a coarse correlated equilibrium (CCE), a\nsolution concept that generalizes NE by allowing possible correlations among\nthe agents' strategies. We propose an algorithm in which each agent\nindependently runs optimistic V-learning (a variant of Q-learning) to\nefficiently explore the unknown environment, while using a stabilized online\nmirror descent (OMD) subroutine for policy updates. We show that the agents can\nfind an $\\epsilon$-approximate CCE in at most $\\widetilde{O}( H^6S A\n/\\epsilon^2)$ episodes, where $S$ is the number of states, $A$ is the size of\nthe largest individual action space, and $H$ is the length of an episode. This\nappears to be the first sample complexity result for learning in generic\ngeneral-sum Markov games. Our results rely on a novel investigation of an\nanytime high-probability regret bound for OMD with a dynamic learning rate and\nweighted regret, which would be of independent interest. One key feature of our\nalgorithm is that it is fully \\emph{decentralized}, in the sense that each\nagent has access to only its local information, and is completely oblivious to\nthe presence of others. This way, our algorithm can readily scale up to an\narbitrary number of agents, without suffering from the exponential dependence\non the number of agents.",
    "descriptor": "",
    "authors": [
      "Weichao Mao",
      "Tamer Ba\u015far"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.05682"
  },
  {
    "id": "arXiv:2110.05686",
    "title": "Uplink NOMA For STAR-RIS Networks",
    "abstract": "A simultaneously transmitting and reflecting reconfigurable intelligent\nsurfaces (STAR-RISs) enhanced uplink non-orthogonal multiple access (NOMA)\ncommunication system is proposed. A total power consumption minimization\nproblem is formulated by jointly optimizing the transmit-power of users,\nreceive-beamforming vectors at the base station (BS), STAR-beamforming vectors\nat the STAR-RIS and time slots. Here, the STAR-beamforming introduced by\nSTAR-RIS consists of transmission- and reflection-beamforming. To solve the\nformulated non-convex problem, an efficient penalty-based alternating\noptimization (P-AltOp) algorithm is proposed. Simulation results validate the\neffectiveness of the proposed scheme and reveal the effect of various system\nparameters on the total power consumption.",
    "descriptor": "",
    "authors": [
      "Jiakuo Zuo",
      "Yuanwei Liu",
      "Zhiguo Ding",
      "Xianbin Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.05686"
  },
  {
    "id": "arXiv:2110.05687",
    "title": "No way to crop: On robust image crop localization",
    "abstract": "Previous image forensics schemes for crop detection are only limited on\npredicting whether an image has been cropped. This paper presents a novel\nscheme for image crop localization using robust watermarking. We further extend\nour scheme to detect tampering attack on the attacked image. We demonstrate\nthat our scheme is the first to provide high-accuracy and robust image crop\nlocalization. Besides, the accuracy of tamper detection is comparable to many\nstate-of-the-art methods.",
    "descriptor": "\nComments: Submitted to IEEE ICASSP 2021. Authors are from Fudan University, Simon Fraser University\n",
    "authors": [
      "Qichao Ying",
      "Xiaoxiao Hu",
      "Hang Zhou",
      "Xiangyu Zhang",
      "Zhengxin You",
      "Zhenxing Qian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05687"
  },
  {
    "id": "arXiv:2110.05688",
    "title": "Inclusive Design: Accessibility Settings for People with Cognitive  Disabilities",
    "abstract": "The advancement of technology has progressed faster than any other field in\nthe world and with the development of these new technologies, it is important\nto make sure that these tools can be used by everyone, including people with\ndisabilities. Accessibility options in computing devices help ensure that\neveryone has the same access to advanced technologies. Unfortunately, for those\nwho require more unique and sometimes challenging accommodations, such as\npeople with Amyotrophic lateral sclerosis ( ALS), the most commonly used\naccessibility features are simply not enough. While assistive technology for\nthose with ALS does exist, it requires multiple peripheral devices that can\nbecome quite expensive collectively. The purpose of this paper is to suggest a\nmore affordable and readily available option for ALS assistive technology that\ncan be implemented on a smartphone or tablet.",
    "descriptor": "",
    "authors": [
      "Trae Waggoner",
      "Julia Ann Jose",
      "Ashwin Nair",
      "Sudarsan Manikandan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05688"
  },
  {
    "id": "arXiv:2110.05689",
    "title": "Hiding Images into Images with Real-world Robustness",
    "abstract": "The existing image embedding networks are basically vulnerable to malicious\nattacks such as JPEG compression and noise adding, not applicable for\nreal-world copyright protection tasks. To solve this problem, we introduce a\ngenerative deep network based method for hiding images into images while\nassuring high-quality extraction from the destructive synthesized images. An\nembedding network is sequentially concatenated with an attack layer, a\ndecoupling network and an image extraction network. The addition of decoupling\nnetwork learns to extract the embedded watermark from the attacked image. We\nalso pinpoint the weaknesses of the adversarial training for robustness in\nprevious works and build our improved real-world attack simulator. Experimental\nresults demonstrate the superiority of the proposed method against typical\ndigital attacks by a large margin, as well as the performance boost of the\nrecovered images with the aid of progressive recovery strategy. Besides, we are\nthe first to robustly hide three secret images.",
    "descriptor": "\nComments: A modified version is submitted to IEEE ICASSP 2021. Authors are from Fudan University, Simon Fraser University and NVIDIA\n",
    "authors": [
      "Qichao Ying",
      "Hang Zhou",
      "Xianhan Zeng",
      "Haisheng Xu",
      "Zhenxing Qian",
      "Xinpeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05689"
  },
  {
    "id": "arXiv:2110.05690",
    "title": "Partial Counterfactual Identification from Observational and  Experimental Data",
    "abstract": "This paper investigates the problem of bounding counterfactual queries from\nan arbitrary collection of observational and experimental distributions and\nqualitative knowledge about the underlying data-generating model represented in\nthe form of a causal diagram. We show that all counterfactual distributions in\nan arbitrary structural causal model (SCM) could be generated by a canonical\nfamily of SCMs with the same causal diagram where unobserved (exogenous)\nvariables are discrete with a finite domain. Utilizing the canonical SCMs, we\ntranslate the problem of bounding counterfactuals into that of polynomial\nprogramming whose solution provides optimal bounds for the counterfactual\nquery. Solving such polynomial programs is in general computationally\nexpensive. We therefore develop effective Monte Carlo algorithms to approximate\nthe optimal bounds from an arbitrary combination of observational and\nexperimental data. Our algorithms are validated extensively on synthetic and\nreal-world datasets.",
    "descriptor": "",
    "authors": [
      "Junzhe Zhang",
      "Jin Tian",
      "Elias Bareinboim"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05690"
  },
  {
    "id": "arXiv:2110.05691",
    "title": "Doubly-Trained Adversarial Data Augmentation for Neural Machine  Translation",
    "abstract": "Neural Machine Translation (NMT) models are known to suffer from noisy\ninputs. To make models robust, we generate adversarial augmentation samples\nthat attack the model and preserve the source-side semantic meaning at the same\ntime. To generate such samples, we propose a doubly-trained architecture that\npairs two NMT models of opposite translation directions with a joint loss\nfunction, which combines the target-side attack and the source-side semantic\nsimilarity constraint. The results from our experiments across three different\nlanguage pairs and two evaluation metrics show that these adversarial samples\nimprove the model robustness.",
    "descriptor": "",
    "authors": [
      "Weiting Tan",
      "Shuoyang Ding",
      "Huda Khayrallah",
      "Philipp Koehn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05691"
  },
  {
    "id": "arXiv:2110.05697",
    "title": "Hierarchical Modeling for Task Recognition and Action Segmentation in  Weakly-Labeled Instructional Videos",
    "abstract": "This paper focuses on task recognition and action segmentation in\nweakly-labeled instructional videos, where only the ordered sequence of\nvideo-level actions is available during training. We propose a two-stream\nframework, which exploits semantic and temporal hierarchies to recognize\ntop-level tasks in instructional videos. Further, we present a novel top-down\nweakly-supervised action segmentation approach, where the predicted task is\nused to constrain the inference of fine-grained action sequences. Experimental\nresults on the popular Breakfast and Cooking 2 datasets show that our\ntwo-stream hierarchical task modeling significantly outperforms existing\nmethods in top-level task recognition for all datasets and metrics.\nAdditionally, using our task recognition framework in the proposed top-down\naction segmentation approach consistently improves the state of the art, while\nalso reducing segmentation inference time by 80-90 percent.",
    "descriptor": "\nComments: Accepted in WACV 2022\n",
    "authors": [
      "Reza Ghoddoosian",
      "Saif Sayed",
      "Vassilis Athitsos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05697"
  },
  {
    "id": "arXiv:2110.05699",
    "title": "On Releasing Annotator-Level Labels and Information in Datasets",
    "abstract": "A common practice in building NLP datasets, especially using crowd-sourced\nannotations, involves obtaining multiple annotator judgements on the same data\ninstances, which are then flattened to produce a single \"ground truth\" label or\nscore, through majority voting, averaging, or adjudication. While these\napproaches may be appropriate in certain annotation tasks, such aggregations\noverlook the socially constructed nature of human perceptions that annotations\nfor relatively more subjective tasks are meant to capture. In particular,\nsystematic disagreements between annotators owing to their socio-cultural\nbackgrounds and/or lived experiences are often obfuscated through such\naggregations. In this paper, we empirically demonstrate that label aggregation\nmay introduce representational biases of individual and group perspectives.\nBased on this finding, we propose a set of recommendations for increased\nutility and transparency of datasets for downstream use cases.",
    "descriptor": "",
    "authors": [
      "Vinodkumar Prabhakaran",
      "Aida Mostafazadeh Davani",
      "Mark D\u00edaz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.05699"
  },
  {
    "id": "arXiv:2110.05700",
    "title": "On Exploring and Improving Robustness of Scene Text Detection Models",
    "abstract": "It is crucial to understand the robustness of text detection models with\nregard to extensive corruptions, since scene text detection techniques have\nmany practical applications. For systematically exploring this problem, we\npropose two datasets from which to evaluate scene text detection models:\nICDAR2015-C (IC15-C) and CTW1500-C (CTW-C). Our study extends the investigation\nof the performance and robustness of the proposed region proposal, regression\nand segmentation-based scene text detection frameworks. Furthermore, we perform\na robustness analysis of six key components: pre-training data, backbone,\nfeature fusion module, multi-scale predictions, representation of text\ninstances and loss function. Finally, we present a simple yet effective\ndata-based method to destroy the smoothness of text regions by merging\nbackground and foreground, which can significantly increase the robustness of\ndifferent text detection networks. We hope that this study will provide valid\ndata points as well as experience for future research. Benchmark, code and data\nwill be made available at\n\\url{https://github.com/wushilian/robust-scene-text-detection-benchmark}.",
    "descriptor": "",
    "authors": [
      "Shilian Wu",
      "Wei Zhai",
      "Yongrui Li",
      "Kewei Wang",
      "Zengfu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05700"
  },
  {
    "id": "arXiv:2110.05702",
    "title": "Auditing Robot Learning for Safety and Compliance during Deployment",
    "abstract": "Robots of the future are going to exhibit increasingly human-like and\nsuper-human intelligence in a myriad of different tasks. They are also likely\ngoing to fail and be incompliant with human preferences in increasingly subtle\nways. Towards the goal of achieving autonomous robots, the robot learning\ncommunity has made rapid strides in applying machine learning techniques to\ntrain robots through data and interaction. This makes the study of how best to\naudit these algorithms for checking their compatibility with humans, pertinent\nand urgent. In this paper, we draw inspiration from the AI Safety and Alignment\ncommunities and make the case that we need to urgently consider ways in which\nwe can best audit our robot learning algorithms to check for failure modes, and\nensure that when operating autonomously, they are indeed behaving in ways that\nthe human algorithm designers intend them to. We believe that this is a\nchallenging problem that will require efforts from the entire robot learning\ncommunity, and do not attempt to provide a concrete framework for auditing.\nInstead, we outline high-level guidance and a possible approach towards\nformulating this framework which we hope will serve as a useful starting point\nfor thinking about auditing in the context of robot learning.",
    "descriptor": "\nComments: Blue Sky paper at the 5th Conference on Robot Learning (CoRL 2021)\n",
    "authors": [
      "Homanga Bharadhwaj"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05702"
  },
  {
    "id": "arXiv:2110.05706",
    "title": "Deep Fusion Prior for Multi-Focus Image Super Resolution Fusion",
    "abstract": "This paper unifies the multi-focus images fusion (MFIF) and blind super\nresolution (SR) problems as the multi-focus image super resolution fusion\n(MFISRF) task, and proposes a novel unified dataset-free unsupervised framework\nnamed deep fusion prior (DFP) to address such MFISRF task. DFP consists of\nSKIPnet network, DoubleReblur focus measurement tactic, decision embedding\nmodule and loss functions. In particular, DFP can obtain MFISRF only from two\nlow-resolution inputs without any extent dataset; SKIPnet implementing\nunsupervised learning via deep image prior is an end-to-end generated network\nacting as the engine of DFP; DoubleReblur is used to determine the primary\ndecision map without learning but based on estimated PSF and Gaussian kernels\nconvolution; decision embedding module optimizes the decision map via learning;\nand DFP losses composed of content loss, joint gradient loss and gradient limit\nloss can obtain high-quality MFISRF results robustly. Experiments have proved\nthat our proposed DFP approaches and even outperforms those state-of-art MFIF\nand SR method combinations. Additionally, DFP is a general framework, thus its\nnetworks and focus measurement tactics can be continuously updated to further\nimprove the MFISRF performance. DFP codes are open source and will be available\nsoon at this http URL",
    "descriptor": "\nComments: 21 pages, 9 figures\n",
    "authors": [
      "Yuanjie Gu",
      "Zhibo Xiao",
      "Hailun Wang",
      "Cheng Liu",
      "Shouyu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.05706"
  },
  {
    "id": "arXiv:2110.05707",
    "title": "Decentralized Cooperative Multi-Agent Reinforcement Learning with  Exploration",
    "abstract": "Many real-world applications of multi-agent reinforcement learning (RL), such\nas multi-robot navigation and decentralized control of cyber-physical systems,\ninvolve the cooperation of agents as a team with aligned objectives. We study\nmulti-agent RL in the most basic cooperative setting -- Markov teams -- a class\nof Markov games where the cooperating agents share a common reward. We propose\nan algorithm in which each agent independently runs stage-based V-learning (a\nQ-learning style algorithm) to efficiently explore the unknown environment,\nwhile using a stochastic gradient descent (SGD) subroutine for policy updates.\nWe show that the agents can learn an $\\epsilon$-approximate Nash equilibrium\npolicy in at most $\\propto\\widetilde{O}(1/\\epsilon^4)$ episodes. Our results\nadvocate the use of a novel \\emph{stage-based} V-learning approach to create a\nstage-wise stationary environment. We also show that under certain smoothness\nassumptions of the team, our algorithm can achieve a nearly \\emph{team-optimal}\nNash equilibrium. Simulation results corroborate our theoretical findings. One\nkey feature of our algorithm is being \\emph{decentralized}, in the sense that\neach agent has access to only the state and its local actions, and is even\n\\emph{oblivious} to the presence of the other agents. Neither communication\namong teammates nor coordination by a central controller is required during\nlearning. Hence, our algorithm can readily generalize to an arbitrary number of\nagents, without suffering from the exponential dependence on the number of\nagents.",
    "descriptor": "",
    "authors": [
      "Weichao Mao",
      "Tamer Ba\u015far",
      "Lin F. Yang",
      "Kaiqing Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.05707"
  },
  {
    "id": "arXiv:2110.05709",
    "title": "Mixed Generalized Multiscale Finite Element Method for Flow Problem in  Thin Domains",
    "abstract": "In this paper, we construct a class of Mixed Generalized Multiscale Finite\nElement Methods for the approximation on a coarse grid for an elliptic problem\nin thin two-dimensional domains. We consider the elliptic equation with\nhomogeneous boundary conditions on the domain walls. For reference solution of\nthe problem, we use a Mixed Finite Element Method on a fine grid that resolves\ncomplex geometry on the grid level. To construct a lower dimensional model, we\nuse the Mixed Generalized Multiscale Finite Element Method, which is based on\nsome multiscale basis functions for velocity fields. The construction of the\nbasis functions is based on the local snapshot space that takes all possible\nflows on the interface between coarse cells into account. In order to reduce\nthe size of the snapshot space and obtain the multiscale approximation, we\nsolve a local spectral problem to identify dominant modes in the snapshot\nspace. We present a convergence analysis of the presented multiscale method.\nNumerical results are presented for two-dimensional problems in three testing\ngeometries along with the errors associated to different numbers of the\nmultiscale basis functions used for the velocity field. Numerical\ninvestigations are conducted for problems with homogeneous and heterogeneous\nproperties respectively.",
    "descriptor": "",
    "authors": [
      "Denis Spiridonov",
      "Maria Vasilyeva",
      "Min Wang",
      "Eric T. Chung"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05709"
  },
  {
    "id": "arXiv:2110.05712",
    "title": "DecGAN: Decoupling Generative Adversarial Network detecting abnormal  neural circuits for Alzheimer's disease",
    "abstract": "One of the main reasons for Alzheimer's disease (AD) is the disorder of some\nneural circuits. Existing methods for AD prediction have achieved great\nsuccess, however, detecting abnormal neural circuits from the perspective of\nbrain networks is still a big challenge. In this work, a novel decoupling\ngenerative adversarial network (DecGAN) is proposed to detect abnormal neural\ncircuits for AD. Concretely, a decoupling module is designed to decompose a\nbrain network into two parts: one part is composed of a few sparse graphs which\nrepresent the neural circuits largely determining the development of AD; the\nother part is a supplement graph, whose influence on AD can be ignored.\nFurthermore, the adversarial strategy is utilized to guide the decoupling\nmodule to extract the feature more related to AD. Meanwhile, by encoding the\ndetected neural circuits to hypergraph data, an analytic module associated with\nthe hyperedge neurons algorithm is designed to identify the neural circuits.\nMore importantly, a novel sparse capacity loss based on the spatial-spectral\nhypergraph similarity is developed to minimize the intrinsic topological\ndistribution of neural circuits, which can significantly improve the accuracy\nand robustness of the proposed model. Experimental results demonstrate that the\nproposed model can effectively detect the abnormal neural circuits at different\nstages of AD, which is helpful for pathological study and early treatment.",
    "descriptor": "",
    "authors": [
      "Junren Pan",
      "Baiying Lei",
      "Shuqiang Wang",
      "Bingchuan Wang",
      "Yong Liu",
      "Yanyan Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05712"
  },
  {
    "id": "arXiv:2110.05713",
    "title": "Foster Strengths and Circumvent Weaknesses: a Speech Enhancement  Framework with Two-branch Collaborative Learning",
    "abstract": "Recent single-channel speech enhancement methods usually convert waveform to\nthe time-frequency domain and use magnitude/complex spectrum as the optimizing\ntarget. However, both magnitude-spectrum-based methods and\ncomplex-spectrum-based methods have their respective pros and cons. In this\npaper, we propose a unified two-branch framework to foster strengths and\ncircumvent weaknesses of different paradigms. The proposed framework could take\nfull advantage of the apparent spectral regularity in magnitude spectrogram and\nbreak the bottleneck that magnitude-based methods have suffered. Within each\nbranch, we use collaborative expert block and its variants as substitutes for\nregular convolution layers. Experiments on TIMIT benchmark demonstrate that our\nmethod is superior to existing state-of-the-art ones.",
    "descriptor": "",
    "authors": [
      "Wenxin Tai",
      "Jiajia Li",
      "Yixiang Wang",
      "Tian Lan",
      "Qiao Liu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05713"
  },
  {
    "id": "arXiv:2110.05716",
    "title": "Convergence and stability of the semi-tamed Milstein method for  commutative stochastic differential equations with non-globally Lipschitz  continuous coefficients",
    "abstract": "A new explicit stochastic scheme of order 1 is proposed for solving\ncommutative stochastic differential equations (SDEs) with non-globally\nLipschitz continuous coefficients. The proposed method is a semi-tamed version\nof Milstein scheme to solve SDEs with the drift coefficient consisting of\nnon-Lipschitz continuous term and globally Lipschitz continuous term. It is\neasily implementable and achieves higher strong convergence order. A stability\ncriterion for this method is derived, which shows that the stability condition\nof the numerical methods and that of the solved equations keep uniform.\nCompared with some widely used numerical schemes, the proposed method has\nbetter performance in inheriting the mean square stability of the exact\nsolution of SDEs. Numerical experiments are given to illustrate the obtained\nconvergence and stability properties.",
    "descriptor": "",
    "authors": [
      "Yulong Liu",
      "Yuanling Niu",
      "Xiujun Cheng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05716"
  },
  {
    "id": "arXiv:2110.05717",
    "title": "Relation-aware Video Reading Comprehension for Temporal Language  Grounding",
    "abstract": "Temporal language grounding in videos aims to localize the temporal span\nrelevant to the given query sentence. Previous methods treat it either as a\nboundary regression task or a span extraction task. This paper will formulate\ntemporal language grounding into video reading comprehension and propose a\nRelation-aware Network (RaNet) to address it. This framework aims to select a\nvideo moment choice from the predefined answer set with the aid of\ncoarse-and-fine choice-query interaction and choice-choice relation\nconstruction. A choice-query interactor is proposed to match the visual and\ntextual information simultaneously in sentence-moment and token-moment levels,\nleading to a coarse-and-fine cross-modal interaction. Moreover, a novel\nmulti-choice relation constructor is introduced by leveraging graph convolution\nto capture the dependencies among video moment choices for the best choice\nselection. Extensive experiments on ActivityNet-Captions, TACoS, and\nCharades-STA demonstrate the effectiveness of our solution. Codes will be\nreleased soon.",
    "descriptor": "\nComments: Accepted by EMNLP-21\n",
    "authors": [
      "Jialin Gao",
      "Xin Sun",
      "Mengmeng Xu",
      "Xi Zhou",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05717"
  },
  {
    "id": "arXiv:2110.05719",
    "title": "Dealing with Disagreements: Looking Beyond the Majority Vote in  Subjective Annotations",
    "abstract": "Majority voting and averaging are common approaches employed to resolve\nannotator disagreements and derive single ground truth labels from multiple\nannotations. However, annotators may systematically disagree with one another,\noften reflecting their individual biases and values, especially in the case of\nsubjective tasks such as detecting affect, aggression, and hate speech.\nAnnotator disagreements may capture important nuances in such tasks that are\noften ignored while aggregating annotations to a single ground truth. In order\nto address this, we investigate the efficacy of multi-annotator models. In\nparticular, our multi-task based approach treats predicting each annotators'\njudgements as separate subtasks, while sharing a common learned representation\nof the task. We show that this approach yields same or better performance than\naggregating labels in the data prior to training across seven different binary\nclassification tasks. Our approach also provides a way to estimate uncertainty\nin predictions, which we demonstrate better correlate with annotation\ndisagreements than traditional methods. Being able to model uncertainty is\nespecially useful in deployment scenarios where knowing when not to make a\nprediction is important.",
    "descriptor": "",
    "authors": [
      "Aida Mostafazadeh Davani",
      "Mark D\u00edaz",
      "Vinodkumar Prabhakaran"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.05719"
  },
  {
    "id": "arXiv:2110.05721",
    "title": "Action-Sufficient State Representation Learning for Control with  Structural Constraints",
    "abstract": "Perceived signals in real-world scenarios are usually high-dimensional and\nnoisy, and finding and using their representation that contains essential and\nsufficient information required by downstream decision-making tasks will help\nimprove computational efficiency and generalization ability in the tasks. In\nthis paper, we focus on partially observable environments and propose to learn\na minimal set of state representations that capture sufficient information for\ndecision-making, termed \\textit{Action-Sufficient state Representations}\n(ASRs). We build a generative environment model for the structural\nrelationships among variables in the system and present a principled way to\ncharacterize ASRs based on structural constraints and the goal of maximizing\ncumulative reward in policy learning. We then develop a structured sequential\nVariational Auto-Encoder to estimate the environment model and extract ASRs.\nOur empirical results on CarRacing and VizDoom demonstrate a clear advantage of\nlearning and using ASRs for policy learning. Moreover, the estimated\nenvironment model and ASRs allow learning behaviors from imagined outcomes in\nthe compact latent space to improve sample efficiency.",
    "descriptor": "",
    "authors": [
      "Biwei Huang",
      "Chaochao Lu",
      "Liu Leqi",
      "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato",
      "Clark Glymour",
      "Bernhard Sch\u00f6lkopf",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05721"
  },
  {
    "id": "arXiv:2110.05722",
    "title": "LightSeq: Accelerated Training for Transformer-based Models on GPUs",
    "abstract": "Transformer-based models have proven to be powerful in many natural language,\ncomputer vision, and speech recognition applications. It is expensive to train\nthese types of models due to unfixed input length, complex computation, and\nlarge numbers of parameters. Existing systems either only focus on efficient\ninference or optimize only BERT-like encoder models. In this paper, we present\nLightSeq, a system for efficient training of Transformer-based models on GPUs.\nWe propose a series of GPU optimization techniques tailored to computation flow\nand memory access patterns of neural layers in Transformers. LightSeq supports\na variety of network architectures, including BERT (encoder-only), GPT\n(decoder-only), and Transformer (encoder-decoder). Our experiments on GPUs with\nvarying models and datasets show that LightSeq is 1.4-3.5x faster than previous\nsystems. In particular, it gains 308% training speedup compared with existing\nsystems on a large public machine translation benchmark (WMT14 English-German).",
    "descriptor": "\nComments: 12 pages, 17 figures\n",
    "authors": [
      "Xiaohui Wang",
      "Ying Xiong",
      "Xian Qian",
      "Yang Wei",
      "Lei Li",
      "Mingxuan Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2110.05722"
  },
  {
    "id": "arXiv:2110.05723",
    "title": "Prediction of Political Leanings of Chinese Speaking Twitter Users",
    "abstract": "This work presents a supervised method for generating a classifier model of\nthe stances held by Chinese-speaking politicians and other Twitter users. Many\nprevious works of political tweets prediction exist on English tweets, but to\nthe best of our knowledge, this is the first work that builds prediction model\non Chinese political tweets. It firstly collects data by scraping tweets of\nfamous political figure and their related users. It secondly defines the\npolitical spectrum in two groups: the group that shows approvals to the Chinese\nCommunist Party and the group that does not. Since there are not space between\nwords in Chinese to identify the independent words, it then completes\nsegmentation and vectorization by Jieba, a Chinese segmentation tool. Finally,\nit trains the data collected from political tweets and produce a classification\nmodel with high accuracy for understanding users' political stances from their\ntweets on Twitter.",
    "descriptor": "",
    "authors": [
      "Fenglei Gu",
      "Duoji Jiang"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05723"
  },
  {
    "id": "arXiv:2110.05724",
    "title": "Dare not to Ask: Problem-Dependent Guarantees for Budgeted Bandits",
    "abstract": "We consider a stochastic multi-armed bandit setting where feedback is limited\nby a (possibly time-dependent) budget, and reward must be actively inquired for\nit to be observed. Previous works on this setting assumed a strict feedback\nbudget and focused on not violating this constraint while providing\nproblem-independent regret guarantees. In this work, we provide\nproblem-dependent guarantees on both the regret and the asked feedback. In\nparticular, we derive problem-dependent lower bounds on the required feedback\nand show that there is a fundamental difference between problems with a unique\nand multiple optimal arms. Furthermore, we present a new algorithm called\nBuFALU for which we derive problem-dependent regret and cumulative feedback\nbounds. Notably, we show that BuFALU naturally adapts to the number of optimal\narms.",
    "descriptor": "",
    "authors": [
      "Nadav Merlis",
      "Yonathan Efroni",
      "Shie Mannor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05724"
  },
  {
    "id": "arXiv:2110.05727",
    "title": "Anatomy of OntoGUM--Adapting GUM to the OntoNotes Scheme to Evaluate  Robustness of SOTA Coreference Algorithms",
    "abstract": "SOTA coreference resolution produces increasingly impressive scores on the\nOntoNotes benchmark. However lack of comparable data following the same scheme\nfor more genres makes it difficult to evaluate generalizability to open domain\ndata. Zhu et al. (2021) introduced the creation of the OntoGUM corpus for\nevaluating geralizability of the latest neural LM-based end-to-end systems.\nThis paper covers details of the mapping process which is a set of\ndeterministic rules applied to the rich syntactic and discourse annotations\nmanually annotated in the GUM corpus. Out-of-domain evaluation across 12 genres\nshows nearly 15-20% degradation for both deterministic and deep learning\nsystems, indicating a lack of generalizability or covert overfitting in\nexisting coreference resolution models.",
    "descriptor": "\nComments: CRAC 2021. arXiv admin note: substantial text overlap with arXiv:2106.00933\n",
    "authors": [
      "Yilun Zhu",
      "Sameer Pradhan",
      "Amir Zeldes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05727"
  },
  {
    "id": "arXiv:2110.05728",
    "title": "Rethinking the Spatial Route Prior in Vision-and-Language Navigation",
    "abstract": "Vision-and-language navigation (VLN) is a trending topic which aims to\nnavigate an intelligent agent to an expected position through natural language\ninstructions. This work addresses the task of VLN from a previously-ignored\naspect, namely the spatial route prior of the navigation scenes. A critically\nenabling innovation of this work is explicitly considering the spatial route\nprior under several different VLN settings. In a most information-rich case of\nknowing environment maps and admitting shortest-path prior, we observe that\ngiven an origin-destination node pair, the internal route can be uniquely\ndetermined. Thus, VLN can be effectively formulated as an ordinary\nclassification problem over all possible destination nodes in the scenes.\nFurthermore, we relax it to other more general VLN settings, proposing a\nsequential-decision variant (by abandoning the shortest-path route prior) and\nan explore-and-exploit scheme (for addressing the case of not knowing the\nenvironment maps) that curates a compact and informative sub-graph to exploit.\nAs reported by [34], the performance of VLN methods has been stuck at a plateau\nin past two years. Even with increased model complexity, the state-of-the-art\nsuccess rate on R2R validation-unseen set has stayed around 62% for single-run\nand 73% for beam-search with model-ensemble. We have conducted comprehensive\nevaluations on both R2R and R4R, and surprisingly found that utilizing the\nspatial route priors may be the key of breaking above-mentioned performance\nceiling. For example, on R2R validation-unseen set, when the number of discrete\nnodes explored is about 40, our single-model success rate reaches 73%, and\nincreases to 78% if a Speaker model is ensembled, which significantly outstrips\nprevious state-of-the-art VLN-BERT with 3 models ensembled.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Xinzhe Zhou",
      "Wei Liu",
      "Yadong Mu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05728"
  },
  {
    "id": "arXiv:2110.05730",
    "title": "Contrastive Learning for Representation Degeneration Problem in  Sequential Recommendation",
    "abstract": "Recent advancements of sequential deep learning models such as Transformer\nand BERT have significantly facilitated the sequential recommendation. However,\naccording to our study, the distribution of item embeddings generated by these\nmodels tends to degenerate into an anisotropic shape, which may result in high\nsemantic similarities among embeddings. In this paper, both empirical and\ntheoretical investigations of this representation degeneration problem are\nfirst provided, based on which a novel recommender model DuoRec is proposed to\nimprove the item embeddings distribution. Specifically, in light of the\nuniformity property of contrastive learning, a contrastive regularization is\ndesigned for DuoRec to reshape the distribution of sequence representations.\nGiven the convention that the recommendation task is performed by measuring the\nsimilarity between sequence representations and item embeddings in the same\nspace via dot product, the regularization can be implicitly applied to the item\nembedding distribution. Existing contrastive learning methods mainly rely on\ndata level augmentation for user-item interaction sequences through item\ncropping, masking, or reordering and can hardly provide semantically consistent\naugmentation samples. In DuoRec, a model-level augmentation is proposed based\non Dropout to enable better semantic preserving. Furthermore, a novel sampling\nstrategy is developed, where sequences having the same target item are chosen\nhard positive samples. Extensive experiments conducted on five datasets\ndemonstrate the superior performance of the proposed DuoRec model compared with\nbaseline methods. Visualization results of the learned representations validate\nthat DuoRec can largely alleviate the representation degeneration problem.",
    "descriptor": "",
    "authors": [
      "Ruihong Qiu",
      "Zi Huang",
      "Hongzhi Yin",
      "Zijian Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.05730"
  },
  {
    "id": "arXiv:2110.05731",
    "title": "Topic Scene Graph Generation by Attention Distillation from Caption",
    "abstract": "If an image tells a story, the image caption is the briefest narrator.\nGenerally, a scene graph prefers to be an omniscient generalist, while the\nimage caption is more willing to be a specialist, which outlines the gist. Lots\nof previous studies have found that a scene graph is not as practical as\nexpected unless it can reduce the trivial contents and noises. In this respect,\nthe image caption is a good tutor. To this end, we let the scene graph borrow\nthe ability from the image caption so that it can be a specialist on the basis\nof remaining all-around, resulting in the so-called Topic Scene Graph. What an\nimage caption pays attention to is distilled and passed to the scene graph for\nestimating the importance of partial objects, relationships, and events.\nSpecifically, during the caption generation, the attention about individual\nobjects in each time step is collected, pooled, and assembled to obtain the\nattention about relationships, which serves as weak supervision for\nregularizing the estimated importance scores of relationships. In addition, as\nthis attention distillation process provides an opportunity for combining the\ngeneration of image caption and scene graph together, we further transform the\nscene graph into linguistic form with rich and free-form expressions by sharing\na single generation model with image caption. Experiments show that attention\ndistillation brings significant improvements in mining important relationships\nwithout strong supervision, and the topic scene graph shows great potential in\nsubsequent applications.",
    "descriptor": "\nComments: published in ICCV 2021\n",
    "authors": [
      "W. Wang",
      "R. Wang",
      "X. Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05731"
  },
  {
    "id": "arXiv:2110.05732",
    "title": "Guided-GAN: Adversarial Representation Learning for Activity Recognition  with Wearables",
    "abstract": "Human activity recognition (HAR) is an important research field in ubiquitous\ncomputing where the acquisition of large-scale labeled sensor data is tedious,\nlabor-intensive and time consuming. State-of-the-art unsupervised remedies\ninvestigated to alleviate the burdens of data annotations in HAR mainly explore\ntraining autoencoder frameworks. In this paper: we explore generative\nadversarial network (GAN) paradigms to learn unsupervised feature\nrepresentations from wearable sensor data; and design a new GAN\nframework-Geometrically-Guided GAN or Guided-GAN-for the task. To demonstrate\nthe effectiveness of our formulation, we evaluate the features learned by\nGuided-GAN in an unsupervised manner on three downstream classification\nbenchmarks. Our results demonstrate Guided-GAN to outperform existing\nunsupervised approaches whilst closely approaching the performance with fully\nsupervised learned representations. The proposed approach paves the way to\nbridge the gap between unsupervised and supervised human activity recognition\nwhilst helping to reduce the cost of human data annotation tasks.",
    "descriptor": "",
    "authors": [
      "Alireza Abedin",
      "Hamid Rezatofighi",
      "Damith C. Ranasinghe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05732"
  },
  {
    "id": "arXiv:2110.05734",
    "title": "Learning Efficient Multi-Agent Cooperative Visual Exploration",
    "abstract": "We consider the task of visual indoor exploration with multiple agents, where\nthe agents need to cooperatively explore the entire indoor region using as few\nsteps as possible. Classical planning-based methods often suffer from\nparticularly expensive computation at each inference step and a limited\nexpressiveness of cooperation strategy. By contrast, reinforcement learning\n(RL) has become a trending paradigm for tackling this challenge due to its\nmodeling capability of arbitrarily complex strategies and minimal inference\noverhead. We extend the state-of-the-art single-agent RL solution, Active\nNeural SLAM (ANS), to the multi-agent setting by introducing a novel RL-based\nglobal-goal planner, Spatial Coordination Planner (SCP), which leverages\nspatial information from each individual agent in an end-to-end manner and\neffectively guides the agents to navigate towards different spatial goals with\nhigh exploration efficiency. SCP consists of a transformer-based relation\nencoder to capture intra-agent interactions and a spatial action decoder to\nproduce accurate goals. In addition, we also implement a few multi-agent\nenhancements to process local information from each agent for an aligned\nspatial representation and more precise planning. Our final solution,\nMulti-Agent Active Neural SLAM (MAANS), combines all these techniques and\nsubstantially outperforms 4 different planning-based methods and various RL\nbaselines in the photo-realistic physical testbed, Habitat.",
    "descriptor": "\nComments: First three authors share equal contribution\n",
    "authors": [
      "Chao Yu",
      "Xinyi Yang",
      "Jiaxuan Gao",
      "Huazhong Yang",
      "Yu Wang",
      "Yi Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.05734"
  },
  {
    "id": "arXiv:2110.05735",
    "title": "Global games with Poisson observations: Bio-inspired distributed  coordination of multi-agent systems",
    "abstract": "Global games are a class of incomplete information games where the payoffs\nexhibit strategic complementarity leading to an incentive for the agents to\ncoordinate their actions. Such games have been used to model scenarios in many\nsocioeconomic phenomena, where the private signals available to the agents are\ntypically assumed to be Gaussian. We study an instance of a global game where\nthe agents observe Poisson random variables, which are inspired by applications\nin microbiology where information signals are disseminated via discrete\nmolecular signals rather than continuous. Although this observation model\nviolates the essential technical assumptions present in the Gaussian case, we\npresent preliminary results on the existence of Bayesian Nash equilibria in\npure threshold policies in two variants of the underlying random\nstate-of-the-world: an arbitrarily distributed discrete binary state and a\ncontinuous state with uniform distribution.",
    "descriptor": "\nComments: Submitted to IEEE American Control Conference 2022\n",
    "authors": [
      "Marcos M. Vasconcelos"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.05735"
  },
  {
    "id": "arXiv:2110.05740",
    "title": "Temporal Abstraction in Reinforcement Learning with the Successor  Representation",
    "abstract": "Reasoning at multiple levels of temporal abstraction is one of the key\nattributes of intelligence. In reinforcement learning, this is often modeled\nthrough temporally extended courses of actions called options. Options allow\nagents to make predictions and to operate at different levels of abstraction\nwithin an environment. Nevertheless, approaches based on the options framework\noften start with the assumption that a reasonable set of options is known\nbeforehand. When this is not the case, there are no definitive answers for\nwhich options one should consider. In this paper, we argue that the successor\nrepresentation (SR), which encodes states based on the pattern of state\nvisitation that follows them, can be seen as a natural substrate for the\ndiscovery and use of temporal abstractions. To support our claim, we take a big\npicture view of recent results, showing how the SR can be used to discover\noptions that facilitate either temporally-extended exploration or planning. We\ncast these results as instantiations of a general framework for option\ndiscovery in which the agent's representation is used to identify useful\noptions, which are then used to further improve its representation. This\nresults in a virtuous, never-ending, cycle in which both the representation and\nthe options are constantly refined based on each other. Beyond option discovery\nitself, we discuss how the SR allows us to augment a set of options into a\ncombinatorially large counterpart without additional learning. This is achieved\nthrough the combination of previously learned options. Our empirical evaluation\nfocuses on options discovered for temporally-extended exploration and on the\nuse of the SR to combine them. The results of our experiments shed light on\ndesign decisions involved in the definition of options and demonstrate the\nsynergy of different methods based on the SR, such as eigenoptions and the\noption keyboard.",
    "descriptor": "\nComments: 56 pages, 28 figures\n",
    "authors": [
      "Marlos C. Machado",
      "Andre Barreto",
      "Doina Precup"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05740"
  },
  {
    "id": "arXiv:2110.05741",
    "title": "Online Refinement of Low-level Feature Based Activation Map for Weakly  Supervised Object Localization",
    "abstract": "We present a two-stage learning framework for weakly supervised object\nlocalization (WSOL). While most previous efforts rely on high-level feature\nbased CAMs (Class Activation Maps), this paper proposes to localize objects\nusing the low-level feature based activation maps. In the first stage, an\nactivation map generator produces activation maps based on the low-level\nfeature maps in the classifier, such that rich contextual object information is\nincluded in an online manner. In the second stage, we employ an evaluator to\nevaluate the activation maps predicted by the activation map generator. Based\non this, we further propose a weighted entropy loss, an attentive erasing, and\nan area loss to drive the activation map generator to substantially reduce the\nuncertainty of activations between object and background, and explore less\ndiscriminative regions. Based on the low-level object information preserved in\nthe first stage, the second stage model gradually generates a well-separated,\ncomplete, and compact activation map of object in the image, which can be\neasily thresholded for accurate localization. Extensive experiments on\nCUB-200-2011 and ImageNet-1K datasets show that our framework surpasses\nprevious methods by a large margin, which sets a new state-of-the-art for WSOL.",
    "descriptor": "\nComments: Accepted to ICCV 2021.(corrected some minor mistakes)\n",
    "authors": [
      "Jinheng Xie",
      "Cheng Luo",
      "Xiangping Zhu",
      "Ziqi Jin",
      "Weizeng Lu",
      "Linlin Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05741"
  },
  {
    "id": "arXiv:2110.05743",
    "title": "Program Transfer and Ontology Awareness for Semantic Parsing in KBQA",
    "abstract": "Semantic parsing in KBQA aims to parse natural language questions into\nlogical forms, whose execution against a knowledge base produces answers.\nLearning semantic parsers from question-answer pairs requires searching over a\nhuge space of logical forms for ones consistent with answers. Current methods\nutilize various prior knowlege or entity-level KB constraints to reduce the\nsearch space. In this paper, we investigate for the first time prior knowledge\nfrom external logical form annotations and ontology-level constraints. We\ndesign a hierarchical architecture for program transfer, and propose an\nontology-guided pruning algorithm to reduce the search space. The experiments\non ComplexWebQuestions show that our method improves the state-of-the-art F1\nscore from 44.0% to 58.7%, with an absolute gain of 14.7%, which demonstrates\nthe effectiveness of program transfer and ontology awareness.",
    "descriptor": "",
    "authors": [
      "Shulin Cao",
      "Jiaxin Shi",
      "Zijun Yao",
      "Lei Hou",
      "Juanzi Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05743"
  },
  {
    "id": "arXiv:2110.05746",
    "title": "Improved Analysis of EDCS via Gallai-Edmonds Decomposition",
    "abstract": "In this note, we revisit the edge-degree constrained subgraph (EDCS)\nintroduced by Bernstein and Stein (ICALP'15). An EDCS is a sparse subgraph\nsatisfying simple edge-degree constraints that is guaranteed to include an\n(almost) $\\frac{2}{3}$-approximate matching of the base graph. Since its\nintroduction, the EDCS has been successfully applied to numerous models of\ncomputation. Motivated by this success, we revisit EDCS and present an improved\nbound for its key property in general graphs.\nOur main result is a new proof of the approximation guarantee of EDCS that\nbuilds on the graph's Gallai-Edmonds decomposition, avoiding the probabilistic\nmethod of the previous proofs. As a result, we get that to obtain a\n$(\\frac{2}{3} - \\epsilon)$-approximation, a sparse EDCS with maximum degree\nbounded by $O(1/\\epsilon)$ is sufficient. This improves the\n$O(\\log(1/\\epsilon)/\\epsilon^2)$ bound of Assadi and Bernstein (SOSA'19) and\nthe $O(1/\\epsilon^3)$ bound of Bernstein and Stein (SODA'16). Our guarantee\nessentially matches what was previously only known for bipartite graphs,\nthereby removing the gap in our understanding of EDCS in general vs. bipartite\ngraphs.",
    "descriptor": "",
    "authors": [
      "Soheil Behnezhad"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.05746"
  },
  {
    "id": "arXiv:2110.05747",
    "title": "Seamless Copy Move Manipulation in Digital Images",
    "abstract": "The importance and relevance of digital image forensics has attracted\nresearchers to establish different techniques for creating as well as detecting\nforgeries. The core category in passive image forgery is copy-move image\nforgery that affects the originality of image by applying a different\ntransformation. In this paper frequency domain image manipulation method is\nbeing presented.The method exploits the localized nature of discrete wavelet\ntransform (DWT) to get hold of the region of the host image to be manipulated.\nBoth the patch and host image are subjected to DWT at the same level $l$ to get\n$3l + 1$ sub-bands and each sub-band of the patch is pasted to the identified\nregion in the corresponding sub-band of the host image. The resultant\nmanipulated host sub-bands are then subjected to inverse DWT to get the final\nmanipulated host image. The proposed method shows good resistance against\ndetection by two frequency domain forgery detection methods from the\nliterature. The purpose of this research work is to create the forgery and\nhighlight the need to produce forgery detection methods that are robust against\nthe malicious copy-move forgery.",
    "descriptor": "\nComments: 9 pages and 9 figures (most having subfigures)\n",
    "authors": [
      "Tanzila Qazi",
      "Mushtaq Ali",
      "Khizar Hayat"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.05747"
  },
  {
    "id": "arXiv:2110.05748",
    "title": "SEPP: Similarity Estimation of Predicted Probabilities for Defending and  Detecting Adversarial Text",
    "abstract": "There are two cases describing how a classifier processes input text, namely,\nmisclassification and correct classification. In terms of misclassified texts,\na classifier handles the texts with both incorrect predictions and adversarial\ntexts, which are generated to fool the classifier, which is called a victim.\nBoth types are misunderstood by the victim, but they can still be recognized by\nother classifiers. This induces large gaps in predicted probabilities between\nthe victim and the other classifiers. In contrast, text correctly classified by\nthe victim is often successfully predicted by the others and induces small\ngaps. In this paper, we propose an ensemble model based on similarity\nestimation of predicted probabilities (SEPP) to exploit the large gaps in the\nmisclassified predictions in contrast to small gaps in the correct\nclassification. SEPP then corrects the incorrect predictions of the\nmisclassified texts. We demonstrate the resilience of SEPP in defending and\ndetecting adversarial texts through different types of victim classifiers,\nclassification tasks, and adversarial attacks.",
    "descriptor": "\nComments: PACLIC 35 (2021) (Oral)\n",
    "authors": [
      "Hoang-Quoc Nguyen-Son",
      "Seira Hidano",
      "Kazuhide Fukushima",
      "Shinsaku Kiyomoto"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05748"
  },
  {
    "id": "arXiv:2110.05750",
    "title": "SportsSum2.0: Generating High-Quality Sports News from Live Text  Commentary",
    "abstract": "Sports game summarization aims to generate news articles from live text\ncommentaries. A recent state-of-the-art work, SportsSum, not only constructs a\nlarge benchmark dataset, but also proposes a two-step framework. Despite its\ngreat contributions, the work has three main drawbacks: 1) the noise existed in\nSportsSum dataset degrades the summarization performance; 2) the neglect of\nlexical overlap between news and commentaries results in low-quality\npseudo-labeling algorithm; 3) the usage of directly concatenating rewritten\nsentences to form news limits its practicability. In this paper, we publish a\nnew benchmark dataset SportsSum2.0, together with a modified summarization\nframework. In particular, to obtain a clean dataset, we employ crowd workers to\nmanually clean the original dataset. Moreover, the degree of lexical overlap is\nincorporated into the generation of pseudo labels. Further, we introduce a\nreranker-enhanced summarizer to take into account the fluency and\nexpressiveness of the summarized news. Extensive experiments show that our\nmodel outperforms the state-of-the-art baseline.",
    "descriptor": "\nComments: Accepted as a short paper in CIKM 2021\n",
    "authors": [
      "Jiaan Wang",
      "Zhixu Li",
      "Qiang Yang",
      "Jianfeng Qu",
      "Zhigang Chen",
      "Qingsheng Liu",
      "Guoping Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05750"
  },
  {
    "id": "arXiv:2110.05752",
    "title": "UniSpeech-SAT: Universal Speech Representation Learning with Speaker  Aware Pre-Training",
    "abstract": "Self-supervised learning (SSL) is a long-standing goal for speech processing,\nsince it utilizes large-scale unlabeled data and avoids extensive human\nlabeling. Recent years witness great successes in applying self-supervised\nlearning in speech recognition, while limited exploration was attempted in\napplying SSL for modeling speaker characteristics. In this paper, we aim to\nimprove the existing SSL framework for speaker representation learning. Two\nmethods are introduced for enhancing the unsupervised speaker information\nextraction. First, we apply the multi-task learning to the current SSL\nframework, where we integrate the utterance-wise contrastive loss with the SSL\nobjective function. Second, for better speaker discrimination, we propose an\nutterance mixing strategy for data augmentation, where additional overlapped\nutterances are created unsupervisely and incorporate during training. We\nintegrate the proposed methods into the HuBERT framework. Experiment results on\nSUPERB benchmark show that the proposed system achieves state-of-the-art\nperformance in universal representation learning, especially for speaker\nidentification oriented tasks. An ablation study is performed verifying the\nefficacy of each proposed method. Finally, we scale up training dataset to 94\nthousand hours public audio data and achieve further performance improvement in\nall SUPERB tasks.",
    "descriptor": "\nComments: ICASSP 2022 Submission\n",
    "authors": [
      "Sanyuan Chen",
      "Yu Wu",
      "Chengyi Wang",
      "Zhengyang Chen",
      "Zhuo Chen",
      "Shujie Liu",
      "Jian Wu",
      "Yao Qian",
      "Furu Wei",
      "Jinyu Li",
      "Xiangzhan Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05752"
  },
  {
    "id": "arXiv:2110.05753",
    "title": "Predicting the Efficiency of CO$_2$ Sequestering by Metal Organic  Frameworks Through Machine Learning Analysis of Structural and Electronic  Properties",
    "abstract": "Due the alarming rate of climate change, the implementation of efficient\nCO$_2$ capture has become crucial. This project aims to create an algorithm\nthat predicts the uptake of CO$_2$ adsorbing Metal-Organic Frameworks (MOFs) by\nusing Machine Learning. These values will in turn gauge the efficiency of these\nMOFs and provide scientists who are looking to maximize the uptake a way to\nknow whether or not the MOF is worth synthesizing. This algorithm will save\nresources such as time and equipment as scientists will be able to disregard\nhypothetical MOFs with low efficiencies. In addition, this paper will also\nhighlight the most important features within the data set. This research will\ncontribute to enable the rapid synthesis of CO$_2$ adsorbing MOFs.",
    "descriptor": "\nComments: 5 pages, 7 figures, github code provided\n",
    "authors": [
      "Mahati Manda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.05753"
  },
  {
    "id": "arXiv:2110.05754",
    "title": "Deep Federated Learning for Autonomous Driving",
    "abstract": "Autonomous driving is an active research topic in both academia and industry.\nHowever, most of the existing solutions focus on improving the accuracy by\ntraining learnable models with centralized large-scale data. Therefore, these\nmethods do not take into account the user's privacy. In this paper, we present\na new approach to learn autonomous driving policy while respecting privacy\nconcerns. We propose a peer-to-peer Deep Federated Learning (DFL) approach to\ntrain deep architectures in a fully decentralized manner and remove the need\nfor central orchestration. We design a new Federated Autonomous Driving network\n(FADNet) that can improve the model stability, ensure convergence, and handle\nimbalanced data distribution problems while is being trained with federated\nlearning methods. Intensively experimental results on three datasets show that\nour approach with FADNet and DFL achieves superior accuracy compared with other\nrecent methods. Furthermore, our approach can maintain privacy by not\ncollecting user data to a central server.",
    "descriptor": "",
    "authors": [
      "Anh Nguyen",
      "Tuong Do",
      "Minh Tran",
      "Binh X. Nguyen",
      "Chien Duong",
      "Tu Phan",
      "Erman Tjiputra",
      "Quang D. Tran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.05754"
  },
  {
    "id": "arXiv:2110.05757",
    "title": "Remote Anomaly Detection in Industry 4.0 Using Resource-Constrained  Devices",
    "abstract": "A central use case for the Internet of Things (IoT) is the adoption of\nsensors to monitor physical processes, such as the environment and industrial\nmanufacturing processes, where they provide data for predictive maintenance,\nanomaly detection, or similar. The sensor devices are typically\nresource-constrained in terms of computation and power, and need to rely on\ncloud or edge computing for data processing. However, the capacity of the\nwireless link and their power constraints limit the amount of data that can be\ntransmitted to the cloud. While this is not problematic for the monitoring of\nslowly varying processes such as temperature, it is more problematic for\ncomplex signals such as those captured by vibration and acoustic sensors. In\nthis paper, we consider the specific problem of remote anomaly detection based\non signals that fall into the latter category over wireless channels with\nresource-constrained sensors. We study the impact of source coding on the\ndetection accuracy with both an anomaly detector based on Principal Component\nAnalysis (PCA) and one based on an autoencoder. We show that the coded\ntransmission is beneficial when the signal-to-noise ratio (SNR) of the channel\nis low, while uncoded transmission performs best in the high SNR regime.",
    "descriptor": "\nComments: Presented at SPAWC 2021\n",
    "authors": [
      "Anders E. Kal\u00f8r",
      "Daniel Michelsanti",
      "Federico Chiariotti",
      "Zheng-Hua Tan",
      "Petar Popovski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.05757"
  },
  {
    "id": "arXiv:2110.05758",
    "title": "Role of Externally Provided Randomness in Stochastic Teams and Zero-sum  Team Games",
    "abstract": "Stochastic team decision problem is extensively studied in literature and the\nexistence of optimal solution is obtained in recent literature. The value of\ninformation in statistical problem and decision theory is classical problem.\nMuch of earlier does not qualitatively describe role of externally provided\nprivate and common randomness in stochastic team problem and team vs team zero\nsum game.\nIn this paper, we study the role of extrenally provided private or common\nrandomness in stochastic team decision. We make observation that the randomness\nindependent of environment does not benefit either team but randomness\ndependent on environment benefit teams and decreases the expected cost\nfunction. We also studied LQG team game with special information structure on\nprivate or common randomness. We extend these study to problem team vs team\nzero sum game. We show that if a game admits saddle point solution, then\nprivate or common randomness independent of environment does not benefit either\nteam. We also analyze the scenario when a team with having more information\nthan other team which is dependent on environment and game has saddle point\nsolution, then team with more information benefits. This is also illustrated\nnumerically for LQG team vs team zero sum game. Finally, we show for discrete\nteam vs team zero sum game that private randomness independent of environment\nbenefits team when there is no saddle point condition. Role of common\nrandomness is discussed for discrete game.",
    "descriptor": "",
    "authors": [
      "Rahul Meshram"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.05758"
  },
  {
    "id": "arXiv:2110.05762",
    "title": "Detecting Damage Building Using Real-time Crowdsourced Images and  Transfer Learning",
    "abstract": "After significant earthquakes, we can see images posted on social media\nplatforms by individuals and media agencies owing to the mass usage of\nsmartphones these days. These images can be utilized to provide information\nabout the shaking damage in the earthquake region both to the public and\nresearch community, and potentially to guide rescue work. This paper presents\nan automated way to extract the damaged building images after earthquakes from\nsocial media platforms such as Twitter and thus identify the particular user\nposts containing such images. Using transfer learning and ~6500 manually\nlabelled images, we trained a deep learning model to recognize images with\ndamaged buildings in the scene. The trained model achieved good performance\nwhen tested on newly acquired images of earthquakes at different locations and\nran in near real-time on Twitter feed after the 2020 M7.0 earthquake in Turkey.\nFurthermore, to better understand how the model makes decisions, we also\nimplemented the Grad-CAM method to visualize the important locations on the\nimages that facilitate the decision.",
    "descriptor": "",
    "authors": [
      "Gaurav Chachra",
      "Qingkai Kong",
      "Jim Huang",
      "Srujay Korlakunta",
      "Jennifer Grannen",
      "Alexander Robson",
      "Richard Allen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.05762"
  },
  {
    "id": "arXiv:2110.05765",
    "title": "Music Sentiment Transfer",
    "abstract": "Music sentiment transfer is a completely novel task. Sentiment transfer is a\nnatural evolution of the heavily-studied style transfer task, as sentiment\ntransfer is rooted in applying the sentiment of a source to be the new\nsentiment for a target piece of media; yet compared to style transfer,\nsentiment transfer has been only scantily studied on images. Music sentiment\ntransfer attempts to apply the high level objective of sentiment transfer to\nthe domain of music. We propose CycleGAN to bridge disparate domains. In order\nto use the network, we choose to use symbolic, MIDI, data as the music format.\nThrough the use of a cycle consistency loss, we are able to create one-to-one\nmappings that preserve the content and realism of the source data. Results and\nliterature suggest that the task of music sentiment transfer is more difficult\nthan image sentiment transfer because of the temporal characteristics of music\nand lack of existing datasets.",
    "descriptor": "\nComments: NSF REU: Computational Methods for Understanding Music, Media, and Minds, University of Rochester\n",
    "authors": [
      "Miles Sigel",
      "Michael Zhou",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05765"
  },
  {
    "id": "arXiv:2110.05769",
    "title": "Interpretation of Emergent Communication in Heterogeneous Collaborative  Embodied Agents",
    "abstract": "Communication between embodied AI agents has received increasing attention in\nrecent years. Despite its use, it is still unclear whether the learned\ncommunication is interpretable and grounded in perception. To study the\ngrounding of emergent forms of communication, we first introduce the\ncollaborative multi-object navigation task CoMON. In this task, an oracle agent\nhas detailed environment information in the form of a map. It communicates with\na navigator agent that perceives the environment visually and is tasked to find\na sequence of goals. To succeed at the task, effective communication is\nessential. CoMON hence serves as a basis to study different communication\nmechanisms between heterogeneous agents, that is, agents with different\ncapabilities and roles. We study two common communication mechanisms and\nanalyze their communication patterns through an egocentric and spatial lens. We\nshow that the emergent communication can be grounded to the agent observations\nand the spatial structure of the 3D environment. Video summary:\nhttps://youtu.be/kLv2rxO9t0g",
    "descriptor": "\nComments: Project page: this https URL ; the first three authors contributed equally\n",
    "authors": [
      "Shivansh Patel",
      "Saim Wani",
      "Unnat Jain",
      "Alexander Schwing",
      "Svetlana Lazebnik",
      "Manolis Savva",
      "Angel X. Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.05769"
  },
  {
    "id": "arXiv:2110.05770",
    "title": "HyperCube: Implicit Field Representations of Voxelized 3D Models",
    "abstract": "Recently introduced implicit field representations offer an effective way of\ngenerating 3D object shapes. They leverage implicit decoder trained to take a\n3D point coordinate concatenated with a shape encoding and to output a value\nwhich indicates whether the point is outside the shape or not. Although this\napproach enables efficient rendering of visually plausible objects, it has two\nsignificant limitations. First, it is based on a single neural network\ndedicated for all objects from a training set which results in a cumbersome\ntraining procedure and its application in real life. More importantly, the\nimplicit decoder takes only points sampled within voxels (and not the entire\nvoxels) which yields problems at the classification boundaries and results in\nempty spaces within the rendered mesh.\nTo solve the above limitations, we introduce a new HyperCube architecture\nbased on interval arithmetic network, that enables direct processing of 3D\nvoxels, trained using a hypernetwork paradigm to enforce model convergence.\nInstead of processing individual 3D samples from within a voxel, our approach\nallows to input the entire voxel (3D cube) represented with its convex hull\ncoordinates, while the target network constructed by a hypernet assigns it to\nan inside or outside category. As a result our HyperCube model outperforms the\ncompeting approaches both in terms of training and inference efficiency, as\nwell as the final mesh quality.",
    "descriptor": "",
    "authors": [
      "Magdalena Proszewska",
      "Marcin Mazur",
      "Tomasz Trzci\u0144ski",
      "Przemys\u0142aw Spurek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05770"
  },
  {
    "id": "arXiv:2110.05771",
    "title": "Toward SMT-Based Refinement Types in Agda",
    "abstract": "Dependent types offer great versatility and power, but developing proofs with\nthem can be tedious and requires considerable human guidance. We propose to\nintegrate Satisfiability Modulo Theories (SMT)-based refinement types into the\ndependently-typed language Agda in an effort to ease some of the burden of\nprogramming with dependent types and combine the strengths of the two\napproaches to mechanized theorem proving.",
    "descriptor": "\nComments: Accepted for publication at HATRA 2021\n",
    "authors": [
      "Gan Shen",
      "Lindsey Kuper"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2110.05771"
  },
  {
    "id": "arXiv:2110.05772",
    "title": "Quantifying Nations Exposure to Traffic Observation and Selective  Tampering",
    "abstract": "Almost all popular Internet services are hosted in a select set of countries,\nforcing other nations to rely on international connectivity to access them. We\ninfer instances where traffic towards a large portion of a country is serviced\nby a small number of Autonomous Systems, and, therefore, may be exposed to\nobservation or selective tampering. We introduce the Country-level Transit\nInfluence (CTI) metric to quantify the significance of a given AS on the\ninternational transit service of a particular country. By studying the CTI\nvalues for the top ASes in each country, we find that 32 nations have transit\necosystems that render them particularly exposed, with traffic destined to over\n40% of their IP addresses privy to a single AS. In the nations where we are\nable to validate our findings with in-country operators, we obtain 83% accuracy\non average. In the countries we examine, CTI reveals two classes of networks\nthat play a particularly prominent role: submarine cable operators and\nstate-owned ASes.",
    "descriptor": "",
    "authors": [
      "Alexander Gamero-Garrido",
      "Esteban Carisimo",
      "Shuai Hao",
      "Bradley Huffaker",
      "Alex C. Snoeren",
      "Alberto Dainotti"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.05772"
  },
  {
    "id": "arXiv:2110.05773",
    "title": "Directionality Reinforcement Learning to Operate Multi-Agent System  without Communication",
    "abstract": "This paper establishes directionality reinforcement learning (DRL) technique\nto propose the complete decentralized multi-agent reinforcement learning method\nwhich can achieve cooperation based on each agent's learning: no communication\nand no observation. Concretely, DRL adds the direction \"agents have to learn to\nreach the farthest goal among reachable ones\" to learning agents to operate the\nagents cooperatively. Furthermore, to investigate the effectiveness of the DRL,\nthis paper compare Q-learning agent with DRL with previous learning agent in\nmaze problems. Experimental results derive that (1) DRL performs better than\nthe previous method in terms of the spending time, (2) the direction makes\nagents learn yielding action for others, and (3) DRL suggests achieving\nmultiagent learning with few costs for any number of agents.",
    "descriptor": "\nComments: 5 pages, 2 figures, accepted at AAMAS Workshop on Multiagent Optimization and Learning 2020 (OptLearnMAS 2020)\n",
    "authors": [
      "Fumito Uwano",
      "Keiki Takadama"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.05773"
  },
  {
    "id": "arXiv:2110.05775",
    "title": "Quantifying Cognitive Factors in Lexical Decline",
    "abstract": "We adopt an evolutionary view on language change in which cognitive factors\n(in addition to social ones) affect the fitness of words and their success in\nthe linguistic ecosystem. Specifically, we propose a variety of\npsycholinguistic factors -- semantic, distributional, and phonological -- that\nwe hypothesize are predictive of lexical decline, in which words greatly\ndecrease in frequency over time. Using historical data across three languages\n(English, French, and German), we find that most of our proposed factors show a\nsignificant difference in the expected direction between each curated set of\ndeclining words and their matched stable words. Moreover, logistic regression\nanalyses show that semantic and distributional factors are significant in\npredicting declining words. Further diachronic analysis reveals that declining\nwords tend to decrease in the diversity of their lexical contexts over time,\ngradually narrowing their 'ecological niches'.",
    "descriptor": "\nComments: Transactions of the Association for Computational Linguistics (TACL) 2021, 16 pages\n",
    "authors": [
      "David Francis",
      "Ella Rabinovich",
      "Farhan Samir",
      "David Mortensen",
      "Suzanne Stevenson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05775"
  },
  {
    "id": "arXiv:2110.05777",
    "title": "Large-scale Self-Supervised Speech Representation Learning for Automatic  Speaker Verification",
    "abstract": "The speech representations learned from large-scale unlabeled data have shown\nbetter generalizability than those from supervised learning and thus attract a\nlot of interest to be applied for various downstream tasks. In this paper, we\nexplore the limits of speech representations learned by different\nself-supervised objectives and datasets for automatic speaker verification\n(ASV), especially with a well-recognized SOTA ASV model, ECAPA-TDNN [1], as a\ndownstream model. The representations from all hidden layers of the pre-trained\nmodel are firstly averaged with learnable weights and then fed into the\nECAPA-TDNN as input features. The experimental results on Voxceleb dataset show\nthat the weighted average representation is significantly superior to FBank, a\nconventional handcrafted feature for ASV. Our best single system achieves\n0.564%, 0.561%, and 1.230% equal error rate (EER) on the three official trials\nof VoxCeleb1, separately. Accordingly, the ensemble system with three\npre-trained models can further improve the EER to 0.431%, 0.507% and 1.081%.\nAmong the three evaluation trials, our best system outperforms the winner\nsystem [2] of the VoxCeleb Speaker Recognition Challenge 2021 (VoxSRC2021) on\nthe VoxCeleb1-E trial.",
    "descriptor": "\nComments: submitted to ICASSP 2022\n",
    "authors": [
      "Zhengyang Chen",
      "Sanyuan Chen",
      "Yu Wu",
      "Yao Qian",
      "Chengyi Wang",
      "Shujie Liu",
      "Yanmin Qian",
      "Michael Zeng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05777"
  },
  {
    "id": "arXiv:2110.05780",
    "title": "We've had this conversation before: A Novel Approach to Measuring Dialog  Similarity",
    "abstract": "Dialog is a core building block of human natural language interactions. It\ncontains multi-party utterances used to convey information from one party to\nanother in a dynamic and evolving manner. The ability to compare dialogs is\nbeneficial in many real world use cases, such as conversation analytics for\ncontact center calls and virtual agent design.\nWe propose a novel adaptation of the edit distance metric to the scenario of\ndialog similarity. Our approach takes into account various conversation aspects\nsuch as utterance semantics, conversation flow, and the participants. We\nevaluate this new approach and compare it to existing document similarity\nmeasures on two publicly available datasets. The results demonstrate that our\nmethod outperforms the other approaches in capturing dialog flow, and is better\naligned with the human perception of conversation similarity.",
    "descriptor": "\nComments: EMNLP 2021, 9 pages\n",
    "authors": [
      "Ofer Lavi",
      "Ella Rabinovich",
      "Segev Shlomov",
      "David Boaz",
      "Inbal Ronen",
      "Ateret Anaby-Tavor"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05780"
  },
  {
    "id": "arXiv:2110.05783",
    "title": "Delay-Sensitive and Power-Efficient Quality Control of Dynamic Video  Streaming using Adaptive Super-Resolution",
    "abstract": "In a decade, the adaptive quality control of video streaming and the\nsuper-resolution (SR) technique have been deeply explored. As edge devices\nimproved to have exceptional processing capability than ever before, streaming\nusers can enhance the received image quality to allow the transmitter to\ncompress the images to save its power or pursue network efficiency. In this\nsense, this paper proposes a novel dynamic video streaming algorithm that\nadaptively compresses video chunks at the transmitter and separately enhances\nthe quality at the receiver using SR. In order to allow transmission of video\nchunks with different compression levels and control of the computation burden,\nwe present the adaptive SR network which is optimized by minimizing the\nweighted sum of losses extracted from different layer outputs. for dynamic\nvideo streaming. In addition, we jointly orchestrate video delivery and\nresource usage, and the proposed video delivery scheme balances the tradeoff\nwell among the average video quality, the queuing delay, buffering time,\ntransmit power, and computation power. Simulation results show that the\nproposed scheme pursues the quality-of-services (QoS) of the video streaming\nbetter than the adaptive quality control without the cooperation of the\ntransmitter and the receiver and the non-adaptive SR network.",
    "descriptor": "\nComments: 15 pages, 5 figures, Submitted to IEEE Transactions on Mobile Computing\n",
    "authors": [
      "Minseok Choi",
      "Won Joon Yun",
      "Joongheon Kim"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.05783"
  },
  {
    "id": "arXiv:2110.05789",
    "title": "Learning Discrete Representations via Constrained Clustering for  Effective and Efficient Dense Retrieval",
    "abstract": "Dense Retrieval (DR) has achieved state-of-the-art first-stage ranking\neffectiveness. However, the efficiency of most existing DR models is limited by\nthe large memory cost of storing dense vectors and the time-consuming nearest\nneighbor search (NNS) in vector space. Therefore, we present RepCONC, a novel\nretrieval model that learns discrete Representations via CONstrained\nClustering. RepCONC jointly trains dual-encoders and the Product Quantization\n(PQ) method to learn discrete document representations and enables fast\napproximate NNS with compact indexes. It models quantization as a constrained\nclustering process, which requires the document embeddings to be uniformly\nclustered around the quantization centroids and supports end-to-end\noptimization of the quantization method and dual-encoders. We theoretically\ndemonstrate the importance of the uniform clustering constraint in RepCONC and\nderive an efficient approximate solution for constrained clustering by reducing\nit to an instance of the optimal transport problem. Besides constrained\nclustering, RepCONC further adopts a vector-based inverted file system (IVF) to\nsupport highly efficient vector search on CPUs. Extensive experiments on two\npopular ad-hoc retrieval benchmarks show that RepCONC achieves better ranking\neffectiveness than competitive vector quantization baselines under different\ncompression ratio settings. It also substantially outperforms a wide range of\nexisting retrieval models in terms of retrieval effectiveness, memory\nefficiency, and time efficiency.",
    "descriptor": "\nComments: WSDM 2022\n",
    "authors": [
      "Jingtao Zhan",
      "Jiaxin Mao",
      "Yiqun Liu",
      "Jiafeng Guo",
      "Min Zhang",
      "Shaoping Ma"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.05789"
  },
  {
    "id": "arXiv:2110.05792",
    "title": "Aspect-driven User Preference and News Representation Learning for News  Recommendation",
    "abstract": "News recommender systems are essential for helping users to efficiently and\neffectively find out those interesting news from a large amount of news. Most\nof existing news recommender systems usually learn topic-level representations\nof users and news for recommendation, and neglect to learn more informative\naspect-level features of users and news for more accurate recommendation. As a\nresult, they achieve limited recommendation performance. Aiming at addressing\nthis deficiency, we propose a novel Aspect-driven News Recommender System\n(ANRS) built on aspect-level user preference and news representation learning.\nHere, \\textit{news aspect} is fine-grained semantic information expressed by a\nset of related words, which indicates specific aspects described by the news.\nIn ANRS, \\textit{news aspect-level encoder} and \\textit{user aspect-level\nencoder} are devised to learn the fine-grained aspect-level representations of\nuser's preferences and news characteristics respectively, which are fed into\n\\textit{click predictor} to judge the probability of the user clicking the\ncandidate news. Extensive experiments are done on the commonly used real-world\ndataset MIND, which demonstrate the superiority of our method compared with\nrepresentative and state-of-the-art methods.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Rongyao Wang",
      "Wenpeng Lu",
      "Shoujin Wang",
      "Xueping Peng",
      "Hao Wu",
      "Qian Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05792"
  },
  {
    "id": "arXiv:2110.05794",
    "title": "Information Theoretic Structured Generative Modeling",
    "abstract": "R\\'enyi's information provides a theoretical foundation for tractable and\ndata-efficient non-parametric density estimation, based on pair-wise\nevaluations in a reproducing kernel Hilbert space (RKHS). This paper extends\nthis framework to parametric probabilistic modeling, motivated by the fact that\nR\\'enyi's information can be estimated in closed-form for Gaussian mixtures.\nBased on this special connection, a novel generative model framework called the\nstructured generative model (SGM) is proposed that makes straightforward\noptimization possible, because costs are scale-invariant, avoiding high\ngradient variance while imposing less restrictions on absolute continuity,\nwhich is a huge advantage in parametric information theoretic optimization. The\nimplementation employs a single neural network driven by an orthonormal input\nappended to a single white noise source adapted to learn an infinite Gaussian\nmixture model (IMoG), which provides an empirically tractable model\ndistribution in low dimensions. To train SGM, we provide three novel\nvariational cost functions, based on R\\'enyi's second-order entropy and\ndivergence, to implement minimization of cross-entropy, minimization of\nvariational representations of $f$-divergence, and maximization of the evidence\nlower bound (conditional probability). We test the framework for estimation of\nmutual information and compare the results with the mutual information neural\nestimation (MINE), for density estimation, for conditional probability\nestimation in Markov models as well as for training adversarial networks. Our\npreliminary results show that SGM significantly improves MINE estimation in\nterms of data efficiency and variance, conventional and variational Gaussian\nmixture models, as well as the performance of generative adversarial networks.",
    "descriptor": "",
    "authors": [
      "Bo Hu",
      "Shujian Yu",
      "Jose C. Principe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.05794"
  },
  {
    "id": "arXiv:2110.05796",
    "title": "Uplink Performance of Cell-Free Massive MIMO Over Spatially Correlated  Rician Fading Channels",
    "abstract": "We consider a practical cell-free massive multiple-input-multiple-output\n(MIMO) system with multi-antenna access points (APs) and spatially correlated\nRician fading channels. The significant phase-shift of the line-of-sight\ncomponent induced by the user equipment movement is modeled randomly.\nFurthermore, we investigate the uplink spectral efficiency (SE) with maximum\nratio (MR)/local minimum mean squared error (L-MMSE) combining and optimal\nlarge-scale fading decoding based on the phase-aware MMSE, phase-aware\nelement-wise MMSE and linear MMSE (LMMSE) estimators. Then new closed-form SE\nexpressions with MR combining are derived. Numerical results validate our\nderived expressions and show that the SE benefits from the spatial correlation.\nIt is important to observe that the performance gap between L-MMSE and MR\ncombining increases with the number of antennas per AP and the SE of the LMMSE\nestimator is lower than that of other estimators due to the lack of\nphase-shifts knowledge.",
    "descriptor": "\nComments: 5 pages, 3 figures, to appear in IEEE Communications Letters\n",
    "authors": [
      "Zhe Wang",
      "Jiayi Zhang",
      "Emil Bj\u00f6rnson",
      "Bo Ai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.05796"
  },
  {
    "id": "arXiv:2110.05797",
    "title": "Zero-bias Deep Neural Network for Quickest RF Signal Surveillance",
    "abstract": "The Internet of Things (IoT) is reshaping modern society by allowing a decent\nnumber of RF devices to connect and share information through RF channels.\nHowever, such an open nature also brings obstacles to surveillance. For\nalleviation, a surveillance oracle, or a cognitive communication entity needs\nto identify and confirm the appearance of known or unknown signal sources in\nreal-time. In this paper, we provide a deep learning framework for RF signal\nsurveillance. Specifically, we jointly integrate the Deep Neural Networks\n(DNNs) and Quickest Detection (QD) to form a sequential signal surveillance\nscheme. We first analyze the latent space characteristic of neural network\nclassification models, and then we leverage the response characteristics of DNN\nclassifiers and propose a novel method to transform existing DNN classifiers\ninto performance-assured binary abnormality detectors. In this way, we\nseamlessly integrate the DNNs with the parametric quickest detection. Finally,\nwe propose an enhanced Elastic Weight Consolidation (EWC) algorithm with better\nnumerical stability for DNNs in signal surveillance systems to evolve\nincrementally, we demonstrate that the zero-bias DNN is superior to regular DNN\nmodels considering incremental learning and decision fairness. We evaluated the\nproposed framework using real signal datasets and we believe this framework is\nhelpful in developing a trustworthy IoT ecosystem.",
    "descriptor": "\nComments: This paper has been accepted for publication in IEEE IPCCC 2021. arXiv admin note: text overlap with arXiv:2105.15098\n",
    "authors": [
      "Yongxin Liu",
      "Yingjie Chen",
      "Jian Wang",
      "Shuteng Niu",
      "Dahai Liu",
      "Houbing Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.05797"
  },
  {
    "id": "arXiv:2110.05798",
    "title": "Adapting TTS models For New Speakers using Transfer Learning",
    "abstract": "Training neural text-to-speech (TTS) models for a new speaker typically\nrequires several hours of high quality speech data. Prior works on voice\ncloning attempt to address this challenge by adapting pre-trained multi-speaker\nTTS models for a new voice, using a few minutes of speech data of the new\nspeaker. However, publicly available large multi-speaker datasets are often\nnoisy, thereby resulting in TTS models that are not suitable for use in\nproducts. We address this challenge by proposing transfer-learning guidelines\nfor adapting high quality single-speaker TTS models for a new speaker, using\nonly a few minutes of speech data. We conduct an extensive study using\ndifferent amounts of data for a new speaker and evaluate the synthesized speech\nin terms of naturalness and voice/style similarity to the target speaker. We\nfind that fine-tuning a single-speaker TTS model on just 30 minutes of data,\ncan yield comparable performance to a model trained from scratch on more than\n27 hours of data for both male and female target speakers.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Paarth Neekhara",
      "Jason Li",
      "Boris Ginsburg"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05798"
  },
  {
    "id": "arXiv:2110.05801",
    "title": "A Simple Way to Verify Linearizability of Concurrent Stacks",
    "abstract": "Linearizability is a commonly accepted correctness criterion for concurrent\ndata structures. However, verifying linearizability of highly concurrent data\nstructures is still a challenging task. In this paper, we present a simple and\ncomplete proof technique for verifying linearizability of concurrent stacks.\nOur proof technique reduces linearizability of concurrent stacks to\nestablishing a set of conditions. These conditions are based on the\nhappened-before order of operations, intuitively express the LIFO semantics and\ncan be proved by simple arguments. Designers of concurrent data structures can\neasily and quickly learn to use the proof technique. We have successfully\napplied the method to several challenging concurrent stacks: the TS stack, the\nHSY stack, and the FA stack, etc.",
    "descriptor": "",
    "authors": [
      "Tangliu Wen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.05801"
  },
  {
    "id": "arXiv:2110.05802",
    "title": "Codabench: Flexible, Easy-to-Use and Reproducible Benchmarking for  Everyone",
    "abstract": "Obtaining standardized crowdsourced benchmark of computational methods is a\nmajor issue in scientific communities. Dedicated frameworks enabling fair\ncontinuous benchmarking in a unified environment are yet to be developed. Here\nwe introduce Codabench, an open-sourced, community-driven platform for\nbenchmarking algorithms or software agents versus datasets or tasks. A public\ninstance of Codabench is open to everyone, free of charge, and allows benchmark\norganizers to compare fairly submissions, under the same setting (software,\nhardware, data, algorithms), with custom protocols and data formats. Codabench\nhas unique features facilitating the organization of benchmarks flexibly,\neasily and reproducibly. Firstly, it supports code submission and data\nsubmission for testing on dedicated compute workers, which can be supplied by\nthe benchmark organizers. This makes the system scalable, at low cost for the\nplatform providers. Secondly, Codabench benchmarks are created from\nself-contained bundles, which are zip files containing a full description of\nthe benchmark in a configuration file (following a well-defined schema),\ndocumentation pages, data, ingestion and scoring programs, making benchmarks\nreusable and portable. The Codabench documentation includes many examples of\nbundles that can serve as templates. Thirdly, Codabench uses dockers for each\ntask's running environment to make results reproducible. Codabench has been\nused internally and externally with more than 10 applications during the past 6\nmonths. As illustrative use cases, we introduce 4 diverse benchmarks covering\nGraph Machine Learning, Cancer Heterogeneity, Clinical Diagnosis and\nReinforcement Learning.",
    "descriptor": "",
    "authors": [
      "Zhen Xu",
      "Huan Zhao",
      "Wei-Wei Tu",
      "Magali Richard",
      "Sergio Escalera",
      "Isabelle Guyon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.05802"
  },
  {
    "id": "arXiv:2110.05804",
    "title": "Cost of space-time formulations: a study on the performance of direct  and iterative solvers on space-time formulations versus time-marching schemes",
    "abstract": "We focus on finite element method computations for time-dependent problems.\nWe prove that the computational cost of the space-time formulation is higher\nthan the cost of the time-marching schemes. This applies to both direct and\niterative solvers. It concerns both uniform and adaptive grids. The only\nexception from this rule is the h adaptive space-time simulation of the\ntraveling point object, resulting in refinements towards their trajectory in\nthe space-time domain. However, if this object has wings and the mesh\nrefinements capture the shape of the wing (if the mesh refinements capture any\ntwo-dimensional manifold) the space-time formulation is more expensive than\ntime-marching schemes. We also show that the cost of static condensation for\nthe higher-order finite element method with hierarchical basis functions is\nalways higher for space-time formulations. Numerical experiments with Octave\nconfirm our theoretical findings.",
    "descriptor": "\nComments: 39 pages, 17 figures, 9 tables\n",
    "authors": [
      "Marcin Skotniczny",
      "Anna Paszynska",
      "Maciej Paszynski"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05804"
  },
  {
    "id": "arXiv:2110.05805",
    "title": "Real-time Skeletonization for Sketch-based Modeling",
    "abstract": "Skeleton creation is an important phase in the character animation pipeline.\nHowever, handcrafting skeleton takes extensive labor time and domain knowledge.\nAutomatic skeletonization provides a solution. However, most of the current\napproaches are far from real-time and lack the flexibility to control the\nskeleton complexity. In this paper, we present an efficient skeletonization\nmethod, which can be seamlessly integrated into the sketch-based modeling\nprocess in real-time. The method contains three steps: local sub-skeleton\nextraction; sub-skeleton connection; and global skeleton refinement. Firstly,\nthe local skeleton is extracted from the processed polygon stroke and forms a\nsubpart along with the sub-mesh. Then, local sub-skeletons are connected\naccording to the intersecting relationships and the modeling sequence of\nsubparts. Lastly, a global refinement method is proposed to give users\ncoarse-to-fine control on the connected skeleton. We demonstrate the\neffectiveness of our method on a variety of examples created by both novices\nand professionals.",
    "descriptor": "\nComments: Shape Modeling International 2021\n",
    "authors": [
      "Jing Ma",
      "Jin Wang",
      "Jituo Li",
      "Dongliang Zhang"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computational Geometry (cs.CG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.05805"
  },
  {
    "id": "arXiv:2110.05807",
    "title": "Optimizing Ranking Systems Online as Bandits",
    "abstract": "Ranking system is the core part of modern retrieval and recommender systems,\nwhere the goal is to rank candidate items given user contexts. Optimizing\nranking systems online means that the deployed system can serve user requests,\ne.g., queries in the web search, and optimize the ranking policy by learning\nfrom user interactions, e.g., clicks. Bandit is a general online learning\nframework and can be used in our optimization task. However, due to the unique\nfeatures of ranking, there are several challenges in designing bandit\nalgorithms for ranking system optimization. In this dissertation, we study and\npropose solutions for four challenges in optimizing ranking systems online:\neffectiveness, safety, nonstationarity, and diversification. First, the\neffectiveness is related to how fast the algorithm learns from interactions. We\nstudy the effective online ranker evaluation task and propose the MergeDTS\nalgorithm to solve the problem effectively. Second, the deployed algorithm\nshould be safe, which means the algorithm only displays reasonable content to\nuser requests. To solve the safe online learning to rank problem, we propose\nthe BubbleRank algorithm. Third, as users change their preferences constantly,\nthe algorithm should handle the nonstationarity. We formulate this\nnonstationary online learning to rank problem as cascade non-stationary bandits\nand propose CascadeDUCB and CascadeSWUCB algorithms to solve the problem.\nFinally, the contents in ranked lists should be diverse. We consider the\nresults diversification task and propose the CascadeHybird algorithm that\nconsiders both the item relevance and results diversification when learning\nfrom user interactions.",
    "descriptor": "\nComments: PhD Thesis of Chang Li defended at the University of Amsterdam on March 4th 2021\n",
    "authors": [
      "Chang Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05807"
  },
  {
    "id": "arXiv:2110.05808",
    "title": "Worst-case Delay Bounds in Time-Sensitive Networks with Packet  Replication and Elimination",
    "abstract": "Packet replication and elimination functions are used by time-sensitive\nnetworks (as in the context of IEEE TSN and IETF DetNet) to increase the\nreliability of the network. Packets are replicated onto redundant paths by a\nreplication function. Later the paths merge again and an elimination function\nremoves the duplicates. This redundancy scheme has an effect on the timing\nbehavior of time-sensitive networks and many challenges arise from conducting\ntiming analyses. The replication can induce a burstiness increase along the\npaths of replicates, as well as packet mis-ordering that could increase the\ndelays in the crossed bridges or routers. The induced packet mis-ordering could\nalso negatively affect the interactions between the redundancy and scheduling\nmechanisms such as traffic regulators (as with per-flow regulators and\ninterleaved regulators, implemented by TSN asynchronous traffic shaping). Using\nthe network calculus framework, we provide a method of worst-case timing\nanalysis for time-sensitive networks that implement redundancy mechanisms in\nthe general use case, i.e., at end-devices and/or intermediate nodes. We first\nprovide a network calculus toolbox for bounding the burstiness increase and the\namount of reordering caused by the elimination function of duplicate packets.\nWe then analyze the interactions with traffic regulators and show that their\nshaping-for-free property does not hold when placed after a packet elimination\nfunction. We provide a bound for the delay penalty when using per-flow\nregulators and prove that the penalty is not bounded with interleaved\nregulators. Finally, we use an industrial use-case to show the applicability\nand the benefits of our findings.",
    "descriptor": "\nComments: 32 pages, 38 figures, 13 tables, submitted\n",
    "authors": [
      "Ludovic Thomas",
      "Ahlem Mifdaoui",
      "Jean-Yves Le Boudec"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.05808"
  },
  {
    "id": "arXiv:2110.05809",
    "title": "Couple Learning: Mean Teacher method with pseudo-labels improves  semi-supervised deep learning results",
    "abstract": "The recently proposed Mean Teacher has achieved state-of-the-art results in\nseveral semi-supervised learning benchmarks. The Mean Teacher method can\nexploit large-scale unlabeled data in a self-ensembling manner. In this paper,\nan effective Couple Learning method based on a well-trained model and a Mean\nTeacher model is proposed. The proposed pseudo-labels generated model (PLG) can\nincrease strongly-labeled data and weakly-labeled data to improve performance\nof the Mean Teacher method. The Mean Teacher method can suppress noise in\npseudo-labels data. The Couple Learning method can extract more information in\nthe compound training data. These experimental results on Task 4 of the\nDCASE2020 challenge demonstrate the superiority of the proposed method,\nachieving about 39.18% F1-score on public eval set, outperforming 37.12% of the\nbaseline system by a significant margin.",
    "descriptor": "\nComments: ICASSP2022\n",
    "authors": [
      "Rui Tao",
      "Long Yan",
      "Kazushige Ouchi",
      "Xiangdong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.05809"
  },
  {
    "id": "arXiv:2110.05810",
    "title": "Open Player Modeling: Empowering Players through Data Transparency",
    "abstract": "Data is becoming an important central point for making design decisions for\nmost software. Game development is not an exception. As data-driven methods and\nsystems start to populate these environments, a good question is: can we make\nmodels developed from this data transparent to users? In this paper, we\nsynthesize existing work from the Intelligent User Interface and Learning\nScience research communities, where they started to investigate the potential\nof making such data and models available to users. We then present a new area\nexploring this question, which we call Open Player Modeling, as an emerging\nresearch area. We define the design space of Open Player Models and present\nexciting open problems that the games research community can explore. We\nconclude the paper with a case study and discuss the potential value of this\napproach.",
    "descriptor": "",
    "authors": [
      "Jichen Zhu",
      "Magy Seif El-Nasr"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05810"
  },
  {
    "id": "arXiv:2110.05812",
    "title": "Satellite Image Semantic Segmentation",
    "abstract": "In this paper, we propose a method for the automatic semantic segmentation of\nsatellite images into six classes (sparse forest, dense forest, moor,\nherbaceous formation, building, and road). We rely on Swin Transformer\narchitecture and build the dataset from IGN open data. We report quantitative\nand qualitative segmentation results on this dataset and discuss strengths and\nlimitations. The dataset and the trained model are made publicly available.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Eric Gu\u00e9rin",
      "Killian Oechslin",
      "Christian Wolf",
      "Beno\u00eet Martinez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.05812"
  },
  {
    "id": "arXiv:2110.05815",
    "title": "Covariance-Based Joint Device Activity and Delay Detection in  Asynchronous mMTC",
    "abstract": "In this letter, we study the joint device activity and delay detection\nproblem in asynchronous massive machine-type communications (mMTC), where all\nactive devices asynchronously transmit their preassigned preamble sequences to\nthe base station (BS) for device identification and delay detection. We first\nformulate this joint detection problem as a maximum likelihood estimation\nproblem, which depends on the received signal only through its sample\ncovariance, and then propose efficient coordinate descent type of algorithms to\nsolve the formulated problem. Our proposed covariance-based approach is sharply\ndifferent from the existing compressed sensing (CS) approach for the same\nproblem. Numerical results show that our proposed covariance-based approach\nsignificantly outperforms the CS approach in terms of the detection performance\nsince our proposed approach can make better use of the BS antennas than the CS\napproach.",
    "descriptor": "\nComments: Submitted to IEEE for possible publication\n",
    "authors": [
      "Zhaorui Wang",
      "Ya-Feng Liu",
      "Liang Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.05815"
  },
  {
    "id": "arXiv:2110.05819",
    "title": "Event-Based high-speed low-latency fiducial marker tracking",
    "abstract": "Motion and dynamic environments, especially under challenging lighting\nconditions, are still an open issue for robust robotic applications. In this\npaper, we propose an end-to-end pipeline for real-time, low latency, 6\ndegrees-of-freedom pose estimation of fiducial markers. Instead of achieving a\npose estimation through a conventional frame-based approach, we employ the\nhigh-speed abilities of event-based sensors to directly refine the spatial\ntransformation, using consecutive events. Furthermore, we introduce a novel\ntwo-way verification process for detecting tracking errors by backtracking the\nestimated pose, allowing us to evaluate the quality of our tracking. This\napproach allows us to achieve pose estimation at a rate up to 156~kHz, while\nonly relying on CPU resources. The average end-to-end latency of our method is\n3~ms. Experimental results demonstrate outstanding potential for robotic tasks,\nsuch as visual servoing in fast action-perception loops.",
    "descriptor": "",
    "authors": [
      "Adam Loch",
      "Germain Haessig",
      "Markus Vincze"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.05819"
  },
  {
    "id": "arXiv:2110.05820",
    "title": "CoarSAS2hvec: Heterogeneous Information Network Embedding with Balanced  Network Sampling",
    "abstract": "Heterogeneous information network (HIN) embedding aims to find the\nrepresentations of nodes that preserve the proximity between entities of\ndifferent nature. A family of approaches that are wildly adopted applies random\nwalk to generate a sequence of heterogeneous context, from which the embedding\nis learned. However, due to the multipartite graph structure of HIN, hub nodes\ntend to be over-represented in the sampled sequence, giving rise to imbalanced\nsamples of the network. Here we propose a new embedding method CoarSAS2hvec.\nThe self-avoid short sequence sampling with the HIN coarsening procedure\n(CoarSAS) is utilized to better collect the rich information in HIN. An\noptimized loss function is used to improve the performance of the HIN structure\nembedding. CoarSAS2hvec outperforms nine other methods in two different tasks\non four real-world data sets. The ablation study confirms that the samples\ncollected by CoarSAS contain richer information of the network compared with\nthose by other methods, which is characterized by a higher information entropy.\nHence, the traditional loss function applied to samples by CoarSAS can also\nyield improved results. Our work addresses a limitation of the\nrandom-walk-based HIN embedding that has not been emphasized before, which can\nshed light on a range of problems in HIN analyses.",
    "descriptor": "",
    "authors": [
      "Ling Zhan",
      "Tao Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05820"
  },
  {
    "id": "arXiv:2110.05828",
    "title": "An Empirical Study of Configuration Mismatches in Linux",
    "abstract": "Ideally the variability of a product line is represented completely and\ncorrectly by its variability model. However, in practice additional variability\nis often represented on the level of the build system or in the code. Such a\nsituation may lead to inconsistencies, where the actually realized variability\ndoes not fully correspond to the one described by the variability model. In\nthis paper we focus on configuration mismatches, i.e., cases where the\neffective variability differs from the variability as it is represented by the\nvariability model. While previous research has already shown that these\nsituations still exist even today in well-analyzed product lines like Linux, so\nfar it was unclear under what circumstances such issues occur in reality. In\nparticular, it is open what types of configuration mismatches occur and how\nsevere they are. Here, our contribution is to close this gap by presenting a\ndetailed manual analysis of 80 configuration mismatches in the Linux 4.4.1\nkernel and assess their criticality. We identify various categories of\nconfiguration issues and show that about two-thirds of the configuration\nmismatches may actually lead to kernel misconfigurations.",
    "descriptor": "",
    "authors": [
      "Sascha El-Sharkawy",
      "Adam Krafczyk",
      "Klaus Schmid"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.05828"
  },
  {
    "id": "arXiv:2110.05833",
    "title": "Predictive design of impact absorbers for mitigating resonances of  flexible structures using a semi-analytical approach",
    "abstract": "Analytical conditions are available for the optimum design of impact\nabsorbers for the case where the host structure is well described as rigid\nbody. Accordingly, the analysis relies on the assumption that the impacts cause\nimmediate dissipation in the contact region, which is modeled in terms of a\nknown coefficient of restitution. When a flexible host structure is considered\ninstead, the impact absorber not only dissipates energy at the time instances\nof impact, but it inflicts nonlinear energy scattering between structural\nmodes. Hence, it is crucial to account for such nonlinear energy transfers\nyielding energy redistribution within the modal space of the structure. In the\npresent work, we develop a design approach for reonantly-driven, flexible host\nstructures. We demonstrate decoupling of the time scales of the impact and the\nresonant vibration. On the long time scale, the dynamics can be properly\nreduced to the fundamental harmonic of the resonant mode. A light impact\nabsorber responds to this enforced motion, and we recover the Slow Invariant\nManifold of the dynamics for the regime of two impacts per period. On the short\ntime scale, the contact mechanics and elasto-dynamics must be finely resolved.\nWe show that it is sufficient to run a numerical simulation of a single impact\nevent with adequate pre-impact velocity. From this simulation, we derive a\nmodal coefficient of restitution and the properties of the contact force pulse,\nneeded to approximate the behavior on the long time scale. We establish that\nthe design problem can be reduced to four dimensionless parameters and\ndemonstrate the approach for the numerical example of a cantilevered beam with\nan impact absorber. We conclude that the proposed semi-analytical procedure\nenables deep qualitative understanding of the problem and, at the same time,\nyields a quantitatively accurate prediction of the optimum design.",
    "descriptor": "\nComments: The final version of this article is available online at this https URL\n",
    "authors": [
      "Timo Theurich",
      "Alexander F. Vakakis",
      "Malte Krack"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2110.05833"
  },
  {
    "id": "arXiv:2110.05835",
    "title": "Boundary integral equation methods for the solution of scattering and  transmission 2D elastodynamic problems",
    "abstract": "We introduce and analyze various Regularized Combined Field Integral\nEquations (CFIER) formulations of time-harmonic Navier equations in media with\npiece-wise constant material properties. These formulations can be derived\nsystematically starting from suitable coercive approximations of\nDirichlet-to-Neumann operators (DtN), and we present a periodic\npseudodifferential calculus framework within which the well posedness of CIER\nformulations can be established. We also use the DtN approximations to derive\nand analyze Optimized Schwarz (OS) methods for the solution of elastodynamics\ntransmission problems. The pseudodifferential calculus we develop in this paper\nrelies on careful singularity splittings of the kernels of Navier boundary\nintegral operators which is also the basis of high-order Nystr\\\"om quadratures\nfor their discretizations. Based on these high-order discretizations we\ninvestigate the rate of convergence of iterative solvers applied to CFIER and\nOS formulations of scattering and transmission problems. We present a variety\nof numerical results that illustrate that the CFIER methodology leads to\nimportant computational savings over the classical CFIE one, whenever iterative\nsolvers are used for the solution of the ensuing discretized boundary integral\nequations. Finally, we show that the OS methods are competitive in the\nhigh-frequency high-contrast regime.",
    "descriptor": "",
    "authors": [
      "Victor Dominguez",
      "Catalin Turc"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05835"
  },
  {
    "id": "arXiv:2110.05836",
    "title": "AVoE: A Synthetic 3D Dataset on Understanding Violation of Expectation  for Artificial Cognition",
    "abstract": "Recent work in cognitive reasoning and computer vision has engendered an\nincreasing popularity for the Violation-of-Expectation (VoE) paradigm in\nsynthetic datasets. Inspired by work in infant psychology, researchers have\nstarted evaluating a model's ability to discriminate between expected and\nsurprising scenes as a sign of its reasoning ability. Existing VoE-based 3D\ndatasets in physical reasoning only provide vision data. However, current\ncognitive models of physical reasoning by psychologists reveal infants create\nhigh-level abstract representations of objects and interactions. Capitalizing\non this knowledge, we propose AVoE: a synthetic 3D VoE-based dataset that\npresents stimuli from multiple novel sub-categories for five event categories\nof physical reasoning. Compared to existing work, AVoE is armed with\nground-truth labels of abstract features and rules augmented to vision data,\npaving the way for high-level symbolic predictions in physical reasoning tasks.",
    "descriptor": "",
    "authors": [
      "Arijit Dasgupta",
      "Jiafei Duan",
      "Marcelo H. Ang Jr",
      "Cheston Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05836"
  },
  {
    "id": "arXiv:2110.05838",
    "title": "Balancing Average and Worst-case Accuracy in Multitask Learning",
    "abstract": "When training and evaluating machine learning models on a large number of\ntasks, it is important to not only look at average task accuracy -- which may\nbe biased by easy or redundant tasks -- but also worst-case accuracy (i.e. the\nperformance on the task with the lowest accuracy). In this work, we show how to\nuse techniques from the distributionally robust optimization (DRO) literature\nto improve worst-case performance in multitask learning. We highlight several\nfailure cases of DRO when applied off-the-shelf and present an improved method,\nLookahead-DRO (L-DRO), which mitigates these issues. The core idea of L-DRO is\nto anticipate the interaction between tasks during training in order to choose\na dynamic re-weighting of the various task losses, which will (i) lead to\nminimal worst-case loss and (ii) train on as many tasks as possible. After\ndemonstrating the efficacy of L-DRO on a small controlled synthetic setting, we\nevaluate it on two realistic benchmarks: a multitask version of the CIFAR-100\nimage classification dataset and a large-scale multilingual language modeling\nexperiment. Our empirical results show that L-DRO achieves a better trade-off\nbetween average and worst-case accuracy with little computational overhead\ncompared to several strong baselines.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Paul Michel",
      "Sebastian Ruder",
      "Dani Yogatama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05838"
  },
  {
    "id": "arXiv:2110.05839",
    "title": "PLNet: Plane and Line Priors for Unsupervised Indoor Depth Estimation",
    "abstract": "Unsupervised learning of depth from indoor monocular videos is challenging as\nthe artificial environment contains many textureless regions. Fortunately, the\nindoor scenes are full of specific structures, such as planes and lines, which\nshould help guide unsupervised depth learning. This paper proposes PLNet that\nleverages the plane and line priors to enhance the depth estimation. We first\nrepresent the scene geometry using local planar coefficients and impose the\nsmoothness constraint on the representation. Moreover, we enforce the planar\nand linear consistency by randomly selecting some sets of points that are\nprobably coplanar or collinear to construct simple and effective consistency\nlosses. To verify the proposed method's effectiveness, we further propose to\nevaluate the flatness and straightness of the predicted point cloud on the\nreliable planar and linear regions. The regularity of these regions indicates\nquality indoor reconstruction. Experiments on NYU Depth V2 and ScanNet show\nthat PLNet outperforms existing methods. The code is available at\n\\url{https://github.com/HalleyJiang/PLNet}.",
    "descriptor": "\nComments: Accepted by 3DV 2021\n",
    "authors": [
      "Hualie Jiang",
      "Laiyan Ding",
      "Junjie Hu",
      "Rui Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05839"
  },
  {
    "id": "arXiv:2110.05840",
    "title": "A bridge between features and evidence for binary attribute-driven  perfect privacy",
    "abstract": "Attribute-driven privacy aims to conceal a single user's attribute, contrary\nto anonymisation that tries to hide the full identity of the user in some data.\nWhen the attribute to protect from malicious inferences is binary, perfect\nprivacy requires the log-likelihood-ratio to be zero resulting in no\nstrength-of-evidence. This work presents an approach based on normalizing flow\nthat maps a feature vector into a latent space where the strength-of-evidence,\nrelated to the binary attribute, and an independent residual are disentangled.\nIt can be seen as a non-linear discriminant analysis where the mapping is\ninvertible allowing generation by mapping the latent variable back to the\noriginal space. This framework allows to manipulate the log-likelihood-ratio of\nthe data and thus to set it to zero for privacy. We show the applicability of\nthe approach on an attribute-driven privacy task where the sex information is\nremoved from speaker embeddings. Results on VoxCeleb2 dataset show the\nefficiency of the method that outperforms in terms of privacy and utility our\nprevious experiments based on adversarial disentanglement.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Paul-Gauthier No\u00e9",
      "Andreas Nautsch",
      "Driss Matrouf",
      "Pierre-Michel Bousquet",
      "Jean-Fran\u00e7ois Bonastre"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05840"
  },
  {
    "id": "arXiv:2110.05841",
    "title": "Relative Molecule Self-Attention Transformer",
    "abstract": "Self-supervised learning holds promise to revolutionize molecule property\nprediction - a central task to drug discovery and many more industries - by\nenabling data efficient learning from scarce experimental data. Despite\nsignificant progress, non-pretrained methods can be still competitive in\ncertain settings. We reason that architecture might be a key bottleneck. In\nparticular, enriching the backbone architecture with domain-specific inductive\nbiases has been key for the success of self-supervised learning in other\ndomains. In this spirit, we methodologically explore the design space of the\nself-attention mechanism tailored to molecular data. We identify a novel\nvariant of self-attention adapted to processing molecules, inspired by the\nrelative self-attention layer, which involves fusing embedded graph and\ndistance relationships between atoms. Our main contribution is Relative\nMolecule Attention Transformer (R-MAT): a novel Transformer-based model based\non the developed self-attention layer that achieves state-of-the-art or very\ncompetitive results across a~wide range of molecule property prediction tasks.",
    "descriptor": "",
    "authors": [
      "\u0141ukasz Maziarka",
      "Dawid Majchrowski",
      "Tomasz Danel",
      "Piotr Gai\u0144ski",
      "Jacek Tabor",
      "Igor Podolak",
      "Pawe\u0142 Morkisz",
      "Stanis\u0142aw Jastrz\u0119bski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05841"
  },
  {
    "id": "arXiv:2110.05842",
    "title": "Across-Task Neural Architecture Search via Meta Learning",
    "abstract": "Adequate labeled data and expensive compute resources are the prerequisites\nfor the success of neural architecture search(NAS). It is challenging to apply\nNAS in meta-learning scenarios with limited compute resources and data. In this\npaper, an across-task neural architecture search (AT-NAS) is proposed to\naddress the problem through combining gradient-based meta-learning with\nEA-based NAS to learn over the distribution of tasks. The supernet is learned\nover an entire set of tasks by meta-learning its weights. Architecture encodes\nof subnets sampled from the supernet are iteratively adapted by evolutionary\nalgorithms while simultaneously searching for a task-sensitive meta-network.\nSearched meta-network can be adapted to a novel task via a few learning steps\nand only costs a little search time. Empirical results show that AT-NAS\nsurpasses the related approaches on few-shot classification accuracy. The\nperformance of AT-NAS on classification benchmarks is comparable to that of\nmodels searched from scratch, by adapting the architecture in less than an hour\nfrom a 5-GPU-day pretrained meta-network.",
    "descriptor": "",
    "authors": [
      "Jingtao Rong",
      "Xinyi Yu",
      "Mingyang Zhang",
      "Linlin Ou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05842"
  },
  {
    "id": "arXiv:2110.05843",
    "title": "Fast Block Linear System Solver Using Q-Learning Schduling for Unified  Dynamic Power System Simulations",
    "abstract": "We present a fast block direct solver for the unified dynamic simulations of\npower systems. This solver uses a novel Q-learning based method for task\nscheduling. Unified dynamic simulations of power systems represent a method in\nwhich the electric-mechanical transient, medium-term and long-term dynamic\nphenomena are organically united. Due to the high rank and large numbers in\nsolving, fast solution of these equations is the key to speeding up the\nsimulation. The sparse systems of simulation contain complex nested block\nstructure, which could be used by the solver to speed up. For the scheduling of\nblocks and frontals in the solver, we use a learning based task-tree scheduling\ntechnique in the framework of Markov Decision Process. That is, we could learn\noptimal scheduling strategies by offline training on many sample matrices. Then\nfor any systems, the solver would get optimal task partition and scheduling on\nthe learned model. Our learning-based algorithm could help improve the\nperformance of sparse solver, which has been verified in some numerical\nexperiments. The simulation on some large power systems shows that our solver\nis 2-6 times faster than KLU, which is the state-of-the-art sparse solver for\ncircuit simulation problems.",
    "descriptor": "\nComments: 8 pages, 3 figures. arXiv admin note: substantial text overlap with arXiv:2109.14929\n",
    "authors": [
      "Yingshi Chen",
      "Xinli Song",
      "HanYang Dai",
      "Tao Liu",
      "Wuzhi Zhong",
      "Guoyang Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Software (cs.MS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05843"
  },
  {
    "id": "arXiv:2110.05847",
    "title": "Evaluation of Abstractive Summarisation Models with Machine Translation  in Deliberative Processes",
    "abstract": "We present work on summarising deliberative processes for non-English\nlanguages. Unlike commonly studied datasets, such as news articles, this\ndeliberation dataset reflects difficulties of combining multiple narratives,\nmostly of poor grammatical quality, in a single text. We report an extensive\nevaluation of a wide range of abstractive summarisation models in combination\nwith an off-the-shelf machine translation model. Texts are translated into\nEnglish, summarised, and translated back to the original language. We obtain\npromising results regarding the fluency, consistency and relevance of the\nsummaries produced. Our approach is easy to implement for many languages for\nproduction purposes by simply changing the translation model.",
    "descriptor": "\nComments: 8 pages, presented in EMNLP 2021 - New Frontiers in Summarization Workshop\n",
    "authors": [
      "M. Arana-Catania",
      "Rob Procter",
      "Yulan He",
      "Maria Liakata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05847"
  },
  {
    "id": "arXiv:2110.05848",
    "title": "Fine-Grained Adversarial Semi-supervised Learning",
    "abstract": "In this paper we exploit Semi-Supervised Learning (SSL) to increase the\namount of training data to improve the performance of Fine-Grained Visual\nCategorization (FGVC). This problem has not been investigated in the past in\nspite of prohibitive annotation costs that FGVC requires. Our approach\nleverages unlabeled data with an adversarial optimization strategy in which the\ninternal features representation is obtained with a second-order pooling model.\nThis combination allows to back-propagate the information of the parts,\nrepresented by second-order pooling, onto unlabeled data in an adversarial\ntraining setting. We demonstrate the effectiveness of the combined use by\nconducting experiments on six state-of-the-art fine-grained datasets, which\ninclude Aircrafts, Stanford Cars, CUB-200-2011, Oxford Flowers, Stanford Dogs,\nand the recent Semi-Supervised iNaturalist-Aves. Experimental results clearly\nshow that our proposed method has better performance than the only previous\napproach that examined this problem; it also obtained higher classification\naccuracy with respect to the supervised learning methods with which we\ncompared.",
    "descriptor": "",
    "authors": [
      "Daniele Mugnai",
      "Federico Pernici",
      "Francesco Turchini",
      "Alberto Del Bimbo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05848"
  },
  {
    "id": "arXiv:2110.05849",
    "title": "Sharing FANCI Features: A Privacy Analysis of Feature Extraction for DGA  Detection",
    "abstract": "The goal of Domain Generation Algorithm (DGA) detection is to recognize\ninfections with bot malware and is often done with help of Machine Learning\napproaches that classify non-resolving Domain Name System (DNS) traffic and are\ntrained on possibly sensitive data. In parallel, the rise of privacy research\nin the Machine Learning world leads to privacy-preserving measures that are\ntightly coupled with a deep learning model's architecture or training routine,\nwhile non deep learning approaches are commonly better suited for the\napplication of privacy-enhancing methods outside the actual classification\nmodule. In this work, we aim to measure the privacy capability of the feature\nextractor of feature-based DGA detector FANCI (Feature-based Automated Nxdomain\nClassification and Intelligence). Our goal is to assess whether a data-rich\nadversary can learn an inverse mapping of FANCI's feature extractor and thereby\nreconstruct domain names from feature vectors. Attack success would pose a\nprivacy threat to sharing FANCI's feature representation, while the opposite\nwould enable this representation to be shared without privacy concerns. Using\nthree real-world data sets, we train a recurrent Machine Learning model on the\nreconstruction task. Our approaches result in poor reconstruction performance\nand we attempt to back our findings with a mathematical review of the feature\nextraction process. We thus reckon that sharing FANCI's feature representation\ndoes not constitute a considerable privacy leakage.",
    "descriptor": "\nComments: Accepted at The Sixth International Conference on Cyber-Technologies and Cyber-Systems (CYBER 2021)\n",
    "authors": [
      "Benedikt Holmes",
      "Arthur Drichel",
      "Ulrike Meyer"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05849"
  },
  {
    "id": "arXiv:2110.05850",
    "title": "Improving Binary Neural Networks through Fully Utilizing Latent Weights",
    "abstract": "Binary Neural Networks (BNNs) rely on a real-valued auxiliary variable W to\nhelp binary training. However, pioneering binary works only use W to accumulate\ngradient updates during backward propagation, which can not fully exploit its\npower and may hinder novel advances in BNNs. In this work, we explore the role\nof W in training besides acting as a latent variable. Notably, we propose to\nadd W into the computation graph, making it perform as a real-valued feature\nextractor to aid the binary training. We make different attempts on how to\nutilize the real-valued weights and propose a specialized supervision.\nVisualization experiments qualitatively verify the effectiveness of our\napproach in making it easier to distinguish between different categories.\nQuantitative experiments show that our approach outperforms current\nstate-of-the-arts, further closing the performance gap between floating-point\nnetworks and BNNs. Evaluation on ImageNet with ResNet-18 (Top-1 63.4%),\nResNet-34 (Top-1 67.0%) achieves new state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Weixiang Xu",
      "Qiang Chen",
      "Xiangyu He",
      "Peisong Wang",
      "Jian Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05850"
  },
  {
    "id": "arXiv:2110.05853",
    "title": "Joint Learning On The Hierarchy Representation for Fine-Grained Human  Action Recognition",
    "abstract": "Fine-grained human action recognition is a core research topic in computer\nvision. Inspired by the recently proposed hierarchy representation of\nfine-grained actions in FineGym and SlowFast network for action recognition, we\npropose a novel multi-task network which exploits the FineGym hierarchy\nrepresentation to achieve effective joint learning and prediction for\nfine-grained human action recognition. The multi-task network consists of three\npathways of SlowOnly networks with gradually increased frame rates for events,\nsets and elements of fine-grained actions, followed by our proposed integration\nlayers for joint learning and prediction. It is a two-stage approach, where it\nfirst learns deep feature representation at each hierarchical level, and is\nfollowed by feature encoding and fusion for multi-task learning. Our empirical\nresults on the FineGym dataset achieve a new state-of-the-art performance, with\n91.80% Top-1 accuracy and 88.46% mean accuracy for element actions, which are\n3.40% and 7.26% higher than the previous best results.",
    "descriptor": "\nComments: Camera ready for IEEE ICIP 2021\n",
    "authors": [
      "Mei Chee Leong",
      "Hui Li Tan",
      "Haosong Zhang",
      "Liyuan Li",
      "Feng Lin",
      "Joo Hwee Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05853"
  },
  {
    "id": "arXiv:2110.05855",
    "title": "MoRS: An Approximate Fault Modelling Framework for Reduced-Voltage SRAMs",
    "abstract": "On-chip memory (usually based on Static RAMs-SRAMs) are crucial components\nfor various computing devices including heterogeneous devices, e.g., GPUs,\nFPGAs, ASICs to achieve high performance. Modern workloads such as Deep Neural\nNetworks (DNNs) running on these heterogeneous fabrics are highly dependent on\nthe on-chip memory architecture for efficient acceleration. Hence, improving\nthe energy-efficiency of such memories directly leads to an efficient system.\nOne of the common methods to save energy is undervolting i.e., supply voltage\nunderscaling below the nominal level. Such systems can be safely undervolted\nwithout incurring faults down to a certain voltage limit. This safe range is\nalso called voltage guardband. However, reducing voltage below the guardband\nlevel without decreasing frequency causes timing-based faults.\nIn this paper, we propose MoRS, a framework that generates the first\napproximate undervolting fault model using real faults extracted from\nexperimental undervolting studies on SRAMs to build the model. We inject the\nfaults generated by MoRS into the on-chip memory of the DNN accelerator to\nevaluate the resilience of the system under the test. MoRS has the advantage of\nsimplicity without any need for high-time overhead experiments while being\naccurate enough in comparison to a fully randomly-generated fault injection\napproach. We evaluate our experiment in popular DNN workloads by mapping\nweights to SRAMs and measure the accuracy difference between the output of the\nMoRS and the real data. Our results show that the maximum difference between\nreal fault data and the output fault model of MoRS is 6.21%, whereas the\nmaximum difference between real data and random fault injection model is 23.2%.\nIn terms of average proximity to the real data, the output of MoRS outperforms\nthe random fault injection approach by 3.21x.",
    "descriptor": "\nComments: 13 pages, 10 figures. This work appears at the Transactions on Computer-Aided Design of Integrated Circuits and Systems: SI on Compiler Frameworks and Co-design Methodologies\n",
    "authors": [
      "\u0130smail Emir Y\u00fcksel",
      "Behzad Salami",
      "O\u011fuz Ergin",
      "Osman Sabri \u00dcnsal",
      "Adrian Cristal Kestelman"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2110.05855"
  },
  {
    "id": "arXiv:2110.05856",
    "title": "text2sdg: An open-source solution to monitoring sustainable development  goals from text",
    "abstract": "Monitoring progress on the United Nations Sustainable Development Goals\n(SDGs) is important for both academic and non-academic organizations. Existing\napproaches to monitoring SDGs have focused on specific data types, namely,\npublications listed in proprietary research databases. We present the text2sdg\nR package, a user-friendly, open-source package that detects SDGs in any kind\nof text data using several different query systems from any text source. The\ntext2sdg package thereby facilitates the monitoring of SDGs for a wide array of\ntext sources and provides a much-needed basis for validating and improving\nextant methods to detect SDGs from text.",
    "descriptor": "",
    "authors": [
      "Dirk U. Wulff",
      "Rui Mata",
      "Dominik S. Meier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05856"
  },
  {
    "id": "arXiv:2110.05858",
    "title": "KernelHaven -- An Experimentation Workbench for Analyzing Software  Product Lines",
    "abstract": "Systematic exploration of hypotheses is a major part of any empirical\nresearch. In software engineering, we often produce unique tools for\nexperiments and evaluate them independently on different data sets. In this\npaper, we present KernelHaven as an experimentation workbench supporting a\nsignificant number of experiments in the domain of static product line analysis\nand verification. It addresses the need for extracting information from a\nvariety of artifacts in this domain by means of an open plug-in infrastructure.\nAvailable plug-ins encapsulate existing tools, which can now be combined\nefficiently to yield new analyses. As an experimentation workbench, it provides\nconfiguration-based definitions of experiments, their documentation, and\ntechnical services, like parallelization and caching. Hence, researchers can\nabstract from technical details and focus on the algorithmic core of their\nresearch problem.\nKernelHaven supports different types of analyses, like correctness checks,\nmetrics, etc., in its specific domain. The concepts presented in this paper can\nalso be transferred to support researchers of other software engineering\ndomains. The infrastructure is available under Apache 2.0:\nhttps://github.com/KernelHaven. The plug-ins are available under their\nindividual licenses.",
    "descriptor": "\nComments: Video: this https URL\n",
    "authors": [
      "Christian Kr\u00f6her",
      "Sascha El-Sharkawy",
      "Klaus Schmid"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.05858"
  },
  {
    "id": "arXiv:2110.05861",
    "title": "Convolutional Neural Networks Are Not Invariant to Translation, but They  Can Learn to Be",
    "abstract": "When seeing a new object, humans can immediately recognize it across\ndifferent retinal locations: the internal object representation is invariant to\ntranslation. It is commonly believed that Convolutional Neural Networks (CNNs)\nare architecturally invariant to translation thanks to the convolution and/or\npooling operations they are endowed with. In fact, several studies have found\nthat these networks systematically fail to recognise new objects on untrained\nlocations. In this work, we test a wide variety of CNNs architectures showing\nhow, apart from DenseNet-121, none of the models tested was architecturally\ninvariant to translation. Nevertheless, all of them could learn to be invariant\nto translation. We show how this can be achieved by pretraining on ImageNet,\nand it is sometimes possible with much simpler data sets when all the items are\nfully translated across the input canvas. At the same time, this invariance can\nbe disrupted by further training due to catastrophic forgetting/interference.\nThese experiments show how pretraining a network on an environment with the\nright `latent' characteristics (a more naturalistic environment) can result in\nthe network learning deep perceptual rules which would dramatically improve\nsubsequent generalization.",
    "descriptor": "",
    "authors": [
      "Valerio Biscione",
      "Jeffrey S. Bowers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05861"
  },
  {
    "id": "arXiv:2110.05864",
    "title": "Observing a group to infer individual characteristics",
    "abstract": "In the study of collective motion, it is common practice to collect movement\ninformation at the level of the group to infer the characteristics of the\nindividual agents and their interactions. However, it is not clear whether one\ncan always correctly infer individual characteristics from movement data of the\ncollective. We investigate this question in the context of a composite crowd\nwith two groups of agents, each with its own desired direction of motion. A\nsimple observer attempts to classify an agent into its group based on its\nmovement information. However, collective effects such as collisions,\nentrainment of agents, formation of lanes and clusters, etc. render the\nclassification problem non-trivial, and lead to misclassifications. Based on\nour understanding of these effects, we propose a new observer algorithm that\ninfers, based only on observed movement information, how the local neighborhood\naids or hinders agent movement. Unlike a traditional supervised learning\napproach, this algorithm is based on physical insights and scaling arguments,\nand does not rely on training-data. This new observer improves classification\nperformance and is able to differentiate agents belonging to different groups\neven when their motion is identical. Data-agnostic approaches like this have\nrelevance to a large class of real-world problems where clean, labeled data is\ndifficult to obtain, and is a step towards hybrid approaches that integrate\nboth data and domain knowledge.",
    "descriptor": "\nComments: Supplementary movies can be found in: this https URL\n",
    "authors": [
      "Arshed Nabeel",
      "Danny Raj M"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.05864"
  },
  {
    "id": "arXiv:2110.05866",
    "title": "MetricGAN-U: Unsupervised speech enhancement/ dereverberation based only  on noisy/ reverberated speech",
    "abstract": "Most of the deep learning-based speech enhancement models are learned in a\nsupervised manner, which implies that pairs of noisy and clean speech are\nrequired during training. Consequently, several noisy speeches recorded in\ndaily life cannot be used to train the model. Although certain unsupervised\nlearning frameworks have also been proposed to solve the pair constraint, they\nstill require clean speech or noise for training. Therefore, in this paper, we\npropose MetricGAN-U, which stands for MetricGAN-unsupervised, to further\nrelease the constraint from conventional unsupervised learning. In MetricGAN-U,\nonly noisy speech is required to train the model by optimizing non-intrusive\nspeech quality metrics. The experimental results verified that MetricGAN-U\noutperforms baselines in both objective and subjective metrics.",
    "descriptor": "",
    "authors": [
      "Szu-Wei Fu",
      "Cheng Yu",
      "Kuo-Hsuan Hung",
      "Mirco Ravanelli",
      "Yu Tsao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05866"
  },
  {
    "id": "arXiv:2110.05869",
    "title": "Reverse Engineering Variability in an Industrial Product Line:  Observations and Lessons Learned",
    "abstract": "Ideally, a variability model is a correct and complete representation of\nproduct line features and constraints among them. Together with a mapping\nbetween features and code, this ensures that only valid products can be\nconfigured and derived. However, in practice the modeled constraints might be\nneither complete nor correct, which causes problems in the configuration and\nproduct derivation phases. This paper presents an approach to reverse engineer\nvariability constraints from the implementation, and thus improve the\ncorrectness and completeness of variability models. We extended the concept of\nfeature effect analysis to extract variability constraints from code artifacts\nof the Bosch PS-EC large-scale product line. We present an industrial\napplication of the approach and discuss its required modifications to handle\nnon-Boolean variability and heterogeneous artifact types.",
    "descriptor": "",
    "authors": [
      "Sascha El-Sharkawy",
      "Dhar Saura Jyoti",
      "Adam Krafczyk",
      "Slawomir Duszynski",
      "Tobias Beichter",
      "Klaus Schmid"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.05869"
  },
  {
    "id": "arXiv:2110.05875",
    "title": "Reverse Engineering Code Dependencies: Converting Integer-Based  Variability to Propositional Logic",
    "abstract": "A number of SAT-based analysis concepts and tools for software product lines\nexist, that extract code dependencies in propositional logic from the source\ncode assets of the product line. On these extracted conditions, SAT-solvers are\nused to reason about the variability. However, in practice, a lot of software\nproduct lines use integer-based variability. The variability variables hold\ninteger values, and integer operators are used in the conditions. Most existing\nanalysis tools can not handle this kind of variability; they expect pure\nBoolean conditions. This paper introduces an approach to convert integer-based\nvariability conditions to propositional logic. Running this approach as a\npreparation on an integer-based product line allows the existing SAT-based\nanalyses to work without any modifications. The pure Boolean formulas, that our\napproach builds as a replacement for the integer-based conditions, are mostly\nequivalent to the original conditions with respect to satisfiability. Our\napproach was motivated by and implemented in the context of a real-world\nindustrial case-study, where such a preparation was necessary to analyze the\nvariability. Our contribution is an approach to convert conditions, that use\ninteger variables, into propositional formulas, to enable easy usage of\nSAT-solvers on the result. It works well on restricted variables (i.e.\nvariables with a small range of allowed values); unrestricted integer variables\nare handled less exact, but still retain useful variability information.",
    "descriptor": "",
    "authors": [
      "Adam Krafczyk",
      "Sascha El-Sharkawy",
      "Klaus Schmid"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.05875"
  },
  {
    "id": "arXiv:2110.05877",
    "title": "OpenHands: Making Sign Language Recognition Accessible with Pose-based  Pretrained Models across Languages",
    "abstract": "AI technologies for Natural Languages have made tremendous progress recently.\nHowever, commensurate progress has not been made on Sign Languages, in\nparticular, in recognizing signs as individual words or as complete sentences.\nWe introduce OpenHands, a library where we take four key ideas from the NLP\ncommunity for low-resource languages and apply them to sign languages for\nword-level recognition. First, we propose using pose extracted through\npretrained models as the standard modality of data to reduce training time and\nenable efficient inference, and we release standardized pose datasets for 6\ndifferent sign languages - American, Argentinian, Chinese, Greek, Indian, and\nTurkish. Second, we train and release checkpoints of 4 pose-based isolated sign\nlanguage recognition models across all 6 languages, providing baselines and\nready checkpoints for deployment. Third, to address the lack of labelled data,\nwe propose self-supervised pretraining on unlabelled data. We curate and\nrelease the largest pose-based pretraining dataset on Indian Sign Language\n(Indian-SL). Fourth, we compare different pretraining strategies and for the\nfirst time establish that pretraining is effective for sign language\nrecognition by demonstrating (a) improved fine-tuning performance especially in\nlow-resource settings, and (b) high crosslingual transfer from Indian-SL to few\nother sign languages. We open-source all models and datasets in OpenHands with\na hope that it makes research in sign languages more accessible, available here\nat https://github.com/AI4Bharat/OpenHands .",
    "descriptor": "\nComments: Submitted to AAAI22, 13 pages, 9 figures, 6 tables\n",
    "authors": [
      "Prem Selvaraj",
      "Gokul NC",
      "Pratyush Kumar",
      "Mitesh Khapra"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05877"
  },
  {
    "id": "arXiv:2110.05878",
    "title": "Sanctuary lost: a cyber-physical warfare in space",
    "abstract": "Over the last decades, space has grown from a purely scientific struggle,\nfueled by the desire to demonstrate superiority of one regime over the other,\nto an anchor point of the economies of essentially all developed countries.\nMany businesses depend crucially on satellite communication or data\nacquisition, not only for defense purposes, but increasingly also for\nday-to-day applications. However, although so far space faring nations\nrefrained from extending their earth-bound conflicts into space, this critical\ninfrastructure is not as invulnerable as common knowledge suggests. In this\npaper, we analyze the threats space vehicles are exposed to and what must\nchange to mitigate them. In particular, we shall focus on cyber threats, which\nmay well be mounted by small countries and terrorist organizations, whose\nincentives do not necessarily include sustainability of the space domain and\nwho may not be susceptible to the threat of mutual retaliation on the ground.\nWe survey incidents, highlight threats and raise awareness from general\npreparedness for accidental faults, which is already widely spread within the\nspace community, to preparedness and tolerance of both accidental and malicious\nfaults (such as targeted attacks by cyber terrorists and nation-state hackers).",
    "descriptor": "",
    "authors": [
      "Rafal Graczyk",
      "Paulo Esteves-Verissimo",
      "Marcus Voelp"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.05878"
  },
  {
    "id": "arXiv:2110.05881",
    "title": "Fourier-based Video Prediction through Relational Object Motion",
    "abstract": "The ability to predict future outcomes conditioned on observed video frames\nis crucial for intelligent decision-making in autonomous systems. Recently,\ndeep recurrent architectures have been applied to the task of video prediction.\nHowever, this often results in blurry predictions and requires tedious training\non large datasets. Here, we explore a different approach by (1) using\nfrequency-domain approaches for video prediction and (2) explicitly inferring\nobject-motion relationships in the observed scene. The resulting predictions\nare consistent with the observed dynamics in a scene and do not suffer from\nblur.",
    "descriptor": "",
    "authors": [
      "Malte Mosbach",
      "Sven Behnke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05881"
  },
  {
    "id": "arXiv:2110.05882",
    "title": "Concepts of Self-maintaining Robots and Their Design",
    "abstract": "This paper proposes an initial theory for robotic systems that can be fully\nself-maintaining. The new design principles focus on functional survival of the\nrobots over long periods of time without human maintenance. Self-maintaining\nsemi-autonomous mobile robots are in great demand in nuclear disposal sites\nfrom where their removal for maintenance is undesirable due to their\nradioactive contamination. Similar are requirements for robots in various\ndefence tasks or space missions. For optimal design, modular solutions are\nbalanced against capabilities to replace smaller components in a robot by\nitself or by help from another robot. Modules are proposed for the basic\nplatform, which enable self-maintenance within a team of robots helping each\nother. The primary method of self-maintenance is replacement of malfunctioning\nmodules or components by the robots themselves. Replacement necessitates a\nrobot team's ability to diagnose and replace malfunctioning modules as needed.\nDue to their design, these robots still remain manually re-configurable if\nopportunity arises for human intervention. Apart from the basic principles, an\nevolutionary design approach is presented and a first mathematical theory of\nthe reliability of a team of self-maintaining robots is introduced.",
    "descriptor": "",
    "authors": [
      "Chenjie Shi",
      "Sandor M Veres"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.05882"
  },
  {
    "id": "arXiv:2110.05885",
    "title": "Monocular Depth Estimation with Sharp Boundary",
    "abstract": "Monocular depth estimation is the base task in computer vision. It has a\ntremendous development in the decade with the development of deep learning. But\nthe boundary blur of the depth map is still a serious problem. Research finds\nthe boundary blur problem is mainly caused by two factors, first, the low-level\nfeatures containing boundary and structure information may loss in deeper\nnetworks during the convolution process., second, the model ignores the errors\nintroduced by the boundary area due to the few portions of the boundary in the\nwhole areas during the backpropagation. In order to mitigate the boundary blur\nproblem, we focus on the above two impact factors. Firstly, we design a scene\nunderstanding module to learn the global information with low- and high-level\nfeatures, and then to transform the global information to different scales with\nour proposed scale transform module according to the different phases in the\ndecoder. Secondly, we propose a boundary-aware depth loss function to pay\nattention to the effects of the boundary's depth value. The extensive\nexperiments show that our method can predict the depth maps with clearer\nboundaries, and the performance of the depth accuracy base on NYU-depth v2 and\nSUN RGB-D is competitive.",
    "descriptor": "\nComments: 20 pages,9 figures\n",
    "authors": [
      "Xin Yang",
      "Qingling Chang",
      "Xinlin Liu",
      "Yan Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05885"
  },
  {
    "id": "arXiv:2110.05886",
    "title": "MGH: Metadata Guided Hypergraph Modeling for Unsupervised Person  Re-identification",
    "abstract": "As a challenging task, unsupervised person ReID aims to match the same\nidentity with query images which does not require any labeled information. In\ngeneral, most existing approaches focus on the visual cues only, leaving\npotentially valuable auxiliary metadata information (e.g., spatio-temporal\ncontext) unexplored. In the real world, such metadata is normally available\nalongside captured images, and thus plays an important role in separating\nseveral hard ReID matches. With this motivation in mind, we\npropose~\\textbf{MGH}, a novel unsupervised person ReID approach that uses meta\ninformation to construct a hypergraph for feature learning and label\nrefinement. In principle, the hypergraph is composed of camera-topology-aware\nhyperedges, which can model the heterogeneous data correlations across cameras.\nTaking advantage of label propagation on the hypergraph, the proposed approach\nis able to effectively refine the ReID results, such as correcting the wrong\nlabels or smoothing the noisy labels. Given the refined results, We further\npresent a memory-based listwise loss to directly optimize the average precision\nin an approximate manner. Extensive experiments on three benchmarks demonstrate\nthe effectiveness of the proposed approach against the state-of-the-art.",
    "descriptor": "\nComments: 10 pages, 3 figures\n",
    "authors": [
      "Yiming Wu",
      "Xintian Wu",
      "Xi Li",
      "Jian Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.05886"
  },
  {
    "id": "arXiv:2110.05888",
    "title": "Fast Static Analyses of Software Product Lines -- An Example With More  Than 42,000 Metrics",
    "abstract": "Context: Software metrics, as one form of static analyses, is a commonly used\napproach in software engineering in order to understand the state of a software\nsystem, in particular to identify potential areas prone to defects.\nFamily-based techniques extract variability information from code artifacts in\nSoftware Product Lines (SPLs) to perform static analysis for all available\nvariants. Many different types of metrics with numerous variants have been\ndefined in literature. When counting all metrics including such variants,\neasily thousands of metrics can be defined. Computing all of them for large\nproduct lines can be an extremely expensive process in terms of performance and\nresource consumption.\nObjective: We address these performance and resource challenges while\nsupporting customizable metric suites, which allow running both, single system\nand variability-aware code metrics.\nMethod: In this paper, we introduce a partial parsing approach used for the\nefficient measurement of more than 42,000 code metric variations. The approach\ncovers variability information and restricts parsing to the relevant parts of\nthe Abstract Syntax Tree (AST).\nConclusions: This partial parsing approach is designed to cover all relevant\ninformation to compute a broad variety of variability-aware code metrics on\ncode artifacts containing annotation-based variability, e.g., realized with\nC-preprocessor statements. It allows for the flexible combination of single\nsystem and variability-aware metrics, which is not supported by existing tools.\nThis is achieved by a novel representation of partially parsed product line\ncode artifacts, which is tailored to the computation of the metrics. Our\napproach consumes considerably less resources, especially when computing many\nmetric variants in parallel.",
    "descriptor": "",
    "authors": [
      "Sascha El-Sharkawy",
      "Adam Krafczyk",
      "Klaus Schmid"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.05888"
  },
  {
    "id": "arXiv:2110.05892",
    "title": "Investigation on Data Adaptation Techniques for Neural Named Entity  Recognition",
    "abstract": "Data processing is an important step in various natural language processing\ntasks. As the commonly used datasets in named entity recognition contain only a\nlimited number of samples, it is important to obtain additional labeled data in\nan efficient and reliable manner. A common practice is to utilize large\nmonolingual unlabeled corpora. Another popular technique is to create synthetic\ndata from the original labeled data (data augmentation). In this work, we\ninvestigate the impact of these two methods on the performance of three\ndifferent named entity recognition tasks.",
    "descriptor": "\nComments: ACL SRW 2021 - camera ready\n",
    "authors": [
      "Evgeniia Tokarchuk",
      "David Thulke",
      "Weiyue Wang",
      "Christian Dugast",
      "Hermann Ney"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05892"
  },
  {
    "id": "arXiv:2110.05894",
    "title": "Numerical analysis of 2D Navier--Stokes equations with additive  stochastic forcing",
    "abstract": "We propose and study a temporal, and spatio-temporal discretisation of the 2D\nstochastic Navier--Stokes equations in bounded domains supplemented with\nno-slip boundary conditions. Considering additive noise, we base its\nconstruction on the related nonlinear random PDE, which is solved by a\ntransform of the solution of the stochastic Navier--Stokes equations. We show\nstrong rate (up to) $1$ in probability for a corresponding discretisation in\nspace and time (and space-time). Convergence of order (up to) 1 in time was\npreviously only known for linear SPDEs.",
    "descriptor": "",
    "authors": [
      "Dominic Breit",
      "Andreas Prohl"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2110.05894"
  },
  {
    "id": "arXiv:2110.05895",
    "title": "Adjusting Queries to Statistical Procedures Under Differential Privacy",
    "abstract": "We consider a dataset $S$ held by an agency, and a vector query of interest,\n$f(S) \\in \\mathbb{R}^k$, to be posed by an analyst, which contains the\ninformation required for certain planned statistical inference. The agency\nreleases the requested vector query with noise that guarantees a given level of\nDifferential Privacy -- DP$(\\varepsilon,\\delta)$ -- using the well-known\nGaussian mechanism. The analyst can choose to pose the vector query $f(S)$ or\nto adjust it by a suitable transformation that can make the agency's response\nmore informative. For any given level of privacy DP$(\\varepsilon,\\delta)$\ndecided by the agency, we study natural situations where the analyst can\nachieve better statistical inference by adjusting the query with a suitable\nsimple explicit transformation.",
    "descriptor": "",
    "authors": [
      "Tomer Shoham",
      "Yosef Rinott"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.05895"
  },
  {
    "id": "arXiv:2110.05896",
    "title": "LaoPLM: Pre-trained Language Models for Lao",
    "abstract": "Trained on the large corpus, pre-trained language models (PLMs) can capture\ndifferent levels of concepts in context and hence generate universal language\nrepresentations. They can benefit multiple downstream natural language\nprocessing (NLP) tasks. Although PTMs have been widely used in most NLP\napplications, especially for high-resource languages such as English, it is\nunder-represented in Lao NLP research. Previous work on Lao has been hampered\nby the lack of annotated datasets and the sparsity of language resources. In\nthis work, we construct a text classification dataset to alleviate the\nresource-scare situation of the Lao language. We additionally present the first\ntransformer-based PTMs for Lao with four versions: BERT-small, BERT-base,\nELECTRA-small and ELECTRA-base, and evaluate it over two downstream tasks:\npart-of-speech tagging and text classification. Experiments demonstrate the\neffectiveness of our Lao models. We will release our models and datasets to the\ncommunity, hoping to facilitate the future development of Lao NLP applications.",
    "descriptor": "",
    "authors": [
      "Nankai Lin",
      "Yingwen Fu",
      "Ziyu Yang",
      "Shengyi Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05896"
  },
  {
    "id": "arXiv:2110.05897",
    "title": "Dimensionality Reduction for $k$-Distance Applied to Persistent Homology",
    "abstract": "Given a set P of n points and a constant k, we are interested in computing\nthe persistent homology of the Cech filtration of P for the k-distance, and\ninvestigate the effectiveness of dimensionality reduction for this problem,\nanswering an open question of Sheehy [Proc. SoCG, 2014]. We show that any\nlinear transformation that preserves pairwise distances up to a (1 +/- e)\nmultiplicative factor, must preserve the persistent homology of the Cech\nfiltration up to a factor of (1-e)^(-1). Our results also show that the\nVietoris-Rips and Delaunay filtrations for the k-distance, as well as the Cech\nfiltration for the approximate k-distance of Buchet et al. [J. Comput. Geom.,\n2016] are preserved up to a (1 +/- e) factor. We also prove extensions of our\nmain theorem, for point sets (i) lying in a region of bounded Gaussian width or\n(ii) on a low-dimensional submanifold, obtaining embeddings having the\ndimension bounds of Lotz [Proc. Roy. Soc., 2019] and Clarkson [Proc. SoCG,\n2008] respectively. Our results also work in the terminal dimensionality\nreduction setting, where the distance of any point in the original ambient\nspace, to any point in P, needs to be approximately preserved.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Shreya Arya",
      "Jean-Daniel Boissonnat",
      "Kunal Dutta",
      "Martin Lotz"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Algebraic Topology (math.AT)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05897"
  },
  {
    "id": "arXiv:2110.05901",
    "title": "Popular matchings with weighted voters",
    "abstract": "In the Popular Matching problem, we are given a bipartite graph $G = (A \\cup\nB, E)$ and for each vertex $v\\in A\\cup B$, strict preferences over the\nneighbors of $v$. Given two matchings $M$ and $M'$, matching $M$ is more\npopular than $M'$ if the number of vertices preferring $M$ to $M'$ is larger\nthan the number of vertices preferring $M'$ to $M$. A matching $M$ is called\npopular if there is no matching $M'$ that is more popular than $M$.\nWe consider a natural generalization of Popular Matching where every vertex\nhas a weight. Then, we call a matching $M$ more popular than matching $M'$ if\nthe weight of vertices preferring $M$ to $M'$ is larger than the weight of\nvertices preferring $M'$ to $M$. For this case, we show that it is NP-hard to\nfind a popular matching. Our main result its a polynomial-time algorithm that\ndelivers a popular matching or a proof for it non-existence in instances where\nall vertices on one side have weight $c > 3$ and all vertices on the other side\nhave weight 1.",
    "descriptor": "",
    "authors": [
      "Klaus Heeger",
      "\u00c1gnes Cseh"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.05901"
  },
  {
    "id": "arXiv:2110.05904",
    "title": "Video Is Graph: Structured Graph Module for Video Action Recognition",
    "abstract": "In the field of action recognition, video clips are always treated as ordered\nframes for subsequent processing. To achieve spatio-temporal perception,\nexisting approaches propose to embed adjacent temporal interaction in the\nconvolutional layer. The global semantic information can therefore be obtained\nby stacking multiple local layers hierarchically. However, such global temporal\naccumulation can only reflect the high-level semantics in deep layers,\nneglecting the potential low-level holistic clues in shallow layers. In this\npaper, we first propose to transform a video sequence into a graph to obtain\ndirect long-term dependencies among temporal frames. To preserve sequential\ninformation during transformation, we devise a structured graph module (SGM),\nachieving fine-grained temporal interactions throughout the entire network. In\nparticular, SGM divides the neighbors of each node into several temporal\nregions so as to extract global structural information with diverse sequential\nflows. Extensive experiments are performed on standard benchmark datasets,\ni.e., Something-Something V1 & V2, Diving48, Kinetics-400, UCF101, and HMDB51.\nThe reported performance and analysis demonstrate that SGM can achieve\noutstanding precision with less computational complexity.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Rong-Chang Li",
      "Tianyang Xu",
      "Xiao-Jun Wu",
      "Josef Kittler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.05904"
  },
  {
    "id": "arXiv:2110.05906",
    "title": "Energy-cost aware off-grid base stations with IoT devices for developing  a green heterogeneous network",
    "abstract": "Heterogeneous network (HetNet) is a specified cellular platform to tackle the\nrapidly growing anticipated data traffic. From communications perspective, data\nloads can be mapped to energy loads that are generally placed on the operator\nnetworks. Meanwhile, renewable energy aided networks offer to curtail fossil\nfuel consumption, so to reduce environmental pollution. This paper proposes a\nrenewable energy based power supply architecture for off-grid HetNet using a\nnovel energy sharing model. Solar photovoltaic (PV) along with sufficient\nenergy storage devices are used for each macro, micro, pico, or femto base\nstation (BS). Additionally, biomass generator (BG) is used for macro and micro\nBSs. The collocated macro and micro BSs are connected through end-to-end\nresistive lines. A novel weighted proportional-fair resource-scheduling\nalgorithm with sleep mechanisms is proposed for non-real time (NRT)\napplications by trading-off the power consumption and communication delays.\nFurthermore, the proposed algorithm with extended discontinuous reception\n(eDRX) and power saving mode (PSM) for narrowband internet of things (IoT)\napplications extends battery lifetime for IoT devices. HOMER optimization\nsoftware is used to perform optimal system architecture, economic, and carbon\nfootprint analyses while Monte-Carlo simulation tool is used for evaluating the\nthroughput and energy efficiency performances. The proposed algorithms are\nvalid for the practical data of the rural areas. We demonstrate the proposed\npower supply architecture is energy-efficient, cost-effective, reliable, and\neco-friendly.",
    "descriptor": "",
    "authors": [
      "Khondoker Ziaul Islam",
      "MD. Sanwar Hossain",
      "B.M. Ruhul Amin",
      "Ferdous Sohel"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.05906"
  },
  {
    "id": "arXiv:2110.05909",
    "title": "Rescoring Sequence-to-Sequence Models for Text Line Recognition with  CTC-Prefixes",
    "abstract": "In contrast to Connectionist Temporal Classification (CTC) approaches,\nSequence-To-Sequence (S2S) models for Handwritten Text Recognition (HTR) suffer\nfrom errors such as skipped or repeated words which often occur at the end of a\nsequence. In this paper, to combine the best of both approaches, we propose to\nuse the CTC-Prefix-Score during S2S decoding. Hereby, during beam search, paths\nthat are invalid according to the CTC confidence matrix are penalised. Our\nnetwork architecture is composed of a Convolutional Neural Network (CNN) as\nvisual backbone, bidirectional Long-Short-Term-Memory-Cells (LSTMs) as encoder,\nand a decoder which is a Transformer with inserted mutual attention layers. The\nCTC confidences are computed on the encoder while the Transformer is only used\nfor character-wise S2S decoding. We evaluate this setup on three HTR data sets:\nIAM, Rimes, and StAZH. On IAM, we achieve a competitive Character Error Rate\n(CER) of 2.95% when pretraining our model on synthetic data and including a\ncharacter-based language model for contemporary English. Compared to other\nstate-of-the-art approaches, our model requires about 10-20 times less\nparameters. Access our shared implementations via this link to GitHub:\nhttps://github.com/Planet-AI-GmbH/tfaip-hybrid-ctc-s2s.",
    "descriptor": "\nComments: 15 pages, 6 tables, 3 figures\n",
    "authors": [
      "Christoph Wick",
      "Jochen Z\u00f6llner",
      "Tobias Gr\u00fcning"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05909"
  },
  {
    "id": "arXiv:2110.05910",
    "title": "Bridging the Band Gap: What Device Physicists Need to Know About Machine  Learning",
    "abstract": "This article surveys the landscape of semiconductor materials and devices\nresearch for the acceleration of machine learning (ML) algorithms. We observe a\ndisconnect between the semiconductor and device physics and engineering\ncommunities, and the digital logic and computer hardware architecture\ncommunities. The article first provides an overview of the principles of\ncomputational complexity and fundamental physical limits to computing and their\nrelation to physical systems. The article then provides an introduction to ML\nby presenting three key components of ML systems: representation, evaluation,\nand optimisation. The article then discusses and provides examples of the\napplication of emerging technologies from the demiconductor and device physics\ndomains as solutions to computational problems, alongside a brief overview of\nemerging devices for computing applications. The article then reviews the\nlandscape of ML accelerators, comparing fixed-function and reprogrammable\ndigital logic with novel devices such as memristors, resistive memories,\nmagnetic memories, and probabilistic bits. We observe broadly lower performance\nof ML accelerators based on novel devices and materials when compared to those\nbased on digital complimentary metal-oxide semiconductor (CMOS) technology,\nparticularly in the MNIST optical character recognition task, a common ML\nbenchmark, and also highlight the lack of a trend of progress in approaches\nbased on novel materials and devices. Lastly, the article proposes figures of\nmerit for meaningful evaluation and comparison of different ML implementations\nin the hope of fostering a dialogue between the materials science, device\nphysics, digital logic, and computer architecture communities by providing a\ncommon frame of reference for their work.",
    "descriptor": "",
    "authors": [
      "Nathaniel Tye",
      "Stephan Hofmann",
      "Phillip Stanley-Marbell"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.05910"
  },
  {
    "id": "arXiv:2110.05911",
    "title": "System for multi-robotic exploration of underground environments  CTU-CRAS-NORLAB in the DARPA Subterranean Challenge",
    "abstract": "We present a field report of CTU-CRAS-NORLAB team from the Subterranean\nChallenge (SubT) organised by the Defense Advanced Research Projects Agency\n(DARPA). The contest seeks to advance technologies that would improve the\nsafety and efficiency of search-and-rescue operations in GPS-denied\nenvironments. During the contest rounds, teams of mobile robots have to find\nspecific objects while operating in environments with limited radio\ncommunication, e.g. mining tunnels, underground stations or natural caverns. We\npresent a heterogeneous exploration robotic system of the CTU-CRAS-NORLAB team,\nwhich achieved the third rank at the SubT Tunnel and Urban Circuit rounds and\nsurpassed the performance of all other non-DARPA-funded teams. The field report\ndescribes the team's hardware, sensors, algorithms and strategies, and\ndiscusses the lessons learned by participating at the DARPA SubT contest.",
    "descriptor": "\nComments: This paper have already been accepted to be published Filed Robotics special issue about DARPA SubT challange\n",
    "authors": [
      "Tom\u00e1\u0161 Rou\u010dek",
      "Martin Pecka",
      "Petr \u010c\u00ed\u017eek",
      "Tom\u00e1\u0161 Pet\u0159\u00ed\u010dek",
      "Jan Bayer",
      "Vojt\u011bch \u0160alansk\u00fd",
      "Teymur Azayev",
      "Daniel He\u0159t",
      "Mat\u011bj Petrl\u00edk",
      "Tom\u00e1\u0161 B\u00e1\u010da",
      "Vojt\u011bch Spurn\u00fd",
      "V\u00edt Kr\u00e1tk\u00fd",
      "Pavel Petr\u00e1\u010dek",
      "Dominic Baril",
      "Maxime Vaidis",
      "Vladim\u00edr Kubelka",
      "Fran\u00e7ois Pomerleau",
      "Jan Faigl",
      "Karel Zimmermann",
      "Martin Saska",
      "Tom\u00e1\u0161 Svoboda",
      "Tom\u00e1\u0161 Krajn\u00edk"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.05911"
  },
  {
    "id": "arXiv:2110.05917",
    "title": "On the complexity of structure and substructure connectivity of graphs",
    "abstract": "The connectivity of a graph is an important parameter to measure its\nreliability. Structure and substructure connectivity are two novel\ngeneralizations of the connectivity. In this paper, we characterize the\ncomplexity of determining structure and substructure connectivity of graphs,\nshowing that they are both NP-complete.",
    "descriptor": "",
    "authors": [
      "Huazhong L\u00fc",
      "Tingzeng Wu"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.05917"
  },
  {
    "id": "arXiv:2110.05922",
    "title": "Trivial or impossible -- dichotomous data difficulty masks model  differences (on ImageNet and beyond)",
    "abstract": "\"The power of a generalization system follows directly from its biases\"\n(Mitchell 1980). Today, CNNs are incredibly powerful generalisation systems --\nbut to what degree have we understood how their inductive bias influences model\ndecisions? We here attempt to disentangle the various aspects that determine\nhow a model decides. In particular, we ask: what makes one model decide\ndifferently from another? In a meticulously controlled setting, we find that\n(1.) irrespective of the network architecture or objective (e.g.\nself-supervised, semi-supervised, vision transformers, recurrent models) all\nmodels end up with a similar decision boundary. (2.) To understand these\nfindings, we analysed model decisions on the ImageNet validation set from epoch\nto epoch and image by image. We find that the ImageNet validation set, among\nothers, suffers from dichotomous data difficulty (DDD): For the range of\ninvestigated models and their accuracies, it is dominated by 46.0% \"trivial\"\nand 11.5% \"impossible\" images (beyond label errors). Only 42.5% of the images\ncould possibly be responsible for the differences between two models' decision\nboundaries. (3.) Only removing the \"impossible\" and \"trivial\" images allows us\nto see pronounced differences between models. (4.) Humans are highly accurate\nat predicting which images are \"trivial\" and \"impossible\" for CNNs (81.4%).\nThis implies that in future comparisons of brains, machines and behaviour, much\nmay be gained from investigating the decisive role of images and the\ndistribution of their difficulties.",
    "descriptor": "\nComments: Under review as a conference paper at ICLR 2022\n",
    "authors": [
      "Kristof Meding",
      "Luca M. Schulze Buschoff",
      "Robert Geirhos",
      "Felix A. Wichmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05922"
  },
  {
    "id": "arXiv:2110.05925",
    "title": "Fast A Posteriori State Error Estimation for Reliable Frequency Sweeping  in Microwave Circuits via the Reduced-Basis Method",
    "abstract": "We develop a compact, reliable model order reduction approach for fast\nfrequency sweeps in microwave circuits by means of the reduced-basis method.\nContrary to what has been previously done, special emphasis is placed on\ncertifying the accuracy of the reduced-order model with respect to the original\nfull-order model in an effective and efficient way. Previous works on model\norder reduction accuracy certification rely on costly $\\textit{a posteriori}$\nerror estimators, which typically require expensive $\\textit{inf-sup}$ constant\nevaluations of the underlying full-order model. This scenario is often too\ntime-consuming and unaffordable in electromagnetic applications. As a result,\nless expensive and heuristic error estimators are commonly used instead. Very\noften, one is interested in knowing about the full state vector, instead of\njust some output quantities derived from the full state. Therefore, error\nestimators for the full state vector become relevant. In this work, we detail\nthe frequency behavior of both the electric field and the state error when an\napproximation to the electric field solution is carried out. Both field\nquantities share the same frequency behavior. Based on this observation, we\nfocus on the efficient estimation of the electric field state error and propose\na fast evaluation of the reduced-order model state error in the frequency band\nof analysis, minimizing the number of full-order model evaluations. This\nmethodology is of paramount importance to carry out a reliable fast frequency\nsweep in microwave circuits. Finally, real-life applications will illustrate\nthe capabilities and efficiency of the proposed approach.",
    "descriptor": "\nComments: 24 pages, 13 Figures, 6 Tables\n",
    "authors": [
      "Valentin de la Rubia",
      "Sridhar Chellappa",
      "Lihong Feng",
      "Peter Benner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05925"
  },
  {
    "id": "arXiv:2110.05926",
    "title": "Weakly-Supervised Semantic Segmentation by Learning Label Uncertainty",
    "abstract": "Since the rise of deep learning, many computer vision tasks have seen\nsignificant advancements. However, the downside of deep learning is that it is\nvery data-hungry. Especially for segmentation problems, training a deep neural\nnet requires dense supervision in the form of pixel-perfect image labels, which\nare very costly. In this paper, we present a new loss function to train a\nsegmentation network with only a small subset of pixel-perfect labels, but take\nthe advantage of weakly-annotated training samples in the form of cheap\nbounding-box labels. Unlike recent works which make use of box-to-mask proposal\ngenerators, our loss trains the network to learn a label uncertainty within the\nbounding-box, which can be leveraged to perform online bootstrapping (i.e.\ntransforming the boxes to segmentation masks), while training the network. We\nevaluated our method on binary segmentation tasks, as well as a multi-class\nsegmentation task (CityScapes vehicles and persons). We trained each task on a\ndataset comprised of only 18% pixel-perfect and 82% bounding-box labels, and\ncompared the results to a baseline model trained on a completely pixel-perfect\ndataset. For the binary segmentation tasks, our method achieves an IoU score\nwhich is ~98.33% as good as our baseline model, while for the multi-class task,\nour method is 97.12% as good as our baseline model (77.5 vs. 79.8 mIoU).",
    "descriptor": "",
    "authors": [
      "Robby Neven",
      "Davy Neven",
      "Bert De Brabandere",
      "Marc Proesmans",
      "Toon Goedem\u00e9"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05926"
  },
  {
    "id": "arXiv:2110.05928",
    "title": "Does it matter who pays back Technical Debt? An empirical study of  self-fixed TD",
    "abstract": "Context: Technical Debt (TD) can be paid back either by those that incurred\nit or by others. We call the former self-fixed TD, and it can be particularly\neffective, as developers are experts in their own code and are well-suited to\nfix the corresponding TD issues. Objective: The goal of our study is to\ninvestigate self-fixed technical debt, especially the extent in which TD is\nself-fixed, which types of TD are more likely to be self-fixed, whether the\nremediation time of self-fixed TD is shorter than non-self-fixed TD and how\ndevelopment behaviors are related to self-fixed TD. Method: We report on an\nempirical study that analyzes the self-fixed issues of five types of TD (i.e.,\nCode, Defect, Design, Documentation and Test), captured via static analysis, in\nmore than 44,000 commits obtained from 20 Python and 16 Java projects of the\nApache Software Foundation. Results: The results show that about half of the\nfixed issues are self-fixed and that the likelihood of contained TD issues\nbeing self-fixed is negatively correlated with project size, the number of\ndevelopers and total issues. Moreover, there is no significant difference of\nthe survival time between self-fixed and non-self-fixed issues. Furthermore,\ndevelopers are more keen to pay back their own TD when it is related to lower\ncode level issues, e.g., Defect Debt and Code Debt. Finally, developers who are\nmore dedicated to or knowledgeable about the project contribute to a higher\nchance of self-fixing TD. Conclusions: These results can benefit both\nresearchers and practitioners by aiding the prioritization of TD remediation\nactivities and refining strategies within development teams, and by informing\nthe development of TD management tools.",
    "descriptor": "",
    "authors": [
      "Jie Tan",
      "Daniel Feitosa",
      "Paris Avgeriou"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.05928"
  },
  {
    "id": "arXiv:2110.05929",
    "title": "One Timestep is All You Need: Training Spiking Neural Networks with  Ultra Low Latency",
    "abstract": "Spiking Neural Networks (SNNs) are energy efficient alternatives to commonly\nused deep neural networks (DNNs). Through event-driven information processing,\nSNNs can reduce the expensive compute requirements of DNNs considerably, while\nachieving comparable performance. However, high inference latency is a\nsignificant hindrance to the edge deployment of deep SNNs. Computation over\nmultiple timesteps not only increases latency as well as overall energy budget\ndue to higher number of operations, but also incurs memory access overhead of\nfetching membrane potentials, both of which lessen the energy benefits of SNNs.\nTo overcome this bottleneck and leverage the full potential of SNNs, we propose\nan Iterative Initialization and Retraining method for SNNs (IIR-SNN) to perform\nsingle shot inference in the temporal axis. The method starts with an SNN\ntrained with T timesteps (T>1). Then at each stage of latency reduction, the\nnetwork trained at previous stage with higher timestep is utilized as\ninitialization for subsequent training with lower timestep. This acts as a\ncompression method, as the network is gradually shrunk in the temporal domain.\nIn this paper, we use direct input encoding and choose T=5, since as per\nliterature, it is the minimum required latency to achieve satisfactory\nperformance on ImageNet. The proposed scheme allows us to obtain SNNs with up\nto unit latency, requiring a single forward pass during inference. We achieve\ntop-1 accuracy of 93.05%, 70.15% and 67.71% on CIFAR-10, CIFAR-100 and\nImageNet, respectively using VGG16, with just 1 timestep. In addition, IIR-SNNs\nperform inference with 5-2500X reduced latency compared to other\nstate-of-the-art SNNs, maintaining comparable or even better accuracy.\nFurthermore, in comparison with standard DNNs, the proposed IIR-SNNs\nprovide25-33X higher energy efficiency, while being comparable to them in\nclassification performance.",
    "descriptor": "",
    "authors": [
      "Sayeed Shafayet Chowdhury",
      "Nitin Rathi",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05929"
  },
  {
    "id": "arXiv:2110.05933",
    "title": "A Deployment Model to Extend Ethically Aligned AI Implementation Method  ECCOLA",
    "abstract": "There is a struggle in Artificial intelligence (AI) ethics to gain ground in\nactionable methods and models to be utilized by practitioners while developing\nand implementing ethically sound AI systems. AI ethics is a vague concept\nwithout a consensus of definition or theoretical grounding and bearing little\nconnection to practice. Practice involving primarily technical tasks like\nsoftware development is not aptly equipped to process and decide upon ethical\nconsiderations. Efforts to create tools and guidelines to help people working\nwith AI development have been concentrating almost solely on the technical\naspects of AI. A few exceptions do apply, such as the ECCOLA method for\ncreating ethically aligned AI -systems. ECCOLA has proven results in terms of\nincreased ethical considerations in AI systems development. Yet, it is a novel\ninnovation, and room for development still exists. This study aims to extend\nECCOLA with a deployment model to drive the adoption of ECCOLA, as any method,\nno matter how good, is of no value without adoption and use. The model includes\nsimple metrics to facilitate the communication of ethical gaps or outcomes of\nethical AI development. It offers the opportunity to assess any AI system at\nany given lifecycle phase, e.g., opening possibilities like analyzing the\nethicality of an AI system under acquisition.",
    "descriptor": "",
    "authors": [
      "Jani Antikainen",
      "Mamia Agbese",
      "Hanna-Kaisa Alanen",
      "Erika Halme",
      "Hannakaisa Isom\u00e4ki",
      "Marianna Jantunen",
      "Kai-Kristian Kemell",
      "Rebekah Rousi",
      "Heidi Vainio-Pekka",
      "Ville Vakkuri"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.05933"
  },
  {
    "id": "arXiv:2110.05939",
    "title": "Intelligent Players in a Fictitious Play Framework",
    "abstract": "Fictitious play is a popular learning algorithm in which players that utilize\nthe history of actions played by the players and the knowledge of their own\npayoff matrix can converge to the Nash equilibrium under certain conditions on\nthe game. We consider the presence of an intelligent player that has access to\nthe entire payoff matrix for the game. We show that by not conforming to\nfictitious play, such a player can achieve a better payoff than the one at the\nNash Equilibrium. This result can be viewed both as a fragility of the\nfictitious play algorithm to a strategic intelligent player and an indication\nthat players should not throw away additional information they may have, as\nsuggested by classical fictitious play.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Bhaskar Vundurthy",
      "Aris Kanellopoulos",
      "Vijay Gupta",
      "Kyriakos Vamvoudakis"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.05939"
  },
  {
    "id": "arXiv:2110.05941",
    "title": "Rank-based loss for learning hierarchical representations",
    "abstract": "Hierarchical taxonomies are common in many contexts, and they are a very\nnatural structure humans use to organise information. In machine learning, the\nfamily of methods that use the 'extra' information is called hierarchical\nclassification. However, applied to audio classification, this remains\nrelatively unexplored. Here we focus on how to integrate the hierarchical\ninformation of a problem to learn embeddings representative of the hierarchical\nrelationships. Previously, triplet loss has been proposed to address this\nproblem, however it presents some issues like requiring the careful\nconstruction of the triplets, and being limited in the extent of hierarchical\ninformation it uses at each iteration. In this work we propose a rank based\nloss function that uses hierarchical information and translates this into a\nrank ordering of target distances between the examples. We show that rank based\nloss is suitable to learn hierarchical representations of the data. By testing\non unseen fine level classes we show that this method is also capable of\nlearning hierarchically correct representations of the new classes. Rank based\nloss has two promising aspects, it is generalisable to hierarchies with any\nnumber of levels, and is capable of dealing with data with incomplete\nhierarchical labels.",
    "descriptor": "\nComments: submitted to ICASSP22\n",
    "authors": [
      "Ines Nolasco",
      "Dan Stowell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05941"
  },
  {
    "id": "arXiv:2110.05942",
    "title": "Resolution of The Linear-Bounded Automata Question",
    "abstract": "This work resolve a longstanding open question in automata theory, i.e. the\n{\\it linear-bounded automata question} ( shortly, {\\it LBA question}), which\ncan also be phrased succinctly in the language of computational complexity\ntheory as $NSPACE[n]\\overset{?}{=}DSPACE[n]$. We prove that $NSPACE[n]\\neq\nDSPACE[n]$. Our proof technique is based on diagonalization against all\ndeterministic Turing machines working in $O(n)$ space. Our proof also implies\nthe following consequences:\n(1) There exists no deterministic Turing machine working in $O(\\log n)$ space\ndeciding the $st$-connectivity question (STCON);\n(2) $L\\neq NL$;\n(3) $L\\neq P$.",
    "descriptor": "\nComments: Comments are welcome\n",
    "authors": [
      "Tianrong Lin"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.05942"
  },
  {
    "id": "arXiv:2110.05945",
    "title": "Multi-condition multi-objective optimization using deep reinforcement  learning",
    "abstract": "A multi-condition multi-objective optimization method that can find Pareto\nfront over a defined condition space is developed for the first time using deep\nreinforcement learning. Unlike the conventional methods which perform\noptimization at a single condition, the present method learns the correlations\nbetween conditions and optimal solutions. The exclusive capability of the\ndeveloped method is examined in the solutions of a novel modified Kursawe\nbenchmark problem and an airfoil shape optimization problem which include\nnonlinear characteristics which are difficult to resolve using conventional\noptimization methods. Pareto front with high resolution over a defined\ncondition space is successfully determined in each problem. Compared with\nmultiple operations of a single-condition optimization method for multiple\nconditions, the present multi-condition optimization method based on deep\nreinforcement learning shows a greatly accelerated search of Pareto front by\nreducing the number of required function evaluations. An analysis of\naerodynamics performance of airfoils with optimally designed shapes confirms\nthat multi-condition optimization is indispensable to avoid significant\ndegradation of target performance for varying flow conditions.",
    "descriptor": "\nComments: 46 pages, 8 figures, 1 algorithm\n",
    "authors": [
      "Sejin Kim",
      "Innyoung Kim",
      "Donghyun You"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2110.05945"
  },
  {
    "id": "arXiv:2110.05947",
    "title": "C3PU: Cross-Coupling Capacitor Processing Unit Using Analog-Mixed Signal  In-Memory Computing for AI Inference",
    "abstract": "This paper presents a novel cross-coupling capacitor processing unit (C3PU)\nthat supports analog-mixed signal in memory computing to perform\nmultiply-and-accumulate (MAC) operations. The C3PU consists of a capacitive\nunit, a CMOS transistor, and a voltage-to-time converter (VTC). The capacitive\nunit serves as a computational element that holds the multiplier operand and\nperforms multiplication once the multiplicand is applied at the terminal. The\nmultiplicand is the input voltage that is converted to a pulse width signal\nusing a low power VTC. The transistor transfers this multiplication where a\nvoltage level is generated. A demonstrator of 5x4 C3PU array that is capable of\nimplementing 4 MAC units is presented. The design has been verified using Monte\nCarlo simulation in 65 nm technology. The 5x4 C3PU consumed energy of 66.4\nfJ/MAC at 0.3 V voltage supply with an error of 5.7%. The proposed unit\nachieves lower energy and occupies a smaller area by 3.4x and 3.6x,\nrespectively, with similar error value when compared to a digital-based 8x4-bit\nfixed point MAC unit. The C3PU has been utilized through an iris fower\nclassification utilizing an artificial neural network which achieved a 90%\nclassification accuracy compared to ideal accuracy of 96.67% using MATLAB.",
    "descriptor": "\nComments: 10 pages, 12 figures and 7 tables\n",
    "authors": [
      "Dima Kilani",
      "Baker Mohammad",
      "Yasmin Halawani",
      "Mohammed F. Tolba",
      "Hani Saleh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.05947"
  },
  {
    "id": "arXiv:2110.05949",
    "title": "Securing music sharing platforms: A Blockchain-Based Approach",
    "abstract": "From online education and trading, all aspects of our lives are affected by\ndigital technology. Among them, the storage of music has also entered the\ndigital era. Music productions created by artists have brought great joy to\npeople. However, when artists upload their works, they are most downloaded and\nreprinted by others, and copyright information and the issue associated with\nthe sharing of music arise. This will have a significant negative impact on the\nenthusiasm and motivation of artists. This paper provides an internet database\nplatform for artists, which uses the distributed and tamper-proof technology of\nEthereum blockchain to store music works, protect the copyright information of\neach album or music produced by artists in the music industry. Design and\nimplementation of the system model and data storage are proposed and data\nstorage processes based on the Ethereum smart contract are demonstrated in\ndetail. The system stores music information on the blockchain network, using\nthe smart contract to provide artists with a fast and efficient royalty\npayment. Node.js is applied to carry out the experiments of our system, and we\ntest Remote Procedure Calls (RPC) with available account and private keys for\ncontract development and use block explorer to track music information on the\nblockchain. Our system enables copyright revenue to be attributed to music\ncreators that helps to eliminate the illegal uploading of music on other\nwebsites.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Isaac Adjei-Mensah",
      "Isaac Osei Agyemang",
      "Collins Sey",
      "Abdulhaq Adetunji Salako"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.05949"
  },
  {
    "id": "arXiv:2110.05951",
    "title": "Evolving Evolutionary Algorithms with Patterns",
    "abstract": "A new model for evolving Evolutionary Algorithms (EAs) is proposed in this\npaper. The model is based on the Multi Expression Programming (MEP) technique.\nEach MEP chromosome encodes an evolutionary pattern that is repeatedly used for\ngenerating the individuals of a new generation. The evolved pattern is embedded\ninto a standard evolutionary scheme that is used for solving a particular\nproblem. Several evolutionary algorithms for function optimization are evolved\nby using the considered model. The evolved evolutionary algorithms are compared\nwith a human-designed Genetic Algorithm. Numerical experiments show that the\nevolved evolutionary algorithms can compete with standard approaches for\nseveral well-known benchmarking problems.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2109.13110\n",
    "authors": [
      "Mihai Oltean"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05951"
  },
  {
    "id": "arXiv:2110.05954",
    "title": "Mining the Weights Knowledge for Optimizing Neural Network Structures",
    "abstract": "Knowledge embedded in the weights of the artificial neural network can be\nused to improve the network structure, such as in network compression. However,\nthe knowledge is set up by hand, which may not be very accurate, and relevant\ninformation may be overlooked. Inspired by how learning works in the mammalian\nbrain, we mine the knowledge contained in the weights of the neural network\ntoward automatic architecture learning in this paper. We introduce a switcher\nneural network (SNN) that uses as inputs the weights of a task-specific neural\nnetwork (called TNN for short). By mining the knowledge contained in the\nweights, the SNN outputs scaling factors for turning off and weighting neurons\nin the TNN. To optimize the structure and the parameters of TNN simultaneously,\nthe SNN and TNN are learned alternately under the same performance evaluation\nof TNN using stochastic gradient descent. We test our method on widely used\ndatasets and popular networks in classification applications. In terms of\naccuracy, we outperform baseline networks and other structure learning methods\nstably and significantly. At the same time, we compress the baseline networks\nwithout introducing any sparse induction mechanism, and our method, in\nparticular, leads to a lower compression rate when dealing with simpler\nbaselines or more difficult tasks. These results demonstrate that our method\ncan produce a more reasonable structure.",
    "descriptor": "",
    "authors": [
      "Mengqiao Han",
      "Xiabi Liu",
      "Zhaoyang Hai",
      "Xin Duan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05954"
  },
  {
    "id": "arXiv:2110.05955",
    "title": "Developing a Lecture Video Recording System Using Augmented Reality",
    "abstract": "Assistive technology is a prerequisite for making a high-quality lecture\nvideo. It is therefore imperative to edit the lecture video after recording. In\nthis study, we aim to reduce the cumbersome task of lecture video editing by\ndeveloping a system that enables the addition of visual effects in the video\nwhile recording. In particular, we use augmented reality (AR) technology to\ndigitize and display in real-time lecture materials, assistant agents, and\nother recording contents used by the lecturer. Our system realizes such a\nmechanism as a lecture recording environment. In addition, our system based on\nAR technology can support the work of the lecturer, which is difficult to do by\noneself while conducting the lecture, using the information of the lecturer's\nposition and the progress of the lecture. We evaluated the system functionality\nand performance, and verified the system's correct behavior. If the burden of\nmaking lecture videos can be reduced, the lecturer will be able to devote more\ntime to improving the quality of lecture contents, which is expected to\ncontribute to the improvement of lectures.",
    "descriptor": "\nComments: 2021 10th International Congress on Advanced Applied Informatics (IIAI-AAI2021), pp.65-70\n",
    "authors": [
      "Yuma Ito",
      "Masato Kikuchi",
      "Tadachika Ozono",
      "Toramatsu Shintani"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.05955"
  },
  {
    "id": "arXiv:2110.05960",
    "title": "Imitating Deep Learning Dynamics via Locally Elastic Stochastic  Differential Equations",
    "abstract": "Understanding the training dynamics of deep learning models is perhaps a\nnecessary step toward demystifying the effectiveness of these models. In\nparticular, how do data from different classes gradually become separable in\ntheir feature spaces when training neural networks using stochastic gradient\ndescent? In this study, we model the evolution of features during deep learning\ntraining using a set of stochastic differential equations (SDEs) that each\ncorresponds to a training sample. As a crucial ingredient in our modeling\nstrategy, each SDE contains a drift term that reflects the impact of\nbackpropagation at an input on the features of all samples. Our main finding\nuncovers a sharp phase transition phenomenon regarding the {intra-class impact:\nif the SDEs are locally elastic in the sense that the impact is more\nsignificant on samples from the same class as the input, the features of the\ntraining data become linearly separable, meaning vanishing training loss;\notherwise, the features are not separable, regardless of how long the training\ntime is. Moreover, in the presence of local elasticity, an analysis of our SDEs\nshows that the emergence of a simple geometric structure called the neural\ncollapse of the features. Taken together, our results shed light on the\ndecisive role of local elasticity in the training dynamics of neural networks.\nWe corroborate our theoretical analysis with experiments on a synthesized\ndataset of geometric shapes and CIFAR-10.",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Jiayao Zhang",
      "Hua Wang",
      "Weijie J. Su"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.05960"
  },
  {
    "id": "arXiv:2110.05966",
    "title": "Multi-channel Narrow-Band Deep Speech Separation with Full-band  Permutation Invariant Training",
    "abstract": "This paper addresses the problem of multi-channel multi-speech separation\nbased on deep learning techniques. In the short time Fourier transform domain,\nwe propose an end-to-end narrow-band network that directly takes as input the\nmulti-channel mixture signals of one frequency, and outputs the separated\nsignals of this frequency. In narrow-band, the spatial information (or\ninter-channel difference) can well discriminate between speakers at different\npositions. This information is intensively used in many narrow-band speech\nseparation methods, such as beamforming and clustering of spatial vectors. The\nproposed network is trained to learn a rule to automatically exploit this\ninformation and perform speech separation. Such a rule should be valid for any\nfrequency, thence the network is shared by all frequencies. In addition, a\nfull-band permutation invariant training criterion is proposed to solve the\nfrequency permutation problem encountered by most narrow-band methods.\nExperiments show that, by focusing on deeply learning the narrow-band\ninformation, the proposed method outperforms the oracle beamforming method and\nthe state-of-the-art deep learning based method.",
    "descriptor": "\nComments: submitted to ICASSP 2022\n",
    "authors": [
      "Changsheng Quan",
      "Xiaofei Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05966"
  },
  {
    "id": "arXiv:2110.05973",
    "title": "Can machines learn to see without visual databases?",
    "abstract": "This paper sustains the position that the time has come for thinking of\nlearning machines that conquer visual skills in a truly human-like context,\nwhere a few human-like object supervisions are given by vocal interactions and\npointing aids only. This likely requires new foundations on computational\nprocesses of vision with the final purpose of involving machines in tasks of\nvisual description by living in their own visual environment under simple\nman-machine linguistic interactions. The challenge consists of developing\nmachines that learn to see without needing to handle visual databases. This\nmight open the doors to a truly orthogonal competitive track concerning deep\nlearning technologies for vision which does not rely on the accumulation of\nhuge visual databases.",
    "descriptor": "",
    "authors": [
      "Alessandro Betti",
      "Marco Gori",
      "Stefano Melacci",
      "Marcello Pelillo",
      "Fabio Roli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05973"
  },
  {
    "id": "arXiv:2110.05975",
    "title": "Frame-level multi-channel speaker verification with large-scale ad-hoc  microphone arrays",
    "abstract": "Automatic speaker verification (ASV) with ad-hoc microphone arrays has\nreceived attention. Unlike traditional microphone arrays, the number of\nmicrophones and their spatial arrangement in an ad-hoc microphone array is\nunknown, which makes conventional multi-channel ASV techniques ineffective in\nad-hoc microphone array settings. Recently, an utterance-level ASV with ad-hoc\nmicrophone arrays has been proposed, which first extracts utterance-level\nspeaker embeddings from each channel of an ad-hoc microphone array, and then\nfuses the embeddings for the final verification. However, this method cannot\nmake full use of the cross-channel information. In this paper, we present a\nnovel multi-channel ASV model at the frame-level. Specifically, we add\nspatio-temporal processing blocks (STB) before the pooling layer, which models\nthe contextual relationship within and between channels and across time,\nrespectively. The channel-attended outputs from STB are sent to the pooling\nlayer to obtain an utterance-level speaker representation. Experimental results\ndemonstrate the effectiveness of the proposed method.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2107.00178\n",
    "authors": [
      "Chengdong Liang",
      "Jiadi Yao",
      "Xiao-Lei Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05975"
  },
  {
    "id": "arXiv:2110.05977",
    "title": "Datasets are not Enough: Challenges in Labeling Network Traffic",
    "abstract": "In contrast to previous surveys, the present work is not focused on reviewing\nthe datasets used in the network security field. The fact is that many of the\navailable public labeled datasets represent the network behavior just for a\nparticular time period. Given the rate of change in malicious behavior and the\nserious challenge to label, and maintain these datasets, they become quickly\nobsolete. Therefore, this work is focused on the analysis of current labeling\nmethodologies applied to network-based data. In the field of network security,\nthe process of labeling a representative network traffic dataset is\nparticularly challenging and costly since very specialized knowledge is\nrequired to classify network traces. Consequently, most of the current traffic\nlabeling methods are based on the automatic generation of synthetic network\ntraces, which hides many of the essential aspects necessary for a correct\ndifferentiation between normal and malicious behavior. Alternatively, a few\nother methods incorporate non-experts users in the labeling process of real\ntraffic with the help of visual and statistical tools. However, after\nconducting an in-depth analysis, it seems that all current methods for labeling\nsuffer from fundamental drawbacks regarding the quality, volume, and speed of\nthe resulting dataset. This lack of consistent methods for continuously\ngenerating a representative dataset with an accurate and validated methodology\nmust be addressed by the network security research community. Moreover, a\nconsistent label methodology is a fundamental condition for helping in the\nacceptance of novel detection approaches based on statistical and machine\nlearning techniques.",
    "descriptor": "",
    "authors": [
      "Jorge Guerra",
      "Carlos Catania",
      "Eduardo Veas"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.05977"
  },
  {
    "id": "arXiv:2110.05992",
    "title": "Weighted Model Counting in FO2 with Cardinality Constraints and Counting  Quantifiers: A Closed Form Formula",
    "abstract": "Weighted First-Order Model Counting (WFOMC) computes the weighted sum of the\nmodels of a first-order logic theory on a given finite domain. First-Order\nLogic theories that admit polynomial-time WFOMC w.r.t domain cardinality are\ncalled domain liftable. We introduce the concept of lifted interpretations as a\ntool for formulating closed-forms for WFOMC. Using lifted interpretations, we\nreconstruct the closed-form formula for polynomial-time FOMC in the universally\nquantified fragment of FO2, earlier proposed by Beame et al. We then expand\nthis closed-form to incorporate cardinality constraints, existential\nquantifiers, and counting quantifiers (a.k.a C2) without losing\ndomain-liftability. Finally, we show that the obtained closed-form motivates a\nnatural definition of a family of weight functions strictly larger than\nsymmetric weight functions.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2009.12237\n",
    "authors": [
      "Sagar Malhotra",
      "Luciano Serafini"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Combinatorics (math.CO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.05992"
  },
  {
    "id": "arXiv:2110.05997",
    "title": "Tensor decompositions and algorithms, with applications to tensor  learning",
    "abstract": "A new algorithm of the canonical polyadic decomposition (CPD) presented here.\nIt features lower computational complexity and memory usage than the available\nstate of the art implementations.\nWe begin with some examples of CPD applications to real world problems. A\nshort summary of the main contributions in this work follows. In chapter 1 we\nreview classical tensor algebra and geometry, with focus on the CPD. Chapter 2\nfocuses on tensor compression, which is considered (in this work) to be one of\nthe most important parts of the CPD algorithm. In chapter 3 we talk about the\nGauss-Newton method, which is a nonlinear least squares method used to minimize\nnonlinear functions. Chapter 4 is the longest one of this thesis. In this\nchapter we introduce the main character of this thesis: Tensor Fox. Basically\nit is a tensor package which includes a CPD solver. After introducing Tensor\nFox we will conduct lots of computational experiments comparing this solver\nwith several others. At the end of this chapter we introduce the Tensor Train\ndecomposition and show how to use it to compute higher order CPDs. We also\ndiscuss some important details such as regularization, preconditioning,\nconditioning, parallelism, etc. In chapter 5 we consider the intersection\nbetween tensor decompositions and machine learning. A novel model is\nintroduced, which works as a tensor version of neural networks. Finally, in\nchapter 6 we reach the final conclusions and introduce our expectations for\nfuture developments.",
    "descriptor": "",
    "authors": [
      "Felipe Bottega Diniz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05997"
  },
  {
    "id": "arXiv:2110.05999",
    "title": "DiscoDVT: Generating Long Text with Discourse-Aware Discrete Variational  Transformer",
    "abstract": "Despite the recent advances in applying pre-trained language models to\ngenerate high-quality texts, generating long passages that maintain long-range\ncoherence is yet challenging for these models. In this paper, we propose\nDiscoDVT, a discourse-aware discrete variational Transformer to tackle the\nincoherence issue. DiscoDVT learns a discrete variable sequence that summarizes\nthe global structure of the text and then applies it to guide the generation\nprocess at each decoding step. To further embed discourse-aware information\ninto the discrete latent representations, we introduce an auxiliary objective\nto model the discourse relations within the text. We conduct extensive\nexperiments on two open story generation datasets and demonstrate that the\nlatent codes learn meaningful correspondence to the discourse structures that\nguide the model to generate long texts with better long-range coherence.",
    "descriptor": "\nComments: Accepted by EMNLP 2021\n",
    "authors": [
      "Haozhe Ji",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05999"
  },
  {
    "id": "arXiv:2110.06003",
    "title": "Impact of delay classes on the data structure in IOTA",
    "abstract": "In distributed ledger technologies (DLTs) with a directed acyclic graph (DAG)\ndata structure, a message-issuing node can decide where to append that message\nand, consequently, how to grow the DAG. This DAG data structure can typically\nbe decomposed into two pools of messages: referenced messages and unreferenced\nmessages (tips). The selection of the parent messages to which a node appends\nthe messages it issues, depends on which messages it considers as tips.\nHowever, the exact time that a message enters the tip pool of a node depends on\nthe delay of that message. In previous works, it was considered that messages\nhave the same or similar delay; however, this generally may not be the case. We\nintroduce the concept of classes of delays, where messages belonging to a\ncertain class have a specific delay, and where these classes coexist in the\nDAG. We provide a general model that predicts the tip pool size for any finite\nnumber of different classes.\nThis categorisation and model is applied to the first iteration of the IOTA\n2.0 protocol (a.k.a. Coordicide), where two distinct classes, namely value and\ndata messages, coexist. We show that the tip pool size depends strongly on the\ndominating class that is present. Finally, we provide a methodology for\ncontrolling the tip pool size by dynamically adjusting the number of references\na message creates.",
    "descriptor": "\nComments: Presented at CBT2021 - 5th Cryptocurrencies and Blockchain Technology workshop this https URL\n",
    "authors": [
      "Andreas Penzkofer",
      "Olivia Saa",
      "Daria Dziuba\u0142towska"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.06003"
  },
  {
    "id": "arXiv:2110.06006",
    "title": "Robust Glare Detection: Review, Analysis, and Dataset Release",
    "abstract": "Sun Glare widely exists in the images captured by unmanned ground and aerial\nvehicles performing in outdoor environments. The existence of such artifacts in\nimages will result in wrong feature extraction and failure of autonomous\nsystems. Humans will try to adapt their view once they observe a glare\n(especially when driving), and this behavior is an essential requirement for\nthe next generation of autonomous vehicles. The source of glare is not limited\nto the sun, and glare can be seen in the images captured during the nighttime\nand in indoor environments, which is due to the presence of different light\nsources; reflective surfaces also influence the generation of such artifacts.\nThe glare's visual characteristics are different on images captured by various\ncameras and depend on several factors such as the camera's shutter speed and\nexposure level. Hence, it is challenging to introduce a general - robust and\naccurate - algorithm for glare detection that can perform well in various\ncaptured images. This research aims to introduce the first dataset for glare\ndetection, which includes images captured by different cameras. Besides, the\neffect of multiple image representations and their combination in glare\ndetection is examined using the proposed deep network architecture. The\nreleased dataset is available at https://github.com/maesfahani/glaredetection",
    "descriptor": "",
    "authors": [
      "Mahdi Abolfazli Esfahani",
      "Han Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.06006"
  },
  {
    "id": "arXiv:2110.06009",
    "title": "Dynamics of scientific collaboration networks due to academic migrations",
    "abstract": "Academic migration is the change of host institution by a researcher,\ntypically aimed at achieving a stronger research profile. Scientific features\nsuch as the number of collaborations, the productivity and its research impact\ntend to be directly affected by such movements. In this paper, we analyse the\ndynamics of the collaboration network of researchers as they move from an\ninstitution to the next one. We specifically highlight cases where they\nincrease and when they shrink, and quantify the dependency between the\ncollaboration networks before and after such a movement. Finally, we drill down\nthe analysis by dividing movements depending on the career stage of the\nresearchers. The analysis shows a remarkable dynamism of collaboration networks\nacross migrations. Interestingly, not always movements result in larger\ncollaboration networks, while the overall similarity between networks across\nmovements is quite limited on average. Qualitatively, the same effects can be\nfound at all career stages, while, clearly, the magnitude of them might vary.\nThese results are based on a dataset extracted from Scopus, containing detailed\nscientific information for the publications of 84,141 researchers.",
    "descriptor": "\nComments: This work was partially funded by the following projects. European Union's Horizon 2020 research and innovation programme: SoBigData++ (No 871042), HumaneAI-Net (No 952026), MARVEL (No 957337). Italian PON-MISE program: OK-INSAID project (No ARS01 00917)\n",
    "authors": [
      "Pavlos Paraskevopoulos",
      "Chiara Boldrini",
      "Andrea Passarella",
      "Marco Conti"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.06009"
  },
  {
    "id": "arXiv:2110.06011",
    "title": "A Modeling Framework for Efficient Reduced Order Simulations of  Parametrized Lithium-Ion Battery Cells",
    "abstract": "In this contribution we present a new modeling and simulation framework for\nparametrized Lithium-ion battery cells. We first derive a new continuum model\nfor a rather general intercalation battery cell on the basis of non-equilibrium\nthermodynamics. In order to efficiently evaluate the resulting parameterized\nnon-linear system of partial differential equations the reduced basis method is\nemployed. The reduced basis method is a model order reduction technique on the\nbasis of an incremental hierarchical approximate proper orthogonal\ndecomposition approach and empirical operator interpolation. The modeling\nframework is particularly well suited to investigate and quantify degradation\neffects of battery cells. Several numerical experiments are given to\ndemonstrate the scope and efficiency of the modeling framework.",
    "descriptor": "",
    "authors": [
      "M. Landstorfer",
      "M. Ohlberger",
      "S. Rave",
      "M. Tacke"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.06011"
  },
  {
    "id": "arXiv:2110.06013",
    "title": "On Wave-Based Majority Gates with Cellular Automata",
    "abstract": "We demonstrate a discrete implementation of a wave-based majority gate in a\nchaotic Life-like cellular automaton. The gate functions via controlling of\npatterns' propagation into stationary channels. The gate presented is\nrealisable in many living and non-living substrates that show wave-like\nactivity of its space-time dynamics or pattern propagation. In the gate a\nsymmetric pattern represents a binary value 0 while a non-symmetric pattern\nrepresents a binary value 1. Origination of the patterns and their symmetry\ntype are encoded by the particle reactions at the beginning of computation. The\npatterns propagate in channels of the gate and compete for the space at the\nintersection of the channels. We implement 3-inputs majority gates using a W\ntopology showing additional implementations of 5-inputs majority gates and one\ntree (cascade) majority gate.",
    "descriptor": "\nComments: 18 pages, 12 figures, 2 tables. this https URL\n",
    "authors": [
      "Genaro J. Martinez",
      "Andrew Adamatzky",
      "Shigeru Ninagawa",
      "Kenichi Morita"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cellular Automata and Lattice Gases (nlin.CG)"
    ],
    "url": "https://arxiv.org/abs/2110.06013"
  },
  {
    "id": "arXiv:2110.06014",
    "title": "Rethinking supervised pre-training for better downstream transferring",
    "abstract": "The pretrain-finetune paradigm has shown outstanding performance on many\napplications of deep learning, where a model is pre-trained on a upstream large\ndataset (e.g. ImageNet), and is then fine-tuned to different downstream tasks.\nThough for most cases, the pre-training stage is conducted based on supervised\nmethods, recent works on self-supervised pre-training have shown powerful\ntransferability and even outperform supervised pre-training on multiple\ndownstream tasks. It thus remains an open question how to better generalize\nsupervised pre-training model to downstream tasks. In this paper, we argue that\nthe worse transferability of existing supervised pre-training methods arise\nfrom the negligence of valuable intra-class semantic difference. This is\nbecause these methods tend to push images from the same class close to each\nother despite of the large diversity in their visual contents, a problem to\nwhich referred as \"overfit of upstream tasks\". To alleviate this problem, we\npropose a new supervised pre-training method based on Leave-One-Out\nK-Nearest-Neighbor, or LOOK for short. It relieves the problem of overfitting\nupstream tasks by only requiring each image to share its class label with most\nof its k nearest neighbors, thus allowing each class to exhibit a multi-mode\ndistribution and consequentially preserving part of intra-class difference for\nbetter transferring to downstream tasks. We developed efficient implementation\nof the proposed method that scales well to large datasets. Experimental studies\non multiple downstream tasks show that LOOK outperforms other state-of-the-art\nmethods for supervised and self-supervised pre-training.",
    "descriptor": "",
    "authors": [
      "Yutong Feng",
      "Jianwen Jiang",
      "Mingqian Tang",
      "Rong Jin",
      "Yue Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06014"
  },
  {
    "id": "arXiv:2110.06015",
    "title": "Structural invariants in individuals language use: the \"ego network\" of  words",
    "abstract": "The cognitive constraints that humans exhibit in their social interactions\nhave been extensively studied by anthropologists, who have highlighted their\nregularities across different types of social networks. We postulate that\nsimilar regularities can be found in other cognitive processes, such as those\ninvolving language production. In order to provide preliminary evidence for\nthis claim, we analyse a dataset containing tweets of a heterogeneous group of\nTwitter users (regular users and professional writers). Leveraging a\nmethodology similar to the one used to uncover the well-established social\ncognitive constraints, we find that a concentric layered structure (which we\ncall ego network of words, in analogy to the ego network of social\nrelationships) very well captures how individuals organise the words they use.\nThe size of the layers in this structure regularly grows (approximately 2-3\ntimes with respect to the previous one) when moving outwards, and the two\npenultimate external layers consistently account for approximately 60% and 30%\nof the used words (the outermost layer contains 100% of the words),\nirrespective of the number of the total number of layers of the user.",
    "descriptor": "\nComments: This work was partially funded by the following projects. European Union's Horizon 2020 research and innovation programme: SoBigData++ (No 871042), HumaneAI-Net (No 952026), MARVEL (No 957337). Italian PON-MISE program: OK-INSAID project (No ARS01 00917)\n",
    "authors": [
      "Kilian Ollivier",
      "Chiara Boldrini",
      "Andrea Passarella",
      "Marco Conti"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.06015"
  },
  {
    "id": "arXiv:2110.06018",
    "title": "On the Security Risks of AutoML",
    "abstract": "Neural Architecture Search (NAS) represents an emerging machine learning (ML)\nparadigm that automatically searches for models tailored to given tasks, which\ngreatly simplifies the development of ML systems and propels the trend of ML\ndemocratization. Yet, little is known about the potential security risks\nincurred by NAS, which is concerning given the increasing use of NAS-generated\nmodels in critical domains.\nThis work represents a solid initial step towards bridging the gap. Through\nan extensive empirical study of 10 popular NAS methods, we show that compared\nwith their manually designed counterparts, NAS-generated models tend to suffer\ngreater vulnerability to various malicious attacks (e.g., adversarial evasion,\nmodel poisoning, and functionality stealing). Further, with both empirical and\nanalytical evidence, we provide possible explanations for such phenomena: given\nthe prohibitive search space and training cost, most NAS methods favor models\nthat converge fast at early training stages; this preference results in\narchitectural properties associated with attack vulnerability (e.g., high loss\nsmoothness and low gradient variance). Our findings not only reveal the\nrelationships between model characteristics and attack vulnerability but also\nsuggest the inherent connections underlying different attacks. Finally, we\ndiscuss potential remedies to mitigate such drawbacks, including increasing\ncell depth and suppressing skip connects, which lead to several promising\nresearch directions.",
    "descriptor": "\nComments: Accepted as a full paper at USENIX Security '22\n",
    "authors": [
      "Ren Pang",
      "Zhaohan Xi",
      "Shouling Ji",
      "Xiapu Luo",
      "Ting Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06018"
  },
  {
    "id": "arXiv:2110.06019",
    "title": "Secure Email -- A Usability Study",
    "abstract": "Several end-to-end encryption technologies for emails such as PGP and S/MIME\nexist since decades. However, end-to-end encryption is barely applied. To\nunderstand why users hesitate to secure their email communication and which\nusability issues they face with PGP, S/MIME as well as with pEp (Pretty Easy\nPrivacy), a fairly new technology, we conducted an online survey and user\ntesting. We found that more than 60% of e-mail users are unaware of the\nexistence of such encryption technologies and never tried to use one. We\nobserved that above all, users are overwhelmed with the management of public\nkeys and struggle with the setup of encryption technology in their mail\nsoftware. Even though users struggle to put email encryption into practice, we\nexperienced roughly the same number of users being aware of the importance of\nemail encryption. Particularly, we found that users are very concerned about\nidentity theft, as 78% want to make sure that no other person is able to write\nemail in their name.",
    "descriptor": "",
    "authors": [
      "Adrian Reuter",
      "Karima Boudaoud",
      "Marco Winckler",
      "Ahmed Abdelmaksoud",
      "Wadie Lemrazzeq"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.06019"
  },
  {
    "id": "arXiv:2110.06020",
    "title": "Uncertainty-based out-of-distribution detection requires suitable  function space priors",
    "abstract": "The need to avoid confident predictions on unfamiliar data has sparked\ninterest in out-of-distribution (OOD) detection. It is widely assumed that\nBayesian neural networks (BNNs) are well suited for this task, as the endowed\nepistemic uncertainty should lead to disagreement in predictions on outliers.\nIn this paper, we question this assumption and show that proper Bayesian\ninference with function space priors induced by neural networks does not\nnecessarily lead to good OOD detection. To circumvent the use of approximate\ninference, we start by studying the infinite-width case, where Bayesian\ninference can be exact due to the correspondence with Gaussian processes.\nStrikingly, the kernels induced under common architectural choices lead to\nuncertainties that do not reflect the underlying data generating process and\nare therefore unsuited for OOD detection. Importantly, we find this OOD\nbehavior to be consistent with the corresponding finite-width networks.\nDesirable function space properties can be encoded in the prior in weight\nspace, however, this currently only applies to a specified subset of the domain\nand thus does not inherently extend to OOD data. Finally, we argue that a\ntrade-off between generalization and OOD capabilities might render the\napplication of BNNs for OOD detection undesirable in practice. Overall, our\nstudy discloses fundamental problems when naively using BNNs for OOD detection\nand opens interesting avenues for future research.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2107.12248\n",
    "authors": [
      "Francesco D'Angelo",
      "Christian Henning"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06020"
  },
  {
    "id": "arXiv:2110.06022",
    "title": "Smart Crawling: A New Approach toward Focus Crawling from Twitter",
    "abstract": "Twitter is a social network that offers a rich and interesting source of\ninformation challenging to retrieve and analyze. Twitter data can be accessed\nusing a REST API. The available operations allow retrieving tweets on the basis\nof a set of keywords but with limitations such as the number of calls per\nminute and the size of results. Besides, there is no control on retrieved\nresults and finding tweets which are relevant to a specific topic is a big\nissue. Given these limitations, it is important that the query keywords cover\nunambiguously the topic of interest in order to both reach the relevant answers\nand decrease the number of API calls. In this paper, we introduce a new\ncrawling algorithm called \"SmartTwitter Crawling\" (STiC) that retrieves a set\nof tweets related to a target topic. In this algorithm, we take an initial\nkeyword query and enrich it using a set of additional keywords that come from\ndifferent data sources. STiC algorithm relies on a DFS search in Twittergraph\nwhere each reached tweet is considered if it is relevant with the query\nkeywords using a scoring, updated throughout the whole crawling process. This\nscoring takes into account the tweet text, hashtags and the users who have\nposted the tweet, replied to the tweet, been mentioned in the tweet or\nretweeted the tweet. Given this score, STiC is able to select relevant tweets\nin each iteration and continue by adding the related valuable tweets. Several\nexperiments have been achieved for different kinds of queries, the results\nshowedthat the precision increases compared to a simple BFS search.",
    "descriptor": "",
    "authors": [
      "Ahmad Khazaie",
      "Nac\u00e9ra Bennacer Seghouani",
      "Francesca Bugiotti"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.06022"
  },
  {
    "id": "arXiv:2110.06025",
    "title": "Privacy-Preserving Phishing Email Detection Based on Federated Learning  and LSTM",
    "abstract": "Phishing emails that appear legitimate lure people into clicking on the\nattached malicious links or documents. Increasingly more sophisticated phishing\ncampaigns in recent years necessitate a more adaptive detection system other\nthan traditional signature-based methods. In this regard, natural language\nprocessing (NLP) with deep neural networks (DNNs) is adopted for knowledge\nacquisition from a large number of emails. However, such sensitive daily\ncommunications containing personal information are difficult to collect on a\nserver for centralized learning in real life due to escalating privacy\nconcerns. To this end, we propose a decentralized phishing email detection\nmethod called the Federated Phish Bowl (FPB) leveraging federated learning and\nlong short-term memory (LSTM). FPB allows common knowledge representation and\nsharing among different clients through the aggregation of trained models to\nsafeguard the email security and privacy. A recent phishing email dataset was\ncollected from an intergovernmental organization to train the model. Moreover,\nwe evaluated the model performance based on various assumptions regarding the\ntotal client number and the level of data heterogeneity. The comprehensive\nexperimental results suggest that FPB is robust to a continually increasing\nclient number and various data heterogeneity levels, retaining a detection\naccuracy of 0.83 and protecting the privacy of sensitive email communications.",
    "descriptor": "",
    "authors": [
      "Yuwei Sun",
      "Ng Chong",
      "Hideya Ochiai"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06025"
  },
  {
    "id": "arXiv:2110.06028",
    "title": "Auction-Based vs Continuous Clearing in Local Flexibility Markets with  Block Bids",
    "abstract": "Flexibility markets can be introduced as a tool for the distribution system\noperator (DSO) to avoid high costs and public opposition against new network\ninvestments. Continuous flexibility markets have the advantage of allowing more\nliquidity, which can be critical in the earlier stages of such markets, and can\nbe operated closer to real-time, thereby enabling a better use of the latest\nforecasts; but, by design, they also result to a lower social welfare compared\nto auction-based markets. This paper has two main contributions. First, it\nintroduces a continuous local flexibility market which includes both network\nconstraints and asymmetric block bids. Second, it proposes an algorithm that\ncan accurately determine the upper and lower bound of the social welfare loss\ncompared with an auction-based clearing model.",
    "descriptor": "",
    "authors": [
      "Alicia Alarc\u00f3n Cobacho",
      "El\u00e9a Prat",
      "Daniel V\u00e1zquez Pombo",
      "Spyros Chatzivasileiadis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.06028"
  },
  {
    "id": "arXiv:2110.06037",
    "title": "SoftNeuro: Fast Deep Inference using Multi-platform Optimization",
    "abstract": "Faster inference of deep learning models is highly demanded on edge devices\nand even servers, for both financial and environmental reasons. To address this\nissue, we propose SoftNeuro, a novel, high-performance inference framework with\nefficient performance tuning. The key idea is to separate algorithmic routines\nfrom network layers. Our framework maximizes the inference performance by\nprofiling various routines for each layer and selecting the fastest path. To\nefficiently find the best path, we propose a routine-selection algorithm based\non dynamic programming. Experiments show that the proposed framework achieves\nboth fast inference and efficient tuning.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Masaki Hilaga",
      "Yasuhiro Kuroda",
      "Hitoshi Matsuo",
      "Tatsuya Kawaguchi",
      "Gabriel Ogawa",
      "Hiroshi Miyake",
      "Yusuke Kozawa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06037"
  },
  {
    "id": "arXiv:2110.06042",
    "title": "SlideGraph+: Whole Slide Image Level Graphs to Predict HER2Status in  Breast Cancer",
    "abstract": "Human epidermal growth factor receptor 2 (HER2) is an important prognostic\nand predictive factor which is overexpressed in 15-20% of breast cancer (BCa).\nThe determination of its status is a key clinical decision making step for\nselection of treatment regimen and prognostication. HER2 status is evaluated\nusing transcroptomics or immunohistochemistry (IHC) through situ hybridisation\n(ISH) which require additional costs and tissue burden in addition to\nanalytical variabilities in terms of manual observational biases in scoring. In\nthis study, we propose a novel graph neural network (GNN) based model (termed\nSlideGraph+) to predict HER2 status directly from whole-slide images of routine\nHaematoxylin and Eosin (H&E) slides. The network was trained and tested on\nslides from The Cancer Genome Atlas (TCGA) in addition to two independent test\ndatasets. We demonstrate that the proposed model outperforms the\nstate-of-the-art methods with area under the ROC curve (AUC) values > 0.75 on\nTCGA and 0.8 on independent test sets. Our experiments show that the proposed\napproach can be utilised for case triaging as well as pre-ordering diagnostic\ntests in a diagnostic setting. It can also be used for other weakly supervised\nprediction problems in computational pathology. The SlideGraph+ code is\navailable at https://github.com/wenqi006/SlideGraph.",
    "descriptor": "\nComments: 20 pages, 11 figures, 3 tables\n",
    "authors": [
      "Wenqi Lu",
      "Michael Toss",
      "Emad Rakha",
      "Nasir Rajpoot",
      "Fayyaz Minhas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06042"
  },
  {
    "id": "arXiv:2110.06043",
    "title": "Topic Model Supervised by Understanding Map",
    "abstract": "Inspired by the notion of Center of Mass in physics, an extension called\nSemantic Center of Mass (SCOM) is proposed, and used to discover the abstract\n\"topic\" of a document. The notion is under a framework model called\nUnderstanding Map Supervised Topic Model (UM-S-TM). The devise aim of UM-S-TM\nis to let both the document content and a semantic network -- specifically,\nUnderstanding Map -- play a role, in interpreting the meaning of a document.\nBased on different justifications, three possible methods are devised to\ndiscover the SCOM of a document. Some experiments on artificial documents and\nUnderstanding Maps are conducted to test their outcomes. In addition, its\nability of vectorization of documents and capturing sequential information are\ntested. We also compared UM-S-TM with probabilistic topic models like Latent\nDirichlet Allocation (LDA) and probabilistic Latent Semantic Analysis (pLSA).",
    "descriptor": "",
    "authors": [
      "Gangli Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06043"
  },
  {
    "id": "arXiv:2110.06049",
    "title": "Improved Pillar with Fine-grained Feature for 3D Object Detection",
    "abstract": "3D object detection with LiDAR point clouds plays an important role in\nautonomous driving perception module that requires high speed, stability and\naccuracy. However, the existing point-based methods are challenging to reach\nthe speed requirements because of too many raw points, and the voxel-based\nmethods are unable to ensure stable speed because of the 3D sparse convolution.\nIn contrast, the 2D grid-based methods, such as PointPillar, can easily achieve\na stable and efficient speed based on simple 2D convolution, but it is hard to\nget the competitive accuracy limited by the coarse-grained point clouds\nrepresentation. So we propose an improved pillar with fine-grained feature\nbased on PointPillar that can significantly improve detection accuracy. It\nconsists of two modules, including height-aware sub-pillar and sparsity-based\ntiny-pillar, which get fine-grained representation respectively in the vertical\nand horizontal direction of 3D space. For height-aware sub-pillar, we introduce\na height position encoding to keep height information of each sub-pillar during\nprojecting to a 2D pseudo image. For sparsity-based tiny-pillar, we introduce\nsparsity-based CNN backbone stacked by dense feature and sparse attention\nmodule to extract feature with larger receptive field efficiently. Experimental\nresults show that our proposed method significantly outperforms previous\nstate-of-the-art 3D detection methods on the Waymo Open Dataset. The related\ncode will be released to facilitate the academic and industrial study.",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Jiahui Fu",
      "Guanghui Ren",
      "Yunpeng Chen",
      "Si Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06049"
  },
  {
    "id": "arXiv:2110.06051",
    "title": "Fast Forward Indexes for Efficient Document Ranking",
    "abstract": "Neural approaches, specifically transformer models, for ranking documents\nhave delivered impressive gains in ranking performance. However, query\nprocessing using such over-parameterized models is both resource and time\nintensive. Consequently, to keep query processing costs manageable, trade-offs\nare made to reduce the number of documents to be re-ranked or consider leaner\nmodels with fewer parameters.\nIn this paper, we propose the fast-forward index -- a simple vector forward\nindex that facilitates ranking documents using interpolation-based ranking\nmodels. Fast-forward indexes pre-compute the dense transformer-based vector\nrepresentations of documents and passages for fast CPU-based semantic\nsimilarity computation during query processing. We propose theoretically\ngrounded index pruning and early stopping techniques to improve the\nquery-processing throughput using fast-forward indexes. We conduct extensive\nlarge-scale experiments over the TREC-DL datasets and show up to 75%\nimprovement in query-processing performance over hybrid indexes using only\nCPUs. Along with the efficiency benefits, we show that fast-forward indexes can\ndeliver superior ranking performance due to the complementary benefits of\ninterpolation between lexical and semantic similarities.",
    "descriptor": "",
    "authors": [
      "Jurek Leonhardt",
      "Koustav Rudra",
      "Megha Khosla",
      "Abhijit Anand",
      "Avishek Anand"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.06051"
  },
  {
    "id": "arXiv:2110.06057",
    "title": "Gated Information Bottleneck for Generalization in Sequential  Environments",
    "abstract": "Deep neural networks suffer from poor generalization to unseen environments\nwhen the underlying data distribution is different from that in the training\nset. By learning minimum sufficient representations from training data, the\ninformation bottleneck (IB) approach has demonstrated its effectiveness to\nimprove generalization in different AI applications. In this work, we propose a\nnew neural network-based IB approach, termed gated information bottleneck\n(GIB), that dynamically drops spurious correlations and progressively selects\nthe most task-relevant features across different environments by a trainable\nsoft mask (on raw features). GIB enjoys a simple and tractable objective,\nwithout any variational approximation or distributional assumption. We\nempirically demonstrate the superiority of GIB over other popular neural\nnetwork-based IB approaches in adversarial robustness and out-of-distribution\n(OOD) detection. Meanwhile, we also establish the connection between IB theory\nand invariant causal representation learning, and observed that GIB\ndemonstrates appealing performance when different environments arrive\nsequentially, a more practical scenario where invariant risk minimization (IRM)\nfails. Code of GIB is available at https://github.com/falesiani/GIB",
    "descriptor": "\nComments: manuscript accepted by IEEE ICDM-21 (regular papers), code is available at this https URL\n",
    "authors": [
      "Francesco Alesiani",
      "Shujian Yu",
      "Xi Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06057"
  },
  {
    "id": "arXiv:2110.06058",
    "title": "Multi-Modal Interaction Graph Convolutional Network for Temporal  Language Localization in Videos",
    "abstract": "This paper focuses on tackling the problem of temporal language localization\nin videos, which aims to identify the start and end points of a moment\ndescribed by a natural language sentence in an untrimmed video. However, it is\nnon-trivial since it requires not only the comprehensive understanding of the\nvideo and sentence query, but also the accurate semantic correspondence capture\nbetween them. Existing efforts are mainly centered on exploring the sequential\nrelation among video clips and query words to reason the video and sentence\nquery, neglecting the other intra-modal relations (e.g., semantic similarity\namong video clips and syntactic dependency among the query words). Towards this\nend, in this work, we propose a Multi-modal Interaction Graph Convolutional\nNetwork (MIGCN), which jointly explores the complex intra-modal relations and\ninter-modal interactions residing in the video and sentence query to facilitate\nthe understanding and semantic correspondence capture of the video and sentence\nquery. In addition, we devise an adaptive context-aware localization method,\nwhere the context information is taken into the candidate moments and the\nmulti-scale fully connected layers are designed to rank and adjust the boundary\nof the generated coarse candidate moments with different lengths. Extensive\nexperiments on Charades-STA and ActivityNet datasets demonstrate the promising\nperformance and superior efficiency of our model.",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Image Processing\n",
    "authors": [
      "Zongmeng Zhang",
      "Xianjing Han",
      "Xuemeng Song",
      "Yan Yan",
      "Liqiang Nie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06058"
  },
  {
    "id": "arXiv:2110.06059",
    "title": "Development of Deep Transformer-Based Models for Long-Term Prediction of  Transient Production of Oil Wells",
    "abstract": "We propose a novel approach to data-driven modeling of a transient production\nof oil wells. We apply the transformer-based neural networks trained on the\nmultivariate time series composed of various parameters of oil wells measured\nduring their exploitation. By tuning the machine learning models for a single\nwell (ignoring the effect of neighboring wells) on the open-source field\ndatasets, we demonstrate that transformer outperforms recurrent neural networks\nwith LSTM/GRU cells in the forecasting of the bottomhole pressure dynamics. We\napply the transfer learning procedure to the transformer-based surrogate model,\nwhich includes the initial training on the dataset from a certain well and\nadditional tuning of the model's weights on the dataset from a target well.\nTransfer learning approach helps to improve the prediction capability of the\nmodel. Next, we generalize the single-well model based on the transformer\narchitecture for multiple wells to simulate complex transient oilfield-level\npatterns. In other words, we create the global model which deals with the\ndataset, comprised of the production history from multiple wells, and allows\nfor capturing the well interference resulting in more accurate prediction of\nthe bottomhole pressure or flow rate evolutions for each well under\nconsideration. The developed instruments for a single-well and oilfield-scale\nmodelling can be used to optimize the production process by selecting the\noperating regime and submersible equipment to increase the hydrocarbon\nrecovery. In addition, the models can be helpful to perform well-testing\navoiding costly shut-in operations.",
    "descriptor": "",
    "authors": [
      "Ildar Abdrakhmanov",
      "Evgenii Kanin",
      "Sergei Boronin",
      "Evgeny Burnaev",
      "Andrei Osiptsov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06059"
  },
  {
    "id": "arXiv:2110.06060",
    "title": "Downtime-Aware O-RAN VNF Deployment Strategy for Optimized Self-Healing  in the O-Cloud",
    "abstract": "Due to the huge surge in the traffic of IoT devices and applications, mobile\nnetworks require a new paradigm shift to handle such demand roll out. With the\n5G economics, those networks should provide virtualized multi-vendor and\nintelligent systems that can scale and efficiently optimize the investment of\nthe underlying infrastructure. Therefore, the market stakeholders have proposed\nthe Open Radio Access Network (O-RAN) as one of the solutions to improve the\nnetwork performance, agility, and time-to-market of new applications. O-RAN\nharnesses the power of artificial intelligence, cloud computing, and new\nnetwork technologies (NFV and SDN) to allow operators to manage their\ninfrastructure in a cost-efficient manner. Therefore, it is necessary to\naddress the O-RAN performance and availability challenges autonomously while\nmaintaining the quality of service. In this work, we propose an optimized\ndeployment strategy for the virtualized O-RAN units in the O-Cloud to minimize\nthe network's outage while complying with the performance and operational\nrequirements. The model's evaluation provides an optimal deployment strategy\nthat maximizes the network's overall availability and adheres to the\nO-RAN-specific requirements.",
    "descriptor": "\nComments: 6 pages, 4 figures, IEEE Global Communications Conference 2021\n",
    "authors": [
      "Ibrahim Tamim",
      "Anas Saci",
      "Manar Jammal",
      "Abdallah Shami"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.06060"
  },
  {
    "id": "arXiv:2110.06064",
    "title": "Spectral analysis of re-parameterized light fields",
    "abstract": "In this paper, we study the spectral properties of re-parameterized light\nfield. Following previous studies of the light field spectrum, which notably\nprovided sampling guidelines, we focus on the two plane parameterization of the\nlight field. However, we introduce additional flexibility by allowing the image\nplane to be tilted and not only parallel. A formal theoretical analysis is\nfirst presented, which shows that more flexible sampling guidelines (i.e. wider\ncamera baselines) can be used to sample the light field when adapting the image\nplane orientation to the scene geometry. We then present our simulations and\nresults to support these theoretical findings. While the work introduced in\nthis paper is mostly theoretical, we believe these new findings open exciting\navenues for more practical application of light fields, such as view synthesis\nor compact representation.",
    "descriptor": "",
    "authors": [
      "Martin Alain",
      "Aljosa Smolic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2110.06064"
  },
  {
    "id": "arXiv:2110.06069",
    "title": "Generalized Memory Approximate Message Passing",
    "abstract": "Generalized approximate message passing (GAMP) is a promising technique for\nunknown signal reconstruction of generalized linear models (GLM). However, it\nrequires that the transformation matrix has independent and identically\ndistributed (IID) entries. In this context, generalized vector AMP (GVAMP) is\nproposed for general unitarily-invariant transformation matrices but it has a\nhigh-complexity matrix inverse. To this end, we propose a universal generalized\nmemory AMP (GMAMP) framework including the existing orthogonal AMP/VAMP, GVAMP,\nand MAMP as special instances. Due to the characteristics that local processors\nare all memory, GMAMP requires stricter orthogonality to guarantee the\nasymptotic IID Gaussianity and state evolution. To satisfy such orthogonality,\nlocal orthogonal memory estimators are established. The GMAMP framework\nprovides a new principle toward building new advanced AMP-type algorithms. As\nan example, we construct a Bayes-optimal GMAMP (BO-GMAMP), which uses a\nlow-complexity memory linear estimator to suppress the linear interference, and\nthus its complexity is comparable to GAMP. Furthermore, we prove that for\nunitarily-invariant transformation matrices, BO-GMAMP achieves the replica\nminimum (i.e., Bayes-optimal) MSE if it has a unique fixed point.",
    "descriptor": "\nComments: 28 pages, 7 figures\n",
    "authors": [
      "Feiyan Tian",
      "Lei Liu",
      "Xiaoming Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.06069"
  },
  {
    "id": "arXiv:2110.06073",
    "title": "Synergy: Resource Sensitive DNN Scheduling in Multi-Tenant Clusters",
    "abstract": "Training Deep Neural Networks (DNNs) is a widely popular workload in both\nenterprises and cloud data centers. Existing schedulers for DNN training\nconsider GPU as the dominant resource, and allocate other resources such as CPU\nand memory proportional to the number of GPUs requested by the job.\nUnfortunately, these schedulers do not consider the impact of a job's\nsensitivity to allocation of CPU, memory, and storage resources. In this work,\nwe propose Synergy, a resource-sensitive scheduler for shared GPU clusters.\nSynergy infers the sensitivity of DNNs to different resources using optimistic\nprofiling; some jobs might benefit from more than the GPU-proportional\nallocation and some jobs might not be affected by less than GPU-proportional\nallocation. Synergy performs such multi-resource workload-aware assignments\nacross a set of jobs scheduled on shared multi-tenant clusters using a new\nnear-optimal online algorithm. Our experiments show that workload-aware CPU and\nmemory allocations can improve average JCT up to 3.4x when compared to\ntraditional GPU-proportional scheduling.",
    "descriptor": "",
    "authors": [
      "Jayashree Mohan",
      "Amar Phanishayee",
      "Janardhan Kulkarni",
      "Vijay Chidambaram"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06073"
  },
  {
    "id": "arXiv:2110.06081",
    "title": "Expressivity and Trainability of Quadratic Networks",
    "abstract": "Inspired by diversity of biological neurons, quadratic artificial neurons can\nplay an important role in deep learning models. The type of quadratic neurons\nof our interest replaces the inner-product operation in the conventional neuron\nwith a quadratic function. Despite promising results so far achieved by\nnetworks of quadratic neurons, there are important issues not well addressed.\nTheoretically, the superior expressivity of a quadratic network over either a\nconventional network or a conventional network via quadratic activation is not\nfully elucidated, which makes the use of quadratic networks not well grounded.\nPractically, although a quadratic network can be trained via generic\nbackpropagation, it can be subject to a higher risk of collapse than the\nconventional counterpart. To address these issues, we first apply the spline\ntheory and a measure from algebraic geometry to give two theorems that\ndemonstrate better model expressivity of a quadratic network than the\nconventional counterpart with or without quadratic activation. Then, we propose\nan effective and efficient training strategy referred to as ReLinear to\nstabilize the training process of a quadratic network, thereby unleashing the\nfull potential in its associated machine learning tasks. Comprehensive\nexperiments on popular datasets are performed to support our findings and\nevaluate the performance of quadratic deep learning.",
    "descriptor": "",
    "authors": [
      "Feng-Lei Fan",
      "Mengzhou Li",
      "Fei Wang",
      "Rongjie Lai",
      "Ge Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.06081"
  },
  {
    "id": "arXiv:2110.06084",
    "title": "Implicit Bias of Linear Equivariant Networks",
    "abstract": "Group equivariant convolutional neural networks (G-CNNs) are generalizations\nof convolutional neural networks (CNNs) which excel in a wide range of\nscientific and technical applications by explicitly encoding group symmetries,\nsuch as rotations and permutations, in their architectures. Although the\nsuccess of G-CNNs is driven by the explicit symmetry bias of their\nconvolutional architecture, a recent line of work has proposed that the\nimplicit bias of training algorithms on a particular parameterization (or\narchitecture) is key to understanding generalization for overparameterized\nneural nets. In this context, we show that $L$-layer full-width linear G-CNNs\ntrained via gradient descent in a binary classification task converge to\nsolutions with low-rank Fourier matrix coefficients, regularized by the\n$2/L$-Schatten matrix norm. Our work strictly generalizes previous analysis on\nthe implicit bias of linear CNNs to linear G-CNNs over all finite groups,\nincluding the challenging setting of non-commutative symmetry groups (such as\npermutations). We validate our theorems via experiments on a variety of groups\nand empirically explore more realistic nonlinear networks, which locally\ncapture similar regularization patterns. Finally, we provide intuitive\ninterpretations of our Fourier space implicit regularization results in real\nspace via uncertainty principles.",
    "descriptor": "\nComments: 28 pages, 19 figures\n",
    "authors": [
      "Hannah Lawrence",
      "Kristian Georgiev",
      "Andrew Dienes",
      "Bobak T. Kiani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06084"
  },
  {
    "id": "arXiv:2110.06085",
    "title": "Continuous Conditional Random Field Convolution for Point Cloud  Segmentation",
    "abstract": "Point cloud segmentation is the foundation of 3D environmental perception for\nmodern intelligent systems. To solve this problem and image segmentation,\nconditional random fields (CRFs) are usually formulated as discrete models in\nlabel space to encourage label consistency, which is actually a kind of\npostprocessing. In this paper, we reconsider the CRF in feature space for point\ncloud segmentation because it can capture the structure of features well to\nimprove the representation ability of features rather than simply smoothing.\nTherefore, we first model the point cloud features with a continuous quadratic\nenergy model and formulate its solution process as a message-passing graph\nconvolution, by which it can be easily integrated into a deep network. We\ntheoretically demonstrate that the message passing in the graph convolution is\nequivalent to the mean-field approximation of a continuous CRF model.\nFurthermore, we build an encoder-decoder network based on the proposed\ncontinuous CRF graph convolution (CRFConv), in which the CRFConv embedded in\nthe decoding layers can restore the details of high-level features that were\nlost in the encoding stage to enhance the location ability of the network,\nthereby benefiting segmentation. Analogous to the CRFConv, we show that the\nclassical discrete CRF can also work collaboratively with the proposed network\nvia another graph convolution to further improve the segmentation results.\nExperiments on various point cloud benchmarks demonstrate the effectiveness and\nrobustness of the proposed method. Compared with the state-of-the-art methods,\nthe proposed method can also achieve competitive segmentation performance.",
    "descriptor": "\nComments: 20 pages + 8 pages (supplemental material)\n",
    "authors": [
      "Fei Yang",
      "Franck Davoine",
      "Huan Wang",
      "Zhong Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.06085"
  },
  {
    "id": "arXiv:2110.06087",
    "title": "Inexact IETI-DP for conforming isogeometric multi-patch discretizations",
    "abstract": "In this paper, we investigate Dual-Primal Isogeometric Tearing and\nInterconnecting (IETI-DP) methods for conforming Galerkin discretizations on\nmulti-patch computational domains with inexact subdomain solvers. Recently, the\nauthors have proven a condition number estimate for a IETI-DP method using\nsparse LU factorizations for the subdomain problems that is explicit, among\nother parameters, in the grid size and the spline degree. In the present paper,\nwe replace the sparse LU factorizations by fast diagonalization based\npreconditioners to get a faster IETI-DP method while maintaining the same\nexplicit condition number bound.",
    "descriptor": "",
    "authors": [
      "Rainer Schneckenleitner",
      "Stefan Takacs"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.06087"
  },
  {
    "id": "arXiv:2110.06088",
    "title": "ConTIG: Continuous Representation Learning on Temporal Interaction  Graphs",
    "abstract": "Representation learning on temporal interaction graphs (TIG) is to model\ncomplex networks with the dynamic evolution of interactions arising in a broad\nspectrum of problems. Existing dynamic embedding methods on TIG discretely\nupdate node embeddings merely when an interaction occurs. They fail to capture\nthe continuous dynamic evolution of embedding trajectories of nodes. In this\npaper, we propose a two-module framework named ConTIG, a continuous\nrepresentation method that captures the continuous dynamic evolution of node\nembedding trajectories. With two essential modules, our model exploit\nthree-fold factors in dynamic networks which include latest interaction,\nneighbor features and inherent characteristics. In the first update module, we\nemploy a continuous inference block to learn the nodes' state trajectories by\nlearning from time-adjacent interaction patterns between node pairs using\nordinary differential equations. In the second transform module, we introduce a\nself-attention mechanism to predict future node embeddings by aggregating\nhistorical temporal interaction information. Experiments results demonstrate\nthe superiority of ConTIG on temporal link prediction, temporal node\nrecommendation and dynamic node classification tasks compared with a range of\nstate-of-the-art baselines, especially for long-interval interactions\nprediction.",
    "descriptor": "\nComments: 12 pages; 6 figures\n",
    "authors": [
      "Xu Yan",
      "Xiaoliang Fan",
      "Peizhen Yang",
      "Zonghan Wu",
      "Shirui Pan",
      "Longbiao Chen",
      "Yu Zang",
      "Cheng Wang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06088"
  },
  {
    "id": "arXiv:2110.06089",
    "title": "Cubature Kalman Filter Based Training of Hybrid Differential Equation  Recurrent Neural Network Physiological Dynamic Models",
    "abstract": "Modeling biological dynamical systems is challenging due to the\ninterdependence of different system components, some of which are not fully\nunderstood. To fill existing gaps in our ability to mechanistically model\nphysiological systems, we propose to combine neural networks with physics-based\nmodels. Specifically, we demonstrate how we can approximate missing ordinary\ndifferential equations (ODEs) coupled with known ODEs using Bayesian filtering\ntechniques to train the model parameters and simultaneously estimate dynamic\nstate variables. As a study case we leverage a well-understood model for blood\ncirculation in the human retina and replace one of its core ODEs with a neural\nnetwork approximation, representing the case where we have incomplete knowledge\nof the physiological state dynamics. Results demonstrate that state dynamics\ncorresponding to the missing ODEs can be approximated well using a neural\nnetwork trained using a recursive Bayesian filtering approach in a fashion\ncoupled with the known state dynamic differential equations. This demonstrates\nthat dynamics and impact of missing state variables can be captured through\njoint state estimation and model parameter estimation within a recursive\nBayesian state estimation (RBSE) framework. Results also indicate that this\nRBSE approach to training the NN parameters yields better outcomes\n(measurement/state estimation accuracy) than training the neural network with\nbackpropagation through time in the same setting.",
    "descriptor": "",
    "authors": [
      "Ahmet Demirkaya",
      "Tales Imbiriba",
      "Kyle Lockwood",
      "Sumientra Rampersad",
      "Elie Alhajjar",
      "Giovanna Guidoboni",
      "Zachary Danziger",
      "Deniz Erdogmus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.06089"
  },
  {
    "id": "arXiv:2110.06090",
    "title": "Addressing the Recruitment and Retention of Female Students in Computer  Science at Third Level",
    "abstract": "In the School of Computing at the Dublin Institute of Technology (DIT),\nIreland, we undertook our Computer Science for All (CS4All) initiative, a five\nyear strategy to implement structural reforms at Faculty level, to address\nrecruitment and retention issues of female undergraduate computer science (CS)\nstudents. Since 2012, under CS4All we implemented a variety of reforms to\nimprove student retention, set up a new CS program to attract more female\nstudents, and delivered changes to promote a sense of community amongst our\nfemale students. We have made significant improvements. For example, we have\nachieved a dramatic improvement in retention rising from 45% to 89% in first\nyear progression rates. Our new hybrid CS International program has more than\ndouble the percentage of females first year enrolments in comparison to our\nother undergraduate programs. As at 2018, we continue to roll out the remaining\nparts of CS4All within our School.",
    "descriptor": "\nComments: This paper represents the runner up submission of the Informatics Europe Minerva 2018 award. 7 pages\n",
    "authors": [
      "Susan McKeever",
      "Deirdre Lillis"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.06090"
  },
  {
    "id": "arXiv:2110.06094",
    "title": "Increasing Gender Balance Across Academic Staffing in Computer Science  -- case study",
    "abstract": "As at 2019, Technological University Dublin* Computer Science is the top\nuniversity in Ireland in terms of gender balance of female academic staff in\ncomputer science schools. In an academic team of approximately 55 full-time\nequivalents, 36% of our academic staff are female, 50% of our senior academic\nleadership team (2 of 4) are female and 75% of our School Executive are female\n(3 of 4), including a female Head of School. This is as a result of our seven\nyear SUCCESS programme which had a four strand approach: Source, Career,\nEnvironment and Support. The Source strand explicitly encouraged females to\napply for each recruitment drive; Career focused on female career and skills\ndevelopment initiatives; Environment created a female-friendly culture and\nreputation, both within the School, across our organisation and across the\nthird level sector in Ireland and Support addressed practical supports for the\nspecific difficulties experienced by female staff. As a result we have had 0%\nturnover in female staff in the past five years (in contrast to 10% male staff\nturnover). We will continue to work across these four strands to preserve our\npipeline of female staff and ensure their success over the coming years in an\nacademic and ICT sector that remains challenging for females.",
    "descriptor": "\nComments: This paper represents the winning submission of the Informatics Europe Minerva 2019 award; 9 pages, including two pages of appendix\n",
    "authors": [
      "Susan Mckeever",
      "Deirdre Lillis"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.06094"
  },
  {
    "id": "arXiv:2110.06100",
    "title": "Improving the Performance of Automated Audio Captioning via Integrating  the Acoustic and Semantic Information",
    "abstract": "Automated audio captioning (AAC) has developed rapidly in recent years,\ninvolving acoustic signal processing and natural language processing to\ngenerate human-readable sentences for audio clips. The current models are\ngenerally based on the neural encoder-decoder architecture, and their decoder\nmainly uses acoustic information that is extracted from the CNN-based encoder.\nHowever, they have ignored semantic information that could help the AAC model\nto generate meaningful descriptions. This paper proposes a novel approach for\nautomated audio captioning based on incorporating semantic and acoustic\ninformation. Specifically, our audio captioning model consists of two\nsub-modules. (1) The pre-trained keyword encoder utilizes pre-trained ResNet38\nto initialize its parameters, and then it is trained by extracted keywords as\nlabels. (2) The multi-modal attention decoder adopts an LSTM-based decoder that\ncontains semantic and acoustic attention modules. Experiments demonstrate that\nour proposed model achieves state-of-the-art performance on the Clotho dataset.\nOur code can be found at https://github.com/WangHelin1997/DCASE2021_Task6_PKU",
    "descriptor": "\nComments: 5 pages, 1 figure, accepted by DCASE 2021 workshop\n",
    "authors": [
      "Zhongjie Ye",
      "Helin Wang",
      "Dongchao Yang",
      "Yuexian Zou"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.06100"
  },
  {
    "id": "arXiv:2110.06105",
    "title": "Photonic Networks-on-Chip Employing Multilevel Signaling: A Cross-Layer  Comparative Study",
    "abstract": "Photonic network-on-chip (PNoC) architectures employ photonic links with\ndense wavelength-division multiplexing (DWDM) to enable high throughput on-chip\ntransfers. Unfortunately, increasing the DWDM degree (i.e., using a larger\nnumber of wavelengths) to achieve higher aggregated datarate in photonic links,\nand hence higher throughput in PNoCs, requires sophisticated and costly laser\nsources along with extra photonic hardware. This extra hardware can introduce\nundesired noise to the photonic link and increase the bit-error-rate (BER),\npower, and area consumption of PNoCs. To mitigate these issues, the use of\n4-pulse amplitude modulation (4-PAM) signaling, instead of the conventional\non-off keying (OOK) signaling, can halve the wavelength signals utilized in\nphotonic links for achieving the target aggregate datarate while reducing the\noverhead of crosstalk noise, BER, and photonic hardware. There are various\ndesigns of 4- PAM modulators reported in the literature. For example, the\nsignal superposition (SS), electrical digital-to-analog converter (EDAC), and\noptical digital-to-analog converter (ODAC) based designs of 4-PAM modulators\nhave been reports. However, it is yet to be explored how these SS, EDAC, and\nODAC based 4-PAM modulators can be utilized to design DWDM-based photonic links\nand PNoC architectures. In this paper, we provide an extensive link-level and\nsystem-level of the SS, EDAC, and ODAC types of 4-PAM modulators from prior\nwork with regards to their applicability and utilization overheads. From our\nlink-level and PNoC-level evaluation, we have observed that the 4-PAM EDAC\nbased variants of photonic links and PNoCs exhibit better performance and\nenergy-efficiency compared to the OOK, 4-PAM SS, and 4-PAM ODAC based links and\nPNoCs.",
    "descriptor": "\nComments: Submitted and Accepted to publish in ACM Journal on Emerging Technologies in Computing Systems\n",
    "authors": [
      "Venkata Sai Praneeth Karempudi",
      "Febin Sunny",
      "Ishan G Thakkar",
      "Sai Vineel Reddy Chittamuru",
      "Mahdi Nikdast",
      "Sudeep Pasricha"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2110.06105"
  },
  {
    "id": "arXiv:2110.06107",
    "title": "Generic Level Polymorphic N-ary Functions",
    "abstract": "Agda's standard library struggles in various places with n-ary functions and\nrelations. It introduces congruence and substitution operators for functions of\narities one and two, and provides users with convenient combinators for\nmanipulating indexed families of arity exactly one.\nAfter a careful analysis of the kinds of problems the unifier can easily\nsolve, we design a unifier-friendly representation of n-ary functions. This\nallows us to write generic programs acting on n-ary functions which\nautomatically reconstruct the representation of their inputs' types by\nunification. In particular, we can define fully level polymorphic n-ary\nversions of congruence, substitution and the combinators for indexed families,\nall requiring minimal user input.",
    "descriptor": "\nComments: Draft of the Tyde19 paper\n",
    "authors": [
      "Guillaume Allais"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.06107"
  },
  {
    "id": "arXiv:2110.06116",
    "title": "Two-level monotonic multistage recommender systems",
    "abstract": "A recommender system learns to predict the user-specific preference or\nintention over many items simultaneously for all users, making personalized\nrecommendations based on a relatively small number of observations. One central\nissue is how to leverage three-way interactions, referred to as user-item-stage\ndependencies on a monotonic chain of events, to enhance the prediction\naccuracy. A monotonic chain of events occurs, for instance, in an article\nsharing dataset, where a ``follow'' action implies a ``like'' action, which in\nturn implies a ``view'' action. In this article, we develop a multistage\nrecommender system utilizing a two-level monotonic property characterizing a\nmonotonic chain of events for personalized prediction. Particularly, we derive\na large-margin classifier based on a nonnegative additive latent factor model\nin the presence of a high percentage of missing observations, particularly\nbetween stages, reducing the number of model parameters for personalized\nprediction while guaranteeing prediction consistency. On this ground, we derive\na regularized cost function to learn user-specific behaviors at different\nstages, linking decision functions to numerical and categorical covariates to\nmodel user-item-stage interactions. Computationally, we derive an algorithm\nbased on blockwise coordinate descent. Theoretically, we show that the\ntwo-level monotonic property enhances the accuracy of learning as compared to a\nstandard method treating each stage individually and an ordinal method\nutilizing only one-level monotonicity. Finally, the proposed method compares\nfavorably with existing methods in simulations and an article sharing dataset.",
    "descriptor": "",
    "authors": [
      "Ben Dai",
      "Xiaotong Shen",
      "Wei Pan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06116"
  },
  {
    "id": "arXiv:2110.06117",
    "title": "Live Multi-Streaming and Donation Recommendations via Coupled  Donation-Response Tensor Factorization",
    "abstract": "In contrast to traditional online videos, live multi-streaming supports\nreal-time social interactions between multiple streamers and viewers, such as\ndonations. However, donation and multi-streaming channel recommendations are\nchallenging due to complicated streamer and viewer relations, asymmetric\ncommunications, and the tradeoff between personal interests and group\ninteractions. In this paper, we introduce Multi-Stream Party (MSP) and\nformulate a new multi-streaming recommendation problem, called Donation and MSP\nRecommendation (DAMRec). We propose Multi-stream Party Recommender System\n(MARS) to extract latent features via socio-temporal coupled donation-response\ntensor factorization for donation and MSP recommendations. Experimental results\non Twitch and Douyu manifest that MARS significantly outperforms existing\nrecommenders by at least 38.8% in terms of hit ratio and mean average\nprecision.",
    "descriptor": "",
    "authors": [
      "Hsu-Chao Lai",
      "Jui-Yi Tsai",
      "Hong-Han Shuai",
      "Jiun-Long Huang",
      "Wang-Chien Lee",
      "De-Nian Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06117"
  },
  {
    "id": "arXiv:2110.06119",
    "title": "The Turing machine of a harmonic oscillator: from the code to the  dynamic system",
    "abstract": "In this work we consider a dynamic system consisting of a damped harmonic\noscillator and we formalize a Turing Machine whose definition in terms of\nstates, alphabet and transition rules, can be considered equivalent to that of\nthe oscillator. We prove that the Turing Machine of a FOR loop corresponds to\nthat of the oscillator and we ask ourselves if it is possible to obtain the\ndynamic system of the harmonic oscillator as a physical realization of the FOR\nloop. We discuss the relationship between the results found and the science of\nCan and Can't. We discuss the possibility of an evolution of computer science\nalso towards non-computerized specialized machines whose operating principle is\ndesigned as an automatic process starting from a source code instead of as a\nwork of human ingenuity. The approach to the implementation of algorithms in\ndynamic systems instead of universal computers can be particularly interesting\nfor the field of both diagnostic and implantable medical devices.",
    "descriptor": "\nComments: 10 pages, 2 figures\n",
    "authors": [
      "Francesco Sisini",
      "Valentina Sisini"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)",
      "Popular Physics (physics.pop-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.06119"
  },
  {
    "id": "arXiv:2110.06120",
    "title": "A fast time domain solver for the equilibrium Dyson equation",
    "abstract": "We consider the numerical solution of the real time equilibrium Dyson\nequation, which is used in calculations of the dynamical properties of quantum\nmany-body systems. We show that this equation can be written as a system of\ncoupled, nonlinear, convolutional Volterra integro-differential equations, for\nwhich the kernel depends self-consistently on the solution. As is typical in\nthe numerical solution of Volterra-type equations, the computational bottleneck\nis the quadratic-scaling cost of history integration. However, the structure of\nthe nonlinear Volterra integral operator precludes the use of standard fast\nalgorithms. We propose a quasilinear-scaling FFT-based algorithm which respects\nthe structure of the nonlinear integral operator. The resulting method can\nreach large propagation times, and is thus well-suited to explore quantum\nmany-body phenomena at low energy scales. We demonstrate the solver with two\nstandard model systems: the Bethe graph, and the Sachdev-Ye-Kitaev model.",
    "descriptor": "",
    "authors": [
      "Jason Kaye",
      "Hugo U. R. Strand"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Strongly Correlated Electrons (cond-mat.str-el)"
    ],
    "url": "https://arxiv.org/abs/2110.06120"
  },
  {
    "id": "arXiv:2110.06123",
    "title": "COVID-19 Diagnosis from Cough Acoustics using ConvNets and Data  Augmentation",
    "abstract": "With the periodic rise and fall of COVID-19 and countries being inflicted by\nits waves, an efficient, economic, and effortless diagnosis procedure for the\nvirus has been the utmost need of the hour. COVID-19 positive individuals may\neven be asymptomatic making the diagnosis difficult, but amongst the infected\nsubjects, the asymptomatic ones need not be entirely free of symptoms caused by\nthe virus. They might not show any observable symptoms like the symptomatic\nsubjects, but they may differ from uninfected ones in the way they cough. These\ndifferences in the coughing sounds are minute and indiscernible to the human\near, however, these can be captured using machine learning-based statistical\nmodels. In this paper, we present a deep learning approach to analyze the\nacoustic dataset provided in Track 1 of the DiCOVA 2021 Challenge containing\ncough sound recordings belonging to both COVID-19 positive and negative\nexamples. To perform the classification on the sound recordings as belonging to\na COVID-19 positive or negative examples, we propose a ConvNet model. Our model\nachieved an AUC score percentage of 72.23 on the blind test set provided by the\nsame for an unbiased evaluation of the models. The ConvNet model incorporated\nwith Data Augmentation further increased the AUC-ROC percentage from 72.23 to\n87.07. It also outperformed the DiCOVA 2021 Challenge's baseline model by 23%\nthus, claiming the top position on the DiCOVA 2021 Challenge leaderboard. This\npaper proposes the use of Mel frequency cepstral coefficients as the feature\ninput for the proposed model.",
    "descriptor": "\nComments: DiCOVA, top 1st\n",
    "authors": [
      "Saranga Kingkor Mahanta",
      "Darsh Kaushik",
      "Shubham Jain",
      "Hoang Van Truong",
      "Koushik Guha"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.06123"
  },
  {
    "id": "arXiv:2110.06124",
    "title": "A Taxonomy and Archetypes of Business Analytics in Smart Manufacturing",
    "abstract": "Fueled by increasing data availability and the rise of technological advances\nfor data processing and communication, business analytics is a key driver for\nsmart manufacturing. However, due to the multitude of different local advances\nas well as its multidisciplinary complexity, both researchers and practitioners\nstruggle to keep track of the progress and acquire new knowledge within the\nfield, as there is a lack of a holistic conceptualization. To address this\nissue, we performed an extensive structured literature review, yielding 904\nrelevant hits, to develop a quadripartite taxonomy as well as to derive\narchetypes of business analytics in smart manufacturing. The taxonomy comprises\nthe following meta-characteristics: application domain, orientation as the\nobjective of the analysis, data origins, and analysis techniques. Collectively,\nthey comprise eight dimensions with a total of 52 distinct characteristics.\nUsing a cluster analysis, we found six archetypes that represent a synthesis of\nexisting knowledge on planning, maintenance (reactive, offline, and online\npredictive), monitoring, and quality management. A temporal analysis highlights\nthe push beyond predictive approaches and confirms that deep learning already\ndominates novel applications. Our results constitute an entry point to the\nfield but can also serve as a reference work and a guide with which to assess\nthe adequacy of one's own instruments.",
    "descriptor": "\nComments: accepted in ACM SIGMIS Database: The DATA BASE for Advances in Information Systems\n",
    "authors": [
      "Jonas Wanner",
      "Christopher Wissuchek",
      "Giacomo Welsch",
      "Christian Janiesch"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.06124"
  },
  {
    "id": "arXiv:2110.06125",
    "title": "Embracing Structure in Data for Billion-Scale Semantic Product Search",
    "abstract": "We present principled approaches to train and deploy dyadic neural embedding\nmodels at the billion scale, focusing our investigation on the application of\nsemantic product search. When training a dyadic model, one seeks to embed two\ndifferent types of entities (e.g., queries and documents or users and movies)\nin a common vector space such that pairs with high relevance are positioned\nnearby. During inference, given an embedding of one type (e.g., a query or a\nuser), one seeks to retrieve the entities of the other type (e.g., documents or\nmovies, respectively) that are highly relevant. In this work, we show that\nexploiting the natural structure of real-world datasets helps address both\nchallenges efficiently. Specifically, we model dyadic data as a bipartite graph\nwith edges between pairs with positive associations. We then propose to\npartition this network into semantically coherent clusters and thus reduce our\nsearch space by focusing on a small subset of these partitions for a given\ninput. During training, this technique enables us to efficiently mine hard\nnegative examples while, at inference, we can quickly find the nearest\nneighbors for a given embedding. We provide offline experimental results that\ndemonstrate the efficacy of our techniques for both training and inference on a\nbillion-scale Amazon.com product search dataset.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Vihan Lakshman",
      "Choon Hui Teo",
      "Xiaowen Chu",
      "Priyanka Nigam",
      "Abhinandan Patni",
      "Pooja Maknikar",
      "SVN Vishwanathan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06125"
  },
  {
    "id": "arXiv:2110.06128",
    "title": "A large scale lexical and semantic analysis of Spanish language  variations in Twitter",
    "abstract": "Dialectometry is a discipline devoted to studying the variations of a\nlanguage around a geographical region. One of their goals is the creation of\nlinguistic atlases capturing the similarities and differences of the language\nunder study around the area in question. For instance, Spanish is one of the\nmost spoken languages across the world, but not necessarily Spanish is written\nand spoken in the same way in different countries. This manuscript presents a\nbroad analysis describing lexical and semantic relationships among 26\nSpanish-speaking countries around the globe. For this study, we analyze\nfour-year of the Twitter geotagged public stream to provide an extensive survey\nof the Spanish language vocabularies of different countries, its distributions,\nsemantic usage of terms, and emojis. We also offer open regional word-embedding\nresources for Spanish Twitter to help other researchers and practitioners take\nadvantage of regionalized models.",
    "descriptor": "",
    "authors": [
      "Eric S. Tellez",
      "Daniela Moctezuma",
      "Sabino Miranda",
      "Mario Graff"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.06128"
  },
  {
    "id": "arXiv:2110.06133",
    "title": "Hotel Preference Rank based on Online Customer Review",
    "abstract": "Topline hotels are now shifting into the digital way in how they understand\ntheir customers to maintain and ensuring satisfaction. Rather than the\nconventional way which uses written reviews or interviews, the hotel is now\nheavily investing in Artificial Intelligence particularly Machine Learning\nsolutions. Analysis of online customer reviews changes the way companies make\ndecisions in a more effective way than using conventional analysis. The purpose\nof this research is to measure hotel service quality. The proposed approach\nemphasizes service quality dimensions reviews of the top-5 luxury hotel in\nIndonesia that appear on the online travel site TripAdvisor based on section\nBest of 2018. In this research, we use a model based on a simple Bayesian\nclassifier to classify each customer review into one of the service quality\ndimensions. Our model was able to separate each classification properly by\naccuracy, kappa, recall, precision, and F-measure measurements. To uncover\nlatent topics in the customer's opinion we use Topic Modeling. We found that\nthe common issue that occurs is about responsiveness as it got the lowest\npercentage compared to others. Our research provides a faster outlook of hotel\nrank based on service quality to end customers based on a summary of the\nprevious online review.",
    "descriptor": "\nComments: 5 pages, 6 figures, 5 tables\n",
    "authors": [
      "Muhammad Apriandito Arya Saputra",
      "Andry Alamsyah",
      "Fajar Ibnu Fatihan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2110.06133"
  },
  {
    "id": "arXiv:2110.06135",
    "title": "Label scarcity in biomedicine: Data-rich latent factor discovery  enhances phenotype prediction",
    "abstract": "High-quality data accumulation is now becoming ubiquitous in the health\ndomain. There is increasing opportunity to exploit rich data from normal\nsubjects to improve supervised estimators in specific diseases with notorious\ndata scarcity. We demonstrate that low-dimensional embedding spaces can be\nderived from the UK Biobank population dataset and used to enhance data-scarce\nprediction of health indicators, lifestyle and demographic characteristics.\nPhenotype predictions facilitated by Variational Autoencoder manifolds\ntypically scaled better with increasing unlabeled data than dimensionality\nreduction by PCA or Isomap. Performances gains from semisupervison approaches\nwill probably become an important ingredient for various medical data science\napplications.",
    "descriptor": "\nComments: Accepted at NIPS 2017 Workshop on Machine Learning for Health\n",
    "authors": [
      "Marc-Andre Schulz",
      "Bertrand Thirion",
      "Alexandre Gramfort",
      "Ga\u00ebl Varoquaux",
      "Danilo Bzdok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2110.06135"
  },
  {
    "id": "arXiv:2110.06146",
    "title": "A SAT Approach to Twin-Width",
    "abstract": "The graph invariant twin-width was recently introduced by Bonnet, Kim,\nThomass\\'e, and Watrigan. Problems expressible in first-order logic, which\nincludes many prominent NP-hard problems, are tractable on graphs of bounded\ntwin-width if a certificate for the twin-width bound is provided as an input.\nComputing such a certificate, however, is an intrinsic problem, for which no\nnontrivial algorithm is known.\nIn this paper, we propose the first practical approach for computing the\ntwin-width of graphs together with the corresponding certificate. We propose\nefficient SAT-encodings that rely on a characterization of twin-width based on\nelimination sequences. This allows us to determine the twin-width of many\nfamous graphs with previously unknown twin-width. We utilize our encodings to\nidentify the smallest graphs for a given twin-width bound $d \\in\n\\{1,\\dots,4\\}$.",
    "descriptor": "\nComments: Preprint of a paper to appear at ALENEX'22\n",
    "authors": [
      "Andr\u00e9 Schidler",
      "Stefan Szeider"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Logic in Computer Science (cs.LO)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.06146"
  },
  {
    "id": "arXiv:2110.06149",
    "title": "Planning from Pixels in Environments with Combinatorially Hard Search  Spaces",
    "abstract": "The ability to form complex plans based on raw visual input is a litmus test\nfor current capabilities of artificial intelligence, as it requires a seamless\ncombination of visual processing and abstract algorithmic execution, two\ntraditionally separate areas of computer science. A recent surge of interest in\nthis field brought advances that yield good performance in tasks ranging from\narcade games to continuous control; these methods however do not come without\nsignificant issues, such as limited generalization capabilities and\ndifficulties when dealing with combinatorially hard planning instances. Our\ncontribution is two-fold: (i) we present a method that learns to represent its\nenvironment as a latent graph and leverages state reidentification to reduce\nthe complexity of finding a good policy from exponential to linear (ii) we\nintroduce a set of lightweight environments with an underlying discrete\ncombinatorial structure in which planning is challenging even for humans.\nMoreover, we show that our methods achieves strong empirical generalization to\nvariations in the environment, even across highly disadvantaged regimes, such\nas \"one-shot\" planning, or in an offline RL paradigm which only provides\nlow-quality trajectories.",
    "descriptor": "",
    "authors": [
      "Marco Bagatella",
      "Mirek Ol\u0161\u00e1k",
      "Michal Rol\u00ednek",
      "Georg Martius"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06149"
  },
  {
    "id": "arXiv:2110.06151",
    "title": "Extracting Feelings of People Regarding COVID-19 by Social Network  Mining",
    "abstract": "In 2020, COVID-19 became the chief concern of the world and is still\nreflected widely in all social networks. Each day, users post millions of\ntweets and comments on this subject, which contain significant implicit\ninformation about the public opinion. In this regard, a dataset of\nCOVID-related tweets in English language is collected, which consists of more\nthan two million tweets from March 23 to June 23 of 2020 to extract the\nfeelings of the people in various countries in the early stages of this\noutbreak. To this end, first, we use a lexicon-based approach in conjunction\nwith the GeoNames geographic database to label the tweets with their locations.\nNext, a method based on the recently introduced and widely cited RoBERTa model\nis proposed to analyze their sentimental content. After that, the trend graphs\nof the frequency of tweets as well as sentiments are produced for the world and\nthe nations that were more engaged with COVID-19. Graph analysis shows that the\nfrequency graphs of the tweets for the majority of nations are significantly\ncorrelated with the official statistics of the daily afflicted in them.\nMoreover, several implicit knowledge is extracted and discussed.",
    "descriptor": "",
    "authors": [
      "Hamed Vahdat-Nejad",
      "Fatemeh Salmani",
      "Mahdi Hajiabadi",
      "Faezeh Azizi",
      "Sajedeh Abbasi",
      "Mohadese Jamalian",
      "Reyhane Mosafer",
      "Hamideh Hajiabadi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06151"
  },
  {
    "id": "arXiv:2110.06155",
    "title": "Memory-Efficient CNN Accelerator Based on Interlayer Feature Map  Compression",
    "abstract": "Existing deep convolutional neural networks (CNNs) generate massive\ninterlayer feature data during network inference. To maintain real-time\nprocessing in embedded systems, large on-chip memory is required to buffer the\ninterlayer feature maps. In this paper, we propose an efficient hardware\naccelerator with an interlayer feature compression technique to significantly\nreduce the required on-chip memory size and off-chip memory access bandwidth.\nThe accelerator compresses interlayer feature maps through transforming the\nstored data into frequency domain using hardware-implemented 8x8 discrete\ncosine transform (DCT). The high-frequency components are removed after the DCT\nthrough quantization. Sparse matrix compression is utilized to further compress\nthe interlayer feature maps. The on-chip memory allocation scheme is designed\nto support dynamic configuration of the feature map buffer size and scratch pad\nsize according to different network-layer requirements. The hardware\naccelerator combines compression, decompression, and CNN acceleration into one\ncomputing stream, achieving minimal compressing and processing delay. A\nprototype accelerator is implemented on an FPGA platform and also synthesized\nin TSMC 28-nm COMS technology. It achieves 403GOPS peak throughput and\n1.4x~3.3x interlayer feature map reduction by adding light hardware area\noverhead, making it a promising hardware accelerator for intelligent IoT\ndevices.",
    "descriptor": "",
    "authors": [
      "Zhuang Shao",
      "Xiaoliang Chen",
      "Li Du",
      "Lei Chen",
      "Yuan Du",
      "Wei Zhuang",
      "Huadong Wei",
      "Chenjia Xie",
      "Zhongfeng Wang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06155"
  },
  {
    "id": "arXiv:2110.06160",
    "title": "Method to Build Equivalent Models of Microgrids for RMS Dynamic  Simulation of Power Systems",
    "abstract": "The high penetration of distributed renewable energy resources in power\nsystems has changed their dynamic behavior, not only at the distribution level\nbut also at the transmission levels. For analyses performed in this new reality\nof interconnected systems, a suitable equivalent model is required to represent\nthe active dynamics of distribution systems. In this context, this paper\nproposes the application of a gray-box method to obtain an appropriate\nequivalent model for active distribution networks. From data measured at the\npoint of common coupling, a trajectory sensitivity analysis is carried out to\nselect the most important parameters of this equivalent model, which are then\nestimated by an evolutionary algorithm. The results show that the application\nof the sensitivity analysis can improve the quality of the parameter estimation\nprocess (since it focuses only on relevant parameters), enabling an efficient\ntuning of an equivalent ADN model.",
    "descriptor": "\nComments: 7 pages with 5 figures, preprint submitted to 22nd Power Systems Computation Conference\n",
    "authors": [
      "Rodrigo A. Ramos",
      "Ahda P. Grilo-Pavani",
      "Artur B. Piardi",
      "Tatiane C. C. Fernandes",
      "Murilo E. C. Bento"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.06160"
  },
  {
    "id": "arXiv:2110.06161",
    "title": "Sign Language Recognition via Skeleton-Aware Multi-Model Ensemble",
    "abstract": "Sign language is commonly used by deaf or mute people to communicate but\nrequires extensive effort to master. It is usually performed with the fast yet\ndelicate movement of hand gestures, body posture, and even facial expressions.\nCurrent Sign Language Recognition (SLR) methods usually extract features via\ndeep neural networks and suffer overfitting due to limited and noisy data.\nRecently, skeleton-based action recognition has attracted increasing attention\ndue to its subject-invariant and background-invariant nature, whereas\nskeleton-based SLR is still under exploration due to the lack of hand\nannotations. Some researchers have tried to use off-line hand pose trackers to\nobtain hand keypoints and aid in recognizing sign language via recurrent neural\nnetworks. Nevertheless, none of them outperforms RGB-based approaches yet. To\nthis end, we propose a novel Skeleton Aware Multi-modal Framework with a Global\nEnsemble Model (GEM) for isolated SLR (SAM-SLR-v2) to learn and fuse\nmulti-modal feature representations towards a higher recognition rate.\nSpecifically, we propose a Sign Language Graph Convolution Network (SL-GCN) to\nmodel the embedded dynamics of skeleton keypoints and a Separable\nSpatial-Temporal Convolution Network (SSTCN) to exploit skeleton features. The\nskeleton-based predictions are fused with other RGB and depth based modalities\nby the proposed late-fusion GEM to provide global information and make a\nfaithful SLR prediction. Experiments on three isolated SLR datasets demonstrate\nthat our proposed SAM-SLR-v2 framework is exceedingly effective and achieves\nstate-of-the-art performance with significant margins. Our code will be\navailable at https://github.com/jackyjsy/SAM-SLR-v2",
    "descriptor": "",
    "authors": [
      "Songyao Jiang",
      "Bin Sun",
      "Lichen Wang",
      "Yue Bai",
      "Kunpeng Li",
      "Yun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06161"
  },
  {
    "id": "arXiv:2110.06163",
    "title": "Finding Relevant Points for Nearest-Neighbor Classification",
    "abstract": "In nearest-neighbor classification problems, a set of $d$-dimensional\ntraining points are given, each with a known classification, and are used to\ninfer unknown classifications of other points by using the same classification\nas the nearest training point. A training point is relevant if its omission\nfrom the training set would change the outcome of some of these inferences. We\nprovide a simple algorithm for thinning a training set down to its subset of\nrelevant points, using as subroutines algorithms for finding the minimum\nspanning tree of a set of points and for finding the extreme points (convex\nhull vertices) of a set of points. The time bounds for our algorithm, in any\nconstant dimension $d\\ge 3$, improve on a previous algorithm for the same\nproblem by Clarkson (FOCS 1994).",
    "descriptor": "\nComments: 15 pages, 3 figures, to appear at the SIAM Symposium on Simplicity in Algorithms (SOSA22)\n",
    "authors": [
      "David Eppstein"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06163"
  },
  {
    "id": "arXiv:2110.06164",
    "title": "M2GAN: A Multi-Stage Self-Attention Network for Image Rain Removal on  Autonomous Vehicles",
    "abstract": "Image deraining is a new challenging problem in applications of autonomous\nvehicles. In a bad weather condition of heavy rainfall, raindrops, mainly\nhitting the vehicle's windshield, can significantly reduce observation ability\neven though the windshield wipers might be able to remove part of it. Moreover,\nrain flows spreading over the windshield can yield the physical effect of\nrefraction, which seriously impede the sightline or undermine the machine\nlearning system equipped in the vehicle. In this paper, we propose a new\nmulti-stage multi-task recurrent generative adversarial network (M2GAN) to deal\nwith challenging problems of raindrops hitting the car's windshield. This\nmethod is also applicable for removing raindrops appearing on a glass window or\nlens. M2GAN is a multi-stage multi-task generative adversarial network that can\nutilize prior high-level information, such as semantic segmentation, to boost\nderaining performance. To demonstrate M2GAN, we introduce the first real-world\ndataset for rain removal on autonomous vehicles. The experimental results show\nthat our proposed method is superior to other state-of-the-art approaches of\nderaining raindrops in respect of quantitative metrics and visual quality.\nM2GAN is considered the first method to deal with challenging problems of\nreal-world rains under unconstrained environments such as autonomous vehicles.",
    "descriptor": "",
    "authors": [
      "Duc Manh Nguyen",
      "Sang-Woong Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.06164"
  },
  {
    "id": "arXiv:2110.06166",
    "title": "Game Theory for Adversarial Attacks and Defenses",
    "abstract": "Adversarial attacks can generate adversarial inputs by applying small but\nintentionally worst-case perturbations to samples from the dataset, which leads\nto even state-of-the-art deep neural networks outputting incorrect answers with\nhigh confidence. Hence, some adversarial defense techniques are developed to\nimprove the security and robustness of the models and avoid them being\nattacked. Gradually, a game-like competition between attackers and defenders\nformed, in which both players would attempt to play their best strategies\nagainst each other while maximizing their own payoffs. To solve the game, each\nplayer would choose an optimal strategy against the opponent based on the\nprediction of the opponent's strategy choice. In this work, we are on the\ndefensive side to apply game-theoretic approaches on defending against attacks.\nWe use two randomization methods, random initialization and stochastic\nactivation pruning, to create diversity of networks. Furthermore, we use one\ndenoising technique, super resolution, to improve models' robustness by\npreprocessing images before attacks. Our experimental results indicate that\nthose three methods can effectively improve the robustness of deep-learning\nneural networks.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Shorya Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.06166"
  },
  {
    "id": "arXiv:2110.06169",
    "title": "Offline Reinforcement Learning with Implicit Q-Learning",
    "abstract": "Offline reinforcement learning requires reconciling two conflicting aims:\nlearning a policy that improves over the behavior policy that collected the\ndataset, while at the same time minimizing the deviation from the behavior\npolicy so as to avoid errors due to distributional shift. This trade-off is\ncritical, because most current offline reinforcement learning methods need to\nquery the value of unseen actions during training to improve the policy, and\ntherefore need to either constrain these actions to be in-distribution, or else\nregularize their values. We propose an offline RL method that never needs to\nevaluate actions outside of the dataset, but still enables the learned policy\nto improve substantially over the best behavior in the data through\ngeneralization. The main insight in our work is that, instead of evaluating\nunseen actions from the latest policy, we can approximate the policy\nimprovement step implicitly by treating the state value function as a random\nvariable, with randomness determined by the action (while still integrating\nover the dynamics to avoid excessive optimism), and then taking a state\nconditional upper expectile of this random variable to estimate the value of\nthe best actions in that state. This leverages the generalization capacity of\nthe function approximator to estimate the value of the best available action at\na given state without ever directly querying a Q-function with this unseen\naction. Our algorithm alternates between fitting this upper expectile value\nfunction and backing it up into a Q-function. Then, we extract the policy via\nadvantage-weighted behavioral cloning. We dub our method implicit Q-learning\n(IQL). IQL demonstrates the state-of-the-art performance on D4RL, a standard\nbenchmark for offline reinforcement learning. We also demonstrate that IQL\nachieves strong performance fine-tuning using online interaction after offline\ninitialization.",
    "descriptor": "",
    "authors": [
      "Ilya Kostrikov",
      "Ashvin Nair",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06169"
  },
  {
    "id": "arXiv:2110.06176",
    "title": "Mention Memory: incorporating textual knowledge into Transformers  through entity mention attention",
    "abstract": "Natural language understanding tasks such as open-domain question answering\noften require retrieving and assimilating factual information from multiple\nsources. We propose to address this problem by integrating a semi-parametric\nrepresentation of a large text corpus into a Transformer model as a source of\nfactual knowledge. Specifically, our method represents knowledge with `mention\nmemory', a table of dense vector representations of every entity mention in a\ncorpus. The proposed model - TOME - is a Transformer that accesses the\ninformation through internal memory layers in which each entity mention in the\ninput passage attends to the mention memory. This approach enables synthesis of\nand reasoning over many disparate sources of information within a single\nTransformer model. In experiments using a memory of 150 million Wikipedia\nmentions, TOME achieves strong performance on several open-domain\nknowledge-intensive tasks, including the claim verification benchmarks HoVer\nand FEVER and several entity-based QA benchmarks. We also show that the model\nlearns to attend to informative mentions without any direct supervision.\nFinally we demonstrate that the model can generalize to new unseen entities by\nupdating the memory without retraining.",
    "descriptor": "",
    "authors": [
      "Michiel de Jong",
      "Yury Zemlyanskiy",
      "Nicholas FitzGerald",
      "Fei Sha",
      "William Cohen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06176"
  },
  {
    "id": "arXiv:2110.06178",
    "title": "TAda! Temporally-Adaptive Convolutions for Video Understanding",
    "abstract": "Spatial convolutions are widely used in numerous deep video models. It\nfundamentally assumes spatio-temporal invariance, i.e., using shared weights\nfor every location in different frames. This work presents Temporally-Adaptive\nConvolutions (TAdaConv) for video understanding, which shows that adaptive\nweight calibration along the temporal dimension is an efficient way to\nfacilitate modelling complex temporal dynamics in videos. Specifically,\nTAdaConv empowers the spatial convolutions with temporal modelling abilities by\ncalibrating the convolution weights for each frame according to its local and\nglobal temporal context. Compared to previous temporal modelling operations,\nTAdaConv is more efficient as it operates over the convolution kernels instead\nof the features, whose dimension is an order of magnitude smaller than the\nspatial resolutions. Further, the kernel calibration also brings an increased\nmodel capacity. We construct TAda2D networks by replacing the spatial\nconvolutions in ResNet with TAdaConv, which leads to on par or better\nperformance compared to state-of-the-art approaches on multiple video action\nrecognition and localization benchmarks. We also demonstrate that as a readily\nplug-in operation with negligible computation overhead, TAdaConv can\neffectively improve many existing video models with a convincing margin. Codes\nand models will be made available at\nhttps://github.com/alibaba-mmai-research/pytorch-video-understanding.",
    "descriptor": "",
    "authors": [
      "Ziyuan Huang",
      "Shiwei Zhang",
      "Liang Pan",
      "Zhiwu Qing",
      "Mingqian Tang",
      "Ziwei Liu",
      "Marcelo H. Ang Jr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06178"
  },
  {
    "id": "arXiv:2110.06183",
    "title": "Blind Modulo Analog-to-Digital Conversion of Vector Processes",
    "abstract": "In a growing number of applications, there is a need to digitize a (possibly\nhigh) number of correlated signals whose spectral characteristics are\nchallenging for traditional analog-to-digital converters (ADCs). Examples,\namong others, include multiple-input multiple-output systems where the ADCs\nmust acquire at once several signals at a very wide but sparsely and\ndynamically occupied bandwidth supporting diverse services. In such scenarios,\nthe resolution requirements can be prohibitively high. As an alternative, the\nrecently proposed modulo-ADC architecture can in principle require dramatically\nfewer bits in the conversion to obtain the target fidelity, but requires that\nspatiotemporal information be known and explicitly taken into account by the\nanalog and digital processing in the converter, which is frequently\nimpractical. Building on our recent work, we address this limitation and\ndevelop a blind version of the architecture that requires no such knowledge in\nthe converter. In particular, it features an automatic modulo-level adjustment\nand a fully adaptive modulo-decoding mechanism, allowing it to asymptotically\nmatch the characteristics of the unknown input signal. Simulation results\ndemonstrate the successful operation of the proposed algorithm.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2108.08937\n",
    "authors": [
      "Amir Weiss",
      "Everest Huang",
      "Or Ordentlich",
      "Gregory W. Wornell"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.06183"
  },
  {
    "id": "arXiv:2110.06186",
    "title": "Parameter Tuning Strategies for Metaheuristic Methods Applied to  Discrete Optimization of Structural Design",
    "abstract": "This paper presents several strategies to tune the parameters of\nmetaheuristic methods for (discrete) design optimization of reinforced concrete\n(RC) structures. A novel utility metric is proposed, based on the area under\nthe average performance curve. The process of modelling, analysis and design of\nrealistic RC structures leads to objective functions for which the evaluation\nis computationally very expensive. To avoid costly simulations, two types of\nsurrogate models are used. The first one consists of the creation of a database\ncontaining all possible solutions. The second one uses benchmark functions to\ncreate a discrete sub-space of them, simulating the main features of realistic\nproblems. Parameter tuning of four metaheuristics is performed based on two\nstrategies. The main difference between them is the parameter control\nestablished to perform partial assessments. The simplest strategy is suitable\nto tune good `generalist' methods, i.e., methods with good performance\nregardless the parameter configuration. The other one is more expensive, but is\nwell suited to assess any method. Tuning results prove that Biogeography-Based\nOptimization, a relatively new evolutionary algorithm, outperforms other\nmethods such as GA or PSO for such optimization problems, due to its particular\napproach of applying recombination and mutation operators.",
    "descriptor": "\nComments: 18 pages, 9 figures, 6 tables. Submitted to a journal\n",
    "authors": [
      "Iv\u00e1n Negrin",
      "Dirk Roose",
      "Ernesto Chagoy\u00e9n"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.06186"
  },
  {
    "id": "arXiv:2110.06192",
    "title": "Beyond Pick-and-Place: Tackling Robotic Stacking of Diverse Shapes",
    "abstract": "We study the problem of robotic stacking with objects of complex geometry. We\npropose a challenging and diverse set of such objects that was carefully\ndesigned to require strategies beyond a simple \"pick-and-place\" solution. Our\nmethod is a reinforcement learning (RL) approach combined with vision-based\ninteractive policy distillation and simulation-to-reality transfer. Our learned\npolicies can efficiently handle multiple object combinations in the real world\nand exhibit a large variety of stacking skills. In a large experimental study,\nwe investigate what choices matter for learning such general vision-based\nagents in simulation, and what affects optimal transfer to the real robot. We\nthen leverage data collected by such policies and improve upon them with\noffline RL. A video and a blog post of our work are provided as supplementary\nmaterial.",
    "descriptor": "\nComments: CoRL 2021. Video: this https URL . Blog: this https URL . Code: this https URL\n",
    "authors": [
      "Alex X. Lee",
      "Coline Devin",
      "Yuxiang Zhou",
      "Thomas Lampe",
      "Konstantinos Bousmalis",
      "Jost Tobias Springenberg",
      "Arunkumar Byravan",
      "Abbas Abdolmaleki",
      "Nimrod Gileadi",
      "David Khosid",
      "Claudio Fantacci",
      "Jose Enrique Chen",
      "Akhil Raju",
      "Rae Jeong",
      "Michael Neunert",
      "Antoine Laurens",
      "Stefano Saliceti",
      "Federico Casarini",
      "Martin Riedmiller",
      "Raia Hadsell",
      "Francesco Nori"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06192"
  },
  {
    "id": "arXiv:2110.06195",
    "title": "Planning Sensing Sequences for Subsurface 3D Tumor Mapping",
    "abstract": "Surgical automation has the potential to enable increased precision and\nreduce the per-patient workload of overburdened human surgeons. An effective\nautomation system must be able to sense and map subsurface anatomy, such as\ntumors, efficiently and accurately. In this work, we present a method that\nplans a sequence of sensing actions to map the 3D geometry of subsurface\ntumors. We leverage a sequential Bayesian Hilbert map to create a 3D\nprobabilistic occupancy model that represents the likelihood that any given\npoint in the anatomy is occupied by a tumor, conditioned on sensor readings. We\niteratively update the map, utilizing Bayesian optimization to determine\nsensing poses that explore unsensed regions of anatomy and exploit the\nknowledge gained by previous sensing actions. We demonstrate our method's\nefficiency and accuracy in three anatomical scenarios including a liver tumor\nscenario generated from a real patient's CT scan. The results show that our\nproposed method significantly outperforms comparison methods in terms of\nefficiency while detecting subsurface tumors with high accuracy.",
    "descriptor": "\nComments: 7 pages, 9 figures, to be published in the proceedings of the 2021 International Symposium on Medical Robotics (ISMR)\n",
    "authors": [
      "Brian Y. Cho",
      "Tucker Hermans",
      "Alan Kuntz"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.06195"
  },
  {
    "id": "arXiv:2110.06196",
    "title": "GraPE: fast and scalable Graph Processing and Embedding",
    "abstract": "Graph Representation Learning methods have enabled a wide range of learning\nproblems to be addressed for data that can be represented in graph form.\nNevertheless, several real world problems in economy, biology, medicine and\nother fields raised relevant scaling problems with existing methods and their\nsoftware implementation, due to the size of real world graphs characterized by\nmillions of nodes and billions of edges. We present GraPE, a software resource\nfor graph processing and random walk based embedding, that can scale with large\nand high-degree graphs and significantly speed up-computation. GraPE comprises\nspecialized data structures, algorithms, and a fast parallel implementation\nthat displays everal orders of magnitude improvement in empirical space and\ntime complexity compared to state of the art software resources, with a\ncorresponding boost in the performance of machine learning methods for edge and\nnode label prediction and for the unsupervised analysis of graphs.GraPE is\ndesigned to run on laptop and desktop computers, as well as on high performance\ncomputing clusters",
    "descriptor": "",
    "authors": [
      "Luca Cappelletti",
      "Tommaso Fontana",
      "Elena Casiraghi",
      "Vida Ravanmehr",
      "Tiffany J.Callahan",
      "Marcin P. Joachimiak",
      "Christopher J. Mungall",
      "Peter N. Robinson",
      "Justin Reese",
      "Giorgio Valentini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.06196"
  },
  {
    "id": "arXiv:2110.06197",
    "title": "Crystal Diffusion Variational Autoencoder for Periodic Material  Generation",
    "abstract": "Generating the periodic structure of stable materials is a long-standing\nchallenge for the material design community. This task is difficult because\nstable materials only exist in a low-dimensional subspace of all possible\nperiodic arrangements of atoms: 1) the coordinates must lie in the local energy\nminimum defined by quantum mechanics, and 2) global stability also requires the\nstructure to follow the complex, yet specific bonding preferences between\ndifferent atom types. Existing methods fail to incorporate these factors and\noften lack proper invariances. We propose a Crystal Diffusion Variational\nAutoencoder (CDVAE) that captures the physical inductive bias of material\nstability. By learning from the data distribution of stable materials, the\ndecoder generates materials in a diffusion process that moves atomic\ncoordinates towards a lower energy state and updates atom types to satisfy\nbonding preferences between neighbors. Our model also explicitly encodes\ninteractions across periodic boundaries and respects permutation, translation,\nrotation, and periodic invariances. We significantly outperform past methods in\nthree tasks: 1) reconstructing the input structure, 2) generating valid,\ndiverse, and realistic materials, and 3) generating materials that optimize a\nspecific property. We also provide several standard datasets and evaluation\nmetrics for the broader machine learning community.",
    "descriptor": "",
    "authors": [
      "Tian Xie",
      "Xiang Fu",
      "Octavian-Eugen Ganea",
      "Regina Barzilay",
      "Tommi Jaakkola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.06197"
  },
  {
    "id": "arXiv:2110.06198",
    "title": "Last Iterate Risk Bounds of SGD with Decaying Stepsize for  Overparameterized Linear Regression",
    "abstract": "Stochastic gradient descent (SGD) has been demonstrated to generalize well in\nmany deep learning applications. In practice, one often runs SGD with a\ngeometrically decaying stepsize, i.e., a constant initial stepsize followed by\nmultiple geometric stepsize decay, and uses the last iterate as the output.\nThis kind of SGD is known to be nearly minimax optimal for classical\nfinite-dimensional linear regression problems (Ge et al., 2019), and provably\noutperforms SGD with polynomially decaying stepsize in terms of the statistical\nminimax rates. However, a sharp analysis for the last iterate of SGD with\ndecaying step size in the overparameterized setting is still open. In this\npaper, we provide problem-dependent analysis on the last iterate risk bounds of\nSGD with decaying stepsize, for (overparameterized) linear regression problems.\nIn particular, for SGD with geometrically decaying stepsize (or tail\ngeometrically decaying stepsize), we prove nearly matching upper and lower\nbounds on the excess risk. Our results demonstrate the generalization ability\nof SGD for a wide class of overparameterized problems, and can recover the\nminimax optimal results up to logarithmic factors in the classical regime.\nMoreover, we provide an excess risk lower bound for SGD with polynomially\ndecaying stepsize and illustrate the advantage of geometrically decaying\nstepsize in an instance-wise manner, which complements the minimax rate\ncomparison made in previous work.",
    "descriptor": "\nComments: 40 pages, 2 figures\n",
    "authors": [
      "Jingfeng Wu",
      "Difan Zou",
      "Vladimir Braverman",
      "Quanquan Gu",
      "Sham M. Kakade"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06198"
  },
  {
    "id": "arXiv:2110.06199",
    "title": "ABO: Dataset and Benchmarks for Real-World 3D Object Understanding",
    "abstract": "We introduce Amazon-Berkeley Objects (ABO), a new large-scale dataset of\nproduct images and 3D models corresponding to real household objects. We use\nthis realistic, object-centric 3D dataset to measure the domain gap for\nsingle-view 3D reconstruction networks trained on synthetic objects. We also\nuse multi-view images from ABO to measure the robustness of state-of-the-art\nmetric learning approaches to different camera viewpoints. Finally, leveraging\nthe physically-based rendering materials in ABO, we perform single- and\nmulti-view material estimation for a variety of complex, real-world geometries.\nThe full dataset is available for download at\nhttps://amazon-berkeley-objects.s3.amazonaws.com/index.html.",
    "descriptor": "",
    "authors": [
      "Jasmine Collins",
      "Shubham Goel",
      "Achleshwar Luthra",
      "Leon Xu",
      "Kenan Deng",
      "Xi Zhang",
      "Tomas F. Yago Vicente",
      "Himanshu Arora",
      "Thomas Dideriksen",
      "Matthieu Guillaumin",
      "Jitendra Malik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.06199"
  },
  {
    "id": "arXiv:2110.06206",
    "title": "StARformer: Transformer with State-Action-Reward Representations",
    "abstract": "Reinforcement Learning (RL) can be considered as a sequence modeling task,\ni.e., given a sequence of past state-action-reward experiences, a model\nautoregressively predicts a sequence of future actions. Recently, Transformers\nhave been successfully adopted to model this problem. In this work, we propose\nState-Action-Reward Transformer (StARformer), which explicitly models local\ncausal relations to help improve action prediction in long sequences.\nStARformer first extracts local representations (i.e., StAR-representations)\nfrom each group of state-action-reward tokens within a very short time span. A\nsequence of such local representations combined with state representations, is\nthen used to make action predictions over a long time span. Our experiments\nshow that StARformer outperforms the state-of-the-art Transformer-based method\non Atari (image) and Gym (state vector) benchmarks, in both offline-RL and\nimitation learning settings. StARformer is also more compliant with longer\nsequences of inputs compared to the baseline. Our code is available at\nhttps://github.com/elicassion/StARformer.",
    "descriptor": "",
    "authors": [
      "Jinghuan Shang",
      "Michael S. Ryoo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06206"
  },
  {
    "id": "arXiv:2110.06207",
    "title": "Open-Set Recognition: A Good Closed-Set Classifier is All You Need",
    "abstract": "The ability to identify whether or not a test sample belongs to one of the\nsemantic classes in a classifier's training set is critical to practical\ndeployment of the model. This task is termed open-set recognition (OSR) and has\nreceived significant attention in recent years. In this paper, we first\ndemonstrate that the ability of a classifier to make the 'none-of-above'\ndecision is highly correlated with its accuracy on the closed-set classes. We\nfind that this relationship holds across loss objectives and architectures, and\nfurther demonstrate the trend both on the standard OSR benchmarks as well as on\na large-scale ImageNet evaluation. Second, we use this correlation to boost the\nperformance of the cross-entropy OSR 'baseline' by improving its closed-set\naccuracy, and with this strong baseline achieve a new state-of-the-art on the\nmost challenging OSR benchmark. Similarly, we boost the performance of the\nexisting state-of-the-art method by improving its closed-set accuracy, but this\ndoes not surpass the strong baseline on the most challenging dataset. Our third\ncontribution is to reappraise the datasets used for OSR evaluation, and\nconstruct new benchmarks which better respect the task of detecting semantic\nnovelty, as opposed to low-level distributional shifts as tackled by\nneighbouring machine learning fields. In this new setting, we again demonstrate\nthat there is negligible difference between the strong baseline and the\nexisting state-of-the-art.",
    "descriptor": "\nComments: 23 pages, 8 figures\n",
    "authors": [
      "Sagar Vaze",
      "Kai Han",
      "Andrea Vedaldi",
      "Andrew Zisserman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06207"
  },
  {
    "id": "arXiv:2110.06208",
    "title": "Towards formalization and monitoring of microscopic traffic parameters  using temporal logic",
    "abstract": "Smart cities are revolutionizing the transportation infrastructure by the\nintegration of technology. However, ensuring that various transportation system\ncomponents are operating as expected and in a safe manner is a great challenge.\nIn this work, we propose the use of formal methods as a means to specify and\nreason about the traffic network's complex properties. Formal methods provide a\nflexible tool to define the safe operation of the traffic network by capturing\nnon-conforming behavior, exploring various possible states of the traffic\nscene, and detecting any inconsistencies within it. Hence, we develop\nspecification-based monitoring for the analysis of traffic networks using the\nformal language, Signal Temporal Logic. We develop monitors that identify\nsafety-related behavior such as conforming to speed limits and maintaining\nappropriate headway. The framework is tested using a calibrated micro-simulated\nhighway scenario and offline specification-based monitoring is applied to\nindividual vehicle trajectories to understand whether they violate or satisfy\nthe defined safety specifications. Statistical analysis of the outputs show\nthat our approach can differentiate violating from conforming vehicle\ntrajectories based on the defined specifications. This work can be utilized by\ntraffic management centers to study the traffic stream properties, identify\npossible hazards, and provide valuable feedback for automating the traffic\nmonitoring systems.",
    "descriptor": "",
    "authors": [
      "Mariam Nour",
      "Mohamed H. Zaki"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.06208"
  },
  {
    "id": "arXiv:2109.13391",
    "title": "Curvature-Aware Derivative-Free Optimization",
    "abstract": "We propose a new line-search method, coined Curvature-Aware Random Search\n(CARS), for derivative-free optimization. CARS exploits approximate curvature\ninformation to estimate the optimal step-size given a search direction. We\nprove that for strongly convex objective functions, CARS converges linearly if\nthe search direction is drawn from a distribution satisfying very mild\nconditions. We also explore a variant, CARS-NQ, which uses Numerical Quadrature\ninstead of a Monte Carlo method when approximating curvature along the search\ndirection. We show CARS-NQ is effective on highly non-convex problems of the\nform $f = f_{\\mathrm{cvx}} + f_{\\mathrm{osc}}$ where $f_{\\mathrm{cvx}}$ is\nstrongly convex and $f_{\\mathrm{osc}}$ is rapidly oscillating. Experimental\nresults show that CARS and CARS-NQ match or exceed the state-of-the-arts on\nbenchmark problem sets.",
    "descriptor": "\nComments: 35 pages, 5 figures\n",
    "authors": [
      "Bumsu Kim",
      "HanQin Cai",
      "Daniel McKenzie",
      "Wotao Yin"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.13391"
  },
  {
    "id": "arXiv:2110.05009",
    "title": "Long-term balanced allocation via thinning",
    "abstract": "We study the long-term behavior of the two-thinning variant of the classical\nballs-and-bins model. In this model, an overseer is provided with uniform\nrandom allocation of $m$ balls into $n$ bins in an on-line fashion. For each\nball, the overseer could reject its allocation and place the ball into a new\nbin drawn independently at random. The purpose of the overseer is to reduce the\nmaximum load of the bins, which is defined as the difference between the\nmaximum number of balls in a single bin and $m/n$, i.e., the average number of\nballs among all bins.\nWe provide tight estimates for three quantities: the lowest maximum load that\ncould be achieved at time $m$, the lowest maximum load that could be achieved\nuniformly over the entire time interval $[m]:=\\{1, 2, \\cdots, m\\}$, and the\nlowest \\emph{typical} maximum load that could be achieved over the interval\n$[m]$, where the typicality means that the maximum load holds for $1-o(1)$\nportion of the times in $[m]$.\nWe show that when $m$ and $n$ are sufficiently large, a typical maximum load\nof $(\\log n)^{1/2+o(1)}$ can be achieved with high probability, asymptotically\nthe same as the optimal maximum load that could be achieved at time $m$.\nHowever, for any strategy, the maximal load among all times in the interval\n$[m]$ is $\\Omega\\big(\\frac{\\log n}{\\log\\log n}\\big)$ with high probability. A\nstrategy achieving this bound is provided.\nAn explanation for this gap is provided by our optimal strategies as follows.\nTo control the typical load, we restrain the maximum load for some time, during\nwhich we accumulate more and more bins with relatively high load. After a\nwhile, we have to employ for a short time a different strategy to reduce the\nnumber of relatively heavily loaded bins, at the expanse of temporarily\ninducing high load in a few bins.",
    "descriptor": "",
    "authors": [
      "Ohad N. Feldheim",
      "Ori Gurel-Gurevich",
      "Jiange Li"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.05009"
  },
  {
    "id": "arXiv:2110.05476",
    "title": "Image Compression and Classification Using Qubits and Quantum Deep  Learning",
    "abstract": "Recent work suggests that quantum machine learning techniques can be used for\nclassical image classification by encoding the images in quantum states and\nusing a quantum neural network for inference. However, such work has been\nrestricted to very small input images, at most 4 x 4, that are unrealistic and\ncannot even be accurately labeled by humans. The primary difficulties in using\nlarger input images is that hitherto-proposed encoding schemes necessitate more\nqubits than are physically realizable. We propose a framework to classify\nlarger, realistic images using quantum systems. Our approach relies on a novel\nencoding mechanism that embeds images in quantum states while necessitating\nfewer qubits than prior work. Our framework is able to classify images that are\nlarger than previously possible, up to 16 x 16 for the MNIST dataset on a\npersonal laptop, and obtains accuracy comparable to classical neural networks\nwith the same number of learnable parameters. We also propose a technique for\nfurther reducing the number of qubits needed to represent images that may\nresult in an easier physical implementation at the expense of final\nperformance. Our work enables quantum machine learning and classification on\nclassical datasets of dimensions that were previously intractable by physically\nrealizable quantum computers or classical simulation",
    "descriptor": "",
    "authors": [
      "Ali Mohsen",
      "Mo Tiwari"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.05476"
  },
  {
    "id": "arXiv:2110.05478",
    "title": "An In-depth Summary of Recent Artificial Intelligence Applications in  Drug Design",
    "abstract": "As a promising tool to navigate in the vast chemical space, artificial\nintelligence (AI) is leveraged for drug design. From the year 2017 to 2021, the\nnumber of applications of several recent AI models (i.e. graph neural network\n(GNN), recurrent neural network (RNN), variation autoencoder (VAE), generative\nadversarial network (GAN), flow and reinforcement learning (RL)) in drug design\nincreases significantly. Many relevant literature reviews exist. However, none\nof them provides an in-depth summary of many applications of the recent AI\nmodels in drug design. To complement the existing literature, this survey\nincludes the theoretical development of the previously mentioned AI models and\ndetailed summaries of 42 recent applications of AI in drug design. Concretely,\n13 of them leverage GNN for molecular property prediction and 29 of them use RL\nand/or deep generative models for molecule generation and optimization. In most\ncases, the focus of the summary is the models, their variants, and\nmodifications for specific tasks in drug design. Moreover, 60 additional\napplications of AI in molecule generation and optimization are briefly\nsummarized in a table. Finally, this survey provides a holistic discussion of\nthe abundant applications so that the tasks, potential solutions, and\nchallenges in AI-based drug design become evident.",
    "descriptor": "\nComments: 26 pages, 6 figures, 3 tables, 253 references\n",
    "authors": [
      "Yi Zhang"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05478"
  },
  {
    "id": "arXiv:2110.05498",
    "title": "Satellite galaxy abundance dependency on cosmology in Magneticum  simulations",
    "abstract": "Context: Modelling satellite galaxy abundance $N_s$ in Galaxy Clusters (GCs)\nis a key element in modelling the Halo Occupation Distribution (HOD), which\nitself is a powerful tool to connect observational studies with numerical\nsimulations. Aims: To study the impact of cosmological parameters on satellite\nabundance both in cosmological simulations and in mock observations. Methods:\nWe build an emulator (HODEmu, \\url{https://github.com/aragagnin/HODEmu/}) of\nsatellite abundance based on cosmological parameters $\\Omega_m, \\Omega_b,\n\\sigma_8, h_0$ and redshift $z.$ We train our emulator using \\magneticum\nhydrodynamic simulations that span 15 different cosmologies, each over $4$\nredshift slices between $0<z<0.5,$ and for each setup we fit normalisation $A$,\nlog-slope $\\beta$ and Gaussian fractional-scatter $\\sigma$ of the $N_s-M$\nrelation. The emulator is based on multi-variate output Gaussian Process\nRegression (GPR). Results: We find that $A$ and $\\beta$ depend on cosmological\nparameters, even if weakly, especially on $\\Omega_m,$ $\\Omega_b.$ This\ndependency can explain some discrepancies found in literature between satellite\nHOD of different cosmological simulations (Magneticum, Illustris, BAHAMAS). We\nalso show that satellite abundance cosmology dependency differs between\nfull-physics (FP) simulations, dark-matter only (DMO), and non-radiative\nsimulations. Conclusions: This work provides a preliminary calibration of the\ncosmological dependency of the satellite abundance of high mass halos, and we\nshowed that modelling HOD with cosmological parameters is necessary to\ninterpret satellite abundance, and we showed the importance of using FP\nsimulations in modelling this dependency.",
    "descriptor": "\nComments: 15 pages, 13 figues, submitted to A&A\n",
    "authors": [
      "Antonio Ragagnin",
      "Alessandra Fumagalli",
      "Tiago Castro",
      "Klaus Dolag",
      "Alexandro Saro",
      "Matteo Costanzi",
      "Sebastian Bocquet"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05498"
  },
  {
    "id": "arXiv:2110.05517",
    "title": "Learnability of the output distributions of local quantum circuits",
    "abstract": "There is currently a large interest in understanding the potential advantages\nquantum devices can offer for probabilistic modelling. In this work we\ninvestigate, within two different oracle models, the probably approximately\ncorrect (PAC) learnability of quantum circuit Born machines, i.e., the output\ndistributions of local quantum circuits. We first show a negative result,\nnamely, that the output distributions of super-logarithmic depth Clifford\ncircuits are not sample-efficiently learnable in the statistical query model,\ni.e., when given query access to empirical expectation values of bounded\nfunctions over the sample space. This immediately implies the hardness, for\nboth quantum and classical algorithms, of learning from statistical queries the\noutput distributions of local quantum circuits using any gate set which\nincludes the Clifford group. As many practical generative modelling algorithms\nuse statistical queries -- including those for training quantum circuit Born\nmachines -- our result is broadly applicable and strongly limits the\npossibility of a meaningful quantum advantage for learning the output\ndistributions of local quantum circuits. As a positive result, we show that in\na more powerful oracle model, namely when directly given access to samples, the\noutput distributions of local Clifford circuits are computationally efficiently\nPAC learnable by a classical learner. Our results are equally applicable to the\nproblems of learning an algorithm for generating samples from the target\ndistribution (generative modelling) and learning an algorithm for evaluating\nits probabilities (density modelling). They provide the first rigorous insights\ninto the learnability of output distributions of local quantum circuits from\nthe probabilistic modelling perspective.",
    "descriptor": "\nComments: 24+11 pages, 5 figures, comments welcome\n",
    "authors": [
      "Marcel Hinsche",
      "Marios Ioannou",
      "Alexander Nietner",
      "Jonas Haferkamp",
      "Yihui Quek",
      "Dominik Hangleiter",
      "Jean-Pierre Seifert",
      "Jens Eisert",
      "Ryan Sweke"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.05517"
  },
  {
    "id": "arXiv:2110.05528",
    "title": "Smoothed Separable Nonnegative Matrix Factorization",
    "abstract": "Given a set of data points belonging to the convex hull of a set of vertices,\na key problem in data analysis and machine learning is to estimate these\nvertices in the presence of noise. Many algorithms have been developed under\nthe assumption that there is at least one nearby data point to each vertex; two\nof the most widely used ones are vertex component analysis (VCA) and the\nsuccessive projection algorithm (SPA). This assumption is known as the\npure-pixel assumption in blind hyperspectral unmixing, and as the separability\nassumption in nonnegative matrix factorization. More recently, Bhattacharyya\nand Kannan (ACM-SIAM Symposium on Discrete Algorithms, 2020) proposed an\nalgorithm for learning a latent simplex (ALLS) that relies on the assumption\nthat there is more than one nearby data point for each vertex. In that\nscenario, ALLS is probalistically more robust to noise than algorithms based on\nthe separability assumption. In this paper, inspired by ALLS, we propose\nsmoothed VCA (SVCA) and smoothed SPA (SSPA) that generalize VCA and SPA by\nassuming the presence of several nearby data points to each vertex. We\nillustrate the effectiveness of SVCA and SSPA over VCA, SPA and ALLS on\nsynthetic data sets, and on the unmixing of hyperspectral images.",
    "descriptor": "\nComments: 27 pages, 11 figures\n",
    "authors": [
      "Nicolas Nadisic",
      "Nicolas Gillis",
      "Christophe Kervazo"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.05528"
  },
  {
    "id": "arXiv:2110.05531",
    "title": "Study of Drug Assimilation in Human System using Physics Informed Neural  Networks",
    "abstract": "Differential equations play a pivotal role in modern world ranging from\nscience, engineering, ecology, economics and finance where these can be used to\nmodel many physical systems and processes. In this paper, we study two\nmathematical models of a drug assimilation in the human system using Physics\nInformed Neural Networks (PINNs). In the first model, we consider the case of\nsingle dose of drug in the human system and in the second case, we consider the\ncourse of this drug taken at regular intervals. We have used the compartment\ndiagram to model these cases. The resulting differential equations are solved\nusing PINN, where we employ a feed forward multilayer perceptron as function\napproximator and the network parameters are tuned for minimum error. Further,\nthe network is trained by finding the gradient of the error function with\nrespect to the network parameters. We have employed DeepXDE, a python library\nfor PINNs, to solve the simultaneous first order differential equations\ndescribing the two models of drug assimilation. The results show high degree of\naccuracy between the exact solution and the predicted solution as much as the\nresulting error reaches10^(-11) for the first model and 10^(-8) for the second\nmodel. This validates the use of PINN in solving any dynamical system.",
    "descriptor": "",
    "authors": [
      "Kanupriya Goswami",
      "Arpana Sharma",
      "Madhu Pruthi",
      "Richa Gupta"
    ],
    "subjectives": [
      "Other Quantitative Biology (q-bio.OT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05531"
  },
  {
    "id": "arXiv:2110.05551",
    "title": "Quantifying the Risk of Wildfire Ignition by Power Lines under Extreme  Weather Conditions",
    "abstract": "This paper presents a surrogate model to quantify the risk of wildfire\nignition by individual power lines under extreme weather conditions. Wind speed\nand wind gust can lead to conductor clashing, which is a cause of igniting\ndisastrous wildfires. The 3D non-linear vibration equations of power lines are\nemployed to generate a dataset that considers physical, structural, and\nmeteorological parameters, including the span of the power line, conductor\ndiameter, wind speed, wind gust, phase clearance, and wind direction. A set of\nmachine learning models is assembled based on these features to generate a\nscore representing the risk of conductor clashing for each power line within a\nnetwork, quantifying the risk of wildfire ignition. The rendered score\nrepresents the chance of the conductor clashing in place of simulating a\nRunge-Kutta method. A discussion on the impact of various meteorological\nparameters on power lines under the energization risk is presented. Besides, it\nis shown how the presented risk measure can be utilized to weigh in the fire\nsafety and service continuity trade-off.",
    "descriptor": "",
    "authors": [
      "Muhammad Waseem",
      "Reza Bayani",
      "Saeed D. Manshadi",
      "Hassan Tavakol-Davani"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.05551"
  },
  {
    "id": "arXiv:2110.05555",
    "title": "QAOAKit: A Toolkit for Reproducible Study, Application, and Verification  of the QAOA",
    "abstract": "Understanding the best known parameters, performance, and systematic behavior\nof the Quantum Approximate Optimization Algorithm (QAOA) remain open research\nquestions, even as the algorithm gains popularity. We introduce QAOAKit, a\nPython toolkit for the QAOA built for exploratory research. QAOAKit is a\nunified repository of preoptimized QAOA parameters and circuit generators for\ncommon quantum simulation frameworks. We combine, standardize, and\ncross-validate previously known parameters for the MaxCut problem, and\nincorporate this into QAOAKit. We also build conversion tools to use these\nparameters as inputs in several quantum simulation frameworks that can be used\nto reproduce, compare, and extend known results from various sources in the\nliterature. We describe QAOAKit and provide examples of how it can be used to\nreproduce research results and tackle open problems in quantum optimization.",
    "descriptor": "",
    "authors": [
      "Ruslan Shaydulin",
      "Kunal Marwaha",
      "Jonathan Wurtz",
      "Phillip C. Lotshaw"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2110.05555"
  },
  {
    "id": "arXiv:2110.05558",
    "title": "Algebraic and Puiseux series solutions of systems of autonomous  algebraic ODEs of dimension one in several variables",
    "abstract": "In this paper we study systems of autonomous algebraic ODEs in several\ndifferential indeterminates. We develop a notion of algebraic dimension of such\nsystems by considering them as algebraic systems. Afterwards we apply\ndifferential elimination and analyze the behavior of the dimension in the\nresulting Thomas decomposition. For such systems of algebraic dimension one, we\nshow that all formal Puiseux series solutions can be approximated up to an\narbitrary order by convergent solutions. We show that the existence of Puiseux\nseries and algebraic solutions can be decided algorithmically. Moreover, we\npresent a symbolic algorithm to compute all algebraic solutions. The output can\neither be represented by triangular systems or by their minimal polynomials.",
    "descriptor": "",
    "authors": [
      "Jose Cano",
      "Sebastian Falkensteiner",
      "Daniel Robertz",
      "Rafael Sendra"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2110.05558"
  },
  {
    "id": "arXiv:2110.05571",
    "title": "SRU++: Pioneering Fast Recurrence with Attention for Speech Recognition",
    "abstract": "The Transformer architecture has been well adopted as a dominant architecture\nin most sequence transduction tasks including automatic speech recognition\n(ASR), since its attention mechanism excels in capturing long-range\ndependencies. While models built solely upon attention can be better\nparallelized than regular RNN, a novel network architecture, SRU++, was\nrecently proposed. By combining the fast recurrence and attention mechanism,\nSRU++ exhibits strong capability in sequence modeling and achieves\nnear-state-of-the-art results in various language modeling and machine\ntranslation tasks with improved compute efficiency. In this work, we present\nthe advantages of applying SRU++ in ASR tasks by comparing with Conformer\nacross multiple ASR benchmarks and study how the benefits can be generalized to\nlong-form speech inputs. On the popular LibriSpeech benchmark, our SRU++ model\nachieves 2.0% / 4.7% WER on test-clean / test-other, showing competitive\nperformances compared with the state-of-the-art Conformer encoder under the\nsame set-up. Specifically, SRU++ can surpass Conformer on long-form speech\ninput with a large margin, based on our analysis.",
    "descriptor": "",
    "authors": [
      "Jing Pan",
      "Tao Lei",
      "Kwangyoun Kim",
      "Kyu Han",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05571"
  },
  {
    "id": "arXiv:2110.05588",
    "title": "DeepFilterNet: A Low Complexity Speech Enhancement Framework for  Full-Band Audio based on Deep Filtering",
    "abstract": "Complex-valued processing has brought deep learning-based speech enhancement\nand signal extraction to a new level. Typically, the process is based on a\ntime-frequency (TF) mask which is applied to a noisy spectrogram, while complex\nmasks (CM) are usually preferred over real-valued masks due to their ability to\nmodify the phase. Recent work proposed to use a complex filter instead of a\npoint-wise multiplication with a mask. This allows to incorporate information\nfrom previous and future time steps exploiting local correlations within each\nfrequency band. In this work, we propose DeepFilterNet, a two stage speech\nenhancement framework utilizing deep filtering. First, we enhance the spectral\nenvelope using ERB-scaled gains modeling the human frequency perception. The\nsecond stage employs deep filtering to enhance the periodic components of\nspeech. Additionally to taking advantage of perceptual properties of speech, we\nenforce network sparsity via separable convolutions and extensive grouping in\nlinear and recurrent layers to design a low complexity architecture. We further\nshow that our two stage deep filtering approach outperforms complex masks over\na variety of frequency resolutions and latencies and demonstrate convincing\nperformance compared to other state-of-the-art models.",
    "descriptor": "",
    "authors": [
      "Hendrik Schr\u00f6ter",
      "Alberto N. Escalante-B.",
      "Tobias Rosenkranz",
      "Andreas Maier"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.05588"
  },
  {
    "id": "arXiv:2110.05632",
    "title": "Wind-robust sound event detection and denoising for bioacoustics",
    "abstract": "Sound recordings are used in various ecological studies, including acoustic\nwildlife monitoring. Such surveys require automatic detection of target sound\nevents. However, current detectors, especially those relying on band-limited\nenergy, are severely impacted by wind. The rapid dynamics of this noise\ninvalidate standard noise estimators, and no satisfactory method for dealing\nwith it exists in bioacoustics, where simple training and generalization\nbetween conditions are important. We propose to estimate the transient noise\nlevel by fitting short-term spectrum models to a wavelet packet representation.\nThis estimator is then combined with log-spectral subtraction to stabilize the\nbackground level. The resulting adjusted wavelet series can be analysed by\nstandard energy detectors. We use real monitoring data to tune this workflow,\nand test it on two acoustic surveys of birds. Additionally, we show how the\nestimator can be incorporated in a denoising method to restore sound. The\nproposed noise-robust workflow greatly reduced the number of false alarms in\nthe surveys, compared to unadjusted energy detection. As a result, the survey\nefficiency (precision of the estimated call density) improved for both species.\nDenoising was also more effective when using the short-term estimate, whereas\nstandard wavelet shrinkage with a constant noise estimate struggled to remove\nthe effects of wind. In contrast to existing methods, the proposed estimator\ncan adjust for transient broadband noises without requiring additional hardware\nor extensive tuning to each species. It improved the detection workflow based\non very little training data, making it particularly attractive for detection\nof rare species.",
    "descriptor": "\nComments: 34 pages, 5 figures, 2 supplementary figures\n",
    "authors": [
      "Julius Juodakis",
      "Stephen Marsland"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Sound (cs.SD)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2110.05632"
  },
  {
    "id": "arXiv:2110.05636",
    "title": "CAPITAL: Optimal Subgroup Identification via Constrained Policy Tree  Search",
    "abstract": "Personalized medicine, a paradigm of medicine tailored to a patient's\ncharacteristics, is an increasingly attractive field in health care. An\nimportant goal of personalized medicine is to identify a subgroup of patients,\nbased on baseline covariates, that benefits more from the targeted treatment\nthan other comparative treatments. Most of the current subgroup identification\nmethods only focus on obtaining a subgroup with an enhanced treatment effect\nwithout paying attention to subgroup size. Yet, a clinically meaningful\nsubgroup learning approach should identify the maximum number of patients who\ncan benefit from the better treatment. In this paper, we present an optimal\nsubgroup selection rule (SSR) that maximizes the number of selected patients,\nand in the meantime, achieves the pre-specified clinically meaningful mean\noutcome, such as the average treatment effect. We derive two equivalent\ntheoretical forms of the optimal SSR based on the contrast function that\ndescribes the treatment-covariates interaction in the outcome. We further\npropose a ConstrAined PolIcy Tree seArch aLgorithm (CAPITAL) to find the\noptimal SSR within the interpretable decision tree class. The proposed method\nis flexible to handle multiple constraints that penalize the inclusion of\npatients with negative treatment effects, and to address time to event data\nusing the restricted mean survival time as the clinically interesting mean\noutcome. Extensive simulations, comparison studies, and real data applications\nare conducted to demonstrate the validity and utility of our method.",
    "descriptor": "",
    "authors": [
      "Hengrui Cai",
      "Wenbin Lu",
      "Rachel Marceau West",
      "Devan V. Mehrotra",
      "Lingkang Huang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.05636"
  },
  {
    "id": "arXiv:2110.05664",
    "title": "Accurate and Generalizable Quantitative Scoring of Liver Steatosis from  Ultrasound Images via Scalable Deep Learning",
    "abstract": "Background & Aims: Hepatic steatosis is a major cause of chronic liver\ndisease. 2D ultrasound is the most widely used non-invasive tool for screening\nand monitoring, but associated diagnoses are highly subjective. We developed a\nscalable deep learning (DL) algorithm for quantitative scoring of liver\nsteatosis from 2D ultrasound images.\nApproach & Results: Using retrospectively collected multi-view ultrasound\ndata from 3,310 patients, 19,513 studies, and 228,075 images, we trained a DL\nalgorithm to diagnose steatosis stages (healthy, mild, moderate, or severe)\nfrom ultrasound diagnoses. Performance was validated on two multi-scanner\nunblinded and blinded (initially to DL developer) histology-proven cohorts (147\nand 112 patients) with histopathology fatty cell percentage diagnoses, and a\nsubset with FibroScan diagnoses. We also quantified reliability across scanners\nand viewpoints. Results were evaluated using Bland-Altman and receiver\noperating characteristic (ROC) analysis. The DL algorithm demonstrates\nrepeatable measurements with a moderate number of images (3 for each viewpoint)\nand high agreement across 3 premium ultrasound scanners. High diagnostic\nperformance was observed across all viewpoints: area under the curves of the\nROC to classify >=mild, >=moderate, =severe steatosis grades were 0.85, 0.90,\nand 0.93, respectively. The DL algorithm outperformed or performed at least\ncomparably to FibroScan with statistically significant improvements for all\nlevels on the unblinded histology-proven cohort, and for =severe steatosis on\nthe blinded histology-proven cohort.\nConclusions: The DL algorithm provides a reliable quantitative steatosis\nassessment across view and scanners on two multi-scanner cohorts. Diagnostic\nperformance was high with comparable or better performance than FibroScan.",
    "descriptor": "\nComments: Journal paper submission, 45 pages (main body: 28 pages, supplementary material: 17 pages)\n",
    "authors": [
      "Bowen Li",
      "Dar-In Tai",
      "Ke Yan",
      "Yi-Cheng Chen",
      "Shiu-Feng Huang",
      "Tse-Hwa Hsu",
      "Wan-Ting Yu",
      "Jing Xiao",
      "Le Lu",
      "Adam P. Harrison"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.05664"
  },
  {
    "id": "arXiv:2110.05674",
    "title": "Deviance Matrix Factorization",
    "abstract": "We investigate a general matrix factorization for deviance-based losses,\nextending the ubiquitous singular value decomposition beyond squared error\nloss. While similar approaches have been explored before, here we propose an\nefficient algorithm that is flexible enough to allow for structural zeros and\nentry weights. Moreover, we provide theoretical support for these\ndecompositions by (i) showing strong consistency under a generalized linear\nmodel setup, (ii) checking the adequacy of a chosen exponential family via a\ngeneralized Hosmer-Lemeshow test, and (iii) determining the rank of the\ndecomposition via a maximum eigenvalue gap method. To further support our\nfindings, we conduct simulation studies to assess robustness to decomposition\nassumptions and extensive case studies using benchmark datasets from image face\nrecognition, natural language processing, network analysis, and biomedical\nstudies. Our theoretical and empirical results indicate that the proposed\ndecomposition is more flexible, general, and can provide improved performance\nwhen compared to traditional methods.",
    "descriptor": "",
    "authors": [
      "Liang Wang",
      "Luis Carvalho"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.05674"
  },
  {
    "id": "arXiv:2110.05695",
    "title": "The Mirrornet : Learning Audio Synthesizer Controls Inspired by  Sensorimotor Interaction",
    "abstract": "Experiments to understand the sensorimotor neural interactions in the human\ncortical speech system support the existence of a bidirectional flow of\ninteractions between the auditory and motor regions. Their key function is to\nenable the brain to 'learn' how to control the vocal tract for speech\nproduction. This idea is the impetus for the recently proposed \"MirrorNet\", a\nconstrained autoencoder architecture. In this paper, the MirrorNet is applied\nto learn, in an unsupervised manner, the controls of a specific audio\nsynthesizer (DIVA) to produce melodies only from their auditory spectrograms.\nThe results demonstrate how the MirrorNet discovers the synthesizer parameters\nto generate the melodies that closely resemble the original and those of unseen\nmelodies, and even determine the best set parameters to approximate renditions\nof complex piano melodies generated by a different synthesizer. This\ngeneralizability of the MirrorNet illustrates its potential to discover from\nsensory data the controls of arbitrary motor-plants such as autonomous\nvehicles.",
    "descriptor": "",
    "authors": [
      "Yashish M. Siriwardena",
      "Guilhem Marion",
      "Shihab Shamma"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.05695"
  },
  {
    "id": "arXiv:2110.05745",
    "title": "VarArray: Array-Geometry-Agnostic Continuous Speech Separation",
    "abstract": "Continuous speech separation using a microphone array was shown to be\npromising in dealing with the speech overlap problem in natural conversation\ntranscription. This paper proposes VarArray, an array-geometry-agnostic speech\nseparation neural network model. The proposed model is applicable to any number\nof microphones without retraining while leveraging the nonlinear correlation\nbetween the input channels. The proposed method adapts different elements that\nwere proposed before separately, including transform-average-concatenate,\nconformer speech separation, and inter-channel phase differences, and combines\nthem in an efficient and cohesive way. Large-scale evaluation was performed\nwith two real meeting transcription tasks by using a fully developed\ntranscription system requiring no prior knowledge such as reference\nsegmentations, which allowed us to measure the impact that the continuous\nspeech separation system could have in realistic settings. The proposed model\noutperformed a previous approach to array-geometry-agnostic modeling for all of\nthe geometry configurations considered, achieving asclite-based\nspeaker-agnostic word error rates of 17.5% and 20.4% for the AMI development\nand evaluation sets, respectively, in the end-to-end setting using no\nground-truth segmentations.",
    "descriptor": "\nComments: 5 pages, 1 figure, 3 tables, submitted to ICASSP 2022\n",
    "authors": [
      "Takuya Yoshioka",
      "Xiaofei Wang",
      "Dongmei Wang",
      "Min Tang",
      "Zirun Zhu",
      "Zhuo Chen",
      "Naoyuki Kanda"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.05745"
  },
  {
    "id": "arXiv:2110.05778",
    "title": "Countable Tensor Products of Hermite Spaces and Spaces of Gaussian  Kernels",
    "abstract": "In recent years finite tensor products of reproducing kernel Hilbert spaces\n(RKHSs) of Gaussian kernels on the one hand and of Hermite spaces on the other\nhand have been considered in tractability analysis of multivariate problems. In\nthe present paper we study countably infinite tensor products for both types of\nspaces. We show that the incomplete tensor product in the sense of von Neumann\nmay be identified with an RKHS whose domain is a proper subset of the sequence\nspace $\\mathbb{R}^\\mathbb{N}$. Moreover, we show that each tensor product of\nspaces of Gaussian kernels having square-summable shape parameters is\nisometrically isomorphic to a tensor product of Hermite spaces; the\ncorresponding isomorphism is given explicitly, respects point evaluations, and\nis also an $L^2$-isometry. This result directly transfers to the case of finite\ntensor products. Furthermore, we provide regularity results for Hermite spaces\nof functions of a single variable.",
    "descriptor": "\nComments: 40 pages\n",
    "authors": [
      "M. Gnewuch",
      "M. Hefter",
      "A. Hinrichs",
      "K. Ritter"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05778"
  },
  {
    "id": "arXiv:2110.05781",
    "title": "BERTraffic: A Robust BERT-Based Approach for Speaker Change Detection  and Role Identification of Air-Traffic Communications",
    "abstract": "Automatic Speech Recognition (ASR) is gaining special interest in Air Traffic\nControl (ATC). ASR allows transcribing the communications between air traffic\ncontrollers (ATCOs) and pilots. These transcriptions are used to extract ATC\ncommand types and named entities such as aircraft callsigns. One common problem\nis when the Speech Activity Detection (SAD) or diarization system fails and\nthen two or more single speaker segments are in the same recording,\njeopardizing the overall system's performance. We developed a system that\ncombines the segmentation of a SAD module with a BERT-based model that performs\nSpeaker Change Detection (SCD) and Speaker Role Identification (SRI) based on\nASR transcripts (i.e., diarization + SRI). This research demonstrates on a\nreal-life ATC test set that performing diarization directly on textual data\nsurpass acoustic level diarization. The proposed model reaches up to\n~0.90/~0.95 F1-score on ATCO/pilot for SRI on several test sets. The text-based\ndiarization system brings a 27% relative improvement on Diarization Error Rate\n(DER) compared to standard acoustic-based diarization. These results were on\nASR transcripts of a challenging ATC test set with an estimated ~13% word error\nrate, validating the approach's robustness even on noisy ASR transcripts.",
    "descriptor": "\nComments: Submitted to the 2022 International Conference on Acoustics, Speech, & Signal Processing (ICASSP)\n",
    "authors": [
      "Juan Zuluaga-Gomez",
      "Seyyed Saeed Sarfjoo",
      "Amrutha Prasad",
      "Iuliia Nigmatulina",
      "Petr Motlicek",
      "Oliver Ohneiser",
      "Hartmut Helmke"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05781"
  },
  {
    "id": "arXiv:2110.05803",
    "title": "SDWNet: A Straight Dilated Network with Wavelet Transformation for Image  Deblurring",
    "abstract": "Image deblurring is a classical computer vision problem that aims to recover\na sharp image from a blurred image. To solve this problem, existing methods\napply the Encode-Decode architecture to design the complex networks to make a\ngood performance. However, most of these methods use repeated up-sampling and\ndown-sampling structures to expand the receptive field, which results in\ntexture information loss during the sampling process and some of them design\nthe multiple stages that lead to difficulties with convergence. Therefore, our\nmodel uses dilated convolution to enable the obtainment of the large receptive\nfield with high spatial resolution. Through making full use of the different\nreceptive fields, our method can achieve better performance. On this basis, we\nreduce the number of up-sampling and down-sampling and design a simple network\nstructure. Besides, we propose a novel module using the wavelet transform,\nwhich effectively helps the network to recover clear high-frequency texture\ndetails. Qualitative and quantitative evaluations of real and synthetic\ndatasets show that our deblurring method is comparable to existing algorithms\nin terms of performance with much lower training requirements. The source code\nand pre-trained models are available at https://github.com/FlyEgle/SDWNet.",
    "descriptor": "\nComments: 10 pages, 7 figures, ICCVW 2021\n",
    "authors": [
      "Wenbin Zou",
      "Mingchao Jiang",
      "Yunchen Zhang",
      "Liang Chen",
      "Zhiyong Lu",
      "Yi Wu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05803"
  },
  {
    "id": "arXiv:2110.05852",
    "title": "On the Self-Penalization Phenomenon in Feature Selection",
    "abstract": "We describe an implicit sparsity-inducing mechanism based on minimization\nover a family of kernels: \\begin{equation*}\n\\min_{\\beta, f}~\\widehat{\\mathbb{E}}[L(Y, f(\\beta^{1/q} \\odot X)] + \\lambda_n\n\\|f\\|_{\\mathcal{H}_q}^2~~\\text{subject to}~~\\beta \\ge 0, \\end{equation*} where\n$L$ is the loss, $\\odot$ is coordinate-wise multiplication and $\\mathcal{H}_q$\nis the reproducing kernel Hilbert space based on the kernel $k_q(x, x') =\nh(\\|x-x'\\|_q^q)$, where $\\|\\cdot\\|_q$ is the $\\ell_q$ norm. Using gradient\ndescent to optimize this objective with respect to $\\beta$ leads to exactly\nsparse stationary points with high probability. The sparsity is achieved\nwithout using any of the well-known explicit sparsification techniques such as\npenalization (e.g., $\\ell_1$), early stopping or post-processing (e.g.,\nclipping).\nAs an application, we use this sparsity-inducing mechanism to build\nalgorithms consistent for feature selection.",
    "descriptor": "\nComments: 54 pages\n",
    "authors": [
      "Michael I. Jordan",
      "Keli Liu",
      "Feng Ruan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.05852"
  },
  {
    "id": "arXiv:2110.05854",
    "title": "A scalable and fast artificial neural network syndrome decoder for  surface codes",
    "abstract": "Surface code error correction offers a highly promising pathway to achieve\nscalable fault-tolerant quantum computing. When operated as stabilizer codes,\nsurface code computations consist of a syndrome decoding step where measured\nstabilizer operators are used to determine appropriate corrections for errors\nin physical qubits. Decoding algorithms have undergone substantial development,\nwith recent work incorporating machine learning (ML) techniques. Despite\npromising initial results, the ML-based syndrome decoders are still limited to\nsmall scale demonstrations with low latency and are incapable of handling\nsurface codes with boundary conditions and various shapes needed for lattice\nsurgery and braiding. Here, we report the development of an artificial neural\nnetwork (ANN) based scalable and fast syndrome decoder capable of decoding\nsurface codes of arbitrary shape and size with data qubits suffering from the\ndepolarizing error model. Based on rigorous training over 50 million random\nquantum error instances, our ANN decoder is shown to work with code distances\nexceeding 1000 (more than 4 million physical qubits), which is the largest\nML-based decoder demonstration to-date. The established ANN decoder\ndemonstrates an execution time in principle independent of code distance,\nimplying that its implementation on dedicated hardware could potentially offer\nsurface code decoding times of O($\\mu$sec), commensurate with the\nexperimentally realisable qubit coherence times. With the anticipated scale-up\nof quantum processors within the next decade, their augmentation with a fast\nand scalable syndrome decoder such as developed in our work is expected to play\na decisive role towards experimental implementation of fault-tolerant quantum\ninformation processing.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Spiro Gicev",
      "Lloyd C. L. Hollenberg",
      "Muhammad Usman"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05854"
  },
  {
    "id": "arXiv:2110.05868",
    "title": "Modelling and analysis of offshore energy hubs",
    "abstract": "Clean, multi-carrier Offshore Energy Hubs (OEHs) may become pivotal for\nefficient offshore wind power generation and distribution. In addition, OEHs\nmay provide decarbonised energy supply for maritime transport, oil and gas\nrecovery, and offshore farming while also enabling conversion and temporary\nstorage of liquefied decarbonised energy carriers for export. Here, we\ninvestigate the role of OEHs in the transition of the Norwegian continental\nshelf energy system towards zero-emission energy supply. We develop a\nmixed-integer linear programming model for investment planning and operational\noptimisation to achieve decarbonisation at minimum costs. We consider clean\ntechnologies, including offshore wind, offshore solar, OEHs and subsea cables.\nWe conduct sensitivity analysis on CO$_2$ tax, CO$_2$ budget and the capacity\nof power from shore. The results show that (a) a hard carbon cap is necessary\nfor stimulating a zero-emission offshore energy system; (b) offshore wind\nintegration and power from shore can more than halve current emissions, but\nOEHs with storage are necessary for zero-emission production and (c) at certain\nCO$_2$ tax levels, the system with OEHs can potentially reduce CO$_2$ emissions\nby 50% and energy losses by 10%, compared to a system with only offshore\nrenewables, gas turbines and power from shore.",
    "descriptor": "",
    "authors": [
      "Hongyu Zhang",
      "Asgeir Tomasgard",
      "Brage Rugstad Knudsen",
      "Harald G. Svendsen",
      "Steffen J. Bakker",
      "Ignacio E. Grossmann"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.05868"
  },
  {
    "id": "arXiv:2110.05876",
    "title": "Label-Aware Ranked Loss for robust People Counting using Automotive  in-cabin Radar",
    "abstract": "In this paper, we introduce the Label-Aware Ranked loss, a novel metric loss\nfunction. Compared to the state-of-the-art Deep Metric Learning losses, this\nfunction takes advantage of the ranked ordering of the labels in regression\nproblems. To this end, we first show that the loss minimises when datapoints of\ndifferent labels are ranked and laid at uniform angles between each other in\nthe embedding space. Then, to measure its performance, we apply the proposed\nloss on a regression task of people counting with a short-range radar in a\nchallenging scenario, namely a vehicle cabin. The introduced approach improves\nthe accuracy as well as the neighboring labels accuracy up to 83.0% and 99.9%:\nAn increase of 6.7%and 2.1% on state-of-the-art methods, respectively.",
    "descriptor": "\nComments: submitted to ICASSP 2022\n",
    "authors": [
      "Lorenzo Servadei",
      "Huawei Sun",
      "Julius Ott",
      "Michael Stephan",
      "Souvik Hazra",
      "Thomas Stadelmayer",
      "Daniela Sanchez Lopera",
      "Robert Wille",
      "Avik Santra"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05876"
  },
  {
    "id": "arXiv:2110.05887",
    "title": "Single Independent Component Recovery and Applications",
    "abstract": "Latent variable discovery is a central problem in data analysis with a broad\nrange of applications in applied science. In this work, we consider data given\nas an invertible mixture of two statistically independent components, and\nassume that one of the components is observed while the other is hidden. Our\ngoal is to recover the hidden component. For this purpose, we propose an\nautoencoder equipped with a discriminator. Unlike the standard nonlinear ICA\nproblem, which was shown to be non-identifiable, in the special case of ICA we\nconsider here, we show that our approach can recover the component of interest\nup to entropy-preserving transformation. We demonstrate the performance of the\nproposed approach on several datasets, including image synthesis, voice\ncloning, and fetal ECG extraction.",
    "descriptor": "",
    "authors": [
      "Uri Shaham",
      "Jonathan Svirsky",
      "Ori Katz",
      "Ronen Talmon"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05887"
  },
  {
    "id": "arXiv:2110.05893",
    "title": "Hide and seek with quantum resources: New and modified protocols for  quantum steganography",
    "abstract": "Steganography is the science of hiding and communicating a secret message by\nembedding it in an innocent looking text such that the eavesdropper is unaware\nof its existence. Previously, attempts were made to establish steganography\nusing quantum key distribution (QKD). Recently, it has been shown that such\nprotocols are vulnerable to a certain steganalysis attack that can detect the\npresence of the hidden message and suppress the entire communication. In this\nwork, we elaborate on the vulnerabilities of the original protocol which make\nit insecure against this detection attack. Further, we propose a novel\nsteganography protocol using discrete modulation continuous variable QKD that\neliminates the threat of this detection-based attack. Deriving from the\nproperties of our protocol, we also propose modifications in the original\nprotocol to dispose of its vulnerabilities and make it insusceptible to\nsteganalysis.",
    "descriptor": "\nComments: It's shown that discrete modulation continuous variable QKD is useful in designing protocols of steganography free from weaknesses of an existing protocol\n",
    "authors": [
      "Rohan Joshi",
      "Akhil Gupta",
      "Kishore Thapliyal",
      "R Srikanth",
      "Anirban Pathak"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.05893"
  },
  {
    "id": "arXiv:2110.05918",
    "title": "On Gegenbauer Point Processes on the unit interval",
    "abstract": "In this note we compute the logarithmic energy of points in the unit interval\n$[-1,1]$ chosen from different Gegenbauer Determinantal Point Processes. We\ncheck that all the different families of Gegenbauer polynomials yield the same\nasymptotic result to third order, we compute exactly the value for Chebyshev\npolynomials and we give a closed expresion for the minimal possible logarithmic\nenergy. The comparison suggests that DPPs cannot match the value of the minimum\nbeyond the third asymptotic term.",
    "descriptor": "",
    "authors": [
      "Carlos Beltr\u00e1n",
      "Antonia M. Delgado",
      "Lidia Fern\u00e1ndez",
      "Joaqu\u00edn F. S\u00e1nchez Lara"
    ],
    "subjectives": [
      "Classical Analysis and ODEs (math.CA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05918"
  },
  {
    "id": "arXiv:2110.05940",
    "title": "Cycle-Tree Guided Attack of Random K-Core",
    "abstract": "The K-core of a graph is the maximal subgraph within which each vertex is\nconnected to at least K other vertices. It is a fundamental network concept for\nunderstanding threshold cascading processes with a discontinuous percolation\ntransition. A minimum attack set contains the smallest number of vertices whose\nremoval induces complete collapse of the K-core. Here we tackle this\nprototypical optimal initial-condition problem from the perspective of\ncycle-tree maximum packing and propose a cycle-tree guided attack (CTGA)\nmessage-passing algorithm. The good performance and time efficiency of CTGA are\nverified on the regular random and Erdos-Renyi random graph ensembles. Our\ncentral idea of projecting a long-range correlated dynamical process to static\nstructural patterns may also be instructive to other hard optimization and\ncontrol problems.",
    "descriptor": "\nComments: 12 pages, 3 figures, preprint\n",
    "authors": [
      "Hai-Jun Zhou"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.05940"
  },
  {
    "id": "arXiv:2110.05948",
    "title": "Denoising Diffusion Gamma Models",
    "abstract": "Generative diffusion processes are an emerging and effective tool for image\nand speech generation. In the existing methods, the underlying noise\ndistribution of the diffusion process is Gaussian noise. However, fitting\ndistributions with more degrees of freedom could improve the performance of\nsuch generative models. In this work, we investigate other types of noise\ndistribution for the diffusion process. Specifically, we introduce the\nDenoising Diffusion Gamma Model (DDGM) and show that noise from Gamma\ndistribution provides improved results for image and speech generation. Our\napproach preserves the ability to efficiently sample state in the training\ndiffusion process while using Gamma noise.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2106.07582\n",
    "authors": [
      "Eliya Nachmani",
      "Robin San Roman",
      "Lior Wolf"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.05948"
  },
  {
    "id": "arXiv:2110.05968",
    "title": "Improving Character Error Rate Is Not Equal to Having Clean Speech:  Speech Enhancement for ASR Systems with Black-box Acoustic Models",
    "abstract": "A deep neural network (DNN)-based speech enhancement (SE) aiming to maximize\nthe performance of an automatic speech recognition (ASR) system is proposed in\nthis paper. In order to optimize the DNN-based SE model in terms of the\ncharacter error rate (CER), which is one of the metric to evaluate the ASR\nsystem and generally non-differentiable, our method uses two DNNs: one for\nspeech processing and one for mimicking the output CERs derived through an\nacoustic model (AM). Then both of DNNs are alternately optimized in the\ntraining phase. Even if the AM is a black-box, e.g., like one provided by a\nthird-party, the proposed method enables the DNN-based SE model to be optimized\nin terms of the CER since the DNN mimicking the AM is differentiable.\nConsequently, it becomes feasible to build CER-centric SE model that has no\nnegative effect, e.g., additional calculation cost and changing network\narchitecture, on the inference phase since our method is merely a training\nscheme for the existing DNN-based methods. Experimental results show that our\nmethod improved CER by 7.3% relative derived through a black-box AM although\ncertain noise levels are kept.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Ryosuke Sawata",
      "Yosuke Kashiwagi",
      "Shusuke Takahashi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05968"
  },
  {
    "id": "arXiv:2110.05976",
    "title": "Early Melanoma Diagnosis with Sequential Dermoscopic Images",
    "abstract": "Dermatologists often diagnose or rule out early melanoma by evaluating the\nfollow-up dermoscopic images of skin lesions. However, existing algorithms for\nearly melanoma diagnosis are developed using single time-point images of\nlesions. Ignoring the temporal, morphological changes of lesions can lead to\nmisdiagnosis in borderline cases. In this study, we propose a framework for\nautomated early melanoma diagnosis using sequential dermoscopic images. To this\nend, we construct our method in three steps. First, we align sequential\ndermoscopic images of skin lesions using estimated Euclidean transformations,\nextract the lesion growth region by computing image differences among the\nconsecutive images, and then propose a spatio-temporal network to capture the\ndermoscopic changes from aligned lesion images and the corresponding difference\nimages. Finally, we develop an early diagnosis module to compute probability\nscores of malignancy for lesion images over time. We collected 179 serial\ndermoscopic imaging data from 122 patients to verify our method. Extensive\nexperiments show that the proposed model outperforms other commonly used\nsequence models. We also compared the diagnostic results of our model with\nthose of seven experienced dermatologists and five registrars. Our model\nachieved higher diagnostic accuracy than clinicians (63.69% vs. 54.33%,\nrespectively) and provided an earlier diagnosis of melanoma (60.7% vs. 32.7% of\nmelanoma correctly diagnosed on the first follow-up images). These results\ndemonstrate that our model can be used to identify melanocytic lesions that are\nat high-risk of malignant transformation earlier in the disease process and\nthereby redefine what is possible in the early detection of melanoma.",
    "descriptor": "",
    "authors": [
      "Zhen Yu",
      "Jennifer Nguyen",
      "Toan D Nguyen",
      "John Kelly",
      "Catriona Mclean",
      "Paul Bonnington",
      "Lei Zhang",
      "Victoria Mar",
      "Zongyuan Ge"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05976"
  },
  {
    "id": "arXiv:2110.05983",
    "title": "Network-Aware Flexibility Requests for Distribution-Level Flexibility  Markets",
    "abstract": "Local flexibility markets will become a central tool for distribution system\noperators (DSOs), who need to ensure a safe grid operation against increased\ncosts and public opposition for new network investments. Despite extended\nrecent literature on local flexibility markets, little attention has been paid\non how to determine the flexibility request that the DSOs shall submit to such\nmarkets. Considering the constraints that the network introduces (e.g. line and\nvoltage limits), so far it has been unclear how the DSO shall determine how\nmuch flexibility it requires and at which network locations. Addressing an open\nquestion for several DSOs, this paper introduces a method to design\nnetwork-aware flexibility requests from a DSO perspective. We consider\nuncertainty, which could be the result of fluctuating renewable production or\ndemand, and we compare our approach against a stochastic market clearing\nmechanism, which serves as a benchmark, deriving analytical conditions for\ntheir performance. We demonstrate our methods on a real German distribution\ngrid.",
    "descriptor": "",
    "authors": [
      "El\u00e9a Prat",
      "Irena Dukovska",
      "Rahul Nellikkath",
      "Lars Herre",
      "Malte Thoma",
      "Spyros Chatzivasileiadis"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.05983"
  },
  {
    "id": "arXiv:2110.05985",
    "title": "A Categorical Semantics of Fuzzy Concepts in Conceptual Spaces",
    "abstract": "We define a symmetric monoidal category modelling fuzzy concepts and fuzzy\nconceptual reasoning within G\\\"ardenfors' framework of conceptual (convex)\nspaces. We propose log-concave functions as models of fuzzy concepts, showing\nthat these are the most general choice satisfying a criterion due to\nG\\\"ardenfors and which are well-behaved compositionally. We then generalise\nthese to define the category of log-concave probabilistic channels between\nconvex spaces, which allows one to model fuzzy reasoning with noisy inputs, and\nprovides a novel example of a Markov category.",
    "descriptor": "",
    "authors": [
      "Sean Tull"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.05985"
  },
  {
    "id": "arXiv:2110.05990",
    "title": "Phase Noise Resilient Three-Level Continuous-Phase Modulation for  DFT-Spread OFDM",
    "abstract": "A novel OFDM-based waveform with low peak-to-average power ratio (PAPR) and\nhigh robustness against phase noise (PN) is presented. It follows the discrete\nFourier transform spread orthogonal frequency division multiplexing\n(DFT-s-OFDM) signal model. 3MSK, is inspired by continuous-phase frequency\nshift keying (FSK), but it uses three frequencies in the baseband model --\nspecifically, 0 and $\\pm f_{symbol}/4$, where $f_{symbol}$ is the symbol rate\n-- which effectively constrains the phase transitions between consecutive\nsymbols to 0 and $\\pm \\pi/2$ rad. Motivated by the phase controlled model of\nmodulation, different degrees of phase continuity can be achieved, while\nsupporting receiver processing with low complexity. The signal characteristics\nare improved by generating an initial time-domain nearly constant envelope\nsignal at higher than the symbol rate. This helps to reach smooth phase\ntransitions between 3MSK symbols. Also the possibility of using excess\nbandwidth is investigated by transmitting additional non-zero subcarriers\noutside active subcarriers of the basic DFT-s-OFDM model, which provides the\ncapability to greatly reduce the PAPR. Due to the fact that the information is\nencoded in the phase transitions, a receiver model that tracks the phase\nvariations without needing reference signals is developed. To this end, it is\nshown that this new modulation is well-suited for non-coherent receivers, even\nunder strong phase noise (PN) conditions, thus allowing to reduce the overhead\nof reference signals. Evaluations of this physical-layer modulation and\nwaveform scheme are performed in terms of transmitter metrics such as PAPR, OOB\nemissions and achievable output power after the power amplifier (PA). Finally,\ncoded radio link evaluations are also shown and provided, demonstrating that\n3MSK has a similar BER performance as that of traditional QPSK.",
    "descriptor": "\nComments: 14 pages, 17 figures. Submitted to IEEE Open Journal of the Communications Society\n",
    "authors": [
      "Markku Renfors",
      "Ismael Peruga Nasarre",
      "Toni Levanen",
      "Mikko Valkama",
      "Kari Pajukoski"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.05990"
  },
  {
    "id": "arXiv:2110.05994",
    "title": "Word Order Does Not Matter For Speech Recognition",
    "abstract": "In this paper, we study training of automatic speech recognition system in a\nweakly supervised setting where the order of words in transcript labels of the\naudio training data is not known. We train a word-level acoustic model which\naggregates the distribution of all output frames using LogSumExp operation and\nuses a cross-entropy loss to match with the ground-truth words distribution.\nUsing the pseudo-labels generated from this model on the training set, we then\ntrain a letter-based acoustic model using Connectionist Temporal Classification\nloss. Our system achieves 2.4%/5.3% on test-clean/test-other subsets of\nLibriSpeech, which is competitive with the supervised baseline's performance.",
    "descriptor": "",
    "authors": [
      "Vineel Pratap",
      "Qiantong Xu",
      "Tatiana Likhomanenko",
      "Gabriel Synnaeve",
      "Ronan Collobert"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.05994"
  },
  {
    "id": "arXiv:2110.06002",
    "title": "Optimisation of Region of Attraction Estimates for the Exponential  Stabilisation of the Intrinsic Geometrically Exact Beam Model",
    "abstract": "A systematic approach to maximise estimates on the region of attraction in\nthe exponential stabilisation of geometrically exact (nonlinear) beam models\nvia boundary feedback is presented. Starting from recently established\nstability results based on Lyapunov arguments, the main contribution of the\npresented work is to maximise the analytically found bounds on the initial\ndatum, for which local exponential stability is guaranteed, via search of\n(optimal) polynomial Lyapunov functionals using an iterative semi-definite\nprogramming approach.",
    "descriptor": "\nComments: Accepted in: IEEE Conference on Decision and Control 2021\n",
    "authors": [
      "Marc Artola",
      "Charlotte Rodriguez",
      "Andrew Wynn",
      "Rafael Palacios",
      "G\u00fcnter Leugering"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.06002"
  },
  {
    "id": "arXiv:2110.06021",
    "title": "Embedded-model flows: Combining the inductive biases of model-free deep  learning and explicit probabilistic modeling",
    "abstract": "Normalizing flows have shown great success as general-purpose density\nestimators. However, many real world applications require the use of\ndomain-specific knowledge, which normalizing flows cannot readily incorporate.\nWe propose embedded-model flows(EMF), which alternate general-purpose\ntransformations with structured layers that embed domain-specific inductive\nbiases. These layers are automatically constructed by converting user-specified\ndifferentiable probabilistic models into equivalent bijective transformations.\nWe also introduce gated structured layers, which allow bypassing the parts of\nthe models that fail to capture the statistics of the data. We demonstrate that\nEMFs can be used to induce desirable properties such as multimodality,\nhierarchical coupling and continuity. Furthermore, we show that EMFs enable a\nhigh performance form of variational inference where the structure of the prior\nmodel is embedded in the variational architecture. In our experiments, we show\nthat this approach outperforms state-of-the-art methods in common structured\ninference problems.",
    "descriptor": "",
    "authors": [
      "Gianluigi Silvestri",
      "Emily Fertig",
      "Dave Moore",
      "Luca Ambrogioni"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06021"
  },
  {
    "id": "arXiv:2110.06023",
    "title": "The physics of higher-order interactions in complex systems",
    "abstract": "Complex networks have become the main paradigm for modelling the dynamics of\ninteracting systems. However, networks are intrinsically limited to describing\npairwise interactions, whereas real-world systems are often characterized by\nhigher-order interactions involving groups of three or more units. Higher-order\nstructures, such as hypergraphs and simplicial complexes, are therefore a\nbetter tool to map the real organization of many social, biological and\nman-made systems. Here, we highlight recent evidence of collective behaviours\ninduced by higher-order interactions, and we outline three key challenges for\nthe physics of higher-order systems.",
    "descriptor": "\nComments: pre-peer-reviewed version of the Nature Physics perspective, 7 pages, 4 figures\n",
    "authors": [
      "Federico Battiston",
      "Enrico Amico",
      "Alain Barrat",
      "Ginestra Bianconi",
      "Guilherme Ferraz de Arruda",
      "Benedetta Franceschiello",
      "Iacopo Iacopini",
      "Sonia K\u00e9fi",
      "Vito Latora",
      "Yamir Moreno",
      "Micah M. Murray",
      "Tiago P. Peixoto",
      "Francesco Vaccarino",
      "Giovanni Petri"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Social and Information Networks (cs.SI)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2110.06023"
  },
  {
    "id": "arXiv:2110.06063",
    "title": "MEDUSA: Multi-scale Encoder-Decoder Self-Attention Deep Neural Network  Architecture for Medical Image Analysis",
    "abstract": "Medical image analysis continues to hold interesting challenges given the\nsubtle characteristics of certain diseases and the significant overlap in\nappearance between diseases. In this work, we explore the concept of\nself-attention for tackling such subtleties in and between diseases. To this\nend, we introduce MEDUSA, a multi-scale encoder-decoder self-attention\nmechanism tailored for medical image analysis. While self-attention deep\nconvolutional neural network architectures in existing literature center around\nthe notion of multiple isolated lightweight attention mechanisms with limited\nindividual capacities being incorporated at different points in the network\narchitecture, MEDUSA takes a significant departure from this notion by\npossessing a single, unified self-attention mechanism with significantly higher\ncapacity with multiple attention heads feeding into different scales in the\nnetwork architecture. To the best of the authors' knowledge, this is the first\n\"single body, multi-scale heads\" realization of self-attention and enables\nexplicit global context amongst selective attention at different levels of\nrepresentational abstractions while still enabling differing local attention\ncontext at individual levels of abstractions. With MEDUSA, we obtain\nstate-of-the-art performance on multiple challenging medical image analysis\nbenchmarks including COVIDx, RSNA RICORD, and RSNA Pneumonia Challenge when\ncompared to previous work. Our MEDUSA model is publicly available.",
    "descriptor": "",
    "authors": [
      "Hossein Aboutalebi",
      "Maya Pavlova",
      "Hayden Gunraj",
      "Mohammad Javad Shafiee",
      "Ali Sabri",
      "Amer Alaref",
      "Alexander Wong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06063"
  },
  {
    "id": "arXiv:2110.06072",
    "title": "Model reduction by least squares moment matching for linear and  nonlinear systems",
    "abstract": "The paper addresses the model reduction problem for linear and nonlinear\nsystems using the notion of least squares moment matching. For linear systems,\nthe main idea is to approximate a transfer function by ensuring that the\ninterpolation conditions imposed by moment matching are satisfied in a least\nsquares sense. The paper revisits this idea using tools from output regulation\ntheory to provide a new time-domain characterization of least squares moment\nmatching. It is shown that least squares moment matching can be characterized\nin terms of an optimization problem involving an invariance equation and in\nterms of the steady-state behavior of an error system. This characterization,\nin turn, is then used to define a nonlinear enhancement of the notion of least\nsquares moment matching and to develop a model reduction theory for nonlinear\nsystems based on the notion of least squares moment matching. Parameterized\nfamilies of models achieving least squares moment matching are determined both\nfor linear and nonlinear systems. The new parameterizations are shown to admit\nnatural geometric and system-theoretic interpretations. The theory is\nillustrated by worked-out numerical examples.",
    "descriptor": "\nComments: Submitted to the IEEE Transactions on Automatic Control. arXiv admin note: substantial text overlap with arXiv:2109.11869\n",
    "authors": [
      "Alberto Padoan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.06072"
  },
  {
    "id": "arXiv:2110.06078",
    "title": "Model-based analysis of brain activity reveals the hierarchy of language  in 305 subjects",
    "abstract": "A popular approach to decompose the neural bases of language consists in\ncorrelating, across individuals, the brain responses to different stimuli (e.g.\nregular speech versus scrambled words, sentences, or paragraphs). Although\nsuccessful, this `model-free' approach necessitates the acquisition of a large\nand costly set of neuroimaging data. Here, we show that a model-based approach\ncan reach equivalent results within subjects exposed to natural stimuli. We\ncapitalize on the recently-discovered similarities between deep language models\nand the human brain to compute the mapping between i) the brain responses to\nregular speech and ii) the activations of deep language models elicited by\nmodified stimuli (e.g. scrambled words, sentences, or paragraphs). Our\nmodel-based approach successfully replicates the seminal study of Lerner et al.\n(2011), which revealed the hierarchy of language areas by comparing the\nfunctional-magnetic resonance imaging (fMRI) of seven subjects listening to\n7min of both regular and scrambled narratives. We further extend and precise\nthese results to the brain signals of 305 individuals listening to 4.1 hours of\nnarrated stories. Overall, this study paves the way for efficient and flexible\nanalyses of the brain bases of language.",
    "descriptor": "\nComments: Accepted to EMNLP 2021 (Findings)\n",
    "authors": [
      "Charlotte Caucheteux",
      "Alexandre Gramfort",
      "Jean-R\u00e9mi King"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06078"
  },
  {
    "id": "arXiv:2110.06080",
    "title": "Characterizing the Immaterial. Noninvasive Imaging and Analysis of  Stephen Benton's Hologram Engine no. 9",
    "abstract": "Invented in 1962, holography is a unique merging of art and technology. It\npersisted at the scientific cutting edge through the 1990s, when digital\nimaging emerged and supplanted film. Today, holography is experiencing new\ninterest as analog holograms enter major museum collections as bona fide works\nof art. In this essay, we articulate our initial steps at Northwestern's Center\nfor Scientific Studies in the Arts to describe the technological challenges on\nthe conservation of holograms, emphasizing their nature as an active material.\nA holographic image requires user interaction to be viewed, and the materials\nare delicate and prone to deterioration. Specifically, we outline our methods\nfor creating digital preservation copies of holographic artworks by documenting\nthe wavefront of propagating light. In so doing, we demonstrate why it remains\nchallenging to faithfully capture their high spatial resolution, the full\nparallax, and deep depths of field without terabytes of data. In addition, we\nuse noninvasive analytical techniques such as spectral imaging, X-ray\nfluorescence, and optical coherence tomography, to provide insights on hologram\nmaterial properties. Through these studies we hope to address current concerns\nabout the long term preservation of holograms while translating this artform\ninto a digital format to entice new audiences.",
    "descriptor": "",
    "authors": [
      "Marc Walton",
      "Pengxiao Hao",
      "Marc Vermeulen",
      "Florian Willomitzer",
      "Oliver Cossairt"
    ],
    "subjectives": [
      "History and Philosophy of Physics (physics.hist-ph)",
      "Computers and Society (cs.CY)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2110.06080"
  },
  {
    "id": "arXiv:2110.06082",
    "title": "Efficient Bayesian network structure learning via local Markov boundary  search",
    "abstract": "We analyze the complexity of learning directed acyclic graphical models from\nobservational data in general settings without specific distributional\nassumptions. Our approach is information-theoretic and uses a local Markov\nboundary search procedure in order to recursively construct ancestral sets in\nthe underlying graphical model. Perhaps surprisingly, we show that for certain\ngraph ensembles, a simple forward greedy search algorithm (i.e. without a\nbackward pruning phase) suffices to learn the Markov boundary of each node.\nThis substantially improves the sample complexity, which we show is at most\npolynomial in the number of nodes. This is then applied to learn the entire\ngraph under a novel identifiability condition that generalizes existing\nconditions from the literature. As a matter of independent interest, we\nestablish finite-sample guarantees for the problem of recovering Markov\nboundaries from data. Moreover, we apply our results to the special case of\npolytrees, for which the assumptions simplify, and provide explicit conditions\nunder which polytrees are identifiable and learnable in polynomial time. We\nfurther illustrate the performance of the algorithm, which is easy to\nimplement, in a simulation study. Our approach is general, works for discrete\nor continuous distributions without distributional assumptions, and as such\nsheds light on the minimal assumptions required to efficiently learn the\nstructure of directed graphical models from data.",
    "descriptor": "\nComments: 30 pages, 3 figures, to appear in NeurIPS 2021\n",
    "authors": [
      "Ming Gao",
      "Bryon Aragam"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06082"
  },
  {
    "id": "arXiv:2110.06122",
    "title": "Nonnegative spatial factorization",
    "abstract": "Gaussian processes are widely used for the analysis of spatial data due to\ntheir nonparametric flexibility and ability to quantify uncertainty, and\nrecently developed scalable approximations have facilitated application to\nmassive datasets. For multivariate outcomes, linear models of coregionalization\ncombine dimension reduction with spatial correlation. However, their\nreal-valued latent factors and loadings are difficult to interpret because,\nunlike nonnegative models, they do not recover a parts-based representation. We\npresent nonnegative spatial factorization (NSF), a spatially-aware\nprobabilistic dimension reduction model that naturally encourages sparsity. We\ncompare NSF to real-valued spatial factorizations such as MEFISTO and\nnonspatial dimension reduction methods using simulations and high-dimensional\nspatial transcriptomics data. NSF identifies generalizable spatial patterns of\ngene expression. Since not all patterns of gene expression are spatial, we also\npropose a hybrid extension of NSF that combines spatial and nonspatial\ncomponents, enabling quantification of spatial importance for both observations\nand features. A TensorFlow implementation of NSF is available from\nhttps://github.com/willtownes/nsf-paper .",
    "descriptor": "",
    "authors": [
      "F. William Townes",
      "Barbara E. Engelhardt"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2110.06122"
  },
  {
    "id": "arXiv:2110.06126",
    "title": "Spatial mixup: Directional loudness modification as data augmentation  for sound event localization and detection",
    "abstract": "Data augmentation methods have shown great importance in diverse supervised\nlearning problems where labeled data is scarce or costly to obtain. For sound\nevent localization and detection (SELD) tasks several augmentation methods have\nbeen proposed, with most borrowing ideas from other domains such as images,\nspeech, or monophonic audio. However, only a few exploit the spatial properties\nof a full 3D audio scene. We propose Spatial Mixup, as an application of\nparametric spatial audio effects for data augmentation, which modifies the\ndirectional properties of a multi-channel spatial audio signal encoded in the\nambisonics domain. Similarly to beamforming, these modifications enhance or\nsuppress signals arriving from certain directions, although the effect is less\npronounced. Therefore enabling deep learning models to achieve invariance to\nsmall spatial perturbations. The method is evaluated with experiments in the\nDCASE 2021 Task 3 dataset, where spatial mixup increases performance over a\nnon-augmented baseline, and compares to other well known augmentation methods.\nFurthermore, combining spatial mixup with other methods greatly improves\nperformance.",
    "descriptor": "\nComments: 5 pages, 2 figures, 4 tables. Submitted to the 2022 International Conference on Acoustics, Speech, & Signal Processing (ICASSP)\n",
    "authors": [
      "Ricardo Falcon-Perez",
      "Kazuki Shimada",
      "Yuichiro Koyama",
      "Shusuke Takahashi",
      "Yuki Mitsufuji"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.06126"
  },
  {
    "id": "arXiv:2110.06131",
    "title": "Fetal Gender Identification using Machine and Deep Learning Algorithms  on Phonocardiogram Signals",
    "abstract": "Phonocardiogram (PCG) signal analysis is a critical, widely-studied\ntechnology to noninvasively analyze the heart's mechanical activity. Through\nevaluating heart sounds, this technology has been chiefly leveraged as a\npreliminary solution to automatically diagnose Cardiovascular diseases among\nadults; however, prenatal tasks such as fetal gender identification have been\nrelatively less studied using fetal Phonocardiography (FPCG). In this work, we\napply common PCG signal processing techniques on the gender-tagged Shiraz\nUniversity Fetal Heart Sounds Database and study the applicability of\npreviously proposed features in classifying fetal gender using both Machine\nLearning and Deep Learning models. Even though PCG data acquisition's\ncost-effectiveness and feasibility make it a convenient method of Fetal Heart\nRate (FHR) monitoring, the contaminated nature of PCG signals with the noise of\nvarious types makes it a challenging modality. To address this problem, we\nexperimented with both static and adaptive noise reduction techniques such as\nLow-pass filtering, Denoising Autoencoders, and Source Separators. We apply a\nwide range of previously proposed classifiers to our dataset and propose a\nnovel ensemble method of Fetal Gender Identification (FGI). Our method\nsubstantially outperformed the baseline and reached up to 91% accuracy in\nclassifying fetal gender of unseen subjects.",
    "descriptor": "",
    "authors": [
      "Reza Khanmohammadi",
      "Mitra Sadat Mirshafiee",
      "Mohammad Mahdi Ghassemi",
      "Tuka Alhanai"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06131"
  },
  {
    "id": "arXiv:2110.06137",
    "title": "An Activity Recognition Framework for Continuous Monitoring of  Non-Steady-State Locomotion of Individuals with Parkinson's Disease",
    "abstract": "Fundamental knowledge in activity recognition of individuals with motor\ndisorders such as Parkinson's disease (PD) has been primarily limited to\ndetection of steady-state/static tasks (sitting, standing, walking). To date,\nidentification of non-steady-state locomotion on uneven terrains (stairs,\nramps) has not received much attention. Furthermore, previous research has\nmainly relied on data from a large number of body locations which could\nadversely affect user convenience and system performance. Here, individuals\nwith mild stages of PD and healthy subjects performed non-steady-state circuit\ntrials comprising stairs, ramp, and changes of direction. An offline analysis\nusing a linear discriminant analysis (LDA) classifier and a Long-Short Term\nMemory (LSTM) neural network was performed for task recognition. The\nperformance of accelerographic and gyroscopic information from varied\nlower/upper-body segments were tested across a set of user-independent and\nuser-dependent training paradigms. Comparing the F1 score of a given signal\nacross classifiers showed improved performance using LSTM compared to LDA.\nUsing LSTM, even a subset of information (e.g., feet data) in\nsubject-independent training appeared to provide F1 score > 0.8. However,\nemploying LDA was shown to be at the expense of being limited to using a\nsubject-dependent training and/or biomechanical data from multiple body\nlocations. The findings could inform a number of applications in the field of\nhealthcare monitoring and developing advanced lower-limb assistive devices by\nproviding insights into classification schemes capable of handling\nnon-steady-state and unstructured locomotion in individuals with mild\nParkinson's disease.",
    "descriptor": "",
    "authors": [
      "Mahdieh Kazemimoghadam",
      "Nicholas P. Fey"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06137"
  },
  {
    "id": "arXiv:2110.06139",
    "title": "Classification of anomalous gait using Machine Learning techniques and  embedded sensors",
    "abstract": "Human gait can be a predictive factor for detecting pathologies that affect\nhuman locomotion according to studies. In addition, it is known that a high\ninvestment is demanded in order to raise a traditional clinical infrastructure\nable to provide human gait examinations, making them unaffordable for\neconomically vulnerable patients. In face of this scenario, this work proposes\nan accessible and modern solution composed of a wearable device, to acquire\n3D-accelerometer and 3D-gyroscope measurements, and machine learning techniques\nto classify between distinct categories of induced gait disorders. In order to\ndevelop the proposed research, it was created a dataset with the target label\nbeing 4 distinct and balanced categories of anomalous gait. The machine\nlearning techniques that achieved the best performances (in terms of accuracy)\nin this dataset were through the application of Principal Component Analysis\nalgorithm following of a Support Vector Machines classifier (94 \\%). Further,\nan architecture based on a Feedforward Neural Network yielded even better\nresults (96 \\%). Finally, it is also presented computational performance\ncomparison between the models implemented.",
    "descriptor": "",
    "authors": [
      "T. R. D. Sa",
      "C. M. S. Figueiredo"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06139"
  },
  {
    "id": "arXiv:2110.06140",
    "title": "EEG functional connectivity and deep learning for automatic diagnosis of  brain disorders: Alzheimer's disease and schizophrenia",
    "abstract": "Mental disorders are among the leading causes of disability worldwide. The\nfirst step in treating these conditions is to obtain an accurate diagnosis, but\nthe absence of established clinical tests makes this task challenging. Machine\nlearning algorithms can provide a possible solution to this problem, as we\ndescribe in this work. We present a method for the automatic diagnosis of\nmental disorders based on the matrix of connections obtained from EEG time\nseries and deep learning. We show that our approach can classify patients with\nAlzheimer's disease and schizophrenia with a high level of accuracy. The\ncomparison with the traditional cases, that use raw EEG time series, shows that\nour method provides the highest precision. Therefore, the application of deep\nneural networks on data from brain connections is a very promising method to\nthe diagnosis of neurological disorders.",
    "descriptor": "\nComments: 10 pages, 5 figures, 9 tables\n",
    "authors": [
      "Caroline L. Alves",
      "Aruane M. Pineda",
      "Kirstin Roster",
      "Christiane Thielemann",
      "Francisco A. Rodrigues"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06140"
  },
  {
    "id": "arXiv:2110.06148",
    "title": "Optimal rate of convergence for approximations of SPDEs with non-regular  drift",
    "abstract": "A fully discrete finite difference scheme for stochastic reaction-diffusion\nequations driven by a $1+1$-dimensional white noise is studied. The optimal\nstrong rate of convergence is proved without posing any regularity assumption\non the non-linear reaction term. The proof relies on stochastic sewing\ntechniques.",
    "descriptor": "\nComments: 37 pages\n",
    "authors": [
      "Oleg Butkovsky",
      "Konstantinos Dareiotis",
      "M\u00e1t\u00e9 Gerencs\u00e9r"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.06148"
  },
  {
    "id": "arXiv:2110.06150",
    "title": "Sparsity in Partially Controllable Linear Systems",
    "abstract": "A fundamental concept in control theory is that of controllability, where any\nsystem state can be reached through an appropriate choice of control inputs.\nIndeed, a large body of classical and modern approaches are designed for\ncontrollable linear dynamical systems. However, in practice, we often encounter\nsystems in which a large set of state variables evolve exogenously and\nindependently of the control inputs; such systems are only \\emph{partially\ncontrollable}. The focus of this work is on a large class of partially\ncontrollable linear dynamical systems, specified by an underlying sparsity\npattern. Our main results establish structural conditions and finite-sample\nguarantees for learning to control such systems. In particular, our structural\nresults characterize those state variables which are irrelevant for optimal\ncontrol, an analysis which departs from classical control techniques. Our\nalgorithmic results adapt techniques from high-dimensional statistics --\nspecifically soft-thresholding and semiparametric least-squares -- to exploit\nthe underlying sparsity pattern in order to obtain finite-sample guarantees\nthat significantly improve over those based on certainty-equivalence. We also\ncorroborate these theoretical improvements over certainty-equivalent control\nthrough a simulation study.",
    "descriptor": "",
    "authors": [
      "Yonathan Efroni",
      "Sham Kakade",
      "Akshay Krishnamurthy",
      "Cyril Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06150"
  },
  {
    "id": "arXiv:2110.06165",
    "title": "Embedding perfectly balanced 2-caterpillar into its optimal hypercube",
    "abstract": "A long-standing conjecture on spanning trees of a hypercube states that a\nbalanced tree on $2^n$ vertices with maximum degree at most $3$ spans the\nhypercube of dimension $n$ \\cite{havel1986}. In this paper, we settle the\nconjecture for a special family of binary trees. A $0$-caterpillar is a path.\nFor $k\\geq 1$, a $k$-caterpillar is a binary tree consisting of a path with\n$j$-caterpillars $(0\\leq j\\leq k-1)$ emanating from some of the vertices on the\npath. A $k$-caterpillar that contains a perfect matching is said to be\nperfectly balanced. In this paper, we show that a perfectly balanced\n$2$-caterpillar on $2^n$ vertices spans the hypercube of dimension $n$.",
    "descriptor": "",
    "authors": [
      "Rishikant Rajdeepak",
      "V. Sunitha"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.06165"
  },
  {
    "id": "arXiv:2110.06172",
    "title": "Complexity of optimizing over the integers",
    "abstract": "In the first part of this paper, we present a unified framework for analyzing\nthe algorithmic complexity of any optimization problem, whether it be\ncontinuous or discrete in nature. This helps to formalize notions like \"input\",\n\"size\" and \"complexity\" in the context of general mathematical optimization,\navoiding context dependent definitions which is one of the sources of\ndifference in the treatment of complexity within continuous and discrete\noptimization. In the second part of the paper, we employ the language developed\nin the first part to study information theoretic and algorithmic complexity of\n{\\em mixed-integer convex optimization}, which contains as a special case\ncontinuous convex optimization on the one hand and pure integer optimization on\nthe other. We strive for the maximum possible generality in our exposition.\nWe hope that this paper contains material that both continuous optimizers and\ndiscrete optimizers find new and interesting, even though almost all of the\nmaterial presented is common knowledge in one or the other community. We see\nthe main merit of this paper as bringing together all of this information under\none unifying umbrella with the hope that this will act as yet another catalyst\nfor more interaction across the continuous-discrete divide. In fact, our\nmotivation behind Part I of the paper is to provide a common language for both\ncommunities.",
    "descriptor": "",
    "authors": [
      "Amitabh Basu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.06172"
  },
  {
    "id": "arXiv:2110.06177",
    "title": "Tracking the risk of a deployed model and detecting harmful distribution  shifts",
    "abstract": "When deployed in the real world, machine learning models inevitably encounter\nchanges in the data distribution, and certain -- but not all -- distribution\nshifts could result in significant performance degradation. In practice, it may\nmake sense to ignore benign shifts, under which the performance of a deployed\nmodel does not degrade substantially, making interventions by a human expert\n(or model retraining) unnecessary. While several works have developed tests for\ndistribution shifts, these typically either use non-sequential methods, or\ndetect arbitrary shifts (benign or harmful), or both. We argue that a sensible\nmethod for firing off a warning has to both (a) detect harmful shifts while\nignoring benign ones, and (b) allow continuous monitoring of model performance\nwithout increasing the false alarm rate. In this work, we design simple\nsequential tools for testing if the difference between source (training) and\ntarget (test) distributions leads to a significant drop in a risk function of\ninterest, like accuracy or calibration. Recent advances in constructing\ntime-uniform confidence sequences allow efficient aggregation of statistical\nevidence accumulated during the tracking process. The designed framework is\napplicable in settings where (some) true labels are revealed after the\nprediction is performed, or when batches of labels become available in a\ndelayed fashion. We demonstrate the efficacy of the proposed framework through\nan extensive empirical study on a collection of simulated and real datasets.",
    "descriptor": "",
    "authors": [
      "Aleksandr Podkopaev",
      "Aaditya Ramdas"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06177"
  },
  {
    "id": "arXiv:1703.01014",
    "title": "Active Learning for Cost-Sensitive Classification",
    "abstract": "Comments: Fixed typos in Appendix A",
    "descriptor": "\nComments: Fixed typos in Appendix A\n",
    "authors": [
      "Akshay Krishnamurthy",
      "Alekh Agarwal",
      "Tzu-Kuo Huang",
      "Hal Daume III",
      "John Langford"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1703.01014"
  },
  {
    "id": "arXiv:1803.01731",
    "title": "Me, My Echo Chamber, and I: Introspection on Social Media Polarization",
    "abstract": "Comments: In WWW 2018: The 2018 Web Conference, April 23-27, 2018, Lyon, France",
    "descriptor": "\nComments: In WWW 2018: The 2018 Web Conference, April 23-27, 2018, Lyon, France\n",
    "authors": [
      "Nabeel Gillani",
      "Ann Yuan",
      "Martin Saveski",
      "Soroush Vosoughi",
      "Deb Roy"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/1803.01731"
  },
  {
    "id": "arXiv:1810.10982",
    "title": "Fr\u00e9chet Distance Under Translation: Conditional Hardness and an  Algorithm via Offline Dynamic Grid Reachability",
    "abstract": "Comments: Published at TALG",
    "descriptor": "\nComments: Published at TALG\n",
    "authors": [
      "Karl Bringmann",
      "Marvin K\u00fcnnemann",
      "Andr\u00e9 Nusser"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1810.10982"
  },
  {
    "id": "arXiv:1906.09501",
    "title": "Learning partial correlation graphs and graphical models by covariance  queries",
    "abstract": "Comments: The title of the paper was changed. The previous title was 'Structure learning in graphical models by covariance queries'. Other minor changes suggested by referees were also implemented",
    "descriptor": "\nComments: The title of the paper was changed. The previous title was 'Structure learning in graphical models by covariance queries'. Other minor changes suggested by referees were also implemented\n",
    "authors": [
      "G\u00e1bor Lugosi",
      "Jakub Truszkowski",
      "Vasiliki Velona",
      "Piotr Zwiernik"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.09501"
  },
  {
    "id": "arXiv:1912.05695",
    "title": "Randomized Exploration for Non-Stationary Stochastic Linear Bandits",
    "abstract": "Comments: An earlier version of this manuscript claimed two perturbation based algorithm and their dynamic regret upper bounds. The argument contained a technical mistake, and the current version presents a fix which deteriorates their dynamic regret bounds from $\\tilde{O}(T^{2/3})$ to $\\tilde{O}(T^{3/4})$",
    "descriptor": "\nComments: An earlier version of this manuscript claimed two perturbation based algorithm and their dynamic regret upper bounds. The argument contained a technical mistake, and the current version presents a fix which deteriorates their dynamic regret bounds from $\\tilde{O}(T^{2/3})$ to $\\tilde{O}(T^{3/4})$\n",
    "authors": [
      "Baekjin Kim",
      "Ambuj Tewari"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1912.05695"
  },
  {
    "id": "arXiv:2001.02798",
    "title": "Self-guided Approximate Linear Programs",
    "abstract": "Comments: 52 pages",
    "descriptor": "\nComments: 52 pages\n",
    "authors": [
      "Parshan Pakiman",
      "Selvaprabu Nadarajah",
      "Negar Soheili",
      "Qihang Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2001.02798"
  },
  {
    "id": "arXiv:2001.08922",
    "title": "RePAD: Real-time Proactive Anomaly Detection for Time Series",
    "abstract": "Comments: 12 pages, 8 figures, the 34th International Conference on Advanced Information Networking and Applications (AINA 2020)",
    "descriptor": "\nComments: 12 pages, 8 figures, the 34th International Conference on Advanced Information Networking and Applications (AINA 2020)\n",
    "authors": [
      "Ming-Chang Lee",
      "Jia-Chun Lin",
      "Ernst Gunnar Gran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2001.08922"
  },
  {
    "id": "arXiv:2001.11001",
    "title": "A Type and Scope Safe Universe of Syntaxes with Binding: Their Semantics  and Proofs",
    "abstract": "Comments: Extended version of the ICFP 18 paper",
    "descriptor": "\nComments: Extended version of the ICFP 18 paper\n",
    "authors": [
      "Guillaume Allais",
      "Robert Atkey",
      "James Chapman",
      "Conor McBride",
      "James McKinna"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2001.11001"
  },
  {
    "id": "arXiv:2002.11571",
    "title": "Assignment Flows for Data Labeling on Graphs: Convergence and Stability",
    "abstract": "Comments: 45 pages, 7 figures, svjour3.cls style",
    "descriptor": "\nComments: 45 pages, 7 figures, svjour3.cls style\n",
    "authors": [
      "Artjom Zern",
      "Alexander Zeilmann",
      "Christoph Schn\u00f6rr"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2002.11571"
  },
  {
    "id": "arXiv:2003.03341",
    "title": "Generalized Parallel Tempering on Bayesian Inverse Problems",
    "abstract": "Comments: Published in statistics and computing this https URL",
    "descriptor": "\nComments: Published in statistics and computing this https URL\n",
    "authors": [
      "Jonas Latz",
      "Juan P. Madrigal-Cianci",
      "Fabio Nobile",
      "Raul Tempone"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2003.03341"
  },
  {
    "id": "arXiv:2003.06649",
    "title": "Partial Queries for Constraint Acquisition",
    "abstract": "Partial Queries for Constraint Acquisition",
    "descriptor": "",
    "authors": [
      "Christian Bessiere",
      "Clement Carbonnel",
      "Anton Dries",
      "Emmanuel Hebrard",
      "George Katsirelos",
      "Nadjib Lazaar",
      "Nina Narodytska",
      "Claude-Guy Quimper",
      "Kostas Stergiou",
      "Dimosthenis C. Tsouros",
      "Toby Walsh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2003.06649"
  },
  {
    "id": "arXiv:2004.02319",
    "title": "ReRe: A Lightweight Real-time Ready-to-Go Anomaly Detection Approach for  Time Series",
    "abstract": "Comments: 10 pages, 9 figures, COMPSAC 2020",
    "descriptor": "\nComments: 10 pages, 9 figures, COMPSAC 2020\n",
    "authors": [
      "Ming-Chang Lee",
      "Jia-Chun Lin",
      "Ernst Gunnar Gran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.02319"
  },
  {
    "id": "arXiv:2004.12940",
    "title": "Hybrid Top-Down and Bottom-Up Approach for Investigating Residential  Load Compositions and Load Percentages",
    "abstract": "Comments: 6 pages, 6 figures",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "Ahmed S. Alahmed",
      "Muhammed M. Almuhaini"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2004.12940"
  },
  {
    "id": "arXiv:2005.04062",
    "title": "Improved Upper Bounds for the Hitting Times of Quantum Walks",
    "abstract": "Improved Upper Bounds for the Hitting Times of Quantum Walks",
    "descriptor": "",
    "authors": [
      "Yosi Atia",
      "Shantanav Chakraborty"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2005.04062"
  },
  {
    "id": "arXiv:2006.02624",
    "title": "Bayesian optimization for modular black-box systems with switching costs",
    "abstract": "Bayesian optimization for modular black-box systems with switching costs",
    "descriptor": "",
    "authors": [
      "Chi-Heng Lin",
      "Joseph D. Miano",
      "Eva L. Dyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.02624"
  },
  {
    "id": "arXiv:2006.07040",
    "title": "Learning Decomposed Representation for Counterfactual Inference",
    "abstract": "Learning Decomposed Representation for Counterfactual Inference",
    "descriptor": "",
    "authors": [
      "Anpeng Wu",
      "Kun Kuang",
      "Junkun Yuan",
      "Bo Li",
      "Runze Wu",
      "Qiang Zhu",
      "Yueting Zhuang",
      "Fei Wu"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.07040"
  },
  {
    "id": "arXiv:2006.07749",
    "title": "Parametric Bootstrap for Differentially Private Confidence Intervals",
    "abstract": "Parametric Bootstrap for Differentially Private Confidence Intervals",
    "descriptor": "",
    "authors": [
      "Cecilia Ferrando",
      "Shufan Wang",
      "Daniel Sheldon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.07749"
  },
  {
    "id": "arXiv:2006.08812",
    "title": "Augmented Sliced Wasserstein Distances",
    "abstract": "Comments: 35 pages, 17figures",
    "descriptor": "\nComments: 35 pages, 17figures\n",
    "authors": [
      "Xiongjie Chen",
      "Yongxin Yang",
      "Yunpeng Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.08812"
  },
  {
    "id": "arXiv:2008.00047",
    "title": "Towards Class-Oriented Poisoning Attacks Against Neural Networks",
    "abstract": "Comments: 14 pages, 9 figures, accepted by Winter Conference on Applications of Computer Vision (WACV) 2022",
    "descriptor": "\nComments: 14 pages, 9 figures, accepted by Winter Conference on Applications of Computer Vision (WACV) 2022\n",
    "authors": [
      "Bingyin Zhao",
      "Yingjie Lao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.00047"
  },
  {
    "id": "arXiv:2008.01188",
    "title": "Learning to Play Two-Player Perfect-Information Games without Knowledge",
    "abstract": "Learning to Play Two-Player Perfect-Information Games without Knowledge",
    "descriptor": "",
    "authors": [
      "Quentin Cohen-Solal"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2008.01188"
  },
  {
    "id": "arXiv:2008.04933",
    "title": "PX-NET: Simple and Efficient Pixel-Wise Training of Photometric Stereo  Networks",
    "abstract": "PX-NET: Simple and Efficient Pixel-Wise Training of Photometric Stereo  Networks",
    "descriptor": "",
    "authors": [
      "Fotios Logothetis",
      "Ignas Budvytis",
      "Roberto Mecca",
      "Roberto Cipolla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2008.04933"
  },
  {
    "id": "arXiv:2008.10983",
    "title": "Instability Margin Analysis for Parametrized LTI Systems with  Application to Repressilator",
    "abstract": "Instability Margin Analysis for Parametrized LTI Systems with  Application to Repressilator",
    "descriptor": "",
    "authors": [
      "Shinji Hara",
      "Tetsuya Iwasaki",
      "Yutaka Hori"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2008.10983"
  },
  {
    "id": "arXiv:2008.12804",
    "title": "Rethinking the Objectives of Extractive Question Answering",
    "abstract": "Comments: camera-ready version accepted to MRQA'21",
    "descriptor": "\nComments: camera-ready version accepted to MRQA'21\n",
    "authors": [
      "Martin Fajcik",
      "Josef Jon",
      "Pavel Smrz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.12804"
  },
  {
    "id": "arXiv:2009.03107",
    "title": "sunny-as2: Enhancing SUNNY for Algorithm Selection",
    "abstract": "sunny-as2: Enhancing SUNNY for Algorithm Selection",
    "descriptor": "",
    "authors": [
      "Tong Liu",
      "Roberto Amadini",
      "Jacopo Mauro",
      "Maurizio Gabbrielli"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.03107"
  },
  {
    "id": "arXiv:2009.03968",
    "title": "Equations in virtually abelian groups: languages and growth",
    "abstract": "Comments: 26 pages, comments welcome. Various changes at the suggestion of the referee",
    "descriptor": "\nComments: 26 pages, comments welcome. Various changes at the suggestion of the referee\n",
    "authors": [
      "Alex Evetts",
      "Alex Levine"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2009.03968"
  },
  {
    "id": "arXiv:2009.08250",
    "title": "Parallax Attention for Unsupervised Stereo Correspondence Learning",
    "abstract": "Comments: Accepted by IEEE TPAMI 2020. arXiv admin note: text overlap with arXiv:1903.05784",
    "descriptor": "\nComments: Accepted by IEEE TPAMI 2020. arXiv admin note: text overlap with arXiv:1903.05784\n",
    "authors": [
      "Longguang Wang",
      "Yulan Guo",
      "Yingqian Wang",
      "Zhengfa Liang",
      "Zaiping Lin",
      "Jungang Yang",
      "Wei An"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.08250"
  },
  {
    "id": "arXiv:2009.10627",
    "title": "Forecasting elections results via the voter model with stubborn nodes",
    "abstract": "Forecasting elections results via the voter model with stubborn nodes",
    "descriptor": "",
    "authors": [
      "Antoine Vendeville",
      "Benjamin Guedj",
      "Shi Zhou"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.10627"
  },
  {
    "id": "arXiv:2009.12080",
    "title": "Computing the covering radius of a polytope with an application to  lonely runners",
    "abstract": "Comments: 22 pages, 4 tables, 2 figures, revised version",
    "descriptor": "\nComments: 22 pages, 4 tables, 2 figures, revised version\n",
    "authors": [
      "Jana Cslovjecsek",
      "Romanos Diogenes Malikiosis",
      "M\u00e1rton Nasz\u00f3di",
      "Matthias Schymura"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2009.12080"
  },
  {
    "id": "arXiv:2009.12919",
    "title": "Benchmarking deep inverse models over time, and the neural-adjoint  method",
    "abstract": "Comments: Preprint. For camera-ready version please visit this https URL",
    "descriptor": "\nComments: Preprint. For camera-ready version please visit this https URL\n",
    "authors": [
      "Simiao Ren",
      "Willie Padilla",
      "Jordan Malof"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.12919"
  },
  {
    "id": "arXiv:2010.01356",
    "title": "Expectigrad: Fast Stochastic Optimization with Robust Convergence  Properties",
    "abstract": "Comments: Preprint. 18 pages, 4 figures, 3 tables",
    "descriptor": "\nComments: Preprint. 18 pages, 4 figures, 3 tables\n",
    "authors": [
      "Brett Daley",
      "Christopher Amato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.01356"
  },
  {
    "id": "arXiv:2010.02990",
    "title": "First-Order Optimization Inspired from Finite-Time Convergent Flows",
    "abstract": "First-Order Optimization Inspired from Finite-Time Convergent Flows",
    "descriptor": "",
    "authors": [
      "Siqi Zhang",
      "Mouhacine Benosman",
      "Orlando Romero",
      "Anoop Cherian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2010.02990"
  },
  {
    "id": "arXiv:2010.05812",
    "title": "A Complete Approach to Loop Verification with Invariants and Summaries",
    "abstract": "Comments: This article extends a conference version at VMCAI'22",
    "descriptor": "\nComments: This article extends a conference version at VMCAI'22\n",
    "authors": [
      "Gidon Ernst"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2010.05812"
  },
  {
    "id": "arXiv:2010.11637",
    "title": "Competitive Control with Delayed Imperfect Information",
    "abstract": "Competitive Control with Delayed Imperfect Information",
    "descriptor": "",
    "authors": [
      "Chenkai Yu",
      "Guanya Shi",
      "Soon-Jo Chung",
      "Yisong Yue",
      "Adam Wierman"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2010.11637"
  },
  {
    "id": "arXiv:2010.14496",
    "title": "Generative Temporal Difference Learning for Infinite-Horizon Prediction",
    "abstract": "Comments: NeurIPS 2020. Project page at: this https URL",
    "descriptor": "\nComments: NeurIPS 2020. Project page at: this https URL\n",
    "authors": [
      "Michael Janner",
      "Igor Mordatch",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.14496"
  },
  {
    "id": "arXiv:2011.04719",
    "title": "Probabilistic Indistinguishability and the Quality of Validity in  Byzantine Agreement",
    "abstract": "Probabilistic Indistinguishability and the Quality of Validity in  Byzantine Agreement",
    "descriptor": "",
    "authors": [
      "Guy Goren",
      "Yoram Moses",
      "Alexander Spiegelman"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2011.04719"
  },
  {
    "id": "arXiv:2011.05074",
    "title": "Efficient and Transferable Adversarial Examples from Bayesian Neural  Networks",
    "abstract": "Efficient and Transferable Adversarial Examples from Bayesian Neural  Networks",
    "descriptor": "",
    "authors": [
      "Martin Gubri",
      "Maxime Cordy",
      "Mike Papadakis",
      "Yves Le Traon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.05074"
  },
  {
    "id": "arXiv:2011.07989",
    "title": "Corrupted Contextual Bandits with Action Order Constraints",
    "abstract": "Corrupted Contextual Bandits with Action Order Constraints",
    "descriptor": "",
    "authors": [
      "Alexander Galozy",
      "Slawomir Nowaczyk",
      "Mattias Ohlsson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.07989"
  },
  {
    "id": "arXiv:2011.08327",
    "title": "On the Capacity of Intensity-Modulation Direct-Detection Gaussian  Optical Wireless Communication Channels: A Tutorial",
    "abstract": "Comments: 36 pages, to appear in IEEE Commun. Surveys and Tutorials, tutorial presented in IWOW 2015, ComNet 2015, Globecom 2018, Globecom 2019, and VTC-Fall 2020",
    "descriptor": "\nComments: 36 pages, to appear in IEEE Commun. Surveys and Tutorials, tutorial presented in IWOW 2015, ComNet 2015, Globecom 2018, Globecom 2019, and VTC-Fall 2020\n",
    "authors": [
      "Anas Chaaban",
      "Zouheir Rezki",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2011.08327"
  },
  {
    "id": "arXiv:2011.10881",
    "title": "Rethinking Transformer-based Set Prediction for Object Detection",
    "abstract": "Comments: Accepted to ICCV 2021",
    "descriptor": "\nComments: Accepted to ICCV 2021\n",
    "authors": [
      "Zhiqing Sun",
      "Shengcao Cao",
      "Yiming Yang",
      "Kris Kitani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.10881"
  },
  {
    "id": "arXiv:2011.11156",
    "title": "Better Aggregation in Test-Time Augmentation",
    "abstract": "Better Aggregation in Test-Time Augmentation",
    "descriptor": "",
    "authors": [
      "Divya Shanmugam",
      "Davis Blalock",
      "Guha Balakrishnan",
      "John Guttag"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.11156"
  },
  {
    "id": "arXiv:2011.14229",
    "title": "Deep Learning for Regularization Prediction in Diffeomorphic Image  Registration",
    "abstract": "Comments: 20 pages, 8 figures",
    "descriptor": "\nComments: 20 pages, 8 figures\n",
    "authors": [
      "Jian Wang",
      "Miaomiao Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.14229"
  },
  {
    "id": "arXiv:2012.05895",
    "title": "Few-Shot Attribute Learning",
    "abstract": "Comments: Technical report, 25 pages",
    "descriptor": "\nComments: Technical report, 25 pages\n",
    "authors": [
      "Mengye Ren",
      "Eleni Triantafillou",
      "Kuan-Chieh Wang",
      "James Lucas",
      "Jake Snell",
      "Xaq Pitkow",
      "Andreas S. Tolias",
      "Richard Zemel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.05895"
  },
  {
    "id": "arXiv:2012.06433",
    "title": "Advanced Algorithms in Heterogeneous and Uncertain Networking  Environments",
    "abstract": "Advanced Algorithms in Heterogeneous and Uncertain Networking  Environments",
    "descriptor": "",
    "authors": [
      "Itamar Cohen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2012.06433"
  },
  {
    "id": "arXiv:2012.09726",
    "title": "Simulation of conditional expectations under fast mean-reverting  stochastic volatility models",
    "abstract": "Simulation of conditional expectations under fast mean-reverting  stochastic volatility models",
    "descriptor": "",
    "authors": [
      "Andrei Cozma",
      "Christoph Reisinger"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Finance (q-fin.CP)"
    ],
    "url": "https://arxiv.org/abs/2012.09726"
  },
  {
    "id": "arXiv:2012.10384",
    "title": "Hybrid Genetic Search for the CVRP: Open-Source Implementation and SWAP*  Neighborhood",
    "abstract": "Hybrid Genetic Search for the CVRP: Open-Source Implementation and SWAP*  Neighborhood",
    "descriptor": "",
    "authors": [
      "Thibaut Vidal"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2012.10384"
  },
  {
    "id": "arXiv:2101.03122",
    "title": "A general theory for anisotropic Kirchhoff-Love shells with embedded  fibers and in-plane bending",
    "abstract": "Comments: This version updates reference list and improves text editing, results unchanged",
    "descriptor": "\nComments: This version updates reference list and improves text editing, results unchanged\n",
    "authors": [
      "Thang Xuan Duong",
      "Vu Ngoc Khi\u00eam",
      "Mikhail Itskov",
      "Roger Andrew Sauer"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2101.03122"
  },
  {
    "id": "arXiv:2101.04948",
    "title": "Deep State Inference: Toward Behavioral Model Inference of Black-box  Software Systems",
    "abstract": "Comments: 17 pages,9 figures. arXiv admin note: text overlap with arXiv:2008.11856",
    "descriptor": "\nComments: 17 pages,9 figures. arXiv admin note: text overlap with arXiv:2008.11856\n",
    "authors": [
      "Foozhan Ataiefard",
      "Mohammad Jafar Mashhadi",
      "Hadi Hemmati",
      "Niel Walkinshaw"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2101.04948"
  },
  {
    "id": "arXiv:2101.05744",
    "title": "A comparative study of scoring systems by simulations",
    "abstract": "Comments: 15 pages, 4 figures, 6 tables",
    "descriptor": "\nComments: 15 pages, 4 figures, 6 tables\n",
    "authors": [
      "L\u00e1szl\u00f3 Csat\u00f3"
    ],
    "subjectives": [
      "Other Statistics (stat.OT)",
      "Computer Science and Game Theory (cs.GT)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2101.05744"
  },
  {
    "id": "arXiv:2101.06553",
    "title": "Self-Supervised Representation Learning from Flow Equivariance",
    "abstract": "Comments: ICCV 2021",
    "descriptor": "\nComments: ICCV 2021\n",
    "authors": [
      "Yuwen Xiong",
      "Mengye Ren",
      "Wenyuan Zeng",
      "Raquel Urtasun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.06553"
  },
  {
    "id": "arXiv:2101.06560",
    "title": "Adversarial Attacks On Multi-Agent Communication",
    "abstract": "Adversarial Attacks On Multi-Agent Communication",
    "descriptor": "",
    "authors": [
      "James Tu",
      "Tsunhsuan Wang",
      "Jingkang Wang",
      "Sivabalan Manivasagam",
      "Mengye Ren",
      "Raquel Urtasun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.06560"
  },
  {
    "id": "arXiv:2101.11117",
    "title": "Streaming Erasure Codes over Multi-Access Relayed Networks",
    "abstract": "Comments: 47 pages, 8 figures",
    "descriptor": "\nComments: 47 pages, 8 figures\n",
    "authors": [
      "Gustavo Kasper Facenda",
      "Elad Domanovitz",
      "Ashish Khisti",
      "Wai-Tian Tan",
      "John Apostolopoulos"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2101.11117"
  },
  {
    "id": "arXiv:2101.12088",
    "title": "Projection based model reduction for the immersed boundary method",
    "abstract": "Projection based model reduction for the immersed boundary method",
    "descriptor": "",
    "authors": [
      "Yushuang Luo",
      "Xiantao Li",
      "Wenrui Hao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2101.12088"
  },
  {
    "id": "arXiv:2102.02196",
    "title": "On Entropy and Bit Patterns of Ring Oscillator Jitter",
    "abstract": "Comments: 6 pages",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Markku-Juhani O. Saarinen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2102.02196"
  },
  {
    "id": "arXiv:2102.06560",
    "title": "How Far Should We Look Back to Achieve Effective Real-Time Time-Series  Anomaly Detection?",
    "abstract": "Comments: 12 pages, 5 figures, and 9 tables, Proceedings of the 35th International Conference on Advanced Information Network-ing and Applications (AINA 2021)",
    "descriptor": "\nComments: 12 pages, 5 figures, and 9 tables, Proceedings of the 35th International Conference on Advanced Information Network-ing and Applications (AINA 2021)\n",
    "authors": [
      "Ming-Chang Lee",
      "Jia-Chun Lin",
      "Ernst Gunnar Gran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.06560"
  },
  {
    "id": "arXiv:2102.07067",
    "title": "Fast Monocular Hand Pose Estimation on Embedded Systems",
    "abstract": "Fast Monocular Hand Pose Estimation on Embedded Systems",
    "descriptor": "",
    "authors": [
      "Shan An",
      "Xiajie Zhang",
      "Dong Wei",
      "Haogang Zhu",
      "Jianyu Yang",
      "Konstantinos A. Tsintotas"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.07067"
  },
  {
    "id": "arXiv:2102.12677",
    "title": "Do Not Let Privacy Overbill Utility: Gradient Embedding Perturbation for  Private Learning",
    "abstract": "Comments: Published as a conference paper at ICLR 2021. Source code available at this https URL",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2021. Source code available at this https URL\n",
    "authors": [
      "Da Yu",
      "Huishuai Zhang",
      "Wei Chen",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.12677"
  },
  {
    "id": "arXiv:2103.04234",
    "title": "Bottlenecks in Blockchain Consensus Protocols",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Salem Alqahtani",
      "Murat Demirbas"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2103.04234"
  },
  {
    "id": "arXiv:2103.05524",
    "title": "On the interplay between data structure and loss function in  classification problems",
    "abstract": "On the interplay between data structure and loss function in  classification problems",
    "descriptor": "",
    "authors": [
      "St\u00e9phane d'Ascoli",
      "Marylou Gabri\u00e9",
      "Levent Sagun",
      "Giulio Biroli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.05524"
  },
  {
    "id": "arXiv:2103.10427",
    "title": "The Low-Rank Simplicity Bias in Deep Networks",
    "abstract": "The Low-Rank Simplicity Bias in Deep Networks",
    "descriptor": "",
    "authors": [
      "Minyoung Huh",
      "Hossein Mobahi",
      "Richard Zhang",
      "Brian Cheung",
      "Pulkit Agrawal",
      "Phillip Isola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.10427"
  },
  {
    "id": "arXiv:2103.12209",
    "title": "Monocular Depth Estimation through Virtual-world Supervision and  Real-world SfM Self-Supervision",
    "abstract": "Comments: Published in IEEE-Transactions on Intelligent Transportation Systems, 2021 14 pages, 10 figures",
    "descriptor": "\nComments: Published in IEEE-Transactions on Intelligent Transportation Systems, 2021 14 pages, 10 figures\n",
    "authors": [
      "Akhil Gurram",
      "Ahmet Faruk Tuna",
      "Fengyi Shen",
      "Onay Urfalioglu",
      "Antonio M. L\u00f3pez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.12209"
  },
  {
    "id": "arXiv:2103.13027",
    "title": "Unveiling the Power of Mixup for Stronger Classifiers",
    "abstract": "Comments: The second version of AutoMix. 12 pages, 7 figures",
    "descriptor": "\nComments: The second version of AutoMix. 12 pages, 7 figures\n",
    "authors": [
      "Zicheng Liu",
      "Siyuan Li",
      "Di Wu",
      "Zhiyuan Chen",
      "Lirong Wu",
      "Jianzhu Guo",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.13027"
  },
  {
    "id": "arXiv:2103.16236",
    "title": "A Dual Active-Set Solver for Embedded Quadratic Programming Using  Recursive LDL' Updates",
    "abstract": "A Dual Active-Set Solver for Embedded Quadratic Programming Using  Recursive LDL' Updates",
    "descriptor": "",
    "authors": [
      "Daniel Arnstr\u00f6m",
      "Alberto Bemporad",
      "Daniel Axehill"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.16236"
  },
  {
    "id": "arXiv:2103.17182",
    "title": "Positive-Negative Momentum: Manipulating Stochastic Gradient Noise to  Improve Generalization",
    "abstract": "Comments: ICML 2021; 20 pages; 13 figures; Key Words: deep learning theory, optimizer, momentum, generalization, gradient noise",
    "descriptor": "\nComments: ICML 2021; 20 pages; 13 figures; Key Words: deep learning theory, optimizer, momentum, generalization, gradient noise\n",
    "authors": [
      "Zeke Xie",
      "Li Yuan",
      "Zhanxing Zhu",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.17182"
  },
  {
    "id": "arXiv:2104.00987",
    "title": "Bayesian Structural Learning for an Improved Diagnosis of Cyber-Physical  Systems",
    "abstract": "Bayesian Structural Learning for an Improved Diagnosis of Cyber-Physical  Systems",
    "descriptor": "",
    "authors": [
      "Nicolas Olivain",
      "Philipp Tiefenbacher",
      "Jens Kohl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.00987"
  },
  {
    "id": "arXiv:2104.01111",
    "title": "Scene Graphs: A Survey of Generations and Applications",
    "abstract": "Comments: 28 pages",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Xiaojun Chang",
      "Pengzhen Ren",
      "Pengfei Xu",
      "Zhihui Li",
      "Xiaojiang Chen",
      "Alex Hauptmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.01111"
  },
  {
    "id": "arXiv:2104.02387",
    "title": "Towards Consistent Hybrid HMM Acoustic Modeling",
    "abstract": "Towards Consistent Hybrid HMM Acoustic Modeling",
    "descriptor": "",
    "authors": [
      "Tina Raissi",
      "Eugen Beck",
      "Ralf Schl\u00fcter",
      "Hermann Ney"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2104.02387"
  },
  {
    "id": "arXiv:2104.04282",
    "title": "Direct Differentiable Augmentation Search",
    "abstract": "Comments: ICCV2021",
    "descriptor": "\nComments: ICCV2021\n",
    "authors": [
      "Aoming Liu",
      "Zehao Huang",
      "Zhiwu Huang",
      "Naiyan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.04282"
  },
  {
    "id": "arXiv:2104.05570",
    "title": "Learning from Subjective Ratings Using Auto-Decoded Deep Latent  Embeddings",
    "abstract": "Comments: Main body includes 10 pages and 3 figures",
    "descriptor": "\nComments: Main body includes 10 pages and 3 figures\n",
    "authors": [
      "Bowen Li",
      "Xinping Ren",
      "Ke Yan",
      "Le Lu",
      "Lingyun Huang",
      "Guotong Xie",
      "Jing Xiao",
      "Dar-In Tai",
      "Adam P. Harrison"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.05570"
  },
  {
    "id": "arXiv:2104.06521",
    "title": "TAAC: Temporally Abstract Actor-Critic for Continuous Control",
    "abstract": "Comments: NeurIPS 2021 camera-ready version",
    "descriptor": "\nComments: NeurIPS 2021 camera-ready version\n",
    "authors": [
      "Haonan Yu",
      "Wei Xu",
      "Haichao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2104.06521"
  },
  {
    "id": "arXiv:2104.08512",
    "title": "Minimal Supervision for Morphological Inflection",
    "abstract": "Comments: EMNLP 2021",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Omer Goldman",
      "Reut Tsarfaty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08512"
  },
  {
    "id": "arXiv:2104.08527",
    "title": "PARE: Part Attention Regressor for 3D Human Body Estimation",
    "abstract": "PARE: Part Attention Regressor for 3D Human Body Estimation",
    "descriptor": "",
    "authors": [
      "Muhammed Kocabas",
      "Chun-Hao P. Huang",
      "Otmar Hilliges",
      "Michael J. Black"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.08527"
  },
  {
    "id": "arXiv:2104.09169",
    "title": "LaLaLoc: Latent Layout Localisation in Dynamic, Unvisited Environments",
    "abstract": "Comments: As presented at the International Conference on Computer Vision (ICCV) 2021",
    "descriptor": "\nComments: As presented at the International Conference on Computer Vision (ICCV) 2021\n",
    "authors": [
      "Henry Howard-Jenkins",
      "Jose-Raul Ruiz-Sarmiento",
      "Victor Adrian Prisacariu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.09169"
  },
  {
    "id": "arXiv:2104.12553",
    "title": "Avoiding bias when inferring race using name-based approaches",
    "abstract": "Avoiding bias when inferring race using name-based approaches",
    "descriptor": "",
    "authors": [
      "Diego Kozlowski",
      "Dakota S. Murray",
      "Alexis Bell",
      "Will Hulsey",
      "Vincent Larivi\u00e8re",
      "Thema Monroe-White",
      "Cassidy R. Sugimoto"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2104.12553"
  },
  {
    "id": "arXiv:2104.12763",
    "title": "MDETR -- Modulated Detection for End-to-End Multi-Modal Understanding",
    "abstract": "MDETR -- Modulated Detection for End-to-End Multi-Modal Understanding",
    "descriptor": "",
    "authors": [
      "Aishwarya Kamath",
      "Mannat Singh",
      "Yann LeCun",
      "Gabriel Synnaeve",
      "Ishan Misra",
      "Nicolas Carion"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.12763"
  },
  {
    "id": "arXiv:2104.13135",
    "title": "LUCES: A Dataset for Near-Field Point Light Source Photometric Stereo",
    "abstract": "LUCES: A Dataset for Near-Field Point Light Source Photometric Stereo",
    "descriptor": "",
    "authors": [
      "Roberto Mecca",
      "Fotios Logothetis",
      "Ignas Budvytis",
      "Roberto Cipolla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.13135"
  },
  {
    "id": "arXiv:2104.14354",
    "title": "SoCRATES: System-on-Chip Resource Adaptive Scheduling using Deep  Reinforcement Learning",
    "abstract": "Comments: This paper has been accepted for publication by 20th IEEE International Conference on Machine Learning and Applications (ICMLA 2021). The copyright is with the IEEE",
    "descriptor": "\nComments: This paper has been accepted for publication by 20th IEEE International Conference on Machine Learning and Applications (ICMLA 2021). The copyright is with the IEEE\n",
    "authors": [
      "Tegg Taekyong Sung",
      "Bo Ryu"
    ],
    "subjectives": [
      "Operating Systems (cs.OS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2104.14354"
  },
  {
    "id": "arXiv:2105.00436",
    "title": "Properties of Graphs Specified by a Regular Language",
    "abstract": "Comments: 25 pages",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Volker Diekert",
      "Henning Fernau",
      "Petra Wolf"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2105.00436"
  },
  {
    "id": "arXiv:2105.01237",
    "title": "COMISR: Compression-Informed Video Super-Resolution",
    "abstract": "Comments: 13 pages, 10 figures",
    "descriptor": "\nComments: 13 pages, 10 figures\n",
    "authors": [
      "Yinxiao Li",
      "Pengchong Jin",
      "Feng Yang",
      "Ce Liu",
      "Ming-Hsuan Yang",
      "Peyman Milanfar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.01237"
  },
  {
    "id": "arXiv:2105.03093",
    "title": "Maximally Satisfying Lower Quotas in the Hospitals/Residents Problem  with Ties",
    "abstract": "Maximally Satisfying Lower Quotas in the Hospitals/Residents Problem  with Ties",
    "descriptor": "",
    "authors": [
      "Hiromichi Goko",
      "Kazuhisa Makino",
      "Shuichi Miyazaki",
      "Yu Yokoi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.03093"
  },
  {
    "id": "arXiv:2105.04211",
    "title": "SigGPDE: Scaling Sparse Gaussian Processes on Sequential Data",
    "abstract": "Comments: Published at ICML 2021",
    "descriptor": "\nComments: Published at ICML 2021\n",
    "authors": [
      "Maud Lemercier",
      "Cristopher Salvi",
      "Thomas Cass",
      "Edwin V. Bonilla",
      "Theodoros Damoulas",
      "Terry Lyons"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04211"
  },
  {
    "id": "arXiv:2105.06718",
    "title": "Modeling the interplay between epidemics and regional socio-economics",
    "abstract": "Comments: 13 pages, 6 figures. Submitted to Physica A: Statistical Mechanics and Its Applications",
    "descriptor": "\nComments: 13 pages, 6 figures. Submitted to Physica A: Statistical Mechanics and Its Applications\n",
    "authors": [
      "Jan E. Snellman",
      "Rafael A. Barrio",
      "Kimmo K. Kaski",
      "Maarit J. K\u00e4pyl\u00e4"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2105.06718"
  },
  {
    "id": "arXiv:2105.08318",
    "title": "Zero-Shot Recommender Systems",
    "abstract": "Zero-Shot Recommender Systems",
    "descriptor": "",
    "authors": [
      "Hao Ding",
      "Yifei Ma",
      "Anoop Deoras",
      "Yuyang Wang",
      "Hao Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.08318"
  },
  {
    "id": "arXiv:2105.11754",
    "title": "ScalaBFS: A Scalable BFS Accelerator on HBM-Enhanced FPGAs",
    "abstract": "ScalaBFS: A Scalable BFS Accelerator on HBM-Enhanced FPGAs",
    "descriptor": "",
    "authors": [
      "Kexin Li",
      "Chenhao Liu",
      "Zhiyuan Shao",
      "Zeke Wang",
      "Minkang Wu",
      "Jiajie Chen",
      "Xiaofei Liao",
      "Hai Jin"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2105.11754"
  },
  {
    "id": "arXiv:2105.12667",
    "title": "Prosodic segmentation for parsing spoken dialogue",
    "abstract": "Comments: This paper has been retracted -- do not cite. An error occurred in the preprocessing of the pitch and intensity features that this model used. This error means that it can no longer be concluded that prosody is as helpful for finding sentence boundaries and parsing as asserted in this paper",
    "descriptor": "\nComments: This paper has been retracted -- do not cite. An error occurred in the preprocessing of the pitch and intensity features that this model used. This error means that it can no longer be concluded that prosody is as helpful for finding sentence boundaries and parsing as asserted in this paper\n",
    "authors": [
      "Elizabeth Nielsen",
      "Mark Steedman",
      "Sharon Goldwater"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.12667"
  },
  {
    "id": "arXiv:2105.14483",
    "title": "Computation of Eigenvalues for Nonlocal Models by Spectral Methods",
    "abstract": "Computation of Eigenvalues for Nonlocal Models by Spectral Methods",
    "descriptor": "",
    "authors": [
      "Luciano Lopez",
      "Sabrina Francesca Pellegrino"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14483"
  },
  {
    "id": "arXiv:2106.01548",
    "title": "When Vision Transformers Outperform ResNets without Pre-training or  Strong Data Augmentations",
    "abstract": "Comments: Release model checkpoints, add analysis for SAM vs. augmentations including landscapes and model properties",
    "descriptor": "\nComments: Release model checkpoints, add analysis for SAM vs. augmentations including landscapes and model properties\n",
    "authors": [
      "Xiangning Chen",
      "Cho-Jui Hsieh",
      "Boqing Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01548"
  },
  {
    "id": "arXiv:2106.02888",
    "title": "Bandwidth-based Step-Sizes for Non-Convex Stochastic Optimization",
    "abstract": "Bandwidth-based Step-Sizes for Non-Convex Stochastic Optimization",
    "descriptor": "",
    "authors": [
      "Xiaoyu Wang",
      "Mikael Johansson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.02888"
  },
  {
    "id": "arXiv:2106.05707",
    "title": "FEVEROUS: Fact Extraction and VERification Over Unstructured and  Structured information",
    "abstract": "Comments: Accepted at NeurIPS 2021 Datasets and Benchmarks Track",
    "descriptor": "\nComments: Accepted at NeurIPS 2021 Datasets and Benchmarks Track\n",
    "authors": [
      "Rami Aly",
      "Zhijiang Guo",
      "Michael Schlichtkrull",
      "James Thorne",
      "Andreas Vlachos",
      "Christos Christodoulopoulos",
      "Oana Cocarascu",
      "Arpit Mittal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.05707"
  },
  {
    "id": "arXiv:2106.07250",
    "title": "Unified Interpretation of Softmax Cross-Entropy and Negative Sampling:  With Case Study for Knowledge Graph Embedding",
    "abstract": "Comments: Accepted at ACL-IJCNLP 2021",
    "descriptor": "\nComments: Accepted at ACL-IJCNLP 2021\n",
    "authors": [
      "Hidetaka Kamigaito",
      "Katsuhiko Hayashi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07250"
  },
  {
    "id": "arXiv:2106.07306",
    "title": "Constraining Linear-chain CRFs to Regular Languages",
    "abstract": "Constraining Linear-chain CRFs to Regular Languages",
    "descriptor": "",
    "authors": [
      "Sean Papay",
      "Roman Klinger",
      "Sebastian Pad\u00f3"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.07306"
  },
  {
    "id": "arXiv:2106.07630",
    "title": "Hierarchically Regularized Deep Forecasting",
    "abstract": "Hierarchically Regularized Deep Forecasting",
    "descriptor": "",
    "authors": [
      "Biswajit Paria",
      "Rajat Sen",
      "Amr Ahmed",
      "Abhimanyu Das"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07630"
  },
  {
    "id": "arXiv:2106.07976",
    "title": "Federated Learning for Internet of Things: A Federated Learning  Framework for On-device Anomaly Data Detection",
    "abstract": "Federated Learning for Internet of Things: A Federated Learning  Framework for On-device Anomaly Data Detection",
    "descriptor": "",
    "authors": [
      "Tuo Zhang",
      "Chaoyang He",
      "Tianhao Ma",
      "Lei Gao",
      "Mark Ma",
      "Salman Avestimehr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.07976"
  },
  {
    "id": "arXiv:2106.09779",
    "title": "Private Federated Learning Without a Trusted Server: Optimal Algorithms  for Convex Losses",
    "abstract": "Private Federated Learning Without a Trusted Server: Optimal Algorithms  for Convex Losses",
    "descriptor": "",
    "authors": [
      "Andrew Lowy",
      "Meisam Razaviyayn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09779"
  },
  {
    "id": "arXiv:2106.10185",
    "title": "NoiseGrad: enhancing explanations by introducing stochasticity to model  weights",
    "abstract": "Comments: 19 pages, 16 figures",
    "descriptor": "\nComments: 19 pages, 16 figures\n",
    "authors": [
      "Kirill Bykov",
      "Anna Hedstr\u00f6m",
      "Shinichi Nakajima",
      "Marina M.-C. H\u00f6hne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10185"
  },
  {
    "id": "arXiv:2106.11420",
    "title": "Policy Smoothing for Provably Robust Reinforcement Learning",
    "abstract": "Policy Smoothing for Provably Robust Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Aounon Kumar",
      "Alexander Levine",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11420"
  },
  {
    "id": "arXiv:2106.12423",
    "title": "Alias-Free Generative Adversarial Networks",
    "abstract": "Alias-Free Generative Adversarial Networks",
    "descriptor": "",
    "authors": [
      "Tero Karras",
      "Miika Aittala",
      "Samuli Laine",
      "Erik H\u00e4rk\u00f6nen",
      "Janne Hellsten",
      "Jaakko Lehtinen",
      "Timo Aila"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.12423"
  },
  {
    "id": "arXiv:2106.12723",
    "title": "Meaningfully Explaining Model Mistakes Using Conceptual Counterfactuals",
    "abstract": "Meaningfully Explaining Model Mistakes Using Conceptual Counterfactuals",
    "descriptor": "",
    "authors": [
      "Abubakar Abid",
      "Mert Yuksekgonul",
      "James Zou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.12723"
  },
  {
    "id": "arXiv:2106.12936",
    "title": "Fundamental limits for learning hidden Markov model parameters",
    "abstract": "Comments: Includes a corrected lower bound proof, and more emphasis added on the entropy rate bounds we obtain",
    "descriptor": "\nComments: Includes a corrected lower bound proof, and more emphasis added on the entropy rate bounds we obtain\n",
    "authors": [
      "Kweku Abraham",
      "Zacharie Naulet",
      "Elisabeth Gassiat"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2106.12936"
  },
  {
    "id": "arXiv:2106.14816",
    "title": "Nash Social Welfare for 2-value Instances",
    "abstract": "Comments: 19 pages",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Hannaneh Akrami",
      "Bhaskar Ray Chaudhury",
      "Kurt Mehlhorn",
      "Golnoosh Shahkarami",
      "Quentin Vermande"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.14816"
  },
  {
    "id": "arXiv:2106.15788",
    "title": "Align Yourself: Self-supervised Pre-training for Fine-grained  Recognition via Saliency Alignment",
    "abstract": "Comments: The second version of CVSA. 10 pages, 4 figures",
    "descriptor": "\nComments: The second version of CVSA. 10 pages, 4 figures\n",
    "authors": [
      "Di Wu",
      "Siyuan Li",
      "Zelin Zang",
      "Kai Wang",
      "Lei Shang",
      "Baigui Sun",
      "Hao Li",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15788"
  },
  {
    "id": "arXiv:2106.15844",
    "title": "Bounded rationality for relaxing best response and mutual consistency:  The Quantal Hierarchy model of decision-making",
    "abstract": "Comments: 36 pages, 15 figures",
    "descriptor": "\nComments: 36 pages, 15 figures\n",
    "authors": [
      "Benjamin Patrick Evans",
      "Mikhail Prokopenko"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2106.15844"
  },
  {
    "id": "arXiv:2106.16031",
    "title": "ResViT: Residual vision transformers for multi-modal medical image  synthesis",
    "abstract": "ResViT: Residual vision transformers for multi-modal medical image  synthesis",
    "descriptor": "",
    "authors": [
      "Onat Dalmaz",
      "Mahmut Yurt",
      "Tolga \u00c7ukur"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16031"
  },
  {
    "id": "arXiv:2107.02474",
    "title": "Implicit Variational Conditional Sampling with Normalizing Flows",
    "abstract": "Implicit Variational Conditional Sampling with Normalizing Flows",
    "descriptor": "",
    "authors": [
      "Vincent Moens",
      "Aivar Sootla",
      "Haitham Bou Ammar",
      "Jun Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.02474"
  },
  {
    "id": "arXiv:2107.02561",
    "title": "Rethinking Positional Encoding",
    "abstract": "Rethinking Positional Encoding",
    "descriptor": "",
    "authors": [
      "Jianqiao Zheng",
      "Sameera Ramasinghe",
      "Simon Lucey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.02561"
  },
  {
    "id": "arXiv:2107.03200",
    "title": "The Geography of Open Source Software: Evidence from GitHub",
    "abstract": "The Geography of Open Source Software: Evidence from GitHub",
    "descriptor": "",
    "authors": [
      "Johannes Wachs",
      "Mariusz Nitecki",
      "William Schueller",
      "Axel Polleres"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.03200"
  },
  {
    "id": "arXiv:2107.04675",
    "title": "Target signatures for thin surfaces",
    "abstract": "Target signatures for thin surfaces",
    "descriptor": "",
    "authors": [
      "Fioralba Cakoni",
      "Peter Monk",
      "Yangwen Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.04675"
  },
  {
    "id": "arXiv:2107.08203",
    "title": "PI2: Generating Visual Analysis Interfaces From Queries",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Yiru Chen",
      "Eugene Wu"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2107.08203"
  },
  {
    "id": "arXiv:2107.08473",
    "title": "Elliptic Curve Fast Fourier Transform (ECFFT) Part I: Fast Polynomial  Algorithms over all Finite Fields",
    "abstract": "Elliptic Curve Fast Fourier Transform (ECFFT) Part I: Fast Polynomial  Algorithms over all Finite Fields",
    "descriptor": "",
    "authors": [
      "Eli Ben-Sasson",
      "Dan Carmon",
      "Swastik Kopparty",
      "David Levit"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.08473"
  },
  {
    "id": "arXiv:2107.09028",
    "title": "Structured Stochastic Gradient MCMC",
    "abstract": "Structured Stochastic Gradient MCMC",
    "descriptor": "",
    "authors": [
      "Antonios Alexos",
      "Alex Boyd",
      "Stephan Mandt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.09028"
  },
  {
    "id": "arXiv:2107.09574",
    "title": "Accelerating Edge Intelligence via Integrated Sensing and Communication",
    "abstract": "Comments: 7 Pages",
    "descriptor": "\nComments: 7 Pages\n",
    "authors": [
      "Tong Zhang",
      "Shuai Wang",
      "Guoliang Li",
      "Fan Liu",
      "Guangxu Zhu",
      "Rui Wang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.09574"
  },
  {
    "id": "arXiv:2107.10388",
    "title": "JS Fake Chorales: a Synthetic Dataset of Polyphonic Music with Human  Annotation",
    "abstract": "JS Fake Chorales: a Synthetic Dataset of Polyphonic Music with Human  Annotation",
    "descriptor": "",
    "authors": [
      "Omar Peracha"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.10388"
  },
  {
    "id": "arXiv:2107.11010",
    "title": "3D Brain Reconstruction by Hierarchical Shape-Perception Network from a  Single Incomplete Image",
    "abstract": "3D Brain Reconstruction by Hierarchical Shape-Perception Network from a  Single Incomplete Image",
    "descriptor": "",
    "authors": [
      "Bowen Hu",
      "Baiying Lei",
      "Shuqiang Wang",
      "Yong Liu",
      "Bingchuan Wang",
      "Min Gan",
      "Yanyan Shen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.11010"
  },
  {
    "id": "arXiv:2107.11076",
    "title": "A monotone scheme for nonlinear partial integro-differential equations  with the convergence rate of $\u03b1$-stable limit theorem under sublinear  expectation",
    "abstract": "Comments: 24 pages",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Mingshang Hu",
      "Lianzi Jiang",
      "Gechun Liang"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.11076"
  },
  {
    "id": "arXiv:2107.12695",
    "title": "Orientations and matrix function-based centralities in multiplex network  analysis of urban public transport",
    "abstract": "Orientations and matrix function-based centralities in multiplex network  analysis of urban public transport",
    "descriptor": "",
    "authors": [
      "Kai Bergermann",
      "Martin Stoll"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.12695"
  },
  {
    "id": "arXiv:2108.01750",
    "title": "Ellipsotopes: Combining Ellipsoids and Zonotopes for Reachability  Analysis and Fault Detection",
    "abstract": "Ellipsotopes: Combining Ellipsoids and Zonotopes for Reachability  Analysis and Fault Detection",
    "descriptor": "",
    "authors": [
      "Shreyas Kousik",
      "Adam Dai",
      "Grace Gao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.01750"
  },
  {
    "id": "arXiv:2108.02274",
    "title": "LEO: Learning Energy-based Models in Factor Graph Optimization",
    "abstract": "Comments: Accepted to Conference on Robot Learning (CoRL) 2021. 17 pages, 13 figures",
    "descriptor": "\nComments: Accepted to Conference on Robot Learning (CoRL) 2021. 17 pages, 13 figures\n",
    "authors": [
      "Paloma Sodhi",
      "Eric Dexheimer",
      "Mustafa Mukadam",
      "Stuart Anderson",
      "Michael Kaess"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.02274"
  },
  {
    "id": "arXiv:2108.03465",
    "title": "A k-mer Based Approach for SARS-CoV-2 Variant Identification",
    "abstract": "Comments: Accepted for Publication at \"International Symposium on Bioinformatics Research and Applications (ISBRA), 2021",
    "descriptor": "\nComments: Accepted for Publication at \"International Symposium on Bioinformatics Research and Applications (ISBRA), 2021\n",
    "authors": [
      "Sarwan Ali",
      "Bikram Sahoo",
      "Naimat Ullah",
      "Alexander Zelikovskiy",
      "Murray Patterson",
      "Imdadullah Khan"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.03465"
  },
  {
    "id": "arXiv:2108.04212",
    "title": "AutoVideo: An Automated Video Action Recognition System",
    "abstract": "Comments: this https URL",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Daochen Zha",
      "Zaid Pervaiz Bhat",
      "Yi-Wei Chen",
      "Yicheng Wang",
      "Sirui Ding",
      "Jiaben Chen",
      "Kwei-Herng Lai",
      "Anmoll Kumar Jain",
      "Mohammad Qazim Bhat",
      "Na Zou",
      "Xia Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2108.04212"
  },
  {
    "id": "arXiv:2108.07482",
    "title": "G-DetKD: Towards General Distillation Framework for Object Detectors via  Contrastive and Semantic-guided Feature Imitation",
    "abstract": "Comments: Accepted by ICCV2021",
    "descriptor": "\nComments: Accepted by ICCV2021\n",
    "authors": [
      "Lewei Yao",
      "Renjie Pi",
      "Hang Xu",
      "Wei Zhang",
      "Zhenguo Li",
      "Tong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.07482"
  },
  {
    "id": "arXiv:2108.08143",
    "title": "Effective and scalable clustering of SARS-CoV-2 sequences",
    "abstract": "Comments: To Appear in: International Conference on Big Data Research (ICBDR)",
    "descriptor": "\nComments: To Appear in: International Conference on Big Data Research (ICBDR)\n",
    "authors": [
      "Sarwan Ali",
      "Tamkanat-E-Ali",
      "Muhammad Asad Khan",
      "Imdadullah Khan",
      "Murray Patterson"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.08143"
  },
  {
    "id": "arXiv:2108.09876",
    "title": "On Quantifying Literals in Boolean Logic and Its Applications to  Explainable AI",
    "abstract": "Comments: Published in the Journal of Artificial Intelligence Research (JAIR), volume 72, 2021",
    "descriptor": "\nComments: Published in the Journal of Artificial Intelligence Research (JAIR), volume 72, 2021\n",
    "authors": [
      "Adnan Darwiche",
      "Pierre Marquis"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2108.09876"
  },
  {
    "id": "arXiv:2108.13097",
    "title": "Deep kernel machines and fast solvers for deep kernel machines",
    "abstract": "Deep kernel machines and fast solvers for deep kernel machines",
    "descriptor": "",
    "authors": [
      "Laurence Aitchison"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13097"
  },
  {
    "id": "arXiv:2108.13465",
    "title": "Full-Cycle Energy Consumption Benchmark for Low-Carbon Computer Vision",
    "abstract": "Comments: ArXiv Preprint",
    "descriptor": "\nComments: ArXiv Preprint\n",
    "authors": [
      "Bo Li",
      "Xinyang Jiang",
      "Donglin Bai",
      "Yuge Zhang",
      "Ningxin Zheng",
      "Xuanyi Dong",
      "Lu Liu",
      "Yuqing Yang",
      "Dongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13465"
  },
  {
    "id": "arXiv:2108.13714",
    "title": "Competing control scenarios in probabilistic SIR epidemics on  social-contact networks",
    "abstract": "Comments: preprint submitted to journal \\ competing control scenarios",
    "descriptor": "\nComments: preprint submitted to journal \\ competing control scenarios\n",
    "authors": [
      "Jan B. Broekaert",
      "Davide La Torre",
      "Faizal Hafiz"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2108.13714"
  },
  {
    "id": "arXiv:2109.00451",
    "title": "Constructive approximation on graded meshes for the integral fractional  Laplacian",
    "abstract": "Constructive approximation on graded meshes for the integral fractional  Laplacian",
    "descriptor": "",
    "authors": [
      "Juan Pablo Borthagaray",
      "Ricardo H. Nochetto"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2109.00451"
  },
  {
    "id": "arXiv:2109.01494",
    "title": "Computing Graph Descriptors on Edge Streams",
    "abstract": "Comments: Extension of work accepted to PAKDD 2020",
    "descriptor": "\nComments: Extension of work accepted to PAKDD 2020\n",
    "authors": [
      "Zohair Raza Hassan",
      "Imdadullah Khan",
      "Mudassir Shabbir",
      "Waseem Abbas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.01494"
  },
  {
    "id": "arXiv:2109.01951",
    "title": "FewshotQA: A simple framework for few-shot learning of question  answering tasks using pre-trained text-to-text models",
    "abstract": "Comments: Accepted to EMNLP 2021 Main Conference",
    "descriptor": "\nComments: Accepted to EMNLP 2021 Main Conference\n",
    "authors": [
      "Rakesh Chada",
      "Pradeep Natarajan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.01951"
  },
  {
    "id": "arXiv:2109.02818",
    "title": "List-decodable Codes and Covering Codes",
    "abstract": "Comments: 41 pages, extended to other metrics, a generalized Singleton upper bound for average-radius list-decodable codes added, McEliece-Rodemich-Rumsey-Welch bound compared",
    "descriptor": "\nComments: 41 pages, extended to other metrics, a generalized Singleton upper bound for average-radius list-decodable codes added, McEliece-Rodemich-Rumsey-Welch bound compared\n",
    "authors": [
      "Hao Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.02818"
  },
  {
    "id": "arXiv:2109.03144",
    "title": "PP-OCRv2: Bag of Tricks for Ultra Lightweight OCR System",
    "abstract": "Comments: 8 pages, 9 figures, 5 tables",
    "descriptor": "\nComments: 8 pages, 9 figures, 5 tables\n",
    "authors": [
      "Yuning Du",
      "Chenxia Li",
      "Ruoyu Guo",
      "Cheng Cui",
      "Weiwei Liu",
      "Jun Zhou",
      "Bin Lu",
      "Yehua Yang",
      "Qiwen Liu",
      "Xiaoguang Hu",
      "Dianhai Yu",
      "Yanjun Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.03144"
  },
  {
    "id": "arXiv:2109.05675",
    "title": "Online Unsupervised Learning of Visual Representations and Categories",
    "abstract": "Comments: Technical report, 28 pages",
    "descriptor": "\nComments: Technical report, 28 pages\n",
    "authors": [
      "Mengye Ren",
      "Tyler R. Scott",
      "Michael L. Iuzzolino",
      "Michael C. Mozer",
      "Richard Zemel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.05675"
  },
  {
    "id": "arXiv:2109.06009",
    "title": "Entropy inequalities for random walks and permutations",
    "abstract": "Comments: 30 pages; v2: added determination of cases of equality; submitted to AIHP",
    "descriptor": "\nComments: 30 pages; v2: added determination of cases of equality; submitted to AIHP\n",
    "authors": [
      "Alexandre Bristiel",
      "Pietro Caputo"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2109.06009"
  },
  {
    "id": "arXiv:2109.06638",
    "title": "Learnable Discrete Wavelet Pooling (LDW-Pooling) For Convolutional  Networks",
    "abstract": "Learnable Discrete Wavelet Pooling (LDW-Pooling) For Convolutional  Networks",
    "descriptor": "",
    "authors": [
      "Bor-Shiun Wang",
      "Jun-Wei Hsieh",
      "Ming-Ching Chang",
      "Ping-Yang Chen",
      "Lipeng Ke",
      "Siwei Lyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2109.06638"
  },
  {
    "id": "arXiv:2109.06721",
    "title": "Linear block and convolutional MDS codes to required rate, distance and  type",
    "abstract": "Linear block and convolutional MDS codes to required rate, distance and  type",
    "descriptor": "",
    "authors": [
      "Ted Hurley"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.06721"
  },
  {
    "id": "arXiv:2109.06788",
    "title": "Computing Balanced Solutions for Large International Kidney Exchange  Schemes",
    "abstract": "Computing Balanced Solutions for Large International Kidney Exchange  Schemes",
    "descriptor": "",
    "authors": [
      "M\u00e1rton Benedek",
      "P\u00e9ter Bir\u00f3",
      "Walter Kern",
      "Dani\u00ebl Paulusma"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.06788"
  },
  {
    "id": "arXiv:2109.08139",
    "title": "Adversarial Attacks against Deep Learning Based Power Control in  Wireless Communications",
    "abstract": "Adversarial Attacks against Deep Learning Based Power Control in  Wireless Communications",
    "descriptor": "",
    "authors": [
      "Brian Kim",
      "Yi Shi",
      "Yalin E. Sagduyu",
      "Tugba Erpek",
      "Sennur Ulukus"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.08139"
  },
  {
    "id": "arXiv:2109.09444",
    "title": "When Do Extended Physics-Informed Neural Networks (XPINNs) Improve  Generalization?",
    "abstract": "Comments: 32 pages, 11 figures",
    "descriptor": "\nComments: 32 pages, 11 figures\n",
    "authors": [
      "Zheyuan Hu",
      "Ameya D. Jagtap",
      "George Em Karniadakis",
      "Kenji Kawaguchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.09444"
  },
  {
    "id": "arXiv:2109.09740",
    "title": "Neural Distance Embeddings for Biological Sequences",
    "abstract": "Comments: Advances in Neural Information Processing Systems (NeurIPS 2021)",
    "descriptor": "\nComments: Advances in Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Gabriele Corso",
      "Rex Ying",
      "Michal P\u00e1ndy",
      "Petar Veli\u010dkovi\u0107",
      "Jure Leskovec",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.09740"
  },
  {
    "id": "arXiv:2109.10756",
    "title": "Constrained multi-agent ergodic area surveying control based on finite  element approximation of the potential field",
    "abstract": "Comments: 17 pages, LaTeX; references added",
    "descriptor": "\nComments: 17 pages, LaTeX; references added\n",
    "authors": [
      "Stefan Ivi\u0107",
      "Ante Sikirica",
      "Bojan Crnkovi\u0107"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.10756"
  },
  {
    "id": "arXiv:2109.12813",
    "title": "An optimised deep spiking neural network architecture without gradients",
    "abstract": "Comments: 18 pages, 6 figures",
    "descriptor": "\nComments: 18 pages, 6 figures\n",
    "authors": [
      "Yeshwanth Bethi",
      "Ying Xu",
      "Gregory Cohen",
      "Andre van Schaik",
      "Saeed Afshar"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.12813"
  },
  {
    "id": "arXiv:2109.13090",
    "title": "Oscillatory Fourier Neural Network: A Compact and Efficient Architecture  for Sequential Processing",
    "abstract": "Oscillatory Fourier Neural Network: A Compact and Efficient Architecture  for Sequential Processing",
    "descriptor": "",
    "authors": [
      "Bing Han",
      "Cheng Wang",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.13090"
  },
  {
    "id": "arXiv:2109.13792",
    "title": "Cluster Synchronization of Networks via a Canonical Transformation for  Simultaneous Block Diagonalization of Matrices",
    "abstract": "Cluster Synchronization of Networks via a Canonical Transformation for  Simultaneous Block Diagonalization of Matrices",
    "descriptor": "",
    "authors": [
      "Shirin Panahi",
      "Isaac Klickstein",
      "Francesco Sorrentino"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.13792"
  },
  {
    "id": "arXiv:2109.13842",
    "title": "Cross-layer Design for Real-Time Grid Operation: Estimation,  Optimization and Power Flow",
    "abstract": "Cross-layer Design for Real-Time Grid Operation: Estimation,  Optimization and Power Flow",
    "descriptor": "",
    "authors": [
      "Miguel Picallo",
      "Dominic Liao-McPherson",
      "Saverio Bolognani",
      "Florian D\u00f6rfler"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.13842"
  },
  {
    "id": "arXiv:2109.14180",
    "title": "Efficient Reinforced Feature Selection via Early Stopping Traverse  Strategy",
    "abstract": "Comments: ICDM 2021",
    "descriptor": "\nComments: ICDM 2021\n",
    "authors": [
      "Kunpeng Liu",
      "Pengfei Wang",
      "Dongjie Wang",
      "Wan Du",
      "Dapeng Oliver Wu",
      "Yanjie Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.14180"
  },
  {
    "id": "arXiv:2109.14764",
    "title": "Gaps, Ambiguity, and Establishing Complexity-Class Containments via  Iterative Constant-Setting",
    "abstract": "Gaps, Ambiguity, and Establishing Complexity-Class Containments via  Iterative Constant-Setting",
    "descriptor": "",
    "authors": [
      "Lane A. Hemaspaandra",
      "Mandar Juvekar",
      "Arian Nadjimzadah",
      "Patrick A. Phillips"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2109.14764"
  },
  {
    "id": "arXiv:2109.14805",
    "title": "Unsupervised Landmark Detection Based Spatiotemporal Motion Estimation  for 4D Dynamic Medical Images",
    "abstract": "Comments: submitted to IEEE Transactions on Cybernetics",
    "descriptor": "\nComments: submitted to IEEE Transactions on Cybernetics\n",
    "authors": [
      "Yuyu Guo",
      "Lei Bi",
      "Dongming Wei",
      "Liyun Chen",
      "Zhengbin Zhu",
      "Dagan Feng",
      "Ruiyan Zhang",
      "Qian Wang",
      "Jinman Kim"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.14805"
  },
  {
    "id": "arXiv:2110.00061",
    "title": "PubTables-1M: Towards a universal dataset and metrics for training and  evaluating table extraction models",
    "abstract": "PubTables-1M: Towards a universal dataset and metrics for training and  evaluating table extraction models",
    "descriptor": "",
    "authors": [
      "Brandon Smock",
      "Rohith Pesala",
      "Robin Abraham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.00061"
  },
  {
    "id": "arXiv:2110.00101",
    "title": "Shaping mmWave Wireless Channel via Multi-Beam Design using  Reconfigurable Intelligent Surfaces",
    "abstract": "Comments: Accepted at IEEE Globecom 2021",
    "descriptor": "\nComments: Accepted at IEEE Globecom 2021\n",
    "authors": [
      "Nariman Torkzaban",
      "Mohammad A. Amir Khojastepour"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2110.00101"
  },
  {
    "id": "arXiv:2110.00273",
    "title": "From SLAM to Situational Awareness: Challenges and Survey",
    "abstract": "Comments: 15 pages, 8 figures",
    "descriptor": "\nComments: 15 pages, 8 figures\n",
    "authors": [
      "Hriday Bavle",
      "Jose Luis Sanchez-Lopez",
      "Eduardo F. Schmidt",
      "Holger Voos"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.00273"
  },
  {
    "id": "arXiv:2110.00623",
    "title": "Calibrated Adversarial Training",
    "abstract": "Comments: ACML 2021 accepted,24 pages",
    "descriptor": "\nComments: ACML 2021 accepted,24 pages\n",
    "authors": [
      "Tianjin Huang",
      "Vlado Menkovski",
      "Yulong Pei",
      "Mykola Pechenizkiy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.00623"
  },
  {
    "id": "arXiv:2110.00745",
    "title": "End-to-End Complex-Valued Multidilated Convolutional Neural Network for  Joint Acoustic Echo Cancellation and Noise Suppression",
    "abstract": "Comments: Submitted to the 2022 International Conference on Acoustics, Speech, & Signal Processing (ICASSP)",
    "descriptor": "\nComments: Submitted to the 2022 International Conference on Acoustics, Speech, & Signal Processing (ICASSP)\n",
    "authors": [
      "Karn N. Watcharasupat",
      "Thi Ngoc Tho Nguyen",
      "Woon-Seng Gan",
      "Shengkui Zhao",
      "Bin Ma"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.00745"
  },
  {
    "id": "arXiv:2110.00954",
    "title": "Adaptive Real-Time Grid Operation via Online Feedback Optimization with  Sensitivity Estimation",
    "abstract": "Adaptive Real-Time Grid Operation via Online Feedback Optimization with  Sensitivity Estimation",
    "descriptor": "",
    "authors": [
      "Miguel Picallo",
      "Lukas Ortmann",
      "Saverio Bolognani",
      "Florian D\u00f6rfler"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.00954"
  },
  {
    "id": "arXiv:2110.01077",
    "title": "Multi-task Voice Activated Framework using Self-supervised Learning",
    "abstract": "Comments: speaker verification, keyword spotting, wav2vec, self-supervised, multi-task learning",
    "descriptor": "\nComments: speaker verification, keyword spotting, wav2vec, self-supervised, multi-task learning\n",
    "authors": [
      "Shehzeen Hussain",
      "Van Nguyen",
      "Shuhua Zhang",
      "Erik Visser"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.01077"
  },
  {
    "id": "arXiv:2110.01212",
    "title": "Inducing Equilibria via Incentives: Simultaneous Design-and-Play Finds  Global Optima",
    "abstract": "Comments: 31 pages; typos corrected",
    "descriptor": "\nComments: 31 pages; typos corrected\n",
    "authors": [
      "Boyi Liu",
      "Jiayang Li",
      "Zhuoran Yang",
      "Hoi-To Wai",
      "Mingyi Hong",
      "Yu Marco Nie",
      "Zhaoran Wang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.01212"
  },
  {
    "id": "arXiv:2110.01654",
    "title": "Improved architectures and training algorithms for deep operator  networks",
    "abstract": "Comments: 40 pages, 27 figures, 11 tables",
    "descriptor": "\nComments: 40 pages, 27 figures, 11 tables\n",
    "authors": [
      "Sifan Wang",
      "Hanwen Wang",
      "Paris Perdikaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.01654"
  },
  {
    "id": "arXiv:2110.02398",
    "title": "Quasi-Newton policy gradient algorithms",
    "abstract": "Comments: 18 pages, 10 figures",
    "descriptor": "\nComments: 18 pages, 10 figures\n",
    "authors": [
      "Haoya Li",
      "Samarth Gupta",
      "Hsiangfu Yu",
      "Lexing Ying",
      "Inderjit Dhillon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.02398"
  },
  {
    "id": "arXiv:2110.02548",
    "title": "Data-Driven Substructuring Technique for Pseudo-Dynamic Hybrid  Simulation of Steel Braced Frames",
    "abstract": "Comments: 8 pages, 4 figures, Added reference for Section 3.2 (in V.2), Submitted to Springer Proceedings of STESSA 2021",
    "descriptor": "\nComments: 8 pages, 4 figures, Added reference for Section 3.2 (in V.2), Submitted to Springer Proceedings of STESSA 2021\n",
    "authors": [
      "Fardad Mokhtari",
      "Ali Imanpour"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2110.02548"
  },
  {
    "id": "arXiv:2110.02627",
    "title": "MovingFashion: a Benchmark for the Video-to-Shop Challenge",
    "abstract": "Comments: Accepted at WACV 2022",
    "descriptor": "\nComments: Accepted at WACV 2022\n",
    "authors": [
      "Marco Godi",
      "Christian Joppi",
      "Geri Skenderi",
      "Marco Cristani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02627"
  },
  {
    "id": "arXiv:2110.02801",
    "title": "Besov regularity for the Dirichlet integral fractional Laplacian in  Lipschitz domains",
    "abstract": "Besov regularity for the Dirichlet integral fractional Laplacian in  Lipschitz domains",
    "descriptor": "",
    "authors": [
      "Juan Pablo Borthagaray",
      "Ricardo H. Nochetto"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.02801"
  },
  {
    "id": "arXiv:2110.02869",
    "title": "Sequence-to-Sequence Lexical Normalization with Multilingual  Transformers",
    "abstract": "Comments: In Proceedings of the 7th Workshop on Noisy User-generated Text (WNUT 2021), EMNLP 2021",
    "descriptor": "\nComments: In Proceedings of the 7th Workshop on Noisy User-generated Text (WNUT 2021), EMNLP 2021\n",
    "authors": [
      "Ana-Maria Bucur",
      "Adrian Cosma",
      "Liviu P. Dinu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.02869"
  },
  {
    "id": "arXiv:2110.03031",
    "title": "RieszNet and ForestRiesz: Automatic Debiased Machine Learning with  Neural Nets and Random Forests",
    "abstract": "RieszNet and ForestRiesz: Automatic Debiased Machine Learning with  Neural Nets and Random Forests",
    "descriptor": "",
    "authors": [
      "Victor Chernozhukov",
      "Whitney K. Newey",
      "Victor Quintas-Martinez",
      "Vasilis Syrgkanis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.03031"
  },
  {
    "id": "arXiv:2110.03157",
    "title": "What Should Future Wireless Network Architectures Be?",
    "abstract": "Comments: 23 pages, 4 figures. This paper only proposes a question on future wireless network architecture designs. To avoid misunderstanding, we replace the term '6G' in the previous version by 'future wireless communication networks' in this updated version",
    "descriptor": "\nComments: 23 pages, 4 figures. This paper only proposes a question on future wireless network architecture designs. To avoid misunderstanding, we replace the term '6G' in the previous version by 'future wireless communication networks' in this updated version\n",
    "authors": [
      "Lu Yang",
      "Ping Li",
      "Miaomiao Dong",
      "Bo Bai",
      "Dmitry Zaporozhets",
      "Xiang Chen",
      "Wei Han",
      "Baochun Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.03157"
  },
  {
    "id": "arXiv:2110.03266",
    "title": "Lagrangian Neural Network with Differentiable Symmetries and Relational  Inductive Bias",
    "abstract": "Lagrangian Neural Network with Differentiable Symmetries and Relational  Inductive Bias",
    "descriptor": "",
    "authors": [
      "Ravinder Bhattoo",
      "Sayan Ranu",
      "N. M. Anoop Krishnan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.03266"
  },
  {
    "id": "arXiv:2110.03370",
    "title": "WenetSpeech: A 10000+ Hours Multi-domain Mandarin Corpus for Speech  Recognition",
    "abstract": "WenetSpeech: A 10000+ Hours Multi-domain Mandarin Corpus for Speech  Recognition",
    "descriptor": "",
    "authors": [
      "Binbin Zhang",
      "Hang Lv",
      "Pengcheng Guo",
      "Qijie Shao",
      "Chao Yang",
      "Lei Xie",
      "Xin Xu",
      "Hui Bu",
      "Xiaoyu Chen",
      "Chenchen Zeng",
      "Di Wu",
      "Zhendong Peng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.03370"
  },
  {
    "id": "arXiv:2110.03605",
    "title": "One Thing to Fool them All: Generating Interpretable, Universal, and  Physically-Realizable Adversarial Features",
    "abstract": "Comments: Code is available at: this https URL",
    "descriptor": "\nComments: Code is available at: this https URL\n",
    "authors": [
      "Stephen Casper",
      "Max Nadeau",
      "Gabriel Kreiman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03605"
  },
  {
    "id": "arXiv:2110.03649",
    "title": "Neural Networks, Inside Out: Solving for Inputs Given Parameters (A  Preliminary Investigation)",
    "abstract": "Neural Networks, Inside Out: Solving for Inputs Given Parameters (A  Preliminary Investigation)",
    "descriptor": "",
    "authors": [
      "Mohammad Sadeq Dousti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.03649"
  },
  {
    "id": "arXiv:2110.03706",
    "title": "SVG-Net: An SVG-based Trajectory Prediction Model",
    "abstract": "SVG-Net: An SVG-based Trajectory Prediction Model",
    "descriptor": "",
    "authors": [
      "Mohammadhossein Bahari",
      "Vahid Zehtab",
      "Sadegh Khorasani",
      "Sana Ayromlou",
      "Saeed Saadatnejad",
      "Alexandre Alahi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03706"
  },
  {
    "id": "arXiv:2110.03915",
    "title": "Optimal QoS-Aware Network Slicing for Service-Oriented Networks with  Flexible Routing",
    "abstract": "Comments: 5 pages, 2 figures, submitted for possible publication",
    "descriptor": "\nComments: 5 pages, 2 figures, submitted for possible publication\n",
    "authors": [
      "Wei-Kun Chen",
      "Ya-Feng Liu",
      "Yu-Hong Dai",
      "Zhi-Quan Luo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.03915"
  },
  {
    "id": "arXiv:2110.04260",
    "title": "Taming Sparsely Activated Transformer with Stochastic Experts",
    "abstract": "Taming Sparsely Activated Transformer with Stochastic Experts",
    "descriptor": "",
    "authors": [
      "Simiao Zuo",
      "Xiaodong Liu",
      "Jian Jiao",
      "Young Jin Kim",
      "Hany Hassan",
      "Ruofei Zhang",
      "Tuo Zhao",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04260"
  },
  {
    "id": "arXiv:2110.04265",
    "title": "A study of the robustness of raw waveform based speaker embeddings under  mismatched conditions",
    "abstract": "A study of the robustness of raw waveform based speaker embeddings under  mismatched conditions",
    "descriptor": "",
    "authors": [
      "Ge Zhu",
      "Frank Cwitkowitz",
      "Zhiyao Duan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04265"
  },
  {
    "id": "arXiv:2110.04385",
    "title": "Individualized Hear-through For Acoustic Transparency Using PCA-Based  Sound Pressure Estimation At The Eardrum",
    "abstract": "Comments: 5 pages, 5 figures, submitted to ICASSP 2022",
    "descriptor": "\nComments: 5 pages, 5 figures, submitted to ICASSP 2022\n",
    "authors": [
      "Wenyu Jin",
      "Tim Schoof",
      "Henning Schepker"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04385"
  },
  {
    "id": "arXiv:2110.04507",
    "title": "TiKick: Toward Playing Multi-agent Football Full Games from Single-agent  Demonstrations",
    "abstract": "TiKick: Toward Playing Multi-agent Football Full Games from Single-agent  Demonstrations",
    "descriptor": "",
    "authors": [
      "Shiyu Huang",
      "Wenze Chen",
      "Longfei Zhang",
      "Ziyang Li",
      "Fengming Zhu",
      "Deheng Ye",
      "Ting Chen",
      "Jun Zhu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04507"
  },
  {
    "id": "arXiv:2110.04651",
    "title": "Nonlocal Games, Compression Theorems, and the Arithmetical Hierarchy",
    "abstract": "Nonlocal Games, Compression Theorems, and the Arithmetical Hierarchy",
    "descriptor": "",
    "authors": [
      "Hamoon Mousavi",
      "Seyed Sajjad Nezhadi",
      "Henry Yuen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Operator Algebras (math.OA)"
    ],
    "url": "https://arxiv.org/abs/2110.04651"
  },
  {
    "id": "arXiv:2110.04659",
    "title": "Exploring constraints on CycleGAN-based CBCT enhancement for adaptive  radiotherapy",
    "abstract": "Exploring constraints on CycleGAN-based CBCT enhancement for adaptive  radiotherapy",
    "descriptor": "",
    "authors": [
      "Suraj Pai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04659"
  },
  {
    "id": "arXiv:2110.04708",
    "title": "Fine-grained Identity Preserving Landmark Synthesis for Face Reenactment",
    "abstract": "Fine-grained Identity Preserving Landmark Synthesis for Face Reenactment",
    "descriptor": "",
    "authors": [
      "Haichao Zhang",
      "Youcheng Ben",
      "Weixi Zhang",
      "Tao Chen",
      "Gang Yu",
      "Bin Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04708"
  },
  {
    "id": "arXiv:2110.04722",
    "title": "Transformer-based Dual Relation Graph for Multi-label Image Recognition",
    "abstract": "Comments: 10 pages, 5 figures. Published in ICCV 2021",
    "descriptor": "\nComments: 10 pages, 5 figures. Published in ICCV 2021\n",
    "authors": [
      "Jiawei Zhao",
      "Ke Yan",
      "Yifan Zhao",
      "Xiaowei Guo",
      "Feiyue Huang",
      "Jia Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04722"
  },
  {
    "id": "arXiv:2110.04725",
    "title": "Yuan 1.0: Large-Scale Pre-trained Language Model in Zero-Shot and  Few-Shot Learning",
    "abstract": "Yuan 1.0: Large-Scale Pre-trained Language Model in Zero-Shot and  Few-Shot Learning",
    "descriptor": "",
    "authors": [
      "Shaohua Wu",
      "Xudong Zhao",
      "Tong Yu",
      "Rongguo Zhang",
      "Chong Shen",
      "Hongli Liu",
      "Feng Li",
      "Hong Zhu",
      "Jiangang Luo",
      "Liang Xu",
      "Xuanwei Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04725"
  },
  {
    "id": "arXiv:2110.04931",
    "title": "BEV-Net: Assessing Social Distancing Compliance by Joint People  Localization and Geometric Reasoning",
    "abstract": "Comments: Published as a conference paper at International Conference on Computer Vision, 2021",
    "descriptor": "\nComments: Published as a conference paper at International Conference on Computer Vision, 2021\n",
    "authors": [
      "Zhirui Dai",
      "Yuepeng Jiang",
      "Yi Li",
      "Bo Liu",
      "Antoni B. Chan",
      "Nuno Vasconcelos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04931"
  },
  {
    "id": "arXiv:2110.04972",
    "title": "Kernel Learning For Sound Field Estimation With L1 and L2  Regularizations",
    "abstract": "Comments: Accepted to IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA) 2021",
    "descriptor": "\nComments: Accepted to IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA) 2021\n",
    "authors": [
      "Ryosuke Horiuchi",
      "Shoichi Koyama",
      "Juliano G. C. Ribeiro",
      "Natsuki Ueno",
      "Hiroshi Saruwatari"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.04972"
  },
  {
    "id": "arXiv:2110.04984",
    "title": "Advances in Multi-turn Dialogue Comprehension: A Survey",
    "abstract": "Comments: Upload as new by mistake. Please see the updated version in the existing one: arXiv:2103.03125",
    "descriptor": "\nComments: Upload as new by mistake. Please see the updated version in the existing one: arXiv:2103.03125\n",
    "authors": [
      "Zhuosheng Zhang",
      "Hai Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.04984"
  },
  {
    "id": "arXiv:2110.05006",
    "title": "Pre-trained Language Models in Biomedical Domain: A Systematic Survey",
    "abstract": "Comments: 46 pages",
    "descriptor": "\nComments: 46 pages\n",
    "authors": [
      "Benyou Wang",
      "Qianqian Xie",
      "Jiahuan Pei",
      "Prayag Tiwari",
      "Zhao Li",
      "Jie fu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05006"
  },
  {
    "id": "arXiv:2110.05020",
    "title": "MELONS: generating melody with long-term structure using transformers  and structure graph",
    "abstract": "MELONS: generating melody with long-term structure using transformers  and structure graph",
    "descriptor": "",
    "authors": [
      "Yi Zou",
      "Pei Zou",
      "Yi Zhao",
      "Kaixiang Zhang",
      "Ran Zhang",
      "Xiaorui Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05020"
  },
  {
    "id": "arXiv:2110.05033",
    "title": "Pitch Preservation In Singing Voice Synthesis",
    "abstract": "Comments: 5 pages, 3 figures",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Shujun Liu",
      "Hai Zhu",
      "Kun Wang",
      "Huajun Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05033"
  },
  {
    "id": "arXiv:2110.05042",
    "title": "Multi-query multi-head attention pooling and Inter-topK penalty for  speaker verification",
    "abstract": "Comments: submitted to ICASSP 2022",
    "descriptor": "\nComments: submitted to ICASSP 2022\n",
    "authors": [
      "Miao Zhao",
      "Yufeng Ma",
      "Yiwei Ding",
      "Yu Zheng",
      "Min Liu",
      "Minqiang Xu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05042"
  },
  {
    "id": "arXiv:2110.05057",
    "title": "Can Stochastic Gradient Langevin Dynamics Provide Differential Privacy  for Deep Learning?",
    "abstract": "Can Stochastic Gradient Langevin Dynamics Provide Differential Privacy  for Deep Learning?",
    "descriptor": "",
    "authors": [
      "Guy Heller",
      "Ethan Fetaya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.05057"
  },
  {
    "id": "arXiv:2110.05075",
    "title": "DANIEL: A Fast and Robust Consensus Maximization Method for Point Cloud  Registration with High Outlier Ratios",
    "abstract": "DANIEL: A Fast and Robust Consensus Maximization Method for Point Cloud  Registration with High Outlier Ratios",
    "descriptor": "",
    "authors": [
      "Lei Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.05075"
  },
  {
    "id": "arXiv:2110.05076",
    "title": "A Closer Look at Prototype Classifier for Few-shot Image Classification",
    "abstract": "Comments: 10 pages with 6 appendix section",
    "descriptor": "\nComments: 10 pages with 6 appendix section\n",
    "authors": [
      "Mingcheng Hou",
      "Issei Sato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05076"
  },
  {
    "id": "arXiv:2110.05146",
    "title": "ViSeRet: A simple yet effective approach to moment retrieval via  fine-grained video segmentation",
    "abstract": "ViSeRet: A simple yet effective approach to moment retrieval via  fine-grained video segmentation",
    "descriptor": "",
    "authors": [
      "Aiden Seungjoon Lee",
      "Hanseok Oh",
      "Minjoon Seo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05146"
  },
  {
    "id": "arXiv:2110.05177",
    "title": "Learning Division with Neural Arithmetic Logic Modules",
    "abstract": "Comments: 28 pages, 24 figures. New experiments included(Section 7 and Appendix G)",
    "descriptor": "\nComments: 28 pages, 24 figures. New experiments included(Section 7 and Appendix G)\n",
    "authors": [
      "Bhumika Mistry",
      "Katayoun Farrahi",
      "Jonathon Hare"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.05177"
  },
  {
    "id": "arXiv:2110.05188",
    "title": "A Theory of Tournament Representations",
    "abstract": "Comments: Fixed typos and minor edits to the proof of Theorem 9",
    "descriptor": "\nComments: Fixed typos and minor edits to the proof of Theorem 9\n",
    "authors": [
      "Arun Rajkumar",
      "Vishnu Veerathu",
      "Abdul Bakey Mir"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05188"
  },
  {
    "id": "arXiv:2110.05291",
    "title": "Graph Neural Network Guided Local Search for the Traveling Salesperson  Problem",
    "abstract": "Graph Neural Network Guided Local Search for the Traveling Salesperson  Problem",
    "descriptor": "",
    "authors": [
      "Benjamin Hudson",
      "Qingbiao Li",
      "Matthew Malencia",
      "Amanda Prorok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.05291"
  },
  {
    "id": "arXiv:2110.05335",
    "title": "From FPGAs to Obfuscated eASICs: Design and Security Trade-offs",
    "abstract": "Comments: The results for the paper are given on the following link: this https URL",
    "descriptor": "\nComments: The results for the paper are given on the following link: this https URL\n",
    "authors": [
      "Zain Ul Abideen",
      "Tiago Diadami Perez",
      "Samuel Pagliarini"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2110.05335"
  },
  {
    "id": "arXiv:2110.05352",
    "title": "All One Needs to Know about Metaverse: A Complete Survey on  Technological Singularity, Virtual Ecosystem, and Research Agenda",
    "abstract": "Comments: 68 pages",
    "descriptor": "\nComments: 68 pages\n",
    "authors": [
      "Lik-Hang Lee",
      "Tristan Braud",
      "Pengyuan Zhou",
      "Lin Wang",
      "Dianlei Xu",
      "Zijun Lin",
      "Abhishek Kumar",
      "Carlos Bermejo",
      "Pan Hui"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.05352"
  }
]
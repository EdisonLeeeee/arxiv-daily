[
  {
    "id": "arXiv:2110.11337",
    "title": "Learning Universal User Representations via Self-Supervised Lifelong  Behaviors Modeling",
    "abstract": "Universal user representation is an important research topic in industry, and\nis widely used in diverse downstream user analysis tasks, such as user\nprofiling and user preference prediction. With the rapid development of\nInternet service platforms, extremely long user behavior sequences have been\naccumulated. However, existing researches have little ability to model\nuniversal user representation based on lifelong sequences of user behavior\nsince registration. In this study, we propose a novel framework called Lifelong\nUser Representation Model (LURM) to tackle this challenge. Specifically, LURM\nconsists of two cascaded sub-models: (i) Bag of Interests (BoI) encodes user\nbehaviors in any time period into a sparse vector with super-high dimension\n(e.g.,105); (ii) Self-supervised Multi-anchor EncoderNetwork (SMEN) maps\nsequences of BoI features to multiple low-dimensional user representations by\ncontrastive learning. SMEN achieves almost lossless dimensionality reduction,\nbenefiting from a novel multi-anchor module which can learn different aspects\nof user preferences. Experiments on several benchmark datasets show that our\napproach outperforms state-of-the-art unsupervised representation methods in\ndownstream tasks",
    "descriptor": "\nComments: during peer review\n",
    "authors": [
      "Bei Yang",
      "Ke Liu",
      "Xiaoxiao Xu",
      "Renjun Xu",
      "Hong Liu",
      "Huan Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11337"
  },
  {
    "id": "arXiv:2110.11338",
    "title": "VLDeformer: Learning Visual-Semantic Embeddings by Vision-Language  Transformer Decomposing",
    "abstract": "Vision-language transformers (VL transformers) have shown impressive accuracy\nin cross-modal retrieval. However, most of the existing VL transformers use\nearly-interaction dataflow that computes a joint representation for the\ntext-image input. In the retrieval stage, such models need to infer on all the\nmatched text-image combinations, which causes high computing costs. The goal of\nthis paper is to decompose the early-interaction dataflow inside the\npre-trained VL transformer to achieve acceleration while maintaining its\noutstanding accuracy. To achieve this, we propose a novel Vision-language\nTransformer Decomposing (VLDeformer) to modify the VL transformer as an\nindividual encoder for a single image or text through contrastive learning,\nwhich accelerates retrieval speed by thousands of times. Meanwhile, we propose\nto compose bi-modal hard negatives for the contrastive learning objective,\nwhich enables the VLDeformer to maintain the outstanding accuracy of the\nbackbone VL transformer. Extensive experiments on COCO and Flickr30k datasets\ndemonstrate the superior performance of the proposed method. Considering both\neffectiveness and efficiency, VLDeformer provides a superior selection for\ncross-modal retrieval in the similar pre-training datascale.",
    "descriptor": "",
    "authors": [
      "Lisai Zhang",
      "Hongfa Wu",
      "Qingcai Chen",
      "Yimeng Deng",
      "Zhonghua Li",
      "Dejiang Kong",
      "Zhao Cao",
      "Joanna Siebert",
      "Yunpeng Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.11338"
  },
  {
    "id": "arXiv:2110.11342",
    "title": "ESOD:Edge-based Task Scheduling for Object Detection",
    "abstract": "Object Detection on the mobile system is a challenge in terms of everything.\nNowadays, many object detection models have been designed, and most of them\nconcentrate on precision. However, the computation burden of those models on\nmobile systems is unacceptable. Researchers have designed some lightweight\nnetworks for mobiles by sacrificing precision. We present a novel edge-based\ntask scheduling framework for object detection (termed as ESOD). In detail, we\ntrain a DNN model (termed as pre-model) to predict which object detection model\nto use for the coming task and offloads to which edge servers by physical\ncharacteristics of the image task (e.g., brightness, saturation). The results\nshow that ESOD can reduce latency and energy consumption by an average of\n22.13% and 29.60% and improve the mAP to 45.8(with 0.9 mAP better),\nrespectively, compared with the SOTA DETR model.",
    "descriptor": "\nComments: Accepted by The Ninth International Conference on Advanced Cloud and Big Data\n",
    "authors": [
      "Yihao Wang",
      "Ling Gao",
      "Jie Ren",
      "Rui Cao",
      "Hai Wang",
      "Jie Zheng",
      "Quanli Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11342"
  },
  {
    "id": "arXiv:2110.11346",
    "title": "Data-Driven Offline Optimization For Architecting Hardware Accelerators",
    "abstract": "Industry has gradually moved towards application-specific hardware\naccelerators in order to attain higher efficiency. While such a paradigm shift\nis already starting to show promising results, designers need to spend\nconsiderable manual effort and perform a large number of time-consuming\nsimulations to find accelerators that can accelerate multiple target\napplications while obeying design constraints. Moreover, such a\n\"simulation-driven\" approach must be re-run from scratch every time the set of\ntarget applications or design constraints change. An alternative paradigm is to\nuse a \"data-driven\", offline approach that utilizes logged simulation data, to\narchitect hardware accelerators, without needing any form of simulations. Such\nan approach not only alleviates the need to run time-consuming simulation, but\nalso enables data reuse and applies even when set of target applications\nchanges. In this paper, we develop such a data-driven offline optimization\nmethod for designing hardware accelerators, dubbed PRIME, that enjoys all of\nthese properties. Our approach learns a conservative, robust estimate of the\ndesired cost function, utilizes infeasible points, and optimizes the design\nagainst this estimate without any additional simulator queries during\noptimization. PRIME architects accelerators -- tailored towards both single and\nmultiple applications -- improving performance upon state-of-the-art\nsimulation-driven methods by about 1.54x and 1.20x, while considerably reducing\nthe required total simulation time by 93% and 99%, respectively. In addition,\nPRIME also architects effective accelerators for unseen applications in a\nzero-shot setting, outperforming simulation-based methods by 1.26x.",
    "descriptor": "\nComments: First two authors contributed equally\n",
    "authors": [
      "Aviral Kumar",
      "Amir Yazdanbakhsh",
      "Milad Hashemi",
      "Kevin Swersky",
      "Sergey Levine"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11346"
  },
  {
    "id": "arXiv:2110.11348",
    "title": "User Incentives for Blockchain-based Data Sharing Platforms",
    "abstract": "Data sharing is very important for accelerating scientific research, business\ninnovations, and for informing individuals. Yet, concerns over data privacy,\ncost, and lack of secure data-sharing solutions have prevented data owners from\nsharing data. To overcome these issues, several research works have proposed\nblockchain-based data-sharing solutions for their ability to add transparency\nand control to the data-sharing process. Yet, while models for decentralized\ndata sharing exist, how to incentivize these structures to enable data sharing\nat scale remains largely unexplored. In this paper, we propose incentive\nmechanisms for decentralized data-sharing platforms. We use smart contracts to\nautomate different payment options between data owners and data requesters. We\ndiscuss multiple cost pricing scenarios for data owners to monetize their data.\nMoreover, we simulate the incentive mechanisms on a blockchain-based\ndata-sharing platform. The evaluation of our simulation indicates that a cost\ncompensation model for the data owner can rapidly cover the cost of data\nsharing and balance the overall incentives for all the actors in the platform.",
    "descriptor": "",
    "authors": [
      "Vikas Jaiman",
      "Leonard Pernice",
      "Visara Urovi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.11348"
  },
  {
    "id": "arXiv:2110.11354",
    "title": "Cybersecurity of Renewable Energy Data and Applications Using  Distributed Ledger Technology",
    "abstract": "Renewable energy sources (RES) are among the most popular emerging energy\nresources during the past two decades. Many countries have introduced various\nenergy policy instruments, such as renewable energy certificates (RECs), to\nsupport the growth of RES. RECs are tradable non-tangible assets, which have a\nmonetary value. Tracking and certification of the origin of an energy resource\nregardless of its type (e.g., a conventional power plant or RES) is a critical\noperation. In addition to the certification of origin, trading transactions are\nneeded to be performed using a secure method. Energy industry participants need\nto secure the data and applications related to RECs. Distributed ledger\ntechnology (DLT) is a perfect framework that can support such REC\nfunctionalities. This paper addresses the cybersecurity aspects in REC trading\nusing Blockchain and a distributed ledger technology, considering detailed\ncybersecurity perspectives.",
    "descriptor": "\nComments: 5 pages, 4 figures, 2021 International Conference & Exposition on Modern Energy and Power Systems (ICMEPS2021)\n",
    "authors": [
      "Umit Cali",
      "Murat Kuzlu",
      "Manisa Pipattanasomporn",
      "Onur Elma",
      "Ramesh Reddi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.11354"
  },
  {
    "id": "arXiv:2110.11384",
    "title": "Decentralised Person Re-Identification with Selective Knowledge  Aggregation",
    "abstract": "Existing person re-identification (Re-ID) methods mostly follow a centralised\nlearning paradigm which shares all training data to a collection for model\nlearning. This paradigm is limited when data from different sources cannot be\nshared due to privacy concerns. To resolve this problem, two recent works have\nintroduced decentralised (federated) Re-ID learning for constructing a globally\ngeneralised model (server)without any direct access to local training data nor\nshared data across different source domains (clients). However, these methods\nare poor on how to adapt the generalised model to maximise its performance on\nindividual client domain Re-ID tasks having different Re-ID label spaces, due\nto a lack of understanding of data heterogeneity across domains. We call this\npoor 'model personalisation'. In this work, we present a new Selective\nKnowledge Aggregation approach to decentralised person Re-ID to optimise the\ntrade-off between model personalisation and generalisation. Specifically, we\nincorporate attentive normalisation into the normalisation layers in a deep\nReID model and propose to learn local normalisation layers specific to each\ndomain, which are decoupled from the global model aggregation in federated\nRe-ID learning. This helps to preserve model personalisation knowledge on each\nlocal client domain and learn instance-specific information. Further, we\nintroduce a dual local normalisation mechanism to learn generalised\nnormalisation layers in each local model, which are then transmitted to the\nglobal model for central aggregation. This facilitates selective knowledge\naggregation on the server to construct a global generalised model for\nout-of-the-box deployment on unseen novel domains. Extensive experiments on\neight person Re-ID datasets show that the proposed approach to decentralised\nRe-ID significantly outperforms the state-of-the-art decentralised methods.",
    "descriptor": "\nComments: accepted at BMVC2021\n",
    "authors": [
      "Shitong Sun",
      "Guile Wu",
      "Shaogang Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11384"
  },
  {
    "id": "arXiv:2110.11385",
    "title": "Self-Initiated Open World Learning for Autonomous AI Agents",
    "abstract": "As more and more AI agents are used in practice, it is time to think about\nhow to make these agents fully autonomous so that they can learn by themselves\nin a self-motivated and self-supervised manner rather than being retrained\nperiodically on the initiation of human engineers using expanded training data.\nAs the real-world is an open environment with unknowns or novelties, detecting\nnovelties or unknowns, gathering ground-truth training data, and incrementally\nlearning the unknowns make the agent more and more knowledgeable and powerful\nover time. The key challenge is how to automate the process so that it is\ncarried out on the agent's own initiative and through its own interactions with\nhumans and the environment. Since an AI agent usually has a performance task,\ncharacterizing each novelty becomes necessary so that the agent can formulate\nan appropriate response to adapt its behavior to cope with the novelty and to\nlearn from it to improve its future responses and task performance. This paper\nproposes a theoretic framework for this learning paradigm to promote the\nresearch of building self-initiated open world learning agents.",
    "descriptor": "",
    "authors": [
      "Bing Liu",
      "Eric Robertson",
      "Scott Grigsby",
      "Sahisnu Mazumder"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11385"
  },
  {
    "id": "arXiv:2110.11390",
    "title": "An Adaptive Digital Autopilot for Fixed-Wing Aircraft with Actuator  Faults",
    "abstract": "This paper develops an adaptive digital autopilot for a fixed-wing aircraft\nand compares its performance with a fixed-gain autopilot. The adaptive digital\nautopilot is constructed by augmenting the autopilot architecture implemented\nin PX4 flight stack with adaptive digital control laws that are updated using\nthe retrospective cost adaptive control algorithm. In order to investigate the\nperformance of the adaptive digital autopilot, the default gains of the\nfixed-gain autopilot are scaled down to degrade its performance. This scenario\nprovides a venue for determining the ability of the adaptive digital autopilot\nto compensate for the detuned fixed-gain autopilot. Next, the performance of\nthe adaptive autopilot is examined under failure conditions by simulating a\nscenario where one of the control surfaces is assumed to be stuck at an unknown\nangular position. The adaptive digital autopilot is tested in simulation, and\nthe resulting performance improvements are examined.",
    "descriptor": "\nComments: 6 pages, 11 figures, submitted to ACC 2022\n",
    "authors": [
      "Joonghyun Lee",
      "John Spencer",
      "Juan Augusto Paredes",
      "Sai Ravela",
      "Dennis S. Bernstein",
      "Ankit Goel"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.11390"
  },
  {
    "id": "arXiv:2110.11391",
    "title": "DEX: Domain Embedding Expansion for Generalized Person Re-identification",
    "abstract": "In recent years, supervised Person Re-identification (Person ReID) approaches\nhave demonstrated excellent performance. However, when these methods are\napplied to inputs from a different camera network, they typically suffer from\nsignificant performance degradation. Different from most domain adaptation (DA)\napproaches addressing this issue, we focus on developing a domain\ngeneralization (DG) Person ReID model that can be deployed without additional\nfine-tuning or adaptation. In this paper, we propose the Domain Embedding\nExpansion (DEX) module. DEX dynamically manipulates and augments deep features\nbased on person and domain labels during training, significantly improving the\ngeneralization capability and robustness of Person ReID models to unseen\ndomains. We also developed a light version of DEX (DEXLite), applying negative\nsampling techniques to scale to larger datasets and reduce memory usage for\nmulti-branch networks. Our proposed DEX and DEXLite can be combined with many\nexisting methods, Bag-of-Tricks (BagTricks), the Multi-Granularity Network\n(MGN), and Part-Based Convolutional Baseline (PCB), in a plug-and-play manner.\nWith DEX and DEXLite, existing methods can gain significant improvements when\ntested on other unseen datasets, thereby demonstrating the general\napplicability of our method. Our solution outperforms the state-of-the-art DG\nPerson ReID methods in all large-scale benchmarks as well as in most the\nsmall-scale benchmarks.",
    "descriptor": "\nComments: Accepted into BMVC 2021\n",
    "authors": [
      "Eugene P.W. Ang",
      "Lin Shan",
      "Alex C. Kot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11391"
  },
  {
    "id": "arXiv:2110.11395",
    "title": "SOSP: Efficiently Capturing Global Correlations by Second-Order  Structured Pruning",
    "abstract": "Pruning neural networks reduces inference time and memory costs. On standard\nhardware, these benefits will be especially prominent if coarse-grained\nstructures, like feature maps, are pruned. We devise two novel saliency-based\nmethods for second-order structured pruning (SOSP) which include correlations\namong all structures and layers. Our main method SOSP-H employs an innovative\nsecond-order approximation, which enables saliency evaluations by fast\nHessian-vector products. SOSP-H thereby scales like a first-order method\ndespite taking into account the full Hessian. We validate SOSP-H by comparing\nit to our second method SOSP-I that uses a well-established Hessian\napproximation, and to numerous state-of-the-art methods. While SOSP-H performs\non par or better in terms of accuracy, it has clear advantages in terms of\nscalability and efficiency. This allowed us to scale SOSP-H to large-scale\nvision tasks, even though it captures correlations across all layers of the\nnetwork. To underscore the global nature of our pruning methods, we evaluate\ntheir performance not only by removing structures from a pretrained network,\nbut also by detecting architectural bottlenecks. We show that our algorithms\nallow to systematically reveal architectural bottlenecks, which we then remove\nto further increase the accuracy of the networks.",
    "descriptor": "",
    "authors": [
      "Manuel Nonnenmacher",
      "Thomas Pfeil",
      "Ingo Steinwart",
      "David Reeb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.11395"
  },
  {
    "id": "arXiv:2110.11400",
    "title": "Channel redundancy and overlap in convolutional neural networks with  channel-wise NNK graphs",
    "abstract": "Feature spaces in the deep layers of convolutional neural networks (CNNs) are\noften very high-dimensional and difficult to interpret. However, convolutional\nlayers consist of multiple channels that are activated by different types of\ninputs, which suggests that more insights may be gained by studying the\nchannels and how they relate to each other. In this paper, we first analyze\ntheoretically channel-wise non-negative kernel (CW-NNK) regression graphs,\nwhich allow us to quantify the overlap between channels and, indirectly, the\nintrinsic dimension of the data representation manifold. We find that\nredundancy between channels is significant and varies with the layer depth and\nthe level of regularization during training. Additionally, we observe that\nthere is a correlation between channel overlap in the last convolutional layer\nand generalization performance. Our experimental results demonstrate that these\ntechniques can lead to a better understanding of deep representations.",
    "descriptor": "\nComments: Under review at ICASSP\n",
    "authors": [
      "David Bonet",
      "Antonio Ortega",
      "Javier Ruiz-Hidalgo",
      "Sarath Shekkizhar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11400"
  },
  {
    "id": "arXiv:2110.11401",
    "title": "Trajectory Prediction using Generative Adversarial Network in  Multi-Class Scenarios",
    "abstract": "Predicting traffic agents' trajectories is an important task for\nauto-piloting. Most previous work on trajectory prediction only considers a\nsingle class of road agents. We use a sequence-to-sequence model to predict\nfuture paths from observed paths and we incorporate class information into the\nmodel by concatenating extracted label representations with traditional\nlocation inputs. We experiment with both LSTM and transformer encoders and we\nuse generative adversarial network as introduced in Social GAN to learn the\nmulti-modal behavior of traffic agents. We train our model on Stanford Drone\ndataset which includes 6 classes of road agents and evaluate the impact of\ndifferent model components on the prediction performance in multi-class scenes.",
    "descriptor": "",
    "authors": [
      "Shilun Li",
      "Tracy Cai",
      "Jiayi Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11401"
  },
  {
    "id": "arXiv:2110.11402",
    "title": "On the Regularization of Autoencoders",
    "abstract": "While much work has been devoted to understanding the implicit (and explicit)\nregularization of deep nonlinear networks in the supervised setting, this paper\nfocuses on unsupervised learning, i.e., autoencoders are trained with the\nobjective of reproducing the output from the input. We extend recent results\n[Jin et al. 2021] on unconstrained linear models and apply them to (1)\nnonlinear autoencoders and (2) constrained linear autoencoders, obtaining the\nfollowing two results: first, we show that the unsupervised setting by itself\ninduces strong additional regularization, i.e., a severe reduction in the\nmodel-capacity of the learned autoencoder: we derive that a deep nonlinear\nautoencoder cannot fit the training data more accurately than a linear\nautoencoder does if both models have the same dimensionality in their last\nhidden layer (and under a few additional assumptions). Our second contribution\nis concerned with the low-rank EDLAE model [Steck 2020], which is a linear\nautoencoder with a constraint on the diagonal of the learned low-rank\nparameter-matrix for improved generalization: we derive a closed-form\napproximation to the optimum of its non-convex training-objective, and\nempirically demonstrate that it is an accurate approximation across all\nmodel-ranks in our experiments on three well-known data sets.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Harald Steck",
      "Dario Garcia Garcia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11402"
  },
  {
    "id": "arXiv:2110.11403",
    "title": "SCENIC: A JAX Library for Computer Vision Research and Beyond",
    "abstract": "Scenic is an open-source JAX library with a focus on Transformer-based models\nfor computer vision research and beyond. The goal of this toolkit is to\nfacilitate rapid experimentation, prototyping, and research of new vision\narchitectures and models. Scenic supports a diverse range of vision tasks\n(e.g., classification, segmentation, detection)and facilitates working on\nmulti-modal problems, along with GPU/TPU support for multi-host, multi-device\nlarge-scale training. Scenic also offers optimized implementations of\nstate-of-the-art research models spanning a wide range of modalities. Scenic\nhas been successfully used for numerous projects and published papers and\ncontinues serving as the library of choice for quick prototyping and\npublication of new research ideas.",
    "descriptor": "",
    "authors": [
      "Mostafa Dehghani",
      "Alexey Gritsenko",
      "Anurag Arnab",
      "Matthias Minderer",
      "Yi Tay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11403"
  },
  {
    "id": "arXiv:2110.11404",
    "title": "Statistical discrimination in learning agents",
    "abstract": "Undesired bias afflicts both human and algorithmic decision making, and may\nbe especially prevalent when information processing trade-offs incentivize the\nuse of heuristics. One primary example is \\textit{statistical discrimination}\n-- selecting social partners based not on their underlying attributes, but on\nreadily perceptible characteristics that covary with their suitability for the\ntask at hand. We present a theoretical model to examine how information\nprocessing influences statistical discrimination and test its predictions using\nmulti-agent reinforcement learning with various agent architectures in a\npartner choice-based social dilemma. As predicted, statistical discrimination\nemerges in agent policies as a function of both the bias in the training\npopulation and of agent architecture. All agents showed substantial statistical\ndiscrimination, defaulting to using the readily available correlates instead of\nthe outcome relevant features. We show that less discrimination emerges with\nagents that use recurrent neural networks, and when their training environment\nhas less bias. However, all agent algorithms we tried still exhibited\nsubstantial bias after learning in biased training populations.",
    "descriptor": "\nComments: 29 pages, 10 figures\n",
    "authors": [
      "Edgar A. Du\u00e9\u00f1ez-Guzm\u00e1n",
      "Kevin R. McKee",
      "Yiran Mao",
      "Ben Coppin",
      "Silvia Chiappa",
      "Alexander Sasha Vezhnevets",
      "Michiel A. Bakker",
      "Yoram Bachrach",
      "Suzanne Sadedin",
      "William Isaac",
      "Karl Tuyls",
      "Joel Z. Leibo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.11404"
  },
  {
    "id": "arXiv:2110.11405",
    "title": "Illiterate DALL$\\cdot$E Learns to Compose",
    "abstract": "Although DALL$\\cdot$E has shown an impressive ability of composition-based\nsystematic generalization in image generation, it requires the dataset of\ntext-image pairs and the compositionality is provided by the text. In contrast,\nobject-centric representation models like the Slot Attention model learn\ncomposable representations without the text prompt. However, unlike\nDALL$\\cdot$E its ability to systematically generalize for zero-shot generation\nis significantly limited. In this paper, we propose a simple but novel\nslot-based autoencoding architecture, called SLATE, for combining the best of\nboth worlds: learning object-centric representations that allows systematic\ngeneralization in zero-shot image generation without text. As such, this model\ncan also be seen as an illiterate DALL$\\cdot$E model. Unlike the pixel-mixture\ndecoders of existing object-centric representation models, we propose to use\nthe Image GPT decoder conditioned on the slots for capturing complex\ninteractions among the slots and pixels. In experiments, we show that this\nsimple and easy-to-implement architecture not requiring a text prompt achieves\nsignificant improvement in in-distribution and out-of-distribution (zero-shot)\nimage generation and qualitatively comparable or better slot-attention\nstructure than the models based on mixture decoders.",
    "descriptor": "",
    "authors": [
      "Gautam Singh",
      "Fei Deng",
      "Sungjin Ahn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11405"
  },
  {
    "id": "arXiv:2110.11407",
    "title": "Video-Data Pipelines for Machine Learning Applications",
    "abstract": "Data pipelines are an essential component for end-to-end solutions that take\nmachine learning algorithms to production. Engineering data pipelines for\nvideo-sequences poses several challenges including isolation of key-frames from\nvideo sequences that are high quality and represent significant variations in\nthe scene. Manual isolation of such quality key-frames can take hours of\nsifting through hours worth of video data. In this work, we present a data\npipeline framework that can automate this process of manual frame sifting in\nvideo sequences by controlling the fraction of frames that can be removed based\non image quality and content type. Additionally, the frames that are retained\ncan be automatically tagged per sequence, thereby simplifying the process of\nautomated data retrieval for future ML model deployments. We analyze the\nperformance of the proposed video-data pipeline for versioned deployment and\nmonitoring for object detection algorithms that are trained on outdoor\nautonomous driving video sequences. The proposed video-data pipeline can retain\nanywhere between 0.1-20% of the all input frames that are representative of\nhigh image quality and high variations in content. This frame selection,\nautomated scene tagging followed by model verification can be completed in\nunder 30 seconds for 22 video-sequences under analysis in this work. Thus, the\nproposed framework can be scaled to additional video-sequence data sets for\nautomating ML versioned deployments.",
    "descriptor": "\nComments: 10 pages, 6 Figures, 5 Tables, conference\n",
    "authors": [
      "Sohini Roychowdhury",
      "James Y. Sato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.11407"
  },
  {
    "id": "arXiv:2110.11411",
    "title": "PROVES: Establishing Image Provenance using Semantic Signatures",
    "abstract": "Modern AI tools, such as generative adversarial networks, have transformed\nour ability to create and modify visual data with photorealistic results.\nHowever, one of the deleterious side-effects of these advances is the emergence\nof nefarious uses in manipulating information in visual data, such as through\nthe use of deep fakes. We propose a novel architecture for preserving the\nprovenance of semantic information in images to make them less susceptible to\ndeep fake attacks. Our architecture includes semantic signing and verification\nsteps. We apply this architecture to verifying two types of semantic\ninformation: individual identities (faces) and whether the photo was taken\nindoors or outdoors. Verification accounts for a collection of common image\ntransformation, such as translation, scaling, cropping, and small rotations,\nand rejects adversarial transformations, such as adversarially perturbed or, in\nthe case of face verification, swapped faces. Experiments demonstrate that in\nthe case of provenance of faces in an image, our approach is robust to\nblack-box adversarial transformations (which are rejected) as well as benign\ntransformations (which are accepted), with few false negatives and false\npositives. Background verification, on the other hand, is susceptible to\nblack-box adversarial examples, but becomes significantly more robust after\nadversarial training.",
    "descriptor": "",
    "authors": [
      "Mingyang Xie",
      "Manav Kulshrestha",
      "Shaojie Wang",
      "Jinghan Yang",
      "Ayan Chakrabarti",
      "Ning Zhang",
      "Yevgeniy Vorobeychik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.11411"
  },
  {
    "id": "arXiv:2110.11414",
    "title": "Real-time, low-cost multi-person 3D pose estimation",
    "abstract": "The process of tracking human anatomy in computer vision is referred to pose\nestimation, and it is used in fields ranging from gaming to surveillance.\nThree-dimensional pose estimation traditionally requires advanced equipment,\nsuch as multiple linked intensity cameras or high-resolution time-of-flight\ncameras to produce depth images. However, there are applications, e.g.~consumer\nelectronics, where significant constraints are placed on the size, power\nconsumption, weight and cost of the usable technology. Here, we demonstrate\nthat computational imaging methods can achieve accurate pose estimation and\novercome the apparent limitations of time-of-flight sensors designed for much\nsimpler tasks. The sensor we use is already widely integrated in consumer-grade\nmobile devices, and despite its low spatial resolution, only 4$\\times$4 pixels,\nour proposed Pixels2Pose system transforms its data into accurate depth maps\nand 3D pose data of multiple people up to a distance of 3 m from the sensor. We\nare able to generate depth maps at a resolution of 32$\\times$32 and 3D\nlocalization of a body parts with an error of only $\\approx$10 cm at a frame\nrate of 7 fps. This work opens up promising real-life applications in scenarios\nthat were previously restricted by the advanced hardware requirements and cost\nof time-of-flight technology.",
    "descriptor": "",
    "authors": [
      "Alice Ruget",
      "Max Tyler",
      "Germ\u00e1n Mora Mart\u00edn",
      "Stirling Scholes",
      "Feng Zhu",
      "Istvan Gyongy",
      "Brent Hearn",
      "Steve McLaughlin",
      "Abderrahim Halimi",
      "Jonathan Leach"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11414"
  },
  {
    "id": "arXiv:2110.11416",
    "title": "Verification of Distributed Quantum Protocols",
    "abstract": "Truly concurrent process algebras are generalizations to the traditional\nprocess algebras for true concurrency, CTC to CCS, APTC to ACP, $\\pi_{tc}$ to\n$\\pi$ calculus, APPTC to probabilistic process algebra, APTC with localities to\nprocess algebra with localities. In quantum process algebras, there are several\nwell-known work, and we ever did some work to unify quantum and classical\ncomputing under the framework of ACP \\cite{ACP} and probabilistic process\nalgebra. Now, it is the time to utilize truly concurrent process algebras with\nlocalities to model quantum computing and unify quantum and classical computing\nin this book. Since this work is with localities, it is suitable to verify the\ndistribution of quantum communication protocols.",
    "descriptor": "\nComments: 151 pages, 23 figures, 60 tables. arXiv admin note: text overlap with arXiv:2107.08453, arXiv:2101.05140, arXiv:1611.09035, arXiv:1610.02500, arXiv:1810.00868, arXiv:2104.05438, arXiv:1311.2960, arXiv:1501.05260, arXiv:2109.05936\n",
    "authors": [
      "Yong Wang"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.11416"
  },
  {
    "id": "arXiv:2110.11417",
    "title": "HIRE-SNN: Harnessing the Inherent Robustness of Energy-Efficient Deep  Spiking Neural Networks by Training with Crafted Input Noise",
    "abstract": "Low-latency deep spiking neural networks (SNNs) have become a promising\nalternative to conventional artificial neural networks (ANNs) because of their\npotential for increased energy efficiency on event-driven neuromorphic\nhardware. Neural networks, including SNNs, however, are subject to various\nadversarial attacks and must be trained to remain resilient against such\nattacks for many applications. Nevertheless, due to prohibitively high training\ncosts associated with SNNs, analysis, and optimization of deep SNNs under\nvarious adversarial attacks have been largely overlooked. In this paper, we\nfirst present a detailed analysis of the inherent robustness of low-latency\nSNNs against popular gradient-based attacks, namely fast gradient sign method\n(FGSM) and projected gradient descent (PGD). Motivated by this analysis, to\nharness the model robustness against these attacks we present an SNN training\nalgorithm that uses crafted input noise and incurs no additional training time.\nTo evaluate the merits of our algorithm, we conducted extensive experiments\nwith variants of VGG and ResNet on both CIFAR-10 and CIFAR-100 datasets.\nCompared to standard trained direct input SNNs, our trained models yield\nimproved classification accuracy of up to 13.7% and 10.1% on FGSM and PGD\nattack-generated images, respectively, with negligible loss in clean image\naccuracy. Our models also outperform inherently robust SNNs trained on\nrate-coded inputs with improved or similar classification performance on\nattack-generated images while having up to 25x and 4.6x lower latency and\ncomputation energy, respectively.",
    "descriptor": "\nComments: 10 pages, 11 figures, 7 tables, International Conference on Computer Vision\n",
    "authors": [
      "Souvik Kundu",
      "Massoud Pedram",
      "Peter A. Beerel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11417"
  },
  {
    "id": "arXiv:2110.11418",
    "title": "SABMIS: Sparse approximation based blind multi-image steganography  scheme",
    "abstract": "Steganography is a technique of hiding secret data in some unsuspected cover\nmedia so that it is visually imperceptible. Image steganography, where the\ncover media is an image, is one of the most used schemes. Here, we focus on\nimage steganography where the hidden data is also an image. Specifically, we\nembed grayscale secret images into a grayscale cover image, which is a\nchallenging problem. Our goal is to develop a steganography scheme with\nenhanced embedding capacity while preserving the visual quality of the\nstego-image and ensuring that the stego-image is resistant to attacks.\nOur proposed scheme involves use of sparse approximation and our novel\nembedding rule, which helps to increase the embedding capacity and adds a layer\nof security. The stego-image is constructed by using the ADMM to solve the\nLASSO formulation of the underlying minimization problem. This method has a\nfast convergence, is easy to implement, and is extensively used in image\nprocessing. Finally, the secret images are extracted from the constructed\nstego-image using the reverse of our embedding rule.\nWe perform extensive experiments on several standard images, and evaluate the\nembedding capacity, PSNR value, MSSIM index, NCC coefficient, entropy, and NAE.\nWe obtain embedding capacities of 2bpp (bits per pixel), 4bpp, 6bpp, and 8bpp\nwhile embedding one, two, three, and four secret images, respectively. Our\nembedding capacities for the first three cases are higher than all the\nembedding capacities obtained in the literature. We are the first ones to embed\nfour images. Further, there is very little deterioration in the quality of the\nstego-image as compared to its corresponding cover image. The quality of the\noriginal secret images and their corresponding extracted secret images is also\nalmost the same. Further, due to our algorithmic design, our scheme is\nresistant to steganographic attacks as well.",
    "descriptor": "\nComments: 24 Pages, 9 Figures, and 5 Tables\n",
    "authors": [
      "Rohit Agrawal",
      "Kapil Ahuja",
      "Marc C. Steinbach",
      "Thomas Wick"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.11418"
  },
  {
    "id": "arXiv:2110.11419",
    "title": "A boundary integral method for 3D nonuniform dielectric waveguide  problems via the windowed Green function",
    "abstract": "This paper proposes an efficient boundary-integral based \"windowed Green\nfunction\" methodology (WGF) for the numerical solution of three-dimensional\nelectromagnetic problems containing dielectric waveguides. The approach, which\ngeneralizes a two-dimensional version of the method introduced recently,\nprovides a highly effective solver for general electromagnetic problems\ncontaining waveguides. In particular, using an auxiliary integral\nrepresentation, the proposed method is able to accurately model incident mode\nexcitation. On the basis of a smooth window function, the integral operators\nalong the infinite waveguide boundaries are smoothly truncated, resulting in\nerrors that decay faster than any negative power of the window size.",
    "descriptor": "",
    "authors": [
      "Emmanuel Garza",
      "Constantine Sideris",
      "Oscar P. Bruno"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.11419"
  },
  {
    "id": "arXiv:2110.11420",
    "title": "Fast Graph Sampling for Short Video Summarization using Gershgorin Disc  Alignment",
    "abstract": "We study the problem of efficiently summarizing a short video into several\nkeyframes, leveraging recent progress in fast graph sampling. Specifically, we\nfirst construct a similarity path graph (SPG) $\\mathcal{G}$, represented by\ngraph Laplacian matrix $\\mathbf{L}$, where the similarities between adjacent\nframes are encoded as positive edge weights. We show that maximizing the\nsmallest eigenvalue $\\lambda_{\\min}(\\mathbf{B})$ of a coefficient matrix\n$\\mathbf{B} = \\text{diag}(\\mathbf{a}) + \\mu \\mathbf{L}$, where $\\mathbf{a}$ is\nthe binary keyframe selection vector, is equivalent to minimizing a worst-case\nsignal reconstruction error. We prove that, after partitioning $\\mathcal{G}$\ninto $Q$ sub-graphs $\\{\\mathcal{G}^q\\}^Q_{q=1}$, the smallest Gershgorin circle\ntheorem (GCT) lower bound of $Q$ corresponding coefficient matrices -- $\\min_q\n\\lambda^-_{\\min}(\\mathbf{B}^q)$ -- is a lower bound for\n$\\lambda_{\\min}(\\mathbf{B})$. This inspires a fast graph sampling algorithm to\niteratively partition $\\mathcal{G}$ into $Q$ sub-graphs using $Q$ samples\n(keyframes), while maximizing $\\lambda^-_{\\min}(\\mathbf{B}^q)$ for each\nsub-graph $\\mathcal{G}^q$. Experimental results show that our algorithm\nachieves comparable video summarization performance as state-of-the-art\nmethods, at a substantially reduced complexity.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Sadid Sahami",
      "Gene Cheung",
      "Chia-Wen Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.11420"
  },
  {
    "id": "arXiv:2110.11424",
    "title": "Analysis of memory consumption by neural networks based on  hyperparameters",
    "abstract": "Deep learning models are trained and deployed in multiple domains. Increasing\nusage of deep learning models alarms the usage of memory consumed while\ncomputation by deep learning models. Existing approaches for reducing memory\nconsumption like model compression, hardware changes are specific. We propose a\ngeneric analysis of memory consumption while training deep learning models in\ncomparison with hyperparameters used for training. Hyperparameters which\nincludes the learning rate, batchsize, number of hidden layers and depth of\nlayers decide the model performance, accuracy of the model. We assume the\noptimizers and type of hidden layers as a known values. The change in\nhyperparamaters and the number of hidden layers are the variables considered in\nthis proposed approach. For better understanding of the computation cost, this\nproposed analysis studies the change in memory consumption with respect to\nhyperparameters as main focus. This results in general analysis of memory\nconsumption changes during training when set of hyperparameters are altered.",
    "descriptor": "\nComments: 8 pages, Rejected by ACML 2021\n",
    "authors": [
      "Mahendran N"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11424"
  },
  {
    "id": "arXiv:2110.11425",
    "title": "A Machine Learning Framework Towards Transparency in Experts' Decision  Quality",
    "abstract": "Expert workers make non-trivial decisions with significant implications.\nExperts' decision accuracy is thus a fundamental aspect of their judgment\nquality, key to both management and consumers of experts' services. Yet, in\nmany important settings, transparency in experts' decision quality is rarely\npossible because ground truth data for evaluating the experts' decisions is\ncostly and available only for a limited set of decisions. Furthermore,\ndifferent experts typically handle exclusive sets of decisions, and thus prior\nsolutions that rely on the aggregation of multiple experts' decisions for the\nsame instance are inapplicable. We first formulate the problem of estimating\nexperts' decision accuracy in this setting and then develop a\nmachine-learning-based framework to address it. Our method effectively\nleverages both abundant historical data on workers' past decisions, and scarce\ndecision instances with ground truth information. We conduct extensive\nempirical evaluations of our method's performance relative to alternatives\nusing both semi-synthetic data based on publicly available datasets, and\npurposefully compiled dataset on real workers' decisions. The results show that\nour approach is superior to existing alternatives across diverse settings,\nincluding different data domains, experts' qualities, and the amount of ground\ntruth data. To our knowledge, this paper is the first to posit and address the\nproblem of estimating experts' decision accuracies from historical data with\nscarcely available ground truth, and it is the first to offer comprehensive\nresults for this problem setting, establishing the performances that can be\nachieved across settings, as well as the state-of-the-art performance on which\nfuture work can build.",
    "descriptor": "",
    "authors": [
      "Wanxue Dong",
      "Maytal Saar-Tsechansky",
      "Tomer Geva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11425"
  },
  {
    "id": "arXiv:2110.11426",
    "title": "Native versus Overlay-based NDN over Wi-Fi 6 for the Internet of  Vehicles",
    "abstract": "Internet of Vehicles (IoV) is a cornerstone building block of smart cities to\nprovide better traffic safety and mobile infotainment. Recently, improved\nefficiency in WLAN-based dense scenarios has become widespread through Wi-Fi 6,\na license-free spectrum technology that can complement the cellular-based\ninfrastructure for IoV. In addition, Named Data Networking (NDN) is a promising\nInternet architecture to accomplish content distribution in dynamic IoV\nscenarios. However, NDN deployments, i.e., native (clean-slate) and overlay\n(running on top of IP stack), require further investigation of their\nperformance over wireless networks, particularly regarding the IoV scenario.\nThis paper performs a comparative simulation-based study of these NDN\ndeployments over Wi-Fi 6 for IoV using real vehicular traces. To the best of\nour knowledge, this is the first effort that extends ndnSIM 2 with an\noverlay-based NDN implementation and that compares it with the native approach.\nResults show that the overlay-based NDN consistently outperforms the native\none, reaching around 99% of requests satisfied, against only 42.35% in the best\ncase of native deployment.",
    "descriptor": "\nComments: Accepted to be published in Proceedings of 13th EAI International Conference on Simulation Tools and Techniques (EAI SIMUtools 2021), Nov 5-6, 2021\n",
    "authors": [
      "Ygor Amaral B. L. de Sena",
      "Kelvin Lopes Dias"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.11426"
  },
  {
    "id": "arXiv:2110.11430",
    "title": "How can classical multidimensional scaling go wrong?",
    "abstract": "Given a matrix $D$ describing the pairwise dissimilarities of a data set, a\ncommon task is to embed the data points into Euclidean space. The classical\nmultidimensional scaling (cMDS) algorithm is a widespread method to do this.\nHowever, theoretical analysis of the robustness of the algorithm and an\nin-depth analysis of its performance on non-Euclidean metrics is lacking.\nIn this paper, we derive a formula, based on the eigenvalues of a matrix\nobtained from $D$, for the Frobenius norm of the difference between $D$ and the\nmetric $D_{\\text{cmds}}$ returned by cMDS. This error analysis leads us to the\nconclusion that when the derived matrix has a significant number of negative\neigenvalues, then $\\|D-D_{\\text{cmds}}\\|_F$, after initially decreasing, will\neventually increase as we increase the dimension. Hence, counterintuitively,\nthe quality of the embedding degrades as we increase the dimension. We\nempirically verify that the Frobenius norm increases as we increase the\ndimension for a variety of non-Euclidean metrics. We also show on several\nbenchmark datasets that this degradation in the embedding results in the\nclassification accuracy of both simple (e.g., 1-nearest neighbor) and complex\n(e.g., multi-layer neural nets) classifiers decreasing as we increase the\nembedding dimension.\nFinally, our analysis leads us to a new efficiently computable algorithm that\nreturns a matrix $D_l$ that is at least as close to the original distances as\n$D_t$ (the Euclidean metric closest in $\\ell_2$ distance). While $D_l$ is not\nmetric, when given as input to cMDS instead of $D$, it empirically results in\nsolutions whose distance to $D$ does not increase when we increase the\ndimension and the classification accuracy degrades less than the cMDS solution.",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Rishi Sonthalia",
      "Gregory Van Buskirk",
      "Benjamin Raichel",
      "Anna C. Gilbert"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11430"
  },
  {
    "id": "arXiv:2110.11431",
    "title": "Categorizing Items with Short and Noisy Descriptions using Ensembled  Transferred Embeddings",
    "abstract": "Item categorization is a machine learning task which aims at classifying\ne-commerce items, typically represented by textual attributes, to their most\nsuitable category from a predefined set of categories. An accurate item\ncategorization system is essential for improving both the user experience and\nthe operational processes of the company. In this work, we focus on item\ncategorization settings in which the textual attributes representing items are\nnoisy and short, and labels (i.e., accurate classification of items into\ncategories) are not available. In order to cope with such settings, we propose\na novel learning framework, Ensembled Transferred Embeddings (ETE), which\nrelies on two key ideas: 1) labeling a relatively small sample of the target\ndataset, in a semi-automatic process, and 2) leveraging other datasets from\nrelated domains or related tasks that are large-scale and labeled, to extract\n\"transferable embeddings\". Evaluation of ETE on a large-scale real-world\ndataset provided to us by PayPal, shows that it significantly outperforms\ntraditional as well as state-of-the-art item categorization methods.",
    "descriptor": "",
    "authors": [
      "Yonatan Hadar",
      "Erez Shmueli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11431"
  },
  {
    "id": "arXiv:2110.11435",
    "title": "Generating Multivariate Load States Using a Conditional Variational  Autoencoder",
    "abstract": "For planning of power systems and for the calibration of operational tools,\nit is essential to analyse system performance in a large range of\nrepresentative scenarios. When the available historical data is limited,\ngenerative models are a promising solution, but modelling high-dimensional\ndependencies is challenging. In this paper, a multivariate load state\ngenerating model on the basis of a conditional variational autoencoder (CVAE)\nneural network is proposed. Going beyond common CVAE implementations, the model\nincludes stochastic variation of output samples under given latent vectors and\nco-optimizes the parameters for this output variability. It is shown that this\nimproves statistical properties of the generated data. The quality of generated\nmultivariate loads is evaluated using univariate and multivariate performance\nmetrics. A generation adequacy case study on the European network is used to\nillustrate model's ability to generate realistic tail distributions. The\nexperiments demonstrate that the proposed generator outperforms other data\ngenerating mechanisms.",
    "descriptor": "\nComments: 7 pages, 5 figures, 1 table\n",
    "authors": [
      "Chenguang Wang",
      "Ensieh Sharifnia",
      "Zhi Gao",
      "Simon H. Tindemans",
      "Peter Palensky"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11435"
  },
  {
    "id": "arXiv:2110.11439",
    "title": "Online Bipartite Matching with Predicted Degrees",
    "abstract": "We propose a model for online graph problems where algorithms are given\naccess to an oracle that predicts the degrees of nodes in the graph (e.g.,\nbased on past data). Within this model, we study the classic problem of online\nbipartite matching. An extensive empirical evaluation shows that a greedy\nalgorithm called MinPredictedDegree compares favorably to state-of-the-art\nonline algorithms for this problem. We also initiate the theoretical study of\nMinPredictedDegree on a natural random graph model with power law degree\ndistribution and show that it produces matchings almost as large as the maximum\nmatching on such graphs.",
    "descriptor": "",
    "authors": [
      "Justin Y. Chen",
      "Piotr Indyk"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11439"
  },
  {
    "id": "arXiv:2110.11443",
    "title": "Off-Dynamics Inverse Reinforcement Learning from Hetero-Domain",
    "abstract": "We propose an approach for inverse reinforcement learning from hetero-domain\nwhich learns a reward function in the simulator, drawing on the demonstrations\nfrom the real world. The intuition behind the method is that the reward\nfunction should not only be oriented to imitate the experts, but should\nencourage actions adjusted for the dynamics difference between the simulator\nand the real world. To achieve this, the widely used GAN-inspired IRL method is\nadopted, and its discriminator, recognizing policy-generating trajectories, is\nmodified with the quantification of dynamics difference. The training process\nof the discriminator can yield the transferable reward function suitable for\nsimulator dynamics, which can be guaranteed by derivation. Effectively, our\nmethod assigns higher rewards for demonstration trajectories which do not\nexploit discrepancies between the two domains. With extensive experiments on\ncontinuous control tasks, our method shows its effectiveness and demonstrates\nits scalability to high-dimensional tasks.",
    "descriptor": "",
    "authors": [
      "Yachen Kang",
      "Jinxin Liu",
      "Xin Cao",
      "Donglin Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11443"
  },
  {
    "id": "arXiv:2110.11445",
    "title": "Reliability-Aware Probabilistic Reserve Procurement",
    "abstract": "Current reserve procurement approaches ignore the stochastic nature of\nreserve asset availability itself and thus limit the type and volume of reserve\noffers. This paper develops a reliability-aware probabilistic approach that\nallows renewable generators to offer reserve capacity with reliability\nattributes. Offers with low reliability are priced at lower levels. The\noriginal non-convex market clearing problem is approximated by a MILP\nreformulation. The proposed probabilistic reserve procurement allows restricted\nreserve providers to enter the market, thereby increases liquidity and has the\npotential to lower procurement costs in power systems with high shares of\nvariable renewable energy sources.",
    "descriptor": "",
    "authors": [
      "Lars Herre",
      "Pierre Pinson",
      "Spyros Chatzivasileiadis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.11445"
  },
  {
    "id": "arXiv:2110.11446",
    "title": "ML with HE: Privacy Preserving Machine Learning Inferences for Genome  Studies",
    "abstract": "Preserving the privacy and security of big data in the context of cloud\ncomputing, while maintaining a certain level of efficiency of its processing\nremains to be a subject, open for improvement. One of the most popular\napplications epitomizing said concerns is found to be useful in genome\nanalysis. This work proposes a secure multi-label tumor classification method\nusing homomorphic encryption, whereby two different machine learning\nalgorithms, SVM and XGBoost, are used to classify the encrypted genome data of\ndifferent tumor types.",
    "descriptor": "",
    "authors": [
      "\u015e. S. Ma\u011fara",
      "C. Y\u0131ld\u0131r\u0131m",
      "F. Yaman",
      "B. Dileko\u011flu",
      "F. R. Tuta\u015f",
      "E. \u00d6zt\u00fcrk",
      "K. Kaya",
      "\u00d6. Ta\u015ftan",
      "E. Sava\u015f"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2110.11446"
  },
  {
    "id": "arXiv:2110.11450",
    "title": "Online Meta-Learning for Scene-Diverse Waveform-Agile Radar Target  Tracking",
    "abstract": "A fundamental problem for waveform-agile radar systems is that the true\nenvironment is unknown, and transmission policies which perform well for a\nparticular tracking instance may be sub-optimal for another. Additionally,\nthere is a limited time window for each target track, and the radar must learn\nan effective strategy from a sequence of measurements in a timely manner. This\npaper studies a Bayesian meta-learning model for radar waveform selection which\nseeks to learn an inductive bias to quickly optimize tracking performance\nacross a class of radar scenes. We cast the waveform selection problem in the\nframework of sequential Bayesian inference, and introduce a contextual bandit\nvariant of the recently proposed meta-Thompson Sampling algorithm, which learns\nan inductive bias in the form of a prior distribution. Each track is treated as\nan instance of a contextual bandit learning problem, coming from a task\ndistribution. We show that the meta-learning process results in an appreciably\nfaster learning, resulting in significantly fewer lost tracks than a\nconventional learning approach equipped with an uninformative prior.",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "Charles E. Thornton",
      "R. Michael Buehrer",
      "Anthony F. Martone"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.11450"
  },
  {
    "id": "arXiv:2110.11451",
    "title": "An EMD-based Method for the Detection of Power Transformer Faults with a  Hierarchical Ensemble Classifier",
    "abstract": "In this paper, an Empirical Mode Decomposition-based method is proposed for\nthe detection of transformer faults from Dissolve gas analysis (DGA) data.\nRatio-based DGA parameters are ranked using their skewness. Optimal sets of\nintrinsic mode function coefficients are obtained from the ranked DGA\nparameters. A Hierarchical classification scheme employing XGBoost is presented\nfor classifying the features to identify six different categories of\ntransformer faults. Performance of the Proposed Method is studied for publicly\navailable DGA data of 377 transformers. It is shown that the proposed method\ncan yield more than 90% sensitivity and accuracy in the detection of\ntransformer faults, a superior performance as compared to conventional methods\nas well as several existing machine learning-based techniques.",
    "descriptor": "\nComments: 04 pages, 04 figures, Conference\n",
    "authors": [
      "Shoaib Meraj Sami",
      "Mohammed Imamul Hassan Bhuiyan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.11451"
  },
  {
    "id": "arXiv:2110.11456",
    "title": "A CutFEM divergence--free discretization for the Stokes problem",
    "abstract": "We construct and analyze a CutFEM discretization for the Stokes problem based\non the Scott-Vogelius pair. The discrete piecewise polynomial spaces are\ndefined on macro-element triangulations which are not fitted to the smooth\nphysical domain. Boundary conditions are imposed via penalization through the\nhelp of a Nitsche-type discretization, whereas stability with respect to small\nand anisotropic cuts of the bulk elements is ensured by adding local ghost\npenalty stabilization terms. We show stability of the scheme as well as a\ndivergence--free property of the discrete velocity outside an $O(h)$\nneighborhood of the boundary. To mitigate the error caused by the violation of\nthe divergence-free condition, we introduce local grad-div stabilization. The\nerror analysis shows that the grad-div parameter can scale like $O(h^{-1})$,\nallowing a rather heavy penalty for the violation of mass conservation, while\nstill ensuring optimal order error estimates.",
    "descriptor": "",
    "authors": [
      "Haoran Liu",
      "Michael Neilan",
      "Maxim Olshanskii"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.11456"
  },
  {
    "id": "arXiv:2110.11457",
    "title": "A well balanced fvc scheme for 2d shallow water flows on unstructured  triangular meshes",
    "abstract": "We consider in this work the numerical resolution of a 2D shallow water\nsystem with a Coriolis effect and bottom friction stresses on unstructured\nmeshes by a new Finite Volume Characteristics (FVC) scheme, which has been\nintroduced in the preliminary works that will be cited below. Our main goal is\nto extend this approach to 2D unstructured formalism while preserving the\nphysical and mathematical properties of the system, including the C-property.\nFirst, we present our extension by preserving the advantages of the finite\nvolume discretization such as conservation property and the method of\ncharacteristics such as elimination of Riemann solvers. Afterward, an approach\nwas applied to the topography source term that leads to a well-balanced scheme\nsatisfying the steady-state condition of still water. A semi-implicit treatment\nwill also be presented in this study to avoid stability problems for the other\nsource terms. Finally, the proposed finite volume method is verified on several\nbenchmark tests and shows good agreement with analytical solutions and\nexperimental results; moreover, it gives a noticeable accuracy and rapidity\nimprovement compared to the original approaches.",
    "descriptor": "",
    "authors": [
      "Moussa Ziggaf",
      "Imad Kissami",
      "Mohamed Boubekeur"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.11457"
  },
  {
    "id": "arXiv:2110.11459",
    "title": "CAPTIVE: Constrained Adversarial Perturbations to Thwart IC Reverse  Engineering",
    "abstract": "Reverse engineering (RE) in Integrated Circuits (IC) is a process in which\none will attempt to extract the internals of an IC, extract the circuit\nstructure, and determine the gate-level information of an IC. In general, RE\nprocess can be done for validation as well as intellectual property (IP)\nstealing intentions. In addition, RE also facilitates different illicit\nactivities such as insertion of hardware Trojan, pirate, or counterfeit a\ndesign, or develop an attack. In this work, we propose an approach to introduce\ncognitive perturbations, with the aid of adversarial machine learning, to the\nIC layout that could prevent the RE process from succeeding. We first construct\na layer-by-layer image dataset of 45nm predictive technology. With this\ndataset, we propose a conventional neural network model called RecoG-Net to\nrecognize the logic gates, which is the first step in RE. RecoG-Net is\nsuccessfully to recognize the gates with more than 99.7% accuracy. Our\nthwarting approach utilizes the concept of the adversarial attack generation\nalgorithms to generate perturbation. Unlike traditional adversarial attacks in\nmachine learning, the perturbation generation needs to be highly constrained to\nmeet the fab rules such as Design Rule Checking (DRC) Layout vs. Schematic\n(LVS) checks. Hence, we propose CAPTIVE as an constrained perturbation\ngeneration satisfying the DRC. The experiments shows that the accuracy of\nreverse engineering using machine learning techniques can decrease from 100% to\napproximately 30% based on the adversary generator.",
    "descriptor": "",
    "authors": [
      "Amir Hosein Afandizadeh Zargari",
      "Marzieh AshrafiAmiri",
      "Minjun Seo",
      "Sai Manoj Pudukotai Dinakarrao",
      "Mohammed E. Fouda",
      "Fadi Kurdahi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.11459"
  },
  {
    "id": "arXiv:2110.11460",
    "title": "MUGL: Large Scale Multi Person Conditional Action Generation with  Locomotion",
    "abstract": "We introduce MUGL, a novel deep neural model for large-scale, diverse\ngeneration of single and multi-person pose-based action sequences with\nlocomotion. Our controllable approach enables variable-length generations\ncustomizable by action category, across more than 100 categories. To enable\nintra/inter-category diversity, we model the latent generative space using a\nConditional Gaussian Mixture Variational Autoencoder. To enable realistic\ngeneration of actions involving locomotion, we decouple local pose and global\ntrajectory components of the action sequence. We incorporate duration-aware\nfeature representations to enable variable-length sequence generation. We use a\nhybrid pose sequence representation with 3D pose sequences sourced from videos\nand 3D Kinect-based sequences of NTU-RGBD-120. To enable principled comparison\nof generation quality, we employ suitably modified strong baselines during\nevaluation. Although smaller and simpler compared to baselines, MUGL provides\nbetter quality generations, paving the way for practical and controllable\nlarge-scale human action generation.",
    "descriptor": "\nComments: Accepted at WACV 2022. Project page : this https URL\n",
    "authors": [
      "Shubh Maheshwari",
      "Debtanu Gupta",
      "Ravi Kiran Sarvadevabhatla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.11460"
  },
  {
    "id": "arXiv:2110.11461",
    "title": "Three Practical Workflow Schedulers for Easy Maximum Parallelism",
    "abstract": "Runtime scheduling and workflow systems are an increasingly popular\nalgorithmic component in HPC because they allow full system utilization with\nrelaxed synchronization requirements. There are so many special-purpose tools\nfor task scheduling, one might wonder why more are needed. Use cases seen on\nthe Summit supercomputer needed better integration with MPI and greater\nflexibility in job launch configurations. Preparation, execution, and analysis\nof computational chemistry simulations at the scale of tens of thousands of\nprocessors revealed three distinct workflow patterns. A separate job scheduler\nwas implemented for each one using extremely simple and robust designs:\nfile-based, task-list based, and bulk-synchronous. Comparing to existing\nmethods shows unique benefits of this work, including simplicity of design,\nsuitability for HPC centers, short startup time, and well-understood per-task\noverhead. All three new tools have been shown to scale to full utilization of\nSummit, and have been made publicly available with tests and documentation.\nThis work presents a complete characterization of the minimum effective task\ngranularity for efficient scheduler usage scenarios. These schedulers have the\nsame bottlenecks, and hence similar task granularities as those reported for\nexisting tools following comparable paradigms.",
    "descriptor": "\nComments: 11 pages, 5 figures, 4 tables\n",
    "authors": [
      "David M. Rogers"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.11461"
  },
  {
    "id": "arXiv:2110.11462",
    "title": "A Fresh Look at the Architecture and Performance of Contemporary  Isolation Platforms",
    "abstract": "With the ever-increasing pervasiveness of the cloud computing paradigm,\nstrong isolation guarantees and low performance overhead from isolation\nplatforms are paramount. An ideal isolation platform offers both: an\nimpermeable isolation boundary while imposing a negligible performance\noverhead. In this paper, we examine various isolation platforms (containers,\nsecure containers, hypervisors, unikernels), and conduct a wide array of\nexperiments to measure the performance overhead and degree of isolation offered\nby the platforms. We find that container platforms have the best, near-native,\nperformance while the newly emerging secure containers suffer from various\noverheads. The highest degree of isolation is achieved by unikernels, closely\nfollowed by traditional containers.",
    "descriptor": "",
    "authors": [
      "Vincent van Rijn",
      "Jan S. Rellermeyer"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.11462"
  },
  {
    "id": "arXiv:2110.11464",
    "title": "FDGATII : Fast Dynamic Graph Attention with Initial Residual and  Identity Mapping",
    "abstract": "While Graph Neural Networks have gained popularity in multiple domains,\ngraph-structured input remains a major challenge due to (a) over-smoothing, (b)\nnoisy neighbours (heterophily), and (c) the suspended animation problem. To\naddress all these problems simultaneously, we propose a novel graph neural\nnetwork FDGATII, inspired by attention mechanism's ability to focus on\nselective information supplemented with two feature preserving mechanisms.\nFDGATII combines Initial Residuals and Identity Mapping with the more\nexpressive dynamic self-attention to handle noise prevalent from the\nneighbourhoods in heterophilic data sets. By using sparse dynamic attention,\nFDGATII is inherently parallelizable in design, whist efficient in operation;\nthus theoretically able to scale to arbitrary graphs with ease. Our approach\nhas been extensively evaluated on 7 datasets. We show that FDGATII outperforms\nGAT and GCN based benchmarks in accuracy and performance on fully supervised\ntasks, obtaining state-of-the-art results on Chameleon and Cornell datasets\nwith zero domain-specific graph pre-processing, and demonstrate its versatility\nand fairness.",
    "descriptor": "\nComments: 10 pages, 5 figures. arXiv admin note: text overlap with arXiv:2007.02133 by other authors\n",
    "authors": [
      "Gayan K. Kulatilleke",
      "Marius Portmann",
      "Ryan Ko",
      "Shekhar S. Chandra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11464"
  },
  {
    "id": "arXiv:2110.11466",
    "title": "MLPerfTM HPC: A Holistic Benchmark Suite for Scientific Machine Learning  on HPC Systems",
    "abstract": "Scientific communities are increasingly adopting machine learning and deep\nlearning models in their applications to accelerate scientific insights. High\nperformance computing systems are pushing the frontiers of performance with a\nrich diversity of hardware resources and massive scale-out capabilities. There\nis a critical need to understand fair and effective benchmarking of machine\nlearning applications that are representative of real-world scientific use\ncases. MLPerfTM is a community-driven standard to benchmark machine learning\nworkloads, focusing on end-to-end performance metrics. In this paper, we\nintroduce MLPerf HPC, a benchmark suite of largescale scientific machine\nlearning training applications, driven by the MLCommonsTM Association. We\npresent the results from the first submission round including a diverse set of\nsome of the world's largest HPC systems. We develop a systematic framework for\ntheir joint analysis and compare them in terms of data staging, algorithmic\nconvergence, and compute performance. As a result, we gain a quantitative\nunderstanding of optimizations on different subsystems such as staging and\non-node loading of data, compute-unit utilization, and communication scheduling\nenabling overall > 10x (end-to-end) performance improvements through system\nscaling. Notably, our analysis shows a scale-dependent interplay between the\ndataset size, a system's memory hierarchy, and training convergence that\nunderlines the importance of near compute storage. To overcome the\ndata-parallel scalability challenge at large batch sizes, we discuss specific\nlearning techniques and hybrid data-and-model parallelism that are effective on\nlarge systems. We conclude by characterizing each benchmark with respect to\nlow-level memory, I/O, and network behavior to parameterize extended roofline\nperformance models in future rounds.",
    "descriptor": "",
    "authors": [
      "Steven Farrell",
      "Murali Emani",
      "Jacob Balma",
      "Lukas Drescher",
      "Aleksandr Drozd",
      "Andreas Fink",
      "Geoffrey Fox",
      "David Kanter",
      "Thorsten Kurth",
      "Peter Mattson",
      "Dawei Mu",
      "Amit Ruhela",
      "Kento Sato",
      "Koichi Shirahata",
      "Tsuguchika Tabaru",
      "Aristeidis Tsaris",
      "Jan Balewski",
      "Ben Cumming",
      "Takumi Danjo",
      "Jens Domke",
      "Takaaki Fukai",
      "Naoto Fukumoto",
      "Tatsuya Fukushi",
      "Balazs Gerofi",
      "Takumi Honda",
      "Toshiyuki Imamura",
      "Akihiko Kasagi",
      "Kentaro Kawakami",
      "Shuhei Kudo",
      "Akiyoshi Kuroda",
      "Maxime Martinasso",
      "Satoshi Matsuoka",
      "Henrique Mendonc",
      "Kazuki Minami",
      "Prabhat Ram",
      "Takashi Sawada",
      "Mallikarjun Shankar",
      "Tom St. John",
      "Akihiro Tabuchi",
      "Venkatram Vishwanath",
      "Mohamed Wahib",
      "Masafumi Yamazaki",
      "Junqi Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.11466"
  },
  {
    "id": "arXiv:2110.11467",
    "title": "Power Transformer Fault Diagnosis with Intrinsic Time-scale  Decomposition and XGBoost Classifier",
    "abstract": "An intrinsic time-scale decomposition (ITD) based method for power\ntransformer fault diagnosis is proposed. Dissolved gas analysis (DGA)\nparameters are ranked according to their skewness, and then ITD based features\nextraction is performed. An optimal set of PRC features are determined by an\nXGBoost classifier. For classification purpose, an XGBoost classifier is used\nto the optimal PRC features set. The proposed method's performance in\nclassification is studied using publicly available DGA data of 376 power\ntransformers and employing an XGBoost classifier. The Proposed method achieves\nmore than 95% accuracy and high sensitivity and F1-score, better than\nconventional methods and some recent machine learning-based fault diagnosis\napproaches. Moreover, it gives better Cohen Kappa and F1-score as compared to\nthe recently introduced EMD-based hierarchical technique for fault diagnosis in\npower transformers.",
    "descriptor": "\nComments: 09 pages, 3 figures, conference\n",
    "authors": [
      "Shoaib Meraj Sami",
      "Mohammed Imamul Hassan Bhuiyan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.11467"
  },
  {
    "id": "arXiv:2110.11468",
    "title": "To Recommend or Not? A Model-Based Comparison of Item-Matching Processes",
    "abstract": "Recommender systems are central to modern online platforms, but a popular\nconcern is that they may be pulling society in dangerous directions (e.g.,\ntowards filter bubbles). However, a challenge with measuring the effects of\nrecommender systems is how to compare user outcomes under these systems to\noutcomes under a credible counterfactual world without such systems. We take a\nmodel-based approach to this challenge, introducing a dichotomy of process\nmodels that we can compare: (1) a \"recommender\" model describing a generic\nitem-matching process under a personalized recommender system and (2) an\n\"organic\" model describing a baseline counterfactual where users search for\nitems without the mediation of any system. Our key finding is that the\nrecommender and organic models result in dramatically different outcomes at\nboth the individual and societal level, as supported by theorems and simulation\nexperiments with real data. The two process models also induce different\ntrade-offs during inference, where standard performance-improving techniques\nsuch as regularization/shrinkage have divergent effects. Shrinkage improves the\nmean squared error of matches in both settings, as expected, but at the cost of\nless diverse (less radical) items chosen in the recommender model but more\ndiverse (more radical) items chosen in the organic model. These findings\nprovide a formal language for how recommender systems may be fundamentally\naltering how we search for and interact with content, in a world increasingly\nmediated by such systems.",
    "descriptor": "",
    "authors": [
      "Serina Chang",
      "Johan Ugander"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.11468"
  },
  {
    "id": "arXiv:2110.11474",
    "title": "AEI: Actors-Environment Interaction with Adaptive Attention for Temporal  Action Proposals Generation",
    "abstract": "Humans typically perceive the establishment of an action in a video through\nthe interaction between an actor and the surrounding environment. An action\nonly starts when the main actor in the video begins to interact with the\nenvironment, while it ends when the main actor stops the interaction. Despite\nthe great progress in temporal action proposal generation, most existing works\nignore the aforementioned fact and leave their model learning to propose\nactions as a black-box. In this paper, we make an attempt to simulate that\nability of a human by proposing Actor Environment Interaction (AEI) network to\nimprove the video representation for temporal action proposals generation. AEI\ncontains two modules, i.e., perception-based visual representation (PVR) and\nboundary-matching module (BMM). PVR represents each video snippet by taking\nhuman-human relations and humans-environment relations into consideration using\nthe proposed adaptive attention mechanism. Then, the video representation is\ntaken by BMM to generate action proposals. AEI is comprehensively evaluated in\nActivityNet-1.3 and THUMOS-14 datasets, on temporal action proposal and\ndetection tasks, with two boundary-matching architectures (i.e., CNN-based and\nGCN-based) and two classifiers (i.e., Unet and P-GCN). Our AEI robustly\noutperforms the state-of-the-art methods with remarkable performance and\ngeneralization for both temporal action proposal generation and temporal action\ndetection.",
    "descriptor": "\nComments: Accepted in BMVC 2021 (Oral Session)\n",
    "authors": [
      "Khoa Vo",
      "Hyekang Joo",
      "Kashu Yamazaki",
      "Sang Truong",
      "Kris Kitani",
      "Ngan Le"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11474"
  },
  {
    "id": "arXiv:2110.11475",
    "title": "Future of Smart Classroom in the Era of Wearable Neurotechnology",
    "abstract": "Interdisciplinary research among engineering, computer science, and\nneuroscience to understand and utilize the human brain signals resulted in\nadvances and widespread applicability of wearable neurotechnology in adaptive\nhuman-in-the-loop smart systems. Considering these advances, we envision that\nfuture education will exploit the advances in wearable neurotechnology and move\ntoward more personalized smart classrooms where instructions and interactions\nare tailored towards. students' individual strengths and needs. In this paper,\nwe discuss the future of smart classrooms and how advances in neuroscience,\nmachine learning, and embedded systems as key enablers will provide the\ninfrastructure for envisioned smart classrooms and personalized education along\nwith open challenges that are required to be addressed.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Mojtaba Taherisadr",
      "Berken Utku Demirel",
      "Mohammad Abdullah Al Faruque",
      "Salma Elmalaki"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.11475"
  },
  {
    "id": "arXiv:2110.11478",
    "title": "MixNorm: Test-Time Adaptation Through Online Normalization Estimation",
    "abstract": "We present a simple and effective way to estimate the batch-norm statistics\nduring test time, to fast adapt a source model to target test samples. Known as\nTest-Time Adaptation, most prior works studying this task follow two\nassumptions in their evaluation where (1) test samples come together as a large\nbatch, and (2) all from a single test distribution. However, in practice, these\ntwo assumptions may not stand, the reasons for which we propose two new\nevaluation settings where batch sizes are arbitrary and multiple distributions\nare considered. Unlike the previous methods that require a large batch of\nsingle distribution during test time to calculate stable batch-norm statistics,\nour method avoid any dependency on large online batches and is able to estimate\naccurate batch-norm statistics with a single sample. The proposed method\nsignificantly outperforms the State-Of-The-Art in the newly proposed settings\nin Test-Time Adaptation Task, and also demonstrates improvements in various\nother settings such as Source-Free Unsupervised Domain Adaptation and Zero-Shot\nClassification.",
    "descriptor": "",
    "authors": [
      "Xuefeng Hu",
      "Gokhan Uzunbas",
      "Sirius Chen",
      "Rui Wang",
      "Ashish Shah",
      "Ram Nevatia",
      "Ser-Nam Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11478"
  },
  {
    "id": "arXiv:2110.11482",
    "title": "Aware Adoption of AI: from Potential to Reusable Value",
    "abstract": "Artificial Intelligence (AI) provides practical advantages in different\napplied domains. This is changing the way decision-makers reason about complex\nsystems. Indeed, broader visibility on greater information (re)sources, e.g.\nBig Data, is now available to intelligent agents. On the other hand, decisions\nare not always based on reusable, multi-purpose, and explainable knowledge.\nTherefore, it is necessary to define new models to describe and manage this new\n(re)source of uncertainty.\nThis contribution aims to introduce a multidimensional framework to deal with\nthe notion of Value in the AI context. In this model, Big Data represent a\ndistinguished dimension (characteristic) of Value rather than an intrinsic\nproperty of Big Data. Great attention is paid to hidden dimensions of value,\nwhich may be linked to emerging innovation processes. The requirements to\ndescribe the framework are provided, and an associated mathematical structure\nis presented to deal with comparison, combination, and update of states of\nknowledge regarding Value. We introduce a notion of consistency of a state of\nknowledge to investigate the relation between Human and Artificial\nintelligences; this form of uncertainty is specified in analogy with two\nscenarios concerning decision-making and non-classical measurements. Finally,\nwe propose future investigations aiming at the inclusion of this form of\nuncertainty in the assessment of impact, risks, and structural modelling.",
    "descriptor": "\nComments: 31 pages, 3 figures, comments are welcome!\n",
    "authors": [
      "Mario Angelelli",
      "Massimiliano Gervasi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11482"
  },
  {
    "id": "arXiv:2110.11485",
    "title": "Soft Lattice Modules that Behave Independently and Collectively",
    "abstract": "Natural systems integrate the work of many sub-units (cells) toward a\nlarge-scale unified goal (morphological and behavioral), which can counteract\nthe effects of unexpected experiences, damage, or simply changes in tasks\ndemands. In this paper, we exploit the opportunities presented by soft,\nmodular, and tensegrity robots to introduce soft lattice modules that parallel\nthe sub-units seen in biological systems. The soft lattice modules are\ncomprised of 3D printed plastic \"skeletons\", linear contracting shape memory\nalloy spring actuators, and permanent magnets that enable adhesion between\nmodules. The soft lattice modules are capable of independent locomotion, and\ncan also join with other modules to achieve collective, self-assembled, larger\nscale tasks such as collective locomotion and moving an object across the\nsurface of the lattice assembly. This work represents a preliminary step toward\nsoft modular systems capable of independent and collective behaviors, and\nprovide a platform for future studies on distributed control.",
    "descriptor": "\nComments: 8 pages, 15 figures, submitted to IEEE RA-L & Robosoft 2022\n",
    "authors": [
      "Luyang Zhao",
      "Yijia Wu",
      "Julien Blanchet",
      "Maxine Perroni-Scharf",
      "Xiaonan Huang",
      "Joran Booth",
      "Rebecca Kramer-Bottiglio",
      "Devin Balkcom"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.11485"
  },
  {
    "id": "arXiv:2110.11486",
    "title": "Guess what? You can boost Federated Learning for free",
    "abstract": "Federated Learning (FL) exploits the computation power of edge devices,\ntypically mobile phones, while addressing privacy by letting data stay where it\nis produced. FL has been used by major service providers to improve item\nrecommendations, virtual keyboards and text auto-completion services. While\nappealing, FL performance is hampered by multiple factors: i) differing\ncapabilities of participating clients (e.g., computing power, memory and\nnetwork connectivity); ii) strict training constraints where devices must be\nidle, plugged-in and connected to an unmetered WiFi; and iii) data\nheterogeneity (a.k.a non-IIDness). Together, these lead to uneven\nparticipation, straggling, dropout and consequently slow down convergence,\nchallenging the practicality of FL for many applications.\nIn this paper, we present GeL, the Guess and Learn algorithm, that\nsignificantly speeds up convergence by guessing model updates for each client.\nThe power of GeL is to effectively perform ''free'' learning steps without any\nadditional gradient computations. GeL provides these guesses through clever use\nof moments in the Adam optimizer in combination with the last computed gradient\non clients. Our extensive experimental study involving five standard FL\nbenchmarks shows that GeL speeds up the convergence up to 1.64x in\nheterogeneous systems in the presence of data non-IIDness, saving tens of\nthousands of gradient computations.",
    "descriptor": "\nComments: 11 pages, 6 figures\n",
    "authors": [
      "Akash Dhasade",
      "Anne-Marie Kermarrec",
      "Rafael Pires"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.11486"
  },
  {
    "id": "arXiv:2110.11488",
    "title": "Certificate Root Stores: An Area of Unity or Disparity?",
    "abstract": "Organizations like Apple, Microsoft, Mozilla and Google maintain certificate\nroot stores, which are used as trust anchors by their software platforms. Is\nthere sufficient consensus on their root-store inclusion and trust policies?\nDisparities appear astounding, including in the government-owned certificates\nthat they trust. Such a status-quo is alarming.",
    "descriptor": "",
    "authors": [
      "Jegan Purushothaman",
      "AbdelRahman Abdou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.11488"
  },
  {
    "id": "arXiv:2110.11489",
    "title": "Supporting Massive DLRM Inference Through Software Defined Memory",
    "abstract": "Deep Learning Recommendation Models (DLRM) are widespread, account for a\nconsiderable data center footprint, and grow by more than 1.5x per year. With\nmodel size soon to be in terabytes range, leveraging Storage ClassMemory (SCM)\nfor inference enables lower power consumption and cost. This paper evaluates\nthe major challenges in extending the memory hierarchy to SCM for DLRM, and\npresents different techniques to improve performance through a Software Defined\nMemory. We show how underlying technologies such as Nand Flash and3DXP\ndifferentiate, and relate to real world scenarios, enabling from 5% to 29%\npower savings.",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Ehsan K. Ardestani",
      "Changkyu Kim",
      "Seung Jae Lee",
      "Luoshang Pan",
      "Valmiki Rampersad",
      "Jens Axboe",
      "Banit Agrawal",
      "Fuxun Yu",
      "Ansha Yu",
      "Trung Le",
      "Hector Yuen",
      "Shishir Juluri",
      "Akshat Nanda",
      "Manoj Wodekar",
      "Dheevatsa Mudigere",
      "Krishnakumar Nair",
      "Maxim Naumov",
      "Chris Peterson",
      "Mikhail Smelyanskiy",
      "Vijay Rao"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11489"
  },
  {
    "id": "arXiv:2110.11491",
    "title": "SymbioLCD: Ensemble-Based Loop Closure Detection using CNN-Extracted  Objects and Visual Bag-of-Words",
    "abstract": "Loop closure detection is an essential tool of Simultaneous Localization and\nMapping (SLAM) to minimize drift in its localization. Many state-of-the-art\nloop closure detection (LCD) algorithms use visual Bag-of-Words (vBoW), which\nis robust against partial occlusions in a scene but cannot perceive the\nsemantics or spatial relationships between feature points. CNN object\nextraction can address those issues, by providing semantic labels and spatial\nrelationships between objects in a scene. Previous work has mainly focused on\nreplacing vBoW with CNN-derived features. In this paper, we propose SymbioLCD,\na novel ensemble-based LCD that utilizes both CNN-extracted objects and vBoW\nfeatures for LCD candidate prediction. When used in tandem, the added elements\nof object semantics and spatial-awareness create a more robust and symbiotic\nloop closure detection system. The proposed SymbioLCD uses scale-invariant\nspatial and semantic matching, Hausdorff distance with temporal constraints,\nand a Random Forest that utilizes combined information from both CNN-extracted\nobjects and vBoW features for predicting accurate loop closure candidates.\nEvaluation of the proposed method shows it outperforms other Machine Learning\n(ML) algorithms - such as SVM, Decision Tree and Neural Network, and\ndemonstrates that there is a strong symbiosis between CNN-extracted object\ninformation and vBoW features which assists accurate LCD candidate prediction.\nFurthermore, it is able to perceive loop closure candidates earlier than\nstate-of-the-art SLAM algorithms, utilizing added spatial and semantic\ninformation from CNN-extracted objects.",
    "descriptor": "\nComments: 7 pages. Accepted at 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\n",
    "authors": [
      "Jonathan J.Y. Kim",
      "Martin Urschler",
      "Patricia J. Riddle",
      "J\u00f6rg S. Wicker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.11491"
  },
  {
    "id": "arXiv:2110.11494",
    "title": "Viash: from scripts to pipelines",
    "abstract": "Most bioinformatics pipelines consist of software components that are tightly\ncoupled to the logic of the pipeline itself. This limits reusability of the\nindividual components in the pipeline or introduces maintenance overhead when\nthey need to be reimplemented in multiple pipelines. We introduce Viash, a tool\nfor speeding up development of robust pipelines through \"code-first\"\nprototyping, separation of concerns and code generation of modular pipeline\ncomponents. By decoupling the component functionality from the pipeline logic,\ncomponent functionality becomes fully pipeline-agnostic, and conversely the\nresulting pipelines are agnostic towards specific component requirements. This\nseparation of concerns improves reusability of components and facilitates\nmultidisciplinar and pan-organisational collaborations. It has been applied in\na variety of projects, from proof-of-concept pipelines to supporting an\ninternational data science competition.\nViash is available as an open-source project at\nhttps://github.com/viash-io/viash and documentation is available at\nhttps://viash.io.",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Robrecht Cannoodt",
      "Hendrik Cannoodt",
      "Eric Van de Kerckhove",
      "Andy Boschmans",
      "Dries De Maeyer",
      "Toni Verbeiren"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.11494"
  },
  {
    "id": "arXiv:2110.11497",
    "title": "Optimal Allocation of Virtual Inertia Devices for Enhancing Frequency  Stability in Low-Inertia PowerSystems",
    "abstract": "As renewable resources gradually replace conventional generation based\nsynchronous machines, the dynamics of the modern grid changes significantly and\nthe system synchronous inertia decreases substantially. This transformation\nposes severe challenges for power system stability; for instance, it may lead\nto larger initial rate of change of frequency and increase frequency\nexcursions. However, new opportunities also arise as novelconverter control\ntechniques, so-called grid-forming strategies, show higher efficiency and\nfaster response than conventional synchronous generators. They mainly involve\nvirtual inertia (VI) emulation to mimic the behavior of synchronous machines.\nIn this study, a state-space model for the power system network is developed\nwith VI as a frequency regulation method. A reduced model based-norm algorithm\n(RMHA) considering the Fiedler mode impact is proposed in this paper to\noptimize the allocation of VI devices and improve power system frequency\nstability. Finally, case studies conducted on the IEEE 24-bus system\ndemonstrate the efficacy of the proposed RMHA approach.",
    "descriptor": "",
    "authors": [
      "Mingjian Tuo",
      "Xingpeng Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.11497"
  },
  {
    "id": "arXiv:2110.11498",
    "title": "Security-Constrained Unit Commitment Con-sidering Locational Frequency  Stability in Low-Inertia Power Grids",
    "abstract": "With increasing installation of wind and solar gen-eration, conventional\nsynchronous generators in power systems are gradually displaced resulting in a\nsignificant reduction in system inertia. Maintaining system frequency within\nacceptable ranges becomes more critical for the stability of a power system. In\nthis paper, we first study the impact of inter-area oscillations on the system\nrate-of-change-of-frequency (RoCoF) security; then, the limitations on\nlocational RoCoFs accounting for G-1 contingency stability are derived. By\nenforcing these frequency related constraints, a location based RoCoF\nconstrained security constrained unit commitment (LRC-SCUC) model is proposed.\nFurthermore, an effective piecewise linearization (PWL) tech-nique is employed\nto formulate a RoCoF linearization problem and linearize the nonlinear function\nrepresenting the location based RoCoF constraints in SCUC. Simulation results\nreveal that the inclusion of inertia-related constraints can substantially\nim-prove the system stability at the cost of higher operation cost. The results\nalso show that deploying virtual inertia techniques not only reduces the total\ncost, but also improves the system market efficiency.",
    "descriptor": "",
    "authors": [
      "Mingjian Tuo",
      "Xingpeng Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.11498"
  },
  {
    "id": "arXiv:2110.11499",
    "title": "Wav2CLIP: Learning Robust Audio Representations From CLIP",
    "abstract": "We propose Wav2CLIP, a robust audio representation learning method by\ndistilling from Contrastive Language-Image Pre-training (CLIP). We\nsystematically evaluate Wav2CLIP on a variety of audio tasks including\nclassification, retrieval, and generation, and show that Wav2CLIP can\noutperform several publicly available pre-trained audio representation\nalgorithms. Wav2CLIP projects audio into a shared embedding space with images\nand text, which enables multimodal applications such as zero-shot\nclassification, and cross-modal retrieval. Furthermore, Wav2CLIP needs just\n~10% of the data to achieve competitive performance on downstream tasks\ncompared with fully supervised models, and is more efficient to pre-train than\ncompeting methods as it does not require learning a visual model in concert\nwith an auditory model. Finally, we demonstrate image generation from Wav2CLIP\nas qualitative assessment of the shared embedding space. Our code and model\nweights are open sourced and made available for further applications.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Ho-Hsiang Wu",
      "Prem Seetharaman",
      "Kundan Kumar",
      "Juan Pablo Bello"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.11499"
  },
  {
    "id": "arXiv:2110.11504",
    "title": "Maximum Power Point Tracking Circuit for an Energy Harvester in 130 nm  CMOS Technology",
    "abstract": "This paper presents design of a Maximum Power Point Tracking (MPPT) circuit\nand its functionality for tuning the maximum power transfer from an energy\nharvester (EH) unit. Simple and practical Perturb and Observe algorithm is\ninvestigated and implemented. We describe the circuit functionality and the\nimprovements that have been introduced to the original algorithm. The proposed\nMPPT design is divided into three main blocks. The output signal is being\ngenerated by the PWM or PFM block. The tracking speed has been enhanced by\nimplementing a variable step size in the Tracking Block. Finally, the overall\npower consumption of the MPPT circuit itself is controlled by the Power\nManagement Block, which manages delivering the clock signal to the rest of the\ncircuit. The RTL code of the proposed MPPT has been described in Verilog, then\nhas been synthesized and placed-and-routed in a general purpose 130nm CMOS\ntechnology.",
    "descriptor": "",
    "authors": [
      "Adam Hudec",
      "Lukas Nagy",
      "Martin Kovac",
      "Viera Stopjakova"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.11504"
  },
  {
    "id": "arXiv:2110.11509",
    "title": "Introduction to data assimilation for parameter estimation",
    "abstract": "In this study, two classes of methods including statistical and variational\ndata assimilation algorithms will be described. In statistical methods, the\nmodel state is updated sequentially based on the previous estimate. Variational\nmethods, on the other hand, seek an estimation in space and time by minimizing\na cost function. Both of these methods require estimates of background state\nwhich is the prior information of the system and its error covariances. In\nterms of linear and Gaussian problems, they have the same solution. In the\nfamily of Kalman Filter algorithms, the conventional Kalman Filter (KF) and\nEnsemble Kalman Filter (EnKF) will be implemented. A three-dimension\nvariational method (3D-Var) will be employed to illustrate the variational\napproaches. A simple case of an ordinary differential equation (ODE) is coupled\nto highlight the difference between these algorithms. Namely, a mass-spring\nsystem governed by a second order differential equation will be examined. We\nalso look at the situation where a periodic external force is applied to the\nsystem. Then different data assimilation algorithms will be applied to this\nsystem. Results from the experiments will be analyzed to showcase the\nadvantages and disadvantages of each method.",
    "descriptor": "",
    "authors": [
      "Loc Luong"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.11509"
  },
  {
    "id": "arXiv:2110.11511",
    "title": "Energy-conserving explicit and implicit time integration methods for the  multi-dimensional Hermite-DG discretization of the Vlasov-Maxwell equations",
    "abstract": "We study the conservation properties of the Hermite-discontinuous Galerkin\n(Hermite-DG) approximation of the Vlasov-Maxwell equations. In this\nsemi-discrete formulation, the total mass is preserved independently for every\nplasma species. Further, an energy invariant exists if central numerical fluxes\nare used in the DG approximation of Maxwell's equations, while a dissipative\nterm is present when upwind fluxes are employed. In general, traditional\ntemporal integrators might fail to preserve invariants associated with\nconservation laws (at the continuous or semi-discrete level) during the time\nevolution. Hence, we analyze the capability of explicit and implicit\nRunge-Kutta (RK) temporal integrators to preserve such invariants. Since\nexplicit RK methods can only ensure preservation of linear invariants but do\nnot provide any control on the system energy, we develop a novel class of\nnonlinear explicit RK schemes. The proposed methods can be tuned to preserve\nthe energy invariant at the continuous or semi-discrete level, a distinction\nthat is important when upwind fluxes are used in the discretization of\nMaxwell's equations since upwind provides a numerical source of energy\ndissipation that is not present when central fluxes are used. We prove that the\nproposed methods are able to preserve the energy invariant and to maintain the\nsemi-discrete energy dissipation (if present) according to the discretization\nof Maxwell's equations. An extensive set of numerical experiments corroborates\nthe theoretical findings. It also suggests that maintaining the semi-discrete\nenergy dissipation when upwind fluxes are used leads to an overall better\naccuracy of the method relative to using upwind fluxes while forcing exact\nenergy conservation.",
    "descriptor": "",
    "authors": [
      "Cecilia Pagliantini",
      "Gianmarco Manzini",
      "Oleksandr Koshkarov",
      "Gian Luca Delzanno",
      "Vadim Roytershteyn"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.11511"
  },
  {
    "id": "arXiv:2110.11512",
    "title": "Volumetric Data Fusion of External Depth and Onboard Proximity Data For  Occluded Space Reduction",
    "abstract": "In this work, we present a method for a probabilistic fusion of external\ndepth and onboard proximity data to form a volumetric 3-D map of a robot's\nenvironment. We extend the Octomap framework to update a representation of the\narea around the robot, dependent on each sensor's optimal range of operation.\nAreas otherwise occluded from an external view are sensed with onboard sensors\nto construct a more comprehensive map of a robot's nearby space. Our simulated\nresults show that a more accurate map with less occlusions can be generated by\nfusing external depth and onboard proximity data.",
    "descriptor": "\nComments: 3 pages, 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2021) 4th Workshop on Proximity Perception\n",
    "authors": [
      "Matthew Strong",
      "Caleb Escobedo",
      "Alessandro Roncone"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.11512"
  },
  {
    "id": "arXiv:2110.11514",
    "title": "SYNERGY: Building Task Bots at Scale Using Symbolic Knowledge and  Machine Teaching",
    "abstract": "In this paper we explore the use of symbolic knowledge and machine teaching\nto reduce human data labeling efforts in building neural task bots. We propose\nSYNERGY, a hybrid learning framework where a task bot is developed in two\nsteps: (i) Symbolic knowledge to neural networks: Large amounts of simulated\ndialog sessions are generated based on task-specific symbolic knowledge which\nis represented as a task schema consisting of dialog flows and task-oriented\ndatabases. Then a pre-trained neural dialog model, SOLOIST, is fine-tuned on\nthe simulated dialogs to build a bot for the task. (ii) Neural learning: The\nfine-tuned neural dialog model is continually refined with a handful of real\ntask-specific dialogs via machine teaching, where training samples are\ngenerated by human teachers interacting with the task bot. We validate SYNERGY\non four dialog tasks. Experimental results show that SYNERGY maps task-specific\nknowledge into neural dialog models achieving greater diversity and coverage of\ndialog flows, and continually improves model performance with machine teaching,\nthus demonstrating strong synergistic effects of symbolic knowledge and machine\nteaching.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Baolin Peng",
      "Chunyuan Li",
      "Zhu Zhang",
      "Jinchao Li",
      "Chenguang Zhu",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11514"
  },
  {
    "id": "arXiv:2110.11516",
    "title": "Contact Anticipation for Physical Human-Robot Interaction with Robotic  Manipulators using Onboard Proximity Sensors",
    "abstract": "In this paper, we present a framework that unites obstacle avoidance and\ndeliberate physical interaction for robotic manipulators. As humans and robots\nbegin to coexist in work and household environments, pure collision avoidance\nis insufficient, as human-robot contact is inevitable and, in some situations,\ndesired. Our work enables manipulators to anticipate, detect, and act on\ncontact. To achieve this, we allow limited deviation from the robot's original\ntrajectory through velocity reduction and motion restrictions. Then, if contact\noccurs, a robot can detect it and maneuver based on a novel dynamic contact\nthresholding algorithm. The core contribution of this work is dynamic contact\nthresholding, which allows a manipulator with onboard proximity sensors to\ntrack nearby objects and reduce contact forces in anticipation of a collision.\nOur framework elicits natural behavior during physical human-robot interaction.\nWe evaluate our system on a variety of scenarios using the Franka Emika Panda\nrobot arm; collectively, our results demonstrate that our contribution is not\nonly able to avoid and react on contact, but also anticipate it.",
    "descriptor": "\nComments: 8 pages, 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) pages 7232 - 7239\n",
    "authors": [
      "Caleb Escobedo",
      "Matthew Strong",
      "Mary West",
      "Ander Aramburu",
      "Alessandro Roncone"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.11516"
  },
  {
    "id": "arXiv:2110.11517",
    "title": "Real-Time Ground-Plane Refined LiDAR SLAM",
    "abstract": "SLAM system using only point cloud has been proven successful in recent\nyears. In most of these systems, they extract features for tracking after\nground removal, which causes large variance on the z-axis. Ground actually\nprovides robust information to obtain [t_z, \\theta_{roll}, \\theta_{pitch}]$. In\nthis project, we followed the LeGO-LOAM, a light-weighted real-time SLAM system\nthat extracts and registers ground as an addition to the original LOAM, and we\nproposed a new clustering-based method to refine the planar extraction\nalgorithm for ground such that the system can handle much more noisy or dynamic\nenvironments. We implemented this method and compared it with LeGo-LOAM on our\ncollected data of CMU campus, as well as a collected dataset for ATV\n(All-Terrain Vehicle) for off-road self-driving. Both visualization and\nevaluation results show obvious improvement of our algorithm.",
    "descriptor": "\nComments: This paper is originally for a term project of CMU course 16833 (Robot Localization and Mapping) Spring 2019\n",
    "authors": [
      "Fan Yang",
      "Mengqing Jiang",
      "Chenxi Xu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.11517"
  },
  {
    "id": "arXiv:2110.11518",
    "title": "Challenges and Opportunities in Integrated Space-Terrestrial Internet of  Things",
    "abstract": "Large geographical regions and communities remain uncovered by terrestrial\nnetwork connections. To enable access equality, near-Earth orbit satellites\nwill play a defining role in providing Internet of Things (IoT) connectivity on\na world-wide scale in a flexible and cost-effective manner. This paper presents\nthe opportunities arising from global IoT solutions based on space assets, as\nwell as the key research challenges to be addressed. In particular, we discuss\nexisting space and terrestrial IoT technologies and protocols, and the\nrequirements that they need to meet to successfully materialize satellite IoT\nservices. We also propose a novel network architecture to be used by NB-IoT and\nLoRaWAN technologies for implementing future space-terrestrial integrated IoT\nnetworks.",
    "descriptor": "",
    "authors": [
      "Juan A. Fraire",
      "Oana Iova",
      "Fabrice Valois"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.11518"
  },
  {
    "id": "arXiv:2110.11519",
    "title": "SiliFuzz: Fuzzing CPUs by proxy",
    "abstract": "CPUs are becoming more complex with every generation, at both the logical and\nthe physical levels. This potentially leads to more logic bugs and electrical\ndefects in CPUs being overlooked during testing, which causes data corruption\nor other undesirable effects when these CPUs are used in production. These\never-present problems may also have simply become more evident as more CPUs are\noperated and monitored by large cloud providers.\nIf the RTL (\"source code\") of a CPU were available, we could apply greybox\nfuzzing to the CPU model almost as we do to any other software\n[arXiv:2102.02308]. However our targets are general purpose x86_64 CPUs\nproduced by third parties, where we do not have the RTL design, so in our case\nCPU implementations are opaque. Moreover, we are more interested in electrical\ndefects as opposed to logic bugs.\nWe present SiliFuzz, a work-in-progress system that finds CPU defects by\nfuzzing software proxies, like CPU simulators or disassemblers, and then\nexecuting the accumulated test inputs (known as the corpus) on actual CPUs on a\nlarge scale. The major difference between this work and traditional software\nfuzzing is that a software bug fixed once will be fixed for all installations\nof the software, while for CPU defects we have to test every individual core\nrepeatedly over its lifetime due to wear and tear. In this paper we also\nanalyze four groups of CPU defects that SiliFuzz has uncovered and describe\npatterns shared by other SiliFuzz findings.",
    "descriptor": "",
    "authors": [
      "Kostya Serebryany",
      "Maxim Lifantsev",
      "Konstantin Shtoyk",
      "Doug Kwan",
      "Peter Hochschild"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2110.11519"
  },
  {
    "id": "arXiv:2110.11520",
    "title": "Power Saving Evaluation with Automatic Offloading",
    "abstract": "Heterogeneous hardware other than small-core CPU such as GPU, FPGA, or\nmany-core CPU is increasingly being used. However, heterogeneous hardware usage\npresents high technical skill barriers such as familiarity with CUDA. To\novercome this challenge, I previously proposed environment-adaptive software\nthat enables automatic conversion, automatic configuration, and\nhigh-performance and low-power operation of once-written code, in accordance\nwith the hardware to be placed. I also previously verified performance\nimprovement of automatic GPU and FPGA offloading. In this paper, I verify\nlow-power operation with environment adaptation by evaluating power utilization\nafter automatic offloading. I compare Watt*seconds of existing applications\nafter automatic offloading with the case of CPU-only processing.",
    "descriptor": "\nComments: 7 pages, 5 figures, The 8th IIAE International Conference on Intelligent Systems and Image Processing 2021 (ICISIP 2021), Sep. 2021\n",
    "authors": [
      "Yoji Yamato"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2110.11520"
  },
  {
    "id": "arXiv:2110.11521",
    "title": "High Level Synthesis Implementation of a Three-dimensional Systolic  Array Architecture for Matrix Multiplications on Intel Stratix 10 FPGAs",
    "abstract": "In this paper, we consider the HLS implementation of a three-dimensional\nsystolic array architecture for matrix multiplication that targets specific\ncharacteristics of Intel Stratix 10 FPGAs in order to produce designs that\nachieve a high floating-point throughput using most of the DSPs at high\nfrequencies in a way that avoids the congestion of the routing fabric. The\ninvestigated three-dimensional systolic array architecture is able to produce\nhardware designs that use 99% of the available DSPs with maximum frequencies\nthat let us achieve performances above 3 TFLOPS.",
    "descriptor": "",
    "authors": [
      "Paolo Gorlani",
      "Christian Plessl"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2110.11521"
  },
  {
    "id": "arXiv:2110.11524",
    "title": "Sequential Decision-Making for Active Object Detection from Hand",
    "abstract": "A key component of understanding hand-object interactions is the ability to\nidentify the active object -- the object that is being manipulated by the human\nhand -- despite the occlusion induced by hand-object interactions. Based on the\nobservation that hand appearance is a strong indicator of the location and size\nof the active object, we set up our active object detection method as a\nsequential decision-making process that is conditioned on the location and\nappearance of the hands. The key innovation of our approach is the design of\nthe active object detection policy that uses an internal representation called\nthe Relational Box Field, which allows for every pixel to regress an improved\nlocation of an active object bounding box, essentially giving every pixel the\nability to vote for a better bounding box location. The policy is trained using\na hybrid imitation learning and reinforcement learning approach, and at test\ntime, the policy is used repeatedly to refine the bounding box location of the\nactive object. We perform experiments on two large-scale datasets: 100DOH and\nMECCANO, improving AP50 performance by 8% and 30%, respectively, over the state\nof the art.",
    "descriptor": "\nComments: 12 pages, 10 figures, 5 tables\n",
    "authors": [
      "Qichen Fu",
      "Xingyu Liu",
      "Kris M. Kitani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11524"
  },
  {
    "id": "arXiv:2110.11525",
    "title": "Digital and Physical-World Attacks on Remote Pulse Detection",
    "abstract": "Remote photoplethysmography (rPPG) is a technique for estimating blood volume\nchanges from reflected light without the need for a contact sensor. We present\nthe first examples of presentation attacks in the digital and physical domains\non rPPG from face video. Digital attacks are easily performed by adding\nimperceptible periodic noise to the input videos. Physical attacks are\nperformed with illumination from visible spectrum LEDs placed in close\nproximity to the face, while still being difficult to perceive with the human\neye. We also show that our attacks extend beyond medical applications, since\nthe method can effectively generate a strong periodic pulse on 3D-printed face\nmasks, which presents difficulties for pulse-based face presentation attack\ndetection (PAD). The paper concludes with ideas for using this work to improve\nrobustness of rPPG methods and pulse-based face PAD.",
    "descriptor": "",
    "authors": [
      "Jeremy Speth",
      "Nathan Vance",
      "Patrick Flynn",
      "Kevin W. Bowyer",
      "Adam Czajka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11525"
  },
  {
    "id": "arXiv:2110.11526",
    "title": "Wide Neural Networks Forget Less Catastrophically",
    "abstract": "A growing body of research in continual learning is devoted to overcoming the\n\"Catastrophic Forgetting\" of neural networks by designing new algorithms that\nare more robust to the distribution shifts. While the recent progress in\ncontinual learning literature is encouraging, our understanding of what\nproperties of neural networks contribute to catastrophic forgetting is still\nlimited. To address this, instead of focusing on continual learning algorithms,\nin this work, we focus on the model itself and study the impact of \"width\" of\nthe neural network architecture on catastrophic forgetting, and show that width\nhas a surprisingly significant effect on forgetting. To explain this effect, we\nstudy the learning dynamics of the network from various perspectives such as\ngradient norm and sparsity, orthogonalization, and lazy training regime. We\nprovide potential explanations that are consistent with the empirical results\nacross different architectures and continual learning benchmarks.",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Seyed Iman Mirzadeh",
      "Arslan Chaudhry",
      "Huiyi Hu",
      "Razvan Pascanu",
      "Dilan Gorur",
      "Mehrdad Farajtabar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11526"
  },
  {
    "id": "arXiv:2110.11527",
    "title": "Proceedings Third Workshop on Formal Methods for Autonomous Systems",
    "abstract": "Autonomous systems are highly complex and present unique challenges for the\napplication of formal methods. Autonomous systems act without human\nintervention, and are often embedded in a robotic system, so that they can\ninteract with the real world. As such, they exhibit the properties of\nsafety-critical, cyber-physical, hybrid, and real-time systems.\nThis EPTCS volume contains the proceedings for the third workshop on Formal\nMethods for Autonomous Systems (FMAS 2021), which was held virtually on the\n21st and 22nd of October 2021. Like the previous workshop, FMAS 2021 was an\nonline, stand-alone event, as an adaptation to the ongoing COVID-19\nrestrictions. Despite the challenges this brought, we were determined to build\non the success of the previous two FMAS workshops.\nThe goal of FMAS is to bring together leading researchers who are tackling\nthe unique challenges of autonomous systems using formal methods, to present\nrecent and ongoing work. We are interested in the use of formal methods to\nspecify, model, or verify autonomous and/or robotic systems; in whole or in\npart. We are also interested in successful industrial applications and\npotential future directions for this emerging application of formal methods.",
    "descriptor": "",
    "authors": [
      "Marie Farrell",
      "Matt Luckcuck"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.11527"
  },
  {
    "id": "arXiv:2110.11534",
    "title": "The Optimal Pilot Power Allocation Strategy for Multi-IRS Assisted  Communication Systems",
    "abstract": "Intelligent reflecting surface (IRS) is a promising technology that enables\nthe precise control of the electromagnetic environment in future wireless\ncommunication networks. To leverage the IRS effectively, the acquisition of\nchannel state information (CSI) is crucial in IRS-assisted communication\nsystems, which, however, is challenging. In this paper, we propose the optimal\npilot power allocation strategy for the channel estimation of IRS-assisted\ncommunication systems, which is capable of further improving the achievable\nrate performance with imperfect CSI. More specifically, first of all, we\nintroduce a multi-IRS-assisted communication system in the face of practical\nchannel estimation errors. Furthermore, the ergodic capacity with imperfect CSI\nis derived in an explicit closed-form expression under the single-input\nsingle-output (SISO) consideration. Secondly, we formulate the optimization\nproblem of maximizing the ergodic capacity with imperfect CSI, subject to the\nconstraint of the average uplink pilot power. Thirdly, the method of Lagrange\nmultipliers is invoked to solve the ergodic rate maximizing problem and thus to\nobtain the optimal pilot power allocation strategy. The resultant pilot power\nallocation solution suggests allocating more amount of power to the pilots for\nestimating the weak reflection channels. Besides, we also elaborate on the\nexpense of the proposed pilot power allocation strategy upon analyzing the\npeak-to-average-power ratio (PAPR) increase quantitatively. Finally, the\nextensive simulation results verify our analysis and reveal some interesting\nresults. For example, for the user in the vicinity of a large IRS, it is\nsuggested to switch off other IRSs and only switch on the IRS nearest the user;\nFor the user near a small IRS, it is better to switch on all IRSs and perform\nthe optimal pilot power allocation for enhancing the achievable rate\nperformance.",
    "descriptor": "",
    "authors": [
      "Jiancheng An",
      "Chao Xu",
      "Lu Gan",
      "Chau Yuen",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.11534"
  },
  {
    "id": "arXiv:2110.11536",
    "title": "Neural-guided, Bidirectional Program Search for Abstraction and  Reasoning",
    "abstract": "One of the challenges facing artificial intelligence research today is\ndesigning systems capable of utilizing systematic reasoning to generalize to\nnew tasks. The Abstraction and Reasoning Corpus (ARC) measures such a\ncapability through a set of visual reasoning tasks. In this paper we report\nincremental progress on ARC and lay the foundations for two approaches to\nabstraction and reasoning not based in brute-force search. We first apply an\nexisting program synthesis system called DreamCoder to create symbolic\nabstractions out of tasks solved so far, and show how it enables solving of\nprogressively more challenging ARC tasks. Second, we design a reasoning\nalgorithm motivated by the way humans approach ARC. Our algorithm constructs a\nsearch graph and reasons over this graph structure to discover task solutions.\nMore specifically, we extend existing execution-guided program synthesis\napproaches with deductive reasoning based on function inverse semantics to\nenable a neural-guided bidirectional search algorithm. We demonstrate the\neffectiveness of the algorithm on three domains: ARC, 24-Game tasks, and a\n'double-and-add' arithmetic puzzle.",
    "descriptor": "\nComments: Conference: Complex Networks 2021\n",
    "authors": [
      "Simon Alford",
      "Anshula Gandhi",
      "Akshay Rangamani",
      "Andrzej Banburski",
      "Tony Wang",
      "Sylee Dandekar",
      "John Chin",
      "Tomaso Poggio",
      "Peter Chin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11536"
  },
  {
    "id": "arXiv:2110.11540",
    "title": "Wacky Weights in Learned Sparse Representations and the Revenge of  Score-at-a-Time Query Evaluation",
    "abstract": "Recent advances in retrieval models based on learned sparse representations\ngenerated by transformers have led us to, once again, consider score-at-a-time\nquery evaluation techniques for the top-k retrieval problem. Previous studies\ncomparing document-at-a-time and score-at-a-time approaches have consistently\nfound that the former approach yields lower mean query latency, although the\nlatter approach has more predictable query latency. In our experiments with\nfour different retrieval models that exploit representational learning with\nbags of words, we find that transformers generate \"wacky weights\" that appear\nto greatly reduce the opportunities for skipping and early exiting\noptimizations that lie at the core of standard document-at-a-time techniques.\nAs a result, score-at-a-time approaches appear to be more competitive in terms\nof query evaluation latency than in previous studies. We find that, if an\neffectiveness loss of up to three percent can be tolerated, a score-at-a-time\napproach can yield substantial gains in mean query latency while at the same\ntime dramatically reducing tail latency.",
    "descriptor": "",
    "authors": [
      "Joel Mackenzie",
      "Andrew Trotman",
      "Jimmy Lin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.11540"
  },
  {
    "id": "arXiv:2110.11542",
    "title": "Adverse Media Mining for KYC and ESG Compliance",
    "abstract": "In recent years, institutions operating in the global market economy face\ngrowing risks stemming from non-financial risk factors such as cyber,\nthird-party, and reputational outweighing traditional risks of credit and\nliquidity. Adverse media or negative news screening is crucial for the\nidentification of such non-financial risks. Typical tools for screening are not\nreal-time, involve manual searches, require labor-intensive monitoring of\ninformation sources. Moreover, they are costly processes to maintain up-to-date\nwith complex regulatory requirements and the institution's evolving risk\nappetite.\nIn this extended abstract, we present an automated system to conduct both\nreal-time and batch search of adverse media for users' queries (person or\norganization entities) using news and other open-source, unstructured sources\nof information. Our scalable, machine-learning driven approach to\nhigh-precision, adverse news filtering is based on four perspectives -\nrelevance to risk domains, search query (entity) relevance, adverse sentiment\nanalysis, and risk encoding. With the help of model evaluations and case\nstudies, we summarize the performance of our deployed application.",
    "descriptor": "\nComments: accepted at: Workshop on Machine Learning in Finance, KDD 2020, August 24, 2020, San Diego, CA, USA. this https URL\n",
    "authors": [
      "Rupinder Paul Khandpur",
      "Albert Aristotle Nanda",
      "Mathew Davis",
      "Chen Li",
      "Daulet Nurmanbetov",
      "Sankalp Gaur",
      "Ashit Talukder"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11542"
  },
  {
    "id": "arXiv:2110.11545",
    "title": "Pseudo Supervised Monocular Depth Estimation with Teacher-Student  Network",
    "abstract": "Despite recent improvement of supervised monocular depth estimation, the lack\nof high quality pixel-wise ground truth annotations has become a major hurdle\nfor further progress. In this work, we propose a new unsupervised depth\nestimation method based on pseudo supervision mechanism by training a\nteacher-student network with knowledge distillation. It strategically\nintegrates the advantages of supervised and unsupervised monocular depth\nestimation, as well as unsupervised binocular depth estimation. Specifically,\nthe teacher network takes advantage of the effectiveness of binocular depth\nestimation to produce accurate disparity maps, which are then used as the\npseudo ground truth to train the student network for monocular depth\nestimation. This effectively converts the problem of unsupervised learning to\nsupervised learning. Our extensive experimental results demonstrate that the\nproposed method outperforms the state-of-the-art on the KITTI benchmark.",
    "descriptor": "",
    "authors": [
      "Huan Liu",
      "Junsong Yuan",
      "Chen Wang",
      "Jun Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11545"
  },
  {
    "id": "arXiv:2110.11551",
    "title": "Signature-Graph Networks",
    "abstract": "We propose a novel approach for visual representation learning called\nSignature-Graph Neural Networks (SGN). SGN learns latent global structures that\naugment the feature representation of Convolutional Neural Networks (CNN). SGN\nconstructs unique undirected graphs for each image based on the CNN feature\nmaps. The feature maps are partitioned into a set of equal and non-overlapping\npatches. The graph nodes are located on high-contrast sharp convolution\nfeatures with the local maxima or minima in these patches. The node embeddings\nare aggregated through novel Signature-Graphs based on horizontal and vertical\nedge connections. The representation vectors are then computed based on the\nspectral Laplacian eigenvalues of the graphs. SGN outperforms existing methods\nof recent graph convolutional networks, generative adversarial networks, and\nauto-encoders with image classification accuracy of 99.65% on ASIRRA, 99.91% on\nMNIST, 98.55% on Fashion-MNIST, 96.18% on CIFAR-10, 84.71% on CIFAR-100, 94.36%\non STL10, and 95.86% on SVHN datasets. We also introduce a novel implementation\nof the state-of-the-art multi-head attention (MHA) on top of the proposed SGN.\nAdding SGN to MHA improved the image classification accuracy from 86.92% to\n94.36% on the STL10 dataset",
    "descriptor": "",
    "authors": [
      "Ali Hamdi",
      "Flora Salim",
      "Du Yong Kim",
      "Xiaojun Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11551"
  },
  {
    "id": "arXiv:2110.11552",
    "title": "GCNScheduler: Scheduling Distributed Computing Applications using Graph  Convolutional Networks",
    "abstract": "We consider the classical problem of scheduling task graphs corresponding to\ncomplex applications on distributed computing systems. A number of heuristics\nhave been previously proposed to optimize task scheduling with respect to\nmetrics such as makespan and throughput. However, they tend to be slow to run,\nparticularly for larger problem instances, limiting their applicability in more\ndynamic systems. Motivated by the goal of solving these problems more rapidly,\nwe propose, for the first time, a graph convolutional network-based scheduler\n(GCNScheduler). By carefully integrating an inter-task data dependency\nstructure with network settings into an input graph and feeding it to an\nappropriate GCN, the GCNScheduler can efficiently schedule tasks of complex\napplications for a given objective. We evaluate our scheme with baselines\nthrough simulations. We show that not only can our scheme quickly and\nefficiently learn from existing scheduling schemes, but also it can easily be\napplied to large-scale settings where current scheduling schemes fail to\nhandle. We show that it achieves better makespan than the classic HEFT\nalgorithm, and almost the same throughput as throughput-oriented HEFT\n(TP-HEFT), while providing several orders of magnitude faster scheduling times\nin both cases. For example, for makespan minimization, GCNScheduler schedules\n50-node task graphs in about 4 milliseconds while HEFT takes more than 1500\nseconds; and for throughput maximization, GCNScheduler schedules 100-node task\ngraphs in about 3.3 milliseconds, compared to about 6.9 seconds for TP-HEFT.",
    "descriptor": "",
    "authors": [
      "Mehrdad Kiamari",
      "Bhaskar Krishnamachari"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11552"
  },
  {
    "id": "arXiv:2110.11553",
    "title": "Prototypical Classifier for Robust Class-Imbalanced Learning",
    "abstract": "Deep neural networks have been shown to be very powerful methods for many\nsupervised learning tasks. However, they can also easily overfit to training\nset biases, i.e., label noise and class imbalance. While both learning with\nnoisy labels and class-imbalanced learning have received tremendous attention,\nexisting works mainly focus on one of these two training set biases. To fill\nthe gap, we propose \\textit{Prototypical Classifier}, which does not require\nfitting additional parameters given the embedding network. Unlike conventional\nclassifiers that are biased towards head classes, Prototypical Classifier\nproduces balanced and comparable predictions for all classes even though the\ntraining set is class-imbalanced. By leveraging this appealing property, we can\neasily detect noisy labels by thresholding the confidence scores predicted by\nPrototypical Classifier, where the threshold is dynamically adjusted through\nthe iteration. A sample reweghting strategy is then applied to mitigate the\ninfluence of noisy labels. We test our method on CIFAR-10-LT, CIFAR-100-LT and\nWebvision datasets, observing that Prototypical Classifier obtains substaintial\nimprovements compared with state of the arts.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Tong Wei",
      "Jiang-Xin Shi",
      "Yu-Feng Li",
      "Min-Ling Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11553"
  },
  {
    "id": "arXiv:2110.11560",
    "title": "Adaptive Bridge between Training and Inference for Dialogue",
    "abstract": "Although exposure bias has been widely studied in some NLP tasks, it faces\nits unique challenges in dialogue response generation, the representative\none-to-various generation scenario. In real human dialogue, there are many\nappropriate responses for the same context, not only with different\nexpressions, but also with different topics. Therefore, due to the much bigger\ngap between various ground-truth responses and the generated synthetic\nresponse, exposure bias is more challenging in dialogue generation task. What's\nmore, as MLE encourages the model to only learn the common words among\ndifferent ground-truth responses, but ignores the interesting and specific\nparts, exposure bias may further lead to the common response generation\nproblem, such as \"I don't know\" and \"HaHa?\" In this paper, we propose a novel\nadaptive switching mechanism, which learns to automatically transit between\nground-truth learning and generated learning regarding the word-level matching\nscore, such as the cosine similarity. Experimental results on both Chinese STC\ndataset and English Reddit dataset, show that our adaptive method achieves a\nsignificant improvement in terms of metric-based evaluation and human\nevaluation, as compared with the state-of-the-art exposure bias approaches.\nFurther analysis on NMT task also shows that our model can achieve a\nsignificant improvement.",
    "descriptor": "\nComments: EMNLP2021\n",
    "authors": [
      "Haoran Xu",
      "Hainan Zhang",
      "Yanyan Zou",
      "Hongshen Chen",
      "Zhuoye Ding",
      "Yanyan Lan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.11560"
  },
  {
    "id": "arXiv:2110.11567",
    "title": "Logical Assessment Formula and its Principles for Evaluations without  Accurate Ground-Truth Labels",
    "abstract": "Logical assessment formula (LAF) was proposed for evaluations without\naccurate ground-truth labels (AGTL). In this paper, we reveal the principles of\nLAF via comprehensive theoretical analyses. From the revealed principles, we\nsummarize the practicability of LAF: 1) LAF can be reasonably applied for\nevaluations without AGTL on a more difficult task, just acting like usual\nstrategies for evaluations with AGTL; 2) LAF can be applied for evaluations\nwithout AGTL from the logical perspective on an easier task, unable to be\nacting like usual strategies for evaluations with AGTL. Experimental results\nand analyses of LAF applied on tumour segmentation for breast cancer support\nthe practicability of LAF summarized from the revealed principles.",
    "descriptor": "\nComments: 35 pages\n",
    "authors": [
      "Yongquan Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11567"
  },
  {
    "id": "arXiv:2110.11570",
    "title": "MIC: Model-agnostic Integrated Cross-channel Recommenders",
    "abstract": "Semantically connecting users and items is a fundamental problem for the\nmatching stage of an industrial recommender system. Recent advances in this\ntopic are based on multi-channel retrieval to efficiently measure users'\ninterest on items from the massive candidate pool. However, existing work are\nprimarily built upon pre-defined retrieval channels, including User-CF (U2U),\nItem-CF (I2I), and Embedding-based Retrieval (U2I), thus access to the limited\ncorrelation between users and items which solely entail from partial\ninformation of latent interactions. In this paper, we propose a model-agnostic\nintegrated cross-channel (MIC) approach for the large-scale recommendation,\nwhich maximally leverages the inherent multi-channel mutual information to\nenhance the matching performance. Specifically, MIC robustly models correlation\nwithin user-item, user-user, and item-item from latent interactions in a\nuniversal schema. For each channel, MIC naturally aligns pairs with semantic\nsimilarity and distinguishes them otherwise with more uniform anisotropic\nrepresentation space. While state-of-the-art methods require specific\narchitectural design, MIC intuitively considers them as a whole by enabling the\ncomplete information flow among users and items. Thus MIC can be easily plugged\ninto other retrieval recommender systems. Extensive experiments show that our\nMIC helps several state-of-the-art models boost their performance on two\nreal-world benchmarks. The satisfactory deployment of the proposed MIC on\nindustrial online services empirically proves its scalability and flexibility.",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Yujie Lu",
      "Ping Nie",
      "Ming Zhao",
      "Ruobing Xie",
      "William Yang Wang",
      "Yi Ren"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.11570"
  },
  {
    "id": "arXiv:2110.11571",
    "title": "Anti-Backdoor Learning: Training Clean Models on Poisoned Data",
    "abstract": "Backdoor attack has emerged as a major security threat to deep neural\nnetworks (DNNs). While existing defense methods have demonstrated promising\nresults on detecting and erasing backdoor triggers, it is still not clear if\nmeasures can be taken to avoid the triggers from being learned into the model\nin the first place. In this paper, we introduce the concept of\n\\emph{anti-backdoor learning}, of which the aim is to train clean models on\nbackdoor-poisoned data. We frame the overall learning process as a dual-task of\nlearning the clean portion of data and learning the backdoor portion of data.\nFrom this view, we identify two inherent characteristics of backdoor attacks as\ntheir weaknesses: 1) the models learn backdoored data at a much faster rate\nthan learning clean data, and the stronger the attack the faster the model\nconverges on backdoored data; and 2) the backdoor task is tied to a specific\nclass (the backdoor target class). Based on these two weaknesses, we propose a\ngeneral learning scheme, Anti-Backdoor Learning (ABL), to automatically prevent\nbackdoor attacks during training. ABL introduces a two-stage \\emph{gradient\nascent} mechanism into standard training to 1) help isolate backdoor examples\nat an early training stage, and 2) break the correlation between backdoor\nexamples and the target class at a later training stage. Through extensive\nexperiments on multiple benchmark datasets against 10 state-of-the-art attacks,\nwe empirically show that ABL-trained models on backdoor-poisoned data achieve\nthe same performance as they were trained on purely clean data. Code is\navailable at \\underline{https://github.com/bboylyg/ABL}.",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Yige Li",
      "Xixiang Lyu",
      "Nodens Koren",
      "Lingjuan Lyu",
      "Bo Li",
      "Xingjun Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11571"
  },
  {
    "id": "arXiv:2110.11572",
    "title": "Reinforcement Learning for Process Control with Application in  Semiconductor Manufacturing",
    "abstract": "Process control is widely discussed in the manufacturing process, especially\nfor semiconductor manufacturing. Due to unavoidable disturbances in\nmanufacturing, different process controllers are proposed to realize variation\nreduction. Since reinforcement learning (RL) has shown great advantages in\nlearning actions from interactions with a dynamic system, we introduce RL\nmethods for process control and propose a new controller called RL-based\ncontroller. Considering the fact that most existing process controllers mainly\nrely on a linear model assumption for the process input-output relationship, we\nfirst propose theoretical properties of RL-based controllers according to the\nlinear model assumption. Then the performance of RL-based controllers and\ntraditional process controllers (e.g., exponentially weighted moving average\n(EWMA), general harmonic rule (GHR) controllers) are compared for linear\nprocesses. Furthermore, we find that the RL-based controllers have potential\nadvantages to deal with other complicated nonlinear processes that are with and\nwithout assumed explicit model formulations. The intensive numerical studies\nvalidate the advantages of the proposed RL-based controllers.",
    "descriptor": "\nComments: 29 pages,9 figures, and 2 Tables\n",
    "authors": [
      "Yanrong Li",
      "Juan Du",
      "Wei Jiang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.11572"
  },
  {
    "id": "arXiv:2110.11573",
    "title": "ModEL: A Modularized End-to-end Reinforcement Learning Framework for  Autonomous Driving",
    "abstract": "Heated debates continue over the best autonomous driving framework. The\nclassic modular pipeline is widely adopted in the industry owing to its great\ninterpretability and stability, whereas the end-to-end paradigm has\ndemonstrated considerable simplicity and learnability along with the rise of\ndeep learning. We introduce a new modularized end-to-end reinforcement learning\nframework (ModEL) for autonomous driving, which combines the merits of both\nprevious approaches. The autonomous driving stack of ModEL is decomposed into\nperception, planning, and control module, leveraging scene understanding,\nend-to-end reinforcement learning, and PID control respectively. Furthermore,\nwe build a fully functional autonomous vehicle to deploy this framework.\nThrough extensive simulation and real-world experiments, our framework has\nshown great generalizability to various complicated scenarios and outperforms\nthe competing baselines.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Guan Wang",
      "Haoyi Niu",
      "Desheng Zhu",
      "Jianming Hu",
      "Xianyuan Zhan",
      "Guyue Zhou"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11573"
  },
  {
    "id": "arXiv:2110.11574",
    "title": "Linear-Equation Ordered-Statistics Decoding",
    "abstract": "In this paper, we propose a new linear-equation ordered-statistics decoding\n(LE-OSD). Unlike the OSD, LE-OSD uses high reliable parity bits rather than\ninformation bits to recover the codeword estimates, which is equivalent to\nsolving a system of linear equations (SLE). Only test error patterns (TEPs)\nthat create feasible SLEs, referred to as the valid TEPs, are used to obtain\ndifferent codeword estimates. We introduce several constraints on the Hamming\nweight of TEPs to limit the overall decoding complexity. Furthermore, we\nanalyze the block error rate (BLER) and the computational complexity of the\nproposed approach. It is shown that LE-OSD has a similar performance as OSD in\nterms of BLER, which can asymptotically approach Maximum-likelihood (ML)\nperformance with proper parameter selections. Simulation results demonstrate\nthat the LE-OSD has a significantly reduced complexity compared to OSD,\nespecially for low-rate codes, that usually require high decoding order in OSD.\nNevertheless, the complexity reduction can also be observed for high-rate\ncodes. In addition, we further improve LE-OSD by applying the decoding stopping\ncondition and the TEP discarding condition. As shown by simulations, the\nimproved LE-OSD has a considerably reduced complexity while maintaining the\nBLER performance, compared to the latest OSD approach from literature.",
    "descriptor": "\nComments: 32 Pages, 5 figures\n",
    "authors": [
      "Chentao Yue",
      "Mahyar Shirvanimoghaddam",
      "Giyoon Park",
      "Ok-Sun Park",
      "Branka Vucetic",
      "Yonghui Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.11574"
  },
  {
    "id": "arXiv:2110.11575",
    "title": "Methodology for Assessing the State of the Practice for Domain X",
    "abstract": "To improve software development methods and tools for research software, we\nfirst need to understand the current state of the practice. Therefore, we have\ndeveloped a methodology for assessing the state of the software development\npractices for a given research software domain. For each domain we wish to\nanswer questions such as: i) What artifacts (documents, code, test cases, etc.)\nare present? ii) What tools are used? iii) What principles, process and\nmethodologies are used? iv) What are the pain points for developers? v) What\nactions are used to improve qualities like maintainability and reproducibility?\nTo answer these questions, our methodology prescribes the following steps: i)\nIdentify the domain; ii) Identify a list of candidate software packages; iii)\nFilter the list to a length of about 30 packages; iv) Gather source code and\ndocumentation for each package; v) Collect repository related data on each\nsoftware package, like number of stars, number of open issues, number of lines\nof code; vi) Fill in the measurement template (the template consists of 108\nquestions to assess 9 qualities (including the qualities of installability,\nusability and visibility)); vii) Interview developers (the interview consists\nof 20 questions and takes about an hour); viii) Rank the software using the\nAnalytic Hierarchy Process (AHP); and, ix) Analyze the data to answer the\nquestions posed above. A domain expert should be engaged throughout the\nprocess, to ensure that implicit information about the domain is properly\nrepresented and to assist with conducting an analysis of the commonalities and\nvariabilities between the 30 selected packages. Using our methodology,\nspreadsheet templates and AHP tool, we estimate (based on our experience with\nusing the process) the time to complete an assessment for a given domain at 173\nperson hours.",
    "descriptor": "\nComments: 35 pages, 3 figures\n",
    "authors": [
      "Spencer Smith",
      "Jacques Carette",
      "Peter Michalski",
      "Ao Dong",
      "Olu Owojaiye"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.11575"
  },
  {
    "id": "arXiv:2110.11577",
    "title": "Investigating Exit Choice in Built Environment Evacuation combining  Immersive Virtual Reality and Discrete Choice Modelling",
    "abstract": "In the event of a fire emergency in the built environment, occupants face a\nrange of evacuation decisions, including the choice of exits. An important\nquestion from the standpoint of evacuation safety is how evacuees make these\nchoices and what factors affect their choices. Understanding how humans weigh\nthese (often) competing factors is essential knowledge for evacuation planning\nand safe design. Here, we use immersive Virtual Reality (VR) experiments to\ninvestigate, in controlled settings, how these trade-offs are made using\nempirical data and econometric choice models. In each VR scenario, participants\nare confronted with trade-offs between choosing exits that are familiar to\nthem, exits that are less occupied, exits that are nearer to them and exits to\nwhich visibility is less affected by fire smoke. The marginal role of these\ncompeting factors on their decisions is quantified in a discrete choice model.\nPost-experiment questionnaires also determine factors such as their perceived\nrealism and emotion evoked by the VR evacuation experience. Results indicate\nthat none of the investigated factors dominated the others in terms of their\ninfluence on exit choices. The participants exhibited patterns of\nmulti-attribute conjoint decision-making, consistent with the recent findings\nin the literature. While lack of familiarity and the presence of smoke both\nnegatively affected the desirability of an exit to evacuees, neither solely\ndetermined exit choice. It was also observed that prioritisation of the said\nfactors by participants changed during the repeated scenarios when compared to\nthe first scenario that they experienced. Results have implications for both\nfire safety designs and future VR evacuation experiment designs. These\nempirical models can also be employed as input in computer simulations of\nbuilding evacuation.",
    "descriptor": "",
    "authors": [
      "R Lovreglio",
      "E Dillies",
      "E Kuligowski",
      "A Rahouti",
      "M Haghani"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.11577"
  },
  {
    "id": "arXiv:2110.11578",
    "title": "PRECAD: Privacy-Preserving and Robust Federated Learning via  Crypto-Aided Differential Privacy",
    "abstract": "Federated Learning (FL) allows multiple participating clients to train\nmachine learning models collaboratively by keeping their datasets local and\nonly exchanging model updates. Existing FL protocol designs have been shown to\nbe vulnerable to attacks that aim to compromise data privacy and/or model\nrobustness. Recently proposed defenses focused on ensuring either privacy or\nrobustness, but not both. In this paper, we develop a framework called PRECAD,\nwhich simultaneously achieves differential privacy (DP) and enhances robustness\nagainst model poisoning attacks with the help of cryptography. Using secure\nmulti-party computation (MPC) techniques (e.g., secret sharing), noise is added\nto the model updates by the honest-but-curious server(s) (instead of each\nclient) without revealing clients' inputs, which achieves the benefit of\ncentralized DP in terms of providing a better privacy-utility tradeoff than\nlocal DP based solutions. Meanwhile, a crypto-aided secure validation protocol\nis designed to verify that the contribution of model update from each client is\nbounded without leaking privacy. We show analytically that the noise added to\nensure DP also provides enhanced robustness against malicious model\nsubmissions. We experimentally demonstrate that our PRECAD framework achieves\nhigher privacy-utility tradeoff and enhances robustness for the trained models.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2012.06337 by other authors\n",
    "authors": [
      "Xiaolan Gu",
      "Ming Li",
      "Li Xiong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11578"
  },
  {
    "id": "arXiv:2110.11579",
    "title": "How to Schedule Near-Optimally under Real-World Constraints",
    "abstract": "Scheduling is a critical part of practical computer systems, and scheduling\nhas also been extensively studied from a theoretical perspective.\nUnfortunately, there is a gap between theory and practice, as the optimal\nscheduling policies presented by theory can be difficult or impossible to\nperfectly implement in practice. In this work, we use recent breakthroughs in\nqueueing theory to begin to bridge this gap. We show how to translate\ntheoretically optimal policies -- which provably minimize mean response time\n(a.k.a. latency) -- into near-optimal policies that are easily implemented in\npractical settings. Specifically, we handle the following real-world\nconstraints:\n- We show how to schedule in systems where job sizes (a.k.a. running time)\nare unknown, or only partially known. We do so using simple policies that\nachieve performance very close to the much more complicated theoretically\noptimal policies.\n- We show how to schedule in systems that have only a limited number of\npriority levels available. We show how to adapt theoretically optimal policies\nto this constrained setting and determine how many levels we need for\nnear-optimal performance.\n- We show how to schedule in systems where job preemption can only happen at\nspecific checkpoints. Adding checkpoints allows for smarter scheduling, but\neach checkpoint incurs time overhead. We give a rule of thumb that\nnear-optimally balances this tradeoff.",
    "descriptor": "",
    "authors": [
      "Ziv Scully",
      "Mor Harchol-Balter"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2110.11579"
  },
  {
    "id": "arXiv:2110.11583",
    "title": "EvoGAN: An Evolutionary Computation Assisted GAN",
    "abstract": "The image synthesis technique is relatively well established which can\ngenerate facial images that are indistinguishable even by human beings.\nHowever, all of these approaches uses gradients to condition the output,\nresulting in the outputting the same image with the same input. Also, they can\nonly generate images with basic expression or mimic an expression instead of\ngenerating compound expression. In real life, however, human expressions are of\ngreat diversity and complexity. In this paper, we propose an evolutionary\nalgorithm (EA) assisted GAN, named EvoGAN, to generate various compound\nexpressions with any accurate target compound expression. EvoGAN uses an EA to\nsearch target results in the data distribution learned by GAN. Specifically, we\nuse the Facial Action Coding System (FACS) as the encoding of an EA and use a\npre-trained GAN to generate human facial images, and then use a pre-trained\nclassifier to recognize the expression composition of the synthesized images as\nthe fitness function to guide the search of the EA. Combined random searching\nalgorithm, various images with the target expression can be easily sythesized.\nQuantitative and Qualitative results are presented on several compound\nexpressions, and the experimental results demonstrate the feasibility and the\npotential of EvoGAN.",
    "descriptor": "\nComments: 20 pages, 9 figures, 1 table\n",
    "authors": [
      "Feng Liu",
      "HanYang Wang",
      "Jiahao Zhang",
      "Ziwang Fu",
      "Aimin Zhou",
      "Jiayin Qi",
      "Zhibin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.11583"
  },
  {
    "id": "arXiv:2110.11584",
    "title": "Multiwave COVID-19 Prediction via Social Awareness-Based Graph Neural  Networks using Mobility and Web Search Data",
    "abstract": "Recurring outbreaks of COVID-19 have posed enduring effects on global\nsociety, which calls for a predictor of pandemic waves using various data with\nearly availability. Existing prediction models that forecast the first outbreak\nwave using mobility data may not be applicable to the multiwave prediction,\nbecause the evidence in the USA and Japan has shown that mobility patterns\nacross different waves exhibit varying relationships with fluctuations in\ninfection cases. Therefore, to predict the multiwave pandemic, we propose a\nSocial Awareness-Based Graph Neural Network (SAB-GNN) that considers the decay\nof symptom-related web search frequency to capture the changes in public\nawareness across multiple waves. SAB-GNN combines GNN and LSTM to model the\ncomplex relationships among urban districts, inter-district mobility patterns,\nweb search history, and future COVID-19 infections. We train our model to\npredict future pandemic outbreaks in the Tokyo area using its mobility and web\nsearch data from April 2020 to May 2021 across four pandemic waves collected by\n_ANONYMOUS_COMPANY_ under strict privacy protection rules. Results show our\nmodel outperforms other baselines including ST-GNN and MPNN+LSTM. Though our\nmodel is not computationally expensive (only 3 layers and 10 hidden neurons),\nthe proposed model enables public agencies to anticipate and prepare for future\npandemic outbreaks.",
    "descriptor": "",
    "authors": [
      "J. Xue",
      "T. Yabe",
      "K. Tsubouchi",
      "J. Ma",
      "S. V. Ukkusuri"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11584"
  },
  {
    "id": "arXiv:2110.11586",
    "title": "Wide and Narrow: Video Prediction from Context and Motion",
    "abstract": "Video prediction, forecasting the future frames from a sequence of input\nframes, is a challenging task since the view changes are influenced by various\nfactors, such as the global context surrounding the scene and local motion\ndynamics. In this paper, we propose a new framework to integrate these\ncomplementary attributes to predict complex pixel dynamics through deep\nnetworks. We present global context propagation networks that iteratively\naggregate the non-local neighboring representations to preserve the contextual\ninformation over the past frames. To capture the local motion pattern of\nobjects, we also devise local filter memory networks that generate adaptive\nfilter kernels by storing the prototypical motion of moving objects in the\nmemory. The proposed framework, utilizing the outputs from both networks, can\naddress blurry predictions and color distortion. We conduct experiments on\nCaltech pedestrian and UCF101 datasets, and demonstrate state-of-the-art\nresults. Especially for multi-step prediction, we obtain an outstanding\nperformance in quantitative and qualitative evaluation.",
    "descriptor": "\nComments: British Machine Vision Conference 2021\n",
    "authors": [
      "Jaehoon Cho",
      "Jiyoung Lee",
      "Changjae Oh",
      "Wonil Song",
      "Kwanghoon Sohn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11586"
  },
  {
    "id": "arXiv:2110.11589",
    "title": "Text Counterfactuals via Latent Optimization and Shapley-Guided Search",
    "abstract": "We study the problem of generating counterfactual text for a classifier as a\nmeans for understanding and debugging classification. Given a textual input and\na classification model, we aim to minimally alter the text to change the\nmodel's prediction. White-box approaches have been successfully applied to\nsimilar problems in vision where one can directly optimize the continuous\ninput. Optimization-based approaches become difficult in the language domain\ndue to the discrete nature of text. We bypass this issue by directly optimizing\nin the latent space and leveraging a language model to generate candidate\nmodifications from optimized latent representations. We additionally use\nShapley values to estimate the combinatoric effect of multiple changes. We then\nuse these estimates to guide a beam search for the final counterfactual text.\nWe achieve favorable performance compared to recent white-box and black-box\nbaselines using human and automatic evaluations. Ablation studies show that\nboth latent optimization and the use of Shapley values improve success rate and\nthe quality of the generated counterfactuals.",
    "descriptor": "\nComments: 9 pages, 2 figures, 3 tables. Accepted at EMNLP 2021\n",
    "authors": [
      "Quintin Pope",
      "Xiaoli Z. Fern"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.11589"
  },
  {
    "id": "arXiv:2110.11590",
    "title": "DIML/CVL RGB-D Dataset: 2M RGB-D Images of Natural Indoor and Outdoor  Scenes",
    "abstract": "This manual is intended to provide a detailed description of the DIML/CVL\nRGB-D dataset. This dataset is comprised of 2M color images and their\ncorresponding depth maps from a great variety of natural indoor and outdoor\nscenes. The indoor dataset was constructed using the Microsoft Kinect v2, while\nthe outdoor dataset was built using the stereo cameras (ZED stereo camera and\nbuilt-in stereo camera). Table I summarizes the details of our dataset,\nincluding acquisition, processing, format, and toolbox. Refer to Section II and\nIII for more details.",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Jaehoon Cho",
      "Dongbo Min",
      "Youngjung Kim",
      "Kwanghoon Sohn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11590"
  },
  {
    "id": "arXiv:2110.11592",
    "title": "Learning Text-Image Joint Embedding for Efficient Cross-Modal Retrieval  with Deep Feature Engineering",
    "abstract": "This paper introduces a two-phase deep feature engineering framework for\nefficient learning of semantics enhanced joint embedding, which clearly\nseparates the deep feature engineering in data preprocessing from training the\ntext-image joint embedding model. We use the Recipe1M dataset for the technical\ndescription and empirical validation. In preprocessing, we perform deep feature\nengineering by combining deep feature engineering with semantic context\nfeatures derived from raw text-image input data. We leverage LSTM to identify\nkey terms, deep NLP models from the BERT family, TextRank, or TF-IDF to produce\nranking scores for key terms before generating the vector representation for\neach key term by using word2vec. We leverage wideResNet50 and word2vec to\nextract and encode the image category semantics of food images to help semantic\nalignment of the learned recipe and image embeddings in the joint latent space.\nIn joint embedding learning, we perform deep feature engineering by optimizing\nthe batch-hard triplet loss function with soft-margin and double negative\nsampling, taking into account also the category-based alignment loss and\ndiscriminator-based alignment loss. Extensive experiments demonstrate that our\nSEJE approach with deep feature engineering significantly outperforms the\nstate-of-the-art approaches.",
    "descriptor": "\nComments: accepted by ACM Transactions on Information Systems(TOIS). arXiv admin note: text overlap with arXiv:2108.00705, arXiv:2108.03788\n",
    "authors": [
      "Zhongwei Xie",
      "Ling Liu",
      "Yanzhao Wu",
      "Luo Zhong",
      "Lin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.11592"
  },
  {
    "id": "arXiv:2110.11593",
    "title": "Automatic Detection of Injection and Press Mold Parts on 2D Drawing  Using Deep Neural Network",
    "abstract": "This paper proposes a method to automatically detect the key feature parts in\na CAD of commercial TV and monitor using a deep neural network. We developed a\ndeep learning pipeline that can detect the injection parts such as hook, boss,\nundercut and press parts such as DPS, Embo-Screwless, Embo-Burring, and EMBO in\nthe 2D CAD drawing images. We first cropped the drawing to a specific size for\nthe training efficiency of a deep neural network. Then, we use Cascade R-CNN to\nfind the position of injection and press parts and use Resnet-50 to predict the\norientation of the parts. Finally, we convert the position of the parts found\nthrough the cropped image to the position of the original image. As a result,\nwe obtained detection accuracy of injection and press parts with 84.1% in AP\n(Average Precision), 91.2% in AR(Average Recall), 72.0% in AP, 87.0% in AR, and\norientation accuracy of injection and press parts with 94.4% and 92.0%, which\ncan facilitate the faster design in industrial product design.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Junseok Lee",
      "Jongwon Kim",
      "Jumi Park",
      "Seunghyeok Back",
      "Seongho Bak",
      "Kyoobin Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11593"
  },
  {
    "id": "arXiv:2110.11597",
    "title": "ProtoShotXAI: Using Prototypical Few-Shot Architecture for Explainable  AI",
    "abstract": "Unexplainable black-box models create scenarios where anomalies cause\ndeleterious responses, thus creating unacceptable risks. These risks have\nmotivated the field of eXplainable Artificial Intelligence (XAI) to improve\ntrust by evaluating local interpretability in black-box neural networks.\nUnfortunately, the ground truth is unavailable for the model's decision, so\nevaluation is limited to qualitative assessment. Further, interpretability may\nlead to inaccurate conclusions about the model or a false sense of trust. We\npropose to improve XAI from the vantage point of the user's trust by exploring\na black-box model's latent feature space. We present an approach, ProtoShotXAI,\nthat uses a Prototypical few-shot network to explore the contrastive manifold\nbetween nonlinear features of different classes. A user explores the manifold\nby perturbing the input features of a query sample and recording the response\nfor a subset of exemplars from any class. Our approach is the first locally\ninterpretable XAI model that can be extended to, and demonstrated on, few-shot\nnetworks. We compare ProtoShotXAI to the state-of-the-art XAI approaches on\nMNIST, Omniglot, and ImageNet to demonstrate, both quantitatively and\nqualitatively, that ProtoShotXAI provides more flexibility for model\nexploration. Finally, ProtoShotXAI also demonstrates novel explainabilty and\ndetectabilty on adversarial samples.",
    "descriptor": "\nComments: 30 pages, 8 figures\n",
    "authors": [
      "Samuel Hess",
      "Gregory Ditzler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11597"
  },
  {
    "id": "arXiv:2110.11599",
    "title": "High Fidelity 3D Reconstructions with Limited Physical Views",
    "abstract": "Multi-view triangulation is the gold standard for 3D reconstruction from 2D\ncorrespondences given known calibration and sufficient views. However in\npractice, expensive multi-view setups -- involving tens sometimes hundreds of\ncameras -- are required in order to obtain the high fidelity 3D reconstructions\nnecessary for many modern applications. In this paper we present a novel\napproach that leverages recent advances in 2D-3D lifting using neural shape\npriors while also enforcing multi-view equivariance. We show how our method can\nachieve comparable fidelity to expensive calibrated multi-view rigs using a\nlimited (2-3) number of uncalibrated camera views.",
    "descriptor": "\nComments: Accepted to 3DV 2021 (project page & code: this https URL)\n",
    "authors": [
      "Mosam Dabhi",
      "Chaoyang Wang",
      "Kunal Saluja",
      "Laszlo Jeni",
      "Ian Fasel",
      "Simon Lucey"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.11599"
  },
  {
    "id": "arXiv:2110.11601",
    "title": "Multimodal Semi-Supervised Learning for3D Objects",
    "abstract": "In recent years, semi-supervised learning has been widely explored and shows\nexcellent data efficiency for 2D data. There is an emerging need to improve\ndata efficiency for 3D tasks due to the scarcity of labeled 3D data. This paper\nexplores how the coherence of different modelities of 3D data (e.g. point\ncloud, image, and mesh) can be used to improve data efficiency for both 3D\nclassification and retrieval tasks. We propose a novel multimodal\nsemi-supervised learning framework by introducing instance-level consistency\nconstraint and a novel multimodal contrastive prototype (M2CP) loss. The\ninstance-level consistency enforces the network to generate consistent\nrepresentations for multimodal data of the same object regardless of its\nmodality. The M2CP maintains a multimodal prototype for each class and learns\nfeatures with small intra-class variations by minimizing the feature distance\nof each object to its prototype while maximizing the distance to the others.\nOur proposed framework significantly outperforms all the state-of-the-art\ncounterparts for both classification and retrieval tasks by a large margin on\nthe modelNet10 and ModelNet40 datasets.",
    "descriptor": "\nComments: BMVC 2021 poster\n",
    "authors": [
      "Zhimin Chen",
      "Longlong Jing",
      "Yang Liang",
      "YingLi Tian",
      "Bing Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11601"
  },
  {
    "id": "arXiv:2110.11602",
    "title": "An O(1) algorithm for implementing the LFU cache eviction scheme",
    "abstract": "Cache eviction algorithms are used widely in operating systems, databases and\nother systems that use caches to speed up execution by caching data that is\nused by the application. There are many policies such as MRU (Most Recently\nUsed), MFU (Most Frequently Used), LRU (Least Recently Used) and LFU (Least\nFrequently Used) which each have their advantages and drawbacks and are hence\nused in specific scenarios. By far, the most widely used algorithm is LRU, both\nfor its $O(1)$ speed of operation as well as its close resemblance to the kind\nof behaviour that is expected by most applications. The LFU algorithm also has\nbehaviour desirable by many real world workloads. However, in many places, the\nLRU algorithm is is preferred over the LFU algorithm because of its lower run\ntime complexity of $O(1)$ versus $O(\\log n)$. We present here an LFU cache\neviction algorithm that has a runtime complexity of $O(1)$ for all of its\noperations, which include insertion, access and deletion(eviction).",
    "descriptor": "",
    "authors": [
      "Dhruv Matani",
      "Ketan Shah",
      "Anirban Mitra"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Information Retrieval (cs.IR)",
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2110.11602"
  },
  {
    "id": "arXiv:2110.11603",
    "title": "ReCFA: Resilient Control-Flow Attestation",
    "abstract": "Recent IoT applications gradually adapt more complicated end systems with\ncommodity software. Ensuring the runtime integrity of these software is a\nchallenging task for the remote controller or cloud services. Popular\nenforcement is the runtime remote attestation which requires the end system\n(prover) to generate evidence for its runtime behavior and a remote trusted\nverifier to attest the evidence. Control-flow attestation is a kind of runtime\nattestation that provides diagnoses towards the remote control-flow hijacking\nat the prover. Most of these attestation approaches focus on small or embedded\nsoftware. The recent advance to attesting complicated software depends on the\nsource code and execution-profiling CFG to measure the subpaths, which may be\nincomplete and unavailable for commodity software.\nIn this work, we propose a resilient control-flow attestation (ReCFA), which\ndoes not need the offline measurement of all legitimate control-flow paths,\nthus scalable to be used on complicated commodity software. Our main\ncontribution is a multi-phase approach to condensing the runtime control-flow\nevents; as a result, the vast amount of control-flow events are abstracted into\na deliverable size. The condensing approach consists of filtering skippable\ncall sites, folding program-structure related control-flow events, and a greedy\ncompression. Our approach is implemented with binary-level static analysis and\ninstrumentation. We employ a shadow stack mechanism at the verifier to enforce\ncontext-sensitive control-flow integrity and diagnose the compromised\ncontrol-flow events violating the security policy. The experimental results on\nreal-world benchmarks show both the efficiency of the control-flow condensing\nand the effectiveness of security enforcement.",
    "descriptor": "",
    "authors": [
      "Yumei Zhang",
      "Xinzhi Liu",
      "Cong Sun",
      "Dongrui Zeng",
      "Gang Tan",
      "Xiao Kan",
      "Siqi Ma"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.11603"
  },
  {
    "id": "arXiv:2110.11608",
    "title": "Multi-Stream Attention Learning for Monocular Vehicle Velocity and  Inter-Vehicle Distance Estimation",
    "abstract": "Vehicle velocity and inter-vehicle distance estimation are essential for ADAS\n(Advanced driver-assistance systems) and autonomous vehicles. To save the cost\nof expensive ranging sensors, recent studies focus on using a low-cost\nmonocular camera to perceive the environment around the vehicle in a\ndata-driven fashion. Existing approaches treat each vehicle independently for\nperception and cause inconsistent estimation. Furthermore, important\ninformation like context and spatial relation in 2D object detection is often\nneglected in the velocity estimation pipeline. In this paper, we explore the\nrelationship between vehicles of the same frame with a\nglobal-relative-constraint (GLC) loss to encourage consistent estimation. A\nnovel multi-stream attention network (MSANet) is proposed to extract different\naspects of features, e.g., spatial and contextual features, for joint vehicle\nvelocity and inter-vehicle distance estimation. Experiments show the\neffectiveness and robustness of our proposed approach. MSANet outperforms\nstate-of-the-art algorithms on both the KITTI dataset and TuSimple velocity\ndataset.",
    "descriptor": "\nComments: Accepted to BMVC 2021\n",
    "authors": [
      "Kuan-Chih Huang",
      "Yu-Kai Huang",
      "Winston H. Hsu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11608"
  },
  {
    "id": "arXiv:2110.11611",
    "title": "Error-Correcting Neural Networks for Semi-Lagrangian Advection in the  Level-Set Method",
    "abstract": "We present a machine learning framework that blends image super-resolution\ntechnologies with scalar transport in the level-set method. Here, we\ninvestigate whether we can compute on-the-fly data-driven corrections to\nminimize numerical viscosity in the coarse-mesh evolution of an interface. The\nproposed system's starting point is the semi-Lagrangian formulation. And, to\nreduce numerical dissipation, we introduce an error-quantifying multilayer\nperceptron. The role of this neural network is to improve the numerically\nestimated surface trajectory. To do so, it processes localized level-set,\nvelocity, and positional data in a single time frame for select vertices near\nthe moving front. Our main contribution is thus a novel\nmachine-learning-augmented transport algorithm that operates alongside\nselective redistancing and alternates with conventional advection to keep the\nadjusted interface trajectory smooth. Consequently, our procedure is more\nefficient than full-scan convolutional-based applications because it\nconcentrates computational effort only around the free boundary. Also, we show\nthrough various tests that our strategy is effective at counteracting both\nnumerical diffusion and mass loss. In passive advection problems, for example,\nour method can achieve the same precision as the baseline scheme at twice the\nresolution but at a fraction of the cost. Similarly, our hybrid technique can\nproduce feasible solidification fronts for crystallization processes. On the\nother hand, highly deforming or lengthy simulations can precipitate bias\nartifacts and inference deterioration. Likewise, stringent design velocity\nconstraints can impose certain limitations, especially for problems involving\nrapid interface changes. In the latter cases, we have identified several\nopportunity avenues to enhance robustness without forgoing our approach's basic\nconcept.",
    "descriptor": "\nComments: Submitted\n",
    "authors": [
      "Luis \u00c1ngel Larios-C\u00e1rdenas",
      "Fr\u00e9d\u00e9ric Gibou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.11611"
  },
  {
    "id": "arXiv:2110.11613",
    "title": "Pairwise Reachability Oracles and Preservers under Failures",
    "abstract": "In this paper, we consider reachability oracles and reachability preservers\nfor directed graphs/networks prone to edge/node failures. Let $G = (V, E)$ be a\ndirected graph on $n$-nodes, and $P\\subseteq V\\times V$ be a set of vertex\npairs in $G$. We present the first non-trivial constructions of single and dual\nfault-tolerant pairwise reachability oracle with constant query time.\nFurthermore, we provide extremal bounds for sparse fault-tolerant reachability\npreservers, resilient to two or more failures. Prior to this work, such oracles\nand reachability preservers were widely studied for the special scenario of\nsingle-source and all-pairs settings. However, for the scenario of arbitrary\npairs, no prior (non-trivial) results were known for dual (or more) failures,\nexcept those implied from the single-source setting. One of the main questions\nis whether it is possible to beat the $O(n |P|)$ size bound (derived from the\nsingle-source setting) for reachability oracle and preserver for dual failures\n(or $O(2^k n|P|)$ bound for $k$ failures). We answer this question\naffirmatively.",
    "descriptor": "",
    "authors": [
      "Diptarka Chakraborty",
      "Kushagra Chatterjee",
      "Keerti Choudhary"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.11613"
  },
  {
    "id": "arXiv:2110.11616",
    "title": "Compressed Geometric Arrays for Point Cloud Processing",
    "abstract": "The ever-increasing demand for 3D modeling in the emerging immersive\napplications has made point clouds an essential class of data for 3D image and\nvideo processing. Tree based structures are commonly used for representing\npoint clouds where pointers are used to realize the connection between nodes.\nTree-based structures significantly suffer from irregular access patterns for\nlarge point clouds. Memory access indirection in such structures is disruptive\nto bandwidth efficiency and performance. In this paper, we propose a point\ncloud representation format based on compressed geometric arrays (CGA). Then,\nwe examine new methods for point cloud processing based on CGA. The proposed\nformat enables a higher bandwidth efficiency via eliminating memory access\nindirections (i.e., pointer chasing at the nodes of tree) thereby improving the\nefficiency of point cloud processing. Our experimental results show that using\nCGA for point cloud operations achieves 1328x speed up, 1321x better bandwidth\nutilization, and 54% reduction in the volume of transferred data as compared to\nthe state-of-the-art tree-based format from point cloud library (PCL).",
    "descriptor": "",
    "authors": [
      "Hoda Roodaki",
      "Mahdi Nazm Bojnordi"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.11616"
  },
  {
    "id": "arXiv:2110.11619",
    "title": "DistFL: Distribution-aware Federated Learning for Mobile Scenarios",
    "abstract": "Federated learning (FL) has emerged as an effective solution to decentralized\nand privacy-preserving machine learning for mobile clients. While traditional\nFL has demonstrated its superiority, it ignores the non-iid (independently\nidentically distributed) situation, which widely exists in mobile scenarios.\nFailing to handle non-iid situations could cause problems such as performance\ndecreasing and possible attacks. Previous studies focus on the \"symptoms\"\ndirectly, as they try to improve the accuracy or detect possible attacks by\nadding extra steps to conventional FL models. However, previous techniques\noverlook the root causes for the \"symptoms\": blindly aggregating models with\nthe non-iid distributions. In this paper, we try to fundamentally address the\nissue by decomposing the overall non-iid situation into several iid clusters\nand conducting aggregation in each cluster. Specifically, we propose\n\\textbf{DistFL}, a novel framework to achieve automated and accurate\n\\textbf{Dist}ribution-aware \\textbf{F}ederated \\textbf{L}earning in a\ncost-efficient way. DistFL achieves clustering via extracting and comparing the\n\\textit{distribution knowledge} from the uploaded models. With this framework,\nwe are able to generate multiple personalized models with distinctive\ndistributions and assign them to the corresponding clients. Extensive\nexperiments on mobile scenarios with popular model architectures have\ndemonstrated the effectiveness of DistFL.",
    "descriptor": "\nComments: This paper has been accepted by IMWUT2021(Ubicomp)\n",
    "authors": [
      "Bingyan Liu",
      "Yifeng Cai",
      "Ziqi Zhang",
      "Yuanchun Li",
      "Leye Wang",
      "Ding Li",
      "Yao Guo",
      "Xiangqun Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.11619"
  },
  {
    "id": "arXiv:2110.11624",
    "title": "SCICAP: Generating Captions for Scientific Figures",
    "abstract": "Researchers use figures to communicate rich, complex information in\nscientific papers. The captions of these figures are critical to conveying\neffective messages. However, low-quality figure captions commonly occur in\nscientific articles and may decrease understanding. In this paper, we propose\nan end-to-end neural framework to automatically generate informative,\nhigh-quality captions for scientific figures. To this end, we introduce SCICAP,\na large-scale figure-caption dataset based on computer science arXiv papers\npublished between 2010 and 2020. After pre-processing - including figure-type\nclassification, sub-figure identification, text normalization, and caption text\nselection - SCICAP contained more than two million figures extracted from over\n290,000 papers. We then established baseline models that caption graph plots,\nthe dominant (19.2%) figure type. The experimental results showed both\nopportunities and steep challenges of generating captions for scientific\nfigures.",
    "descriptor": "\nComments: Accepted by EMNLP 2021 Findings\n",
    "authors": [
      "Ting-Yao",
      "C. Lee Giles",
      "Ting-Hao 'Kenneth' Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11624"
  },
  {
    "id": "arXiv:2110.11626",
    "title": "Rethinking Generalization Performance of Surgical Phase Recognition with  Expert-Generated Annotations",
    "abstract": "As the area of application of deep neural networks expands to areas requiring\nexpertise, e.g., in medicine and law, more exquisite annotation processes for\nexpert knowledge training are required. In particular, it is difficult to\nguarantee generalization performance in the clinical field in the case of\nexpert knowledge training where opinions may differ even among experts on\nannotations. To raise the issue of the annotation generation process for\nexpertise training of CNNs, we verified the annotations for surgical phase\nrecognition of laparoscopic cholecystectomy and subtotal gastrectomy for\ngastric cancer. We produce calibrated annotations for the seven phases of\ncholecystectomy by analyzing the discrepancies of previously annotated labels\nand by discussing the criteria of surgical phases. For gastrectomy for gastric\ncancer has more complex twenty-one surgical phases, we generate consensus\nannotation by the revision process with five specialists. By training the\nCNN-based surgical phase recognition networks with revised annotations, we\nachieved improved generalization performance over models trained with original\nannotation under the same cross-validation settings. We showed that the\nexpertise data annotation pipeline for deep neural networks should be more\nrigorous based on the type of problem to apply clinical field.",
    "descriptor": "\nComments: Bridging the Gap: From Machine Learning Research to Clinical Practice @ NeurIPS 2021 (Spotlight)\n",
    "authors": [
      "Seungbum Hong",
      "Jiwon Lee",
      "Bokyung Park",
      "Ahmed A. Alwusaibie",
      "Anwar H. Alfadhel",
      "SungHyun Park",
      "Woo Jin Hyung",
      "Min-Kook Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11626"
  },
  {
    "id": "arXiv:2110.11627",
    "title": "On the largest singular values of certain large random matrices with  application to the estimation of the minimal dimension of the state-space  representations of high-dimensional time series",
    "abstract": "This paper is devoted to the estimation of the minimal dimension P of the\nstate-space realizations of a high-dimensional time series y, defined as a\nnoisy version (the noise is white and Gaussian) of a useful signal with low\nrank rational spectral density, in the high-dimensional asymptotic regime where\nthe number of available samples N and the dimension of the time series M\nconverge towards infinity at the same rate. In the classical low-dimensional\nregime, P is estimated as the number of significant singular values of the\nempirical autocovariance matrix between the past and the future of y, or as the\nnumber of significant estimated canonical correlation coefficients between the\npast and the future of y. Generalizing large random matrix methods developed in\nthe past to analyze classical spiked models, the behaviour of the above\nsingular values and canonical correlation coefficients is studied in the\nhigh-dimensional regime. It is proved that they are smaller than certain\nthresholds depending on the statistics of the noise, except a finite number of\noutliers that are due to the useful signal. The number of singular values of\nthe sample autocovariance matrix above the threshold is evaluated, is shown to\nbe almost independent from P in general, and cannot therefore be used to\nestimate P accurately. In contrast, the number s of canonical correlation\ncoefficients larger than the corresponding threshold is shown to be less than\nor equal to P, and explicit conditions under which it is equal to P are\nprovided. Under the corresponding assumptions, s is thus a consistent estimate\nof P in the high-dimensional regime. The core of the paper is the development\nof the necessary large random matrix tools.",
    "descriptor": "",
    "authors": [
      "Daria Tieplova",
      "Philippe Loubaton"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2110.11627"
  },
  {
    "id": "arXiv:2110.11628",
    "title": "CI-Based One-Bit Precoding for Multiuser Downlink Massive MIMO Systems  with PSK Modulation: A Negative $\\ell_1$ Penalty Approach",
    "abstract": "In this paper, we consider the one-bit precoding problem for the multiuser\ndownlink massive multiple-input multiple-output (MIMO) system with phase shift\nkeying (PSK) modulation and focus on the celebrated constructive interference\n(CI)-based problem formulation. We first establish the NP-hardness of the\nproblem (even in the single-user case), which reveals the intrinsic difficulty\nof globally solving the problem. Then, we propose a novel negative $\\ell_1$\npenalty model for the considered problem, which penalizes the one-bit\nconstraint into the objective with a negative $\\ell_1$-norm term, and show the\nequivalence between (global and local) solutions of the original problem and\nthe penalty problem when the penalty parameter is sufficiently large. We\nfurther transform the penalty model into an equivalent min-max problem and\npropose an efficient alternating optimization (AO) algorithm for solving it.\nThe AO algorithm enjoys low per-iteration complexity and is guaranteed to\nconverge to the stationary point of the min-max problem. To further reduce the\ncomputational cost, we also propose a low-complexity implementation of the AO\nalgorithm, where the values of the variables will be fixed in later iterations\nonce they satisfy the one-bit constraint. Numerical results show that, compared\nagainst the state-of-the-art CI-based algorithms, both of the proposed\nalgorithms generally achieve better bit-error-rate (BER) performance with lower\ncomputational cost, especially when the problem is difficult (e.g., high-order\nmodulations, large number of antennas, or high user-antenna ratio).",
    "descriptor": "\nComments: 13 pages, 8 figures, submitted for possible publication. arXiv admin note: text overlap with arXiv:2110.04768\n",
    "authors": [
      "Zheyu Wu",
      "Bo Jiang",
      "Ya-Feng Liu",
      "Yu-Hong Dai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.11628"
  },
  {
    "id": "arXiv:2110.11630",
    "title": "Improving Face Recognition with Large Age Gaps by Learning to  Distinguish Children",
    "abstract": "Despite the unprecedented improvement of face recognition, existing face\nrecognition models still show considerably low performances in determining\nwhether a pair of child and adult images belong to the same identity. Previous\napproaches mainly focused on increasing the similarity between child and adult\nimages of a given identity to overcome the discrepancy of facial appearances\ndue to aging. However, we observe that reducing the similarity between child\nimages of different identities is crucial for learning distinct features among\nchildren and thus improving face recognition performance in child-adult pairs.\nBased on this intuition, we propose a novel loss function called the\nInter-Prototype loss which minimizes the similarity between child images.\nUnlike the previous studies, the Inter-Prototype loss does not require\nadditional child images or training additional learnable parameters. Our\nextensive experiments and in-depth analyses show that our approach outperforms\nexisting baselines in face recognition with child-adult pairs. Our code and\nnewly-constructed test sets of child-adult pairs are available at\nhttps://github.com/leebebeto/Inter-Prototype.",
    "descriptor": "\nComments: Accepted to BMVC 2021\n",
    "authors": [
      "Jungsoo Lee",
      "Jooyeol Yun",
      "Sunghyun Park",
      "Yonggyu Kim",
      "Jaegul Choo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11630"
  },
  {
    "id": "arXiv:2110.11633",
    "title": "Explainable Landscape-Aware Optimization Performance Prediction",
    "abstract": "Efficient solving of an unseen optimization problem is related to appropriate\nselection of an optimization algorithm and its hyper-parameters. For this\npurpose, automated algorithm performance prediction should be performed that in\nmost commonly-applied practices involves training a supervised ML algorithm\nusing a set of problem landscape features. However, the main issue of training\nsuch models is their limited explainability since they only provide information\nabout the joint impact of the set of landscape features to the end prediction\nresults. In this study, we are investigating explainable landscape-aware\nregression models where the contribution of each landscape feature to the\nprediction of the optimization algorithm performance is estimated on a global\nand local level. The global level provides information about the impact of the\nfeature across all benchmark problems' instances, while the local level\nprovides information about the impact on a specific problem instance. The\nexperimental results are obtained using the COCO benchmark problems and three\ndifferently configured modular CMA-ESs. The results show a proof of concept\nthat different set of features are important for different problem instances,\nwhich indicates that further personalization of the landscape space is required\nwhen training an automated algorithm performance prediction model.",
    "descriptor": "\nComments: To appear in the Proceedings of IEEE Symposium Series on Computational Intelligence (IEEE SSCI 2021)\n",
    "authors": [
      "Risto Trajanov",
      "Stefan Dimeski",
      "Martin Popovski",
      "Peter Koro\u0161ec",
      "Tome Eftimov"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11633"
  },
  {
    "id": "arXiv:2110.11634",
    "title": "High-performance Estimation of Jamming Covariance Matrix for IRS-aided  Directional Modulation Network with a Malicious Attacker",
    "abstract": "In this paper, we investigate the anti-jamming problem of a directional\nmodulation (DM) system with the aid of intelligent reflecting surface (IRS). As\nan efficient tool to combat malicious jamming, receive beamforming (RBF) is\nusually designed to be on null-space of jamming channel or covariance matrix\nfrom Mallory to Bob. Thus, it is very necessary to estimate the receive jamming\ncovariance matrix (JCM) at Bob. To achieve a precise JCM estimate, three JCM\nestimation methods, including eigenvalue decomposition (EVD), parametric\nestimation method by gradient descend (PEM-GD) and parametric estimation method\nby alternating optimization (PEM-AO), are proposed. Here, the proposed EVD is\nunder rank-2 constraint of JCM. The PEM-GD method fully explores the structure\nfeatures of JCM and the PEM-AO is to decrease the computational complexity of\nthe former via dimensionality reduction. The simulation results show that in\nlow and medium jamming-noise ratio (JNR) regions, the proposed three methods\nperform better than the existing sample covariance matrix method. The proposed\nPEM-GD and PEM-AO outperform EVD method and existing clutter and disturbance\ncovariance estimator RCML.",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "Hangjia He",
      "Ting Su",
      "Hongjun Wang",
      "Yin Teng",
      "Weiping Shi",
      "Feng Shu",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.11634"
  },
  {
    "id": "arXiv:2110.11636",
    "title": "Occlusion-Robust Object Pose Estimation with Holistic Representation",
    "abstract": "Practical object pose estimation demands robustness against occlusions to the\ntarget object. State-of-the-art (SOTA) object pose estimators take a two-stage\napproach, where the first stage predicts 2D landmarks using a deep network and\nthe second stage solves for 6DOF pose from 2D-3D correspondences. Albeit widely\nadopted, such two-stage approaches could suffer from novel occlusions when\ngeneralising and weak landmark coherence due to disrupted features. To address\nthese issues, we develop a novel occlude-and-blackout batch augmentation\ntechnique to learn occlusion-robust deep features, and a multi-precision\nsupervision architecture to encourage holistic pose representation learning for\naccurate and coherent landmark predictions. We perform careful ablation tests\nto verify the impact of our innovations and compare our method to SOTA pose\nestimators. Without the need of any post-processing or refinement, our method\nexhibits superior performance on the LINEMOD dataset. On the YCB-Video dataset\nour method outperforms all non-refinement methods in terms of the ADD(-S)\nmetric. We also demonstrate the high data-efficiency of our method. Our code is\navailable at this http URL",
    "descriptor": "\nComments: WACV 2022\n",
    "authors": [
      "Bo Chen",
      "Tat-Jun Chin",
      "Marius Klimavicius"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11636"
  },
  {
    "id": "arXiv:2110.11644",
    "title": "EXSCALATE: An extreme-scale in-silico virtual screening platform to  evaluate 1 trillion compounds in 60 hours on 81 PFLOPS supercomputers",
    "abstract": "The social and economic impact of the COVID-19 pandemic demands the reduction\nof the time required to find a therapeutic cure. In the contest of urgent\ncomputing, we re-designed the Exscalate molecular docking platform to benefit\nfrom heterogeneous computation nodes and to avoid scaling issues. We deployed\nthe Exscalate platform on two top European supercomputers (CINECA-Marconi100\nand ENI-HPC5), with a combined computational power of 81 PFLOPS, to evaluate\nthe interaction between 70 billions of small molecules and 15 binding-sites of\n12 viral proteins of Sars-Cov2. The experiment lasted 60 hours and overall it\nperformed a trillion of evaluations.",
    "descriptor": "",
    "authors": [
      "Davide Gadioli",
      "Emanuele Vitali",
      "Federico Ficarelli",
      "Chiara Latini",
      "Candida Manelfi",
      "Carmine Talarico",
      "Cristina Silvano",
      "Carlo Cavazzoni",
      "Gianluca Palermo",
      "Andrea Rosario Beccari"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2110.11644"
  },
  {
    "id": "arXiv:2110.11645",
    "title": "CTP-Net For Cross-Domain Trajectory Prediction",
    "abstract": "Deep learning based trajectory prediction methods rely on large amount of\nannotated future trajectories, but may not generalize well to a new scenario\ncaptured by another camera. Meanwhile, annotating trajectories for training a\nnetwork for this new scenario is time-consuming and expensive, therefore it is\ndesirable to adapt the model trained with the annotated source domain\ntrajectories to the target domain.\nTo tackle domain adaptation for trajectory prediction, we propose a\nCross-domain Trajectory Prediction Network (CTP-Net), in which LSTMs are used\nto encode the observed trajectories of both domain, and their features are\naligned by a cross-domain feature discriminator. Further, considering the\nconsistency between the observed trajectories and the predicted trajectories in\nthe target domain, a target domain offset discriminator is utilized to\nadversarially regularize the future trajectory predictions to be consistent\nwith the observed trajectories. Extensive experiments demonstrate the\neffectiveness of the proposed domain adaptation for trajectory prediction\nsetting as well as our method on domain adaptation for trajectory prediction.",
    "descriptor": "",
    "authors": [
      "Pingxuan Huang",
      "Yanyan Fang",
      "Bo Hu",
      "Shenghua Gao",
      "Jing Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11645"
  },
  {
    "id": "arXiv:2110.11646",
    "title": "WebFed: Cross-platform Federated Learning Framework Based on Web Browser  with Local Differential Privacy",
    "abstract": "For data isolated islands and privacy issues, federated learning has been\nextensively invoking much interest since it allows clients to collaborate on\ntraining a global model using their local data without sharing any with a third\nparty. However, the existing federated learning frameworks always need\nsophisticated condition configurations (e.g., sophisticated driver\nconfiguration of standalone graphics card like NVIDIA, compile environment)\nthat bring much inconvenience for large-scale development and deployment. To\nfacilitate the deployment of federated learning and the implementation of\nrelated applications, we innovatively propose WebFed, a novel browser-based\nfederated learning framework that takes advantage of the browser's features\n(e.g., Cross-platform, JavaScript Programming Features) and enhances the\nprivacy protection via local differential privacy mechanism. Finally, We\nconduct experiments on heterogeneous devices to evaluate the performance of the\nproposed WebFed framework.",
    "descriptor": "",
    "authors": [
      "Zhuotao Lian",
      "Qinglin Yang",
      "Qingkui Zeng",
      "Chunhua Su"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.11646"
  },
  {
    "id": "arXiv:2110.11650",
    "title": "Pixel-by-Pixel Cross-Domain Alignment for Few-Shot Semantic Segmentation",
    "abstract": "In this paper we consider the task of semantic segmentation in autonomous\ndriving applications. Specifically, we consider the cross-domain few-shot\nsetting where training can use only few real-world annotated images and many\nannotated synthetic images. In this context, aligning the domains is made more\nchallenging by the pixel-wise class imbalance that is intrinsic in the\nsegmentation and that leads to ignoring the underrepresented classes and\noverfitting the well represented ones. We address this problem with a novel\nframework called Pixel-By-Pixel Cross-Domain Alignment (PixDA). We propose a\nnovel pixel-by-pixel domain adversarial loss following three criteria: (i)\nalign the source and the target domain for each pixel, (ii) avoid negative\ntransfer on the correctly represented pixels, and (iii) regularize the training\nof infrequent classes to avoid overfitting. The pixel-wise adversarial training\nis assisted by a novel sample selection procedure, that handles the imbalance\nbetween source and target data, and a knowledge distillation strategy, that\navoids overfitting towards the few target images. We demonstrate on standard\nsynthetic-to-real benchmarks that PixDA outperforms previous state-of-the-art\nmethods in (1-5)-shot settings.",
    "descriptor": "\nComments: Accepted at WACV 2022\n",
    "authors": [
      "Antonio Tavera",
      "Fabio Cermelli",
      "Carlo Masone",
      "Barbara Caputo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11650"
  },
  {
    "id": "arXiv:2110.11652",
    "title": "Action Planning for Packing Long Linear Elastic Objects into Compact  Boxes with Bimanual Robotic Manipulation",
    "abstract": "Automatic packing of objects is a critical component for efficient shipping\nin the Industry 4.0 era. Although robots have shown great success in\npick-and-place operations with rigid products, the autonomous shaping and\npacking of elastic materials into compact boxes remains one of the most\nchallenging problems in robotics; The automation of packing tasks is crucial at\nthis moment given the accelerating shift towards e-commerce (which requires to\nmanipulate multiple types of materials). In this paper, we propose a new action\nplanning approach to automatically pack long linear elastic objects into\ncommon-size boxes with a bimanual robotic system. For that, we developed an\nefficient vision-based method to compute the objects' geometry and track its\ndeformation in real-time and without special markers; The algorithm filters and\norders the feedback point cloud that is captured by a depth sensor. A reference\nobject model is introduced to plan the manipulation targets and to complete\noccluded parts of the object. Action primitives are used to construct\nhigh-level behaviors, which enable the execution of all packing steps. To\nvalidate the proposed theory, we conduct a detailed experimental study with\nmultiple types and lengths of objects and packing boxes. The proposed\nmethodology is original and its demonstrated manipulation capabilities have not\n(to the best of the authors knowledge) been previously reported in the\nliterature.",
    "descriptor": "",
    "authors": [
      "Wanyu Ma",
      "Bin Zhang",
      "Lijun Han",
      "Shengzeng Huo",
      "Hesheng Wang",
      "David Navarro-Alarcon"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.11652"
  },
  {
    "id": "arXiv:2110.11657",
    "title": "Projective Manifold Gradient Layer for Deep Rotation Regression",
    "abstract": "Regressing rotations on SO(3) manifold using deep neural networks is an\nimportant yet unsolved problem. The gap between Euclidean network output space\nand the non-Euclidean SO(3) manifold imposes a severe challenge for neural\nnetwork learning in both forward and backward passes. While several works have\nproposed different regression-friendly rotation representations, very few works\nhave been devoted to improving the gradient backpropagating in the backward\npass. In this paper, we propose a manifold-aware gradient that directly\nbackpropagates into deep network weights. Leveraging the Riemannian gradient\nand a novel projective gradient, our proposed regularized projective manifold\ngradient (RPMG) helps networks achieve new state-of-the-art performance in a\nvariety of rotation estimation tasks. The proposed gradient layer can also be\napplied to other smooth manifolds such as the unit sphere.",
    "descriptor": "",
    "authors": [
      "Jiayi Chen",
      "Yingda Yin",
      "Tolga Birdal",
      "Baoquan Chen",
      "Leonidas Guibas",
      "He Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11657"
  },
  {
    "id": "arXiv:2110.11661",
    "title": "1st Place Solution for the UVO Challenge on Video-based Open-World  Segmentation 2021",
    "abstract": "In this report, we introduce our (pretty straightforard) two-step\n\"detect-then-match\" video instance segmentation method. The first step performs\ninstance segmentation for each frame to get a large number of instance mask\nproposals. The second step is to do inter-frame instance mask matching with the\nhelp of optical flow. We demonstrate that with high quality mask proposals, a\nsimple matching mechanism is good enough for tracking. Our approach achieves\nthe first place in the UVO 2021 Video-based Open-World Segmentation Challenge.",
    "descriptor": "\nComments: Code:this https URL arXiv admin note: substantial text overlap with arXiv:2110.10239\n",
    "authors": [
      "Yuming Du",
      "Wen Guo",
      "Yang Xiao",
      "Vincent Lepetit"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11661"
  },
  {
    "id": "arXiv:2110.11662",
    "title": "Reimagine BiSeNet for Real-Time Domain Adaptation in Semantic  Segmentation",
    "abstract": "Semantic segmentation models have reached remarkable performance across\nvarious tasks. However, this performance is achieved with extremely large\nmodels, using powerful computational resources and without considering training\nand inference time. Real-world applications, on the other hand, necessitate\nmodels with minimal memory demands, efficient inference speed, and executable\nwith low-resources embedded devices, such as self-driving vehicles. In this\npaper, we look at the challenge of real-time semantic segmentation across\ndomains, and we train a model to act appropriately on real-world data even\nthough it was trained on a synthetic realm. We employ a new lightweight and\nshallow discriminator that was specifically created for this purpose. To the\nbest of our knowledge, we are the first to present a real-time adversarial\napproach for assessing the domain adaption problem in semantic segmentation. We\ntested our framework in the two standard protocol: GTA5 to Cityscapes and\nSYNTHIA to Cityscapes. Code is available at:\nhttps://github.com/taveraantonio/RTDA.",
    "descriptor": "\nComments: Accepted at I-RIM 3D 2021\n",
    "authors": [
      "Antonio Tavera",
      "Carlo Masone",
      "Barbara Caputo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11662"
  },
  {
    "id": "arXiv:2110.11664",
    "title": "GCCN: Global Context Convolutional Network",
    "abstract": "In this paper, we propose Global Context Convolutional Network (GCCN) for\nvisual recognition. GCCN computes global features representing contextual\ninformation across image patches. These global contextual features are defined\nas local maxima pixels with high visual sharpness in each patch. These features\nare then concatenated and utilised to augment the convolutional features. The\nlearnt feature vector is normalised using the global context features using\nFrobenius norm. This straightforward approach achieves high accuracy in\ncompassion to the state-of-the-art methods with 94.6% and 95.41% on CIFAR-10\nand STL-10 datasets, respectively. To explore potential impact of GCCN on other\nvisual representation tasks, we implemented GCCN as a based model to few-shot\nimage classification. We learn metric distances between the augmented feature\nvectors and their prototypes representations, similar to Prototypical and\nMatching Networks. GCCN outperforms state-of-the-art few-shot learning methods\nachieving 99.9%, 84.8% and 80.74% on Omniglot, MiniImageNet and CUB-200,\nrespectively. GCCN has significantly improved on the accuracy of\nstate-of-the-art prototypical and matching networks by up to 30% in different\nfew-shot learning scenarios.",
    "descriptor": "",
    "authors": [
      "Ali Hamdi",
      "Flora Salim",
      "Du Yong Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11664"
  },
  {
    "id": "arXiv:2110.11665",
    "title": "Diversified Sampling for Batched Bayesian Optimization with  Determinantal Point Processes",
    "abstract": "In Bayesian Optimization (BO) we study black-box function optimization with\nnoisy point evaluations and Bayesian priors. Convergence of BO can be greatly\nsped up by batching, where multiple evaluations of the black-box function are\nperformed in a single round. The main difficulty in this setting is to propose\nat the same time diverse and informative batches of evaluation points. In this\nwork, we introduce DPP-Batch Bayesian Optimization (DPP-BBO), a universal\nframework for inducing batch diversity in sampling based BO by leveraging the\nrepulsive properties of Determinantal Point Processes (DPP) to naturally\ndiversify the batch sampling procedure. We illustrate this framework by\nformulating DPP-Thompson Sampling (DPP-TS) as a variant of the popular Thompson\nSampling (TS) algorithm and introducing a Markov Chain Monte Carlo procedure to\nsample from it. We then prove novel Bayesian simple regret bounds for both\nclassical batched TS as well as our counterpart DPP-TS, with the latter bound\nbeing tighter. Our real-world, as well as synthetic, experiments demonstrate\nimproved performance of DPP-BBO over classical batching methods with Gaussian\nprocess and Cox process models.",
    "descriptor": "",
    "authors": [
      "Elvis Nava",
      "Mojm\u00edr Mutn\u00fd",
      "Andreas Krause"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.11665"
  },
  {
    "id": "arXiv:2110.11672",
    "title": "Explainable, automated urban interventions to improve pedestrian and  vehicle safety",
    "abstract": "At the moment, urban mobility research and governmental initiatives are\nmostly focused on motor-related issues, e.g. the problems of congestion and\npollution. And yet, we can not disregard the most vulnerable elements in the\nurban landscape: pedestrians, exposed to higher risks than other road users.\nIndeed, safe, accessible, and sustainable transport systems in cities are a\ncore target of the UN's 2030 Agenda. Thus, there is an opportunity to apply\nadvanced computational tools to the problem of traffic safety, in regards\nespecially to pedestrians, who have been often overlooked in the past. This\npaper combines public data sources, large-scale street imagery and computer\nvision techniques to approach pedestrian and vehicle safety with an automated,\nrelatively simple, and universally-applicable data-processing scheme. The steps\ninvolved in this pipeline include the adaptation and training of a Residual\nConvolutional Neural Network to determine a hazard index for each given urban\nscene, as well as an interpretability analysis based on image segmentation and\nclass activation mapping on those same images. Combined, the outcome of this\ncomputational approach is a fine-grained map of hazard levels across a city,\nand an heuristic to identify interventions that might simultaneously improve\npedestrian and vehicle safety. The proposed framework should be taken as a\ncomplement to the work of urban planners and public authorities.",
    "descriptor": "",
    "authors": [
      "Cristina Bustos",
      "Daniel Rhoads",
      "Albert Sole-Ribalta",
      "David Masip",
      "Alex Arenas",
      "Agata Lapedriza",
      "Javier Borge-Holthoefer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11672"
  },
  {
    "id": "arXiv:2110.11679",
    "title": "Depth-only Object Tracking",
    "abstract": "Depth (D) indicates occlusion and is less sensitive to illumination changes,\nwhich make depth attractive modality for Visual Object Tracking (VOT). Depth is\nused in RGBD object tracking where the best trackers are deep RGB trackers with\nadditional heuristic using depth maps. There are two potential reasons for the\nheuristics: 1) the lack of large RGBD tracking datasets to train deep RGBD\ntrackers and 2) the long-term evaluation protocol of VOT RGBD that benefits\nfrom heuristics such as depth-based occlusion detection. In this work, we study\nhow far D-only tracking can go if trained with large amounts of depth data. To\ncompensate the lack of depth data, we generate depth maps for tracking. We\ntrain a \"Depth-DiMP\" from the scratch with the generated data and fine-tune it\nwith the available small RGBD tracking datasets. The depth-only DiMP achieves\ngood accuracy in depth-only tracking and combined with the original RGB DiMP\nthe end-to-end trained RGBD-DiMP outperforms the recent VOT 2020 RGBD winners.",
    "descriptor": "\nComments: Accepted to BMVC2021\n",
    "authors": [
      "Song Yan",
      "Jinyu Yang",
      "Ales Leonardis",
      "Joni-Kristian Kamarainen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11679"
  },
  {
    "id": "arXiv:2110.11680",
    "title": "Deep Two-Stream Video Inference for Human Body Pose and Shape Estimation",
    "abstract": "Several video-based 3D pose and shape estimation algorithms have been\nproposed to resolve the temporal inconsistency of single-image-based methods.\nHowever it still remains challenging to have stable and accurate\nreconstruction. In this paper, we propose a new framework Deep Two-Stream Video\nInference for Human Body Pose and Shape Estimation (DTS-VIBE), to generate 3D\nhuman pose and mesh from RGB videos. We reformulate the task as a\nmulti-modality problem that fuses RGB and optical flow for more reliable\nestimation. In order to fully utilize both sensory modalities (RGB or optical\nflow), we train a two-stream temporal network based on transformer to predict\nSMPL parameters. The supplementary modality, optical flow, helps to maintain\ntemporal consistency by leveraging motion knowledge between two consecutive\nframes. The proposed algorithm is extensively evaluated on the Human3.6 and\n3DPW datasets. The experimental results show that it outperforms other\nstate-of-the-art methods by a significant margin.",
    "descriptor": "\nComments: Accepted by WACV2022\n",
    "authors": [
      "Ziwen Li",
      "Bo Xu",
      "Han Huang",
      "Cheng Lu",
      "Yandong Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11680"
  },
  {
    "id": "arXiv:2110.11681",
    "title": "Conditional Variational Autoencoder for Learned Image Reconstruction",
    "abstract": "Learned image reconstruction techniques using deep neural networks have\nrecently gained popularity, and have delivered promising empirical results.\nHowever, most approaches focus on one single recovery for each observation, and\nthus neglect the uncertainty information. In this work, we develop a novel\ncomputational framework that approximates the posterior distribution of the\nunknown image at each query observation. The proposed framework is very\nflexible: It handles implicit noise models and priors, it incorporates the data\nformation process (i.e., the forward operator), and the learned reconstructive\nproperties are transferable between different datasets. Once the network is\ntrained using the conditional variational autoencoder loss, it provides a\ncomputationally efficient sampler for the approximate posterior distribution\nvia feed-forward propagation, and the summarizing statistics of the generated\nsamples are used for both point-estimation and uncertainty quantification. We\nillustrate the proposed framework with extensive numerical experiments on\npositron emission tomography (with both moderate and low count levels) showing\nthat the framework generates high-quality samples when compared with\nstate-of-the-art methods.",
    "descriptor": "\nComments: 22 pages, preliminary version appeared as 1908.01010\n",
    "authors": [
      "Chen Zhang",
      "Riccardo Barbano Bangti Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.11681"
  },
  {
    "id": "arXiv:2110.11685",
    "title": "Adaptive Fusion Affinity Graph with Noise-free Online Low-rank  Representation for Natural Image Segmentation",
    "abstract": "Affinity graph-based segmentation methods have become a major trend in\ncomputer vision. The performance of these methods relies on the constructed\naffinity graph, with particular emphasis on the neighborhood topology and\npairwise affinities among superpixels. Due to the advantages of assimilating\ndifferent graphs, a multi-scale fusion graph has a better performance than a\nsingle graph with single-scale. However, these methods ignore the noise from\nimages which influences the accuracy of pairwise similarities. Multi-scale\ncombinatorial grouping and graph fusion also generate a higher computational\ncomplexity. In this paper, we propose an adaptive fusion affinity graph\n(AFA-graph) with noise-free low-rank representation in an online manner for\nnatural image segmentation. An input image is first over-segmented into\nsuperpixels at different scales and then filtered by the proposed improved\nkernel density estimation method. Moreover, we select global nodes of these\nsuperpixels on the basis of their subspace-preserving presentation, which\nreveals the feature distribution of superpixels exactly. To reduce time\ncomplexity while improving performance, a sparse representation of global nodes\nbased on noise-free online low-rank representation is used to obtain a global\ngraph at each scale. The global graph is finally used to update a local graph\nwhich is built upon all superpixels at each scale. Experimental results on the\nBSD300, BSD500, MSRC, SBD, and PASCAL VOC show the effectiveness of AFA-graph\nin comparison with state-of-the-art approaches.",
    "descriptor": "\nComments: 12 pages, 12 figures\n",
    "authors": [
      "Yang Zhang",
      "Moyun Liu",
      "Huiming Zhang",
      "Guodong Sun",
      "Jingwu He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.11685"
  },
  {
    "id": "arXiv:2110.11688",
    "title": "Differentially Private Coordinate Descent for Composite Empirical Risk  Minimization",
    "abstract": "Machine learning models can leak information about the data used to train\nthem. Differentially Private (DP) variants of optimization algorithms like\nStochastic Gradient Descent (DP-SGD) have been designed to mitigate this,\ninducing a trade-off between privacy and utility. In this paper, we propose a\nnew method for composite Differentially Private Empirical Risk Minimization\n(DP-ERM): Differentially Private proximal Coordinate Descent (DP-CD). We\nanalyze its utility through a novel theoretical analysis of inexact coordinate\ndescent, and highlight some regimes where DP-CD outperforms DP-SGD, thanks to\nthe possibility of using larger step sizes. We also prove new lower bounds for\ncomposite DP-ERM under coordinate-wise regularity assumptions, that are, in\nsome settings, nearly matched by our algorithm. In practical implementations,\nthe coordinate-wise nature of DP-CD updates demands special care in choosing\nthe clipping thresholds used to bound individual contributions to the\ngradients. A natural parameterization of these thresholds emerges from our\ntheory, limiting the addition of unnecessarily large noise without requiring\ncoordinate-wise hyperparameter tuning or extra computational cost.",
    "descriptor": "\nComments: 27 pages, 2 figures\n",
    "authors": [
      "Paul Mangold",
      "Aur\u00e9lien Bellet",
      "Joseph Salmon",
      "Marc Tommasi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.11688"
  },
  {
    "id": "arXiv:2110.11692",
    "title": "ListReader: Extracting List-form Answers for Opinion Questions",
    "abstract": "Question answering (QA) is a high-level ability of natural language\nprocessing. Most extractive ma-chine reading comprehension models focus on\nfactoid questions (e.g., who, when, where) and restrict the output answer as a\nshort and continuous span in the original passage. However, in real-world\nscenarios, many questions are non-factoid (e.g., how, why) and their answers\nare organized in the list format that contains multiple non-contiguous spans.\nNaturally, existing extractive models are by design unable to answer such\nquestions. To address this issue, this paper proposes ListReader, a neural\nex-tractive QA model for list-form answer. In addition to learning the\nalignment between the question and content, we introduce a heterogeneous graph\nneural network to explicitly capture the associations among candidate segments.\nMoreover, our model adopts a co-extraction setting that can extract either\nspan- or sentence-level answers, allowing better applicability. Two large-scale\ndatasets of different languages are constructed to support this study.\nExperimental results show that our model considerably outperforms various\nstrong baselines. Further discussions provide an intuitive understanding of how\nour model works and where the performance gain comes from.",
    "descriptor": "",
    "authors": [
      "Peng Cui",
      "Dongyao Hu",
      "Le Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.11692"
  },
  {
    "id": "arXiv:2110.11695",
    "title": "Node package manager's dependency network robustness",
    "abstract": "The robustness of npm dependency network is a crucial property, since many\nprojects and web applications heavily rely on the functionalities of packages,\nespecially popular ones that have many dependant packages. In the past, there\nhave been instances where the removal or update of certain npm packages has\ncaused widespread chaos and web-page downtime on the internet. Our goal is to\ntrack the network's resilience to such occurrences through time and figure out\nwhether the state of the network is trending towards a more robust structure.\nWe show that the network is not robust to targeted attacks, since a security\nrisk in a few crucial nodes affects a large part of the network. Because such\npackages are often backed up by serious communities with high standards, the\nissue is not alarming and is a consequence of power law distribution of the\nnetwork. The current trend in average number of dependencies and effect of\nimportant nodes on the rest of the network is decreasing, which further\nimproves the resilience and sets a positive path in development. Furthermore,\nwe show that communities form around the most important packages, although they\ndo not conform well to the common community definition using modularity. We\nalso provide guidelines for package development that increases the robustness\nof the network and reduces the possibility of introducing security risks.",
    "descriptor": "\nComments: 5 pages, 4 figures, created as part of the Introduction to Network Analysis class at FRI UL, Slovenia. Mentor: doc. dr. Lovro \\v{S}ubelj\n",
    "authors": [
      "Andrej Hafner",
      "An\u017ee Mur",
      "Jaka Bernard"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.11695"
  },
  {
    "id": "arXiv:2110.11697",
    "title": "An Efficient Branch-and-Bound Solver for Hitting Set",
    "abstract": "The hitting set problem asks for a collection of sets over a universe $U$ to\nfind a minimum subset of $U$ that intersects each of the given sets. It is\nNP-hard and equivalent to the problem set cover. We give a branch-and-bound\nalgorithm to solve hitting set. Though it requires exponential time in the\nworst case, it can solve many practical instances from different domains in\nreasonable time. Our algorithm outperforms a modern ILP solver, the\nstate-of-the-art for hitting set, by at least an order of magnitude on most\ninstances.",
    "descriptor": "",
    "authors": [
      "Thomas Bl\u00e4sius",
      "Tobias Friedrich",
      "David Stangl",
      "Christopher Weyand"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.11697"
  },
  {
    "id": "arXiv:2110.11700",
    "title": "Proof-Carrying Parameters in Certified Symbolic Execution: The Case  Study of Antiunification",
    "abstract": "Unification and antiunification are essential algorithms used by symbolic\nexecution engines and verification tools. Complex frameworks for defining\nprogramming languages, such as K, aim to generate various tools (e.g.,\ninterpreters, symbolic execution engines, deductive verifiers, etc.) using only\nthe formal definition of a language. K is the best effort implementation of\nMatching Logic, a logical framework for defining languages. When used at an\nindustrial scale, a tool like the K framework is constantly updated, and in the\nsame time it is required to be trustworthy. Ensuring the correctness of such a\nframework is practically impossible. A solution is to generate proof objects as\ncorrectness certificates that can be checked by an external trusted checker.\nIn K, symbolic execution makes intensive use of unification and\nantiunification algorithms to handle conjunctions and disjunctions of term\npatterns. Conjunctions and disjunctions of formulae have to be automatically\nnormalised and the generation of proof objects needs to take such\nnormalisations into account. The executions of these algorithms can be seen as\nparameters of the symbolic execution steps and they have to provide proof\nobjects that are used then to generate the proof object for the program\nexecution step. We show in this paper that Plotkin's antiunification can be\nused to normalise disjunctions and to generate the corresponding proof objects.\nWe provide a prototype implementation of our proof object generation technique\nand a checker for certifying the generated objects.",
    "descriptor": "\nComments: Technical Report at Faculty of Computer Science\n",
    "authors": [
      "Andrei Arusoaie",
      "Dorel Lucanu"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.11700"
  },
  {
    "id": "arXiv:2110.11707",
    "title": "Variational Wasserstein Barycenters with c-Cyclical Monotonicity",
    "abstract": "Wasserstein barycenter, built on the theory of optimal transport, provides a\npowerful framework to aggregate probability distributions, and it has\nincreasingly attracted great attention within the machine learning community.\nHowever, it suffers from severe computational burden, especially for high\ndimensional and continuous settings. To this end, we develop a novel continuous\napproximation method for the Wasserstein barycenters problem given sample\naccess to the input distributions. The basic idea is to introduce a variational\ndistribution as the approximation of the true continuous barycenter, so as to\nframe the barycenters computation problem as an optimization problem, where\nparameters of the variational distribution adjust the proxy distribution to be\nsimilar to the barycenter. Leveraging the variational distribution, we\nconstruct a tractable dual formulation for the regularized Wasserstein\nbarycenter problem with c-cyclical monotonicity, which can be efficiently\nsolved by stochastic optimization. We provide theoretical analysis on\nconvergence and demonstrate the practical effectiveness of our method on real\napplications of subset posterior aggregation and synthetic data.",
    "descriptor": "",
    "authors": [
      "Jinjin Chi",
      "Zhiyao Yang",
      "Jihong Ouyang",
      "Ximing Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.11707"
  },
  {
    "id": "arXiv:2110.11709",
    "title": "Creating Knowledge Graphs Subsets using Shape Expressions",
    "abstract": "The initial adoption of knowledge graphs by Google and later by big companies\nhas increased their adoption and popularity. In this paper we present a formal\nmodel for three different types of knowledge graphs which we call RDF-based\ngraphs, property graphs and wikibase graphs. In order to increase the quality\nof Knowledge Graphs, several approaches have appeared to describe and validate\ntheir contents. Shape Expressions (ShEx) has been proposed as concise language\nfor RDF validation. We give a brief introduction to ShEx and present two\nextensions that can also be used to describe and validate property graphs\n(PShEx) and wikibase graphs (WShEx). One problem of knowledge graphs is the\nlarge amount of data they contain, which jeopardizes their practical\napplication. In order to palliate this problem, one approach is to create\nsubsets of those knowledge graphs for some domains. We propose the following\napproaches to generate those subsets: Entity-matching, simple matching, ShEx\nmatching, ShEx plus Slurp and ShEx plus Pregel which are based on declaratively\ndefining the subsets by either matching some content or by Shape Expressions.\nThe last approach is based on a novel validation algorithm for ShEx based on\nthe Pregel algorithm that can handle big data graphs and has been implemented\non Apache Spark GraphX.",
    "descriptor": "",
    "authors": [
      "Jose Emilio Labra Gayo"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11709"
  },
  {
    "id": "arXiv:2110.11712",
    "title": "Incremental SSSP for Sparse Digraphs Beyond the Hopset Barrier",
    "abstract": "Given a directed, weighted graph $G=(V,E)$ undergoing edge insertions, the\nincremental single-source shortest paths (SSSP) problem asks for the\nmaintenance of approximate distances from a dedicated source $s$ while\noptimizing the total time required to process the insertion sequence of $m$\nedges.\nRecently, Gutenberg, Williams and Wein [STOC'20] introduced a deterministic\n$\\tilde{O}(n^2)$ algorithm for this problem, achieving near linear time for\nvery dense graphs. For sparse graphs, Chechik and Zhang [SODA'21] recently\npresented a deterministic $\\tilde{O}(m^{5/3})$ algorithm, and an adaptive\nrandomized algorithm with run-time $\\tilde{O}(m\\sqrt{n} + m^{7/5})$. This\nalgorithm is remarkable for two reasons: 1) in very spare graphs it reaches the\ndirected hopset barrier of $\\tilde{\\Omega}(n^{3/2})$ that applied to all\nprevious approaches for partially-dynamic SSSP [STOC'14, SODA'20, FOCS'20]\n\\emph{and} 2) it does not resort to a directed hopset technique itself.\nIn this article we introduce \\emph{propagation synchronization}, a new\ntechnique for controlling the error build-up on paths throughout batches of\ninsertions. This leads us to a significant improvement of the approach in\n[SODA'21] yielding a \\emph{deterministic} $\\tilde{O}(m^{3/2})$ algorithm for\nthe problem. By a very careful combination of our new technique with the\nsampling approach from [SODA'21], we further obtain an adaptive randomized\nalgorithm with total update time $\\tilde{O}(m^{4/3})$. This is the first\npartially-dynamic SSSP algorithm in sparse graphs to bypass the notorious\ndirected hopset barrier which is often seen as the fundamental challenge\ntowards achieving truly near-linear time algorithms.",
    "descriptor": "\nComments: Accepted at SODA'22\n",
    "authors": [
      "Rasmus Kyng",
      "Simon Meierhans",
      "Maximilian Probst Gutenberg"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.11712"
  },
  {
    "id": "arXiv:2110.11713",
    "title": "Mechanistic Interpretation of Machine Learning Inference: A Fuzzy  Feature Importance Fusion Approach",
    "abstract": "With the widespread use of machine learning to support decision-making, it is\nincreasingly important to verify and understand the reasons why a particular\noutput is produced. Although post-training feature importance approaches assist\nthis interpretation, there is an overall lack of consensus regarding how\nfeature importance should be quantified, making explanations of model\npredictions unreliable. In addition, many of these explanations depend on the\nspecific machine learning approach employed and on the subset of data used when\ncalculating feature importance. A possible solution to improve the reliability\nof explanations is to combine results from multiple feature importance\nquantifiers from different machine learning approaches coupled with\nre-sampling. Current state-of-the-art ensemble feature importance fusion uses\ncrisp techniques to fuse results from different approaches. There is, however,\nsignificant loss of information as these approaches are not context-aware and\nreduce several quantifiers to a single crisp output. More importantly, their\nrepresentation of 'importance' as coefficients is misleading and\nincomprehensible to end-users and decision makers. Here we show how the use of\nfuzzy data fusion methods can overcome some of the important limitations of\ncrisp fusion methods.",
    "descriptor": "\nComments: 12 pages, 11 figures, 8 tables\n",
    "authors": [
      "Divish Rengasamy",
      "Jimiama M. Mase",
      "Mercedes Torres Torres",
      "Benjamin Rothwell",
      "David A. Winkler",
      "Grazziela P. Figueredo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.11713"
  },
  {
    "id": "arXiv:2110.11719",
    "title": "Experience with PCIe streaming on FPGA for high throughput ML  inferencing",
    "abstract": "Achieving maximum possible rate of inferencing with minimum hardware\nresources plays a major role in reducing enterprise operational costs. In this\npaper we explore use of PCIe streaming on FPGA based platforms to achieve high\nthroughput. PCIe streaming is a unique capability available on FPGA that\neliminates the need for memory copy overheads. We have presented our results\nfor inferences on a gradient boosted trees model, for online retail\nrecommendations. We compare the results achieved with the popular library\nimplementations on GPU and the CPU platforms and observe that the PCIe\nstreaming enabled FPGA implementation achieves the best overall measured\nperformance. We also measure power consumption across all platforms and find\nthat the PCIe streaming on FPGA platform achieves the 25x and 12x better energy\nefficiency than an implementation on CPU and GPU platforms, respectively. We\ndiscuss the conditions that need to be met, in order to achieve this kind of\nacceleration on the FPGA. Further, we analyze the run time statistics on GPU\nand FPGA and identify opportunities to enhance performance on both the\nplatforms.",
    "descriptor": "",
    "authors": [
      "Piyush Manavar",
      "Manoj Nambiar",
      "Nupur Sumeet",
      "Rekha Singhal",
      "Sharod Choudhary",
      "Amey Pandit"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2110.11719"
  },
  {
    "id": "arXiv:2110.11723",
    "title": "A Simple Boosting Framework for Transshipment",
    "abstract": "Transshipment, also known under the names of earth mover's distance,\nuncapacitated min-cost flow, or Wasserstein's metric, is an important and\nwell-studied problem that asks to find a flow of minimum cost that routes a\ngeneral demand vector. Adding to its importance, recent advancements in our\nunderstanding of algorithms for transshipment have led to breakthroughs for the\nfundamental problem of computing shortest paths. Specifically, the recent\nnear-optimal $(1+\\varepsilon)$-approximate single-source shortest path\nalgorithms in the parallel and distributed settings crucially solve\ntransshipment as a central step of their approach.\nThe key property that differentiates transshipment from other similar\nproblems like shortest path is the so-called \\emph{boosting}: one can boost a\n(bad) approximate solution to a near-optimal $(1 + \\varepsilon)$-approximate\nsolution. This conceptually reduces the problem to finding an approximate\nsolution. However, not all approximations can be boosted -- there have been\nseveral proposed approaches that were shown to be susceptible to boosting, and\na few others where boosting was left as an open question.\nThe main takeaway of our paper is that any black-box $\\alpha$-approximate\ntransshipment solver that computes a \\emph{dual} solution can be boosted to an\n$(1 + \\varepsilon)$-approximate solver. Moreover, we significantly simplify and\ndecouple previous approaches to transshipment (in sequential, parallel, and\ndistributed settings) by showing all of them (implicitly) obtain approximate\ndual solutions.\nOur analysis is very simple and relies only on the well-known multiplicative\nweights framework. Furthermore, to keep the paper completely self-contained, we\nprovide a new (and arguably much simpler) analysis of multiplicative weights\nthat leverages well-known optimization tools to bypass the ad-hoc calculations\nused in the standard analyses.",
    "descriptor": "",
    "authors": [
      "Goran Zuzic"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.11723"
  },
  {
    "id": "arXiv:2110.11725",
    "title": "Stabilization Voltage of a DC-Microgrid Using ANFIS Controller  Considering EVs, DERs, and Transient Storage",
    "abstract": "A hybrid DC microgrid with a stochastic power resource such as a PV,\nPhotovoltaic, an EV, electrical vehicle, and an ultracapacitor is studied in\nthis paper to stabilize the voltage. The PV is considered as the main power\nresource while battery and ultracapacitor are considered as supplementary power\nsources for long-term and short-term power insufficiency. Fuzzy logic, namely\nANFIS, controller is proposed to control bus voltage, and decreasing the stress\nupon the battery of EV, and transfer energy between ancillary sources in an\nappropriate timely manner. Besides, particle swarm optimization is applied to\ntune the fuzzy inference systems to fully handle the abovementioned goals in an\noptimal manner. The proposed methodology is compared with the conventional\ncontroller approach, and the effectiveness of the proposed method is\ninvestigated by a simulation for different types of energy inequality\nconditions. Moreover, ultra-capacitor, namely transient storage, is considered\nto protect the battery of EV from charging multiple times.",
    "descriptor": "\nComments: 18 pages, 27 figures, don't submitted\n",
    "authors": [
      "Hussein Zolfaghari",
      "Amin Ramezani",
      "Hamid Reza Momeni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.11725"
  },
  {
    "id": "arXiv:2110.11728",
    "title": "BlendGAN: Implicitly GAN Blending for Arbitrary Stylized Face Generation",
    "abstract": "Generative Adversarial Networks (GANs) have made a dramatic leap in\nhigh-fidelity image synthesis and stylized face generation. Recently, a\nlayer-swapping mechanism has been developed to improve the stylization\nperformance. However, this method is incapable of fitting arbitrary styles in a\nsingle model and requires hundreds of style-consistent training images for each\nstyle. To address the above issues, we propose BlendGAN for arbitrary stylized\nface generation by leveraging a flexible blending strategy and a generic\nartistic dataset. Specifically, we first train a self-supervised style encoder\non the generic artistic dataset to extract the representations of arbitrary\nstyles. In addition, a weighted blending module (WBM) is proposed to blend face\nand style representations implicitly and control the arbitrary stylization\neffect. By doing so, BlendGAN can gracefully fit arbitrary styles in a unified\nmodel while avoiding case-by-case preparation of style-consistent training\nimages. To this end, we also present a novel large-scale artistic face dataset\nAAHQ. Extensive experiments demonstrate that BlendGAN outperforms\nstate-of-the-art methods in terms of visual quality and style diversity for\nboth latent-guided and reference-guided stylized face synthesis.",
    "descriptor": "",
    "authors": [
      "Mingcong Liu",
      "Qiang Li",
      "Zekui Qin",
      "Guoxin Zhang",
      "Pengfei Wan",
      "Wen Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11728"
  },
  {
    "id": "arXiv:2110.11729",
    "title": "FakeNewsLab: Experimental Study on Biases and Pitfalls Preventing us  from Distinguishing True from False News",
    "abstract": "Misinformation posting and spreading in Social Media is ignited by personal\ndecisions on the truthfulness of news that may cause wide and deep cascades at\na large scale in a fraction of minutes. When individuals are exposed to\ninformation, they usually take a few seconds to decide if the content (or the\nsource) is reliable, and eventually to share it. Although the opportunity to\nverify the rumour is often just one click away, many users fail to make a\ncorrect evaluation. We studied this phenomenon by implementing a web-based\nquestionnaire that was compiled by 7,298 different volunteers. Participants\nwere asked to mark 20 news as true or false. Interestingly, false news is\ncorrectly identified more frequently than true news, but showing the full\narticle instead of just the title, surprisingly, does not increase general\naccuracy. Also, displaying the original source of the news may contribute to\nmislead the user in some cases, while the wisdom of the crowd can positively\nassist individuals' ability to classify correctly. Furthermore, participants\nthat autonomously opened an additional browser tab while compiling the survey\nshow higher accuracy than users that did not. This suggests a parallel\nfact-checking activity that support users' decisions. Finally, users that\ndeclare themselves as young adults are also those who open a new tab more\noften, suggesting more familiarity with the Web.",
    "descriptor": "\nComments: 18 pages, 11 figures, 3 tables\n",
    "authors": [
      "Giancarlo Ruffo",
      "Alfonso Semeraro"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.11729"
  },
  {
    "id": "arXiv:2110.11736",
    "title": "MANDERA: Malicious Node Detection in Federated Learning via Ranking",
    "abstract": "Federated learning is a distributed learning paradigm which seeks to preserve\nthe privacy of each participating node's data. However, federated learning is\nvulnerable to attacks, specifically to our interest, model integrity attacks.\nIn this paper, we propose a novel method for malicious node detection called\nMANDERA. By transferring the original message matrix into a ranking matrix\nwhose column shows the relative rankings of all local nodes along different\nparameter dimensions, our approach seeks to distinguish the malicious nodes\nfrom the benign ones with high efficiency based on key characteristics of the\nrank domain. We have proved, under mild conditions, that MANDERA is guaranteed\nto detect all malicious nodes under typical Byzantine attacks with no prior\nknowledge or history about the participating nodes. The effectiveness of the\nproposed approach is further confirmed by experiments on two classic datasets,\nCIFAR-10 and MNIST. Compared to the state-of-art methods in the literature for\ndefending Byzantine attacks, MANDERA is unique in its way to identify the\nmalicious nodes by ranking and its robustness to effectively defense a wide\nrange of attacks.",
    "descriptor": "\nComments: 14 pages, 6 figures, ICLR\n",
    "authors": [
      "Wanchuang Zhu",
      "Benjamin Zi Hao Zhao",
      "Simon Luo",
      "Ke Deng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11736"
  },
  {
    "id": "arXiv:2110.11737",
    "title": "Measuring the Non-Transitivity in Chess",
    "abstract": "It has long been believed that Chess is the \\emph{Drosophila} of Artificial\nIntelligence (AI). Studying Chess can productively provide valid knowledge\nabout complex systems. Although remarkable progress has been made on solving\nChess, the geometrical landscape of Chess in the strategy space is still\nmysterious. Judging on AI-generated strategies, researchers hypothesised that\nthe strategy space of Chess possesses a spinning top geometry, with the upright\naxis representing the \\emph{transitive} dimension (e.g., A beats B, B beats C,\nA beats C), and the radial axis representing the \\emph{non-transitive}\ndimension (e.g., A beats B, B beats C, C beats A). However, it is unclear\nwhether such a hypothesis holds for real-world strategies. In this paper, we\nquantify the non-transitivity in Chess through real-world data from human\nplayers. Specifically, we performed two ways of non-transitivity\nquantifications -- Nash Clustering and counting the number of\nRock-Paper-Scissor cycles -- on over one billion match data from Lichess and\nFICS. Our findings positively indicate that the strategy space occupied by\nreal-world Chess strategies demonstrates a spinning top geometry, and more\nimportantly, there exists a strong connection between the degree of\nnon-transitivity and the progression of a Chess player's rating. In particular,\nhigh degrees of non-transitivity tend to prevent human players from making\nprogress on their Elo rating, whereas progressions are easier to make at the\nlevel of ratings where the degree of non-transitivity is lower. Additionally,\nwe also investigate the implication of the degree of non-transitivity for\npopulation-based training methods. By considering \\emph{fixed-memory Fictitious\nPlay} as a proxy, we reach the conclusion that maintaining large-size and\ndiverse populations of strategies is imperative to training effective AI agents\nin solving Chess types of games.",
    "descriptor": "",
    "authors": [
      "Ricky Sanjaya",
      "Jun Wang",
      "Yaodong Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.11737"
  },
  {
    "id": "arXiv:2110.11739",
    "title": "UBR$^2$S: Uncertainty-Based Resampling and Reweighting Strategy for  Unsupervised Domain Adaptation",
    "abstract": "Unsupervised domain adaptation (UDA) deals with the adaptation process of a\nmodel to an unlabeled target domain while annotated data is only available for\na given source domain. This poses a challenging task, as the domain shift\nbetween source and target instances deteriorates a model's performance when not\naddressed. In this paper, we propose UBR$^2$S - the Uncertainty-Based\nResampling and Reweighting Strategy - to tackle this problem. UBR$^2$S employs\na Monte Carlo dropout-based uncertainty estimate to obtain per-class\nprobability distributions, which are then used for dynamic resampling of\npseudo-labels and reweighting based on their sample likelihood and the\naccompanying decision error. Our proposed method achieves state-of-the-art\nresults on multiple UDA datasets with single and multi-source adaptation tasks\nand can be applied to any off-the-shelf network architecture. Code for our\nmethod is available at https://gitlab.com/tringwald/UBR2S.",
    "descriptor": "\nComments: Accepted at the 32nd British Machine Vision Conference (BMVC 2021)\n",
    "authors": [
      "Tobias Ringwald",
      "Rainer Stiefelhagen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11739"
  },
  {
    "id": "arXiv:2110.11740",
    "title": "Selfish & Opaque Transaction Ordering in the Bitcoin Blockchain: The  Case for Chain Neutrality",
    "abstract": "Most public blockchain protocols, including the popular Bitcoin and Ethereum\nblockchains, do not formally specify the order in which miners should select\ntransactions from the pool of pending (or uncommitted) transactions for\ninclusion in the blockchain. Over the years, informal conventions or \"norms\"\nfor transaction ordering have, however, emerged via the use of shared software\nby miners, e.g., the GetBlockTemplate (GBT) mining protocol in Bitcoin Core.\nToday, a widely held view is that Bitcoin miners prioritize transactions based\non their offered \"transaction fee-per-byte.\" Bitcoin users are, consequently,\nencouraged to increase the fees to accelerate the commitment of their\ntransactions, particularly during periods of congestion. In this paper, we\naudit the Bitcoin blockchain and present statistically significant evidence of\nmining pools deviating from the norms to accelerate the commitment of\ntransactions for which they have (i) a selfish or vested interest, or (ii)\nreceived dark-fee payments via opaque (non-public) side-channels. As\nblockchains are increasingly being used as a record-keeping substrate for a\nvariety of decentralized (financial technology) systems, our findings call for\nan urgent discussion on defining neutrality norms that miners must adhere to\nwhen ordering transactions in the chains. Finally, we make our data sets and\nscripts publicly available.",
    "descriptor": "\nComments: This is a pre-print of our paper accepted to appear to ACM IMC 2021\n",
    "authors": [
      "Johnnatan Messias",
      "Mohamed Alzayat",
      "Balakrishnan Chandrasekaran",
      "Krishna P. Gummadi",
      "Patrick Loiseau",
      "Alan Mislove"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.11740"
  },
  {
    "id": "arXiv:2110.11742",
    "title": "Few-shot Semantic Segmentation with Self-supervision from Pseudo-classes",
    "abstract": "Despite the success of deep learning methods for semantic segmentation,\nfew-shot semantic segmentation remains a challenging task due to the limited\ntraining data and the generalisation requirement for unseen classes. While\nrecent progress has been particularly encouraging, we discover that existing\nmethods tend to have poor performance in terms of meanIoU when query images\ncontain other semantic classes besides the target class. To address this issue,\nwe propose a novel self-supervised task that generates random pseudo-classes in\nthe background of the query images, providing extra training data that would\notherwise be unavailable when predicting individual target classes. To that\nend, we adopted superpixel segmentation for generating the pseudo-classes. With\nthis extra supervision, we improved the meanIoU performance of the\nstate-of-the-art method by 2.5% and 5.1% on the one-shot tasks, as well as 6.7%\nand 4.4% on the five-shot tasks, on the PASCAL-5i and COCO benchmarks,\nrespectively.",
    "descriptor": "\nComments: To appear in the proceedings of the British Machine Vision Conference (BMVC) 2021\n",
    "authors": [
      "Yiwen Li",
      "Gratianus Wesley Putra Data",
      "Yunguan Fu",
      "Yipeng Hu",
      "Victor Adrian Prisacariu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11742"
  },
  {
    "id": "arXiv:2110.11744",
    "title": "The Critique of Crowds: Using Collective Criticism to Crowdsource  Subjective Preferences",
    "abstract": "Crowdsourcing encompasses everything from large collaborative projects to\nmicrotasks performed in parallel and at scale. However, understanding\nsubjective preferences can still be difficult: a majority of problems do not\nhave validated questionnaires and pairwise comparisons do not scale, even with\naccess to the crowd. Furthermore, in daily life we are used to expressing\nopinions as critiques (e.g. it was too cold, too spicy, too big), rather than\ndescribing precise preferences or choosing between (perhaps equally bad)\ndiscrete options. Unfortunately, it is difficult to analyze such qualitative\nfeedback, especially when we want to make quantitative decisions.\nIn this article, we present collective criticism, a crowdsourcing approach\nwhere users provide feedback to microtasks in the form of critiques, such as\n\"it was too easy/too challenging\". This qualitative feedback is used to perform\nquantitative analysis of users' preferences and opinions. Collective criticism\nhas several advantages over other approaches: \"too much/too little\"-style\ncritiques are easy for users to provide and it allows us to build predictive\nmodels for the optimal parameterization of the variables being critiqued. We\npresent two case studies where we model: (i) aesthetic preferences in neural\nstyle transfer and (ii) hedonic experiences in the video game Tetris. These\nstudies demonstrate the flexibility of our approach, and show that it produces\nrobust results that are straightforward for experimenters to interpret and\ninline with users' stated preferences.",
    "descriptor": "",
    "authors": [
      "Alan Medlar",
      "Jing Li",
      "Yang Liu",
      "Dorota Glowacka"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.11744"
  },
  {
    "id": "arXiv:2110.11746",
    "title": "Creating and Reenacting Controllable 3D Humans with Differentiable  Rendering",
    "abstract": "This paper proposes a new end-to-end neural rendering architecture to\ntransfer appearance and reenact human actors. Our method leverages a carefully\ndesigned graph convolutional network (GCN) to model the human body manifold\nstructure, jointly with differentiable rendering, to synthesize new videos of\npeople in different contexts from where they were initially recorded. Unlike\nrecent appearance transferring methods, our approach can reconstruct a fully\ncontrollable 3D texture-mapped model of a person, while taking into account the\nmanifold structure from body shape and texture appearance in the view\nsynthesis. Specifically, our approach models mesh deformations with a\nthree-stage GCN trained in a self-supervised manner on rendered silhouettes of\nthe human body. It also infers texture appearance with a convolutional network\nin the texture domain, which is trained in an adversarial regime to reconstruct\nhuman texture from rendered images of actors in different poses. Experiments on\ndifferent videos show that our method successfully infers specific body\ndeformations and avoid creating texture artifacts while achieving the best\nvalues for appearance in terms of Structural Similarity (SSIM), Learned\nPerceptual Image Patch Similarity (LPIPS), Mean Squared Error (MSE), and\nFr\\'echet Video Distance (FVD). By taking advantages of both differentiable\nrendering and the 3D parametric model, our method is fully controllable, which\nallows controlling the human synthesis from both pose and rendering parameters.\nThe source code is available at\nhttps://www.verlab.dcc.ufmg.br/retargeting-motion/wacv2022.",
    "descriptor": "\nComments: 10 pages, 6 figures, to appear in Proceedings of the IEEE Winter Conference on Applications of Computer Vision (WACV) 2022\n",
    "authors": [
      "Thiago L. Gomes",
      "Thiago M. Coutinho",
      "Rafael Azevedo",
      "Renato Martins",
      "Erickson R. Nascimento"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11746"
  },
  {
    "id": "arXiv:2110.11755",
    "title": "Monitoring with Verified Guarantees",
    "abstract": "Runtime monitoring is generally considered a light-weight alternative to\nformal verification. In safety-critical systems, however, the monitor itself is\na critical component. For example, if the monitor is responsible for initiating\nemergency protocols, as proposed in a recent aviation standard, then the safety\nof the entire system critically depends on guarantees of the correctness of the\nmonitor. In this paper, we present a verification extension to the Lola\nmonitoring language that integrates the efficient specification of the monitor\nwith Hoare-style annotations that guarantee the correctness of the monitor\nspecification. We add two new operators, assume and assert, which specify\nassumptions of the monitor and expectations on its output, respectively. The\nvalidity of the annotations is established by an integrated SMT solver. We\nreport on experience in applying the approach to specifications from the\navionics domain, where the annotation with assumptions and assertions has lead\nto the discovery of safety-critical errors in the specifications. The errors\nrange from incorrect default values in offset computations to complex\nalgorithmic errors that result in unexpected temporal patterns.",
    "descriptor": "",
    "authors": [
      "Dauer J.C.",
      "Finkbeiner B.",
      "Schirmer S"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.11755"
  },
  {
    "id": "arXiv:2110.11756",
    "title": "An efficient FV-based Virtual Boundary Method for the simulation of  fluid-solid interaction",
    "abstract": "In this work, the Immersed Boundary Method (IBM) with feedback forcing\nintroduced by Goldstein et al. (1993) and often referred in the literature as\nthe Virtual Boundary Method (VBM), is addressed. The VBM has been extensively\napplied both within a Spectral and a Finite Difference (FD) framework. Here, we\npropose to combine the VBM with a computationally efficient Finite Volume (FV)\nmethod. We will show that for similar computational configurations, FV and FD\nmethods provide significantly different results. Furthermore, we propose to\nmodify the standard feedback forcing scheme, based on a Proportional-Integral\n(PI) controller, with the introduction of a derivative action, in order to\nobtain a Proportial-Integral-Derivative (PID) controller. The stability\nanalysis for the Backward Differentiation Formula of order 1 (BDF1) time scheme\nis modified accordingly, and extended to the Backward Differentiation Formula\nof order 2 (BDF2) time scheme. We will show that, for the BDF2 time scheme, the\nderivative action allows to improve the stability characteristics of the\nsystem. Our approach is validated against numerical data available in the\nliterature for a stationary/rigidly moving 2D circular cylinder in several\nconfigurations. Finally, a Fluid-Structure Interaction (FSI) benchmark, related\nto the frequency response of a cantilever beam coupled with a fluid, is\npresented: we numerically demonstrate that the introduction of the derivative\naction plays an important role in order to properly detect the fluid-structure\ninteraction coupling.",
    "descriptor": "\nComments: 23 pages, 18 figures, 9 tables\n",
    "authors": [
      "Michele Girfoglio",
      "Giovanni Stabile",
      "Andrea Mola",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.11756"
  },
  {
    "id": "arXiv:2110.11758",
    "title": "The Crew: The Quest for Planet Nine is NP-Complete",
    "abstract": "In this paper we study the cooperative card game, The Crew: The Quest for\nPlanet Nine from the viewpoint of algorithmic combinatorial game theory. The\nCrew: The Quest for Planet Nine, is a game based off of traditional trick\ntaking card games, like bridge or hearts. In The Crew, players are dealt a hand\nof cards, with cards being from one of $c$ colors and having a value between 1\nto $n$. Players also draft objectives, which correspond to a card in the\ncurrent game that they must collect in order to win. Players then take turns\neach playing one card in a trick, with the player who played the highest value\ncard taking the trick and all cards played in it. If all players complete all\nof their objectives, the players win. The game also forces players to not talk\nabout the cards in their hand, and has a number of \"Task Tokens\" which can\nmodify the rules slightly. In this work, we introduce and formally define a\nperfect-information model of this problem, and show that the general unbounded\nversion, as well as the constant player count version are both intractable.\nHowever, we also show that two bounded versions of this decision problem --\ndeciding whether or not all players can complete their objectives -- can be\nsolved in polynomial time.",
    "descriptor": "\nComments: 14 pages, 3 figures\n",
    "authors": [
      "Frederick Reiber"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.11758"
  },
  {
    "id": "arXiv:2110.11759",
    "title": "Findings of the 2nd Photonics and Electronics Technology for Extreme  Scale Computing Workgroup (REPETE): Design Challenges for Socket Level  Photonic I/O",
    "abstract": "To inform research activities in HPC interconnect of strategic importance to\nthe USG beyond 2018, in January of 2018, the DoD sponsored the 2nd Photonics\nand Electronics Technology for Extreme-scale Computing (REPETE) workgroup.\nREPETE investigated new challenges in the area of HPC interconnect inspired by\ntechnology trends and challenges of vital importance to USG stakeholders.\nThe REPETE Working group investigated two focus areas of interest to the USG:\nSocket Level Photonic IO and Cryogenic Photonic IO. The working group spanned\nindustry, academia, and government, in research, development, product, and\ntechnology investment areas.\nThe workgroup team focusing on current and future design challenges for\nsocket level photonic IO began discussing technical challenges and current\nstate of applying photonics to off-chip IO in April of 2019 through biweekly\nmeetings that concluded in early September of 2019. The focus of these meetings\nwas to discuss what technology exists for moving the conversion of electrical\nsignaling to photonic signaling from the node (as is currently done) down to\nwithin the socket for off-chip IO.\nAreas discussed include: I/O Requirements and Trends at the Compute Socket\nfor 2025 and Beyond; Current and Near-Term Copper Solutions for Off-Chip,\nSocket-Level Interconnect; Current Photonic Solutions for Off-Chip or\nSocket-Level Interconnect; Light Generation for Off-Chip, Socket-Level IO;\nFabrication and Packaging of Photonic Integrated Circuits; All-Photonic\nSwitching Technology; and Simulation of Photonic Interconnects.",
    "descriptor": "",
    "authors": [
      "Karen Grutter",
      "Tom Salter",
      "Tim Horton"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2110.11759"
  },
  {
    "id": "arXiv:2110.11763",
    "title": "Game Redesign in No-regret Game Playing",
    "abstract": "We study the game redesign problem in which an external designer has the\nability to change the payoff function in each round, but incurs a design cost\nfor deviating from the original game. The players apply no-regret learning\nalgorithms to repeatedly play the changed games with limited feedback. The\ngoals of the designer are to (i) incentivize all players to take a specific\ntarget action profile frequently; and (ii) incur small cumulative design cost.\nWe present game redesign algorithms with the guarantee that the target action\nprofile is played in T-o(T) rounds while incurring only o(T) cumulative design\ncost. Game redesign describes both positive and negative applications: a\nbenevolent designer who incentivizes players to take a target action profile\nwith better social welfare compared to the solution of the original game, or a\nmalicious attacker whose target action profile benefits themselves but not the\nplayers. Simulations on four classic games confirm the effectiveness of our\nproposed redesign algorithms.",
    "descriptor": "",
    "authors": [
      "Yuzhe Ma",
      "Young Wu",
      "Xiaojin Zhu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11763"
  },
  {
    "id": "arXiv:2110.11765",
    "title": "MOTENS: A Pedagogical Design Model for Serious Cyber Games",
    "abstract": "In the last few years, serious games have become popular, with a consensus of\nthe benefits for teaching cyber security awareness and education. However,\nthere is still a lack of pedagogical driven methodologies and tools to support\nserious games design to ensure they achieve the learning objectives. This paper\nproposes MOTENS, a pedagogical model, to design serious cyber games based on\nthe gaps we identified in the current games design models and the lessons\nlearnt from creating a serious tabletop game called Riskio, designed to teach\ncyber security awareness and education. The MOTENS model has six high-level\ncomponents. Five components are linked to the games/design mechanics, and one\ncomponent, `Theory', that supports the design's cognitive principles, including\nplayers' motivation. The model is used to design serious cyber games and goes\nthrough five stages, from identifying and segmenting target players, steps to\ncreating game mechanics linked to pedagogy instruction and then to testing to\ncreate a serious game that is designed to achieve the games learning\nobjectives.",
    "descriptor": "\nComments: 22 pages, 12 figures and 6 tables\n",
    "authors": [
      "Stephen Hart",
      "Basel Halak",
      "Vladimiro Sassone"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.11765"
  },
  {
    "id": "arXiv:2110.11766",
    "title": "Semantic Identifiers and DNS Names for IoT",
    "abstract": "In this paper, we propose a scheme for representing semantic metadata of IoT\ndevices in compact identifiers and DNS names to enable simple discovery and\nsearch with standard DNS servers. Our scheme defines a binary identifier as a\nsequence of bits: a Context to use and several bits of fields corresponding to\nsemantic properties specific to the Context. The bit string is then encoded as\nbase32 characters and registered in DNS. Furthermore, we use the compact\nsemantic DNS names to offer support for search and discovery. We propose to\ntake advantage of the DNS system as the basic functionality for querying and\ndiscovery of semantic properties related to IoT devices. We have defined three\nspecific Contexts for hierarchical semantic properties as well as logical and\ngeographical locations. For this last part, we have developed two prototypes\nfor managing geo-identifiers in LoRa networks, one based on Node and the Redis\nin-memory database, the other one based on the CoreDNS server.",
    "descriptor": "",
    "authors": [
      "Simon Fernandez",
      "Michele Amoretti",
      "Fabrizio Restori",
      "Maciej Korczynski",
      "Andrzej Duda"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.11766"
  },
  {
    "id": "arXiv:2110.11767",
    "title": "Exploiting Cross-Modal Prediction and Relation Consistency for  Semi-Supervised Image Captioning",
    "abstract": "The task of image captioning aims to generate captions directly from images\nvia the automatically learned cross-modal generator. To build a well-performing\ngenerator, existing approaches usually need a large number of described images,\nwhich requires a huge effects on manual labeling. However, in real-world\napplications, a more general scenario is that we only have limited amount of\ndescribed images and a large number of undescribed images. Therefore, a\nresulting challenge is how to effectively combine the undescribed images into\nthe learning of cross-modal generator. To solve this problem, we propose a\nnovel image captioning method by exploiting the Cross-modal Prediction and\nRelation Consistency (CPRC), which aims to utilize the raw image input to\nconstrain the generated sentence in the commonly semantic space. In detail,\nconsidering that the heterogeneous gap between modalities always leads to the\nsupervision difficulty of using the global embedding directly, CPRC turns to\ntransform both the raw image and corresponding generated sentence into the\nshared semantic space, and measure the generated sentence from two aspects: 1)\nPrediction consistency. CPRC utilizes the prediction of raw image as soft label\nto distill useful supervision for the generated sentence, rather than employing\nthe traditional pseudo labeling; 2) Relation consistency. CPRC develops a novel\nrelation consistency between augmented images and corresponding generated\nsentences to retain the important relational knowledge. In result, CPRC\nsupervises the generated sentence from both the informativeness and\nrepresentativeness perspectives, and can reasonably use the undescribed images\nto learn a more effective generator under the semi-supervised scenario.",
    "descriptor": "",
    "authors": [
      "Yang Yang",
      "Hongchen Wei",
      "Hengshu Zhu",
      "Dianhai Yu",
      "Hui Xiong",
      "Qingshan Liu",
      "Jian Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11767"
  },
  {
    "id": "arXiv:2110.11769",
    "title": "Clustering of Bank Customers using LSTM-based encoder-decoder and  Dynamic Time Warping",
    "abstract": "Clustering is an unsupervised data mining technique that can be employed to\nsegment customers. The efficient clustering of customers enables banks to\ndesign and make offers based on the features of the target customers. The\npresent study uses a real-world financial dataset (Berka, 2000) to cluster bank\ncustomers by an encoder-decoder network and the dynamic time warping (DTW)\nmethod. The customer features required for clustering are obtained in four\nways: Dynamic Time Warping (DTW), Recency Frequency and Monetary (RFM), LSTM\nencoder-decoder network, and our proposed hybrid method. Once the LSTM model\nwas trained by customer transaction data, a feature vector of each customer was\nautomatically extracted by the encoder.Moreover, the distance between pairs of\nsequences of transaction amounts was obtained using DTW. Another vector feature\nwas calculated for customers by RFM scoring. In the hybrid method, the feature\nvectors are combined from the encoder-decoder output, the DTW distance, and the\ndemographic data (e.g., age and gender). Finally, feature vectors were\nintroduced as input to the k-means clustering algorithm, and we compared\nclustering results with Silhouette and Davies-Bouldin index. As a result, the\nclusters obtained from the hybrid approach are more accurate and meaningful\nthan those derived from individual clustering techniques. In addition, the type\nof neural network layers had a substantial effect on the clusters, and high\nnetwork error does not necessarily worsen clustering performance.",
    "descriptor": "",
    "authors": [
      "Ehsan Barkhordar",
      "Mohammad Hassan Shirali-Shahreza",
      "Hamid Reza Sadeghi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.11769"
  },
  {
    "id": "arXiv:2110.11772",
    "title": "Grounding force-directed network layouts with latent space models",
    "abstract": "Force-directed layout algorithms are ubiquitously-used tools for network\nvisualization across a variety of scientific disciplines. However, they lack\ntheoretical grounding which allows to interpret their outcomes rigorously. We\npropose an approach building on latent space network models, which assume that\nthe probability of nodes forming a tie depends on their distance in an\nunobserved latent space. From such latent space models, we derive force\nequations for a force-directed layout algorithm. With this approach,\nforce-directed layouts become interpretable, since the forces infer positions\nwhich maximize the likelihood of the given network under the latent space\nmodel. We implement these forces for (un)directed unweighted and weighted\nnetworks. We spatialise different real-world networks, where we find central\nnetwork properties reflected in the layout, and compare the layouts to\ndifferent force-directed algorithms already in use today.",
    "descriptor": "",
    "authors": [
      "Felix Gaisbauer",
      "Armin Pournaki",
      "Sven Banisch",
      "Eckehard Olbrich"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.11772"
  },
  {
    "id": "arXiv:2110.11773",
    "title": "Sinkformers: Transformers with Doubly Stochastic Attention",
    "abstract": "Attention based models such as Transformers involve pairwise interactions\nbetween data points, modeled with a learnable attention matrix. Importantly,\nthis attention matrix is normalized with the SoftMax operator, which makes it\nrow-wise stochastic. In this paper, we propose instead to use Sinkhorn's\nalgorithm to make attention matrices doubly stochastic. We call the resulting\nmodel a Sinkformer. We show that the row-wise stochastic attention matrices in\nclassical Transformers get close to doubly stochastic matrices as the number of\nepochs increases, justifying the use of Sinkhorn normalization as an\ninformative prior. On the theoretical side, we show that, unlike the SoftMax\noperation, this normalization makes it possible to understand the iterations of\nself-attention modules as a discretized gradient-flow for the Wasserstein\nmetric. We also show in the infinite number of samples limit that, when\nrescaling both attention matrices and depth, Sinkformers operate a heat\ndiffusion. On the experimental side, we show that Sinkformers enhance model\naccuracy in vision and natural language processing tasks. In particular, on 3D\nshapes classification, Sinkformers lead to a significant improvement.",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Michael E. Sander",
      "Pierre Ablin",
      "Mathieu Blondel",
      "Gabriel Peyr\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.11773"
  },
  {
    "id": "arXiv:2110.11774",
    "title": "Learning Stable Vector Fields on Lie Groups",
    "abstract": "Learning robot motions from demonstration requires having models that are\nable to represent vector fields for the full robot pose when the task is\ndefined in operational space. Recent advances in reactive motion generation\nhave shown that it is possible to learn adaptive, reactive, smooth, and stable\nvector fields. However, these approaches define a vector field on a flat\nEuclidean manifold, while representing vector fields for orientations required\nto model the dynamics in non-Euclidean manifolds, such as Lie Groups. In this\npaper, we present a novel vector field model that can guarantee most of the\nproperties of previous approaches i.e., stability, smoothness, and reactivity\nbeyond the Euclidean space. In the experimental evaluation, we show the\nperformance of our proposed vector field model to learn stable vector fields\nfor full robot poses as SE(2) and SE(3) in both simulated and real robotics\ntasks.",
    "descriptor": "\nComments: ICRA RA-L preprint\n",
    "authors": [
      "Julen Urain",
      "Davide Tateo",
      "Jan Peters"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11774"
  },
  {
    "id": "arXiv:2110.11775",
    "title": "Federated Learning over Wireless IoT Networks with Optimized  Communication and Resources",
    "abstract": "To leverage massive distributed data and computation resources, machine\nlearning in the network edge is considered to be a promising technique\nespecially for large-scale model training. Federated learning (FL), as a\nparadigm of collaborative learning techniques, has obtained increasing research\nattention with the benefits of communication efficiency and improved data\nprivacy. Due to the lossy communication channels and limited communication\nresources (e.g., bandwidth and power), it is of interest to investigate fast\nresponding and accurate FL schemes over wireless systems. Hence, we investigate\nthe problem of jointly optimized communication efficiency and resources for FL\nover wireless Internet of things (IoT) networks. To reduce complexity, we\ndivide the overall optimization problem into two sub-problems, i.e., the client\nscheduling problem and the resource allocation problem. To reduce the\ncommunication costs for FL in wireless IoT networks, a new client scheduling\npolicy is proposed by reusing stale local model parameters. To maximize\nsuccessful information exchange over networks, a Lagrange multiplier method is\nfirst leveraged by decoupling variables including power variables, bandwidth\nvariables and transmission indicators. Then a linear-search based power and\nbandwidth allocation method is developed. Given appropriate hyper-parameters,\nwe show that the proposed communication-efficient federated learning (CEFL)\nframework converges at a strong linear rate. Through extensive experiments, it\nis revealed that the proposed CEFL framework substantially boosts both the\ncommunication efficiency and learning performance of both training loss and\ntest accuracy for FL over wireless IoT networks compared to a basic FL approach\nwith uniform resource allocation.",
    "descriptor": "",
    "authors": [
      "Hao Chen",
      "Shaocheng Huang",
      "Deyou Zhang",
      "Ming Xiao",
      "Mikael Skoglund",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.11775"
  },
  {
    "id": "arXiv:2110.11778",
    "title": "Domain Adaptation and Active Learning for Fine-Grained Recognition in  the Field of Biodiversity",
    "abstract": "Deep-learning methods offer unsurpassed recognition performance in a wide\nrange of domains, including fine-grained recognition tasks. However, in most\nproblem areas there are insufficient annotated training samples. Therefore, the\ntopic of transfer learning respectively domain adaptation is particularly\nimportant. In this work, we investigate to what extent unsupervised domain\nadaptation can be used for fine-grained recognition in a biodiversity context\nto learn a real-world classifier based on idealized training data, e.g.\npreserved butterflies and plants. Moreover, we investigate the influence of\ndifferent normalization layers, such as Group Normalization in combination with\nWeight Standardization, on the classifier. We discovered that domain adaptation\nworks very well for fine-grained recognition and that the normalization methods\nhave a great influence on the results. Using domain adaptation and Transferable\nNormalization, the accuracy of the classifier could be increased by up to 12.35\n% compared to the baseline. Furthermore, the domain adaptation system is\ncombined with an active learning component to improve the results. We compare\ndifferent active learning strategies with each other. Surprisingly, we found\nthat more sophisticated strategies provide better results than the random\nselection baseline for only one of the two datasets. In this case, the distance\nand diversity strategy performed best. Finally, we present a problem analysis\nof the datasets.",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Bernd Gruner",
      "Matthias K\u00f6rschens",
      "Bj\u00f6rn Barz",
      "Joachim Denzler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11778"
  },
  {
    "id": "arXiv:2110.11779",
    "title": "SwiftLane: Towards Fast and Efficient Lane Detection",
    "abstract": "Recent work done on lane detection has been able to detect lanes accurately\nin complex scenarios, yet many fail to deliver real-time performance\nspecifically with limited computational resources. In this work, we propose\nSwiftLane: a simple and light-weight, end-to-end deep learning based framework,\ncoupled with the row-wise classification formulation for fast and efficient\nlane detection. This framework is supplemented with a false positive\nsuppression algorithm and a curve fitting technique to further increase the\naccuracy. Our method achieves an inference speed of 411 frames per second,\nsurpassing state-of-the-art in terms of speed while achieving comparable\nresults in terms of accuracy on the popular CULane benchmark dataset. In\naddition, our proposed framework together with TensorRT optimization\nfacilitates real-time lane detection on a Nvidia Jetson AGX Xavier as an\nembedded system while achieving a high inference speed of 56 frames per second.",
    "descriptor": "\nComments: Accepted to 20th IEEE International Conference on Machine Learning and Applications (ICMLA) 2021\n",
    "authors": [
      "Oshada Jayasinghe",
      "Damith Anhettigama",
      "Sahan Hemachandra",
      "Shenali Kariyawasam",
      "Ranga Rodrigo",
      "Peshala Jayasekara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11779"
  },
  {
    "id": "arXiv:2110.11784",
    "title": "Safe rules for the identification of zeros in the solutions of the SLOPE  problem",
    "abstract": "In this paper we propose a methodology to accelerate the resolution of the\nso-called ``Sorted L-One Penalized Estimation'' (SLOPE) problem. Our method\nleverages the concept of ``safe screening'', well-studied in the literature for\n\\textit{group-separable} sparsity-inducing norms, and aims at identifying the\nzeros in the solution of SLOPE. More specifically, we introduce a family of\n\\(n!\\) safe screening rules for this problem, where \\(n\\) is the dimension of\nthe primal variable, and propose a tractable procedure to verify if one of\nthese tests is passed. Our procedure has a complexity \\(\\mathcal{O}(n\\log n +\nLT)\\) where \\(T\\leq n\\) is a problem-dependent constant and \\(L\\) is the number\nof zeros identified by the tests. We assess the performance of our proposed\nmethod on a numerical benchmark and emphasize that it leads to significant\ncomputational savings in many setups.",
    "descriptor": "\nComments: 24 pages, 3 figures\n",
    "authors": [
      "Cl\u00e9ment Elvira",
      "C\u00e9dric Herzet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11784"
  },
  {
    "id": "arXiv:2110.11788",
    "title": "An analysis on metric-driven multi-target sensor management: GOSPA  versus OSPA",
    "abstract": "This paper presents an analysis on sensor management using a cost function\nbased on a multi-target metric, in particular, the optimal\nsubpattern-assignment (OSPA) metric, the unnormalised OSPA (UOSPA) metric and\nthe generalised OSPA (GOSPA) metric (\\alpha=2). We consider the problem of\nmanaging an array of sensors, where each sensor is able to observe a region of\nthe surveillance area, not covered by other sensors, with a given sensing cost.\nWe look at the case in which there are far-away, independent potential targets,\nat maximum one per sensor region. In this set-up, the optimal action using\nGOSPA is taken for each sensor independently, as we may expect. On the\ncontrary, as a consequence of the spooky effect at a distance in optimal\nOSPA/UOSPA estimation, the optimal actions for different sensors using OSPA and\nUOSPA are entangled.",
    "descriptor": "\nComments: A presentation on the GOSPA metric can be found at this https URL\n",
    "authors": [
      "\u00c1ngel F. Garc\u00eda-Fern\u00e1ndez",
      "Marcel Hernandez",
      "Simon Maskell"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.11788"
  },
  {
    "id": "arXiv:2110.11790",
    "title": "Automatic Guide Generation for Stan via NumPyro",
    "abstract": "Stan is a very popular probabilistic language with a state-of-the-art HMC\nsampler but it only offers a limited choice of algorithms for black-box\nvariational inference. In this paper, we show that using our recently proposed\ncompiler from Stan to Pyro, Stan users can easily try the set of algorithms\nimplemented in Pyro for black-box variational inference. We evaluate our\napproach on PosteriorDB, a database of Stan models with corresponding data and\nreference posterior samples. Results show that the eight algorithms available\nin Pyro offer a range of possible compromises between complexity and accuracy.\nThis paper illustrates that compiling Stan to another probabilistic language\ncan be used to leverage new features for Stan users, and give access to a large\nset of examples for language developers who implement these new features.",
    "descriptor": "\nComments: PROBPROG 2021\n",
    "authors": [
      "Guillaume Baudart",
      "Louis Mandel"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2110.11790"
  },
  {
    "id": "arXiv:2110.11794",
    "title": "Federated Unlearning via Class-Discriminative Pruning",
    "abstract": "We explore the problem of selectively forgetting categories from trained CNN\nclassification models in the federated learning (FL). Given that the data used\nfor training cannot be accessed globally in FL, our insights probe deep into\nthe internal influence of each channel. Through the visualization of feature\nmaps activated by different channels, we observe that different channels have a\nvarying contribution to different categories in image classification. Inspired\nby this, we propose a method for scrubbing the model clean of information about\nparticular categories. The method does not require retraining from scratch, nor\nglobal access to the data used for training. Instead, we introduce the concept\nof Term Frequency Inverse Document Frequency (TF-IDF) to quantize the class\ndiscrimination of channels. Channels with high TF-IDF scores have more\ndiscrimination on the target categories and thus need to be pruned to unlearn.\nThe channel pruning is followed by a fine-tuning process to recover the\nperformance of the pruned model. Evaluated on CIFAR10 dataset, our method\naccelerates the speed of unlearning by 8.9x for the ResNet model, and 7.9x for\nthe VGG model under no degradation in accuracy, compared to retraining from\nscratch. For CIFAR100 dataset, the speedups are 9.9x and 8.4x, respectively. We\nenvision this work as a complementary block for FL towards compliance with\nlegal and ethical criteria.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Junxiao Wang",
      "Song Guo",
      "Xin Xie",
      "Heng Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11794"
  },
  {
    "id": "arXiv:2110.11805",
    "title": "Model, sample, and epoch-wise descents: exact solution of gradient flow  in the random feature model",
    "abstract": "Recent evidence has shown the existence of a so-called double-descent and\neven triple-descent behavior for the generalization error of deep-learning\nmodels. This important phenomenon commonly appears in implemented neural\nnetwork architectures, and also seems to emerge in epoch-wise curves during the\ntraining process. A recent line of research has highlighted that random matrix\ntools can be used to obtain precise analytical asymptotics of the\ngeneralization (and training) errors of the random feature model. In this\ncontribution, we analyze the whole temporal behavior of the generalization and\ntraining errors under gradient flow for the random feature model. We show that\nin the asymptotic limit of large system size the full time-evolution path of\nboth errors can be calculated analytically. This allows us to observe how the\ndouble and triple descents develop over time, if and when early stopping is an\noption, and also observe time-wise descent structures. Our techniques are based\non Cauchy complex integral representations of the errors together with recent\nrandom matrix methods based on linear pencils.",
    "descriptor": "",
    "authors": [
      "Antoine Bodin",
      "Nicolas Macris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.11805"
  },
  {
    "id": "arXiv:2110.11806",
    "title": "Multi-Horizon Planning of Multi-Energy Systems",
    "abstract": "In order to reach EU's goal of zero emissions in 2050, the energy system will\ngo through a significant transition over the next decades. To substitute fossil\nenergy carriers, renewable energy sources will be mainly integrated in the\npower system. Thereby, sector coupling will play a major role by making\nflexibility from other sectors such as heat or transport accessible to the\npower system. Planning the cost optimal transition requires a whole-system view\nover multiple horizons and across all sectors. This imposes the need for\nmulti-energy system (MES) models coupled with multi-horizon investment models.\nThis paper presents two multi-horizon planning approaches to determine the cost\noptimal pathway of a MES. As a major contribution, we propose a new method to\nincorporate technology-dependent learning cost curves in the planning problem\nand show that the resulting mixed-integer linear programming problem can be\nsolved faster with a Benders decomposition technique as compared to a closed\noptimization. As a further contribution, we demonstrate the usefulness of our\napproach by showing the MES expansion pathway for a small German test system.",
    "descriptor": "\nComments: submitted at Power Systems Computation Conference, 2022, Porto\n",
    "authors": [
      "Tim Felling",
      "Oliver Levers",
      "Philipp Fortenbacher"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.11806"
  },
  {
    "id": "arXiv:2110.11807",
    "title": "Signal-Envelope: A C++ library with Python bindings for temporal  envelope estimation",
    "abstract": "Signals can be interpreted as composed of a rapidly varying component\nmodulated by a slower varying envelope. Identifying this envelope is an\nessential operation in signal processing, with applications in areas ranging\nfrom seismology to medicine. Conventional envelope detection approaches based\non classic methods tend to lack generality, however, and need to be tailored to\neach specific application in order to yield reasonable results. Taking\ninspiration from geometric concepts, most notably the theory of alpha-shapes,\nwe introduce a general-purpose library to efficiently extract the envelope of\narbitrary signals.",
    "descriptor": "",
    "authors": [
      "Carlos Tarjano",
      "Valdecy Pereira"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.11807"
  },
  {
    "id": "arXiv:2110.11808",
    "title": "On the design of regularized explicit predictive controllers from  input-output data",
    "abstract": "On the wave of recent advances in data-driven predictive control, we present\nan explicit predictive controller that can be constructed from a batch of\ninput/output data only. The proposed explicit law is build upon a regularized\nimplicit data-driven predictive control problem, so as to guarantee the\nuniqueness of the explicit predictive controller. As a side benefit, the use of\nregularization is shown to improve the capability of the explicit law in coping\nwith noise on the data. The effectiveness of the retrieved explicit law and the\nrepercussions of regularization on noise handling are analyzed on two benchmark\nsimulation case studies, showing the potential of the proposed regularized\nexplicit controller.",
    "descriptor": "\nComments: Preprint submitted to IEEE Transaction on Automatic Control\n",
    "authors": [
      "Valentina Breschi",
      "Andrea Sassella",
      "Simone Formentin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.11808"
  },
  {
    "id": "arXiv:2110.11809",
    "title": "PropMix: Hard Sample Filtering and Proportional MixUp for Learning with  Noisy Labels",
    "abstract": "The most competitive noisy label learning methods rely on an unsupervised\nclassification of clean and noisy samples, where samples classified as noisy\nare re-labelled and \"MixMatched\" with the clean samples. These methods have two\nissues in large noise rate problems: 1) the noisy set is more likely to contain\nhard samples that are in-correctly re-labelled, and 2) the number of samples\nproduced by MixMatch tends to be reduced because it is constrained by the small\nclean set size. In this paper, we introduce the learning algorithm PropMix to\nhandle the issues above. PropMix filters out hard noisy samples, with the goal\nof increasing the likelihood of correctly re-labelling the easy noisy samples.\nAlso, PropMix places clean and re-labelled easy noisy samples in a training set\nthat is augmented with MixUp, removing the clean set size constraint and\nincluding a large proportion of correctly re-labelled easy noisy samples. We\nalso include self-supervised pre-training to improve robustness to high noisy\nlabel scenarios. Our experiments show that PropMix has state-of-the-art (SOTA)\nresults on CIFAR-10/-100(with symmetric, asymmetric and semantic label noise),\nRed Mini-ImageNet (from the Controlled Noisy Web Labels), Clothing1M and\nWebVision. In severe label noise bench-marks, our results are substantially\nbetter than other methods. The code is available\nathttps://github.com/filipe-research/PropMix.",
    "descriptor": "\nComments: Paper accepted at BMVC'21: The 32nd British Machine Vision Conference\n",
    "authors": [
      "Filipe R. Cordeiro",
      "Vasileios Belagiannis",
      "Ian Reid",
      "Gustavo Carneiro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11809"
  },
  {
    "id": "arXiv:2110.11810",
    "title": "IVS3D: An Open Source Framework for Intelligent Video Sampling and  Preprocessing to Facilitate 3D Reconstruction",
    "abstract": "The creation of detailed 3D models is relevant for a wide range of\napplications such as navigation in three-dimensional space, construction\nplanning or disaster assessment. However, the complex processing and long\nexecution time for detailed 3D reconstructions require the original database to\nbe reduced in order to obtain a result in reasonable time. In this paper we\ntherefore present our framework iVS3D for intelligent pre-processing of image\nsequences. Our software is able to down sample entire videos to a specific\nframe rate, as well as to resize and crop the individual images. Furthermore,\nthanks to our modular architecture, it is easy to develop and integrate plugins\nwith additional algorithms. We provide three plugins as baseline methods that\nenable an intelligent selection of suitable images and can enrich them with\nadditional information. To filter out images affected by motion blur, we\ndeveloped a plugin that detects these frames and also searches the spatial\nneighbourhood for suitable images as replacements. The second plugin uses\noptical flow to detect redundant images caused by a temporarily stationary\ncamera. In our experiments, we show how this approach leads to a more balanced\nimage sampling if the camera speed varies, and that excluding such redundant\nimages leads to a time saving of 8.1\\percent for our sequences. A third plugin\nmakes it possible to exclude challenging image regions from the 3D\nreconstruction by performing semantic segmentation. As we think that the\ncommunity can greatly benefit from such an approach, we will publish our\nframework and the developed plugins open source using the MIT licence to allow\nco-development and easy extension.",
    "descriptor": "\nComments: Accepted for the 16th International Symposium on Visual Computing (ISVC 2021)\n",
    "authors": [
      "Max Hermann",
      "Thomas Pollok",
      "Daniel Brommer",
      "Dominic Zahn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11810"
  },
  {
    "id": "arXiv:2110.11813",
    "title": "Handling Concurrency in Behavior Trees",
    "abstract": "This paper addresses the concurrency issues affecting Behavior Trees (BTs), a\npopular tool to model the behaviors of autonomous agents in the video game and\nthe robotics industry.\nBT designers can easily build complex behaviors composing simpler ones, which\nrepresents a key advantage of BTs. The parallel composition of BTs expresses a\nway to combine concurrent behaviors that has high potential, since composing\npre-existing BTs in parallel results easier than composing in parallel\nclassical control architectures, as finite state machines or teleo-reactive\nprograms. However, BT designers rarely use such composition due to the\nunderlying concurrency problems similar to the ones faced in concurrent\nprogramming. As a result, the parallel composition, despite its potential,\nfinds application only in the composition of simple behaviors or where the\ndesigner can guarantee the absence of conflicts by design.\nIn this paper, we define two new BT nodes to tackle the concurrency problems\nin BTs and we show how to exploit them to create predictable behaviors. In\naddition, we introduce measures to assess execution performance and show how\ndifferent design choices affect them. We validate our approach in both\nsimulations and the real world. Simulated experiments provide statistically\nsignificant data, whereas real-world experiments show the applicability of our\nmethod on real robots. We provided an open-source implementation of the novel\nBT formulation and published all the source code to reproduce the numerical\nexamples and experiments.",
    "descriptor": "\nComments: preprint version accepted to be published in IEEE Transaction on Robotics. arXiv admin note: text overlap with arXiv:1908.01539\n",
    "authors": [
      "Michele Colledanchise",
      "Lorenzo Natale"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.11813"
  },
  {
    "id": "arXiv:2110.11815",
    "title": "cleanTS: Automated (AutoML) Tool to Clean Univariate Time Series at  Microscales",
    "abstract": "Data cleaning is one of the most important tasks in data analysis processes.\nOne of the perennial challenges in data analytics is the detection and handling\nof non-valid data. Failing to do so can result in inaccurate analytics and\nunreliable decisions. The process of properly cleaning such data takes much\ntime. Errors are prevalent in time series data. It is usually found that real\nworld data is unclean and requires some pre-processing. The analysis of large\namounts of data is difficult. This paper is intended to provide an easy to use\nand reliable system which automates the cleaning process of univariate time\nseries data. Automating the process greatly reduces the time required.\nVisualizing a large amount of data at once is not very effective. To tackle\nthis issue, an R package cleanTS is proposed. The proposed system provides a\nway to analyze data on different scales and resolutions. Also, it provides\nusers with tools and a benchmark system for comparing various techniques used\nin data cleaning.",
    "descriptor": "\nComments: The cleanTS package is available in CRAN (this https URL)\n",
    "authors": [
      "Mayur Kishor Shende",
      "Andres E. Feijoo-Lorenzo",
      "Neeraj Dhanraj Bokde"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.11815"
  },
  {
    "id": "arXiv:2110.11819",
    "title": "Break your Bandit Routine with LSD Rewards: a Last Switch Dependent  Analysis of Satiation and Seasonality",
    "abstract": "Motivated by the fact that humans like some level of unpredictability or\nnovelty, and might therefore get quickly bored when interacting with a\nstationary policy, we introduce a novel non-stationary bandit problem, where\nthe expected reward of an arm is fully determined by the time elapsed since the\narm last took part in a switch of actions. Our model generalizes previous\nnotions of delay-dependent rewards, and also relaxes most assumptions on the\nreward function. This enables the modeling of phenomena such as progressive\nsatiation and periodic behaviours. Building upon the Combinatorial Semi-Bandits\n(CSB) framework, we design an algorithm and prove a bound on its regret with\nrespect to the optimal non-stationary policy (which is NP-hard to compute).\nSimilarly to previous works, our regret analysis is based on defining and\nsolving an appropriate trade-off between approximation and estimation.\nPreliminary experiments confirm the superiority of our algorithm over both the\noracle greedy approach and a vanilla CSB solver.",
    "descriptor": "",
    "authors": [
      "Pierre Laforgue",
      "Giulia Clerici",
      "Nicol\u00f2 Cesa-Bianchi",
      "Ran Gilad-Bachrach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11819"
  },
  {
    "id": "arXiv:2110.11821",
    "title": "Node-based Generalized Friendship Paradox fails",
    "abstract": "The Friendship Paradox--the principle that ``your friends have more friends\nthan you do''--is a combinatorial fact about degrees in a graph; but given that\nmany Web-based social activities are correlated with a user's degree, this fact\nhas been taken more broadly to suggest the empirical principle that ``your\nfriends are also more active than you are.'' This Generalized Friendship\nParadox, the notion that any attribute positively correlated with degree obeys\nthe Friendship Paradox, has been established mathematically in a network-level\nversion that essentially aggregates uniformly over all the edges of a network.\nHere we show, however, that the natural node-based version of the Generalized\nFriendship Paradox--which aggregates over nodes, not edges--may fail, even for\ndegree-attribute correlations approaching 1. Whether this version holds depends\nnot only on degree-attribute correlations, but also on the underlying network\nstructure and thus can't be said to be a universal phenomenon. We establish\nboth positive and negative results for this node-based version of the\nGeneralized Friendship Paradox and consider its implications for social-network\ndata.",
    "descriptor": "\nComments: 8 pages, 5 figures, 1 table\n",
    "authors": [
      "Anna Evtushenko",
      "Jon Kleinberg"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.11821"
  },
  {
    "id": "arXiv:2110.11822",
    "title": "Unraveling the hidden environmental impacts of AI solutions for  environment",
    "abstract": "In the past ten years artificial intelligence has encountered such dramatic\nprogress that it is seen now as a tool of choice to solve environmental issues\nand in the first place greenhouse gas emissions (GHG). At the same time the\ndeep learning community began to realize that training models with more and\nmore parameters required a lot of energy and as a consequence GHG emissions. To\nour knowledge, questioning the complete environmental impacts of AI methods for\nenvironment (\"AI for green\"), and not only GHG, has never been addressed\ndirectly. In this article we propose to study the possible negative impact of\n\"AI for green\" 1) by reviewing first the different types of AI impacts 2) by\npresenting the different methodologies used to assess those impacts, in\nparticular life cycle assessment and 3) by discussing how to assess the\nenvironmental usefulness of a general AI service.",
    "descriptor": "",
    "authors": [
      "Anne-Laure Ligozat",
      "Julien Lef\u00e8vre",
      "Aur\u00e9lie Bugeau",
      "Jacques Combaz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.11822"
  },
  {
    "id": "arXiv:2110.11826",
    "title": "Predictive machine learning for prescriptive applications: a coupled  training-validating approach",
    "abstract": "In this research we propose a new method for training predictive machine\nlearning models for prescriptive applications. This approach, which we refer to\nas coupled validation, is based on tweaking the validation step in the standard\ntraining-validating-testing scheme. Specifically, the coupled method considers\nthe prescription loss as the objective for hyper-parameter calibration. This\nmethod allows for intelligent introduction of bias in the prediction stage to\nimprove decision making at the prescriptive stage, and is generally applicable\nto most machine learning methods, including recently proposed hybrid\nprediction-stochastic-optimization techniques, and can be easily implemented\nwithout model-specific mathematical modeling. Several experiments with\nsynthetic and real data demonstrate promising results in reducing the\nprescription costs in both deterministic and stochastic models.",
    "descriptor": "",
    "authors": [
      "Ebrahim Mortaz",
      "Alexander Vinel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.11826"
  },
  {
    "id": "arXiv:2110.11827",
    "title": "Uniquely Decodable Multi-Amplitude Sequence for Massive Grant-free  Multiple-Access Adder Channels",
    "abstract": "Massive grant-free multiple-access is a valuable research topic for next\ngeneration multiple-access, since it significantly reduces the control\nsignaling overhead and transmission latency. This paper constructs a novel\nuniquely-decodable multi-amplitude sequence (UDAS) set for grant-free\nmultiple-access systems, which can provide high spectrum efficiency (SE)\nwithout additional redundancy and realize low-complexity active user detection\n(AUD). We firstly propose an UDAS-based multi-dimensional bit interleaving\ncoded modulation (MD-BICM) transmitter. Then, this paper presents the detailed\ndefinition of UDAS, and provides three conditions for constructing a UDAS set.\nFollowing, two kinds of UDAS sets are constructed based on cyclic and\nquasi-cyclic matrix modes; and some important features of the\ncyclic/quasi-cyclic UDAS sets are deduced. Besides, we present a statistic of\nUDAS feature based AUD algorithm (SoF-AUD), and a joint multiuser detection and\nimproved message passing iterative decoding algorithm for the proposed system.\nFinally, the active user error rate (AUER) and Shannon limits of the proposed\nsystem are deduced in details. Simulation results show that the AUER of our\nproposed system can reach an extremely low value $10^{-6}$, when $E_b/N_0$ is 0\ndB and the length of transmit block is larger than a given value (e.g., 576).\nMeanwhile, the SE of our proposed system can compare with the designed\nnon-orthogonal multiple-access (NOMA) codebooks, verifying the valid and\nflexible.",
    "descriptor": "\nComments: 14 pages, 8 figures\n",
    "authors": [
      "Q.Y. Yu",
      "K.X. Song"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.11827"
  },
  {
    "id": "arXiv:2110.11829",
    "title": "CNN-based Omnidirectional Object Detection for HermesBot Autonomous  Delivery Robot with Preliminary Frame Classification",
    "abstract": "Mobile autonomous robots include numerous sensors for environment perception.\nCameras are an essential tool for robot's localization, navigation, and\nobstacle avoidance. To process a large flow of data from the sensors, it is\nnecessary to optimize algorithms, or to utilize substantial computational\npower. In our work, we propose an algorithm for optimizing a neural network for\nobject detection using preliminary binary frame classification. An autonomous\noutdoor mobile robot with 6 rolling-shutter cameras on the perimeter providing\na 360-degree field of view was used as the experimental setup. The obtained\nexperimental results revealed that the proposed optimization accelerates the\ninference time of the neural network in the cases with up to 5 out of 6 cameras\ncontaining target objects.",
    "descriptor": "\nComments: Accepted to IEEE 20th International Conference on Advanced Robotics (ICAR) 2021, 6 pages, 7 figures\n",
    "authors": [
      "Saian Protasov",
      "Pavel Karpyshev",
      "Ivan Kalinov",
      "Pavel Kopanev",
      "Nikita Mikhailovskiy",
      "Alexander Sedunin",
      "Dzmitry Tsetserukou"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11829"
  },
  {
    "id": "arXiv:2110.11830",
    "title": "Multi-attribute Pizza Generator: Cross-domain Attribute Control with  Conditional StyleGAN",
    "abstract": "Multi-attribute conditional image generation is a challenging problem in\ncomputervision. We propose Multi-attribute Pizza Generator (MPG), a conditional\nGenerative Neural Network (GAN) framework for synthesizing images from a\ntrichotomy of attributes: content, view-geometry, and implicit visual style. We\ndesign MPG by extending the state-of-the-art StyleGAN2, using a new\nconditioning technique that guides the intermediate feature maps to learn\nmulti-scale multi-attribute entangled representationsof controlling attributes.\nBecause of the complex nature of the multi-attribute image generation problem,\nwe regularize the image generation by predicting the explicit conditioning\nattributes (ingredients and view). To synthesize a pizza image with view\nattributesoutside the range of natural training images, we design a CGI pizza\ndataset PizzaView using 3D pizza models and employ it to train a view attribute\nregressor to regularize the generation process, bridging the real and CGI\ntraining datasets. To verify the efficacy of MPG, we test it on Pizza10, a\ncarefully annotated multi-ingredient pizza image dataset. MPG can successfully\ngenerate photo-realistic pizza images with desired ingredients and view\nattributes, beyond the range of those observed in real-world training data.",
    "descriptor": "\nComments: To appear in British Machine Vision Conference (BMVC) 2021. arXiv admin note: text overlap with arXiv:2012.02821\n",
    "authors": [
      "Fangda Han",
      "Guoyao Hao",
      "Ricardo Guerrero",
      "Vladimir Pavlovic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11830"
  },
  {
    "id": "arXiv:2110.11833",
    "title": "Refined decay bounds on the entries of spectral projectors associated  with sparse Hermitian matrices",
    "abstract": "Spectral projectors of Hermitian matrices play a key role in many\napplications, and especially in electronic structure computations. Linear\nscaling methods for gapped systems are based on the fact that these special\nmatrix functions are localized, which means that the entries decay\nexponentially away from the main diagonal or with respect to more general\nsparsity patterns. The relation with the sign function together with an\nintegral representation is used to obtain new decay bounds, which turn out to\nbe optimal in an asymptotic sense. The influence of isolated eigenvalues in the\nspectrum on the decay properties is also investigated and a superexponential\nbehaviour is predicted.",
    "descriptor": "\nComments: 25 pages, 7 figures\n",
    "authors": [
      "Michele Benzi",
      "Michele Rinelli"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.11833"
  },
  {
    "id": "arXiv:2110.11836",
    "title": "The Log-Interleave Bound: Towards the Unification of Sorting and the BST  Model",
    "abstract": "We study the connections between sorting and the binary search tree model,\nwith an aim towards showing that the fields are connected more deeply than is\ncurrently known. The main vehicle of our study is the log-interleave bound, a\nmeasure of the information-theoretic complexity of a permutation $\\pi$. When\nviewed through the lens of adaptive sorting -- the study of lists which are\nnearly sorted according to some measure of disorder -- the log-interleave bound\nis comparable to the most powerful known measure of disorder. Many of these\nmeasures of disorder are themselves virtually identical to well-known upper\nbounds in the BST model, such as the working set bound or the dynamic finger\nbound, suggesting a connection between BSTs and sorting. We present three\nresults about the log-interleave bound which solidify the aforementioned\nconnections. The first is a proof that the log-interleave bound is always\nwithin a $\\lg \\lg n$ multiplicative factor of a known lower bound in the BST\nmodel, meaning that an online BST algorithm matching the log-interleave bound\nwould perform within the same bounds as the state-of-the-art $\\lg \\lg\nn$-competitive BST. The second result is an offline algorithm in the BST model\nwhich uses $O(\\text{LIB}(\\pi))$ accesses to search for any permutation $\\pi$.\nThe technique used to design this algorithm also serves as a general way to\nshow whether a sorting algorithm can be transformed into an offline BST\nalgorithm. The final result is a mergesort algorithm which performs work within\nthe log-interleave bound of a permutation $\\pi$. This mergesort also happens to\nbe highly parallel, adding to a line of work in parallel BST operations.",
    "descriptor": "",
    "authors": [
      "Guy Blelloch",
      "Magdalen Dobson"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.11836"
  },
  {
    "id": "arXiv:2110.11842",
    "title": "Multi-view Contrastive Graph Clustering",
    "abstract": "With the explosive growth of information technology, multi-view graph data\nhave become increasingly prevalent and valuable. Most existing multi-view\nclustering techniques either focus on the scenario of multiple graphs or\nmulti-view attributes. In this paper, we propose a generic framework to cluster\nmulti-view attributed graph data. Specifically, inspired by the success of\ncontrastive learning, we propose multi-view contrastive graph clustering (MCGC)\nmethod to learn a consensus graph since the original graph could be noisy or\nincomplete and is not directly applicable. Our method composes of two key\nsteps: we first filter out the undesirable high-frequency noise while\npreserving the graph geometric features via graph filtering and obtain a smooth\nrepresentation of nodes; we then learn a consensus graph regularized by graph\ncontrastive loss. Results on several benchmark datasets show the superiority of\nour method with respect to state-of-the-art approaches. In particular, our\nsimple approach outperforms existing deep learning-based methods.",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Erlin Pan",
      "Zhao Kang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.11842"
  },
  {
    "id": "arXiv:2110.11844",
    "title": "TADRN: Triple-Attentive Dual-Recurrent Network for Ad-hoc Array  Multichannel Speech Enhancement",
    "abstract": "Deep neural networks (DNNs) have been successfully used for multichannel\nspeech enhancement in fixed array geometries. However, challenges remain for\nad-hoc arrays with unknown microphone placements. We propose a deep neural\nnetwork based approach for ad-hoc array processing: Triple-Attentive\nDual-Recurrent Network (TADRN). TADRN uses self-attention across channels for\nlearning spatial information and a dual-path attentive recurrent network (ARN)\nfor temporal modeling. Temporal modeling is done independently for all channels\nby dividing a signal into smaller chunks and using an intra-chunk ARN for local\nmodeling and an inter-chunk ARN for global modeling. Consequently, TADRN uses\ntriple-path attention: inter-channel, intra-chunk, and inter-chunk, and\ndual-path recurrence: intra-chunk and inter-chunk. Experimental results show\nexcellent performance of TADRN. We demonstrate that TADRN improves speech\nenhancement by leveraging additional randomly placed microphones, even at\nlocations far from the target source. Additionally, large improvements in\nobjective scores are observed when poorly placed microphones in the scene are\ncomplemented with more effective microphone positions, such as those closer to\na target source.",
    "descriptor": "\nComments: submitted to ICASSP 2022\n",
    "authors": [
      "Ashutosh Pandey",
      "Buye Xu",
      "Anurag Kumar",
      "Jacob Donley",
      "Paul Calamia",
      "DeLiang Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.11844"
  },
  {
    "id": "arXiv:2110.11847",
    "title": "Probabilistic Numerical Method of Lines for Time-Dependent Partial  Differential Equations",
    "abstract": "This work develops a class of probabilistic algorithms for the numerical\nsolution of nonlinear, time-dependent partial differential equations (PDEs).\nCurrent state-of-the-art PDE solvers treat the space- and time-dimensions\nseparately, serially, and with black-box algorithms, which obscures the\ninteractions between spatial and temporal approximation errors and misguides\nthe quantification of the overall error. To fix this issue, we introduce a\nprobabilistic version of a technique called method of lines. The proposed\nalgorithm begins with a Gaussian process interpretation of finite difference\nmethods, which then interacts naturally with filtering-based probabilistic\nordinary differential equation (ODE) solvers because they share a common\nlanguage: Bayesian inference. Joint quantification of space- and\ntime-uncertainty becomes possible without losing the performance benefits of\nwell-tuned ODE solvers. Thereby, we extend the toolbox of probabilistic\nprograms for differential equation simulation to PDEs.",
    "descriptor": "",
    "authors": [
      "Nicholas Kr\u00e4mer",
      "Jonathan Schmidt",
      "Philipp Hennig"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.11847"
  },
  {
    "id": "arXiv:2110.11850",
    "title": "Lightweight Decoding Strategies for Increasing Specificity",
    "abstract": "Language models are known to produce vague and generic outputs. We propose\ntwo unsupervised decoding strategies based on either word-frequency or\npoint-wise mutual information to increase the specificity of any model that\noutputs a probability distribution over its vocabulary at generation time. We\ntest the strategies in a prompt completion task; with human evaluations, we\nfind that both strategies increase the specificity of outputs with only modest\ndecreases in sensibility. We also briefly present a summarization use case,\nwhere these strategies can produce more specific summaries.",
    "descriptor": "",
    "authors": [
      "Katy Ilonka Gero",
      "Chris Kedzie",
      "Savvas Petridis",
      "Lydia Chilton"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.11850"
  },
  {
    "id": "arXiv:2110.11851",
    "title": "Voting algorithms for unique games on complete graphs",
    "abstract": "An approximation algorithm for a Constraint Satisfaction Problem is called\nrobust if it outputs an assignment satisfying a $(1 - f(\\epsilon))$-fraction of\nthe constraints on any $(1-\\epsilon)$-satisfiable instance, where the loss\nfunction $f$ is such that $f(\\epsilon) \\rightarrow 0$ as $\\epsilon \\rightarrow\n0$. Moreover, the runtime of the algorithm should not depend in any way on\n$\\epsilon$. In this paper, we present such an algorithm for {\\sc\nMin-Unique-Games(q)} on complete graphs with $q$ labels. Specifically, the loss\nfunction is $f(\\epsilon) = (\\epsilon + c_{\\epsilon} \\epsilon^2)$, where\n$c_{\\epsilon}$ is a constant depending on $\\epsilon$ such that $\\lim_{\\epsilon\n\\rightarrow 0} c_{\\epsilon} = 16$. The runtime of our algorithm is $O(qn^3)$\n(with no dependence on $\\epsilon$) and can run in time $O(qn^2)$ using a\nrandomized implementation with a slightly larger constant $c_{\\epsilon}$. Our\nalgorithm is combinatorial and uses voting to find an assignment. We prove\nNP-hardness (using a randomized reduction) for {\\sc Min-Unique-Games(q)} on\ncomplete graphs even in the case where the constraints form a cyclic\npermutation, which is also known as {\\sc Min-Linear-Equations-mod-$q$} on\ncomplete graphs.",
    "descriptor": "",
    "authors": [
      "Antoine M\u00e9ot",
      "Arnaud de Mesmay",
      "Moritz M\u00fchlenthaler",
      "Alantha Newman"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.11851"
  },
  {
    "id": "arXiv:2110.11852",
    "title": "Recurrence along Depth: Deep Convolutional Neural Networks with  Recurrent Layer Aggregation",
    "abstract": "This paper introduces a concept of layer aggregation to describe how\ninformation from previous layers can be reused to better extract features at\nthe current layer. While DenseNet is a typical example of the layer aggregation\nmechanism, its redundancy has been commonly criticized in the literature. This\nmotivates us to propose a very light-weighted module, called recurrent layer\naggregation (RLA), by making use of the sequential structure of layers in a\ndeep CNN. Our RLA module is compatible with many mainstream deep CNNs,\nincluding ResNets, Xception and MobileNetV2, and its effectiveness is verified\nby our extensive experiments on image classification, object detection and\ninstance segmentation tasks. Specifically, improvements can be uniformly\nobserved on CIFAR, ImageNet and MS COCO datasets, and the corresponding\nRLA-Nets can surprisingly boost the performances by 2-3% on the object\ndetection task. This evidences the power of our RLA module in helping main CNNs\nbetter learn structural information in images.",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Jingyu Zhao",
      "Yanwen Fang",
      "Guodong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11852"
  },
  {
    "id": "arXiv:2110.11853",
    "title": "Polynomial-Time Sum-of-Squares Can Robustly Estimate Mean and Covariance  of Gaussians Optimally",
    "abstract": "In this work, we revisit the problem of estimating the mean and covariance of\nan unknown $d$-dimensional Gaussian distribution in the presence of an\n$\\varepsilon$-fraction of adversarial outliers. The pioneering work of [DKK+16]\ngave a polynomial time algorithm for this task with optimal\n$\\tilde{O}(\\varepsilon)$ error using $n = \\textrm{poly}(d, 1/\\varepsilon)$\nsamples.\nOn the other hand, [KS17b] introduced a general framework for robust moment\nestimation via a canonical sum-of-squares relaxation that succeeds for the more\ngeneral class of certifiably subgaussian and certifiably hypercontractive\n[BK20] distributions. When specialized to Gaussians, this algorithm obtains the\nsame $\\tilde{O}(\\varepsilon)$ error guarantee as [DKK+16] but incurs a\nsuper-polynomial sample complexity ($n = d^{O(\\log(1/\\varepsilon)}$) and\nrunning time ($n^{O(\\log(1/\\varepsilon))}$). This cost appears inherent to\ntheir analysis as it relies only on sum-of-squares certificates of upper bounds\non directional moments while the analysis in [DKK+16] relies on lower bounds on\ndirectional moments inferred from algebraic relationships between moments of\nGaussian distributions.\nWe give a new, simple analysis of the same canonical sum-of-squares\nrelaxation used in [KS17b, BK20] and show that for Gaussian distributions,\ntheir algorithm achieves the same error, sample complexity and running time\nguarantees as of the specialized algorithm in [DKK+16]. Our key innovation is a\nnew argument that allows using moment lower bounds without having\nsum-of-squares certificates for them. We believe that our proof technique will\nlikely be useful in developing further robust estimation algorithms.",
    "descriptor": "",
    "authors": [
      "Pravesh K. Kothari",
      "Peter Manohar",
      "Brian Hu Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.11853"
  },
  {
    "id": "arXiv:2110.11855",
    "title": "Auctions Between Regret-Minimizing Agents",
    "abstract": "We analyze a scenario in which software agents implemented as regret\nminimizing algorithms engage in a repeated auction on behalf of their users. We\nstudy first price and second price auctions, as well as their generalized\nversions (e.g., as those used for ad auctions). Using both theoretical analysis\nand simulations, we show that, surprisingly, in second price auctions the\nplayers have incentives to mis-report their true valuations to their own\nlearning agents, while in the first price auction it is a dominant strategy for\nall players to truthfully report their valuations to their agents.",
    "descriptor": "",
    "authors": [
      "Yoav Kolumbus",
      "Noam Nisan"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11855"
  },
  {
    "id": "arXiv:2110.11860",
    "title": "AIR-Nets: An Attention-Based Framework for Locally Conditioned Implicit  Representations",
    "abstract": "This paper introduces Attentive Implicit Representation Networks (AIR-Nets),\na simple, but highly effective architecture for 3D reconstruction from point\nclouds. Since representing 3D shapes in a local and modular fashion increases\ngeneralization and reconstruction quality, AIR-Nets encode an input point cloud\ninto a set of local latent vectors anchored in 3D space, which locally describe\nthe object's geometry, as well as a global latent description, enforcing global\nconsistency. Our model is the first grid-free, encoder-based approach that\nlocally describes an implicit function. The vector attention mechanism from\n[Zhao et al. 2020] serves as main point cloud processing module, and allows for\npermutation invariance and translation equivariance. When queried with a 3D\ncoordinate, our decoder gathers information from the global and nearby local\nlatent vectors in order to predict an occupancy value. Experiments on the\nShapeNet dataset show that AIR-Nets significantly outperform previous\nstate-of-the-art encoder-based, implicit shape learning methods and especially\ndominate in the sparse setting. Furthermore, our model generalizes well to the\nFAUST dataset in a zero-shot setting. Finally, since AIR-Nets use a sparse\nlatent representation and follow a simple operating scheme, the model offers\nseveral exiting avenues for future work. Our code is available at\nhttps://github.com/SimonGiebenhain/AIR-Nets.",
    "descriptor": "\nComments: Project code: this https URL\n",
    "authors": [
      "Simon Giebenhain",
      "Bastian Goldl\u00fccke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11860"
  },
  {
    "id": "arXiv:2110.11862",
    "title": "Graph Filtration Kernels",
    "abstract": "The majority of popular graph kernels is based on the concept of Haussler's\n$\\mathcal{R}$-convolution kernel and defines graph similarities in terms of\nmutual substructures. In this work, we enrich these similarity measures by\nconsidering graph filtrations: Using meaningful orders on the set of edges,\nwhich allow to construct a sequence of nested graphs, we can consider a graph\nat multiple granularities. For one thing, this provides access to features on\ndifferent levels of resolution. Furthermore, rather than to simply compare\nfrequencies of features in graphs, it allows for their comparison in terms of\nwhen and for how long they exist in the sequences. In this work, we propose a\nfamily of graph kernels that incorporate these existence intervals of features.\nWhile our approach can be applied to arbitrary graph features, we particularly\nhighlight Weisfeiler-Lehman vertex labels, leading to efficient kernels. We\nshow that using Weisfeiler-Lehman labels over certain filtrations strictly\nincreases the expressive power over the ordinary Weisfeiler-Lehman procedure in\nterms of deciding graph isomorphism. In fact, this result directly yields more\npowerful graph kernels based on such features and has implications to graph\nneural networks due to their close relationship to the Weisfeiler-Lehman\nmethod. We empirically validate the expressive power of our graph kernels and\nshow significant improvements over state-of-the-art graph kernels in terms of\npredictive performance on various real-world benchmark datasets.",
    "descriptor": "",
    "authors": [
      "Till Hendrik Schulz",
      "Pascal Welke",
      "Stefan Wrobel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11862"
  },
  {
    "id": "arXiv:2110.11864",
    "title": "Deep learning-based NLP Data Pipeline for EHR Scanned Document  Information Extraction",
    "abstract": "Scanned documents in electronic health records (EHR) have been a challenge\nfor decades, and are expected to stay in the foreseeable future. Current\napproaches for processing often include image preprocessing, optical character\nrecognition (OCR), and text mining. However, there is limited work that\nevaluates the choice of image preprocessing methods, the selection of NLP\nmodels, and the role of document layout. The impact of each element remains\nunknown. We evaluated this method on a use case of two key indicators for sleep\napnea, Apnea hypopnea index (AHI) and oxygen saturation (SaO2) values, from\nscanned sleep study reports. Our data that included 955 manually annotated\nreports was secondarily utilized from a previous study in the University of\nTexas Medical Branch. We performed image preprocessing: gray-scaling followed\nby 1 iteration of dilating and erode, and 20% contrast increasing. The OCR was\nimplemented with the Tesseract OCR engine. A total of seven Bag-of-Words models\n(Logistic Regression, Ridge Regression, Lasso Regression, Support Vector\nMachine, k-Nearest Neighbor, Na\\\"ive Bayes, and Random Forest) and three deep\nlearning-based models (BiLSTM, BERT, and Clinical BERT) were evaluated. We also\nevaluated the combinations of image preprocessing methods (gray-scaling, dilate\n& erode, increased contrast by 20%, increased contrast by 60%), and two deep\nlearning architectures (with and without structured input that provides\ndocument layout information). Our proposed method using Clinical BERT reached\nan AUROC of 0.9743 and document accuracy of 94.76% for AHI, and an AUROC of\n0.9523, and document accuracy of 91.61% for SaO2. We demonstrated the proper\nuse of image preprocessing and document layout could be beneficial to scanned\ndocument processing.",
    "descriptor": "\nComments: 6 tables, 7 figures\n",
    "authors": [
      "Enshuo Hsu",
      "Ioannis Malagaris",
      "Yong-Fang Kuo",
      "Rizwana Sultana",
      "Kirk Roberts"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11864"
  },
  {
    "id": "arXiv:2110.11865",
    "title": "Multipoint-to-point data aggregation using a single receiver and  frequency-multiplexed intensity-modulated ONUs",
    "abstract": "We demonstrate 2.5-GHz-spacing frequency multiplexing capable of aggregating\n64 intensity-modulated end-users using low-speed electronic and optoelectronic\ncomponents. All optical network units (ONUs) achieved high per-user capacity\nwith dedicated optical bands, enabling future large-bandwidth and low latency\napplications.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Zichuan Zhou",
      "Jinlong Wei",
      "Kari A. Clark",
      "Eric Sillekens",
      "Callum Deakin",
      "Ronit Sohanpal",
      "Yuan Luo",
      "Radan Slav\u00edk",
      "Zhixin Liu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.11865"
  },
  {
    "id": "arXiv:2110.11866",
    "title": "Morlet wavelet transform using attenuated sliding Fourier transform and  kernel integral for graphic processing unit",
    "abstract": "Morlet or Gabor wavelet transforms as well as Gaussian smoothing, are widely\nused in signal processing and image processing. However, the computational\ncomplexity of their direct calculations is proportional not only to the number\nof data points in a signal but also to the smoothing size, which is the\nstandard deviation in the Gaussian function in their transform functions. Thus,\nwhen the standard deviation is large, its considerable computation time\ndiminishes the advantages of aforementioned transforms. Therefore, it is\nimportant to formulate an algorithm to reduce the calculation time of the\ntransformations. In this paper, we first review calculation methods of Gaussian\nsmoothing by using the sliding Fourier transform (SFT) and our proposed\nattenuated SFT (ASFT) \\cite{YamashitaICPR2020}. Based on these methods, we\npropose two types of calculation methods for Morlet wavelet transforms. We also\npropose an algorithm to calculate SFT using the kernel integral on graphic\nprocessing unit (GPU). When the number of calculation cores in GPU is not less\nthan the number of data points, the order of its calculation time is the\nlogarithm of the smoothing size and does not depend on the number of data\npoints. Using experiments, we compare the two methods for calculating the\nMorlet wavelet transform and evaluate the calculation time of the proposed\nalgorithm using a kernel integral on GPU. For example, when the number of data\npoints and the standard deviation are 102400 and 8192.0, respectively, the\ncalculation time of the Morlet wavelet transform by the proposed method is\n0.545 ms, which 413.6 times faster than a conventional method.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Yukihiko Yamashita",
      "Toru Wakahar"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.11866"
  },
  {
    "id": "arXiv:2110.11867",
    "title": "CeyMo: See More on Roads -- A Novel Benchmark Dataset for Road Marking  Detection",
    "abstract": "In this paper, we introduce a novel road marking benchmark dataset for road\nmarking detection, addressing the limitations in the existing publicly\navailable datasets such as lack of challenging scenarios, prominence given to\nlane markings, unavailability of an evaluation script, lack of annotation\nformats and lower resolutions. Our dataset consists of 2887 total images with\n4706 road marking instances belonging to 11 classes. The images have a high\nresolution of 1920 x 1080 and capture a wide range of traffic, lighting and\nweather conditions. We provide road marking annotations in polygons, bounding\nboxes and pixel-level segmentation masks to facilitate a diverse range of road\nmarking detection algorithms. The evaluation metrics and the evaluation script\nwe provide, will further promote direct comparison of novel approaches for road\nmarking detection with existing methods. Furthermore, we evaluate the\neffectiveness of using both instance segmentation and object detection based\napproaches for the road marking detection task. Speed and accuracy scores for\ntwo instance segmentation models and two object detector models are provided as\na performance baseline for our benchmark dataset. The dataset and the\nevaluation script will be publicly available.",
    "descriptor": "\nComments: Accepted to 2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV 2022)\n",
    "authors": [
      "Oshada Jayasinghe",
      "Sahan Hemachandra",
      "Damith Anhettigama",
      "Shenali Kariyawasam",
      "Ranga Rodrigo",
      "Peshala Jayasekara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11867"
  },
  {
    "id": "arXiv:2110.11868",
    "title": "Proposition d'approches de d\u00e9ploiement des unit\u00e9s de bord de route  dans les r\u00e9seaux v\u00e9hiculaires",
    "abstract": "Road Side Units (RSUs) have a crucial role in maintaining Vehicular Ad-hoc\nNetworks (VANETs) connectivity and coverage, especially, for applications\ngathering or disseminating non-safety information. In big cities with complex\nroad network topology, a huge number of costly RSUs must be deployed to collect\ndata gathered by all moving vehicles. In this respect, several research works\nfocusing on RSUs deployment have been proposed. The thriving challenge would be\nto (i) reduce the deployment cost by minimizing as far as possible the number\nof used RSUs; and (ii) to maximize the coverage ratio. In this thesis, we\nintroduce a spatio-temporal RSU deployment framework including three methods\nnamely SPaCov/SPaCov+, HeSPic and MIP. SPaCov starts by mining frequent\nmobility patterns of moving vehicles from their trajectories then it computes\nthe best RSU locations that cover the extracted patterns. Nonetheless, SPaCov+\nextracts the frequent mobility patterns as well as the rare ones to enhance the\ncoverage ratio. HeSiC is a budget-constrained spatio-temporal coverage method\nthat aims to maximize the coverage ratio subject to a budget constraint, which\nis defined in terms of RSUs number. MIP is a spatio-temporal coverage method\nthat aims to finding representative transactions from the sequential database\nand computing coverage. Performed simulations highlight the efficiency and the\neffectiveness of the proposed RSU deployment framework in terms of coverage\nratio, deployment cost, network latency and overhead.",
    "descriptor": "\nComments: Doctoral thesis, in French\n",
    "authors": [
      "Seif Ben Chaabene"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.11868"
  },
  {
    "id": "arXiv:2110.11869",
    "title": "FLiText: A Faster and Lighter Semi-Supervised Text Classification with  Convolution Networks",
    "abstract": "In natural language processing (NLP), state-of-the-art (SOTA) semi-supervised\nlearning (SSL) frameworks have shown great performance on deep pre-trained\nlanguage models such as BERT, and are expected to significantly reduce the\ndemand for manual labeling. However, our empirical studies indicate that these\nframeworks are not suitable for lightweight models such as TextCNN, LSTM and\netc. In this work, we develop a new SSL framework called FLiText, which stands\nfor Faster and Lighter semi-supervised Text classification. FLiText introduces\nan inspirer network together with the consistency regularization framework,\nwhich leverages a generalized regular constraint on the lightweight models for\nefficient SSL. As a result, FLiText obtains new SOTA performance for\nlightweight models across multiple SSL benchmarks on text classification.\nCompared with existing SOTA SSL methods on TextCNN, FLiText improves the\naccuracy of lightweight model TextCNN from 51.00% to 90.49% on IMDb, 39.8% to\n58.06% on Yelp-5, and from 55.3% to 65.08% on Yahoo. In addition, compared with\nthe fully supervised method on the full dataset, FLiText just uses less than 1%\nof labeled data to improve the accuracy by 6.59%, 3.94%, and 3.22% on the\ndatasets of IMDb, Yelp-5, and Yahoo respectively.",
    "descriptor": "",
    "authors": [
      "Chen Liu",
      "Mengchao Zhang",
      "Zhibin Fu",
      "Pan Hou",
      "Yu Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11869"
  },
  {
    "id": "arXiv:2110.11870",
    "title": "Biomedical text summarization using Conditional Generative Adversarial  Network(CGAN)",
    "abstract": "Text summarization in medicine can help doctors for reducing the time to\naccess important information from countless documents. The paper offers a\nsupervised extractive summarization method based on conditional generative\nadversarial networks using convolutional neural networks. Unlike previous\nmodels, which often use greedy methods to select sentences, we use a new\napproach for selecting sentences. Moreover, we provide a network for biomedical\nword embedding, which improves summarization. An essential contribution of the\npaper is introducing a new loss function for the discriminator, making the\ndiscriminator perform better. The proposed model achieves results comparable to\nthe state-of-the-art approaches, as determined by the ROUGE metric. Experiments\non the medical dataset show that the proposed method works on average 5% better\nthan the competing models and is more similar to the reference summaries.",
    "descriptor": "\nComments: 12 pages, to appear in artificial intelligence in medicine journal\n",
    "authors": [
      "Seyed Vahid Moravvej",
      "Abdolreza Mirzaei",
      "Mehran Safayani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.11870"
  },
  {
    "id": "arXiv:2110.11872",
    "title": "Patient level simulation and reinforcement learning to discover novel  strategies for treating ovarian cancer",
    "abstract": "The prognosis for patients with epithelial ovarian cancer remains dismal\ndespite improvements in survival for other cancers. Treatment involves multiple\nlines of chemotherapy and becomes increasingly heterogeneous after first-line\ntherapy. Reinforcement learning with real-world outcomes data has the potential\nto identify novel treatment strategies to improve overall survival. We design a\nreinforcement learning environment to model epithelial ovarian cancer treatment\ntrajectories and use model free reinforcement learning to investigate\ntherapeutic regimens for simulated patients.",
    "descriptor": "",
    "authors": [
      "Brian Murphy",
      "Mustafa Nasir-Moin",
      "Grace von Oiste",
      "Viola Chen",
      "Howard A Riina",
      "Douglas Kondziolka",
      "Eric K Oermann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11872"
  },
  {
    "id": "arXiv:2110.11873",
    "title": "Numerical solutions to linear transfer problems of polarized radiation  II. Krylov methods and matrix-free implementation",
    "abstract": "Context. Numerical solutions to transfer problems of polarized radiation in\nsolar and stellar atmospheres commonly rely on stationary iterative methods,\nwhich often perform poorly when applied to large problems. In recent times,\nstationary iterative methods have been replaced by state-of-the-art\npreconditioned Krylov iterative methods for many applications. However, a\ngeneral description and a convergence analysis of Krylov methods in the\npolarized radiative transfer context are still lacking. Aims. We describe the\npractical application of preconditioned Krylov methods to linear transfer\nproblems of polarized radiation, possibly in a matrix-free context. The main\naim is to clarify the advantages and drawbacks of various Krylov accelerators\nwith respect to stationary iterative methods. Methods. We report the\nconvergence rate and the run time of various Krylov-accelerated techniques\ncombined with different formal solvers when applied to a 1D benchmark transfer\nproblem of polarized radiation. In particular, we analyze the GMRES, BICGSTAB,\nand CGS Krylov methods, preconditioned with Jacobi, or (S)SOR. Results. Krylov\nmethods accelerate the convergence, reduce the run time, and improve the\nrobustness of standard stationary iterative methods. Jacobi-preconditioned\nKrylov methods outperform SOR-preconditioned stationary iterations in all\nrespects. In particular, the Jacobi-GMRES method offers the best overall\nperformance for the problem setting in use. Conclusions. Krylov methods can be\nmore challenging to implement than stationary iterative methods. However, an\nalgebraic formulation of the radiative transfer problem allows one to apply and\nstudy Krylov acceleration strategies with little effort. Furthermore, many\navailable numerical libraries implement matrix-free Krylov routines, enabling\nan almost effortless transition to Krylov methods.",
    "descriptor": "",
    "authors": [
      "Pietro Benedusi",
      "Gioele Janett",
      "Luca Belluzzi",
      "Rolf Krause"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Solar and Stellar Astrophysics (astro-ph.SR)"
    ],
    "url": "https://arxiv.org/abs/2110.11873"
  },
  {
    "id": "arXiv:2110.11875",
    "title": "GeneDisco: A Benchmark for Experimental Design in Drug Discovery",
    "abstract": "In vitro cellular experimentation with genetic interventions, using for\nexample CRISPR technologies, is an essential step in early-stage drug discovery\nand target validation that serves to assess initial hypotheses about causal\nassociations between biological mechanisms and disease pathologies. With\nbillions of potential hypotheses to test, the experimental design space for in\nvitro genetic experiments is extremely vast, and the available experimental\ncapacity - even at the largest research institutions in the world - pales in\nrelation to the size of this biological hypothesis space. Machine learning\nmethods, such as active and reinforcement learning, could aid in optimally\nexploring the vast biological space by integrating prior knowledge from various\ninformation sources as well as extrapolating to yet unexplored areas of the\nexperimental design space based on available data. However, there exist no\nstandardised benchmarks and data sets for this challenging task and little\nresearch has been conducted in this area to date. Here, we introduce GeneDisco,\na benchmark suite for evaluating active learning algorithms for experimental\ndesign in drug discovery. GeneDisco contains a curated set of multiple publicly\navailable experimental data sets as well as open-source implementations of\nstate-of-the-art active learning policies for experimental design and\nexploration.",
    "descriptor": "",
    "authors": [
      "Arash Mehrjou",
      "Ashkan Soleymani",
      "Andrew Jesson",
      "Pascal Notin",
      "Yarin Gal",
      "Stefan Bauer",
      "Patrick Schwab"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.11875"
  },
  {
    "id": "arXiv:2110.11876",
    "title": "Tight and Robust Private Mean Estimation with Few Users",
    "abstract": "In this work, we study high-dimensional mean estimation under user-level\ndifferential privacy, and attempt to design an\n$(\\epsilon,\\delta)$-differentially private mechanism using as few users as\npossible. In particular, we provide a nearly optimal trade-off between the\nnumber of users and the number of samples per user required for private mean\nestimation, even when the number of users is as low as\n$O(\\frac{1}{\\epsilon}\\log\\frac{1}{\\delta})$. Interestingly our bound\n$O(\\frac{1}{\\epsilon}\\log\\frac{1}{\\delta})$ on the number of users is\nindependent of the dimension, unlike the previous work that depends\npolynomially on the dimension, solving a problem left open by Amin et\nal.~(ICML'2019). Our mechanism enjoys robustness up to the point that even if\nthe information of $49\\%$ of the users are corrupted, our final estimation is\nstill approximately accurate. Finally, our results also apply to a broader\nrange of problems such as learning discrete distributions, stochastic convex\noptimization, empirical risk minimization, and a variant of stochastic gradient\ndescent via a reduction to differentially private mean estimation.",
    "descriptor": "\nComments: 38 pages\n",
    "authors": [
      "Hossein Esfandiari",
      "Vahab Mirrokni",
      "Shyam Narayanan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.11876"
  },
  {
    "id": "arXiv:2110.11879",
    "title": "An N-gram based approach to auto-extracting topics from research  articles",
    "abstract": "A lot of manual work goes into identifying a topic for an article. With a\nlarge volume of articles, the manual process can be exhausting. Our approach\naims to address this issue by automatically extracting topics from the text of\nlarge Numbers of articles. This approach takes into account the efficiency of\nthe process. Based on existing N-gram analysis, our research examines how often\ncertain words appear in documents in order to support automatic topic\nextraction. In order to improve efficiency, we apply custom filtering standards\nto our research. Additionally, delete as many noncritical or irrelevant phrases\nas possible. In this way, we can ensure we are selecting unique keyphrases for\neach article, which capture its core idea. For our research, we chose to center\non the autonomous vehicle domain, since the research is relevant to our daily\nlives. We have to convert the PDF versions of most of the research papers into\neditable types of files such as TXT. This is because most of the research\npapers are only in PDF format. To test our proposed idea of automating,\nnumerous articles on robotics have been selected. Next, we evaluate our\napproach by comparing the result with that obtained manually.",
    "descriptor": "",
    "authors": [
      "Linkai Zhu",
      "Maoyi Huang",
      "Maomao Chen",
      "Wennan Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11879"
  },
  {
    "id": "arXiv:2110.11881",
    "title": "Simple Dialogue System with AUDITED",
    "abstract": "We devise a multimodal conversation system for dialogue utterances composed\nof text, image or both modalities. We leverage Auxiliary UnsuperviseD vIsual\nand TExtual Data (AUDITED). To improve the performance of text-based task, we\nutilize translations of target sentences from English to French to form the\nassisted supervision. For the image-based task, we employ the DeepFashion\ndataset in which we seek nearest neighbor images of positive and negative\ntarget images of the MMD data. These nearest neighbors form the nearest\nneighbor embedding providing an external context for target images. We form two\nmethods to create neighbor embedding vectors, namely Neighbor Embedding by Hard\nAssignment (NEHA) and Neighbor Embedding by Soft Assignment (NESA) which\ngenerate context subspaces per target image. Subsequently, these subspaces are\nlearnt by our pipeline as a context for the target data. We also propose a\ndiscriminator which switches between the image- and text-based tasks. We show\nimprovements over baselines on the large-scale Multimodal Dialogue Dataset\n(MMD) and SIMMC.",
    "descriptor": "\nComments: Accepted by the BMVC 2021\n",
    "authors": [
      "Yusuf Tas",
      "Piotr Koniusz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.11881"
  },
  {
    "id": "arXiv:2110.11885",
    "title": "A novel fourth-order WENO interpolation technique. A possible new tool  designed for radiative transfer",
    "abstract": "Context. Several numerical problems require the interpolation of discrete\ndata that present various types of discontinuities. The radiative transfer is a\ntypical example of such a problem. This calls for high-order well-behaved\ntechniques to interpolate both smooth and discontinuous data. Aims. The final\naim is to propose new techniques suitable for applications in the context of\nnumerical radiative transfer. Methods. We have proposed and tested two\ndifferent techniques. Essentially non-oscillatory (ENO) techniques generate\nseveral candidate interpolations based on different substencils. The smoothest\ncandidate interpolation is determined from a measure for the local smoothness,\nthereby enabling the essential non-oscillatory property. Weighted ENO (WENO)\ntechniques use a convex combination of all candidate substencils to obtain\nhigh-order accuracy in smooth regions while keeping the essentially\nnon-oscillatory property. In particular, we have outlined and tested a novel\nwell-performing fourth-order WENO interpolation technique for both uniform and\nnonuniform grids. Results. Numerical tests prove that the fourth-order WENO\ninterpolation guarantees fourth-order accuracy in smooth regions of the\ninterpolated functions. In the presence of discontinuities, the fourth-order\nWENO interpolation enables the non-oscillatory property, avoiding oscillations.\nUnlike B\\'ezier and monotonic high-order Hermite interpolations, it does not\ndegenerate to a linear interpolation near smooth extrema of the interpolated\nfunction. Conclusions. The novel fourth-order WENO interpolation guarantees\nhigh accuracy in smooth regions, while effectively handling discontinuities.\nThis interpolation technique might be particularly suitable for several\nproblems, including a number of radiative transfer applications such as\nmultidimensional problems, multigrid methods, and formal solutions.",
    "descriptor": "",
    "authors": [
      "Gioele Janett",
      "Oskar Steiner",
      "Ernest Alsina Ballester",
      "Luca Belluzzi",
      "Siddhartha Mishra"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Solar and Stellar Astrophysics (astro-ph.SR)"
    ],
    "url": "https://arxiv.org/abs/2110.11885"
  },
  {
    "id": "arXiv:2110.11886",
    "title": "Conditional Gaussian PAC-Bayes",
    "abstract": "Recent studies have empirically investigated different methods to train a\nstochastic classifier by optimising a PAC-Bayesian bound via stochastic\ngradient descent. Most of these procedures need to replace the\nmisclassification error with a surrogate loss, leading to a mismatch between\nthe optimisation objective and the actual generalisation bound. The present\npaper proposes a novel training algorithm that optimises the PAC-Bayesian\nbound, without relying on any surrogate loss. Empirical results show that the\nbounds obtained with this approach are tighter than those found in the\nliterature.",
    "descriptor": "",
    "authors": [
      "Eugenio Clerico",
      "George Deligiannidis",
      "Arnaud Doucet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.11886"
  },
  {
    "id": "arXiv:2110.11887",
    "title": "C$^{4}$Net: Contextual Compression and Complementary Combination Network  for Salient Object Detection",
    "abstract": "Deep learning solutions of the salient object detection problem have achieved\ngreat results in recent years. The majority of these models are based on\nencoders and decoders, with a different multi-feature combination. In this\npaper, we show that feature concatenation works better than other combination\nmethods like multiplication or addition. Also, joint feature learning gives\nbetter results, because of the information sharing during their processing. We\ndesigned a Complementary Extraction Module (CEM) to extract necessary features\nwith edge preservation. Our proposed Excessiveness Loss (EL) function helps to\nreduce false-positive predictions and purifies the edges with other weighted\nloss functions. Our designed Pyramid-Semantic Module (PSM) with Global guiding\nflow (G) makes the prediction more accurate by providing high-level\ncomplementary information to shallower layers. Experimental results show that\nthe proposed model outperforms the state-of-the-art methods on all benchmark\ndatasets under three evaluation metrics.",
    "descriptor": "",
    "authors": [
      "Hazarapet Tunanyan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11887"
  },
  {
    "id": "arXiv:2110.11891",
    "title": "On the Necessity of Auditable Algorithmic Definitions for Machine  Unlearning",
    "abstract": "Machine unlearning, i.e. having a model forget about some of its training\ndata, has become increasingly more important as privacy legislation promotes\nvariants of the right-to-be-forgotten. In the context of deep learning,\napproaches for machine unlearning are broadly categorized into two classes:\nexact unlearning methods, where an entity has formally removed the data point's\nimpact on the model by retraining the model from scratch, and approximate\nunlearning, where an entity approximates the model parameters one would obtain\nby exact unlearning to save on compute costs. In this paper we first show that\nthe definition that underlies approximate unlearning, which seeks to prove the\napproximately unlearned model is close to an exactly retrained model, is\nincorrect because one can obtain the same model using different datasets. Thus\none could unlearn without modifying the model at all. We then turn to exact\nunlearning approaches and ask how to verify their claims of unlearning. Our\nresults show that even for a given training trajectory one cannot formally\nprove the absence of certain data points used during training. We thus conclude\nthat unlearning is only well-defined at the algorithmic level, where an\nentity's only possible auditable claim to unlearning is that they used a\nparticular algorithm designed to allow for external scrutiny during an audit.",
    "descriptor": "",
    "authors": [
      "Anvith Thudi",
      "Hengrui Jia",
      "Ilia Shumailov",
      "Nicolas Papernot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.11891"
  },
  {
    "id": "arXiv:2110.11894",
    "title": "Towards Using Clothes Style Transfer for Scenario-aware Person Video  Generation",
    "abstract": "Clothes style transfer for person video generation is a challenging task, due\nto drastic variations of intra-person appearance and video scenarios. To tackle\nthis problem, most recent AdaIN-based architectures are proposed to extract\nclothes and scenario features for generation. However, these approaches suffer\nfrom being short of fine-grained details and are prone to distort the origin\nperson. To further improve the generation performance, we propose a novel\nframework with disentangled multi-branch encoders and a shared decoder.\nMoreover, to pursue the strong video spatio-temporal consistency, an\ninner-frame discriminator is delicately designed with input being cross-frame\ndifference. Besides, the proposed framework possesses the property of scenario\nadaptation. Extensive experiments on the TEDXPeople benchmark demonstrate the\nsuperiority of our method over state-of-the-art approaches in terms of image\nquality and video coherence.",
    "descriptor": "",
    "authors": [
      "Jingning Xu",
      "benlai Tang",
      "Mingjie Wang",
      "Siyuan Bian",
      "Wenyi Guo",
      "Xiang Yin",
      "Zejun Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.11894"
  },
  {
    "id": "arXiv:2110.11898",
    "title": "REACH: Refining Alloy Scenarios by Scope",
    "abstract": "Writing declarative models has numerous benefits, ranging from automated\nreasoning and correction of design-level properties be-fore systems are built,\nto automated testing and debugging of their implementations after they are\nbuilt. Alloy is a declarative modeling language that is well suited for\nverifying system designs. A key strength of Alloy is its scenario-finding\ntoolset, the Analyzer, which allows users to explore all valid scenarios that\nadhere to the model's constraints up to a user-provided scope. In Alloy, it is\ncommon for users to desire to first validate smaller scenarios, then once\nconfident, move onto validating larger scenarios. However, the Analyzer only\npresents scenarios in the order they are discovered by the SAT solver. This\npaper presents Reach, an extension to the Analyzer which allows users to\nexplore scenarios by size. Experimental results reveal Reach's enumeration\nimproves performance while having the added benefit of maintaining a\nsemi-sorted ordering of scenarios for the user. Moreover, we highlight Reach's\nability to improve the performance of Alloy's analysis when the user makes\nincremental changes to the scope of the enumeration.",
    "descriptor": "",
    "authors": [
      "Ana Jovanovic",
      "Allison Sullivan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.11898"
  },
  {
    "id": "arXiv:2110.11899",
    "title": "Challenges in Procedural Multimodal Machine Comprehension:A Novel Way To  Benchmark",
    "abstract": "We focus on Multimodal Machine Reading Comprehension (M3C) where a model is\nexpected to answer questions based on given passage (or context), and the\ncontext and the questions can be in different modalities. Previous works such\nas RecipeQA have proposed datasets and cloze-style tasks for evaluation.\nHowever, we identify three critical biases stemming from the question-answer\ngeneration process and memorization capabilities of large deep models. These\nbiases makes it easier for a model to overfit by relying on spurious\ncorrelations or naive data patterns. We propose a systematic framework to\naddress these biases through three Control-Knobs that enable us to generate a\ntest bed of datasets of progressive difficulty levels. We believe that our\nbenchmark (referred to as Meta-RecipeQA) will provide, for the first time, a\nfine grained estimate of a model's generalization capabilities. We also propose\na general M3C model that is used to realize several prior SOTA models and\nmotivate a novel hierarchical transformer based reasoning network (HTRN). We\nperform a detailed evaluation of these models with different language and\nvisual features on our benchmark. We observe a consistent improvement with HTRN\nover SOTA (~18% in Visual Cloze task and ~13% in average over all the tasks).\nWe also observe a drop in performance across all the models when testing on\nRecipeQA and proposed Meta-RecipeQA (e.g. 83.6% versus 67.1% for HTRN), which\nshows that the proposed dataset is relatively less biased. We conclude by\nhighlighting the impact of the control knobs with some quantitative results.",
    "descriptor": "",
    "authors": [
      "Pritish Sahu",
      "Karan Sikka",
      "Ajay Divakaran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.11899"
  },
  {
    "id": "arXiv:2110.11903",
    "title": "A Physics-Based Data-Driven Approach for Finite Time Estimation of  Pandemic Growth",
    "abstract": "COVID-19 is a global health crisis that has had unprecedented, widespread\nimpact on households across the United States and has been declared a global\npandemic on March 11, 2020 by World Health Organization (WHO) [1]. According to\nCenters for Disease Control and Prevention (CDC) [2], the spread of COVID-19\noccurs through person-to-person transmission i.e. close contact with infected\npeople through contaminated surfaces and respiratory fluids carrying infectious\nvirus. This paper presents a data-driven physics-based approach to analyze and\npredict the rapid growth and spread dynamics of the pandemic. Temporal and\nSpatial conservation laws are used to model the evolution of the COVID-19\npandemic. We integrate quadratic programming and neural networks to learn the\nparameters and estimate the pandemic growth. The proposed prediction model is\nvalidated through finite time estimation of the pandemic growth using the total\nnumber of cases, deaths and recoveries in the United States recorded from March\n12, 2020 until October 1, 2021 [3].",
    "descriptor": "",
    "authors": [
      "Harshvardhan Uppaluru",
      "Hamid Emadi",
      "Hossein Rastgoftar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.11903"
  },
  {
    "id": "arXiv:2110.11905",
    "title": "\"It may be a pain in the backside but...\" Insights into the impact of  GDPR on business after three years",
    "abstract": "The General Data Protection Regulation (GDPR) came into effect in May 2018\nand is designed to safeguard EU citizens' data privacy. The benefits of the\nregulation to consumers' rights and to regulators' powers are well known. The\nbenefits to regulated businesses are less obvious and under-researched.\nThe aim of this study is to investigate if GDPR is all pain and no gain for\nbusiness. Using semi-structured interviews, we survey 14 C-level executives\nresponsible for business, finance, marketing, legal and technology drawn from\nsix small, medium and large companies in the UK and Ireland.\nWe find the threat of fines has focused the corporate mind and made business\nmore privacy aware. Organisationally, it has created new power bases within\ncompanies to advocate GDPR. It has forced companies, in varying degrees, to\nmodernise their platforms and indirectly benefited them with better risk\nmanagement processes, information security infrastructure and up to date\ncustomer databases. Compliance, for some, is used as a reputational signal of\ntrustworthiness.\nWe find many implementation challenges remain. New business development and\nintra-company communication is more constrained. Regulation has increased costs\nand internal bureaucracy. Grey areas remain due to a lack of case law.\nDisgruntled customers and ex-employees weaponise Subject Access Requests (SAR)\nas a tool of retaliation. Small businesses see GDPR as overkill and\noverwhelming.\nWe conclude GDPR may be regarded as a pain by business but it has made it\nmore careful with data.\nWe recommend the EU consider tailoring a version of the regulation that is\nbetter suited to SMEs and modifying the messaging to be more positive whilst\nstill exploiting news of fines to reinforce corporate data discipline.",
    "descriptor": "",
    "authors": [
      "Gerard Buckley",
      "Tristan Caulfield",
      "Ingolf Becker"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.11905"
  },
  {
    "id": "arXiv:2110.11911",
    "title": "Self-supervised denoising for massive noisy images",
    "abstract": "We propose an effective deep learning model for signal reconstruction, which\nrequires no signal prior, no noise model calibration, and no clean samples.\nThis model only assumes that the noise is independent of the measurement and\nthat the true signals share the same structured information. We demonstrate its\nperformance on a variety of real-world applications, from sub-\\r{A}ngstr\\\"{o}m\nresolution atomic images to sub-arcsecond resolution astronomy images.",
    "descriptor": "",
    "authors": [
      "Feng Wang",
      "Trond R. Henninen",
      "Debora Keller",
      "Rolf Erni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.11911"
  },
  {
    "id": "arXiv:2110.11918",
    "title": "MIGS: Meta Image Generation from Scene Graphs",
    "abstract": "Generation of images from scene graphs is a promising direction towards\nexplicit scene generation and manipulation. However, the images generated from\nthe scene graphs lack quality, which in part comes due to high difficulty and\ndiversity in the data. We propose MIGS (Meta Image Generation from Scene\nGraphs), a meta-learning based approach for few-shot image generation from\ngraphs that enables adapting the model to different scenes and increases the\nimage quality by training on diverse sets of tasks. By sampling the data in a\ntask-driven fashion, we train the generator using meta-learning on different\nsets of tasks that are categorized based on the scene attributes. Our results\nshow that using this meta-learning approach for the generation of images from\nscene graphs achieves state-of-the-art performance in terms of image quality\nand capturing the semantic relationships in the scene. Project Website:\nhttps://migs2021.github.io/",
    "descriptor": "\nComments: Accepted at BMVC 2021\n",
    "authors": [
      "Azade Farshad",
      "Sabrina Musatian",
      "Helisa Dhamo",
      "Nassir Navab"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11918"
  },
  {
    "id": "arXiv:2110.11919",
    "title": "Look behind the Censorship: Reposting-User Characterization and  Muted-Topic Restoration",
    "abstract": "The emergence of social media has largely eased the way people receive\ninformation and participate in public discussions. However, in countries with\nstrict regulations on discussions in the public space, social media is no\nexception. To limit the degree of dissent or inhibit the spread of ``harmful''\ninformation, a common approach is to impose censorship on social media. In this\npaper, we focus on a study of censorship on Weibo, the counterpart of Twitter\nin China. Specifically, we 1) create a web-scraping pipeline and collect a\nlarge dataset solely focus on the reposts from Weibo; 2) discover the\ncharacteristics of users whose reposts contain censored information, in terms\nof gender, location, device, and account type; and 3) conduct a thematic\nanalysis by extracting and analyzing topic information. Note that although the\noriginal posts are no longer visible, we can use comments user wrote when\nreposting the original post to infer the topic of the original content. We find\nthat such efforts can recover the discussions around social events that\ntriggered massive discussions but were later muted. Further, we show the\nvariations of inferred topics across different user groups and time frames.",
    "descriptor": "",
    "authors": [
      "Yichi Qian",
      "Qiyi Shan",
      "Hanjia Lyu",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.11919"
  },
  {
    "id": "arXiv:2110.11920",
    "title": "Convergence to weak solutions of a space-time hybridized discontinuous  Galerkin method for the incompressible Navier--Stokes equations",
    "abstract": "We prove that a space-time hybridized discontinuous Galerkin method for the\nevolutionary Navier--Stokes equations converges to a weak solution as the time\nstep and mesh size tend to zero. Moreover, we show that this weak solution\nsatisfies the energy inequality. To perform our analysis, we make use of\ndiscrete functional analysis tools and a discrete version of the\nAubin--Lions--Simon theorem.",
    "descriptor": "",
    "authors": [
      "Keegan L. A. Kirk",
      "Ay\u00e7\u0131l \u00c7e\u015fmelio\u01e7lu",
      "Sander Rhebergen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.11920"
  },
  {
    "id": "arXiv:2110.11924",
    "title": "Gapoera: Application Programming Interface for AI Environment of  Indonesian Board Game",
    "abstract": "Currently, the development of computer games has shown a tremendous surge.\nThe ease and speed of internet access today have also influenced the\ndevelopment of computer games, especially computer games that are played\nonline. Internet technology has allowed computer games to be played in\nmultiplayer mode. Interaction between players in a computer game can be built\nin several ways, one of which is by providing balanced opponents. Opponents can\nbe developed using intelligent agents. On the other hand, research on\ndeveloping intelligent agents is also growing rapidly. In computer game\ndevelopment, one of the easiest ways to measure the performance of an\nintelligent agent is to develop a virtual environment that allows the\nintelligent agent to interact with other players. In this research, we try to\ndevelop an intelligent agent and virtual environment for the board game. To be\neasily accessible, the intelligent agent and virtual environment are then\ndeveloped into an Application Programming Interface (API) service called\nGapoera API. The Gapoera API service that is built is expected to help game\ndevelopers develop a game without having to think much about the artificial\nintelligence that will be embedded in the game. This service provides a basic\nmultilevel intelligent agent that can provide users with playing board games\ncommonly played in Indonesia. Although the Gapoera API can be used for various\ntypes of games, in this paper, we will focus on the discussion on a popular\ntraditional board game in Indonesia, namely Mancala. The test results conclude\nthat the multilevel agent concept developed has worked as expected. On the\nother hand, the development of the Gapoera API service has also been\nsuccessfully accessed on several game platforms.",
    "descriptor": "\nComments: The following article has been accepted in The 6th International Conference on Information Technology and Digital Applications. After it is published, it will be found at this https URL\n",
    "authors": [
      "Rian Adam Rajagede",
      "Galang Prihadi Mahardhika"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.11924"
  },
  {
    "id": "arXiv:2110.11927",
    "title": "Solving Large-Scale Granular Resource Allocation Problems Efficiently  with POP",
    "abstract": "Resource allocation problems in many computer systems can be formulated as\nmathematical optimization problems. However, finding exact solutions to these\nproblems using off-the-shelf solvers is often intractable for large problem\nsizes with tight SLAs, leading system designers to rely on cheap, heuristic\nalgorithms. We observe, however, that many allocation problems are granular:\nthey consist of a large number of clients and resources, each client requests a\nsmall fraction of the total number of resources, and clients can\ninterchangeably use different resources. For these problems, we propose an\nalternative approach that reuses the original optimization problem formulation\nand leads to better allocations than domain-specific heuristics. Our technique,\nPartitioned Optimization Problems (POP), randomly splits the problem into\nsmaller problems (with a subset of the clients and resources in the system) and\ncoalesces the resulting sub-allocations into a global allocation for all\nclients. We provide theoretical and empirical evidence as to why random\npartitioning works well. In our experiments, POP achieves allocations within\n1.5% of the optimal with orders-of-magnitude improvements in runtime compared\nto existing systems for cluster scheduling, traffic engineering, and load\nbalancing.",
    "descriptor": "\nComments: Accepted to SOSP 2021 (extended version)\n",
    "authors": [
      "Deepak Narayanan",
      "Fiodar Kazhamiaka",
      "Firas Abuzaid",
      "Peter Kraft",
      "Akshay Agrawal",
      "Srikanth Kandula",
      "Stephen Boyd",
      "Matei Zaharia"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.11927"
  },
  {
    "id": "arXiv:2110.11929",
    "title": "Double Trouble: How to not explain a text classifier's decisions using  counterfactuals synthesized by masked language models?",
    "abstract": "Explaining how important each input feature is to a classifier's decision is\ncritical in high-stake applications. An underlying principle behind dozens of\nexplanation methods is to take the prediction difference between\nbefore-and-after an input feature (here, a token) is removed as its attribution\n- the individual treatment effect in causal inference. A recent method called\nInput Marginalization (IM) (Kim et al., 2020) uses BERT to replace a token -\ni.e. simulating the do(.) operator - yielding more plausible counterfactuals.\nHowever, our rigorous evaluation using five metrics and on three datasets found\nIM explanations to be consistently more biased, less accurate, and less\nplausible than those derived from simply deleting a word.",
    "descriptor": "\nComments: 9+8 pages, 4+12 figures\n",
    "authors": [
      "Thang M. Pham",
      "Trung Bui",
      "Long Mai",
      "Anh Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11929"
  },
  {
    "id": "arXiv:2110.11934",
    "title": "Cleaning Dirty Books: Post-OCR Processing for Previously Scanned Texts",
    "abstract": "Substantial amounts of work are required to clean large collections of\ndigitized books for NLP analysis, both because of the presence of errors in the\nscanned text and the presence of duplicate volumes in the corpora. In this\npaper, we consider the issue of deduplication in the presence of optical\ncharacter recognition (OCR) errors. We present methods to handle these errors,\nevaluated on a collection of 19,347 texts from the Project Gutenberg dataset\nand 96,635 texts from the HathiTrust Library. We demonstrate that improvements\nin language models now enable the detection and correction of OCR errors\nwithout consideration of the scanning image itself. The inconsistencies found\nby aligning pairs of scans of the same underlying work provides training data\nto build models for detecting and correcting errors. We identify the canonical\nversion for each of 17,136 repeatedly-scanned books from 58,808 scans. Finally,\nwe investigate methods to detect and correct errors in single-copy texts. We\nshow that on average, our method corrects over six times as many errors as it\nintroduces. We also provide interesting analysis on the relation between\nscanning quality and other factors such as location and publication year.",
    "descriptor": "\nComments: Accepted for Findings of EMNLP 2021\n",
    "authors": [
      "Allen Kim",
      "Charuta Pethe",
      "Naoya Inoue",
      "Steve Skiena"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.11934"
  },
  {
    "id": "arXiv:2110.11938",
    "title": "A Framework for Learning Assessment through Multimodal Analysis of  Reading Behaviour and Language Comprehension",
    "abstract": "Reading comprehension, which has been defined as gaining an understanding of\nwritten text through a process of translating grapheme into meaning, is an\nimportant academic skill. Other language learning skills - writing, speaking\nand listening, all are connected to reading comprehension. There have been\nseveral measures proposed by researchers to automate the assessment of\ncomprehension skills for second language (L2) learners, especially English as\nSecond Language (ESL) and English as Foreign Language (EFL) learners. However,\ncurrent methods measure particular skills without analysing the impact of\nreading frequency on comprehension skills. In this dissertation, we show how\ndifferent skills could be measured and scored automatically. We also\ndemonstrate, using example experiments on multiple forms of learners'\nresponses, how frequent reading practices could impact on the variables of\nmultimodal skills (reading pattern, writing, and oral fluency).\nThis thesis comprises of five studies. The first and second studies are based\non eye-tracking data collected from EFL readers in repeated reading (RR)\nsessions. The third and fourth studies are to evaluate free-text summary\nwritten by EFL readers in repeated reading sessions. The fifth and last study,\ndescribed in the sixth chapter of the thesis, is to evaluate recorded oral\nsummaries recited by EFL readers in repeated reading sessions.\nIn a nutshell, through this dissertation, we show that multimodal skills of\nlearners could be assessed to measure their comprehension skills as well as to\nmeasure the effect of repeated readings on these skills in the course of time,\nby finding significant features and by applying machine learning techniques\nwith a combination of statistical models such as LMER.",
    "descriptor": "\nComments: PhD Thesis, August 2021, Indian Institute of Information Technology Allahabad, Prayagraj, India\n",
    "authors": [
      "Santosh Kumar Barnwal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.11938"
  },
  {
    "id": "arXiv:2110.11939",
    "title": "Adaptive FEM for Helmholtz Equation with Large Wave Number",
    "abstract": "A posteriori upper and lower bounds are derived for the linear finite element\nmethod (FEM) for the Helmholtz equation with large wave number. It is proved\nrigorously that the standard residual type error estimator seriously\nunderestimates the true error of the FE solution for the mesh size $h$ in the\npreasymptotic regime, which is first observed by Babu\\v{s}ka, et al. for an one\ndimensional problem. By establishing an equivalence relationship between the\nerror estimators for the FE solution and the corresponding elliptic projection\nof the exact solution, an adaptive algorithm is proposed and its convergence\nand quasi-optimality are proved under condition that $k^3h_0^{1+\\al}$ is\nsufficiently small, where $h_0$ is the initial mesh size and $\\frac12<\\al\\le 1$\nis a regularity constant depending on the maximum reentrant angle of the\ndomain. Numerical tests are given to verify the theoretical findings and to\nshow that the adaptive continuous interior penalty finite element method\n(CIP-FEM) with appropriately selected penalty parameters can greatly reduce the\npollution error and hence the residual type error estimator for this CIP-FEM is\nreliable and efficient even in the preasymptotic regime.",
    "descriptor": "",
    "authors": [
      "Songyao Duan",
      "Haijun Wu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.11939"
  },
  {
    "id": "arXiv:2110.11940",
    "title": "Logical Activation Functions: Logit-space equivalents of Boolean  Operators",
    "abstract": "Neuronal representations within artificial neural networks are commonly\nunderstood as logits, representing the log-odds score of presence (versus\nabsence) of features within the stimulus. Under this interpretation, we can\nderive the probability $P(x_0 \\land x_1)$ that a pair of independent features\nare both present in the stimulus from their logits. By converting the resulting\nprobability back into a logit, we obtain a logit-space equivalent of the AND\noperation. However, since this function involves taking multiple exponents and\nlogarithms, it is not well suited to be directly used within neural networks.\nWe thus constructed an efficient approximation named $\\text{AND}_\\text{AIL}$\n(the AND operator Approximate for Independent Logits) utilizing only comparison\nand addition operations, which can be deployed as an activation function in\nneural networks. Like MaxOut, $\\text{AND}_\\text{AIL}$ is a generalization of\nReLU to two-dimensions. Additionally, we constructed efficient approximations\nof the logit-space equivalents to the OR and XNOR operators. We deployed these\nnew activation functions, both in isolation and in conjunction, and\ndemonstrated their effectiveness on a variety of tasks including image\nclassification, transfer learning, abstract reasoning, and compositional\nzero-shot learning.",
    "descriptor": "",
    "authors": [
      "Scott C. Lowe",
      "Robert Earle",
      "Jason d'Eon",
      "Thomas Trappenberg",
      "Sageev Oore"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11940"
  },
  {
    "id": "arXiv:2110.11945",
    "title": "SOFT: Softmax-free Transformer with Linear Complexity",
    "abstract": "Vision transformers (ViTs) have pushed the state-of-the-art for various\nvisual recognition tasks by patch-wise image tokenization followed by\nself-attention. However, the employment of self-attention modules results in a\nquadratic complexity in both computation and memory usage. Various attempts on\napproximating the self-attention computation with linear complexity have been\nmade in Natural Language Processing. However, an in-depth analysis in this work\nshows that they are either theoretically flawed or empirically ineffective for\nvisual recognition. We further identify that their limitations are rooted in\nkeeping the softmax self-attention during approximations. Specifically,\nconventional self-attention is computed by normalizing the scaled dot-product\nbetween token feature vectors. Keeping this softmax operation challenges any\nsubsequent linearization efforts. Based on this insight, for the first time, a\nsoftmax-free transformer or SOFT is proposed. To remove softmax in\nself-attention, Gaussian kernel function is used to replace the dot-product\nsimilarity without further normalization. This enables a full self-attention\nmatrix to be approximated via a low-rank matrix decomposition. The robustness\nof the approximation is achieved by calculating its Moore-Penrose inverse using\na Newton-Raphson method. Extensive experiments on ImageNet show that our SOFT\nsignificantly improves the computational efficiency of existing ViT variants.\nCrucially, with a linear complexity, much longer token sequences are permitted\nin SOFT, resulting in superior trade-off between accuracy and complexity.",
    "descriptor": "\nComments: NeurIPS 2021 Spotlight. Project page at this https URL\n",
    "authors": [
      "Jiachen Lu",
      "Jinghan Yao",
      "Junge Zhang",
      "Xiatian Zhu",
      "Hang Xu",
      "Weiguo Gao",
      "Chunjing Xu",
      "Tao Xiang",
      "Li Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11945"
  },
  {
    "id": "arXiv:2110.11948",
    "title": "Learning Proposals for Practical Energy-Based Regression",
    "abstract": "Energy-based models (EBMs) have experienced a resurgence within machine\nlearning in recent years, including as a promising alternative for\nprobabilistic regression. However, energy-based regression requires a proposal\ndistribution to be manually designed for training, and an initial estimate has\nto be provided at test-time. We address both of these issues by introducing a\nconceptually simple method to automatically learn an effective proposal\ndistribution, which is parameterized by a separate network head. To this end,\nwe derive a surprising result, leading to a unified training objective that\njointly minimizes the KL divergence from the proposal to the EBM, and the\nnegative log-likelihood of the EBM. At test-time, we can then employ importance\nsampling with the trained proposal to efficiently evaluate the learned EBM and\nproduce stand-alone predictions. Furthermore, we utilize our derived training\nobjective to learn mixture density networks (MDNs) with a jointly trained\nenergy-based teacher, consistently outperforming conventional MDN training on\nfour real-world regression tasks within computer vision. Code is available at\nhttps://github.com/fregu856/ebms_proposals.",
    "descriptor": "\nComments: Code is available at this https URL\n",
    "authors": [
      "Fredrik K. Gustafsson",
      "Martin Danelljan",
      "Thomas B. Sch\u00f6n"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.11948"
  },
  {
    "id": "arXiv:2110.11950",
    "title": "Adversarial robustness for latent models: Revisiting the robust-standard  accuracies tradeoff",
    "abstract": "Over the past few years, several adversarial training methods have been\nproposed to improve the robustness of machine learning models against\nadversarial perturbations in the input. Despite remarkable progress in this\nregard, adversarial training is often observed to drop the standard test\naccuracy. This phenomenon has intrigued the research community to investigate\nthe potential tradeoff between standard and robust accuracy as two performance\nmeasures. In this paper, we revisit this tradeoff for latent models and argue\nthat this tradeoff is mitigated when the data enjoys a low-dimensional\nstructure. In particular, we consider binary classification under two data\ngenerative models, namely Gaussian mixture model and generalized linear model,\nwhere the feature data lie on a low-dimensional manifold. We show that as the\nmanifold dimension to the ambient dimension decreases, one can obtain models\nthat are nearly optimal with respect to both, the standard accuracy and the\nrobust accuracy measures.",
    "descriptor": "",
    "authors": [
      "Adel Javanmard",
      "Mohammad Mehrabi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.11950"
  },
  {
    "id": "arXiv:2110.11339",
    "title": "Unsupervised cross-user adaptation in taste sensationrecognition based  on surface electromyography withconformal prediction and domain  regularizedcomponent analysis",
    "abstract": "Human taste sensation can be qualitatively described with surface\nelectromyography. However, the pattern recognition models trained on one\nsubject (the source domain) do not generalize well on other subjects (the\ntarget domain). To improve the generalizability and transferability of taste\nsensation models developed with sEMG data, two methods were innovatively\napplied in this study: domain regularized component analysis (DRCA) and\nconformal prediction with shrunken centroids (CPSC). The effectiveness of these\ntwo methods was investigated independently in an unlabeled data augmentation\nprocess with the unlabeled data from the target domain, and the same cross-user\nadaptation pipeline were conducted on six subjects. The results show that DRCA\nimproved the classification accuracy on six subjects (p < 0.05), compared with\nthe baseline models trained only with the source domain data;, while CPSC did\nnot guarantee the accuracy improvement. Furthermore, the combination of DRCA\nand CPSC presented statistically significant improvement (p < 0.05) in\nclassification accuracy on six subjects. The proposed strategy combining DRCA\nand CPSC showed its effectiveness in addressing the cross-user data\ndistribution drift in sEMG-based taste sensation recognition application. It\nalso shows the potential in more cross-user adaptation applications.",
    "descriptor": "",
    "authors": [
      "Hengyang Wang",
      "Xianghao Zhan",
      "Li Liu",
      "Asif Ullah",
      "Huiyan Li",
      "Han Gao",
      "You Wang",
      "Guang Li"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11339"
  },
  {
    "id": "arXiv:2110.11347",
    "title": "Multidimensional representations in late-life depression: convergence in  neuroimaging, cognition, clinical symptomatology and genetics",
    "abstract": "Late-life depression (LLD) is characterized by considerable heterogeneity in\nclinical manifestation. Unraveling such heterogeneity would aid in elucidating\netiological mechanisms and pave the road to precision and individualized\nmedicine. We sought to delineate, cross-sectionally and longitudinally,\ndisease-related heterogeneity in LLD linked to neuroanatomy, cognitive\nfunctioning, clinical symptomatology, and genetic profiles. Multimodal data\nfrom a multicentre sample (N=996) were analyzed. A semi-supervised clustering\nmethod (HYDRA) was applied to regional grey matter (GM) brain volumes to derive\ndimensional representations. Two dimensions were identified, which accounted\nfor the LLD-related heterogeneity in voxel-wise GM maps, white matter (WM)\nfractional anisotropy (FA), neurocognitive functioning, clinical phenotype, and\ngenetics. Dimension one (Dim1) demonstrated relatively preserved brain anatomy\nwithout WM disruptions relative to healthy controls. In contrast, dimension two\n(Dim2) showed widespread brain atrophy and WM integrity disruptions, along with\ncognitive impairment and higher depression severity. Moreover, one de novo\nindependent genetic variant (rs13120336) was significantly associated with Dim\n1 but not with Dim 2. Notably, the two dimensions demonstrated significant\nSNP-based heritability of 18-27% within the general population (N=12,518 in\nUKBB). Lastly, in a subset of individuals having longitudinal measurements,\nDim2 demonstrated a more rapid longitudinal decrease in GM and brain age, and\nwas more likely to progress to Alzheimers disease, compared to Dim1 (N=1,413\nparticipants and 7,225 scans from ADNI, BLSA, and BIOCARD datasets).",
    "descriptor": "",
    "authors": [
      "Junhao Wen",
      "Cynthia H.Y. Fu",
      "Duygu Tosun",
      "Yogasudha Veturi",
      "Zhijian Yang",
      "Ahmed Abdulkadir",
      "Elizabeth Mamourian",
      "Dhivya Srinivasan",
      "Jingxuan Bao",
      "Guray Erus",
      "Haochang Shou",
      "Mohamad Habes",
      "Jimit Doshi",
      "Erdem Varol",
      "Scott R Mackin",
      "Aristeidis Sotiras",
      "Yong Fan",
      "Andrew J. Saykin",
      "Yvette I. Sheline",
      "Li Shen",
      "Marylyn D. Ritchie",
      "David A. Wolk",
      "Marilyn Albert",
      "Susan M. Resnick",
      "Christos Davatzikos"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11347"
  },
  {
    "id": "arXiv:2110.11377",
    "title": "CaloFlow II: Even Faster and Still Accurate Generation of Calorimeter  Showers with Normalizing Flows",
    "abstract": "Recently, we introduced CaloFlow, a high-fidelity generative model for GEANT4\ncalorimeter shower emulation based on normalizing flows. Here, we present\nCaloFlow v2, an improvement on our original framework that speeds up shower\ngeneration by a further factor of 500 relative to the original. The improvement\nis based on a technique called Probability Density Distillation, originally\ndeveloped for speech synthesis in the ML literature, and which we develop\nfurther by introducing a set of powerful new loss terms. We demonstrate that\nCaloFlow v2 preserves the same high fidelity of the original using qualitative\n(average images, histograms of high level features) and quantitative\n(classifier metric between GEANT4 and generated samples) measures. The result\nis a generative model for calorimeter showers that matches the state-of-the-art\nin speed (a factor of $10^4$ faster than GEANT4) and greatly surpasses the\nprevious state-of-the-art in fidelity.",
    "descriptor": "\nComments: 28 pages, 15 figures, 4 tables\n",
    "authors": [
      "Claudius Krause",
      "David Shih"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2110.11377"
  },
  {
    "id": "arXiv:2110.11382",
    "title": "Efficient and Robust Mixed-Integer Optimization Methods for Training  Binarized Deep Neural Networks",
    "abstract": "Compared to classical deep neural networks its binarized versions can be\nuseful for applications on resource-limited devices due to their reduction in\nmemory consumption and computational demands. In this work we study deep neural\nnetworks with binary activation functions and continuous or integer weights\n(BDNN). We show that the BDNN can be reformulated as a mixed-integer linear\nprogram with bounded weight space which can be solved to global optimality by\nclassical mixed-integer programming solvers. Additionally, a local search\nheuristic is presented to calculate locally optimal networks. Furthermore to\nimprove efficiency we present an iterative data-splitting heuristic which\niteratively splits the training set into smaller subsets by using the k-mean\nmethod. Afterwards all data points in a given subset are forced to follow the\nsame activation pattern, which leads to a much smaller number of integer\nvariables in the mixed-integer programming formulation and therefore to\ncomputational improvements. Finally for the first time a robust model is\npresented which enforces robustness of the BDNN during training. All methods\nare tested on random and real datasets and our results indicate that all models\ncan often compete with or even outperform classical DNNs on small network\narchitectures confirming the viability for applications having restricted\nmemory or computing power.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2007.03326\n",
    "authors": [
      "Jannis Kurtz",
      "Bubacarr Bah"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11382"
  },
  {
    "id": "arXiv:2110.11383",
    "title": "Finite-Time Complexity of Online Primal-Dual Natural Actor-Critic  Algorithm for Constrained Markov Decision Processes",
    "abstract": "We consider a discounted cost constrained Markov decision process (CMDP)\npolicy optimization problem, in which an agent seeks to maximize a discounted\ncumulative reward subject to a number of constraints on discounted cumulative\nutilities. To solve this constrained optimization program, we study an online\nactor-critic variant of a classic primal-dual method where the gradients of\nboth the primal and dual functions are estimated using samples from a single\ntrajectory generated by the underlying time-varying Markov processes. This\nonline primal-dual natural actor-critic algorithm maintains and iteratively\nupdates three variables: a dual variable (or Lagrangian multiplier), a primal\nvariable (or actor), and a critic variable used to estimate the gradients of\nboth primal and dual variables. These variables are updated simultaneously but\non different time scales (using different step sizes) and they are all\nintertwined with each other. Our main contribution is to derive a finite-time\nanalysis for the convergence of this algorithm to the global optimum of a CMDP\nproblem. Specifically, we show that with a proper choice of step sizes the\noptimality gap and constraint violation converge to zero in expectation at a\nrate $\\mathcal{O}(1/K^{1/6})$, where K is the number of iterations. To our\nknowledge, this paper is the first to study the finite-time complexity of an\nonline primal-dual actor-critic method for solving a CMDP problem. We also\nvalidate the effectiveness of this algorithm through numerical simulations.",
    "descriptor": "",
    "authors": [
      "Sihan Zeng",
      "Thinh T. Doan",
      "Justin Romberg"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11383"
  },
  {
    "id": "arXiv:2110.11387",
    "title": "GNC Analysis and Robotic Systems Configuration of Collision-free Earth  Observation Satellites (CfEOS) Constellations",
    "abstract": "The high number of objects in the LEO is a risk that collisions between\nsub-orbital or escape velocity objects with an orbiting object of satellites\noccur when two satellites collide while orbiting the earth. One of the\napproaches to avoid collisions is a robotic configuration of satellite\nconstellations. Satellite constellations should not be confused with satellite\nclusters, which are groups of satellites moving in close proximity to each\nother in nearly identical orbits; nor with satellite series or satellite\nprograms, which are generations of satellites launched successively; nor with\nsatellite fleets, which are groups of satellites from the same manufacturer or\noperator that operate an independent system. CfEOS constellations designed for\ngeospatial applications and Earth observation. Unlike a single satellite, a\nconstellation can provide permanent global or near-global coverage anywhere on\nEarth. CfEOS constellations are configured in sets of complementary orbital\nplanes and connect to ground stations located around the globe. This paper\ndescribes the GNC analysis, the orbit propagation and robotic systems\nconfiguration for Collision-free Earth observation satellites (CfEOS)\nconstellations.",
    "descriptor": "\nComments: 9 pages, 1 table, 8 figures\n",
    "authors": [
      "Manuel Ntumba",
      "Saurabh Gore",
      "Pulkit Jain",
      "Jean-Baptiste Awanyo"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.11387"
  },
  {
    "id": "arXiv:2110.11396",
    "title": "A Data-Driven Reconstruction Technique based on Newton's Method for  Emission Tomography",
    "abstract": "In this work, we present the Deep Newton Reconstruction Network (DNR-Net), a\nhybrid data-driven reconstruction technique for emission tomography inspired by\nNewton's method, a well-known iterative optimization algorithm. The DNR-Net\nemploys prior information about the tomographic problem provided by the\nprojection operator while utilizing deep learning approaches to a) imitate\nNewton's method by approximating the Newton descent direction and b) provide\ndata-driven regularisation. We demonstrate that DNR-Net is capable of providing\nhigh-quality image reconstructions using data from SPECT phantom simulations by\napplying it to reconstruct images from noisy sinograms, each one containing 24\nprojections. The Structural Similarity Index (SSIM) and the Contrast-to-Noise\nratio (CNR) were used to quantify the image quality. We also compare our\nresults to those obtained by the OSEM method. According to the quantitative\nresults, the DNR-Net produces reconstructions comparable to the ones produced\nby OSEM while featuring higher contrast and less noise.",
    "descriptor": "\nComments: 7 pages, 4 figures, Proceedings\n",
    "authors": [
      "Loizos Koutsantonis",
      "Tiago Carneiro",
      "Emmanuel Kieffer",
      "Frederic Pinel",
      "Pascal Bouvry"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.11396"
  },
  {
    "id": "arXiv:2110.11437",
    "title": "An echelon form of weakly infeasible semidefinite programs and bad  projections of the psd cone",
    "abstract": "A weakly infeasible semidefinite program (SDP) has no feasible solution, but\nit has approximate solutions whose constraint violation is arbitrarily small.\nThese SDPs are ill-posed and numerically often unsolvable. They are also\nclosely related to \"bad\" linear projections that map the cone of positive\nsemidefinite matrices to a nonclosed set. We describe a simple echelon form of\nweakly infeasible SDPs with the following properties: (i) it is obtained by\nelementary row operations and congruence transformations, (ii) it makes weak\ninfeasibility evident, and (iii) it permits us to construct any weakly\ninfeasible SDP or bad linear projection by an elementary combinatorial\nalgorithm. Based on our echelon form we generate a challenging library of\nweakly infeasible SDPs. Finally, we show that some SDPs in the literature are\nin our echelon form, for example, the SDP from the sum-of-squares relaxation of\nminimizing the famous Motzkin polynomial.",
    "descriptor": "\nComments: to appear\n",
    "authors": [
      "G\u00e1bor Pataki",
      "Aleksandr Touzov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Symbolic Computation (cs.SC)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2110.11437"
  },
  {
    "id": "arXiv:2110.11438",
    "title": "Objective Measures of Perceptual Audio Quality Reviewed: An Evaluation  of Their Application Domain Dependence",
    "abstract": "Over the past few decades, computational methods have been developed to\nestimate perceptual audio quality. These methods, also referred to as objective\nquality measures, are usually developed and intended for a specific application\ndomain. Because of their convenience, they are often used outside their\noriginal intended domain, even if it is unclear whether they provide reliable\nquality estimates in this case. This work studies the correlation of well-known\nstate-of-the-art objective measures with human perceptual scores in two\ndifferent domains: audio coding and source separation. The following objective\nmeasures are considered: fwSNRseg, dLLR, PESQ, PEAQ, POLQA, PEMO-Q,\nViSQOLAudio, (SI-)BSSEval, PEASS, LKR-PI, 2f-model, and HAAQI. Additionally, a\nnovel measure (SI-SA2f) is presented, based on the 2f-model and a BSSEval-based\nsignal decomposition. We use perceptual scores from 7 listening tests about\naudio coding and 7 listening tests about source separation as ground-truth data\nfor the correlation analysis. The results show that one method (2f-model)\nperforms significantly better than the others on both domains and indicate that\nthe dataset for training the method and a robust underlying auditory model are\ncrucial factors towards a universal, domain-independent objective measure.",
    "descriptor": "",
    "authors": [
      "Matteo Torcoli",
      "Thorsten Kastner",
      "J\u00fcrgen Herre"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.11438"
  },
  {
    "id": "arXiv:2110.11442",
    "title": "Towards Noise-adaptive, Problem-adaptive Stochastic Gradient Descent",
    "abstract": "We design step-size schemes that make stochastic gradient descent (SGD)\nadaptive to (i) the noise $\\sigma^2$ in the stochastic gradients and (ii)\nproblem-dependent constants. When minimizing smooth, strongly-convex functions\nwith condition number $\\kappa$, we first prove that $T$ iterations of SGD with\nNesterov acceleration and exponentially decreasing step-sizes can achieve a\nnear-optimal $\\tilde{O}(\\exp(-T/\\sqrt{\\kappa}) + \\sigma^2/T)$ convergence rate.\nUnder a relaxed assumption on the noise, with the same step-size scheme and\nknowledge of the smoothness, we prove that SGD can achieve an\n$\\tilde{O}(\\exp(-T/\\kappa) + \\sigma^2/T)$ rate. In order to be adaptive to the\nsmoothness, we use a stochastic line-search (SLS) and show (via upper and\nlower-bounds) that SGD converges at the desired rate, but only to a\nneighbourhood of the solution. Next, we use SGD with an offline estimate of the\nsmoothness and prove convergence to the minimizer. However, its convergence is\nslowed down proportional to the estimation error and we prove a lower-bound\njustifying this slowdown. Compared to other step-size schemes, we empirically\ndemonstrate the effectiveness of exponential step-sizes coupled with a novel\nvariant of SLS.",
    "descriptor": "",
    "authors": [
      "Sharan Vaswani",
      "Benjamin Dubois-Taine",
      "Reza Babanezhad"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.11442"
  },
  {
    "id": "arXiv:2110.11477",
    "title": "Conditioning of Random Feature Matrices: Double Descent and  Generalization Error",
    "abstract": "We provide (high probability) bounds on the condition number of random\nfeature matrices. In particular, we show that if the complexity ratio\n$\\frac{N}{m}$ where $N$ is the number of neurons and $m$ is the number of data\nsamples scales like $\\log^{-3}(N)$ or $\\log^{3}(m)$, then the random feature\nmatrix is well-conditioned. This result holds without the need of\nregularization and relies on establishing a bound on the restricted isometry\nconstant of the random feature matrix. In addition, we prove that the risk\nassociated with regression problems using a random feature matrix exhibits the\ndouble descent phenomenon and that this is an effect of the double descent\nbehavior of the condition number. The risk bounds include the\nunderparameterized setting using the least squares problem and the\noverparameterized setting where using either the minimum norm interpolation\nproblem or a sparse regression problem. For the least squares or sparse\nregression cases, we show that the risk decreases as $m$ and $N$ increase, even\nin the presence of bounded or random noise. The risk bound matches the optimal\nscaling in the literature and the constants in our results are explicit and\nindependent of the dimension of the data.",
    "descriptor": "",
    "authors": [
      "Zhijun Chen",
      "Hayden Schaeffer"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2110.11477"
  },
  {
    "id": "arXiv:2110.11479",
    "title": "Synt++: Utilizing Imperfect Synthetic Data to Improve Speech Recognition",
    "abstract": "With recent advances in speech synthesis, synthetic data is becoming a viable\nalternative to real data for training speech recognition models. However,\nmachine learning with synthetic data is not trivial due to the gap between the\nsynthetic and the real data distributions. Synthetic datasets may contain\nartifacts that do not exist in real data such as structured noise, content\nerrors, or unrealistic speaking styles. Moreover, the synthesis process may\nintroduce a bias due to uneven sampling of the data manifold. We propose two\nnovel techniques during training to mitigate the problems due to the\ndistribution gap: (i) a rejection sampling algorithm and (ii) using separate\nbatch normalization statistics for the real and the synthetic samples. We show\nthat these methods significantly improve the training of speech recognition\nmodels using synthetic data. We evaluate the proposed approach on keyword\ndetection and Automatic Speech Recognition (ASR) tasks, and observe up to 18%\nand 13% relative error reduction, respectively, compared to naively using the\nsynthetic data.",
    "descriptor": "",
    "authors": [
      "Ting-Yao Hu",
      "Mohammadreza Armandpour",
      "Ashish Shrivastava",
      "Jen-Hao Rick Chang",
      "Hema Koppula",
      "Oncel Tuzel"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.11479"
  },
  {
    "id": "arXiv:2110.11493",
    "title": "Surface code compilation via edge-disjoint paths",
    "abstract": "We provide an efficient algorithm to compile quantum circuits for\nfault-tolerant execution. We target surface codes, which form a 2D grid of\nlogical qubits with nearest-neighbor logical operations. Embedding an input\ncircuit's qubits in surface codes can result in long-range two-qubit operations\nacross the grid. We show how to prepare many long-range Bell pairs on qubits\nconnected by edge-disjoint paths of ancillas in constant depth which can be\nused to perform these long-range operations. This forms one core part of our\nEdge-Disjoint Paths Compilation (EDPC) algorithm, by easily performing parallel\nlong-range Clifford operations in constant depth. It also allows us to\nestablish a connection between surface code compilation and several\nwell-studied edge-disjoint paths problems. Similar techniques allow us to\nperform non-Clifford single-qubit rotations far from magic state distillation\nfactories. In this case, we can easily find the maximum set of paths by a\nmax-flow reduction, which forms the other major part of our EDPC algorithm. We\ncompare EDPC to other compilation approaches including a SWAP-based algorithm,\nand find significantly improved performance for circuits built from parallel\nCNOTs, and for circuits which implement the multi-controlled X gate.",
    "descriptor": "",
    "authors": [
      "Michael Beverland",
      "Vadym Kliuchnikov",
      "Eddie Schoute"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2110.11493"
  },
  {
    "id": "arXiv:2110.11496",
    "title": "A Preconditioned Iterative Interior Point Approach to the Conic Bundle  Subproblem",
    "abstract": "The conic bundle implementation of the spectral bundle method for large scale\nsemidefinite programming solves in each iteration a semidefinite quadratic\nsubproblem by an interior point approach. For larger cutting model sizes the\nlimiting operation is collecting and factorizing a Schur complement of the\nprimal-dual KKT system. We explore possibilities to improve on this by an\niterative approach that exploits structural low rank properties. Two\npreconditioning approaches are proposed and analyzed. Both might be of interest\nfor rank structured positive definite systems in general. The first employs\nprojections onto random subspaces, the second projects onto a subspace that is\nchosen deterministically based on structural interior point properties. For\nboth approaches theoretic bounds are derived for the associated condition\nnumber. In the instances tested the deterministic preconditioner provides\nsurprisingly efficient control on the actual condition number. The results\nsuggest that for large scale instances the iterative solver is usually the\nbetter choice if precision requirements are moderate or if the size of the\nSchur complemented system clearly exceeds the active dimension within the\nsubspace giving rise to the cutting model of the bundle method.",
    "descriptor": "\nComments: 29+9 pages, 4 figures\n",
    "authors": [
      "Christoph Helmberg"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.11496"
  },
  {
    "id": "arXiv:2110.11501",
    "title": "Cortico-cerebellar networks as decoupling neural interfaces",
    "abstract": "The brain solves the credit assignment problem remarkably well. For credit to\nbe assigned across neural networks they must, in principle, wait for specific\nneural computations to finish. How the brain deals with this inherent locking\nproblem has remained unclear. Deep learning methods suffer from similar locking\nconstraints both on the forward and feedback phase. Recently, decoupled neural\ninterfaces (DNIs) were introduced as a solution to the forward and feedback\nlocking problems in deep networks. Here we propose that a specialised brain\nregion, the cerebellum, helps the cerebral cortex solve similar locking\nproblems akin to DNIs. To demonstrate the potential of this framework we\nintroduce a systems-level model in which a recurrent cortical network receives\nonline temporal feedback predictions from a cerebellar module. We test this\ncortico-cerebellar recurrent neural network (ccRNN) model on a number of\nsensorimotor (line and digit drawing) and cognitive tasks (pattern recognition\nand caption generation) that have been shown to be cerebellar-dependent. In all\ntasks, we observe that ccRNNs facilitates learning while reducing ataxia-like\nbehaviours, consistent with classical experimental observations. Moreover, our\nmodel also explains recent behavioural and neuronal observations while making\nseveral testable predictions across multiple levels. Overall, our work offers a\nnovel perspective on the cerebellum as a brain-wide decoupling machine for\nefficient credit assignment and opens a new avenue between deep learning and\nneuroscience.",
    "descriptor": "\nComments: To appear in Advances in Neural Information Processing Systems 35 (NeurIPS 2021); 15 pages and 5 figures in the main manuscript; 8 pages and 8 figures in the supplementary material\n",
    "authors": [
      "Joseph Pemberton",
      "Ellen Boven",
      "Richard Apps",
      "Rui Ponte Costa"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11501"
  },
  {
    "id": "arXiv:2110.11538",
    "title": "Computing the Invariant Distribution of Randomly Perturbed Dynamical  Systems Using Deep Learning",
    "abstract": "The invariant distribution, which is characterized by the stationary\nFokker-Planck equation, is an important object in the study of randomly\nperturbed dynamical systems. Traditional numerical methods for computing the\ninvariant distribution based on the Fokker-Planck equation, such as finite\ndifference or finite element methods, are limited to low-dimensional systems\ndue to the curse of dimensionality. In this work, we propose a deep learning\nbased method to compute the generalized potential, i.e. the negative logarithm\nof the invariant distribution multiplied by the noise. The idea of the method\nis to learn a decomposition of the force field, as specified by the\nFokker-Planck equation, from the trajectory data. The potential component of\nthe decomposition gives the generalized potential. The method can deal with\nhigh-dimensional systems, possibly with partially known dynamics. Using the\ngeneralized potential also allows us to deal with systems at low temperatures,\nwhere the invariant distribution becomes singular around the metastable states.\nThese advantages make it an efficient method to analyze invariant distributions\nfor practical dynamical systems. The effectiveness of the proposed method is\ndemonstrated by numerical examples.",
    "descriptor": "",
    "authors": [
      "Bo Lin",
      "Qianxiao Li",
      "Weiqing Ren"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.11538"
  },
  {
    "id": "arXiv:2110.11558",
    "title": "MHAttnSurv: Multi-Head Attention for Survival Prediction Using  Whole-Slide Pathology Images",
    "abstract": "In pathology, whole-slide images (WSI) based survival prediction has\nattracted increasing interest. However, given the large size of WSIs and the\nlack of pathologist annotations, extracting the prognostic information from\nWSIs remains a challenging task. Previous studies have used multiple instance\nlearning approaches to combine the information from multiple randomly sampled\npatches, but different visual patterns may contribute differently to prognosis\nprediction. In this study, we developed a multi-head attention approach to\nfocus on various parts of a tumor slide, for more comprehensive information\nextraction from WSIs. We evaluated our approach on four cancer types from The\nCancer Genome Atlas database. Our model achieved an average c-index of 0.640,\noutperforming two existing state-of-the-art approaches for WSI-based survival\nprediction, which have an average c-index of 0.603 and 0.619 on these datasets.\nVisualization of our attention maps reveals each attention head focuses\nsynergistically on different morphological patterns.",
    "descriptor": "",
    "authors": [
      "Shuai Jiang",
      "Arief A. Suriawinata",
      "Saeed Hassanpour"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2110.11558"
  },
  {
    "id": "arXiv:2110.11561",
    "title": "Merging Two Cultures: Deep and Statistical Learning",
    "abstract": "Merging the two cultures of deep and statistical learning provides insights\ninto structured high-dimensional data. Traditional statistical modeling is\nstill a dominant strategy for structured tabular data. Deep learning can be\nviewed through the lens of generalized linear models (GLMs) with composite link\nfunctions. Sufficient dimensionality reduction (SDR) and sparsity performs\nnonlinear feature engineering. We show that prediction, interpolation and\nuncertainty quantification can be achieved using probabilistic methods at the\noutput layer of the model. Thus a general framework for machine learning arises\nthat first generates nonlinear features (a.k.a factors) via sparse\nregularization and stochastic gradient optimisation and second uses a\nstochastic output layer for predictive uncertainty. Rather than using shallow\nadditive architectures as in many statistical models, deep learning uses layers\nof semi affine input transformations to provide a predictive rule. Applying\nthese layers of transformations leads to a set of attributes (a.k.a features)\nto which predictive statistical methods can be applied. Thus we achieve the\nbest of both worlds: scalability and fast predictive rule construction together\nwith uncertainty quantification. Sparse regularisation with un-supervised or\nsupervised learning finds the features. We clarify the duality between shallow\nand wide models such as PCA, PPR, RRR and deep but skinny architectures such as\nautoencoders, MLPs, CNN, and LSTM. The connection with data transformations is\nof practical importance for finding good network architectures. By\nincorporating probabilistic components at the output level we allow for\npredictive uncertainty. For interpolation we use deep Gaussian process and ReLU\ntrees for classification. We provide applications to regression, classification\nand interpolation. Finally, we conclude with directions for future research.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2106.14085\n",
    "authors": [
      "Anindya Bhadra",
      "Jyotishka Datta",
      "Nick Polson",
      "Vadim Sokolov",
      "Jianeng Xu"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.11561"
  },
  {
    "id": "arXiv:2110.11582",
    "title": "An Economy of Neural Networks: Learning from Heterogeneous Experiences",
    "abstract": "This paper proposes a new way to model behavioral agents in dynamic\nmacro-financial environments. Agents are described as neural networks and learn\npolicies from idiosyncratic past experiences. I investigate the feedback\nbetween irrationality and past outcomes in an economy with heterogeneous shocks\nsimilar to Aiyagari (1994). In the model, the rational expectations assumption\nis seriously violated because learning of a decision rule for savings is\nunstable. Agents who fall into learning traps save either excessively or save\nnothing, which provides a candidate explanation for several empirical puzzles\nabout wealth distribution. Neural network agents have a higher average MPC and\nexhibit excess sensitivity of consumption. Learning can negatively affect\nintergenerational mobility.",
    "descriptor": "\nComments: 47 pages\n",
    "authors": [
      "Artem Kuriksha"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.11582"
  },
  {
    "id": "arXiv:2110.11585",
    "title": "Monotone edge flips to an orientation of maximum edge-connectivity \u00e0  la Nash-Williams",
    "abstract": "We initiate the study of $k$-edge-connected orientations of undirected graphs\nthrough edge flips for $k \\geq 2$. We prove that in every orientation of an\nundirected $2k$-edge-connected graph, there exists a sequence of edges such\nthat flipping their directions one by one does not decrease the\nedge-connectivity, and the final orientation is $k$-edge-connected. This yields\nan ``edge-flip based'' new proof of Nash-Williams' theorem: an undirected graph\n$G$ has a $k$-edge-connected orientation if and only if $G$ is\n$2k$-edge-connected. As another consequence of the theorem, we prove that the\nedge-flip graph of $k$-edge-connected orientations of an undirected graph $G$\nis connected if $G$ is $(2k+2)$-edge-connected. This has been known to be true\nonly when $k=1$.",
    "descriptor": "",
    "authors": [
      "Takehiro Ito",
      "Yuni Iwamasa",
      "Naonori Kakimura",
      "Naoyuki Kamiyama",
      "Yusuke Kobayashi",
      "Shun-ichi Maezawa",
      "Yuta Nozaki",
      "Yoshio Okamoto",
      "Kenta Ozeki"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.11585"
  },
  {
    "id": "arXiv:2110.11591",
    "title": "Model Inspired Autoencoder for Unsupervised Hyperspectral Image  Super-Resolution",
    "abstract": "This paper focuses on hyperspectral image (HSI) super-resolution that aims to\nfuse a low-spatial-resolution HSI and a high-spatial-resolution multispectral\nimage to form a high-spatial-resolution HSI (HR-HSI). Existing deep\nlearning-based approaches are mostly supervised that rely on a large number of\nlabeled training samples, which is unrealistic. The commonly used model-based\napproaches are unsupervised and flexible but rely on hand-craft priors.\nInspired by the specific properties of model, we make the first attempt to\ndesign a model inspired deep network for HSI super-resolution in an\nunsupervised manner. This approach consists of an implicit autoencoder network\nbuilt on the target HR-HSI that treats each pixel as an individual sample. The\nnonnegative matrix factorization (NMF) of the target HR-HSI is integrated into\nthe autoencoder network, where the two NMF parts, spectral and spatial\nmatrices, are treated as decoder parameters and hidden outputs respectively. In\nthe encoding stage, we present a pixel-wise fusion model to estimate hidden\noutputs directly, and then reformulate and unfold the model's algorithm to form\nthe encoder network. With the specific architecture, the proposed network is\nsimilar to a manifold prior-based model, and can be trained patch by patch\nrather than the entire image. Moreover, we propose an additional unsupervised\nnetwork to estimate the point spread function and spectral response function.\nExperimental results conducted on both synthetic and real datasets demonstrate\nthe effectiveness of the proposed approach.",
    "descriptor": "",
    "authors": [
      "Jianjun Liu",
      "Zebin Wu",
      "Liang Xiao",
      "Xiao-Jun Wu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11591"
  },
  {
    "id": "arXiv:2110.11670",
    "title": "Model-aided Geometrical Shaping of Dual-polarization 4D Formats in the  Nonlinear Fiber Channel",
    "abstract": "The geometry of dual-polarization four-dimensional constellations is\noptimized in the optical fiber channel using a recent nonlinear interference\nmodel. A 0.27 bit/4D rate gain and 13\\% reach increase are attained compared to\npolarization-multiplexed formats.",
    "descriptor": "\nComments: Submitted to the Optical Fiber Communication Conference (OFC) 2022\n",
    "authors": [
      "Gabriele Liga",
      "Bin Chen",
      "Alex Alvarado"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.11670"
  },
  {
    "id": "arXiv:2110.11678",
    "title": "DQC: a Python program package for Differentiable Quantum Chemistry",
    "abstract": "Automatic differentiation represents a paradigm shift in scientific\nprogramming, where evaluating both functions and their derivatives is required\nfor most applications. By removing the need to explicitly derive expressions\nfor gradients, development times can be be shortened, and calculations\nsimplified. For these reasons, automatic differentiation has fueled the rapid\ngrowth of a variety of sophisticated machine learning techniques over the past\ndecade, but is now also increasingly showing its value to support {\\it ab\ninitio} simulations of quantum systems, and enhance computational quantum\nchemistry. Here we present an open-source differentiable quantum chemistry\nsimulation code, DQC, and explore applications facilitated by automatic\ndifferentiation: (1) calculating molecular perturbation properties; (2)\nreoptimizing a basis set for hydrocarbons; (3) checking the stability of\nself-consistent field wave functions; and (4) predicting molecular properties\nvia alchemical perturbations.",
    "descriptor": "",
    "authors": [
      "Muhammad F. Kasim",
      "Susi Lehtola",
      "Sam M. Vinko"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11678"
  },
  {
    "id": "arXiv:2110.11684",
    "title": "Multimodal-Boost: Multimodal Medical Image Super-Resolution using  Multi-Attention Network with Wavelet Transform",
    "abstract": "Multimodal medical images are widely used by clinicians and physicians to\nanalyze and retrieve complementary information from high-resolution images in a\nnon-invasive manner. The loss of corresponding image resolution degrades the\noverall performance of medical image diagnosis. Deep learning based single\nimage super resolution (SISR) algorithms has revolutionized the overall\ndiagnosis framework by continually improving the architectural components and\ntraining strategies associated with convolutional neural networks (CNN) on\nlow-resolution images. However, existing work lacks in two ways: i) the SR\noutput produced exhibits poor texture details, and often produce blurred edges,\nii) most of the models have been developed for a single modality, hence,\nrequire modification to adapt to a new one. This work addresses (i) by\nproposing generative adversarial network (GAN) with deep multi-attention\nmodules to learn high-frequency information from low-frequency data. Existing\napproaches based on the GAN have yielded good SR results; however, the texture\ndetails of their SR output have been experimentally confirmed to be deficient\nfor medical images particularly. The integration of wavelet transform (WT) and\nGANs in our proposed SR model addresses the aforementioned limitation\nconcerning textons. The WT divides the LR image into multiple frequency bands,\nwhile the transferred GAN utilizes multiple attention and upsample blocks to\npredict high-frequency components. Moreover, we present a learning technique\nfor training a domain-specific classifier as a perceptual loss function.\nCombining multi-attention GAN loss with a perceptual loss function results in a\nreliable and efficient performance. Applying the same model for medical images\nfrom diverse modalities is challenging, our work addresses (ii) by training and\nperforming on several modalities via transfer learning.",
    "descriptor": "\nComments: 14 pages, 12 Figures, and 3 Tables. Submitted to IEEE/ACM TCBB\n",
    "authors": [
      "Farah Deeba",
      "Fayaz Ali Dharejo",
      "Muhammad Zawish",
      "Yuanchun Zhou",
      "Kapal Dev",
      "Sunder Ali Khowaja",
      "Nawab Muhammad Faseeh Qureshi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11684"
  },
  {
    "id": "arXiv:2110.11694",
    "title": "Airport-Airline Coordination with Economic, Environmental and Social  Considerations",
    "abstract": "In this paper, we examine the effect of various contracts between a socially\nconcerned airport and an environmentally conscious airline regarding their\nprofitability and channel coordination under two distinct settings. First, we\nconsider no government interventions, while in the second, we explore\ngovernment-imposed taxations to curb emissions. Furthermore, we investigate the\nimpact of passenger greening sensitivity, greening cost, and consumer surplus\ncoefficient on conveyance fees, ticket fare, greening level and the channel\nwelfare. Our analysis shows that the revenue sharing and linear two part tariff\ncontracts coordinate the decentralised airport-airline channel. Our findings\nalso reveal that players greening and social efforts can improve both the\nwelfare and efficiency of the channel simultaneously. Importantly, under\ngovernment interventions, taxation does help improve the greening level of the\nchannel in both coordinating and non coordinating contracts. However, the\ngreening level in the non-coordinating contracts with taxation is still less\nthan the coordinating contracts even without tax. Finally, we also extended the\nmodel to include a duopoly airline market with pricing and greening\ncompetition. We analyze the effect of competetiton between airlines on airport\nutility, airline profit, ticket fare and greening level.",
    "descriptor": "",
    "authors": [
      "Aasheesh Dixit",
      "Patanjal Kumar",
      "Suresh Jakhar"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.11694"
  },
  {
    "id": "arXiv:2110.11706",
    "title": "The convergence analysis of an accelerated iteration for solving  algebraic Riccati equations",
    "abstract": "The discrete-time algebraic Riccati equation (DARE) have extensive\napplications in optimal control problems. We provide new theoretical supports\nto the stability properties of solutions to the DARE and reduce the convergence\nconditions under which the accelerated fixed-point iteration (AFPI) can be\napplied to compute the numerical solutions of DARE. In particular, we verify\nthat the convergence of AFPI is R-superlinear when the spectral radius of the\nclosed-loop matrix is greater than 1, which is shown by mild assumption and\nonly using primary matrix theories. Numerical examples are shown to illustrate\nthe consistency and effectiveness of our theoretical results.",
    "descriptor": "",
    "authors": [
      "Chun-Yueh Chiang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.11706"
  },
  {
    "id": "arXiv:2110.11721",
    "title": "Projection-Free Algorithm for Stochastic Bi-level Optimization",
    "abstract": "This work presents the first projection-free algorithm to solve stochastic\nbi-level optimization problems, where the objective function depends on the\nsolution of another stochastic optimization problem. The proposed\n$\\textbf{S}$tochastic $\\textbf{Bi}$-level $\\textbf{F}$rank-$\\textbf{W}$olfe\n($\\textbf{SBFW}$) algorithm can be applied to streaming settings and does not\nmake use of large batches or checkpoints. The sample complexity of SBFW is\nshown to be $\\mathcal{O}(\\epsilon^{-3})$ for convex objectives and\n$\\mathcal{O}(\\epsilon^{-4})$ for non-convex objectives. Improved rates are\nderived for the stochastic compositional problem, which is a special case of\nthe bi-level problem, and entails minimizing the composition of two\nexpected-value functions. The proposed $\\textbf{S}$tochastic\n$\\textbf{C}$ompositional $\\textbf{F}$rank-$\\textbf{W}$olfe ($\\textbf{SCFW}$) is\nshown to achieve a sample complexity of $\\mathcal{O}(\\epsilon^{-2})$ for convex\nobjectives and $\\mathcal{O}(\\epsilon^{-3})$ for non-convex objectives, at par\nwith the state-of-the-art sample complexities for projection-free algorithms\nsolving single-level problems. We demonstrate the advantage of the proposed\nmethods by solving the problem of matrix completion with denoising and the\nproblem of policy value evaluation in reinforcement learning.",
    "descriptor": "\nComments: 34 Pages\n",
    "authors": [
      "Zeeshan Akhtar",
      "Amrit Singh Bedi",
      "Srujan Teja Thomdapu",
      "Ketan Rajawat"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11721"
  },
  {
    "id": "arXiv:2110.11724",
    "title": "On the Connection Between Quantum Pseudorandomness and Quantum Hardware  Assumptions",
    "abstract": "This paper, for the first time, addresses the questions related to the\nconnections between the quantum pseudorandomness and quantum hardware\nassumptions, specifically quantum physical unclonable functions (qPUFs). Our\nresults show that the efficient pseudorandom quantum states (PRS) are\nsufficient to construct the challenge set for the universally unforgeable qPUF,\nimproving the previous existing constructions that are based on the Haar-random\nstates. We also show that both the qPUFs and the quantum pseudorandom unitaries\n(PRUs) can be constructed from each other, providing new ways to obtain PRS\nfrom the hardware assumptions. Moreover, we provide a sufficient condition (in\nterms of the diamond norm) that a set of unitaries should have to be a PRU in\norder to construct a universally unforgeable qPUF, giving yet another novel\ninsight into the properties of the PRUs. Later, as an application of our\nresults, we show that the efficiency of an existing qPUF-based client-server\nidentification protocol can be improved without losing the security\nrequirements of the protocol.",
    "descriptor": "\nComments: 31 pages, 3 figures\n",
    "authors": [
      "Mina Doosti",
      "Niraj Kumar",
      "Elham Kashefi",
      "Kaushik Chakraborty"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.11724"
  },
  {
    "id": "arXiv:2110.11738",
    "title": "A Fast and Accurate Splitting Method for Optimal Transport: Analysis and  Implementation",
    "abstract": "We develop a fast and reliable method for solving large-scale optimal\ntransport (OT) problems at an unprecedented combination of speed and accuracy.\nBuilt on the celebrated Douglas-Rachford splitting technique, our method\ntackles the original OT problem directly instead of solving an approximate\nregularized problem, as many state-of-the-art techniques do. This allows us to\nprovide sparse transport plans and avoid numerical issues of methods that use\nentropic regularization. The algorithm has the same cost per iteration as the\npopular Sinkhorn method, and each iteration can be executed efficiently, in\nparallel. The proposed method enjoys an iteration complexity $O(1/\\epsilon)$\ncompared to the best-known $O(1/\\epsilon^2)$ of the Sinkhorn method. In\naddition, we establish a linear convergence rate for our formulation of the OT\nproblem. We detail an efficient GPU implementation of the proposed method that\nmaintains a primal-dual stopping criterion at no extra cost. Substantial\nexperiments demonstrate the effectiveness of our method, both in terms of\ncomputation times and robustness.",
    "descriptor": "\nComments: 24 pages, 4 figures\n",
    "authors": [
      "Vien V. Mai",
      "Jacob Lindb\u00e4ck",
      "Mikael Johansson"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.11738"
  },
  {
    "id": "arXiv:2110.11749",
    "title": "The Equilibrium Hypothesis: Rethinking implicit regularization in Deep  Neural Networks",
    "abstract": "Modern Deep Neural Networks (DNNs) exhibit impressive generalization\nproperties on a variety of tasks without explicit regularization, suggesting\nthe existence of hidden regularization effects. Recent work by Baratin et al.\n(2021) sheds light on an intriguing implicit regularization effect, showing\nthat some layers are much more aligned with data labels than other layers. This\nsuggests that as the network grows in depth and width, an implicit layer\nselection phenomenon occurs during training. In this work, we provide the first\nexplanation for this alignment hierarchy. We introduce and empirically validate\nthe Equilibrium Hypothesis which states that the layers that achieve some\nbalance between forward and backward information loss are the ones with the\nhighest alignment to data labels. Our experiments demonstrate an excellent\nmatch with the theoretical predictions.",
    "descriptor": "",
    "authors": [
      "Yizhang Lou",
      "Chris Mingard",
      "Soufiane Hayou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11749"
  },
  {
    "id": "arXiv:2110.11751",
    "title": "Forecasting Financial Market Structure from Network Features using  Machine Learning",
    "abstract": "We propose a model that forecasts market correlation structure from link- and\nnode-based financial network features using machine learning. For such, market\nstructure is modeled as a dynamic asset network by quantifying time-dependent\nco-movement of asset price returns across company constituents of major global\nmarket indices. We provide empirical evidence using three different network\nfiltering methods to estimate market structure, namely Dynamic Asset Graph\n(DAG), Dynamic Minimal Spanning Tree (DMST) and Dynamic Threshold Networks\n(DTN). Experimental results show that the proposed model can forecast market\nstructure with high predictive performance with up to $40\\%$ improvement over a\ntime-invariant correlation-based benchmark. Non-pair-wise correlation features\nshowed to be important compared to traditionally used pair-wise correlation\nmeasures for all markets studied, particularly in the long-term forecasting of\nstock market structure. Evidence is provided for stock constituents of the\nDAX30, EUROSTOXX50, FTSE100, HANGSENG50, NASDAQ100 and NIFTY50 market indices.\nFindings can be useful to improve portfolio selection and risk management\nmethods, which commonly rely on a backward-looking covariance matrix to\nestimate portfolio risk.",
    "descriptor": "\nComments: 22 pages, 13 figures\n",
    "authors": [
      "Douglas Castilho",
      "Tharsis T. P. Souza",
      "Soong Moon Kang",
      "Jo\u00e3o Gama",
      "Andr\u00e9 C. P. L. F. de Carvalho"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Portfolio Management (q-fin.PM)"
    ],
    "url": "https://arxiv.org/abs/2110.11751"
  },
  {
    "id": "arXiv:2110.11760",
    "title": "Distributed Simulation And Visualization of The ALICE Detector Magnetic  Field",
    "abstract": "The ALICE detector at CERN uses properties of the magnetic field acting on\ncharged particles as part of the particle tracking and identification system --\nvia measuring the strength of bending of charged particles in a magnetic field\nsupplied by electromagnets. During the calibration of the detector the magnetic\nfield was measured by the scientific team. The measurement points were then\nfitted using Chebyshev polynomials to create a field model. That model is used\nextensively in particle trajectory reconstruction, but for maximum\ncompatibility it is handled by CPU-only software. We propose multiple\napproaches to the implementation of the model in a shader language, which\nallows it to run in a graphical GPU environment. This makes the model run more\nefficiently, as well as enables it to be used for field visualisation, which\nwas not previously done for ALICE.",
    "descriptor": "",
    "authors": [
      "Piotr Nowakowski",
      "Przemys\u0142aw Rokita",
      "\u0141ukasz Graczykowski"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.11760"
  },
  {
    "id": "arXiv:2110.11780",
    "title": "Reconstruction of Sentinel-2 Time Series Using Robust Gaussian Mixture  Models -- Application to the Detection of Anomalous Crop Development in wheat  and rapeseed crops",
    "abstract": "Missing data is a recurrent problem in remote sensing, mainly due to cloud\ncoverage for multispectral images and acquisition problems. This can be a\ncritical issue for crop monitoring, especially for applications relying on\nmachine learning techniques, which generally assume that the feature matrix\ndoes not have missing values. This paper proposes a Gaussian Mixture Model\n(GMM) for the reconstruction of parcel-level features extracted from\nmultispectral images. A robust version of the GMM is also investigated, since\ndatasets can be contaminated by inaccurate samples or features (e.g., wrong\ncrop type reported, inaccurate boundaries, undetected clouds, etc). Additional\nfeatures extracted from Synthetic Aperture Radar (SAR) images using Sentinel-1\ndata are also used to provide complementary information and improve the\nimputations. The robust GMM investigated in this work assigns reduced weights\nto the outliers during the estimation of the GMM parameters, which improves the\nfinal reconstruction. These weights are computed at each step of an\nExpectation-Maximization (EM) algorithm by using outlier scores provided by the\nisolation forest algorithm. Experimental validation is conducted on rapeseed\nand wheat parcels located in the Beauce region (France). Overall, we show that\nthe GMM imputation method outperforms other reconstruction strategies. A mean\nabsolute error (MAE) of 0.013 (resp. 0.019) is obtained for the imputation of\nthe median Normalized Difference Index (NDVI) of the rapeseed (resp. wheat)\nparcels. Other indicators (e.g., Normalized Difference Water Index) and\nstatistics (for instance the interquartile range, which captures heterogeneity\namong the parcel indicator) are reconstructed at the same time with good\naccuracy. In a dataset contaminated by irrelevant samples, using the robust GMM\nis recommended since the standard GMM imputation can lead to inaccurate imputed\nvalues.",
    "descriptor": "",
    "authors": [
      "Florian Mouret",
      "Mohanad Albughdadi",
      "Sylvie Duthoit",
      "Denis Kouam\u00e9",
      "Guillaume Rieu",
      "Jean-Yves Tourneret"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11780"
  },
  {
    "id": "arXiv:2110.11795",
    "title": "HDRVideo-GAN: Deep Generative HDR Video Reconstruction",
    "abstract": "High dynamic range (HDR) videos provide a more visually realistic experience\nthan the standard low dynamic range (LDR) videos. Despite having significant\nprogress in HDR imaging, it is still a challenging task to capture high-quality\nHDR video with a conventional off-the-shelf camera. Existing approaches rely\nentirely on using dense optical flow between the neighboring LDR sequences to\nreconstruct an HDR frame. However, they lead to inconsistencies in color and\nexposure over time when applied to alternating exposures with noisy frames. In\nthis paper, we propose an end-to-end GAN-based framework for HDR video\nreconstruction from LDR sequences with alternating exposures. We first extract\nclean LDR frames from noisy LDR video with alternating exposures with a\ndenoising network trained in a self-supervised setting. Using optical flow, we\nthen align the neighboring alternating-exposure frames to a reference frame and\nthen reconstruct high-quality HDR frames in a complete adversarial setting. To\nfurther improve the robustness and quality of generated frames, we incorporate\ntemporal stability-based regularization term along with content and style-based\nlosses in the cost function during the training procedure. Experimental results\ndemonstrate that our framework achieves state-of-the-art performance and\ngenerates superior quality HDR frames of a video over the existing methods.",
    "descriptor": "",
    "authors": [
      "Mrinal Anand",
      "Nidhin Harilal",
      "Chandan Kumar",
      "Shanmuganathan Raman"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11795"
  },
  {
    "id": "arXiv:2110.11802",
    "title": "Deep Convolutional Autoencoders as Generic Feature Extractors in  Seismological Applications",
    "abstract": "The idea of using a deep autoencoder to encode seismic waveform features and\nthen use them in different seismological applications is appealing. In this\npaper, we designed tests to evaluate this idea of using autoencoders as feature\nextractors for different seismological applications, such as event\ndiscrimination (i.e., earthquake vs. noise waveforms, earthquake vs. explosion\nwaveforms, and phase picking). These tests involve training an autoencoder,\neither undercomplete or overcomplete, on a large amount of earthquake\nwaveforms, and then using the trained encoder as a feature extractor with\nsubsequent application layers (either a fully connected layer, or a\nconvolutional layer plus a fully connected layer) to make the decision. By\ncomparing the performance of these newly designed models against the baseline\nmodels trained from scratch, we conclude that the autoencoder feature extractor\napproach may only perform well under certain conditions such as when the target\nproblems require features to be similar to the autoencoder encoded features,\nwhen a relatively small amount of training data is available, and when certain\nmodel structures and training strategies are utilized. The model structure that\nworks best in all these tests is an overcomplete autoencoder with a\nconvolutional layer and a fully connected layer to make the estimation.",
    "descriptor": "",
    "authors": [
      "Qingkai Kong",
      "Andrea Chiang",
      "Ana C. Aguiar",
      "M. Giselle Fern\u00e1ndez-Godino",
      "Stephen C. Myers",
      "Donald D. Lucas"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11802"
  },
  {
    "id": "arXiv:2110.11804",
    "title": "Probabilistic fine-tuning of pruning masks and PAC-Bayes self-bounded  learning",
    "abstract": "We study an approach to learning pruning masks by optimizing the expected\nloss of stochastic pruning masks, i.e., masks which zero out each weight\nindependently with some weight-specific probability. We analyze the training\ndynamics of the induced stochastic predictor in the setting of linear\nregression, and observe a data-adaptive L1 regularization term, in contrast to\nthe dataadaptive L2 regularization term known to underlie dropout in linear\nregression. We also observe a preference to prune weights that are less\nwell-aligned with the data labels. We evaluate probabilistic fine-tuning for\noptimizing stochastic pruning masks for neural networks, starting from masks\nproduced by several baselines. In each case, we see improvements in test error\nover baselines, even after we threshold fine-tuned stochastic pruning masks.\nFinally, since a stochastic pruning mask induces a stochastic neural network,\nwe consider training the weights and/or pruning probabilities simultaneously to\nminimize a PAC-Bayes bound on generalization error. Using data-dependent\npriors, we obtain a selfbounded learning algorithm with strong performance and\nnumerically tight bounds. In the linear model, we show that a PAC-Bayes\ngeneralization error bound is controlled by the magnitude of the change in\nfeature alignment between the 'prior' and 'posterior' data.",
    "descriptor": "\nComments: 34 pages, 10 figures\n",
    "authors": [
      "Soufiane Hayou",
      "Bobby He",
      "Gintare Karolina Dziugaite"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11804"
  },
  {
    "id": "arXiv:2110.11812",
    "title": "Probabilistic ODE Solutions in Millions of Dimensions",
    "abstract": "Probabilistic solvers for ordinary differential equations (ODEs) have emerged\nas an efficient framework for uncertainty quantification and inference on\ndynamical systems. In this work, we explain the mathematical assumptions and\ndetailed implementation schemes behind solving {high-dimensional} ODEs with a\nprobabilistic numerical algorithm. This has not been possible before due to\nmatrix-matrix operations in each solver step, but is crucial for scientifically\nrelevant problems -- most importantly, the solution of discretised {partial}\ndifferential equations. In a nutshell, efficient high-dimensional probabilistic\nODE solutions build either on independence assumptions or on Kronecker\nstructure in the prior model. We evaluate the resulting efficiency on a range\nof problems, including the probabilistic numerical simulation of a differential\nequation with millions of dimensions.",
    "descriptor": "",
    "authors": [
      "Nicholas Kr\u00e4mer",
      "Nathanael Bosch",
      "Jonathan Schmidt",
      "Philipp Hennig"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.11812"
  },
  {
    "id": "arXiv:2110.11848",
    "title": "Clustering Market Regimes using the Wasserstein Distance",
    "abstract": "The problem of rapid and automated detection of distinct market regimes is a\ntopic of great interest to financial mathematicians and practitioners alike. In\nthis paper, we outline an unsupervised learning algorithm for clustering\nfinancial time-series into a suitable number of temporal segments (market\nregimes). As a special case of the above, we develop a robust algorithm that\nautomates the process of classifying market regimes. The method is robust in\nthe sense that it does not depend on modelling assumptions of the underlying\ntime series as our experiments with real datasets show. This method -- dubbed\nthe Wasserstein $k$-means algorithm -- frames such a problem as one on the\nspace of probability measures with finite $p^\\text{th}$ moment, in terms of the\n$p$-Wasserstein distance between (empirical) distributions. We compare our\nWK-means approach with a more traditional clustering algorithms by studying the\nso-called maximum mean discrepancy scores between, and within clusters. In both\ncases it is shown that the WK-means algorithm vastly outperforms all considered\ncompetitor approaches. We demonstrate the performance of all approaches both in\na controlled environment on synthetic data, and on real data.",
    "descriptor": "\nComments: 37 pages, 40 figures\n",
    "authors": [
      "Blanka Horvath",
      "Zacharia Issa",
      "Aitor Muguruza"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)",
      "Mathematical Finance (q-fin.MF)"
    ],
    "url": "https://arxiv.org/abs/2110.11848"
  },
  {
    "id": "arXiv:2110.11854",
    "title": "Using scientific machine learning for experimental bifurcation analysis  of dynamic systems",
    "abstract": "Augmenting mechanistic ordinary differential equation (ODE) models with\nmachine-learnable structures is an novel approach to create highly accurate,\nlow-dimensional models of engineering systems incorporating both expert\nknowledge and reality through measurement data. Our exploratory study focuses\non training universal differential equation (UDE) models for physical nonlinear\ndynamical systems with limit cycles: an aerofoil undergoing flutter\noscillations and an electrodynamic nonlinear oscillator. We consider examples\nwhere training data is generated by numerical simulations, whereas we also\nemploy the proposed modelling concept to physical experiments allowing us to\ninvestigate problems with a wide range of complexity. To collect the training\ndata, the method of control-based continuation is used as it captures not just\nthe stable but also the unstable limit cycles of the observed system. This\nfeature makes it possible to extract more information about the observed system\nthan the standard, open-loop approach would allow. We use both neural networks\nand Gaussian processes as universal approximators alongside the mechanistic\nmodels to give a critical assessment of the accuracy and robustness of the UDE\nmodelling approach. We also highlight the potential issues one may run into\nduring the training procedure indicating the limits of the current modelling\nframework.",
    "descriptor": "\nComments: 16 pages, 15 figures\n",
    "authors": [
      "Sandor Beregi",
      "David A. W. Barton",
      "Djamel Rezgui",
      "Simon A. Neild"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11854"
  },
  {
    "id": "arXiv:2110.11856",
    "title": "L-2 Regularized maximum likelihood for $\u03b2$-model in large and sparse  networks",
    "abstract": "The $\\beta$-model is a powerful tool for modeling network generation driven\nby node degree heterogeneity. Its simple yet expressive nature particularly\nwell-suits large and sparse networks, where many network models become\ninfeasible due to computational challenge and observation scarcity. However,\nexisting estimation algorithms for $\\beta$-model do not scale up; and\ntheoretical understandings remain limited to dense networks. This paper brings\nseveral major improvements to the method and theory of $\\beta$-model to address\nurgent needs of practical applications. Our contributions include: 1. method:\nwe propose a new $\\ell_2$ penalized MLE scheme; we design a novel algorithm\nthat can comfortably handle sparse networks of millions of nodes, much faster\nand more memory-parsimonious than any existing algorithm; 2. theory: we present\nnew error bounds on beta-models under much weaker assumptions; we also\nestablish new lower-bounds and new asymptotic normality results; distinct from\nexisting literature, our results cover both small and large regularization\nscenarios and reveal their distinct asymptotic dependency structures; 3.\napplication: we apply our method to large COVID-19 network data sets and\ndiscover meaningful results.",
    "descriptor": "",
    "authors": [
      "Yu Zhang",
      "Qiuping Wang",
      "Yuan Zhang",
      "Ting Yan",
      "Jing Luo"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Social and Information Networks (cs.SI)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.11856"
  },
  {
    "id": "arXiv:2110.11858",
    "title": "A strong version of Cobham's theorem",
    "abstract": "Let $k,\\ell\\geq 2$ be two multiplicatively independent integers. Cobham's\nfamous theorem states that a set $X\\subseteq \\mathbb{N}$ is both\n$k$-recognizable and $\\ell$-recognizable if and only if it is definable in\nPresburger arithmetic. Here we show the following strengthening: let\n$X\\subseteq \\mathbb{N}^m$ be $k$-recognizable, let $Y\\subseteq \\mathbb{N}^m$ be\n$\\ell$-recognizable such that both $X$ and $Y$ are not definable in Presburger\narithmetic. Then the first-order logical theory of $(\\mathbb{N},+,X,Y)$ is\nundecidable. This is in contrast to a well-known theorem of B\\\"uchi that the\nfirst-order logical theory of $(\\mathbb{N},+,X)$ is decidable.",
    "descriptor": "",
    "authors": [
      "Philipp Hieronymi",
      "Christian Schulz"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.11858"
  },
  {
    "id": "arXiv:2110.11923",
    "title": "Climbing the Diagonal Clifford Hierarchy",
    "abstract": "Magic state distillation and the Shor factoring algorithm make essential use\nof logical diagonal gates. We introduce a method of synthesizing CSS codes that\nrealize a target logical diagonal gate at some level $l$ in the Clifford\nhierarchy. The method combines three basic operations: concatenation, removal\nof $Z$-stabilizers, and addition of $X$-stabilizers. It explicitly tracks the\nlogical gate induced by a diagonal physical gate that preserves a CSS code. The\nfirst step is concatenation, where the input is a CSS code and a physical\ndiagonal gate at level $l$ inducing a logical diagonal gate at the same level.\nThe output is a new code for which a physical diagonal gate at level $l+1$\ninduces the original logical gate. The next step is judicious removal of\n$Z$-stabilizers to increase the level of the induced logical operator. We\nidentify three ways of climbing the logical Clifford hierarchy from level $l$\nto level $l+1$, each built on a recursive relation on the Pauli coefficients of\nthe induced logical operators. Removal of $Z$-stabilizers may reduce distance,\nand the purpose of the third basic operation, addition of $X$-stabilizers, is\nto compensate for such losses. For the coherent noise model, we apply this\napproach to describe a simple switch between computation and storage of\nintermediate results in a decoherence-free subspace. The approach taken in\nprior work focuses on the code states, and results in sufficient conditions for\na CSS code to be fixed by a transversal $Z$-rotation. In contrast, we derive\nnecessary and sufficient conditions by analyzing the action of a transversal\ndiagonal gate on the stabilizer group that determines the code. The power of\nour approach to logical gate synthesis is demonstrated by two proofs of\nconcept: the $[[2^{l+1}-2,2,2]]$ triorthogonal code family, and the\n$[[2^m,\\binom{m}{r},2^{\\min\\{r,m-r\\}}]]$ quantum Reed-Muller code family.",
    "descriptor": "\nComments: Jingzhen Hu and Qingzhong Liang contribute equally to this work. 15 pages, two columns, 8 figures, and 1 table. Comments welcome! arXiv admin note: text overlap with arXiv:2109.13481\n",
    "authors": [
      "Jingzhen Hu",
      "Qingzhong Liang",
      "Robert Calderbank"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.11923"
  },
  {
    "id": "arXiv:2110.11925",
    "title": "A Path-based Approach to Analyzing the Global Liner Shipping Network",
    "abstract": "The maritime shipping network is the backbone of global trade. Data about the\nmovement of cargo through this network comes in various forms, from ship-level\nAutomatic Identification System (AIS) data, to aggregated bilateral trade\nvolume statistics. Multiple network representations of the shipping system can\nbe derived from any one data source, each of which has advantages and\ndisadvantages. In this work, we examine data in the form of liner shipping\nservice routes, a list of walks through the port-to-port network aggregated\nfrom individual shipping companies by a large shipping logistics database. This\ndata is inherently sequential, in that each route represents a sequence of\nports called upon by a cargo ship. Previous work has analyzed this data without\ntaking full advantage of the sequential information. Our contribution is to\ndevelop a path-based methodology for analyzing liner shipping service route\ndata, computing navigational trajectories through the network that respect the\nroutes and comparing these paths with those computed using other network\nrepresentations of the same data. We further use these trajectories to\nre-analyze the role of a previously-identified structural core through the\nnetwork, as well as to define and analyze a measure of betweenness centrality\nfor nodes and edges.",
    "descriptor": "\nComments: 32 pages, 11 figures\n",
    "authors": [
      "Timothy LaRock",
      "Mengqiao Xu",
      "Tina Eliassi-Rad"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.11925"
  },
  {
    "id": "arXiv:2110.11943",
    "title": "Solving N-player dynamic routing games with congestion: a mean field  approach",
    "abstract": "The recent emergence of navigational tools has changed traffic patterns and\nhas now enabled new types of congestion-aware routing control like dynamic road\npricing. Using the fundamental diagram of traffic flows - applied in\nmacroscopic and mesoscopic traffic modeling - the article introduces a new\nN-player dynamic routing game with explicit congestion dynamics. The model is\nwell-posed and can reproduce heterogeneous departure times and congestion spill\nback phenomena. However, as Nash equilibrium computations are PPAD-complete,\nsolving the game becomes intractable for large but realistic numbers of\nvehicles N. Therefore, the corresponding mean field game is also introduced.\nExperiments were performed on several classical benchmark networks of the\ntraffic community: the Pigou, Braess, and Sioux Falls networks with\nheterogeneous origin, destination and departure time tuples. The Pigou and the\nBraess examples reveal that the mean field approximation is generally very\naccurate and computationally efficient as soon as the number of vehicles\nexceeds a few dozen. On the Sioux Falls network (76 links, 100 time steps),\nthis approach enables learning traffic dynamics with more than 14,000 vehicles.",
    "descriptor": "",
    "authors": [
      "Theophile Cabannes",
      "Mathieu Lauriere",
      "Julien Perolat",
      "Raphael Marinier",
      "Sertan Girgin",
      "Sarah Perrin",
      "Olivier Pietquin",
      "Alexandre M. Bayen",
      "Eric Goubault",
      "Romuald Elie"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.11943"
  },
  {
    "id": "arXiv:2110.11952",
    "title": "Optimal randomized classification trees",
    "abstract": "Classification and Regression Trees (CARTs) are off-the-shelf techniques in\nmodern Statistics and Machine Learning. CARTs are traditionally built by means\nof a greedy procedure, sequentially deciding the splitting predictor\nvariable(s) and the associated threshold. This greedy approach trains trees\nvery fast, but, by its nature, their classification accuracy may not be\ncompetitive against other state-of-the-art procedures. Moreover, controlling\ncritical issues, such as the misclassification rates in each of the classes, is\ndifficult. To address these shortcomings, optimal decision trees have been\nrecently proposed in the literature, which use discrete decision variables to\nmodel the path each observation will follow in the tree. Instead, we propose a\nnew approach based on continuous optimization. Our classifier can be seen as a\nrandomized tree, since at each node of the decision tree a random decision is\nmade. The computational experience reported demonstrates the good performance\nof our procedure.",
    "descriptor": "\nComments: This research has been financed in part by research projects EC H2020 MSCA RISE NeEDS (Grant agreement ID: 822214), FQM-329 and P18-FR-2369 (Junta de Andaluc\\'ia), and PID2019-110886RB-I00 (Ministerio de Ciencia, Innovaci\\'on y Universidades, Spain). This support is gratefully acknowledged\n",
    "authors": [
      "Rafael Blanquero",
      "Emilio Carrizosa",
      "Cristina Molero-R\u00edo",
      "Dolores Romero Morales"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.11952"
  },
  {
    "id": "arXiv:1207.2602",
    "title": "A Novel Approach Coloured Object Tracker with Adaptive Model and  Bandwidth using Mean Shift Algorithm",
    "abstract": "Comments: conflict of interest with co-author",
    "descriptor": "\nComments: conflict of interest with co-author\n",
    "authors": [
      "Seyed Amir Mohammadi",
      "Mohammad Reza Mahzoun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1207.2602"
  },
  {
    "id": "arXiv:1805.01310",
    "title": "Efficiently Enumerating Hitting Sets of Hypergraphs Arising in Data  Profiling",
    "abstract": "Comments: 48 pages, 8 PDF figures; completely rewritten, new fine-grained lower bounds; accepted at JCSS",
    "descriptor": "\nComments: 48 pages, 8 PDF figures; completely rewritten, new fine-grained lower bounds; accepted at JCSS\n",
    "authors": [
      "Thomas Bl\u00e4sius",
      "Tobias Friedrich",
      "Julius Lischeid",
      "Kitty Meeks",
      "Martin Schirneck"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/1805.01310"
  },
  {
    "id": "arXiv:1808.02247",
    "title": "Extending some results on the second neighborhood conjecture",
    "abstract": "Comments: 23 pages, 2 figures",
    "descriptor": "\nComments: 23 pages, 2 figures\n",
    "authors": [
      "Suresh Dara",
      "Mathew C. Francis",
      "Dalu Jacob",
      "N. Narayanan"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/1808.02247"
  },
  {
    "id": "arXiv:1902.01048",
    "title": "Average cost optimal control under weak ergodicity hypotheses: Relative  value iterations",
    "abstract": "Comments: 32 pages",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Ari Arapostathis",
      "Vivek S. Borkar"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1902.01048"
  },
  {
    "id": "arXiv:1904.10230",
    "title": "A Large RGB-D Dataset for Semi-supervised Monocular Depth Estimation",
    "abstract": "Comments: this https URL",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Jaehoon Cho",
      "Dongbo Min",
      "Youngjung Kim",
      "Kwanghoon Sohn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1904.10230"
  },
  {
    "id": "arXiv:1905.05254",
    "title": "Optimal Multithreaded Batch-Parallel 2-3 Trees",
    "abstract": "Optimal Multithreaded Batch-Parallel 2-3 Trees",
    "descriptor": "",
    "authors": [
      "Wei Quan Lim"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/1905.05254"
  },
  {
    "id": "arXiv:1912.10122",
    "title": "A Region-based Randers Geodesic Approach for Image Segmentation",
    "abstract": "A Region-based Randers Geodesic Approach for Image Segmentation",
    "descriptor": "",
    "authors": [
      "Da Chen",
      "Jean-Marie Mirebeau",
      "Huazhong Shu",
      "Laurent D. Cohen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/1912.10122"
  },
  {
    "id": "arXiv:2003.04315",
    "title": "LIMEADE: A General Framework for Explanation-Based Human Tuning of  Opaque Machine Learners",
    "abstract": "Comments: 16 pages, 7 figures",
    "descriptor": "\nComments: 16 pages, 7 figures\n",
    "authors": [
      "Benjamin Charles Germain Lee",
      "Doug Downey",
      "Kyle Lo",
      "Daniel S. Weld"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.04315"
  },
  {
    "id": "arXiv:2004.03686",
    "title": "Exemplar Fine-Tuning for 3D Human Model Fitting Towards In-the-Wild 3D  Human Pose Estimation",
    "abstract": "Exemplar Fine-Tuning for 3D Human Model Fitting Towards In-the-Wild 3D  Human Pose Estimation",
    "descriptor": "",
    "authors": [
      "Hanbyul Joo",
      "Natalia Neverova",
      "Andrea Vedaldi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2004.03686"
  },
  {
    "id": "arXiv:2004.03808",
    "title": "Improving BERT with Self-Supervised Attention",
    "abstract": "Improving BERT with Self-Supervised Attention",
    "descriptor": "",
    "authors": [
      "Yiren Chen",
      "Xiaoyu Kou",
      "Jiangang Bai",
      "Yunhai Tong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2004.03808"
  },
  {
    "id": "arXiv:2004.06278",
    "title": "Squares: A Fast Counter-Based RNG",
    "abstract": "Comments: A software package with example programs is available at this http URL",
    "descriptor": "\nComments: A software package with example programs is available at this http URL\n",
    "authors": [
      "Bernard Widynski"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2004.06278"
  },
  {
    "id": "arXiv:2004.08298",
    "title": "IDDA: a large-scale multi-domain dataset for autonomous driving",
    "abstract": "Comments: Accepted at IROS 2020 and RA-L. Download at: this https URL",
    "descriptor": "\nComments: Accepted at IROS 2020 and RA-L. Download at: this https URL\n",
    "authors": [
      "Emanuele Alberti",
      "Antonio Tavera",
      "Carlo Masone",
      "Barbara Caputo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2004.08298"
  },
  {
    "id": "arXiv:2005.13985",
    "title": "Mass Estimation of Galaxy Clusters with Deep Learning II: CMB Cluster  Lensing",
    "abstract": "Comments: 11 pages, 6 figures",
    "descriptor": "\nComments: 11 pages, 6 figures\n",
    "authors": [
      "N. Gupta",
      "C. L. Reichardt"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Machine Learning (cs.LG)",
      "General Relativity and Quantum Cosmology (gr-qc)"
    ],
    "url": "https://arxiv.org/abs/2005.13985"
  },
  {
    "id": "arXiv:2006.03372",
    "title": "Scaling Up Distance-generalized Core Decomposition",
    "abstract": "Scaling Up Distance-generalized Core Decomposition",
    "descriptor": "",
    "authors": [
      "Qiangqiang Dai",
      "Rong-Hua Li",
      "Lu Qin",
      "Guoren Wang",
      "Weihua Yang",
      "Zhiwei Zhang",
      "Ye Yuan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2006.03372"
  },
  {
    "id": "arXiv:2006.05033",
    "title": "Hardware Implementation of Spiking Neural Networks Using  Time-To-First-Spike Encoding",
    "abstract": "Hardware Implementation of Spiking Neural Networks Using  Time-To-First-Spike Encoding",
    "descriptor": "",
    "authors": [
      "Seongbin Oh",
      "Dongseok Kwon",
      "Gyuho Yeom",
      "Won-Mook Kang",
      "Soochang Lee",
      "Sung Yun Woo",
      "Jang Saeng Kim",
      "Min Kyu Park",
      "Jong-Ho Lee"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2006.05033"
  },
  {
    "id": "arXiv:2006.10858",
    "title": "Rehabilitating Isomap: Euclidean Representation of Geodesic Structure",
    "abstract": "Comments: 27 pages, 4 figures",
    "descriptor": "\nComments: 27 pages, 4 figures\n",
    "authors": [
      "Michael W. Trosset",
      "Gokcen Buyukbas"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.10858"
  },
  {
    "id": "arXiv:2006.15138",
    "title": "Distributed Uplink Beamforming in Cell-Free Networks Using Deep  Reinforcement Learning",
    "abstract": "Distributed Uplink Beamforming in Cell-Free Networks Using Deep  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Firas Fredj",
      "Yasser Al-Eryani",
      "Setareh Maghsudi",
      "Mohamed Akrout",
      "Ekram Hossain"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.15138"
  },
  {
    "id": "arXiv:2006.15304",
    "title": "A Retinex based GAN Pipeline to Utilize Paired and Unpaired Datasets for  Enhancing Low Light Images",
    "abstract": "A Retinex based GAN Pipeline to Utilize Paired and Unpaired Datasets for  Enhancing Low Light Images",
    "descriptor": "",
    "authors": [
      "Harshana Weligampola",
      "Gihan Jayatilaka",
      "Suren Sritharan",
      "Roshan Godaliyadda",
      "Parakrama Ekanayaka",
      "Roshan Ragel",
      "Vijitha Herath"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2006.15304"
  },
  {
    "id": "arXiv:2007.00323",
    "title": "Future Urban Scenes Generation Through Vehicles Synthesis",
    "abstract": "Comments: Accepted at ICPR2020",
    "descriptor": "\nComments: Accepted at ICPR2020\n",
    "authors": [
      "Alessandro Simoni",
      "Luca Bergamini",
      "Andrea Palazzi",
      "Simone Calderara",
      "Rita Cucchiara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2007.00323"
  },
  {
    "id": "arXiv:2007.00514",
    "title": "Regularized Online Allocation Problems: Fairness and Beyond",
    "abstract": "Regularized Online Allocation Problems: Fairness and Beyond",
    "descriptor": "",
    "authors": [
      "Santiago Balseiro",
      "Haihao Lu",
      "Vahab Mirrokni"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.00514"
  },
  {
    "id": "arXiv:2007.07767",
    "title": "Bi-objective facility location in the presence of uncertainty",
    "abstract": "Bi-objective facility location in the presence of uncertainty",
    "descriptor": "",
    "authors": [
      "Najmesadat Nazemi",
      "Sophie N. Parragh",
      "Walter J. Gutjahr"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2007.07767"
  },
  {
    "id": "arXiv:2007.10770",
    "title": "Compositional equivalences based on Open pNets",
    "abstract": "Compositional equivalences based on Open pNets",
    "descriptor": "",
    "authors": [
      "Rab\u00e9a Ameur-Boulifa",
      "Ludovic Henrio",
      "Eric Madelaine"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2007.10770"
  },
  {
    "id": "arXiv:2007.13261",
    "title": "From climate change to pandemics: decision science can help scientists  have impact",
    "abstract": "From climate change to pandemics: decision science can help scientists  have impact",
    "descriptor": "",
    "authors": [
      "Christopher M. Baker",
      "Patricia T. Campbell",
      "Iadine Chades",
      "Angela J. Dean",
      "Susan M. Hester",
      "Matthew H. Holden",
      "James M. McCaw",
      "Jodie McVernon",
      "Robert Moss",
      "Freya M. Shearer",
      "Hugh P. Possingham"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2007.13261"
  },
  {
    "id": "arXiv:2008.02104",
    "title": "Stabilization of Complementarity Systems via Contact-Aware Controllers",
    "abstract": "Comments: The final preprint, accepted to T-RO. arXiv admin note: text overlap with arXiv:1909.11221",
    "descriptor": "\nComments: The final preprint, accepted to T-RO. arXiv admin note: text overlap with arXiv:1909.11221\n",
    "authors": [
      "Alp Aydinoglu",
      "Philip Sieg",
      "Victor M. Preciado",
      "Michael Posa"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2008.02104"
  },
  {
    "id": "arXiv:2010.03106",
    "title": "Structured Logconcave Sampling with a Restricted Gaussian Oracle",
    "abstract": "Comments: 58 pages. The results of Section 5 of this paper, as well as an empirical evaluation, appeared earlier as arXiv:2006.05976. This version fixes an error in the proof of Theorem 1, see Section 1.4",
    "descriptor": "\nComments: 58 pages. The results of Section 5 of this paper, as well as an empirical evaluation, appeared earlier as arXiv:2006.05976. This version fixes an error in the proof of Theorem 1, see Section 1.4\n",
    "authors": [
      "Yin Tat Lee",
      "Ruoqi Shen",
      "Kevin Tian"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.03106"
  },
  {
    "id": "arXiv:2010.06909",
    "title": "A Note on the Stochastic Ruler Method for Discrete Simulation  Optimization",
    "abstract": "A Note on the Stochastic Ruler Method for Discrete Simulation  Optimization",
    "descriptor": "",
    "authors": [
      "Varun Ramamohan",
      "Utkarsh Agrawal",
      "Mohit Goyal"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2010.06909"
  },
  {
    "id": "arXiv:2010.07027",
    "title": "A Light Heterogeneous Graph Collaborative Filtering Model using Textual  Information",
    "abstract": "Comments: Accepted by Knowledge-Based Systems",
    "descriptor": "\nComments: Accepted by Knowledge-Based Systems\n",
    "authors": [
      "Chaoyang Wang",
      "Zhiqiang Guo",
      "Guohui Li",
      "Jianjun Li",
      "Peng Pan",
      "Ke Liu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.07027"
  },
  {
    "id": "arXiv:2010.11289",
    "title": "Shedding Light on Blind Spots: Developing a Reference Architecture to  Leverage Video Data for Process Mining",
    "abstract": "Shedding Light on Blind Spots: Developing a Reference Architecture to  Leverage Video Data for Process Mining",
    "descriptor": "",
    "authors": [
      "Wolfgang Kratsch",
      "Fabian Koenig",
      "Maximilian Roeglinger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.11289"
  },
  {
    "id": "arXiv:2011.00580",
    "title": "Sparsity-Control Ternary Weight Networks",
    "abstract": "Comments: version 1 of SCA; accepted by journal \"Neural Networks\"; the final version could be a little different from this version",
    "descriptor": "\nComments: version 1 of SCA; accepted by journal \"Neural Networks\"; the final version could be a little different from this version\n",
    "authors": [
      "Xiang Deng",
      "Zhongfei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.00580"
  },
  {
    "id": "arXiv:2011.05957",
    "title": "Counting Homomorphic Cycles in Degenerate Graphs",
    "abstract": "Counting Homomorphic Cycles in Degenerate Graphs",
    "descriptor": "",
    "authors": [
      "Lior Gishboliner",
      "Yevgeny Levanzov",
      "Asaf Shapira",
      "Raphael Yuster"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2011.05957"
  },
  {
    "id": "arXiv:2011.06748",
    "title": "Safe and Robust Motion Planning for Dynamic Robotics via Control Barrier  Functions",
    "abstract": "Comments: 7 pages, 4 figures, accepted for presentation in 60th Conference on Decision and Control (CDC2021)",
    "descriptor": "\nComments: 7 pages, 4 figures, accepted for presentation in 60th Conference on Decision and Control (CDC2021)\n",
    "authors": [
      "Aniketh Manjunath",
      "Quan Nguyen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2011.06748"
  },
  {
    "id": "arXiv:2011.08545",
    "title": "Dynamic Hard Pruning of Neural Networks at the Edge of the Internet",
    "abstract": "Dynamic Hard Pruning of Neural Networks at the Edge of the Internet",
    "descriptor": "",
    "authors": [
      "Lorenzo Valerio",
      "Franco Maria Nardini",
      "Andrea Passarella",
      "Raffaele Perego"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.08545"
  },
  {
    "id": "arXiv:2011.09697",
    "title": "Deep Motion Blind Video Stabilization",
    "abstract": "Deep Motion Blind Video Stabilization",
    "descriptor": "",
    "authors": [
      "Muhammad Kashif Ali",
      "Sangjoon Yu",
      "Tae Hyun Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.09697"
  },
  {
    "id": "arXiv:2011.11953",
    "title": "DomainMix: Learning Generalizable Person Re-Identification Without Human  Annotations",
    "abstract": "Comments: Accepted to BMVC 2021",
    "descriptor": "\nComments: Accepted to BMVC 2021\n",
    "authors": [
      "Wenhao Wang",
      "Shengcai Liao",
      "Fang Zhao",
      "Cuicui Kang",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.11953"
  },
  {
    "id": "arXiv:2011.14543",
    "title": "Exponential Stability and Tuning for a Class of Mechanical Systems",
    "abstract": "Comments: ECC 2021- Accepted version with minor changes. Fixed a minor gramatic typo in experiments section",
    "descriptor": "\nComments: ECC 2021- Accepted version with minor changes. Fixed a minor gramatic typo in experiments section\n",
    "authors": [
      "Carmen Chan-Zheng",
      "Pablo Borja",
      "Nima Monshizadeh",
      "Jacquelien M.A. Scherpen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2011.14543"
  },
  {
    "id": "arXiv:2012.02679",
    "title": "What is a meaningful representation of protein sequences?",
    "abstract": "Comments: 17 pages, 8 figures, 2 tables",
    "descriptor": "\nComments: 17 pages, 8 figures, 2 tables\n",
    "authors": [
      "Nicki Skafte Detlefsen",
      "S\u00f8ren Hauberg",
      "Wouter Boomsma"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2012.02679"
  },
  {
    "id": "arXiv:2012.03790",
    "title": "Matching Distributions via Optimal Transport for Semi-Supervised  Learning",
    "abstract": "Matching Distributions via Optimal Transport for Semi-Supervised  Learning",
    "descriptor": "",
    "authors": [
      "Fariborz Taherkhani",
      "Hadi Kazemi",
      "Ali Dabouei",
      "Jeremy Dawson",
      "Nasser M. Nasrabadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.03790"
  },
  {
    "id": "arXiv:2012.13477",
    "title": "A Kernel-Independent Sum-of-Exponentials Method",
    "abstract": "Comments: 32 pages, 3 figures, 6 tables; Related VPMR code released at this https URL",
    "descriptor": "\nComments: 32 pages, 3 figures, 6 tables; Related VPMR code released at this https URL\n",
    "authors": [
      "Zixuan Gao",
      "Jiuyang Liang",
      "Zhenli Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2012.13477"
  },
  {
    "id": "arXiv:2012.14906",
    "title": "Synthesizing Decentralized Controllers with Graph Neural Networks and  Imitation Learning",
    "abstract": "Synthesizing Decentralized Controllers with Graph Neural Networks and  Imitation Learning",
    "descriptor": "",
    "authors": [
      "Fernando Gama",
      "Qingbiao Li",
      "Ekaterina Tolstaya",
      "Amanda Prorok",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2012.14906"
  },
  {
    "id": "arXiv:2101.01881",
    "title": "MSD: Saliency-aware Knowledge Distillation for Multimodal Understanding",
    "abstract": "Comments: Accepted to EMNLP 2021 Findings",
    "descriptor": "\nComments: Accepted to EMNLP 2021 Findings\n",
    "authors": [
      "Woojeong Jin",
      "Maziar Sanjabi",
      "Shaoliang Nie",
      "Liang Tan",
      "Xiang Ren",
      "Hamed Firooz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.01881"
  },
  {
    "id": "arXiv:2101.10027",
    "title": "Understanding and Achieving Efficient Robustness with Adversarial  Supervised Contrastive Learning",
    "abstract": "Understanding and Achieving Efficient Robustness with Adversarial  Supervised Contrastive Learning",
    "descriptor": "",
    "authors": [
      "Anh Bui",
      "Trung Le",
      "He Zhao",
      "Paul Montague",
      "Seyit Camtepe",
      "Dinh Phung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.10027"
  },
  {
    "id": "arXiv:2102.03313",
    "title": "Rethinking Neural Networks With Benford's Law",
    "abstract": "Comments: Short version accepted to NeurIPS 2021 ML4PS Workshop",
    "descriptor": "\nComments: Short version accepted to NeurIPS 2021 ML4PS Workshop\n",
    "authors": [
      "Surya Kant Sahu",
      "Abhinav Java",
      "Arshad Shaikh",
      "Yannic Kilcher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.03313"
  },
  {
    "id": "arXiv:2102.03509",
    "title": "Robust normalizing flows using Bernstein-type polynomials",
    "abstract": "Robust normalizing flows using Bernstein-type polynomials",
    "descriptor": "",
    "authors": [
      "Sameera Ramasinghe",
      "Kasun Fernando",
      "Salman Khan",
      "Nick Barnes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.03509"
  },
  {
    "id": "arXiv:2102.03824",
    "title": "Neural Termination Analysis",
    "abstract": "Neural Termination Analysis",
    "descriptor": "",
    "authors": [
      "Mirco Giacobbe",
      "Daniel Kroening",
      "Julian Parsert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2102.03824"
  },
  {
    "id": "arXiv:2102.03868",
    "title": "U-vectors: Generating clusterable speaker embedding from unlabeled data",
    "abstract": "Comments: 18 pages, 7 figures",
    "descriptor": "\nComments: 18 pages, 7 figures\n",
    "authors": [
      "M. F. Mridha",
      "Abu Quwsar Ohi",
      "Muhammad Mostafa Monowar",
      "Md. Abdul Hamid",
      "Md. Rashedul Islam",
      "Yutaka Watanobe"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2102.03868"
  },
  {
    "id": "arXiv:2102.05379",
    "title": "Argmax Flows and Multinomial Diffusion: Learning Categorical  Distributions",
    "abstract": "Comments: Accepted at Neural Information Processing Systems (NeurIPS 2021)",
    "descriptor": "\nComments: Accepted at Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Emiel Hoogeboom",
      "Didrik Nielsen",
      "Priyank Jaini",
      "Patrick Forr\u00e9",
      "Max Welling"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.05379"
  },
  {
    "id": "arXiv:2102.06289",
    "title": "When and How Mixup Improves Calibration",
    "abstract": "When and How Mixup Improves Calibration",
    "descriptor": "",
    "authors": [
      "Linjun Zhang",
      "Zhun Deng",
      "Kenji Kawaguchi",
      "James Zou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.06289"
  },
  {
    "id": "arXiv:2102.06665",
    "title": "Bayesian Uncertainty Estimation of Learned Variational MRI  Reconstruction",
    "abstract": "Comments: 19 pages, 11 figures",
    "descriptor": "\nComments: 19 pages, 11 figures\n",
    "authors": [
      "Dominik Narnhofer",
      "Alexander Effland",
      "Erich Kobler",
      "Kerstin Hammernik",
      "Florian Knoll",
      "Thomas Pock"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.06665"
  },
  {
    "id": "arXiv:2102.06679",
    "title": "Adversarial Branch Architecture Search for Unsupervised Domain  Adaptation",
    "abstract": "Comments: Accepted at WACV 2022",
    "descriptor": "\nComments: Accepted at WACV 2022\n",
    "authors": [
      "Luca Robbiano",
      "Muhammad Rameez Ur Rahman",
      "Fabio Galasso",
      "Barbara Caputo",
      "Fabio Maria Carlucci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.06679"
  },
  {
    "id": "arXiv:2102.08559",
    "title": "Numerical Solver for the Boltzmann Equation With Self-Adaptive Collision  Operators",
    "abstract": "Numerical Solver for the Boltzmann Equation With Self-Adaptive Collision  Operators",
    "descriptor": "",
    "authors": [
      "Zhenning Cai",
      "Yanli Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2102.08559"
  },
  {
    "id": "arXiv:2102.09244",
    "title": "HandTailor: Towards High-Precision Monocular 3D Hand Recovery",
    "abstract": "Comments: BMVC2021",
    "descriptor": "\nComments: BMVC2021\n",
    "authors": [
      "Jun Lv",
      "Wenqiang Xu",
      "Lixin Yang",
      "Sucheng Qian",
      "Chongzhao Mao",
      "Cewu Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.09244"
  },
  {
    "id": "arXiv:2102.12894",
    "title": "Constrained Optimization to Train Neural Networks on Critical and  Under-Represented Classes",
    "abstract": "Comments: Accepted to the 35th Conference on Neural Information Processing Systems (NeurIPS 2021)",
    "descriptor": "\nComments: Accepted to the 35th Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Sara Sangalli",
      "Ertunc Erdil",
      "Andreas Hoetker",
      "Olivio Donati",
      "Ender Konukoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.12894"
  },
  {
    "id": "arXiv:2103.10411",
    "title": "Group interactions modulate critical mass dynamics in social convention",
    "abstract": "Comments: 10 pages, 5 figures, Supplementary Material (13 pages, 12 figures)",
    "descriptor": "\nComments: 10 pages, 5 figures, Supplementary Material (13 pages, 12 figures)\n",
    "authors": [
      "Iacopo Iacopini",
      "Giovanni Petri",
      "Andrea Baronchelli",
      "Alain Barrat"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2103.10411"
  },
  {
    "id": "arXiv:2103.13492",
    "title": "Analysis of an exactly mass conserving space-time hybridized  discontinuous Galerkin method for the time-dependent Navier--Stokes equations",
    "abstract": "Analysis of an exactly mass conserving space-time hybridized  discontinuous Galerkin method for the time-dependent Navier--Stokes equations",
    "descriptor": "",
    "authors": [
      "Keegan L. A. Kirk",
      "Tam\u00e1s L. Horv\u00e1th",
      "Sander Rhebergen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.13492"
  },
  {
    "id": "arXiv:2103.14010",
    "title": "Self-Supervised Training Enhances Online Continual Learning",
    "abstract": "Comments: Accepted to BMVC-2021",
    "descriptor": "\nComments: Accepted to BMVC-2021\n",
    "authors": [
      "Jhair Gallardo",
      "Tyler L. Hayes",
      "Christopher Kanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.14010"
  },
  {
    "id": "arXiv:2103.14482",
    "title": "Converse extensionality and apartness",
    "abstract": "Comments: Fixed typos and added an appendix with a proof-theoretic treatment of our results",
    "descriptor": "\nComments: Fixed typos and added an appendix with a proof-theoretic treatment of our results\n",
    "authors": [
      "Benno van den Berg",
      "Robert Passmann"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2103.14482"
  },
  {
    "id": "arXiv:2104.02352",
    "title": "Stochastic convergence of regularized solutions and their finite element  approximations to inverse source problems",
    "abstract": "Stochastic convergence of regularized solutions and their finite element  approximations to inverse source problems",
    "descriptor": "",
    "authors": [
      "Zhiming Chen",
      "Wenlong Zhang",
      "Jun Zou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.02352"
  },
  {
    "id": "arXiv:2104.07123",
    "title": "The MuSe 2021 Multimodal Sentiment Analysis Challenge: Sentiment,  Emotion, Physiological-Emotion, and Stress",
    "abstract": "The MuSe 2021 Multimodal Sentiment Analysis Challenge: Sentiment,  Emotion, Physiological-Emotion, and Stress",
    "descriptor": "",
    "authors": [
      "Lukas Stappen",
      "Alice Baird",
      "Lukas Christ",
      "Lea Schumann",
      "Benjamin Sertolli",
      "Eva-Maria Messner",
      "Erik Cambria",
      "Guoying Zhao",
      "Bj\u00f6rn W. Schuller"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.07123"
  },
  {
    "id": "arXiv:2104.09493",
    "title": "Bayesian Uncertainty and Expected Gradient Length -- Regression: Two  Sides Of The Same Coin?",
    "abstract": "Comments: Accepted: WACV 2022, Algorithms track",
    "descriptor": "\nComments: Accepted: WACV 2022, Algorithms track\n",
    "authors": [
      "Megh Shukla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.09493"
  },
  {
    "id": "arXiv:2104.11884",
    "title": "Social Distancing via Social Scheduling",
    "abstract": "Social Distancing via Social Scheduling",
    "descriptor": "",
    "authors": [
      "Deepesh Kumar Lall",
      "Garima Shakya",
      "Swaprava Nath"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2104.11884"
  },
  {
    "id": "arXiv:2104.12064",
    "title": "RULF: Rust Library Fuzzing via API Dependency Graph Traversal",
    "abstract": "Comments: This paper has been accepted in Proc. of The 36th IEEE/ACM International Conference on Automated Software Engineering (ASE), November, 2021",
    "descriptor": "\nComments: This paper has been accepted in Proc. of The 36th IEEE/ACM International Conference on Automated Software Engineering (ASE), November, 2021\n",
    "authors": [
      "Jianfeng Jiang",
      "Hui Xu",
      "Yangfan Zhou"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2104.12064"
  },
  {
    "id": "arXiv:2104.13023",
    "title": "A mass-, kinetic energy- and helicity-conserving mimetic dual-field  discretization for three-dimensional incompressible Navier-Stokes equations,  part I: Periodic domains",
    "abstract": "Comments: 26 pages, 11 figures",
    "descriptor": "\nComments: 26 pages, 11 figures\n",
    "authors": [
      "Yi Zhang",
      "Artur Palha",
      "Marc Gerritsma",
      "Leo G. Rebholz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.13023"
  },
  {
    "id": "arXiv:2104.13030",
    "title": "A Survey on Neural Recommendation: From Collaborative Filtering to  Information-rich Recommendation",
    "abstract": "Comments: In submission",
    "descriptor": "\nComments: In submission\n",
    "authors": [
      "Le Wu",
      "Xiangnan He",
      "Xiang Wang",
      "Kun Zhang",
      "Meng Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.13030"
  },
  {
    "id": "arXiv:2105.01466",
    "title": "GraphTMT: Unsupervised Graph-based Topic Modeling from Video Transcripts",
    "abstract": "Comments: JT and LS contributed equally to this work",
    "descriptor": "\nComments: JT and LS contributed equally to this work\n",
    "authors": [
      "Lukas Stappen",
      "Jason Thies",
      "Gerhard Hagerer",
      "Bj\u00f6rn W. Schuller",
      "Georg Groh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2105.01466"
  },
  {
    "id": "arXiv:2105.02541",
    "title": "From Bounded Checking to Verification of Equivalence via Symbolic Up-to  Techniques",
    "abstract": "From Bounded Checking to Verification of Equivalence via Symbolic Up-to  Techniques",
    "descriptor": "",
    "authors": [
      "Vasileios Koutavas",
      "Yu-Yang Lin",
      "Nikos Tzevelekos"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.02541"
  },
  {
    "id": "arXiv:2105.03726",
    "title": "Mental Models of Adversarial Machine Learning",
    "abstract": "Comments: 18 pages, 8 figures, under submission",
    "descriptor": "\nComments: 18 pages, 8 figures, under submission\n",
    "authors": [
      "Lukas Bieringer",
      "Kathrin Grosse",
      "Michael Backes",
      "Katharina Krombholz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.03726"
  },
  {
    "id": "arXiv:2105.04447",
    "title": "SCTN: Sparse Convolution-Transformer Network for Scene Flow Estimation",
    "abstract": "SCTN: Sparse Convolution-Transformer Network for Scene Flow Estimation",
    "descriptor": "",
    "authors": [
      "Bing Li",
      "Cheng Zheng",
      "Silvio Giancola",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.04447"
  },
  {
    "id": "arXiv:2105.05408",
    "title": "A survey of size counting in population protocols",
    "abstract": "A survey of size counting in population protocols",
    "descriptor": "",
    "authors": [
      "David Doty",
      "Mahsa Eftekhari"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.05408"
  },
  {
    "id": "arXiv:2105.07447",
    "title": "Non-Fungible Token (NFT): Overview, Evaluation, Opportunities and  Challenges",
    "abstract": "Comments: Tech Report on NFT",
    "descriptor": "\nComments: Tech Report on NFT\n",
    "authors": [
      "Qin Wang",
      "Rujia Li",
      "Qi Wang",
      "Shiping Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.07447"
  },
  {
    "id": "arXiv:2105.07962",
    "title": "DFENet: A Novel Dimension Fusion Edge Guided Network for Brain MRI  Segmentation",
    "abstract": "Comments: Submitted at SN Computer Science",
    "descriptor": "\nComments: Submitted at SN Computer Science\n",
    "authors": [
      "Hritam Basak",
      "Rukhshanda Hussain",
      "Ajay Rana"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.07962"
  },
  {
    "id": "arXiv:2105.11827",
    "title": "Narwhal and Tusk: A DAG-based Mempool and Efficient BFT Consensus",
    "abstract": "Narwhal and Tusk: A DAG-based Mempool and Efficient BFT Consensus",
    "descriptor": "",
    "authors": [
      "George Danezis",
      "Eleftherios Kokoris Kogias",
      "Alberto Sonnino",
      "Alexander Spiegelman"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.11827"
  },
  {
    "id": "arXiv:2105.12710",
    "title": "Enhance to Read Better: A Multi-Task Adversarial Network for Handwritten  Document Image Enhancement",
    "abstract": "Comments: Accepted in Pattern Recognition",
    "descriptor": "\nComments: Accepted in Pattern Recognition\n",
    "authors": [
      "Sana Khamekhem Jemni",
      "Mohamed Ali Souibgui",
      "Yousri Kessentini",
      "Alicia Forn\u00e9s"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.12710"
  },
  {
    "id": "arXiv:2105.12806",
    "title": "A Universal Law of Robustness via Isoperimetry",
    "abstract": "A Universal Law of Robustness via Isoperimetry",
    "descriptor": "",
    "authors": [
      "S\u00e9bastien Bubeck",
      "Mark Sellke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.12806"
  },
  {
    "id": "arXiv:2106.00200",
    "title": "Iterative Hierarchical Attention for Answering Complex Questions over  Long Documents",
    "abstract": "Iterative Hierarchical Attention for Answering Complex Questions over  Long Documents",
    "descriptor": "",
    "authors": [
      "Haitian Sun",
      "William W. Cohen",
      "Ruslan Salakhutdinov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00200"
  },
  {
    "id": "arXiv:2106.00797",
    "title": "QLSD: Quantised Langevin stochastic dynamics for Bayesian federated  learning",
    "abstract": "QLSD: Quantised Langevin stochastic dynamics for Bayesian federated  learning",
    "descriptor": "",
    "authors": [
      "Maxime Vono",
      "Vincent Plassier",
      "Alain Durmus",
      "Aymeric Dieuleveut",
      "Eric Moulines"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00797"
  },
  {
    "id": "arXiv:2106.02262",
    "title": "Envy-free division of multi-layered cakes",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Ayumi Igarashi",
      "Fr\u00e9d\u00e9ric Meunier"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2106.02262"
  },
  {
    "id": "arXiv:2106.02393",
    "title": "Multitask Online Mirror Descent",
    "abstract": "Multitask Online Mirror Descent",
    "descriptor": "",
    "authors": [
      "Nicol\u00f2 Cesa-Bianchi",
      "Pierre Laforgue",
      "Andrea Paudice",
      "Massimiliano Pontil"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02393"
  },
  {
    "id": "arXiv:2106.02636",
    "title": "MERLOT: Multimodal Neural Script Knowledge Models",
    "abstract": "Comments: project page at this https URL; NeurIPS 2021 camera ready",
    "descriptor": "\nComments: project page at this https URL; NeurIPS 2021 camera ready\n",
    "authors": [
      "Rowan Zellers",
      "Ximing Lu",
      "Jack Hessel",
      "Youngjae Yu",
      "Jae Sung Park",
      "Jize Cao",
      "Ali Farhadi",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02636"
  },
  {
    "id": "arXiv:2106.03616",
    "title": "Beamforming and Transmit Power Design for Intelligent Reconfigurable  Surface-aided Secure Spatial Modulation",
    "abstract": "Beamforming and Transmit Power Design for Intelligent Reconfigurable  Surface-aided Secure Spatial Modulation",
    "descriptor": "",
    "authors": [
      "Feng Shu",
      "Xinyi Jiang",
      "Wenlong Cai",
      "Weiping Shi",
      "Mengxing Huang",
      "Jiangzhou Wang",
      "Xiaohu You"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.03616"
  },
  {
    "id": "arXiv:2106.07382",
    "title": "Simulation of viscoelastic Cosserat rods based on the geometrically  exact dynamics of special Euclidean strands",
    "abstract": "Comments: 17 pages, 9 figures",
    "descriptor": "\nComments: 17 pages, 9 figures\n",
    "authors": [
      "G. G. Giusteri",
      "E. Miglio",
      "N. Parolini",
      "M. Penati",
      "R. Zambetti"
    ],
    "subjectives": [
      "Classical Physics (physics.class-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.07382"
  },
  {
    "id": "arXiv:2106.07769",
    "title": "The Flip Side of the Reweighted Coin: Duality of Adaptive Dropout and  Regularization",
    "abstract": "Comments: 19 pages, 2 figures. Accepted to NeurIPS 2021",
    "descriptor": "\nComments: 19 pages, 2 figures. Accepted to NeurIPS 2021\n",
    "authors": [
      "Daniel LeJeune",
      "Hamid Javadi",
      "Richard G. Baraniuk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07769"
  },
  {
    "id": "arXiv:2106.08250",
    "title": "Constrained Motion Planning of A Cable-Driven Soft Robot With  Compressible Curvature Modeling",
    "abstract": "Comments: 8 pages, 9 figures",
    "descriptor": "\nComments: 8 pages, 9 figures\n",
    "authors": [
      "Jiewen Lai",
      "Bo Lu",
      "Qingxiang Zhao",
      "Henry K. Chu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.08250"
  },
  {
    "id": "arXiv:2106.08365",
    "title": "Predicting Unreliable Predictions by Shattering a Neural Network",
    "abstract": "Comments: Updated version (Oct 2021)",
    "descriptor": "\nComments: Updated version (Oct 2021)\n",
    "authors": [
      "Xu Ji",
      "Razvan Pascanu",
      "Devon Hjelm",
      "Andrea Vedaldi",
      "Balaji Lakshminarayanan",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.08365"
  },
  {
    "id": "arXiv:2106.09553",
    "title": "Do Large Scale Molecular Language Representations Capture Important  Structural Information?",
    "abstract": "Do Large Scale Molecular Language Representations Capture Important  Structural Information?",
    "descriptor": "",
    "authors": [
      "Jerret Ross",
      "Brian Belgodere",
      "Vijil Chenthamarakshan",
      "Inkit Padhi",
      "Youssef Mroueh",
      "Payel Das"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2106.09553"
  },
  {
    "id": "arXiv:2106.09708",
    "title": "Multi-Label Learning from Single Positive Labels",
    "abstract": "Comments: CVPR 2021. Supplementary material included",
    "descriptor": "\nComments: CVPR 2021. Supplementary material included\n",
    "authors": [
      "Elijah Cole",
      "Oisin Mac Aodha",
      "Titouan Lorieul",
      "Pietro Perona",
      "Dan Morris",
      "Nebojsa Jojic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09708"
  },
  {
    "id": "arXiv:2106.13082",
    "title": "On the relationship between predictive coding and backpropagation",
    "abstract": "On the relationship between predictive coding and backpropagation",
    "descriptor": "",
    "authors": [
      "Robert Rosenbaum"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.13082"
  },
  {
    "id": "arXiv:2106.13646",
    "title": "Two Standard Decks of Playing Cards are Sufficient for a ZKP for Sudoku",
    "abstract": "Comments: A shortened version of this paper has appeared at COCOON 2021",
    "descriptor": "\nComments: A shortened version of this paper has appeared at COCOON 2021\n",
    "authors": [
      "Suthee Ruangwises"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.13646"
  },
  {
    "id": "arXiv:2106.15183",
    "title": "Multi-Exit Vision Transformer for Dynamic Inference",
    "abstract": "Comments: Accepted by the 2021 British Machine Vision Conference (BMVC 2021)",
    "descriptor": "\nComments: Accepted by the 2021 British Machine Vision Conference (BMVC 2021)\n",
    "authors": [
      "Arian Bakhtiarnia",
      "Qi Zhang",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15183"
  },
  {
    "id": "arXiv:2107.01899",
    "title": "Ray-ONet: Efficient 3D Reconstruction From A Single RGB Image",
    "abstract": "Comments: accepted in BMVC 2021",
    "descriptor": "\nComments: accepted in BMVC 2021\n",
    "authors": [
      "Wenjing Bian",
      "Zirui Wang",
      "Kejie Li",
      "Victor Adrian Prisacariu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01899"
  },
  {
    "id": "arXiv:2107.07630",
    "title": "Evaluation of Human-AI Teams for Learned and Rule-Based Agents in Hanabi",
    "abstract": "Comments: Accepted for publication at NeurIPS 2021",
    "descriptor": "\nComments: Accepted for publication at NeurIPS 2021\n",
    "authors": [
      "Ho Chit Siu",
      "Jaime D. Pena",
      "Edenna Chen",
      "Yutai Zhou",
      "Victor J. Lopez",
      "Kyle Palko",
      "Kimberlee C. Chang",
      "Ross E. Allen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.07630"
  },
  {
    "id": "arXiv:2107.07724",
    "title": "Active learning for imbalanced data under cold start",
    "abstract": "Comments: 9 pages, 6 figures, 2 tables",
    "descriptor": "\nComments: 9 pages, 6 figures, 2 tables\n",
    "authors": [
      "Ricardo Barata",
      "Miguel Leite",
      "Ricardo Pacheco",
      "Marco O. P. Sampaio",
      "Jo\u00e3o Tiago Ascens\u00e3o",
      "Pedro Bizarro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.07724"
  },
  {
    "id": "arXiv:2107.09391",
    "title": "Built-in Elastic Transformations for Improved Robustness",
    "abstract": "Built-in Elastic Transformations for Improved Robustness",
    "descriptor": "",
    "authors": [
      "Sadaf Gulshad",
      "Ivan Sosnovik",
      "Arnold Smeulders"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.09391"
  },
  {
    "id": "arXiv:2107.10295",
    "title": "How to Tell Deep Neural Networks What We Know",
    "abstract": "Comments: 15 pages; Revised Version for Nature Scientific Reports. arXiv admin note: substantial text overlap with arXiv:2103.00180",
    "descriptor": "\nComments: 15 pages; Revised Version for Nature Scientific Reports. arXiv admin note: substantial text overlap with arXiv:2103.00180\n",
    "authors": [
      "Tirtharaj Dash",
      "Sharad Chitlangia",
      "Aditya Ahuja",
      "Ashwin Srinivasan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.10295"
  },
  {
    "id": "arXiv:2107.11912",
    "title": "Performance vs Programming Effort between Rust and C on Multicore  Architectures: Case Study in N-Body",
    "abstract": "Comments: This article was accepted for publication in 2021 XLVI Latin American Computing Conference (CLEI)",
    "descriptor": "\nComments: This article was accepted for publication in 2021 XLVI Latin American Computing Conference (CLEI)\n",
    "authors": [
      "Manuel Costanzo",
      "Enzo Rucci",
      "Marcelo Naiouf",
      "Armando De Giusti"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2107.11912"
  },
  {
    "id": "arXiv:2107.13634",
    "title": "Don't Separate, Learn to Remix: End-to-End Neural Remixing with Joint  Optimization",
    "abstract": "Don't Separate, Learn to Remix: End-to-End Neural Remixing with Joint  Optimization",
    "descriptor": "",
    "authors": [
      "Haici Yang",
      "Shivani Firodiya",
      "Nicholas J. Bryan",
      "Minje Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.13634"
  },
  {
    "id": "arXiv:2107.14423",
    "title": "Lunaport: Math, Mechanics & Transport",
    "abstract": "Comments: 58 pages, to be submitted to Symmetry, for Special Issue on Symmetry in Mechanical and Transport Engineering, Transport Logistics, and Mathematical Design of Efficient Transport Facilities",
    "descriptor": "\nComments: 58 pages, to be submitted to Symmetry, for Special Issue on Symmetry in Mechanical and Transport Engineering, Transport Logistics, and Mathematical Design of Efficient Transport Facilities\n",
    "authors": [
      "Paul C. Kainen"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.14423"
  },
  {
    "id": "arXiv:2108.01454",
    "title": "Inscriptis -- A Python-based HTML to text conversion library optimized  for knowledge extraction from the Web",
    "abstract": "Comments: Preprint of the published version, which includes all improvements made during the review process",
    "descriptor": "\nComments: Preprint of the published version, which includes all improvements made during the review process\n",
    "authors": [
      "Albert Weichselbraun"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2108.01454"
  },
  {
    "id": "arXiv:2108.03297",
    "title": "Joint AP Probing and Scheduling: A Contextual Bandit Approach",
    "abstract": "Joint AP Probing and Scheduling: A Contextual Bandit Approach",
    "descriptor": "",
    "authors": [
      "Tianyi Xu",
      "Ding Zhang",
      "Parth H. Pathak",
      "Zizhan Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2108.03297"
  },
  {
    "id": "arXiv:2108.03893",
    "title": "Self-supervised Learning of Occlusion Aware Flow Guided 3D Geometry  Perception with Adaptive Cross Weighted Loss from Monocular Videos",
    "abstract": "Comments: 7pages,4figures",
    "descriptor": "\nComments: 7pages,4figures\n",
    "authors": [
      "Jiaojiao Fang",
      "Guizhong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.03893"
  },
  {
    "id": "arXiv:2108.07127",
    "title": "Active Learning for Massively Parallel Translation of Constrained Text  into Low Resource Languages",
    "abstract": "Active Learning for Massively Parallel Translation of Constrained Text  into Low Resource Languages",
    "descriptor": "",
    "authors": [
      "Zhong Zhou",
      "Alex Waibel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.07127"
  },
  {
    "id": "arXiv:2108.08129",
    "title": "Quantitative Uniform Stability of the Iterative Proportional Fitting  Procedure",
    "abstract": "Comments: 14 pages",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "George Deligiannidis",
      "Valentin De Bortoli",
      "Arnaud Doucet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2108.08129"
  },
  {
    "id": "arXiv:2108.09481",
    "title": "DSP-SLAM: Object Oriented SLAM with Deep Shape Priors",
    "abstract": "Comments: To be published at 3DV 2021",
    "descriptor": "\nComments: To be published at 3DV 2021\n",
    "authors": [
      "Jingwen Wang",
      "Martin R\u00fcnz",
      "Lourdes Agapito"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.09481"
  },
  {
    "id": "arXiv:2108.11898",
    "title": "Supervised Compression for Resource-Constrained Edge Computing Systems",
    "abstract": "Comments: Accepted to WACV 2022. Code and models are available at this https URL",
    "descriptor": "\nComments: Accepted to WACV 2022. Code and models are available at this https URL\n",
    "authors": [
      "Yoshitomo Matsubara",
      "Ruihan Yang",
      "Marco Levorato",
      "Stephan Mandt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.11898"
  },
  {
    "id": "arXiv:2108.13664",
    "title": "Lane level context and hidden space characterization for autonomous  driving",
    "abstract": "Lane level context and hidden space characterization for autonomous  driving",
    "descriptor": "",
    "authors": [
      "Corentin Sanchez",
      "Philippe Xu",
      "Alexandre Armand",
      "Philippe Bonnifait"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.13664"
  },
  {
    "id": "arXiv:2109.01896",
    "title": "GamePlan: Game-Theoretic Multi-Agent Planning with Human Drivers at  Intersections, Roundabouts, and Merging",
    "abstract": "Comments: Updated exposition",
    "descriptor": "\nComments: Updated exposition\n",
    "authors": [
      "Rohan Chandra",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2109.01896"
  },
  {
    "id": "arXiv:2109.02716",
    "title": "Vision Transformers For Weeds and Crops Classification Of High  Resolution UAV Images",
    "abstract": "Comments: Compared to the last version of the article, we have added some experiments, that is the evaluation of the performances by varying the number of samples in the test and train sets",
    "descriptor": "\nComments: Compared to the last version of the article, we have added some experiments, that is the evaluation of the performances by varying the number of samples in the test and train sets\n",
    "authors": [
      "Reenul Reedha",
      "Eric Dericquebourg",
      "Raphael Canals",
      "Adel Hafiane"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.02716"
  },
  {
    "id": "arXiv:2109.03560",
    "title": "Graph-MVP: Multi-View Prototypical Contrastive Learning for Multiplex  Graphs",
    "abstract": "Comments: Preprint. Work in progress",
    "descriptor": "\nComments: Preprint. Work in progress\n",
    "authors": [
      "Baoyu Jing",
      "Yuejia Xiang",
      "Xi Chen",
      "Yu Chen",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03560"
  },
  {
    "id": "arXiv:2109.04160",
    "title": "Compositional Affinity Propagation: When Clusters Have Compositional  Structure",
    "abstract": "Compositional Affinity Propagation: When Clusters Have Compositional  Structure",
    "descriptor": "",
    "authors": [
      "Jacob Whitehill",
      "Zeqian Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04160"
  },
  {
    "id": "arXiv:2109.07234",
    "title": "The Unreasonable Effectiveness of the Baseline: Discussing SVMs in Legal  Text Classification",
    "abstract": "Comments: 6 pages, to be presented at JURIX 2021",
    "descriptor": "\nComments: 6 pages, to be presented at JURIX 2021\n",
    "authors": [
      "Benjamin Clavi\u00e9",
      "Marc Alphonsus"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07234"
  },
  {
    "id": "arXiv:2109.08061",
    "title": "Invertible Frowns: Video-to-Video Facial Emotion Translation",
    "abstract": "Comments: 9 pages, 2 figures, 4 tables, accepted at ADGD @ ACM Multimedia 2021",
    "descriptor": "\nComments: 9 pages, 2 figures, 4 tables, accepted at ADGD @ ACM Multimedia 2021\n",
    "authors": [
      "Ian Magnusson",
      "Aruna Sankaranarayanan",
      "Andrew Lippman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.08061"
  },
  {
    "id": "arXiv:2109.08660",
    "title": "Predicting the effects of waning vaccine immunity against COVID-19  through high-resolution agent-based modeling",
    "abstract": "Comments: 47 pages; 10 figures; Under review",
    "descriptor": "\nComments: 47 pages; 10 figures; Under review\n",
    "authors": [
      "Agnieszka Truszkowska",
      "Lorenzo Zino",
      "Sachit Butail",
      "Emanuele Caroppo",
      "Zhong-Ping Jiang",
      "Alessandro Rizzo",
      "Maurizio Porfiri"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Systems and Control (eess.SY)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2109.08660"
  },
  {
    "id": "arXiv:2109.08722",
    "title": "Efficient Variational Graph Autoencoders for Unsupervised Cross-domain  Prerequisite Chains",
    "abstract": "Comments: Accepted by the Efficient Natural Language and Speech Processing (ENLSP) Workshop, NeurIPS 2021",
    "descriptor": "\nComments: Accepted by the Efficient Natural Language and Speech Processing (ENLSP) Workshop, NeurIPS 2021\n",
    "authors": [
      "Irene Li",
      "Vanessa Yan",
      "Dragomir Radev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.08722"
  },
  {
    "id": "arXiv:2109.08860",
    "title": "Groups Influence with Minimum Cost in Social Networks",
    "abstract": "Comments: There are some results of the article that need to be corrected",
    "descriptor": "\nComments: There are some results of the article that need to be corrected\n",
    "authors": [
      "Phuong N. H. Pham",
      "Canh V. Pham",
      "Hieu V. Duong",
      "Thanh T. Nguyen",
      "My T. Thai"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2109.08860"
  },
  {
    "id": "arXiv:2109.08863",
    "title": "Streaming algorithms for Budgeted $k$-Submodular Maximization problem",
    "abstract": "Comments: There are some results of the article that need to be corrected",
    "descriptor": "\nComments: There are some results of the article that need to be corrected\n",
    "authors": [
      "Canh V. Pham",
      "Quang C. Vu",
      "Dung K. T. Ha",
      "Tai T. Nguyen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2109.08863"
  },
  {
    "id": "arXiv:2109.10760",
    "title": "FaceEraser: Removing Facial Parts for Augmented Reality",
    "abstract": "Comments: 18 pages, 15 figures. ICCV 2021, Fifth Workshop on Computer Vision for AR/VR",
    "descriptor": "\nComments: 18 pages, 15 figures. ICCV 2021, Fifth Workshop on Computer Vision for AR/VR\n",
    "authors": [
      "Miao Hua",
      "Lijie Liu",
      "Ziyang Cheng",
      "Qian He",
      "Bingchuan Li",
      "Zili Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.10760"
  },
  {
    "id": "arXiv:2109.10964",
    "title": "Multi-Objective Bayesian Optimization over High-Dimensional Search  Spaces",
    "abstract": "Multi-Objective Bayesian Optimization over High-Dimensional Search  Spaces",
    "descriptor": "",
    "authors": [
      "Samuel Daulton",
      "David Eriksson",
      "Maximilian Balandat",
      "Eytan Bakshy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.10964"
  },
  {
    "id": "arXiv:2109.12825",
    "title": "Probability Distribution on Full Rooted Trees",
    "abstract": "Probability Distribution on Full Rooted Trees",
    "descriptor": "",
    "authors": [
      "Yuta Nakahara",
      "Shota Saito",
      "Akira Kamatsuka",
      "Toshiyasu Matsushima"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.12825"
  },
  {
    "id": "arXiv:2109.13238",
    "title": "Visually Grounded Reasoning across Languages and Cultures",
    "abstract": "Comments: EMNLP 2021; Fangyu and Emanuele contributed equally; MaRVL website: this https URL",
    "descriptor": "\nComments: EMNLP 2021; Fangyu and Emanuele contributed equally; MaRVL website: this https URL\n",
    "authors": [
      "Fangyu Liu",
      "Emanuele Bugliarello",
      "Edoardo Maria Ponti",
      "Siva Reddy",
      "Nigel Collier",
      "Desmond Elliott"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.13238"
  },
  {
    "id": "arXiv:2109.14162",
    "title": "Can multi-label classification networks know what they don't know?",
    "abstract": "Comments: Paper published at NeurIPS 2021",
    "descriptor": "\nComments: Paper published at NeurIPS 2021\n",
    "authors": [
      "Haoran Wang",
      "Weitang Liu",
      "Alex Bocchieri",
      "Yixuan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.14162"
  },
  {
    "id": "arXiv:2109.15086",
    "title": "Key Point Analysis via Contrastive Learning and Extractive Argument  Summarization",
    "abstract": "Key Point Analysis via Contrastive Learning and Extractive Argument  Summarization",
    "descriptor": "",
    "authors": [
      "Milad Alshomary",
      "Timon Gurcke",
      "Shahbaz Syed",
      "Philipp Heinrich",
      "Maximilian Splieth\u00f6ver",
      "Philipp Cimiano",
      "Martin Potthast",
      "Henning Wachsmuth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.15086"
  },
  {
    "id": "arXiv:2109.15193",
    "title": "AIive: Interactive Visualization and Sonification of Neural Networks in  Virtual Reality",
    "abstract": "Comments: 3 pages, 3 figures, 2021 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)",
    "descriptor": "\nComments: 3 pages, 3 figures, 2021 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)\n",
    "authors": [
      "Zhuoyue Lyu",
      "Jiannan Li",
      "Bryan Wang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.15193"
  },
  {
    "id": "arXiv:2110.02912",
    "title": "Generative Optimization Networks for Memory Efficient Data Generation",
    "abstract": "Comments: Accepted in NeurIPS 2021 - Workshop on ML for Systems",
    "descriptor": "\nComments: Accepted in NeurIPS 2021 - Workshop on ML for Systems\n",
    "authors": [
      "Shreshth Tuli",
      "Shikhar Tuli",
      "Giuliano Casale",
      "Nicholas R. Jennings"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02912"
  },
  {
    "id": "arXiv:2110.03278",
    "title": "Virtual Multi-Modality Self-Supervised Foreground Matting for  Human-Object Interaction",
    "abstract": "Comments: Accepted by ICCV2021",
    "descriptor": "\nComments: Accepted by ICCV2021\n",
    "authors": [
      "Bo Xu",
      "Han Huang",
      "Cheng Lu",
      "Ziwen Li",
      "Yandong Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.03278"
  },
  {
    "id": "arXiv:2110.04850",
    "title": "Direct source and early reflections localization using deep  deconvolution network under reverberant environment",
    "abstract": "Direct source and early reflections localization using deep  deconvolution network under reverberant environment",
    "descriptor": "",
    "authors": [
      "Shan Gao",
      "Xihong Wu",
      "Tianshu Qu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.04850"
  },
  {
    "id": "arXiv:2110.05035",
    "title": "Using Personality Detection Tools for Software Engineering Research: How  Far Can We Go?",
    "abstract": "Using Personality Detection Tools for Software Engineering Research: How  Far Can We Go?",
    "descriptor": "",
    "authors": [
      "Fabio Calefato",
      "Filippo Lanubile"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05035"
  },
  {
    "id": "arXiv:2110.07355",
    "title": "Floating Isogeometric Analysis",
    "abstract": "Floating Isogeometric Analysis",
    "descriptor": "",
    "authors": [
      "Helge C. Hille",
      "Siddhant Kumar",
      "Laura De Lorenzis"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2110.07355"
  },
  {
    "id": "arXiv:2110.07402",
    "title": "Self-Supervised Learning by Estimating Twin Class Distributions",
    "abstract": "Comments: Technical report",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Feng Wang",
      "Tao Kong",
      "Rufeng Zhang",
      "Huaping Liu",
      "Hang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.07402"
  },
  {
    "id": "arXiv:2110.07869",
    "title": "A Dual-Perception Graph Neural Network with Multi-hop Graph Generator",
    "abstract": "Comments: 9 pages",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Li Zhou",
      "Wenyu Chen",
      "Dingyi Zeng",
      "Shaohuan Cheng",
      "Wanlong Liu",
      "Hong Qu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.07869"
  },
  {
    "id": "arXiv:2110.08471",
    "title": "Fast Projection onto the Capped Simplex with Applications to Sparse  Regression in Bioinformatics",
    "abstract": "Comments: 12 pages, 5 figures",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Andersen Ang",
      "Jianzhu Ma",
      "Nianjun Liu",
      "Kun Huang",
      "Yijie Wang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2110.08471"
  },
  {
    "id": "arXiv:2110.08513",
    "title": "Deep Reinforcement Learning for Practical Phase Shift Optimization in  RIS-aided MISO URLLC Systems",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Ramin Hashemi",
      "Samad Ali",
      "Nurul Huda Mahmood",
      "Matti Latva-aho"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.08513"
  },
  {
    "id": "arXiv:2110.08858",
    "title": "Backpropagation with Biologically Plausible Spatio-Temporal Adjustment  For Training Deep Spiking Neural Networks",
    "abstract": "Backpropagation with Biologically Plausible Spatio-Temporal Adjustment  For Training Deep Spiking Neural Networks",
    "descriptor": "",
    "authors": [
      "Guobin Shen",
      "Dongcheng Zhao",
      "Yi Zeng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08858"
  },
  {
    "id": "arXiv:2110.08913",
    "title": "Real Time Cluster Path Tracing",
    "abstract": "Comments: 5 pages, 7 figures. To be published in Siggraph Asia 2021's Telecommunication Program",
    "descriptor": "\nComments: 5 pages, 7 figures. To be published in Siggraph Asia 2021's Telecommunication Program\n",
    "authors": [
      "Feng Xie",
      "Petro Mishchuk",
      "Warren Hunt"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.08913"
  },
  {
    "id": "arXiv:2110.09012",
    "title": "Navigation of a UAV Equipped with a Reconfigurable Intelligent Surface  for LoS Wireless Communication with a Ground Vehicle",
    "abstract": "Comments: Dear Sir/Madam I am writing to withdraw the paper because I submitted it without approval of other authors. Sincerely Mohsen",
    "descriptor": "\nComments: Dear Sir/Madam I am writing to withdraw the paper because I submitted it without approval of other authors. Sincerely Mohsen\n",
    "authors": [
      "Mohsen Eskandari",
      "Hailong Huang",
      "Andrey V. Savkin",
      "Wei Ni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.09012"
  },
  {
    "id": "arXiv:2110.09470",
    "title": "No RL, No Simulation: Learning to Navigate without Navigating",
    "abstract": "No RL, No Simulation: Learning to Navigate without Navigating",
    "descriptor": "",
    "authors": [
      "Meera Hahn",
      "Devendra Chaplot",
      "Shubham Tulsiani",
      "Mustafa Mukadam",
      "James M. Rehg",
      "Abhinav Gupta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09470"
  },
  {
    "id": "arXiv:2110.09594",
    "title": "Bayesian Persuasion in Sequential Trials",
    "abstract": "Bayesian Persuasion in Sequential Trials",
    "descriptor": "",
    "authors": [
      "Shih-Tang Su",
      "Vijay G. Subramanian",
      "Grant Schoenebeck"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.09594"
  },
  {
    "id": "arXiv:2110.09638",
    "title": "Repeated Games, Optimal Channel Capture, and Open Problems for Slotted  Multiple Access",
    "abstract": "Comments: 19 pages",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Michael J. Neely"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.09638"
  },
  {
    "id": "arXiv:2110.09749",
    "title": "Importance Estimation from Multiple Perspectives for Keyphrase  Extraction",
    "abstract": "Comments: 11 pages, 3 figures, Accepted by EMNLP 2021 (main conference)",
    "descriptor": "\nComments: 11 pages, 3 figures, Accepted by EMNLP 2021 (main conference)\n",
    "authors": [
      "Mingyang Song",
      "Liping Jing",
      "Lin Xiao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.09749"
  },
  {
    "id": "arXiv:2110.10083",
    "title": "Contrastive Active Inference",
    "abstract": "Comments: Accepted as a conference paper at 35th Conference on Neural Information Processing Systems (NeurIPS 2021)",
    "descriptor": "\nComments: Accepted as a conference paper at 35th Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Pietro Mazzaglia",
      "Tim Verbelen",
      "Bart Dhoedt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10083"
  },
  {
    "id": "arXiv:2110.10570",
    "title": "Behavioral Experiments for Understanding Catastrophic Forgetting",
    "abstract": "Comments: Add supplementary materials",
    "descriptor": "\nComments: Add supplementary materials\n",
    "authors": [
      "Samuel J. Bell",
      "Neil D. Lawrence"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10570"
  },
  {
    "id": "arXiv:2110.10724",
    "title": "Semi-supervised physics guided deep learning framework for predicting  the I-V characteristics of GAN HEMT",
    "abstract": "Semi-supervised physics guided deep learning framework for predicting  the I-V characteristics of GAN HEMT",
    "descriptor": "",
    "authors": [
      "Shivanshu Mishra",
      "Bipin Gaikwad",
      "Nidhi Chaturvedi"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10724"
  },
  {
    "id": "arXiv:2110.10828",
    "title": "AdamD: Improved bias-correction in Adam",
    "abstract": "Comments: 8 pages, 1 figure",
    "descriptor": "\nComments: 8 pages, 1 figure\n",
    "authors": [
      "John St John"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10828"
  },
  {
    "id": "arXiv:2110.10854",
    "title": "Performance Analysis for Covert Communications Under Faster-than-Nyquist  Signaling",
    "abstract": "Comments: We found some technical issues in our paper. So we decide to withdraw it temporarily",
    "descriptor": "\nComments: We found some technical issues in our paper. So we decide to withdraw it temporarily\n",
    "authors": [
      "Yuan Li",
      "Yuchen Zhang",
      "Wanyu Xiang",
      "Jianquan Wang",
      "Sa Xiao",
      "Liang Chang",
      "Wanbin Tang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.10854"
  },
  {
    "id": "arXiv:2110.10953",
    "title": "MOS: A Low Latency and Lightweight Framework for Face Detection,  Landmark Localization, and Head Pose Estimation",
    "abstract": "Comments: Accepted at BMVC 2021",
    "descriptor": "\nComments: Accepted at BMVC 2021\n",
    "authors": [
      "Yepeng Liu",
      "Zaiwang Gu",
      "Shenghua Gao",
      "Dong Wang",
      "Yusheng Zeng",
      "Jun Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.10953"
  },
  {
    "id": "arXiv:2110.11023",
    "title": "Augmenting Knowledge Distillation With Peer-To-Peer Mutual Learning For  Model Compression",
    "abstract": "Comments: changed the format of paper",
    "descriptor": "\nComments: changed the format of paper\n",
    "authors": [
      "Usma Niyaz",
      "Deepti R. Bathula"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11023"
  },
  {
    "id": "arXiv:2110.11040",
    "title": "InterpolationSLAM: A Novel Robust Visual SLAM System in Rotational  Motion",
    "abstract": "Comments: I actually want update the old version of my last paper. Because my wrong operation, I published a new one",
    "descriptor": "\nComments: I actually want update the old version of my last paper. Because my wrong operation, I published a new one\n",
    "authors": [
      "Zhenkun Zhu",
      "Jikai Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.11040"
  },
  {
    "id": "arXiv:2110.11043",
    "title": "Improving the Deployment of Recycling Classification through Efficient  Hyper-Parameter Analysis",
    "abstract": "Improving the Deployment of Recycling Classification through Efficient  Hyper-Parameter Analysis",
    "descriptor": "",
    "authors": [
      "Mazin Abdulmahmood",
      "Ryan Grammenos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11043"
  },
  {
    "id": "arXiv:2110.11088",
    "title": "RoMA: a Method for Neural Network Robustness Measurement and Assessment",
    "abstract": "RoMA: a Method for Neural Network Robustness Measurement and Assessment",
    "descriptor": "",
    "authors": [
      "Natan Levy",
      "Guy Katz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11088"
  },
  {
    "id": "arXiv:2110.11111",
    "title": "A Deep Insight into Measuring Face Image Utility with General and  Face-specific Image Quality Metrics",
    "abstract": "Comments: Accepted at the IEEE Winter Conference on Applications of Computer Vision, WACV 2022",
    "descriptor": "\nComments: Accepted at the IEEE Winter Conference on Applications of Computer Vision, WACV 2022\n",
    "authors": [
      "Biying Fu",
      "Cong Chen",
      "Olaf Henniger",
      "Naser Damer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11111"
  },
  {
    "id": "arXiv:2110.11148",
    "title": "HCV: Hierarchy-Consistency Verification for Incremental  Implicitly-Refined Classification",
    "abstract": "Comments: accepted in BMVC 2021",
    "descriptor": "\nComments: accepted in BMVC 2021\n",
    "authors": [
      "Kai Wang",
      "Xialei Liu",
      "Luis Herranz",
      "Joost van de Weijer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11148"
  },
  {
    "id": "arXiv:2110.11154",
    "title": "Personalized Transfer of User Preferences for Cross-domain  Recommendation",
    "abstract": "Comments: Accepted by WSDM 2022",
    "descriptor": "\nComments: Accepted by WSDM 2022\n",
    "authors": [
      "Yongchun Zhu",
      "Zhenwei Tang",
      "Yudan Liu",
      "Fuzhen Zhuang",
      "Ruobing Xie",
      "Xu Zhang",
      "Leyu Lin",
      "Qing He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11154"
  },
  {
    "id": "arXiv:2110.11191",
    "title": "Generative Adversarial Graph Convolutional Networks for Human Action  Synthesis",
    "abstract": "Comments: Published as a conference paper at WACV 2022. Code and pretrained models available at this https URL",
    "descriptor": "\nComments: Published as a conference paper at WACV 2022. Code and pretrained models available at this https URL\n",
    "authors": [
      "Bruno Degardin",
      "Jo\u00e3o Neves",
      "Vasco Lopes",
      "Jo\u00e3o Brito",
      "Ehsan Yaghoubi",
      "Hugo Proen\u00e7a"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11191"
  },
  {
    "id": "arXiv:2110.11281",
    "title": "Super-resolution of multiphase materials by combining complementary 2D  and 3D image data using generative adversarial networks",
    "abstract": "Super-resolution of multiphase materials by combining complementary 2D  and 3D image data using generative adversarial networks",
    "descriptor": "",
    "authors": [
      "Amir Dahari",
      "Steve Kench",
      "Isaac Squires",
      "Samuel J. Cooper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11281"
  },
  {
    "id": "arXiv:2110.11283",
    "title": "The Effect of Wearing a Face Mask on Face Image Quality",
    "abstract": "Comments: Accepted at the 16th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2021",
    "descriptor": "\nComments: Accepted at the 16th IEEE International Conference on Automatic Face and Gesture Recognition, FG 2021\n",
    "authors": [
      "Biying Fu",
      "Florian Kirchbuchner",
      "Naser Damer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.11283"
  },
  {
    "id": "arXiv:2110.11293",
    "title": "An Empirical Study on GANs with Margin Cosine Loss and Relativistic  Discriminator",
    "abstract": "Comments: 16 pages, 5 figures",
    "descriptor": "\nComments: 16 pages, 5 figures\n",
    "authors": [
      "Cuong V. Nguyen",
      "Tien-Dung Cao",
      "Tram Truong-Huu",
      "Khanh N. Pham",
      "Binh T. Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11293"
  }
]
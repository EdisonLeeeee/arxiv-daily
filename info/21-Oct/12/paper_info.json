[
  {
    "id": "arXiv:2110.04297",
    "title": "3D Meta-Segmentation Neural Network",
    "abstract": "Though deep learning methods have shown great success in 3D point cloud part\nsegmentation, they generally rely on a large volume of labeled training data,\nwhich makes the model suffer from unsatisfied generalization abilities to\nunseen classes with limited data. To address this problem, we present a novel\nmeta-learning strategy that regards the 3D shape segmentation function as a\ntask. By training over a number of 3D part segmentation tasks, our method is\ncapable to learn the prior over the respective 3D segmentation function space\nwhich leads to an optimal model that is rapidly adapting to new part\nsegmentation tasks. To implement our meta-learning strategy, we propose two\nnovel modules: meta part segmentation learner and part segmentation learner.\nDuring the training process, the part segmentation learner is trained to\ncomplete a specific part segmentation task in the few-shot scenario. In the\nmeantime, the meta part segmentation learner is trained to capture the prior\nfrom multiple similar part segmentation tasks. Based on the learned information\nof task distribution, our meta part segmentation learner is able to dynamically\nupdate the part segmentation learner with optimal parameters which enable our\npart segmentation learner to rapidly adapt and have great generalization\nability on new part segmentation tasks. We demonstrate that our model achieves\nsuperior part segmentation performance with the few-shot setting on the widely\nused dataset: ShapeNet.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2110.03854\n",
    "authors": [
      "Yu Hao",
      "Yi Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04297"
  },
  {
    "id": "arXiv:2110.04301",
    "title": "Causal ImageNet: How to discover spurious features in Deep Learning?",
    "abstract": "A key reason for the lack of reliability of deep neural networks in the real\nworld is their heavy reliance on {\\it spurious} input features that are\ncausally unrelated to the true label. Focusing on image classifications, we\ndefine causal attributes as the set of visual features that are always a part\nof the object while spurious attributes are the ones that are likely to {\\it\nco-occur} with the object but not a part of it (e.g., attribute ``fingers\" for\nclass ``band aid\"). Traditional methods for discovering spurious features\neither require extensive human annotations (thus, not scalable), or are useful\non specific models. In this work, we introduce a {\\it scalable} framework to\ndiscover a subset of spurious and causal visual attributes used in inferences\nof a general model and localize them on a large number of images with minimal\nhuman supervision. Our methodology is based on this key idea: to identify\nspurious or causal \\textit{visual attributes} used in model predictions, we\nidentify spurious or causal \\textit{neural features} (penultimate layer neurons\nof a robust model) via limited human supervision (e.g., using top 5 activating\nimages per feature). We then show that these neural feature annotations {\\it\ngeneralize} extremely well to many more images {\\it without} any human\nsupervision. We use the activation maps for these neural features as the soft\nmasks to highlight spurious or causal visual attributes. Using this\nmethodology, we introduce the {\\it Causal Imagenet} dataset containing causal\nand spurious masks for a large set of samples from Imagenet. We assess the\nperformance of several popular Imagenet models and show that they rely heavily\non various spurious features in their predictions.",
    "descriptor": "",
    "authors": [
      "Sahil Singla",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04301"
  },
  {
    "id": "arXiv:2110.04316",
    "title": "COVID-19 Face Mask Recognition with Advanced Face Cut Algorithm for  Human Safety Measures",
    "abstract": "In the last year, the outbreak of COVID-19 has deployed computer vision and\nmachine learning algorithms in various fields to enhance human life\ninteractions. COVID-19 is a highly contaminated disease that affects mainly the\nrespiratory organs of the human body. We must wear a mask in this situation as\nthe virus can be contaminated through the air and a non-masked person can be\naffected. Our proposal deploys a computer vision and deep learning framework to\nrecognize face masks from images or videos. We have implemented a Boundary\ndependent face cut recognition algorithm that can cut the face from the image\nusing 27 landmarks and then the preprocessed image can further be sent to the\ndeep learning ResNet50 model. The experimental result shows a significant\nadvancement of 3.4 percent compared to the YOLOV3 mask recognition architecture\nin just 10 epochs.",
    "descriptor": "\nComments: 5 pages, 7 figures\n",
    "authors": [
      "Arkaprabha Basu",
      "Md Firoj Ali"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.04316"
  },
  {
    "id": "arXiv:2110.04318",
    "title": "Learning a Self-Expressive Network for Subspace Clustering",
    "abstract": "State-of-the-art subspace clustering methods are based on self-expressive\nmodel, which represents each data point as a linear combination of other data\npoints. However, such methods are designed for a finite sample dataset and lack\nthe ability to generalize to out-of-sample data. Moreover, since the number of\nself-expressive coefficients grows quadratically with the number of data\npoints, their ability to handle large-scale datasets is often limited. In this\npaper, we propose a novel framework for subspace clustering, termed\nSelf-Expressive Network (SENet), which employs a properly designed neural\nnetwork to learn a self-expressive representation of the data. We show that our\nSENet can not only learn the self-expressive coefficients with desired\nproperties on the training data, but also handle out-of-sample data. Besides,\nwe show that SENet can also be leveraged to perform subspace clustering on\nlarge-scale datasets. Extensive experiments conducted on synthetic data and\nreal world benchmark data validate the effectiveness of the proposed method. In\nparticular, SENet yields highly competitive performance on MNIST, Fashion MNIST\nand Extended MNIST and state-of-the-art performance on CIFAR-10. The code is\navailable at https://github.com/zhangsz1998/Self-Expressive-Network.",
    "descriptor": "\nComments: 15 pages, 11 figures, 6 tables. The paper is the complete version of the CVPR2021's paper with a set of extra experimental results and a link to download the code\n",
    "authors": [
      "Shangzhi Zhang",
      "Chong You",
      "Ren\u00e9 Vidal",
      "Chun-Guang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04318"
  },
  {
    "id": "arXiv:2110.04320",
    "title": "Constraint-Aware Deep Reinforcement Learning for End-to-End Resource  Orchestration in Mobile Networks",
    "abstract": "Network slicing is a promising technology that allows mobile network\noperators to efficiently serve various emerging use cases in 5G. It is\nchallenging to optimize the utilization of network infrastructures while\nguaranteeing the performance of network slices according to service level\nagreements (SLAs). To solve this problem, we propose SafeSlicing that\nintroduces a new constraint-aware deep reinforcement learning (CaDRL) algorithm\nto learn the optimal resource orchestration policy within two steps, i.e.,\noffline training in a simulated environment and online learning with the real\nnetwork system. On optimizing the resource orchestration, we incorporate the\nconstraints on the statistical performance of slices in the reward function\nusing Lagrangian multipliers, and solve the Lagrangian relaxed problem via a\npolicy network. To satisfy the constraints on the system capacity, we design a\nconstraint network to map the latent actions generated from the policy network\nto the orchestration actions such that the total resources allocated to network\nslices do not exceed the system capacity. We prototype SafeSlicing on an\nend-to-end testbed developed by using OpenAirInterface LTE, OpenDayLight-based\nSDN, and CUDA GPU computing platform. The experimental results show that\nSafeSlicing reduces more than 20% resource usage while meeting SLAs of network\nslices as compared with other solutions.",
    "descriptor": "\nComments: This paper is accepted by IEEE ICNP 2021\n",
    "authors": [
      "Qiang Liu",
      "Nakjung Choi",
      "Tao Han"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.04320"
  },
  {
    "id": "arXiv:2110.04321",
    "title": "Computing an Optimal Pitching Strategy in a Baseball At-Bat",
    "abstract": "The field of quantitative analytics has transformed the world of sports over\nthe last decade. To date, these analytic approaches are statistical at their\ncore, characterizing what is and what was, while using this information to\ndrive decisions about what to do in the future. However, as we often view team\nsports, such as soccer, hockey, and baseball, as pairwise win-lose encounters,\nit seems natural to model these as zero-sum games. We propose such a model for\none important class of sports encounters: a baseball at-bat, which is a matchup\nbetween a pitcher and a batter. Specifically, we propose a novel model of this\nencounter as a zero-sum stochastic game, in which the goal of the batter is to\nget on base, an outcome the pitcher aims to prevent. The value of this game is\nthe on-base percentage (i.e., the probability that the batter gets on base). In\nprinciple, this stochastic game can be solved using classical approaches. The\nmain technical challenges lie in predicting the distribution of pitch locations\nas a function of pitcher intention, predicting the distribution of outcomes if\nthe batter decides to swing at a pitch, and characterizing the level of\npatience of a particular batter. We address these challenges by proposing novel\npitcher and batter representations as well as a novel deep neural network\narchitecture for outcome prediction. Our experiments using Kaggle data from the\n2015 to 2018 Major League Baseball seasons demonstrate the efficacy of the\nproposed approach.",
    "descriptor": "",
    "authors": [
      "Connor Douglas",
      "Everett Witt",
      "Mia Bendy",
      "Yevgeniy Vorobeychik"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.04321"
  },
  {
    "id": "arXiv:2110.04323",
    "title": "Snowy: Recommending Utterances for Conversational Visual Analysis",
    "abstract": "Natural language interfaces (NLIs) have become a prevalent medium for\nconducting visual data analysis, enabling people with varying levels of\nanalytic experience to ask questions of and interact with their data. While\nthere have been notable improvements with respect to language understanding\ncapabilities in these systems, fundamental user experience and interaction\nchallenges including the lack of analytic guidance (i.e., knowing what aspects\nof the data to consider) and discoverability of natural language input (i.e.,\nknowing how to phrase input utterances) persist. To address these challenges,\nwe investigate utterance recommendations that contextually provide analytic\nguidance by suggesting data features (e.g., attributes, values, trends) while\nimplicitly making users aware of the types of phrasings that an NLI supports.\nWe present SNOWY, a prototype system that generates and recommends utterances\nfor visual analysis based on a combination of data interestingness metrics and\nlanguage pragmatics. Through a preliminary user study, we found that utterance\nrecommendations in SNOWY support conversational visual analysis by guiding the\nparticipants' analytic workflows and making them aware of the system's language\ninterpretation capabilities. Based on the feedback and observations from the\nstudy, we discuss potential implications and considerations for incorporating\nrecommendations in future NLIs for visual analysis.",
    "descriptor": "\nComments: To appear at the 2021 ACM Symposium on User Interface Software and Technology (UIST); 17 pages (10 figures, 2 tables)\n",
    "authors": [
      "Arjun Srinivasan",
      "Vidya Setlur"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.04323"
  },
  {
    "id": "arXiv:2110.04326",
    "title": "Near Optimal Interpolation based Time-Limited Model Order Reduction",
    "abstract": "This paper presents an interpolatory framework for time-limited $H_2$ optimal\nmodel order reduction named Limited Time Iterative Rational Krylov Algorithm\n(LT-IRKA). The algorithm yields high fidelity reduced order models over limited\ntime intervals of the form, $\\begin{bmatrix}0 & \\tau \\end{bmatrix}$ with $\\tau\n< \\infty$ for linear time invariant (LTI) systems. Using the time limited $H_2$\nnorm, we derive interpolation based $H_{2,\\tau}$ optimality conditions. The\nLT-IRKA yields a near optimal $H_2(\\tau)$ reduced order system. The nearness to\nthe exact $H_2(\\tau)$ optimal reduced system is quantized in terms of the\nerrors in the interpolation based $H_2(\\tau)$ optimality conditions. We\ndemonstrate with numerical examples how the proposed algorithm nearly satisfies\nthe time-limited optimality conditions and also how it performs with respect to\nthe Time-Limited Two sided Iteration Algorithm (TL-TSIA), the Time-Limited\nBalanced Truncation (TL-BT), the Iterative Rational Krylov Algorithm (IRKA) and\nthe Time-Limited Pseudo Optimal Rational Krylov (TL-PORK) Algorithm over a\nfinite time interval.",
    "descriptor": "",
    "authors": [
      "Kasturi Das",
      "Srinivasan Krishnaswamy",
      "Somanath Majhi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.04326"
  },
  {
    "id": "arXiv:2110.04327",
    "title": "DPUV3INT8: A Compiler View to programmable FPGA Inference Engines",
    "abstract": "We have a FPGA design, we make it fast, efficient, and tested for a few\nimportant examples. Now we must infer a general solution to deploy in the data\ncenter. Here, we describe the FPGA DPUV3INT8 design and our compiler effort.\nThe hand-tuned SW-HW solution for Resnet50\\_v1 has (close to) 2 times better\nimages per second (throughput) than our best FPGA implementation; the compiler\ngeneralizes the hand written techniques achieving about 1.5 times better\nperformance for the same example, the compiler generalizes the optimizations to\na model zoo of networks, and it achieves 80+\\% HW efficiency.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Paolo D'Alberto",
      "Jiangsha Ma",
      "Jintao Li",
      "Yiming Hu",
      "Manasa Bollavaram",
      "Shaoxia Fang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04327"
  },
  {
    "id": "arXiv:2110.04328",
    "title": "Distinguishing rule- and exemplar-based generalization in learning  systems",
    "abstract": "Despite the increasing scale of datasets in machine learning, generalization\nto unseen regions of the data distribution remains crucial. Such extrapolation\nis by definition underdetermined and is dictated by a learner's inductive\nbiases. Machine learning systems often do not share the same inductive biases\nas humans and, as a result, extrapolate in ways that are inconsistent with our\nexpectations. We investigate two distinct such inductive biases: feature-level\nbias (differences in which features are more readily learned) and\nexemplar-vs-rule bias (differences in how these learned features are used for\ngeneralization). Exemplar- vs. rule-based generalization has been studied\nextensively in cognitive psychology, and, in this work, we present a protocol\ninspired by these experimental approaches for directly probing this trade-off\nin learning systems. The measures we propose characterize changes in\nextrapolation behavior when feature coverage is manipulated in a combinatorial\nsetting. We present empirical results across a range of models and across both\nexpository and real-world image and language domains. We demonstrate that\nmeasuring the exemplar-rule trade-off while controlling for feature-level bias\nprovides a more complete picture of extrapolation behavior than existing\nformalisms. We find that most standard neural network models have a propensity\ntowards exemplar-based extrapolation and discuss the implications of these\nfindings for research on data augmentation, fairness, and systematic\ngeneralization.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Ishita Dasgupta",
      "Erin Grant",
      "Thomas L. Griffiths"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04328"
  },
  {
    "id": "arXiv:2110.04330",
    "title": "KG-FiD: Infusing Knowledge Graph in Fusion-in-Decoder for Open-Domain  Question Answering",
    "abstract": "Current Open-Domain Question Answering (ODQA) model paradigm often contains a\nretrieving module and a reading module. Given an input question, the reading\nmodule predicts the answer from the relevant passages which are retrieved by\nthe retriever. The recent proposed Fusion-in-Decoder (FiD), which is built on\ntop of the pretrained generative model T5, achieves the state-of-the-art\nperformance in the reading module. Although being effective, it remains\nconstrained by inefficient attention on all retrieved passages which contain a\nlot of noise. In this work, we propose a novel method KG-FiD, which filters\nnoisy passages by leveraging the structural relationship among the retrieved\npassages with a knowledge graph. We initiate the passage node embedding from\nthe FiD encoder and then use graph neural network (GNN) to update the\nrepresentation for reranking. To improve the efficiency, we build the GNN on\ntop of the intermediate layer output of the FiD encoder and only pass a few top\nreranked passages into the higher layers of encoder and decoder for answer\ngeneration. We also apply the proposed GNN based reranking method to enhance\nthe passage retrieval results in the retrieving module. Extensive experiments\non common ODQA benchmark datasets (Natural Question and TriviaQA) demonstrate\nthat KG-FiD can improve vanilla FiD by up to 1.5% on answer exact match score\nand achieve comparable performance with FiD with only 40% of computation cost.",
    "descriptor": "",
    "authors": [
      "Donghan Yu",
      "Chenguang Zhu",
      "Yuwei Fang",
      "Wenhao Yu",
      "Shuohang Wang",
      "Yichong Xu",
      "Xiang Ren",
      "Yiming Yang",
      "Michael Zeng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04330"
  },
  {
    "id": "arXiv:2110.04332",
    "title": "Using Trust for Heterogeneous Human-Robot Team Task Allocation",
    "abstract": "Human-robot teams have the ability to perform better across various tasks\nthan human-only and robot-only teams. However, such improvements cannot be\nrealized without proper task allocation. Trust is an important factor in\nteaming relationships, and can be used in the task allocation strategy. Despite\nthe importance, most existing task allocation strategies do not incorporate\ntrust. This paper reviews select studies on trust and task allocation. We also\nsummarize and discuss how a bi-directional trust model can be used for a task\nallocation strategy. The bi-directional trust model represents task\nrequirements and agents by their capabilities, and can be used to predict trust\nfor both existing and new tasks. Our task allocation approach uses predicted\ntrust in the agent and expected total reward for task assignment. Finally, we\npresent some directions for future work, including the incorporation of trust\nfrom the human and human capacity for task allocation, and a negotiation phase\nfor resolving task disagreements.",
    "descriptor": "\nComments: Presented at AI-HRI symposium as part of AAAI-FSS 2021 (arXiv:2109.10836)\n",
    "authors": [
      "Arsha Ali",
      "Hebert Azevedo-Sa",
      "Dawn M. Tilbury",
      "Lionel P. Robert Jr"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.04332"
  },
  {
    "id": "arXiv:2110.04334",
    "title": "Using Subobservers to Synthesize Opacity-Enforcing Supervisors",
    "abstract": "In discrete-event system control, the worst-case time complexity for\ncomputing a system's observer is exponential in the number of that system's\nstates. This results in practical difficulties since some problems require\ncalculating multiple observers for a changing system, e.g., synthesizing an\nopacity-enforcing supervisor. Although calculating these observers in an\niterative manner allows us to synthesize an opacity-enforcing supervisor and\nalthough methods have been proposed to reduce the computational demands, room\nexists for a practical and intuitive solution. Here we extend the subautomaton\nrelationship to the notion of a subobserver and demonstrate its use in reducing\nthe computations required for iterated observer calculations. We then\ndemonstrate the subobserver relationship's power by simplifying\nstate-of-the-art synthesis approaches for opacity-enforcing supervisors under\nrealistic assumptions.",
    "descriptor": "\nComments: 28 pages, 7 figures, submitted to Discrete Event Dynamic Systems\n",
    "authors": [
      "Richard Hugh Moulton",
      "Behnam Behinaein Hamgini",
      "Zahra Abedi Khouzani",
      "R\u00f4mulo Meira-G\u00f2es",
      "Fei Wang",
      "Karen Rudie"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.04334"
  },
  {
    "id": "arXiv:2110.04337",
    "title": "Adversarial Token Attacks on Vision Transformers",
    "abstract": "Vision transformers rely on a patch token based self attention mechanism, in\ncontrast to convolutional networks. We investigate fundamental differences\nbetween these two families of models, by designing a block sparsity based\nadversarial token attack. We probe and analyze transformer as well as\nconvolutional models with token attacks of varying patch sizes. We infer that\ntransformer models are more sensitive to token attacks than convolutional\nmodels, with ResNets outperforming Transformer models by up to $\\sim30\\%$ in\nrobust accuracy for single token attacks.",
    "descriptor": "",
    "authors": [
      "Ameya Joshi",
      "Gauri Jagatap",
      "Chinmay Hegde"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04337"
  },
  {
    "id": "arXiv:2110.04339",
    "title": "Local discontinuous Galerkin methods for the abcd nonlinear Boussinesq  system",
    "abstract": "Boussinesq type equations have been widely studied to model the surface water\nwave. In this paper, we consider the abcd Boussinesq system which is a family\nof Boussinesq type equations including many well-known models such as the\nclassical Boussinesq system, BBM-BBM system, Bona-Smith system etc. We propose\nlocal discontinuous Galerkin (LDG) methods, with carefully chosen numerical\nfluxes, to numerically solve this abcd Boussinesq system. The main focus of\nthis paper is to rigorously establish a priori error estimate of the proposed\nLDG methods for a wide range of the parameters a, b, c, d. Numerical\nexperiments are shown to test the convergence rates, and to demonstrate that\nthe proposed methods can simulate the head-on collision of traveling wave and\nfinite time blow-up behavior well.",
    "descriptor": "",
    "authors": [
      "Jiawei Sun",
      "Shusen Xie",
      "Yulong Xing"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.04339"
  },
  {
    "id": "arXiv:2110.04345",
    "title": "A Framework for Private Communication with Secret Block Structure",
    "abstract": "Harnessing a block-sparse prior to recover signals through underdetermined\nlinear measurements has been extensively shown to allow exact recovery in\nconditions where classical compressed sensing would provably fail. We exploit\nthis result to propose a novel private communication framework where the\nsecrecy is achieved by transmitting instances of an unidentifiable compressed\nsensing problem over a public channel. The legitimate receiver can attempt to\novercome this ill-posedness by leveraging secret knowledge of a block structure\nthat was used to encode the transmitter's message. We study the privacy\nguarantees of this communication protocol to a single transmission, and to\nmultiple transmissions without refreshing the shared secret. Additionally, we\npropose an algorithm for an eavesdropper to learn the block structure via the\nmethod of moments and highlight the privacy benefits of this framework through\nnumerical experiments.",
    "descriptor": "",
    "authors": [
      "Maxime Ferreira Da Costa",
      "Urbashi Mitra"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.04345"
  },
  {
    "id": "arXiv:2110.04347",
    "title": "Towards Sample-efficient Apprenticeship Learning from Suboptimal  Demonstration",
    "abstract": "Learning from Demonstration (LfD) seeks to democratize robotics by enabling\nnon-roboticist end-users to teach robots to perform novel tasks by providing\ndemonstrations. However, as demonstrators are typically non-experts, modern LfD\ntechniques are unable to produce policies much better than the suboptimal\ndemonstration. A previously-proposed framework, SSRR, has shown success in\nlearning from suboptimal demonstration but relies on noise-injected\ntrajectories to infer an idealized reward function. A random approach such as\nnoise-injection to generate trajectories has two key drawbacks: 1) Performance\ndegradation could be random depending on whether the noise is applied to vital\nstates and 2) Noise-injection generated trajectories may have limited\nsuboptimality and therefore will not accurately represent the whole scope of\nsuboptimality. We present Systematic Self-Supervised Reward Regression, S3RR,\nto investigate systematic alternatives for trajectory degradation. We carry out\nempirical evaluations and find S3RR can learn comparable or better reward\ncorrelation with ground-truth against a state-of-the-art learning from\nsuboptimal demonstration framework.",
    "descriptor": "\nComments: Presented at AI-HRI symposium as part of AAAI-FSS 2021 (arXiv:2109.10836)\n",
    "authors": [
      "Letian Chen",
      "Rohan Paleja",
      "Matthew Gombolay"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04347"
  },
  {
    "id": "arXiv:2110.04350",
    "title": "FSL: Federated Supermask Learning",
    "abstract": "Federated learning (FL) allows multiple clients with (private) data to\ncollaboratively train a common machine learning model without sharing their\nprivate training data. In-the-wild deployment of FL faces two major hurdles:\nrobustness to poisoning attacks and communication efficiency. To address these\nconcurrently, we propose Federated Supermask Learning (FSL). FSL server trains\na global subnetwork within a randomly initialized neural network by aggregating\nlocal subnetworks of all collaborating clients. FSL clients share local\nsubnetworks in the form of rankings of network edges; more useful edges have\nhigher ranks. By sharing integer rankings, instead of float weights, FSL\nrestricts the space available to craft effective poisoning updates, and by\nsharing subnetworks, FSL reduces the communication cost of training. We show\ntheoretically and empirically that FSL is robust by design and also\nsignificantly communication efficient; all this without compromising clients'\nprivacy. Our experiments demonstrate the superiority of FSL in real-world FL\nsettings; in particular, (1) FSL achieves similar performances as\nstate-of-the-art FedAvg with significantly lower communication costs: for\nCIFAR10, FSL achieves same performance as Federated Averaging while reducing\ncommunication cost by ~35%. (2) FSL is substantially more robust to poisoning\nattacks than state-of-the-art robust aggregation algorithms. We have released\nthe code for reproducibility.",
    "descriptor": "",
    "authors": [
      "Hamid Mozaffari",
      "Virat Shejwalkar",
      "Amir Houmansadr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04350"
  },
  {
    "id": "arXiv:2110.04352",
    "title": "Hankel-structured Tensor Robust PCA for Multivariate Traffic Time Series  Anomaly Detection",
    "abstract": "Spatiotemporal traffic data (e.g., link speed/flow) collected from sensor\nnetworks can be organized as multivariate time series with additional spatial\nattributes. A crucial task in analyzing such data is to identify and detect\nanomalous observations and events from the data with complex spatial and\ntemporal dependencies. Robust Principal Component Analysis (RPCA) is a widely\nused tool for anomaly detection. However, the traditional RPCA purely relies on\nthe global low-rank assumption while ignoring the local temporal correlations.\nIn light of this, this study proposes a Hankel-structured tensor version of\nRPCA for anomaly detection in spatiotemporal data. We treat the raw data with\nanomalies as a multivariate time series matrix (location $\\times$ time) and\nassume the denoised matrix has a low-rank structure. Then we transform the\nlow-rank matrix to a third-order tensor by applying temporal Hankelization. In\nthe end, we decompose the corrupted matrix into a low-rank Hankel tensor and a\nsparse matrix. With the Hankelization operation, the model can simultaneously\ncapture the global and local spatiotemporal correlations and exhibit more\nrobust performance. We formulate the problem as an optimization problem and use\ntensor nuclear norm (TNN) to approximate the tensor rank and $l_1$ norm to\napproximate the sparsity. We develop an efficient solution algorithm based on\nthe Alternating Direction Method of Multipliers (ADMM). Despite having three\nhyper-parameters, the model is easy to set in practice. We evaluate the\nproposed method by synthetic data and metro passenger flow time series and the\nresults demonstrate the accuracy of anomaly detection.",
    "descriptor": "",
    "authors": [
      "Xudong Wang",
      "Luis Miranda-Moreno",
      "Lijun Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04352"
  },
  {
    "id": "arXiv:2110.04353",
    "title": "Learning to Describe Solutions for Bug Reports Based on Developer  Discussions",
    "abstract": "When a software bug is reported, developers engage in a discussion to\ncollaboratively resolve it. While the solution is likely formulated within the\ndiscussion, it is often buried in a large amount of text, making it difficult\nto comprehend, which delays its implementation. To expedite bug resolution, we\npropose generating a concise natural language description of the solution by\nsynthesizing relevant content within the discussion, which encompasses both\nnatural language and source code. Furthermore, to support generating an\ninformative description during an ongoing discussion, we propose a secondary\ntask of determining when sufficient context about the solution emerges in\nreal-time. We construct a dataset for these tasks with a novel technique for\nobtaining noisy supervision from repository changes linked to bug reports. We\nestablish baselines for generating solution descriptions, and develop a\nclassifier which makes a prediction following each new utterance on whether or\nnot the necessary context for performing generation is available. Through\nautomated and human evaluation, we find these tasks to form an ideal testbed\nfor complex reasoning in long, bimodal dialogue context.",
    "descriptor": "",
    "authors": [
      "Sheena Panthaplackel",
      "Junyi Jessy Li",
      "Milos Gligoric",
      "Raymond J. Mooney"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.04353"
  },
  {
    "id": "arXiv:2110.04357",
    "title": "Training Transition Policies via Distribution Matching for Complex Tasks",
    "abstract": "Humans decompose novel complex tasks into simpler ones to exploit previously\nlearned skills. Analogously, hierarchical reinforcement learning seeks to\nleverage lower-level policies for simple tasks to solve complex ones. However,\nbecause each lower-level policy induces a different distribution of states,\ntransitioning from one lower-level policy to another may fail due to an\nunexpected starting state. We introduce transition policies that smoothly\nconnect lower-level policies by producing a distribution of states and actions\nthat matches what is expected by the next policy. Training transition policies\nis challenging because the natural reward signal -- whether the next policy can\nexecute its subtask successfully -- is sparse. By training transition policies\nvia adversarial inverse reinforcement learning to match the distribution of\nexpected states and actions, we avoid relying on task-based reward. To further\nimprove performance, we use deep Q-learning with a binary action space to\ndetermine when to switch from a transition policy to the next pre-trained\npolicy, using the success or failure of the next subtask as the reward.\nAlthough the reward is still sparse, the problem is less severe due to the\nsimple binary action space. We demonstrate our method on continuous bipedal\nlocomotion and arm manipulation tasks that require diverse skills. We show that\nit smoothly connects the lower-level policies, achieving higher success rates\nthan previous methods that search for successful trajectories based on a reward\nfunction, but do not match the state distribution.",
    "descriptor": "",
    "authors": [
      "Ju-Seung Byun",
      "Andrew Perrault"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04357"
  },
  {
    "id": "arXiv:2110.04361",
    "title": "SubTab: Subsetting Features of Tabular Data for Self-Supervised  Representation Learning",
    "abstract": "Self-supervised learning has been shown to be very effective in learning\nuseful representations, and yet much of the success is achieved in data types\nsuch as images, audio, and text. The success is mainly enabled by taking\nadvantage of spatial, temporal, or semantic structure in the data through\naugmentation. However, such structure may not exist in tabular datasets\ncommonly used in fields such as healthcare, making it difficult to design an\neffective augmentation method, and hindering a similar progress in tabular data\nsetting. In this paper, we introduce a new framework, Subsetting features of\nTabular data (SubTab), that turns the task of learning from tabular data into a\nmulti-view representation learning problem by dividing the input features to\nmultiple subsets. We argue that reconstructing the data from the subset of its\nfeatures rather than its corrupted version in an autoencoder setting can better\ncapture its underlying latent representation. In this framework, the joint\nrepresentation can be expressed as the aggregate of latent variables of the\nsubsets at test time, which we refer to as collaborative inference. Our\nexperiments show that the SubTab achieves the state of the art (SOTA)\nperformance of 98.31% on MNIST in tabular setting, on par with CNN-based SOTA\nmodels, and surpasses existing baselines on three other real-world datasets by\na significant margin.",
    "descriptor": "\nComments: NeurIPS 2021. Code can be found at this https URL\n",
    "authors": [
      "Talip Ucar",
      "Ehsan Hajiramezanali",
      "Lindsay Edwards"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04361"
  },
  {
    "id": "arXiv:2110.04363",
    "title": "Certifying Robustness to Programmable Data Bias in Decision Trees",
    "abstract": "Datasets can be biased due to societal inequities, human biases,\nunder-representation of minorities, etc. Our goal is to certify that models\nproduced by a learning algorithm are pointwise-robust to potential dataset\nbiases. This is a challenging problem: it entails learning models for a large,\nor even infinite, number of datasets, ensuring that they all produce the same\nprediction. We focus on decision-tree learning due to the interpretable nature\nof the models. Our approach allows programmatically specifying bias models\nacross a variety of dimensions (e.g., missing data for minorities), composing\ntypes of bias, and targeting bias towards a specific group. To certify\nrobustness, we use a novel symbolic technique to evaluate a decision-tree\nlearner on a large, or infinite, number of datasets, certifying that each and\nevery dataset produces the same prediction for a specific test point. We\nevaluate our approach on datasets that are commonly used in the fairness\nliterature, and demonstrate our approach's viability on a range of bias models.",
    "descriptor": "\nComments: To be published at NeurIPS 2021. 22 pages, 4 figures\n",
    "authors": [
      "Anna P. Meyer",
      "Aws Albarghouthi",
      "Loris D'Antoni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.04363"
  },
  {
    "id": "arXiv:2110.04366",
    "title": "Towards a Unified View of Parameter-Efficient Transfer Learning",
    "abstract": "Fine-tuning large pre-trained language models on downstream tasks has become\nthe de-facto learning paradigm in NLP. However, conventional approaches\nfine-tune all the parameters of the pre-trained model, which becomes\nprohibitive as the model size and the number of tasks grow. Recent work has\nproposed a variety of parameter-efficient transfer learning methods that only\nfine-tune a small number of (extra) parameters to attain strong performance.\nWhile effective, the critical ingredients for success and the connections among\nthe various methods are poorly understood. In this paper, we break down the\ndesign of state-of-the-art parameter-efficient transfer learning methods and\npresent a unified framework that establishes connections between them.\nSpecifically, we re-frame them as modifications to specific hidden states in\npre-trained models, and define a set of design dimensions along which different\nmethods vary, such as the function to compute the modification and the position\nto apply the modification. Through comprehensive empirical studies across\nmachine translation, text summarization, language understanding, and text\nclassification benchmarks, we utilize the unified view to identify important\ndesign choices in previous methods. Furthermore, our unified framework enables\nthe transfer of design elements across different approaches, and as a result we\nare able to instantiate new parameter-efficient fine-tuning methods that tune\nless parameters than previous methods while being more effective, achieving\ncomparable results to fine-tuning all parameters on all four tasks.",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Junxian He",
      "Chunting Zhou",
      "Xuezhe Ma",
      "Taylor Berg-Kirkpatrick",
      "Graham Neubig"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04366"
  },
  {
    "id": "arXiv:2110.04367",
    "title": "Hybrid Random Features",
    "abstract": "We propose a new class of random feature methods for linearizing softmax and\nGaussian kernels called hybrid random features (HRFs) that automatically adapt\nthe quality of kernel estimation to provide most accurate approximation in the\ndefined regions of interest. Special instantiations of HRFs lead to well-known\nmethods such as trigonometric (Rahimi and Recht, 2007) or (recently introduced\nin the context of linear-attention Transformers) positive random features\n(Choromanski et al., 2021). By generalizing Bochner's Theorem for\nsoftmax/Gaussian kernels and leveraging random features for compositional\nkernels, the HRF-mechanism provides strong theoretical guarantees - unbiased\napproximation and strictly smaller worst-case relative errors than its\ncounterparts. We conduct exhaustive empirical evaluation of HRF ranging from\npointwise kernel estimation experiments, through tests on data admitting\nclustering structure to benchmarking implicit-attention Transformers (also for\ndownstream Robotics applications), demonstrating its quality in a wide spectrum\nof machine learning problems.",
    "descriptor": "",
    "authors": [
      "Krzysztof Choromanski",
      "Haoxian Chen",
      "Han Lin",
      "Yuanzhe Ma",
      "Arijit Sehanobish",
      "Deepali Jain",
      "Michael S Ryoo",
      "Jake Varley",
      "Andy Zeng",
      "Valerii Likhosherstov",
      "Dmitry Kalashnikov",
      "Vikas Sindhwani",
      "Adrian Weller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04367"
  },
  {
    "id": "arXiv:2110.04369",
    "title": "A Loss Curvature Perspective on Training Instability in Deep Learning",
    "abstract": "In this work, we study the evolution of the loss Hessian across many\nclassification tasks in order to understand the effect the curvature of the\nloss has on the training dynamics. Whereas prior work has focused on how\ndifferent learning rates affect the loss Hessian observed during training, we\nalso analyze the effects of model initialization, architectural choices, and\ncommon training heuristics such as gradient clipping and learning rate warmup.\nOur results demonstrate that successful model and hyperparameter choices allow\nthe early optimization trajectory to either avoid -- or navigate out of --\nregions of high curvature and into flatter regions that tolerate a higher\nlearning rate. Our results suggest a unifying perspective on how disparate\nmitigation strategies for training instability ultimately address the same\nunderlying failure mode of neural network optimization, namely poor\nconditioning. Inspired by the conditioning perspective, we show that learning\nrate warmup can improve training stability just as much as batch normalization,\nlayer normalization, MetaInit, GradInit, and Fixup initialization.",
    "descriptor": "\nComments: 20 pages, 16 figures\n",
    "authors": [
      "Justin Gilmer",
      "Behrooz Ghorbani",
      "Ankush Garg",
      "Sneha Kudugunta",
      "Behnam Neyshabur",
      "David Cardoze",
      "George Dahl",
      "Zachary Nado",
      "Orhan Firat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04369"
  },
  {
    "id": "arXiv:2110.04371",
    "title": "DispersedLedger: High-Throughput Byzantine Consensus on Variable  Bandwidth Networks",
    "abstract": "The success of blockchains has sparked interest in large-scale deployments of\nByzantine fault tolerant (BFT) consensus protocols over wide area networks. A\ncentral feature of such networks is variable communication bandwidth across\nnodes and across time. We present DispersedLedger, an asynchronous BFT protocol\nthat provides near-optimal throughput in the presence of such variable network\nbandwidth. The core idea of DispersedLedger is to enable nodes to propose,\norder, and agree on blocks of transactions without having to download their\nfull content. By enabling nodes to agree on an ordered log of blocks, with a\nguarantee that each block is available within the network and unmalleable,\nDispersedLedger decouples bandwidth-intensive block downloads at different\nnodes, allowing each to make progress at its own pace. We build a full system\nprototype and evaluate it on real-world and emulated networks. Our results on a\ngeo-distributed wide-area deployment across the Internet shows that\nDispersedLedger achieves 2x better throughput and 74% reduction in latency\ncompared to HoneyBadger, the state-of-the-art asynchronous protocol.",
    "descriptor": "",
    "authors": [
      "Lei Yang",
      "Seo Jin Park",
      "Mohammad Alizadeh",
      "Sreeram Kannan",
      "David Tse"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.04371"
  },
  {
    "id": "arXiv:2110.04372",
    "title": "Fair Regression under Sample Selection Bias",
    "abstract": "Recent research on fair regression focused on developing new fairness notions\nand approximation methods as target variables and even the sensitive attribute\nare continuous in the regression setting. However, all previous fair regression\nresearch assumed the training data and testing data are drawn from the same\ndistributions. This assumption is often violated in real world due to the\nsample selection bias between the training and testing data. In this paper, we\ndevelop a framework for fair regression under sample selection bias when\ndependent variable values of a set of samples from the training data are\nmissing as a result of another hidden process. Our framework adopts the classic\nHeckman model for bias correction and the Lagrange duality to achieve fairness\nin regression based on a variety of fairness notions. Heckman model describes\nthe sample selection process and uses a derived variable called the Inverse\nMills Ratio (IMR) to correct sample selection bias. We use fairness inequality\nand equality constraints to describe a variety of fairness notions and apply\nthe Lagrange duality theory to transform the primal problem into the dual\nconvex optimization. For the two popular fairness notions, mean difference and\nmean squared error difference, we derive explicit formulas without iterative\noptimization, and for Pearson correlation, we derive its conditions of\nachieving strong duality. We conduct experiments on three real-world datasets\nand the experimental results demonstrate the approach's effectiveness in terms\nof both utility and fairness metrics.",
    "descriptor": "",
    "authors": [
      "Wei Du",
      "Xintao Wu",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.04372"
  },
  {
    "id": "arXiv:2110.04374",
    "title": "A Few More Examples May Be Worth Billions of Parameters",
    "abstract": "We investigate the dynamics of increasing the number of model parameters\nversus the number of labeled examples across a wide variety of tasks. Our\nexploration reveals that while scaling parameters consistently yields\nperformance improvements, the contribution of additional examples highly\ndepends on the task's format. Specifically, in open question answering tasks,\nenlarging the training set does not improve performance. In contrast,\nclassification, extractive question answering, and multiple choice tasks\nbenefit so much from additional examples that collecting a few hundred examples\nis often \"worth\" billions of parameters. We hypothesize that unlike open\nquestion answering, which involves recalling specific information, solving\nstrategies for tasks with a more restricted output space transfer across\nexamples, and can therefore be learned with small amounts of labeled data.",
    "descriptor": "",
    "authors": [
      "Yuval Kirstain",
      "Patrick Lewis",
      "Sebastian Riedel",
      "Omer Levy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04374"
  },
  {
    "id": "arXiv:2110.04375",
    "title": "Neural Link Prediction with Walk Pooling",
    "abstract": "Graph neural networks achieve high accuracy in link prediction by jointly\nleveraging graph topology and node attributes. Topology, however, is\nrepresented indirectly; state-of-the-art methods based on subgraph\nclassification label nodes with distance to the target link, so that, although\ntopological information is present, it is tempered by pooling. This makes it\nchallenging to leverage features like loops and motifs associated with network\nformation mechanisms. We propose a link prediction algorithm based on a new\npooling scheme called WalkPool. WalkPool combines the expressivity of\ntopological heuristics with the feature-learning ability of neural networks. It\nsummarizes a putative link by random walk probabilities of adjacent paths.\nInstead of extracting transition probabilities from the original graph, it\ncomputes the transition matrix of a \"predictive\" latent graph by applying\nattention to learned features; this may be interpreted as feature-sensitive\ntopology fingerprinting. WalkPool can leverage unsupervised node features or be\ncombined with GNNs and trained end-to-end. It outperforms state-of-the-art\nmethods on all common link prediction benchmarks, both homophilic and\nheterophilic, with and without node attributes. Applying WalkPool to a set of\nunsupervised GNNs significantly improves prediction accuracy, suggesting that\nit may be used as a general-purpose graph pooling scheme.",
    "descriptor": "",
    "authors": [
      "Liming Pan",
      "Cheng Shi",
      "Ivan Dokmani\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.04375"
  },
  {
    "id": "arXiv:2110.04383",
    "title": "Learning 3D Representations of Molecular Chirality with Invariance to  Bond Rotations",
    "abstract": "Molecular chirality, a form of stereochemistry most often describing relative\nspatial arrangements of bonded neighbors around tetrahedral carbon centers,\ninfluences the set of 3D conformers accessible to the molecule without changing\nits 2D graph connectivity. Chirality can strongly alter (bio)chemical\ninteractions, particularly protein-drug binding. Most 2D graph neural networks\n(GNNs) designed for molecular property prediction at best use atomic labels to\nna\\\"ively treat chirality, while E(3)-invariant 3D GNNs are invariant to\nchirality altogether. To enable representation learning on molecules with\ndefined stereochemistry, we design an SE(3)-invariant model that processes\ntorsion angles of a 3D molecular conformer. We explicitly model conformational\nflexibility by integrating a novel type of invariance to rotations about\ninternal molecular bonds into the architecture, mitigating the need for\nmulti-conformer data augmentation. We test our model on four benchmarks:\ncontrastive learning to distinguish conformers of different stereoisomers in a\nlearned latent space, classification of chiral centers as R/S, prediction of\nhow enantiomers rotate circularly polarized light, and ranking enantiomers by\ntheir docking scores in an enantiosensitive protein pocket. We compare our\nmodel, Chiral InterRoto-Invariant Neural Network (ChIRo), with 2D and 3D GNNs\nto demonstrate that our model achieves state of the art performance when\nlearning chiral-sensitive functions from molecular structures.",
    "descriptor": "",
    "authors": [
      "Keir Adams",
      "Lagnajit Pattanaik",
      "Connor W. Coley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04383"
  },
  {
    "id": "arXiv:2110.04384",
    "title": "Evaluation of Summarization Systems across Gender, Age, and Race",
    "abstract": "Summarization systems are ultimately evaluated by human annotators and\nraters. Usually, annotators and raters do not reflect the demographics of end\nusers, but are recruited through student populations or crowdsourcing platforms\nwith skewed demographics. For two different evaluation scenarios -- evaluation\nagainst gold summaries and system output ratings -- we show that summary\nevaluation is sensitive to protected attributes. This can severely bias system\ndevelopment and evaluation, leading us to build models that cater for some\ngroups rather than others.",
    "descriptor": "",
    "authors": [
      "Anna J\u00f8rgensen",
      "Anders S\u00f8gaard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04384"
  },
  {
    "id": "arXiv:2110.04390",
    "title": "Multi-Agent Autonomy: Advancements and Challenges in Subterranean  Exploration",
    "abstract": "Artificial intelligence has undergone immense growth and maturation in recent\nyears, though autonomous systems have traditionally struggled when fielded in\ndiverse and previously unknown environments. DARPA is seeking to change that\nwith the Subterranean Challenge, by providing roboticists the opportunity to\nsupport civilian and military first responders in complex and high-risk\nunderground scenarios. The subterranean domain presents a handful of\nchallenges, such as limited communication, diverse topology and terrain, and\ndegraded sensing. Team MARBLE proposes a solution for autonomous exploration of\nunknown subterranean environments in which coordinated agents search for\nartifacts of interest. The team presents two navigation algorithms in the form\nof a metric-topological graph-based planner and a continuous frontier-based\nplanner. To facilitate multi-agent coordination, agents share and merge new map\ninformation and candidate goal-points. Agents deploy communication beacons at\ndifferent points in the environment, extending the range at which maps and\nother information can be shared. Onboard autonomy reduces the load on human\nsupervisors, allowing agents to detect and localize artifacts and explore\nautonomously outside established communication networks. Given the scale,\ncomplexity, and tempo of this challenge, a range of lessons were learned, most\nimportantly, that frequent and comprehensive field testing in representative\nenvironments is key to rapidly refining system performance.",
    "descriptor": "\nComments: 39 pages, 21 figures, Field Robotics special issue: Advancements and lessons learned during Phase I & II of the DARPA Subterranean Challenge\n",
    "authors": [
      "Michael T. Ohradzansky",
      "Eugene R. Rush",
      "Danny G. Riley",
      "Andrew B. Mills",
      "Shakeeb Ahmad",
      "Steve McGuire",
      "Harel Biggie",
      "Kyle Harlow",
      "Michael J. Miles",
      "Eric W. Frew",
      "Christoffer Heckman",
      "J. Sean Humbert"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.04390"
  },
  {
    "id": "arXiv:2110.04392",
    "title": "The Eval4NLP Shared Task on Explainable Quality Estimation: Overview and  Results",
    "abstract": "In this paper, we introduce the Eval4NLP-2021shared task on explainable\nquality estimation. Given a source-translation pair, this shared task requires\nnot only to provide a sentence-level score indicating the overall quality of\nthe translation, but also to explain this score by identifying the words that\nnegatively impact translation quality. We present the data, annotation\nguidelines and evaluation setup of the shared task, describe the six\nparticipating systems, and analyze the results. To the best of our knowledge,\nthis is the first shared task on explainable NLP evaluation metrics. Datasets\nand results are available at https://github.com/eval4nlp/SharedTask2021.",
    "descriptor": "",
    "authors": [
      "Marina Fomicheva",
      "Piyawat Lertvittayakumjorn",
      "Wei Zhao",
      "Steffen Eger",
      "Yang Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04392"
  },
  {
    "id": "arXiv:2110.04393",
    "title": "Randomized algorithms for rounding in the Tensor-Train format",
    "abstract": "The Tensor-Train (TT) format is a highly compact low-rank representation for\nhigh-dimensional tensors. TT is particularly useful when representing\napproximations to the solutions of certain types of parametrized partial\ndifferential equations. For many of these problems, computing the solution\nexplicitly would require an infeasible amount of memory and computational time.\nWhile the TT format makes these problems tractable, iterative techniques for\nsolving the PDEs must be adapted to perform arithmetic while maintaining the\nimplicit structure. The fundamental operation used to maintain feasible memory\nand computational time is called rounding, which truncates the internal ranks\nof a tensor already in TT format. We propose several randomized algorithms for\nthis task that are generalizations of randomized low-rank matrix approximation\nalgorithms and provide significant reduction in computation compared to\ndeterministic TT-rounding algorithms. Randomization is particularly effective\nin the case of rounding a sum of TT-tensors (where we observe 20x speedup),\nwhich is the bottleneck computation in the adaptation of GMRES to vectors in TT\nformat. We present the randomized algorithms and compare their empirical\naccuracy and computational time with deterministic alternatives.",
    "descriptor": "",
    "authors": [
      "Hussam Al Daas",
      "Grey Ballard",
      "Paul Cazeaux",
      "Eric Hallman",
      "Agnieszka Miedlar",
      "Mirjeta Pasha",
      "Tim W. Reid",
      "Arvind K. Saibaba"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.04393"
  },
  {
    "id": "arXiv:2110.04394",
    "title": "Identifiying blockchain-based cryptocurrency accounts using investment  portfolios",
    "abstract": "Cryptocurrencies based on decentralized systems, especially blockchain, are\ngaining popularity more than ever. Freedom advocates hail blockchain technology\nas a breakthrough in digital privacy and internet anonymity. Unfortunately,\nafter recent studies conducted, it may come as a surprise that the transactions\nare, in fact, not always anonymous. In this short paper, the possibility of\nidentifying a user's accounts in different cryptocurrencies given the user's\nportfolio of investment gained from social media is investigated. In this\nstudy, the generic elements of blockchain systems are briefly studied. In\nsection \\ref{sec:blocksim}, BlockSim which is a tool for simulating\ntransactions, and an algorithm for answering this question is introduced.",
    "descriptor": "",
    "authors": [
      "Amin Aghaee"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.04394"
  },
  {
    "id": "arXiv:2110.04397",
    "title": "Measure Twice, Cut Once: Quantifying Bias and Fairness in Deep Neural  Networks",
    "abstract": "Algorithmic bias is of increasing concern, both to the research community,\nand society at large. Bias in AI is more abstract and unintuitive than\ntraditional forms of discrimination and can be more difficult to detect and\nmitigate. A clear gap exists in the current literature on evaluating the\nrelative bias in the performance of multi-class classifiers. In this work, we\npropose two simple yet effective metrics, Combined Error Variance (CEV) and\nSymmetric Distance Error (SDE), to quantitatively evaluate the class-wise bias\nof two models in comparison to one another. By evaluating the performance of\nthese new metrics and by demonstrating their practical application, we show\nthat they can be used to measure fairness as well as bias. These demonstrations\nshow that our metrics can address specific needs for measuring bias in\nmulti-class classification.",
    "descriptor": "",
    "authors": [
      "Cody Blakeney",
      "Gentry Atkinson",
      "Nathaniel Huish",
      "Yan Yan",
      "Vangelis Metris",
      "Ziliang Zong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.04397"
  },
  {
    "id": "arXiv:2110.04398",
    "title": "The Role of Masks in Mitigating Viral Spread on Networks",
    "abstract": "Masks have remained an important mitigation strategy in the fight against\nCOVID-19 due to their ability to prevent the transmission of respiratory\ndroplets between individuals. In this work, we provide a comprehensive\nquantitative analysis of the impact of mask-wearing. To this end, we propose a\nnovel agent-based model of viral spread on networks where agents may either\nwear no mask, or wear one of several types of masks with different properties\n(e.g., cloth or surgical). We derive analytical expressions for three key\nepidemiological quantities: the probability of emergence, the epidemic\nthreshold, and the expected epidemic size. In particular, we show how the\naforementioned quantities depend on the structure of the contact network, viral\ntransmission dynamics, and the distribution of the different types of masks\nwithin the population. We then investigate the impact of different allocations\nof masks within the population through extensive simulations. We also\ninvestigate tradeoffs between masks with high outward efficiency but low inward\nefficiency and masks with high inward efficiency but low outward efficiency.\nInterestingly, we find that the former type of mask is most useful for\ncontrolling the spread in the early stages of an epidemic, while the latter\ntype is most useful in mitigating the impact of an already large spread.",
    "descriptor": "",
    "authors": [
      "Yurun Tian",
      "Anirudh Sridhar",
      "H.Vincent Poor",
      "Osman Yagan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.04398"
  },
  {
    "id": "arXiv:2110.04399",
    "title": "Global Explainability of BERT-Based Evaluation Metrics by Disentangling  along Linguistic Factors",
    "abstract": "Evaluation metrics are a key ingredient for progress of text generation\nsystems. In recent years, several BERT-based evaluation metrics have been\nproposed (including BERTScore, MoverScore, BLEURT, etc.) which correlate much\nbetter with human assessment of text generation quality than BLEU or ROUGE,\ninvented two decades ago. However, little is known what these metrics, which\nare based on black-box language model representations, actually capture (it is\ntypically assumed they model semantic similarity). In this work, we \\wei{use a\nsimple regression based global explainability technique to} disentangle metric\nscores along linguistic factors, including semantics, syntax, morphology, and\nlexical overlap. We show that the different metrics capture all aspects to some\ndegree, but that they are all substantially sensitive to lexical overlap, just\nlike BLEU and ROUGE. This exposes limitations of these novelly proposed\nmetrics, which we also highlight in an adversarial test scenario.",
    "descriptor": "\nComments: EMNLP2021 Camera Ready\n",
    "authors": [
      "Marvin Kaster",
      "Wei Zhao",
      "Steffen Eger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04399"
  },
  {
    "id": "arXiv:2110.04400",
    "title": "HydraSum -- Disentangling Stylistic Features in Text Summarization using  Multi-Decoder Models",
    "abstract": "Existing abstractive summarization models lack explicit control mechanisms\nthat would allow users to influence the stylistic features of the model\noutputs. This results in generating generic summaries that do not cater to the\nusers needs or preferences. To address this issue we introduce HydraSum, a new\nsummarization architecture that extends the single decoder framework of current\nmodels, e.g. BART, to a mixture-of-experts version consisting of multiple\ndecoders. Our proposed model encourages each expert, i.e. decoder, to learn and\ngenerate stylistically-distinct summaries along dimensions such as\nabstractiveness, length, specificity, and others. At each time step, HydraSum\nemploys a gating mechanism that decides the contribution of each individual\ndecoder to the next token's output probability distribution. Through\nexperiments on three summarization datasets (CNN, Newsroom, XSum), we\ndemonstrate that this gating mechanism automatically learns to assign\ncontrasting summary styles to different HydraSum decoders under the standard\ntraining objective without the need for additional supervision. We further show\nthat a guided version of the training process can explicitly govern which\nsummary style is partitioned between decoders, e.g. high abstractiveness vs.\nlow abstractiveness or high specificity vs. low specificity, and also increase\nthe stylistic-difference between individual decoders. Finally, our experiments\ndemonstrate that our decoder framework is highly flexible: during inference, we\ncan sample from individual decoders or mixtures of different subsets of the\ndecoders to yield a diverse set of summaries and enforce single- and\nmulti-style control over summary generation.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Tanya Goyal",
      "Nazneen Fatema Rajani",
      "Wenhao Liu",
      "Wojciech Kry\u015bci\u0144ski"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04400"
  },
  {
    "id": "arXiv:2110.04402",
    "title": "Walking into the complex plane to 'order' better time integrators",
    "abstract": "Most numerical methods for time integration use real time steps. Complex time\nsteps provide an additional degree of freedom, as we can select the magnitude\nof the step in both the real and imaginary directions. By time stepping along\nspecific paths in the complex plane, integrators can gain higher orders of\naccuracy or achieve expanded stability regions. Complex time stepping also\nallows us to break the Runge-Kutta order barrier, enabling 5th order accuracy\nusing only five function evaluations. We show how to derive these paths for\nexplicit and implicit methods, discuss computational costs and storage\nbenefits, and demonstrate clear advantages for complex-valued systems like the\nSchrodinger equation.",
    "descriptor": "\nComments: 30 pages, 15 figures\n",
    "authors": [
      "Jithin D. George",
      "Samuel Y. Jung",
      "Niall M. Mangan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Complex Variables (math.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04402"
  },
  {
    "id": "arXiv:2110.04403",
    "title": "Temperature as Uncertainty in Contrastive Learning",
    "abstract": "Contrastive learning has demonstrated great capability to learn\nrepresentations without annotations, even outperforming supervised baselines.\nHowever, it still lacks important properties useful for real-world application,\none of which is uncertainty. In this paper, we propose a simple way to generate\nuncertainty scores for many contrastive methods by re-purposing temperature, a\nmysterious hyperparameter used for scaling. By observing that temperature\ncontrols how sensitive the objective is to specific embedding locations, we aim\nto learn temperature as an input-dependent variable, treating it as a measure\nof embedding confidence. We call this approach \"Temperature as Uncertainty\", or\nTaU. Through experiments, we demonstrate that TaU is useful for\nout-of-distribution detection, while remaining competitive with benchmarks on\nlinear evaluation. Moreover, we show that TaU can be learned on top of\npretrained models, enabling uncertainty scores to be generated post-hoc with\npopular off-the-shelf models. In summary, TaU is a simple yet versatile method\nfor generating uncertainties for contrastive learning. Open source code can be\nfound at: https://github.com/mhw32/temperature-as-uncertainty-public.",
    "descriptor": "\nComments: 4 pages content; 1 page supplement\n",
    "authors": [
      "Oliver Zhang",
      "Mike Wu",
      "Jasmine Bayrooti",
      "Noah Goodman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04403"
  },
  {
    "id": "arXiv:2110.04406",
    "title": "Accessible Visualization via Natural Language Descriptions: A Four-Level  Model of Semantic Content",
    "abstract": "Natural language descriptions sometimes accompany visualizations to better\ncommunicate and contextualize their insights, and to improve their\naccessibility for readers with disabilities. However, it is difficult to\nevaluate the usefulness of these descriptions, and how effectively they improve\naccess to meaningful information, because we have little understanding of the\nsemantic content they convey, and how different readers receive this content.\nIn response, we introduce a conceptual model for the semantic content conveyed\nby natural language descriptions of visualizations. Developed through a\ngrounded theory analysis of 2,147 sentences, our model spans four levels of\nsemantic content: enumerating visualization construction properties (e.g.,\nmarks and encodings); reporting statistical concepts and relations (e.g.,\nextrema and correlations); identifying perceptual and cognitive phenomena\n(e.g., complex trends and patterns); and elucidating domain-specific insights\n(e.g., social and political context). To demonstrate how our model can be\napplied to evaluate the effectiveness of visualization descriptions, we conduct\na mixed-methods evaluation with 30 blind and 90 sighted readers, and find that\nthese reader groups differ significantly on which semantic content they rank as\nmost useful. Together, our model and findings suggest that access to meaningful\ninformation is strongly reader-specific, and that research in automatic\nvisualization captioning should orient toward descriptions that more richly\ncommunicate overall trends and statistics, sensitive to reader preferences. Our\nwork further opens a space of research on natural language as a data interface\ncoequal with visualization.",
    "descriptor": "\nComments: An accessible HTML version of the article is available at: this http URL\n",
    "authors": [
      "Alan Lundgard",
      "Arvind Satyanarayan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04406"
  },
  {
    "id": "arXiv:2110.04411",
    "title": "Unsupervised Pose-Aware Part Decomposition for 3D Articulated Objects",
    "abstract": "Articulated objects exist widely in the real world. However, previous 3D\ngenerative methods for unsupervised part decomposition are unsuitable for such\nobjects, because they assume a spatially fixed part location, resulting in\ninconsistent part parsing. In this paper, we propose PPD (unsupervised\nPose-aware Part Decomposition) to address a novel setting that explicitly\ntargets man-made articulated objects with mechanical joints, considering the\npart poses. We show that category-common prior learning for both part shapes\nand poses facilitates the unsupervised learning of (1) part decomposition with\nnon-primitive-based implicit representation, and (2) part pose as joint\nparameters under single-frame shape supervision. We evaluate our method on\nsynthetic and real datasets, and we show that it outperforms previous works in\nconsistent part parsing of the articulated objects based on comparable part\npose estimation performance to the supervised baseline.",
    "descriptor": "",
    "authors": [
      "Yuki Kawana",
      "Yusuke Mukuta",
      "Tatsuya Harada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04411"
  },
  {
    "id": "arXiv:2110.04412",
    "title": "Mobile 3D Printing Robot Simulation with Viscoelastic Fluids",
    "abstract": "The system design and algorithm development of mobile 3D printing robots need\na realistic simulation. They require a mobile robot simulation platform to\ninteroperate with a physics-based material simulation for handling interactions\nbetween the time-variant deformable 3D printing materials and other simulated\nrigid bodies in the environment, which is not available for roboticists yet. To\nbridge this gap and enable the real-time simulation of mobile 3D printing\nprocesses, we develop a simulation framework that includes particle-based\nviscoelastic fluid simulation and particle-to-mesh conversion in the widely\nadopted Gazebo robotics simulator, avoiding the bottlenecks of traditional\nadditive manufacturing simulation approaches. This framework is the first of\nits kind that enables the simulation of robot arms or mobile manipulators\ntogether with viscoelastic fluids. The method is tested using various material\nproperties and multiple collaborating robots to demonstrate its simulation\nability for the robots to plan and control the printhead trajectories and to\nvisually sense at the same time the printed fluid materials as a free-form\nmesh. The scalability as a function of available material particles in the\nsimulation was also studied. A simulation with an average of 5 FPS was achieved\non a regular desktop computer.",
    "descriptor": "\nComments: IROS 2021 Conference in the Simulation Category, 7 pages total, 2 are references\n",
    "authors": [
      "Uljad Berdica",
      "Yuewei Fu",
      "Yuchen Liu",
      "Emmanouil Angelidis",
      "Chen Feng"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.04412"
  },
  {
    "id": "arXiv:2110.04413",
    "title": "Robustness Evaluation of Transformer-based Form Field Extractors via  Form Attacks",
    "abstract": "We propose a novel framework to evaluate the robustness of transformer-based\nform field extraction methods via form attacks. We introduce 14 novel form\ntransformations to evaluate the vulnerability of the state-of-the-art field\nextractors against form attacks from both OCR level and form level, including\nOCR location/order rearrangement, form background manipulation and form\nfield-value augmentation. We conduct robustness evaluation using real invoices\nand receipts, and perform comprehensive research analysis. Experimental results\nsuggest that the evaluated models are very susceptible to form perturbations\nsuch as the variation of field-values (~15% drop in F1 score), the\ndisarrangement of input text order(~15% drop in F1 score) and the disruption of\nthe neighboring words of field-values(~10% drop in F1 score). Guided by the\nanalysis, we make recommendations to improve the design of field extractors and\nthe process of data collection.",
    "descriptor": "",
    "authors": [
      "Le Xue",
      "Mingfei Gao",
      "Zeyuan Chen",
      "Caiming Xiong",
      "Ran Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04413"
  },
  {
    "id": "arXiv:2110.04414",
    "title": "Gated recurrent units and temporal convolutional network for multilabel  classification",
    "abstract": "Multilabel learning tackles the problem of associating a sample with multiple\nclass labels. This work proposes a new ensemble method for managing multilabel\nclassification: the core of the proposed approach combines a set of gated\nrecurrent units and temporal convolutional neural networks trained with\nvariants of the Adam optimization approach. Multiple Adam variants, including\nnovel one proposed here, are compared and tested; these variants are based on\nthe difference between present and past gradients, with step size adjusted for\neach parameter. The proposed neural network approach is also combined with\nIncorporating Multiple Clustering Centers (IMCC), which further boosts\nclassification performance. Multiple experiments on nine data sets representing\na wide variety of multilabel tasks demonstrate the robustness of our best\nensemble, which is shown to outperform the state-of-the-art. The MATLAB code\nfor generating the best ensembles in the experimental section will be available\nat https://github.com/LorisNanni.",
    "descriptor": "",
    "authors": [
      "Loris Nanni",
      "Alessandra Lumini",
      "Alessandro Manfe",
      "Sheryl Brahnam",
      "Giorgio Venturin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04414"
  },
  {
    "id": "arXiv:2110.04418",
    "title": "Moral-Trust Violation vs Performance-Trust Violation by a Robot: Which  Hurts More?",
    "abstract": "In recent years a modern conceptualization of trust in human-robot\ninteraction (HRI) was introduced by Ullman et al.\\cite{ullman2018does}. This\nnew conceptualization of trust suggested that trust between humans and robots\nis multidimensional, incorporating both performance aspects (i.e., similar to\nthe trust in human-automation interaction) and moral aspects (i.e., similar to\nthe trust in human-human interaction). But how does a robot violating each of\nthese different aspects of trust affect human trust in a robot? How does trust\nin robots change when a robot commits a moral-trust violation compared to a\nperformance-trust violation? And whether physiological signals have the\npotential to be used for assessing gain/loss of each of these two trust aspects\nin a human. We aim to design an experiment to study the effects of\nperformance-trust violation and moral-trust violation separately in a search\nand rescue task. We want to see whether two failures of a robot with equal\nmagnitudes would affect human trust differently if one failure is due to a\nperformance-trust violation and the other is a moral-trust violation.",
    "descriptor": "\nComments: Presented at AI-HRI symposium as part of AAAI-FSS 2021 (arXiv:2109.10836)\n",
    "authors": [
      "Zahra Rezaei Khavas",
      "Russell Perkins",
      "S.Reza Ahmadzadeh",
      "Paul Robinette"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04418"
  },
  {
    "id": "arXiv:2110.04419",
    "title": "Detecting Community Sensitive Norm Violations in Online Conversations",
    "abstract": "Online platforms and communities establish their own norms that govern what\nbehavior is acceptable within the community. Substantial effort in NLP has\nfocused on identifying unacceptable behaviors and, recently, on forecasting\nthem before they occur. However, these efforts have largely focused on toxicity\nas the sole form of community norm violation. Such focus has overlooked the\nmuch larger set of rules that moderators enforce. Here, we introduce a new\ndataset focusing on a more complete spectrum of community norms and their\nviolations in the local conversational and global community contexts. We\nintroduce a series of models that use this data to develop context- and\ncommunity-sensitive norm violation detection, showing that these changes give\nhigh performance.",
    "descriptor": "\nComments: Findings of EMNLP 2021\n",
    "authors": [
      "Chan Young Park",
      "Julia Mendelsohn",
      "Karthik Radhakrishnan",
      "Kinjal Jain",
      "Tushar Kanakagiri",
      "David Jurgens",
      "Yulia Tsvetkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04419"
  },
  {
    "id": "arXiv:2110.04420",
    "title": "An optimization-based strategy for peridynamic-FEM coupling and for the  prescription of nonlocal boundary conditions",
    "abstract": "We develop and analyze an optimization-based method for the coupling of a\nstatic peri-dynamic (PD) model and a static classical elasticity model. The\napproach formulates the coupling as a control problem in which the states are\nthe solutions of the PD and classical equations, the objective is to minimize\ntheir mismatch on an overlap of the PD and classical domains, and the controls\nare virtual volume constraints and boundary conditions applied at the\nlocal-nonlocal interface. Our numerical tests performed on three-dimensional\ngeometries illustrate the consistency and accuracy of our method, its numerical\nconvergence, and its applicability to realistic engineering geometries. We\ndemonstrate the coupling strategy as a means to reduce computational expense by\nconfining the nonlocal model to a subdomain of interest, and as a means to\ntransmit local (e.g., traction) boundary conditions applied at a surface to a\nnonlocal model in the bulk of the domain.",
    "descriptor": "\nComments: 25 pages, 11 figures\n",
    "authors": [
      "Marta D'Elia",
      "David Littlewood",
      "Jeremy Trageser",
      "Mauro Perego",
      "Pavel Bochev"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.04420"
  },
  {
    "id": "arXiv:2110.04421",
    "title": "DeepABM: Scalable, efficient and differentiable agent-based simulations  via graph neural networks",
    "abstract": "We introduce DeepABM, a framework for agent-based modeling that leverages\ngeometric message passing of graph neural networks for simulating action and\ninteractions over large agent populations. Using DeepABM allows scaling\nsimulations to large agent populations in real-time and running them\nefficiently on GPU architectures. To demonstrate the effectiveness of DeepABM,\nwe build DeepABM-COVID simulator to provide support for various\nnon-pharmaceutical interventions (quarantine, exposure notification,\nvaccination, testing) for the COVID-19 pandemic, and can scale to populations\nof representative size in real-time on a GPU. Specifically, DeepABM-COVID can\nmodel 200 million interactions (over 100,000 agents across 180 time-steps) in\n90 seconds, and is made available online to help researchers with modeling and\nanalysis of various interventions. We explain various components of the\nframework and discuss results from one research study to evaluate the impact of\ndelaying the second dose of the COVID-19 vaccine in collaboration with clinical\nand public health experts. While we simulate COVID-19 spread, the ideas\nintroduced in the paper are generic and can be easily extend to other forms of\nagent-based simulations. Furthermore, while beyond scope of this document,\nDeepABM enables inverse agent-based simulations which can be used to learn\nphysical parameters in the (micro) simulations using gradient-based\noptimization with large-scale real-world (macro) data. We are optimistic that\nthe current work can have interesting implications for bringing ABM and AI\ncommunities closer.",
    "descriptor": "\nComments: Accepted at Winter Simulation Conference 2021\n",
    "authors": [
      "Ayush Chopra",
      "Esma Gel",
      "Jayakumar Subramanian",
      "Balaji Krishnamurthy",
      "Santiago Romero-Brufau",
      "Kalyan S. Pasupathy",
      "Thomas C. Kingsley",
      "Ramesh Raskar"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04421"
  },
  {
    "id": "arXiv:2110.04422",
    "title": "Theoretically Principled Deep RL Acceleration via Nearest Neighbor  Function Approximation",
    "abstract": "Recently, deep reinforcement learning (RL) has achieved remarkable empirical\nsuccess by integrating deep neural networks into RL frameworks. However, these\nalgorithms often require a large number of training samples and admit little\ntheoretical understanding. To mitigate these issues, we propose a theoretically\nprincipled nearest neighbor (NN) function approximator that can improve the\nvalue networks in deep RL methods. Inspired by human similarity judgments, the\nNN approximator estimates the action values using rollouts on past observations\nand can provably obtain a small regret bound that depends only on the intrinsic\ncomplexity of the environment. We present (1) Nearest Neighbor Actor-Critic\n(NNAC), an online policy gradient algorithm that demonstrates the practicality\nof combining function approximation with deep RL, and (2) a plug-and-play NN\nupdate module that aids the training of existing deep RL methods. Experiments\non classical control and MuJoCo locomotion tasks show that the NN-accelerated\nagents achieve higher sample efficiency and stability than the baseline agents.\nBased on its theoretical benefits, we believe that the NN approximator can be\nfurther applied to other complex domains to speed-up learning.",
    "descriptor": "",
    "authors": [
      "Junhong Shen",
      "Lin F. Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04422"
  },
  {
    "id": "arXiv:2110.04425",
    "title": "Arabic Speech Emotion Recognition Employing Wav2vec2.0 and HuBERT Based  on BAVED Dataset",
    "abstract": "Recently, there have been tremendous research outcomes in the fields of\nspeech recognition and natural language processing. This is due to the\nwell-developed multi-layers deep learning paradigms such as wav2vec2.0,\nWav2vecU, WavBERT, and HuBERT that provide better representation learning and\nhigh information capturing. Such paradigms run on hundreds of unlabeled data,\nthen fine-tuned on a small dataset for specific tasks. This paper introduces a\ndeep learning constructed emotional recognition model for Arabic speech\ndialogues. The developed model employs the state of the art audio\nrepresentations include wav2vec2.0 and HuBERT. The experiment and performance\nresults of our model overcome the previous known outcomes.",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "Omar Mohamed",
      "Salah A. Aly"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04425"
  },
  {
    "id": "arXiv:2110.04426",
    "title": "Vision-based Navigation for a Small-scale Quadruped Robot Pegasus-Mini",
    "abstract": "Quadruped locomotion is currently a vibrant research area, which has reached\na level of maturity and performance that enables some of the most advanced\nreal-world applications with autonomous quadruped robots both in academia and\nindustry. Blind robust quadruped locomotion has been pushed forward in control\nand technology aspects within recent decades. However, in the complicated\nenvironment, the capability including terrain perception and path planning is\nstill required. Visual perception is an indispensable ability in legged\nlocomotion for such a demand. This study explores a vision-based navigation\nmethod for a small-scale quadruped robot Pegasus-Mini, aiming to propose a\nmethod that enables efficient and reliable navigation for the small-scale\nquadruped locomotion. The vision-based navigation method proposed in this study\nis applicable in such a small-scale quadruped robot platform in which the\ncomputation resources and space are limited. The semantic segmentation based on\na CNN model is adopted for the real-time path segmentation in the outdoor\nenvironment. The desired traverse trajectory is generated through real-time\nupdating the middle line, which is calculated from the edge position of the\nsegmented path in the images. To enhance the stability of the path planning\ndirectly based on the semantic segmentation method, a trajectory compensation\nmethod is supplemented considering the temporal information to revise the\nuntrustworthy planned path. Experiments of semantic segmentation and navigation\nin a garden scene are demonstrated to verify the effectiveness of the proposed\nmethod.",
    "descriptor": "",
    "authors": [
      "Deng Ganyu",
      "Luo Jianwen",
      "Sun Caiming",
      "Pan Dongwei",
      "Peng Longyao",
      "Ding Ning",
      "Zhang Aidong"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.04426"
  },
  {
    "id": "arXiv:2110.04427",
    "title": "Harnessing Unlabeled Data to Improve Generalization of Biometric Gender  and Age Classifiers",
    "abstract": "With significant advances in deep learning, many computer vision applications\nhave reached the inflection point. However, these deep learning models need\nlarge amount of labeled data for model training and optimum parameter\nestimation. Limited labeled data for model training results in over-fitting and\nimpacts their generalization performance. However, the collection and\nannotation of large amount of data is a very time consuming and expensive\noperation. Further, due to privacy and security concerns, the large amount of\nlabeled data could not be collected for certain applications such as those\ninvolving medical field. Self-training, Co-training, and Self-ensemble methods\nare three types of semi-supervised learning methods that can be used to exploit\nunlabeled data. In this paper, we propose self-ensemble based deep learning\nmodel that along with limited labeled data, harness unlabeled data for\nimproving the generalization performance. We evaluated the proposed\nself-ensemble based deep-learning model for soft-biometric gender and age\nclassification. Experimental evaluation on CelebA and VISOB datasets suggest\ngender classification accuracy of 94.46% and 81.00%, respectively, using only\n1000 labeled samples and remaining 199k samples as unlabeled samples for CelebA\ndataset and similarly,1000 labeled samples with remaining 107k samples as\nunlabeled samples for VISOB dataset. Comparative evaluation suggest that there\nis $5.74\\%$ and $8.47\\%$ improvement in the accuracy of the self-ensemble model\nwhen compared with supervised model trained on the entire CelebA and VISOB\ndataset, respectively. We also evaluated the proposed learning method for\nage-group prediction on Adience dataset and it outperformed the baseline\nsupervised deep-learning learning model with a better exact accuracy of 55.55\n$\\pm$ 4.28 which is 3.92% more than the baseline.",
    "descriptor": "\nComments: 7 pages, 5 figures, 5 tables\n",
    "authors": [
      "Aakash Varma Nadimpalli",
      "Narsi Reddy",
      "Sreeraj Ramachandran",
      "Ajita Rattani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04427"
  },
  {
    "id": "arXiv:2110.04429",
    "title": "Improving Distantly-Supervised Named Entity Recognition with  Self-Collaborative Denoising Learning",
    "abstract": "Distantly supervised named entity recognition (DS-NER) efficiently reduces\nlabor costs but meanwhile intrinsically suffers from the label noise due to the\nstrong assumption of distant supervision. Typically, the wrongly labeled\ninstances comprise numbers of incomplete and inaccurate annotation noise, while\nmost prior denoising works are only concerned with one kind of noise and fail\nto fully explore useful information in the whole training set. To address this\nissue, we propose a robust learning paradigm named Self-Collaborative Denoising\nLearning (SCDL), which jointly trains two teacher-student networks in a\nmutually-beneficial manner to iteratively perform noisy label refinery. Each\nnetwork is designed to exploit reliable labels via self denoising, and two\nnetworks communicate with each other to explore unreliable annotations by\ncollaborative denoising. Extensive experimental results on five real-world\ndatasets demonstrate that SCDL is superior to state-of-the-art DS-NER denoising\nmethods.",
    "descriptor": "\nComments: EMNLP 2021 Accept-Findings\n",
    "authors": [
      "Xinghua Zhang",
      "Bowen Yu",
      "Tingwen Liu",
      "Zhenyu Zhang",
      "Jiawei Sheng",
      "Mengge Xue",
      "Hongbo Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04429"
  },
  {
    "id": "arXiv:2110.04430",
    "title": "RankingMatch: Delving into Semi-Supervised Learning with Consistency  Regularization and Ranking Loss",
    "abstract": "Semi-supervised learning (SSL) has played an important role in leveraging\nunlabeled data when labeled data is limited. One of the most successful SSL\napproaches is based on consistency regularization, which encourages the model\nto produce unchanged with perturbed input. However, there has been less\nattention spent on inputs that have the same label. Motivated by the\nobservation that the inputs having the same label should have the similar model\noutputs, we propose a novel method, RankingMatch, that considers not only the\nperturbed inputs but also the similarity among the inputs having the same\nlabel. We especially introduce a new objective function, dubbed BatchMean\nTriplet loss, which has the advantage of computational efficiency while taking\ninto account all input samples. Our RankingMatch achieves state-of-the-art\nperformance across many standard SSL benchmarks with a variety of labeled data\namounts, including 95.13% accuracy on CIFAR-10 with 250 labels, 77.65% accuracy\non CIFAR-100 with 10000 labels, 97.76% accuracy on SVHN with 250 labels, and\n97.77% accuracy on SVHN with 1000 labels. We also perform an ablation study to\nprove the efficacy of the proposed BatchMean Triplet loss against existing\nversions of Triplet loss.",
    "descriptor": "",
    "authors": [
      "Trung Q. Tran",
      "Mingu Kang",
      "Daeyoung Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04430"
  },
  {
    "id": "arXiv:2110.04431",
    "title": "SOMA: Solving Optical Marker-Based MoCap Automatically",
    "abstract": "Marker-based optical motion capture (mocap) is the \"gold standard\" method for\nacquiring accurate 3D human motion in computer vision, medicine, and graphics.\nThe raw output of these systems are noisy and incomplete 3D points or short\ntracklets of points. To be useful, one must associate these points with\ncorresponding markers on the captured subject; i.e. \"labelling\". Given these\nlabels, one can then \"solve\" for the 3D skeleton or body surface mesh.\nCommercial auto-labeling tools require a specific calibration procedure at\ncapture time, which is not possible for archival data. Here we train a novel\nneural network called SOMA, which takes raw mocap point clouds with varying\nnumbers of points, labels them at scale without any calibration data,\nindependent of the capture technology, and requiring only minimal human\nintervention. Our key insight is that, while labeling point clouds is highly\nambiguous, the 3D body provides strong constraints on the solution that can be\nexploited by a learning-based method. To enable learning, we generate massive\ntraining sets of simulated noisy and ground truth mocap markers animated by 3D\nbodies from AMASS. SOMA exploits an architecture with stacked self-attention\nelements to learn the spatial structure of the 3D body and an optimal transport\nlayer to constrain the assignment (labeling) problem while rejecting outliers.\nWe extensively evaluate SOMA both quantitatively and qualitatively. SOMA is\nmore accurate and robust than existing state of the art research methods and\ncan be applied where commercial systems cannot. We automatically label over 8\nhours of archival mocap data across 4 different datasets captured using various\ntechnologies and output SMPL-X body models. The model and data is released for\nresearch purposes at https://soma.is.tue.mpg.de/.",
    "descriptor": "\nComments: ICCV 2021\n",
    "authors": [
      "Nima Ghorbani",
      "Michael J. Black"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.04431"
  },
  {
    "id": "arXiv:2110.04432",
    "title": "Group-matching algorithms for subjects and items",
    "abstract": "We consider the problem of constructing matched groups such that the\nresulting groups are statistically similar with respect to their average values\nfor multiple covariates. This group-matching problem arises in many cases,\nincluding quasi-experimental and observational studies in which subjects or\nitems are sampled from pre-existing groups, scenarios in which traditional\npair-matching approaches may be inappropriate. We consider the case in which\none is provided with an existing sample and iteratively eliminates samples so\nthat the groups \"match\" according to arbitrary statistically-defined criteria.\nThis problem is NP-hard. However, using artificial and real-world data sets, we\nshow that heuristics implemented by the ldamatch package produce high-quality\nmatches.",
    "descriptor": "",
    "authors": [
      "G\u00e9za Kiss",
      "Kyle Gorman",
      "Jan P.H. van Santen"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04432"
  },
  {
    "id": "arXiv:2110.04435",
    "title": "Two-stage Visual Cues Enhancement Network for Referring Image  Segmentation",
    "abstract": "Referring Image Segmentation (RIS) aims at segmenting the target object from\nan image referred by one given natural language expression. The diverse and\nflexible expressions as well as complex visual contents in the images raise the\nRIS model with higher demands for investigating fine-grained matching behaviors\nbetween words in expressions and objects presented in images. However, such\nmatching behaviors are hard to be learned and captured when the visual cues of\nreferents (i.e. referred objects) are insufficient, as the referents with weak\nvisual cues tend to be easily confused by cluttered background at boundary or\neven overwhelmed by salient objects in the image. And the insufficient visual\ncues issue can not be handled by the cross-modal fusion mechanisms as done in\nprevious work. In this paper, we tackle this problem from a novel perspective\nof enhancing the visual information for the referents by devising a Two-stage\nVisual cues enhancement Network (TV-Net), where a novel Retrieval and\nEnrichment Scheme (RES) and an Adaptive Multi-resolution feature Fusion (AMF)\nmodule are proposed. Through the two-stage enhancement, our proposed TV-Net\nenjoys better performances in learning fine-grained matching behaviors between\nthe natural language expression and image, especially when the visual\ninformation of the referent is inadequate, thus produces better segmentation\nresults. Extensive experiments are conducted to validate the effectiveness of\nthe proposed method on the RIS task, with our proposed TV-Net surpassing the\nstate-of-the-art approaches on four benchmark datasets.",
    "descriptor": "\nComments: Accepted by ACM MM 2021\n",
    "authors": [
      "Yang Jiao",
      "Zequn Jie",
      "Weixin Luo",
      "Jingjing Chen",
      "Yu-Gang Jiang",
      "Xiaolin Wei",
      "Lin Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04435"
  },
  {
    "id": "arXiv:2110.04437",
    "title": "Clustering Human Trust Dynamics for Customized Real-time Prediction",
    "abstract": "Trust calibration is necessary to ensure appropriate user acceptance in\nadvanced automation technologies. A significant challenge to achieve trust\ncalibration is to quantitatively estimate human trust in real-time. Although\nmultiple trust models exist, these models have limited predictive performance\npartly due to individual differences in trust dynamics. A personalized model\nfor each person can address this issue, but it requires a significant amount of\ndata for each user. We present a methodology to develop customized model by\nclustering humans based on their trust dynamics. The clustering-based method\naddresses the individual differences in trust dynamics while requiring\nsignificantly less data than personalized model. We show that our\nclustering-based customized models not only outperform the general model based\non entire population, but also outperform simple demographic factor-based\ncustomized models. Specifically, we propose that two models based on\n``confident'' and ``skeptical'' group of participants, respectively, can\nrepresent the trust behavior of the population. The ``confident'' participants,\nas compared to the ``skeptical'' participants, have higher initial trust\nlevels, lose trust slower when they encounter low reliability operations, and\nhave higher trust levels during trust-repair after the low reliability\noperations. In summary, clustering-based customized models improve trust\nprediction performance for further trust calibration considerations.",
    "descriptor": "\nComments: To be published in 2021 IEEE 24rd International Conference on Intelligent Transportation Systems (ITSC)\n",
    "authors": [
      "Jundi Liu",
      "Kumar Akash",
      "Teruhisa Misu",
      "Xingwei Wu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.04437"
  },
  {
    "id": "arXiv:2110.04438",
    "title": "Towards Lightweight Applications: Asymmetric Enroll-Verify Structure for  Speaker Verification",
    "abstract": "With the development of deep learning, automatic speaker verification has\nmade considerable progress over the past few years. However, to design a\nlightweight and robust system with limited computational resources is still a\nchallenging problem. Traditionally, a speaker verification system is\nsymmetrical, indicating that the same embedding extraction model is applied for\nboth enrollment and verification in inference. In this paper, we come up with\nan innovative asymmetric structure, which takes the large-scale ECAPA-TDNN\nmodel for enrollment and the small-scale ECAPA-TDNNLite model for verification.\nAs a symmetrical system, our proposed ECAPA-TDNNLite model achieves an EER of\n3.07% on the Voxceleb1 original test set with only 11.6M FLOPS. Moreover, the\nasymmetric structure further reduces the EER to 2.31%, without increasing any\ncomputational costs during verification.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Qingjian Lin",
      "Lin Yang",
      "Xuyang Wang",
      "Xiaoyi Qin",
      "Junjie Wang",
      "Ming Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.04438"
  },
  {
    "id": "arXiv:2110.04439",
    "title": "Research on Knowledge based Expert System for Medical Diagnosis",
    "abstract": "In this paper we propose the design and implementation of a generic medical\nknowledge based system (MKBS) for identifying diseases from several symptoms\nand signs. To diagnosis diseases, user will be asked by the system for\ndifferent questions and finally inference engine will use certainty factor to\nprune out low possible solutions. In this system some important aspects like\nKnowledge bases system, Knowledge representation, Inference Engine has been\naddressed. New certainty fact has been introduced to get conclusion about same\nfiring rules. The proposed disease diagnosis system also uses a graphical user\nuser interface to facilitate user to interact a with expert system more easily.\nThe proposed system is generic and knowledge based, and it can be integrated\nwith any rule bases system in disease diagnosis.",
    "descriptor": "",
    "authors": [
      "Xin Huang",
      "Xuejiao Tang",
      "Wenbin Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04439"
  },
  {
    "id": "arXiv:2110.04441",
    "title": "Natural Language for Human-Robot Collaboration: Problems Beyond Language  Grounding",
    "abstract": "To enable robots to instruct humans in collaborations, we identify several\naspects of language processing that are not commonly studied in this context.\nThese include location, planning, and generation. We suggest evaluations for\neach task, offer baselines for simple methods, and close by discussing\nchallenges and opportunities in studying language for collaboration.",
    "descriptor": "\nComments: 5 pages, 2 figures, Presented at AI-HRI symposium as part of AAAI-FSS 2021 (arXiv:2109.10836)\n",
    "authors": [
      "Seth Pate",
      "Wei Xu",
      "Ziyi Yang",
      "Maxwell Love",
      "Siddarth Ganguri",
      "Lawson L.S. Wong"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.04441"
  },
  {
    "id": "arXiv:2110.04442",
    "title": "Deep Learning of Potential Outcomes",
    "abstract": "This review systematizes the emerging literature for causal inference using\ndeep neural networks under the potential outcomes framework. It provides an\nintuitive introduction on how deep learning can be used to estimate/predict\nheterogeneous treatment effects and extend causal inference to settings where\nconfounding is non-linear, time varying, or encoded in text, networks, and\nimages. To maximize accessibility, we also introduce prerequisite concepts from\ncausal inference and deep learning. The survey differs from other treatments of\ndeep learning and causal inference in its sharp focus on observational causal\nestimation, its extended exposition of key algorithms, and its detailed\ntutorials for implementing, training, and selecting among deep estimators in\nTensorflow 2 available at github.com/kochbj/Deep-Learning-for-Causal-Inference.",
    "descriptor": "",
    "authors": [
      "Bernard Koch",
      "Tim Sainburg",
      "Pablo Geraldo",
      "Song Jiang",
      "Yizhou Sun",
      "Jacob Gates Foster"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04442"
  },
  {
    "id": "arXiv:2110.04447",
    "title": "EfficientPhys: Enabling Simple, Fast and Accurate Camera-Based Vitals  Measurement",
    "abstract": "Camera-based physiological measurement is a growing field with neural models\nproviding state-the-art-performance. Prior research have explored various\n``end-to-end'' models; however these methods still require several\npreprocessing steps. These additional operations are often non-trivial to\nimplement making replication and deployment difficult and can even have a\nhigher computational budget than the ``core'' network itself. In this paper, we\npropose two novel and efficient neural models for camera-based physiological\nmeasurement called EfficientPhys that remove the need for face detection,\nsegmentation, normalization, color space transformation or any other\npreprocessing steps. Using an input of raw video frames, our models achieve\nstate-of-the-art accuracy on three public datasets. We show that this is the\ncase whether using a transformer or convolutional backbone. We further evaluate\nthe latency of the proposed networks and show that our most light weight\nnetwork also achieves a 33% improvement in efficiency.",
    "descriptor": "",
    "authors": [
      "Xin Liu",
      "Brian L. Hill",
      "Ziheng Jiang",
      "Shwetak Patel",
      "Daniel McDuff"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.04447"
  },
  {
    "id": "arXiv:2110.04448",
    "title": "A State Transfer Method That Adapts to Network Bandwidth Variations in  Geographic State Machine Replication",
    "abstract": "We present a new state transfer method for geographic State Machine\nReplication (SMR) that dynamically allocates the state to be transferred among\nreplicas according to changes in communication bandwidths. SMR is a method that\nimproves fault tolerance by replicating a service to multiple replicas. When a\nreplica is newly added or is recovered from a failure, the other replicas\ntransfer the current state of the service to it. However, in geographic SMR,\nthe communication bandwidths of replicas are different and constantly changing.\nTherefore, existing state transfer methods cannot fully utilize the available\nbandwidth, and their state transfer time becomes long. To overcome this\nproblem, our method divides the state into multiple chunks and assigns them to\nreplicas based on each replica's bandwidth so that the broader a replica's\nbandwidth is, the more chunks it transfers. The number of assigned chunks is\ndynamically updated based on the currently estimated bandwidth. The performance\nevaluation on Amazon EC2 shows that the proposed method reduces the state\ntransfer time by up to 47% compared with the existing one.",
    "descriptor": "\nComments: This manuscript was submitted to the Ninth International Symposium on Computing and Networking (CANDAR 2021)\n",
    "authors": [
      "Tairi Chiba",
      "Ren Ohmura",
      "Junya Nakamura"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.04448"
  },
  {
    "id": "arXiv:2110.04450",
    "title": "Scene Editing as Teleoperation: A Case Study in 6DoF Kit Assembly",
    "abstract": "Studies in robot teleoperation have been centered around action\nspecifications -- from continuous joint control to discrete end-effector pose\ncontrol. However, these robot-centric interfaces often require skilled\noperators with extensive robotics expertise. To make teleoperation accessible\nto non-expert users, we propose the framework \"Scene Editing as Teleoperation\"\n(SEaT), where the key idea is to transform the traditional \"robot-centric\"\ninterface into a \"scene-centric\" interface -- instead of controlling the robot,\nusers focus on specifying the task's goal by manipulating digital twins of the\nreal-world objects. As a result, a user can perform teleoperation without any\nexpert knowledge of the robot hardware. To achieve this goal, we utilize a\ncategory-agnostic scene-completion algorithm that translates the real-world\nworkspace (with unknown objects) into a manipulable virtual scene\nrepresentation and an action-snapping algorithm that refines the user input\nbefore generating the robot's action plan. To train the algorithms, we\nprocedurally generated a large-scale, diverse kit-assembly dataset that\ncontains object-kit pairs that mimic real-world object-kitting tasks. Our\nexperiments in simulation and on a real-world system demonstrate that our\nframework improves both the efficiency and success rate for 6DoF kit-assembly\ntasks. A user study demonstrates that SEaT framework participants achieve a\nhigher task success rate and report a lower subjective workload compared to an\nalternative robot-centric interface. Video can be found at\nhttps://www.youtube.com/watch?v=-NdR3mkPbQQ .",
    "descriptor": "",
    "authors": [
      "Shubham Agrawal",
      "Yulong Li",
      "Jen-Shuo Liu",
      "Steven K. Feiner",
      "Shuran Song"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04450"
  },
  {
    "id": "arXiv:2110.04451",
    "title": "Using multiple reference audios and style embedding constraints for  speech synthesis",
    "abstract": "The end-to-end speech synthesis model can directly take an utterance as\nreference audio, and generate speech from the text with prosody and speaker\ncharacteristics similar to the reference audio. However, an appropriate\nacoustic embedding must be manually selected during inference. Due to the fact\nthat only the matched text and speech are used in the training process, using\nunmatched text and speech for inference would cause the model to synthesize\nspeech with low content quality. In this study, we propose to mitigate these\ntwo problems by using multiple reference audios and style embedding constraints\nrather than using only the target audio. Multiple reference audios are\nautomatically selected using the sentence similarity determined by\nBidirectional Encoder Representations from Transformers (BERT). In addition, we\nuse ''target'' style embedding from a Pre-trained encoder as a constraint by\nconsidering the mutual information between the predicted and ''target'' style\nembedding. The experimental results show that the proposed model can improve\nthe speech naturalness and content quality with multiple reference audios and\ncan also outperform the baseline model in ABX preference tests of style\nsimilarity.",
    "descriptor": "\nComments: 5 pages,3 figures submitted to ICASSP2022\n",
    "authors": [
      "Cheng Gong",
      "Longbiao Wang",
      "Zhenhua Ling",
      "Ju Zhang",
      "Jianwu Dang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.04451"
  },
  {
    "id": "arXiv:2110.04452",
    "title": "Towards AI Logic for Social Reasoning",
    "abstract": "Artificial Intelligence (AI) logic formalizes the reasoning of intelligent\nagents. In this paper, we discuss how an argumentation-based AI logic could be\nused also to formalize important aspects of social reasoning. Besides reasoning\nabout the knowledge and actions of individual agents, social AI logic can\nreason also about social dependencies among agents using the rights,\nobligations and permissions of the agents. We discuss four aspects of social AI\nlogic. First, we discuss how rights represent relations between the obligations\nand permissions of intelligent agents. Second, we discuss how to argue about\nthe right-to-know, a central issue in the recent discussion of privacy and\nethics. Third, we discuss how a wide variety of conflicts among intelligent\nagents can be identified and (sometimes) resolved by comparing formal\narguments. Importantly, to cover a wide range of arguments occurring in daily\nlife, also fallacious arguments can be represented and reasoned about. Fourth,\nwe discuss how to argue about the freedom to act for intelligent agents.\nExamples from social, legal and ethical reasoning highlight the challenges in\ndeveloping social AI logic. The discussion of the four challenges leads to a\nresearch program for argumentation-based social AI logic, contributing towards\nthe future development of AI logic.",
    "descriptor": "",
    "authors": [
      "Huimin Dong",
      "R\u00e9ka Markovich",
      "Leendert van der Torre"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.04452"
  },
  {
    "id": "arXiv:2110.04453",
    "title": "A Novel Quantum Calculus-based Complex Least Mean Square Algorithm  (q-CLMS)",
    "abstract": "In this research, a novel adaptive filtering algorithm is proposed for\ncomplex domain signal processing. The proposed algorithm is based on Wirtinger\ncalculus and is called as q-Complex Least Mean Square (q-CLMS) algorithm. The\nproposed algorithm could be considered as an extension of the q-LMS algorithm\nfor the complex domain. Transient and steady-state analyses of the proposed\nq-CLMS algorithm are performed and exact analytical expressions for mean\nanalysis, mean square error (MSE), excess mean square error (EMSE), mean square\ndeviation (MSD) and misadjustment are presented. Extensive experiments have\nbeen conducted and a good match between the simulation results and theoretical\nfindings is reported. The proposed q-CLMS algorithm is also explored for\nwhitening applications with satisfactory performance. A modification of the\nproposed q-CLMS algorithm called Enhanced $q$-CLMS (Eq-CLMS) is also proposed.\nThe Eq-CLMS algorithm eliminates the need for a pre-coded value of the\nq-parameter thereby automatically adapting to the best value. Extensive\nexperiments are performed on system identification and channel equalization\ntasks and the proposed algorithm is shown to outperform several benchmark and\nstate-of-the-art approaches namely Complex Least Mean Square (CLMS), Normalized\nComplex Least Mean Square (NCLMS), Variable Step Size Complex Least Mean Square\n(VSS-CLMS), Complex FLMS (CFLMS) and Fractional-ordered-CLMS (FoCLMS)\nalgorithms.",
    "descriptor": "\nComments: 35 pages, 14 figures\n",
    "authors": [
      "Alishba Sadiq",
      "Imran Naseem",
      "Shujaat Khan",
      "Muhammad Moinuddin",
      "Roberto Togneri",
      "Mohammed Bennamoun"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.04453"
  },
  {
    "id": "arXiv:2110.04454",
    "title": "Dynamic Logic of Legal Competences",
    "abstract": "We propose a new formalization of legal competences, and in particular for\nthe Hohfeldian categories of power and immunity, through a deontic\nreinterpretation of dynamic epistemic logic. We argue that this logic\nexplicitly captures the norm-changing character of legal competences while\nproviding a sophisticated reduction of the latter to static normative\npositions. The logic is completely axiomatizable, and we apply it to a concrete\ncase in German contract law to illustrate that it can capture the distinction\nbetween legal ability and legal permissibility.",
    "descriptor": "",
    "authors": [
      "Huimin Dong",
      "Olivier Roy"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04454"
  },
  {
    "id": "arXiv:2110.04457",
    "title": "Tailoring the Cyber Security Framework: How to Overcome the Complexities  of Secure Live Virtual Machine Migration in Cloud Computing",
    "abstract": "This paper proposes a novel secure live virtual machine migration framework\nby using a virtual trusted platform module instance to improve the integrity of\nthe migration process from one virtual machine to another on the same platform.\nThe proposed framework, called Koror\\=a, is designed and developed on a public\ninfrastructure-as-a-service cloud-computing environment and runs concurrently\non the same hardware components (Input/Output, Central Processing Unit, Memory)\nand the same hypervisor (Xen); however, a combination of parameters needs to be\nevaluated before implementing Koror\\=a. The implementation of Koror\\=a is not\npractically feasible in traditional distributed computing environments. It\nrequires fixed resources with high-performance capabilities, connected through\na high-speed, reliable network. The following research objectives were\ndetermined to identify the integrity features of live virtual machine migration\nin the cloud system:\nTo understand the security issues associated with cloud computing, virtual\ntrusted platform modules, virtualization, live virtual machine migration, and\nhypervisors; To identify the requirements for the proposed framework, including\nthose related to live VM migration among different hypervisors; To design and\nvalidate the model, processes, and architectural features of the proposed\nframework; To propose and implement an end-to-end security architectural\nblueprint for cloud environments, providing an integrated view of protection\nmechanisms, and then to validate the proposed framework to improve the\nintegrity of live VM migration. This is followed by a comprehensive review of\nthe evaluation system architecture and the proposed framework state machine.\nThe overarching aim of this paper, therefore, is to present a detailed analysis\nof the cloud computing security problem, from the perspective of cloud\narchitectures and the cloud... [Abridged]",
    "descriptor": "\nComments: Conference paper, 8 pages, 3 figures, Proceedings of the International Conference on Information Resources Management (CONF-IRM2020)\n",
    "authors": [
      "Hanif Deylami",
      "Jairo Gutierrez",
      "Roopak Sinha"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.04457"
  },
  {
    "id": "arXiv:2110.04459",
    "title": "Adversarial Training for Face Recognition Systems using Contrastive  Adversarial Learning and Triplet Loss Fine-tuning",
    "abstract": "Though much work has been done in the domain of improving the adversarial\nrobustness of facial recognition systems, a surprisingly small percentage of it\nhas focused on self-supervised approaches. In this work, we present an approach\nthat combines Ad-versarial Pre-Training with Triplet Loss\nAdversarialFine-Tuning. We compare our methods with the pre-trained ResNet50\nmodel that forms the backbone of FaceNet, finetuned on our CelebA dataset.\nThrough comparing adversarial robustness achieved without adversarial training,\nwith triplet loss adversarial training, and our contrastive pre-training\ncombined with triplet loss adversarial fine-tuning, we find that our method\nachieves comparable results with far fewer epochs re-quired during fine-tuning.\nThis seems promising, increasing the training time for fine-tuning should yield\neven better results. In addition to this, a modified semi-supervised experiment\nwas conducted, which demonstrated the improvement of contrastive adversarial\ntraining with the introduction of small amounts of labels.",
    "descriptor": "",
    "authors": [
      "Nazmul Karim",
      "Umar Khalid",
      "Nick Meeker",
      "Sarinda Samarasinghe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04459"
  },
  {
    "id": "arXiv:2110.04461",
    "title": "Toward Hole-Driven Development with Liquid Haskell",
    "abstract": "Liquid Haskell is an extension to the Haskell programming language that adds\nsupport for refinement types: data types augmented with SMT-decidable logical\npredicates that refine the set of values that can inhabit a type. Furthermore,\nLiquid Haskell's support for refinement reflection enables the use of Haskell\nfor general-purpose mechanized theorem proving. A growing list of large-scale\nmechanized proof developments in Liquid Haskell take advantage of this\ncapability. Adding theorem-proving capabilities to a \"legacy\" language like\nHaskell lets programmers directly verify properties of real-world Haskell\nprograms (taking advantage of the existing highly tuned compiler, run-time\nsystem, and libraries), just by writing Haskell. However, more established\nproof assistants like Agda and Coq offer far better support for interactive\nproof development and insight into the proof state (for instance, what subgoals\nstill need to be proved to finish a partially-complete proof). In contrast,\nLiquid Haskell provides only coarse-grained feedback to the user -- either it\nreports a type error, or not -- unfortunately hindering its usability as a\ntheorem prover.\nIn this paper, we propose improving the usability of Liquid Haskell by\nextending it with support for Agda-style typed holes and interactive editing\ncommands that take advantage of them. In Agda, typed holes allow programmers to\nindicate unfinished parts of a proof, and incrementally complete the proof in a\ndialogue with the compiler. While GHC Haskell already has its own Agda-inspired\nsupport for typed holes, we posit that typed holes would be especially powerful\nand useful if combined with Liquid Haskell's refinement types and SMT\nautomation. We discuss how typed holes might work in Liquid Haskell, and we\nconsider possible implementation approaches and next steps.",
    "descriptor": "\nComments: Accepted for publication at HATRA 2021\n",
    "authors": [
      "Patrick Redmond",
      "Gan Shen",
      "Lindsey Kuper"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2110.04461"
  },
  {
    "id": "arXiv:2110.04465",
    "title": "Predicting decision-making in the future: Human versus Machine",
    "abstract": "Deep neural networks (DNNs) have become remarkably successful in data\nprediction, and have even been used to predict future actions based on limited\ninput. This raises the question: do these systems actually \"understand\" the\nevent similar to humans? Here, we address this issue using videos taken from an\naccident situation in a driving simulation. In this situation, drivers had to\nchoose between crashing into a suddenly-appeared obstacle or steering their car\noff a previously indicated cliff. We compared how well humans and a DNN\npredicted this decision as a function of time before the event. The DNN\noutperformed humans for early time-points, but had an equal performance for\nlater time-points. Interestingly, spatio-temporal image manipulations and\nGrad-CAM visualizations uncovered some expected behavior, but also highlighted\npotential differences in temporal processing for the DNN.",
    "descriptor": "",
    "authors": [
      "Hoe Sung Ryu",
      "Uijong Ju",
      "Christian Wallraven"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04465"
  },
  {
    "id": "arXiv:2110.04466",
    "title": "ProductAE: Towards Training Larger Channel Codes based on Neural Product  Codes",
    "abstract": "There have been significant research activities in recent years to automate\nthe design of channel encoders and decoders via deep learning. Due the\ndimensionality challenge in channel coding, it is prohibitively complex to\ndesign and train relatively large neural channel codes via deep learning\ntechniques. Consequently, most of the results in the literature are limited to\nrelatively short codes having less than 100 information bits. In this paper, we\nconstruct ProductAEs, a computationally efficient family of deep-learning\ndriven (encoder, decoder) pairs, that aim at enabling the training of\nrelatively large channel codes (both encoders and decoders) with a manageable\ntraining complexity. We build upon the ideas from classical product codes, and\npropose constructing large neural codes using smaller code components. More\nspecifically, instead of directly training the encoder and decoder for a large\nneural code of dimension $k$ and blocklength $n$, we provide a framework that\nrequires training neural encoders and decoders for the code parameters\n$(k_1,n_1)$ and $(k_2,n_2)$ such that $k_1 k_2=k$ and $n_1 n_2=n$. Our training\nresults show significant gains, over all ranges of signal-to-noise ratio (SNR),\nfor a code of parameters $(100,225)$ and a moderate-length code of parameters\n$(196,441)$, over polar codes under successive cancellation (SC) decoder.\nMoreover, our results demonstrate meaningful gains over Turbo Autoencoder\n(TurboAE) and state-of-the-art classical codes. This is the first work to\ndesign product autoencoders and a pioneering work on training large channel\ncodes.",
    "descriptor": "",
    "authors": [
      "Mohammad Vahid Jamali",
      "Hamid Saber",
      "Homayoon Hatami",
      "Jung Hyun Bae"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.04466"
  },
  {
    "id": "arXiv:2110.04471",
    "title": "Provably Efficient Black-Box Action Poisoning Attacks Against  Reinforcement Learning",
    "abstract": "Due to the broad range of applications of reinforcement learning (RL),\nunderstanding the effects of adversarial attacks against RL model is essential\nfor the safe applications of this model. Prior works on adversarial attacks\nagainst RL mainly focus on either observation poisoning attacks or environment\npoisoning attacks. In this paper, we introduce a new class of attacks named\naction poisoning attacks, where an adversary can change the action signal\nselected by the agent. Compared with existing attack models, the attacker's\nability in the proposed action poisoning attack model is more restricted, and\nhence the attack model is more practical. We study the action poisoning attack\nin both white-box and black-box settings. We introduce an adaptive attack\nscheme called LCB-H, which works for most RL agents in the black-box setting.\nWe prove that the LCB-H attack can force any efficient RL agent, whose dynamic\nregret scales sublinearly with the total number of steps taken, to choose\nactions according to a policy selected by the attacker very frequently, with\nonly sublinear cost. In addition, we apply LCB-H attack against a popular\nmodel-free RL algorithm: UCB-H. We show that, even in the black-box setting, by\nspending only logarithm cost, the proposed LCB-H attack scheme can force the\nUCB-H agent to choose actions according to the policy selected by the attacker\nvery frequently.",
    "descriptor": "",
    "authors": [
      "Guanlin Liu",
      "Lifeng Lai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.04471"
  },
  {
    "id": "arXiv:2110.04473",
    "title": "Self-adaptive Multi-task Particle Swarm Optimization",
    "abstract": "Multi-task optimization (MTO) studies how to simultaneously solve multiple\noptimization problems for the purpose of obtaining better performance on each\nproblem. Over the past few years, evolutionary MTO (EMTO) was proposed to\nhandle MTO problems via evolutionary algorithms. So far, many EMTO algorithms\nhave been developed and demonstrated well performance on solving real-world\nproblems. However, there remain many works to do in adapting knowledge transfer\nto task relatedness in EMTO. Different from the existing works, we develop a\nself-adaptive multi-task particle swarm optimization (SaMTPSO) through the\ndeveloped knowledge transfer adaptation strategy, the focus search strategy and\nthe knowledge incorporation strategy. In the knowledge transfer adaptation\nstrategy, each task has a knowledge source pool that consists of all knowledge\nsources. Each source (task) outputs knowledge to the task. And knowledge\ntransfer adapts to task relatedness via individuals' choice on different\nsources of a pool, where the chosen probabilities for different sources are\ncomputed respectively according to task's success rate in generating improved\nsolutions via these sources. In the focus search strategy, if there is no\nknowledge source benefit the optimization of a task, then all knowledge sources\nin the task's pool are forbidden to be utilized except the task, which helps to\nimprove the performance of the proposed algorithm. Note that the task itself is\nas a knowledge source of its own. In the knowledge incorporation strategy, two\ndifferent forms are developed to help the SaMTPSO explore and exploit the\ntransferred knowledge from a chosen source, each leading to a version of the\nSaMTPSO. Several experiments are conducted on two test suites. The results of\nthe SaMTPSO are comparing to that of 3 popular EMTO algorithms and a particle\nswarm algorithm, which demonstrates the superiority of the SaMTPSO.",
    "descriptor": "",
    "authors": [
      "Xiaolong Zheng",
      "Deyun Zhou",
      "Na Li",
      "Yu Lei",
      "Tao Wu",
      "Maoguo Gong"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04473"
  },
  {
    "id": "arXiv:2110.04474",
    "title": "A Mutual learning framework for Few-shot Sound Event Detection",
    "abstract": "Although prototypical network (ProtoNet) has proved to be an effective method\nfor few-shot sound event detection, two problems still exist. Firstly, the\nsmall-scaled support set is insufficient so that the class prototypes may not\nrepresent the class center accurately. Secondly, the feature extractor is\ntask-agnostic (or class-agnostic): the feature extractor is trained with\nbase-class data and directly applied to unseen-class data. To address these\nissues, we present a novel mutual learning framework with transductive\nlearning, which aims at iteratively updating the class prototypes and feature\nextractor. More specifically, we propose to update class prototypes with\ntransductive inference to make the class prototypes as close to the true class\ncenter as possible. To make the feature extractor to be task-specific, we\npropose to use the updated class prototypes to fine-tune the feature extractor.\nAfter that, a fine-tuned feature extractor further helps produce better class\nprototypes. Our method achieves the F-score of 38.4$\\%$ on the DCASE 2021 Task\n5 evaluation set, which won the first place in the few-shot bioacoustic event\ndetection task of Detection and Classification of Acoustic Scenes and Events\n(DCASE) 2021 Challenge.",
    "descriptor": "\nComments: Submitted to ICASSP2022\n",
    "authors": [
      "Dongchao Yang",
      "Helin Wang",
      "Yuexian Zou",
      "Zhongjie Ye",
      "Wenwu Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.04474"
  },
  {
    "id": "arXiv:2110.04475",
    "title": "Leveraging recent advances in Pre-Trained Language Models  forEye-Tracking Prediction",
    "abstract": "Cognitively inspired Natural Language Pro-cessing uses human-derived\nbehavioral datalike eye-tracking data, which reflect the seman-tic\nrepresentations of language in the humanbrain to augment the neural nets to\nsolve arange of tasks spanning syntax and semanticswith the aim of teaching\nmachines about lan-guage processing mechanisms. In this paper,we use the ZuCo\n1.0 and ZuCo 2.0 dataset con-taining the eye-gaze features to explore\ndiffer-ent linguistic models to directly predict thesegaze features for each\nword with respect to itssentence. We tried different neural networkmodels with\nthe words as inputs to predict thetargets. And after lots of experimentation\nandfeature engineering finally devised a novel ar-chitecture consisting of\nRoBERTa Token Clas-sifier with a dense layer on top for languagemodeling and a\nstand-alone model consistingof dense layers followed by a transformer layerfor\nthe extra features we engineered. Finally,we took the mean of the outputs of\nboth thesemodels to make the final predictions. We eval-uated the models using\nmean absolute error(MAE) and the R2 score for each target.",
    "descriptor": "",
    "authors": [
      "Varun Madhavan",
      "Aditya Girish Pawate",
      "Shraman Pal",
      "Abhranil Chandra"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04475"
  },
  {
    "id": "arXiv:2110.04476",
    "title": "Label quality in AffectNet: results of crowd-based re-annotation",
    "abstract": "AffectNet is one of the most popular resources for facial expression\nrecognition (FER) on relatively unconstrained in-the-wild images. Given that\nimages were annotated by only one annotator with limited consistency checks on\nthe data, however, label quality and consistency may be limited. Here, we take\na similar approach to a study that re-labeled another, smaller dataset\n(FER2013) with crowd-based annotations, and report results from a re-labeling\nand re-annotation of a subset of difficult AffectNet faces with 13 people on\nboth expression label, and valence and arousal ratings. Our results show that\nhuman labels overall have medium to good consistency, whereas human ratings\nespecially for valence are in excellent agreement. Importantly, however,\ncrowd-based labels are significantly shifting towards neutral and happy\ncategories and crowd-based affective ratings form a consistent pattern\ndifferent from the original ratings. ResNets fully trained on the original\nAffectNet dataset do not predict human voting patterns, but when weakly-trained\ndo so much better, particularly for valence. Our results have important\nramifications for label quality in affective computing.",
    "descriptor": "",
    "authors": [
      "Doo Yon Kim",
      "Christian Wallraven"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04476"
  },
  {
    "id": "arXiv:2110.04478",
    "title": "Themis: A Network Bandwidth-Aware Collective Scheduling Policy for  Distributed Training of DL Models",
    "abstract": "The continuous growth in both size and training data for modern Deep Neural\nNetworks (DNNs) models has led to training tasks taking days or even months.\nDistributed training is a solution to reduce training time by splitting the\ntask across multiple NPUs (e.g., GPU/TPU). However, distributed training adds\ncommunication overhead between the NPUs in order to synchronize the gradients\nand/or activation, depending on the parallelization strategy. In today's\ndatacenters, for training at scale, NPUs are connected through\nmulti-dimensional interconnection links with different bandwidth and latency.\nHence, keeping all network dimensions busy and maximizing the network BW is a\nchallenging task in such a hybrid network environment, as this work identifies.\nWe propose Themis, a novel collective scheduling scheme that dynamically\nschedules collectives (divided into chunks) to balance the communication loads\nacross all dimensions, further improving the network BW utilization. Our\nresults show that on average, Themis can improve the network BW utilization of\nsingle All-Reduce by 1.88x (2.92x max), and improve the end-to-end training\niteration performance of real workloads such as ResNet-50, GNMT, DLRM, and\nTransformer- 1T by 1.49x (1.96x max), 1.41x (1.81x max), 1.42x (1.80x max), and\n1.35x (1.78x max), respectively.",
    "descriptor": "",
    "authors": [
      "Saeed Rashidi",
      "William Won",
      "Sudarshan Srinivasan",
      "Srinivas Sridharan",
      "Tushar Krishna"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.04478"
  },
  {
    "id": "arXiv:2110.04479",
    "title": "A Feature Consistency Driven Attention Erasing Network for Fine-Grained  Image Retrieval",
    "abstract": "Large-scale fine-grained image retrieval has two main problems. First, low\ndimensional feature embedding can fasten the retrieval process but bring\naccuracy reduce due to overlooking the feature of significant attention regions\nof images in fine-grained datasets. Second, fine-grained images lead to the\nsame category query hash codes mapping into the different cluster in database\nhash latent space. To handle these two issues, we propose a feature consistency\ndriven attention erasing network (FCAENet) for fine-grained image retrieval.\nFor the first issue, we propose an adaptive augmentation module in FCAENet,\nwhich is selective region erasing module (SREM). SREM makes the network more\nrobust on subtle differences of fine-grained task by adaptively covering some\nregions of raw images. The feature extractor and hash layer can learn more\nrepresentative hash code for fine-grained images by SREM. With regard to the\nsecond issue, we fully exploit the pair-wise similarity information and add the\nenhancing space relation loss (ESRL) in FCAENet to make the vulnerable relation\nstabler between the query hash code and database hash code. We conduct\nextensive experiments on five fine-grained benchmark datasets (CUB2011,\nAircraft, NABirds, VegFru, Food101) for 12bits, 24bits, 32bits, 48bits hash\ncode. The results show that FCAENet achieves the state-of-the-art (SOTA)\nfine-grained retrieval performance compared with other methods.",
    "descriptor": "\nComments: 30 pages, 9 figures\n",
    "authors": [
      "Qi Zhao",
      "Xu Wang",
      "Shuchang Lyu",
      "Binghao Liu",
      "Yifan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04479"
  },
  {
    "id": "arXiv:2110.04480",
    "title": "Bayesian Active Summarization",
    "abstract": "Bayesian Active Learning has had significant impact to various NLP problems,\nbut nevertheless it's application to text summarization has been explored very\nlittle. We introduce Bayesian Active Summarization (BAS), as a method of\ncombining active learning methods with state-of-the-art summarization models.\nOur findings suggest that BAS achieves better and more robust performance,\ncompared to random selection, particularly for small and very small data\nannotation budgets. Using BAS we showcase it is possible to leverage large\nsummarization models to effectively solve real-world problems with very limited\nannotated data.",
    "descriptor": "",
    "authors": [
      "Alexios Gidiotis",
      "Grigorios Tsoumakas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04480"
  },
  {
    "id": "arXiv:2110.04481",
    "title": "Comparing Facial Expression Recognition in Humans and Machines: Using  CAM, GradCAM, and Extremal Perturbation",
    "abstract": "Facial expression recognition (FER) is a topic attracting significant\nresearch in both psychology and machine learning with a wide range of\napplications. Despite a wealth of research on human FER and considerable\nprogress in computational FER made possible by deep neural networks (DNNs),\ncomparatively less work has been done on comparing the degree to which DNNs may\nbe comparable to human performance. In this work, we compared the recognition\nperformance and attention patterns of humans and machines during a\ntwo-alternative forced-choice FER task. Human attention was here gathered\nthrough click data that progressively uncovered a face, whereas model attention\nwas obtained using three different popular techniques from explainable AI: CAM,\nGradCAM and Extremal Perturbation. In both cases, performance was gathered as\npercent correct. For this task, we found that humans outperformed machines\nquite significantly. In terms of attention patterns, we found that Extremal\nPerturbation had the best overall fit with the human attention map during the\ntask.",
    "descriptor": "",
    "authors": [
      "Serin Park",
      "Christian Wallraven"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04481"
  },
  {
    "id": "arXiv:2110.04483",
    "title": "Visualizing the embedding space to explain the effect of knowledge  distillation",
    "abstract": "Recent research has found that knowledge distillation can be effective in\nreducing the size of a network and in increasing generalization. A pre-trained,\nlarge teacher network, for example, was shown to be able to bootstrap a student\nmodel that eventually outperforms the teacher in a limited label environment.\nDespite these advances, it still is relatively unclear \\emph{why} this method\nworks, that is, what the resulting student model does 'better'. To address this\nissue, here, we utilize two non-linear, low-dimensional embedding methods\n(t-SNE and IVIS) to visualize representation spaces of different layers in a\nnetwork. We perform a set of extensive experiments with different architecture\nparameters and distillation methods. The resulting visualizations and metrics\nclearly show that distillation guides the network to find a more compact\nrepresentation space for higher accuracy already in earlier layers compared to\nits non-distilled version.",
    "descriptor": "",
    "authors": [
      "Hyun Seung Lee",
      "Christian Wallraven"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04483"
  },
  {
    "id": "arXiv:2110.04486",
    "title": "PAMA-TTS: Progression-Aware Monotonic Attention for Stable Seq2Seq TTS  With Accurate Phoneme Duration Control",
    "abstract": "Sequence expansion between encoder and decoder is a critical challenge in\nsequence-to-sequence TTS. Attention-based methods achieve great naturalness but\nsuffer from unstable issues like missing and repeating phonemes, not to mention\naccurate duration control. Duration-informed methods, on the contrary, seem to\neasily adjust phoneme duration but show obvious degradation in speech\nnaturalness. This paper proposes PAMA-TTS to address the problem. It takes the\nadvantage of both flexible attention and explicit duration models. Based on the\nmonotonic attention mechanism, PAMA-TTS also leverages token duration and\nrelative position of a frame, especially countdown information, i.e. in how\nmany future frames the present phoneme will end. They help the attention to\nmove forward along the token sequence in a soft but reliable control.\nExperimental results prove that PAMA-TTS achieves the highest naturalness,\nwhile has on-par or even better duration controllability than the\nduration-informed model.",
    "descriptor": "\nComments: Submitted to ICASSP 2022. 5 pages, 4 figures, 3 tables. Audio samples are available at: this https URL\n",
    "authors": [
      "Yunchao He",
      "Jian Luan",
      "Yujun Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04486"
  },
  {
    "id": "arXiv:2110.04487",
    "title": "Colour augmentation for improved semi-supervised semantic segmentation",
    "abstract": "Consistency regularization describes a class of approaches that have yielded\nstate-of-the-art results for semi-supervised classification. While\nsemi-supervised semantic segmentation proved to be more challenging, a number\nof successful approaches have been recently proposed. Recent work explored the\nchallenges involved in using consistency regularization for segmentation\nproblems. In their self-supervised work Chen et al. found that colour\naugmentation prevents a classification network from using image colour\nstatistics as a short-cut for self-supervised learning via instance\ndiscrimination. Drawing inspiration from this we find that a similar problem\nimpedes semi-supervised semantic segmentation and offer colour augmentation as\na solution, improving semi-supervised semantic segmentation performance on\nchallenging photographic imagery.",
    "descriptor": "\nComments: 9 pages, 1 figure\n",
    "authors": [
      "Geoff French",
      "Michal Mackiewicz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04487"
  },
  {
    "id": "arXiv:2110.04488",
    "title": "Demystifying the Transferability of Adversarial Attacks in Computer  Networks",
    "abstract": "Deep Convolutional Neural Networks (CNN) models are one of the most popular\nnetworks in deep learning. With their large fields of application in different\nareas, they are extensively used in both academia and industry. CNN-based\nmodels include several exciting implementations such as early breast cancer\ndetection or detecting developmental delays in children (e.g., autism, speech\ndisorders, etc.). However, previous studies demonstrate that these models are\nsubject to various adversarial attacks. Interestingly, some adversarial\nexamples could potentially still be effective against different unknown models.\nThis particular property is known as adversarial transferability, and prior\nworks slightly analyzed this characteristic in a very limited application\ndomain. In this paper, we aim to demystify the transferability threats in\ncomputer networks by studying the possibility of transferring adversarial\nexamples. In particular, we provide the first comprehensive study which\nassesses the robustness of CNN-based models for computer networks against\nadversarial transferability. In our experiments, we consider five different\nattacks: (1) the Iterative Fast Gradient Method (I-FGSM), (2) the\nJacobian-based Saliency Map attack (JSMA), (3) the L-BFGS attack, (4) the\nProjected Gradient Descent attack (PGD), and (5) the DeepFool attack. These\nattacks are performed against two well-known datasets: the N-BaIoT dataset and\nthe Domain Generating Algorithms (DGA) dataset. Our results show that the\ntransferability happens in specific use cases where the adversary can easily\ncompromise the victim's network with very few knowledge of the targeted model.",
    "descriptor": "\nComments: 12\n",
    "authors": [
      "Ehsan Nowroozi",
      "Mauro Conti",
      "Yassine Mekdad",
      "Mohammad Hajian Berenjestanaki",
      "Abdeslam EL Fergougui"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.04488"
  },
  {
    "id": "arXiv:2110.04492",
    "title": "Weight Evolution: Improving Deep Neural Networks Training through  Evolving Inferior Weight Values",
    "abstract": "To obtain good performance, convolutional neural networks are usually\nover-parameterized. This phenomenon has stimulated two interesting topics:\npruning the unimportant weights for compression and reactivating the\nunimportant weights to make full use of network capability. However, current\nweight reactivation methods usually reactivate the entire filters, which may\nnot be precise enough. Looking back in history, the prosperity of filter\npruning is mainly due to its friendliness to hardware implementation, but\npruning at a finer structure level, i.e., weight elements, usually leads to\nbetter network performance. We study the problem of weight element reactivation\nin this paper. Motivated by evolution, we select the unimportant filters and\nupdate their unimportant elements by combining them with the important elements\nof important filters, just like gene crossover to produce better offspring, and\nthe proposed method is called weight evolution (WE). WE is mainly composed of\nfour strategies. We propose a global selection strategy and a local selection\nstrategy and combine them to locate the unimportant filters. A forward matching\nstrategy is proposed to find the matched important filters and a crossover\nstrategy is proposed to utilize the important elements of the important filters\nfor updating unimportant filters. WE is plug-in to existing network\narchitectures. Comprehensive experiments show that WE outperforms the other\nreactivation methods and plug-in training methods with typical convolutional\nneural networks, especially lightweight networks. Our code is available at\nhttps://github.com/BZQLin/Weight-evolution.",
    "descriptor": "\nComments: This paper is accepted by ACM Multimedia 2021\n",
    "authors": [
      "Zhenquan Lin",
      "Kailing Guo",
      "Xiaofen Xing",
      "Xiangmin Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04492"
  },
  {
    "id": "arXiv:2110.04493",
    "title": "High-performance computation of the exponential of a large sparse matrix",
    "abstract": "Computation of the large sparse matrix exponential has been an important\ntopic in many fields, such as network and finite-element analysis. The existing\nscaling and squaring algorithm (SSA) is not suitable for the computation of the\nlarge sparse matrix exponential as it requires greater memories and\ncomputational cost than is actually needed. By introducing two novel concepts,\ni.e., real bandwidth and bandwidth, to measure the sparsity of the matrix, the\nsparsity of the matrix exponential is analyzed. It is found that for every\nmatrix computed in the squaring phase of the SSA, a corresponding sparse\napproximate matrix exists. To obtain the sparse approximate matrix, a new\nfiltering technique in terms of forward error analysis is proposed. Combining\nthe filtering technique with the idea of keeping track of the incremental part,\na competitive algorithm is developed for the large sparse matrix exponential.\nThe proposed method can primarily alleviate the over-scaling problem due to the\nfiltering technique. Three sets of numerical experiments, including one large\nmatrix with a dimension larger than 2e6 , are conducted. The numerical\nexperiments show that, compared with the expm function in MATLAB, the proposed\nalgorithm can provide higher accuracy at lower computational cost and with less\nmemory.",
    "descriptor": "",
    "authors": [
      "Feng Wu",
      "Kailing Zhang",
      "Li Zhu",
      "Jiayao Hu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.04493"
  },
  {
    "id": "arXiv:2110.04494",
    "title": "SGMNet: Scene Graph Matching Network for Few-Shot Remote Sensing Scene  Classification",
    "abstract": "Few-Shot Remote Sensing Scene Classification (FSRSSC) is an important task,\nwhich aims to recognize novel scene classes with few examples. Recently,\nseveral studies attempt to address the FSRSSC problem by following few-shot\nnatural image classification methods. These existing methods have made\npromising progress and achieved superior performance. However, they all\noverlook two unique characteristics of remote sensing images: (i) object\nco-occurrence that multiple objects tend to appear together in a scene image\nand (ii) object spatial correlation that these co-occurrence objects are\ndistributed in the scene image following some spatial structure patterns. Such\nunique characteristics are very beneficial for FSRSSC, which can effectively\nalleviate the scarcity issue of labeled remote sensing images since they can\nprovide more refined descriptions for each scene class. To fully exploit these\ncharacteristics, we propose a novel scene graph matching-based meta-learning\nframework for FSRSSC, called SGMNet. In this framework, a scene graph\nconstruction module is carefully designed to represent each test remote sensing\nimage or each scene class as a scene graph, where the nodes reflect these\nco-occurrence objects meanwhile the edges capture the spatial correlations\nbetween these co-occurrence objects. Then, a scene graph matching module is\nfurther developed to evaluate the similarity score between each test remote\nsensing image and each scene class. Finally, based on the similarity scores, we\nperform the scene class prediction via a nearest neighbor classifier. We\nconduct extensive experiments on UCMerced LandUse, WHU19, AID, and\nNWPU-RESISC45 datasets. The experimental results show that our method obtains\nsuperior performance over the previous state-of-the-art methods.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Baoquan Zhang",
      "Shanshan Feng",
      "Xutao Li",
      "Yunming Ye",
      "Rui Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04494"
  },
  {
    "id": "arXiv:2110.04495",
    "title": "Multi-Agent MDP Homomorphic Networks",
    "abstract": "This paper introduces Multi-Agent MDP Homomorphic Networks, a class of\nnetworks that allows distributed execution using only local information, yet is\nable to share experience between global symmetries in the joint state-action\nspace of cooperative multi-agent systems. In cooperative multi-agent systems,\ncomplex symmetries arise between different configurations of the agents and\ntheir local observations. For example, consider a group of agents navigating:\nrotating the state globally results in a permutation of the optimal joint\npolicy. Existing work on symmetries in single agent reinforcement learning can\nonly be generalized to the fully centralized setting, because such approaches\nrely on the global symmetry in the full state-action spaces, and these can\nresult in correspondences across agents. To encode such symmetries while still\nallowing distributed execution we propose a factorization that decomposes\nglobal symmetries into local transformations. Our proposed factorization allows\nfor distributing the computation that enforces global symmetries over local\nagents and local interactions. We introduce a multi-agent equivariant policy\nnetwork based on this factorization. We show empirically on symmetric\nmulti-agent problems that distributed execution of globally symmetric policies\nimproves data efficiency compared to non-equivariant baselines.",
    "descriptor": "",
    "authors": [
      "Elise van der Pol",
      "Herke van Hoof",
      "Frans A. Oliehoek",
      "Max Welling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.04495"
  },
  {
    "id": "arXiv:2110.04502",
    "title": "EnsembleNTLDetect: An Intelligent Framework for Electricity Theft  Detection in Smart Grid",
    "abstract": "Artificial intelligence-based techniques applied to the electricity\nconsumption data generated from the smart grid prove to be an effective\nsolution in reducing Non Technical Loses (NTLs), thereby ensures safety,\nreliability, and security of the smart energy systems. However, imbalanced\ndata, consecutive missing values, large training times, and complex\narchitectures hinder the real time application of electricity theft detection\nmodels. In this paper, we present EnsembleNTLDetect, a robust and scalable\nelectricity theft detection framework that employs a set of efficient data\npre-processing techniques and machine learning models to accurately detect\nelectricity theft by analysing consumers' electricity consumption patterns.\nThis framework utilises an enhanced Dynamic Time Warping Based Imputation\n(eDTWBI) algorithm to impute missing values in the time series data and\nleverages the Near-miss undersampling technique to generate balanced data.\nFurther, stacked autoencoder is introduced for dimensionality reduction and to\nimprove training efficiency. A Conditional Generative Adversarial Network\n(CTGAN) is used to augment the dataset to ensure robust training and a soft\nvoting ensemble classifier is designed to detect the consumers with aberrant\nconsumption patterns. Furthermore, experiments were conducted on the real-time\nelectricity consumption data provided by the State Grid Corporation of China\n(SGCC) to validate the reliability and efficiency of EnsembleNTLDetect over the\nstate-of-the-art electricity theft detection models in terms of various quality\nmetrics.",
    "descriptor": "\nComments: Accepted at the 2nd Workshop on Large-scale Industrial Time Series Analysis at the 21st IEEE International Conference on Data Mining (ICDM), 2021\n",
    "authors": [
      "Yogesh Kulkarni",
      "Sayf Hussain Z",
      "Krithi Ramamritham",
      "Nivethitha Somu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04502"
  },
  {
    "id": "arXiv:2110.04503",
    "title": "Multi-Relation Aware Temporal Interaction Network Embedding",
    "abstract": "Temporal interaction networks are formed in many fields, e.g., e-commerce,\nonline education, and social network service. Temporal interaction network\nembedding can effectively mine the information in temporal interaction\nnetworks, which is of great significance to the above fields. Usually, the\noccurrence of an interaction affects not only the nodes directly involved in\nthe interaction (interacting nodes), but also the neighbor nodes of interacting\nnodes. However, existing temporal interaction network embedding methods only\nuse historical interaction relations to mine neighbor nodes, ignoring other\nrelation types. In this paper, we propose a multi-relation aware temporal\ninteraction network embedding method (MRATE). Based on historical interactions,\nMRATE mines historical interaction relations, common interaction relations, and\ninteraction sequence similarity relations to obtain the neighbor based\nembeddings of interacting nodes. The hierarchical multi-relation aware\naggregation method in MRATE first employs graph attention networks (GATs) to\naggregate the interaction impacts propagated through a same relation type and\nthen combines the aggregated interaction impacts from multiple relation types\nthrough the self-attention mechanism. Experiments are conducted on three public\ntemporal interaction network datasets, and the experimental results show the\neffectiveness of MRATE.",
    "descriptor": "\nComments: 18 pages, 4 figures\n",
    "authors": [
      "Ling Chen",
      "Shanshan Yu",
      "Dandan Lyu",
      "Da Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04503"
  },
  {
    "id": "arXiv:2110.04504",
    "title": "An Isotropy Analysis in the Multilingual BERT Embedding Space",
    "abstract": "Several studies have explored various advantages of multilingual pre-trained\nmodels (e.g., multilingual BERT) in capturing shared linguistic knowledge.\nHowever, their limitations have not been paid enough attention. In this paper,\nwe investigate the representation degeneration problem in multilingual\ncontextual word representations (CWRs) of BERT and show that the embedding\nspaces of the selected languages suffer from anisotropy problem. Our\nexperimental results demonstrate that, similarly to their monolingual\ncounterparts, increasing the isotropy of multilingual embedding space can\nsignificantly improve its representation power and performance. Our analysis\nindicates that although the degenerated directions vary in different languages,\nthey encode similar linguistic knowledge, suggesting a shared linguistic space\namong languages.",
    "descriptor": "",
    "authors": [
      "Sara Rajaee",
      "Mohammad Taher Pilehvar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04504"
  },
  {
    "id": "arXiv:2110.04507",
    "title": "TiKick: Toward Playing Multi-agent Football Full Games from Single-agent  Demonstrations",
    "abstract": "Deep reinforcement learning (DRL) has achieved super-human performance on\ncomplex video games (e.g., StarCraft II and Dota II). However, current DRL\nsystems still suffer from challenges of multi-agent coordination, sparse\nrewards, stochastic environments, etc. In seeking to address these challenges,\nwe employ a football video game, e.g., Google Research Football (GRF), as our\ntestbed and develop an end-to-end learning-based AI system (denoted as TiKick\nto complete this challenging task. In this work, we first generated a large\nreplay dataset from the self-playing of single-agent experts, which are\nobtained from league training. We then developed a distributed learning system\nand new offline algorithms to learn a powerful multi-agent AI from the fixed\nsingle-agent dataset. To the best of our knowledge, Tikick is the first\nlearning-based AI system that can take over the multi-agent Google Research\nFootball full game, while previous work could either control a single agent or\nexperiment on toy academic scenarios. Extensive experiments further show that\nour pre-trained model can accelerate the training process of the modern\nmulti-agent algorithm and our method achieves state-of-the-art performances on\nvarious academic scenarios.",
    "descriptor": "",
    "authors": [
      "Shiyu Huang",
      "Wenze Chen",
      "Longfei Zhang",
      "Ziyang Li",
      "Fengming Zhu",
      "Deheng Ye",
      "Ting Chen",
      "Jun Zhu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04507"
  },
  {
    "id": "arXiv:2110.04514",
    "title": "Towards Open-World Feature Extrapolation: An Inductive Graph Learning  Approach",
    "abstract": "We target open-world feature extrapolation problem where the feature space of\ninput data goes through expansion and a model trained on partially observed\nfeatures needs to handle new features in test data without further retraining.\nThe problem is of much significance for dealing with features incrementally\ncollected from different fields. To this end, we propose a new learning\nparadigm with graph representation and learning. Our framework contains two\nmodules: 1) a backbone network (e.g., feedforward neural nets) as a lower model\ntakes features as input and outputs predicted labels; 2) a graph neural network\nas an upper model learns to extrapolate embeddings for new features via message\npassing over a feature-data graph built from observed data. Based on our\nframework, we design two training strategies, a self-supervised approach and an\ninductive learning approach, to endow the model with extrapolation ability and\nalleviate feature-level over-fitting. We also provide theoretical analysis on\nthe generalization error on test data with new features, which dissects the\nimpact of training features and algorithms on generalization performance. Our\nexperiments over several classification datasets and large-scale advertisement\nclick prediction datasets demonstrate that our model can produce effective\nembeddings for unseen features and significantly outperforms baseline methods\nthat adopt KNN and local aggregation.",
    "descriptor": "\nComments: Accepted to NeurIPS 2021 conference\n",
    "authors": [
      "Qitian Wu",
      "Chenxiao Yang",
      "Junchi Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.04514"
  },
  {
    "id": "arXiv:2110.04517",
    "title": "Extending Multi-Text Sentence Fusion Resources via Pyramid Annotations",
    "abstract": "NLP models that compare or consolidate information across multiple documents\noften struggle when challenged with recognizing substantial information\nredundancies across the texts. For example, in multi-document summarization it\nis crucial to identify salient information across texts and then generate a\nnon-redundant summary, while facing repeated and usually differently-phrased\nsalient content. To facilitate researching such challenges, the sentence-level\ntask of \\textit{sentence fusion} was proposed, yet previous datasets for this\ntask were very limited in their size and scope. In this paper, we revisit and\nsubstantially extend previous dataset creation efforts. With careful\nmodifications, relabeling and employing complementing data sources, we were\nable to triple the size of a notable earlier dataset. Moreover, we show that\nour extended version uses more representative texts for multi-document tasks\nand provides a larger and more diverse training set, which substantially\nimproves model training.",
    "descriptor": "",
    "authors": [
      "Daniela Brook Weiss",
      "Paul Roit",
      "Ori Ernst",
      "Ido Dagan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04517"
  },
  {
    "id": "arXiv:2110.04518",
    "title": "DMRST: A Joint Framework for Document-Level Multilingual RST Discourse  Segmentation and Parsing",
    "abstract": "Text discourse parsing weighs importantly in understanding information flow\nand argumentative structure in natural language, making it beneficial for\ndownstream tasks. While previous work significantly improves the performance of\nRST discourse parsing, they are not readily applicable to practical use cases:\n(1) EDU segmentation is not integrated into most existing tree parsing\nframeworks, thus it is not straightforward to apply such models on newly-coming\ndata. (2) Most parsers cannot be used in multilingual scenarios, because they\nare developed only in English. (3) Parsers trained from single-domain treebanks\ndo not generalize well on out-of-domain inputs. In this work, we propose a\ndocument-level multilingual RST discourse parsing framework, which conducts EDU\nsegmentation and discourse tree parsing jointly. Moreover, we propose a\ncross-translation augmentation strategy to enable the framework to support\nmultilingual parsing and improve its domain generality. Experimental results\nshow that our model achieves state-of-the-art performance on document-level\nmultilingual RST parsing in all sub-tasks.",
    "descriptor": "\nComments: Published in CODI@EMNLP 2021\n",
    "authors": [
      "Zhengyuan Liu",
      "Ke Shi",
      "Nancy F. Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04518"
  },
  {
    "id": "arXiv:2110.04519",
    "title": "Pairwise Margin Maximization for Deep Neural Networks",
    "abstract": "The weight decay regularization term is widely used during training to\nconstrain expressivity, avoid overfitting, and improve generalization.\nHistorically, this concept was borrowed from the SVM maximum margin principle\nand extended to multi-class deep networks. Carefully inspecting this principle\nreveals that it is not optimal for multi-class classification in general, and\nin particular when using deep neural networks. In this paper, we explain why\nthis commonly used principle is not optimal and propose a new regularization\nscheme, called {\\em Pairwise Margin Maximization} (PMM), which measures the\nminimal amount of displacement an instance should take until its predicted\nclassification is switched. In deep neural networks, PMM can be implemented in\nthe vector space before the network's output layer, i.e., in the deep feature\nspace, where we add an additional normalization term to avoid convergence to a\ntrivial solution. We demonstrate empirically a substantial improvement when\ntraining a deep neural network with PMM compared to the standard regularization\nterms.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2009.06011\n",
    "authors": [
      "Berry Weinstein",
      "Shai Fine",
      "Yacov Hel-Or"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04519"
  },
  {
    "id": "arXiv:2110.04522",
    "title": "Rumor Detection on Twitter with Claim-Guided Hierarchical Graph  Attention Networks",
    "abstract": "Rumors are rampant in the era of social media. Conversation structures\nprovide valuable clues to differentiate between real and fake claims. However,\nexisting rumor detection methods are either limited to the strict relation of\nuser responses or oversimplify the conversation structure. In this study, to\nsubstantially reinforces the interaction of user opinions while alleviating the\nnegative impact imposed by irrelevant posts, we first represent the\nconversation thread as an undirected interaction graph. We then present a\nClaim-guided Hierarchical Graph Attention Network for rumor classification,\nwhich enhances the representation learning for responsive posts considering the\nentire social contexts and attends over the posts that can semantically infer\nthe target claim. Extensive experiments on three Twitter datasets demonstrate\nthat our rumor detection method achieves much better performance than\nstate-of-the-art methods and exhibits a superior capacity for detecting rumors\nat early stages.",
    "descriptor": "\nComments: Accepted to the main conference of EMNLP2021\n",
    "authors": [
      "Hongzhan Lin",
      "Jing Ma",
      "Mingfei Cheng",
      "Zhiwei Yang",
      "Liangliang Chen",
      "Guang Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04522"
  },
  {
    "id": "arXiv:2110.04525",
    "title": "Generating Disentangled Arguments with Prompts: A Simple Event  Extraction Framework that Works",
    "abstract": "Event Extraction bridges the gap between text and event signals. Based on the\nassumption of trigger-argument dependency, existing approaches have achieved\nstate-of-the-art performance with expert-designed templates or complicated\ndecoding constraints. In this paper, for the first time we introduce the\nprompt-based learning strategy to the domain of Event Extraction, which\nempowers the automatic exploitation of label semantics on both input and output\nsides. To validate the effectiveness of the proposed generative method, we\nconduct extensive experiments with 11 diverse baselines. Empirical results show\nthat, in terms of F1 score on Argument Extraction, our simple architecture is\nstronger than any other generative counterpart and even competitive with\nalgorithms that require template engineering. Regarding the measure of recall,\nit sets new overall records for both Argument and Trigger Extractions. We\nhereby recommend this framework to the community, with the code publicly\navailable at https://git.io/GDAP.",
    "descriptor": "",
    "authors": [
      "Jinghui Si",
      "Xutan Peng",
      "Chen Li",
      "Haotian Xu",
      "Jianxin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04525"
  },
  {
    "id": "arXiv:2110.04526",
    "title": "Improving Multi-Party Dialogue Discourse Parsing via Domain Integration",
    "abstract": "While multi-party conversations are often less structured than monologues and\ndocuments, they are implicitly organized by semantic level correlations across\nthe interactive turns, and dialogue discourse analysis can be applied to\npredict the dependency structure and relations between the elementary discourse\nunits, and provide feature-rich structural information for downstream tasks.\nHowever, the existing corpora with dialogue discourse annotation are collected\nfrom specific domains with limited sample sizes, rendering the performance of\ndata-driven approaches poor on incoming dialogues without any domain\nadaptation. In this paper, we first introduce a Transformer-based parser, and\nassess its cross-domain performance. We next adopt three methods to gain domain\nintegration from both data and language modeling perspectives to improve the\ngeneralization capability. Empirical results show that the neural parser can\nbenefit from our proposed methods, and performs better on cross-domain dialogue\nsamples.",
    "descriptor": "\nComments: Published in CODI@EMNLP 2021\n",
    "authors": [
      "Zhengyuan Liu",
      "Nancy F. Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04526"
  },
  {
    "id": "arXiv:2110.04533",
    "title": "The GKK Algorithm is the Fastest over Simple Mean-Payoff Games",
    "abstract": "We study the algorithm of Gurvich, Khachyian and Karzanov (GKK algorithm)\nwhen it is ran over mean-payoff games with no simple cycle of weight zero. We\npropose a new symmetric analysis, lowering the $O(n^2 N)$ upper-bound of\nPisaruk on the number of iterations down to $N + Ep + Em$, which is smaller\nthan $nN$, where $n$ is the number of vertices, $N$ is the largest absolute\nvalue of a weight, and $Ep$ and $Em$ are respectively the largest finite energy\nand dual-energy values of the game. Since each iteration is computed in $O(m)$,\nthis improves on the state of the art pseudopolynomial $O(mnN)$ runtime bound\nof Brim, Chaloupka, Doyen, Gentilini and Raskin, by taking into account the\nstructure of the game graph. We complement our result by showing that the\nanalysis of Dorfman, Kaplan and Zwick also applies to the GKK algorithm, which\nis thus also subject to the state of the art combinatorial runtime bound of\n$O(m 2^{n/2})$.",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Pierre Ohlmann"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.04533"
  },
  {
    "id": "arXiv:2110.04534",
    "title": "Teaching Robots to Grasp Like Humans: An Interactive Approach",
    "abstract": "This work investigates how the intricate task of grasping may be learned from\nhumans based on demonstrations and corrections. Due to the complexity of the\ntask, these demonstrations are often slow and even slightly flawed,\nparticularly at moments when multiple aspects (i.e., end-effector movement,\norientation, and gripper width) have to be demonstrated at once. Rather than\ntraining a person to provide better demonstrations, non-expert users are\nprovided with the ability to interactively modify the dynamics of their initial\ndemonstration through teleoperated corrective feedback. This in turn allows\nthem to teach motions outside of their own physical capabilities. In the end,\nthe goal is to obtain a faster but reliable execution of the task. The\npresented framework learns the desired movement dynamics based on the current\nCartesian Position with Gaussian Processes (GP), resulting in a reactive,\ntime-invariant policy. Using GPs also allows online interactive corrections and\nactive disturbance rejection through epistemic uncertainty minimization. The\nexperimental evaluation of the framework is carried out on a Franka-Emika\nPanda.",
    "descriptor": "",
    "authors": [
      "Anna M\u00e9sz\u00e1ros",
      "Giovanni Franzese",
      "Jens Kober"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04534"
  },
  {
    "id": "arXiv:2110.04535",
    "title": "ZSpeedL -- Evaluating the Performance of Zero-Shot Learning Methods  using Low-Power Devices",
    "abstract": "The recognition of unseen objects from a semantic representation or textual\ndescription, usually denoted as zero-shot learning, is more prone to be used in\nreal-world scenarios when compared to traditional object recognition.\nNevertheless, no work has evaluated the feasibility of deploying zero-shot\nlearning approaches in these scenarios, particularly when using low-power\ndevices. In this paper, we provide the first benchmark on the inference time of\nzero-shot learning, comprising an evaluation of state-of-the-art approaches\nregarding their speed/accuracy trade-off. An analysis to the processing time of\nthe different phases of the ZSL inference stage reveals that visual feature\nextraction is the major bottleneck in this paradigm, but, we show that\nlightweight networks can dramatically reduce the overall inference time without\nreducing the accuracy obtained by the de facto ResNet101 architecture. Also,\nthis benchmark evaluates how different ZSL approaches perform in low-power\ndevices, and how the visual feature extraction phase could be optimized in this\nhardware. To foster the research and deployment of ZSL systems capable of\noperating in real-world scenarios, we release the evaluation framework used in\nthis benchmark (https://github.com/CristianoPatricio/zsl-methods).",
    "descriptor": "\nComments: 8 pages. Accepted at the 17th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS), 2021\n",
    "authors": [
      "Cristiano Patr\u00edcio",
      "Jo\u00e3o Neves"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04535"
  },
  {
    "id": "arXiv:2110.04538",
    "title": "Focus Your Distribution: Coarse-to-Fine Non-Contrastive Learning for  Anomaly Detection and Localization",
    "abstract": "The essence of unsupervised anomaly detection is to learn the compact\ndistribution of normal samples and detect outliers as anomalies in testing.\nMeanwhile, the anomalies in real-world are usually subtle and fine-grained in a\nhigh-resolution image especially for industrial applications. Towards this end,\nwe propose a novel framework for unsupervised anomaly detection and\nlocalization. Our method aims at learning dense and compact distribution from\nnormal images with a coarse-to-fine alignment process. The coarse alignment\nstage standardizes the pixel-wise position of objects in both image and feature\nlevels. The fine alignment stage then densely maximizes the similarity of\nfeatures among all corresponding locations in a batch. To facilitate the\nlearning with only normal images, we propose a new pretext task called\nnon-contrastive learning for the fine alignment stage. Non-contrastive learning\nextracts robust and discriminating normal image representations without making\nassumptions on abnormal samples, and it thus empowers our model to generalize\nto various anomalous scenarios. Extensive experiments on two typical industrial\ndatasets of MVTec AD and BenTech AD demonstrate that our framework is effective\nin detecting various real-world defects and achieves a new state-of-the-art in\nindustrial unsupervised anomaly detection.",
    "descriptor": "",
    "authors": [
      "Ye Zheng",
      "Xiang Wang",
      "Rui Deng",
      "Tianpeng Bao",
      "Rui Zhao",
      "Liwei Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04538"
  },
  {
    "id": "arXiv:2110.04539",
    "title": "A New Innovation Concept on End user Contextual and Behavioural  Perspectives",
    "abstract": "The phenomenon of innovation has been shifting away from focusing on tangible\nto intangible modernization with its vitalizing context. This shift appears\nvitally in innovation developed by individual end-users in organizations and\nsocieties, including the exploration of the intangible end-user innovation\nexistence and impact in the household sector on a national scale. Some examples\nof intangible end-user innovation include technique, service, and user\nbehavior. Although, there is a variety of intangible end-user innovation\ndiscussed in the literature, limited understanding is existed for constructing\nan efficient and comprehensive typology, which encompasses the nature of this\ninnovation phenomenon. This research study explores this original phenomenon\nfor proposing a new concept that will act as an overarching descriptor of\ninnovation types: idea, object, and behavior. This proposed concept, relating\nto intangible innovation, will explain the sequence within one or many\nconnected intangible activities that provide novelty to its end-user relative\nto previous activities and practices. Using a design science research approach,\nthe study comprises two goals: a) identifying opportunities and issues to\nmeasure intangible inputs to the innovation and b) proposing a framework for\nextending the existing innovation theories that to better capture intangible\nend-user innovation and its diffusion insights in their online environment\nacross nations",
    "descriptor": "\nComments: Conf paper\n",
    "authors": [
      "Reem Aman",
      "Shah J. Miah",
      "Janet Dzator"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.04539"
  },
  {
    "id": "arXiv:2110.04540",
    "title": "Emergent Insight of the Cyber Security Management for Saudi Arabian  Universities: A Content Analysis",
    "abstract": "While cyber security has become a prominent concept of emerging information\ngovernance, the Kingdom of Saudi Arabia has been dealing with severe threats to\nindividual and organizational IT systems for a long time. These risks have\nrecently permeated into educational institutions, thereby undermining the\nconfidentiality of information as well as the delivery of education. Recent\nresearch has identified various causes and possible solutions to the problem.\nHowever, most scholars have considered a reductionist approach, in which the\nability of computer configurations to prevent unwanted intrusions is evaluated\nby breaking them down to their constituent parts. This method is inadequate at\nstudying complex adaptive systems. Therefore, the proposed project is designed\nto utilize a holistic stance to assess the cybersecurity management and\npolicies in Saudi Arabian universities. Qualitative research, entailing a\nthorough critical review of ten public universities, will be utilized to\ninvestigate the subject matter. The subsequent recommendations can be adopted\nto enhance the security of IT systems, not only in institutional settings but\nalso in any other environment in which such structures are used.",
    "descriptor": "\nComments: Conf\n",
    "authors": [
      "Masmali",
      "Miah"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.04540"
  },
  {
    "id": "arXiv:2110.04541",
    "title": "The Inductive Bias of In-Context Learning: Rethinking Pretraining  Example Design",
    "abstract": "Pretraining Neural Language Models (NLMs) over a large corpus involves\nchunking the text into training examples, which are contiguous text segments of\nsizes processable by the neural architecture. We highlight a bias introduced by\nthis common practice: we prove that the pretrained NLM can model much stronger\ndependencies between text segments that appeared in the same training example,\nthan it can between text segments that appeared in different training examples.\nThis intuitive result has a twofold role. First, it formalizes the motivation\nbehind a broad line of recent successful NLM training heuristics, proposed for\nthe pretraining and fine-tuning stages, which do not necessarily appear related\nat first glance. Second, our result clearly indicates further improvements to\nbe made in NLM pretraining for the benefit of Natural Language Understanding\ntasks. As an example, we propose \"kNN-Pretraining\": we show that including\nsemantically related non-neighboring sentences in the same pretraining example\nyields improved sentence representations and open domain question answering\nabilities. This theoretically motivated degree of freedom for \"pretraining\nexample design\" indicates new training schemes for self-improving\nrepresentations.",
    "descriptor": "",
    "authors": [
      "Yoav Levine",
      "Noam Wies",
      "Daniel Jannai",
      "Dan Navon",
      "Yedid Hoshen",
      "Amnon Shashua"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04541"
  },
  {
    "id": "arXiv:2110.04543",
    "title": "Class-Balanced Active Learning for Image Classification",
    "abstract": "Active learning aims to reduce the labeling effort that is required to train\nalgorithms by learning an acquisition function selecting the most relevant data\nfor which a label should be requested from a large unlabeled data pool. Active\nlearning is generally studied on balanced datasets where an equal amount of\nimages per class is available. However, real-world datasets suffer from severe\nimbalanced classes, the so called long-tail distribution. We argue that this\nfurther complicates the active learning process, since the imbalanced data pool\ncan result in suboptimal classifiers. To address this problem in the context of\nactive learning, we proposed a general optimization framework that explicitly\ntakes class-balancing into account. Results on three datasets showed that the\nmethod is general (it can be combined with most existing active learning\nalgorithms) and can be effectively applied to boost the performance of both\ninformative and representative-based active learning methods. In addition, we\nshowed that also on balanced datasets our method generally results in a\nperformance gain.",
    "descriptor": "\nComments: Accepted at WACV2022 conference\n",
    "authors": [
      "Javad Zolfaghari Bengar",
      "Joost van de Weijer",
      "Laura Lopez Fuentes",
      "Bogdan Raducanu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04543"
  },
  {
    "id": "arXiv:2110.04544",
    "title": "CLIP-Adapter: Better Vision-Language Models with Feature Adapters",
    "abstract": "Large-scale contrastive vision-language pre-training has shown significant\nprogress in visual representation learning. Unlike traditional visual systems\ntrained by a fixed set of discrete labels, a new paradigm was introduced in\n\\cite{radford2021learning} to directly learn to align images with raw texts in\nan open-vocabulary setting. On downstream tasks, a carefully chosen text prompt\nis employed to make zero-shot predictions.~To avoid non-trivial prompt\nengineering, context optimization \\cite{zhou2021coop} has been proposed to\nlearn continuous vectors as task-specific prompts with few-shot training\nexamples.~In this paper, we show that there is an alternative path to achieve\nbetter vision-language models other than prompt tuning.~While prompt tuning is\nfor the textual inputs, we propose CLIP-Adapter to conduct fine-tuning with\nfeature adapters on either visual or language branch. Specifically,\nCLIP-Adapter adopts an additional bottleneck layer to learn new features and\nperforms residual-style feature blending with the original pre-trained\nfeatures.~As a consequence, CLIP-Adapter is able to outperform context\noptimization while maintains a simple design. Experiments and extensive\nablation studies on various visual classification tasks demonstrate the\neffectiveness of our approach.",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Peng Gao",
      "Shijie Geng",
      "Renrui Zhang",
      "Teli Ma",
      "Rongyao Fang",
      "Yongfeng Zhang",
      "Hongsheng Li",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04544"
  },
  {
    "id": "arXiv:2110.04545",
    "title": "Towards Data-Free Domain Generalization",
    "abstract": "In this work, we investigate the unexplored intersection of domain\ngeneralization and data-free learning. In particular, we address the question:\nHow can knowledge contained in models trained on different source data domains\ncan be merged into a single model that generalizes well to unseen target\ndomains, in the absence of source and target domain data? Machine learning\nmodels that can cope with domain shift are essential for for real-world\nscenarios with often changing data distributions. Prior domain generalization\nmethods typically rely on using source domain data, making them unsuitable for\nprivate decentralized data. We define the novel problem of Data-Free Domain\nGeneralization (DFDG), a practical setting where models trained on the source\ndomains separately are available instead of the original datasets, and\ninvestigate how to effectively solve the domain generalization problem in that\ncase. We propose DEKAN, an approach that extracts and fuses domain-specific\nknowledge from the available teacher models into a student model robust to\ndomain shift. Our empirical evaluation demonstrates the effectiveness of our\nmethod which achieves first state-of-the-art results in DFDG by significantly\noutperforming ensemble and data-free knowledge distillation baselines.",
    "descriptor": "",
    "authors": [
      "Ahmed Frikha",
      "Haokun Chen",
      "Denis Krompa\u00df",
      "Thomas Runkler",
      "Volker Tresp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04545"
  },
  {
    "id": "arXiv:2110.04553",
    "title": "Adaptive Variable Impedance Control for a Modular Soft Robot Manipulator  in Configuration Space",
    "abstract": "Compliance is a strong requirement for human-robot interactions. Soft-robots\nprovide an opportunity to cover the lack of compliance in conventional\nactuation mechanisms, however, the control of them is very challenging given\ntheir intrinsic complex motions. Therefore, soft-robots require new approaches\nto e.g., modeling, control, dynamics, and planning. One of the control\nstrategies that ensures compliance is the impedance control. During the task\nexecution in the presence of coupling force and position constraints, a dynamic\nbehavior increases the flexibility of the impedance control. This imposes some\nadditional constraints on the stability of the control system. To tackle them,\nwe propose a variable impedance control in configuration space for a modular\nsoft robot manipulator (MSRM) in the presence of model uncertainties and\nexternal forces. The external loads are estimated in configuration space using\na momentum-based approach in order to reduce the calculation complexity, and\nthe adaptive back-stepping sliding mode (ABSM) controller is designed to guard\nagainst uncertainties. Stability analysis is performed using Lyapunov theory\nwhich guarantees not only the exponential stability of each state under the\ndesigned control law, but also the global stability of the closed-loop system.\nThe system performance is benchmarked against other conventional control\nmethods, such as the sliding mode (SM) and inverse dynamics PD controllers. The\nresults show the effectiveness of the proposed variable impedance control in\nstabilizing the position error and diminishing the impact of the external load\ncompared to SM and PD controllers.",
    "descriptor": "",
    "authors": [
      "Mahmood Mazare",
      "Silvia Tolu",
      "Mostafa Taghizadeh"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.04553"
  },
  {
    "id": "arXiv:2110.04558",
    "title": "Unsupervised Representation Learning Meets Pseudo-Label Supervised  Self-Distillation: A New Approach to Rare Disease Classification",
    "abstract": "Rare diseases are characterized by low prevalence and are often chronically\ndebilitating or life-threatening. Imaging-based classification of rare diseases\nis challenging due to the severe shortage in training examples. Few-shot\nlearning (FSL) methods tackle this challenge by extracting generalizable prior\nknowledge from a large base dataset of common diseases and normal controls, and\ntransferring the knowledge to rare diseases. Yet, most existing methods require\nthe base dataset to be labeled and do not make full use of the precious\nexamples of the rare diseases. To this end, we propose in this work a novel\nhybrid approach to rare disease classification, featuring two key novelties\ntargeted at the above drawbacks. First, we adopt the unsupervised\nrepresentation learning (URL) based on self-supervising contrastive loss,\nwhereby to eliminate the overhead in labeling the base dataset. Second, we\nintegrate the URL with pseudo-label supervised classification for effective\nself-distillation of the knowledge about the rare diseases, composing a hybrid\napproach taking advantages of both unsupervised and (pseudo-) supervised\nlearning on the base dataset. Experimental results on classification of rare\nskin lesions show that our hybrid approach substantially outperforms existing\nFSL methods (including those using fully supervised base dataset) for rare\ndisease classification via effective integration of the URL and pseudo-label\ndriven self-distillation, thus establishing a new state of the art.",
    "descriptor": "\nComments: Published in proceedings of MICCAI 2021\n",
    "authors": [
      "Jinghan Sun",
      "Dong Wei",
      "Kai Ma",
      "Liansheng Wang",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04558"
  },
  {
    "id": "arXiv:2110.04559",
    "title": "Graph Neural Networks in Real-Time Fraud Detection with Lambda  Architecture",
    "abstract": "Transaction checkout fraud detection is an essential risk control components\nfor E-commerce marketplaces. In order to leverage graph networks to decrease\nfraud rate efficiently and guarantee the information flow passed through\nneighbors only from the past of the checkouts, we first present a novel\nDirected Dynamic Snapshot (DDS) linkage design for graph construction and a\nLambda Neural Networks (LNN) architecture for effective inference with Graph\nNeural Networks embeddings. Experiments show that our LNN on DDS graph,\noutperforms baseline models significantly and is computational efficient for\nreal-time fraud detection.",
    "descriptor": "",
    "authors": [
      "Mingxuan Lu",
      "Zhichao Han",
      "Zitao Zhang",
      "Yang Zhao",
      "Yinan Shan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.04559"
  },
  {
    "id": "arXiv:2110.04562",
    "title": "Temporally Consistent Video Colorization with Deep Feature Propagation  and Self-regularization Learning",
    "abstract": "Video colorization is a challenging and highly ill-posed problem. Although\nrecent years have witnessed remarkable progress in single image colorization,\nthere is relatively less research effort on video colorization and existing\nmethods always suffer from severe flickering artifacts (temporal inconsistency)\nor unsatisfying colorization performance. We address this problem from a new\nperspective, by jointly considering colorization and temporal consistency in a\nunified framework. Specifically, we propose a novel temporally consistent video\ncolorization framework (TCVC). TCVC effectively propagates frame-level deep\nfeatures in a bidirectional way to enhance the temporal consistency of\ncolorization. Furthermore, TCVC introduces a self-regularization learning (SRL)\nscheme to minimize the prediction difference obtained with different time\nsteps. SRL does not require any ground-truth color videos for training and can\nfurther improve temporal consistency. Experiments demonstrate that our method\ncan not only obtain visually pleasing colorized video, but also achieve clearly\nbetter temporal consistency than state-of-the-art methods.",
    "descriptor": "\nComments: 13 pages, 10 figures\n",
    "authors": [
      "Yihao Liu",
      "Hengyuan Zhao",
      "Kelvin C.K. Chan",
      "Xintao Wang",
      "Chen Change Loy",
      "Yu Qiao",
      "Chao Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.04562"
  },
  {
    "id": "arXiv:2110.04563",
    "title": "Automatic Recognition of Abdominal Organs in Ultrasound Images based on  Deep Neural Networks and K-Nearest-Neighbor Classification",
    "abstract": "Abdominal ultrasound imaging has been widely used to assist in the diagnosis\nand treatment of various abdominal organs. In order to shorten the examination\ntime and reduce the cognitive burden on the sonographers, we present a\nclassification method that combines the deep learning techniques and\nk-Nearest-Neighbor (k-NN) classification to automatically recognize various\nabdominal organs in the ultrasound images in real time. Fine-tuned deep neural\nnetworks are used in combination with PCA dimension reduction to extract\nhigh-level features from raw ultrasound images, and a k-NN classifier is\nemployed to predict the abdominal organ in the image. We demonstrate the\neffectiveness of our method in the task of ultrasound image classification to\nautomatically recognize six abdominal organs. A comprehensive comparison of\ndifferent configurations is conducted to study the influence of different\nfeature extractors and classifiers on the classification accuracy. Both\nquantitative and qualitative results show that with minimal training effort,\nour method can \"lazily\" recognize the abdominal organs in the ultrasound images\nin real time with an accuracy of 96.67%. Our implementation code is publicly\navailable at: https://github.com/LeeKeyu/abdominal_ultrasound_classification.",
    "descriptor": "\nComments: Accepted at ROBIO 2021. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Keyu Li",
      "Yangxin Xu",
      "Max Q.-H. Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04563"
  },
  {
    "id": "arXiv:2110.04564",
    "title": "Human-Aware Robot Navigation via Reinforcement Learning with Hindsight  Experience Replay and Curriculum Learning",
    "abstract": "In recent years, the growing demand for more intelligent service robots is\npushing the development of mobile robot navigation algorithms to allow safe and\nefficient operation in a dense crowd. Reinforcement learning (RL) approaches\nhave shown superior ability in solving sequential decision making problems, and\nrecent work has explored its potential to learn navigation polices in a\nsocially compliant manner. However, the expert demonstration data used in\nexisting methods is usually expensive and difficult to obtain. In this work, we\nconsider the task of training an RL agent without employing the demonstration\ndata, to achieve efficient and collision-free navigation in a crowded\nenvironment. To address the sparse reward navigation problem, we propose to\nincorporate the hindsight experience replay (HER) and curriculum learning (CL)\ntechniques with RL to efficiently learn the optimal navigation policy in the\ndense crowd. The effectiveness of our method is validated in a simulated\ncrowd-robot coexisting environment. The results demonstrate that our method can\neffectively learn human-aware navigation without requiring additional\ndemonstration data.",
    "descriptor": "\nComments: Accepted at ROBIO 2021. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Keyu Li",
      "Ye Lu",
      "Max Q.-H. Meng"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04564"
  },
  {
    "id": "arXiv:2110.04571",
    "title": "Widen The Backdoor To Let More Attackers In",
    "abstract": "As collaborative learning and the outsourcing of data collection become more\ncommon, malicious actors (or agents) which attempt to manipulate the learning\nprocess face an additional obstacle as they compete with each other. In\nbackdoor attacks, where an adversary attempts to poison a model by introducing\nmalicious samples into the training data, adversaries have to consider that the\npresence of additional backdoor attackers may hamper the success of their own\nbackdoor. In this paper, we investigate the scenario of a multi-agent backdoor\nattack, where multiple non-colluding attackers craft and insert triggered\nsamples in a shared dataset which is used by a model (a defender) to learn a\ntask. We discover a clear backfiring phenomenon: increasing the number of\nattackers shrinks each attacker's attack success rate (ASR). We then exploit\nthis phenomenon to minimize the collective ASR of attackers and maximize\ndefender's robustness accuracy by (i) artificially augmenting the number of\nattackers, and (ii) indexing to remove the attacker's sub-dataset from the\nmodel for inference, hence proposing 2 defenses.",
    "descriptor": "",
    "authors": [
      "Siddhartha Datta",
      "Giulio Lovisotto",
      "Ivan Martinovic",
      "Nigel Shadbolt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.04571"
  },
  {
    "id": "arXiv:2110.04572",
    "title": "X-model: Improving Data Efficiency in Deep Learning with A Minimax Model",
    "abstract": "To mitigate the burden of data labeling, we aim at improving data efficiency\nfor both classification and regression setups in deep learning. However, the\ncurrent focus is on classification problems while rare attention has been paid\nto deep regression, which usually requires more human effort to labeling.\nFurther, due to the intrinsic difference between categorical and continuous\nlabel space, the common intuitions for classification, e.g., cluster\nassumptions or pseudo labeling strategies, cannot be naturally adapted into\ndeep regression. To this end, we first delved into the existing data-efficient\nmethods in deep learning and found that they either encourage invariance to\ndata stochasticity (e.g., consistency regularization under different\naugmentations) or model stochasticity (e.g., difference penalty for predictions\nof models with different dropout). To take the power of both worlds, we propose\na novel X-model by simultaneously encouraging the invariance to {data\nstochasticity} and {model stochasticity}. Further, the X-model plays a minimax\ngame between the feature extractor and task-specific heads to further enhance\nthe invariance to model stochasticity. Extensive experiments verify the\nsuperiority of the X-model among various tasks, from a single-value prediction\ntask of age estimation to a dense-value prediction task of keypoint\nlocalization, a 2D synthetic, and a 3D realistic dataset, as well as a\nmulti-category object recognition task.",
    "descriptor": "",
    "authors": [
      "Ximei Wang",
      "Xinyang Chen",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04572"
  },
  {
    "id": "arXiv:2110.04573",
    "title": "Space-Time-Separable Graph Convolutional Network for Pose Forecasting",
    "abstract": "Human pose forecasting is a complex structured-data sequence-modelling task,\nwhich has received increasing attention, also due to numerous potential\napplications. Research has mainly addressed the temporal dimension as time\nseries and the interaction of human body joints with a kinematic tree or by a\ngraph. This has decoupled the two aspects and leveraged progress from the\nrelevant fields, but it has also limited the understanding of the complex\nstructural joint spatio-temporal dynamics of the human pose. Here we propose a\nnovel Space-Time-Separable Graph Convolutional Network (STS-GCN) for pose\nforecasting. For the first time, STS-GCN models the human pose dynamics only\nwith a graph convolutional network (GCN), including the temporal evolution and\nthe spatial joint interaction within a single-graph framework, which allows the\ncross-talk of motion and spatial correlations. Concurrently, STS-GCN is the\nfirst space-time-separable GCN: the space-time graph connectivity is factored\ninto space and time affinity matrices, which bottlenecks the space-time\ncross-talk, while enabling full joint-joint and time-time correlations. Both\naffinity matrices are learnt end-to-end, which results in connections\nsubstantially deviating from the standard kinematic tree and the linear-time\ntime series. In experimental evaluation on three complex, recent and\nlarge-scale benchmarks, Human3.6M [Ionescu et al. TPAMI'14], AMASS [Mahmood et\nal. ICCV'19] and 3DPW [Von Marcard et al. ECCV'18], STS-GCN outperforms the\nstate-of-the-art, surpassing the current best technique [Mao et al. ECCV'20] by\nover 32% in average at the most difficult long-term predictions, while only\nrequiring 1.7% of its parameters. We explain the results qualitatively and\nillustrate the graph interactions by the factored joint-joint and time-time\nlearnt graph connections.\nOur source code is available at: https://github.com/FraLuca/STSGCN",
    "descriptor": "",
    "authors": [
      "Theodoros Sofianos",
      "Alessio Sampieri",
      "Luca Franco",
      "Fabio Galasso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04573"
  },
  {
    "id": "arXiv:2110.04574",
    "title": "A Faster Algorithm for Max Cut in Dense Graphs",
    "abstract": "We design an algorithm for approximating the size of \\emph{Max Cut} in dense\ngraphs. Given a proximity parameter $\\varepsilon \\in (0,1)$, our algorithm\napproximates the size of \\emph{Max Cut} of a graph $G$ with $n$ vertices,\nwithin an additive error of $\\varepsilon n^2$, with sample complexity\n$\\mathcal{O}(\\frac{1}{\\varepsilon^3} \\log^2 \\frac{1}{\\varepsilon} \\log \\log\n\\frac{1}{\\varepsilon})$ and query complexity of\n$\\mathcal{O}(\\frac{1}{\\varepsilon^4} \\log^3 \\frac{1}{\\varepsilon} \\log \\log\n\\frac{1}{\\varepsilon})$. Since Goldreich, Goldwasser and Ron (JACM 98) gave the\nfirst algorithm with sample complexity $\\mathcal{O}(\\frac{1}{\\varepsilon^5}\\log\n\\frac{1}{\\varepsilon})$ and query complexity of\n$\\mathcal{O}(\\frac{1}{\\varepsilon^7}\\log^2 \\frac{1}{\\varepsilon})$, there have\nbeen several efforts employing techniques from diverse areas with a focus on\nimproving the sample and query complexities. Our work makes the first\nimprovement in the sample complexity as well as query complexity after more\nthan a decade from the previous best results of Alon, Vega, Kannan and\nKarpinski (JCSS 03) and of Mathieu and Schudy (SODA 08) respectively, both with\nsample complexity\n$\\mathcal{O}\\left(\\frac{1}{{\\varepsilon}^4}{\\log}\\frac{1}{\\varepsilon}\\right)$.\nWe also want to note that the best time complexity of this problem was by Alon,\nVega, Karpinski and Kannan (JCSS 03). By combining their result with an\napproximation technique by Arora, Karger and Karpinski (STOC 95), they obtained\nan algorithm with time complexity of $2^{\\mathcal{O}(\\frac{1}{{\\varepsilon}^2}\n\\log \\frac{1}{\\varepsilon})}$. In this work, we have improved this further to\n$2^{\\mathcal{O}(\\frac{1}{\\varepsilon} \\log \\frac{1}{\\varepsilon} )}$.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Arijit Ghosh",
      "Gopinath Mishra",
      "Rahul Raychaudhury",
      "Sayantan Sen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.04574"
  },
  {
    "id": "arXiv:2110.04580",
    "title": "Active Altruism Learning and Information Sufficiency for Autonomous  Driving",
    "abstract": "Safe interaction between vehicles requires the ability to choose actions that\nreveal the preferences of the other vehicles. Since exploratory actions often\ndo not directly contribute to their objective, an interactive vehicle must also\nable to identify when it is appropriate to perform them. In this work we\ndemonstrate how Active Learning methods can be used to incentivise an\nautonomous vehicle (AV) to choose actions that reveal information about the\naltruistic inclinations of another vehicle. We identify a property, Information\nSufficiency, that a reward function should have in order to keep exploration\nfrom unnecessarily interfering with the pursuit of an objective. We empirically\ndemonstrate that reward functions that do not have Information Sufficiency are\nprone to inadequate exploration, which can result in sub-optimal behaviour. We\npropose a reward definition that has Information Sufficiency, and show that it\nfacilitates an AV choosing exploratory actions to estimate altruistic tendency,\nwhilst also compensating for the possibility of conflicting beliefs between\nvehicles.",
    "descriptor": "\nComments: 9 pages, 10 figures\n",
    "authors": [
      "Jack Geary",
      "Henry Gouk",
      "Subramanian Ramamoorthy"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.04580"
  },
  {
    "id": "arXiv:2110.04582",
    "title": "Numerical modelling of variable density shallow water flows with  friction term",
    "abstract": "In this study, we focus on the modelling of coupled systems of shallow water\nflows and solute transport with source terms due to variable topography and\nfriction effect. Our aim is to propose efficient and accurate numerical\ntechniques for modelling these systems using unstructured triangular grids. We\nused a Riemann-solver free method for the hyperbolic shallow water system and a\nsuitable discretization technique for the bottom topography. The friction\nsource term is discretized using the techniques proposed by (Xia and Liang\n2018). Our approach performs very well for stationary flow in the presence of\nvariable topography, and it is well-balanced for the concentration in the\npresence of wet and dry zones. In our techniques, we used linear piecewise\nreconstructions for the variables of the coupled system. The proposed method is\nwell-balanced, and we prove that it exactly preserves the nontrivial\nsteady-state solutions of the coupled system. Numerical experiments are carried\nout to validate the performance and robustness of the proposed numerical\nmethod. Our numerical results show that the method is stable, well-balanced and\naccurate to model the coupled systems of shallow water flows and solute\ntransport.",
    "descriptor": "\nComments: 10 pages, 4 figures, Conference paper\n",
    "authors": [
      "Amine Hanini",
      "Abdelaziz Beljadid",
      "Driss Ouazar"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.04582"
  },
  {
    "id": "arXiv:2110.04590",
    "title": "An Exploration of Self-Supervised Pretrained Representations for  End-to-End Speech Recognition",
    "abstract": "Self-supervised pretraining on speech data has achieved a lot of progress.\nHigh-fidelity representation of the speech signal is learned from a lot of\nuntranscribed data and shows promising performance. Recently, there are several\nworks focusing on evaluating the quality of self-supervised pretrained\nrepresentations on various tasks without domain restriction, e.g. SUPERB.\nHowever, such evaluations do not provide a comprehensive comparison among many\nASR benchmark corpora. In this paper, we focus on the general applications of\npretrained speech representations, on advanced end-to-end automatic speech\nrecognition (E2E-ASR) models. We select several pretrained speech\nrepresentations and present the experimental results on various open-source and\npublicly available corpora for E2E-ASR. Without any modification of the\nback-end model architectures or training strategy, some of the experiments with\npretrained representations, e.g., WSJ, WSJ0-2mix with HuBERT, reach or\noutperform current state-of-the-art (SOTA) recognition performance. Moreover,\nwe further explore more scenarios for whether the pretraining representations\nare effective, such as the cross-language or overlapped speech. The scripts,\nconfiguratons and the trained models have been released in ESPnet to let the\ncommunity reproduce our experiments and improve them.",
    "descriptor": "\nComments: To appear in ASRU2021\n",
    "authors": [
      "Xuankai Chang",
      "Takashi Maekaku",
      "Pengcheng Guo",
      "Jing Shi",
      "Yen-Ju Lu",
      "Aswin Shanmugam Subramanian",
      "Tianzi Wang",
      "Shu-wen Yang",
      "Yu Tsao",
      "Hung-yi Lee",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.04590"
  },
  {
    "id": "arXiv:2110.04593",
    "title": "Flattening Sharpness for Dynamic Gradient Projection Memory Benefits  Continual Learning",
    "abstract": "The backpropagation networks are notably susceptible to catastrophic\nforgetting, where networks tend to forget previously learned skills upon\nlearning new ones. To address such the 'sensitivity-stability' dilemma, most\nprevious efforts have been contributed to minimizing the empirical risk with\ndifferent parameter regularization terms and episodic memory, but rarely\nexploring the usages of the weight loss landscape. In this paper, we\ninvestigate the relationship between the weight loss landscape and\nsensitivity-stability in the continual learning scenario, based on which, we\npropose a novel method, Flattening Sharpness for Dynamic Gradient Projection\nMemory (FS-DGPM). In particular, we introduce a soft weight to represent the\nimportance of each basis representing past tasks in GPM, which can be\nadaptively learned during the learning process, so that less important bases\ncan be dynamically released to improve the sensitivity of new skill learning.\nWe further introduce Flattening Sharpness (FS) to reduce the generalization gap\nby explicitly regulating the flatness of the weight loss landscape of all seen\ntasks. As demonstrated empirically, our proposed method consistently\noutperforms baselines with the superior ability to learn new skills while\nalleviating forgetting effectively.",
    "descriptor": "\nComments: NeurIPS2021\n",
    "authors": [
      "Danruo Deng",
      "Guangyong Chen",
      "Jianye Hao",
      "Qiong Wang",
      "Pheng-Ann Heng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04593"
  },
  {
    "id": "arXiv:2110.04596",
    "title": "Deep Long-Tailed Learning: A Survey",
    "abstract": "Deep long-tailed learning, one of the most challenging problems in visual\nrecognition, aims to train well-performing deep models from a large number of\nimages that follow a long-tailed class distribution. In the last decade, deep\nlearning has emerged as a powerful recognition model for learning high-quality\nimage representations and has led to remarkable breakthroughs in generic visual\nrecognition. However, long-tailed class imbalance, a common problem in\npractical visual recognition tasks, often limits the practicality of deep\nnetwork based recognition models in real-world applications, since they can be\neasily biased towards dominant classes and perform poorly on tail classes. To\naddress this problem, a large number of studies have been conducted in recent\nyears, making promising progress in the field of deep long-tailed learning.\nConsidering the rapid evolution of this field, this paper aims to provide a\ncomprehensive survey on recent advances in deep long-tailed learning. To be\nspecific, we group existing deep long-tailed learning studies into three main\ncategories (i.e., class re-balancing, information augmentation and module\nimprovement), and review these methods following this taxonomy in detail.\nAfterward, we empirically analyze several state-of-the-art methods by\nevaluating to what extent they address the issue of class imbalance via a newly\nproposed evaluation metric, i.e., relative accuracy. We conclude the survey by\nhighlighting important applications of deep long-tailed learning and\nidentifying several promising directions for future research.",
    "descriptor": "",
    "authors": [
      "Yifan Zhang",
      "Bingyi Kang",
      "Bryan Hooi",
      "Shuicheng Yan",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04596"
  },
  {
    "id": "arXiv:2110.04597",
    "title": "A Proximal Algorithm for Sampling from Non-smooth Potentials",
    "abstract": "Markov chain Monte Carlo (MCMC) is an effective and dominant method to sample\nfrom high-dimensional complex distributions. Yet, most existing MCMC methods\nare only applicable to settings with smooth potentials (log-densities). In this\nwork, we examine sampling problems with non-smooth potentials. We propose a\nnovel MCMC algorithm for sampling from non-smooth potentials. We provide a\nnon-asymptotical analysis of our algorithm and establish a polynomial-time\ncomplexity $\\tilde {\\cal O}(d\\varepsilon^{-1})$ to obtain $\\varepsilon$ total\nvariation distance to the target density, better than all existing results\nunder the same assumptions. Our method is based on the proximal bundle method\nand an alternating sampling framework. This framework requires the so-called\nrestricted Gaussian oracle, which can be viewed as a sampling counterpart of\nthe proximal mapping in convex optimization. One key contribution of this work\nis a fast algorithm that realizes the restricted Gaussian oracle for any convex\nnon-smooth potential with bounded Lipschitz constant.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Jiaming Liang",
      "Yongxin Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.04597"
  },
  {
    "id": "arXiv:2110.04598",
    "title": "Self-explaining Neural Network with Plausible Explanations",
    "abstract": "Explaining the predictions of complex deep learning models, often referred to\nas black boxes, is critical in high-stakes domains like healthcare. However,\npost-hoc model explanations often are not understandable by clinicians and are\ndifficult to integrate into clinical workflow. Further, while most explainable\nmodels use individual clinical variables as units of explanation, human\nunderstanding often rely on higher-level concepts or feature representations.\nIn this paper, we propose a novel, self-explaining neural network for\nlongitudinal in-hospital mortality prediction using domain-knowledge driven\nSequential Organ Failure Assessment (SOFA) organ-specific scores as the atomic\nunits of explanation. We also design a novel procedure to quantitatively\nvalidate the model explanations against gold standard discharge diagnosis\ninformation of patients. Our results provide interesting insights into how each\nof the SOFA organ scores contribute to mortality at different timesteps within\nlongitudinal patient trajectory.",
    "descriptor": "\nComments: Machine Learning for Health (ML4H) 2021\n",
    "authors": [
      "Sayantan Kumar",
      "Sean C. Yu",
      "Andrew Michelson",
      "Philip R.O. Payne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04598"
  },
  {
    "id": "arXiv:2110.04599",
    "title": "Embed Everything: A Method for Efficiently Co-Embedding Multi-Modal  Spaces",
    "abstract": "Any general artificial intelligence system must be able to interpret, operate\non, and produce data in a multi-modal latent space that can represent audio,\nimagery, text, and more. In the last decade, deep neural networks have seen\nremarkable success in unimodal data distributions, while transfer learning\ntechniques have seen a massive expansion of model reuse across related domains.\nHowever, training multi-modal networks from scratch remains expensive and\nillusive, while heterogeneous transfer learning (HTL) techniques remain\nrelatively underdeveloped. In this paper, we propose a novel and cost-effective\nHTL strategy for co-embedding multi-modal spaces. Our method avoids cost\ninefficiencies by preprocessing embeddings using pretrained models for all\ncomponents, without passing gradients through these models. We prove the use of\nthis system in a joint image-audio embedding task. Our method has wide-reaching\napplications, as successfully bridging the gap between different latent spaces\ncould provide a framework for the promised \"universal\" embedding.",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Sarah Di",
      "Robin Yu",
      "Amol Kapoor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.04599"
  },
  {
    "id": "arXiv:2110.04600",
    "title": "A Review of Physics-based Machine Learning in Civil Engineering",
    "abstract": "The recent development of machine learning (ML) and Deep Learning (DL)\nincreases the opportunities in all the sectors. ML is a significant tool that\ncan be applied across many disciplines, but its direct application to civil\nengineering problems can be challenging. ML for civil engineering applications\nthat are simulated in the lab often fail in real-world tests. This is usually\nattributed to a data mismatch between the data used to train and test the ML\nmodel and the data it encounters in the real world, a phenomenon known as data\nshift. However, a physics-based ML model integrates data, partial differential\nequations (PDEs), and mathematical models to solve data shift problems.\nPhysics-based ML models are trained to solve supervised learning tasks while\nrespecting any given laws of physics described by general nonlinear equations.\nPhysics-based ML, which takes center stage across many science disciplines,\nplays an important role in fluid dynamics, quantum mechanics, computational\nresources, and data storage. This paper reviews the history of physics-based ML\nand its application in civil engineering.",
    "descriptor": "",
    "authors": [
      "Shashank Reddy Vadyala",
      "Sai Nethra Betgeri1",
      "Dr. John C. Matthews",
      "Dr. Elizabeth Matthews"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04600"
  },
  {
    "id": "arXiv:2110.04603",
    "title": "Learning Single/Multi-Attribute of Object with Symmetry and Group",
    "abstract": "Attributes and objects can compose diverse compositions. To model the\ncompositional nature of these concepts, it is a good choice to learn them as\ntransformations, e.g., coupling and decoupling. However, complex\ntransformations need to satisfy specific principles to guarantee rationality.\nHere, we first propose a previously ignored principle of attribute-object\ntransformation: Symmetry. For example, coupling peeled-apple with attribute\npeeled should result in peeled-apple, and decoupling peeled from apple should\nstill output apple. Incorporating the symmetry, we propose a transformation\nframework inspired by group theory, i.e., SymNet. It consists of two modules:\nCoupling Network and Decoupling Network. We adopt deep neural networks to\nimplement SymNet and train it in an end-to-end paradigm with the group axioms\nand symmetry as objectives. Then, we propose a Relative Moving Distance (RMD)\nbased method to utilize the attribute change instead of the attribute pattern\nitself to classify attributes. Besides the compositions of single-attribute and\nobject, our RMD is also suitable for complex compositions of multiple\nattributes and objects when incorporating attribute correlations. SymNet can be\nutilized for attribute learning, compositional zero-shot learning and\noutperforms the state-of-the-art on four widely-used benchmarks. Code is at\nhttps://github.com/DirtyHarryLYL/SymNet.",
    "descriptor": "\nComments: TPAMI, an extended version of SymNet (CVPR'20), a part of HAKE-Object. Code: this https URL arXiv admin note: substantial text overlap with arXiv:2004.00587\n",
    "authors": [
      "Yong-Lu Li",
      "Yue Xu",
      "Xinyu Xu",
      "Xiaohan Mao",
      "Cewu Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04603"
  },
  {
    "id": "arXiv:2110.04605",
    "title": "A novel finite element approximation of anisotropic curve shortening  flow",
    "abstract": "We extend the DeTurck trick from the classical isotropic curve shortening\nflow to the anisotropic setting. Here the anisotropic energy density is allowed\nto depend on space, which allows an interpretation in the context of Finsler\nmetrics, giving rise to e.g.\\ geodesic curvature flow in Riemannian manifolds.\nAssuming that the density is strictly convex and smooth, we introduce a novel\nweak formulation for anisotropic curve shortening flow. We then derive an\noptimal $H^1$--error bound for a continuous-in-time semidiscrete finite element\napproximation that uses piecewise linear elements. In addition, we consider\nsome fully practical fully discrete schemes and prove their unconditional\nstability. Finally, we present several numerical simulations, including some\nconvergence experiments that confirm the derived error bound, as well as\napplications to crystalline curvature flow and geodesic curvature flow.",
    "descriptor": "\nComments: 31 pages, 12 figures\n",
    "authors": [
      "Klaus Deckelnick",
      "Robert N\u00fcrnberg"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2110.04605"
  },
  {
    "id": "arXiv:2110.04606",
    "title": "Linear-time algorithm for vertex 2-coloring without monochromatic  triangles on planar graphs",
    "abstract": "In the problem of 2-coloring without monochromatic triangles (or\ntriangle-tree 2-coloring), vertices of the simple, connected, undirected graph\nare colored with either 'black' or 'white' such that there are no 3 mutually\nadjacent vertices of the same color. In this paper we are positively answering\nthe question posed in our previous work, namely, if there exists an algorithm\nsolving 2-coloring without monochromatic triangles on planar graphs with\nlinear-time complexity.",
    "descriptor": "",
    "authors": [
      "Micha\u0142 Karpi\u0144ski",
      "Krzysztof Piecuch"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.04606"
  },
  {
    "id": "arXiv:2110.04614",
    "title": "Empathetic Response Generation through Graph-based Multi-hop Reasoning  on Emotional Causality",
    "abstract": "Empathetic response generation aims to comprehend the user emotion and then\nrespond to it appropriately. Most existing works merely focus on what the\nemotion is and ignore how the emotion is evoked, thus weakening the capacity of\nthe model to understand the emotional experience of the user for generating\nempathetic responses. To tackle this problem, we consider the emotional\ncausality, namely, what feelings the user expresses (i.e., emotion) and why the\nuser has such feelings (i.e., cause). Then, we propose a novel graph-based\nmodel with multi-hop reasoning to model the emotional causality of the\nempathetic conversation. Finally, we demonstrate the effectiveness of our model\non EMPATHETICDIALOGUES in comparison with several competitive models.",
    "descriptor": "\nComments: The manuscript is accepted and published in Knowledge-Based Systems\n",
    "authors": [
      "Jiashuo Wang",
      "Wenjie LI",
      "Peiqin Lin",
      "Feiteng Mu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04614"
  },
  {
    "id": "arXiv:2110.04615",
    "title": "Evaluation and Ranking of Replica Deployments in Geographic State  Machine Replication",
    "abstract": "Geographic state machine replication (SMR) is a replication method in which\nreplicas of a service are located on multiple continents to improve the fault\ntolerance of a general service. Nowadays, geographic SMR is easily realized\nusing public cloud services; SMR provides extraordinary resilience against\ncatastrophic disasters. Previous studies have revealed that the geographic\ndistribution of the replicas has a significant influence on the performance of\nthe geographic SMR; however, the optimal way for a system integrator to deploy\nreplicas remains unknown. In this paper, we propose a method to evaluate and\nrank replica deployments to assist a system integrator in deciding a final\nreplica deployment. In the method, we also propose a novel evaluation function\nthat estimates a latency of SMR protocols with round-trip time (RTT). To\ndemonstrate the effectiveness of the proposed method, we build thousands of\ngeographic SMRs on Amazon Web Services and present experimental results. The\nresults show that the proposed method that estimates a latency based on RTTs\ncan generate consistent rankings with reasonable calculation time.",
    "descriptor": "",
    "authors": [
      "Shota Numakura",
      "Junya Nakamura",
      "Ren Ohmura"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.04615"
  },
  {
    "id": "arXiv:2110.04616",
    "title": "Discriminative Multimodal Learning via Conditional Priors in Generative  Models",
    "abstract": "Deep generative models with latent variables have been used lately to learn\njoint representations and generative processes from multi-modal data. These two\nlearning mechanisms can, however, conflict with each other and representations\ncan fail to embed information on the data modalities. This research studies the\nrealistic scenario in which all modalities and class labels are available for\nmodel training, but where some modalities and labels required for downstream\ntasks are missing. We show, in this scenario, that the variational lower bound\nlimits mutual information between joint representations and missing modalities.\nWe, to counteract these problems, introduce a novel conditional multi-modal\ndiscriminative model that uses an informative prior distribution and optimizes\na likelihood-free objective function that maximizes mutual information between\njoint representations and missing modalities. Extensive experimentation shows\nthe benefits of the model we propose, the empirical results showing that our\nmodel achieves state-of-the-art results in representative problems such as\ndownstream classification, acoustic inversion and annotation generation.",
    "descriptor": "",
    "authors": [
      "Rogelio A. Mancisidor",
      "Michael Kampffmeyer",
      "Kjersti Aas",
      "Robert Jenssen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04616"
  },
  {
    "id": "arXiv:2110.04618",
    "title": "A Multiple Snapshot Attack on Deniable Storage Systems",
    "abstract": "While disk encryption is suitable for use in most situations where\nconfidentiality of disks is required, stronger guarantees are required in\nsituations where adversaries may employ coercive tactics to gain access to\ncryptographic keys. Deniable volumes are one such solution in which the\nsecurity goal is to prevent an adversary from discovering that there is an\nencrypted volume. Multiple snapshot attacks, where an adversary is able to gain\naccess to two or more images of a disk, have often been proposed in the\ndeniable storage system literature; however, there have been no concrete\nattacks proposed or carried out. We present the first multiple snapshot attack,\nand we find that it is applicable to most, if not all, implemented deniable\nstorage systems. Our attack leverages the pattern of consecutive block changes\nan adversary would have access to with two snapshots, and demonstrate that with\nhigh probability it detects moderately sized and large hidden volumes, while\nmaintaining a low false positive rate.",
    "descriptor": "\nComments: Submitted to MASCOTS 2021\n",
    "authors": [
      "Kyle Fredrickson",
      "Austen Barker",
      "Darrell D. E. Long"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.04618"
  },
  {
    "id": "arXiv:2110.04619",
    "title": "Google Landmark Retrieval 2021 Competition Third Place Solution",
    "abstract": "We present our solutions to the Google Landmark Challenges 2021, for both the\nretrieval and the recognition tracks. Both solutions are ensembles of\ntransformers and ConvNet models based on Sub-center ArcFace with dynamic\nmargins. Since the two tracks share the same training data, we used the same\npipeline and training approach, but with different model selections for the\nensemble and different post-processing. The key improvement over last year is\nnewer state-of-the-art vision architectures, especially transformers which\nsignificantly outperform ConvNets for the retrieval task. We finished third and\nfourth places for the retrieval and recognition tracks respectively.",
    "descriptor": "",
    "authors": [
      "Qishen Ha",
      "Bo Liu",
      "Hongwei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04619"
  },
  {
    "id": "arXiv:2110.04620",
    "title": "A Framework for Rationale Extraction for Deep QA models",
    "abstract": "As neural-network-based QA models become deeper and more complex, there is a\ndemand for robust frameworks which can access a model's rationale for its\nprediction. Current techniques that provide insights on a model's working are\neither dependent on adversarial datasets or are proposing models with explicit\nexplanation generation components. These techniques are time-consuming and\nchallenging to extend to existing models and new datasets. In this work, we use\n`Integrated Gradients' to extract rationale for existing state-of-the-art\nmodels in the task of Reading Comprehension based Question Answering (RCQA). On\ndetailed analysis and comparison with collected human rationales, we find that\nthough ~40-80% words of extracted rationale coincide with the human rationale\n(precision), only 6-19% of human rationale is present in the extracted\nrationale (recall).",
    "descriptor": "\nComments: 5 pages including references\n",
    "authors": [
      "Sahana Ramnath",
      "Preksha Nema",
      "Deep Sahni",
      "Mitesh M. Khapra"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04620"
  },
  {
    "id": "arXiv:2110.04621",
    "title": "Universal Paralinguistic Speech Representations Using Self-Supervised  Conformers",
    "abstract": "Many speech applications require understanding aspects beyond the words being\nspoken, such as recognizing emotion, detecting whether the speaker is wearing a\nmask, or distinguishing real from synthetic speech. In this work, we introduce\na new state-of-the-art paralinguistic representation derived from large-scale,\nfully self-supervised training of a 600M+ parameter Conformer-based\narchitecture. We benchmark on a diverse set of speech tasks and demonstrate\nthat simple linear classifiers trained on top of our time-averaged\nrepresentation outperform nearly all previous results, in some cases by large\nmargins. Our analyses of context-window size demonstrate that, surprisingly, 2\nsecond context-windows achieve 98% the performance of the Conformers that use\nthe full long-term context. Furthermore, while the best per-task\nrepresentations are extracted internally in the network, stable performance\nacross several layers allows a single universal representation to reach near\noptimal performance on all tasks.",
    "descriptor": "",
    "authors": [
      "Joel Shor",
      "Aren Jansen",
      "Wei Han",
      "Daniel Park",
      "Yu Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.04621"
  },
  {
    "id": "arXiv:2110.04622",
    "title": "Does Preprocessing Help Training Over-parameterized Neural Networks?",
    "abstract": "Deep neural networks have achieved impressive performance in many areas.\nDesigning a fast and provable method for training neural networks is a\nfundamental question in machine learning.\nThe classical training method requires paying $\\Omega(mnd)$ cost for both\nforward computation and backward computation, where $m$ is the width of the\nneural network, and we are given $n$ training points in $d$-dimensional space.\nIn this paper, we propose two novel preprocessing ideas to bypass this\n$\\Omega(mnd)$ barrier:\n$\\bullet$ First, by preprocessing the initial weights of the neural networks,\nwe can train the neural network in $\\widetilde{O}(m^{1-\\Theta(1/d)} n d)$ cost\nper iteration.\n$\\bullet$ Second, by preprocessing the input data points, we can train the\nneural network in $\\widetilde{O} (m^{4/5} nd )$ cost per iteration.\nFrom the technical perspective, our result is a sophisticated combination of\ntools in different fields, greedy-type convergence analysis in optimization,\nsparsity observation in practical work, high-dimensional geometric search in\ndata structure, concentration and anti-concentration in probability. Our\nresults also provide theoretical insights for a large number of previously\nestablished fast training methods.\nIn addition, our classical algorithm can be generalized to the Quantum\ncomputation model. Interestingly, we can get a similar sublinear cost per\niteration but avoid preprocessing initial weights or input data points.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Zhao Song",
      "Shuo Yang",
      "Ruizhe Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04622"
  },
  {
    "id": "arXiv:2110.04627",
    "title": "Vector-quantized Image Modeling with Improved VQGAN",
    "abstract": "Pretraining language models with next-token prediction on massive text\ncorpora has delivered phenomenal zero-shot, few-shot, transfer learning and\nmulti-tasking capabilities on both generative and discriminative language\ntasks. Motivated by this success, we explore a Vector-quantized Image Modeling\n(VIM) approach that involves pretraining a Transformer to predict rasterized\nimage tokens autoregressively. The discrete image tokens are encoded from a\nlearned Vision-Transformer-based VQGAN (ViT-VQGAN). We first propose multiple\nimprovements over vanilla VQGAN from architecture to codebook learning,\nyielding better efficiency and reconstruction fidelity. The improved ViT-VQGAN\nfurther improves vector-quantized image modeling tasks, including\nunconditional, class-conditioned image generation and unsupervised\nrepresentation learning. When trained on ImageNet at 256x256 resolution, we\nachieve Inception Score (IS) of 175.1 and Fr'echet Inception Distance (FID) of\n4.17, a dramatic improvement over the vanilla VQGAN, which obtains 70.6 and\n17.04 for IS and FID, respectively. Based on ViT-VQGAN and unsupervised\npretraining, we further evaluate the pretrained Transformer by averaging\nintermediate features, similar to Image GPT (iGPT). This ImageNet-pretrained\nVIM-L significantly beats iGPT-L on linear-probe accuracy from 60.3% to 72.2%\nfor a similar model size. ViM-L also outperforms iGPT-XL which is trained with\nextra web image data and larger model size.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Jiahui Yu",
      "Xin Li",
      "Jing Yu Koh",
      "Han Zhang",
      "Ruoming Pang",
      "James Qin",
      "Alexander Ku",
      "Yuanzhong Xu",
      "Jason Baldridge",
      "Yonghui Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04627"
  },
  {
    "id": "arXiv:2110.04629",
    "title": "Evaluating Predictive Distributions: Does Bayesian Deep Learning Work?",
    "abstract": "Posterior predictive distributions quantify uncertainties ignored by point\nestimates. This paper introduces \\textit{The Neural Testbed}, which provides\ntools for the systematic evaluation of agents that generate such predictions.\nCrucially, these tools assess not only the quality of marginal predictions per\ninput, but also joint predictions given many inputs. Joint distributions are\noften critical for useful uncertainty quantification, but they have been\nlargely overlooked by the Bayesian deep learning community. We benchmark\nseveral approaches to uncertainty estimation using a neural-network-based data\ngenerating process. Our results reveal the importance of evaluation beyond\nmarginal predictions. Further, they reconcile sources of confusion in the\nfield, such as why Bayesian deep learning approaches that generate accurate\nmarginal predictions perform poorly in sequential decision tasks, how\nincorporating priors can be helpful, and what roles epistemic versus aleatoric\nuncertainty play when evaluating performance. We also present experiments on\nreal-world challenge datasets, which show a high correlation with testbed\nresults, and that the importance of evaluating joint predictive distributions\ncarries over to real data. As part of this effort, we opensource The Neural\nTestbed, including all implementations from this paper.",
    "descriptor": "",
    "authors": [
      "Ian Osband",
      "Zheng Wen",
      "Seyed Mohammad Asghari",
      "Vikranth Dwaracherla",
      "Botao Hao",
      "Morteza Ibrahimi",
      "Dieterich Lawson",
      "Xiuyuan Lu",
      "Brendan O'Donoghue",
      "Benjamin Van Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04629"
  },
  {
    "id": "arXiv:2110.04633",
    "title": "Credit Assignment Safety Learning from Human Demonstrations",
    "abstract": "A critical need in assistive robotics, such as assistive wheelchairs for\nnavigation, is a need to learn task intent and safety guarantees through user\ninteractions in order to ensure safe task performance. For tasks where the\nobjectives from the user are not easily defined, learning from user\ndemonstrations has been a key step in enabling learning. However, most robot\nlearning from demonstration (LfD) methods primarily rely on optimal\ndemonstration in order to successfully learn a control policy, which can be\nchallenging to acquire from novice users. Recent work does use suboptimal and\nfailed demonstrations to learn about task intent; few focus on learning safety\nguarantees to prevent repeat failures experienced, essential for assistive\nrobots. Furthermore, interactive human-robot learning aims to minimize effort\nfrom the human user to facilitate deployment in the real-world. As such,\nrequiring users to label the unsafe states or keyframes from the demonstrations\nshould not be a necessary requirement for learning. Here, we propose an\nalgorithm to learn a safety value function from a set of suboptimal and failed\ndemonstrations that is used to generate a real-time safety control filter.\nImportantly, we develop a credit assignment method that extracts the failure\nstates from the failed demonstrations without requiring human labelling or\nprespecified knowledge of unsafe regions. Furthermore, we extend our\nformulation to allow for user-specific safety functions, by incorporating\nuser-defined safety rankings from which we can generate safety level sets\naccording to the users' preferences. By using both suboptimal and failed\ndemonstrations and the developed credit assignment formulation, we enable\nlearning a safety value function with minimal effort needed from the user,\nmaking it more feasible for widespread use in human-robot interactive learning\ntasks.",
    "descriptor": "\nComments: Presented at AI-HRI symposium as part of AAAI-FSS 2021 (arXiv:2109.10836)\n",
    "authors": [
      "Ahalya Prabhakar",
      "Aude Billard"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.04633"
  },
  {
    "id": "arXiv:2110.04634",
    "title": "Multimodal Sensory Learning for Real-time, Adaptive Manipulation",
    "abstract": "Adaptive control for real-time manipulation requires quick estimation and\nprediction of object properties. While robot learning in this area primarily\nfocuses on using vision, many tasks cannot rely on vision due to object\nocclusion. Here, we formulate a learning framework that uses multimodal sensory\nfusion of tactile and audio data in order to quickly characterize and predict\nan object's properties. The predictions are used in a developed reactive\ncontroller to adapt the grip on the object to compensate for the predicted\ninertial forces experienced during motion. Drawing inspiration from how humans\ninteract with objects, we propose an experimental setup from which we can\nunderstand how to best utilize different sensory signals and actively interact\nwith and manipulate objects to quickly learn their object properties for safe\nmanipulation.",
    "descriptor": "\nComments: Presented at AI-HRI symposium as part of AAAI-FSS 2021 (arXiv:2109.10836)\n",
    "authors": [
      "Ahalya Prabhakar",
      "Stanislas Furrer",
      "Lorenzo Panchetti",
      "Maxence Perret",
      "Aude Billard"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.04634"
  },
  {
    "id": "arXiv:2110.04638",
    "title": "An Independent Learning Algorithm for a Class of Symmetric Stochastic  Games",
    "abstract": "In multi-agent reinforcement learning, independent learners are those that do\nnot access the action selections of other learning agents in the system. This\npaper investigates the feasibility of using independent learners to find\napproximate equilibrium policies in non-episodic, discounted stochastic games.\nWe define a property, here called the $\\epsilon$-revision paths property, and\nprove that a class of games exhibiting symmetry among the players has this\nproperty for any $\\epsilon \\geq 0$. Building on this result, we present an\nindependent learning algorithm that comes with high probability guarantees of\napproximate equilibrium in this class of games. This guarantee is made assuming\nsymmetry alone, without additional assumptions such as a zero sum, team, or\npotential game structure.",
    "descriptor": "",
    "authors": [
      "Bora Yongacoglu",
      "G\u00fcrdal Arslan",
      "Serdar Y\u00fcksel"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.04638"
  },
  {
    "id": "arXiv:2110.04639",
    "title": "Multi-task learning on the edge: cost-efficiency and theoretical  optimality",
    "abstract": "This article proposes a distributed multi-task learning (MTL) algorithm based\non supervised principal component analysis (SPCA) which is: (i) theoretically\noptimal for Gaussian mixtures, (ii) computationally cheap and scalable.\nSupporting experiments on synthetic and real benchmark data demonstrate that\nsignificant energy gains can be obtained with no performance loss.",
    "descriptor": "\nComments: 4 pages, 5 figures, code to reproduce figure available at: this https URL\n",
    "authors": [
      "Sami Fakhry",
      "Romain Couillet",
      "Malik Tiomoko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04639"
  },
  {
    "id": "arXiv:2110.04640",
    "title": "Lookup or Exploratory: What is Your Search Intent?",
    "abstract": "Search query specificity is broadly divided into two categories - Exploratory\nor Lookup. If a query specificity can be identified at the run time, it can be\nused to significantly improve the search results as well as quality of\nsuggestions to alter the query. However, with millions of queries coming every\nday on a commercial search engine, it is non-trivial to develop a horizontal\ntechnique to determine query specificity at run time. Existing techniques\nsuffer either from lack of enough training data or are dependent on information\nsuch as query length or session information. In this paper, we show that such\nmethodologies are inadequate or at times misleading. We propose a novel\nmethodology, to overcome these limitations. First, we demonstrate a\nheuristic-based method to identify Exploratory or Lookup intent queries at\nscale, classifying millions of queries into the two classes with a high\naccuracy, as shown in our experiments. Our methodology is not dependent on\nsession data or on query length. Next, we train a transformer-based deep neural\nnetwork to classify the queries into one of the two classes at run time. Our\nmethod uses a bidirectional GRU initialized with pretrained BERT-base-uncased\nembeddings and an augmented triplet loss to classify the intent of queries\nwithout using any session data. We also introduce a novel Semi-Greedy Iterative\nTraining approach to fine-tune our model. Our model is deployable for real time\nquery specificity identification with response time of less than one\nmillisecond. Our technique is generic, and the results have valuable\nimplications for improving the quality of search results and suggestions.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Manoj K. Agarwal",
      "Tezan Sahu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.04640"
  },
  {
    "id": "arXiv:2110.04644",
    "title": "On the Relation between Syntactic Divergence and Zero-Shot Performance",
    "abstract": "We explore the link between the extent to which syntactic relations are\npreserved in translation and the ease of correctly constructing a parse tree in\na zero-shot setting. While previous work suggests such a relation, it tends to\nfocus on the macro level and not on the level of individual edges-a gap we aim\nto address. As a test case, we take the transfer of Universal Dependencies (UD)\nparsing from English to a diverse set of languages and conduct two sets of\nexperiments. In one, we analyze zero-shot performance based on the extent to\nwhich English source edges are preserved in translation. In another, we apply\nthree linguistically motivated transformations to UD, creating more\ncross-lingually stable versions of it, and assess their zero-shot parsability.\nIn order to compare parsing performance across different schemes, we perform\nextrinsic evaluation on the downstream task of cross-lingual relation\nextraction (RE) using a subset of a popular English RE benchmark translated to\nRussian and Korean. In both sets of experiments, our results suggest a strong\nrelation between cross-lingual stability and zero-shot parsing performance.",
    "descriptor": "\nComments: Accepted to EMNLP 2021\n",
    "authors": [
      "Ofir Arviv",
      "Dmitry Nikolaev",
      "Taelin Karidi",
      "Omri Abend"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04644"
  },
  {
    "id": "arXiv:2110.04645",
    "title": "Breaking the Sample Complexity Barrier to Regret-Optimal Model-Free  Reinforcement Learning",
    "abstract": "Achieving sample efficiency in online episodic reinforcement learning (RL)\nrequires optimally balancing exploration and exploitation. When it comes to a\nfinite-horizon episodic Markov decision process with $S$ states, $A$ actions\nand horizon length $H$, substantial progress has been achieved towards\ncharacterizing the minimax-optimal regret, which scales on the order of\n$\\sqrt{H^2SAT}$ (modulo log factors) with $T$ the total number of samples.\nWhile several competing solution paradigms have been proposed to minimize\nregret, they are either memory-inefficient, or fall short of optimality unless\nthe sample size exceeds an enormous threshold (e.g., $S^6A^4\n\\,\\mathrm{poly}(H)$ for existing model-free methods).\nTo overcome such a large sample size barrier to efficient RL, we design a\nnovel model-free algorithm, with space complexity $O(SAH)$, that achieves\nnear-optimal regret as soon as the sample size exceeds the order of\n$SA\\,\\mathrm{poly}(H)$. In terms of this sample size requirement (also referred\nto the initial burn-in cost),\nour method improves -- by at least a factor of $S^5A^3$ -- upon any prior\nmemory-efficient algorithm that is asymptotically regret-optimal. Leveraging\nthe recently introduced variance reduction strategy (also called {\\em\nreference-advantage decomposition}), the proposed algorithm employs an {\\em\nearly-settled} reference update rule, with the aid of two Q-learning sequences\nwith upper and lower confidence bounds. The design principle of our\nearly-settled variance reduction method might be of independent interest to\nother RL settings that involve intricate exploration-exploitation trade-offs.",
    "descriptor": "\nComments: Short version in Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Gen Li",
      "Laixi Shi",
      "Yuxin Chen",
      "Yuantao Gu",
      "Yuejie Chi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04645"
  },
  {
    "id": "arXiv:2110.04647",
    "title": "Learning to Follow Language Instructions with Compositional Policies",
    "abstract": "We propose a framework that learns to execute natural language instructions\nin an environment consisting of goal-reaching tasks that share components of\ntheir task descriptions. Our approach leverages the compositionality of both\nvalue functions and language, with the aim of reducing the sample complexity of\nlearning novel tasks. First, we train a reinforcement learning agent to learn\nvalue functions that can be subsequently composed through a Boolean algebra to\nsolve novel tasks. Second, we fine-tune a seq2seq model pretrained on web-scale\ncorpora to map language to logical expressions that specify the required value\nfunction compositions. Evaluating our agent in the BabyAI domain, we observe a\ndecrease of 86% in the number of training steps needed to learn a second task\nafter mastering a single task. Results from ablation studies further indicate\nthat it is the combination of compositional value functions and language\nrepresentations that allows the agent to quickly generalize to new tasks.",
    "descriptor": "\nComments: Presented at AI-HRI symposium as part of AAAI-FSS 2021 (arXiv:2109.10836)\n",
    "authors": [
      "Vanya Cohen",
      "Geraud Nangue Tasse",
      "Nakul Gopalan",
      "Steven James",
      "Matthew Gombolay",
      "Benjamin Rosman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04647"
  },
  {
    "id": "arXiv:2110.04648",
    "title": "From Fragmentation to Liberation",
    "abstract": "In this paper, I argue that \"Internet fragmentation\" as a phenomenon is only\nmeaningful in the context of the US's hegemonic control over the Internet. I\npropose a broader and, I argue, more richly predictive frame: Internet\nconflict. I show how this frame provides fresh analytical purchase to some of\nthe questions I list above, using it to contextualize several apparently\ndistinct phenomena. I conclude by arguing that only one question gives this\nanalytical frame, or any other, a higher purpose: what particular interventions\nto Internet governance can produce meaningfully liberatory outcomes? Any\ndescriptive framework is only useful insofar as it can be mobilized to answer\nthis normative question.",
    "descriptor": "",
    "authors": [
      "Nick Merrill"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.04648"
  },
  {
    "id": "arXiv:2110.04649",
    "title": "Interactive Hierarchical Guidance using Language",
    "abstract": "Reinforcement learning has been successful in many tasks ranging from robotic\ncontrol, games, energy management etc. In complex real world environments with\nsparse rewards and long task horizons, sample efficiency is still a major\nchallenge. Most complex tasks can be easily decomposed into high-level planning\nand low level control. Therefore, it is important to enable agents to leverage\nthe hierarchical structure and decompose bigger tasks into multiple smaller\nsub-tasks. We introduce an approach where we use language to specify sub-tasks\nand a high-level planner issues language commands to a low level controller.\nThe low-level controller executes the sub-tasks based on the language commands.\nOur experiments show that this method is able to solve complex long horizon\nplanning tasks with limited human supervision. Using language has added benefit\nof interpretability and ability for expert humans to take over the high-level\nplanning task and provide language commands if necessary.",
    "descriptor": "\nComments: Presented at AI-HRI symposium as part of AAAI-FSS 2021 (arXiv:2109.10836)\n",
    "authors": [
      "Bharat Prakash",
      "Nicholas Waytowich",
      "Tim Oates",
      "Tinoosh Mohsenin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04649"
  },
  {
    "id": "arXiv:2110.04652",
    "title": "Representation Learning for Online and Offline RL in Low-rank MDPs",
    "abstract": "This work studies the question of Representation Learning in RL: how can we\nlearn a compact low-dimensional representation such that on top of the\nrepresentation we can perform RL procedures such as exploration and\nexploitation, in a sample efficient manner. We focus on the low-rank Markov\nDecision Processes (MDPs) where the transition dynamics correspond to a\nlow-rank transition matrix. Unlike prior works that assume the representation\nis known (e.g., linear MDPs), here we need to learn the representation for the\nlow-rank MDP. We study both the online RL and offline RL settings. For the\nonline setting, operating with the same computational oracles used in FLAMBE\n(Agarwal et.al), the state-of-art algorithm for learning representations in\nlow-rank MDPs, we propose an algorithm REP-UCB Upper Confidence Bound driven\nRepresentation learning for RL), which significantly improves the sample\ncomplexity from $\\widetilde{O}( A^9 d^7 / (\\epsilon^{10} (1-\\gamma)^{22}))$ for\nFLAMBE to $\\widetilde{O}( A^4 d^4 / (\\epsilon^2 (1-\\gamma)^{3}) )$ with $d$\nbeing the rank of the transition matrix (or dimension of the ground truth\nrepresentation), $A$ being the number of actions, and $\\gamma$ being the\ndiscounted factor. Notably, REP-UCB is simpler than FLAMBE, as it directly\nbalances the interplay between representation learning, exploration, and\nexploitation, while FLAMBE is an explore-then-commit style approach and has to\nperform reward-free exploration step-by-step forward in time. For the offline\nRL setting, we develop an algorithm that leverages pessimism to learn under a\npartial coverage condition: our algorithm is able to compete against any policy\nas long as it is covered by the offline distribution.",
    "descriptor": "",
    "authors": [
      "Masatoshi Uehara",
      "Xuezhou Zhang",
      "Wen Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04652"
  },
  {
    "id": "arXiv:2110.04653",
    "title": "Topological Data Analysis (TDA) Techniques Enhance Hand Pose  Classification from ECoG Neural Recordings",
    "abstract": "Electrocorticogram (ECoG) well characterizes hand movement intentions and\ngestures. In the present work we aim to investigate the possibility to enhance\nhand pose classification, in a Rock-Paper-Scissor - and Rest - task, by\nintroducing topological descriptors of time series data. We hypothesized that\nan innovative approach based on topological data analysis can extract hidden\ninformation that are not detectable with standard Brain Computer Interface\n(BCI)techniques. To investigate this hypothesis, we integrate topological\nfeatures together with power band features and feed them to several standard\nclassifiers, e.g. Random Forest,Gradient Boosting. Model selection is thus\ncompleted after a meticulous phase of bayesian hyperparameter optimization.\nWith our method, we observed robust results in terms of ac-curacy for a\nfour-labels classification problem, with limited available data. Through\nfeature importance investigation, we conclude that topological descriptors are\nable to extract useful discriminative information and provide novel\ninsights.Since our data are restricted to single-patient recordings,\ngeneralization might be limited. Nevertheless, our method can be extended and\napplied to a wide range of neurophysiological recordings and it might be an\nintriguing point of departure for future studies.",
    "descriptor": "",
    "authors": [
      "Simone Azeglio",
      "Arianna Di Bernardo",
      "Gabriele Penna",
      "Fabrizio Pittatore",
      "Simone Poetto",
      "Johannes Gruenwald",
      "Christoph Kapeller",
      "Kyousuke Kamada",
      "Christoph Guger"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2110.04653"
  },
  {
    "id": "arXiv:2110.04655",
    "title": "Disentangled Sequence to Sequence Learning for Compositional  Generalization",
    "abstract": "There is mounting evidence that existing neural network models, in particular\nthe very popular sequence-to-sequence architecture, struggle with compositional\ngeneralization, i.e., the ability to systematically generalize to unseen\ncompositions of seen components. In this paper we demonstrate that one of the\nreasons hindering compositional generalization relates to the representations\nbeing entangled. We propose an extension to sequence-to-sequence models which\nallows us to learn disentangled representations by adaptively re-encoding (at\neach time step) the source input. Specifically, we condition the source\nrepresentations on the newly decoded target context which makes it easier for\nthe encoder to exploit specialized information for each prediction rather than\ncapturing all source information in a single forward pass. Experimental results\non semantic parsing and machine translation empirically show that our proposal\nyields more disentangled representations and better generalization.",
    "descriptor": "",
    "authors": [
      "Hao Zheng",
      "Mirella Lapata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04655"
  },
  {
    "id": "arXiv:2110.04656",
    "title": "Streaming on-device detection of device directed speech from voice and  touch-based invocation",
    "abstract": "When interacting with smart devices such as mobile phones or wearables, the\nuser typically invokes a virtual assistant (VA) by saying a keyword or by\npressing a button on the device. However, in many cases, the VA can\naccidentally be invoked by the keyword-like speech or accidental button press,\nwhich may have implications on user experience and privacy. To this end, we\npropose an acoustic false-trigger-mitigation (FTM) approach for on-device\ndevice-directed speech detection that simultaneously handles the voice-trigger\nand touch-based invocation. To facilitate the model deployment on-device, we\nintroduce a new streaming decision layer, derived using the notion of temporal\nconvolutional networks (TCN) [1], known for their computational efficiency. To\nthe best of our knowledge, this is the first approach that can detect\ndevice-directed speech from more than one invocation type in a streaming\nfashion. We compare this approach with streaming alternatives based on vanilla\nAverage layer, and canonical LSTMs, and show: (i) that all the models show only\na small degradation in accuracy compared with the invocation-specific models,\nand (ii) that the newly introduced streaming TCN consistently performs better\nor comparable with the alternatives, while mitigating device undirected speech\nfaster in time, and with (relative) reduction in runtime peak-memory over the\nLSTM-based approach of 33% vs. 7%, when compared to a non-streaming\ncounterpart.",
    "descriptor": "",
    "authors": [
      "Ognjen Rudovic",
      "Akanksha Bindal",
      "Vineet Garg",
      "Pramod Simha",
      "Pranay Dighe",
      "Sachin Kajarekar"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.04656"
  },
  {
    "id": "arXiv:2110.04657",
    "title": "On sets of linear forms of maximal complexity",
    "abstract": "We present a uniform description of sets of $m$ linear forms in $n$ variables\nover the field of rational numbers whose computation requires $m(n - 1)$\nadditions.",
    "descriptor": "",
    "authors": [
      "Michael Kaminski",
      "Igor E. Shparlinski",
      "Michel Waldschmidt"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2110.04657"
  },
  {
    "id": "arXiv:2110.04658",
    "title": "Self-appearance-aided Differential Evolution for Motion Transfer",
    "abstract": "Image animation transfers the motion of a driving video to a static object in\na source image, while keeping the source identity unchanged. Great progress has\nbeen made in unsupervised motion transfer recently, where no labelled data or\nground truth domain priors are needed. However, current unsupervised approaches\nstill struggle when there are large motion or viewpoint discrepancies between\nthe source and driving images. In this paper, we introduce three measures that\nwe found to be effective for overcoming such large viewpoint changes. Firstly,\nto achieve more fine-grained motion deformation fields, we propose to apply\nNeural-ODEs for parametrizing the evolution dynamics of the motion transfer\nfrom source to driving. Secondly, to handle occlusions caused by large\nviewpoint and motion changes, we take advantage of the appearance flow obtained\nfrom the source image itself (\"self-appearance\"), which essentially \"borrows\"\nsimilar structures from other regions of an image to inpaint missing regions.\nFinally, our framework is also able to leverage the information from additional\nreference views which help to drive the source identity in spite of varying\nmotion state. Extensive experiments demonstrate that our approach outperforms\nthe state-of-the-arts by a significant margin (~40%), across six benchmarks\nvarying from human faces, human bodies to robots and cartoon characters. Model\ngenerality analysis indicates that our approach generalises the best across\ndifferent object categories as well.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Peirong Liu",
      "Rui Wang",
      "Xuefei Cao",
      "Yipin Zhou",
      "Ashish Shah",
      "Maxime Oquab",
      "Camille Couprie",
      "Ser-Nam Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04658"
  },
  {
    "id": "arXiv:2110.04660",
    "title": "K-Splits: Improved K-Means Clustering Algorithm to Automatically Detect  the Number of Clusters",
    "abstract": "This paper introduces k-splits, an improved hierarchical algorithm based on\nk-means to cluster data without prior knowledge of the number of clusters.\nK-splits starts from a small number of clusters and uses the most significant\ndata distribution axis to split these clusters incrementally into better fits\nif needed. Accuracy and speed are two main advantages of the proposed method.\nWe experiment on six synthetic benchmark datasets plus two real-world datasets\nMNIST and Fashion-MNIST, to prove that our algorithm has excellent accuracy in\nfinding the correct number of clusters under different conditions. We also show\nthat k-splits is faster than similar methods and can even be faster than the\nstandard k-means in lower dimensions. Finally, we suggest using k-splits to\nuncover the exact position of centroids and then input them as initial points\nto the k-means algorithm to fine-tune the results.",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Seyed Omid Mohammadi",
      "Ahmad Kalhor",
      "Hossein Bodaghi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.04660"
  },
  {
    "id": "arXiv:2110.04662",
    "title": "Cognitively Inspired Learning of Incremental Drifting Concepts",
    "abstract": "Humans continually expand their learned knowledge to new domains and learn\nnew concepts without any interference with past learned experiences. In\ncontrast, machine learning models perform poorly in a continual learning\nsetting, where input data distribution changes over time. Inspired by the\nnervous system learning mechanisms, we develop a computational model that\nenables a deep neural network to learn new concepts and expand its learned\nknowledge to new domains incrementally in a continual learning setting. We rely\non the Parallel Distributed Processing theory to encode abstract concepts in an\nembedding space in terms of a multimodal distribution. This embedding space is\nmodeled by internal data representations in a hidden network layer. We also\nleverage the Complementary Learning Systems theory to equip the model with a\nmemory mechanism to overcome catastrophic forgetting through implementing\npseudo-rehearsal. Our model can generate pseudo-data points for experience\nreplay and accumulate new experiences to past learned experiences without\ncausing cross-task interference.",
    "descriptor": "",
    "authors": [
      "Mohammad Rostami",
      "Aram Galstyan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04662"
  },
  {
    "id": "arXiv:2110.04663",
    "title": "Learning to Control Complex Robots Using High-Dimensional Interfaces:  Preliminary Insights",
    "abstract": "Human body motions can be captured as a high-dimensional continuous signal\nusing motion sensor technologies. The resulting data can be surprisingly rich\nin information, even when captured from persons with limited mobility. In this\nwork, we explore the use of limited upper-body motions, captured via motion\nsensors, as inputs to control a 7 degree-of-freedom assistive robotic arm. It\nis possible that even dense sensor signals lack the salient information and\nindependence necessary for reliable high-dimensional robot control. As the\nhuman learns over time in the context of this limitation, intelligence on the\nrobot can be leveraged to better identify key learning challenges, provide\nuseful feedback, and support individuals until the challenges are managed. In\nthis short paper, we examine two uninjured participants' data from an ongoing\nstudy, to extract preliminary results and share insights. We observe\nopportunities for robot intelligence to step in, including the identification\nof inconsistencies in time spent across all control dimensions, asymmetries in\nindividual control dimensions, and user progress in learning. Machine reasoning\nabout these situations may facilitate novel interface learning in the future.",
    "descriptor": "\nComments: Presented at AI-HRI symposium as part of AAAI-FSS 2021 (arXiv:2109.10836)\n",
    "authors": [
      "Jongmin M. Lee",
      "Temesgen Gebrekristos",
      "Dalia De Santis",
      "Mahdieh Nejati-Javaremi",
      "Deepak Gopinath",
      "Biraj Parikh",
      "Ferdinando A. Mussa-Ivaldi",
      "Brenna D. Argall"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.04663"
  },
  {
    "id": "arXiv:2110.04664",
    "title": "Using Human-Guided Causal Knowledge for More Generalized Robot Task  Planning",
    "abstract": "A major challenge in research involving artificial intelligence (AI) is the\ndevelopment of algorithms that can find solutions to problems that can\ngeneralize to different environments and tasks. Unlike AI, humans are adept at\nfinding solutions that can transfer. We hypothesize this is because their\nsolutions are informed by causal models. We propose to use human-guided causal\nknowledge to help robots find solutions that can generalize to a new\nenvironment. We develop and test the feasibility of a language interface that\nna\\\"ive participants can use to communicate these causal models to a planner.\nWe find preliminary evidence that participants are able to use our interface\nand generate causal models that achieve near-generalization. We outline an\nexperiment aimed at testing far-generalization using our interface and describe\nour longer terms goals for these causal models.",
    "descriptor": "\nComments: Presented at AI-HRI symposium as part of AAAI-FSS 2021 (arXiv:2109.10836)\n",
    "authors": [
      "Semir Tatlidil",
      "Yanqi Liu",
      "Emily Sheetz",
      "R. Iris Bahar",
      "Steven Sloman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.04664"
  },
  {
    "id": "arXiv:2110.04667",
    "title": "Competitive Perimeter Defense of Conical Environments",
    "abstract": "We consider a perimeter defense problem in a planar conical environment in\nwhich a single vehicle, having a finite capture radius, aims to defend a\nconcentric perimeter from mobile intruders. The intruders are arbitrarily\nreleased at the circumference of the environment and move radially toward the\nperimeter with fixed speed. We present a competitive analysis approach to this\nproblem by measuring the performance of multiple online algorithms for the\nvehicle against arbitrary inputs, relative to an optimal offline algorithm that\nhas access to all future inputs. In particular, we first establish a necessary\ncondition on the parameter space to guarantee finite competitiveness of any\nalgorithm, and then characterize a parameter regime in which the competitive\nratio is guaranteed to be at least 2 for any algorithm. We then design and\nanalyze three online algorithms and characterize parameter regimes for which\nthey have finite competitive ratios. Specifically, our first two algorithms are\nprovably 1, and 2-competitive, respectively, whereas our third algorithm\nexhibits a finite competitive ratio that depends on the problem parameters.\nFinally, we provide numerous parameter space plots providing insights into the\nrelative performance of our algorithms.",
    "descriptor": "",
    "authors": [
      "Shivam Bajaj",
      "Eric Torng",
      "Shaunak D. Bopardikar",
      "Alexander Von Moll",
      "Isaac Weintraub",
      "Eloy Garcia",
      "David W. Casbeer"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.04667"
  },
  {
    "id": "arXiv:2110.04669",
    "title": "Leveraging Experience in Lazy Search",
    "abstract": "Lazy graph search algorithms are efficient at solving motion planning\nproblems where edge evaluation is the computational bottleneck. These\nalgorithms work by lazily computing the shortest potentially feasible path,\nevaluating edges along that path, and repeating until a feasible path is found.\nThe order in which edges are selected is critical to minimizing the total\nnumber of edge evaluations: a good edge selector chooses edges that are not\nonly likely to be invalid, but also eliminates future paths from consideration.\nWe wish to learn such a selector by leveraging prior experience. We formulate\nthis problem as a Markov Decision Process (MDP) on the state of the search\nproblem. While solving this large MDP is generally intractable, we show that we\ncan compute oracular selectors that can solve the MDP during training. With\naccess to such oracles, we use imitation learning to find effective policies.\nIf new search problems are sufficiently similar to problems solved during\ntraining, the learned policy will choose a good edge evaluation ordering and\nsolve the motion planning problem quickly. We evaluate our algorithms on a wide\nrange of 2D and 7D problems and show that the learned selector outperforms\nbaseline commonly used heuristics. We further provide a novel theoretical\nanalysis of lazy search in a Bayesian framework as well as regret guarantees on\nour imitation learning based approach to motion planning.",
    "descriptor": "\nComments: Extended journal version accepted for publication at Autonomous Robots; 17 pages. arXiv admin note: substantial text overlap with arXiv:1907.07238\n",
    "authors": [
      "Mohak Bhardwaj",
      "Sanjiban Choudhury",
      "Byron Boots",
      "Siddhartha Srinivasa"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04669"
  },
  {
    "id": "arXiv:2110.04677",
    "title": "Interpretable Aesthetic Analysis Model for Intelligent Photography  Guidance Systems",
    "abstract": "An aesthetics evaluation model is at the heart of predicting users' aesthetic\nexperience and developing user interfaces with higher quality. However,\nprevious methods on aesthetic evaluation largely ignore the interpretability of\nthe model and are consequently not suitable for many human-computer interaction\ntasks. We solve this problem by using a hyper-network to learn the overall\naesthetic rating as a combination of individual aesthetic attribute scores. We\nfurther introduce a specially designed attentional mechanism in attribute score\nestimators to enable the users to know exactly which parts/elements of visual\ninputs lead to the estimated score. We demonstrate our idea by designing an\nintelligent photography guidance system. Computational results and user studies\ndemonstrate the interpretability and effectiveness of our method.",
    "descriptor": "",
    "authors": [
      "Xiaoran Wu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.04677"
  },
  {
    "id": "arXiv:2110.04678",
    "title": "An Overview of Techniques for Biomarker Discovery in Voice Signal",
    "abstract": "This paper reflects on the effect of several categories of medical conditions\non human voice, focusing on those that may be hypothesized to have effects on\nvoice, but for which the changes themselves may be subtle enough to have eluded\nobservation in standard analytical examinations of the voice signal. It\npresents three categories of techniques that can potentially uncover such\nelusive biomarkers and allow them to be measured and used for predictive and\ndiagnostic purposes. These approaches include proxy techniques, model-based\nanalytical techniques and data-driven AI techniques.",
    "descriptor": "\nComments: Last two authors contributed equally to the paper\n",
    "authors": [
      "Rita Singh",
      "Ankit Shah",
      "Hira Dhamyal"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.04678"
  },
  {
    "id": "arXiv:2110.04683",
    "title": "Mixture Model Auto-Encoders: Deep Clustering through Dictionary Learning",
    "abstract": "State-of-the-art approaches for clustering high-dimensional data utilize deep\nauto-encoder architectures. Many of these networks require a large number of\nparameters and suffer from a lack of interpretability, due to the black-box\nnature of the auto-encoders. We introduce Mixture Model Auto-Encoders\n(MixMate), a novel architecture that clusters data by performing inference on a\ngenerative model. Derived from the perspective of sparse dictionary learning\nand mixture models, MixMate comprises several auto-encoders, each tasked with\nreconstructing data in a distinct cluster, while enforcing sparsity in the\nlatent space. Through experiments on various image datasets, we show that\nMixMate achieves competitive performance compared to state-of-the-art deep\nclustering algorithms, while using orders of magnitude fewer parameters.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Alexander Lin",
      "Andrew H. Song",
      "Demba Ba"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.04683"
  },
  {
    "id": "arXiv:2110.04684",
    "title": "Can Audio Captions Be Evaluated with Image Caption Metrics?",
    "abstract": "Automated audio captioning aims at generating textual descriptions for an\naudio clip. To evaluate the quality of generated audio captions, previous works\ndirectly adopt image captioning metrics like SPICE and CIDEr, without\njustifying their suitability in this new domain, which may mislead the\ndevelopment of advanced models. This problem is still unstudied due to the lack\nof human judgment datasets on caption quality. Therefore, we firstly construct\ntwo evaluation benchmarks, AudioCaps-Eval and Clotho-Eval. They are established\nwith pairwise comparison instead of absolute rating to achieve better\ninter-annotator agreement. Current metrics are found in poor correlation with\nhuman annotations on these datasets. To overcome their limitations, we propose\na metric named FENSE, where we combine the strength of Sentence-BERT in\ncapturing similarity, and a novel Error Detector to penalize erroneous\nsentences for robustness. On the newly established benchmarks, FENSE\noutperforms current metrics by 14-25% accuracy. Code, data and web demo\navailable at: https://github.com/blmoistawinde/fense",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Zelin Zhou",
      "Zhiling Zhang",
      "Xuenan Xu",
      "Zeyu Xie",
      "Mengyue Wu",
      "Kenny Q. Zhu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.04684"
  },
  {
    "id": "arXiv:2110.04685",
    "title": "Learning Visual Shape Control of Novel 3D Deformable Objects from  Partial-View Point Clouds",
    "abstract": "If robots could reliably manipulate the shape of 3D deformable objects, they\ncould find applications in fields ranging from home care to warehouse\nfulfillment to surgical assistance. Analytic models of elastic, 3D deformable\nobjects require numerous parameters to describe the potentially infinite\ndegrees of freedom present in determining the object's shape. Previous attempts\nat performing 3D shape control rely on hand-crafted features to represent the\nobject shape and require training of object-specific control models. We\novercome these issues through the use of our novel DeformerNet neural network\narchitecture, which operates on a partial-view point cloud of the object being\nmanipulated and a point cloud of the goal shape to learn a low-dimensional\nrepresentation of the object shape. This shape embedding enables the robot to\nlearn to define a visual servo controller that provides Cartesian pose changes\nto the robot end-effector causing the object to deform towards its target\nshape. Crucially, we demonstrate both in simulation and on a physical robot\nthat DeformerNet reliably generalizes to object shapes and material stiffness\nnot seen during training and outperforms comparison methods for both the\ngeneric shape control and the surgical task of retraction.",
    "descriptor": "\nComments: Submitted to IEEE Conference on Robotics and Automation (ICRA) 2022. 8 pages, 10 figures\n",
    "authors": [
      "Bao Thach",
      "Brian Y. Cho",
      "Alan Kuntz",
      "Tucker Hermans"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04685"
  },
  {
    "id": "arXiv:2110.04686",
    "title": "Braxlines: Fast and Interactive Toolkit for RL-driven Behavior  Engineering beyond Reward Maximization",
    "abstract": "The goal of continuous control is to synthesize desired behaviors. In\nreinforcement learning (RL)-driven approaches, this is often accomplished\nthrough careful task reward engineering for efficient exploration and running\nan off-the-shelf RL algorithm. While reward maximization is at the core of RL,\nreward engineering is not the only -- sometimes nor the easiest -- way for\nspecifying complex behaviors. In this paper, we introduce \\braxlines, a toolkit\nfor fast and interactive RL-driven behavior generation beyond simple reward\nmaximization that includes Composer, a programmatic API for generating\ncontinuous control environments, and set of stable and well-tested baselines\nfor two families of algorithms -- mutual information maximization (MiMax) and\ndivergence minimization (DMin) -- supporting unsupervised skill learning and\ndistribution sketching as other modes of behavior specification. In addition,\nwe discuss how to standardize metrics for evaluating these algorithms, which\ncan no longer rely on simple reward maximization. Our implementations build on\na hardware-accelerated Brax simulator in Jax with minimal modifications,\nenabling behavior synthesis within minutes of training. We hope Braxlines can\nserve as an interactive toolkit for rapid creation and testing of environments\nand behaviors, empowering explosions of future benchmark designs and new modes\nof RL-driven behavior generation and their algorithmic research.",
    "descriptor": "",
    "authors": [
      "Shixiang Shane Gu",
      "Manfred Diaz",
      "Daniel C. Freeman",
      "Hiroki Furuta",
      "Seyed Kamyar Seyed Ghasemipour",
      "Anton Raichuk",
      "Byron David",
      "Erik Frey",
      "Erwin Coumans",
      "Olivier Bachem"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04686"
  },
  {
    "id": "arXiv:2110.04689",
    "title": "Surrogate-Assisted Reference Vector Adaptation to Various Pareto Front  Shapes for Many-Objective Bayesian Optimization",
    "abstract": "We propose a surrogate-assisted reference vector adaptation (SRVA) method to\nsolve expensive multi- and many-objective optimization problems with various\nPareto front shapes. SRVA is coupled with a multi-objective Bayesian\noptimization (MBO) algorithm using reference vectors for scalarization of\nobjective functions. The Kriging surrogate models for MBO is used to estimate\nthe Pareto front shape and generate adaptive reference vectors uniformly\ndistributed on the estimated Pareto front. We combine SRVA with expected\nimprovement of penalty-based boundary intersection as an infill criterion for\nMBO. The proposed algorithm is compared with two other MBO algorithms by\napplying them to benchmark problems with various Pareto front shapes.\nExperimental results show that the proposed algorithm outperforms the other two\nin the problems whose objective functions are reasonably approximated by the\nKriging models. SRVA improves diversity of non-dominated solutions for these\nproblems with continuous, discontinuous, and degenerated Pareto fronts.\nBesides, the proposed algorithm obtains much better solutions from early stages\nof optimization especially in many-objective problems.",
    "descriptor": "\nComments: 8 pages, 4 figures, 4 tables\n",
    "authors": [
      "Nobuo Namura"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.04689"
  },
  {
    "id": "arXiv:2110.04690",
    "title": "Beyond Road Extraction: A Dataset for Map Update using Aerial Images",
    "abstract": "The increasing availability of satellite and aerial imagery has sparked\nsubstantial interest in automatically updating street maps by processing aerial\nimages. Until now, the community has largely focused on road extraction, where\nroad networks are inferred from scratch from an aerial image. However, given\nthat relatively high-quality maps exist in most parts of the world, in\npractice, inference approaches must be applied to update existing maps rather\nthan infer new ones. With recent road extraction methods showing high accuracy,\nwe argue that it is time to transition to the more practical map update task,\nwhere an existing map is updated by adding, removing, and shifting roads,\nwithout introducing errors in parts of the existing map that remain up-to-date.\nIn this paper, we develop a new dataset called MUNO21 for the map update task,\nand show that it poses several new and interesting research challenges. We\nevaluate several state-of-the-art road extraction methods on MUNO21, and find\nthat substantial further improvements in accuracy will be needed to realize\nautomatic map update.",
    "descriptor": "\nComments: ICCV 2021\n",
    "authors": [
      "Favyen Bastani",
      "Sam Madden"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04690"
  },
  {
    "id": "arXiv:2110.04691",
    "title": "Edge Centric Secure Data Sharing with Digital Twins in Smart Ecosystems",
    "abstract": "Internet of Things (IoT) is a rapidly growing industry currently being\nintegrated into both consumer and industrial environments on a wide scale.\nWhile the technology is available and deployment has a low barrier of entry in\nfuture applications, proper security frameworks are still at infancy stage and\nare being developed to fit varied implementations and device architectures.\nFurther, the need for edge centric mechanisms are critical to offer security in\nreal time smart connected applications with minimal or negligible overhead.\nIn this paper, we propose a novel approach of data security by using multiple\ndevice shadows (aka digital twins) for a single physical object. These twins\nare paramount to separate data among different virtual objects based on tags\nassigned on-the-fly, and are used to limit access to different data points by\nauthorized users/applications only. The novelty of the proposed architecture\nresides in the attachment of dynamic tags to key-value pairs reported by\nphysical devices in the system. We further examine the advantages of tagging\ndata in a digital twin system, and the performance impacts of the proposed data\nseparation scheme. The proposed solution is deployed at the edge, supporting\nlow latency and real time security mechanisms with minimal overhead, and is\nlight-weight as reflected by captured performance metrics.",
    "descriptor": "",
    "authors": [
      "Glen Cathey",
      "James Benson",
      "Maanak Gupta",
      "Ravi Sandhu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.04691"
  },
  {
    "id": "arXiv:2110.04697",
    "title": "An Augmented Reality Platform for Introducing Reinforcement Learning to  K-12 Students with Robots",
    "abstract": "Interactive reinforcement learning, where humans actively assist during an\nagent's learning process, has the promise to alleviate the sample complexity\nchallenges of practical algorithms. However, the inner workings and state of\nthe robot are typically hidden from the teacher when humans provide feedback.\nTo create a common ground between the human and the learning robot, in this\npaper, we propose an Augmented Reality (AR) system that reveals the hidden\nstate of the learning to the human users. This paper describes our system's\ndesign and implementation and concludes with a discussion on two directions for\nfuture work which we are pursuing: 1) use of our system in AI education\nactivities at the K-12 level; and 2) development of a framework for an AR-based\nhuman-in-the-loop reinforcement learning, where the human teacher can see\nsensory and cognitive representations of the robot overlaid in the real world.",
    "descriptor": "\nComments: AAAI-FSS 2021 (arXiv:2109.10836)\n",
    "authors": [
      "Ziyi Zhang",
      "Samuel Micah Akai-Nettey",
      "Adonai Addo",
      "Chris Rogers",
      "Jivko Sinapov"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04697"
  },
  {
    "id": "arXiv:2110.04698",
    "title": "A Closer Look at Advantage-Filtered Behavioral Cloning in High-Noise  Datasets",
    "abstract": "Recent Offline Reinforcement Learning methods have succeeded in learning\nhigh-performance policies from fixed datasets of experience. A particularly\neffective approach learns to first identify and then mimic optimal\ndecision-making strategies. Our work evaluates this method's ability to scale\nto vast datasets consisting almost entirely of sub-optimal noise. A thorough\ninvestigation on a custom benchmark helps identify several key challenges\ninvolved in learning from high-noise datasets. We re-purpose prioritized\nexperience sampling to locate expert-level demonstrations among millions of\nlow-performance samples. This modification enables offline agents to learn\nstate-of-the-art policies in benchmark tasks using datasets where expert\nactions are outnumbered nearly 65:1.",
    "descriptor": "\nComments: Honors Undergraduate Thesis, UVA 2021. 15 pages\n",
    "authors": [
      "Jake Grigsby",
      "Yanjun Qi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04698"
  },
  {
    "id": "arXiv:2110.04699",
    "title": "Toward Ubiquitous and Flexible Coverage of UAV-IRS-Assisted NOMA  Networks",
    "abstract": "This paper studies methods to achieve a high and flexible coverage\nperformance of a large-scale cellular network. The network shall enable\nunmanned aerial vehicles (UAVs) for non-orthogonal multiple access (NOMA)\ntransmission enhancement so as to simultaneously serve two users. The\nconsidered scenario consists of a network with a tier of base stations and\nUAVs. Each UAV is mounted with an intelligent reflecting surface (IRS) in order\nto serve as an aerial IRS reflecting signals between a base station and a user\nin the network. All the UAVs in the network are deployed based on a newly\nproposed three-dimensional (3D) point process leading to a tractable yet\naccurate analysis of the association statistics, which is otherwise difficult\nto analyze due to the mobility of UAVs. In light of this, we also analyze the\ndownlink coverage of UAV-IRS-assisted NOMA transmission for two users and\nderive the corresponding coverage probabilities. Our coverage analyses shed\nlight on the optimal allocations of transmit power between NOMA users and UAVs\nto accomplish the goal of ubiquitous and flexible NOMA transmission. We also\nconduct numerical simulations to validate our coverage analysis results while\ndemonstrating the improved coverage performance achieved by aerial IRSs.",
    "descriptor": "\nComments: 6 pages; 3 figures; conference\n",
    "authors": [
      "Chun-Hung Liu",
      "Md Asif Syed",
      "Lu Wei"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.04699"
  },
  {
    "id": "arXiv:2110.04701",
    "title": "Time Complexity Analysis of Evolutionary Algorithms for 2-Hop  (1,2)-Minimum Spanning Tree Problem",
    "abstract": "The Minimum Spanning Tree problem (abbr. MSTP) is a well-known combinatorial\noptimization problem that has been extensively studied by the researchers in\nthe field of evolutionary computing to theoretically analyze the optimization\nperformance of evolutionary algorithms. Within the paper, we consider a\nconstrained version of the problem named 2-Hop (1,2)-Minimum Spanning Tree\nproblem (abbr. 2H-(1,2)-MSTP) in the context of evolutionary algorithms, which\nhas been shown to be NP-hard. Following how evolutionary algorithms are applied\nto solve the MSTP, we first consider the evolutionary algorithms with search\npoints in edge-based representation adapted to the 2H-(1,2)-MSTP (including the\n(1+1) EA, Global Simple Evolutionary Multi-Objective Optimizer and its two\nvariants). More specifically, we separately investigate the upper bounds on\ntheir expected time (i.e., the expected number of fitness evaluations) to\nobtain a $\\frac{3}{2}$-approximate solution with respect to different fitness\nfunctions. Inspired by the special structure of 2-hop spanning trees, we also\nconsider the (1+1) EA with search points in vertex-based representation that\nseems not so natural for the problem and give an upper bound on its expected\ntime to obtain a $\\frac{3}{2}$-approximate solution, which is better than the\nabove mentioned ones.",
    "descriptor": "",
    "authors": [
      "Feng Shi",
      "Frank Neumann",
      "Jianxin Wang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.04701"
  },
  {
    "id": "arXiv:2110.04703",
    "title": "Selectable Set Randomized Kaczmarz",
    "abstract": "The Randomized Kaczmarz method (RK) is a stochastic iterative method for\nsolving linear systems that has recently grown in popularity due to its speed\nand low memory requirement. Selectable Set Randomized Kaczmarz (SSRK) is an\nvariant of RK that leverages existing information about the Kaczmarz iterate to\nidentify an adaptive ``selectable set'' and thus yields an improved convergence\nguarantee. In this paper, we propose a general perspective for selectable set\napproaches and prove a convergence result for that framework. In addition, we\ndefine two specific selectable set sampling strategies that have competitive\nconvergence guarantees to those of other variants of RK. One selectable set\nsampling strategy leverages information about the previous iterate, while the\nother leverages the orthogonality structure of the problem via the Gramian\nmatrix. We complement our theoretical results with numerical experiments that\ncompare our proposed rules with those existing in the literature.",
    "descriptor": "",
    "authors": [
      "Yotam Yaniv",
      "Jacob D. Moorman",
      "William Swartworth",
      "Thomas Tu",
      "Daji Landis",
      "Deanna Needell"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.04703"
  },
  {
    "id": "arXiv:2110.04704",
    "title": "3D Object Detection Combining Semantic and Geometric Features from Point  Clouds",
    "abstract": "In this paper, we investigate the combination of voxel-based methods and\npoint-based methods, and propose a novel end-to-end two-stage 3D object\ndetector named SGNet for point clouds scenes. The voxel-based methods voxelize\nthe scene to regular grids, which can be processed with the current advanced\nfeature learning frameworks based on convolutional layers for semantic feature\nlearning. Whereas the point-based methods can better extract the geometric\nfeature of the point due to the coordinate reservations. The combination of the\ntwo is an effective solution for 3D object detection from point clouds.\nHowever, most current methods use a voxel-based detection head with anchors for\nfinal classification and localization. Although the preset anchors cover the\nentire scene, it is not suitable for point clouds detection tasks with larger\nscenes and multiple categories due to the limitation of voxel size. In this\npaper, we propose a voxel-to-point module (VTPM) that captures semantic and\ngeometric features. The VTPM is a Voxel-Point-Based Module that finally\nimplements 3D object detection in point space, which is more conducive to the\ndetection of small-size objects and avoids the presets of anchors in inference\nstage. In addition, a Confidence Adjustment Module (CAM) with the\ncenter-boundary-aware confidence attention is proposed to solve the\nmisalignment between the predicted confidence and proposals in the regions of\nthe interest (RoI) selection. The SGNet proposed in this paper has achieved\nstate-of-the-art results for 3D object detection in the KITTI dataset,\nespecially in the detection of small-size objects such as cyclists. Actually,\nas of September 19, 2021, for KITTI dataset, SGNet ranked 1st in 3D and BEV\ndetection on cyclists with easy difficulty level, and 2nd in the 3D detection\nof moderate cyclists.",
    "descriptor": "",
    "authors": [
      "Hao Peng",
      "Guofeng Tong",
      "Zheng Li",
      "Yaqi Wang",
      "Yuyuan Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04704"
  },
  {
    "id": "arXiv:2110.04707",
    "title": "Numerical approximation for a nonlinear variable-order fractional  differential equation via an integral equation method",
    "abstract": "We study a numerical approximation for a nonlinear variable-order fractional\ndifferential equation via an integral equation method. Due to the lack of the\nmonotonicity of the discretization coefficients of the variable-order\nfractional derivative in standard approximation schemes, existing numerical\nanalysis techniques do not apply directly. By an approximate inversion\ntechnique, the proposed model is transformed as a second kind Volterra integral\nequation, based on which a collocation method under uniform or graded mesh is\ndeveloped and analyzed. In particular, the error estimates improve the existing\nresults by proving a consistent and sharper mesh grading parameter and\ncharacterizing the convergence rates in terms of the initial value of the\nvariable order, which demonstrates its critical role in determining the\nsmoothness of the solutions and thus the numerical accuracy.",
    "descriptor": "",
    "authors": [
      "Xiangcheng Zheng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.04707"
  },
  {
    "id": "arXiv:2110.04708",
    "title": "Fine_grained_Identity_Preserving_Landmark_Synthesis_for_Face_Reenactment",
    "abstract": "Recent face reenactment works are limited by the coarse reference landmarks,\nleading to unsatisfactory identity preserving performance due to the\ndistribution gap between the manipulated landmarks and those sampled from a\nreal person. To address this issue, we propose a fine-grained\nidentity-preserving landmark-guided face reenactment approach. The proposed\nmethod has two novelties. First, a landmark synthesis network which is designed\nto generate fine-grained landmark faces with more details. The network refines\nthe manipulated landmarks and generates a smooth and gradually changing face\nlandmark sequence with good identity preserving ability. Second, several novel\nloss functions including synthesized face identity preserving loss,\nforeground/background mask loss as well as boundary loss are designed, which\naims at synthesizing clear and sharp high-quality faces. Experiments are\nconducted on our self-collected BeautySelfie and the public VoxCeleb1 datasets.\nThe presented qualitative and quantitative results show that our method can\nreenact fine-grained higher quality faces with good ID-preserved appearance\ndetails, fewer artifacts and clearer boundaries than state-of-the-art works.\nCode will be released for reproduction.",
    "descriptor": "",
    "authors": [
      "Haichao Zhang",
      "Youcheng Ben",
      "Weixi Zhang",
      "Tao Chen",
      "Gang Yu",
      "Bin Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04708"
  },
  {
    "id": "arXiv:2110.04710",
    "title": "Sketch Me A Video",
    "abstract": "Video creation has been an attractive yet challenging task for artists to\nexplore. With the advancement of deep learning, recent works try to utilize\ndeep convolutional neural networks to synthesize a video with the aid of a\nguiding video, and have achieved promising results. However, the acquisition of\nguiding videos, or other forms of guiding temporal information is costly\nexpensive and difficult in reality. Therefore, in this work we introduce a new\nvideo synthesis task by employing two rough bad-drwan sketches only as input to\ncreate a realistic portrait video. A two-stage Sketch-to-Video model is\nproposed, which consists of two key novelties: 1) a feature retrieve and\nprojection (FRP) module, which parititions the input sketch into different\nparts and utilizes these parts for synthesizing a realistic start or end frame\nand meanwhile generating rich semantic features, is designed to alleviate the\nsketch out-of-domain problem due to arbitrarily drawn free-form sketch styles\nby different users. 2) A motion projection followed by feature blending module,\nwhich projects a video (used only in training phase) into a motion space\nmodeled by normal distribution and blends the motion variables with semantic\nfeatures extracted above, is proposed to alleviate the guiding temporal\ninformation missing problem in the test phase. Experiments conducted on a\ncombination of CelebAMask-HQ and VoxCeleb2 dataset well validate that, our\nmethod can acheive both good quantitative and qualitative results in\nsynthesizing high-quality videos from two rough bad-drawn sketches.",
    "descriptor": "",
    "authors": [
      "Haichao Zhang",
      "Gang Yu",
      "Tao Chen",
      "Guozhong Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04710"
  },
  {
    "id": "arXiv:2110.04711",
    "title": "SuperShaper: Task-Agnostic Super Pre-training of BERT Models with  Variable Hidden Dimensions",
    "abstract": "Task-agnostic pre-training followed by task-specific fine-tuning is a default\napproach to train NLU models. Such models need to be deployed on devices across\nthe cloud and the edge with varying resource and accuracy constraints. For a\ngiven task, repeating pre-training and fine-tuning across tens of devices is\nprohibitively expensive. We propose SuperShaper, a task agnostic pre-training\napproach which simultaneously pre-trains a large number of Transformer models\nby varying shapes, i.e., by varying the hidden dimensions across layers. This\nis enabled by a backbone network with linear bottleneck matrices around each\nTransformer layer which are sliced to generate differently shaped sub-networks.\nIn spite of its simple design space and efficient implementation, SuperShaper\ndiscovers networks that effectively trade-off accuracy and model size:\nDiscovered networks are more accurate than a range of hand-crafted and\nautomatically searched networks on GLUE benchmarks. Further, we find two\ncritical advantages of shape as a design variable for Neural Architecture\nSearch (NAS): (a) heuristics of good shapes can be derived and networks found\nwith these heuristics match and even improve on carefully searched networks\nacross a range of parameter counts, and (b) the latency of networks across\nmultiple CPUs and GPUs are insensitive to the shape and thus enable\ndevice-agnostic search. In summary, SuperShaper radically simplifies NAS for\nlanguage models and discovers networks that generalize across tasks, parameter\nconstraints, and devices.",
    "descriptor": "",
    "authors": [
      "Vinod Ganesan",
      "Gowtham Ramesh",
      "Pratyush Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04711"
  },
  {
    "id": "arXiv:2110.04714",
    "title": "Real-time FPGA Design for OMP Targeting 8K Image Reconstruction",
    "abstract": "During the past decade, implementing reconstruction algorithms on hardware\nhas been at the center of much attention in the field of real-time\nreconstruction in Compressed Sensing (CS). Orthogonal Matching Pursuit (OMP) is\nthe most widely used reconstruction algorithm on hardware implementation\nbecause OMP obtains good quality reconstruction results under a proper time\ncost. OMP includes Dot Product (DP) and Least Square Problem (LSP). These two\nparts have numerous division calculations and considerable vector-based\nmultiplications, which limit the implementation of real-time reconstruction on\nhardware. In the theory of CS, besides the reconstruction algorithm, the choice\nof sensing matrix affects the quality of reconstruction. It also influences the\nreconstruction efficiency by affecting the hardware architecture. Thus,\ndesigning a real-time hardware architecture of OMP needs to take three factors\ninto consideration. The choice of sensing matrix, the implementation of DP and\nLSP. In this paper, a sensing matrix, which is sparsity and contains zero\nvectors mainly, is adopted to optimize the OMP reconstruction to break the\nbottleneck of reconstruction efficiency. Based on the features of the chosen\nmatrix, the DP and LSP are implemented by simple shift, add and comparing\nprocedures. This work is implemented on the Xilinx Virtex UltraScale+ FPGA\ndevice. To reconstruct a digital signal with 1024 length under 0.25 sampling\nrate, the proposal method costs 0.818us while the state-of-the-art costs\n238$us. Thus, this work speedups the state-of-the-art method 290 times. This\nwork costs 0.026s to reconstruct an 8K gray image, which achieves 30FPS\nreal-time reconstruction.",
    "descriptor": "",
    "authors": [
      "Jiayao Xu",
      "Chen Fu",
      "Zhiqiang Zhang",
      "Jinjia Zhou"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04714"
  },
  {
    "id": "arXiv:2110.04719",
    "title": "Structure learning in polynomial time: Greedy algorithms, Bregman  information, and exponential families",
    "abstract": "Greedy algorithms have long been a workhorse for learning graphical models,\nand more broadly for learning statistical models with sparse structure. In the\ncontext of learning directed acyclic graphs, greedy algorithms are popular\ndespite their worst-case exponential runtime. In practice, however, they are\nvery efficient. We provide new insight into this phenomenon by studying a\ngeneral greedy score-based algorithm for learning DAGs. Unlike edge-greedy\nalgorithms such as the popular GES and hill-climbing algorithms, our approach\nis vertex-greedy and requires at most a polynomial number of score evaluations.\nWe then show how recent polynomial-time algorithms for learning DAG models are\na special case of this algorithm, thereby illustrating how these order-based\nalgorithms can be rigourously interpreted as score-based algorithms. This\nobservation suggests new score functions and optimality conditions based on the\nduality between Bregman divergences and exponential families, which we explore\nin detail. Explicit sample and computational complexity bounds are derived.\nFinally, we provide extensive experiments suggesting that this algorithm indeed\noptimizes the score in a variety of settings.",
    "descriptor": "\nComments: 36 pages, 9 figures\n",
    "authors": [
      "Goutham Rajendran",
      "Bohdan Kivva",
      "Ming Gao",
      "Bryon Aragam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04719"
  },
  {
    "id": "arXiv:2110.04722",
    "title": "Transformer-based Dual Relation Graph for Multi-label Image Recognition",
    "abstract": "The simultaneous recognition of multiple objects in one image remains a\nchallenging task, spanning multiple events in the recognition field such as\nvarious object scales, inconsistent appearances, and confused inter-class\nrelationships. Recent research efforts mainly resort to the statistic label\nco-occurrences and linguistic word embedding to enhance the unclear semantics.\nDifferent from these researches, in this paper, we propose a novel\nTransformer-based Dual Relation learning framework, constructing complementary\nrelationships by exploring two aspects of correlation,~\\ie, structural relation\ngraph and semantic relation graph. The structural relation graph aims to\ncapture long-range correlations from object context, by developing a\ncross-scale transformer-based architecture. The semantic graph dynamically\nmodels the semantic meanings of image objects with explicit semantic-aware\nconstraints. In addition, we also incorporate the learnt structural\nrelationship into the semantic graph, constructing a joint relation graph for\nrobust representations. With the collaborative learning of these two effective\nrelation graphs, our approach achieves new state-of-the-art on two popular\nmulti-label recognition benchmarks, i.e., MS-COCO and VOC 2007 dataset.",
    "descriptor": "\nComments: 10 pages, 5 figures. Published in ICCV 2021\n",
    "authors": [
      "Jiawei Zhao",
      "Ke Yan",
      "Yifan Zhao",
      "Jia Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04722"
  },
  {
    "id": "arXiv:2110.04724",
    "title": "Enhancing Utility in the Watchdog Privacy Mechanism",
    "abstract": "This paper is concerned with enhancing data utility in the privacy watchdog\nmethod for attaining information-theoretic privacy. For a specific privacy\nconstraint, the watchdog method filters out the high-risk data symbols through\napplying a uniform data regulation scheme, e.g., merging all high-risk symbols\ntogether. While this method entirely trades the symbols resolution off for\nprivacy, we show that the data utility can be greatly improved by partitioning\nthe high-risk symbols set and individually privatizing each subset. We further\npropose an agglomerative merging algorithm that finds a suitable partition of\nhigh-risk symbols: it starts with a singleton high-risk symbol, which is\niteratively fused with others until the resulting subsets are\nprivate.~Numerical simulations demonstrate the efficacy of this algorithm in\nprivately achieving higher utilities in the watchdog scheme.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Mohammad Amin Zarrabian",
      "Ni Ding",
      "Parastoo Sadeghi",
      "Thierry Rakotoarivelo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.04724"
  },
  {
    "id": "arXiv:2110.04725",
    "title": "Yuan 1.0: Large-Scale Pre-trained Language Model in Zero-Shot and  Few-Shot Learning",
    "abstract": "Recent work like GPT-3 has demonstrated excellent performance of Zero-Shot\nand Few-Shot learning on many natural language processing (NLP) tasks by\nscaling up model size, dataset size and the amount of computation. However,\ntraining a model like GPT-3 requires huge amount of computational resources\nwhich makes it challengeable to researchers. In this work, we propose a method\nthat incorporates large-scale distributed training performance into model\narchitecture design. With this method, Yuan 1.0, the current largest singleton\nlanguage model with 245B parameters, achieves excellent performance on\nthousands GPUs during training, and the state-of-the-art results on NLP tasks.\nA data processing method is designed to efficiently filter massive amount of\nraw data. The current largest high-quality Chinese corpus with 5TB high quality\ntexts is built based on this method. In addition, a calibration and label\nexpansion method is proposed to improve the Zero-Shot and Few-Shot performance,\nand steady improvement is observed on the accuracy of various tasks. Yuan 1.0\npresents strong capacity of natural language generation, and the generated\narticles are difficult to distinguish from the human-written ones.",
    "descriptor": "",
    "authors": [
      "Shaohua Wu",
      "Xudong Zhao",
      "Tong Yu",
      "Rongguo Zhang",
      "Chong Shen",
      "Hongli Liu",
      "Feng Li",
      "Hong Zhu",
      "Jiangang Luo",
      "Liang Xu",
      "Xuanwei Zhang",
      "Jun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04725"
  },
  {
    "id": "arXiv:2110.04727",
    "title": "LDC-Net: A Unified Framework for Localization, Detection and Counting in  Dense Crowds",
    "abstract": "The rapid development in visual crowd analysis shows a trend to count people\nby positioning or even detecting, rather than simply summing a density map. It\nalso enlightens us back to the essence of the field, detection to count, which\ncan give more abundant crowd information and has more practical applications.\nHowever, some recent work on crowd localization and detection has two\nlimitations: 1) The typical detection methods can not handle the dense crowds\nand a large variation in scale; 2) The density map heuristic methods suffer\nfrom performance deficiency in position and box prediction, especially in high\ndensity or large-size crowds. In this paper, we devise a tailored baseline for\ndense crowds location, detection, and counting from a new perspective, named as\nLDC-Net for convenience, which has the following features: 1) A strong but\nminimalist paradigm to detect objects by only predicting a location map and a\nsize map, which endows an ability to detect in a scene with any capacity ($0\n\\sim 10,000+$ persons); 2) Excellent cross-scale ability in facing a large\nvariation, such as the head ranging in $0 \\sim 100,000+$ pixels; 3) Achieve\nsuperior performance in location and box prediction tasks, as well as a\ncompetitive counting performance compared with the density-based methods.\nFinally, the source code and pre-trained models will be released.",
    "descriptor": "\nComments: 17 Pages, 11 figures\n",
    "authors": [
      "Qi wang",
      "Tao Han",
      "Junyu Gao",
      "Yuan Yuan",
      "Xuelong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04727"
  },
  {
    "id": "arXiv:2110.04729",
    "title": "Humans' Assessment of Robots as Moral Regulators: Importance of  Perceived Fairness and Legitimacy",
    "abstract": "Previous research has shown that the fairness and the legitimacy of a moral\ndecision-maker are important for people's acceptance of and compliance with the\ndecision-maker. As technology rapidly advances, there have been increasing\nhopes and concerns about building artificially intelligent entities that are\ndesigned to intervene against norm violations. However, it is unclear how\npeople would perceive artificial moral regulators that impose punishment on\nhuman wrongdoers. Grounded in theories of psychology and law, we predict that\nthe perceived fairness of punishment imposed by a robot would increase the\nlegitimacy of the robot functioning as a moral regulator, which would in turn,\nincrease people's willingness to accept and comply with the robot's decisions.\nWe close with a conceptual framework for building a robot moral regulator that\nsuccessfully can regulate norm violations.",
    "descriptor": "\nComments: Presented at AI-HRI symposium as part of AAAI-FSS 2021 (arXiv:2109.10836)\n",
    "authors": [
      "Boyoung Kim",
      "Elizabeth Phillips"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.04729"
  },
  {
    "id": "arXiv:2110.04731",
    "title": "Universal Adversarial Attacks on Neural Networks for Power Allocation in  a Massive MIMO System",
    "abstract": "Deep learning (DL) architectures have been successfully used in many\napplications including wireless systems. However, they have been shown to be\nsusceptible to adversarial attacks. We analyze DL-based models for a regression\nproblem in the context of downlink power allocation in massive\nmultiple-input-multiple-output systems and propose universal adversarial\nperturbation (UAP)-crafting methods as white-box and black-box attacks. We\nbenchmark the UAP performance of white-box and black-box attacks for the\nconsidered application and show that the adversarial success rate can achieve\nup to 60% and 40%, respectively. The proposed UAP-based attacks make a more\npractical and realistic approach as compared to classical white-box attacks.",
    "descriptor": "\nComments: accepted for publication in IEEE Wireless Communications Letters\n",
    "authors": [
      "Pablo Mill\u00e1n Santos",
      "B. R. Manoj",
      "Meysam Sadeghi",
      "Erik G. Larsson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04731"
  },
  {
    "id": "arXiv:2110.04733",
    "title": "Safeguarding UAV Networks Through Integrated Sensing, Jamming, and  Communications",
    "abstract": "This paper proposes an integrated sensing, jamming, and communications (ISJC)\nframework for securing unmanned aerial vehicle (UAV)-enabled wireless networks.\nThe proposed framework advocates the dual use of artificial noise transmitted\nby an information UAV for simultaneous jamming and sensing of an eavesdropping\nUAV. Based on the information sensed in the previous time slot, an optimization\nproblem for online resource allocation design is formulated to maximize the\nnumber of securely served users in the current time slot, while taking into\naccount a tracking performance constraint and quality-of-service (QoS)\nrequirements regarding the leakage information rate to the eavesdropper and the\ndownlink data rate to the legitimate users. A channel correlation-based\nalgorithm is proposed to obtain a suboptimal solution for the design problem.\nSimulation results demonstrate the security benefits of integrating sensing\ninto UAV communication systems.",
    "descriptor": "\nComments: 5 pages, 4 figures, submitted to ICASSP 2022\n",
    "authors": [
      "Zhiqiang Wei",
      "Fan Liu",
      "Derrick Wing Kwan Ng",
      "Robert Schober"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.04733"
  },
  {
    "id": "arXiv:2110.04736",
    "title": "Semi-Blind Multiuser Detection Under the Presence of Reconfigurable  Intelligent Surfaces",
    "abstract": "A multiuser multiple-input multiple-output wireless communication system is\nanalytically studied, which operates with the aid of a reconfigurable\nintelligent surface (RIS). The intermediate RIS is equipped with multiple\nelements and operates via random phase rotations to simultaneously serve\nmultiple users. Independent Rayleigh fading conditions are assumed among the\nincluded channels. The system performance is analytically studied when the\nlinear yet efficient zero-forcing detection is implemented at the receiver. In\nparticular, the outage performance is derived in closed-form expression for\ndifferent system configuration setups with regards to the available channel\nstate information at the receiver. Further, a joint coherent/noncoherent linear\ndetection is analytically presented. Finally, some new engineering insights are\nprovided, such as how the channel state information and/or the volume of\nantenna/RIS arrays impact on the overall system performance as well as the\narising efficiency on the performance/complexity tradeoff by utilizing the\njoint coherent/noncoherent scheme.",
    "descriptor": "",
    "authors": [
      "Nikolaos I. Miridakis",
      "Theodoros A. Tsiftsis",
      "Guanghua Yang",
      "Panagiotis A. Karkazis",
      "Helen C. Leligou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.04736"
  },
  {
    "id": "arXiv:2110.04740",
    "title": "Algorithmic collusion: A critical review",
    "abstract": "The prospect of collusive agreements being stabilized via the use of pricing\nalgorithms is widely discussed by antitrust experts and economists. However,\nthe literature is often lacking the perspective of computer scientists, and\nseems to regularly overestimate the applicability of recent progress in machine\nlearning to the complex coordination problem firms face in forming cartels.\nSimilarly, modelling results supporting the possibility of collusion by\nlearning algorithms often use simple market simulations which allows them to\nuse simple algorithms that do not produce many of the problems machine learning\npractitioners have to deal with in real-world problems, which could prove to be\nparticularly detrimental to learning collusive agreements. After critically\nreviewing the literature on algorithmic collusion, and connecting it to results\nfrom computer science, we find that while it is likely too early to adapt\nantitrust law to be able to deal with self-learning algorithms colluding in\nreal markets, other forms of algorithmic collusion, such as hub-and-spoke\narrangements facilitated by centralized pricing algorithms might already\nwarrant legislative action.",
    "descriptor": "\nComments: 47 pages, 1 table\n",
    "authors": [
      "Florian E. Dorner"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04740"
  },
  {
    "id": "arXiv:2110.04741",
    "title": "Enhance Long Text Understanding via Distilled Gist Detector from  Abstractive Summarization",
    "abstract": "Long text understanding is important yet challenging in natural language\nprocessing. A long article or essay usually contains many redundant words that\nare not pertinent to its gist and sometimes can be regarded as noise. In this\npaper, we consider the problem of how to disentangle the gist-relevant and\nirrelevant information for long text understanding. With distillation\nmechanism, we transfer the knowledge about how to focus the salient parts from\nthe abstractive summarization model and further integrate the distilled model,\nnamed \\emph{Gist Detector}, into existing models as a supplementary component\nto augment the long text understanding. Experiments on document classification,\ndistantly supervised open-domain question answering (DS-QA) and non-parallel\ntext style transfer show that our method can significantly improve the\nperformance of the baseline models, and achieves state-of-the-art overall\nresults for document classification.",
    "descriptor": "",
    "authors": [
      "Yan Liu",
      "Yazheng Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04741"
  },
  {
    "id": "arXiv:2110.04743",
    "title": "ZARTS: On Zero-order Optimization for Neural Architecture Search",
    "abstract": "Differentiable architecture search (DARTS) has been a popular one-shot\nparadigm for NAS due to its high efficiency. It introduces trainable\narchitecture parameters to represent the importance of candidate operations and\nproposes first/second-order approximation to estimate their gradients, making\nit possible to solve NAS by gradient descent algorithm. However, our in-depth\nempirical results show that the approximation will often distort the loss\nlandscape, leading to the biased objective to optimize and in turn inaccurate\ngradient estimation for architecture parameters. This work turns to zero-order\noptimization and proposes a novel NAS scheme, called ZARTS, to search without\nenforcing the above approximation. Specifically, three representative\nzero-order optimization methods are introduced: RS, MGS, and GLD, among which\nMGS performs best by balancing the accuracy and speed. Moreover, we explore the\nconnections between RS/MGS and gradient descent algorithm and show that our\nZARTS can be seen as a robust gradient-free counterpart to DARTS. Extensive\nexperiments on multiple datasets and search spaces show the remarkable\nperformance of our method. In particular, results on 12 benchmarks verify the\noutstanding robustness of ZARTS, where the performance of DARTS collapses due\nto its known instability issue. Also, we search on the search space of DARTS to\ncompare with peer methods, and our discovered architecture achieves 97.54%\naccuracy on CIFAR-10 and 75.7% top-1 accuracy on ImageNet, which are\nstate-of-the-art performance.",
    "descriptor": "",
    "authors": [
      "Xiaoxing Wang",
      "Wenxuan Guo",
      "Junchi Yan",
      "Jianlin Su",
      "Xiaokang Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04743"
  },
  {
    "id": "arXiv:2110.04744",
    "title": "Long Expressive Memory for Sequence Modeling",
    "abstract": "We propose a novel method called Long Expressive Memory (LEM) for learning\nlong-term sequential dependencies. LEM is gradient-based, it can efficiently\nprocess sequential tasks with very long-term dependencies, and it is\nsufficiently expressive to be able to learn complicated input-output maps. To\nderive LEM, we consider a system of multiscale ordinary differential equations,\nas well as a suitable time-discretization of this system. For LEM, we derive\nrigorous bounds to show the mitigation of the exploding and vanishing gradients\nproblem, a well-known challenge for gradient-based recurrent sequential\nlearning methods. We also prove that LEM can approximate a large class of\ndynamical systems to high accuracy. Our empirical results, ranging from image\nand time-series classification through dynamical systems prediction to speech\nrecognition and language modeling, demonstrate that LEM outperforms\nstate-of-the-art recurrent neural networks, gated recurrent units, and long\nshort-term memory models.",
    "descriptor": "",
    "authors": [
      "T. Konstantin Rusch",
      "Siddhartha Mishra",
      "N. Benjamin Erichson",
      "Michael W. Mahoney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04744"
  },
  {
    "id": "arXiv:2110.04748",
    "title": "Time Series Classification Using Convolutional Neural Network On  Imbalanced Datasets",
    "abstract": "Time Series Classification (TSC) has drawn a lot of attention in literature\nbecause of its broad range of applications for different domains, such as\nmedical data mining, weather forecasting. Although TSC algorithms are designed\nfor balanced datasets, most real-life time series datasets are imbalanced. The\nSkewed distribution is a problem for time series classification both in\ndistance-based and feature-based algorithms under the condition of poor class\nseparability. To address the imbalance problem, both sampling-based and\nalgorithmic approaches are used in this paper. Different methods significantly\nimprove time series classification's performance on imbalanced datasets.\nDespite having a high imbalance ratio, the result showed that F score could be\nas high as 97.6% for the simulated TwoPatterns Dataset.",
    "descriptor": "",
    "authors": [
      "Syed Rawshon Jamil"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04748"
  },
  {
    "id": "arXiv:2110.04751",
    "title": "Dynamic Process Isolation",
    "abstract": "In the quest for efficiency and performance, edge-computing providers\neliminate isolation boundaries between tenants, such as strict process\nisolation, and instead let them compute in a more lightweight multi-threaded\nsingle-process design. Edge-computing providers support a high number of\ntenants per machine to reduce the physical distance to customers without\nrequiring a large number of machines. Isolation is provided by sandboxing\nmechanisms, e.g., tenants can only run sandboxed V8 JavaScript code. While this\nis as secure as a sandbox for software vulnerabilities, microarchitectural\nattacks can bypass these sandboxes.\nIn this paper, we show that it is possible to mount a Spectre attack on such\na restricted environment, leaking secrets from co-located tenants. Cloudflare\nWorkers is one of the top three edge-computing solutions and handles millions\nof HTTP requests per second worldwide across tens of thousands of web sites\nevery day. We demonstrate a remote Spectre attack using amplification\ntechniques in combination with a remote timing server, which is capable of\nleaking 120 bit/h. This motivates our main contribution, Dynamic Process\nIsolation, a process isolation mechanism that only isolates suspicious worker\nscripts following a detection mechanism. In the worst case of only false\npositives, Dynamic Process Isolation simply degrades to process isolation. Our\nproof-of-concept implementation augments a real-world cloud infrastructure\nframework, Cloudflare Workers, which is used in production at large scale. With\na false-positive rate of only 0.61%, we demonstrate that our solution vastly\noutperforms strict process isolation in terms of performance. In our security\nevaluation, we show that Dynamic Process Isolation statistically provides the\nsame security guarantees as strict process isolation, fully mitigating Spectre\nattacks between multiple tenants.",
    "descriptor": "",
    "authors": [
      "Martin Schwarzl",
      "Pietro Borrello",
      "Andreas Kogler",
      "Kenton Varda",
      "Thomas Schuster",
      "Daniel Gruss",
      "Michael Schwarz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.04751"
  },
  {
    "id": "arXiv:2110.04753",
    "title": "Transaction Fees on a Honeymoon: Ethereum's EIP-1559 One Month Later",
    "abstract": "Ethereum Improvement Proposal (EIP) 1559 was recently implemented to\ntransform Ethereum's transaction fee market. EIP-1559 utilizes an algorithmic\nupdate rule with a constant learning rate to estimate a base fee. The base fee\nreflects prevailing network conditions and hence provides a more reliable\noracle for current gas prices.\nUsing on-chain data from the period after its launch, we evaluate the impact\nof EIP-1559 on user experience and market performance. Our empirical findings\nsuggest that while EIP-1559 achieves its goals on average, short-term behavior\nis marked by intense oscillations in block sizes and slow adjustments during\nperiods of demand bursts (e.g., NFT drops). Both phenomena lead to unwanted\ninter-block variability in mining rewards. We then study the effect of\ndifferent learning rates and propose an alternative mechanism that uses a\nvariable learning rate. Our simulations show that the latter outperforms the\nstandard EIP-1559 mechanism under various demand scenarios. These results\nprovide evidence that such mechanisms may constitute a promising direction for\nfuture research and contribute to the ongoing discussion on EIP-1559 (and\nEIP-1559 based) mechanisms and to design of more efficient transaction fee\nmarkets.",
    "descriptor": "\nComments: IEEE Blockchain-2021, The 4th IEEE International Conference on Blockchain, Melbourne, Australia | 06-08 December 2021\n",
    "authors": [
      "Daniel Reijsbergen",
      "Shyam Sridhar",
      "Barnabe Monnot",
      "Stefanos Leonardos",
      "Stratis Skoulakis",
      "Georgios Piliouras"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.04753"
  },
  {
    "id": "arXiv:2110.04754",
    "title": "Towards High-fidelity Singing Voice Conversion with Acoustic Reference  and Contrastive Predictive Coding",
    "abstract": "Recently, phonetic posteriorgrams (PPGs) based methods have been quite\npopular in non-parallel singing voice conversion systems. However, due to the\nlack of acoustic information in PPGs, style and naturalness of the converted\nsinging voices are still limited. To solve these problems, in this paper, we\nutilize an acoustic reference encoder to implicitly model singing\ncharacteristics. We experiment with different auxiliary features, including mel\nspectrograms, HuBERT, and the middle hidden feature (PPG-Mid) of pretrained\nautomatic speech recognition (ASR) model, as the input of the reference\nencoder, and finally find the HuBERT feature is the best choice. In addition,\nwe use contrastive predictive coding (CPC) module to further smooth the voices\nby predicting future observations in latent space. Experiments show that,\ncompared with the baseline models, our proposed model can significantly improve\nthe naturalness of converted singing voices and the similarity with the target\nsinger. Moreover, our proposed model can also make the speakers with just\nspeech data sing.",
    "descriptor": "",
    "authors": [
      "Chao Wang",
      "Zhonghao Li",
      "Benlai Tang",
      "Xiang Yin",
      "Yuan Wan",
      "Yibiao Yu",
      "Zejun Ma"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.04754"
  },
  {
    "id": "arXiv:2110.04755",
    "title": "Nano Version Control and Robots of Robots: Data Driven, Regenerative  Production Code",
    "abstract": "A reflection of the Corona pandemic highlights the need for more sustainable\nproduction systems using automation. The goal is to retain automation of\nrepetitive tasks while allowing complex parts to come together. We recognize\nthe fragility and how hard it is to create traditional automation. We introduce\na method which converts one really hard problem of producing sustainable\nproduction code into three simpler problems being data, patterns and working\nprototypes. We use developer seniority as a metric to measure whether the\nproposed method is easier. By using agent-based simulation and NanoVC repos for\nagent arbitration, we are able to create a simulated environment where patterns\ndeveloped by people are used to transform working prototypes into templates\nthat data can be fed through to create the robots that create the production\ncode. Having two layers of robots allow early implementation choices to be\nreplaced as we gather more feedback from the working system. Several benefits\nof this approach have been discovered, with the most notable being that the\nRobot of Robots encodes a legacy of the person that designed it in the form of\nthe 3 ingredients (data, patterns and working prototypes). This method allows\nus to achieve our goal of reducing the fragility of the production code while\nremoving the difficulty of getting there.",
    "descriptor": "\nComments: Presented at the 3rd Electrical Engineering Postgraduate Symposium\n",
    "authors": [
      "Lukasz Machowski",
      "Tshilidzi Marwala"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04755"
  },
  {
    "id": "arXiv:2110.04760",
    "title": "Unsupervised High-Fidelity Facial Texture Generation and Reconstruction",
    "abstract": "Many methods have been proposed over the years to tackle the task of facial\n3D geometry and texture recovery from a single image. Such methods often fail\nto provide high-fidelity texture without relying on 3D facial scans during\ntraining. In contrast, the complementary task of 3D facial generation has not\nreceived as much attention. As opposed to the 2D texture domain, where GANs\nhave proven to produce highly realistic facial images, the more challenging 3D\ngeometry domain has not yet caught up to the same levels of realism and\ndiversity.\nIn this paper, we propose a novel unified pipeline for both tasks, generation\nof both geometry and texture, and recovery of high-fidelity texture. Our\ntexture model is learned, in an unsupervised fashion, from natural images as\nopposed to scanned texture maps. To the best of our knowledge, this is the\nfirst such unified framework independent of scanned textures.\nOur novel training pipeline incorporates a pre-trained 2D facial generator\ncoupled with a deep feature manipulation methodology. By applying precise 3DMM\nfitting, we can seamlessly integrate our modeled textures into synthetically\ngenerated background images forming a realistic composition of our textured\nmodel with background, hair, teeth, and body. This enables us to apply transfer\nlearning from the domain of 2D image generation, thus, benefiting greatly from\nthe impressive results obtained in this domain.\nWe provide a comprehensive study on several recent methods comparing our\nmodel in generation and reconstruction tasks. As the extensive qualitative, as\nwell as quantitative analysis, demonstrate, we achieve state-of-the-art results\nfor both tasks.",
    "descriptor": "",
    "authors": [
      "Ron Slossberg",
      "Ibrahim Jubran",
      "Ron Kimmel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04760"
  },
  {
    "id": "arXiv:2110.04764",
    "title": "Deep Learning Based Person Re-Identification Methods: A Survey and  Outlook of Recent Works",
    "abstract": "In recent years, with the increasing demand for public safety and the rapid\ndevelopment of intelligent surveillance networks, person re-identification\n(Re-ID) has become one of the hot research topics in the field of computer\nvision. Its main research goal is to retrieve persons with the same identity\nfrom different cameras. However, traditional person Re-ID methods require\nmanual marking of person targets, which consumes a lot of labor costs. With the\nwidespread application of deep neural networks in the field of computer vision,\na large number of deep learning-based person Re-ID methods have emerged. To\nfacilitate researchers to better understand the latest research results and\nfuture development trends in this field. Firstly, we compare traditional and\ndeep learning-based person Re-ID methods, and present the main contributions of\nseveral person Re-ID surveys, and analyze their focused dimensions and\nshortcomings. Secondly, we focus on the current classic deep learning-based\nperson Re-ID methods, including methods for deep metric learning, local feature\nlearning, generate adversarial networks, sequence feature learning, and graph\nconvolutional networks. Furthermore, we subdivide the above five categories\naccording to their technique types, analyzing and comparing the experimental\nperformance of part subcategories of the method. Finally, we discuss the\nchallenges that remain in the field of person Re-ID field and prospects for\nfuture research directions.",
    "descriptor": "\nComments: 21 pages, 13 figures\n",
    "authors": [
      "Zhangqiang Ming",
      "Min Zhu",
      "Xiaoyong Wei",
      "Xiangkun Wang",
      "Jiamin Zhu",
      "Junlong Cheng",
      "Yong Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04764"
  },
  {
    "id": "arXiv:2110.04765",
    "title": "Multi-task Learning with Metadata for Music Mood Classification",
    "abstract": "Mood recognition is an important problem in music informatics and has key\napplications in music discovery and recommendation. These applications have\nbecome even more relevant with the rise of music streaming. Our work\ninvestigates the research question of whether we can leverage audio metadata\nsuch as artist and year, which is readily available, to improve the performance\nof mood classification models. To this end, we propose a multi-task learning\napproach in which a shared model is simultaneously trained for mood and\nmetadata prediction tasks with the goal to learn richer representations.\nExperimentally, we demonstrate that applying our technique on the existing\nstate-of-the-art convolutional neural networks for mood classification improves\ntheir performances consistently. We conduct experiments on multiple datasets\nand report that our approach can lead to improvements in the average precision\nmetric by up to 8.7 points.",
    "descriptor": "",
    "authors": [
      "Rajnish Kumar",
      "Manjeet Dahiya"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.04765"
  },
  {
    "id": "arXiv:2110.04767",
    "title": "Developing Smart Web-Search Using RegEx",
    "abstract": "Due to the increasing storage data on Web Applications, it becomes very\ndifficult to use only keyword-based searches to provide comprehensive search\nresults, thus increasing the difficulty for web users to search information on\nthe web. In this paper, we proposed using a combined method of keyword-based\nand Regular expressions (regEx) searches to perform a search using strings of\ntargeted items for optimal results even as the volume of data around the world\non the Internet continues to explode. The idea is to embed regEx patterns as\npart of the search engine's algorithm in a web application project to provide\nstrings related to the targeted items for more comprehensive coverage of search\nresults. The user's search query is a string of characters guided by search\nboundaries selected from the entry point. The results returned from the search\noperation are different results within a category determined by the search\nboundaries. This is designed to be beneficial to a user who has an obscure idea\nabout the information he/she wanted to search but knows the boundaries within\nwhich to get the information. This technique can be applied to data processing\ntasks such as information extraction and search refinement.",
    "descriptor": "\nComments: 4 pages and 2 images\n",
    "authors": [
      "Ikechukwu Onyenwe",
      "Stanley Ogbonna",
      "Ebele Onyedimma",
      "Onyedikachukwu Ikechukwu-Onyenwe",
      "Chidinma Nwafor"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.04767"
  },
  {
    "id": "arXiv:2110.04768",
    "title": "A Novel Negative $\\ell_1$ Penalty Approach for Multiuser One-Bit Massive  MIMO Downlink with PSK Signaling",
    "abstract": "This paper considers the one-bit precoding problem for the multiuser downlink\nmassive multiple-input multiple-output (MIMO) system with phase shift keying\n(PSK) modulation and focuses on the celebrated constructive interference\n(CI)-based problem formulation. The existence of the discrete one-bit\nconstraint makes the problem generally hard to solve. In this paper, we propose\nan efficient negative $\\ell_1$ penalty approach for finding a high-quality\nsolution of the considered problem. Specifically, we first propose a novel\nnegative $\\ell_1$ penalty model, which penalizes the one-bit constraint into\nthe objective with a negative $\\ell_1$-norm term, and show the equivalence\nbetween (global and local) solutions of the original problem and the penalty\nproblem when the penalty parameter is sufficiently large. We further transform\nthe penalty model into an equivalent min-max problem and propose an efficient\nalternating optimization (AO) algorithm for solving it. The AO algorithm enjoys\nlow per-iteration complexity and is guaranteed to converge to the stationary\npoint of the min-max problem. Numerical results show that, compared against the\nstate-of-the-art CI-based algorithms, the proposed algorithm generally achieves\nbetter bit-error-rate (BER) performance with lower computational cost.",
    "descriptor": "\nComments: 5 pages, 4 figures, submitted to IEEE ICASSP 2022\n",
    "authors": [
      "Zheyu Wu",
      "Bo Jiang",
      "Ya-Feng Liu",
      "Yu-Hong Dai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.04768"
  },
  {
    "id": "arXiv:2110.04770",
    "title": "Weakly Supervised Contrastive Learning",
    "abstract": "Unsupervised visual representation learning has gained much attention from\nthe computer vision community because of the recent achievement of contrastive\nlearning. Most of the existing contrastive learning frameworks adopt the\ninstance discrimination as the pretext task, which treating every single\ninstance as a different class. However, such method will inevitably cause class\ncollision problems, which hurts the quality of the learned representation.\nMotivated by this observation, we introduced a weakly supervised contrastive\nlearning framework (WCL) to tackle this issue. Specifically, our proposed\nframework is based on two projection heads, one of which will perform the\nregular instance discrimination task. The other head will use a graph-based\nmethod to explore similar samples and generate a weak label, then perform a\nsupervised contrastive learning task based on the weak label to pull the\nsimilar images closer. We further introduced a K-Nearest Neighbor based\nmulti-crop strategy to expand the number of positive samples. Extensive\nexperimental results demonstrate WCL improves the quality of self-supervised\nrepresentations across different datasets. Notably, we get a new\nstate-of-the-art result for semi-supervised learning. With only 1\\% and 10\\%\nlabeled examples, WCL achieves 65\\% and 72\\% ImageNet Top-1 Accuracy using\nResNet50, which is even higher than SimCLRv2 with ResNet101.",
    "descriptor": "",
    "authors": [
      "Mingkai Zheng",
      "Fei Wang",
      "Shan You",
      "Chen Qian",
      "Changshui Zhang",
      "Xiaogang Wang",
      "Chang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04770"
  },
  {
    "id": "arXiv:2110.04773",
    "title": "Digging Into Self-Supervised Learning of Feature Descriptors",
    "abstract": "Fully-supervised CNN-based approaches for learning local image descriptors\nhave shown remarkable results in a wide range of geometric tasks. However, most\nof them require per-pixel ground-truth keypoint correspondence data which is\ndifficult to acquire at scale. To address this challenge, recent weakly- and\nself-supervised methods can learn feature descriptors from relative camera\nposes or using only synthetic rigid transformations such as homographies. In\nthis work, we focus on understanding the limitations of existing\nself-supervised approaches and propose a set of improvements that combined lead\nto powerful feature descriptors. We show that increasing the search space from\nin-pair to in-batch for hard negative mining brings consistent improvement. To\nenhance the discriminativeness of feature descriptors, we propose a\ncoarse-to-fine method for mining local hard negatives from a wider search space\nby using global visual image descriptors. We demonstrate that a combination of\nsynthetic homography transformation, color augmentation, and photorealistic\nimage stylization produces useful representations that are viewpoint and\nillumination invariant. The feature descriptors learned by the proposed\napproach perform competitively and surpass their fully- and weakly-supervised\ncounterparts on various geometric benchmarks such as image-based localization,\nsparse feature matching, and image retrieval.",
    "descriptor": "\nComments: Camera ready (3DV 2021)\n",
    "authors": [
      "Iaroslav Melekhov",
      "Zakaria Laskar",
      "Xiaotian Li",
      "Shuzhe Wang",
      "Juho Kannala"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04773"
  },
  {
    "id": "arXiv:2110.04776",
    "title": "Fitting large mixture models using stochastic component selection",
    "abstract": "Traditional methods for unsupervised learning of finite mixture models\nrequire to evaluate the likelihood of all components of the mixture. This\nbecomes computationally prohibitive when the number of components is large, as\nit is, for example, in the sum-product (transform) networks. Therefore, we\npropose to apply a combination of the expectation maximization and the\nMetropolis-Hastings algorithm to evaluate only a small number of,\nstochastically sampled, components, thus substantially reducing the\ncomputational cost. The Markov chain of component assignments is sequentially\ngenerated across the algorithm's iterations, having a non-stationary target\ndistribution whose parameters vary via a gradient-descent scheme. We put\nemphasis on generality of our method, equipping it with the ability to train\nboth shallow and deep mixture models which involve complex, and possibly\nnonlinear, transformations. The performance of our method is illustrated in a\nvariety of synthetic and real-data contexts, considering deep models, such as\nmixtures of normalizing flows and sum-product (transform) networks.",
    "descriptor": "",
    "authors": [
      "Milan Pape\u017e",
      "Tom\u00e1\u0161 Pevn\u00fd",
      "V\u00e1clav \u0160m\u00eddl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04776"
  },
  {
    "id": "arXiv:2110.04777",
    "title": "On snapshot-based model reduction under compatibility conditions for a  nonlinear flow problem on networks",
    "abstract": "This paper is on the construction of structure-preserving, online-efficient\nreduced models for the barotropic Euler equations with a friction term on\nnetworks. The nonlinear flow problem finds broad application in the context of\ngas distribution networks. We propose a snapshot-based reduction approach that\nconsists of a mixed variational Galerkin approximation combined with\nquadrature-type complexity reduction. Its main feature is that certain\ncompatibility conditions are assured during the training phase, which make our\napproach structure-preserving. The resulting reduced models are locally mass\nconservative and inherit an energy-bound and port-Hamiltonian structure. We\nalso derive a well-posedness result for them. In the training phase, the\ncompatibility conditions pose challenges, we face constrained data\napproximation problems as opposed to the unconstrained training problems in the\nconventional reduction methods. The training of our model order reduction\nconsists of a principal component analysis under a compatibility constraint\nand, notably, yields reduced models that fulfill an optimality condition for\nthe snapshot data. The training of our quadrature-type complexity reduction\ninvolves a semi-definite program with combinatorial aspects, which we approach\nby a greedy procedure.",
    "descriptor": "",
    "authors": [
      "Bj\u00f6rn Liljegren-Sailer",
      "Nicole Marheineke"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.04777"
  },
  {
    "id": "arXiv:2110.04779",
    "title": "About one method of constructing Hermite trigonometric splines",
    "abstract": "The method of constructing trigonometric Hermite splines, which interpolate\nthe values of some periodic function and its derivatives in the nodes of a\nuniform grid, is considered. The proposed method is based on the periodicity\nproperties of trigonometric functions and is reduced to solving only systems of\nlinear algebraic equations of the second order; solutions of these systems can\nbe obtained in advance. When implementing this method, it is necessary to\ncalculate the coefficients of interpolation trigonometric polynomials that\ninterpolate the values of the function itself and the values of its derivatives\nat the nodes of the uniform grid; known fast Fourier transform algorithms can\nbe used for this purpose. Examples of construction of trigonometric Hermite\nsplines of the first and second orders are given. The proposed method can be\nrecommended for practical use.",
    "descriptor": "",
    "authors": [
      "V.P. Denysiuk"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.04779"
  },
  {
    "id": "arXiv:2110.04781",
    "title": "Polynomial and trigonometric splines",
    "abstract": "Classes of simple polynomial and simple trigonometric splines given by\nFourier series are considered. It is shown that the class of simple\ntrigonometric splines includes the class of simple polynomial splines. For some\nparameter values, the polynomial splines coincide with the trigonometric ones;\nthis allows to transfer to such trigonometric splines all the results obtained\nfor polynomial splines. Thus, it was possible to combine two powerful theories\n- the theory of trigonometric Fourier series and the theory of simple\npolynomial splines. The above material is illustrated by numerous examples.",
    "descriptor": "",
    "authors": [
      "V. Denysiuk"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.04781"
  },
  {
    "id": "arXiv:2110.04785",
    "title": "A Generalization of Array Codes with Local Properties and Efficient  Encoding/Decoding",
    "abstract": "A maximum distance separable (MDS) array code is composed of $m\\times (k+r)$\narrays such that any $k$ out of $k+r$ columns suffice to retrieve all the\ninformation symbols. Expanded-Blaum-Roth (EBR) codes and\nExpanded-Independent-Parity (EIP) codes are two classes of MDS array codes that\ncan repair any one symbol in a column by locally accessing some other symbols\nwithin the column, where the number of symbols $m$ in a column is a prime\nnumber. By generalizing the constructions of EBR and EIP codes, we propose new\nMDS array codes, such that any one symbol can be locally recovered and the\nnumber of symbols in a column can be not only a prime number but also a power\nof an odd prime number. Also, we present an efficient encoding/decoding method\nfor the proposed generalized EBR (GEBR) and generalized EIP (GEIP) codes based\non the LU factorization of a Vandermonde matrix. We show that the proposed\ndecoding method has less computational complexity than existing methods.\nFurthermore, we show that the proposed GEBR codes have both a larger minimum\nsymbol distance and a larger recovery ability of erased lines for some\nparameters when compared to EBR codes. We show that EBR codes can recover any\n$r$ erased lines of a slope for any parameter $r$, which was an open problem in\n[2].",
    "descriptor": "",
    "authors": [
      "Hanxu Hou",
      "Yunghsiang S. Han",
      "Patrick P. C. Lee",
      "You Wu",
      "Guojun Han",
      "Mario Blaum"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.04785"
  },
  {
    "id": "arXiv:2110.04788",
    "title": "Garmr: Defending the gates of PKU-based sandboxing",
    "abstract": "Memory Protection Keys for Userspace (PKU) is a recent hardware feature that\nallows programs to assign virtual memory pages to protection domains, and to\nchange domain access permissions using inexpensive, unprivileged instructions.\nSeveral in-process memory isolation approaches leverage this feature to prevent\nuntrusted code from accessing sensitive program state and data. Typically,\nPKU-based isolation schemes need to be used in conjunction with mitigations\nsuch as CFI because untrusted code, when compromised, can otherwise bypass the\nPKU access permissions using unprivileged instructions or operating system\nAPIs.\nRecently, researchers proposed fully self-contained PKUbased memory isolation\nschemes that do not rely on other mitigations. These systems use exploit-proof\ncall gates to transfer control between trusted and untrusted code, as well as a\nsandbox that prevents tampering with the PKU infrastructure from untrusted\ncode.\nIn this paper, we show that these solutions are not complete. We first\ndevelop two proof-of-concept attacks against a state-of-the-art PKU-based\nmemory isolation scheme. We then present Garmr, a PKU-based sandboxing\nframework that can overcome limitations of existing sandboxes. We apply Garmr\nto several memory isolation schemes and show that it is practical, efficient\nand secure.",
    "descriptor": "",
    "authors": [
      "Alexios Voulimeneas",
      "Jonas Vinck",
      "Ruben Mechelinck",
      "Stijn Volckaert"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.04788"
  },
  {
    "id": "arXiv:2110.04792",
    "title": "6D-ViT: Category-Level 6D Object Pose Estimation via Transformer-based  Instance Representation Learning",
    "abstract": "This paper presents 6D-ViT, a transformer-based instance representation\nlearning network, which is suitable for highly accurate category-level object\npose estimation on RGB-D images. Specifically, a novel two-stream\nencoder-decoder framework is dedicated to exploring complex and powerful\ninstance representations from RGB images, point clouds and categorical shape\npriors. For this purpose, the whole framework consists of two main branches,\nnamed Pixelformer and Pointformer. The Pixelformer contains a pyramid\ntransformer encoder with an all-MLP decoder to extract pixelwise appearance\nrepresentations from RGB images, while the Pointformer relies on a cascaded\ntransformer encoder and an all-MLP decoder to acquire the pointwise geometric\ncharacteristics from point clouds. Then, dense instance representations (i.e.,\ncorrespondence matrix, deformation field) are obtained from a multi-source\naggregation network with shape priors, appearance and geometric information as\ninput. Finally, the instance 6D pose is computed by leveraging the\ncorrespondence among dense representations, shape priors, and the instance\npoint clouds. Extensive experiments on both synthetic and real-world datasets\ndemonstrate that the proposed 3D instance representation learning framework\nachieves state-of-the-art performance on both datasets, and significantly\noutperforms all existing methods.",
    "descriptor": "\nComments: 13 pages, 12 figures\n",
    "authors": [
      "Lu Zou",
      "Zhangjin Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04792"
  },
  {
    "id": "arXiv:2110.04794",
    "title": "PASTE: A Tagging-Free Decoding Framework Using Pointer Networks for  Aspect Sentiment Triplet Extraction",
    "abstract": "Aspect Sentiment Triplet Extraction (ASTE) deals with extracting opinion\ntriplets, consisting of an opinion target or aspect, its associated sentiment,\nand the corresponding opinion term/span explaining the rationale behind the\nsentiment. Existing research efforts are majorly tagging-based. Among the\nmethods taking a sequence tagging approach, some fail to capture the strong\ninterdependence between the three opinion factors, whereas others fall short of\nidentifying triplets with overlapping aspect/opinion spans. A recent grid\ntagging approach on the other hand fails to capture the span-level semantics\nwhile predicting the sentiment between an aspect-opinion pair. Different from\nthese, we present a tagging-free solution for the task, while addressing the\nlimitations of the existing works. We adapt an encoder-decoder architecture\nwith a Pointer Network-based decoding framework that generates an entire\nopinion triplet at each time step thereby making our solution end-to-end.\nInteractions between the aspects and opinions are effectively captured by the\ndecoder by considering their entire detected spans while predicting their\nconnecting sentiment. Extensive experiments on several benchmark datasets\nestablish the better efficacy of our proposed approach, especially in the\nrecall, and in predicting multiple and aspect/opinion-overlapped triplets from\nthe same review sentence. We report our results both with and without BERT and\nalso demonstrate the utility of domain-specific BERT post-training for the\ntask.",
    "descriptor": "\nComments: Accepted as a Long Paper at EMNLP 2021 (Main Conference); 13 pages; Codes: this https URL\n",
    "authors": [
      "Rajdeep Mukherjee",
      "Tapas Nayak",
      "Yash Butala",
      "Sourangshu Bhattacharya",
      "Pawan Goyal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04794"
  },
  {
    "id": "arXiv:2110.04795",
    "title": "Group Signatures and Accountable Ring Signatures from Isogeny-based  Assumptions",
    "abstract": "Group signatures are an important cryptographic primitive providing both\nanonymity and accountability to signatures. Accountable ring signatures combine\nfeatures from both ring signatures and group signatures, and can be directly\ntransformed to group signatures. While there exists extensive work on\nconstructing group signatures from various post-quantum assumptions, there has\nnot been any using isogeny-based assumptions. In this work, we propose the\nfirst construction of isogeny-based group signatures, which is a direct result\nof our isogeny-based accountable ring signature. This is also the first\nconstruction of accountable ring signatures based on post-quantum assumptions.\nOur schemes are based on the decisional CSIDH assumption (D-CSIDH) and are\nproven secure under the random oracle model (ROM).",
    "descriptor": "",
    "authors": [
      "Kai-Min Chung",
      "Yao-Ching Hsieh",
      "Mi-Ying Huang",
      "Yu-Hsuan Huang",
      "Tanja Lange",
      "Bo-Yin Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.04795"
  },
  {
    "id": "arXiv:2110.04796",
    "title": "Tensor Arnoldi-Tikhonov and GMRES-type methods for ill-posed problems  with a t-product structure",
    "abstract": "This paper describes solution methods for linear discrete ill-posed problems\ndefined by third order tensors and the t-product formalism introduced in [M. E.\nKilmer and C. D. Martin, Factorization strategies for third order tensors,\nLinear Algebra Appl., 435 (2011), pp. 641--658]. A t-product Arnoldi\n(t-Arnoldi) process is defined and applied to reduce a large-scale Tikhonov\nregularization problem for third order tensors to a problem of small size. The\ndata may be represented by a laterally oriented matrix or a third order tensor,\nand the regularization operator is a third order tensor. The discrepancy\nprinciple is used to determine the regularization parameter and the number of\nsteps of the t-Arnoldi process. Numerical examples compare results for several\nsolution methods, and illustrate the potential superiority of solution methods\nthat tensorize over solution methods that matricize linear discrete ill-posed\nproblems for third order tensors.",
    "descriptor": "",
    "authors": [
      "Lothar Reichel",
      "Ugochukwu O. Ugwu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.04796"
  },
  {
    "id": "arXiv:2110.04800",
    "title": "Self-Supervised 3D Face Reconstruction via Conditional Estimation",
    "abstract": "We present a conditional estimation (CEST) framework to learn 3D facial\nparameters from 2D single-view images by self-supervised training from videos.\nCEST is based on the process of analysis by synthesis, where the 3D facial\nparameters (shape, reflectance, viewpoint, and illumination) are estimated from\nthe face image, and then recombined to reconstruct the 2D face image. In order\nto learn semantically meaningful 3D facial parameters without explicit access\nto their labels, CEST couples the estimation of different 3D facial parameters\nby taking their statistical dependency into account. Specifically, the\nestimation of any 3D facial parameter is not only conditioned on the given\nimage, but also on the facial parameters that have already been derived.\nMoreover, the reflectance symmetry and consistency among the video frames are\nadopted to improve the disentanglement of facial parameters. Together with a\nnovel strategy for incorporating the reflectance symmetry and consistency, CEST\ncan be efficiently trained with in-the-wild video clips. Both qualitative and\nquantitative experiments demonstrate the effectiveness of CEST.",
    "descriptor": "\nComments: ICCV 2021 (15 pages)\n",
    "authors": [
      "Yandong Wen",
      "Weiyang Liu",
      "Bhiksha Raj",
      "Rita Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.04800"
  },
  {
    "id": "arXiv:2110.04806",
    "title": "Fast and Robust Structural Damage Analysis of Civil Infrastructure Using  UAV Imagery",
    "abstract": "The usage of Unmanned Aerial Vehicles (UAVs) in the context of structural\nhealth inspection is recently gaining tremendous popularity. Camera mounted\nUAVs enable the fast acquisition of a large number of images often used for\nmapping, 3D model reconstruction, and as an assisting tool for inspectors. Due\nto the number of images captured during large scale UAV surveys, a manual\nimage-based inspection analysis of entire assets cannot be efficiently\nperformed by qualified engineers. Additionally, comparing defects to past\ninspections requires the retrieval of relevant images which is often\nimpractical without extensive metadata or computer-vision-based algorithms.\nIn this paper, we propose an end-to-end method for automated structural\ninspection damage analysis. Using automated object detection and segmentation\nwe accurately localize defects, bridge utilities and elements. Next, given the\nhigh overlap in UAV imagery, points of interest are extracted, and defects are\nlocated and matched throughout the image database, considerably reducing data\nredundancy while maintaining a detailed record of the defects.\nOur technique not only enables fast and robust damage analysis of UAV\nimagery, as we show herein, but is also effective for analyzing manually\nacquired images.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Alon Oring"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04806"
  },
  {
    "id": "arXiv:2110.04808",
    "title": "Graph Models for Biological Pathway Visualization: State of the Art and  Future Challenges",
    "abstract": "The concept of multilayer networks has become recently integrated into\ncomplex systems modeling since it encapsulates a very general concept of\ncomplex relationships. Biological pathways are an example of complex real-world\nnetworks, where vertices represent biological entities, and edges indicate the\nunderlying connectivity. For this reason, using multilayer networks to model\nbiological knowledge allows us to formally cover essential properties and\ntheories in the field, which also raises challenges in visualization. This is\nbecause, in the early days of pathway visualization research, only restricted\ntypes of graphs, such as simple graphs, clustered graphs, and others were\nadopted. In this paper, we revisit a heterogeneous definition of biological\nnetworks and aim to provide an overview to see the gaps between data modeling\nand visual representation. The contribution will, therefore, lie in providing\nguidelines and challenges of using multilayer networks as a unified data\nstructure for the biological pathway visualization.",
    "descriptor": "",
    "authors": [
      "Hsiang-Yun Wu",
      "Martin N\u00f6llenburg",
      "Ivan Viola"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.04808"
  },
  {
    "id": "arXiv:2110.04810",
    "title": "Application of Graph Convolutions in a Lightweight Model for Skeletal  Human Motion Forecasting",
    "abstract": "Prediction of movements is essential for successful cooperation with\nintelligent systems. We propose a model that integrates organized spatial\ninformation as given through the moving body's skeletal structure. This\ninherent structure is exploited in our model through application of Graph\nConvolutions and we demonstrate how this allows leveraging the structured\nspatial information into competitive predictions that are based on a\nlightweight model that requires a comparatively small number of parameters.",
    "descriptor": "\nComments: To be published in conference proceedings of ESANN 2021\n",
    "authors": [
      "Luca Hermes",
      "Barbara Hammer",
      "Malte Schilling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.04810"
  },
  {
    "id": "arXiv:2110.04820",
    "title": "Better Pseudo-label: Joint Domain-aware Label and Dual-classifier for  Semi-supervised Domain Generalization",
    "abstract": "With the goal of directly generalizing trained models to unseen target\ndomains, domain generalization (DG), a newly proposed learning paradigm, has\nattracted considerable attention. Previous DG models usually require a\nsufficient quantity of annotated samples from observed source domains during\ntraining. In this paper, we relax this requirement about full annotation and\ninvestigate semi-supervised domain generalization (SSDG) where only one source\ndomain is fully annotated along with the other domains totally unlabeled in the\ntraining process. With the challenges of tackling the domain gap between\nobserved source domains and predicting unseen target domains, we propose a\nnovel deep framework via joint domain-aware labels and dual-classifier to\nproduce high-quality pseudo-labels. Concretely, to predict accurate\npseudo-labels under domain shift, a domain-aware pseudo-labeling module is\ndeveloped. Also, considering inconsistent goals between generalization and\npseudo-labeling: former prevents overfitting on all source domains while latter\nmight overfit the unlabeled source domains for high accuracy, we employ a\ndual-classifier to independently perform pseudo-labeling and domain\ngeneralization in the training process. Extensive results on publicly available\nDG benchmark datasets show the efficacy of our proposed SSDG method compared to\nthe well-designed baselines and the state-of-the-art semi-supervised learning\nmethods.",
    "descriptor": "",
    "authors": [
      "Ruiqi Wang",
      "Lei Qi",
      "Yinghuan Shi",
      "Yang Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04820"
  },
  {
    "id": "arXiv:2110.04821",
    "title": "DCT: Dynamic Compressive Transformer for Modeling Unbounded Sequence",
    "abstract": "In this paper, we propose Dynamic Compressive Transformer (DCT), a\ntransformer-based framework for modeling the unbounded sequence. In contrast to\nthe previous baselines which append every sentence representation to memory,\nconditionally selecting and appending them is a more reasonable solution to\ndeal with unlimited long sequences. Our model uses a policy that determines\nwhether the sequence should be kept in memory with a compressed state or\ndiscarded during the training process. With the benefits of retaining\nsemantically meaningful sentence information in the memory system, our\nexperiment results on Enwik8 benchmark show that DCT outperforms the previous\nstate-of-the-art (SOTA) model.",
    "descriptor": "",
    "authors": [
      "Kai-Po Chang",
      "Wei-Yun Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04821"
  },
  {
    "id": "arXiv:2110.04824",
    "title": "Haar Wavelet Feature Compression for Quantized Graph Convolutional  Networks",
    "abstract": "Graph Convolutional Networks (GCNs) are widely used in a variety of\napplications, and can be seen as an unstructured version of standard\nConvolutional Neural Networks (CNNs). As in CNNs, the computational cost of\nGCNs for large input graphs (such as large point clouds or meshes) can be high\nand inhibit the use of these networks, especially in environments with low\ncomputational resources. To ease these costs, quantization can be applied to\nGCNs. However, aggressive quantization of the feature maps can lead to a\nsignificant degradation in performance. On a different note, Haar wavelet\ntransforms are known to be one of the most effective and efficient approaches\nto compress signals. Therefore, instead of applying aggressive quantization to\nfeature maps, we propose to utilize Haar wavelet compression and light\nquantization to reduce the computations and the bandwidth involved with the\nnetwork. We demonstrate that this approach surpasses aggressive feature\nquantization by a significant margin, for a variety of problems ranging from\nnode classification to point cloud classification and part and semantic\nsegmentation.",
    "descriptor": "",
    "authors": [
      "Moshe Eliasof",
      "Benjamin Bodner",
      "Eran Treister"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.04824"
  },
  {
    "id": "arXiv:2110.04826",
    "title": "Multi-symplectic discontinuous Galerkin methods for the stochastic  Maxwell equations with additive noise",
    "abstract": "One- and multi-dimensional stochastic Maxwell equations with additive noise\nare considered in this paper. It is known that such system can be written in\nthe multi-symplectic structure, and the stochastic energy increases linearly in\ntime. High order discontinuous Galerkin methods are designed for the stochastic\nMaxwell equations with additive noise, and we show that the proposed methods\nsatisfy the discrete form of the stochastic energy linear growth property and\npreserve the multi-symplectic structure on the discrete level. Optimal error\nestimate of the semi-discrete DG method is also analyzed. The fully discrete\nmethods are obtained by coupling with symplectic temporal discretizations. One-\nand two-dimensional numerical results are provided to demonstrate the\nperformance of the proposed methods, and optimal error estimates and linear\ngrowth of the discrete energy can be observed for all cases.",
    "descriptor": "",
    "authors": [
      "Jiawei Sun",
      "Chi-Wang Shu",
      "Yulong Xing"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.04826"
  },
  {
    "id": "arXiv:2110.04828",
    "title": "FLAME: Facial Landmark Heatmap Activated Multimodal Gaze Estimation",
    "abstract": "3D gaze estimation is about predicting the line of sight of a person in 3D\nspace. Person-independent models for the same lack precision due to anatomical\ndifferences of subjects, whereas person-specific calibrated techniques add\nstrict constraints on scalability. To overcome these issues, we propose a novel\ntechnique, Facial Landmark Heatmap Activated Multimodal Gaze Estimation\n(FLAME), as a way of combining eye anatomical information using eye landmark\nheatmaps to obtain precise gaze estimation without any person-specific\ncalibration. Our evaluation demonstrates a competitive performance of about 10%\nimprovement on benchmark datasets ColumbiaGaze and EYEDIAP. We also conduct an\nablation study to validate our method.",
    "descriptor": "\nComments: Preprint. Final paper accepted at the 17th IEEE International Conference on Advanced Video and Signal-based Surveillance, AVSS 2021, Virtual, November 16-19, 2021. 8 pages\n",
    "authors": [
      "Neelabh Sinha",
      "Michal Balazia",
      "Fran\u00e7ois Bremond"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04828"
  },
  {
    "id": "arXiv:2110.04830",
    "title": "Vectorization of Raster Manga by Deep Reinforcement Learning",
    "abstract": "Manga is a popular Japanese-style comic form that consists of black-and-white\nstroke lines. Compared with images of real-world scenarios, the simpler\ntextures and fewer color gradients of mangas are the extra natures that can be\nvectorized. In this paper, we propose Mang2Vec, the first approach for\nvectorizing raster mangas using Deep Reinforcement Learning (DRL). Unlike\nexisting learning-based works of image vectorization, we present a new view\nthat considers an entire manga as a collection of basic primitives \"stroke\nline\", and the sequence of strokes lines can be deep decomposed for further\nvectorization. We train a designed DRL agent to produce the most suitable\nsequence of stroke lines, which is constrained to follow the visual feature of\nthe target manga. Next, the control parameters of strokes are collected to\ntranslated to vector format. To improve our performances on visual quality and\nstorage size, we further propose an SA reward to generate accurate stokes, and\na pruning mechanism to avoid producing error and redundant strokes.\nQuantitative and qualitative experiments demonstrate that our Mang2Vec can\nproduce impressive results and reaches the state-of-the-art level.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Hao Su",
      "Jianwei Niu",
      "Xuefeng Liu",
      "Jiahe Cui",
      "Ji Wan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04830"
  },
  {
    "id": "arXiv:2110.04831",
    "title": "Feature Imitating Networks",
    "abstract": "In this paper, we introduce a novel approach to neural learning: the\nFeature-Imitating-Network (FIN). A FIN is a neural network with weights that\nare initialized to reliably approximate one or more closed-form statistical\nfeatures, such as Shannon's entropy. In this paper, we demonstrate that FINs\n(and FIN ensembles) provide best-in-class performance for a variety of\ndownstream signal processing and inference tasks, while using less data and\nrequiring less fine-tuning compared to other networks of similar (or even\ngreater) representational power. We conclude that FINs can help bridge the gap\nbetween domain experts and machine learning practitioners by enabling\nresearchers to harness insights from feature-engineering to enhance the\nperformance of contemporary representation learning approaches.",
    "descriptor": "",
    "authors": [
      "Sari Saba-Sadiya",
      "Tuka Alhanai",
      "Mohammad M Ghassemi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04831"
  },
  {
    "id": "arXiv:2110.04835",
    "title": "Reinforcement Learning In Two Player Zero Sum Simultaneous Action Games",
    "abstract": "Two player zero sum simultaneous action games are common in video games,\nfinancial markets, war, business competition, and many other settings. We first\nintroduce the fundamental concepts of reinforcement learning in two player zero\nsum simultaneous action games and discuss the unique challenges this type of\ngame poses. Then we introduce two novel agents that attempt to handle these\nchallenges by using joint action Deep Q-Networks (DQN). The first agent, called\nthe Best Response AgenT (BRAT), builds an explicit model of its opponent's\npolicy using imitation learning, and then uses this model to find the best\nresponse to exploit the opponent's strategy. The second agent, Meta-Nash DQN,\nbuilds an implicit model of its opponent's policy in order to produce a context\nvariable that is used as part of the Q-value calculation. An explicit minimax\nover Q-values is used to find actions close to Nash equilibrium. We find\nempirically that both agents converge to Nash equilibrium in a self-play\nsetting for simple matrix games, while also performing well in games with\nlarger state and action spaces. These novel algorithms are evaluated against\nvanilla RL algorithms as well as recent state of the art multi-agent and two\nagent algorithms. This work combines ideas from traditional reinforcement\nlearning, game theory, and meta learning.",
    "descriptor": "",
    "authors": [
      "Patrick Phillips"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.04835"
  },
  {
    "id": "arXiv:2110.04837",
    "title": "Using Edge Cases to Disentangle Fairness and Solidarity in AI Ethics",
    "abstract": "Principles of fairness and solidarity in AI ethics regularly overlap,\ncreating obscurity in practice: acting in accordance with one can appear\nindistinguishable from deciding according to the rules of the other. However,\nthere exist irregular cases where the two concepts split, and so reveal their\ndisparate meanings and uses. This paper explores two cases in AI medical\nethics, one that is irregular and the other more conventional, to fully\ndistinguish fairness and solidarity. Then the distinction is applied to the\nfrequently cited COMPAS versus ProPublica dispute in judicial ethics. The\napplication provides a broader model for settling contemporary and topical\ndebates about fairness and solidarity. It also implies a deeper and\ndisorienting truth about AI ethics principles and their justification.",
    "descriptor": "\nComments: Full published version at AI Ethics (2021): this https URL\n",
    "authors": [
      "James Brusseau"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.04837"
  },
  {
    "id": "arXiv:2110.04840",
    "title": "Heavy Ball Neural Ordinary Differential Equations",
    "abstract": "We propose heavy ball neural ordinary differential equations (HBNODEs),\nleveraging the continuous limit of the classical momentum accelerated gradient\ndescent, to improve neural ODEs (NODEs) training and inference. HBNODEs have\ntwo properties that imply practical advantages over NODEs: (i) The adjoint\nstate of an HBNODE also satisfies an HBNODE, accelerating both forward and\nbackward ODE solvers, thus significantly reducing the number of function\nevaluations (NFEs) and improving the utility of the trained models. (ii) The\nspectrum of HBNODEs is well structured, enabling effective learning of\nlong-term dependencies from complex sequential data. We verify the advantages\nof HBNODEs over NODEs on benchmark tasks, including image classification,\nlearning complex dynamics, and sequential modeling. Our method requires\nremarkably fewer forward and backward NFEs, is more accurate, and learns\nlong-term dependencies more effectively than the other ODE-based neural network\nmodels. Code is available at \\url{https://github.com/hedixia/HeavyBallNODE}.",
    "descriptor": "\nComments: 23 pages, 9 figures, Accepted for publication at Advances in Neural Information Processing Systems (NeurIPS) 2021\n",
    "authors": [
      "Hedi Xia",
      "Vai Suliafu",
      "Hangjie Ji",
      "Tan M. Nguyen",
      "Andrea L. Bertozzi",
      "Stanley J. Osher",
      "Bao Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.04840"
  },
  {
    "id": "arXiv:2110.04841",
    "title": "SplitPlace: Intelligent Placement of Split Neural Nets in Mobile Edge  Environments",
    "abstract": "In recent years, deep learning models have become ubiquitous in industry and\nacademia alike. Modern deep neural networks can solve one of the most complex\nproblems today, but coming with the price of massive compute and storage\nrequirements. This makes deploying such massive neural networks challenging in\nthe mobile edge computing paradigm, where edge nodes are resource-constrained,\nhence limiting the input analysis power of such frameworks. Semantic and\nlayer-wise splitting of neural networks for distributed processing show some\nhope in this direction. However, there are no intelligent algorithms that place\nsuch modular splits to edge nodes for optimal performance. This work proposes a\nnovel placement policy, SplitPlace, for the placement of such neural network\nsplit fragments on mobile edge hosts for efficient and scalable computing.",
    "descriptor": "\nComments: First Place - Gold Medal at the Student Research Competition at ACM SIGMETRICS Conference 2021\n",
    "authors": [
      "Shreshth Tuli"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.04841"
  },
  {
    "id": "arXiv:2110.04844",
    "title": "Frequency-aware SGD for Efficient Embedding Learning with Provable  Benefits",
    "abstract": "Embedding learning has found widespread applications in recommendation\nsystems and natural language modeling, among other domains. To learn quality\nembeddings efficiently, adaptive learning rate algorithms have demonstrated\nsuperior empirical performance over SGD, largely accredited to their\ntoken-dependent learning rate. However, the underlying mechanism for the\nefficiency of token-dependent learning rate remains underexplored. We show that\nincorporating frequency information of tokens in the embedding learning\nproblems leads to provably efficient algorithms, and demonstrate that common\nadaptive algorithms implicitly exploit the frequency information to a large\nextent. Specifically, we propose (Counter-based) Frequency-aware Stochastic\nGradient Descent, which applies a frequency-dependent learning rate for each\ntoken, and exhibits provable speed-up compared to SGD when the token\ndistribution is imbalanced. Empirically, we show the proposed algorithms are\nable to improve or match adaptive algorithms on benchmark recommendation tasks\nand a large-scale industrial recommendation system, closing the performance gap\nbetween SGD and adaptive algorithms. Our results are the first to show\ntoken-dependent learning rate provably improves convergence for non-convex\nembedding learning problems.",
    "descriptor": "",
    "authors": [
      "Yan Li",
      "Dhruv Choudhary",
      "Xiaohan Wei",
      "Baichuan Yuan",
      "Bhargav Bhushanam",
      "Tuo Zhao",
      "Guanghui Lan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.04844"
  },
  {
    "id": "arXiv:2110.04845",
    "title": "What Makes Sentences Semantically Related: A Textual Relatedness Dataset  and Empirical Study",
    "abstract": "The degree of semantic relatedness (or, closeness in meaning) of two units of\nlanguage has long been considered fundamental to understanding meaning.\nAutomatically determining relatedness has many applications such as question\nanswering and summarization. However, prior NLP work has largely focused on\nsemantic similarity (a subset of relatedness), because of a lack of relatedness\ndatasets. Here for the first time, we introduce a dataset of semantic\nrelatedness for sentence pairs. This dataset, STR-2021, has 5,500 English\nsentence pairs manually annotated for semantic relatedness using a comparative\nannotation framework. We show that the resulting scores have high reliability\n(repeat annotation correlation of 0.84). We use the dataset to explore a number\nof questions on what makes two sentences more semantically related. We also\nevaluate a suite of sentence representation methods on their ability to place\npairs that are more related closer to each other in vector space.",
    "descriptor": "",
    "authors": [
      "Mohamed Abdalla",
      "Krishnapriya Vishnubhotla",
      "Saif M. Mohammad"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04845"
  },
  {
    "id": "arXiv:2110.04854",
    "title": "Identity-Guided Face Generation with Multi-modal Contour Conditions",
    "abstract": "Recent face generation methods have tried to synthesize faces based on the\ngiven contour condition, like a low-resolution image or a sketch. However, the\nproblem of identity ambiguity remains unsolved, which usually occurs when the\ncontour is too vague to provide reliable identity information (e.g., when its\nresolution is extremely low). In this work, we propose a framework that takes\nthe contour and an extra image specifying the identity as the inputs, where the\ncontour can be of various modalities, including the low-resolution image,\nsketch, and semantic label map. This task especially fits the situation of\ntracking the known criminals or making intelligent creations for entertainment.\nConcretely, we propose a novel dual-encoder architecture, in which an identity\nencoder extracts the identity-related feature, accompanied by a main encoder to\nobtain the rough contour information and further fuse all the information\ntogether. The encoder output is iteratively fed into a pre-trained StyleGAN\ngenerator until getting a satisfying result. To the best of our knowledge, this\nis the first work that achieves identity-guided face generation conditioned on\nmulti-modal contour images. Moreover, our method can produce photo-realistic\nresults with 1024$\\times$1024 resolution. Code will be available at\nhttps://git.io/Jo4yh.",
    "descriptor": "\nComments: 5 pages, 4 figures, submitted to ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\n",
    "authors": [
      "Qingyan Bai",
      "Weihao Xia",
      "Fei Yin",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04854"
  },
  {
    "id": "arXiv:2110.04857",
    "title": "Cooperative Assistance in Robotic Surgery through Multi-Agent  Reinforcement Learning",
    "abstract": "Cognitive cooperative assistance in robot-assisted surgery holds the\npotential to increase quality of care in minimally invasive interventions.\nAutomation of surgical tasks promises to reduce the mental exertion and fatigue\nof surgeons. In this work, multi-agent reinforcement learning is demonstrated\nto be robust to the distribution shift introduced by pairing a learned policy\nwith a human team member. Multi-agent policies are trained directly from images\nin simulation to control multiple instruments in a sub task of the minimally\ninvasive removal of the gallbladder. These agents are evaluated individually\nand in cooperation with humans to demonstrate their suitability as autonomous\nassistants. Compared to human teams, the hybrid teams with artificial agents\nperform better considering completion time (44.4% to 71.2% shorter) as well as\nnumber of collisions (44.7% to 98.0% fewer). Path lengths, however, increase\nunder control of an artificial agent (11.4% to 33.5% longer). A multi-agent\nformulation of the learning problem was favored over a single-agent formulation\non this surgical sub task, due to the sequential learning of the two\ninstruments. This approach may be extended to other tasks that are difficult to\nformulate within the standard reinforcement learning framework. Multi-agent\nreinforcement learning may shift the paradigm of cognitive robotic surgery\ntowards seamless cooperation between surgeons and assistive technologies.",
    "descriptor": "\nComments: Accepted at the 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2021)\n",
    "authors": [
      "Paul Maria Scheikl",
      "Bal\u00e1zs Gyenes",
      "Tornike Davitashvili",
      "Rayan Younis",
      "Andr\u00e9 Schulze",
      "Beat P. M\u00fcller-Stich",
      "Gerhard Neumann",
      "Martin Wagner",
      "Franziska Mathis-Ullrich"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.04857"
  },
  {
    "id": "arXiv:2110.04861",
    "title": "A Deep Learning Inference Scheme Based on Pipelined Matrix  Multiplication Acceleration Design and Non-uniform Quantization",
    "abstract": "Matrix multiplication is the bedrock in Deep Learning inference application.\nWhen it comes to hardware acceleration on edge computing devices, matrix\nmultiplication often takes up a great majority of the time. To achieve better\nperformance in edge computing, we introduce a low-power Multi-layer Perceptron\n(MLP) accelerator based on a pipelined matrix multiplication scheme and a\nnonuniform quantization methodology. The implementation is running on\nField-programmable Gate Array (FPGA) devices and tested its performance on\nhandwritten digit classification and Q-learning tasks. Results show that our\nmethod can achieve better performance with fewer power consumption.",
    "descriptor": "",
    "authors": [
      "Yuyang Zhang",
      "Dik Hin Leung",
      "Min Guo",
      "Yijia Xiao",
      "Haoyue Liu",
      "Yunfei Li",
      "Jiyuan Zhang",
      "Guan Wang",
      "Zhen Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2110.04861"
  },
  {
    "id": "arXiv:2110.04865",
    "title": "Parallel Minimum Spanning Forest Computation using Sparse Matrix Kernels",
    "abstract": "Formulations of graph algorithms using sparse linear algebra have yielded\nhighly scalable distributed algorithms for problems such as connectivity and\nshortest path computation. We develop the first formulation of the\nAwerbuch-Shiloach parallel minimum spanning forest (MSF) algorithm using linear\nalgebra primitives. We introduce a multilinear kernel that operates on an\nadjacency matrix and two vectors. This kernel updates graph vertices by\nsimultaneously using information from both adjacent edges and vertices. In\naddition, we explore optimizations to accelerate the shortcutting step in the\nAwerbuch-Shiloach algorithm. We implement this MSF algorithm with Cyclops, a\ndistributed-memory library for generalized sparse tensor algebra. We analyze\nthe parallel scalability of our implementation on the Stampede2 supercomputer.",
    "descriptor": "",
    "authors": [
      "Tim Baer",
      "Raghavendra Kanakagiri",
      "Edgar Solomonik"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.04865"
  },
  {
    "id": "arXiv:2110.04866",
    "title": "CoRGi: Content-Rich Graph Neural Networks with Attention",
    "abstract": "Graph representations of a target domain often project it to a set of\nentities (nodes) and their relations (edges). However, such projections often\nmiss important and rich information. For example, in graph representations used\nin missing value imputation, items - represented as nodes - may contain rich\ntextual information. However, when processing graphs with graph neural networks\n(GNN), such information is either ignored or summarized into a single vector\nrepresentation used to initialize the GNN. Towards addressing this, we present\nCoRGi, a GNN that considers the rich data within nodes in the context of their\nneighbors. This is achieved by endowing CoRGi's message passing with a\npersonalized attention mechanism over the content of each node. This way, CoRGi\nassigns user-item-specific attention scores with respect to the words that\nappear in an item's content. We evaluate CoRGi on two edge-value prediction\ntasks and show that CoRGi is better at making edge-value predictions over\nexisting methods, especially on sparse regions of the graph.",
    "descriptor": "",
    "authors": [
      "Jooyeon Kim",
      "Angus Lamb",
      "Simon Woodhead",
      "Simon Peyton Jones",
      "Cheng Zheng",
      "Miltiadis Allamanis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04866"
  },
  {
    "id": "arXiv:2110.04869",
    "title": "NViT: Vision Transformer Compression and Parameter Redistribution",
    "abstract": "Transformers yield state-of-the-art results across many tasks. However, they\nstill impose huge computational costs during inference. We apply global,\nstructural pruning with latency-aware regularization on all parameters of the\nVision Transformer (ViT) model for latency reduction. Furthermore, we analyze\nthe pruned architectures and find interesting regularities in the final weight\nstructure. Our discovered insights lead to a new architecture called NViT\n(Novel ViT), with a redistribution of where parameters are used. This\narchitecture utilizes parameters more efficiently and enables control of the\nlatency-accuracy trade-off. On ImageNet-1K, we prune the DEIT-Base (Touvron et\nal., 2021) model to a 2.6x FLOPs reduction, 5.1x parameter reduction, and 1.9x\nrun-time speedup with only 0.07% loss in accuracy. We achieve more than 1%\naccuracy gain when compressing the base model to the throughput of the\nSmall/Tiny variants. NViT gains 0.1-1.1% accuracy over the hand-designed DEIT\nfamily when trained from scratch, while being faster.",
    "descriptor": "",
    "authors": [
      "Huanrui Yang",
      "Hongxu Yin",
      "Pavlo Molchanov",
      "Hai Li",
      "Jan Kautz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04869"
  },
  {
    "id": "arXiv:2110.04875",
    "title": "Scope2Screen: Focus+Context Techniques for Pathology Tumor Assessment in  Multivariate Image Data",
    "abstract": "Inspection of tissues using a light microscope is the primary method of\ndiagnosing many diseases, notably cancer. Highly multiplexed tissue imaging\nbuilds on this foundation, enabling the collection of up to 60 channels of\nmolecular information plus cell and tissue morphology using antibody staining.\nThis provides unique insight into disease biology and promises to help with the\ndesign of patient-specific therapies. However, a substantial gap remains with\nrespect to visualizing the resulting multivariate image data and effectively\nsupporting pathology workflows in digital environments on screen. We,\ntherefore, developed Scope2Screen, a scalable software system for focus+context\nexploration and annotation of whole-slide, high-plex, tissue images. Our\napproach scales to analyzing 100GB images of 10^9 or more pixels per channel,\ncontaining millions of cells. A multidisciplinary team of visualization\nexperts, microscopists, and pathologists identified key image exploration and\nannotation tasks involving finding, magnifying, quantifying, and organizing\nROIs in an intuitive and cohesive manner. Building on a scope2screen metaphor,\nwe present interactive lensing techniques that operate at single-cell and\ntissue levels. Lenses are equipped with task-specific functionality and\ndescriptive statistics, making it possible to analyze image features, cell\ntypes, and spatial arrangements (neighborhoods) across image channels and\nscales. A fast sliding-window search guides users to regions similar to those\nunder the lens; these regions can be analyzed and considered either separately\nor as part of a larger image collection. A novel snapshot method enables linked\nlens configurations and image statistics to be saved, restored, and shared. We\nvalidate our designs with domain experts and apply Scope2Screen in two case\nstudies involving lung and colorectal cancers to discover cancer-relevant image\nfeatures.",
    "descriptor": "",
    "authors": [
      "Jared Jessup",
      "Robert Krueger",
      "Simon Warchol",
      "John Hoffer",
      "Jeremy Muhlich",
      "Cecily C. Ritch",
      "Giorgio Gaglia",
      "Shannon Coy",
      "Yu-An Chen",
      "Jia-Ren Lin",
      "Sandro Santagata",
      "Peter K. Sorger",
      "Hanspeter Pfister"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.04875"
  },
  {
    "id": "arXiv:2110.04878",
    "title": "On Automatic Text Extractive Summarization Based on Graph and  pre-trained Language Model Attention",
    "abstract": "Representing text as graph to solve the summarization task has been discussed\nfor more than 10 years. However, with the development of attention or\nTransformer, the connection between attention and graph remains poorly\nunderstood. We demonstrate that the text structure can be analyzed through the\nattention matrix, which represents the relation between sentences by the\nattention weights. In this work, we show that the attention matrix produced in\npre-training language model can be used as the adjacent matrix of graph\nconvolutional network model. Our model performs a competitive result on 2\ndifferent datasets based on the ROUGE index. Also, with fewer parameters, the\nmodel reduces the computation resource when training and inferring.",
    "descriptor": "",
    "authors": [
      "Yuan-Ching Lin",
      "Jinwen Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04878"
  },
  {
    "id": "arXiv:2110.04880",
    "title": "Human Factors Considerations in Satellite Operation's Human-Computer  Interaction Technologies: A Review of Current Applications and Theory",
    "abstract": "Satellite operations are a subset of remote operations that draw similarities\nwith remotely piloted aircraft (RPA) and uncrewed aerial vehicle (UAV)\noperations. Increased research into boredom, complacency, habituation, and\nvigilance as they relate to satellite operations is required due to a lack of\nprevalence in the literature. Circadian rhythms, crew resource management, and\nshift work dynamics may exacerbate complacency-driven automation bias and\nsocial loafing errors in satellite operations. This overview of theory and\napplications aims to specifically focus on satellite operations literature\nwithin human factors research to identify areas requiring an expansion of\nknowledge. The human-in-the-loop commonality enables human factors lessons to\nbe passed to satellite operations from unrelated sectors to mitigate\ncatastrophic human error potentially. As such, this literature review details\nthe need for increased research in satellite operations human factors.",
    "descriptor": "\nComments: 20 Pages\n",
    "authors": [
      "David G.I. Heinrich",
      "Ian McAndrew",
      "Jeremy Pretty"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.04880"
  },
  {
    "id": "arXiv:2110.04886",
    "title": "Multi-Class Cell Detection Using Spatial Context Representation",
    "abstract": "In digital pathology, both detection and classification of cells are\nimportant for automatic diagnostic and prognostic tasks. Classifying cells into\nsubtypes, such as tumor cells, lymphocytes or stromal cells is particularly\nchallenging. Existing methods focus on morphological appearance of individual\ncells, whereas in practice pathologists often infer cell classes through their\nspatial context. In this paper, we propose a novel method for both detection\nand classification that explicitly incorporates spatial contextual information.\nWe use the spatial statistical function to describe local density in both a\nmulti-class and a multi-scale manner. Through representation learning and deep\nclustering techniques, we learn advanced cell representation with both\nappearance and spatial context. On various benchmarks, our method achieves\nbetter performance than state-of-the-arts, especially on the classification\ntask.",
    "descriptor": "",
    "authors": [
      "Shahira Abousamra",
      "David Belinsky",
      "John Van Arnam",
      "Felicia Allard",
      "Eric Yee",
      "Rajarsi Gupta",
      "Tahsin Kurc",
      "Dimitris Samaras",
      "Joel Saltz",
      "Chao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04886"
  },
  {
    "id": "arXiv:2110.04887",
    "title": "Adversarial Attacks in a Multi-view Setting: An Empirical Study of the  Adversarial Patches Inter-view Transferability",
    "abstract": "While machine learning applications are getting mainstream owing to a\ndemonstrated efficiency in solving complex problems, they suffer from inherent\nvulnerability to adversarial attacks. Adversarial attacks consist of additive\nnoise to an input which can fool a detector. Recently, successful real-world\nprintable adversarial patches were proven efficient against state-of-the-art\nneural networks. In the transition from digital noise based attacks to\nreal-world physical attacks, the myriad of factors affecting object detection\nwill also affect adversarial patches. Among these factors, view angle is one of\nthe most influential, yet under-explored. In this paper, we study the effect of\nview angle on the effectiveness of an adversarial patch. To this aim, we\npropose the first approach that considers a multi-view context by combining\nexisting adversarial patches with a perspective geometric transformation in\norder to simulate the effect of view angle changes. Our approach has been\nevaluated on two datasets: the first dataset which contains most real world\nconstraints of a multi-view context, and the second dataset which empirically\nisolates the effect of view angle. The experiments show that view angle\nsignificantly affects the performance of adversarial patches, where in some\ncases the patch loses most of its effectiveness. We believe that these results\nmotivate taking into account the effect of view angles in future adversarial\nattacks, and open up new opportunities for adversarial defenses.",
    "descriptor": "\nComments: To appear in the 20th CyberWorlds Conference\n",
    "authors": [
      "Bilel Tarchoun",
      "Ihsen Alouani",
      "Anouar Ben Khalifa",
      "Mohamed Ali Mahjoub"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04887"
  },
  {
    "id": "arXiv:2110.04888",
    "title": "Language Models As or For Knowledge Bases",
    "abstract": "Pre-trained language models (LMs) have recently gained attention for their\npotential as an alternative to (or proxy for) explicit knowledge bases (KBs).\nIn this position paper, we examine this hypothesis, identify strengths and\nlimitations of both LMs and KBs, and discuss the complementary nature of the\ntwo paradigms. In particular, we offer qualitative arguments that latent LMs\nare not suitable as a substitute for explicit KBs, but could play a major role\nfor augmenting and curating KBs.",
    "descriptor": "",
    "authors": [
      "Simon Razniewski",
      "Andrew Yates",
      "Nora Kassner",
      "Gerhard Weikum"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.04888"
  },
  {
    "id": "arXiv:2110.04889",
    "title": "Distantly-Supervised Evidence Retrieval Enables Question Answering  without Evidence Annotation",
    "abstract": "Open-domain question answering answers a question based on evidence retrieved\nfrom a large corpus. State-of-the-art neural approaches require intermediate\nevidence annotations for training. However, such intermediate annotations are\nexpensive, and methods that rely on them cannot transfer to the more common\nsetting, where only question-answer pairs are available. This paper\ninvestigates whether models can learn to find evidence from a large corpus,\nwith only distant supervision from answer labels for model training, thereby\ngenerating no additional annotation cost. We introduce a novel approach\n(DistDR) that iteratively improves over a weak retriever by alternately finding\nevidence from the up-to-date model and encouraging the model to learn the most\nlikely evidence. Without using any evidence labels, DistDR is on par with\nfully-supervised state-of-the-art methods on both multi-hop and single-hop QA\nbenchmarks. Our analysis confirms that DistDR finds more accurate evidence over\niterations, which leads to model improvements.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Chen Zhao",
      "Chenyan Xiong",
      "Jordan Boyd-Graber",
      "Hal Daum\u00e9 III"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04889"
  },
  {
    "id": "arXiv:2110.04890",
    "title": "Perceptions and attitudes of Children and Young People to Artificial  Intelligence in Medicine",
    "abstract": "There is increasing interest in Artificial Intelligence and its application\nto medicine. Perceptions are less well-known, notably amongst children and\nyoung people. 21 members of a Young Persons Advisory Group for research,\nrecommend creating an enabling environment with children and young people,\nthrough educational workshops with practical examples that use Artificial\nIntelligence to help, but not replace humans, address issues, build trust, and\neffectively communicate about potential opportunities.",
    "descriptor": "\nComments: 6 Pages, 1 figure, 1 table\n",
    "authors": [
      "Sheena Visram",
      "Deirdre Leyden",
      "Oceiah Annesley",
      "Dauda Bappa",
      "Neil J Sebire"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.04890"
  },
  {
    "id": "arXiv:2110.04891",
    "title": "Have best of both worlds: two-pass hybrid and E2E cascading framework  for speech recognition",
    "abstract": "Hybrid and end-to-end (E2E) systems have their individual advantages, with\ndifferent error patterns in the speech recognition results. By jointly modeling\naudio and text, the E2E model performs better in matched scenarios and scales\nwell with a large amount of paired audio-text training data. The modularized\nhybrid model is easier for customization, and better to make use of a massive\namount of unpaired text data. This paper proposes a two-pass hybrid and E2E\ncascading (HEC) framework to combine the hybrid and E2E model in order to take\nadvantage of both sides, with hybrid in the first pass and E2E in the second\npass. We show that the proposed system achieves 8-10% relative word error rate\nreduction with respect to each individual system. More importantly, compared\nwith the pure E2E system, we show the proposed system has the potential to keep\nthe advantages of hybrid system, e.g., customization and segmentation\ncapabilities. We also show the second pass E2E model in HEC is robust with\nrespect to the change in the first pass hybrid model.",
    "descriptor": "",
    "authors": [
      "Guoli Ye",
      "Vadim Mazalov",
      "Jinyu Li",
      "Yifan Gong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.04891"
  },
  {
    "id": "arXiv:2110.04899",
    "title": "Influencing the Influencers: Evaluating Person-to-Person Influence on  Social Networks Using Granger Causality",
    "abstract": "We introduce a novel method for analyzing person-to-person content influence\non Twitter. Using an Ego-Alter framework and Granger Causality, we examine\nPresident Donald Trump (the Ego) and the people he retweets (Alters) as a case\nstudy. We find that each Alter has a different scope of influence across\nmultiple topics, different magnitude of influence on a given topic, and the\nmagnitude of a single Alter's influence can vary across topics. This work is\nnovel in its focus on person-to-person influence and content-based influence.\nIts impact is two-fold: (1) identifying \"canaries in the coal mine\" who could\nbe observed by misinformation researchers or platforms to identify\nmisinformation narratives before super-influencers spread them to large\naudiences, and (2) enabling digital marketing targeted toward upstream Alters\nof super-influencers.",
    "descriptor": "",
    "authors": [
      "Richard Kuzma",
      "Iain J. Cruickshank",
      "Kathleen M. Carley"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.04899"
  },
  {
    "id": "arXiv:2110.04902",
    "title": "Synthetic Data for Multi-Parameter Camera-Based Physiological Sensing",
    "abstract": "Synthetic data is a powerful tool in training data hungry deep learning\nalgorithms. However, to date, camera-based physiological sensing has not taken\nfull advantage of these techniques. In this work, we leverage a high-fidelity\nsynthetics pipeline for generating videos of faces with faithful blood flow and\nbreathing patterns. We present systematic experiments showing how\nphysiologically-grounded synthetic data can be used in training camera-based\nmulti-parameter cardiopulmonary sensing. We provide empirical evidence that\nheart and breathing rate measurement accuracy increases with the number of\nsynthetic avatars in the training set. Furthermore, training with avatars with\ndarker skin types leads to better overall performance than training with\navatars with lighter skin types. Finally, we discuss the opportunities that\nsynthetics present in the domain of camera-based physiological sensing and\nlimitations that need to be overcome.",
    "descriptor": "",
    "authors": [
      "Daniel McDuff",
      "Xin Liu",
      "Javier Hernandez",
      "Erroll Wood",
      "Tadas Baltrusaitis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04902"
  },
  {
    "id": "arXiv:2110.04904",
    "title": "Modality-Guided Subnetwork for Salient Object Detection",
    "abstract": "Recent RGBD-based models for saliency detection have attracted research\nattention. The depth clues such as boundary clues, surface normal, shape\nattribute, etc., contribute to the identification of salient objects with\ncomplicated scenarios. However, most RGBD networks require multi-modalities\nfrom the input side and feed them separately through a two-stream design, which\ninevitably results in extra costs on depth sensors and computation. To tackle\nthese inconveniences, we present in this paper a novel fusion design named\nmodality-guided subnetwork (MGSnet). It has the following superior designs: 1)\nOur model works for both RGB and RGBD data, and dynamically estimating depth if\nnot available. Taking the inner workings of depth-prediction networks into\naccount, we propose to estimate the pseudo-geometry maps from RGB input -\nessentially mimicking the multi-modality input. 2) Our MGSnet for RGB SOD\nresults in real-time inference but achieves state-of-the-art performance\ncompared to other RGB models. 3) The flexible and lightweight design of MGS\nfacilitates the integration into RGBD two-streaming models. The introduced\nfusion design enables a cross-modality interaction to enable further progress\nbut with a minimal cost.",
    "descriptor": "\nComments: Accepted to 3DV 2021\n",
    "authors": [
      "Zongwei Wu",
      "Guillaume Allibert",
      "Christophe Stolz",
      "Chao Ma",
      "C\u00e9dric Demonceaux"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04904"
  },
  {
    "id": "arXiv:2110.04906",
    "title": "Operationalizing Convolutional Neural Network Architectures for  Prohibited Object Detection in X-Ray Imagery",
    "abstract": "The recent advancement in deep Convolutional Neural Network (CNN) has brought\ninsight into the automation of X-ray security screening for aviation security\nand beyond. Here, we explore the viability of two recent end-to-end object\ndetection CNN architectures, Cascade R-CNN and FreeAnchor, for prohibited item\ndetection by balancing processing time and the impact of image data compression\nfrom an operational viewpoint. Overall, we achieve maximal detection\nperformance using a FreeAnchor architecture with a ResNet50 backbone, obtaining\nmean Average Precision (mAP) of 87.7 and 85.8 for using the OPIXray and SIXray\nbenchmark datasets, showing superior performance over prior work on both. With\nfewer parameters and less training time, FreeAnchor achieves the highest\ndetection inference speed of ~13 fps (3.9 ms per image). Furthermore, we\nevaluate the impact of lossy image compression upon detector performance. The\nCNN models display substantial resilience to the lossy compression, resulting\nin only a 1.1% decrease in mAP at the JPEG compression level of 50.\nAdditionally, a thorough evaluation of data augmentation techniques is\nprovided, including adaptions of MixUp and CutMix strategy as well as other\nstandard transformations, further improving the detection accuracy.",
    "descriptor": "",
    "authors": [
      "Thomas W. Webb",
      "Neelanjan Bhowmik",
      "Yona Falinie A. Gaus",
      "Toby P. Breckon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04906"
  },
  {
    "id": "arXiv:2110.04916",
    "title": "Brilliant Challenges Optimization Problem Submission Contest Final  Report",
    "abstract": "This paper concludes the Brilliant Challenges contest. Participants had to\ndesign interesting optimization problems and publish them using the Optil.io\nplatform. It was the first widely-advertised contest in the area of operational\nresearch where the objective was to submit the problem definition instead of\nthe algorithmic solutions. Thus, it is a crucial contribution to Open Science\nand the application of crowdsourcing methodology to solve discrete optimization\nproblems. The paper briefly describes submitted problems, presents the winners,\nand discusses the contest's achievements and shortcomings. Finally, we define\nguidelines supporting the organization of contests of similar type in the\nfuture.",
    "descriptor": "",
    "authors": [
      "Jan Badura",
      "Artur Laskowski",
      "Maciej Antczak",
      "Jacek Blazewicz",
      "Grzegorz Pawlak",
      "Erwin Pesch",
      "Thomas Villmann",
      "Szymon Wasik"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/2110.04916"
  },
  {
    "id": "arXiv:2110.04917",
    "title": "Morphable Detector for Object Detection on Demand",
    "abstract": "Many emerging applications of intelligent robots need to explore and\nunderstand new environments, where it is desirable to detect objects of novel\nclasses on the fly with minimum online efforts. This is an object detection on\ndemand (ODOD) task. It is challenging, because it is impossible to annotate a\nlarge number of data on the fly, and the embedded systems are usually unable to\nperform back-propagation which is essential for training. Most existing\nfew-shot detection methods are confronted here as they need extra training. We\npropose a novel morphable detector (MD), that simply \"morphs\" some of its\nchangeable parameters online estimated from the few samples, so as to detect\nnovel classes without any extra training. The MD has two sets of parameters,\none for the feature embedding and the other for class representation (called\n\"prototypes\"). Each class is associated with a hidden prototype to be learned\nby integrating the visual and semantic embeddings. The learning of the MD is\nbased on the alternate learning of the feature embedding and the prototypes in\nan EM-like approach which allows the recovery of an unknown prototype from a\nfew samples of a novel class. Once an MD is learned, it is able to use a few\nsamples of a novel class to directly compute its prototype to fulfill the\nonline morphing process. We have shown the superiority of the MD in Pascal,\nCOCO and FSOD datasets. The code is available\nhttps://github.com/Zhaoxiangyun/Morphable-Detector.",
    "descriptor": "\nComments: ICCV 2021\n",
    "authors": [
      "Xiangyun Zhao",
      "Xu Zou",
      "Ying Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04917"
  },
  {
    "id": "arXiv:2110.04921",
    "title": "Increasing a microscope's effective field of view via overlapped imaging  and machine learning",
    "abstract": "This work demonstrates a multi-lens microscopic imaging system that overlaps\nmultiple independent fields of view on a single sensor for high-efficiency\nautomated specimen analysis. Automatic detection, classification and counting\nof various morphological features of interest is now a crucial component of\nboth biomedical research and disease diagnosis. While convolutional neural\nnetworks (CNNs) have dramatically improved the accuracy of counting cells and\nsub-cellular features from acquired digital image data, the overall throughput\nis still typically hindered by the limited space-bandwidth product (SBP) of\nconventional microscopes. Here, we show both in simulation and experiment that\noverlapped imaging and co-designed analysis software can achieve accurate\ndetection of diagnostically-relevant features for several applications,\nincluding counting of white blood cells and the malaria parasite, leading to\nmulti-fold increase in detection and processing throughput with minimal\nreduction in accuracy.",
    "descriptor": "",
    "authors": [
      "Xing Yao",
      "Vinayak Pathak",
      "Haoran Xi",
      "Amey Chaware",
      "Colin Cooke",
      "Kanghyun Kim",
      "Shiqi Xu",
      "Yuting Li",
      "Timothy Dunn",
      "Pavan Chandra Konda",
      "Kevin C. Zhou",
      "Roarke Horstmeyer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Optics (physics.optics)",
      "Cell Behavior (q-bio.CB)"
    ],
    "url": "https://arxiv.org/abs/2110.04921"
  },
  {
    "id": "arXiv:2110.04922",
    "title": "Meta-learning an Intermediate Representation for Few-shot Block-wise  Prediction of Landslide Susceptibility",
    "abstract": "Predicting a landslide susceptibility map (LSM) is essential for risk\nrecognition and disaster prevention. Despite the successful application of\ndata-driven prediction approaches, current data-driven methods generally apply\na single global model to predict the LSM for an entire target region. However,\nwe argue that, in complex circumstances, especially in large-scale areas, each\npart of the region holds different landslide-inducing environments, and\ntherefore, should be predicted individually with respective models. In this\nstudy, target scenarios were segmented into blocks for individual analysis\nusing topographical factors. But simply conducting training and testing using\nlimited samples within each block is hardly possible for a satisfactory LSM\nprediction, due to the adverse effect of \\textit{overfitting}. To solve the\nproblems, we train an intermediate representation by the meta-learning\nparadigm, which is superior for capturing information from LSM tasks in order\nto generalize proficiently. We chose this based on the hypothesis that there\nare more general concepts among LSM tasks that are sensitive to variations in\ninput features. Thus, using the intermediate representation, we can easily\nadapt the model for different blocks or even unseen tasks using few exemplar\nsamples. Experimental results on two study areas demonstrated the validity of\nour block-wise analysis in large scenarios and revealed the top few-shot\nadaption performances of the proposed methods.",
    "descriptor": "",
    "authors": [
      "Li Chen",
      "Yulin Ding",
      "Han Hu",
      "Qing Zhu",
      "Haowei Zeng",
      "Haojia Yu",
      "Qisen Shang",
      "Yongfei Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04922"
  },
  {
    "id": "arXiv:2110.04923",
    "title": "Crack detection using tap-testing and machine learning techniques to  prevent potential rockfall incidents",
    "abstract": "Rockfalls are a hazard for the safety of infrastructure as well as people.\nIdentifying loose rocks by inspection of slopes adjacent to roadways and other\ninfrastructure and removing them in advance can be an effective way to prevent\nunexpected rockfall incidents. This paper proposes a system towards an\nautomated inspection for potential rockfalls. A robot is used to repeatedly\nstrike or tap on the rock surface. The sound from the tapping is collected by\nthe robot and subsequently classified with the intent of identifying rocks that\nare broken and prone to fall. Principal Component Analysis (PCA) of the\ncollected acoustic data is used to recognize patterns associated with rocks of\nvarious conditions, including intact as well as rock with different types and\nlocations of cracks. The PCA classification was first demonstrated simulating\nsounds of different characteristics that were automatically trained and tested.\nSecondly, a laboratory test was conducted tapping rock specimens with three\ndifferent levels of discontinuity in depth and shape. A real microphone mounted\non the robot recorded the sound and the data were classified in three clusters\nwithin 2D space. A model was created using the training data to classify the\nreminder of the data (the test data). The performance of the method is\nevaluated with a confusion matrix.",
    "descriptor": "",
    "authors": [
      "Roya Nasimi",
      "Fernando Moreu",
      "John Stormont"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.04923"
  },
  {
    "id": "arXiv:2110.04931",
    "title": "BEV-Net: Assessing Social Distancing Compliance by Joint People  Localization and Geometric Reasoning",
    "abstract": "Social distancing, an essential public health measure to limit the spread of\ncontagious diseases, has gained significant attention since the outbreak of the\nCOVID-19 pandemic. In this work, the problem of visual social distancing\ncompliance assessment in busy public areas, with wide field-of-view cameras, is\nconsidered. A dataset of crowd scenes with people annotations under a bird's\neye view (BEV) and ground truth for metric distances is introduced, and several\nmeasures for the evaluation of social distance detection systems are proposed.\nA multi-branch network, BEV-Net, is proposed to localize individuals in world\ncoordinates and identify high-risk regions where social distancing is violated.\nBEV-Net combines detection of head and feet locations, camera pose estimation,\na differentiable homography module to map image into BEV coordinates, and\ngeometric reasoning to produce a BEV map of the people locations in the scene.\nExperiments on complex crowded scenes demonstrate the power of the approach and\nshow superior performance over baselines derived from methods in the\nliterature. Applications of interest for public health decision makers are\nfinally discussed. Datasets, code and pretrained models are publicly available\nat GitHub.",
    "descriptor": "\nComments: Published as a conference paper at International Conference on Computer Vision, 2021\n",
    "authors": [
      "Zhirui Dai",
      "Yuepeng Jiang",
      "Yi Li",
      "Bo Liu",
      "Antoni B. Chan",
      "Nuno Vasconcelos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04931"
  },
  {
    "id": "arXiv:2110.04932",
    "title": "An Analysis of COVID-19 Knowledge Graph Construction and Applications",
    "abstract": "The construction and application of knowledge graphs have seen a rapid\nincrease across many disciplines in recent years. Additionally, the problem of\nuncovering relationships between developments in the COVID-19 pandemic and\nsocial media behavior is of great interest to researchers hoping to curb the\nspread of the disease. In this paper we present a knowledge graph constructed\nfrom COVID-19 related tweets in the Los Angeles area, supplemented with federal\nand state policy announcements and disease spread statistics. By incorporating\ndates, topics, and events as entities, we construct a knowledge graph that\ndescribes the connections between these useful information. We use natural\nlanguage processing and change point analysis to extract tweet-topic,\ntweet-date, and event-date relations. Further analysis on the constructed\nknowledge graph provides insight into how tweets reflect public sentiments\ntowards COVID-19 related topics and how changes in these sentiments correlate\nwith real-world events.",
    "descriptor": "",
    "authors": [
      "Dominic Flocco",
      "Bryce Palmer-Toy",
      "Ruixiao Wang",
      "Hongyu Zhu",
      "Rishi Sonthalia",
      "Junyuan Lin",
      "Andrea L. Bertozzi",
      "P. Jeffrey Brantingham"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04932"
  },
  {
    "id": "arXiv:2110.04933",
    "title": "A Faster Algorithm for Maximum Independent Set on Interval Filament  Graphs",
    "abstract": "We provide an algorithm requiring only $O(N^2)$ time to compute the maximum\nweight independent set of interval filament graphs. This also implies an\n$O(N^4)$ algorithm to compute the maximum weight induced matching of interval\nfilament graphs. Both algorithms significantly improve upon the previous best\ncomplexities for these problems. Previously, the maximum weight independent set\nand maximum weight induced matching problems required $O(N^3)$ and $O(N^6)$\ntime respectively.",
    "descriptor": "",
    "authors": [
      "Darcy Best",
      "Max Ward"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.04933"
  },
  {
    "id": "arXiv:2110.04934",
    "title": "Wav2vec-Switch: Contrastive Learning from Original-noisy Speech Pairs  for Robust Speech Recognition",
    "abstract": "The goal of self-supervised learning (SSL) for automatic speech recognition\n(ASR) is to learn good speech representations from a large amount of unlabeled\nspeech for the downstream ASR task. However, most SSL frameworks do not\nconsider noise robustness which is crucial for real-world applications. In this\npaper we propose wav2vec-Switch, a method to encode noise robustness into\ncontextualized representations of speech via contrastive learning.\nSpecifically, we feed original-noisy speech pairs simultaneously into the\nwav2vec 2.0 network. In addition to the existing contrastive learning task, we\nswitch the quantized representations of the original and noisy speech as\nadditional prediction targets of each other. By doing this, it enforces the\nnetwork to have consistent predictions for the original and noisy speech, thus\nallows to learn contextualized representation with noise robustness. Our\nexperiments on synthesized and real noisy data show the effectiveness of our\nmethod: it achieves 2.9--4.9% relative word error rate (WER) reduction on the\nsynthesized noisy LibriSpeech data without deterioration on the original data,\nand 5.7% on CHiME-4 real 1-channel noisy data compared to a data augmentation\nbaseline even with a strong language model for decoding. Our results on CHiME-4\ncan match or even surpass those with well-designed speech enhancement\ncomponents.",
    "descriptor": "\nComments: 5 pages, 1 figure, submitted to ICASSP 2022\n",
    "authors": [
      "Yiming Wang",
      "Jinyu Li",
      "Heming Wang",
      "Yao Qian",
      "Chengyi Wang",
      "Yu Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.04934"
  },
  {
    "id": "arXiv:2110.04935",
    "title": "Learning Temporally-Consistent Representations for Data-Efficient  Reinforcement Learning",
    "abstract": "Deep reinforcement learning (RL) agents that exist in high-dimensional state\nspaces, such as those composed of images, have interconnected learning burdens.\nAgents must learn an action-selection policy that completes their given task,\nwhich requires them to learn a representation of the state space that discerns\nbetween useful and useless information. The reward function is the only\nsupervised feedback that RL agents receive, which causes a representation\nlearning bottleneck that can manifest in poor sample efficiency. We present\n$k$-Step Latent (KSL), a new representation learning method that enforces\ntemporal consistency of representations via a self-supervised auxiliary task\nwherein agents learn to recurrently predict action-conditioned representations\nof the state space. The state encoder learned by KSL produces low-dimensional\nrepresentations that make optimization of the RL task more sample efficient.\nAltogether, KSL produces state-of-the-art results in both data efficiency and\nasymptotic performance in the popular PlaNet benchmark suite. Our analyses show\nthat KSL produces encoders that generalize better to new tasks unseen during\ntraining, and its representations are more strongly tied to reward, are more\ninvariant to perturbations in the state space, and move more smoothly through\nthe temporal axis of the RL problem than other methods such as DrQ, RAD, CURL,\nand SAC-AE.",
    "descriptor": "",
    "authors": [
      "Trevor McInroe",
      "Lukas Sch\u00e4fer",
      "Stefano V. Albrecht"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04935"
  },
  {
    "id": "arXiv:2110.04942",
    "title": "Application of Neural Network in Optimization of Chemical Process",
    "abstract": "Artificial neural network (ANN) has been widely used due to its strong\nnonlinear mapping ability, fault tolerance and self-learning ability. This\narticle summarizes the development history of artificial neural networks,\nintroduces three common neural network types, BP neural network, RBF neural\nnetwork and convolutional neural network, and focuses on the practical\napplication in chemical process optimization, especially the results achieved\nin multi-objective control optimization and process parameter improvement.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Fei Liang",
      "Taowen Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.04942"
  },
  {
    "id": "arXiv:2110.04943",
    "title": "SCEHR: Supervised Contrastive Learning for Clinical Risk Prediction  using Electronic Health Records",
    "abstract": "Contrastive learning has demonstrated promising performance in image and text\ndomains either in a self-supervised or a supervised manner. In this work, we\nextend the supervised contrastive learning framework to clinical risk\nprediction problems based on longitudinal electronic health records (EHR). We\npropose a general supervised contrastive loss $\\mathcal{L}_{\\text{Contrastive\nCross Entropy} } + \\lambda \\mathcal{L}_{\\text{Supervised Contrastive\nRegularizer}}$ for learning both binary classification (e.g. in-hospital\nmortality prediction) and multi-label classification (e.g. phenotyping) in a\nunified framework. Our supervised contrastive loss practices the key idea of\ncontrastive learning, namely, pulling similar samples closer and pushing\ndissimilar ones apart from each other, simultaneously by its two components:\n$\\mathcal{L}_{\\text{Contrastive Cross Entropy} }$ tries to contrast samples\nwith learned anchors which represent positive and negative clusters, and\n$\\mathcal{L}_{\\text{Supervised Contrastive Regularizer}}$ tries to contrast\nsamples with each other according to their supervised labels. We propose two\nversions of the above supervised contrastive loss and our experiments on\nreal-world EHR data demonstrate that our proposed loss functions show benefits\nin improving the performance of strong baselines and even state-of-the-art\nmodels on benchmarking tasks for clinical risk predictions. Our loss functions\nwork well with extremely imbalanced data which are common for clinical risk\nprediction problems. Our loss functions can be easily used to replace (binary\nor multi-label) cross-entropy loss adopted in existing clinical predictive\nmodels. The Pytorch code is released at\n\\url{https://github.com/calvin-zcx/SCEHR}.",
    "descriptor": "",
    "authors": [
      "Chengxi Zang",
      "Fei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04943"
  },
  {
    "id": "arXiv:2110.04945",
    "title": "NFT-K: Non-Fungible Tangent Kernels",
    "abstract": "Deep neural networks have become essential for numerous applications due to\ntheir strong empirical performance such as vision, RL, and classification.\nUnfortunately, these networks are quite difficult to interpret, and this limits\ntheir applicability in settings where interpretability is important for safety,\nsuch as medical imaging. One type of deep neural network is neural tangent\nkernel that is similar to a kernel machine that provides some aspect of\ninterpretability. To further contribute interpretability with respect to\nclassification and the layers, we develop a new network as a combination of\nmultiple neural tangent kernels, one to model each layer of the deep neural\nnetwork individually as opposed to past work which attempts to represent the\nentire network via a single neural tangent kernel. We demonstrate the\ninterpretability of this model on two datasets, showing that the multiple\nkernels model elucidates the interplay between the layers and predictions.",
    "descriptor": "",
    "authors": [
      "Sina Alemohammad",
      "Hossein Babaei",
      "CJ Barberan",
      "Naiming Liu",
      "Lorenzo Luzi",
      "Blake Mason",
      "Richard G. Baraniuk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04945"
  },
  {
    "id": "arXiv:2110.04946",
    "title": "LaughNet: synthesizing laughter utterances from waveform silhouettes and  a single laughter example",
    "abstract": "Emotional and controllable speech synthesis is a topic that has received much\nattention. However, most studies focused on improving the expressiveness and\ncontrollability in the context of linguistic content, even though natural\nverbal human communication is inseparable from spontaneous non-speech\nexpressions such as laughter, crying, or grunting. We propose a model called\nLaughNet for synthesizing laughter by using waveform silhouettes as inputs. The\nmotivation is not simply synthesizing new laughter utterances but testing a\nnovel synthesis-control paradigm that uses an abstract representation of the\nwaveform. We conducted basic listening test experiments, and the results showed\nthat LaughNet can synthesize laughter utterances with moderate quality and\nretain the characteristics of the training example. More importantly, the\ngenerated waveforms have shapes similar to the input silhouettes. For future\nwork, we will test the same method on other types of human nonverbal\nexpressions and integrate it into more elaborated synthesis systems.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Hieu-Thi Luong",
      "Junichi Yamagishi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.04946"
  },
  {
    "id": "arXiv:2110.04947",
    "title": "Towards Demystifying Representation Learning with Non-contrastive  Self-supervision",
    "abstract": "Non-contrastive methods of self-supervised learning (such as BYOL and\nSimSiam) learn representations by minimizing the distance between two views of\nthe same image. These approaches have achieved remarkable performance in\npractice, but it is not well understood 1) why these methods do not collapse to\nthe trivial solutions and 2) how the representation is learned. Tian el al.\n(2021) made an initial attempt on the first question and proposed DirectPred\nthat sets the predictor directly. In our work, we analyze a generalized version\nof DirectPred, called DirectSet($\\alpha$). We show that in a simple linear\nnetwork, DirectSet($\\alpha$) provably learns a desirable projection matrix and\nalso reduces the sample complexity on downstream tasks. Our analysis suggests\nthat weight decay acts as an implicit threshold that discard the features with\nhigh variance under augmentation, and keep the features with low variance.\nInspired by our theory, we simplify DirectPred by removing the expensive\neigen-decomposition step. On CIFAR-10, CIFAR-100, STL-10 and ImageNet,\nDirectCopy, our simpler and more computationally efficient algorithm, rivals or\neven outperforms DirectPred.",
    "descriptor": "",
    "authors": [
      "Xiang Wang",
      "Xinlei Chen",
      "Simon S. Du",
      "Yuandong Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04947"
  },
  {
    "id": "arXiv:2110.04951",
    "title": "Bug Prediction Using Source Code Embedding Based on Doc2Vec",
    "abstract": "Bug prediction is a resource demanding task that is hard to automate using\nstatic source code analysis. In many fields of computer science, machine\nlearning has proven to be extremely useful in tasks like this, however, for it\nto work we need a way to use source code as input. We propose a simple, but\nmeaningful representation for source code based on its abstract syntax tree and\nthe Doc2Vec embedding algorithm. This representation maps the source code to a\nfixed length vector which can be used for various upstream tasks -- one of\nwhich is bug prediction. We measured this approach's validity by itself and its\neffectiveness compared to bug prediction based solely on code metrics. We also\nexperimented on numerous machine learning approaches to check the connection\nbetween different embedding parameters with different machine learning models.\nOur results show that this representation provides meaningful information as it\nimproves the bug prediction accuracy in most cases, and is always at least as\ngood as only using code metrics as features.",
    "descriptor": "",
    "authors": [
      "Tam\u00e1s Aladics",
      "Judit J\u00e1sz",
      "Rudolf Ferenc"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.04951"
  },
  {
    "id": "arXiv:2110.04953",
    "title": "Compact CNN Models for On-device Ocular-based User Recognition in Mobile  Devices",
    "abstract": "A number of studies have demonstrated the efficacy of deep learning\nconvolutional neural network (CNN) models for ocular-based user recognition in\nmobile devices. However, these high-performing networks have enormous space and\ncomputational complexity due to the millions of parameters and computations\ninvolved. These requirements make the deployment of deep learning models to\nresource-constrained mobile devices challenging. To this end, only a handful of\nstudies based on knowledge distillation and patch-based models have been\nproposed to obtain compact size CNN models for ocular recognition in the mobile\nenvironment. In order to further advance the state-of-the-art, this study for\nthe first time evaluates five neural network pruning methods and compares them\nwith the knowledge distillation method for on-device CNN inference and mobile\nuser verification using ocular images. Subject-independent analysis on VISOB\nand UPFR-Periocular datasets suggest the efficacy of layerwise magnitude-based\npruning at a compression rate of 8 for mobile ocular-based authentication using\nResNet50 as the base model. Further, comparison with the knowledge distillation\nsuggests the efficacy of knowledge distillation over pruning methods in terms\nof verification accuracy and the real-time inference measured as deep feature\nextraction time on five mobile devices, namely, iPhone 6, iPhone X, iPhone XR,\niPad Air 2 and iPad 7th Generation.",
    "descriptor": "\nComments: 8 pages. arXiv admin note: text overlap with arXiv:2003.03033 by other authors\n",
    "authors": [
      "Ali Almadan",
      "Ajita Rattani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04953"
  },
  {
    "id": "arXiv:2110.04954",
    "title": "Recurrent Attention Models with Object-centric Capsule Representation  for Multi-object Recognition",
    "abstract": "The visual system processes a scene using a sequence of selective glimpses,\neach driven by spatial and object-based attention. These glimpses reflect what\nis relevant to the ongoing task and are selected through recurrent processing\nand recognition of the objects in the scene. In contrast, most models treat\nattention selection and recognition as separate stages in a feedforward\nprocess. Here we show that using capsule networks to create an object-centric\nhidden representation in an encoder-decoder model with iterative glimpse\nattention yields effective integration of attention and recognition. We\nevaluate our model on three multi-object recognition tasks; highly overlapping\ndigits, digits among distracting clutter and house numbers, and show that it\nlearns to effectively move its glimpse window, recognize and reconstruct the\nobjects, all with only the classification as supervision. Our work takes a step\ntoward a general architecture for how to integrate recurrent object-centric\nrepresentation into the planning of attentional glimpses.",
    "descriptor": "",
    "authors": [
      "Hossein Adeli",
      "Seoyoung Ahn",
      "Gregory Zelinsky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2110.04954"
  },
  {
    "id": "arXiv:2110.04955",
    "title": "BuildingNet: Learning to Label 3D Buildings",
    "abstract": "We introduce BuildingNet: (a) a large-scale dataset of 3D building models\nwhose exteriors are consistently labeled, (b) a graph neural network that\nlabels building meshes by analyzing spatial and structural relations of their\ngeometric primitives. To create our dataset, we used crowdsourcing combined\nwith expert guidance, resulting in 513K annotated mesh primitives, grouped into\n292K semantic part components across 2K building models. The dataset covers\nseveral building categories, such as houses, churches, skyscrapers, town halls,\nlibraries, and castles. We include a benchmark for evaluating mesh and point\ncloud labeling. Buildings have more challenging structural complexity compared\nto objects in existing benchmarks (e.g., ShapeNet, PartNet), thus, we hope that\nour dataset can nurture the development of algorithms that are able to cope\nwith such large-scale geometric data for both vision and graphics tasks e.g.,\n3D semantic segmentation, part-based generative models, correspondences,\ntexturing, and analysis of point cloud data acquired from real-world buildings.\nFinally, we show that our mesh-based graph neural network significantly\nimproves performance over several baselines for labeling 3D meshes.",
    "descriptor": "\nComments: Accepted to ICCV 2021 (oral)\n",
    "authors": [
      "Pratheba Selvaraju",
      "Mohamed Nabail",
      "Marios Loizou",
      "Maria Maslioukova",
      "Melinos Averkiou",
      "Andreas Andreou",
      "Siddhartha Chaudhuri",
      "Evangelos Kalogerakis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.04955"
  },
  {
    "id": "arXiv:2110.04956",
    "title": "Optimal Stochastic Evasive Maneuvers Using the Schrodinger's Equation",
    "abstract": "In this paper, preys with stochastic evasion policies are considered. The\nstochasticity adds unpredictable changes to the prey's path for avoiding\npredator's attacks. The prey's cost function is composed of two terms balancing\nthe unpredictability factor (by using stochasticity to make the task of\nforecasting its future positions by the predator difficult) and energy\nconsumption (the least amount of energy required for performing a maneuver).\nThe optimal probability density functions of the actions of the prey for\ntrading-off unpredictability and energy consumption is shown to be\ncharacterized by the stationary Schrodinger's equation.",
    "descriptor": "",
    "authors": [
      "Farhad Farokhi",
      "Magnus Egerstedt"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.04956"
  },
  {
    "id": "arXiv:2110.04957",
    "title": "Provably Stable Full-Spectrum Dispersion Relation Preserving Schemes",
    "abstract": "The dispersion error is often the dominant error for computed solutions of\nwave propagation problems with high-frequency components. In this paper, we\ndefine and give explicit examples of $\\alpha$-dispersion-relation-preserving\nschemes. These are dual-pair finite-difference schemes for systems of\nhyperbolic partial differential equations which preserve the\ndispersion-relation of the continuous problem uniformly to an $\\alpha \\%$-error\ntolerance. We give a general framework to design provably stable finite\ndifference operators that preserve the dispersion relation for hyperbolic\nsystems such as the elastic wave equation. The operators we derive here can\nresolve the highest frequency ($\\pi$-mode) present on any equidistant grid at a\ntolerance of $5\\%$ error. This significantly improves on the current standard\nthat have a tolerance of $100 \\%$ error.",
    "descriptor": "",
    "authors": [
      "Christopher Williams",
      "Kenneth Duru"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.04957"
  },
  {
    "id": "arXiv:2110.04959",
    "title": "Heterogeneous Stream-reservoir Graph Networks with Data Assimilation",
    "abstract": "Accurate prediction of water temperature in streams is critical for\nmonitoring and understanding biogeochemical and ecological processes in\nstreams. Stream temperature is affected by weather patterns (such as solar\nradiation) and water flowing through the stream network. Additionally, stream\ntemperature can be substantially affected by water releases from man-made\nreservoirs to downstream segments. In this paper, we propose a heterogeneous\nrecurrent graph model to represent these interacting processes that underlie\nstream-reservoir networks and improve the prediction of water temperature in\nall river segments within a network. Because reservoir release data may be\nunavailable for certain reservoirs, we further develop a data assimilation\nmechanism to adjust the deep learning model states to correct for the\nprediction bias caused by reservoir releases. A well-trained temporal modeling\ncomponent is needed in order to use adjusted states to improve future\npredictions. Hence, we also introduce a simulation-based pre-training strategy\nto enhance the model training. Our evaluation for the Delaware River Basin has\ndemonstrated the superiority of our proposed method over multiple existing\nmethods. We have extensively studied the effect of the data assimilation\nmechanism under different scenarios. Moreover, we show that the proposed method\nusing the pre-training strategy can still produce good predictions even with\nlimited training data.",
    "descriptor": "",
    "authors": [
      "Shengyu Chen",
      "Alison Appling",
      "Samantha Oliver",
      "Hayley Corson-Dosch",
      "Jordan Read",
      "Jeffrey Sadler",
      "Jacob Zwart",
      "Xiaowei Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04959"
  },
  {
    "id": "arXiv:2110.04960",
    "title": "Performance Evaluation of Deep Transfer Learning on Multiclass  Identification of Common Weed Species in Cotton Production Systems",
    "abstract": "Precision weed management offers a promising solution for sustainable\ncropping systems through the use of chemical-reduced/non-chemical robotic\nweeding techniques, which apply suitable control tactics to individual weeds.\nTherefore, accurate identification of weed species plays a crucial role in such\nsystems to enable precise, individualized weed treatment. This paper makes a\nfirst comprehensive evaluation of deep transfer learning (DTL) for identifying\ncommon weeds specific to cotton production systems in southern United States. A\nnew dataset for weed identification was created, consisting of 5187 color\nimages of 15 weed classes collected under natural lighting conditions and at\nvaried weed growth stages, in cotton fields during the 2020 and 2021 field\nseasons. We evaluated 27 state-of-the-art deep learning models through transfer\nlearning and established an extensive benchmark for the considered weed\nidentification task. DTL achieved high classification accuracy of F1 scores\nexceeding 95%, requiring reasonably short training time (less than 2.5 hours)\nacross models. ResNet101 achieved the best F1-score of 99.1% whereas 14 out of\nthe 27 models achieved F1 scores exceeding 98.0%. However, the performance on\nminority weed classes with few training samples was less satisfactory for\nmodels trained with a conventional, unweighted cross entropy loss function. To\naddress this issue, a weighted cross entropy loss function was adopted, which\nachieved substantially improved accuracies for minority weed classes.\nFurthermore, a deep learning-based cosine similarity metrics was employed to\nanalyze the similarity among weed classes, assisting in the interpretation of\nclassifications. Both the codes for model benchmarking and the weed dataset are\nmade publicly available, which expect to be be a valuable resource for future\nresearch in weed identification and beyond.",
    "descriptor": "\nComments: 15 pages, 8 figures, 3 tables\n",
    "authors": [
      "Dong Chen",
      "Yuzhen Lu",
      "Zhaojiang Li",
      "Sierra Young"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04960"
  },
  {
    "id": "arXiv:2110.04961",
    "title": "Equivalence Analysis between Counterfactual Regret Minimization and  Online Mirror Descent",
    "abstract": "Counterfactual Regret Minimization (CFR) is a kind of regret minimization\nalgorithm that minimizes the total regret by minimizing the local\ncounterfactual regrets. CFRs have a fast convergence rate in practice and they\nhave been widely used for solving large-scale imperfect-information\nExtensive-form games (EFGs). However, due to their locality, CFRs are difficult\nto analyze and extend. Follow-the-Regularized-Lead (FTRL) and Online Mirror\nDescent (OMD) algorithms are regret minimization algorithms in Online Convex\nOptimization. They are mathematically elegant but less practical in solving\nEFGs. In this paper, we provide a new way to analyze and extend CFRs, by\nproving that CFR with Regret Matching and CFR with Regret Matching+ are special\nforms of FTRL and OMD, respectively. With these equivalences, two new\nalgorithms, which can be considered as the extensions of vanilla CFR and CFR+,\nare deduced from the perspective of FTRL and OMD. In these two variants,\nmaintaining the local counterfactual regrets is not necessary anymore. The\nexperiments show that the two variants converge faster than vanilla CFR and\nCFR+ in some EFGs.",
    "descriptor": "",
    "authors": [
      "Weiming Liu",
      "Huacong Jiang",
      "Bin Li",
      "Houqiang Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04961"
  },
  {
    "id": "arXiv:2110.04962",
    "title": "Uplink Performance of Cell-Free Massive MIMO with Multi-Antenna Users  Over Jointly-Correlated Rayleigh Fading Channels",
    "abstract": "In this paper, we investigate a cell-free massive MIMO system with both\naccess points (APs) and user equipments (UEs) equipped with multiple antennas\nover jointly correlated Rayleigh fading channels. We study four uplink\nimplementations, from fully centralized processing to fully distributed\nprocessing, and derive achievable spectral efficiency (SE) expressions with\nminimum mean-squared error successive interference cancellation (MMSE-SIC)\ndetectors and arbitrary combining schemes. Furthermore, the global and local\nMMSE combining schemes are derived based on full and local channel state\ninformation (CSI) obtained under pilot contamination, which can maximize the\nachievable SE for the fully centralized and distributed implementation,\nrespectively. We study a two-layer decoding implementation with an arbitrary\ncombining scheme in the first layer and optimal large-scale fading decoding in\nthe second layer. Besides, we compute novel closed-form SE expressions for the\ntwo-layer decoding implementation with maximum ratio combining. We compare the\nSE of different implementation levels and combining schemes and investigate the\neffect of having additional UE antennas. Note that increasing the number of\nantennas per UE may degrade the SE performance and the optimal number of UE\nantennas maximizing the SE is related to the implementation levels, the length\nof the resource block, and the number of UEs.",
    "descriptor": "\nComments: 30 pages, 9 figures\n",
    "authors": [
      "Zhe Wang",
      "Jiayi Zhang",
      "Bo Ai",
      "Chau Yuen",
      "M\u00e9rouane Debbah"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.04962"
  },
  {
    "id": "arXiv:2110.04964",
    "title": "Label-Occurrence-Balanced Mixup for Long-tailed Recognition",
    "abstract": "Mixup is a popular data augmentation method, with many variants subsequently\nproposed. These methods mainly create new examples via convex combination of\nrandom data pairs and their corresponding one-hot labels. However, most of them\nadhere to a random sampling and mixing strategy, without considering the\nfrequency of label occurrence in the mixing process. When applying mixup to\nlong-tailed data, a label suppression issue arises, where the frequency of\nlabel occurrence for each class is imbalanced and most of the new examples will\nbe completely or partially assigned with head labels. The suppression effect\nmay further aggravate the problem of data imbalance and lead to a poor\nperformance on tail classes. To address this problem, we propose\nLabel-Occurrence-Balanced Mixup to augment data while keeping the label\noccurrence for each class statistically balanced. In a word, we employ two\nindependent class-balanced samplers to select data pairs and mix them to\ngenerate new data. We test our method on several long-tailed vision and sound\nrecognition benchmarks. Experimental results show that our method significantly\npromotes the adaptability of mixup method to imbalanced data and achieves\nsuperior performance compared with state-of-the-art long-tailed learning\nmethods.",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Shaoyu Zhang",
      "Chen Chen",
      "Xiujuan Zhang",
      "Silong Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04964"
  },
  {
    "id": "arXiv:2110.04966",
    "title": "Revisit Dictionary Learning for Video Compressive Sensing under the  Plug-and-Play Framework",
    "abstract": "Aiming at high-dimensional (HD) data acquisition and analysis, snapshot\ncompressive imaging (SCI) obtains the 2D compressed measurement of HD data with\noptical imaging systems and reconstructs HD data using compressive sensing\nalgorithms. While the Plug-and-Play (PnP) framework offers an emerging solution\nto SCI reconstruction, its intrinsic denoising process is still a challenging\nproblem. Unfortunately, existing denoisers in the PnP framework either suffer\nlimited performance or require extensive training data. In this paper, we\npropose an efficient and effective shallow-learning-based algorithm for video\nSCI reconstruction. Revisiting dictionary learning methods, we empower the PnP\nframework with a new denoiser, the kernel singular value decomposition (KSVD).\nBenefited from the advent of KSVD, our algorithm retains a good trade-off among\nquality, speed, and training difficulty. On a variety of datasets, both\nquantitative and qualitative evaluations of our simulation results demonstrate\nthe effectiveness of our proposed method. In comparison to a typical baseline\nusing total variation, our method achieves around $2$ dB improvement in PSNR\nand 0.2 in SSIM. We expect that our proposed PnP-KSVD algorithm can serve as a\nnew baseline for video SCI reconstruction.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Qing Yang",
      "Yaping Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.04966"
  },
  {
    "id": "arXiv:2110.04967",
    "title": "Koopman Operator Based Modeling and Control of Rigid Body Motion  Represented by Dual Quaternions",
    "abstract": "In this paper, we systematically derive a finite set of Koopman based\nobservables to construct a lifted linear state space model that describes the\nrigid body dynamics based on the dual quaternion representation. In general,\nthe Koopman operator is a linear infinite dimensional operator, which means\nthat the derived linear state space model of the rigid body dynamics will be\ninfinite-dimensional, which is not suitable for modeling and control design\npurposes. Recently, finite approximations of the operator computed by means of\nmethods like the Extended Dynamic Mode Decomposition (EDMD) have shown\npromising results for different classes of problems. However, without using an\nappropriate set of observables in the EDMD approach, there can be no guarantees\nthat the computed approximation of the nonlinear dynamics is sufficiently\naccurate. The major challenge in using the Koopman operator for constructing a\nlinear state space model is the choice of observables. State-of-the-art methods\nin the field compute the approximations of the observables by using neural\nnetworks, standard radial basis functions (RBFs), polynomials or heuristic\napproximations of these functions. However, these observables might not\nprovidea sufficiently accurate approximation or representation of the dynamics.\nIn contrast, we first show the pointwise convergence of the derived observable\nfunctions to zero, thereby allowing us to choose a finite set of these\nobservables. Next, we use the derived observables in EDMD to compute the lifted\nlinear state and input matrices for the rigid body dynamics. Finally, we show\nthat an LQR type (linear) controller, which is designed based on the truncated\nlinear state space model, can steer the rigid body to a desired state while its\nperformance is commensurate with that of a nonlinear controller. The efficacy\nof our approach is demonstrated through numerical simulations.",
    "descriptor": "",
    "authors": [
      "Vrushabh Zinage",
      "Efstathios Bakolas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.04967"
  },
  {
    "id": "arXiv:2110.04968",
    "title": "Deep Learning for Uplink Spectral Efficiency in Cell-Free Massive MIMO  Systems",
    "abstract": "In this paper, we introduce a Deep Neural Network (DNN) to maximize the\nProportional Fairness (PF) of the Spectral Efficiency (SE) of uplinks in\nCell-Free (CF) massive Multiple-Input Multiple-Output (MIMO) systems. The\nproblem of maximizing the PF of the SE is a non-convex optimization problem in\nthe design variables. We will develop a DNN which takes pilot sequences and\nlarge-scale fading coefficients of the users as inputs and produces the outputs\nof optimal transmit powers. By consisting of densely residual connections\nbetween layers, the proposed DNN can efficiently exploit the hierarchical\nfeatures of the input and motivates the feed-forward nature of DNN\narchitecture. Experimental results showed that, compared to the conventional\niterative optimization algorithm, the proposed DNN has excessively lower\ncomputational complexity with the trade-off of approximately only 1% loss in\nthe sum rate and the fairness performance. This demonstrated that our proposed\nDNN is reasonably suitable for real-time signal processing in CF massive MIMO\nsystems.",
    "descriptor": "",
    "authors": [
      "Le Ty Khanh",
      "Pham Quoc Viet",
      "Ha Hoang Kha",
      "Nguyen Minh Hoang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.04968"
  },
  {
    "id": "arXiv:2110.04971",
    "title": "A Deep Generative Model for Matrix Reordering",
    "abstract": "Depending on the node ordering, an adjacency matrix can highlight distinct\ncharacteristics of a graph. Deriving a \"proper\" node ordering is thus a\ncritical step in visualizing a graph as an adjacency matrix. Users often try\nmultiple matrix reorderings using different methods until they find one that\nmeets the analysis goal. However, this trial-and-error approach is laborious\nand disorganized, which is especially challenging for novices. This paper\npresents a technique that enables users to effortlessly find a matrix\nreordering they want. Specifically, we design a generative model that learns a\nlatent space of diverse matrix reorderings of the given graph. We also\nconstruct an intuitive user interface from the learned latent space by creating\na map of various matrix reorderings. We demonstrate our approach through\nquantitative and qualitative evaluations of the generated reorderings and\nlearned latent spaces. The results show that our model is capable of learning a\nlatent space of diverse matrix reorderings. Most existing research in this area\ngenerally focused on developing algorithms that can compute \"better\" matrix\nreorderings for particular circumstances. This paper introduces a fundamentally\nnew approach to matrix visualization of a graph, where a machine learning model\nlearns to generate diverse matrix reorderings of a graph.",
    "descriptor": "",
    "authors": [
      "Oh-Hyun Kwon",
      "Chiun-How Kao",
      "Chun-houh Chen",
      "Kwan-Liu Ma"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.04971"
  },
  {
    "id": "arXiv:2110.04972",
    "title": "Kernel Learning For Sound Field Estimation With L1 and L2  Regularizations",
    "abstract": "A method to estimate an acoustic field from discrete microphone measurements\nis proposed. A kernel-interpolation-based method using the kernel function\nformulated for sound field interpolation has been used in various applications.\nThe kernel function with directional weighting makes it possible to incorporate\nprior information on source directions to improve estimation accuracy. However,\nin prior studies, parameters for directional weighting have been empirically\ndetermined. We propose a method to optimize these parameters using observation\nvalues, which is particularly useful when prior information on source\ndirections is uncertain. The proposed algorithm is based on discretization of\nthe parameters and representation of the kernel function as a weighted sum of\nsub-kernels. Two types of regularization for the weights, $L_1$ and $L_2$, are\ninvestigated. Experimental results indicate that the proposed method achieves\nhigher estimation accuracy than the method without kernel learning.",
    "descriptor": "\nComments: Accepted to IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA) 2021\n",
    "authors": [
      "Ryosuke Horiuchi",
      "Shoichi Koyama",
      "Juliano G. C. Ribeiro",
      "Natsuki Ueno",
      "Hiroshi Saruwatari"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.04972"
  },
  {
    "id": "arXiv:2110.04974",
    "title": "Value-Function-based Sequential Minimization for Bi-level Optimization",
    "abstract": "Gradient-based Bi-Level Optimization (BLO) methods have been widely applied\nto solve modern machine learning problems. However, most existing solution\nstrategies are theoretically designed based on restrictive assumptions (e.g.,\nconvexity of the lower-level sub-problem), and computationally not applicable\nfor high-dimensional tasks. Moreover, there are almost no gradient-based\nmethods that can efficiently handle BLO in those challenging scenarios, such as\nBLO with functional constraints and pessimistic BLO. In this work, by\nreformulating BLO into an approximated single-level problem based on the\nvalue-function, we provide a new method, named Bi-level Value-Function-based\nSequential Minimization (BVFSM), to partially address the above issues. To be\nspecific, BVFSM constructs a series of value-function-based approximations, and\nthus successfully avoids the repeated calculations of recurrent gradient and\nHessian inverse required by existing approaches, which are time-consuming\n(especially for high-dimensional tasks). We also extend BVFSM to address BLO\nwith additional upper- and lower-level functional constraints. More\nimportantly, we demonstrate that the algorithmic framework of BVFSM can also be\nused for the challenging pessimistic BLO, which has never been properly solved\nby existing gradient-based methods. On the theoretical side, we strictly prove\nthe convergence of BVFSM on these types of BLO, in which the restrictive\nlower-level convexity assumption is completely discarded. To our best\nknowledge, this is the first gradient-based algorithm that can solve different\nkinds of BLO problems (e.g., optimistic, pessimistic and with constraints) all\nwith solid convergence guarantees. Extensive experiments verify our theoretical\ninvestigations and demonstrate the superiority of BVFSM on various real-world\napplications.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Risheng Liu",
      "Xuan Liu",
      "Shangzhi Zeng",
      "Jin Zhang",
      "Yixuan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.04974"
  },
  {
    "id": "arXiv:2110.04977",
    "title": "A Review on Part-of-Speech Technologies",
    "abstract": "Developing an automatic part-of-speech (POS) tagging for any new language is\nconsidered a necessary step for further computational linguistics methodology\nbeyond tagging, like chunking and parsing, to be fully applied to the language.\nMany POS disambiguation technologies have been developed for this type of\nresearch and there are factors that influence the choice of choosing one. This\ncould be either corpus-based or non-corpus-based. In this paper, we present a\nreview of POS tagging technologies.",
    "descriptor": "\nComments: 8 pages, 3 images\n",
    "authors": [
      "Onyenwe Ikechukwu",
      "Onyedikachukwu Ikechukwu-Onyenwe",
      "Onyedinma Ebele"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04977"
  },
  {
    "id": "arXiv:2110.04983",
    "title": "Understanding the Safety Requirements for Learning-based Power Systems  Operations",
    "abstract": "Recent advancements in machine learning and reinforcement learning have\nbrought increased attention to their applicability in a range of\ndecision-making tasks in the operations of power systems, such as short-term\nemergency control, Volt/VAr control, long-term residential demand response and\nbattery energy management. Despite the promises of providing strong\nrepresentation of complex system dynamics and fast, efficient learned operation\nstrategies, the safety requirements of such learning paradigms are less\ndiscussed. This paper explores the design requirements on both data and model\nside of such learning algorithms by exploiting the impacts of adversarial\nattacks on safety critical system operations. Case studies performed on both\nvoltage regulation and topology control tasks demonstrated the potential\nvulnerabilities of the standard reinforcement learning algorithms, and possible\nmeasures of machine learning robustness and security are discussed for power\nsystems operation tasks.",
    "descriptor": "\nComments: In submission\n",
    "authors": [
      "Yize Chen",
      "Daniel Arnold",
      "Yuanyuan Shi",
      "Sean Peisert"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.04983"
  },
  {
    "id": "arXiv:2110.04984",
    "title": "Advances in Multi-turn Dialogue Comprehension: A Survey",
    "abstract": "Training machines to understand natural language and interact with humans is\nan elusive and essential task of artificial intelligence. A diversity of\ndialogue systems has been designed with the rapid development of deep learning\ntechniques, especially the recent pre-trained language models (PrLMs). Among\nthese studies, the fundamental yet challenging type of task is dialogue\ncomprehension whose role is to teach the machines to read and comprehend the\ndialogue context before responding. In this paper, we review the previous\nmethods from the technical perspective of dialogue modeling for the dialogue\ncomprehension task. We summarize the characteristics and challenges of dialogue\ncomprehension in contrast to plain-text reading comprehension. Then, we discuss\nthree typical patterns of dialogue modeling. In addition, we categorize\ndialogue-related pre-training techniques which are employed to enhance PrLMs in\ndialogue scenarios. Finally, we highlight the technical advances in recent\nyears and point out the lessons from the empirical analysis and the prospects\ntowards a new frontier of researches.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2103.03125\n",
    "authors": [
      "Zhuosheng Zhang",
      "Hai Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.04984"
  },
  {
    "id": "arXiv:2110.04988",
    "title": "Stereo Hybrid Event-Frame (SHEF) Cameras for 3D Perception",
    "abstract": "Stereo camera systems play an important role in robotics applications to\nperceive the 3D world. However, conventional cameras have drawbacks such as low\ndynamic range, motion blur and latency due to the underlying frame-based\nmechanism. Event cameras address these limitations as they report the\nbrightness changes of each pixel independently with a fine temporal resolution,\nbut they are unable to acquire absolute intensity information directly.\nAlthough integrated hybrid event-frame sensors (eg., DAVIS) are available, the\nquality of data is compromised by coupling at the pixel level in the circuit\nfabrication of such cameras. This paper proposes a stereo hybrid event-frame\n(SHEF) camera system that offers a sensor modality with separate high-quality\npure event and pure frame cameras, overcoming the limitations of each separate\nsensor and allowing for stereo depth estimation. We provide a SHEF dataset\ntargeted at evaluating disparity estimation algorithms and introduce a stereo\ndisparity estimation algorithm that uses edge information extracted from the\nevent stream correlated with the edge detected in the frame data. Our disparity\nestimation outperforms the state-of-the-art stereo matching algorithm on the\nSHEF dataset.",
    "descriptor": "\nComments: 10 pages, 6 figures, accepted for presentation at International Conference on Intelligent Robots and Systems (IROS), 2021\n",
    "authors": [
      "Ziwei Wang",
      "Liyuan Pan",
      "Yonhon Ng",
      "Zheyu Zhuang",
      "Robert Mahony"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04988"
  },
  {
    "id": "arXiv:2110.04994",
    "title": "Omnidata: A Scalable Pipeline for Making Multi-Task Mid-Level Vision  Datasets from 3D Scans",
    "abstract": "This paper introduces a pipeline to parametrically sample and render\nmulti-task vision datasets from comprehensive 3D scans from the real world.\nChanging the sampling parameters allows one to \"steer\" the generated datasets\nto emphasize specific information. In addition to enabling interesting lines of\nresearch, we show the tooling and generated data suffice to train robust vision\nmodels.\nCommon architectures trained on a generated starter dataset reached\nstate-of-the-art performance on multiple common vision tasks and benchmarks,\ndespite having seen no benchmark or non-pipeline data. The depth estimation\nnetwork outperforms MiDaS and the surface normal estimation network is the\nfirst to achieve human-level performance for in-the-wild surface normal\nestimation -- at least according to one metric on the OASIS benchmark.\nThe Dockerized pipeline with CLI, the (mostly python) code, PyTorch\ndataloaders for the generated data, the generated starter dataset, download\nscripts and other utilities are available through our project website,\nhttps://omnidata.vision.",
    "descriptor": "\nComments: ICCV 2021: See project website this https URL\n",
    "authors": [
      "Ainaz Eftekhar",
      "Alexander Sax",
      "Roman Bachmann",
      "Jitendra Malik",
      "Amir Zamir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.04994"
  },
  {
    "id": "arXiv:2110.04995",
    "title": "The Skellam Mechanism for Differentially Private Federated Learning",
    "abstract": "We introduce the multi-dimensional Skellam mechanism, a discrete differential\nprivacy mechanism based on the difference of two independent Poisson random\nvariables. To quantify its privacy guarantees, we analyze the privacy loss\ndistribution via a numerical evaluation and provide a sharp bound on the\nR\\'enyi divergence between two shifted Skellam distributions. While useful in\nboth centralized and distributed privacy applications, we investigate how it\ncan be applied in the context of federated learning with secure aggregation\nunder communication constraints. Our theoretical findings and extensive\nexperimental evaluations demonstrate that the Skellam mechanism provides the\nsame privacy-accuracy trade-offs as the continuous Gaussian mechanism, even\nwhen the precision is low. More importantly, Skellam is closed under summation\nand sampling from it only requires sampling from a Poisson distribution -- an\nefficient routine that ships with all machine learning and data analysis\nsoftware packages. These features, along with its discrete nature and\ncompetitive privacy-accuracy trade-offs, make it an attractive alternative to\nthe newly introduced discrete Gaussian mechanism.",
    "descriptor": "\nComments: Paper published in NeurIPS 2021\n",
    "authors": [
      "Naman Agarwal",
      "Peter Kairouz",
      "Ziyu Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04995"
  },
  {
    "id": "arXiv:2110.04997",
    "title": "IoT Equipped Intelligent Distributed Framework for Smart Healthcare  Systems",
    "abstract": "The fundamental aim of the healthcare sector is to incorporate different\ntechnologies to observe and keep a track of the various clinical parameters of\nthe patients in day to day life. Distant patient observation applications are\nbecoming popular as economical healthcare services are facilitated by these\napps. The process of data management gathered through these applications also\nrequire due attention. Although cloud facilitated healthcare applications cater\na variety of solutions to store patients record and deliver the required data\nas per need of all the stakeholders but are affected by security issues, more\nresponse time and affecting the continues availability of the system. To\novercome these challenges, an intelligent IoT based distributed framework to\ndeploy remote healthcare services is proposed in this chapter. In the proposed\nmodel, various entities of the system are interconnected using IoT and\nDistributed Database Management Systems is used to cater secure and fast data\navailability to the patients and health care workers. The concept of Blockchain\nis used to ensure the security of the patient medical records. The proposed\nmodel will comprise of intelligent analysis of the clinical records fetched\nfrom Distributed Database Management Systems secured with Blockchain. Proposed\nmodel is tested with true clinical data and results are discussed in detail.",
    "descriptor": "\nComments: 29 pages and 9 figures\n",
    "authors": [
      "Sita Rani",
      "Meetali Chauhan",
      "Aman Kataria",
      "Alex Khang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.04997"
  },
  {
    "id": "arXiv:2110.05001",
    "title": "Dynamic Control of Soft Robotic Arm",
    "abstract": "In this article, the control problem of one section pneumatically actuated\nsoft robotic arm is investigated in detail. To date, extensive prior work has\nbeen done in soft robotics kinematics and dynamics modeling. Proper controller\ndesigns can complement the modeling part since they are able to compensate\nother effects that have not been considered in the modeling, such as the model\nuncertainties, system parameter identification error, hysteresis, etc. In this\npaper, we explored different control approaches (kinematic control, PD+feedback\nlinearization, passivity control, adaptive passivity control) and summarized\nthe advantages and disadvantages of each controller. We further investigated\nthe robot control problem in the practical scenarios when the sensor noise\nexists, actuator velocity measurement is not available, and the hysteresis\neffect is non-neglectable. Our simulation results indicated that the adaptive\npassivity control with sigma modification terms, along with a high-gain\nobserver presents a better performance in comparison with other approaches.\nAlthough this paper mainly presented the simulation results of various\ncontrollers, the work will pave the way for practical implementation of soft\nrobot control.",
    "descriptor": "\nComments: 8 pages, 10 figures\n",
    "authors": [
      "Milad Azizkhani",
      "Isuru S. Godage",
      "Yue Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.05001"
  },
  {
    "id": "arXiv:2110.05003",
    "title": "Disturbing Target Values for Neural Network Regularization",
    "abstract": "Diverse regularization techniques have been developed such as L2\nregularization, Dropout, DisturbLabel (DL) to prevent overfitting. DL, a\nnewcomer on the scene, regularizes the loss layer by flipping a small share of\nthe target labels at random and training the neural network on this distorted\ndata so as to not learn the training data. It is observed that high confidence\nlabels during training cause the overfitting problem and DL selects disturb\nlabels at random regardless of the confidence of labels. To solve this\nshortcoming of DL, we propose Directional DisturbLabel (DDL) a novel\nregularization technique that makes use of the class probabilities to infer the\nconfident labels and using these labels to regularize the model. This active\nregularization makes use of the model behavior during training to regularize it\nin a more directed manner. To address regression problems, we also propose\nDisturbValue (DV), and DisturbError (DE). DE uses only predefined confident\nlabels to disturb target values. DV injects noise into a portion of target\nvalues at random similar to DL. In this paper, 6 and 8 datasets are used to\nvalidate the robustness of our methods in classification and regression tasks\nrespectively. Finally, we demonstrate that our methods are either comparable to\nor outperform DisturbLabel, L2 regularization, and Dropout. Also, we achieve\nthe best performance in more than half the datasets by combining our methods\nwith either L2 regularization or Dropout.",
    "descriptor": "\nComments: 10 pages,2 figures, 6 tables\n",
    "authors": [
      "Yongho Kim",
      "Hanna Lukashonak",
      "Paweena Tarepakdee",
      "Klavdia Zavalich",
      "Mofassir ul Islam Arif"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05003"
  },
  {
    "id": "arXiv:2110.05005",
    "title": "Quasi-Cyclic Stern Proof of Knowledge",
    "abstract": "The 1993 Stern authentication protocol is a code-based zero-knowledge\nprotocol with cheating probability equal to 2/3 based on the syndrome decoding\nproblem which permits to obtain a proof of knowledge of a small weight vector.\nThis protocol was improved a few years later by V\\'eron, who proposed a\nvariation of the scheme based on the general syndrome decoding problem which\nleads to better results in term of communication. A few years later, the AGS\nprotocol introduced a variation of the V\\'eron protocol based on quasi-cyclic\nmatrices. The AGS protocol permits to obtain an asymptotic cheating probability\nof 1/2 and a strong improvement in term of communications. In the present paper\nwe propose two new contributions. First, a Quasi-Cyclic Stern proof of\nknowledge construction which constitutes an adaptation of the AGS scheme in a\nsyndrome decoding context. The main interest of this adaptation is that at the\ndifference of the regular (non quasi-cyclic) case, the Quasi-Cyclic Stern\nprotocol is better in terms of communication than its V\\'eron counterpart (the\nAGS protocol, which can be seen as a Quasi-Cyclic V\\'eron protocol). The\ndifference comes from the fact that a seed related optimization is better for\nQC-Stern than for QC-V\\'eron. Secondly, we also propose a general new\noptimization to handle random seeds in this type of protocol. Overall, the two\nnew optimizations we propose permit to gain about 17.5% in the length of\ncommunication compared to the previous best approach for this type of\nprotocols. Such optimizations are of great matter in the ongoing context where\na new signature call for proposals has been announced by the NIST and for which\nsuch zero-knowledge approaches are a real alternative, as it was shown in the\nfirst signature call for proposals of the NIST.",
    "descriptor": "",
    "authors": [
      "Lo\u00efc Bidoux",
      "Philippe Gaborit",
      "Nicolas Sendrier"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.05005"
  },
  {
    "id": "arXiv:2110.05006",
    "title": "Pre-trained Language Models in Biomedical Domain: A Survey from  Multiscale Perspective",
    "abstract": "Pre-trained language models have been the de facto paradigm for most natural\nlanguage processing (NLP) tasks. In the biomedical domain, which also benefits\nfrom NLP techniques, various pre-trained language models were proposed by\nleveraging domain datasets including biomedical literature, biomedical social\nmedial, electronic health records, and other biological sequences. Large\namounts of efforts have been explored on applying these biomedical pre-trained\nlanguage models to downstream biomedical tasks, from informatics, medicine, and\ncomputer science (CS) communities. However, it seems that the vast majority of\nexisting works are isolated from each other probably because of the\ncross-discipline characteristics. It is expected to propose a survey that not\nonly systematically reviews recent advances of biomedical pre-trained language\nmodels and their applications but also standardizes terminology, taxonomy, and\nbenchmarks. Therefore, this paper summarizes the recent progress of pre-trained\nlanguage models used in the biomedical domain. Particularly, an overview and\ntaxonomy of existing biomedical pre-trained language models as well as their\napplications in biomedical downstream tasks are exhaustively discussed. At\nlast, we illustrate various limitations and future trends, which we hope can\nprovide inspiration for the future research.",
    "descriptor": "",
    "authors": [
      "Benyou Wang",
      "Qianqian Xie",
      "Jiahuan Pei",
      "Prayag Tiwari",
      "Zhao Li",
      "Jie fu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05006"
  },
  {
    "id": "arXiv:2110.05007",
    "title": "Boosting Fast Adversarial Training with Learnable Adversarial  Initialization",
    "abstract": "Adversarial training (AT) has been demonstrated to be effective in improving\nmodel robustness by leveraging adversarial examples for training. However, most\nAT methods are in face of expensive time and computational cost for calculating\ngradients at multiple steps in generating adversarial examples. To boost\ntraining efficiency, fast gradient sign method (FGSM) is adopted in fast AT\nmethods by calculating gradient only once. Unfortunately, the robustness is far\nfrom satisfactory. One reason may arise from the initialization fashion.\nExisting fast AT generally uses a random sample-agnostic initialization, which\nfacilitates the efficiency yet hinders a further robustness improvement. Up to\nnow, the initialization in fast AT is still not extensively explored. In this\npaper, we boost fast AT with a sample-dependent adversarial initialization,\ni.e., an output from a generative network conditioned on a benign image and its\ngradient information from the target network. As the generative network and the\ntarget network are optimized jointly in the training phase, the former can\nadaptively generate an effective initialization with respect to the latter,\nwhich motivates gradually improved robustness. Experimental evaluations on four\nbenchmark databases demonstrate the superiority of our proposed method over\nstate-of-the-art fast AT methods, as well as comparable robustness to advanced\nmulti-step AT methods. The code is released at\nhttps://github.com//jiaxiaojunQAQ//FGSM-SDI.",
    "descriptor": "",
    "authors": [
      "Xiaojun Jia",
      "Yong Zhang",
      "Baoyuan Wu",
      "Jue Wang",
      "Xiaochun Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05007"
  },
  {
    "id": "arXiv:2110.05014",
    "title": "An Information-Theoretic Analysis of The Cost of Decentralization for  Learning and Inference Under Privacy Constraints",
    "abstract": "In vertical federated learning (FL), the features of a data sample are\ndistributed across multiple agents. As such, inter-agent collaboration can be\nbeneficial not only during the learning phase, as is the case for standard\nhorizontal FL, but also during the inference phase. A fundamental theoretical\nquestion in this setting is how to quantify the cost, or performance loss, of\ndecentralization for learning and/or inference. In this paper, we consider\ngeneral supervised learning problems with any number of agents, and provide a\nnovel information-theoretic quantification of the cost of decentralization in\nthe presence of privacy constraints on inter-agent communication within a\nBayesian framework. The cost of decentralization for learning and/or inference\nis shown to be quantified in terms of conditional mutual information terms\ninvolving features and label variables.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Sharu Theresa Jose",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.05014"
  },
  {
    "id": "arXiv:2110.05015",
    "title": "A Survey on Proactive Customer Care: Enabling Science and Steps to  Realize it",
    "abstract": "In recent times, advances in artificial intelligence (AI) and IoT have\nenabled seamless and viable maintenance of appliances in home and building\nenvironments. Several studies have shown that AI has the potential to provide\npersonalized customer support which could predict and avoid errors more\nreliably than ever before. In this paper, we have analyzed the various building\nblocks needed to enable a successful AI-driven predictive maintenance use-case.\nUnlike, existing surveys which mostly provide a deep dive into the recent AI\nalgorithms for Predictive Maintenance (PdM), our survey provides the complete\nview; starting from business impact to recent technology advancements in\nalgorithms as well as systems research and model deployment. Furthermore, we\nprovide exemplar use-cases on predictive maintenance of appliances using\npublicly available data sets. Our survey can serve as a template needed to\ndesign a successful predictive maintenance use-case. Finally, we touch upon\nexisting public data sources and provide a step-wise breakdown of an AI-driven\nproactive customer care (PCC) use-case, starting from generic anomaly detection\nto fault prediction and finally root-cause analysis. We highlight how such a\nstep-wise approach can be advantageous for accurate model building and helpful\nfor gaining insights into predictive maintenance of electromechanical\nappliances.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1912.07383, arXiv:2007.02500 by other authors\n",
    "authors": [
      "Viswanath Ganapathy",
      "Sauptik Dhar",
      "Olimpiya Saha",
      "Pelin Kurt Garberson",
      "Javad Heydari",
      "Mohak Shah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05015"
  },
  {
    "id": "arXiv:2110.05018",
    "title": "Time-varying Graph Learning Under Structured Temporal Priors",
    "abstract": "This paper endeavors to learn time-varying graphs by using structured\ntemporal priors that assume underlying relations between arbitrary two graphs\nin the graph sequence. Different from many existing chain structure based\nmethods in which the priors like temporal homogeneity can only describe the\nvariations of two consecutive graphs, we propose a structure named\n\\emph{temporal graph} to characterize the underlying real temporal relations.\nUnder this framework, the chain structure is actually a special case of our\ntemporal graph. We further proposed Alternating Direction Method of Multipliers\n(ADMM), a distributed algorithm, to solve the induced optimization problem.\nNumerical experiments demonstrate the superiorities of our method.",
    "descriptor": "\nComments: 5 pages 5 figures\n",
    "authors": [
      "Xiang Zhang",
      "Qiao Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.05018"
  },
  {
    "id": "arXiv:2110.05020",
    "title": "MELONS: generating melody with long-term structure using transformers  and structure graph",
    "abstract": "The creation of long melody sequences requires effective expression of\ncoherent musical structure. However, there is no clear representation of\nmusical structure. Recent works on music generation have suggested various\napproaches to deal with the structural information of music, but generating a\nfull-song melody with clear long-term structure remains a challenge. In this\npaper, we propose MEL-ONS, a melody generation framework based on a graph\nrepresentation of music structure which consists of eight types of bar-level\nrelations. MELONS adopts a multi-step generation method with transformer-based\nnetworks by factoring melody generation into two sub-problems: structure\ngeneration and structure conditional melody generation. Experimental results\nshow that MELONS can produce structured melodies with high quality and rich\ncontents.",
    "descriptor": "",
    "authors": [
      "Yi Zou",
      "Pei Zou",
      "Yi Zhao",
      "Kaixiang Zhang",
      "Ran Zhang",
      "Xiaorui Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05020"
  },
  {
    "id": "arXiv:2110.05021",
    "title": "Cross Domain Emotion Recognition using Few Shot Knowledge Transfer",
    "abstract": "Emotion recognition from text is a challenging task due to diverse emotion\ntaxonomies, lack of reliable labeled data in different domains, and highly\nsubjective annotation standards. Few-shot and zero-shot techniques can\ngeneralize across unseen emotions by projecting the documents and emotion\nlabels onto a shared embedding space. In this work, we explore the task of\nfew-shot emotion recognition by transferring the knowledge gained from\nsupervision on the GoEmotions Reddit dataset to the SemEval tweets corpus,\nusing different emotion representation methods. The results show that knowledge\ntransfer using external knowledge bases and fine-tuned encoders perform\ncomparably as supervised baselines, requiring minimal supervision from the task\ndataset.",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Justin Olah",
      "Sabyasachee Baruah",
      "Digbalay Bose",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05021"
  },
  {
    "id": "arXiv:2110.05022",
    "title": "Blockchain for Edge of Things: Applications, Opportunities, and  Challenges",
    "abstract": "In recent years, blockchain networks have attracted significant attention in\nmany research areas beyond cryptocurrency, one of them being the Edge of Things\n(EoT) that is enabled by the combination of edge computing and the Internet of\nThings (IoT). In this context, blockchain networks enabled with unique features\nsuch as decentralization, immutability, and traceability, have the potential to\nreshape and transform the conventional EoT systems with higher security levels.\nParticularly, the convergence of blockchain and EoT leads to a new paradigm,\ncalled BEoT that has been regarded as a promising enabler for future services\nand applications. In this paper, we present a state-of-the-art review of recent\ndevelopments in BEoT technology and discover its great opportunities in many\napplication domains. We start our survey by providing an updated introduction\nto blockchain and EoT along with their recent advances. Subsequently, we\ndiscuss the use of BEoT in a wide range of industrial applications, from smart\ntransportation, smart city, smart healthcare to smart home and smart grid.\nSecurity challenges in BEoT paradigm are also discussed and analyzed, with some\nkey services such as access authentication, data privacy preservation, attack\ndetection, and trust management. Finally, some key research challenges and\nfuture directions are also highlighted to instigate further research in this\npromising area.",
    "descriptor": "\nComments: The paper is accepted for publication in IEEE IoTJ\n",
    "authors": [
      "Thippa Reddy Gadekallu",
      "Quoc-Viet Pham",
      "Dinh C. Nguyen",
      "Praveen Kumar Reddy Maddikunta",
      "N Deepa",
      "Prabadevi B",
      "Pubudu N. Pathirana",
      "Jun Zhao",
      "Won-Joo Hwang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.05022"
  },
  {
    "id": "arXiv:2110.05023",
    "title": "Online Graph Learning in Dynamic Environments",
    "abstract": "Inferring the underlying graph topology that characterizes structured data is\npivotal to many graph-based models when pre-defined graphs are not available.\nThis paper focuses on learning graphs in the case of sequential data in dynamic\nenvironments. For sequential data, we develop an online version of classic\nbatch graph learning method. To better track graphs in dynamic environments, we\nassume graphs evolve in certain patterns such that dynamic priors might be\nembedded in the online graph learning framework. When the information of these\nhidden patterns is not available, we use history data to predict the evolution\nof graphs. Furthermore, dynamic regret analysis of the proposed method is\nperformed and illustrates that our online graph learning algorithms can reach\nsublinear dynamic regret. Experimental results support the fact that our method\nis superior to the state-of-art methods.",
    "descriptor": "",
    "authors": [
      "Xiang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.05023"
  },
  {
    "id": "arXiv:2110.05025",
    "title": "Self-supervised Learning is More Robust to Dataset Imbalance",
    "abstract": "Self-supervised learning (SSL) is a scalable way to learn general visual\nrepresentations since it learns without labels. However, large-scale unlabeled\ndatasets in the wild often have long-tailed label distributions, where we know\nlittle about the behavior of SSL. In this work, we systematically investigate\nself-supervised learning under dataset imbalance. First, we find out via\nextensive experiments that off-the-shelf self-supervised representations are\nalready more robust to class imbalance than supervised representations. The\nperformance gap between balanced and imbalanced pre-training with SSL is\nsignificantly smaller than the gap with supervised learning, across sample\nsizes, for both in-domain and, especially, out-of-domain evaluation. Second,\ntowards understanding the robustness of SSL, we hypothesize that SSL learns\nricher features from frequent data: it may learn\nlabel-irrelevant-but-transferable features that help classify the rare classes\nand downstream tasks. In contrast, supervised learning has no incentive to\nlearn features irrelevant to the labels from frequent examples. We validate\nthis hypothesis with semi-synthetic experiments and theoretical analyses on a\nsimplified setting. Third, inspired by the theoretical insights, we devise a\nre-weighted regularization technique that consistently improves the SSL\nrepresentation quality on imbalanced datasets with several evaluation criteria,\nclosing the small gap between balanced and imbalanced datasets with the same\nnumber of examples.",
    "descriptor": "",
    "authors": [
      "Hong Liu",
      "Jeff Z. HaoChen",
      "Adrien Gaidon",
      "Tengyu Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.05025"
  },
  {
    "id": "arXiv:2110.05028",
    "title": "The CaLiGraph Ontology as a Challenge for OWL Reasoners",
    "abstract": "CaLiGraph is a large-scale cross-domain knowledge graph generated from\nWikipedia by exploiting the category system, list pages, and other list\nstructures in Wikipedia, containing more than 15 million typed entities and\naround 10 million relation assertions. Other than knowledge graphs such as\nDBpedia and YAGO, whose ontologies are comparably simplistic, CaLiGraph also\nhas a rich ontology, comprising more than 200,000 class restrictions. Those two\nproperties - a large A-box and a rich ontology - make it an interesting\nchallenge for benchmarking reasoners. In this paper, we show that a reasoning\ntask which is particularly relevant for CaLiGraph, i.e., the materialization of\nowl:hasValue constraints into assertions between individuals and between\nindividuals and literals, is insufficiently supported by available reasoning\nsystems. We provide differently sized benchmark subsets of CaLiGraph, which can\nbe used for performance analysis of reasoning systems.",
    "descriptor": "\nComments: To be presented at the Semantic Reasoning Evaluation Challenge at the International Semantic Web Conference (ISWC), 2021\n",
    "authors": [
      "Nicolas Heist",
      "Heiko Paulheim"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05028"
  },
  {
    "id": "arXiv:2110.05029",
    "title": "Internal Feedback in Biological Control: Constraints and Layered  Architectures",
    "abstract": "Feedback is ubiquitous in both biological and engineered control systems. In\nbiology, in addition to typical feedback between plant and controller, we\nobserve feedback pathways within control systems, which we call internal\nfeedback pathways (IFPs), that are often very complex. IFP is most familiar in\nneural systems, our primary motivation, but it appears everywhere from\nbacterial signal transduction to the human immune system. Standard modern and\nrobust control theory potentially explains some previously cryptic IFP, but new\ntheory expands this substantially. In this paper we describe the biology\nmotivation for studying complex IFP and introduce the concepts necessary to\nexplain it. The requisite theory will be explored in more detail in several\ncompanion papers.",
    "descriptor": "\nComments: This paper expands on material in arXiv:2109.11752 and is also a companion to arXiv:2109.11757\n",
    "authors": [
      "Anish A. Sarma",
      "Jing-Shuang",
      "Josefin Stenberg",
      "John C. Doyle"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Molecular Networks (q-bio.MN)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2110.05029"
  },
  {
    "id": "arXiv:2110.05031",
    "title": "EDFace-Celeb-1M: Benchmarking Face Hallucination with a Million-scale  Dataset",
    "abstract": "Recent deep face hallucination methods show stunning performance in\nsuper-resolving severely degraded facial images, even surpassing human ability.\nHowever, these algorithms are mainly evaluated on non-public synthetic\ndatasets. It is thus unclear how these algorithms perform on public face\nhallucination datasets. Meanwhile, most of the existing datasets do not well\nconsider the distribution of races, which makes face hallucination methods\ntrained on these datasets biased toward some specific races. To address the\nabove two problems, in this paper, we build a public Ethnically Diverse Face\ndataset, EDFace-Celeb-1M, and design a benchmark task for face hallucination.\nOur dataset includes 1.7 million photos that cover different countries, with\nbalanced race composition. To the best of our knowledge, it is the largest and\npublicly available face hallucination dataset in the wild. Associated with this\ndataset, this paper also contributes various evaluation protocols and provides\ncomprehensive analysis to benchmark the existing state-of-the-art methods. The\nbenchmark evaluations demonstrate the performance and limitations of\nstate-of-the-art algorithms.",
    "descriptor": "",
    "authors": [
      "Kaihao Zhang",
      "Dongxu Li",
      "Wenhan Luo",
      "Jingyu Liu",
      "Jiankang Deng",
      "Wei Liu",
      "Stefanos Zafeiriou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05031"
  },
  {
    "id": "arXiv:2110.05032",
    "title": "Bid Optimization using Maximum Entropy Reinforcement Learning",
    "abstract": "Real-time bidding (RTB) has become a critical way of online advertising. In\nRTB, an advertiser can participate in bidding ad impressions to display its\nadvertisements. The advertiser determines every impression's bidding price\naccording to its bidding strategy. Therefore, a good bidding strategy can help\nadvertisers improve cost efficiency. This paper focuses on optimizing a single\nadvertiser's bidding strategy using reinforcement learning (RL) in RTB.\nUnfortunately, it is challenging to optimize the bidding strategy through RL at\nthe granularity of impression due to the highly dynamic nature of the RTB\nenvironment. In this paper, we first utilize a widely accepted linear bidding\nfunction to compute every impression's base price and optimize it by a mutable\nadjustment factor derived from the RTB auction environment, to avoid optimizing\nevery impression's bidding price directly. Specifically, we use the maximum\nentropy RL algorithm (Soft Actor-Critic) to optimize the adjustment factor\ngeneration policy at the impression-grained level. Finally, the empirical study\non a public dataset demonstrates that the proposed bidding strategy has\nsuperior performance compared with the baselines.",
    "descriptor": "",
    "authors": [
      "Mengjuan Liu",
      "Jinyu Liu",
      "Zhengning Hu",
      "Yuchen Ge",
      "Xuyun Nie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.05032"
  },
  {
    "id": "arXiv:2110.05033",
    "title": "Pitch Preservation In Singing Voice Synthesis",
    "abstract": "Suffering from limited singing voice corpus, existing singing voice synthesis\n(SVS) methods that build encoder-decoder neural networks to directly generate\nspectrogram could lead to out-of-tune issues during the inference phase. To\nattenuate these issues, this paper presents a novel acoustic model with\nindependent pitch encoder and phoneme encoder, which disentangles the phoneme\nand pitch information from music score to fully utilize the corpus.\nSpecifically, according to equal temperament theory, the pitch encoder is\nconstrained by a pitch metric loss that maps distances between adjacent input\npitches into corresponding frequency multiples between the encoder outputs. For\nthe phoneme encoder, based on the analysis that same phonemes corresponding to\nvarying pitches can produce similar pronunciations, this encoder is followed by\nan adversarially trained pitch classifier to enforce the identical phonemes\nwith different pitches mapping into the same phoneme feature space. By these\nmeans, the sparse phonemes and pitches in original input spaces can be\ntransformed into more compact feature spaces respectively, where the same\nelements cluster closely and cooperate mutually to enhance synthesis quality.\nThen, the outputs of the two encoders are summed together to pass through the\nfollowing decoder in the acoustic model. Experimental results indicate that the\nproposed approaches can characterize intrinsic structure between pitch inputs\nto obtain better pitch synthesis accuracy and achieve superior singing\nsynthesis performance against the advanced baseline system.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Shujun Liu",
      "Hai Zhu",
      "Kun Wang",
      "Huajun Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05033"
  },
  {
    "id": "arXiv:2110.05034",
    "title": "When is gray-box modeling advantageous for virtual flow metering?",
    "abstract": "Integration of physics and machine learning in virtual flow metering\napplications is known as gray-box modeling. The combination is believed to\nenhance multiphase flow rate predictions. However, the superiority of gray-box\nmodels is yet to be demonstrated in the literature. This article examines\nscenarios where a gray-box model is expected to outperform physics-based and\ndata-driven models. The experiments are conducted with synthetic data where\nproperties of the underlying data generating process are known and controlled.\nThe results show that a gray-box model yields increased prediction accuracy\nover a physics-based model in the presence of process-model mismatch. They also\nshow improvements over a data-driven model when the amount of available data is\nsmall. On the other hand, gray-box and data-driven models are similarly\ninfluenced by noisy measurements. Lastly, the results indicate that a gray-box\napproach may be advantageous in nonstationary process conditions.\nUnfortunately, choosing the best model prior to training is challenging, and\noverhead on model development is unavoidable.",
    "descriptor": "\nComments: 6 pages, 7 figures\n",
    "authors": [
      "M. Hotvedt",
      "B. Grimstad",
      "D. Ljungquist",
      "L. Imsland"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05034"
  },
  {
    "id": "arXiv:2110.05035",
    "title": "Using Personality Detection Tools for Software Engineering Research: How  Far Can We Go?",
    "abstract": "Assessing the personality of software engineers may help to match individual\ntraits with the characteristics of development activities such as code review\nand testing, as well as support managers in team composition. However,\nself-assessment questionnaires are not a practical solution for collecting\nmultiple observations on a large scale. Instead, automatic personality\ndetection, while overcoming these limitations, is based on off-the-shelf\nsolutions trained on non-technical corpora, which might not be readily\napplicable to technical domains like Software Engineering (SE). In this paper,\nwe first assess the performance of general-purpose personality detection tools\nwhen applied to a technical corpus of developers' emails retrieved from the\npublic archives of the Apache Software Foundation. We observe a general low\naccuracy of predictions and an overall disagreement among the tools. Second, we\nreplicate two previous research studies in SE by replacing the personality\ndetection tool used to infer developers' personalities from pull-request\ndiscussions and emails. We observe that the original results are not confirmed,\ni.e., changing the tool used in the original study leads to diverging\nconclusions. Our results suggest a need for personality detection tools\nspecially targeted for the software engineering domain.",
    "descriptor": "",
    "authors": [
      "Fabio Calefato",
      "Filippo Lanubile"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05035"
  },
  {
    "id": "arXiv:2110.05038",
    "title": "Recurrent Model-Free RL is a Strong Baseline for Many POMDPs",
    "abstract": "Many problems in RL, such as meta RL, robust RL, and generalization in RL,\ncan be cast as POMDPs. In theory, simply augmenting model-free RL with memory,\nsuch as recurrent neural networks, provides a general approach to solving all\ntypes of POMDPs. However, prior work has found that such recurrent model-free\nRL methods tend to perform worse than more specialized algorithms that are\ndesigned for specific types of POMDPs. This paper revisits this claim. We find\nthat careful architecture and hyperparameter decisions yield a recurrent\nmodel-free implementation that performs on par with (and occasionally\nsubstantially better than) more sophisticated recent techniques in their\nrespective domains. We also release a simple and efficient implementation of\nrecurrent model-free RL for future work to use as a baseline for POMDPs. Code\nis available at https://github.com/twni2016/pomdp-baselines",
    "descriptor": "",
    "authors": [
      "Tianwei Ni",
      "Benjamin Eysenbach",
      "Ruslan Salakhutdinov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.05038"
  },
  {
    "id": "arXiv:2110.05041",
    "title": "Provenance in Temporal Interaction Networks",
    "abstract": "In temporal interaction networks, vertices correspond to entities, which\nexchange data quantities (e.g., money, bytes, messages) over time. Tracking the\norigin of data that have reached a given vertex at any time can help data\nanalysts to understand the reasons behind the accumulated quantity at the\nvertex or behind the interactions between entities. In this paper, we study\ndata provenance in a temporal interaction network. We investigate alternative\npropagation models that may apply to different application scenarios. For each\nsuch model, we propose annotation mechanisms that track the origin of\npropagated data in the network and the routes of data quantities. Besides\nanalyzing the space and time complexity of these mechanisms, we propose\ntechniques that reduce their cost in practice, by either (i) limiting\nprovenance tracking to a subset of vertices or groups of vertices, or (ii)\ntracking provenance only for quantities that were generated in the near past or\nlimiting the provenance data in each vertex by a budget constraint. Our\nexperimental evaluation on five real datasets shows that quantity propagation\nmodels based on generation time or receipt order scale well on large graphs; on\nthe other hand, a model that propagates quantities proportionally has high\nspace and time requirements and can benefit from the aforementioned cost\nreduction techniques.",
    "descriptor": "",
    "authors": [
      "Chrysanthi Kosyfaki Nikos Mamoulis"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.05041"
  },
  {
    "id": "arXiv:2110.05042",
    "title": "Multi-query Multi-head Attention Pooling and inter-topK penalty for  speaker verification",
    "abstract": "This paper describes the multi-query multi-head attention (MQMHA) pooling and\ninter-topK penalty methods which were first proposed in our submitted system\ndescription for VoxCeleb speaker recognition challenge (VoxSRC) 2021. Most\nmulti-head attention pooling mechanisms either attend to the whole feature\nthrough multiple heads or attend to several split parts of the whole feature.\nOur proposed MQMHA combines both these two mechanisms and gain more diversified\ninformation. The margin-based softmax loss functions are commonly adopted to\nobtain discriminative speaker representations. To further enhance the\ninter-class discriminability, we propose a method that adds an extra inter-topK\npenalty on some confused speakers. By adopting both the MQMHA and inter-topK\npenalty, we achieved state-of-the-art performance in all of the public VoxCeleb\ntest sets.",
    "descriptor": "\nComments: submitted to ICASSP 2021\n",
    "authors": [
      "Miao Zhao",
      "Yufeng Ma",
      "Yiwei Ding",
      "Yu Zheng",
      "Min Liu",
      "Minqiang Xu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05042"
  },
  {
    "id": "arXiv:2110.05043",
    "title": "Robust Safety for Move",
    "abstract": "A program that maintains key safety properties even when interacting with\narbitrary untrusted code is said to enjoy \\emph{robust safety}. Proving that a\nprogram written in a mainstream language is robustly safe is typically\nchallenging because it requires static verification tools that work precisely\neven in the presence of language features like dynamic dispatch and shared\nmutability. The emerging \\move programming language was designed to support\nstrong encapsulation and static verification in the service of secure smart\ncontract programming. However, the language design has not been analyzed using\na theoretical framework like robust safety.\nIn this paper, we define robust safety for the \\move language and introduce a\ngeneric framework for static tools that wish to enforce it. Our framework\nconsists of two abstract components: a program verifier that can prove an\ninvariant holds in a closed-world setting (e.g., the Move Prover), and a novel\n\\emph{encapsulator} that checks if the verifier's result generalizes to an\nopen-world setting. We formalise an escape analysis as an instantiation of the\nencapsulator and prove that it attains the required security properties.\nFinally, we implement our encapsulator as an extension to the Move Prover and\nuse the combination to analyze a representative benchmark set of real-world\n\\move programs. This toolchain certifies $>$99\\% of the \\move modules we\nanalyze, validating that automatic enforcement of strong security properties\nlike robust safety is practical for \\move.",
    "descriptor": "",
    "authors": [
      "Marco Patrignani",
      "Sam Blackshear"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2110.05043"
  },
  {
    "id": "arXiv:2110.05044",
    "title": "Biometric Template Protection for Neural-Network-based Face Recognition  Systems: A Survey of Methods and Evaluation Techniques",
    "abstract": "This paper presents a survey of biometric template protection (BTP) methods\nfor securing face templates in neural-network-based face recognition systems.\nThe BTP methods are categorised into two types: Non-NN and NN-learned. Non-NN\nmethods use a neural network (NN) as a feature extractor, but the BTP part is\nbased on a non-NN algorithm applied at image-level or feature-level. In\ncontrast, NN-learned methods specifically employ a NN to learn a protected\ntemplate from the unprotected face image/features. We present examples of\nNon-NN and NN-learned face BTP methods from the literature, along with a\ndiscussion of the two categories' comparative strengths and weaknesses. We also\ninvestigate the techniques used to evaluate these BTP methods, in terms of the\nthree most common criteria: recognition accuracy, irreversibility, and\nrenewability/unlinkability. As expected, the recognition accuracy of protected\nface recognition systems is generally evaluated using the same (empirical)\ntechniques employed for evaluating standard (unprotected) biometric systems. On\nthe contrary, most irreversibility and renewability/unlinkability evaluations\nare based on theoretical assumptions/estimates or verbal implications, with no\nempirical validation in a practical face recognition context. So, we recommend\na greater focus on empirical evaluation strategies, to provide more concrete\ninsights into the irreversibility and renewability/unlinkability of face BTP\nmethods in practice. An exploration of the reproducibility of the studied BTP\nworks, in terms of the public availability of their implementation code and\nevaluation datasets/procedures, suggests that it would currently be difficult\nfor the BTP community to faithfully replicate (and thus validate) most of the\nreported findings. So, we advocate for a push towards reproducibility, in the\nhope of furthering our understanding of the face BTP research field.",
    "descriptor": "\nComments: Consists of: 27 pages, 2 figures, 9 tables. Submitted to: IEEE TIFS\n",
    "authors": [
      "Vedrana Krivoku\u0107a Hahn",
      "S\u00e9bastien Marcel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.05044"
  },
  {
    "id": "arXiv:2110.05051",
    "title": "Gaussian rule for integrals involving Bessel functions",
    "abstract": "In this work we develop the Gaussian quadrature rule for weight functions\ninvolving fractional powers, exponentials and Bessel functions of the first\nkind. Besides the computation based on the use of the standard and the modified\nChebyshev algorithm, here we present a very stable algorithm based on the\npreconditioning of the moment matrix. Numerical experiments are provided and a\ngeophysical application is considered.",
    "descriptor": "",
    "authors": [
      "Eleonora Denich",
      "Paolo Novati"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05051"
  },
  {
    "id": "arXiv:2110.05052",
    "title": "LSC-GAN: Latent Style Code Modeling for Continuous Image-to-image  Translation",
    "abstract": "Image-to-image (I2I) translation is usually carried out among discrete\ndomains. However, image domains, often corresponding to a physical value, are\nusually continuous. In other words, images gradually change with the value, and\nthere exists no obvious gap between different domains. This paper intends to\nbuild the model for I2I translation among continuous varying domains. We first\ndivide the whole domain coverage into discrete intervals, and explicitly model\nthe latent style code for the center of each interval. To deal with continuous\ntranslation, we design the editing modules, changing the latent style code\nalong two directions. These editing modules help to constrain the codes for\ndomain centers during training, so that the model can better understand the\nrelation among them. To have diverse results, the latent style code is further\ndiversified with either the random noise or features from the reference image,\ngiving the individual style code to the decoder for label-based or\nreference-based synthesis. Extensive experiments on age and viewing angle\ntranslation show that the proposed method can achieve high-quality results, and\nit is also flexible for users.",
    "descriptor": "",
    "authors": [
      "Qiusheng Huang",
      "Xueqi Hu",
      "Li Sun",
      "Qingli Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05052"
  },
  {
    "id": "arXiv:2110.05053",
    "title": "Integrating Structural Description of Data Format Information into  Programming to Auto-generate File Reading Programs",
    "abstract": "File reading is the basis for data sharing and scientific computing. However,\nmanual programming for file reading is labour-intensive and time-consuming, as\ndata formats are heterogeneous and complex. To address such an issue, this\nstudy proposes a novel approach for the automatic generation of file reading\nprograms based on structured and self-described data format information. This\napproach provides two modes composed of sequentially and randomly reading. The\nfile data format is described by Data Format Markup Language and thus DFML\ndocuments are generated. The formation of data type sequences by parsing those\nDFML documents. The generation of programs for sequential or random reading\ndata with formed data type sequences and general programing rules for specific\nprogramming languages. A tool named DFML Editor was developed for generating\nand editing DFML documents. Case studies on binary files, i.e., ESRI point\nshapefiles and plain text files, i.e., input files of Storm Water Management\nModel, were conducted with the software developed for automatic program\ngeneration and file reading. Experimental results show that the proposed\napproach is effective for automatically generating programs for reading files.\nThe idea in this study is also helpful for automatically writing files.",
    "descriptor": "\nComments: 28 pages, 17 figures\n",
    "authors": [
      "Xinghua Cheng",
      "Erjie Hu",
      "Di Hu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.05053"
  },
  {
    "id": "arXiv:2110.05054",
    "title": "Source Mixing and Separation Robust Audio Steganography",
    "abstract": "Audio steganography aims at concealing secret information in carrier audio\nwith imperceptible modification on the carrier. Although previous works\naddressed the robustness of concealed message recovery against distortions\nintroduced during transmission, they do not address the robustness against\naggressive editing such as mixing of other audio sources and source separation.\nIn this work, we propose for the first time a steganography method that can\nembed information into individual sound sources in a mixture such as\ninstrumental tracks in music. To this end, we propose a time-domain model and\ncurriculum learning essential to learn to decode the concealed message from the\nseparated sources. Experimental results show that the proposed method\nsuccessfully conceals the information in an imperceptible perturbation and that\nthe information can be correctly recovered even after mixing of other sources\nand separation by a source separation algorithm. Furthermore, we show that the\nproposed method can be applied to multiple sources simultaneously without\ninterfering with the decoder for other sources even after the sources are mixed\nand separated.",
    "descriptor": "",
    "authors": [
      "Naoya Takahashi",
      "Mayank Kumar Singh",
      "Yuki Mitsufuji"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05054"
  },
  {
    "id": "arXiv:2110.05055",
    "title": "Bridging the Gap between Label- and Reference-based Synthesis in  Multi-attribute Image-to-Image Translation",
    "abstract": "The image-to-image translation (I2IT) model takes a target label or a\nreference image as the input, and changes a source into the specified target\ndomain. The two types of synthesis, either label- or reference-based, have\nsubstantial differences. Particularly, the label-based synthesis reflects the\ncommon characteristics of the target domain, and the reference-based shows the\nspecific style similar to the reference. This paper intends to bridge the gap\nbetween them in the task of multi-attribute I2IT. We design the label- and\nreference-based encoding modules (LEM and REM) to compare the domain\ndifferences. They first transfer the source image and target label (or\nreference) into a common embedding space, by providing the opposite directions\nthrough the attribute difference vector. Then the two embeddings are simply\nfused together to form the latent code S_rand (or S_ref), reflecting the domain\nstyle differences, which is injected into each layer of the generator by SPADE.\nTo link LEM and REM, so that two types of results benefit each other, we\nencourage the two latent codes to be close, and set up the cycle consistency\nbetween the forward and backward translations on them. Moreover, the\ninterpolation between the S_rand and S_ref is also used to synthesize an extra\nimage. Experiments show that label- and reference-based synthesis are indeed\nmutually promoted, so that we can have the diverse results from LEM, and high\nquality results with the similar style of the reference.",
    "descriptor": "\nComments: accepted by ICCV 2021\n",
    "authors": [
      "Qiusheng Huang",
      "Zhilin Zheng",
      "Xueqi Hu",
      "Li Sun",
      "Qingli Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05055"
  },
  {
    "id": "arXiv:2110.05056",
    "title": "Controllable Recommenders using Deep Generative Models and  Disentanglement",
    "abstract": "In this paper, we consider controllability as a means to satisfy dynamic\npreferences of users, enabling them to control recommendations such that their\ncurrent preference is met. While deep models have shown improved performance\nfor collaborative filtering, they are generally not amenable to fine grained\ncontrol by a user, leading to the development of methods like deep language\ncritiquing. We propose an alternate view, where instead of keyphrase based\ncritiques, a user is provided 'knobs' in a disentangled latent space, with each\nknob corresponding to an item aspect. Disentanglement here refers to a latent\nspace where generative factors (here, a preference towards an item category\nlike genre) are captured independently in their respective dimensions, thereby\nenabling predictable manipulations, otherwise not possible in an entangled\nspace. We propose using a (semi-)supervised disentanglement objective for this\npurpose, as well as multiple metrics to evaluate the controllability and the\ndegree of personalization of controlled recommendations. We show that by\nupdating the disentangled latent space based on user feedback, and by\nexploiting the generative nature of the recommender, controlled and\npersonalized recommendations can be produced. Through experiments on two widely\nused collaborative filtering datasets, we demonstrate that a controllable\nrecommender can be trained with a slight reduction in recommender performance,\nprovided enough supervision is provided. The recommendations produced by these\nmodels appear to both conform to a user's current preference and remain\npersonalized.",
    "descriptor": "\nComments: 10 pages, 1 figure\n",
    "authors": [
      "Samarth Bhargav",
      "Evangelos Kanoulas"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.05056"
  },
  {
    "id": "arXiv:2110.05057",
    "title": "Can Stochastic Gradient Langevin Dynamics Provide Differential Privacy  for Deep\\\\ Learning?",
    "abstract": "Bayesian learning via Stochastic Gradient Langevin Dynamics (SGLD) has been\nsuggested for differentially private learning. While previous research provides\ndifferential privacy bounds for SGLD when close to convergence or at the\ninitial steps of the algorithm, the question of what differential privacy\nguarantees can be made in between remains unanswered. This interim region is\nessential, especially for Bayesian neural networks, as it is hard to guarantee\nconvergence to the posterior. This paper will show that using SGLD might result\nin unbounded privacy loss for this interim region, even when sampling from the\nposterior is as differentially private as desired.",
    "descriptor": "",
    "authors": [
      "Guy Heller",
      "Ethan Fetaya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.05057"
  },
  {
    "id": "arXiv:2110.05059",
    "title": "Amicable examples for informed source separation",
    "abstract": "This paper deals with the problem of informed source separation (ISS), where\nthe sources are accessible during the so-called \\textit{encoding} stage.\nPrevious works computed side-information during the encoding stage and source\nseparation models were designed to utilize the side-information to improve the\nseparation performance. In contrast, in this work, we improve the performance\nof a pretrained separation model that does not use any side-information. To\nthis end, we propose to adopt an adversarial attack for the opposite purpose,\ni.e., rather than computing the perturbation to degrade the separation, we\ncompute an imperceptible perturbation called amicable noise to improve the\nseparation. Experimental results show that the proposed approach selectively\nimproves the performance of the targeted separation model by 2.23 dB on average\nand is robust to signal compression. Moreover, we propose multi-model\nmulti-purpose learning that control the effect of the perturbation on different\nmodels individually.",
    "descriptor": "",
    "authors": [
      "Naoya Takahashi",
      "Yuki Mitsufuji"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05059"
  },
  {
    "id": "arXiv:2110.05060",
    "title": "Two-level Group Convolution",
    "abstract": "Group convolution has been widely used in order to reduce the computation\ntime of convolution, which takes most of the training time of convolutional\nneural networks. However, it is well known that a large number of groups\nsignificantly reduce the performance of group convolution. In this paper, we\npropose a new convolution methodology called ``two-level'' group convolution\nthat is robust with respect to the increase of the number of groups and\nsuitable for multi-GPU parallel computation. We first observe that the group\nconvolution can be interpreted as a one-level block Jacobi approximation of the\nstandard convolution, which is a popular notion in the field of numerical\nanalysis. In numerical analysis, there have been numerous studies on the\ntwo-level method that introduces an intergroup structure that resolves the\nperformance degradation issue without disturbing parallel computation.\nMotivated by these, we introduce a coarse-level structure which promotes\nintergroup communication without being a bottleneck in the group convolution.\nWe show that all the additional work induced by the coarse-level structure can\nbe efficiently processed in a distributed memory system. Numerical results that\nverify the robustness of the proposed method with respect to the number of\ngroups are presented. Moreover, we compare the proposed method to various\napproaches for group convolution in order to highlight the superiority of the\nproposed method in terms of execution time, memory efficiency, and performance.",
    "descriptor": "",
    "authors": [
      "Youngkyu Lee",
      "Jongho Park",
      "Chang-Ock Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05060"
  },
  {
    "id": "arXiv:2110.05063",
    "title": "Efficient Extensional Binary Tries",
    "abstract": "Lookup tables (finite maps) are a ubiquitous data structure. In pure\nfunctional languages they are best represented using trees instead of hash\ntables. In pure functional languages within constructive logic, without a\nprimitive integer type, they are well represented using binary tries instead of\nsearch trees. In this work, we introduce canonical binary tries, an improved\nbinary-trie data structure that enjoys a natural extensionality property, quite\nuseful in proofs, and supports sparseness more efficiently. We provide full\nproofs of correctness in Coq. We provide microbenchmark measurements of\ncanonical binary tries versus several other data structures for finite maps, in\na variety of application contexts; as well as measurement of canonical versus\noriginal tries in a big, real system. The application context of data\nstructures contained in theorem statements imposes unusual requirements for\nwhich canonical tries are particularly well suited.",
    "descriptor": "",
    "authors": [
      "Andrew Appel",
      "Xavier Leroy"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2110.05063"
  },
  {
    "id": "arXiv:2110.05064",
    "title": "Ab-Initio Potential Energy Surfaces by Pairing GNNs with Neural Wave  Functions",
    "abstract": "Solving the Schr\\\"odinger equation is key to many quantum mechanical\nproperties. However, an analytical solution is only tractable for\nsingle-electron systems. Recently, neural networks succeeded at modelling wave\nfunctions of many-electron systems. Together with the variational Monte-Carlo\n(VMC) framework, this led to solutions on par with the best known classical\nmethods. Still, these neural methods require tremendous amounts of\ncomputational resources as one has to train a separate model for each molecular\ngeometry. In this work, we combine a Graph Neural Network (GNN) with a neural\nwave function to simultaneously solve the Schr\\\"odinger equation for multiple\ngeometries via VMC. This enables us to model continuous subsets of the\npotential energy surface with a single training pass. Compared to existing\nstate-of-the-art networks, our Potential Energy Surface Network (PESNet) speeds\nup training for multiple geometries by up to 40 times while matching or\nsurpassing their accuracy. This may open the path to accurate and orders of\nmagnitude cheaper quantum mechanical calculations.",
    "descriptor": "",
    "authors": [
      "Nicholas Gao",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.05064"
  },
  {
    "id": "arXiv:2110.05069",
    "title": "Efficient Training of Audio Transformers with Patchout",
    "abstract": "The great success of transformer-based models in natural language processing\n(NLP) has led to various attempts at adapting these architectures to other\ndomains such as vision and audio. Recent work has shown that transformers can\noutperform Convolutional Neural Networks (CNNs) on vision and audio tasks.\nHowever, one of the main shortcomings of transformer models, compared to the\nwell-established CNNs, is the computational complexity. Compute and memory\ncomplexity grow quadratically with the input length. Therefore, there has been\nextensive work on optimizing transformers, but often at the cost of lower\npredictive performance. In this work, we propose a novel method to optimize and\nregularize transformers on audio spectrograms. The proposed models achieve a\nnew state-of-the-art performance on Audioset and can be trained on a single\nconsumer-grade GPU. Furthermore, we propose a transformer model that\noutperforms CNNs in terms of both performance and training speed.",
    "descriptor": "\nComments: Source code: this https URL\n",
    "authors": [
      "Khaled Koutini",
      "Jan Schl\u00fcter",
      "Hamid Eghbal-zadeh",
      "Gerhard Widmer"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05069"
  },
  {
    "id": "arXiv:2110.05071",
    "title": "Document-Level Text Simplification: Dataset, Criteria and Baseline",
    "abstract": "Text simplification is a valuable technique. However, current research is\nlimited to sentence simplification. In this paper, we define and investigate a\nnew task of document-level text simplification, which aims to simplify a\ndocument consisting of multiple sentences. Based on Wikipedia dumps, we first\nconstruct a large-scale dataset named D-Wikipedia and perform analysis and\nhuman evaluation on it to show that the dataset is reliable. Then, we propose a\nnew automatic evaluation metric called D-SARI that is more suitable for the\ndocument-level simplification task. Finally, we select several representative\nmodels as baseline models for this task and perform automatic evaluation and\nhuman evaluation. We analyze the results and point out the shortcomings of the\nbaseline models.",
    "descriptor": "\nComments: 17 pages, 1 figure, accepted by EMNLP 2021\n",
    "authors": [
      "Renliang Sun",
      "Hanqi Jin",
      "Xiaojun Wan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05071"
  },
  {
    "id": "arXiv:2110.05072",
    "title": "$\u03c6$-FEM: an efficient simulation tool using simple meshes for  problems in structure mechanics and heat transfer",
    "abstract": "One of the major issues in the computational mechanics is to take into\naccount the geometrical complexity. To overcome this difficulty and to avoid\nthe expensive mesh generation, geometrically unfitted methods, i.e. the\nnumerical methods using the simple computational meshes that do not fit the\nboundary of the domain, and/or the internal interfaces, have been widely\ndeveloped. In the present work, we investigate the performances of an unfitted\nmethod called $\\phi$-FEM that converges optimally and uses classical finite\nelement spaces so that it can be easily implemented using general FEM\nlibraries. The main idea is to take into account the geometry thanks to a level\nset function describing the boundary or the interface. Up to now, the\n$\\phi$-FEM approach has been proposed, tested and substantiated mathematically\nonly in some simplest settings: Poisson equation with Dirichlet/Neumann/Robin\nboundary conditions. Our goal here is to demonstrate its applicability to some\nmore sophisticated governing equations arising in the computational mechanics.\nWe consider the linear elasticity equations accompanied by either pure\nDirichlet boundary conditions or by the mixed ones (Dirichlet and Neumann\nboundary conditions co-existing on parts of the boundary), an interface problem\n(linear elasticity with material coefficients abruptly changing over an\ninternal interface), a model of elastic structures with cracks, and finally the\nheat equation. In all these settings, we derive an appropriate variant of\n$\\phi$-FEM and then illustrate it by numerical tests on manufactured solutions.\nWe also compare the accuracy and efficiency of $\\phi$-FEM with those of the\nstandard fitted FEM on the meshes of similar size, revealing the substantial\ngains that can be achieved by $\\phi$-FEM in both the accuracy and the\ncomputational time.",
    "descriptor": "",
    "authors": [
      "Stephane Cotin",
      "Michel Duprez",
      "Vanessa Lleras",
      "Alexei Lozinski",
      "Killian Vuillemot"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05072"
  },
  {
    "id": "arXiv:2110.05074",
    "title": "VTBR: Semantic-based Pretraining for Person Re-Identification",
    "abstract": "Pretraining is a dominant paradigm in computer vision. Generally, supervised\nImageNet pretraining is commonly used to initialize the backbones of person\nre-identification (Re-ID) models. However, recent works show a surprising\nresult that ImageNet pretraining has limited impacts on Re-ID system due to the\nlarge domain gap between ImageNet and person Re-ID data. To seek an alternative\nto traditional pretraining, we manually construct a diversified FineGPR-C\ncaption dataset for the first time on person Re-ID events. Based on it, we\npropose a pure semantic-based pretraining approach named VTBR, which uses dense\ncaptions to learn visual representations with fewer images. Specifically, we\ntrain convolutional networks from scratch on the captions of FineGPR-C dataset,\nand transfer them to downstream Re-ID tasks. Comprehensive experiments\nconducted on benchmarks show that our VTBR can achieve competitive performance\ncompared with ImageNet pretraining -- despite using up to 1.4x fewer images,\nrevealing its potential in Re-ID pretraining.",
    "descriptor": "",
    "authors": [
      "Suncheng Xiang",
      "Zirui Zhang",
      "Mengyuan Guan",
      "Hao Chen",
      "Binjie Yan",
      "Ting Liu",
      "Yuzhuo Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05074"
  },
  {
    "id": "arXiv:2110.05075",
    "title": "DANIEL: A Fast and Robust Consensus Maximization Method for Point Cloud  Registration with High Outlier Ratios",
    "abstract": "Correspondence-based point cloud registration is a cornerstone in geometric\ncomputer vision, robotics perception, photogrammetry and remote sensing, which\nseeks to estimate the best rigid transformation between two point clouds from\nthe correspondences established over 3D keypoints. However, due to limited\nrobustness and accuracy, current 3D keypoint matching techniques are very prone\nto yield outliers, probably even in very large numbers, making robust\nestimation for point cloud registration of great importance. Unfortunately,\nexisting robust methods may suffer from high computational cost or insufficient\nrobustness when encountering high (or even extreme) outlier ratios, hardly\nideal enough for practical use. In this paper, we present a novel\ntime-efficient RANSAC-type consensus maximization solver, named DANIEL\n(Double-layered sAmpliNg with consensus maximization based on stratIfied\nElement-wise compatibiLity), for robust registration. DANIEL is designed with\ntwo layers of random sampling, in order to find inlier subsets with the lowest\ncomputational cost possible. Specifically, we: (i) apply the rigidity\nconstraint to prune raw outliers in the first layer of one-point sampling, (ii)\nintroduce a series of stratified element-wise compatibility tests to conduct\nrapid compatibility checking between minimal models so as to realize more\nefficient consensus maximization in the second layer of two-point sampling, and\n(iii) probabilistic termination conditions are employed to ensure the timely\nreturn of the final inlier set. Based on a variety of experiments over multiple\nreal datasets, we show that DANIEL is robust against over 99% outliers and also\nsignificantly faster than existing state-of-the-art robust solvers (e.g.\nRANSAC, FGR, GORE).",
    "descriptor": "",
    "authors": [
      "Lei Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.05075"
  },
  {
    "id": "arXiv:2110.05076",
    "title": "A Closer Look at Prototype Classifier for Few-shot Image Classification",
    "abstract": "The prototypical network is a prototype classifier based on meta-learning and\nis widely used for few-shot learning because it classifies unseen examples by\nconstructing class-specific prototypes without adjusting hyper-parameters\nduring meta-testing. Interestingly, recent research has attracted a lot of\nattention, showing that a linear classifier with fine-tuning, which does not\nuse a meta-learning algorithm, performs comparably with the prototypical\nnetwork. However, fine-tuning requires additional hyper-parameters when\nadapting a model to a new environment. In addition, although the purpose of\nfew-shot learning is to enable the model to quickly adapt to a new environment,\nfine-tuning needs to be applied every time a new class appears, making fast\nadaptation difficult. In this paper, we analyze how a prototype classifier\nworks equally well without fine-tuning and meta-learning. We experimentally\nfound that directly using the feature vector extracted using standard\npre-trained models to construct a prototype classifier in meta-testing does not\nperform as well as the prototypical network and linear classifiers with\nfine-tuning and feature vectors of pre-trained models. Thus, we derive a novel\ngeneralization bound for the prototypical network and show that focusing on the\nvariance of the norm of a feature vector can improve performance. We\nexperimentally investigated several normalization methods for minimizing the\nvariance of the norm and found that the same performance can be obtained by\nusing the L2 normalization and embedding space transformation without\nfine-tuning or meta-learning.",
    "descriptor": "\nComments: 10 pages with 6 appendix section\n",
    "authors": [
      "Mingcheng Hou",
      "Issei Sato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05076"
  },
  {
    "id": "arXiv:2110.05078",
    "title": "State Estimation Using a Network of Distributed Observers With Unknown  Inputs",
    "abstract": "State estimation for a class of linear time-invariant systems with\ndistributed output measurements (distributed sensors) and unknown inputs is\naddressed in this paper. The objective is to design a network of observers such\nthat the state vector of the entire system can be estimated, while each\nobserver (or node) has access to only local output measurements that may not be\nsufficient on its own to reconstruct the entire system's state. Existing\nresults in the literature on distributed state estimation assume either that\nthe system does not have inputs, or that all the system's inputs are globally\nknown to all the observers. Accordingly, we address this gap by proposing a\ndistributed observer capable of estimating the overall system's state in the\npresence of inputs, while each node only has limited local information on\ninputs and outputs. We provide a design method that guarantees convergence of\nthe estimation errors under some mild joint detectability conditions. This\ndesign suits undirected communication graphs that may have switching topologies\nand also applies to strongly connected directed graphs. We also give existence\nconditions that harmonize with existing results on unknown input observers.\nFinally, simulation results verify the effectiveness of the proposed estimation\nscheme for various scenarios.",
    "descriptor": "",
    "authors": [
      "Guitao Yang",
      "Angelo Barboni",
      "Hamed Rezaee",
      "Thomas Parisini"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.05078"
  },
  {
    "id": "arXiv:2110.05085",
    "title": "Efficiently and Globally Solving Joint Beamforming and Compression  Problem in the Cooperative Cellular Network via Lagrangian Duality",
    "abstract": "Consider the joint beamforming and quantization problem in the cooperative\ncellular network, where multiple relay-like base stations (BSs) connected to\nthe central processor (CP) via rate-limited fronthaul links cooperatively serve\nthe users. This problem can be formulated as the minimization of the total\ntransmit power, subject to all users' signal-to-interference-plus-noise-ratio\n(SINR) constraints and all relay-like BSs' fronthaul rate constraints. In this\npaper, we first show that there is no duality gap between the considered\nproblem and its Lagrangian dual by showing the tightness of the semidefinite\nrelaxation (SDR) of the considered problem. Then we propose an efficient\nalgorithm based on Lagrangian duality for solving the considered problem. The\nproposed algorithm judiciously exploits the special structure of the\nKarush-Kuhn-Tucker (KKT) conditions of the considered problem and finds the\nsolution that satisfies the KKT conditions via two fixed-point iterations. The\nproposed algorithm is highly efficient (as evaluating the functions in both\nfixed-point iterations are computationally cheap) and is guaranteed to find the\nglobal solution of the problem. Simulation results show the efficiency and the\ncorrectness of the proposed algorithm.",
    "descriptor": "\nComments: 5 pages, 1 figure, submitted to IEEE ICASSP 2022\n",
    "authors": [
      "Xilai Fan",
      "Ya-Feng Liu",
      "Liang Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.05085"
  },
  {
    "id": "arXiv:2110.05086",
    "title": "Deep Video Anomaly Detection: Opportunities and Challenges",
    "abstract": "Anomaly detection is a popular and vital task in various research contexts,\nwhich has been studied for several decades. To ensure the safety of people's\nlives and assets, video surveillance has been widely deployed in various public\nspaces, such as crossroads, elevators, hospitals, banks, and even in private\nhomes. Deep learning has shown its capacity in a number of domains, ranging\nfrom acoustics, images, to natural language processing. However, it is\nnon-trivial to devise intelligent video anomaly detection systems cause\nanomalies significantly differ from each other in different application\nscenarios. There are numerous advantages if such intelligent systems could be\nrealised in our daily lives, such as saving human resources in a large degree,\nreducing financial burden on the government, and identifying the anomalous\nbehaviours timely and accurately. Recently, many studies on extending deep\nlearning models for solving anomaly detection problems have emerged, resulting\nin beneficial advances in deep video anomaly detection techniques. In this\npaper, we present a comprehensive review of deep learning-based methods to\ndetect the video anomalies from a new perspective. Specifically, we summarise\nthe opportunities and challenges of deep learning models on video anomaly\ndetection tasks, respectively. We put forth several potential future research\ndirections of intelligent video anomaly detection system in various application\ndomains. Moreover, we summarise the characteristics and technical problems in\ncurrent deep learning methods for video anomaly detection.",
    "descriptor": "\nComments: 8 pages, 2 figures\n",
    "authors": [
      "Jing Ren",
      "Feng Xia",
      "Yemeng Liu",
      "Ivan Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.05086"
  },
  {
    "id": "arXiv:2110.05087",
    "title": "A Multi-Resolution Front-End for End-to-End Speech Anti-Spoofing",
    "abstract": "The choice of an optimal time-frequency resolution is usually a difficult but\nimportant step in tasks involving speech signal classification, e.g., speech\nanti-spoofing. The variations of the performance with different choices of\ntimefrequency resolutions can be as large as those with different model\narchitectures, which makes it difficult to judge what the improvement actually\ncomes from when a new network architecture is invented and introduced as the\nclassifier. In this paper, we propose a multi-resolution front-end for feature\nextraction in an end-to-end classification framework. Optimal weighted\ncombinations of multiple time-frequency resolutions will be learned\nautomatically given the objective of a classification task. Features extracted\nwith different time-frequency resolutions are weighted and concatenated as\ninputs to the successive networks, where the weights are predicted by a\nlearnable neural network inspired by the weighting block in\nsqueeze-and-excitation networks (SENet). Furthermore, the refinement of the\nchosen timefrequency resolutions is investigated by pruning the ones with\nrelatively low importance, which reduces the complexity and size of the model.\nThe proposed method is evaluated on the tasks of speech anti-spoofing in\nASVSpoof 2019 and its superiority has been justified by comparing with similar\nbaselines.",
    "descriptor": "\nComments: submitted to ICASSP 2022\n",
    "authors": [
      "Wei Liu",
      "Meng Sun",
      "Xiongwei Zhang",
      "Hugo Van hamme",
      "Thomas Fang Zheng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05087"
  },
  {
    "id": "arXiv:2110.05088",
    "title": "Privacy-Preserving Multiparty Protocol for Feature Selection Problem",
    "abstract": "In this paper, we propose a secure multiparty protocol for the feature\nselection problem. Let $D$ be the set of data, $F$ the set of features, and $C$\nthe set of classes, where the feature value $x(F_i)$ and the class $x(C)$ are\ngiven for each $x\\in D$ and $F_i \\in F$. For a triple $(D,F,C)$, the feature\nselection problem is to find a consistent and minimal subset $F' \\subseteq F$,\nwhere `consistent' means that, for any $x,y\\in D$, $x(C)=y(C)$ if\n$x(F_i)=y(F_i)$ for $F_i\\in F'$, and `minimal' means that any proper subset of\n$F'$ is no longer consistent. The feature selection problem corresponds to\nfinding a succinct description of $D$, and has various applications in the\nfield of artificial intelligence. In this study, we extend this problem to\nprivacy-preserving computation model for multiple users. We propose the first\nalgorithm for the privacy-preserving feature selection problem based on the\nfully homomorphic encryption. When parties $A$ and $B$ possess their own\npersonal data $D_A$ and $D_B$, they jointly compute the feature selection\nproblem for the entire data set $D_A\\cup D_B$ without revealing their privacy\nunder the \\em{semi-honest} model.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Shinji Ono",
      "Jun Takata",
      "Masaharu Kataoka",
      "Tomohiro I",
      "Kilho Shin",
      "Hiroshi Sakamoto"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.05088"
  },
  {
    "id": "arXiv:2110.05089",
    "title": "Feature Selection for Recommender Systems with Quantum Computing",
    "abstract": "The promise of quantum computing to open new unexplored possibilities in\nseveral scientific fields has been long discussed, but until recently the lack\nof a functional quantum computer has confined this discussion mostly to\ntheoretical algorithmic papers. It was only in the last few years that small\nbut functional quantum computers have become available to the broader research\ncommunity. One paradigm in particular, quantum annealing, can be used to sample\noptimal solutions for a number of NP-hard optimization problems represented\nwith classical operations research tools, providing an easy access to the\npotential of this emerging technology. One of the tasks that most naturally\nfits in this mathematical formulation is feature selection. In this paper, we\ninvestigate how to design a hybrid feature selection algorithm for recommender\nsystems that leverages the domain knowledge and behavior hidden in the user\ninteractions data. We represent the feature selection as an optimization\nproblem and solve it on a real quantum computer, provided by D-Wave. The\nresults indicate that the proposed approach is effective in selecting a limited\nset of important features and that quantum computers are becoming powerful\nenough to enter the wider realm of applied science.",
    "descriptor": "",
    "authors": [
      "Riccardo Nembrini",
      "Maurizio Ferrari Dacrema",
      "Paolo Cremonesi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.05089"
  },
  {
    "id": "arXiv:2110.05092",
    "title": "Adaptively Multi-view and Temporal Fusing Transformer for 3D Human Pose  Estimation",
    "abstract": "In practical application, 3D Human Pose Estimation (HPE) is facing with\nseveral variable elements, involving the number of views, the length of the\nvideo sequence, and whether using camera calibration. To this end, we propose a\nunified framework named Multi-view and Temporal Fusing Transformer\n(MTF-Transformer) to adaptively handle varying view numbers and video length\nwithout calibration. MTF-Transformer consists of Feature Extractor, Multi-view\nFusing Transformer (MFT), and Temporal Fusing Transformer (TFT). Feature\nExtractor estimates the 2D pose from each image and encodes the predicted\ncoordinates and confidence into feature embedding for further 3D pose\ninference. It discards the image features and focuses on lifting the 2D pose\ninto the 3D pose, making the subsequent modules computationally lightweight\nenough to handle videos. MFT fuses the features of a varying number of views\nwith a relative-attention block. It adaptively measures the implicit\nrelationship between each pair of views and reconstructs the features. TFT\naggregates the features of the whole sequence and predicts 3D pose via a\ntransformer, which is adaptive to the length of the video and takes full\nadvantage of the temporal information. With these modules, MTF-Transformer\nhandles different application scenes, varying from a monocular-single-image to\nmulti-view-video, and the camera calibration is avoidable. We demonstrate\nquantitative and qualitative results on the Human3.6M, TotalCapture, and KTH\nMultiview Football II. Compared with state-of-the-art methods with camera\nparameters, experiments show that MTF-Transformer not only obtains comparable\nresults but also generalizes well to dynamic capture with an arbitrary number\nof unseen views. Code is available in\nhttps://github.com/lelexx/MTF-Transformer.",
    "descriptor": "",
    "authors": [
      "Hui Shuai",
      "Lele Wu",
      "Qingshan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05092"
  },
  {
    "id": "arXiv:2110.05096",
    "title": "Density-Based Clustering with Kernel Diffusion",
    "abstract": "Finding a suitable density function is essential for density-based clustering\nalgorithms such as DBSCAN and DPC. A naive density corresponding to the\nindicator function of a unit $d$-dimensional Euclidean ball is commonly used in\nthese algorithms. Such density suffers from capturing local features in complex\ndatasets. To tackle this issue, we propose a new kernel diffusion density\nfunction, which is adaptive to data of varying local distributional\ncharacteristics and smoothness. Furthermore, we develop a surrogate that can be\nefficiently computed in linear time and space and prove that it is\nasymptotically equivalent to the kernel diffusion density function. Extensive\nempirical experiments on benchmark and large-scale face image datasets show\nthat the proposed approach not only achieves a significant improvement over\nclassic density-based clustering algorithms but also outperforms the\nstate-of-the-art face clustering methods by a large margin.",
    "descriptor": "",
    "authors": [
      "Chao Zheng",
      "Yingjie Chen",
      "Chong Chen",
      "Jianqiang Huang",
      "Xian-Sheng Hua"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05096"
  },
  {
    "id": "arXiv:2110.05098",
    "title": "SurroundNet: Towards Effective Low-Light Image Enhancement",
    "abstract": "Although Convolution Neural Networks (CNNs) has made substantial progress in\nthe low-light image enhancement task, one critical problem of CNNs is the\nparadox of model complexity and performance. This paper presents a novel\nSurroundNet which only involves less than 150$K$ parameters (about 80-98\npercent size reduction compared to SOTAs) and achieves very competitive\nperformance. The proposed network comprises several Adaptive Retinex Blocks\n(ARBlock), which can be viewed as a novel extension of Single Scale Retinex in\nfeature space. The core of our ARBlock is an efficient illumination estimation\nfunction called Adaptive Surround Function (ASF). It can be regarded as a\ngeneral form of surround functions and be implemented by convolution layers. In\naddition, we also introduce a Low-Exposure Denoiser (LED) to smooth the\nlow-light image before the enhancement. We evaluate the proposed method on the\nreal-world low-light dataset. Experimental results demonstrate that the\nsuperiority of our submitted SurroundNet in both performance and network\nparameters against State-of-the-Art low-light image enhancement methods. Code\nis available at https: github.com/ouc-ocean-group/SurroundNet.",
    "descriptor": "",
    "authors": [
      "Fei Zhou",
      "Xin Sun",
      "Junyu Dong",
      "Haoran Zhao",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05098"
  },
  {
    "id": "arXiv:2110.05102",
    "title": "Multiple Object Trackers in OpenCV: A Benchmark",
    "abstract": "Object tracking is one of the most important and fundamental disciplines of\nComputer Vision. Many Computer Vision applications require specific object\ntracking capabilities, including autonomous and smart vehicles, video\nsurveillance, medical treatments, and many others. The OpenCV as one of the\nmost popular libraries for Computer Vision includes several hundred Computer\nVision algorithms. Object tracking tasks in the library can be roughly\nclustered in single and multiple object trackers. The library is widely used\nfor real-time applications, but there are a lot of unanswered questions such as\nwhen to use a specific tracker, how to evaluate its performance, and for what\nkind of objects will the tracker yield the best results? In this paper, we\nevaluate 7 trackers implemented in OpenCV against the MOT20 dataset. The\nresults are shown based on Multiple Object Tracking Accuracy (MOTA) and\nMultiple Object Tracking Precision (MOTP) metrics.",
    "descriptor": "\nComments: 6 pages, 5 figures, 4 tables\n",
    "authors": [
      "Na\u0111a Dardagan",
      "Adnan Br\u0111anin",
      "D\u017eemil D\u017eigal",
      "Amila Akagic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05102"
  },
  {
    "id": "arXiv:2110.05103",
    "title": "Achieving safe minimum circle circumnavigation around multiple targets:  a dynamic compensation approach",
    "abstract": "Minimum circle circumnavigation is proposed in this paper, which is of\nspecial value in target monitoring, capturing and/or attacking. In this paper,\na safe minimum circle circumnavigation of multiple targets based on bearing\nmeasurements is studied. In contrast with the traditional circumnavigation\nproblem, with the new pattern, one agent is able to enclose multiple targets\nalong a minimum circle with the desired enclosing distance and tangential\nspeed. To achieve the minimum circle circumnavigation, an algorithm including\ndynamic compensators and a control protocol is proposed, by which collision is\navoided between the agent and the multiple targets during the whole moving\nprocess. Moreover, the control protocol developed for a single agent is further\nextended to the scenarios of multiple agents by adding a coordination mechanism\ninto the tangential velocity term, which drives the agents to distribute evenly\non each expected circular orbit with the same radius or different radius.\nSimulations results illustrate the effectiveness of the proposed methods.",
    "descriptor": "\nComments: 30 pages,9 figures,27 references\n",
    "authors": [
      "Chao Wang",
      "Yingjing Shi",
      "Rui Li",
      "Yongduan Song"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.05103"
  },
  {
    "id": "arXiv:2110.05111",
    "title": "Dynamic Forecasting of Conversation Derailment",
    "abstract": "Online conversations can sometimes take a turn for the worse, either due to\nsystematic cultural differences, accidental misunderstandings, or mere malice.\nAutomatically forecasting derailment in public online conversations provides an\nopportunity to take early action to moderate it. Previous work in this space is\nlimited, and we extend it in several ways. We apply a pretrained language\nencoder to the task, which outperforms earlier approaches. We further\nexperiment with shifting the training paradigm for the task from a static to a\ndynamic one to increase the forecast horizon. This approach shows mixed\nresults: in a high-quality data setting, a longer average forecast horizon can\nbe achieved at the cost of a small drop in F1; in a low-quality data setting,\nhowever, dynamic training propagates the noise and is highly detrimental to\nperformance.",
    "descriptor": "\nComments: To appear at EMNLP 2021\n",
    "authors": [
      "Yova Kementchedjhieva",
      "Anders S\u00f8gaard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05111"
  },
  {
    "id": "arXiv:2110.05113",
    "title": "Learning High-Speed Flight in the Wild",
    "abstract": "Quadrotors are agile. Unlike most other machines, they can traverse extremely\ncomplex environments at high speeds. To date, only expert human pilots have\nbeen able to fully exploit their capabilities. Autonomous operation with\non-board sensing and computation has been limited to low speeds.\nState-of-the-art methods generally separate the navigation problem into\nsubtasks: sensing, mapping, and planning. While this approach has proven\nsuccessful at low speeds, the separation it builds upon can be problematic for\nhigh-speed navigation in cluttered environments. Indeed, the subtasks are\nexecuted sequentially, leading to increased processing latency and a\ncompounding of errors through the pipeline. Here we propose an end-to-end\napproach that can autonomously fly quadrotors through complex natural and\nman-made environments at high speeds, with purely onboard sensing and\ncomputation. The key principle is to directly map noisy sensory observations to\ncollision-free trajectories in a receding-horizon fashion. This direct mapping\ndrastically reduces processing latency and increases robustness to noisy and\nincomplete perception. The sensorimotor mapping is performed by a convolutional\nnetwork that is trained exclusively in simulation via privileged learning:\nimitating an expert with access to privileged information. By simulating\nrealistic sensor noise, our approach achieves zero-shot transfer from\nsimulation to challenging real-world environments that were never experienced\nduring training: dense forests, snow-covered terrain, derailed trains, and\ncollapsed buildings. Our work demonstrates that end-to-end policies trained in\nsimulation enable high-speed autonomous flight through challenging\nenvironments, outperforming traditional obstacle avoidance pipelines.",
    "descriptor": "\nComments: 16 pages (+7 supplementary)\n",
    "authors": [
      "Antonio Loquercio",
      "Elia Kaufmann",
      "Ren\u00e9 Ranftl",
      "Matthias M\u00fcller",
      "Vladlen Koltun",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.05113"
  },
  {
    "id": "arXiv:2110.05115",
    "title": "A Comprehensive Comparison of Word Embeddings in Event & Entity  Coreference Resolution",
    "abstract": "Coreference Resolution is an important NLP task and most state-of-the-art\nmethods rely on word embeddings for word representation. However, one issue\nthat has been largely overlooked in literature is that of comparing the\nperformance of different embeddings across and within families in this task.\nTherefore, we frame our study in the context of Event and Entity Coreference\nResolution (EvCR & EnCR), and address two questions : 1) Is there a trade-off\nbetween performance (predictive & run-time) and embedding size? 2) How do the\nembeddings' performance compare within and across families? Our experiments\nreveal several interesting findings. First, we observe diminishing returns in\nperformance with respect to embedding size. E.g. a model using solely a\ncharacter embedding achieves 86% of the performance of the largest model (Elmo,\nGloVe, Character) while being 1.2% of its size. Second, the larger model using\nmultiple embeddings learns faster overall despite being slower per epoch.\nHowever, it is still slower at test time. Finally, Elmo performs best on both\nEvCR and EnCR, while GloVe and FastText perform best in EvCR and EnCR\nrespectively.",
    "descriptor": "\nComments: 10 pages, 1 table,10 figures, to be published in Findings of EMNLP 2021\n",
    "authors": [
      "Judicael Poumay",
      "Ashwin Ittoo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05115"
  },
  {
    "id": "arXiv:2110.05116",
    "title": "Towards Explainable Real Estate Valuation via Evolutionary Algorithms",
    "abstract": "Human lives are increasingly influenced by algorithms, which therefore need\nto meet higher standards not only in accuracy but also with respect to\nexplainability. This is especially true for high-stakes areas such as real\nestate valuation, where algorithms decide over the price of one of the most\nvaluable objects one can own. Unfortunately, the methods applied there often\nexhibit a trade-off between accuracy and explainability.\nOn the one hand, there are explainable approaches such as case-based\nreasoning (CBR), where each decision is supported by specific previous cases.\nHowever, such methods are often wanting in accuracy. On the other hand, there\nare unexplainable machine learning approaches, which provide higher accuracy\nbut are not scrutable in their decision-making.\nIn this paper, we apply evolutionary algorithms (EAs) to close the\nperformance gap between explainable and unexplainable approaches. They yield\nsimilarity functions (used in CBR to find comparable cases), which are fitted\nto the data set at hand. As a consequence, CBR achieves higher accuracy than\nstate-of-the-art deep neural networks (DNNs), while maintaining its\ninterpretability and explainability. This holds true even when we fit the\nneural network architecture to the data using evolutionary architecture search.\nThese results stem from our empirical evaluation on a large data set of real\nestate offers from Japan, where we compare known similarity functions and DNN\narchitectures with their EA-improved counterparts. In our testing, DNNs\noutperform previous CBR approaches. However, with the EA-learned similarity\nfunction CBR is even more accurate than DNNs.",
    "descriptor": "",
    "authors": [
      "Sebastian Angrick",
      "Ben Bals",
      "Niko Hastrich",
      "Maximilian Kleissl",
      "Jonas Schmidt",
      "Vanja Dosko\u010d",
      "Maximilian Katzmann",
      "Louise Molitor",
      "Tobias Friedrich"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.05116"
  },
  {
    "id": "arXiv:2110.05118",
    "title": "Confidential Token-Based License Management",
    "abstract": "In a global economy with many competitive participants, licensing and\ntracking of 3D printed parts is desirable if not mandatory for many use-cases.\nWe investigate a blockchain-based approach, as blockchains provide many\nattractive features, like decentralized architecture and high security\nassurances. An often neglected aspect of the product life-cycle management is\nthe confidentiality of transactions to hide valuable business information from\ncompetitors. To solve the combined problem of trust and confidentiality, we\npresent a confidential licensing and tracking system which works on any\npublicly verifiable, token-based blockchain that supports tokens of different\ntypes representing licenses or attributes of parts. Together with the secure\nintegration of a unique eID in each part, our system provides an efficient,\nimmutable and authenticated transaction log scalable to thousands of\ntransactions per second. With our confidential Token-Based License Management\nsystem (cTLM), large industries such as automotive or aviation can license and\ntrace all parts confidentially.",
    "descriptor": "\nComments: To be published in the proceedings of the 2021 Workshop on Additive Manufacturing (3D Printing) Security (AMSec '21)\n",
    "authors": [
      "Felix Engelmann",
      "Jan Philip Speichert",
      "Ralf God",
      "Frank Kargl",
      "Christoph B\u00f6sch"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.05118"
  },
  {
    "id": "arXiv:2110.05119",
    "title": "An automated threshold Edge Drawing algorithm",
    "abstract": "Parameter choosing in classical edge detection algorithms can be a costly and\ncomplex task. Choosing the correct parameters can improve considerably the\nresulting edge-map. In this paper we present a version of Edge Drawing\nalgorithm in which we include an automated threshold choosing step. To better\nhighlight the effect of this additional step we use different first order\noperators in the algorithm. Visual and statistical results are presented to\nsustain the benefits of the proposed automated threshold scheme.",
    "descriptor": "",
    "authors": [
      "Ciprian Orhei",
      "Muguras Mocofan",
      "Silviu Vert",
      "Radu Vasiu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05119"
  },
  {
    "id": "arXiv:2110.05122",
    "title": "Pano-AVQA: Grounded Audio-Visual Question Answering on 360$^\\circ$  Videos",
    "abstract": "360$^\\circ$ videos convey holistic views for the surroundings of a scene. It\nprovides audio-visual cues beyond pre-determined normal field of views and\ndisplays distinctive spatial relations on a sphere. However, previous benchmark\ntasks for panoramic videos are still limited to evaluate the semantic\nunderstanding of audio-visual relationships or spherical spatial property in\nsurroundings. We propose a novel benchmark named Pano-AVQA as a large-scale\ngrounded audio-visual question answering dataset on panoramic videos. Using\n5.4K 360$^\\circ$ video clips harvested online, we collect two types of novel\nquestion-answer pairs with bounding-box grounding: spherical spatial relation\nQAs and audio-visual relation QAs. We train several transformer-based models\nfrom Pano-AVQA, where the results suggest that our proposed spherical spatial\nembeddings and multimodal training objectives fairly contribute to a better\nsemantic understanding of the panoramic surroundings on the dataset.",
    "descriptor": "\nComments: Published to ICCV2021\n",
    "authors": [
      "Heeseung Yun",
      "Youngjae Yu",
      "Wonsuk Yang",
      "Kangil Lee",
      "Gunhee Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05122"
  },
  {
    "id": "arXiv:2110.05125",
    "title": "Non-Parametric Neuro-Adaptive Coordination of Multi-Agent Systems",
    "abstract": "We develop a learning-based algorithm for the distributed formation control\nof networked multi-agent systems governed by unknown, nonlinear dynamics. Most\nexisting algorithms either assume certain parametric forms for the unknown\ndynamic terms or resort to unnecessarily large control inputs in order to\nprovide theoretical guarantees. The proposed algorithm avoids these drawbacks\nby integrating neural network-based learning with adaptive control in a\ntwo-step procedure. In the first step of the algorithm, each agent learns a\ncontroller, represented as a neural network, using training data that\ncorrespond to a collection of formation tasks and agent parameters. These\nparameters and tasks are derived by varying the nominal agent parameters and\nthe formation specifications of the task in hand, respectively. In the second\nstep of the algorithm, each agent incorporates the trained neural network into\nan online and adaptive control policy in such a way that the behavior of the\nmulti-agent closed-loop system satisfies a user-defined formation task. Both\nthe learning phase and the adaptive control policy are distributed, in the\nsense that each agent computes its own actions using only local information\nfrom its neighboring agents. The proposed algorithm does not use any a priori\ninformation on the agents' unknown dynamic terms or any approximation schemes.\nWe provide formal theoretical guarantees on the achievement of the formation\ntask.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2106.13498\n",
    "authors": [
      "Christos K. Verginis",
      "Zhe Xu",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05125"
  },
  {
    "id": "arXiv:2110.05128",
    "title": "REIN-2: Giving Birth to Prepared Reinforcement Learning Agents Using  Reinforcement Learning Agents",
    "abstract": "Deep Reinforcement Learning (Deep RL) has been in the spotlight for the past\nfew years, due to its remarkable abilities to solve problems which were\nconsidered to be practically unsolvable using traditional Machine Learning\nmethods. However, even state-of-the-art Deep RL algorithms have various\nweaknesses that prevent them from being used extensively within industry\napplications, with one such major weakness being their sample-inefficiency. In\nan effort to patch these issues, we integrated a meta-learning technique in\norder to shift the objective of learning to solve a task into the objective of\nlearning how to learn to solve a task (or a set of tasks), which we empirically\nshow that improves overall stability and performance of Deep RL algorithms. Our\nmodel, named REIN-2, is a meta-learning scheme formulated within the RL\nframework, the goal of which is to develop a meta-RL agent (meta-learner) that\nlearns how to produce other RL agents (inner-learners) that are capable of\nsolving given environments. For this task, we convert the typical interaction\nof an RL agent with the environment into a new, single environment for the\nmeta-learner to interact with. Compared to traditional state-of-the-art Deep RL\nalgorithms, experimental results show remarkable performance of our model in\npopular OpenAI Gym environments in terms of scoring and sample efficiency,\nincluding the Mountain Car hard-exploration environment.",
    "descriptor": "",
    "authors": [
      "Aristotelis Lazaridis",
      "Ioannis Vlahavas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05128"
  },
  {
    "id": "arXiv:2110.05129",
    "title": "Adaptive F-FFT Demodulation for ICI Mitigation in Differential  Underwater Acoustic OFDM Systems",
    "abstract": "This paper addresses the problem of frequency-domain inter-carrier\ninterference (ICI) mitigation for differential orthogonal frequency-division\nmultiplexing (OFDM) systems. The classical fractional fast Fourier transform\n(F-FFT), adopting the fixed sampling interval, would suffer from the limited\naccuracy of ICI mitigation and low adaptability in dynamic Doppler spread. To\ntarget the above challenges, we propose an adaptive fractional Fourier\ntransform (A-FFT) demodulation method, in which an estimation algorithm based\non the coordinate descent approach is designed to compute the fiducial\nfrequency offset without increasing pilots. By means of compensating ICI at\nfractions of the fiducial frequency offset adapted to the time-varying Doppler\nshift, the A-FFT has the capability of tracking Doppler fluctuations over the\nunderwater acoustic channels, thus extending the application range of\nfrequency-domain ICI mitigation. Simulation results show that the A-FFT is\nsignificantly superior to the existing classical methods, the partial fast\nFourier transform (P-FFT) and the F-FFT, for both medium and high Doppler\nfactors and large carrier numbers in terms of the mean squared error (MSE).\nNumerically, the MSE of the A-FFT is reduced by $\\bf{39.88\\%-72.14\\%}$ compared\nto that of the F-FFT with the input signal-to-noise ratio ranging from 10 dB to\n30 dB at a Doppler factor of $\\bf{2.5\\times 10^{-4}}$ and a carrier number of\n1024, while the P-FFT even cannot work well.",
    "descriptor": "\nComments: 6 pages, 5 figures, conference\n",
    "authors": [
      "Jihui Qiu",
      "Yuzhou Li",
      "Yunlong Huang",
      "Yimeng Wang",
      "Lingyu Gu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.05129"
  },
  {
    "id": "arXiv:2110.05132",
    "title": "The Center of Attention: Center-Keypoint Grouping via Attention for  Multi-Person Pose Estimation",
    "abstract": "We introduce CenterGroup, an attention-based framework to estimate human\nposes from a set of identity-agnostic keypoints and person center predictions\nin an image. Our approach uses a transformer to obtain context-aware embeddings\nfor all detected keypoints and centers and then applies multi-head attention to\ndirectly group joints into their corresponding person centers. While most\nbottom-up methods rely on non-learnable clustering at inference, CenterGroup\nuses a fully differentiable attention mechanism that we train end-to-end\ntogether with our keypoint detector. As a result, our method obtains\nstate-of-the-art performance with up to 2.5x faster inference time than\ncompeting bottom-up methods. Our code is available at\nhttps://github.com/dvl-tum/center-group .",
    "descriptor": "\nComments: Accepted to ICCV 2021; reports improved multi-scale results\n",
    "authors": [
      "Guillem Bras\u00f3",
      "Nikita Kister",
      "Laura Leal-Taix\u00e9"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05132"
  },
  {
    "id": "arXiv:2110.05133",
    "title": "Offensive Language Detection with BERT-based models, By Customizing  Attention Probabilities",
    "abstract": "This paper describes a novel study on using `Attention Mask' input in\ntransformers and using this approach for detecting offensive content in both\nEnglish and Persian languages. The paper's principal focus is to suggest a\nmethodology to enhance the performance of the BERT-based models on the\n`Offensive Language Detection' task. Therefore, we customize attention\nprobabilities by changing the `Attention Mask' input to create more efficacious\nword embeddings. To do this, we firstly tokenize the training set of the\nexploited datasets (by BERT tokenizer). Then, we apply Multinomial Naive Bayes\nto map these tokens to two probabilities. These probabilities indicate the\nlikelihood of making a text non-offensive or offensive, provided that it\ncontains that token. Afterwards, we use these probabilities to define a new\nterm, namely Offensive Score. Next, we create two separate (because of the\ndifferences in the types of the employed datasets) equations based on Offensive\nScores for each language to re-distribute the `Attention Mask' input for paying\nmore attention to more offensive phrases. Eventually, we put the F1-macro score\nas our evaluation metric and fine-tune several combinations of BERT with ANNs,\nCNNs and RNNs to examine the effect of using this methodology on various\ncombinations. The results indicate that all models will enhance with this\nmethodology. The most improvement was 2% and 10% for English and Persian\nlanguages, respectively.",
    "descriptor": "",
    "authors": [
      "Peyman Alavi",
      "Pouria Nikvand",
      "Mehrnoush Shamsfard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05133"
  },
  {
    "id": "arXiv:2110.05145",
    "title": "Sim2Air - Synthetic aerial dataset for UAV monitoring",
    "abstract": "In this paper we propose a novel approach to generate a synthetic aerial\ndataset for application in UAV monitoring. We propose to accentuate shape-based\nobject representation by applying texture randomization. A diverse dataset with\nphotorealism in all parameters such as shape, pose, lighting, scale, viewpoint,\netc. except for atypical textures is created in a 3D modelling software\nBlender. Our approach specifically targets two conditions in aerial images\nwhere texture of objects is difficult to detect, namely illumination changes\nand objects occupying only a small portion of the image. Experimental\nevaluation confirmed our approach by increasing the mAP value by 17 and 3.7\npoints on two test datasets of real images. In analysing domain similarity, we\nconclude that the more the generalisation capability is put to the test, the\nmore obvious are the advantages of the shape-based representation.",
    "descriptor": "",
    "authors": [
      "Antonella Barisic",
      "Frano Petric",
      "Stjepan Bogdan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.05145"
  },
  {
    "id": "arXiv:2110.05146",
    "title": "ViSeRet: A simple yet effective approach to moment retrieval via  fine-grained video segmentation",
    "abstract": "Video-text retrieval has many real-world applications such as media\nanalytics, surveillance, and robotics. This paper presents the 1st place\nsolution to the video retrieval track of the ICCV VALUE Challenge 2021. We\npresent a simple yet effective approach to jointly tackle two video-text\nretrieval tasks (video retrieval and video corpus moment retrieval) by\nleveraging the model trained only on the video retrieval task. In addition, we\ncreate an ensemble model that achieves the new state-of-the-art performance on\nall four datasets (TVr, How2r, YouCook2r, and VATEXr) presented in the VALUE\nChallenge.",
    "descriptor": "",
    "authors": [
      "Aiden Seungjoon Lee",
      "Hanseok Oh",
      "Minjoon Seo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05146"
  },
  {
    "id": "arXiv:2110.05148",
    "title": "Service Scheduling for Random Requests with Fixed Waiting Costs",
    "abstract": "We study service scheduling problems in a slotted system in which agents\narrive with service requests according to a Bernoulli process and have to leave\nwithin two slots after arrival, service costs are quadratic in service rates,\nand there are also waiting costs. We consider fixed waiting costs. We frame the\nproblems as average cost Markov decision processes. While the studied system is\na linear system with quadratic costs, it has state dependent control. Moreover,\nit also possesses a non-standard cost function structure in the case of fixed\nwaiting costs, rendering the optimization problem complex. Here, we\ncharacterize optimal policy. We also consider a system in which the agents make\nscheduling decisions for their respective service requests keeping their own\ncost in view. We again consider fixed waiting costs and frame this scheduling\nproblem as a stochastic game. Here, we provide Nash equilibrium.",
    "descriptor": "",
    "authors": [
      "Ramya Burra",
      "Chandramani Singh",
      "Joy Kuri"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.05148"
  },
  {
    "id": "arXiv:2110.05150",
    "title": "Human Values in Mobile App Development: An Empirical Study on  Bangladeshi Agriculture Mobile Apps",
    "abstract": "Given the ubiquity of mobile applications (apps) in daily lives,\nunderstanding and reflecting end-users' human values (e.g., transparency,\nprivacy, social recognition etc.) in apps has become increasingly important.\nViolations of end users' values by software applications have been reported in\nthe media and have resulted in a wide range of difficulties for end users.\nValue violations may bring more and lasting problems for marginalized and\nvulnerable groups of end-users. This research aims to understand the extent to\nwhich the values of Bangladeshi female farmers, marginalized and vulnerable\nend-users, who are less studied by the software engineering community, are\nreflected in agriculture apps in Bangladesh. Further to this, we aim to\nidentify possible strategies to embed their values in those apps. To this end,\nwe conducted a mixed-methods empirical study consisting of 13 interviews with\napp practitioners and four focus groups with 20 Bangladeshi female farmers. The\naccumulated results from the interviews and focus groups identified 22 values\nof Bangladeshi female farmers, which the participants expect to be reflected in\nthe agriculture apps. Among these 22 values, 15 values (e.g., accuracy,\nindependence) are already reflected and 7 values (e.g., accessibility,\npleasure) are ignored/violated in the existing agriculture apps. We also\nidentified 14 strategies (e.g., \"applying human-centered approaches to elicit\nvalues\", \"establishing a dedicated team/person for values concerns\") to address\nBangladeshi female farmers' values in agriculture apps.",
    "descriptor": "\nComments: 18 pages, 6 figures, Manuscript submitted to IEEE Transactions on Software Engineering (2021)\n",
    "authors": [
      "Rifat Ara Shams",
      "Mojtaba Shahin",
      "Gillian Oliver",
      "Jon Whittle",
      "Waqar Hussain",
      "Harsha Perera",
      "Arif Nurwidyantoro"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.05150"
  },
  {
    "id": "arXiv:2110.05151",
    "title": "WeTS: A Benchmark for Translation Suggestion",
    "abstract": "Translation Suggestion (TS), which provides alternatives for specific words\nor phrases given the entire documents translated by machine translation (MT)\n\\cite{lee2021intellicat}, has been proven to play a significant role in post\nediting (PE). However, there is still no publicly available data set to support\nin-depth research for this problem, and no reproducible experimental results\ncan be followed by researchers in this community. To break this limitation, we\ncreate a benchmark data set for TS, called \\emph{WeTS}, which contains golden\ncorpus annotated by expert translators on four translation directions. Apart\nfrom the human-annotated golden corpus, we also propose several novel methods\nto generate synthetic corpus which can substantially improve the performance of\nTS. With the corpus we construct, we introduce the Transformer-based model for\nTS, and experimental results show that our model achieves State-Of-The-Art\n(SOTA) results on all four translation directions, including English-to-German,\nGerman-to-English, Chinese-to-English and English-to-Chinese. Codes and corpus\ncan be found at \\url{https://github.com/ZhenYangIACAS/WeTS.git}.",
    "descriptor": "\nComments: Translation suggestion, Transformer\n",
    "authors": [
      "Zhen Yang",
      "Yingxue Zhang",
      "Ernan Li",
      "Fandong Meng",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05151"
  },
  {
    "id": "arXiv:2110.05153",
    "title": "Decentralized sliding-mode control laws for the bearing-based formation  tracking problem",
    "abstract": "This paper studies the time-varying bearing-based tracking of leader-follower\nformations. The desired constraints between agents are specified by bearing\nvectors, and several leaders are moving with a bounded reference velocity. Each\nfollowers can measure the relative positions of its neighbors, its own\nvelocities, and receive information from their neighbors. Under the assumptions\nthat the desired formation is infinitesimally bearing rigid and the local\nreference frames of followers are aligned with each other, two control laws are\npresented in this paper based on sliding mode control approach. Stability\nanalyses are given based on Lyapunov stability theory and supported by\nnumerical simulations.",
    "descriptor": "\nComments: Accepted to ICCAIS 2021\n",
    "authors": [
      "Dung Van Vu",
      "Minh Hoang Trinh"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.05153"
  },
  {
    "id": "arXiv:2110.05154",
    "title": "Privacy preserving local analysis of digital trace data: A  proof-of-concept",
    "abstract": "We present PORT, a software platform for local data extraction and analysis\nof digital trace data. While digital trace data collected by private and public\nparties hold a huge potential for social-scientific discovery, their most\nuseful parts have been unattainable for academic researchers due to privacy\nconcerns and prohibitive API access. However, the EU General Data Protection\nRegulation (GDPR) grants all citizens the right to an electronic copy of their\npersonal data. All major data controllers, such as social media platforms,\nbanks, online shops, loyalty card systems and public transportation cards\ncomply with this right by providing their clients with a `Data Download\nPackage' (DDP). Previously, a conceptual workflow was introduced allowing\ncitizens to donate their data to scientific- researchers. In this workflow,\ncitizens' DDPs are processed locally on their machines before they are asked to\nprovide informed consent to share a subset of the processed data with the\nresearchers. In this paper, we present the newly developed software PORT that\nimplements the local processing part of this workflow, protecting privacy by\nshielding sensitive data from any contact with outside observers -- including\nthe researchers themselves. Thus, PORT enables a host of potential applications\nof social data science to hitherto unobtainable data.",
    "descriptor": "",
    "authors": [
      "Laura Boeschoten",
      "Adri\u00ebnne Mendrik",
      "Emiel van der Veen",
      "Jeroen Vloothuis",
      "Haili Hu",
      "Roos Voorvaart",
      "Daniel Oberski"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.05154"
  },
  {
    "id": "arXiv:2110.05156",
    "title": "Beyond Desktop Computation: Challenges in Scaling a GPU Infrastructure",
    "abstract": "Enterprises and labs performing computationally expensive data science\napplications sooner or later face the problem of scale but unconnected\ninfrastructure. For this up-scaling process, an IT service provider can be\nhired or in-house personnel can attempt to implement a software stack. The\nfirst option can be quite expensive if it is just about connecting several\nmachines. For the latter option often experience is missing with the data\nscience staff in order to navigate through the software jungle. In this\ntechnical report, we illustrate the decision process towards an on-premises\ninfrastructure, our implemented system architecture, and the transformation of\nthe software stack towards a scaleable GPU cluster system.",
    "descriptor": "\nComments: 6 pages, 2 figures, to be published in Proceedings of the 4th International Data Science Conference - iDSC2021\n",
    "authors": [
      "Martin Uray",
      "Eduard Hirsch",
      "Gerold Katzinger",
      "Michael Gadermayr"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05156"
  },
  {
    "id": "arXiv:2110.05158",
    "title": "Can the brain use waves to solve planning problems?",
    "abstract": "A variety of behaviors like spatial navigation or bodily motion can be\nformulated as graph traversal problems through cognitive maps. We present a\nneural network model which can solve such tasks and is compatible with a broad\nrange of empirical findings about the mammalian neocortex and hippocampus. The\nneurons and synaptic connections in the model represent structures that can\nresult from self-organization into a cognitive map via Hebbian learning, i.e.\ninto a graph in which each neuron represents a point of some abstract\ntask-relevant manifold and the recurrent connections encode a distance metric\non the manifold. Graph traversal problems are solved by wave-like activation\npatterns which travel through the recurrent network and guide a localized peak\nof activity onto a path from some starting position to a target state.",
    "descriptor": "\nComments: 37 pages, 11 figures\n",
    "authors": [
      "Henry Powell",
      "Mathias Winkel",
      "Alexander V. Hopp",
      "Helmut Linde"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2110.05158"
  },
  {
    "id": "arXiv:2110.05159",
    "title": "Beyond Accuracy: A Consolidated Tool for Visual Question Answering  Benchmarking",
    "abstract": "On the way towards general Visual Question Answering (VQA) systems that are\nable to answer arbitrary questions, the need arises for evaluation beyond\nsingle-metric leaderboards for specific datasets. To this end, we propose a\nbrowser-based benchmarking tool for researchers and challenge organizers, with\nan API for easy integration of new models and datasets to keep up with the\nfast-changing landscape of VQA. Our tool helps test generalization capabilities\nof models across multiple datasets, evaluating not just accuracy, but also\nperformance in more realistic real-world scenarios such as robustness to input\nnoise. Additionally, we include metrics that measure biases and uncertainty, to\nfurther explain model behavior. Interactive filtering facilitates discovery of\nproblematic behavior, down to the data sample level. As proof of concept, we\nperform a case study on four models. We find that state-of-the-art VQA models\nare optimized for specific tasks or datasets, but fail to generalize even to\nother in-domain test sets, for example they cannot recognize text in images.\nOur metrics allow us to quantify which image and question embeddings provide\nmost robustness to a model. All code is publicly available.",
    "descriptor": "\nComments: 6.5 pages, 9 figures\n",
    "authors": [
      "Dirk V\u00e4th",
      "Pascal Tilli",
      "Ngoc Thang Vu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05159"
  },
  {
    "id": "arXiv:2110.05160",
    "title": "Spoki: Unveiling a New Wave of Scanners through a Reactive Network  Telescope",
    "abstract": "Large-scale Internet scans are a common method to identify victims of a\nspecific attack. Stateless scanning like in ZMap has been established as an\nefficient approach to probing at Internet scale. Stateless scans, however, need\na second phase to perform the attack, which remains invisible to network\ntelescopes that only capture the first incoming packet and is not observed as a\nrelated event by honeypots. In this work, we examine Internet-wide scan traffic\nthrough Spoki, a reactive network telescope operating in real-time that we\ndesign and implement. Spoki responds to asynchronous TCP SYN packets and\nengages in TCP handshakes initiated in the second phase of two-phase scans.\nBecause it is extremely lightweight it scales to large prefixes where it has\nthe unique opportunity to record the first data sequence submitted within the\nTCP handshake ACK. We analyze two-phase scanners during a three months period\nusing globally deployed Spoki reactive telescopes as well as flow data sets\nfrom IXPs and ISPs. We find that a predominant fraction of TCP SYNs on the\nInternet has irregular characteristics. Our findings also provide a clear\nsignature of today's scans as: (i) highly targeted, (ii) scanning activities\nnotably vary between regional vantage points, and (iii) a significant share\noriginates from malicious sources.",
    "descriptor": "\nComments: Proc. of 31st USENIX Security Symposium, camera-ready\n",
    "authors": [
      "Raphael Hiesgen",
      "Marcin Nawrocki",
      "Alistair King",
      "Alberto Dainotti",
      "Thomas C. Schmidt",
      "Matthias W\u00e4hlisch"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.05160"
  },
  {
    "id": "arXiv:2110.05162",
    "title": "Deploying Containerized QuantEx Quantum Simulation Software on HPC  Systems",
    "abstract": "The simulation of quantum circuits using the tensor network method is very\ncomputationally demanding and requires significant High Performance Computing\n(HPC) resources to find an efficient contraction order and to perform the\ncontraction of the large tensor networks. In addition, the researchers want a\nworkflow that is easy to customize, reproduce and migrate to different HPC\nsystems. In this paper, we discuss the issues associated with the deployment of\nthe QuantEX quantum computing simulation software within containers on\ndifferent HPC systems. Also, we compare the performance of the containerized\nsoftware with the software running on bare metal.",
    "descriptor": "",
    "authors": [
      "David Brayford",
      "John Brennan",
      "Momme Allalen",
      "Kenneth Hanley",
      "Luigi Iapichino",
      "Lee ORiordan",
      "Niall Moran"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.05162"
  },
  {
    "id": "arXiv:2110.05164",
    "title": "Ethical Assurance: A practical approach to the responsible design,  development, and deployment of data-driven technologies",
    "abstract": "This article offers several contributions to the interdisciplinary project of\nresponsible research and innovation in data science and AI. First, it provides\na critical analysis of current efforts to establish practical mechanisms for\nalgorithmic assessment, which are used to operationalise normative principles,\nsuch as sustainability, accountability, transparency, fairness, and\nexplainability, in order to identify limitations and gaps with the current\napproaches. Second, it provides an accessible introduction to the methodology\nof argument-based assurance, and explores how it is currently being applied in\nthe development of safety cases for autonomous and intelligent systems. Third,\nit generalises this method to incorporate wider ethical, social, and legal\nconsiderations, in turn establishing a novel version of argument-based\nassurance that we call 'ethical assurance'. Ethical assurance is presented as a\nstructured means for unifying the myriad practical mechanisms that have been\nproposed, as it is built upon a process-based form of project governance that\nsupports inclusive and participatory ethical deliberation while also remaining\ngrounded in social and technical realities. Finally, it sets an agenda for\nethical assurance, by detailing current challenges, open questions, and next\nsteps, which serve as a springboard to build an active (and interdisciplinary)\nresearch programme as well as contribute to ongoing discussions in policy and\ngovernance.",
    "descriptor": "",
    "authors": [
      "Christopher Burr",
      "David Leslie"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.05164"
  },
  {
    "id": "arXiv:2110.05165",
    "title": "Exchangeability-Aware Sum-Product Networks",
    "abstract": "Sum-Product Networks (SPNs) are expressive probabilistic models that provide\nexact, tractable inference. They achieve this efficiency by making used of\nlocal independence. On the other hand, mixtures of exchangeable variable models\n(MEVMs) are a class of tractable probabilistic models that make use of\nexchangeability of random variables to render inference tractable.\nExchangeability, which arises naturally in systems consisting of multiple,\ninterrelated entities, has not been considered for efficient representation and\ninference in SPNs yet. The contribution of this paper is a novel probabilistic\nmodel which we call Exchangeability-Aware Sum-Product Networks (XSPNs). It\ncontains both SPNs and MEVMs as special cases, and combines the ability of SPNs\nto efficiently learn deep probabilistic models with the ability of MEVMs to\nefficiently handle exchangeable random variables. We also introduce a structure\nlearning algorithm for XSPNs and empirically show that they can be more\naccurate and efficient than conventional SPNs when the data contains repeated,\ninterchangeable parts.",
    "descriptor": "",
    "authors": [
      "Stefan L\u00fcdtke",
      "Christian Bartelt",
      "Heiner Stuckenschmidt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.05165"
  },
  {
    "id": "arXiv:2110.05168",
    "title": "On Solving the Minimum Common String Partition Problem by Decision  Diagrams",
    "abstract": "In the Minimum Common String Partition Problem (MCSP), we are given two\nstrings on input, and we want to partition both into the same collection of\nsubstrings, minimizing the number of the substrings in the partition. This\ncombinatorial optimization problem has applications in computational biology\nand is NP-hard. Many different heuristic and exact methods exist for this\nproblem, such as a Greedy approach, Ant Colony Optimization, or Integer Linear\nProgramming. In this paper, we formulate the MCSP as a Dynamic Program and\ndevelop an exact solution algorithm based on Decision Diagrams for it. We also\nintroduce a restricted Decision Diagram that allows to compute heuristic\nsolutions to the MCSP and compare the quality of solution and runtime on\ninstances from literature with existing approaches. Our approach scales well\nand is suitable for heuristic solution of large-scale instances.",
    "descriptor": "\nComments: 11 pages, 2 tables, 5 graphs, submitted to ICORES'22\n",
    "authors": [
      "Milo\u0161 Chrom\u00fd",
      "Markus Sinnl"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.05168"
  },
  {
    "id": "arXiv:2110.05169",
    "title": "Learning a subspace of policies for online adaptation in Reinforcement  Learning",
    "abstract": "Deep Reinforcement Learning (RL) is mainly studied in a setting where the\ntraining and the testing environments are similar. But in many practical\napplications, these environments may differ. For instance, in control systems,\nthe robot(s) on which a policy is learned might differ from the robot(s) on\nwhich a policy will run. It can be caused by different internal factors (e.g.,\ncalibration issues, system attrition, defective modules) or also by external\nchanges (e.g., weather conditions). There is a need to develop RL methods that\ngeneralize well to variations of the training conditions. In this article, we\nconsider the simplest yet hard to tackle generalization setting where the test\nenvironment is unknown at train time, forcing the agent to adapt to the\nsystem's new dynamics. This online adaptation process can be computationally\nexpensive (e.g., fine-tuning) and cannot rely on meta-RL techniques since there\nis just a single train environment. To do so, we propose an approach where we\nlearn a subspace of policies within the parameter space. This subspace contains\nan infinite number of policies that are trained to solve the training\nenvironment while having different parameter values. As a consequence, two\npolicies in that subspace process information differently and exhibit different\nbehaviors when facing variations of the train environment. Our experiments\ncarried out over a large variety of benchmarks compare our approach with\nbaselines, including diversity-based methods. In comparison, our approach is\nsimple to tune, does not need any extra component (e.g., discriminator) and\nlearns policies able to gather a high reward on unseen environments.",
    "descriptor": "",
    "authors": [
      "Jean-Baptiste Gaya",
      "Laure Soulier",
      "Ludovic Denoyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05169"
  },
  {
    "id": "arXiv:2110.05170",
    "title": "Domain Adaptive Semantic Segmentation with Regional Contrastive  Consistency Regularization",
    "abstract": "Unsupervised domain adaptation (UDA) aims to bridge the domain shift between\nthe labeled source domain and the unlabeled target domain. However, most\nexisting works perform the global-level feature alignment for semantic\nsegmentation, while the local consistency between the regions has been largely\nneglected, and these methods are less robust to changing of outdoor\nenvironments. Motivated by the above facts, we propose a novel and fully\nend-to-end trainable approach, called regional contrastive consistency\nregularization (RCCR) for domain adaptive semantic segmentation. Our core idea\nis to pull the similar regional features extracted from the same location of\ndifferent images to be closer, and meanwhile push the features from the\ndifferent locations of the two images to be separated. We innovatively propose\nmomentum projector heads, where the teacher projector is the exponential moving\naverage of the student. Besides, we present a region-wise contrastive loss with\ntwo sampling strategies to realize effective regional consistency. Finally, a\nmemory bank mechanism is designed to learn more robust and stable region-wise\nfeatures under varying environments. Extensive experiments on two common UDA\nbenchmarks, i.e., GTAV to Cityscapes and SYNTHIA to Cityscapes, demonstrate\nthat our approach outperforms the state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Qianyu Zhou",
      "Chuyun Zhuang",
      "Xuequan Lu",
      "Lizhuang Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05170"
  },
  {
    "id": "arXiv:2110.05172",
    "title": "K-Wav2vec 2.0: Automatic Speech Recognition based on Joint Decoding of  Graphemes and Syllables",
    "abstract": "Wav2vec 2.0 is an end-to-end framework of self-supervised learning for speech\nrepresentation that is successful in automatic speech recognition (ASR), but\nmost of the work on the topic has been developed with a single language:\nEnglish. Therefore, it is unclear whether the self-supervised framework is\neffective in recognizing other languages with different writing systems, such\nas Korean which uses the Hangul having a unique writing system. In this paper,\nwe present K-Wav2Vec 2.0, which is a modified version of Wav2vec 2.0 designed\nfor Korean automatic speech recognition by exploring and optimizing various\nfactors of the original Wav2vec 2.0. In fine-tuning, we propose a multi-task\nhierarchical architecture to reflect the Korean writing structure. Moreover, a\njoint decoder is applied to alleviate the problem of words existing outside of\nthe vocabulary. In pre-training, we attempted the cross-lingual transfer of the\npre-trained model by further pre-training the English Wav2vec 2.0 on a Korean\ndataset, considering limited resources. Our experimental results demonstrate\nthat the proposed method yields the best performance on both Korean ASR\ndatasets: Ksponspeech (a large-scale Korean speech corpus) and Clovacall (a\ncall-based dialog corpus). Further pre-training is also effective in language\nadaptation, leading to large improvements without additional data.",
    "descriptor": "\nComments: 13 pages, 4 figures\n",
    "authors": [
      "Jounghee Kim",
      "Pilsung Kang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05172"
  },
  {
    "id": "arXiv:2110.05173",
    "title": "A Characterization of Totally Compatible Automata",
    "abstract": "Every function on a finite set defines an equivalence relation and,\ntherefore, a partition called the kernel of the function. Automata such that\nevery possible partition is the kernel of a word are called totally compatible.\nA characterization of such automata is given together with an algorithm to\nrecognize them in polynomial running time with respect to the number of states.",
    "descriptor": "",
    "authors": [
      "David Fernando Casas Torres"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.05173"
  },
  {
    "id": "arXiv:2110.05177",
    "title": "Learning Division with Neural Arithmetic Logic Modules",
    "abstract": "To achieve systematic generalisation, it first makes sense to master simple\ntasks such as arithmetic. Of the four fundamental arithmetic operations\n(+,-,$\\times$,$\\div$), division is considered the most difficult for both\nhumans and computers. In this paper we show that robustly learning division in\na systematic manner remains a challenge even at the simplest level of dividing\ntwo numbers. We propose two novel approaches for division which we call the\nNeural Reciprocal Unit (NRU) and the Neural Multiplicative Reciprocal Unit\n(NMRU), and present improvements for an existing division module, the Real\nNeural Power Unit (Real NPU). Experiments in learning division with input\nredundancy on 225 different training sets, find that our proposed modifications\nto the Real NPU obtains an average success of 85.3$\\%$ improving over the\noriginal by 15.1$\\%$. In light of the suggestion above, our NMRU approach can\nfurther improve the success to 91.6$\\%$.",
    "descriptor": "\nComments: 25 pages, 21 figures\n",
    "authors": [
      "Bhumika Mistry",
      "Katayoun Farrahi",
      "Jonathon Hare"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.05177"
  },
  {
    "id": "arXiv:2110.05178",
    "title": "Gradual Federated Learning with Simulated Annealing",
    "abstract": "Federated averaging (FedAvg) is a popular federated learning (FL) technique\nthat updates the global model by averaging local models and then transmits the\nupdated global model to devices for their local model update. One main\nlimitation of FedAvg is that the average-based global model is not necessarily\nbetter than local models in the early stage of the training process so that\nFedAvg might diverge in realistic scenarios, especially when the data is\nnon-identically distributed across devices and the number of data samples\nvaries significantly from device to device. In this paper, we propose a new FL\ntechnique based on simulated annealing. The key idea of the proposed technique,\nhenceforth referred to as \\textit{simulated annealing-based FL} (SAFL), is to\nallow a device to choose its local model when the global model is immature.\nSpecifically, by exploiting the simulated annealing strategy, we make each\ndevice choose its local model with high probability in early iterations when\nthe global model is immature. From extensive numerical experiments using\nvarious benchmark datasets, we demonstrate that SAFL outperforms the\nconventional FedAvg technique in terms of the convergence speed and the\nclassification accuracy.",
    "descriptor": "",
    "authors": [
      "Luong Trung Nguyen",
      "Junhan Kim",
      "Byonghyo Shim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05178"
  },
  {
    "id": "arXiv:2110.05182",
    "title": "TSG: Target-Selective Gradient Backprop for Probing CNN Visual Saliency",
    "abstract": "The explanation for deep neural networks has drawn extensive attention in the\ndeep learning community over the past few years. In this work, we study the\nvisual saliency, a.k.a. visual explanation, to interpret convolutional neural\nnetworks. Compared to iteration based saliency methods, single backward pass\nbased saliency methods benefit from faster speed and are widely used in\ndownstream visual tasks. Thus our work focuses on single backward pass\napproaches. However, existing methods in this category struggle to successfully\nproduce fine-grained saliency maps concentrating on specific target classes.\nThat said, producing faithful saliency maps satisfying both\ntarget-selectiveness and fine-grainedness using a single backward pass is a\nchallenging problem in the field. To mitigate this problem, we revisit the\ngradient flow inside the network, and find that the entangled semantics and\noriginal weights may disturb the propagation of target-relevant saliency.\nInspired by those observations, we propose a novel visual saliency framework,\ntermed Target-Selective Gradient (TSG) backprop, which leverages rectification\noperations to effectively emphasize target classes and further efficiently\npropagate the saliency to the input space, thereby generating target-selective\nand fine-grained saliency maps. The proposed TSG consists of two components,\nnamely, TSG-Conv and TSG-FC, which rectify the gradients for convolutional\nlayers and fully-connected layers, respectively. Thorough qualitative and\nquantitative experiments on ImageNet and Pascal VOC show that the proposed\nframework achieves more accurate and reliable results than other competitive\nmethods.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Image Processing\n",
    "authors": [
      "Lin Cheng",
      "Pengfei Fang",
      "Yanjie Liang",
      "Liao Zhang",
      "Chunhua Shen",
      "Hanzi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05182"
  },
  {
    "id": "arXiv:2110.05183",
    "title": "Dual Attention-Based Federated Learning for Wireless Traffic Prediction",
    "abstract": "Wireless traffic prediction is essential for cellular networks to realize\nintelligent network operations, such as load-aware resource management and\npredictive control. Existing prediction approaches usually adopt centralized\ntraining architectures and require the transferring of huge amounts of traffic\ndata, which may raise delay and privacy concerns for certain scenarios. In this\nwork, we propose a novel wireless traffic prediction framework named\n\\textit{Dual Attention-Based Federated Learning} (FedDA), by which a\nhigh-quality prediction model is trained collaboratively by multiple edge\nclients. To simultaneously capture the various wireless traffic patterns and\nkeep raw data locally, FedDA first groups the clients into different clusters\nby using a small augmentation dataset. Then, a quasi-global model is trained\nand shared among clients as prior knowledge, aiming to solve the statistical\nheterogeneity challenge confronted with federated learning. To construct the\nglobal model, a dual attention scheme is further proposed by aggregating the\nintra- and inter-cluster models, instead of simply averaging the weights of\nlocal models. We conduct extensive experiments on two real-world wireless\ntraffic datasets and results show that FedDA outperforms state-of-the-art\nmethods. The average mean squared error performance gains on the two datasets\nare up to 10\\% and 30\\%, respectively.",
    "descriptor": "\nComments: IEEE INFOCOM 2021 - IEEE Conference on Computer Communications\n",
    "authors": [
      "Chuanting Zhang",
      "Shuping Dang",
      "Basem Shihada",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.05183"
  },
  {
    "id": "arXiv:2110.05184",
    "title": "Solving Rep-tile by Computers: Performance of Solvers and Analyses of  Solutions",
    "abstract": "A rep-tile is a polygon that can be dissected into smaller copies (of the\nsame size) of the original polygon. A polyomino is a polygon that is formed by\njoining one or more unit squares edge to edge. These two notions were first\nintroduced and investigated by Solomon W. Golomb in the 1950s and popularized\nby Martin Gardner in the 1960s. Since then, dozens of studies have been made in\ncommunities of recreational mathematics and puzzles. In this study, we first\nfocus on the specific rep-tiles that have been investigated in these\ncommunities. Since the notion of rep-tiles is so simple that can be formulated\nmathematically in a natural way, we can apply a representative puzzle solver, a\nMIP solver, and SAT-based solvers for solving the rep-tile problem in common.\nIn comparing their performance, we can conclude that the puzzle solver is the\nweakest while the SAT-based solvers are the strongest in the context of simple\npuzzle solving. We then turn to analyses of the specific rep-tiles. Using some\nproperties of the rep-tile patterns found by a solver, we can complete analyses\nof specific rep-tiles up to certain sizes. That is, up to certain sizes, we can\ndetermine the existence of solutions, clarify the number of the solutions, or\nwe can enumerate all the solutions for each size. In the last case, we find new\nseries of solutions for the rep-tiles which have never been found in the\ncommunities.",
    "descriptor": "\nComments: 14 pages, 12 figures\n",
    "authors": [
      "Mutsunori Banbara",
      "Kenji Hashimoto",
      "Takashi Horiyama",
      "Shin-ichi Minato",
      "Kakeru Nakamura",
      "Masaaki Nishino",
      "Masahiko Sakai",
      "Ryuhei Uehara",
      "Yushi Uno",
      "Norihito Yasuda"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.05184"
  },
  {
    "id": "arXiv:2110.05185",
    "title": "Dynamic Binary Neural Network by learning channel-wise thresholds",
    "abstract": "Binary neural networks (BNNs) constrain weights and activations to +1 or -1\nwith limited storage and computational cost, which is hardware-friendly for\nportable devices. Recently, BNNs have achieved remarkable progress and been\nadopted into various fields. However, the performance of BNNs is sensitive to\nactivation distribution. The existing BNNs utilized the Sign function with\npredefined or learned static thresholds to binarize activations. This process\nlimits representation capacity of BNNs since different samples may adapt to\nunequal thresholds. To address this problem, we propose a dynamic BNN (DyBNN)\nincorporating dynamic learnable channel-wise thresholds of Sign function and\nshift parameters of PReLU. The method aggregates the global information into\nthe hyper function and effectively increases the feature expression ability.\nThe experimental results prove that our method is an effective and\nstraightforward way to reduce information loss and enhance performance of BNNs.\nThe DyBNN based on two backbones of ReActNet (MobileNetV1 and ResNet18) achieve\n71.2% and 67.4% top1-accuracy on ImageNet dataset, outperforming baselines by a\nlarge margin (i.e., 1.8% and 1.5% respectively).",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Jiehua Zhang",
      "Zhuo Su",
      "Yanghe Feng",
      "Xin Lu",
      "Matti Pietik\u00e4inen",
      "Li Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.05185"
  },
  {
    "id": "arXiv:2110.05186",
    "title": "A MultiModal Social Robot Toward Personalized Emotion Interaction",
    "abstract": "Human emotions are expressed through multiple modalities, including verbal\nand non-verbal information. Moreover, the affective states of human users can\nbe the indicator for the level of engagement and successful interaction,\nsuitable for the robot to use as a rewarding factor to optimize robotic\nbehaviors through interaction. This study demonstrates a multimodal human-robot\ninteraction (HRI) framework with reinforcement learning to enhance the robotic\ninteraction policy and personalize emotional interaction for a human user. The\ngoal is to apply this framework in social scenarios that can let the robots\ngenerate a more natural and engaging HRI framework.",
    "descriptor": "\nComments: Presented at AI-HRI symposium as part of AAAI-FSS 2021 (arXiv:2109.10836)\n",
    "authors": [
      "Baijun Xie",
      "Chung Hyuk Park"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05186"
  },
  {
    "id": "arXiv:2110.05187",
    "title": "Clustering Plotted Data by Image Segmentation",
    "abstract": "Clustering algorithms are one of the main analytical methods to detect\npatterns in unlabeled data. Existing clustering methods typically treat samples\nin a dataset as points in a metric space and compute distances to group\ntogether similar points. In this paper, we present a wholly different way of\nclustering points in 2-dimensional space, inspired by how humans cluster data:\nby training neural networks to perform instance segmentation on plotted data.\nOur approach, Visual Clustering, has several advantages over traditional\nclustering algorithms: it is much faster than most existing clustering\nalgorithms (making it suitable for very large datasets), it agrees strongly\nwith human intuition for clusters, and it is by default hyperparameter free\n(although additional steps with hyperparameters can be introduced for more\ncontrol of the algorithm). We describe the method and compare it to ten other\nclustering methods on synthetic data to illustrate its advantages and\ndisadvantages. We then demonstrate how our approach can be extended to higher\ndimensional data and illustrate its performance on real-world data. The\nimplementation of Visual Clustering is publicly available and can be applied to\nany dataset in a few lines of code.",
    "descriptor": "",
    "authors": [
      "Tarek Naous",
      "Srinjay Sarkar",
      "Abubakar Abid",
      "James Zou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05187"
  },
  {
    "id": "arXiv:2110.05188",
    "title": "A Theory of Tournament Representations",
    "abstract": "Real world tournaments are almost always intransitive. Recent works have\nnoted that parametric models which assume $d$ dimensional node representations\ncan effectively model intransitive tournaments. However, nothing is known about\nthe structure of the class of tournaments that arise out of any fixed $d$\ndimensional representations. In this work, we develop a novel theory for\nunderstanding parametric tournament representations. Our first contribution is\nto structurally characterize the class of tournaments that arise out of $d$\ndimensional representations. We do this by showing that these tournament\nclasses have forbidden configurations which must necessarily be union of flip\nclasses, a novel way to partition the set of all tournaments. We further\ncharacterise rank $2$ tournaments completely by showing that the associated\nforbidden flip class contains just $2$ tournaments. Specifically, we show that\nthe rank $2$ tournaments are equivalent to locally-transitive tournaments. This\ninsight allows us to show that the minimum feedback arc set problem on this\ntournament class can be solved using the standard Quicksort procedure. For a\ngeneral rank $d$ tournament class, we show that the flip class associated with\na coned-doubly regular tournament of size $\\mathcal{O}(\\sqrt{d})$ must be a\nforbidden configuration. To answer a dual question, using a celebrated result\nof \\cite{forster}, we show a lower bound of $\\mathcal{O}(\\sqrt{n})$ on the\nminimum dimension needed to represent all tournaments on $n$ nodes. For any\ngiven tournament, we show a novel upper bound on the smallest representation\ndimension that depends on the least size of the number of unique nodes in any\nfeedback arc set of the flip class associated with a tournament. We show how\nour results also shed light on upper bound of sign-rank of matrices.",
    "descriptor": "\nComments: 13 pages, 3 figures\n",
    "authors": [
      "Arun Rajkumar",
      "Vishnu Veerathu",
      "Abdul Bakey Mir"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05188"
  },
  {
    "id": "arXiv:2110.05192",
    "title": "Convex-Concave Min-Max Stackelberg Games",
    "abstract": "Min-max optimization problems (i.e., min-max games) have been attracting a\ngreat deal of attention because of their applicability to a wide range of\nmachine learning problems. Although significant progress has been made\nrecently, the literature to date has focused on games with independent strategy\nsets; little is known about solving games with dependent strategy sets, which\ncan be characterized as min-max Stackelberg games. We introduce two first-order\nmethods that solve a large class of convex-concave min-max Stackelberg games,\nand show that our methods converge in polynomial time. Min-max Stackelberg\ngames were first studied by Wald, under the posthumous name of Wald's maximin\nmodel, a variant of which is the main paradigm used in robust optimization,\nwhich means that our methods can likewise solve many convex robust optimization\nproblems. We observe that the computation of competitive equilibria in Fisher\nmarkets also comprises a min-max Stackelberg game. Further, we demonstrate the\nefficacy and efficiency of our algorithms in practice by computing competitive\nequilibria in Fisher markets with varying utility structures. Our experiments\nsuggest potential ways to extend our theoretical results, by demonstrating how\ndifferent smoothness properties can affect the convergence rate of our\nalgorithms.",
    "descriptor": "\nComments: 25 pages, 4 tables, 1 figure, Forthcoming in NeurIPS 2021\n",
    "authors": [
      "Denizalp Goktas",
      "Amy Greenwald"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05192"
  },
  {
    "id": "arXiv:2110.05201",
    "title": "Performance Analysis of Fractional Learning Algorithms",
    "abstract": "Fractional learning algorithms are trending in signal processing and adaptive\nfiltering recently. However, it is unclear whether the proclaimed superiority\nover conventional algorithms is well-grounded or is a myth as their performance\nhas never been extensively analyzed. In this article, a rigorous analysis of\nfractional variants of the least mean squares and steepest descent algorithms\nis performed. Some critical schematic kinks in fractional learning algorithms\nare identified. Their origins and consequences on the performance of the\nlearning algorithms are discussed and swift ready-witted remedies are proposed.\nApposite numerical experiments are conducted to discuss the convergence and\nefficiency of the fractional learning algorithms in stochastic environments.",
    "descriptor": "\nComments: 29 pages, 6 figures\n",
    "authors": [
      "Abdul Wahab",
      "Shujaat Khan",
      "Imran Naseem",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.05201"
  },
  {
    "id": "arXiv:2110.05203",
    "title": "Tracking of stabilizing, optimal control in fixed-time based on  time-varying objective function",
    "abstract": "The controller of an input-affine system is determined through minimizing a\ntime-varying objective function, where stabilization is ensured via a Lyapunov\nfunction decay condition as constraint. This constraint is incorporated into\nthe objective function via a barrier function. The time-varying minimum of the\nresulting relaxed cost function is determined by a tracking system. This system\nis constructed using derivatives up to second order of the relaxed cost\nfunction and improves the existing approaches in time-varying optimization.\nUnder some mild assumptions, the tracking system yields a solution which is\nfeasible for all times, and it converges to the optimal solution of the relaxed\nobjective function in a user-defined fixed-time. The effectiveness of these\nresults in comparison to exponential convergence is demonstrated in a case\nstudy.",
    "descriptor": "\nComments: 6 pages, 4 figures, accepted for IEEE CDC 2021\n",
    "authors": [
      "Patrick Schmidt",
      "Thomas G\u00f6hrt",
      "Stefan Streif"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.05203"
  },
  {
    "id": "arXiv:2110.05204",
    "title": "CLIP4Caption ++: Multi-CLIP for Video Caption",
    "abstract": "This report describes our solution to the VALUE Challenge 2021 in the\ncaptioning task. Our solution, named CLIP4Caption++, is built on\nX-Linear/X-Transformer, which is an advanced model with encoder-decoder\narchitecture. We make the following improvements on the proposed\nCLIP4Caption++: We employ an advanced encoder-decoder model architecture\nX-Transformer as our main framework and make the following improvements: 1) we\nutilize three strong pre-trained CLIP models to extract the text-related\nappearance visual features. 2) we adopt the TSN sampling strategy for data\nenhancement. 3) we involve the video subtitle information to provide richer\nsemantic information. 3) we introduce the subtitle information, which fuses\nwith the visual features as guidance. 4) we design word-level and\nsentence-level ensemble strategies. Our proposed method achieves 86.5, 148.4,\n64.5 CIDEr scores on VATEX, YC2C, and TVC datasets, respectively, which shows\nthe superior performance of our proposed CLIP4Caption++ on all three datasets.",
    "descriptor": "\nComments: 4 pages, VALUE Challenge 2021 captioning task chamionship solution\n",
    "authors": [
      "Mingkang Tang",
      "Zhanyu Wang",
      "Zhaoyang Zeng",
      "Fengyun Rao",
      "Dian Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05204"
  },
  {
    "id": "arXiv:2110.05205",
    "title": "Navigation In Urban Environments Amongst Pedestrians Using  Multi-Objective Deep Reinforcement Learning",
    "abstract": "Urban autonomous driving in the presence of pedestrians as vulnerable road\nusers is still a challenging and less examined research problem. This work\nformulates navigation in urban environments as a multi objective reinforcement\nlearning problem. A deep learning variant of thresholded lexicographic\nQ-learning is presented for autonomous navigation amongst pedestrians. The\nmulti objective DQN agent is trained on a custom urban environment developed in\nCARLA simulator. The proposed method is evaluated by comparing it with a single\nobjective DQN variant on known and unknown environments. Evaluation results\nshow that the proposed method outperforms the single objective DQN variant with\nrespect to all aspects.",
    "descriptor": "",
    "authors": [
      "Niranjan Deshpande",
      "Dominique Vaufreydaz",
      "Anne Spalanzani"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.05205"
  },
  {
    "id": "arXiv:2110.05208",
    "title": "Supervision Exists Everywhere: A Data Efficient Contrastive  Language-Image Pre-training Paradigm",
    "abstract": "Recently, large-scale Contrastive Language-Image Pre-training (CLIP) has\nattracted unprecedented attention for its impressive zero-shot recognition\nability and excellent transferability to downstream tasks. However, CLIP is\nquite data-hungry and requires 400M image-text pairs for pre-training, thereby\nrestricting its adoption. This work proposes a novel training paradigm, Data\nefficient CLIP (DeCLIP), to alleviate this limitation. We demonstrate that by\ncarefully utilizing the widespread supervision among the image-text pairs, our\nDe-CLIP can learn generic visual features more efficiently. Instead of using\nthe single image-text contrastive supervision, we fully exploit data potential\nthrough the use of (1) self-supervision within each modality; (2) multi-view\nsupervision across modalities; (3) nearest-neighbor supervision from other\nsimilar pairs. Benefiting from intrinsic supervision, our DeCLIP-ResNet50 can\nachieve 60.4% zero-shot top1 accuracy on ImageNet, which is 0.8% above the\nCLIP-ResNet50 while using 7.1 x fewer data. Our DeCLIP-ResNet50 outperforms its\ncounterpart in 8 out of 11 visual datasets when transferred to downstream\ntasks. Moreover, Scaling up the model and computing also works well in our\nframework.Our code, dataset and models are released at:\nhttps://github.com/Sense-GVT/DeCLIP",
    "descriptor": "\nComments: 18 pages, 10 figures\n",
    "authors": [
      "Yangguang Li",
      "Feng Liang",
      "Lichen Zhao",
      "Yufeng Cui",
      "Wanli Ouyang",
      "Jing Shao",
      "Fengwei Yu",
      "Junjie Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05208"
  },
  {
    "id": "arXiv:2110.05213",
    "title": "It is Not as Good as You Think! Evaluating Simultaneous Machine  Translation on Interpretation Data",
    "abstract": "Most existing simultaneous machine translation (SiMT) systems are trained and\nevaluated on offline translation corpora. We argue that SiMT systems should be\ntrained and tested on real interpretation data. To illustrate this argument, we\npropose an interpretation test set and conduct a realistic evaluation of SiMT\ntrained on offline translations. Our results, on our test set along with 3\nexisting smaller scale language pairs, highlight the difference of up-to 13.83\nBLEU score when SiMT models are evaluated on translation vs interpretation\ndata. In the absence of interpretation training data, we propose a\ntranslation-to-interpretation (T2I) style transfer method which allows\nconverting existing offline translations into interpretation-style data,\nleading to up-to 2.8 BLEU improvement. However, the evaluation gap remains\nnotable, calling for constructing large-scale interpretation corpora better\nsuited for evaluating and developing SiMT systems.",
    "descriptor": "\nComments: EMNLP2021\n",
    "authors": [
      "Jinming Zhao",
      "Philip Arthur",
      "Gholamreza Haffari",
      "Trevor Cohn",
      "Ehsan Shareghi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05213"
  },
  {
    "id": "arXiv:2110.05216",
    "title": "High-order Tensor Pooling with Attention for Action Recognition",
    "abstract": "We aim at capturing high-order statistics of feature vectors formed by a\nneural network, and propose end-to-end second- and higher-order pooling to form\na tensor descriptor. Tensor descriptors require a robust similarity measure due\nto low numbers of aggregated vectors and the burstiness phenomenon, when a\ngiven feature appears more/less frequently than statistically expected. We show\nthat the Heat Diffusion Process (HDP) on a graph Laplacian is closely related\nto the Eigenvalue Power Normalization (EPN) of the covariance/auto-correlation\nmatrix, whose inverse forms a loopy graph Laplacian. We show that the HDP and\nthe EPN play the same role, i.e., to boost or dampen the magnitude of the\neigenspectrum thus preventing the burstiness. Finally, we equip higher-order\ntensors with EPN which acts as a spectral detector of higher-order occurrences\nto prevent burstiness. We prove that for a tensor of order r built from d\ndimensional feature descriptors, such a detector gives the likelihood if at\nleast one higher-order occurrence is `projected' into one of binom(d,r)\nsubspaces represented by the tensor; thus forming a tensor power normalization\nmetric endowed with binom(d,r) such `detectors'.",
    "descriptor": "",
    "authors": [
      "Piotr Koniusz",
      "Lei Wang",
      "Ke Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05216"
  },
  {
    "id": "arXiv:2110.05221",
    "title": "Multi-Task Learning for Situated Multi-Domain End-to-End Dialogue  Systems",
    "abstract": "Task-oriented dialogue systems have been a promising area in the NLP field.\nPrevious work showed the effectiveness of using a single GPT-2 based model to\npredict belief states and responses via causal language modeling. In this\npaper, we leverage multi-task learning techniques to train a GPT-2 based model\non a more challenging dataset with multiple domains, multiple modalities, and\nmore diversity in output formats.\nUsing only a single model, our method achieves better performance on all\nsub-tasks, across domains, compared to task and domain-specific models.\nFurthermore, we evaluated several proposed strategies for GPT-2 based dialogue\nsystems with comprehensive ablation studies, showing that all techniques can\nfurther improve the performance.",
    "descriptor": "",
    "authors": [
      "Po-Nien Kung",
      "Chung-Cheng Chang",
      "Tse-Hsuan Yang",
      "Hsin-Kai Hsu",
      "Yu-Jia Liou",
      "Yun-Nung Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05221"
  },
  {
    "id": "arXiv:2110.05223",
    "title": "Continual Learning with Differential Privacy",
    "abstract": "In this paper, we focus on preserving differential privacy (DP) in continual\nlearning (CL), in which we train ML models to learn a sequence of new tasks\nwhile memorizing previous tasks. We first introduce a notion of continual\nadjacent databases to bound the sensitivity of any data record participating in\nthe training process of CL. Based upon that, we develop a new DP-preserving\nalgorithm for CL with a data sampling strategy to quantify the privacy risk of\ntraining data in the well-known Averaged Gradient Episodic Memory (A-GEM)\napproach by applying a moments accountant. Our algorithm provides formal\nguarantees of privacy for data records across tasks in CL. Preliminary\ntheoretical analysis and evaluations show that our mechanism tightens the\nprivacy loss while maintaining a promising model utility.",
    "descriptor": "\nComments: The paper will appear at ICONIP21\n",
    "authors": [
      "Pradnya Desai",
      "Phung Lai",
      "NhatHai Phan",
      "My T. Thai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.05223"
  },
  {
    "id": "arXiv:2110.05228",
    "title": "Fast Attributed Graph Embedding via Density of States",
    "abstract": "Given a node-attributed graph, how can we efficiently represent it with few\nnumerical features that expressively reflect its topology and attribute\ninformation? We propose A-DOGE, for Attributed DOS-based Graph Embedding, based\non density of states (DOS, a.k.a. spectral density) to tackle this problem.\nA-DOGE is designed to fulfill a long desiderata of desirable characteristics.\nMost notably, it capitalizes on efficient approximation algorithms for DOS,\nthat we extend to blend in node labels and attributes for the first time,\nmaking it fast and scalable for large attributed graphs and graph databases.\nBeing based on the entire eigenspectrum of a graph, A-DOGE can capture\nstructural and attribute properties at multiple (\"glocal\") scales. Moreover, it\nis unsupervised (i.e. agnostic to any specific objective) and lends itself to\nvarious interpretations, which makes it is suitable for exploratory graph\nmining tasks. Finally, it processes each graph independent of others, making it\namenable for streaming settings as well as parallelization. Through extensive\nexperiments, we show the efficacy and efficiency of A-DOGE on exploratory graph\nanalysis and graph classification tasks, where it significantly outperforms\nunsupervised baselines and achieves competitive performance with modern\nsupervised GNNs, while achieving the best trade-off between accuracy and\nruntime.",
    "descriptor": "\nComments: ICDM 2021\n",
    "authors": [
      "Saurabh Sawlani",
      "Lingxiao Zhao",
      "Leman Akoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.05228"
  },
  {
    "id": "arXiv:2110.05239",
    "title": "Combining Image Features and Patient Metadata to Enhance Transfer  Learning",
    "abstract": "In this work, we compare the performance of six state-of-the-art deep neural\nnetworks in classification tasks when using only image features, to when these\nare combined with patient metadata. We utilise transfer learning from networks\npretrained on ImageNet to extract image features from the ISIC HAM10000 dataset\nprior to classification. Using several classification performance metrics, we\nevaluate the effects of including metadata with the image features.\nFurthermore, we repeat our experiments with data augmentation. Our results show\nan overall enhancement in performance of each network as assessed by all\nmetrics, only noting degradation in a vgg16 architecture. Our results indicate\nthat this performance enhancement may be a general property of deep networks\nand should be explored in other areas. Moreover, these improvements come at a\nnegligible additional cost in computation time, and therefore are a practical\nmethod for other applications.",
    "descriptor": "\nComments: paper has been accepted at the EMBC 2021 this https URL\n",
    "authors": [
      "Spencer A. Thomas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.05239"
  },
  {
    "id": "arXiv:2110.05240",
    "title": "Evaluating generative networks using Gaussian mixtures of image features",
    "abstract": "We develop a measure for evaluating the performance of generative networks\ngiven two sets of images. A popular performance measure currently used to do\nthis is the Fr\\'echet Inception Distance (FID). However, FID assumes that\nimages featurized using the penultimate layer of Inception-v3 follow a Gaussian\ndistribution. This assumption allows FID to be easily computed, since FID uses\nthe 2-Wasserstein distance of two Gaussian distributions fitted to the\nfeaturized images. However, we show that Inception-v3 features of the ImageNet\ndataset are not Gaussian; in particular, each marginal is not Gaussian. To\nremedy this problem, we model the featurized images using Gaussian mixture\nmodels (GMMs) and compute the 2-Wasserstein distance restricted to GMMs. We\ndefine a performance measure, which we call WaM, on two sets of images by using\nInception-v3 (or another classifier) to featurize the images, estimate two\nGMMs, and use the restricted 2-Wasserstein distance to compare the GMMs. We\nexperimentally show the advantages of WaM over FID, including how FID is more\nsensitive than WaM to image perturbations. By modelling the non-Gaussian\nfeatures obtained from Inception-v3 as GMMs and using a GMM metric, we can more\naccurately evaluate generative network performance.",
    "descriptor": "",
    "authors": [
      "Lorenzo Luzi",
      "Carlos Ortiz Marrero",
      "Nile Wynar",
      "Richard G. Baraniuk",
      "Michael J. Henry"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05240"
  },
  {
    "id": "arXiv:2110.05242",
    "title": "Accelerating Multi-Objective Neural Architecture Search by Random-Weight  Evaluation",
    "abstract": "For the goal of automated design of high-performance deep convolutional\nneural networks (CNNs), Neural Architecture Search (NAS) methodology is\nbecoming increasingly important for both academia and industries.Due to the\ncostly stochastic gradient descent (SGD) training of CNNs for performance\nevaluation, most existing NAS methods are computationally expensive for\nreal-world deployments. To address this issue, we first introduce a new\nperformance estimation metric, named Random-Weight Evaluation (RWE) to quantify\nthe quality of CNNs in a cost-efficient manner. Instead of fully training the\nentire CNN, the RWE only trains its last layer and leaves the remainders with\nrandomly initialized weights, which results in a single network evaluation in\nseconds.Second, a complexity metric is adopted for multi-objective NAS to\nbalance the model size and performance. Overall, our proposed method obtains a\nset of efficient models with state-of-the-art performance in two real-world\nsearch spaces. Then the results obtained on the CIFAR-10 dataset are\ntransferred to the ImageNet dataset to validate the practicality of the\nproposed algorithm. Moreover, ablation studies on NAS-Bench-301 datasets reveal\nthe effectiveness of the proposed RWE in estimating the performance compared\nwith existing methods.",
    "descriptor": "",
    "authors": [
      "Shengran Hu",
      "Ran Cheng",
      "Cheng He",
      "Zhichao Lu",
      "Jing Wang",
      "Miao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.05242"
  },
  {
    "id": "arXiv:2110.05261",
    "title": "Automatic Recall of Software Lessons Learned for Software Project  Managers",
    "abstract": "Lessons learned (LL) records constitute the software organization memory of\nsuccesses and failures. LL are recorded within the organization repository for\nfuture reference to optimize planning, gain experience, and elevate market\ncompetitiveness. However, manually searching this repository is a daunting\ntask, so it is often disregarded. This can lead to the repetition of previous\nmistakes or even missing potential opportunities. This, in turn, can negatively\naffect the profitability and competitiveness of organizations. We aim to\npresent a novel solution that provides an automatic process to recall relevant\nLL and to push those LL to project managers. This will dramatically save the\ntime and effort of manually searching the unstructured LL repositories and thus\nencourage the LL exploitation. We exploit existing project artifacts to build\nthe LL search queries on-the-fly in order to bypass the tedious manual\nsearching. An empirical case study is conducted to build the automatic LL\nrecall solution and evaluate its effectiveness. The study employs three of the\nmost popular information retrieval models to construct the solution.\nFurthermore, a real-world dataset of 212 LL records from 30 different software\nprojects is used for validation. Top-k and MAP well-known accuracy metrics are\nused as well. Our case study results confirm the effectiveness of the automatic\nLL recall solution. Also, the results prove the success of using existing\nproject artifacts to dynamically build the search query string. This is\nsupported by a discerning accuracy of about 70% achieved in the case of top-k.\nThe automatic LL recall solution is valid with high accuracy. It will eliminate\nthe effort needed to manually search the LL repository. Therefore, this will\npositively encourage project managers to reuse the available LL knowledge,\nwhich will avoid old pitfalls and unleash hidden business opportunities.",
    "descriptor": "",
    "authors": [
      "Tamer Mohamed Abdellatif",
      "Luiz Fernando Capretz",
      "Danny Ho"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.05261"
  },
  {
    "id": "arXiv:2110.05263",
    "title": "2021 Drexel Society of Artificial Intelligence Research Conference",
    "abstract": "The 2021 Drexel Society of Artificial Intelligence Research Conference\nhighlights papers focused on a broad set of papers in machine learning. This\nwas our organizations' first annual conference. It was conducted virtually via\nZoom. The highlights are currently posted on YouTube.",
    "descriptor": "\nComments: Six papers\n",
    "authors": [
      "Ethan Jacob Moyer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05263"
  },
  {
    "id": "arXiv:2110.05266",
    "title": "Chaos as an interpretable benchmark for forecasting and data-driven  modelling",
    "abstract": "The striking fractal geometry of strange attractors underscores the\ngenerative nature of chaos: like probability distributions, chaotic systems can\nbe repeatedly measured to produce arbitrarily-detailed information about the\nunderlying attractor. Chaotic systems thus pose a unique challenge to modern\nstatistical learning techniques, while retaining quantifiable mathematical\nproperties that make them controllable and interpretable as benchmarks. Here,\nwe present a growing database currently comprising 131 known chaotic dynamical\nsystems spanning fields such as astrophysics, climatology, and biochemistry.\nEach system is paired with precomputed multivariate and univariate time series.\nOur dataset has comparable scale to existing static time series databases;\nhowever, our systems can be re-integrated to produce additional datasets of\narbitrary length and granularity. Our dataset is annotated with known\nmathematical properties of each system, and we perform feature analysis to\nbroadly categorize the diverse dynamics present across the collection. Chaotic\nsystems inherently challenge forecasting models, and across extensive\nbenchmarks we correlate forecasting performance with the degree of chaos\npresent. We also exploit the unique generative properties of our dataset in\nseveral proof-of-concept experiments: surrogate transfer learning to improve\ntime series classification, importance sampling to accelerate model training,\nand benchmarking symbolic regression algorithms.",
    "descriptor": "\nComments: 10 pages, 4 figures, plus appendices\n",
    "authors": [
      "William Gilpin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2110.05266"
  },
  {
    "id": "arXiv:2110.05270",
    "title": "Investigating Transfer Learning Capabilities of Vision Transformers and  CNNs by Fine-Tuning a Single Trainable Block",
    "abstract": "In recent developments in the field of Computer Vision, a rise is seen in the\nuse of transformer-based architectures. They are surpassing the\nstate-of-the-art set by CNN architectures in accuracy but on the other hand,\nthey are computationally very expensive to train from scratch. As these models\nare quite recent in the Computer Vision field, there is a need to study it's\ntransfer learning capabilities and compare it with CNNs so that we can\nunderstand which architecture is better when applied to real world problems\nwith small data. In this work, we follow a simple yet restrictive method for\nfine-tuning both CNN and Transformer models pretrained on ImageNet1K on\nCIFAR-10 and compare them with each other. We only unfreeze the last\ntransformer/encoder or last convolutional block of a model and freeze all the\nlayers before it while adding a simple MLP at the end for classification. This\nsimple modification lets us use the raw learned weights of both these neural\nnetworks. From our experiments, we find out that transformers-based\narchitectures not only achieve higher accuracy than CNNs but some transformers\neven achieve this feat with around 4 times lesser number of parameters.",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Durvesh Malpure",
      "Onkar Litake",
      "Rajesh Ingle"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05270"
  },
  {
    "id": "arXiv:2110.05279",
    "title": "Sliced Mutual Information: A Scalable Measure of Statistical Dependence",
    "abstract": "Mutual information (MI) is a fundamental measure of statistical dependence,\nwith a myriad of applications to information theory, statistics, and machine\nlearning. While it possesses many desirable structural properties, the\nestimation of high-dimensional MI from samples suffers from the curse of\ndimensionality. Motivated by statistical scalability to high dimensions, this\npaper proposes \\emph{sliced} MI (SMI) as a surrogate measure of dependence. SMI\nis defined as an average of MI terms between one-dimensional random\nprojections. We show that it preserves many of the structural properties of\nclassic MI, while gaining scalable computation and efficient estimation from\nsamples. Furthermore, and in contrast to classic MI, SMI can grow as a result\nof deterministic transformations. This enables leveraging SMI for feature\nextraction by optimizing it over processing functions of raw data to identify\nuseful representations thereof. Our theory is supported by numerical studies of\nindependence testing and feature extraction, which demonstrate the potential\ngains SMI offers over classic MI for high-dimensional inference.",
    "descriptor": "",
    "authors": [
      "Ziv Goldfeld",
      "Kristjan Greenewald"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.05279"
  },
  {
    "id": "arXiv:2110.05280",
    "title": "Multi-institutional Validation of Two-Streamed Deep Learning Method for  Automated Delineation of Esophageal Gross Tumor Volume using planning-CT and  FDG-PETCT",
    "abstract": "Background: The current clinical workflow for esophageal gross tumor volume\n(GTV) contouring relies on manual delineation of high labor-costs and interuser\nvariability. Purpose: To validate the clinical applicability of a deep learning\n(DL) multi-modality esophageal GTV contouring model, developed at 1 institution\nwhereas tested at multiple ones. Methods and Materials: We collected 606\nesophageal cancer patients from four institutions. 252 institution-1 patients\nhad a treatment planning-CT (pCT) and a pair of diagnostic FDG-PETCT; 354\npatients from other 3 institutions had only pCT. A two-streamed DL model for\nGTV segmentation was developed using pCT and PETCT scans of a 148 patient\ninstitution-1 subset. This built model had the flexibility of segmenting GTVs\nvia only pCT or pCT+PETCT combined. For independent evaluation, the rest 104\ninstitution-1 patients behaved as unseen internal testing, and 354 institutions\n2-4 patients were used for external testing. We evaluated manual revision\ndegrees by human experts to assess the contour-editing effort. The performance\nof the deep model was compared against 4 radiation oncologists in a multiuser\nstudy with 20 random external patients. Contouring accuracy and time were\nrecorded for the pre-and post-DL assisted delineation process. Results: Our\nmodel achieved high segmentation accuracy in internal testing (mean Dice score:\n0.81 using pCT and 0.83 using pCT+PET) and generalized well to external\nevaluation (mean DSC: 0.80). Expert assessment showed that the predicted\ncontours of 88% patients need only minor or no revision. In multi-user\nevaluation, with the assistance of a deep model, inter-observer variation and\nrequired contouring time were reduced by 37.6% and 48.0%, respectively.\nConclusions: Deep learning predicted GTV contours were in close agreement with\nthe ground truth and could be adopted clinically with mostly minor or no\nchanges.",
    "descriptor": "\nComments: 36 pages, 10 figures\n",
    "authors": [
      "Xianghua Ye",
      "Dazhou Guo",
      "Chen-kan Tseng",
      "Jia Ge",
      "Tsung-Min Hung",
      "Ping-Ching Pai",
      "Yanping Ren",
      "Lu Zheng",
      "Xinli Zhu",
      "Ling Peng",
      "Ying Chen",
      "Xiaohua Chen",
      "Chen-Yu Chou",
      "Danni Chen",
      "Jiaze Yu",
      "Yuzhen Chen",
      "Feiran Jiao",
      "Yi Xin",
      "Lingyun Huang",
      "Guotong Xie",
      "Jing Xiao",
      "Le Lu",
      "Senxiang Yan",
      "Dakai Jin",
      "Tsung-Ying Ho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05280"
  },
  {
    "id": "arXiv:2110.05283",
    "title": "Phase Collapse in Neural Networks",
    "abstract": "Deep convolutional image classifiers progressively transform the spatial\nvariability into a smaller number of channels, which linearly separates all\nclasses. A fundamental challenge is to understand the role of rectifiers\ntogether with convolutional filters in this transformation. Rectifiers with\nbiases are often interpreted as thresholding operators which improve sparsity\nand discrimination. This paper demonstrates that it is a different phase\ncollapse mechanism which explains the ability to progressively eliminate\nspatial variability, while improving linear class separation. This is explained\nand shown numerically by defining a simplified complex-valued convolutional\nnetwork architecture. It implements spatial convolutions with wavelet filters\nand uses a complex modulus to collapse phase variables. This phase collapse\nnetwork reaches the classification accuracy of ResNets of similar depths,\nwhereas its performance is considerably degraded when replacing the phase\ncollapse with thresholding operators. This is justified by explaining how\niterated phase collapses progressively improve separation of class means, as\nopposed to thresholding non-linearities.",
    "descriptor": "\nComments: 14 pages, 1 figure\n",
    "authors": [
      "Florentin Guth",
      "John Zarka",
      "St\u00e9phane Mallat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.05283"
  },
  {
    "id": "arXiv:2110.05285",
    "title": "The Effects of Vehicle-to-Infrastructure Communication Reliability on  Performance of Signalized Intersection Traffic Control",
    "abstract": "A vehicle-to-infrastructure communication can inform an intersection\ncontroller about the location and speed of connected vehicles. Recently, the\ndesign of adaptive intersection control algorithms that take advantage of this\ninformation evoked a lot of research, typically assuming a perfect\ncommunication. In this study, we explore possible effects of a temporal\ndecrease in the reliability of the communication channel, on a throughput of a\nsignalized intersection. We model road traffic and DSRC-VANET communication by\nintegrating the well-established traffic and communication simulation tools\n(Vissim and OMNeT++). Comparisons of the perfect communication conditions with\nchallenging, but realistic conditions involving communication distortions show\nthat the adaptive intersection control may suffer from significantly increased\naverage delays of vehicles. The level of delays is largely independent of\nwhether the communication distortions affect all or only a single intersection\napproach. For some signal groups, the average vehicle delays are significantly\nincreased, while for the others they are decreased, leading to the disbalance\nand unfairness. We show that the data received in the previous time intervals\nand simple assumptions about the vehicle movements can be used to estimate the\nlost data. The compensation of the communication distortions affecting a single\nintersection approach decreases the average vehicle delays. When the\ncommunication distortions impacting all the intersection approaches are\ncompensated for, the vehicle delays are even set back to the levels comparable\nwith the perfect communication conditions. Overall, the results demonstrate\nthat the impact of the communication distortions should be considered in the\ndesign of the adaptive intersection control algorithms.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Ilya Finkelberg",
      "Tibor Petrov",
      "Ayelet Gal-Tzur",
      "Nina Zarkhin",
      "Peter Pocta",
      "Tatiana Kovacikova",
      "Lubos Buzna",
      "Milan Dado",
      "Tomer Toledo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.05285"
  },
  {
    "id": "arXiv:2110.05286",
    "title": "Learning from Ambiguous Demonstrations with Self-Explanation Guided  Reinforcement Learning",
    "abstract": "Our work aims at efficiently leveraging ambiguous demonstrations for the\ntraining of a reinforcement learning (RL) agent. An ambiguous demonstration can\nusually be interpreted in multiple ways, which severely hinders the RL-Agent\nfrom learning stably and efficiently. Since an optimal demonstration may also\nsuffer from being ambiguous, previous works that combine RL and learning from\ndemonstration (RLfD works) may not work well. Inspired by how humans handle\nsuch situations, we propose to use self-explanation (an agent generates\nexplanations for itself) to recognize valuable high-level relational features\nas an interpretation of why a successful trajectory is successful. This way,\nthe agent can provide some guidance for its RL learning. Our main contribution\nis to propose the Self-Explanation for RL from Demonstrations (SERLfD)\nframework, which can overcome the limitations of traditional RLfD works. Our\nexperimental results show that an RLfD model can be improved by using our\nSERLfD framework in terms of training stability and performance.",
    "descriptor": "",
    "authors": [
      "Yantian Zha",
      "Lin Guan",
      "Subbarao Kambhampati"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05286"
  },
  {
    "id": "arXiv:2110.05287",
    "title": "TEET! Tunisian Dataset for Toxic Speech Detection",
    "abstract": "The complete freedom of expression in social media has its costs especially\nin spreading harmful and abusive content that may induce people to act\naccordingly. Therefore, the need of detecting automatically such a content\nbecomes an urgent task that will help and enhance the efficiency in limiting\nthis toxic spread. Compared to other Arabic dialects which are mostly based on\nMSA, the Tunisian dialect is a combination of many other languages like MSA,\nTamazight, Italian and French. Because of its rich language, dealing with NLP\nproblems can be challenging due to the lack of large annotated datasets. In\nthis paper we are introducing a new annotated dataset composed of approximately\n10k of comments. We provide an in-depth exploration of its vocabulary through\nfeature engineering approaches as well as the results of the classification\nperformance of machine learning classifiers like NB and SVM and deep learning\nmodels such as ARBERT, MARBERT and XLM-R.",
    "descriptor": "",
    "authors": [
      "Slim Gharbi",
      "Heger Arfaoui",
      "Hatem Haddad",
      "Mayssa Kchaou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05287"
  },
  {
    "id": "arXiv:2110.05290",
    "title": "Homogeneous Learning: Self-Attention Decentralized Deep Learning",
    "abstract": "Federated learning (FL) has been facilitating privacy-preserving deep\nlearning in many walks of life such as medical image classification, network\nintrusion detection, and so forth. Whereas it necessitates a central parameter\nserver for model aggregation, which brings about delayed model communication\nand vulnerability to adversarial attacks. A fully decentralized architecture\nlike Swarm Learning allows peer-to-peer communication among distributed nodes,\nwithout the central server. One of the most challenging issues in decentralized\ndeep learning is that data owned by each node are usually non-independent and\nidentically distributed (non-IID), causing time-consuming convergence of model\ntraining. To this end, we propose a decentralized learning model called\nHomogeneous Learning (HL) for tackling non-IID data with a self-attention\nmechanism. In HL, training performs on each round's selected node, and the\ntrained model of a node is sent to the next selected node at the end of each\nround. Notably, for the selection, the self-attention mechanism leverages\nreinforcement learning to observe a node's inner state and its surrounding\nenvironment's state, and find out which node should be selected to optimize the\ntraining. We evaluate our method with various scenarios for an image\nclassification task. The result suggests that HL can produce a better\nperformance compared with standalone learning and greatly reduce both the total\ntraining rounds by 50.8% and the communication cost by 74.6% compared with\nrandom policy-based decentralized learning for training on non-IID data.",
    "descriptor": "",
    "authors": [
      "Yuwei Sun",
      "Hideya Ochiai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05290"
  },
  {
    "id": "arXiv:2110.05291",
    "title": "Graph Neural Network Guided Local Search for the Traveling Salesperson  Problem",
    "abstract": "Solutions to the Traveling Salesperson Problem (TSP) have practical\napplications to processes in transportation, logistics, and automation, yet\nmust be computed with minimal delay to satisfy the real-time nature of the\nunderlying tasks. However, solving large TSP instances quickly without\nsacrificing solution quality remains challenging for current approximate\nalgorithms. To close this gap, we present a hybrid data-driven approach for\nsolving the TSP based on Graph Neural Networks (GNNs) and Guided Local Search\n(GLS). Our model predicts the regret of including each edge of the problem\ngraph in the solution; GLS uses these predictions in conjunction with the\noriginal problem graph to find solutions. Our experiments demonstrate that this\napproach converges to optimal solutions at a faster rate than state-of-the-art\nlearning-based approaches and non-learning GLS algorithms for the TSP, notably\nfinding optimal solutions to 96% of the 50-node problem set, 7% more than the\nnext best benchmark, and to 20% of the 100-node problem set, 4.5x more than the\nnext best benchmark. When generalizing from 20-node problems to the 100-node\nproblem set, our approach finds solutions with an average optimality gap of\n2.5%, a 10x improvement over the next best learning-based benchmark.",
    "descriptor": "",
    "authors": [
      "Benjamin Hudson",
      "Qingbiao Li",
      "Matthew Malencia",
      "Amanda Prorok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.05291"
  },
  {
    "id": "arXiv:2110.05292",
    "title": "Understanding Pooling in Graph Neural Networks",
    "abstract": "Inspired by the conventional pooling layers in convolutional neural networks,\nmany recent works in the field of graph machine learning have introduced\npooling operators to reduce the size of graphs. The great variety in the\nliterature stems from the many possible strategies for coarsening a graph,\nwhich may depend on different assumptions on the graph structure or the\nspecific downstream task. In this paper we propose a formal characterization of\ngraph pooling based on three main operations, called selection, reduction, and\nconnection, with the goal of unifying the literature under a common framework.\nFollowing this formalization, we introduce a taxonomy of pooling operators and\ncategorize more than thirty pooling methods proposed in recent literature. We\npropose criteria to evaluate the performance of a pooling operator and use them\nto investigate and contrast the behavior of different classes of the taxonomy\non a variety of tasks.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Daniele Grattarola",
      "Daniele Zambon",
      "Filippo Maria Bianchi",
      "Cesare Alippi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05292"
  },
  {
    "id": "arXiv:2110.05295",
    "title": "AskMe: Joint Individual-level and Community-level Behavior Interaction  for Question Recommendation",
    "abstract": "Questions in Community Question Answering (CQA) sites are recommended to\nusers, mainly based on users' interest extracted from questions that users have\nanswered or have asked. However, there is a general phenomenon that users\nanswer fewer questions while pay more attention to follow questions and vote\nanswers. This can impact the performance when recommending questions to users\n(for obtaining their answers) by using their historical answering behaviors on\nexisting studies. To address the data sparsity issue, we propose AskMe, which\naims to leverage the rich, hybrid behavior interactions in CQA to improve the\nquestion recommendation performance. On the one hand, we model the rich\ncorrelations between the users' diverse behaviors (e.g., answer, follow, vote)\nto obtain the individual-level behavior interaction. On the other hand, we\nmodel the sophisticated behavioral associations between similar users to obtain\nthe community-level behavior interaction. Finally, we propose the way of\nelement-level fusion to mix these two kinds of interactions together to predict\nthe ranking scores. A dataset collected from Zhihu (1126 users, 219434\nquestions) is utilized to evaluate the performance of the proposed model, and\nthe experimental results show that our model has gained the best performance\ncompared to baseline methods, especially when the historical answering\nbehaviors data is scarce.",
    "descriptor": "\nComments: 26 pages; 10 fingures\n",
    "authors": [
      "Nuo Li",
      "Bin Guo",
      "Yan Liu",
      "Lina Yao",
      "Jiaqi Liu",
      "Zhiwen Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.05295"
  },
  {
    "id": "arXiv:2110.05301",
    "title": "On a Benefit of Mask Language Modeling: Robustness to Simplicity Bias",
    "abstract": "Despite the success of pretrained masked language models (MLM), why MLM\npretraining is useful is still a qeustion not fully answered. In this work we\ntheoretically and empirically show that MLM pretraining makes models robust to\nlexicon-level spurious features, partly answer the question. We theoretically\nshow that, when we can model the distribution of a spurious feature $\\Pi$\nconditioned on the context, then (1) $\\Pi$ is at least as informative as the\nspurious feature, and (2) learning from $\\Pi$ is at least as simple as learning\nfrom the spurious feature. Therefore, MLM pretraining rescues the model from\nthe simplicity bias caused by the spurious feature. We also explore the\nefficacy of MLM pretraing in causal settings. Finally we close the gap between\nour theories and the real world practices by conducting experiments on the hate\nspeech detection and the name entity recognition tasks.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Ting-Rui Chiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05301"
  },
  {
    "id": "arXiv:2110.05303",
    "title": "Teaching K-12 Classrooms Data Programming: A Three-Week Workshop with  Online and Unplugged Activities",
    "abstract": "This paper shares our experience in a three-session online workshop using a\nnew web-based data programming environment, Marti. The programming environment\nuses a card-based programming strategy in both unplugged and online activities.\nEducators can use the physical cards in a board-game style or use the\nprogramming environment's mobile application to scan these cards and render the\nfinal visualization on their phones/tablets. The web environment also uses\nvisual draggable cards for programming that can manipulate and visualize data.\nWe used Marti and its offered unplugged activities in three sessions with 12\nmiddle school and 12 high school students, focusing on the data fundamentals,\nanalysis, and visualization. We assert that integrating unplugged-style\npseudo-code creation and supporting a similar experience using the available\ndevices have considerable potential for delivering equal and affordable data\nprogramming education for all.",
    "descriptor": "",
    "authors": [
      "Alpay Sabuncuo\u011flu",
      "As\u0131m Evren Yanta\u00e7",
      "Tevfik Metin Sezgin"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.05303"
  },
  {
    "id": "arXiv:2110.05304",
    "title": "You Mostly Walk Alone: Analyzing Feature Attribution in Trajectory  Prediction",
    "abstract": "Predicting the future trajectory of a moving agent can be easy when the past\ntrajectory continues smoothly but is challenging when complex interactions with\nother agents are involved. Recent deep learning approaches for trajectory\nprediction show promising performance and partially attribute this to\nsuccessful reasoning about agent-agent interactions. However, it remains\nunclear which features such black-box models actually learn to use for making\npredictions. This paper proposes a procedure that quantifies the contributions\nof different cues to model performance based on a variant of Shapley values.\nApplying this procedure to state-of-the-art trajectory prediction methods on\nstandard benchmark datasets shows that they are, in fact, unable to reason\nabout interactions. Instead, the past trajectory of the target is the only\nfeature used for predicting its future. For a task with richer social\ninteraction patterns, on the other hand, the tested models do pick up such\ninteractions to a certain extent, as quantified by our feature attribution\nmethod. We discuss the limits of the proposed method and its links to causality",
    "descriptor": "",
    "authors": [
      "Osama Makansi",
      "Julius von K\u00fcgelgen",
      "Francesco Locatello",
      "Peter Gehler",
      "Dominik Janzing",
      "Thomas Brox",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05304"
  },
  {
    "id": "arXiv:2110.05305",
    "title": "Black Box Absolute Reconstruction for Sums of Powers of Linear Forms",
    "abstract": "We study the decomposition of multivariate polynomials as sums of powers of\nlinear forms. We give a randomized algorithm for the following problem: If a\nhomogeneous polynomial $f \\in K[x_1 , . . . , x_n]$ (where $K \\subseteq\n\\mathbb{C}$) of degree $d$ is given as a blackbox, decide whether it can be\nwritten as a linear combination of $d$-th powers of linearly independent\ncomplex linear forms. The main novel features of the algorithm are:\n(1) For $d = 3$, we improve by a factor of $n$ on the running time from an\nalgorithm by Koiran and Skomra. The price to be paid for this improvement\nthough is that the algorithm now has two-sided error.\n(2) For $d > 3$, we provide the first randomized blackbox algorithm for this\nproblem that runs in time polynomial in $n$ and $d$ (in an algebraic model\nwhere only arithmetic operations and equality tests are allowed). Previous\nalgorithms for this problem as well as most of the existing reconstruction\nalgorithms for other classes appeal to a polynomial factorization subroutine.\nThis requires extraction of complex polynomial roots at unit cost and in\nstandard models such as the unit-cost RAM or the Turing machine this approach\ndoes not yield polynomial time algorithms.\n(3) For $d > 3$, when $f$ has rational coefficients, the running time of the\nblackbox algorithm is polynomial in $n,d$ and the maximal bit size of any\ncoefficient of $f$. This yields the first algorithm for this problem over\n$\\mathbb{C}$ with polynomial running time in the bit model of computation.",
    "descriptor": "",
    "authors": [
      "Pascal Koiran",
      "Subhayan Saha"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.05305"
  },
  {
    "id": "arXiv:2110.05310",
    "title": "An Enriched Galerkin Method for the Stokes Equations",
    "abstract": "We present a new enriched Galerkin (EG) scheme for the Stokes equations based\non piecewise linear elements for the velocity unknowns and piecewise constant\nelements for the pressure. The proposed EG method augments the conforming\npiecewise linear space for velocity by adding an additional degree of freedom\nwhich corresponds to one discontinuous linear basis function per element. Thus,\nthe total number of degrees of freedom is significantly reduced in comparison\nwith standard conforming, non-conforming, and discontinuous Galerkin schemes\nfor the Stokes equation. We show the well-posedness of the new EG approach and\nprove that the scheme converges optimally. For the solution of the resulting\nlarge-scale indefinite linear systems we propose robust block preconditioners,\nyielding scalable results independent of the discretization and physical\nparameters. Numerical results confirm the convergence rates of the\ndiscretization and also the robustness of the linear solvers for a variety of\ntest problems.",
    "descriptor": "",
    "authors": [
      "Son-Young Yi",
      "Xiaozhe Hu",
      "Sanghyun Lee",
      "James H. Adler",
      "Ludmil T. Zikatanov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05310"
  },
  {
    "id": "arXiv:2110.05311",
    "title": "Simultaneous Transmitting and ReflectingIntelligent Surfaces-Empowered  NOMA Networks",
    "abstract": "In this paper, we propose simultaneous transmitting and reflecting\nreconfigurable intelligent surface (STAR-RIS) assisted non-orthogonal multiple\naccess (NOMA) networks. The considered STAR-RIS utilizes the mode switching\n(MS) protocol to serve multiple NOMA users located on both sides of the RIS\nsurface. Based on the MS protocol, each STAR-RIS element can operate in full\ntransmission or reflection mode. Within this perspective, we propose a novel\nalgorithm to partition the STAR-RIS surface among the available users. This\nalgorithm aims to determine the proper number of transmitting/reflecting\nelements needs to be assigned to each user in order to maximize the system\nsum-rate while guaranteeing the quality-of-service requirements for individual\nusers. For the proposed system, we derive closed-form analytical expressions\nfor the outage probability (OP) and its corresponding asymptotic behavior under\ndifferent user deployments. Finally, Monte Carlo simulations are performed in\norder to verify the correctness of the theoretical analysis. It is shown that\nthe proposed system outperforms the classical NOMA and orthogonal multiple\naccess systems in terms of OP and sum-rate.",
    "descriptor": "\nComments: 10 pages, 8 figures\n",
    "authors": [
      "Mahmoud Aldababsa",
      "Aymen Khaleel",
      "Ertugrul Basar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.05311"
  },
  {
    "id": "arXiv:2110.05313",
    "title": "Unsupervised Source Separation via Bayesian Inference in the Latent  Domain",
    "abstract": "State of the art audio source separation models rely on supervised\ndata-driven approaches, which can be expensive in terms of labeling resources.\nOn the other hand, approaches for training these models without any direct\nsupervision are typically high-demanding in terms of memory and time\nrequirements, and remain impractical to be used at inference time. We aim to\ntackle these limitations by proposing a simple yet effective unsupervised\nseparation algorithm, which operates directly on a latent representation of\ntime-domain signals. Our algorithm relies on deep Bayesian priors in the form\nof pre-trained autoregressive networks to model the probability distributions\nof each source. We leverage the low cardinality of the discrete latent space,\ntrained with a novel loss term imposing a precise arithmetic structure on it,\nto perform exact Bayesian inference without relying on an approximation\nstrategy. We validate our approach on the Slakh dataset arXiv:1909.08494,\ndemonstrating results in line with state of the art supervised approaches while\nrequiring fewer resources with respect to other unsupervised methods.",
    "descriptor": "\nComments: 5 pages, 1 figure\n",
    "authors": [
      "Michele Mancusi",
      "Emilian Postolache",
      "Marco Fumero",
      "Andrea Santilli",
      "Luca Cosmo",
      "Emanuele Rodol\u00e0"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05313"
  },
  {
    "id": "arXiv:2110.05319",
    "title": "Efficient Training of High-Resolution Representation Seismic Image Fault  Segmentation Network by Weakening Anomaly Labels",
    "abstract": "Seismic data fault detection has recently been regarded as a 3D image\nsegmentation task. The nature of fault structures in seismic image makes it\ndifficult to manually label faults. Manual labeling often has many false\nnegative labels (abnormal labels), which will seriously harm the training\nprocess. In this work, we find that region-based loss significantly outperforms\ndistribution-based loss when dealing with falsenegative labels, therefore we\npropose Mask Dice loss (MD loss), which is the first reported region-based loss\nfunction for training 3D image segmentation models using sparse 2D slice\nlabels. In addition, fault is an edge feature, and the current network widely\nused for fault segmentation downsamples the features multiple times, which is\nnot conducive to edge characterization and thus requires many parameters and\ncomputational effort to preserve the features. We propose Fault-Net, which\nalways maintains the high-resolution features of seismic images, and the\ninference process preserves the edge information of faults and performs\neffective feature fusion to achieve high-quality fault segmentation with only a\nfew parameters and computational effort. Experimental results show that MD loss\ncan clearly weaken the effect of anomalous labels. The Fault-Net parameter is\nonly 0.42MB, support up to 528^3(1.5x10^8, Float32) size cuboid inference on\n16GB video ram, and its inference speed on CPU and GPU is significantly faster\nthan other networks, but the result of our method is the state-of-the-art in\nthe FORCE fault identification competition.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Yimin Dou",
      "Kewen Li",
      "Jianbing Zhu",
      "Shaoquan Tan",
      "Zongchao Huang",
      "Xiao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.05319"
  },
  {
    "id": "arXiv:2110.05321",
    "title": "Quantum solutions to possible challenges of Blockchain technology",
    "abstract": "Technological advancements of Blockchain and other Distributed Ledger\nTechniques (DLTs) promise to provide significant advantages to applications\nseeking transparency, redundancy, and accountability. Actual adoption of these\nemerging technologies requires incorporating cost-effective, fast, QoS-enabled,\nsecure, and scalable design. With the recent advent of quantum computing, the\nsecurity of current blockchain cryptosystems can be compromised to a greater\nextent. Quantum algorithms like Shor's large integer factorization algorithm\nand Grover's unstructured database search algorithm can provide exponential and\nquadratic speedup, respectively, in contrast to their classical counterpart.\nThis can put threats on both public-key cryptosystems and hash functions, which\nnecessarily demands to migrate from classical cryptography to quantum-secure\ncryptography. Moreover, the computational latency of blockchain platforms\ncauses slow transaction speed, so quantum computing principles might provide\nsignificant speedup and scalability in transaction processing and accelerating\nthe mining process. For such purpose, this article first studies current and\nfuture classical state-of-the-art blockchain scalability and security\nprimitives. The relevant quantum-safe blockchain cryptosystem initiatives which\nhave been taken by Bitcoin, Ethereum, Corda, etc. are stated and compared with\nrespect to key sizes, hash length, execution time, computational overhead, and\nenergy efficiency. Post Quantum Cryptographic algorithms like Code-based,\nLattice-based, Multivariate-based, and other schemes are not well suited for\nclassical blockchain technology due to several disadvantages in practical\nimplementation. Decryption latency, massive consumption of computational\nresources, and increased key size are few challenges that can hinder blockchain\nperformance.",
    "descriptor": "",
    "authors": [
      "Nivedita Dey",
      "Mrityunjay Ghosh",
      "Amlan Chakrabarti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2110.05321"
  },
  {
    "id": "arXiv:2110.05323",
    "title": "ProgFed: Effective, Communication, and Computation Efficient Federated  Learning by Progressive Training",
    "abstract": "Federated learning is a powerful distributed learning scheme that allows\nnumerous edge devices to collaboratively train a model without sharing their\ndata. However, training is resource-intensive for edge devices, and limited\nnetwork bandwidth is often the main bottleneck. Prior work often overcomes the\nconstraints by condensing the models or messages into compact formats, e.g., by\ngradient compression or distillation. In contrast, we propose ProgFed, the\nfirst progressive training framework for efficient and effective federated\nlearning. It inherently reduces computation and two-way communication costs\nwhile maintaining the strong performance of the final models. We theoretically\nprove that ProgFed converges at the same asymptotic rate as standard training\non full models. Extensive results on a broad range of architectures, including\nCNNs (VGG, ResNet, ConvNets) and U-nets, and diverse tasks from simple\nclassification to medical image segmentation show that our highly effective\ntraining approach saves up to $20\\%$ computation and up to $63\\%$ communication\ncosts for converged models. As our approach is also complimentary to prior work\non compression, we can achieve a wide range of trade-offs, showing reduced\ncommunication of up to $50\\times$ at only $0.1\\%$ loss in utility.",
    "descriptor": "",
    "authors": [
      "Hui-Po Wang",
      "Sebastian U. Stich",
      "Yang He",
      "Mario Fritz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05323"
  },
  {
    "id": "arXiv:2110.05324",
    "title": "Learnable Adaptive Cosine Estimator (LACE) for Image Classification",
    "abstract": "In this work, we propose a new loss to improve feature discriminability and\nclassification performance. Motivated by the adaptive cosine/coherence\nestimator (ACE), our proposed method incorporates angular information that is\ninherently learned by artificial neural networks. Our learnable ACE (LACE)\ntransforms the data into a new ``whitened\" space that improves the inter-class\nseparability and intra-class compactness. We compare our LACE to alternative\nstate-of-the art softmax-based and feature regularization approaches. Our\nresults show that the proposed method can serve as a viable alternative to\ncross entropy and angular softmax approaches. Our code is publicly available:\nhttps://github.com/GatorSense/LACE.",
    "descriptor": "\nComments: Accepted to WACV 2022; 14 pages (including appendix), 3 figures\n",
    "authors": [
      "Joshua Peeples",
      "Connor McCurley",
      "Sarah Walker",
      "Dylan Stewart",
      "Alina Zare"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05324"
  },
  {
    "id": "arXiv:2110.05328",
    "title": "AMRA*: Anytime Multi-Resolution Multi-Heuristic A*",
    "abstract": "Heuristic search-based motion planning algorithms typically discretise the\nsearch space in order to solve the shortest path problem. Their performance is\nclosely related to this discretisation. A fine discretisation allows for better\napproximations of the continuous search space, but makes the search for a\nsolution more computationally costly. A coarser resolution might allow the\nalgorithms to find solutions quickly at the expense of quality. For large state\nspaces, it can be beneficial to search for solutions across multiple\nresolutions even though defining the discretisations is challenging. The\nrecently proposed algorithm Multi-Resolution A* (MRA*) searches over multiple\nresolutions. It traverses large areas of obstacle-free space and escapes local\nminima at a coarse resolution. It can also navigate so-called narrow\npassageways at a finer resolution. In this work, we develop AMRA*, an anytime\nversion of MRA*. AMRA* tries to find a solution quickly using the coarse\nresolution as much as possible. It then refines the solution by relying on the\nfine resolution to discover better paths that may not have been available at\nthe coarse resolution. In addition to being anytime, AMRA* can also leverage\ninformation sharing between multiple heuristics. We prove that AMRA* is\ncomplete and optimal (in-the-limit of time) with respect to the finest\nresolution. We show its performance on 2D grid navigation and 4D kinodynamic\nplanning problems.",
    "descriptor": "\nComments: Submitted to ICRA 2022, code available at this https URL\n",
    "authors": [
      "Dhruv Mauria Saxena",
      "Tushar Kusnur",
      "Maxim Likhachev"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05328"
  },
  {
    "id": "arXiv:2110.05329",
    "title": "Addressing the Stability-Plasticity Dilemma via Knowledge-Aware  Continual Learning",
    "abstract": "Continual learning agents should incrementally learn a sequence of tasks\nwhile satisfying two main desiderata: accumulating on previous knowledge\nwithout forgetting and transferring previous relevant knowledge to help in\nfuture learning. Existing research largely focuses on alleviating the\ncatastrophic forgetting problem. There, an agent is altered to prevent\nforgetting based solely on previous tasks. This hinders the balance between\npreventing forgetting and maximizing the forward transfer. In response to this,\nwe investigate the stability-plasticity dilemma to determine which model\ncomponents are eligible to be reused, added, fixed, or updated to achieve this\nbalance. We address the class incremental learning scenario where the agent is\nprone to ambiguities between old and new classes. With our proposed\nKnowledge-Aware contiNual learner (KAN), we demonstrate that considering the\nsemantic similarity between old and new classes helps in achieving this\nbalance. We show that being aware of existing knowledge helps in: (1)\nincreasing the forward transfer from similar knowledge, (2) reducing the\nrequired capacity by leveraging existing knowledge, (3) protecting dissimilar\nknowledge, and (4) increasing robustness to the class order in the sequence. We\nevaluated sequences of similar tasks, dissimilar tasks, and a mix of both\nconstructed from the two commonly used benchmarks for class-incremental\nlearning; CIFAR-10 and CIFAR-100.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Ghada Sokar",
      "Decebal Constantin Mocanu",
      "Mykola Pechenizkiy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05329"
  },
  {
    "id": "arXiv:2110.05330",
    "title": "Edge-wise funnel output synchronization of heterogeneous agents with  relative degree one",
    "abstract": "In a recent work by three of the authors, in order to enforce synchronization\nfor scalar heterogeneous multi-agent systems with some useful characteristics,\na node-wise funnel coupling law was proposed. The emergent dynamics, to which\neach of the agents synchronizes, was characterized and it was studied how\nnetworks can be synthesized which exhibit these emergent dynamics. The\nadvantage of this synthesis is its suitability for plug-and-play operation.\nHowever, the aforementioned emergent dynamics under node-wise funnel coupling\nare determined by an algebraic equation which does not admit an explicit\nsolution in general, and even its pointwise solution proves rather difficult.\nFurthermore, the contractivity assumption on the emergent dynamics, required to\nestablish the synchronization, is hard to be checked without solving the\nalgebraic equation. To resolve these drawbacks, in the present paper we present\na new funnel coupling law that uses edge-wise output differences. Under this\nnovel coupling the benign properties of node-wise funnel coupling are retained,\nbut the emergent dynamics are given explicitly by the blended dynamics of the\nmulti-agent system, which already proved an advantageous tool in the analysis\nand design of such networks. Additionally, our results are not restricted to\nscalar systems and treat the case that neighboring agents only communicate\ntheir output information, and not their complete state.",
    "descriptor": "\nComments: 13 pages, 3 figures\n",
    "authors": [
      "Jin Gyu Lee",
      "Thomas Berger",
      "Stephan Trenn",
      "Hyungbo Shim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.05330"
  },
  {
    "id": "arXiv:2110.05335",
    "title": "From FPGAs to Obfuscated eASICs: Design and Security Trade-offs",
    "abstract": "Threats associated with the untrusted fabrication of integrated circuits\n(ICs) are numerous: piracy, overproduction, reverse engineering, hardware\ntrojans, etc. The use of reconfigurable elements (i.e., look-up tables as in\nFPGAs) is a known obfuscation technique. In the extreme case, when the circuit\nis entirely implemented as an FPGA, no information is revealed to the adversary\nbut at a high cost in area, power, and performance. In the opposite extreme,\nwhen the same circuit is implemented as an ASIC, best-in-class performance is\nobtained but security is compromised. This paper investigates an intermediate\nsolution between these two. Our results are supported by a custom CAD tool that\nexplores this FPGA-ASIC design space and enables a standard-cell based physical\nsynthesis flow that is flexible and compatible with current design practices.\nLayouts are presented for obfuscated circuits in a 65nm commercial technology,\ndemonstrating the attained obfuscation both graphically and quantitatively.\nFurthermore, our security analysis revealed that for truly hiding the circuit's\nintent (not only portions of its structure), the obfuscated design also has to\nchiefly resemble an FPGA: only some small amount of logic can be made static\nfor an adversary to remain unaware of what the circuit does.",
    "descriptor": "\nComments: The results for the paper are given on the following link: this https URL\n",
    "authors": [
      "Zain Ul Abideen",
      "Tiago Diadami Perez",
      "Samuel Pagliarini"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2110.05335"
  },
  {
    "id": "arXiv:2110.05340",
    "title": "Revitalizing CNN Attentions via Transformers in Self-Supervised Visual  Representation Learning",
    "abstract": "Studies on self-supervised visual representation learning (SSL) improve\nencoder backbones to discriminate training samples without labels. While CNN\nencoders via SSL achieve comparable recognition performance to those via\nsupervised learning, their network attention is under-explored for further\nimprovement. Motivated by the transformers that explore visual attention\neffectively in recognition scenarios, we propose a CNN Attention REvitalization\n(CARE) framework to train attentive CNN encoders guided by transformers in SSL.\nThe proposed CARE framework consists of a CNN stream (C-stream) and a\ntransformer stream (T-stream), where each stream contains two branches.\nC-stream follows an existing SSL framework with two CNN encoders, two\nprojectors, and a predictor. T-stream contains two transformers, two\nprojectors, and a predictor. T-stream connects to CNN encoders and is in\nparallel to the remaining C-Stream. During training, we perform SSL in both\nstreams simultaneously and use the T-stream output to supervise C-stream. The\nfeatures from CNN encoders are modulated in T-stream for visual attention\nenhancement and become suitable for the SSL scenario. We use these modulated\nfeatures to supervise C-stream for learning attentive CNN encoders. To this\nend, we revitalize CNN attention by using transformers as guidance. Experiments\non several standard visual recognition benchmarks, including image\nclassification, object detection, and semantic segmentation, show that the\nproposed CARE framework improves CNN encoder backbones to the state-of-the-art\nperformance.",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Chongjian Ge",
      "Youwei Liang",
      "Yibing Song",
      "Jianbo Jiao",
      "Jue Wang",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05340"
  },
  {
    "id": "arXiv:2110.05342",
    "title": "Semi-Autoregressive Image Captioning",
    "abstract": "Current state-of-the-art approaches for image captioning typically adopt an\nautoregressive manner, i.e., generating descriptions word by word, which\nsuffers from slow decoding issue and becomes a bottleneck in real-time\napplications. Non-autoregressive image captioning with continuous iterative\nrefinement, which eliminates the sequential dependence in a sentence\ngeneration, can achieve comparable performance to the autoregressive\ncounterparts with a considerable acceleration. Nevertheless, based on a\nwell-designed experiment, we empirically proved that iteration times can be\neffectively reduced when providing sufficient prior knowledge for the language\ndecoder. Towards that end, we propose a novel two-stage framework, referred to\nas Semi-Autoregressive Image Captioning (SAIC), to make a better trade-off\nbetween performance and speed. The proposed SAIC model maintains autoregressive\nproperty in global but relieves it in local. Specifically, SAIC model first\njumpily generates an intermittent sequence in an autoregressive manner, that\nis, it predicts the first word in every word group in order. Then, with the\nhelp of the partially deterministic prior information and image features, SAIC\nmodel non-autoregressively fills all the skipped words with one iteration.\nExperimental results on the MS COCO benchmark demonstrate that our SAIC model\noutperforms the preceding non-autoregressive image captioning models while\nobtaining a competitive inference speedup. Code is available at\nhttps://github.com/feizc/SAIC.",
    "descriptor": "\nComments: ACM MM2021 Oral\n",
    "authors": [
      "Xu Yan",
      "Zhengcong Fei",
      "Zekang Li",
      "Shuhui Wang",
      "Qingming Huang",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05342"
  },
  {
    "id": "arXiv:2110.05343",
    "title": "Leveraging Transformers for StarCraft Macromanagement Prediction",
    "abstract": "Inspired by the recent success of transformers in natural language processing\nand computer vision applications, we introduce a transformer-based neural\narchitecture for two key StarCraft II (SC2) macromanagement tasks: global state\nand build order prediction. Unlike recurrent neural networks which suffer from\na recency bias, transformers are able to capture patterns across very long time\nhorizons, making them well suited for full game analysis. Our model utilizes\nthe MSC (Macromanagement in StarCraft II) dataset and improves on the top\nperforming gated recurrent unit (GRU) architecture in predicting global state\nand build order as measured by mean accuracy over multiple time horizons. We\npresent ablation studies on our proposed architecture that support our design\ndecisions. One key advantage of transformers is their ability to generalize\nwell, and we demonstrate that our model achieves an even better accuracy when\nused in a transfer learning setting in which models trained on games with one\nracial matchup (e.g., Terran vs. Protoss) are transferred to a different one.\nWe believe that transformers' ability to model long games, potential for\nparallelization, and generalization performance make them an excellent choice\nfor StarCraft agents.",
    "descriptor": "\nComments: 6 pages, 2 figures, IEEE ICMLA 2021\n",
    "authors": [
      "Muhammad Junaid Khan",
      "Shah Hassan",
      "Gita Sukthankar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05343"
  },
  {
    "id": "arXiv:2110.05344",
    "title": "Quantum multi-factor authentication",
    "abstract": "We present a quantum multi-factor authentication mechanism based on the\nhidden-matching quantum communication complexity problem. It offers step-up\ngraded authentication for users via a quantum token. In this paper, we outline\nthe protocol, demonstrate that it can be used in a largely classical setting,\nexplain how it can be implemented in SASL, and discuss arising security\nfeatures. We also offer a comparison between our mechanism and current\nstate-of-the-art multi-factor authentication mechanisms.",
    "descriptor": "",
    "authors": [
      "Hazel Murray",
      "David Malone"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.05344"
  },
  {
    "id": "arXiv:2110.05351",
    "title": "Sparse recovery of elliptic solvers from matrix-vector products",
    "abstract": "In this work, we show that solvers of elliptic boundary value problems in $d$\ndimensions can be approximated to accuracy $\\epsilon$ from only\n$\\mathcal{O}\\left(\\log(N)\\log^{d}(N / \\epsilon)\\right)$ matrix-vector products\nwith carefully chosen vectors (right-hand sides). The solver is only accessed\nas a black box, and the underlying operator may be unknown and of an\narbitrarily high order. Our algorithm (1) has complexity\n$\\mathcal{O}\\left(N\\log^2(N)\\log^{2d}(N / \\epsilon)\\right)$ and represents the\nsolution operator as a sparse Cholesky factorization with\n$\\mathcal{O}\\left(N\\log(N)\\log^{d}(N / \\epsilon)\\right)$ nonzero entries, (2)\nallows for embarrassingly parallel evaluation of the solution operator and the\ncomputation of its log-determinant, (3) allows for\n$\\mathcal{O}\\left(\\log(N)\\log^{d}(N / \\epsilon)\\right)$ complexity computation\nof individual entries of the matrix representation of the solver that in turn\nenables its recompression to an $\\mathcal{O}\\left(N\\log^{d}(N /\n\\epsilon)\\right)$ complexity representation. As a byproduct, our compression\nscheme produces a homogenized solution operator with near-optimal approximation\naccuracy. We include rigorous proofs of these results, and to the best of our\nknowledge, the proposed algorithm achieves the best trade-off between accuracy\n$\\epsilon$ and the number of required matrix-vector products of the original\nsolver.",
    "descriptor": "",
    "authors": [
      "Florian Sch\u00e4fer",
      "Houman Owhadi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05351"
  },
  {
    "id": "arXiv:2110.05352",
    "title": "From Internet and Extended Reality to Metaverse: Technology Survey,  Ecosystem, and Future Directions",
    "abstract": "Since the popularisation of the Internet in the 1990s, the cyberspace has\nkept evolving. We have created various computer-mediated virtual environments\nincluding social networks, video conferencing, virtual 3D worlds (e.g., VR\nChat), augmented reality applications (e.g., Pokemon Go), and Non-Fungible\nToken Games (e.g., Upland). Such virtual environments, albeit non-perpetual and\nunconnected, have bought us various degrees of digital transformation. The term\n`metaverse' has been coined to further facilitate the digital transformation in\nevery aspect of our physical lives. At the core of the metaverse stands the\nvision of an immersive Internet as a gigantic, unified, persistent, and shared\nrealm. While the metaverse may seem futuristic, catalysed by emerging\ntechnologies such as Extended Reality, 5G, and Artificial Intelligence, the\ndigital `big bang' of our cyberspace is not far away. This survey paper\npresents the first effort to offer a comprehensive framework that examines the\nlatest metaverse development under the dimensions of state-of-the-art\ntechnologies and metaverse ecosystems, and illustrates the possibility of the\ndigital `big bang'. First, technologies are the enablers that drive the\ntransition from the current Internet to the metaverse. We thus examine eight\nenabling technologies rigorously - Extended Reality, User Interactivity\n(Human-Computer Interaction), Artificial Intelligence, Blockchain, Computer\nVision, Edge and Cloud computing, and Future Mobile Networks. In terms of\napplications, the metaverse ecosystem allows human users to live and play\nwithin a self-sustaining, persistent, and shared realm. Therefore, we discuss\nsix user-centric factors -- Avatar, Content Creation, Virtual Economy, Social\nAcceptability, Security and Privacy, and Trust and Accountability. Finally, we\npropose a concrete research agenda for the development of the metaverse.",
    "descriptor": "\nComments: 68 pages, IEEE ACCESS (UNDER REVIEW)\n",
    "authors": [
      "Lik-Hang Lee",
      "Tristan Braud",
      "Pengyuan Zhou",
      "Lin Wang",
      "Dianlei Xu",
      "Zijun Lin",
      "Abhishek Kumar",
      "Carlos Bermejo",
      "Pan Hui"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.05352"
  },
  {
    "id": "arXiv:2110.05354",
    "title": "Internal Language Model Adaptation with Text-Only Data for End-to-End  Speech Recognition",
    "abstract": "Text-only adaptation of an end-to-end (E2E) model remains a challenging task\nfor automatic speech recognition (ASR). Language model (LM) fusion-based\napproaches require an additional external LM during inference, significantly\nincreasing the computation cost. To overcome this, we propose an internal LM\nadaptation (ILMA) of the E2E model using text-only data. Trained with\naudio-transcript pairs, an E2E model implicitly learns an internal LM that\ncharacterizes the token sequence probability which is approximated by the E2E\nmodel output after zeroing out the encoder contribution. During ILMA, we\nfine-tune the internal LM, i.e., the E2E components excluding the encoder, to\nminimize a cross-entropy loss. To make ILMA effective, it is essential to train\nthe E2E model with an internal LM loss besides the standard E2E loss.\nFurthermore, we propose to regularize ILMA by minimizing the Kullback-Leibler\ndivergence between the output distributions of the adapted and unadapted\ninternal LMs. ILMA is the most effective when we update only the last linear\nlayer of the joint network. ILMA enables a fast text-only adaptation of the E2E\nmodel without increasing the run-time computational cost. Experimented with\n30K-hour trained transformer transducer models, ILMA achieves up to 34.9%\nrelative word error rate reduction from the unadapted baseline.",
    "descriptor": "\nComments: 5 pages, submitted to ICASSP 2022\n",
    "authors": [
      "Zhong Meng",
      "Yashesh Gaur",
      "Naoyuki Kanda",
      "Jinyu Li",
      "Xie Chen",
      "Yu Wu",
      "Yifan Gong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05354"
  },
  {
    "id": "arXiv:2110.05355",
    "title": "Instance-based Label Smoothing For Better Calibrated Classification  Networks",
    "abstract": "Label smoothing is widely used in deep neural networks for multi-class\nclassification. While it enhances model generalization and reduces\noverconfidence by aiming to lower the probability for the predicted class, it\ndistorts the predicted probabilities of other classes resulting in poor\nclass-wise calibration. Another method for enhancing model generalization is\nself-distillation where the predictions of a teacher network trained with\none-hot labels are used as the target for training a student network. We take\ninspiration from both label smoothing and self-distillation and propose two\nnovel instance-based label smoothing approaches, where a teacher network\ntrained with hard one-hot labels is used to determine the amount of per class\nsmoothness applied to each instance. The assigned smoothing factor is\nnon-uniformly distributed along with the classes according to their similarity\nwith the actual class. Our methods show better generalization and calibration\nover standard label smoothing on various deep neural architectures and image\nclassification datasets.",
    "descriptor": "\nComments: 8 pages, 3 figures, ICMLA 2021\n",
    "authors": [
      "Mohamed Maher",
      "Meelis Kull"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05355"
  },
  {
    "id": "arXiv:2110.05357",
    "title": "Graph-Guided Network for Irregularly Sampled Multivariate Time Series",
    "abstract": "In many domains, including healthcare, biology, and climate science, time\nseries are irregularly sampled with variable time between successive\nobservations and different subsets of variables (sensors) are observed at\ndifferent time points, even after alignment to start events. These data create\nmultiple challenges for prevailing models that assume fully observed and\nfixed-length feature representations. To address these challenges, it is\nessential to understand the relationships between sensors and how they evolve\nover time. Here, we introduce RAINDROP, a graph-guided network for learning\nrepresentations of irregularly sampled multivariate time series. RAINDROP\nrepresents every sample as a graph, where nodes indicate sensors and edges\nrepresent dependencies between them. RAINDROP models dependencies between\nsensors using neural message passing and temporal self-attention. It considers\nboth inter-sensor relationships shared across samples and those unique to each\nsample that can vary with time, and it adaptively estimates misaligned\nobservations based on nearby observations. We use RAINDROP to classify time\nseries and interpret temporal dynamics of three healthcare and human activity\ndatasets. RAINDROP outperforms state-of-the-art methods by up to 11.4%\n(absolute points in F1 score), including methods that deal with irregular\nsampling using fixed discretization and set functions, and even in challenging\nleave-sensor-out settings and setups that require generalizing to new patient\ngroups.",
    "descriptor": "",
    "authors": [
      "Xiang Zhang",
      "Marko Zeman",
      "Theodoros Tsiligkaridis",
      "Marinka Zitnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05357"
  },
  {
    "id": "arXiv:2110.05360",
    "title": "Towards Providing Connectivity When and Where It Counts: An Overview of  Deployable 5G Networks",
    "abstract": "Public safety operations require fast and reliable mission critical\ncommunications under various scenarios, in which the availability of wireless\nconnectivity can be a question of life or death. To provide connectivity when\nand where it counts, we have witnessed a growing demand for deployable networks\nfor public safety in natural disasters or emergency situations. This article\ninvestigates the opportunities of using the 5th generation (5G) new radio (NR)\nstandard for designing flexible and reliable deployable networks. We describe\nuse cases and provide an overview of deployable 5G network concepts, including\narchitecture options, system performance analysis, and coexistence aspects. We\nalso identify technical challenges that can be considered in the evolution of\n5G NR to unlock the full potential of deployable 5G networks.",
    "descriptor": "\nComments: 8 pages, 6 figures, submit to IEEE Communications Standards Magazine\n",
    "authors": [
      "Jingya Li",
      "Xingqin Lin",
      "Keerthi Kumar Nagalapur",
      "Zhiqiang Qi",
      "Adri\u00e1n Lahuerta-Lavieja",
      "Thomas Chapman",
      "Sam Agneessens",
      "Henrik Sahlin",
      "Daniel Guldbrand",
      "Joakim \u00c5kesson"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.05360"
  },
  {
    "id": "arXiv:2110.05362",
    "title": "Focus on what matters: Applying Discourse Coherence Theory to Cross  Document Coreference",
    "abstract": "Performing event and entity coreference resolution across documents vastly\nincreases the number of candidate mentions, making it intractable to do the\nfull $n^2$ pairwise comparisons. Existing approaches simplify by considering\ncoreference only within document clusters, but this fails to handle\ninter-cluster coreference, common in many applications. As a result\ncross-document coreference algorithms are rarely applied to downstream tasks.\nWe draw on an insight from discourse coherence theory: potential coreferences\nare constrained by the reader's discourse focus. We model the entities/events\nin a reader's focus as a neighborhood within a learned latent embedding space\nwhich minimizes the distance between mentions and the centroids of their gold\ncoreference clusters. We then use these neighborhoods to sample only hard\nnegatives to train a fine-grained classifier on mention pairs and their local\ndiscourse features. Our approach achieves state-of-the-art results for both\nevents and entities on the ECB+, Gun Violence, Football Coreference, and\nCross-Domain Cross-Document Coreference corpora. Furthermore, training on\nmultiple corpora improves average performance across all datasets by 17.2 F1\npoints, leading to a robust coreference resolution model for use in downstream\ntasks where link distribution is unknown.",
    "descriptor": "\nComments: 9 pages, 8 figures, To be published in the 2021 Main Conference on Empirical Methods in Natural Language Processing\n",
    "authors": [
      "William Held",
      "Dan Iter",
      "Dan Jurafsky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05362"
  },
  {
    "id": "arXiv:2110.05365",
    "title": "Intriguing Properties of Input-dependent Randomized Smoothing",
    "abstract": "Randomized smoothing is currently considered the state-of-the-art method to\nobtain certifiably robust classifiers. Despite its remarkable performance, the\nmethod is associated with various serious problems such as ``certified accuracy\nwaterfalls'', certification vs. accuracy trade-off, or even fairness issues.\nInput-dependent smoothing approaches have been proposed to overcome these\nflaws. However, we demonstrate that these methods lack formal guarantees and so\nthe resulting certificates are not justified. We show that the input-dependent\nsmoothing, in general, suffers from the curse of dimensionality, forcing the\nvariance function to have low semi-elasticity. On the other hand, we provide a\ntheoretical and practical framework that enables the usage of input-dependent\nsmoothing even in the presence of the curse of dimensionality, under strict\nrestrictions. We present one concrete design of the smoothing variance and test\nit on CIFAR10 and MNIST. Our design solves some of the problems of classical\nsmoothing and is formally underlined, yet further improvement of the design is\nstill necessary.",
    "descriptor": "",
    "authors": [
      "Peter S\u00faken\u00edk",
      "Aleksei Kuvshinov",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.05365"
  },
  {
    "id": "arXiv:2110.05367",
    "title": "Improving Gender Fairness of Pre-Trained Language Models without  Catastrophic Forgetting",
    "abstract": "Although pre-trained language models, such as BERT, achieve state-of-art\nperformance in many language understanding tasks, they have been demonstrated\nto inherit strong gender bias from its training data. Existing studies\naddressing the gender bias issue of pre-trained models, usually recollect and\nbuild gender-neutral data on their own and conduct a second phase pre-training\non the released pre-trained model with such data. However, given the limited\nsize of the gender-neutral data and its potential distributional mismatch with\nthe original pre-training data, catastrophic forgetting would occur during the\nsecond-phase pre-training. Forgetting on the original training data may damage\nthe model's downstream performance to a large margin. In this work, we first\nempirically show that even if the gender-neutral data for second-phase\npre-training comes from the original training data, catastrophic forgetting\nstill occurs if the size of gender-neutral data is smaller than that of\noriginal training data. Then, we propose a new method, GEnder Equality Prompt\n(GEEP), to improve gender fairness of pre-trained models without forgetting.\nGEEP learns gender-related prompts to reduce gender bias, conditioned on frozen\nlanguage models. Since all pre-trained parameters are frozen, forgetting on\ninformation from the original training data can be alleviated to the most\nextent. Then GEEP trains new embeddings of profession names as gender equality\nprompts conditioned on the frozen model. Empirical results show that GEEP not\nonly achieves state-of-the-art performances on gender debiasing in various\napplications such as pronoun predicting and coreference resolution, but also\nachieves comparable results on general downstream tasks such as GLUE with\noriginal pre-trained models without much forgetting.",
    "descriptor": "",
    "authors": [
      "Zahra Fatemi",
      "Chen Xing",
      "Wenhao Liu",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05367"
  },
  {
    "id": "arXiv:2110.05369",
    "title": "Explainable Fact-checking through Question Answering",
    "abstract": "Misleading or false information has been creating chaos in some places around\nthe world. To mitigate this issue, many researchers have proposed automated\nfact-checking methods to fight the spread of fake news. However, most methods\ncannot explain the reasoning behind their decisions, failing to build trust\nbetween machines and humans using such technology. Trust is essential for\nfact-checking to be applied in the real world. Here, we address fact-checking\nexplainability through question answering. In particular, we propose generating\nquestions and answers from claims and answering the same questions from\nevidence. We also propose an answer comparison model with an attention\nmechanism attached to each question. Leveraging question answering as a proxy,\nwe break down automated fact-checking into several steps -- this separation\naids models' explainability as it allows for more detailed analysis of their\ndecision-making processes. Experimental results show that the proposed model\ncan achieve state-of-the-art performance while providing reasonable explainable\ncapabilities.",
    "descriptor": "\nComments: 5 pages, 3 figures, 2 tables. Submitted to the 2022 International Conference on Acoustics, Speech, & Signal Processing (ICASSP)\n",
    "authors": [
      "Jing Yang",
      "Didier Vega-Oliveros",
      "Ta\u00eds Seibt",
      "Anderson Rocha"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05369"
  },
  {
    "id": "arXiv:2110.05370",
    "title": "Classifying SMEs for Approaching Cybersecurity Competence and Awareness",
    "abstract": "Cybersecurity is increasingly a concern for small and medium-sized\nenterprises (SMEs), and there exist many awareness training programs and tools\nfor them. The literature mainly studies SMEs as a unitary type of company and\nprovides one-size-fits-all recommendations and solutions. However, SMEs are not\nhomogeneous. They are diverse with different vulnerabilities, cybersecurity\nneeds, and competencies. Few studies considered such differences in standards\nand certificates for security tools adoption and cybersecurity tailoring for\nthese SMEs. This study proposes a classification framework with an outline of\ncybersecurity improvement needs for each class. The framework suggests five SME\ntypes based on their characteristics and specific security needs: cybersecurity\nabandoned SME, unskilled SME, expert-connected SME, capable SME, and\ncybersecurity provider SME. In addition to describing the five classes, the\nstudy explains the framework's usage in sampled SMEs. The framework proposes\nsolutions for each class to approach cybersecurity awareness and competence\nmore consistent with SME needs. The final publication is available at ACM\nDigital Library via this https URL https://doi.org/10.1145/3465481.3469200",
    "descriptor": "\nComments: 7 pages, 1 Table, The 16th International Conference on Availability, Reliability and Security. (ARES 2021)\n",
    "authors": [
      "Alireza Shojaifar",
      "Heini Jarvinen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.05370"
  },
  {
    "id": "arXiv:2110.05371",
    "title": "Graph-Based Machine Learning Improves Just-in-Time Defect Prediction",
    "abstract": "The increasing complexity of today's software requires the contribution of\nthousands of developers. This complex collaboration structure makes developers\nmore likely to introduce defect-prone changes that lead to software faults.\nDetermining when these defect-prone changes are introduced has proven\nchallenging, and using traditional machine learning (ML) methods to make these\ndeterminations seems to have reached a plateau. In this work, we build\ncontribution graphs consisting of developers and source files to capture the\nnuanced complexity of changes required to build software. By leveraging these\ncontribution graphs, our research shows the potential of using graph-based ML\nto improve Just-In-Time (JIT) defect prediction. We hypothesize that features\nextracted from the contribution graphs may be better predictors of defect-prone\nchanges than intrinsic features derived from software characteristics. We\ncorroborate our hypothesis using graph-based ML for classifying edges that\nrepresent defect-prone changes. This new framing of the JIT defect prediction\nproblem leads to remarkably better results. We test our approach on 14\nopen-source projects and show that our best model can predict whether or not a\ncode change will lead to a defect with an F1 score as high as 86.25$\\%$. This\nrepresents an increase of as much as 55.4$\\%$ over the state-of-the-art in JIT\ndefect prediction. We describe limitations, open challenges, and how this\nmethod can be used for operational JIT defect prediction.",
    "descriptor": "\nComments: 9 pages, 2 figures, 2 tables\n",
    "authors": [
      "Jonathan Bryan",
      "Pablo Moriano"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.05371"
  },
  {
    "id": "arXiv:2110.05375",
    "title": "Precision and Fitness in Object-Centric Process Mining",
    "abstract": "Traditional process mining considers only one single case notion and\ndiscovers and analyzes models based on this. However, a single case notion is\noften not a realistic assumption in practice. Multiple case notions might\ninteract and influence each other in a process. Object-centric process mining\nintroduces the techniques and concepts to handle multiple case notions. So far,\nsuch event logs have been standardized and novel process model discovery\ntechniques were proposed. However, notions for evaluating the quality of a\nmodel are missing. These are necessary to enable future research on improving\nobject-centric discovery and providing an objective evaluation of model\nquality. In this paper, we introduce a notion for the precision and fitness of\nan object-centric Petri net with respect to an object-centric event log. We\ngive a formal definition and accompany this with an example. Furthermore, we\nprovide an algorithm to calculate these quality measures. We discuss our\nprecision and fitness notion based on an event log with different models. Our\nprecision and fitness notions are an appropriate way to generalize quality\nmeasures to the object-centric setting since we are able to consider multiple\ncase notions, their dependencies and their interactions.",
    "descriptor": "",
    "authors": [
      "Jan Niklas Adams",
      "Wil M.P. van der Aalst"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05375"
  },
  {
    "id": "arXiv:2110.05376",
    "title": "Evaluating User Perception of Speech Recognition System Quality with  Semantic Distance Metric",
    "abstract": "Measuring automatic speech recognition (ASR) system quality is critical for\ncreating user-satisfying voice-driven applications. Word Error Rate (WER) has\nbeen traditionally used to evaluate ASR system quality; however, it sometimes\ncorrelates poorly with user perception of transcription quality. This is\nbecause WER weighs every word equally and does not consider semantic\ncorrectness which has a higher impact on user perception. In this work, we\npropose evaluating ASR output hypotheses quality with SemDist that can measure\nsemantic correctness by using the distance between the semantic vectors of the\nreference and hypothesis extracted from a pre-trained language model. Our\nexperimental results of 71K and 36K user annotated ASR output quality show that\nSemDist achieves higher correlation with user perception than WER. We also show\nthat SemDist has higher correlation with downstream NLU tasks than WER.",
    "descriptor": "\nComments: submitted 2022 ICASSP\n",
    "authors": [
      "Suyoun Kim",
      "Duc Le",
      "Weiyi Zheng",
      "Tarun Singh",
      "Abhinav Arora",
      "Xiaoyu Zhai",
      "Christian Fuegen",
      "Ozlem Kalinli",
      "Michael L. Seltzer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05376"
  },
  {
    "id": "arXiv:2110.05379",
    "title": "Point Cloud Augmentation with Weighted Local Transformations",
    "abstract": "Despite the extensive usage of point clouds in 3D vision, relatively limited\ndata are available for training deep neural networks. Although data\naugmentation is a standard approach to compensate for the scarcity of data, it\nhas been less explored in the point cloud literature. In this paper, we propose\na simple and effective augmentation method called PointWOLF for point cloud\naugmentation. The proposed method produces smoothly varying non-rigid\ndeformations by locally weighted transformations centered at multiple anchor\npoints. The smooth deformations allow diverse and realistic augmentations.\nFurthermore, in order to minimize the manual efforts to search the optimal\nhyperparameters for augmentation, we present AugTune, which generates augmented\nsamples of desired difficulties producing targeted confidence scores. Our\nexperiments show our framework consistently improves the performance for both\nshape classification and part segmentation tasks. Particularly, with\nPointNet++, PointWOLF achieves the state-of-the-art 89.7 accuracy on shape\nclassification with the real-world ScanObjectNN dataset.",
    "descriptor": "\nComments: 9 pages, Accepted to ICCV 2021\n",
    "authors": [
      "Sihyeon Kim",
      "Sanghyeok Lee",
      "Dasol Hwang",
      "Jaewon Lee",
      "Seong Jae Hwang",
      "Hyunwoo J. Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05379"
  },
  {
    "id": "arXiv:2110.05382",
    "title": "SignBERT: Pre-Training of Hand-Model-Aware Representation for Sign  Language Recognition",
    "abstract": "Hand gesture serves as a critical role in sign language. Current\ndeep-learning-based sign language recognition (SLR) methods may suffer\ninsufficient interpretability and overfitting due to limited sign data sources.\nIn this paper, we introduce the first self-supervised pre-trainable SignBERT\nwith incorporated hand prior for SLR. SignBERT views the hand pose as a visual\ntoken, which is derived from an off-the-shelf pose extractor. The visual tokens\nare then embedded with gesture state, temporal and hand chirality information.\nTo take full advantage of available sign data sources, SignBERT first performs\nself-supervised pre-training by masking and reconstructing visual tokens.\nJointly with several mask modeling strategies, we attempt to incorporate hand\nprior in a model-aware method to better model hierarchical context over the\nhand sequence. Then with the prediction head added, SignBERT is fine-tuned to\nperform the downstream SLR task. To validate the effectiveness of our method on\nSLR, we perform extensive experiments on four public benchmark datasets, i.e.,\nNMFs-CSL, SLR500, MSASL and WLASL. Experiment results demonstrate the\neffectiveness of both self-supervised learning and imported hand prior.\nFurthermore, we achieve state-of-the-art performance on all benchmarks with a\nnotable gain.",
    "descriptor": "\nComments: ICCV 2021\n",
    "authors": [
      "Hezhen Hu",
      "Weichao Zhao",
      "Wengang Zhou",
      "Yuechen Wang",
      "Houqiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05382"
  },
  {
    "id": "arXiv:2110.05386",
    "title": "Towards Streaming Egocentric Action Anticipation",
    "abstract": "Egocentric action anticipation is the task of predicting the future actions a\ncamera wearer will likely perform based on past video observations. While in a\nreal-world system it is fundamental to output such predictions before the\naction begins, past works have not generally paid attention to model runtime\nduring evaluation. Indeed, current evaluation schemes assume that predictions\ncan be made offline, and hence that computational resources are not limited. In\ncontrast, in this paper, we propose a ``streaming'' egocentric action\nanticipation evaluation protocol which explicitly considers model runtime for\nperformance assessment, assuming that predictions will be available only after\nthe current video segment is processed, which depends on the processing time of\na method. Following the proposed evaluation scheme, we benchmark different\nstate-of-the-art approaches for egocentric action anticipation on two popular\ndatasets. Our analysis shows that models with a smaller runtime tend to\noutperform heavier models in the considered streaming scenario, thus changing\nthe rankings generally observed in standard offline evaluations. Based on this\nobservation, we propose a lightweight action anticipation model consisting in a\nsimple feed-forward 3D CNN, which we propose to optimize using knowledge\ndistillation techniques and a custom loss. The results show that the proposed\napproach outperforms prior art in the streaming scenario, also in combination\nwith other lightweight models.",
    "descriptor": "",
    "authors": [
      "Antonino Furnari",
      "Giovanni Maria Farinella"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05386"
  },
  {
    "id": "arXiv:2110.05387",
    "title": "CASPR: A Commonsense Reasoning-based Conversational Socialbot",
    "abstract": "We report on the design and development of the CASPR system, a socialbot\ndesigned to compete in the Amazon Alexa Socialbot Challenge 4. CASPR's\ndistinguishing characteristic is that it will use automated commonsense\nreasoning to truly \"understand\" dialogs, allowing it to converse like a human.\nThree main requirements of a socialbot are that it should be able to\n\"understand\" users' utterances, possess a strategy for holding a conversation,\nand be able to learn new knowledge. We developed techniques such as\nconversational knowledge template (CKT) to approximate commonsense reasoning\nneeded to hold a conversation on specific topics. We present the philosophy\nbehind CASPR's design as well as details of its implementation. We also report\non CASPR's performance as well as discuss lessons learned.",
    "descriptor": "\nComments: 4th Proceedings of Amazon Alexa Prize (Alexa Prize 2021)\n",
    "authors": [
      "Kinjal Basu",
      "Huaduo Wang",
      "Nancy Dominguez",
      "Xiangci Li",
      "Fang Li",
      "Sarat Chandra Varanasi",
      "Gopal Gupta"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.05387"
  },
  {
    "id": "arXiv:2110.05388",
    "title": "Logical Foundations of Quantitative Equality (long version)",
    "abstract": "Quantitative reasoning provides a flexible approach capable to deal with the\nuncertainty and imprecision that affects modern software systems due to their\ncomplexity. Its distinguishing feature is the use of distances, instead of\nequivalence relations, so that one can measure how much two objects are\nsimilar, rather than just saying whether they are equivalent or not. In this\npaper we aim at providing a solid logical ground to quantitative reasoning,\nusing the categorical language of Lawvere's hyperdoctrines. The key idea is to\nsee distances as equality predicates in Linear Logic. Adding equality to Linear\nLogic, however, is not as trivial as it might appear. The linear version of the\nusual rules for equality, asserting that it is reflexive and substitutive, has\nthe consequence that equality collapses to an equivalence relation, as it can\nbe used an arbitrary number of times. To overcome this issue, we consider the\nextension of Linear Logic with graded modalities and use them to write a\nresource sensitive substitution rule that keeps equality quantitative. We\nintroduce a deductive calculus for (Graded) Linear Logic with quantitative\nequality and the notion of Lipschitz doctrine to give semantics to it. Main\nexamples are based on metric spaces and Lipschitz maps and on quantitative\nrealisability.",
    "descriptor": "",
    "authors": [
      "Francesco Dagnino",
      "Fabio Pasquali"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2110.05388"
  },
  {
    "id": "arXiv:2110.05390",
    "title": "Synthesizing Machine Learning Programs with PAC Guarantees via  Statistical Sketching",
    "abstract": "We study the problem of synthesizing programs that include machine learning\ncomponents such as deep neural networks (DNNs). We focus on statistical\nproperties, which are properties expected to hold with high probability --\ne.g., that an image classification model correctly identifies people in images\nwith high probability. We propose novel algorithms for sketching and\nsynthesizing such programs by leveraging ideas from statistical learning theory\nto provide statistical soundness guarantees. We evaluate our approach on\nsynthesizing list processing programs that include DNN components used to\nprocess image inputs, as well as case studies on image classification and on\nprecision medicine. Our results demonstrate that our approach can be used to\nsynthesize programs with probabilistic guarantees.",
    "descriptor": "",
    "authors": [
      "Osbert Bastani"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05390"
  },
  {
    "id": "arXiv:2110.05392",
    "title": "Local Effects of Grid-Forming Converters Providing Frequency Regulation  to Bulk Power Grids",
    "abstract": "The progressive displacing of conventional generation in favour of renewable\nenergy sources requires restoring an adequate capacity of regulating power to\nensure reliable operation of power systems. Battery Energy Storage Systems\n(BESSs) are considered to be promising assets to restore suitable frequency\nregulation capacity levels. BESSs are typically connected to the grid with\npower-converters, able to operate in either grid-forming or grid-following\nmodes. This paper quantitatively assesses the impact on the local distribution\ngrid of BESSs providing frequency regulation to bulk power systems. Specific\nmetrics are proposed to compare the performance of grid-forming and\ngrid-following control. Experimental results are obtained taking advantage of a\n720 kVA/500 kWh BESS connected to the 20 kV distribution grid of the EPFL\ncampus. The quantitative evaluation based on suitably proposed metrics confirms\nthe superior performance of the grid-forming strategy, compared to the\ngrid-following one.",
    "descriptor": "\nComments: 5 pages, 6 figures, accepted by conference 2021 IEEE PES Innovative Smart Grid Technology - Asia\n",
    "authors": [
      "Antonio Zecchino",
      "Francesco Gerini",
      "Yihui Zuo",
      "Rachid Cherkaoui",
      "Mario Paolone",
      "Elena Vagnoni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.05392"
  },
  {
    "id": "arXiv:2110.05402",
    "title": "Robustness in Nonorthogonal Multiple Access 5G Networks",
    "abstract": "The diversity of fifth generation (5G) network use cases, multiple access\ntechnologies, and network deployments requires measures of network robustness\nthat complement throughput-centric error rates. In this paper, we investigate\nrobustness in nonorthogonal multiple access (NOMA) 5G networks through temporal\nnetwork theory. We develop a graph model and analytical framework to\ncharacterize time-varying network connectedness as a function of NOMA\noverloading. We extend our analysis to derive lower bounds and probability\nexpressions for the number of medium access control frames required to achieve\npairwise connectivity between all network devices. We support our analytical\nresults through simulation.",
    "descriptor": "\nComments: 11 pages, 3 figures, This paper has been accepted for the 55th Hawaii International Conference on System Sciences (HICSS-55)\n",
    "authors": [
      "Benjamin Pimentel",
      "Alex Bordetsky",
      "Ralucca Gera"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.05402"
  },
  {
    "id": "arXiv:2110.05403",
    "title": "Artificial Intelligence in Electric Machine Drives: Advances and Trends",
    "abstract": "This review paper systematically summarizes the existing literature on\napplying classical AI techniques and advanced deep learning algorithms to\nelectric machine drives. It is anticipated that with the rapid progress in deep\nlearning models and embedded hardware platforms, AI-based data-driven\napproaches will become increasingly popular for the automated high-performance\ncontrol of electric machines. Additionally, this paper also provides some\noutlook towards promoting its widespread application in the industry, such as\nimplementing advanced RL algorithms with good domain adaptation and transfer\nlearning capabilities and deploying them onto low-cost SoC FPGA devices.",
    "descriptor": "",
    "authors": [
      "Shen Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05403"
  },
  {
    "id": "arXiv:2110.05404",
    "title": "Symmetries in Reversible Programming: From Symmetric Rig Groupoids to  Reversible Programming Languages",
    "abstract": "The $\\mathit{\\Pi}$ family of reversible programming languages for boolean\ncircuits is presented as a syntax of combinators witnessing type isomorphisms\nof algebraic datatypes. In this paper, we give a denotational semantics for\nthis language, using the language of weak groupoids \\`a la Homotopy Type\nTheory, and show how to derive an equational theory for it, presented by\n2-combinators witnessing equivalences of reversible circuits. We establish a\ncorrespondence between the syntactic groupoid of the language and a formally\npresented univalent subuniverse of finite types. The correspondence relates\n1-combinators to 1-paths, and 2-combinators to 2-paths in the universe, which\nis shown to be sound and complete for both levels, establishing full\nabstraction and adequacy. We extend the already established Curry-Howard\ncorrespondence for $\\mathit{\\Pi}$ to a Curry-Howard-Lambek correspondence\nbetween Reversible Logic, Reversible Programming Languages, and Symmetric Rig\nGroupoids, by showing that the syntax of $\\mathit{\\Pi}$ is presented by the\nfree symmetric rig groupoid, given by finite sets and permutations. Our proof\nuses techniques from the theory of group presentations and rewriting systems to\nsolve the word problem for symmetric groups. Using the formalisation of our\nresults, we show how to perform normalisation-by-evaluation, verification, and\nsynthesis of reversible logic gates, motivated by examples from quantum\ncomputing.",
    "descriptor": "\nComments: Conditionally accepted to POPL'22\n",
    "authors": [
      "Vikraman Choudhury",
      "Jacek Karwowski",
      "Amr Sabry"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.05404"
  },
  {
    "id": "arXiv:2110.05409",
    "title": "Breaking the Softmax Bottleneck for Sequential Recommender Systems with  Dropout and Decoupling",
    "abstract": "The Softmax bottleneck was first identified in language modeling as a\ntheoretical limit on the expressivity of Softmax-based models. Being one of the\nmost widely-used methods to output probability, Softmax-based models have found\na wide range of applications, including session-based recommender systems\n(SBRSs). Softmax-based models consist of a Softmax function on top of a final\nlinear layer. The bottleneck has been shown to be caused by rank deficiency in\nthe final linear layer due to its connection with matrix factorization. In this\npaper, we show that there are more aspects to the Softmax bottleneck in SBRSs.\nContrary to common beliefs, overfitting does happen in the final linear layer,\nwhile it is often associated with complex networks. Furthermore, we identified\nthat the common technique of sharing item embeddings among session sequences\nand the candidate pool creates a tight-coupling that also contributes to the\nbottleneck. We propose a simple yet effective method, Dropout and Decoupling\n(D&D), to alleviate these problems. Our experiments show that our method\nsignificantly improves the accuracy of a variety of Softmax-based SBRS\nalgorithms. When compared to other computationally expensive methods, such as\nMLP and MoS (Mixture of Softmaxes), our method performs on par with and at\ntimes even better than those methods, while keeping the same time complexity as\nSoftmax-based models.",
    "descriptor": "",
    "authors": [
      "Ying-Chen Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.05409"
  },
  {
    "id": "arXiv:2110.05412",
    "title": "Free Commutative Monoids in Homotopy Type Theory",
    "abstract": "We develop a constructive theory of finite multisets, defining them as free\ncommutative monoids in Homotopy Type Theory.\nWe formalise two algebraic presentations of this construction using 1-HITs,\nestablishing the universal property for each and thereby their equivalence.\nThese presentations correspond to equational theories including a commutation\naxiom.\nIn this setting, we prove important structural combinatorial properties of\nsingleton multisets arising from concatenations and projections of multisets.\nThis is done in generality, without assuming decidable equality on the carrier\nset.\nFurther, as applications, we present a constructive formalisation of the\nrelational model of differential linear logic and use it to characterise the\nequality type of multisets.\nThis leads us to the introduction of a novel conditional equational\npresentation of the finite-multiset construction.",
    "descriptor": "\nComments: Under submission\n",
    "authors": [
      "Vikraman Choudhury",
      "Marcelo Fiore"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Combinatorics (math.CO)",
      "Category Theory (math.CT)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.05412"
  },
  {
    "id": "arXiv:2110.05415",
    "title": "Safe Model-Based Reinforcement Learning Using Robust Control Barrier  Functions",
    "abstract": "Reinforcement Learning (RL) is effective in many scenarios. However, it\ntypically requires the exploration of a sufficiently large number of\nstate-action pairs, some of which may be unsafe. Consequently, its application\nto safety-critical systems remains a challenge. Towards this end, an\nincreasingly common approach to address safety involves the addition of a\nsafety layer that projects the RL actions onto a safe set of actions. In turn,\na challenge for such frameworks is how to effectively couple RL with the safety\nlayer to improve the learning performance. In the context of leveraging control\nbarrier functions for safe RL training, prior work focuses on a restricted\nclass of barrier functions and utilizes an auxiliary neural net to account for\nthe effects of the safety layer which inherently results in an approximation.\nIn this paper, we frame safety as a differentiable\nrobust-control-barrier-function layer in a model-based RL framework. As such,\nthis approach both ensures safety and effectively guides exploration during\ntraining resulting in increased sample efficiency as demonstrated in the\nexperiments.",
    "descriptor": "\nComments: Submitted to the 2022 IEEE International Conference on Robotics and Automation (ICRA)\n",
    "authors": [
      "Yousef Emam",
      "Paul Glotfelter",
      "Zsolt Kira",
      "Magnus Egerstedt"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.05415"
  },
  {
    "id": "arXiv:2110.05419",
    "title": "Bottom-Up Constituency Parsing and Nested Named Entity Recognition with  Pointer Networks",
    "abstract": "Constituency parsing and nested named entity recognition (NER) are typical\n\\textit{nested structured prediction} tasks since they both aim to predict a\ncollection of nested and non-crossing spans. There are many previous studies\nadapting constituency parsing methods to tackle nested NER. In this work, we\npropose a novel global pointing mechanism for bottom-up parsing with pointer\nnetworks to do both tasks, which needs linear steps to parse. Our method obtain\nthe state-of-the-art performance on PTB among all BERT-based models (96.01 F1\nscore) and competitive performance on CTB7 in constituency parsing; and\ncomparable performance on three benchmark datasets of nested NER: ACE2004,\nACE2005, and GENIA. Our code is publicly available at\n\\url{https://github.com/sustcsonglin/pointer-net-for-nested}",
    "descriptor": "",
    "authors": [
      "Songlin Yang",
      "Kewei Tu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05419"
  },
  {
    "id": "arXiv:2110.05421",
    "title": "The One Step Malliavin scheme: new discretization of BSDEs implemented  with deep learning regressions",
    "abstract": "A novel discretization is presented for forward-backward stochastic\ndifferential equations (FBSDE) with differentiable coefficients, simultaneously\nsolving the BSDE and its Malliavin sensitivity problem. The control process is\nestimated by the corresponding linear BSDE driving the trajectories of the\nMalliavin derivatives of the solution pair, which implies the need to provide\naccurate $\\Gamma$ estimates. The approximation is based on a merged formulation\ngiven by the Feynman-Kac formulae and the Malliavin chain rule. The continuous\ntime dynamics is discretized with a theta-scheme. In order to allow for an\nefficient numerical solution of the arising semi-discrete conditional\nexpectations in possibly high-dimensions, it is fundamental that the chosen\napproach admits to differentiable estimates. Two fully-implementable schemes\nare considered: the BCOS method as a reference in the one-dimensional framework\nand neural network Monte Carlo regressions in case of high-dimensional\nproblems, similarly to the recently emerging class of Deep BSDE methods [Han et\nal. (2018), Hur\\'e et al. (2020)]. An error analysis is carried out to show\n$L^2$ convergence of order $1/2$, under standard Lipschitz assumptions and\nadditive noise in the forward diffusion. Numerical experiments are provided for\na range of different semi- and quasi-linear equations up to $50$ dimensions,\ndemonstrating that the proposed scheme yields a significant improvement in the\ncontrol estimations.",
    "descriptor": "\nComments: 31 pages, 4 figures, 2 tables\n",
    "authors": [
      "Balint Negyesi",
      "Kristoffer Andersson",
      "Cornelis W. Oosterlee"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05421"
  },
  {
    "id": "arXiv:2110.05422",
    "title": "Calibrate your listeners! Robust communication-based training for  pragmatic speakers",
    "abstract": "To be good conversational partners, natural language processing (NLP) systems\nshould be trained to produce contextually useful utterances. Prior work has\ninvestigated training NLP systems with communication-based objectives, where a\nneural listener stands in as a communication partner. However, these systems\ncommonly suffer from semantic drift where the learned language diverges\nradically from natural language. We propose a method that uses a population of\nneural listeners to regularize speaker training. We first show that language\ndrift originates from the poor uncertainty calibration of a neural listener,\nwhich makes high-certainty predictions on novel sentences. We explore ensemble-\nand dropout-based populations of listeners and find that the former results in\nbetter uncertainty quantification. We evaluate both population-based objectives\non reference games, and show that the ensemble method with better calibration\nenables the speaker to generate pragmatic utterances while scaling to a large\nvocabulary and generalizing to new games and listeners.",
    "descriptor": "\nComments: Findings of EMNLP 2021 Code: this https URL\n",
    "authors": [
      "Rose E. Wang",
      "Julia White",
      "Jesse Mu",
      "Noah D. Goodman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.05422"
  },
  {
    "id": "arXiv:2110.05423",
    "title": "Using Document Similarity Methods to create Parallel Datasets for Code  Translation",
    "abstract": "Translating source code from one programming language to another is a\ncritical, time-consuming task in modernizing legacy applications and codebases.\nRecent work in this space has drawn inspiration from the software naturalness\nhypothesis by applying natural language processing techniques towards\nautomating the code translation task. However, due to the paucity of parallel\ndata in this domain, supervised techniques have only been applied to a limited\nset of popular programming languages. To bypass this limitation, unsupervised\nneural machine translation techniques have been proposed to learn code\ntranslation using only monolingual corpora. In this work, we propose to use\ndocument similarity methods to create noisy parallel datasets of code, thus\nenabling supervised techniques to be applied for automated code translation\nwithout having to rely on the availability or expensive curation of parallel\ncode datasets. We explore the noise tolerance of models trained on such\nautomatically-created datasets and show that these models perform comparably to\nmodels trained on ground truth for reasonable levels of noise. Finally, we\nexhibit the practical utility of the proposed method by creating parallel\ndatasets for languages beyond the ones explored in prior work, thus expanding\nthe set of programming languages for automated code translation.",
    "descriptor": "",
    "authors": [
      "Mayank Agarwal",
      "Kartik Talamadupula",
      "Fernando Martinez",
      "Stephanie Houde",
      "Michael Muller",
      "John Richards",
      "Steven I Ross",
      "Justin D. Weisz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05423"
  },
  {
    "id": "arXiv:2110.05424",
    "title": "Nonlocal diffusion of variable order on graphs",
    "abstract": "Some aspects of nonlocal dynamics on directed and undirected networks for an\ninitial value problem whose Jacobian matrix is a variable-order fractional\npower of a Laplacian matrix are discussed here. Both directed and undirected\ngraphs are considered. Under appropriate assumptions, the existence,\nuniqueness, and uniform asymptotic stability of the solutions of the underlying\ninitial value problem are proved. Some examples giving a sample of the behavior\nof the dynamics are also included.",
    "descriptor": "",
    "authors": [
      "Daniele Bertaccini",
      "Fabio Durastante"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05424"
  },
  {
    "id": "arXiv:2110.05429",
    "title": "Differentially Private Approximate Quantiles",
    "abstract": "In this work we study the problem of differentially private (DP) quantiles,\nin which given dataset $X$ and quantiles $q_1, ..., q_m \\in [0,1]$, we want to\noutput $m$ quantile estimations which are as close as possible to the true\nquantiles and preserve DP. We describe a simple recursive DP algorithm, which\nwe call ApproximateQuantiles (AQ), for this task. We give a worst case upper\nbound on its error, and show that its error is much lower than of previous\nimplementations on several different datasets. Furthermore, it gets this low\nerror while running time two orders of magnitude faster that the best previous\nimplementation.",
    "descriptor": "",
    "authors": [
      "Haim Kaplan",
      "Shachar Schnapp",
      "Uri Stemmer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.05429"
  },
  {
    "id": "arXiv:2110.05430",
    "title": "Density-based interpretable hypercube region partitioning for mixed  numeric and categorical data",
    "abstract": "Consider a structured dataset of features, such as $\\{\\textrm{SEX},\n\\textrm{INCOME}, \\textrm{RACE}, \\textrm{EXPERIENCE}\\}$. A user may want to know\nwhere in the feature space observations are concentrated, and where it is\nsparse or empty. The existence of large sparse or empty regions can provide\ndomain knowledge of soft or hard feature constraints (e.g., what is the typical\nincome range, or that it may be unlikely to have a high income with few years\nof work experience). Also, these can suggest to the user that machine learning\n(ML) model predictions for data inputs in sparse or empty regions may be\nunreliable.\nAn interpretable region is a hyper-rectangle, such as $\\{\\textrm{RACE}\n\\in\\{\\textrm{Black}, \\textrm{White}\\}\\}\\:\\&$ $\\{10 \\leq \\:\\textrm{EXPERIENCE}\n\\:\\leq 13\\}$, containing all observations satisfying the constraints;\ntypically, such regions are defined by a small number of features. Our method\nconstructs an observation density-based partition of the observed feature space\nin the dataset into such regions. It has a number of advantages over others in\nthat it works on features of mixed type (numeric or categorical) in the\noriginal domain, and can separate out empty regions as well.\nAs can be seen from visualizations, the resulting partitions accord with\nspatial groupings that a human eye might identify; the results should thus\nextend to higher dimensions. We also show some applications of the partition to\nother data analysis tasks, such as inferring about ML model error, measuring\nhigh-dimensional density variability, and causal inference for treatment\neffect. Many of these applications are made possible by the hyper-rectangular\nform of the partition regions.",
    "descriptor": "",
    "authors": [
      "Samuel Ackerman",
      "Eitan Farchi",
      "Orna Raz",
      "Marcel Zalmanovici",
      "Maya Zohar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.05430"
  },
  {
    "id": "arXiv:2110.05433",
    "title": "Mesh Draping: Parametrization-Free Neural Mesh Transfer",
    "abstract": "Despite recent advances in geometric modeling, 3D mesh modeling still\ninvolves a considerable amount of manual labor by experts. In this paper, we\nintroduce Mesh Draping: a neural method for transferring existing mesh\nstructure from one shape to another. The method drapes the source mesh over the\ntarget geometry and at the same time seeks to preserve the carefully designed\ncharacteristics of the source mesh. At its core, our method deforms the source\nmesh using progressive positional encoding. We show that by leveraging\ngradually increasing frequencies to guide the neural optimization, we are able\nto achieve stable and high quality mesh transfer. Our approach is simple and\nrequires little user guidance, compared to contemporary surface mapping\ntechniques which rely on parametrization or careful manual tuning. Most\nimportantly, Mesh Draping is a parameterization-free method, and thus\napplicable to a variety of target shape representations, including point\nclouds, polygon soups, and non-manifold meshes. We demonstrate that the\ntransferred meshing remains faithful to the source mesh design characteristics,\nand at the same time fits the target geometry well.",
    "descriptor": "\nComments: 12 pages. Portions of this work previously appeared as arXiv:2104.09125v1 which has been split into two works: arXiv:2104.09125v2+ and this work\n",
    "authors": [
      "Amir Hertz",
      "Or Perel",
      "Raja Giryes",
      "Olga Sorkine-Hornung",
      "Daniel Cohen-Or"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05433"
  },
  {
    "id": "arXiv:2110.05437",
    "title": "Autonomous Racing using a Hybrid Imitation-Reinforcement Learning  Architecture",
    "abstract": "In this work, we present a rigorous end-to-end control strategy for\nautonomous vehicles aimed at minimizing lap times in a time attack racing\nevent. We also introduce AutoRACE Simulator developed as a part of this\nresearch project, which was employed to simulate accurate vehicular and\nenvironmental dynamics along with realistic audio-visual effects. We adopted a\nhybrid imitation-reinforcement learning architecture and crafted a novel reward\nfunction to train a deep neural network policy to drive (using imitation\nlearning) and race (using reinforcement learning) a car autonomously in less\nthan 20 hours. Deployment results were reported as a direct comparison of 10\nautonomous laps against 100 manual laps by 10 different human players. The\nautonomous agent not only exhibited superior performance by gaining 0.96\nseconds over the best manual lap, but it also dominated the human players by\n1.46 seconds with regard to the mean lap time. This dominance could be\njustified in terms of better trajectory optimization and lower reaction time of\nthe autonomous agent.",
    "descriptor": "",
    "authors": [
      "Chinmay Vilas Samak",
      "Tanmay Vilas Samak",
      "Sivanathan Kandhasamy"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.05437"
  },
  {
    "id": "arXiv:2110.05438",
    "title": "Zero-CPU Collection with Direct Telemetry Access",
    "abstract": "Programmable switches are driving a massive increase in fine-grained\nmeasurements. This puts significant pressure on telemetry collectors that have\nto process reports from many switches. Past research acknowledged this problem\nby either improving collectors' stack performance or by limiting the amount of\ndata sent from switches. In this paper, we take a different and radical\napproach: switches are responsible for directly inserting queryable telemetry\ndata into the collectors' memory, bypassing their CPU, and thereby improving\ntheir collection scalability. We propose to use a method we call \\emph{direct\ntelemetry access}, where switches jointly write telemetry reports directly into\nthe same collector's memory region, without coordination. Our solution, DART,\nis probabilistic, trading memory redundancy and query success probability for\nCPU resources at collectors. We prototype DART using commodity hardware such as\nP4 switches and RDMA NICs and show that we get high query success rates with a\nreasonable memory overhead. For example, we can collect INT path tracing\ninformation on a fat tree topology without a collector's CPU involvement while\nachieving 99.9\\% query success probability and using just 300 bytes per flow.",
    "descriptor": "\nComments: To appear in ACM HotNets 2021\n",
    "authors": [
      "Jonatan Langlet",
      "Ran Ben Basat",
      "Sivaramakrishnan Ramanathan",
      "Gabriele Oliaro",
      "Michael Mitzenmacher",
      "Minlan Yu",
      "Gianni Antichi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Data Structures and Algorithms (cs.DS)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.05438"
  },
  {
    "id": "arXiv:2110.05440",
    "title": "Safe Human-Interactive Control via Shielding",
    "abstract": "Ensuring safety for human-interactive robotics is important due to the\npotential for human injury. The key challenge is defining safety in a way that\naccounts for the complex range of human behaviors without modeling the human as\nan unconstrained adversary. We propose a novel approach to ensuring safety in\nthese settings. Our approach focuses on defining backup actions that we believe\nhuman always considers taking to avoid an accident -- e.g., brake to avoid\nrear-ending the other agent. Given such a definition, we consider a safety\nconstraint that guarantees safety as long as the human takes the appropriate\nbackup actions when necessary to ensure safety. Then, we propose an algorithm\nthat overrides an arbitrary given controller as needed to ensure that the robot\nis safe. We evaluate our approach in a simulated environment, interacting with\nboth real and simulated humans.",
    "descriptor": "",
    "authors": [
      "Jeevana Priya Inala",
      "Yecheng Jason Ma",
      "Osbert Bastani",
      "Xin Zhang",
      "Armando Solar-Lezama"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.05440"
  },
  {
    "id": "arXiv:2110.05441",
    "title": "Theoretical and numerical analysis for an interspecies competition model  with chemoattraction-consumption in fluids",
    "abstract": "This work is devoted to the theoretical and numerical analysis of a\ntwo-species chemotaxis- Navier-Stokes system with Lotka-Volterra competitive\nkinetics in a bounded domain of Rd, d = 2, 3. First, we study the existence of\nglobal weak solutions and establish a regularity criterion which provides\nsufficient conditions to ensure the strong regularity of the weak solutions.\nAfter, we propose a finite element numerical scheme in which we use a splitting\ntechnique obtained by introducing an auxiliary variable given by the gradient\nof the chemical concentration and applying an inductive strategy, in order to\ndeal with the chemoattraction terms in the two-species equations and prove\noptimal error estimates. For this scheme, we study the well-posedness and\nderive some uniform estimates for the discrete variables required in the\nconvergence analysis. Finally, we present some numerical simulations oriented\nto verify the good behavior of our scheme, as well as to check numerically the\noptimal error estimates proved in our theoretical analysis.",
    "descriptor": "",
    "authors": [
      "Carlos Mateo Beltr\u00e1n-Larrotta",
      "Diego Armando Rueda-G\u00f3mez",
      "\u00c9lder Jes\u00fas Villamizar-Roa"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.05441"
  },
  {
    "id": "arXiv:2110.05442",
    "title": "Neural Algorithmic Reasoners are Implicit Planners",
    "abstract": "Implicit planning has emerged as an elegant technique for combining learned\nmodels of the world with end-to-end model-free reinforcement learning. We study\nthe class of implicit planners inspired by value iteration, an algorithm that\nis guaranteed to yield perfect policies in fully-specified tabular\nenvironments. We find that prior approaches either assume that the environment\nis provided in such a tabular form -- which is highly restrictive -- or infer\n\"local neighbourhoods\" of states to run value iteration over -- for which we\ndiscover an algorithmic bottleneck effect. This effect is caused by explicitly\nrunning the planning algorithm based on scalar predictions in every state,\nwhich can be harmful to data efficiency if such scalars are improperly\npredicted. We propose eXecuted Latent Value Iteration Networks (XLVINs), which\nalleviate the above limitations. Our method performs all planning computations\nin a high-dimensional latent space, breaking the algorithmic bottleneck. It\nmaintains alignment with value iteration by carefully leveraging neural\ngraph-algorithmic reasoning and contrastive self-supervised learning. Across\neight low-data settings -- including classical control, navigation and Atari --\nXLVINs provide significant improvements to data efficiency against value\niteration-based implicit planners, as well as relevant model-free baselines.\nLastly, we empirically verify that XLVINs can closely align with value\niteration.",
    "descriptor": "\nComments: To appear at NeurIPS 2021 (Spotlight talk). 20 pages, 10 figures. arXiv admin note: text overlap with arXiv:2010.13146\n",
    "authors": [
      "Andreea Deac",
      "Petar Veli\u010dkovi\u0107",
      "Ognjen Milinkovi\u0107",
      "Pierre-Luc Bacon",
      "Jian Tang",
      "Mladen Nikoli\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.05442"
  },
  {
    "id": "arXiv:2110.05444",
    "title": "User-driven Design and Evaluation of Liquid Types in Java",
    "abstract": "Bugs that are detected earlier during the development lifecycle are easier\nand cheaper to fix, whereas bugs that are found during production are difficult\nand expensive to address, and may have dire consequences. Type systems are\nparticularly effective at identifying and preventing bugs early in the\ndevelopment lifecycle by causing invalid programs to result in build failure.\nLiquid Types are more powerful than those found in mainstream programming\nlanguages, allowing the detection of more classes of bugs. However, while\nLiquid Types were proposed in 2008 with their integration in ML and\nsubsequently introduced in C (2012), Javascript(2012) and Haskell(2014) through\nlanguage extensions, they have yet to become widely adopted by mainstream\ndevelopers. This paper investigates how Liquid Types can be integrated in a\nmainstream programming language, Java, by proposing a new design that aims to\nlower the barrier to entry and adapts to problems that Java developers commonly\nencounter at runtime. To promote accessibility, we conducted a series of\ndeveloper surveys to design the syntax of LiquidJava, our prototype. To\nevaluate the prototype's usability, we conducted a user study of 30 Java\ndevelopers, concluding that users intend to use LiquidJava and that it helped\nto find more bugs and debug faster.",
    "descriptor": "",
    "authors": [
      "Catarina Gamboa",
      "Paulo Alexandre Santos",
      "Christopher S. Timperley",
      "Alcides Fonseca"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.05444"
  },
  {
    "id": "arXiv:2110.05445",
    "title": "Disease Informed Neural Networks",
    "abstract": "We introduce Disease Informed Neural Networks (DINNs) -- neural networks\ncapable of learning how diseases spread, forecasting their progression, and\nfinding their unique parameters (e.g. death rate). Here, we used DINNs to\nidentify the dynamics of 11 highly infectious and deadly diseases. These\nsystems vary in their complexity, ranging from 3D to 9D ODEs, and from a few\nparameters to over a dozen. The diseases include COVID, Anthrax, HIV, Zika,\nSmallpox, Tuberculosis, Pneumonia, Ebola, Dengue, Polio, and Measles. Our\ncontribution is three fold. First, we extend the recent physics informed neural\nnetworks (PINNs) approach to a large number of infectious diseases. Second, we\nperform an extensive analysis of the capabilities and shortcomings of PINNs on\ndiseases. Lastly, we show the ease at which one can use DINN to effectively\nlearn COVID's spread dynamics and forecast its progression a month into the\nfuture from real-life data. Code and data can be found here:\nhttps://github.com/Shaier/DINN.",
    "descriptor": "",
    "authors": [
      "Sagi Shaier",
      "Maziar Raissi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2110.05445"
  },
  {
    "id": "arXiv:2110.05448",
    "title": "Unsupervised Neural Machine Translation with Generative Language Models  Only",
    "abstract": "We show how to derive state-of-the-art unsupervised neural machine\ntranslation systems from generatively pre-trained language models. Our method\nconsists of three steps: few-shot amplification, distillation, and\nbacktranslation. We first use the zero-shot translation ability of large\npre-trained language models to generate translations for a small set of\nunlabeled sentences. We then amplify these zero-shot translations by using them\nas few-shot demonstrations for sampling a larger synthetic dataset. This\ndataset is distilled by discarding the few-shot demonstrations and then\nfine-tuning. During backtranslation, we repeatedly generate translations for a\nset of inputs and then fine-tune a single language model on both directions of\nthe translation task at once, ensuring cycle-consistency by swapping the roles\nof gold monotext and generated translations when fine-tuning. By using our\nmethod to leverage GPT-3's zero-shot translation capability, we achieve a new\nstate-of-the-art in unsupervised translation on the WMT14 English-French\nbenchmark, attaining a BLEU score of 42.1.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Jesse Michael Han",
      "Igor Babuschkin",
      "Harrison Edwards",
      "Arvind Neelakantan",
      "Tao Xu",
      "Stanislas Polu",
      "Alex Ray",
      "Pranav Shyam",
      "Aditya Ramesh",
      "Alec Radford",
      "Ilya Sutskever"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05448"
  },
  {
    "id": "arXiv:2110.05454",
    "title": "Momentum Centering and Asynchronous Update for Adaptive Gradient Methods",
    "abstract": "We propose ACProp (Asynchronous-centering-Prop), an adaptive optimizer which\ncombines centering of second momentum and asynchronous update (e.g. for $t$-th\nupdate, denominator uses information up to step $t-1$, while numerator uses\ngradient at $t$-th step). ACProp has both strong theoretical properties and\nempirical performance. With the example by Reddi et al. (2018), we show that\nasynchronous optimizers (e.g. AdaShift, ACProp) have weaker convergence\ncondition than synchronous optimizers (e.g. Adam, RMSProp, AdaBelief); within\nasynchronous optimizers, we show that centering of second momentum further\nweakens the convergence condition. We demonstrate that ACProp has a convergence\nrate of $O(\\frac{1}{\\sqrt{T}})$ for the stochastic non-convex case, which\nmatches the oracle rate and outperforms the $O(\\frac{logT}{\\sqrt{T}})$ rate of\nRMSProp and Adam. We validate ACProp in extensive empirical studies: ACProp\noutperforms both SGD and other adaptive optimizers in image classification with\nCNN, and outperforms well-tuned adaptive optimizers in the training of various\nGAN models, reinforcement learning and transformers. To sum up, ACProp has good\ntheoretical properties including weak convergence condition and optimal\nconvergence rate, and strong empirical performance including good\ngeneralization like SGD and training stability like Adam.",
    "descriptor": "",
    "authors": [
      "Juntang Zhuang",
      "Yifan Ding",
      "Tommy Tang",
      "Nicha Dvornek",
      "Sekhar Tatikonda",
      "James S. Duncan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.05454"
  },
  {
    "id": "arXiv:2110.05456",
    "title": "Rome was built in 1776: A Case Study on Factual Correctness in  Knowledge-Grounded Response Generation",
    "abstract": "Recently neural response generation models have leveraged large pre-trained\ntransformer models and knowledge snippets to generate relevant and informative\nresponses. However, this does not guarantee that generated responses are\nfactually correct. In this paper, we examine factual correctness in\nknowledge-grounded neural response generation models. We present a human\nannotation setup to identify three different response types: responses that are\nfactually consistent with respect to the input knowledge, responses that\ncontain hallucinated knowledge, and non-verifiable chitchat style responses. We\nuse this setup to annotate responses generated using different stateof-the-art\nmodels, knowledge snippets, and decoding strategies. In addition, to facilitate\nthe development of a factual consistency detector, we automatically create a\nnew corpus called Conv-FEVER that is adapted from the Wizard of Wikipedia\ndataset and includes factually consistent and inconsistent responses. We\ndemonstrate the benefit of our Conv-FEVER dataset by showing that the models\ntrained on this data perform reasonably well to detect factually inconsistent\nresponses with respect to the provided knowledge through evaluation on our\nhuman annotated data. We will release the Conv-FEVER dataset and the human\nannotated responses.",
    "descriptor": "",
    "authors": [
      "Sashank Santhanam",
      "Behnam Hedayatnia",
      "Spandana Gella",
      "Aishwarya Padmakumar",
      "Seokhwan Kim",
      "Yang Liu",
      "Dilek Hakkani-Tur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05456"
  },
  {
    "id": "arXiv:2110.05457",
    "title": "Legged Robots that Keep on Learning: Fine-Tuning Locomotion Policies in  the Real World",
    "abstract": "Legged robots are physically capable of traversing a wide range of\nchallenging environments, but designing controllers that are sufficiently\nrobust to handle this diversity has been a long-standing challenge in robotics.\nReinforcement learning presents an appealing approach for automating the\ncontroller design process and has been able to produce remarkably robust\ncontrollers when trained in a suitable range of environments. However, it is\ndifficult to predict all likely conditions the robot will encounter during\ndeployment and enumerate them at training-time. What if instead of training\ncontrollers that are robust enough to handle any eventuality, we enable the\nrobot to continually learn in any setting it finds itself in? This kind of\nreal-world reinforcement learning poses a number of challenges, including\nefficiency, safety, and autonomy. To address these challenges, we propose a\npractical robot reinforcement learning system for fine-tuning locomotion\npolicies in the real world. We demonstrate that a modest amount of real-world\ntraining can substantially improve performance during deployment, and this\nenables a real A1 quadrupedal robot to autonomously fine-tune multiple\nlocomotion skills in a range of environments, including an outdoor lawn and a\nvariety of indoor terrains.",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Laura Smith",
      "J. Chase Kew",
      "Xue Bin Peng",
      "Sehoon Ha",
      "Jie Tan",
      "Sergey Levine"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.05457"
  },
  {
    "id": "arXiv:2110.05458",
    "title": "Learning Realistic Human Reposing using Cyclic Self-Supervision with 3D  Shape, Pose, and Appearance Consistency",
    "abstract": "Synthesizing images of a person in novel poses from a single image is a\nhighly ambiguous task. Most existing approaches require paired training images;\ni.e. images of the same person with the same clothing in different poses.\nHowever, obtaining sufficiently large datasets with paired data is challenging\nand costly. Previous methods that forego paired supervision lack realism. We\npropose a self-supervised framework named SPICE (Self-supervised Person Image\nCrEation) that closes the image quality gap with supervised methods. The key\ninsight enabling self-supervision is to exploit 3D information about the human\nbody in several ways. First, the 3D body shape must remain unchanged when\nreposing. Second, representing body pose in 3D enables reasoning about self\nocclusions. Third, 3D body parts that are visible before and after reposing,\nshould have similar appearance features. Once trained, SPICE takes an image of\na person and generates a new image of that person in a new target pose. SPICE\nachieves state-of-the-art performance on the DeepFashion dataset, improving the\nFID score from 29.9 to 7.8 compared with previous unsupervised methods, and\nwith performance similar to the state-of-the-art supervised method (6.4). SPICE\nalso generates temporally coherent videos given an input image and a sequence\nof poses, despite being trained on static images only.",
    "descriptor": "\nComments: International Conference on Computer Vision (ICCV)\n",
    "authors": [
      "Soubhik Sanyal",
      "Alex Vorobiov",
      "Timo Bolkart",
      "Matthew Loper",
      "Betty Mohler",
      "Larry Davis",
      "Javier Romero",
      "Michael J. Black"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05458"
  },
  {
    "id": "arXiv:2110.05461",
    "title": "Implicit gradients based novel conservative numerical scheme for  compressible flows",
    "abstract": "This paper introduces a novel approach to compute the numerical fluxes at the\ncell boundaries for a cell-centered conservative numerical scheme. Explicit\ngradients used in deriving the reconstruction polynomials are replaced by\nhigh-order gradients computed by compact finite differences, referred to as\nimplicit gradients in this paper. The new approach has superior dispersion and\ndissipation properties in comparison to the compact reconstruction approach. A\nproblem-independent shock capturing approach via Boundary Variation Diminishing\n(BVD) algorithm is used to suppress oscillations for the simulation of flows\nwith shocks and material interfaces. Several numerical test cases are carried\nout to verify the proposed method's capability using the implicit gradient\nmethod for compressible flows.",
    "descriptor": "",
    "authors": [
      "Amareshwara Sainadh Chamarthi",
      "Abhishek Chintagunta",
      "Natan Hoffmann",
      "Hiroaki Nishikawa",
      "Steven H. Frankel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05461"
  },
  {
    "id": "arXiv:2110.05464",
    "title": "We Need to Talk About Data: The Importance of Data Readiness in Natural  Language Processing",
    "abstract": "In this paper, we identify the state of data as being an important reason for\nfailure in applied Natural Language Processing (NLP) projects. We argue that\nthere is a gap between academic research in NLP and its application to problems\noutside academia, and that this gap is rooted in poor mutual understanding\nbetween academic researchers and their non-academic peers who seek to apply\nresearch results to their operations. To foster transfer of research results\nfrom academia to non-academic settings, and the corresponding influx of\nrequirements back to academia, we propose a method for improving the\ncommunication between researchers and external stakeholders regarding the\naccessibility, validity, and utility of data based on Data Readiness Levels\n\\cite{lawrence2017data}. While still in its infancy, the method has been\niterated on and applied in multiple innovation and research projects carried\nout with stakeholders in both the private and public sectors. Finally, we\ninvite researchers and practitioners to share their experiences, and thus\ncontributing to a body of work aimed at raising awareness of the importance of\ndata readiness for NLP.",
    "descriptor": "",
    "authors": [
      "Fredrik Olsson",
      "Magnus Sahlgren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05464"
  },
  {
    "id": "arXiv:2110.05472",
    "title": "Differentiable Stereopsis: Meshes from multiple views using  differentiable rendering",
    "abstract": "We propose Differentiable Stereopsis, a multi-view stereo approach that\nreconstructs shape and texture from few input views and noisy cameras. We pair\ntraditional stereopsis and modern differentiable rendering to build an\nend-to-end model which predicts textured 3D meshes of objects with varying\ntopologies and shape. We frame stereopsis as an optimization problem and\nsimultaneously update shape and cameras via simple gradient descent. We run an\nextensive quantitative analysis and compare to traditional multi-view stereo\ntechniques and state-of-the-art learning based methods. We show compelling\nreconstructions on challenging real-world scenes and for an abundance of object\ntypes with complex shape, topology and texture. Project webpage:\nhttps://shubham-goel.github.io/ds/",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Shubham Goel",
      "Georgia Gkioxari",
      "Jitendra Malik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05472"
  },
  {
    "id": "arXiv:2110.05474",
    "title": "Semi-Supervised Semantic Segmentation via Adaptive Equalization Learning",
    "abstract": "Due to the limited and even imbalanced data, semi-supervised semantic\nsegmentation tends to have poor performance on some certain categories, e.g.,\ntailed categories in Cityscapes dataset which exhibits a long-tailed label\ndistribution. Existing approaches almost all neglect this problem, and treat\ncategories equally. Some popular approaches such as consistency regularization\nor pseudo-labeling may even harm the learning of under-performing categories,\nthat the predictions or pseudo labels of these categories could be too\ninaccurate to guide the learning on the unlabeled data. In this paper, we look\ninto this problem, and propose a novel framework for semi-supervised semantic\nsegmentation, named adaptive equalization learning (AEL). AEL adaptively\nbalances the training of well and badly performed categories, with a confidence\nbank to dynamically track category-wise performance during training. The\nconfidence bank is leveraged as an indicator to tilt training towards\nunder-performing categories, instantiated in three strategies: 1) adaptive\nCopy-Paste and CutMix data augmentation approaches which give more chance for\nunder-performing categories to be copied or cut; 2) an adaptive data sampling\napproach to encourage pixels from under-performing category to be sampled; 3) a\nsimple yet effective re-weighting method to alleviate the training noise raised\nby pseudo-labeling. Experimentally, AEL outperforms the state-of-the-art\nmethods by a large margin on the Cityscapes and Pascal VOC benchmarks under\nvarious data partition protocols. Code is available at\nhttps://github.com/hzhupku/SemiSeg-AEL",
    "descriptor": "\nComments: Accepted by NeurIPS 2021 (spotlight). Code is available at this https URL\n",
    "authors": [
      "Hanzhe Hu",
      "Fangyun Wei",
      "Han Hu",
      "Qiwei Ye",
      "Jinshi Cui",
      "Liwei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05474"
  },
  {
    "id": "arXiv:2101.12010",
    "title": "Modeling Spatial Nonstationarity via Deformable Convolutions for Deep  Traffic Flow Prediction",
    "abstract": "Deep neural networks are being increasingly used for short-term traffic flow\nprediction, which can be generally categorized as convolutional (CNNs) or graph\nneural networks (GNNs). CNNs are preferable for region-wise traffic prediction\nby taking advantage of localized spatial correlations, whilst GNNs achieves\nbetter performance for graph-structured traffic data. When applied to\nregion-wise traffic prediction, CNNs typically partition an underlying\nterritory into grid-like spatial units, and employ standard convolutions to\nlearn spatial dependence among the units. However, standard convolutions with\nfixed geometric structures cannot fully model the nonstationary characteristics\nof local traffic flows. To overcome the deficiency, we introduce deformable\nconvolution that augments the spatial sampling locations with additional\noffsets, to enhance the modeling capability of spatial nonstationarity. On this\nbasis, we design a deep deformable convolutional residual network, namely\nDeFlow-Net, that can effectively model global spatial dependence, local spatial\nnonstationarity, and temporal periodicity of traffic flows. Furthermore, to\nbetter fit with convolutions, we suggest to first aggregate traffic flows\naccording to pre-conceived regions or self-organized regions based on traffic\nflows, then dispose to sequentially organized raster images for network input.\nExtensive experiments on real-world traffic flows demonstrate that DeFlow-Net\noutperforms GNNs and existing CNNs using standard convolutions, and spatial\npartition by pre-conceived regions or self-organized regions further enhances\nthe performance. We also demonstrate the advantage of DeFlow-Net in maintaining\nspatial autocorrelation, and reveal the impacts of partition shapes and scales\non deep traffic flow prediction.",
    "descriptor": "",
    "authors": [
      "Wei Zeng",
      "Chengqiao Lin",
      "Kang Liu",
      "Juncong Lin",
      "Anthony K. H. Tung"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.12010"
  },
  {
    "id": "arXiv:2109.05848",
    "title": "Closed-Loop Neural Prostheses with On-Chip Intelligence: A Review and A  Low-Latency Machine Learning Model for Brain State Detection",
    "abstract": "The application of closed-loop approaches in systems neuroscience and\ntherapeutic stimulation holds great promise for revolutionizing our\nunderstanding of the brain and for developing novel neuromodulation therapies\nto restore lost functions. Neural prostheses capable of multi-channel neural\nrecording, on-site signal processing, rapid symptom detection, and closed-loop\nstimulation are critical to enabling such novel treatments. However, the\nexisting closed-loop neuromodulation devices are too simplistic and lack\nsufficient on-chip processing and intelligence. In this paper, we first discuss\nboth commercial and investigational closed-loop neuromodulation devices for\nbrain disorders. Next, we review state-of-the-art neural prostheses with\non-chip machine learning, focusing on application-specific integrated circuits\n(ASIC). System requirements, performance and hardware comparisons, design\ntrade-offs, and hardware optimization techniques are discussed. To facilitate a\nfair comparison and guide design choices among various on-chip classifiers, we\npropose a new energy-area (E-A) efficiency figure of merit that evaluates\nhardware efficiency and multi-channel scalability. Finally, we present several\ntechniques to improve the key design metrics of tree-based on-chip classifiers,\nboth in the context of ensemble methods and oblique structures.",
    "descriptor": "",
    "authors": [
      "Bingzhao Zhu",
      "Uisub Shin",
      "Mahsa Shoaran"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2109.05848"
  },
  {
    "id": "arXiv:2110.03176",
    "title": "Emergence of Robust and Efficient Networks in a Family of Attachment  Models",
    "abstract": "Self-organization of robust and efficient networks is important for a future\ndesign of communication or transportation systems, because both characteristics\nare not coexisting in many real networks. As one of the candidates for the\ncoexisting, the optimal robustness of onion-like structure with positive\ndegree-degree correlations has recently been found, and it can be generated by\nincrementally growing methods based on a pair of random and intermediation\nattachments with the minimum degree selection. In this paper, we introduce a\ncontinuous interpolation by a parameter $\\beta\\geq 0$ between random and the\nminimum degree attachments to investigate the reason why the minimum degree\nselection is important. However, we find that the special case of the minimum\ndegree attachment can generate highly robust networks but with low efficiency\nas a chain structure. Furthermore, we consider two intermediation models\nmodified with the inverse preferential attachment for investigating the effect\nof distance on the emergence of robust onion-like structure. The inverse\npreferential attachments in a class of mixed attachment and two intermediation\nmodels are effective for the emergence of robust onion-like structure, however,\nwhen $\\beta$ is large enough, a small amount of random attachment is necessary\nfor the network efficiency. Such attachment models indicate a prospective\ndirection to the future growth of our network infrastructures.",
    "descriptor": "",
    "authors": [
      "Fuxuan Liao",
      "Yukio Hayashi"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2110.03176"
  },
  {
    "id": "arXiv:2110.04308",
    "title": "VIRUP : The Virtual Reality Universe Project",
    "abstract": "VIRUP is a new C++ open source software that provides an interactive virtual\nreality environment to navigate through large scientific astrophysical datasets\nobtained from both observations and simulations. It is tailored to visualize\nterabytes of data, rendering at 90 frames per second in order to ensure an\noptimal immersion experience. While VIRUP has initially been designed to work\nwith gaming virtual reality headsets, it supports different modern immersive\nsystems like 3D screens, 180 deg. domes or 360 deg. panorama. VIRUP is\nscriptable thanks to the Python language, a feature that allows to immerse\nvisitors through pre-selected scenes or to pre-render sequences to create\nmovies. A companion video (https://www.youtube.com/watch?v=KJJXbcf8kxA) to the\nlast SDSS 2020 release as well as a 21 minute long documentary, The Archaeology\nof Light, https://go.epfl.ch/ArchaeologyofLight have been both 100% produced\nusing VIRUP.",
    "descriptor": "\nComments: 9 pages, 8 figures. Webpage:this http URL, link to \"The Archaeology of Light\": this https URL\n",
    "authors": [
      "Florian Cabot",
      "Yves Revaz",
      "Jean-Paul Kneib",
      "Hadrien Gurnel",
      "Sarah Kenderdine"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Graphics (cs.GR)",
      "Human-Computer Interaction (cs.HC)",
      "Physics Education (physics.ed-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.04308"
  },
  {
    "id": "arXiv:2110.04331",
    "title": "MusicNet: Compact Convolutional Neural Network for Real-time Background  Music Detection",
    "abstract": "With the recent growth of remote and hybrid work, online meetings often\nencounter challenging audio contexts such as background noise, music, and echo.\nAccurate real-time detection of music events can help to improve the user\nexperience in such scenarios, e.g., by switching to high-fidelity\nmusic-specific codec or selecting the optimal noise suppression model.\nIn this paper, we present MusicNet -- a compact high-performance model for\ndetecting background music in the real-time communications pipeline. In online\nvideo meetings, which is our main use case, music almost always co-occurs with\nspeech and background noises, making the accurate classification quite\nchallenging.\nThe proposed model is a binary classifier that consists of a compact\nconvolutional neural network core preceded by an in-model featurization layer.\nIt takes 9 seconds of raw audio as input and does not require any\nmodel-specific featurization on the client.\nWe train our model on a balanced subset of the AudioSet data and use 1000\ncrowd-sourced real test clips to validate the model. Finally, we compare\nMusicNet performance to 20 other state-of-the-art models.\nOur classifier gives a true positive rate of 81.3% at a 0.1% false positive\nrate, which is significantly better than any other model in the study. Our\nmodel is also 10x smaller and has 4x faster inference than the comparable\nbaseline.",
    "descriptor": "",
    "authors": [
      "Chandan K.A. Reddy",
      "Vishak Gopa",
      "Harishchandra Dubey",
      "Sergiy Matusevych",
      "Ross Cutler",
      "Robert Aichner"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04331"
  },
  {
    "id": "arXiv:2110.04338",
    "title": "Learning from non-irreducible Markov chains",
    "abstract": "Most of the existing literature on supervised learning problems focuses on\nthe case when the training data set is drawn from an i.i.d. sample. However,\nmany practical supervised learning problems are characterized by temporal\ndependence and strong correlation between the marginals of the data-generating\nprocess, suggesting that the i.i.d. assumption is not always justified. This\nproblem has been already considered in the context of Markov chains satisfying\nthe Doeblin condition. This condition, among other things, implies that the\nchain is not singular in its behavior, i.e. it is irreducible. In this article,\nwe focus on the case when the training data set is drawn from a not necessarily\nirreducible Markov chain. Under the assumption that the chain is uniformly\nergodic with respect to the $\\mathrm{L}^1$-Wasserstein distance, and certain\nregularity assumptions on the hypothesis class and the state space of the\nchain, we first obtain a uniform convergence result for the corresponding\nsample error, and then we conclude learnability of the approximate sample error\nminimization algorithm and find its generalization bounds. At the end, a\nrelative uniform convergence result for the sample error is also discussed.",
    "descriptor": "",
    "authors": [
      "Nikola Sandri\u0107",
      "Stjepan \u0160ebek"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04338"
  },
  {
    "id": "arXiv:2110.04378",
    "title": "Performance optimizations on deep noise suppression models",
    "abstract": "We study the role of magnitude structured pruning as an architecture search\nto speed up the inference time of a deep noise suppression (DNS) model. While\ndeep learning approaches have been remarkably successful in enhancing audio\nquality, their increased complexity inhibits their deployment in real-time\napplications. We achieve up to a 7.25X inference speedup over the baseline,\nwith a smooth model performance degradation. Ablation studies indicate that our\nproposed network re-parameterization (i.e., size per layer) is the major driver\nof the speedup, and that magnitude structured pruning does comparably to\ndirectly training a model in the smaller size. We report inference speed\nbecause a parameter reduction does not necessitate speedup, and we measure\nmodel quality using an accurate non-intrusive objective speech quality metric.",
    "descriptor": "",
    "authors": [
      "Jerry Chee",
      "Sebastian Braun",
      "Vishak Gopal",
      "Ross Cutler"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04378"
  },
  {
    "id": "arXiv:2110.04385",
    "title": "Individualized Hear-through For Acoustic Transparency Using PCA-Based  Sound Pressure Estimation At The Eardrum",
    "abstract": "The hear-through functionality on hearing devices, which allows hearing\nequivalent to the open-ear while providing the possibility to modify the sound\npressure at the eardrum in a desired manner, has drawn great attention from\nresearchers in recent years. To this end, the output of the device is processed\nby means of an equalization filter, such that the transfer function between\nexternal sound sources and the eardrum is equivalent for the open-ear and the\naided condition with the device in the ear. To achieve an ideal performance,\nthe equalization filter design assumes the exact knowledge of all the relevant\nacoustic transfer functions. A particular challenge is the transfer function\nbetween the hearing device receiver and the eardrum, which is difficult to\nobtain in practice as it requires additional probe-tube measurements. In this\nwork, we address this issue by proposing an individualized hear-through\nequalization filter design that leverages the measurement of the so-called\nsecondary path to predict the sound pressure at the eardrum. Experimental\nresults using real-ear measured transfer functions confirm that the proposed\nmethod achieves a good sound quality compared to the open-ear while\noutperforming the generic filter design that is based on an average\nequalization.",
    "descriptor": "\nComments: 5 pages, 5 figures, submitted to ICASSP 2022\n",
    "authors": [
      "Wenyu Jin",
      "Tim Schoof",
      "Henning Schepker"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04385"
  },
  {
    "id": "arXiv:2110.04391",
    "title": "Aura: Privacy-preserving augmentation to improve test set diversity in  noise suppression applications",
    "abstract": "Noise suppression models running in production environments are commonly\ntrained on publicly available datasets. However, this approach leads to\nregressions in production environments due to the lack of training/testing on\nrepresentative customer data. Moreover, due to privacy reasons, developers\ncannot listen to customer content. This `ears-off' situation motivates\naugmenting existing datasets in a privacy-preserving manner. In this paper, we\npresent Aura, a solution to make existing noise suppression test sets more\nchallenging and diverse while limiting the sampling budget. Aura is `ears-off'\nbecause it relies on a feature extractor and a metric of speech quality, DNSMOS\nP.835, both pre-trained on data obtained from public sources. As an application\nof \\aura, we augment a current benchmark test set in noise suppression by\nsampling audio files from a new batch of data of 20K clean speech clips from\nLibrivox mixed with noise clips obtained from AudioSet. Aura makes the existing\nbenchmark test set harder by 100% in DNSMOS P.835, a 26 improvement in\nSpearman's rank correlation coefficient (SRCC) compared to random sampling and,\nidentifies 73% out-of-distribution samples to augment the test set.",
    "descriptor": "",
    "authors": [
      "Xavier Gitiaux",
      "Aditya Khant",
      "Chandan Reddy",
      "Jayant Gupchup",
      "Ross Cutler"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04391"
  },
  {
    "id": "arXiv:2110.04396",
    "title": "When to Call Your Neighbor? Strategic Communication in Cooperative  Stochastic Bandits",
    "abstract": "In cooperative bandits, a framework that captures essential features of\ncollective sequential decision making, agents can minimize group regret, and\nthereby improve performance, by leveraging shared information. However, sharing\ninformation can be costly, which motivates developing policies that minimize\ngroup regret while also reducing the number of messages communicated by agents.\nExisting cooperative bandit algorithms obtain optimal performance when agents\nshare information with their neighbors at \\textit{every time step}, i.e., full\ncommunication. This requires $\\Theta(T)$ number of messages, where $T$ is the\ntime horizon of the decision making process. We propose \\textit{ComEx}, a novel\ncost-effective communication protocol in which the group achieves the same\norder of performance as full communication while communicating only $O(\\log T)$\nnumber of messages. Our key step is developing a method to identify and only\ncommunicate the information crucial to achieving optimal performance. Further\nwe propose novel algorithms for several benchmark cooperative bandit frameworks\nand show that our algorithms obtain \\textit{state-of-the-art} performance while\nconsistently incurring a significantly smaller communication cost than existing\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Udari Madhushani",
      "Naomi Leonard"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04396"
  },
  {
    "id": "arXiv:2110.04405",
    "title": "Quantum pixel representations and compression for $N$-dimensional images",
    "abstract": "We introduce a novel and uniform framework for quantum pixel representations\nthat overarches many of the most popular representations proposed in the recent\nliterature, such as (I)FRQI, (I)NEQR, MCRQI, and (I)NCQI. The proposed QPIXL\nframework results in more efficient circuit implementations and significantly\nreduces the gate complexity for all considered quantum pixel representations.\nOur method only requires a linear number of gates in terms of the number of\npixels and does not use ancilla qubits. Furthermore, the circuits only consist\nof Ry gates and CNOT gates making them practical in the NISQ era. Additionally,\nwe propose a circuit and image compression algorithm that is shown to be highly\neffective, being able to reduce the necessary gates to prepare an FRQI state\nfor example scientific images by up to 90% without sacrificing image quality.\nOur algorithms are made publicly available as part of QPIXL++, a Quantum Image\nPixel Library.",
    "descriptor": "",
    "authors": [
      "Mercy G. Amankwah",
      "Daan Camps",
      "E. Wes Bethel",
      "Roel Van Beeumen",
      "Talita Perciano"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04405"
  },
  {
    "id": "arXiv:2110.04410",
    "title": "TitaNet: Neural Model for speaker representation with 1D Depth-wise  separable convolutions and global context",
    "abstract": "In this paper, we propose TitaNet, a novel neural network architecture for\nextracting speaker representations. We employ 1D depth-wise separable\nconvolutions with Squeeze-and-Excitation (SE) layers with global context\nfollowed by channel attention based statistics pooling layer to map\nvariable-length utterances to a fixed-length embedding (t-vector). TitaNet is a\nscalable architecture and achieves state-of-the-art performance on speaker\nverification task with an equal error rate (EER) of 0.68% on the VoxCeleb1\ntrial file and also on speaker diarization tasks with diarization error rate\n(DER) of 1.73% on AMI-MixHeadset, 1.99% on AMI-Lapel and 1.11% on CH109.\nFurthermore, we investigate various sizes of TitaNet and present a light\nTitaNet-S model with only 6M parameters that achieve near state-of-the-art\nresults in diarization tasks.",
    "descriptor": "\nComments: preprint. Submitted to ICASSP 2022\n",
    "authors": [
      "Nithin Rao Koluguri",
      "Taejin Park",
      "Boris Ginsburg"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04410"
  },
  {
    "id": "arXiv:2110.04440",
    "title": "Multimodal Approach for Assessing Neuromotor Coordination in  Schizophrenia Using Convolutional Neural Networks",
    "abstract": "This study investigates the speech articulatory coordination in schizophrenia\nsubjects exhibiting strong positive symptoms (e.g. hallucinations and\ndelusions), using two distinct channel-delay correlation methods. We show that\nthe schizophrenic subjects with strong positive symptoms and who are markedly\nill pose complex articulatory coordination pattern in facial and speech\ngestures than what is observed in healthy subjects. This distinction in speech\ncoordination pattern is used to train a multimodal convolutional neural network\n(CNN) which uses video and audio data during speech to distinguish\nschizophrenic patients with strong positive symptoms from healthy subjects. We\nalso show that the vocal tract variables (TVs) which correspond to place of\narticulation and glottal source outperform the Mel-frequency Cepstral\nCoefficients (MFCCs) when fused with Facial Action Units (FAUs) in the proposed\nmultimodal network. For the clinical dataset we collected, our best performing\nmultimodal network improves the mean F1 score for detecting schizophrenia by\naround 18% with respect to the full vocal tract coordination (FVTC) baseline\nmethod implemented with fusing FAUs and MFCCs.",
    "descriptor": "\nComments: 5 pages. arXiv admin note: text overlap with arXiv:2102.07054\n",
    "authors": [
      "Yashish M. Siriwardena",
      "Chris Kitchen",
      "Deanna L. Kelly",
      "Carol Espy-Wilson"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04440"
  },
  {
    "id": "arXiv:2110.04456",
    "title": "Deep Joint Source-Channel Coding for Wireless Image Transmission with  Adaptive Rate Control",
    "abstract": "We present a novel adaptive deep joint source-channel coding (JSCC) scheme\nfor wireless image transmission. The proposed scheme supports multiple rates\nusing a single deep neural network (DNN) model and learns to dynamically\ncontrol the rate based on the channel condition and image contents.\nSpecifically, a policy network is introduced to exploit the tradeoff space\nbetween the rate and signal quality. To train the policy network, the\nGumbel-Softmax trick is adopted to make the policy network differentiable and\nhence the whole JSCC scheme can be trained end-to-end. To the best of our\nknowledge, this is the first deep JSCC scheme that can automatically adjust its\nrate using a single network model. Experiments show that our scheme\nsuccessfully learns a reasonable policy that decreases channel bandwidth\nutilization for high SNR scenarios or simple image contents. For an arbitrary\ntarget rate, our rate-adaptive scheme using a single model achieves similar\nperformance compared to an optimized model specifically trained for that fixed\ntarget rate. To reproduce our results, we make the source code publicly\navailable at https://github.com/mingyuyng/Dynamic_JSCC.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Mingyu Yang",
      "Hun-Seok Kim"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.04456"
  },
  {
    "id": "arXiv:2110.04458",
    "title": "Vision Transformer based COVID-19 Detection using Chest X-rays",
    "abstract": "COVID-19 is a global pandemic, and detecting them is a momentous task for\nmedical professionals today due to its rapid mutations. Current methods of\nexamining chest X-rays and CT scan requires profound knowledge and are time\nconsuming, which suggests that it shrinks the precious time of medical\npractitioners when people's lives are at stake. This study tries to assist this\nprocess by achieving state-of-the-art performance in classifying chest X-rays\nby fine-tuning Vision Transformer(ViT). The proposed approach uses pretrained\nmodels, fine-tuned for detecting the presence of COVID-19 disease on chest\nX-rays. This approach achieves an accuracy score of 97.61%, precision score of\n95.34%, recall score of 93.84% and, f1-score of 94.58%. This result signifies\nthe performance of transformer-based models on chest X-ray.",
    "descriptor": "",
    "authors": [
      "Koushik Sivarama Krishnan",
      "Karthik Sivarama Krishnan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04458"
  },
  {
    "id": "arXiv:2110.04464",
    "title": "Peripherality in networks: theory and applications",
    "abstract": "We investigate several related measures of peripherality and centrality for\nvertices and edges in networks, including the Mostar index which was recently\nintroduced as a measure of peripherality for both edges and networks. We refute\na conjecture on the maximum possible Mostar index of bipartite graphs from\n(Do\\v{s}li\\'{c} et al, Journal of Mathematical Chemistry, 2018) and (Ali and\nDo\\v{s}li\\'{c}, Applied Mathematics and Computation, 2021). We also correct a\nresult from the latter paper, where they claimed that the maximum possible\nvalue of the terminal Mostar index among all trees of order $n$ is\n$(n-1)(n-2)$. We show that this maximum is $(n-1)(n-3)$ for $n \\ge 3$, and that\nit is only attained by the star.\nWe asymptotically answer another problem on the maximum difference between\nthe Mostar index and the irregularity of trees from (F. Gao et al, On the\ndifference of Mostar index and irregularity of graphs, Bulletin of the\nMalaysian Mathematical Sciences Society, 2021). We also prove a number of\nextremal bounds and computational complexity results about the Mostar index,\nirregularity, and measures of peripherality and centrality.\nWe discuss graphs where the Mostar index is not an accurate measure of\nperipherality. We construct a general family of graphs with the property that\nthe Mostar index is strictly greater for edges that are closer to the center.\nWe also investigate centrality and peripherality in two graphs which represent\nthe SuperFast and MOZART-4 systems of atmospheric chemical reactions by\ncomputing various measures of peripherality and centrality for the vertices and\nedges in these graphs. For both of these graphs, we find that the Mostar index\nis closer to a measure of centrality than peripherality of the edges. We also\nintroduce some new indices which perform well as measures of peripherality on\nthe SuperFast and MOZART-4 graphs.",
    "descriptor": "",
    "authors": [
      "Jesse Geneson",
      "Shen-Fu Tsai"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.04464"
  },
  {
    "id": "arXiv:2110.04482",
    "title": "Towards Lifelong Learning of Multilingual Text-To-Speech Synthesis",
    "abstract": "This work presents a lifelong learning approach to train a multilingual\nText-To-Speech (TTS) system, where each language was seen as an individual task\nand was learned sequentially and continually. It does not require pooled data\nfrom all languages altogether, and thus alleviates the storage and computation\nburden. One of the challenges of lifelong learning methods is \"catastrophic\nforgetting\": in TTS scenario it means that model performance quickly degrades\non previous languages when adapted to a new language. We approach this problem\nvia a data-replay-based lifelong learning method. We formulate the replay\nprocess as a supervised learning problem, and propose a simple yet effective\ndual-sampler framework to tackle the heavily language-imbalanced training\nsamples. Through objective and subjective evaluations, we show that this\nsupervised learning formulation outperforms other gradient-based and\nregularization-based lifelong learning methods, achieving 43% Mel-Cepstral\nDistortion reduction compared to a fine-tuning baseline.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Mu Yang",
      "Shaojin Ding",
      "Tianlong Chen",
      "Tong Wang",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04482"
  },
  {
    "id": "arXiv:2110.04484",
    "title": "Wav2vec-S: Semi-Supervised Pre-Training for Speech Recognition",
    "abstract": "Self-supervised pre-training has dramatically improved the performance of\nautomatic speech recognition (ASR). However, most existing self-supervised\npre-training approaches are task-agnostic, i.e., could be applied to various\ndownstream tasks. And there is a gap between the task-agnostic pre-training and\nthe task-specific downstream fine-tuning, which may degrade the downstream\nperformance. In this work, we propose a novel pre-training paradigm called\nwav2vec-S, where we use task-specific semi-supervised pre-training to bridge\nthis gap. Specifically, the semi-supervised pre-training is conducted on the\nbasis of self-supervised pre-training such as wav2vec 2.0. Experiments on ASR\nshow that compared to wav2vec 2.0, wav2vec-S only requires marginal increment\nof pre-training time but could significantly improve ASR performance on\nin-domain, cross-domain and cross-lingual datasets. The average relative WER\nreductions are 26.3% and 6.3% for 1h and 10h fine-tuning, respectively.",
    "descriptor": "",
    "authors": [
      "Han Zhu",
      "Li Wang",
      "Ying Hou",
      "Jindong Wang",
      "Gaofeng Cheng",
      "Pengyuan Zhang",
      "Yonghong Yan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04484"
  },
  {
    "id": "arXiv:2110.04485",
    "title": "Application of quantum computing to a linear non-Gaussian acyclic model  for novel medical knowledge discovery",
    "abstract": "Recently, with the digitalization of medicine, the utilization of real-world\nmedical data collected from clinical sites has been attracting attention. In\nthis study, quantum computing was applied to a linear non-Gaussian acyclic\nmodel to discover causal relationships from real-world medical data alone.\nSpecifically, the independence measure of DirectLiNGAM, a causal discovery\nalgorithm, was calculated using the quantum kernel and its accuracy on\nreal-world medical data was verified. When DirectLiNGAM with the quantum kernel\n(qLiNGAM) was applied to real-world medical data, a case was confirmed in which\nthe causal structure could be correctly estimated when the amount of data was\nsmall, which was not possible with existing methods. It is suggested that\nqLiNGAM may be able to discover new medical knowledge and contribute to the\nsolution of medical problems, even when only a small amount of data is\navailable.",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Hideaki Kawaguchi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04485"
  },
  {
    "id": "arXiv:2110.04491",
    "title": "Invertible Tone Mapping with Selectable Styles",
    "abstract": "Although digital cameras can acquire high-dynamic range (HDR) images, the\ncaptured HDR information are mostly quantized to low-dynamic range (LDR) images\nfor display compatibility and compact storage. In this paper, we propose an\ninvertible tone mapping method that converts the multi-exposure HDR to a true\nLDR (8-bit per color channel) and reserves the capability to accurately restore\nthe original HDR from this {\\em invertible LDR}. Our invertible LDR can mimic\nthe appearance of a user-selected tone mapping style. It can be shared over any\nexisting social network platforms that may re-encode or format-convert the\nuploaded images, without much hurting the accuracy of the restored HDR\ncounterpart. To achieve this, we regard the tone mapping and the restoration as\ncoupled processes, and formulate them as an encoding-and-decoding problem\nthrough convolutional neural networks. Particularly, our model supports\npluggable style modulators, each of which bakes a specific tone mapping style,\nand thus favors the application flexibility. Our method is evaluated with a\nrich variety of HDR images and multiple tone mapping operators, which shows the\nsuperiority over relevant state-of-the-art methods. Also, we conduct ablation\nstudy to justify our design and discuss the robustness and generality toward\nreal applications.",
    "descriptor": "",
    "authors": [
      "Zhuming Zhang",
      "Menghan Xia",
      "Xueting Liu",
      "Chengze Li",
      "Tien-Tsin Wong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04491"
  },
  {
    "id": "arXiv:2110.04511",
    "title": "Data Augmentation with Locally-time Reversed Speech for Automatic Speech  Recognition",
    "abstract": "Psychoacoustic studies have shown that locally-time reversed (LTR) speech,\ni.e., signal samples time-reversed within a short segment, can be accurately\nrecognised by human listeners. This study addresses the question of how well a\nstate-of-the-art automatic speech recognition (ASR) system would perform on LTR\nspeech. The underlying objective is to explore the feasibility of deploying LTR\nspeech in the training of end-to-end (E2E) ASR models, as an attempt to data\naugmentation for improving the recognition performance. The investigation\nstarts with experiments to understand the effect of LTR speech on\ngeneral-purpose ASR. LTR speech with reversed segment duration of 5 ms - 50 ms\nis rendered and evaluated. For ASR training data augmentation with LTR speech,\ntraining sets are created by combining natural speech with different partitions\nof LTR speech. The efficacy of data augmentation is confirmed by ASR results on\nspeech corpora in various languages and speaking styles. ASR on LTR speech with\nreversed segment duration of 15 ms - 30 ms is found to have lower error rate\nthan with other segment duration. Data augmentation with these LTR speech\nachieves satisfactory and consistent improvement on ASR performance.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Si-Ioi Ng",
      "Tan Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04511"
  },
  {
    "id": "arXiv:2110.04523",
    "title": "An Empirical Study on Compressed Decentralized Stochastic Gradient  Algorithms with Overparameterized Models",
    "abstract": "This paper considers decentralized optimization with application to machine\nlearning on graphs. The growing size of neural network (NN) models has\nmotivated prior works on decentralized stochastic gradient algorithms to\nincorporate communication compression. On the other hand, recent works have\ndemonstrated the favorable convergence and generalization properties of\noverparameterized NNs. In this work, we present an empirical analysis on the\nperformance of compressed decentralized stochastic gradient (DSG) algorithms\nwith overparameterized NNs. Through simulations on an MPI network environment,\nwe observe that the convergence rates of popular compressed DSG algorithms are\nrobust to the size of NNs. Our findings suggest a gap between theories and\npractice of the compressed DSG algorithms in the existing literature.",
    "descriptor": "\nComments: 7 pages, 6 figures, accepted to APSIPA 2021\n",
    "authors": [
      "Arjun Ashok Rao",
      "Hoi-To Wai"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04523"
  },
  {
    "id": "arXiv:2110.04584",
    "title": "Visually Exploring Multi-Purpose Audio Data",
    "abstract": "We analyse multi-purpose audio using tools to visualise similarities within\nthe data that may be observed via unsupervised methods. The success of machine\nlearning classifiers is affected by the information contained within system\ninputs, so we investigate whether latent patterns within the data may explain\nperformance limitations of such classifiers. We use the visual assessment of\ncluster tendency (VAT) technique on a well known data set to observe how the\nsamples naturally cluster, and we make comparisons to the labels used for audio\ngeotagging and acoustic scene classification. We demonstrate that VAT helps to\nexplain and corroborate confusions observed in prior work to classify this\naudio, yielding greater insight into the performance - and limitations - of\nsupervised classification systems. While this exploratory analysis is conducted\non data for which we know the \"ground truth\" labels, this method of visualising\nthe natural groupings as dictated by the data leads to important questions\nabout unlabelled data that can help the evaluation and realistic expectations\nof future (including self-supervised) classification systems.",
    "descriptor": "\nComments: Presented at MMSP 2021\n",
    "authors": [
      "David Heise",
      "Helen L. Bear"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Human-Computer Interaction (cs.HC)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04584"
  },
  {
    "id": "arXiv:2110.04585",
    "title": "An evaluation of data augmentation methods for sound scene geotagging",
    "abstract": "Sound scene geotagging is a new topic of research which has evolved from\nacoustic scene classification. It is motivated by the idea of audio\nsurveillance. Not content with only describing a scene in a recording, a\nmachine which can locate where the recording was captured would be of use to\nmany. In this paper we explore a series of common audio data augmentation\nmethods to evaluate which best improves the accuracy of audio geotagging\nclassifiers. Our work improves on the state-of-the-art city geotagging method\nby 23% in terms of classification accuracy.",
    "descriptor": "\nComments: Presented at Interspeech 2021\n",
    "authors": [
      "Helen L. Bear",
      "Veronica Morfi",
      "Emmanouil Benetos"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04585"
  },
  {
    "id": "arXiv:2110.04591",
    "title": "Zig-Zag Modules: Cosheaves and K-Theory",
    "abstract": "Persistence modules have a natural home in the setting of stratified spaces\nand constructible cosheaves. In this article, we first give explicit\nconstructible cosheaves for common data-motivated persistence modules, namely,\nfor modules that arise from zig-zag filtrations (including monotone\nfiltrations), and for augmented persistence modules (which encode the data of\ninstantaneous events). We then identify an equivalence of categories between a\nparticular notion of zig-zag modules and the combinatorial entrance path\ncategory on stratified $\\mathbb{R}$. Finally, we compute the algebraic\n$K$-theory of generalized zig-zag modules and describe connections to both\nEuler curves and $K_0$ of the monoid of persistence diagrams as described by\nBubenik and Elchesen.",
    "descriptor": "\nComments: 26 pages, comments welcome\n",
    "authors": [
      "Ryan E. Grady",
      "Anna Schenfisch"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2110.04591"
  },
  {
    "id": "arXiv:2110.04604",
    "title": "Learning MRI Artifact Removal With Unpaired Data",
    "abstract": "Retrospective artifact correction (RAC) improves image quality post\nacquisition and enhances image usability. Recent machine learning driven\ntechniques for RAC are predominantly based on supervised learning and therefore\npractical utility can be limited as data with paired artifact-free and\nartifact-corrupted images are typically insufficient or even non-existent. Here\nwe show that unwanted image artifacts can be disentangled and removed from an\nimage via an RAC neural network learned with unpaired data. This implies that\nour method does not require matching artifact-corrupted data to be either\ncollected via acquisition or generated via simulation. Experimental results\ndemonstrate that our method is remarkably effective in removing artifacts and\nretaining anatomical details in images with different contrasts.",
    "descriptor": "",
    "authors": [
      "Siyuan Liu",
      "Kim-Han Thung",
      "Liangqiong Qu",
      "Weili Lin",
      "Dinggang Shen",
      "Pew-Thian Yap"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04604"
  },
  {
    "id": "arXiv:2110.04612",
    "title": "Personalized Automatic Speech Recognition Trained on Small Disordered  Speech Datasets",
    "abstract": "This study investigates the performance of personalized automatic speech\nrecognition (ASR) for recognizing disordered speech using small amounts of\nper-speaker adaptation data. We trained personalized models for 195 individuals\nwith different types and severities of speech impairment with training sets\nranging in size from <1 minute to 18-20 minutes of speech data. Word error rate\n(WER) thresholds were selected to determine Success Percentage (the percentage\nof personalized models reaching the target WER) in different application\nscenarios. For the home automation scenario, 79% of speakers reached the target\nWER with 18-20 minutes of speech; but even with only 3-4 minutes of speech, 63%\nof speakers reached the target WER. Further evaluation found similar\nimprovement on test sets with conversational and out-of-domain, unprompted\nphrases. Our results demonstrate that with only a few minutes of recordings,\nindividuals with disordered speech could benefit from personalized ASR.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Jimmy Tobin",
      "Katrin Tomanek"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04612"
  },
  {
    "id": "arXiv:2110.04624",
    "title": "Iterative Refinement Graph Neural Network for Antibody  Sequence-Structure Co-design",
    "abstract": "Antibodies are versatile proteins that bind to pathogens like viruses and\nstimulate the adaptive immune system. The specificity of antibody binding is\ndetermined by complementarity-determining regions (CDRs) at the tips of these\nY-shaped proteins. In this paper, we propose a generative model to\nautomatically design the CDRs of antibodies with enhanced binding specificity\nor neutralization capabilities. Previous generative approaches formulate\nprotein design as a structure-conditioned sequence generation task, assuming\nthe desired 3D structure is given a priori. In contrast, we propose to\nco-design the sequence and 3D structure of CDRs as graphs. Our model unravels a\nsequence autoregressively while iteratively refining its predicted global\nstructure. The inferred structure in turn guides subsequent residue choices.\nFor efficiency, we model the conditional dependence between residues inside and\noutside of a CDR in a coarse-grained manner. Our method achieves superior\nlog-likelihood on the test set and outperforms previous baselines in designing\nantibodies capable of neutralizing the SARS-CoV-2 virus.",
    "descriptor": "",
    "authors": [
      "Wengong Jin",
      "Jeremy Wohlwend",
      "Regina Barzilay",
      "Tommi Jaakkola"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04624"
  },
  {
    "id": "arXiv:2110.04632",
    "title": "DenseNet approach to segmentation and classification of dermatoscopic  skin lesions images",
    "abstract": "At present, cancer is one of the most important health issues in the world.\nBecause early detection and appropriate treatment in cancer are very effective\nin the recovery and survival of patients, image processing as a diagnostic tool\ncan help doctors to diagnose in the first recognition of cancer. One of the\nmost important steps in diagnosing a skin lesion is to automatically detect the\nborder of the skin image because the accuracy of the next steps depends on it.\nIf these subtleties are identified, they can have a great impact on the\ndiagnosis of the disease. Therefore, there is a good opportunity to develop\nmore accurate algorithms to analyze such images. This paper proposes an\nimproved method for segmentation and classification for skin lesions using two\narchitectures, the U-Net for image segmentation and the DenseNet121 for image\nclassification which have excellent accuracy. We tested the segmentation\narchitecture of our model on the ISIC-2018 dataset and the classification on\nthe HAM10000 dataset. Our results show that the combination of U-Net and\nDenseNet121 architectures provides acceptable results in dermatoscopic image\nanalysis compared to previous research. Another classification examined in this\nstudy is cancerous and non-cancerous samples. In this classification, cancerous\nand non-cancerous samples were detected in DenseNet121 network with 79.49% and\n93.11% accuracy respectively.",
    "descriptor": "",
    "authors": [
      "Reza Zare",
      "Arash Pourkazemi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04632"
  },
  {
    "id": "arXiv:2110.04637",
    "title": "Depth Optimized Ansatz Circuit in QAOA for Max-Cut",
    "abstract": "While a Quantum Approximate Optimization Algorithm (QAOA) is intended to\nprovide a quantum advantage in finding approximate solutions to combinatorial\noptimization problems, noise in the system is a hurdle in exploiting its full\npotential. Several error mitigation techniques have been studied to lessen the\neffect of noise on this algorithm. Recently, Majumdar et al. proposed a Depth\nFirst Search (DFS) based method to reduce $n-1$ CNOT gates in the ansatz design\nof QAOA for finding Max-Cut in a graph G = (V, E), |V| = n. However, this\nmethod tends to increase the depth of the circuit, making it more prone to\nrelaxation error. The depth of the circuit is proportional to the height of the\nDFS tree, which can be $n-1$ in the worst case. In this paper, we propose an\n$O(\\Delta \\cdot n^2)$ greedy heuristic algorithm, where $\\Delta$ is the maximum\ndegree of the graph, that finds a spanning tree of lower height, thus reducing\nthe overall depth of the circuit while still retaining the $n-1$ reduction in\nthe number of CNOT gates needed in the ansatz. We numerically show that this\nalgorithm achieves nearly 10 times increase in the probability of success for\neach iteration of QAOA for Max-Cut. We further show that although the average\ndepth of the circuit produced by this heuristic algorithm still grows linearly\nwith n, our algorithm reduces the slope of the linear increase from 1 to 0.11.",
    "descriptor": "\nComments: 12 pages, single column\n",
    "authors": [
      "Ritajit Majumdar",
      "Debasmita Bhoumik",
      "Dhiraj Madan",
      "Dhinakaran Vinayagamurthy",
      "Shesha Raghunathan",
      "Susmita Sur-Kolay"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.04637"
  },
  {
    "id": "arXiv:2110.04651",
    "title": "Nonlocal Games, Compression Theorems, and the Arithmetical Hierarchy",
    "abstract": "We investigate the connection between the complexity of nonlocal games and\nthe arithmetical hierarchy, a classification of languages according to the\ncomplexity of arithmetical formulas defining them. It was recently shown by Ji,\nNatarajan, Vidick, Wright and Yuen that deciding whether the\n(finite-dimensional) quantum value of a nonlocal game is $1$ or at most\n$\\frac{1}{2}$ is complete for the class $\\Sigma_1$ (i.e., $\\mathsf{RE}$). A\nresult of Slofstra implies that deciding whether the commuting operator value\nof a nonlocal game is equal to $1$ is complete for the class $\\Pi_1$ (i.e.,\n$\\mathsf{coRE}$). We prove that deciding whether the quantum value of a\ntwo-player nonlocal game is exactly equal to $1$ is complete for $\\Pi_2$; this\nclass is in the second level of the arithmetical hierarchy and corresponds to\nformulas of the form ``$\\forall x \\, \\exists y \\, \\phi(x,y)$''. This shows that\nexactly computing the quantum value is strictly harder than approximating it,\nand also strictly harder than computing the commuting operator value (either\nexactly or approximately). We explain how results about the complexity of\nnonlocal games all follow in a unified manner from a technique known as\ncompression. At the core of our $\\Pi_2$-completeness result is a new\n``gapless'' compression theorem that holds for both quantum and commuting\noperator strategies. Our compression theorem yields as a byproduct an\nalternative proof of Slofstra's result that the set of quantum correlations is\nnot closed. We also show how a ``gap-preserving'' compression theorem for\ncommuting operator strategies would imply that approximating the commuting\noperator value is complete for $\\Pi_1$.",
    "descriptor": "",
    "authors": [
      "Hamoon Mousavi",
      "Seyed Sajjad Nezhadi",
      "Henry Yuen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Operator Algebras (math.OA)"
    ],
    "url": "https://arxiv.org/abs/2110.04651"
  },
  {
    "id": "arXiv:2110.04654",
    "title": "Complex Network-Based Approach for Feature Extraction and Classification  of Musical Genres",
    "abstract": "Musical genre's classification has been a relevant research topic. The\nassociation between music and genres is fundamental for the media industry,\nwhich manages musical recommendation systems, and for music streaming services,\nwhich may appear classified by genres. In this context, this work presents a\nfeature extraction method for the automatic classification of musical genres,\nbased on complex networks and their topological measurements. The proposed\nmethod initially converts the musics into sequences of musical notes and then\nmaps the sequences as complex networks. Topological measurements are extracted\nto characterize the network topology, which composes a feature vector that\napplies to the classification of musical genres. The method was evaluated in\nthe classification of 10 musical genres by adopting the GTZAN dataset and 8\nmusical genres by adopting the FMA dataset. The results were compared with\nmethods in the literature. The proposed method outperformed all compared\nmethods by presenting high accuracy and low standard deviation, showing its\nsuitability for the musical genre's classification, which contributes to the\nmedia industry in the automatic classification with assertiveness and\nrobustness. The proposed method is implemented in an open source in the Python\nlanguage and freely available at https://github.com/omatheuspimenta/examinner.",
    "descriptor": "",
    "authors": [
      "Matheus Henrique Pimenta-Zanon",
      "Glaucia Maria Bressan",
      "Fabr\u00edcio Martins Lopes"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04654"
  },
  {
    "id": "arXiv:2110.04659",
    "title": "Exploring constraints on CycleGAN-based CBCT enhancement for adaptive  radiotherapy",
    "abstract": "Research exploring CycleGAN-based synthetic image generation has recently\naccelerated in the medical community, as it is able to leverage unpaired\ndatasets effectively. However, clinical acceptance of these synthetic images\npose a significant challenge as they are subject to strict evaluation\nprotocols. A commonly established drawback of the CycleGAN, the introduction of\nartifacts in generated images is unforgivable in the case of medical images. In\nan attempt to alleviate this drawback, we explore different constraints of the\nCycleGAN along with investigation of adaptive control of these constraints. The\nbenefits of imposing additional constraints on the CycleGAN, in the form of\nstructure retaining losses is also explored. A generalized frequency loss\ninspired by \\cite{jiang2020focal} that preserves content in the frequency\ndomain between source and target is investigated and compared with existing\nlosses such as the MIND loss arXiv:1809.04536. Synthetic images generated from\nour methods are quantitatively and qualitatively investigated and outperform\nthe baseline CycleGAN and other approaches. Furthermore, no observable\nartifacts or loss in image quality is found, which is critical for acceptance\nof these synthetic images. The synthetic medical images thus generated are also\nevaluated using domain-specific evaluation and using segmentation as a\ndownstream task, in order to clearly highlight their applicability to clinical\nworkflows.",
    "descriptor": "",
    "authors": [
      "Suraj Pai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04659"
  },
  {
    "id": "arXiv:2110.04692",
    "title": "Poformer: A simple pooling transformer for speaker verification",
    "abstract": "Most recent speaker verification systems are based on extracting speaker\nembeddings using a deep neural network. The pooling layer in the network aims\nto aggregate frame-level features extracted by the backbone. In this paper, we\npropose a new transformer based pooling structure called PoFormer to enhance\nthe ability of the pooling layer to capture information along the whole time\naxis. Different from previous works that apply attention mechanism in a simple\nway or implement the multi-head mechanism in serial instead of in parallel,\nPoFormer follows the initial transformer structure with some minor\nmodifications like a positional encoding generator, drop path and LayerScale to\nmake the training procedure more stable and to prevent overfitting. Evaluated\non various datasets, PoFormer outperforms the existing pooling system with at\nleast a 13.00% improvement in EER and a 9.12% improvement in minDCF.",
    "descriptor": "\nComments: submitted to ICASSP 2022\n",
    "authors": [
      "Yufeng Ma",
      "Yiwei Ding",
      "Miao Zhao",
      "Yu Zheng",
      "Min Liu",
      "Minqiang Xu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04692"
  },
  {
    "id": "arXiv:2110.04694",
    "title": "Multi-Channel End-to-End Neural Diarization with Distributed Microphones",
    "abstract": "Recent progress on end-to-end neural diarization (EEND) has enabled\noverlap-aware speaker diarization with a single neural network. This paper\nproposes to enhance EEND by using multi-channel signals from distributed\nmicrophones. We replace Transformer encoders in EEND with two types of encoders\nthat process a multi-channel input: spatio-temporal and co-attention encoders.\nBoth are independent of the number and geometry of microphones and suitable for\ndistributed microphone settings. We also propose a model adaptation method\nusing only single-channel recordings. With simulated and real-recorded\ndatasets, we demonstrated that the proposed method outperformed conventional\nEEND when a multi-channel input was given while maintaining comparable\nperformance with a single-channel input. We also showed that the proposed\nmethod performed well even when spatial information is inoperative given\nmulti-channel inputs, such as in hybrid meetings in which the utterances of\nmultiple remote participants are played back from the same loudspeaker.",
    "descriptor": "",
    "authors": [
      "Shota Horiguchi",
      "Yuki Takashima",
      "Paola Garcia",
      "Shinji Watanabe",
      "Yohei Kawaguchi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04694"
  },
  {
    "id": "arXiv:2110.04702",
    "title": "Stability of Neural Networks on Manifolds to Relative Perturbations",
    "abstract": "Graph Neural Networks (GNNs) show impressive performance in many practical\nscenarios, which can be largely attributed to their stability properties.\nEmpirically, GNNs can scale well on large size graphs, but this is contradicted\nby the fact that existing stability bounds grow with the number of nodes.\nGraphs with well-defined limits can be seen as samples from manifolds. Hence,\nin this paper, we analyze the stability properties of convolutional neural\nnetworks on manifolds to understand the stability of GNNs on large graphs.\nSpecifically, we focus on stability to relative perturbations of the\nLaplace-Beltrami operator. To start, we construct frequency ratio threshold\nfilters which separate the infinite-dimensional spectrum of the\nLaplace-Beltrami operator. We then prove that manifold neural networks composed\nof these filters are stable to relative operator perturbations. As a product of\nthis analysis, we observe that manifold neural networks exhibit a trade-off\nbetween stability and discriminability. Finally, we illustrate our results\nempirically in a wireless resource allocation scenario where the\ntransmitter-receiver pairs are assumed to be sampled from a manifold.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Zhiyang Wang",
      "Luana Ruiz",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04702"
  },
  {
    "id": "arXiv:2110.04738",
    "title": "Uncertainty in Data-Driven Kalman Filtering for Partially Known  State-Space Models",
    "abstract": "Providing a metric of uncertainty alongside a state estimate is often crucial\nwhen tracking a dynamical system. Classic state estimators, such as the Kalman\nfilter (KF), provide a time-dependent uncertainty measure from knowledge of the\nunderlying statistics, however, deep learning based tracking systems struggle\nto reliably characterize uncertainty. In this paper, we investigate the ability\nof KalmanNet, a recently proposed hybrid model-based deep state tracking\nalgorithm, to estimate an uncertainty measure. By exploiting the interpretable\nnature of KalmanNet, we show that the error covariance matrix can be computed\nbased on its internal features, as an uncertainty measure. We demonstrate that\nwhen the system dynamics are known, KalmanNet-which learns its mapping from\ndata without access to the statistics-provides uncertainty similar to that\nprovided by the KF; and while in the presence of evolution model-mismatch,\nKalmanNet pro-vides a more accurate error estimation.",
    "descriptor": "\nComments: 4 Pages, One references page, 5 figures. Submitted to ICASSP 2022\n",
    "authors": [
      "Itzik Klein",
      "Guy Revach",
      "Nir Shlezinger",
      "Jonas E. Mehr",
      "Ruud J. G. van Sloun",
      "Yonina. C. Eldar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04738"
  },
  {
    "id": "arXiv:2110.04742",
    "title": "Sideward contact tracing and the control of epidemics in large  gatherings",
    "abstract": "Effective contact tracing is crucial to contain epidemic spreading without\ndisrupting societal activities especially in the present time of coexistence\nwith a pandemic outbreak. Large gatherings play a key role, potentially\nfavoring superspreading events. However, the effects of tracing in large groups\nhave not been fully assessed so far. We show that beside forward tracing, which\nreconstructs to whom disease spreads, and backward tracing, which searches from\nwhom disease spreads, a third \"sideward\" tracing is at work in large\ngatherings. This is an indirect tracing that detects infected asymptomatic\nindividuals, even if they have neither been directly infected by, nor directly\ntransmitted the infection to the index case. We analyze this effect in a model\nof epidemic spreading for SARS-CoV-2, within the framework of simplicial\nactivity-driven temporal networks. We determine the contribution of the three\ntracing mechanisms to the suppression of epidemic spreading, unveiling the\nimportance of sideward tracing and suggesting optimal strategies. We show the\npractical relevance of our results on an empirical dataset of gatherings in a\nUniversity Campus.",
    "descriptor": "\nComments: Main document: 11 pages, 5 figures; Supplementary Information: 13 pages, 4 figures\n",
    "authors": [
      "Marco Mancastroppa",
      "Andrea Guizzo",
      "Claudio Castellano",
      "Alessandro Vezzani",
      "Raffaella Burioni"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2110.04742"
  },
  {
    "id": "arXiv:2110.04745",
    "title": "Reinforcement Learning for Systematic FX Trading",
    "abstract": "We conduct a detailed experiment on major cash fx pairs, accurately\naccounting for transaction and funding costs. These sources of profit and loss,\nincluding the price trends that occur in the currency markets, are made\navailable to our recurrent reinforcement learner via a quadratic utility, which\nlearns to target a position directly. We improve upon earlier work, by casting\nthe problem of learning to target a risk position, in an online learning\ncontext. This online learning occurs sequentially in time, but also in the form\nof transfer learning. We transfer the output of radial basis function hidden\nprocessing units, whose means, covariances and overall size are determined by\nGaussian mixture models, to the recurrent reinforcement learner and baseline\nmomentum trader. Thus the intrinsic nature of the feature space is learnt and\nmade available to the upstream models. The recurrent reinforcement learning\ntrader achieves an annualised portfolio information ratio of 0.52 with compound\nreturn of 9.3%, net of execution and funding cost, over a 7 year test set. This\nis despite forcing the model to trade at the close of the trading day 5pm EST,\nwhen trading costs are statistically the most expensive. These results are\ncomparable with the momentum baseline trader, reflecting the low interest\ndifferential environment since the the 2008 financial crisis, and very obvious\ncurrency trends since then. The recurrent reinforcement learner does\nnevertheless maintain an important advantage, in that the model's weights can\nbe adapted to reflect the different sources of profit and loss variation. This\nis demonstrated visually by a USDRUB trading agent, who learns to target\ndifferent positions, that reflect trading in the absence or presence of cost.",
    "descriptor": "",
    "authors": [
      "Gabriel Borrageiro",
      "Nick Firoozye",
      "Paolo Barucca"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04745"
  },
  {
    "id": "arXiv:2110.04749",
    "title": "Modeling of Pan Evaporation Based on the Development of Machine Learning  Methods",
    "abstract": "For effective planning and management of water resources and implementation\nof the related strategies, it is important to ensure proper estimation of\nevaporation losses, especially in regions that are prone to drought. Changes in\nclimatic factors, such as changes in temperature, wind speed, sunshine hours,\nhumidity, and solar radiation can have a significant impact on the evaporation\nprocess. As such, evaporation is a highly non-linear, non-stationary process,\nand can be difficult to be modeled based on climatic factors, especially in\ndifferent agro-climatic conditions. The aim of this study, therefore, is to\ninvestigate the feasibility of several machines learning (ML) models\n(conditional random forest regression, Multivariate Adaptive Regression\nSplines, Bagged Multivariate Adaptive Regression Splines, Model Tree M5, K-\nnearest neighbor, and the weighted K- nearest neighbor) for modeling the\nmonthly pan evaporation estimation. This study proposes the development of\nnewly explored ML models for modeling evaporation losses in three different\nlocations over the Iraq region based on the available climatic data in such\nareas. The evaluation of the performance of the proposed model based on various\nevaluation criteria showed the capability of the proposed weighted K- nearest\nneighbor model in modeling the monthly evaporation losses in the studies areas\nwith better accuracy when compared with the other existing models used as a\nbenchmark in this study.",
    "descriptor": "",
    "authors": [
      "Mustafa Al-Mukhtar"
    ],
    "subjectives": [
      "Popular Physics (physics.pop-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04749"
  },
  {
    "id": "arXiv:2110.04752",
    "title": "How Robust are Limit Order Book Representations under Data Perturbation?",
    "abstract": "The success of machine learning models in the financial domain is highly\nreliant on the quality of the data representation. In this paper, we focus on\nthe representation of limit order book data and discuss the opportunities and\nchallenges for learning representations of such data. We also experimentally\nanalyse the issues associated with existing representations and present a\nguideline for future research in this area.",
    "descriptor": "",
    "authors": [
      "Yufei Wu",
      "Mahmoud Mahfouz",
      "Daniele Magazzeni",
      "Manuela Veloso"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04752"
  },
  {
    "id": "arXiv:2110.04756",
    "title": "Rethinking Noise Synthesis and Modeling in Raw Denoising",
    "abstract": "The lack of large-scale real raw image denoising dataset gives rise to\nchallenges on synthesizing realistic raw image noise for training denoising\nmodels. However, the real raw image noise is contributed by many noise sources\nand varies greatly among different sensors. Existing methods are unable to\nmodel all noise sources accurately, and building a noise model for each sensor\nis also laborious. In this paper, we introduce a new perspective to synthesize\nnoise by directly sampling from the sensor's real noise. It inherently\ngenerates accurate raw image noise for different camera sensors. Two efficient\nand generic techniques: pattern-aligned patch sampling and high-bit\nreconstruction help accurate synthesis of spatial-correlated noise and high-bit\nnoise respectively. We conduct systematic experiments on SIDD and ELD datasets.\nThe results show that (1) our method outperforms existing methods and\ndemonstrates wide generalization on different sensors and lighting conditions.\n(2) Recent conclusions derived from DNN-based noise modeling methods are\nactually based on inaccurate noise parameters. The DNN-based methods still\ncannot outperform physics-based statistical methods.",
    "descriptor": "\nComments: ICCV2021\n",
    "authors": [
      "Yi Zhang",
      "Hongwei Qin",
      "Xiaogang Wang",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04756"
  },
  {
    "id": "arXiv:2110.04763",
    "title": "Fat-shattering dimension of $k$-fold maxima",
    "abstract": "We provide improved estimates on the fat-shattering dimension of the $k$-fold\nmaximum of real-valued function classes. The latter consists of all ways of\nchoosing $k$ functions, one from each of the $k$ classes, and computing their\npointwise maximum. The bound is stated in terms of the fat-shattering\ndimensions of the component classes. For linear and affine function classes, we\nprovide a considerably sharper upper bound and a matching lower bound,\nachieving, in particular, an optimal dependence on $k$. Along the way, we point\nout and correct a number of erroneous claims in the literature.",
    "descriptor": "",
    "authors": [
      "Aryeh Kontorovich",
      "Idan Attias"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04763"
  },
  {
    "id": "arXiv:2110.04775",
    "title": "Estimating the confidence of speech spoofing countermeasure",
    "abstract": "Conventional speech spoofing countermeasures (CMs) are designed to make a\nbinary decision on an input trial. However, a CM trained on a closed-set\ndatabase is theoretically not guaranteed to perform well on unknown spoofing\nattacks. In some scenarios, an alternative strategy is to let the CM defer a\ndecision when it is not confident. The question is then how to estimate a CM's\nconfidence regarding an input trial. We investigated a few confidence\nestimators that can be easily plugged into a CM. On the ASVspoof2019 logical\naccess database, the results demonstrate that an energy-based estimator and a\nneural-network-based one achieved acceptable performance in identifying unknown\nattacks in the test set. On a test set with additional unknown attacks and bona\nfide trials from other databases, the confidence estimators performed\nmoderately well, and the CMs better discriminated bona fide and spoofed trials\nthat had a high confidence score. Additional results also revealed the\ndifficulty in enhancing a confidence estimator by adding unknown attacks to the\ntraining set.",
    "descriptor": "\nComments: Work in progress. Comments are welcome\n",
    "authors": [
      "Xin Wang",
      "Junichi Yamagishi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04775"
  },
  {
    "id": "arXiv:2110.04782",
    "title": "Hard instance learning for quantum adiabatic prime factorization",
    "abstract": "Prime factorization is a difficult problem with classical computing, whose\nexponential hardness is the foundation of Rivest-Shamir-Adleman (RSA)\ncryptography. With programmable quantum devices, adiabatic quantum computing\nhas been proposed as a plausible approach to solve prime factorization, having\npromising advantage over classical computing. Here, we find there are certain\nhard instances that are consistently intractable for both classical simulated\nannealing and un-configured adiabatic quantum computing (AQC). Aiming at an\nautomated architecture for optimal configuration of quantum adiabatic\nfactorization, we apply a deep reinforcement learning (RL) method to configure\nthe AQC algorithm. By setting the success probability of the worst-case problem\ninstances as the reward to RL, we show the AQC performance on the hard\ninstances is dramatically improved by RL configuration. The success probability\nalso becomes more evenly distributed over different problem instances, meaning\nthe configured AQC is more stable as compared to the un-configured case.\nThrough a technique of transfer learning, we find prominent evidence that the\nframework of AQC configuration is scalable -- the configured AQC as trained on\nfive qubits remains working efficiently on nine qubits with a minimal amount of\nadditional training cost.",
    "descriptor": "\nComments: 10 pages, 6 figures. Comments are welcome\n",
    "authors": [
      "Jian Lin",
      "Zhengfeng Zhang",
      "Junping Zhang",
      "Xiaopeng Li"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04782"
  },
  {
    "id": "arXiv:2110.04791",
    "title": "Stepwise-Refining Speech Separation Network via Fine-Grained Encoding in  High-order Latent Domain",
    "abstract": "The crux of single-channel speech separation is how to encode the mixture of\nsignals into such a latent embedding space that the signals from different\nspeakers can be precisely separated. Existing methods for speech separation\neither transform the speech signals into frequency domain to perform separation\nor seek to learn a separable embedding space by constructing a latent domain\nbased on convolutional filters. While the latter type of methods learning an\nembedding space achieves substantial improvement for speech separation, we\nargue that the embedding space defined by only one latent domain does not\nsuffice to provide a thoroughly separable encoding space for speech separation.\nIn this paper, we propose the Stepwise-Refining Speech Separation Network\n(SRSSN), which follows a coarse-to-fine separation framework. It first learns a\n1-order latent domain to define an encoding space and thereby performs a rough\nseparation in the coarse phase. Then the proposed SRSSN learns a new latent\ndomain along each basis function of the existing latent domain to obtain a\nhigh-order latent domain in the refining phase, which enables our model to\nperform a refining separation to achieve a more precise speech separation. We\ndemonstrate the effectiveness of our SRSSN by conducting extensive experiments,\nincluding speech separation in a clean (noise-free) setting on WSJ0-2/3mix\ndatasets as well as in noisy/reverberant settings on WHAM!/WHAMR! datasets.\nFurthermore, we also perform experiments of speech recognition on separated\nspeech signals by our model to evaluate the performance of speech separation\nindirectly.",
    "descriptor": "",
    "authors": [
      "Zengwei Yao",
      "Wenjie Pei",
      "Fanglin Chen",
      "Guangming Lu",
      "David Zhang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04791"
  },
  {
    "id": "arXiv:2110.04814",
    "title": "Finding Second-Order Stationary Point for Nonconvex-Strongly-Concave  Minimax Problem",
    "abstract": "We study the smooth minimax optimization problem of the form $\\min_{\\bf\nx}\\max_{\\bf y} f({\\bf x},{\\bf y})$, where the objective function is\nstrongly-concave in ${\\bf y}$ but possibly nonconvex in ${\\bf x}$. This problem\nincludes a lot of applications in machine learning such as regularized GAN,\nreinforcement learning and adversarial training. Most of existing theory\nrelated to gradient descent accent focus on establishing the convergence result\nfor achieving the first-order stationary point of $f({\\bf x},{\\bf y})$ or\nprimal function $P({\\bf x})\\triangleq \\max_{\\bf y} f({\\bf x},{\\bf y})$. In this\npaper, we design a new optimization method via cubic Newton iterations, which\ncould find an ${\\mathcal\nO}\\left(\\varepsilon,\\kappa^{1.5}\\sqrt{\\rho\\varepsilon}\\right)$-second-order\nstationary point of $P({\\bf x})$ with ${\\mathcal\nO}\\left(\\kappa^{1.5}\\sqrt{\\rho}\\varepsilon^{-1.5}\\right)$ second-order oracle\ncalls and $\\tilde{\\mathcal\nO}\\left(\\kappa^{2}\\sqrt{\\rho}\\varepsilon^{-1.5}\\right)$ first-order oracle\ncalls, where $\\kappa$ is the condition number and $\\rho$ is the Hessian\nsmoothness coefficient of $f({\\bf x},{\\bf y})$. For high-dimensional problems,\nwe propose an variant algorithm to avoid expensive cost form second-order\noracle, which solves the cubic sub-problem inexactly via gradient descent and\nmatrix Chebyshev expansion. This strategy still obtains desired approximate\nsecond-order stationary point with high probability but only requires\n$\\tilde{\\mathcal O}\\left(\\kappa^{1.5}\\ell\\varepsilon^{-2}\\right)$\nHessian-vector oracle and $\\tilde{\\mathcal\nO}\\left(\\kappa^{2}\\sqrt{\\rho}\\varepsilon^{-1.5}\\right)$ first-order oracle\ncalls. To the best of our knowledge, this is the first work considers\nnon-asymptotic convergence behavior of finding second-order stationary point\nfor minimax problem without convex-concave assumption.",
    "descriptor": "",
    "authors": [
      "Luo Luo",
      "Cheng Chen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04814"
  },
  {
    "id": "arXiv:2110.04829",
    "title": "Adaptive joint distribution learning",
    "abstract": "We develop a new framework for embedding (joint) probability distributions in\ntensor product reproducing kernel Hilbert spaces (RKHS). This framework\naccommodates a low-dimensional, positive, and normalized model of a\nRadon-Nikodym derivative, estimated from sample sizes of up to several million\ndata points, alleviating the inherent limitations of RKHS modeling.\nWell-defined normalized and positive conditional distributions are natural\nby-products to our approach. The embedding is fast to compute and naturally\naccommodates learning problems ranging from prediction to classification. The\ntheoretical findings are supplemented by favorable numerical results.",
    "descriptor": "",
    "authors": [
      "Damir Filipovic",
      "Michael Multerer",
      "Paul Schneider"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.04829"
  },
  {
    "id": "arXiv:2110.04850",
    "title": "Direct source and early reflections localization using deep  deconvolution network under reverbrate environment",
    "abstract": "This paper proposes a deconvolution-based network (DCNN) model for DOA\nestimation of direct source and early reflections under reverberate scenarios.\nConsidering that the first-order reflections of the sound source also contain\nspatial directivity like the direct source, we treat both of them as the\nsources in the learning process. We use the covariance matrix of high order\nAmbisonics (HOA) signals in time domain as the input feature of the network,\nwhich is concise while contains precise spatial information under reverberate\nscenarios. Besides, we use the deconvolution-based network for the spatial\npseudo-spectrum (SPS) reconstruction in the 2D polar space, based on which the\nspatial relationship between elevation and azimuth can be depicted. We have\ncarried out a series of experiments based on simulated and measured data under\ndifferent reverberate scenarios, which prove the robustness and accuracy of the\nproposed DCNN model.",
    "descriptor": "",
    "authors": [
      "Shan Gao",
      "Xihong Wu",
      "Tianshu Qu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.04850"
  },
  {
    "id": "arXiv:2110.04862",
    "title": "Re-entry prediction and demisability analysis for the atmospheric  disposal of geosynchronous satellites",
    "abstract": "The paper presents a re-entry analysis of Geosynchronous Orbit (GSO)\nsatellites on disposal trajectories that enhance the effects of the Earth\noblateness and lunisolar perturbations. These types of trajectories can lead to\na natural re-entry of the spacecraft within 20 years. An analysis was performed\nto characterise the entry conditions for these satellites and the risk they can\npose for people on the ground if disposal via re-entry is used. The paper first\nproposes a methodology to interface the long-term propagation used to study the\nevolution of the disposal trajectories and the destructive re-entry simulations\nused to assess the spacecraft casualty risk. This is achieved by revisiting the\nconcept of overshoot boundary. The paper also presents the demisability and\ncasualty risk analysis for a representative spacecraft configuration, showing\nthat the casualty risk is greater than the 10$^{-4}$ threshold and that further\nactions should be taken to improve the compliance of these satellites in case\nof disposal via re-entry is used.",
    "descriptor": "",
    "authors": [
      "Mirko Trisolini",
      "Camilla Colombo"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2110.04862"
  },
  {
    "id": "arXiv:2110.04863",
    "title": "Injecting Text and Cross-lingual Supervision in Few-shot Learning from  Self-Supervised Models",
    "abstract": "Self-supervised model pre-training has recently garnered significant\ninterest, but relatively few efforts have explored using additional resources\nin fine-tuning these models. We demonstrate how universal phoneset acoustic\nmodels can leverage cross-lingual supervision to improve transfer of pretrained\nself-supervised representations to new languages. We also show how\ntarget-language text can be used to enable and improve fine-tuning with the\nlattice-free maximum mutual information (LF-MMI) objective. In three\nlow-resource languages these techniques greatly improved few-shot learning\nperformance.",
    "descriptor": "\nComments: \\c{opyright} 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Matthew Wiesner",
      "Desh Raj",
      "Sanjeev Khudanpur"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04863"
  },
  {
    "id": "arXiv:2110.04897",
    "title": "The influence of structural variations on the constitutive response and  strain variations in thin fibrous materials",
    "abstract": "The stochastic variations in the structural properties of thin fiber networks\ngovern to a great extent their mechanical performance. To assess the influence\nof local structural variability on the local strain and mechanical response of\nthe network, we propose a multiscale approach combining modeling, numerical\nsimulation and experimental measurements. Based on micro-mechanical fiber\nnetwork simulations, a continuum model describing the response at the mesoscale\nlevel is first developed. Experimentally measured spatial fields of thickness,\ndensity, fiber orientation and anisotropy are thereafter used as input to a\nmacroscale finite-element model. The latter is used to simulate the impact of\nspatial variability of each of the studied structural properties. In addition,\nthis work brings novelty by including the influence of the drying condition\nduring the production process on the fiber properties. The proposed approach is\nexperimentally validated by comparison to measured strain fields and uniaxial\nresponses. The results suggest that the spatial variability in density presents\nthe highest impact on the local strain field followed by thickness and fiber\norientation. Meanwhile, for the mechanical response, the fiber orientation\nangle with respect to the drying restraints is the key influencer and its\ncontribution to the anisotropy of the mechanical properties is greater than the\ncontribution of the fiber anisotropy developed during the fiber sheet-making.",
    "descriptor": "\nComments: 12 pages, 14 figures\n",
    "authors": [
      "Mossab Alzweighi",
      "Rami Mansour",
      "Jussi Lahti",
      "Ulrich Hirn",
      "Artem Kulachenko"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.04897"
  },
  {
    "id": "arXiv:2110.04898",
    "title": "Response surface single loop reliability-based design optimization with  higher-order reliability assessment",
    "abstract": "Reliability-based design optimization (RBDO) aims at determination of the\noptimal design in the presence of uncertainty. The available Single-Loop\napproaches for RBDO are based on the First-Order Reliability Method (FORM) for\nthe computation of the probability of failure, along with different\napproximations in order to avoid the expensive inner loop aiming at finding the\nMost Probable Point (MPP). However, the use of FORM in RBDO may not lead to\nsufficient accuracy depending on the degree of nonlinearity of the limit-state\nfunction. This is demonstrated for an extensively studied reliability-based\ndesign for vehicle crashworthiness problem solved in this paper, where all RBDO\nmethods based on FORM strongly violates the probabilistic constraints. The\nResponse Surface Single Loop (RSSL) method for RBDO is proposed based on the\nhigher order probability computation for quadratic models previously presented\nby the authors. The RSSL-method bypasses the concept of an MPP and has high\naccuracy and efficiency. The method can solve problems with both constant and\nvarying standard deviation of design variables and is particularly well suited\nfor typical industrial applications where general quadratic response surface\nmodels can be used. If the quadratic response surface models of the\ndeterministic constraints are valid in the whole region of interest, the method\nbecomes a true single loop method with accuracy higher than traditional SORM.\nIn other cases, quadratic response surface models are fitted to the\ndeterministic constraints around the deterministic solution and the RBDO\nproblem is solved using the proposed single loop method.",
    "descriptor": "\nComments: 17 pages, 10 figures\n",
    "authors": [
      "Rami Mansour",
      "M\u00e5rten Olsson"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.04898"
  },
  {
    "id": "arXiv:2110.04903",
    "title": "NormVAE: Normative Modeling on Neuroimaging Data using Variational  Autoencoders",
    "abstract": "Normative modeling is an emerging method for understanding the heterogeneous\nbiology underlying neuropsychiatric and neurodegenerative disorders at the\nlevel of the individual participant. Deep autoencoders have been implemented as\nnormative models, where patient-level deviations are modelled as the squared\ndifference between the actual and reconstructed input without any uncertainty\nestimates in the deviations. In this study, we assessed NormVAE, a novel\nnormative modeling based variational autoencoder (VAE) which calculates\nsubject-level normative abnormality maps (NAM) for quantifying uncertainty in\nthe deviations. Our experiments on brain neuroimaging data of Alzheimer's\nDisease (AD) patients demonstrated that the NormVAE-generated patient-level\nabnormality maps exhibit increased sensitivity to disease staging compared to a\nbaseline VAE, which generates deterministic subject-level deviations without\nany uncertainty estimates.",
    "descriptor": "\nComments: 35th Conference on Neural Information Processing Systems (NeurIPS 2021 Workshop : Medical Imaging Meets NeurIPS\n",
    "authors": [
      "Sayantan Kumar",
      "Aristeidis Sotiras"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04903"
  },
  {
    "id": "arXiv:2110.04908",
    "title": "Personalizing ASR with limited data using targeted subset selection",
    "abstract": "We study the task of personalizing ASR models to a target non-native\nspeaker/accent while being constrained by a transcription budget on the\nduration of utterances selected from a large unlabelled corpus. We propose a\nsubset selection approach using the recently proposed submodular mutual\ninformation functions, in which we identify a diverse set of utterances that\nmatch the target speaker/accent. This is specified through a few target\nutterances and achieved by modelling the relationship between the target subset\nand the selected subset using submodular mutual information functions. This\nmethod is applied at both the speaker and accent levels. We personalize the\nmodel by fine tuning it with utterances selected and transcribed from the\nunlabelled corpus. Our method is able to consistently identify utterances from\nthe target speaker/accent using just speech features. We show that the targeted\nsubset selection approach improves upon random sampling by as much as 2% to 5%\n(absolute) depending on the speaker and accent and is 2x to 4x more\nlabel-efficient compared to random sampling. We also compare with a skyline\nwhere we specifically pick from the target and generally outperforms the oracle\nin its selections.",
    "descriptor": "",
    "authors": [
      "Mayank Kothyari",
      "Anmol Reddy Mekala",
      "Rishabh Iyer",
      "Ganesh Ramakrishnan",
      "Preethi Jyothi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04908"
  },
  {
    "id": "arXiv:2110.04910",
    "title": "A Hybrid Scattering Transform for Signals with Isolated Singularities",
    "abstract": "The scattering transform is a wavelet-based model of Convolutional Neural\nNetworks originally introduced by S. Mallat. Mallat's analysis shows that this\nnetwork has desirable stability and invariance guarantees and therefore helps\nexplain the observation that the filters learned by early layers of a\nConvolutional Neural Network typically resemble wavelets. Our aim is to\nunderstand what sort of filters should be used in the later layers of the\nnetwork. Towards this end, we propose a two-layer hybrid scattering transform.\nIn our first layer, we convolve the input signal with a wavelet filter\ntransform to promote sparsity, and, in the second layer, we convolve with a\nGabor filter to leverage the sparsity created by the first layer. We show that\nthese measurements characterize information about signals with isolated\nsingularities. We also show that the Gabor measurements used in the second\nlayer can be used to synthesize sparse signals such as those produced by the\nfirst layer.",
    "descriptor": "",
    "authors": [
      "Michael Perlmutter",
      "Jieqian He",
      "Mark Iwen",
      "Matthew Hirn"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.04910"
  },
  {
    "id": "arXiv:2110.04913",
    "title": "Are Words the Quanta of Human Language? Extending the Domain of Quantum  Cognition",
    "abstract": "Quantum structures were identified as relevant for describing situations\noccurring in human cognition in the domain of quantum cognition and were also\nfruitfully used in information retrieval and natural language processing in the\ndomain of quantum information theory. In the present article, we build on\nrecent prior work and show that additionally to the already identified quantum\nstructures also quantization is present in human cognition. It appears in the\nform of the words behaving as quanta of human language, very analogous to how\nphotons behave as quanta of electromagnetic radiation. We illustrate this by\nshowing on an example text that Bose-Einstein statistics provides a perfect\nmodel while Maxwell-Boltzmann statistics is totally inadequate. Like the\nindistinguishability of quantum particles introduces a specific form of\nentanglement this also happens with words. We investigate this entanglement,\ncompute the von Neumann entropy and the amount of non purity of the density\nmatrices of the words and note that non-locality occurs spontaneously. We\ninterpret these results in terms of the prospect of developing a\nquantum-inspired thermodynamics for the cultural layer of human society, based\non a statistical analysis similar to what we propose in this article.",
    "descriptor": "\nComments: 28 pages, 3 figures. arXiv admin note: text overlap with arXiv:1909.06845\n",
    "authors": [
      "Diederik Aerts",
      "Lester Beltran"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Computation and Language (cs.CL)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.04913"
  },
  {
    "id": "arXiv:2110.04925",
    "title": "Quadratic Multiform Separation: A New Classification Model in Machine  Learning",
    "abstract": "In this paper we present a new classification model in machine learning. Our\nresult is threefold: 1) The model produces comparable predictive accuracy to\nthat of most common classification models. 2) It runs significantly faster than\nmost common classification models. 3) It has the ability to identify a portion\nof unseen samples for which class labels can be found with much higher\npredictive accuracy. Currently there are several patents pending on the\nproposed model.",
    "descriptor": "\nComments: 14 pages, 1 figure\n",
    "authors": [
      "Ko-Hui Michael Fan",
      "Chih-Chung Chang",
      "Kuang-Hsiao-Yin Kongguoluo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04925"
  },
  {
    "id": "arXiv:2110.04926",
    "title": "Convergence of Random Reshuffling Under The Kurdyka-\u0141ojasiewicz  Inequality",
    "abstract": "We study the random reshuffling (RR) method for smooth nonconvex optimization\nproblems with a finite-sum structure. Though this method is widely utilized in\npractice such as the training of neural networks, its convergence behavior is\nonly understood in several limited settings. In this paper, under the\nwell-known Kurdyka-Lojasiewicz (KL) inequality, we establish strong limit-point\nconvergence results for RR with appropriate diminishing step sizes, namely, the\nwhole sequence of iterates generated by RR is convergent and converges to a\nsingle stationary point in an almost sure sense. In addition, we derive the\ncorresponding rate of convergence, depending on the KL exponent and the\nsuitably selected diminishing step sizes. When the KL exponent lies in\n$[0,\\frac12]$, the convergence is at a rate of $\\mathcal{O}(t^{-1})$ with $t$\ncounting the iteration number. When the KL exponent belongs to $(\\frac12,1)$,\nour derived convergence rate is of the form $\\mathcal{O}(t^{-q})$ with $q\\in\n(0,1)$ depending on the KL exponent. The standard KL inequality-based\nconvergence analysis framework only applies to algorithms with a certain\ndescent property. Remarkably, we conduct convergence analysis for the\nnon-descent RR with diminishing step sizes based on the KL inequality, which\ngeneralizes the standard KL analysis framework. We summarize our main steps and\ncore ideas in an analysis framework, which is of independent interest. As a\ndirect application of this framework, we also establish similar strong\nlimit-point convergence results for the shuffled proximal point method.",
    "descriptor": "",
    "authors": [
      "Xiao Li",
      "Andre Milzarek",
      "Junwen Qiu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04926"
  },
  {
    "id": "arXiv:2110.04948",
    "title": "Advancing Momentum Pseudo-Labeling with Conformer and Initialization  Strategy",
    "abstract": "Pseudo-labeling (PL), a semi-supervised learning (SSL) method where a seed\nmodel performs self-training using pseudo-labels generated from untranscribed\nspeech, has been shown to enhance the performance of end-to-end automatic\nspeech recognition (ASR). Our prior work proposed momentum pseudo-labeling\n(MPL), which performs PL-based SSL via an interaction between online and\noffline models, inspired by the mean teacher framework. MPL achieves remarkable\nresults on various semi-supervised settings, showing robustness to variations\nin the amount of data and domain mismatch severity. However, there is further\nroom for improving the seed model used to initialize the MPL training, as it is\nin general critical for a PL-based method to start training from high-quality\npseudo-labels. To this end, we propose to enhance MPL by (1) introducing the\nConformer architecture to boost the overall recognition accuracy and (2)\nexploiting iterative pseudo-labeling with a language model to improve the seed\nmodel before applying MPL. The experimental results demonstrate that the\nproposed approaches effectively improve MPL performance, outperforming other\nPL-based methods. We also present in-depth investigations to make our\nimprovements effective, e.g., with regard to batch normalization typically used\nin Conformer and LM quality.",
    "descriptor": "\nComments: Submitted to ICASSP2022\n",
    "authors": [
      "Yosuke Higuchi",
      "Niko Moritz",
      "Jonathan Le Roux",
      "Takaaki Hori"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04948"
  },
  {
    "id": "arXiv:2110.04980",
    "title": "An Efficient Deep Learning Model for Automatic Modulation Recognition  Based on Parameter Estimation and Transformation",
    "abstract": "Automatic modulation recognition (AMR) is a promising technology for\nintelligent communication receivers to detect signal modulation schemes.\nRecently, the emerging deep learning (DL) research has facilitated\nhigh-performance DL-AMR approaches. However, most DL-AMR models only focus on\nrecognition accuracy, leading to huge model sizes and high computational\ncomplexity, while some lightweight and low-complexity models struggle to meet\nthe accuracy requirements. This letter proposes an efficient DL-AMR model based\non phase parameter estimation and transformation, with convolutional neural\nnetwork (CNN) and gated recurrent unit (GRU) as the feature extraction layers,\nwhich can achieve high recognition accuracy equivalent to the existing\nstate-of-the-art models but reduces more than a third of the volume of their\nparameters. Meanwhile, our model is more competitive in training time and test\ntime than the benchmark models with similar recognition accuracy. Moreover, we\nfurther propose to compress our model by pruning, which maintains the\nrecognition accuracy higher than 90% while has less than 1/8 of the number of\nparameters comparing with state-of-the-art models.",
    "descriptor": "",
    "authors": [
      "Fuxin Zhang",
      "Chunbo Luo",
      "Jialang Xu",
      "Yang Luo"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04980"
  },
  {
    "id": "arXiv:2110.04986",
    "title": "COVID-Datathon: Biomarker identification for COVID-19 severity based on  BALF scRNA-seq data",
    "abstract": "The severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) emergence\nbegan in late 2019 and has since spread rapidly worldwide. The characteristics\nof respiratory immune response to this emerging virus is not clear. Recently,\nSingle-cell RNA sequencing (scRNA-seq) transcriptome profiling of\nBronchoalveolar lavage fluid (BALF) cells has been done to elucidate the\npotential mechanisms underlying in COVID-19. With the aim of better utilizing\nthis atlas of BALF cells in response to the virus, here we propose a\nbioinformatics pipeline to identify candidate biomarkers of COVID-19 severity,\nwhich may help characterize BALF cells to have better mechanistic understanding\nof SARS-CoV-2 infection. The proposed pipeline is implemented in R and is\navailable at https://github.com/namini94/scBALF_Hackathon.",
    "descriptor": "",
    "authors": [
      "Seyednami Niyakan",
      "Xiaoning Qian"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04986"
  },
  {
    "id": "arXiv:2110.04987",
    "title": "Binary Programming Formulations for the Upper Domination Problem",
    "abstract": "We consider Upper Domination, the problem of finding the minimal dominating\nset of maximum cardinality. Very few exact algorithms have been described for\nsolving Upper Domination. In particular, no binary programming formulations for\nUpper Domination have been described in literature, although such formulations\nhave proved quite successful for other kinds of domination problems. We\nintroduce two such binary programming formulations, and compare their\nperformance on various kinds of graphs. We demonstrate that the first performs\nbetter in most cases, but the second performs better for very sparse graphs.\nAlso included is a short proof that the upper domination of any generalized\nPetersen graph P(n,k) is equal to n.",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Ryan Burdett",
      "Michael Haythorpe",
      "Alex Newcombe"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.04987"
  },
  {
    "id": "arXiv:2110.04993",
    "title": "On the energy landscape of symmetric quantum signal processing",
    "abstract": "Symmetric quantum signal processing provides a parameterized representation\nof a real polynomial, which can be translated into an efficient quantum circuit\nfor performing a wide range of computational tasks on quantum computers. For a\ngiven polynomial, the parameters (called phase factors) can be obtained by\nsolving an optimization problem. However, the cost function is non-convex, and\nhas a very complex energy landscape with numerous global and local minima. It\nis therefore surprising that the solution can be robustly obtained in practice,\nstarting from a fixed initial guess $\\Phi^0$ that contains no information of\nthe input polynomial. To investigate this phenomenon, we first explicitly\ncharacterize all the global minima of the cost function. We then prove that one\nparticular global minimum (called the maximal solution) belongs to a\nneighborhood of $\\Phi^0$, on which the cost function is strongly convex under\nsuitable conditions. This explains the aforementioned success of optimization\nalgorithms, and solves the open problem of finding phase factors using only\nstandard double precision arithmetic operations.",
    "descriptor": "\nComments: 46 pages, 5 figures,\n",
    "authors": [
      "Jiasu Wang",
      "Yulong Dong",
      "Lin Lin"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.04993"
  },
  {
    "id": "arXiv:2110.04996",
    "title": "Designing off-sample performance metrics",
    "abstract": "Modern machine learning systems are traditionally designed and tested with\nthe overall goal of achieving the best possible performance on average. In this\nwork, we consider an approach to building learning systems which treats the\nquestion of \"how should we quantify good off-sample performance?\" as a key\ndesign decision. We describe this proposal using a simple and general\nformulation, place the current dominant paradigm within the proper historical\ncontext, and then survey the literature for more recent developments that\ndepart from tradition and can be viewed as special cases of our proposed\nmethodology.",
    "descriptor": "",
    "authors": [
      "Matthew J. Holland"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04996"
  },
  {
    "id": "arXiv:2110.04998",
    "title": "Nonparametric Functional Analysis of Generalized Linear Models Under  Nonlinear Constraints",
    "abstract": "This article introduces a novel nonparametric methodology for Generalized\nLinear Models which combines the strengths of the binary regression and latent\nvariable formulations for categorical data, while overcoming their\ndisadvantages. Requiring minimal assumptions, it extends recently published\nparametric versions of the methodology and generalizes it. If the underlying\ndata generating process is asymmetric, it gives uniformly better prediction and\ninference performance over the parametric formulation. Furthermore, it\nintroduces a new classification statistic utilizing which I show that overall,\nit has better model fit, inference and classification performance than the\nparametric version, and the difference in performance is statistically\nsignificant especially if the data generating process is asymmetric. In\naddition, the methodology can be used to perform model diagnostics for any\nmodel specification. This is a highly useful result, and it extends existing\nwork for categorical model diagnostics broadly across the sciences. The\nmathematical results also highlight important new findings regarding the\ninterplay of statistical significance and scientific significance. Finally, the\nmethodology is applied to various real-world datasets to show that it may\noutperform widely used existing models, including Random Forests and Deep\nNeural Networks with very few iterations.",
    "descriptor": "",
    "authors": [
      "K. P. Chowdhury"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.04998"
  },
  {
    "id": "arXiv:2110.05000",
    "title": "Exact Matching of Random Graphs with Constant Correlation",
    "abstract": "This paper deals with the problem of graph matching or network alignment for\nErd\\H{o}s--R\\'enyi graphs, which can be viewed as a noisy average-case version\nof the graph isomorphism problem. Let $G$ and $G'$ be $G(n, p)$\nErd\\H{o}s--R\\'enyi graphs marginally, identified with their adjacency matrices.\nAssume that $G$ and $G'$ are correlated such that $\\mathbb{E}[G_{ij} G'_{ij}] =\np(1-\\alpha)$. For a permutation $\\pi$ representing a latent matching between\nthe vertices of $G$ and $G'$, denote by $G^\\pi$ the graph obtained from\npermuting the vertices of $G$ by $\\pi$. Observing $G^\\pi$ and $G'$, we aim to\nrecover the matching $\\pi$. In this work, we show that for every $\\varepsilon\n\\in (0,1]$, there is $n_0>0$ depending on $\\varepsilon$ and absolute constants\n$\\alpha_0, R > 0$ with the following property. Let $n \\ge n_0$,\n$(1+\\varepsilon) \\log n \\le np \\le n^{\\frac{1}{R \\log \\log n}}$, and $0 <\n\\alpha < \\min(\\alpha_0,\\varepsilon/4)$. There is a polynomial-time algorithm\n$F$ such that $\\mathbb{P}\\{F(G^\\pi,G')=\\pi\\}=1-o(1)$. This is the first\npolynomial-time algorithm that recovers the exact matching between vertices of\ncorrelated Erd\\H{o}s--R\\'enyi graphs with constant correlation with high\nprobability. The algorithm is based on comparison of partition trees associated\nwith the graph vertices.",
    "descriptor": "\nComments: 53 pages, 1 figure\n",
    "authors": [
      "Cheng Mao",
      "Mark Rudelson",
      "Konstantin Tikhomirov"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.05000"
  },
  {
    "id": "arXiv:2110.05036",
    "title": "Multi-View Self-Attention Based Transformer for Speaker Recognition",
    "abstract": "Initially developed for natural language processing (NLP), Transformer model\nis now widely used for speech processing tasks such as speaker recognition, due\nto its powerful sequence modeling capabilities. However, conventional\nself-attention mechanisms are originally designed for modeling textual sequence\nwithout considering the characteristics of speech and speaker modeling.\nBesides, different Transformer variants for speaker recognition have not been\nwell studied. In this work, we propose a novel multi-view self-attention\nmechanism and present an empirical study of different Transformer variants with\nor without the proposed attention mechanism for speaker recognition.\nSpecifically, to balance the capabilities of capturing global dependencies and\nmodeling the locality, we propose a multi-view self-attention mechanism for\nspeaker Transformer, in which different attention heads can attend to different\nranges of the receptive field. Furthermore, we introduce and compare five\nTransformer variants with different network architectures, embedding locations,\nand pooling methods to learn speaker embeddings. Experimental results on the\nVoxCeleb1 and VoxCeleb2 datasets show that the proposed multi-view\nself-attention mechanism achieves improvement in the performance of speaker\nrecognition, and the proposed speaker Transformer network attains excellent\nresults compared with state-of-the-art models.",
    "descriptor": "\nComments: Submitted to the ICASSP 2022\n",
    "authors": [
      "Rui Wang",
      "Junyi Ao",
      "Long Zhou",
      "Shujie Liu",
      "Zhihua Wei",
      "Tom Ko",
      "Qing Li",
      "Yu Zhang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.05036"
  },
  {
    "id": "arXiv:2110.05039",
    "title": "Symmetry-Enhanced Attention Network for Acute Ischemic Infarct  Segmentation with Non-Contrast CT Images",
    "abstract": "Quantitative estimation of the acute ischemic infarct is crucial to improve\nneurological outcomes of the patients with stroke symptoms. Since the density\nof lesions is subtle and can be confounded by normal physiologic changes,\nanatomical asymmetry provides useful information to differentiate the ischemic\nand healthy brain tissue. In this paper, we propose a symmetry enhanced\nattention network (SEAN) for acute ischemic infarct segmentation. Our proposed\nnetwork automatically transforms an input CT image into the standard space\nwhere the brain tissue is bilaterally symmetric. The transformed image is\nfurther processed by a Ushape network integrated with the proposed symmetry\nenhanced attention for pixel-wise labelling. The symmetry enhanced attention\ncan efficiently capture context information from the opposite side of the image\nby estimating long-range dependencies. Experimental results show that the\nproposed SEAN outperforms some symmetry-based state-of-the-art methods in terms\nof both dice coefficient and infarct localization.",
    "descriptor": "\nComments: This paper has been accepted by MICCAI2021\n",
    "authors": [
      "Kongming Liang",
      "Kai Han",
      "Xiuli Li",
      "Xiaoqing Cheng",
      "Yiming Li",
      "Yizhou Wang",
      "Yizhou Yu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05039"
  },
  {
    "id": "arXiv:2110.05068",
    "title": "A weighted graph zeta function involved in the Szegedy walk",
    "abstract": "We define a new weighted zeta function for a finite graph and obtain its\ndeterminant expression. This result gives the characteristic polynomial of the\ntransition matrix of the Szegedy walk on a graph.",
    "descriptor": "",
    "authors": [
      "Ayaka Ishikawa",
      "Norio Konno"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.05068"
  },
  {
    "id": "arXiv:2110.05082",
    "title": "Computational aspects of finding a solution asymptotics for a singularly  perturbed system of differential equations",
    "abstract": "We analyze the spatial structure of asymptotics of a solution to a singularly\nperturbed system of mass transfer equations. The leading term of the\nasymptotics is described by a parabolic equation with possibly degenerate\nspatial part. We prove a theorem that establishes a relationship between the\ndegree of degeneracy and the numbers of equations in the system and spatial\nvariables in some particular cases. The work hardly depends on the calculation\nof the eigenvalues of matrices that determine the spatial structure of the\nasymptotics by the means of computer algebra system Wolfram Mathematica. We put\nforward a hypothesis on the existence of the found connection for an arbitrary\nnumber of equations and spatial variables.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Vitaly A. Krasikov",
      "Andrey V. Nesterov"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2110.05082"
  },
  {
    "id": "arXiv:2110.05093",
    "title": "Consistency of the Full and Reduced Order Models for Evolve-Filter-Relax  Regularization of Convection-Dominated, Marginally-Resolved Flows",
    "abstract": "Numerical stabilization is often used to eliminate (alleviate) the spurious\noscillations generally produced by full order models (FOMs) in under-resolved\nor marginally-resolved simulations of convection-dominated flows. In this\npaper, we investigate the role of numerical stabilization in reduced order\nmodels (ROMs) of marginally-resolved convection-dominated flows. Specifically,\nwe investigate the FOM-ROM consistency, i.e., whether the numerical\nstabilization is beneficial both at the FOM and the ROM level. As a numerical\nstabilization strategy, we focus on the evolve-filter-relax (EFR)\nregularization algorithm, which centers around spatial filtering. To\ninvestigate the FOM-ROM consistency, we consider two ROM strategies: (I) the\nEFR-ROM, in which the EFR stabilization is used at the FOM level, but not at\nthe ROM level; and (ii) the EFR-EFRROM, in which the EFR stabilization is used\nboth at the FOM and at the ROM level. We compare the EFR-ROM with the\nEFR-EFRROM in the numerical simulation of a 2D flow past a circular cylinder in\nthe convection-dominated, marginally-resolved regime. We also perform model\nreduction with respect to both time and Reynolds number. Our numerical\ninvestigation shows that the EFR-EFRROM is more accurate than the EFR-ROM,\nwhich suggests that FOM-ROM consistency is beneficial in\nconvection-dominated,marginally-resolved flows.",
    "descriptor": "",
    "authors": [
      "Maria Strazzullo",
      "Michele Girfoglio",
      "Francesco Ballarin",
      "Traian Iliescu",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05093"
  },
  {
    "id": "arXiv:2110.05144",
    "title": "AWEU-Net: An Attention-Aware Weight Excitation U-Net for Lung Nodule  Segmentation",
    "abstract": "Lung cancer is deadly cancer that causes millions of deaths every year around\nthe world. Accurate lung nodule detection and segmentation in computed\ntomography (CT) images is the most important part of diagnosing lung cancer in\nthe early stage. Most of the existing systems are semi-automated and need to\nmanually select the lung and nodules regions to perform the segmentation task.\nTo address these challenges, we proposed a fully automated end-to-end lung\nnodule detection and segmentation system based on a deep learning approach. In\nthis paper, we used Optimized Faster R-CNN; a state-of-the-art detection model\nto detect the lung nodule regions in the CT scans. Furthermore, we proposed an\nattention-aware weight excitation U-Net, called AWEU-Net, for lung nodule\nsegmentation and boundaries detection. To achieve more accurate nodule\nsegmentation, in AWEU-Net, we proposed position attention-aware weight\nexcitation (PAWE), and channel attention-aware weight excitation (CAWE) blocks\nto highlight the best aligned spatial and channel features in the input feature\nmaps. The experimental results demonstrate that our proposed model yields a\nDice score of 89.79% and 90.35%, and an intersection over union (IoU) of 82.34%\nand 83.21% on the publicly LUNA16 and LIDC-IDRI datasets, respectively.",
    "descriptor": "\nComments: 15 pages, submitted to MDPI applied sciences journal\n",
    "authors": [
      "Syeda Furruka Banu",
      "Md. Mostafa Kamal Sarker",
      "Mohamed Abdel-Nasser",
      "Domenec Puig",
      "Hatem A. Raswan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05144"
  },
  {
    "id": "arXiv:2110.05167",
    "title": "Robust and Scalable SDE Learning: A Functional Perspective",
    "abstract": "Stochastic differential equations provide a rich class of flexible generative\nmodels, capable of describing a wide range of spatio-temporal processes. A host\nof recent work looks to learn data-representing SDEs, using neural networks and\nother flexible function approximators. Despite these advances, learning remains\ncomputationally expensive due to the sequential nature of SDE integrators. In\nthis work, we propose an importance-sampling estimator for probabilities of\nobservations of SDEs for the purposes of learning. Crucially, the approach we\nsuggest does not rely on such integrators. The proposed method produces\nlower-variance gradient estimates compared to algorithms based on SDE\nintegrators and has the added advantage of being embarrassingly parallelizable.\nThis facilitates the effective use of large-scale parallel hardware for massive\ndecreases in computation time.",
    "descriptor": "",
    "authors": [
      "Scott Cameron",
      "Tyron Cameron",
      "Arnu Pretorius",
      "Stephen Roberts"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05167"
  },
  {
    "id": "arXiv:2110.05196",
    "title": "Learning and Dynamical Models for Sub-seasonal Climate Forecasting:  Comparison and Collaboration",
    "abstract": "Sub-seasonal climate forecasting (SSF) is the prediction of key climate\nvariables such as temperature and precipitation on the 2-week to 2-month time\nhorizon. Skillful SSF would have substantial societal value in areas such as\nagricultural productivity, hydrology and water resource management, and\nemergency planning for extreme events such as droughts and wildfires. Despite\nits societal importance, SSF has stayed a challenging problem compared to both\nshort-term weather forecasting and long-term seasonal forecasting. Recent\nstudies have shown the potential of machine learning (ML) models to advance\nSSF. In this paper, for the first time, we perform a fine-grained comparison of\na suite of modern ML models with start-of-the-art physics-based dynamical\nmodels from the Subseasonal Experiment (SubX) project for SSF in the western\ncontiguous United States. Additionally, we explore mechanisms to enhance the ML\nmodels by using forecasts from dynamical models. Empirical results illustrate\nthat, on average, ML models outperform dynamical models while the ML models\ntend to be conservatives in their forecasts compared to the SubX models.\nFurther, we illustrate that ML models make forecasting errors under extreme\nweather conditions, e.g., cold waves due to the polar vortex, highlighting the\nneed for separate models for extreme events. Finally, we show that suitably\nincorporating dynamical model forecasts as inputs to ML models can\nsubstantially improve the forecasting performance of the ML models. The SSF\ndataset constructed for the work, dynamical model predictions, and code for the\nML models are released along with the paper for the benefit of the broader\nmachine learning community.",
    "descriptor": "",
    "authors": [
      "Sijie He",
      "Xinyan Li",
      "Laurie Trenary",
      "Benjamin A Cash",
      "Timothy DelSole",
      "Arindam Banerjee"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05196"
  },
  {
    "id": "arXiv:2110.05225",
    "title": "\u03b2-Intact-VAE: Identifying and Estimating Causal Effects under  Limited Overlap",
    "abstract": "As an important problem in causal inference, we discuss the identification\nand estimation of treatment effects (TEs) under limited overlap; that is, when\nsubjects with certain features belong to a single treatment group. We use a\nlatent variable to model a prognostic score which is widely used in\nbiostatistics and sufficient for TEs; i.e., we build a generative prognostic\nmodel. We prove that the latent variable recovers a prognostic score, and the\nmodel identifies individualized treatment effects. The model is then learned as\n\\beta-Intact-VAE--a new type of variational autoencoder (VAE). We derive the TE\nerror bounds that enable representations balanced for treatment groups\nconditioned on individualized features. The proposed method is compared with\nrecent methods using (semi-)synthetic datasets.",
    "descriptor": "\nComments: Updated version of the NeurIPS 2021 submission (this https URL). Largely improve readability and the presentation of experimental results. arXiv admin note: text overlap with arXiv:2109.15062\n",
    "authors": [
      "Pengzhou Wu",
      "Kenji Fukumizu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.05225"
  },
  {
    "id": "arXiv:2110.05230",
    "title": "Packing list-colourings",
    "abstract": "List colouring is an influential and classic topic in graph theory. We\ninitiate the study of a natural strengthening of this problem, where instead of\none list-colouring, we seek many in parallel. Our explorations have uncovered a\npotentially rich seam of interesting problems spanning chromatic graph theory.\nGiven a $k$-list-assignment $L$ of a graph $G$, which is the assignment of a\nlist $L(v)$ of $k$ colours to each vertex $v\\in V(G)$, we study the existence\nof $k$ pairwise-disjoint proper colourings of $G$ using colours from these\nlists. We may refer to this as a \\emph{list-packing}. Using a mix of\ncombinatorial and probabilistic methods, we set out some basic upper bounds on\nthe smallest $k$ for which such a list-packing is always guaranteed, in terms\nof the number of vertices, the degeneracy, the maximum degree, or the (list)\nchromatic number of $G$. (The reader might already find it interesting that\nsuch a minimal $k$ is well defined.) We also pursue a more focused study of the\ncase when $G$ is a bipartite graph. Our results do not yet rule out the\ntantalising prospect that the minimal $k$ above is not too much larger than the\nlist chromatic number.\nOur study has taken inspiration from study of the strong chromatic number,\nand we also explore generalisations of the problem above in the same spirit.",
    "descriptor": "\nComments: 31 pages, 2 tables\n",
    "authors": [
      "Stijn Cambie",
      "Wouter Cames van Batenburg",
      "Ewan Davies",
      "Ross J. Kang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.05230"
  },
  {
    "id": "arXiv:2110.05231",
    "title": "Multi-modal Self-supervised Pre-training for Regulatory Genome Across  Cell Types",
    "abstract": "In the genome biology research, regulatory genome modeling is an important\ntopic for many regulatory downstream tasks, such as promoter classification,\ntransaction factor binding sites prediction. The core problem is to model how\nregulatory elements interact with each other and its variability across\ndifferent cell types. However, current deep learning methods often focus on\nmodeling genome sequences of a fixed set of cell types and do not account for\nthe interaction between multiple regulatory elements, making them only perform\nwell on the cell types in the training set and lack the generalizability\nrequired in biological applications. In this work, we propose a simple yet\neffective approach for pre-training genome data in a multi-modal and\nself-supervised manner, which we call GeneBERT. Specifically, we simultaneously\ntake the 1d sequence of genome data and a 2d matrix of (transcription factors x\nregions) as the input, where three pre-training tasks are proposed to improve\nthe robustness and generalizability of our model. We pre-train our model on the\nATAC-seq dataset with 17 million genome sequences. We evaluate our GeneBERT on\nregulatory downstream tasks across different cell types, including promoter\nclassification, transaction factor binding sites prediction, disease risk\nestimation, and splicing sites prediction. Extensive experiments demonstrate\nthe effectiveness of multi-modal and self-supervised pre-training for\nlarge-scale regulatory genomics data.",
    "descriptor": "",
    "authors": [
      "Shentong Mo",
      "Xi Fu",
      "Chenyang Hong",
      "Yizhen Chen",
      "Yuxuan Zheng",
      "Xiangru Tang",
      "Zhiqiang Shen",
      "Eric P Xing",
      "Yanyan Lan"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05231"
  },
  {
    "id": "arXiv:2110.05241",
    "title": "Streaming Transformer Transducer Based Speech Recognition Using  Non-Causal Convolution",
    "abstract": "This paper improves the streaming transformer transducer for speech\nrecognition by using non-causal convolution. Many works apply the causal\nconvolution to improve streaming transformer ignoring the lookahead context. We\npropose to use non-causal convolution to process the center block and lookahead\ncontext separately. This method leverages the lookahead context in convolution\nand maintains similar training and decoding efficiency. Given the similar\nlatency, using the non-causal convolution with lookahead context gives better\naccuracy than causal convolution, especially for open-domain dictation\nscenarios. Besides, this paper applies talking-head attention and a novel\nhistory context compression scheme to further improve the performance. The\ntalking-head attention improves the multi-head self-attention by transferring\ninformation among different heads. The history context compression method\nintroduces more extended history context compactly. On our in-house data, the\nproposed methods improve a small Emformer baseline with lookahead context by\nrelative WERR 5.1\\%, 14.5\\%, 8.4\\% on open-domain dictation, assistant general\nscenarios, and assistant calling scenarios, respectively.",
    "descriptor": "\nComments: 5 pages, 3 figures, submit to ICASSP 2022\n",
    "authors": [
      "Yangyang Shi",
      "Chunyang Wu",
      "Dilin Wang",
      "Alex Xiao",
      "Jay Mahadeokar",
      "Xiaohui Zhang",
      "Chunxi Liu",
      "Ke Li",
      "Yuan Shangguan",
      "Varun Nagaraja",
      "Ozlem Kalinli",
      "Mike Seltzer"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05241"
  },
  {
    "id": "arXiv:2110.05243",
    "title": "Score-based diffusion models for accelerated MRI",
    "abstract": "Score-based diffusion models provide a powerful way to model images using the\ngradient of the data distribution. Leveraging the learned score function as a\nprior, here we introduce a way to sample data from a conditional distribution\ngiven the measurements, such that the model can be readily used for solving\ninverse problems in imaging, especially for accelerated MRI. In short, we train\na continuous time-dependent score function with denoising score matching. Then,\nat the inference stage, we iterate between numerical SDE solver and data\nconsistency projection step to achieve reconstruction. Our model requires\nmagnitude images only for training, and yet is able to reconstruct\ncomplex-valued data, and even extends to parallel imaging. The proposed method\nis agnostic to sub-sampling patterns, and can be used with any sampling\nschemes. Also, due to its generative nature, our approach can quantify\nuncertainty, which is not possible with standard regression settings. On top of\nall the advantages, our method also has very strong performance, even beating\nthe models trained with full supervision. With extensive experiments, we verify\nthe superiority of our method in terms of quality and practicality.",
    "descriptor": "",
    "authors": [
      "Hyungjin Chung",
      "Jong chul Ye"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05243"
  },
  {
    "id": "arXiv:2110.05249",
    "title": "A Comparative Study on Non-Autoregressive Modelings for Speech-to-Text  Generation",
    "abstract": "Non-autoregressive (NAR) models simultaneously generate multiple outputs in a\nsequence, which significantly reduces the inference speed at the cost of\naccuracy drop compared to autoregressive baselines. Showing great potential for\nreal-time applications, an increasing number of NAR models have been explored\nin different fields to mitigate the performance gap against AR models. In this\nwork, we conduct a comparative study of various NAR modeling methods for\nend-to-end automatic speech recognition (ASR). Experiments are performed in the\nstate-of-the-art setting using ESPnet. The results on various tasks provide\ninteresting findings for developing an understanding of NAR ASR, such as the\naccuracy-speed trade-off and robustness against long-form utterances. We also\nshow that the techniques can be combined for further improvement and applied to\nNAR end-to-end speech translation. All the implementations are publicly\navailable to encourage further research in NAR speech processing.",
    "descriptor": "\nComments: Accepted to ASRU2021\n",
    "authors": [
      "Yosuke Higuchi",
      "Nanxin Chen",
      "Yuya Fujita",
      "Hirofumi Inaguma",
      "Tatsuya Komatsu",
      "Jaesong Lee",
      "Jumon Nozaki",
      "Tianzi Wang",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.05249"
  },
  {
    "id": "arXiv:2110.05256",
    "title": "On $q$-ary shortened-$1$-perfect-like codes",
    "abstract": "We study codes with parameters of $q$-ary shortened Hamming codes, i.e.,\n$(n=(q^m-q)/(q-1), q^{n-m}, 3)_q$. At first, we prove the fact mentioned in\n[A.E.Brouwer et al. Bounds on mixed binary/ternary codes. IEEE Trans. Inf.\nTheory 44 (1998) 140-161] that such codes are optimal, generalizing it to a\nbound for multifold packings of radius-$1$ balls, with a corollary for multiple\ncoverings. In particular, we show that the punctured Hamming code is an optimal\n$q$-fold packing with minimum distance $2$. At second, we show the existence of\n$4$-ary codes with parameters of shortened $1$-perfect codes that cannot be\nobtained by shortening a $1$-perfect code. Keywords: Hamming graph; multifold\npackings; multiple coverings; perfect codes.",
    "descriptor": "",
    "authors": [
      "Minjia Shi",
      "Rongsheng Wu",
      "Denis S. Krotov"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.05256"
  },
  {
    "id": "arXiv:2110.05260",
    "title": "Designing Composites with Target Effective Young's Modulus using  Reinforcement Learning",
    "abstract": "Advancements in additive manufacturing have enabled design and fabrication of\nmaterials and structures not previously realizable. In particular, the design\nspace of composite materials and structures has vastly expanded, and the\nresulting size and complexity has challenged traditional design methodologies,\nsuch as brute force exploration and one factor at a time (OFAT) exploration, to\nfind optimum or tailored designs. To address this challenge, supervised machine\nlearning approaches have emerged to model the design space using curated\ntraining data; however, the selection of the training data is often determined\nby the user. In this work, we develop and utilize a Reinforcement learning\n(RL)-based framework for the design of composite structures which avoids the\nneed for user-selected training data. For a 5 $\\times$ 5 composite design space\ncomprised of soft and compliant blocks of constituent material, we find that\nusing this approach, the model can be trained using 2.78% of the total design\nspace consists of $2^{25}$ design possibilities. Additionally, the developed\nRL-based framework is capable of finding designs at a success rate exceeding\n90%. The success of this approach motivates future learning frameworks to\nutilize RL for the design of composites and other material systems.",
    "descriptor": "\nComments: Accepted to the Symposium on Computational Fabrication (SCF) 2021\n",
    "authors": [
      "Aldair E. Gongora",
      "Siddharth Mysore",
      "Beichen Li",
      "Wan Shou",
      "Wojciech Matusik",
      "Elise F. Morgan",
      "Keith A. Brown",
      "Emily Whiting"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05260"
  },
  {
    "id": "arXiv:2110.05267",
    "title": "Interactive Feature Fusion for End-to-End Noise-Robust Speech  Recognition",
    "abstract": "Speech enhancement (SE) aims to suppress the additive noise from a noisy\nspeech signal to improve the speech's perceptual quality and intelligibility.\nHowever, the over-suppression phenomenon in the enhanced speech might degrade\nthe performance of downstream automatic speech recognition (ASR) task due to\nthe missing latent information. To alleviate such problem, we propose an\ninteractive feature fusion network (IFF-Net) for noise-robust speech\nrecognition to learn complementary information from the enhanced feature and\noriginal noisy feature. Experimental results show that the proposed method\nachieves absolute word error rate (WER) reduction of 4.1% over the best\nbaseline on RATS Channel-A corpus. Our further analysis indicates that the\nproposed IFF-Net can complement some missing information in the over-suppressed\nenhanced feature.",
    "descriptor": "\nComments: 5 pages, 7 figures, Submitted to ICASSP 2022\n",
    "authors": [
      "Yuchen Hu",
      "Nana Hou",
      "Chen Chen",
      "Eng Siong Chng"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.05267"
  },
  {
    "id": "arXiv:2110.05306",
    "title": "Deep Unsupervised Feature Selection by Discarding Nuisance and  Correlated Features",
    "abstract": "Modern datasets often contain large subsets of correlated features and\nnuisance features, which are not or loosely related to the main underlying\nstructures of the data. Nuisance features can be identified using the Laplacian\nscore criterion, which evaluates the importance of a given feature via its\nconsistency with the Graph Laplacians' leading eigenvectors. We demonstrate\nthat in the presence of large numbers of nuisance features, the Laplacian must\nbe computed on the subset of selected features rather than on the complete\nfeature set. To do this, we propose a fully differentiable approach for\nunsupervised feature selection, utilizing the Laplacian score criterion to\navoid the selection of nuisance features. We employ an autoencoder architecture\nto cope with correlated features, trained to reconstruct the data from the\nsubset of selected features. Building on the recently proposed concrete layer\nthat allows controlling for the number of selected features via architectural\ndesign, simplifying the optimization process. Experimenting on several\nreal-world datasets, we demonstrate that our proposed approach outperforms\nsimilar approaches designed to avoid only correlated or nuisance features, but\nnot both. Several state-of-the-art clustering results are reported.",
    "descriptor": "",
    "authors": [
      "Uri Shaham",
      "Ofir Lindenbaum",
      "Jonathan Svirsky",
      "Yuval Kluger"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05306"
  },
  {
    "id": "arXiv:2110.05317",
    "title": "Dynamic Median Consensus Over Random Networks",
    "abstract": "This paper studies the problem of finding the median of N distinct numbers\ndistributed across networked agents. Each agent updates its estimate for the\nmedian from noisy local observations of one of the N numbers and information\nfrom neighbors. We consider an undirected random network that is connected on\naverage, and a noisy observation sequence that has finite variance and almost\nsurely decaying bias. We present a consensus+innovations algorithm with clipped\ninnovations. Under some regularity assumptions on the network and observation\nmodel, we show that each agent's local estimate converges to the set of\nmedian(s) almost surely at an asymptotic sublinear rate. Numerical experiments\ndemonstrate the effectiveness of the presented algorithm.",
    "descriptor": "\nComments: 8 pages, 3 figures, IEEE CDC 2021\n",
    "authors": [
      "Shuhua Yu",
      "Yuan Chen",
      "Soummya Kar"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.05317"
  },
  {
    "id": "arXiv:2110.05327",
    "title": "Compositionality as we see it, everywhere around us",
    "abstract": "There are different meanings of the term \"compositionality\" within science:\nwhat one researcher would call compositional, is not at all compositional for\nanother researcher. The most established conception is usually attributed to\nFrege, and is characterised by a bottom-up flow of meanings: the meaning of the\nwhole can be derived from the meanings of the parts, and how these parts are\nstructured together.\nInspired by work on compositionality in quantum theory, and categorical\nquantum mechanics in particular, we propose the notions of Schrodinger,\nWhitehead, and complete compositionality. Accounting for recent important\ndevelopments in quantum technology and artificial intelligence, these do not\nhave the bottom-up meaning flow as part of their definitions.\nSchrodinger compositionality accommodates quantum theory, and also\nmeaning-as-context. Complete compositionality further strengthens Schrodinger\ncompositionality in order to single out theories like ZX-calculus, that are\ncomplete with regard to the intended model. All together, our new notions aim\nto capture the fact that compositionality is at its best when it is `real',\n`non-trivial', and even more when it also is `complete'.\nAt this point we only put forward the intuitive and/or restricted formal\ndefinitions, and leave a fully comprehensive definition to future collaborative\nwork.",
    "descriptor": "\nComments: 22 pages, lots of refs, lots of pictures, as usual\n",
    "authors": [
      "Bob Coecke"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.05327"
  },
  {
    "id": "arXiv:2110.05428",
    "title": "Learning Temporally Causal Latent Processes from General Temporal Data",
    "abstract": "Our goal is to recover time-delayed latent causal variables and identify\ntheir relations from measured temporal data. Estimating causally-related latent\nvariables from observations is particularly challenging as the latent variables\nare not uniquely recoverable in the most general case. In this work, we\nconsider both a nonparametric, nonstationary setting and a parametric setting\nfor the latent processes and propose two provable conditions under which\ntemporally causal latent processes can be identified from their nonlinear\nmixtures. We propose LEAP, a theoretically-grounded architecture that extends\nVariational Autoencoders (VAEs) by enforcing our conditions through proper\nconstraints in causal process prior. Experimental results on various data sets\ndemonstrate that temporally causal latent processes are reliably identified\nfrom observed variables under different dependency structures and that our\napproach considerably outperforms baselines that do not leverage history or\nnonstationarity information. This is one of the first works that successfully\nrecover time-delayed latent processes from nonlinear mixtures without using\nsparsity or minimality assumptions.",
    "descriptor": "",
    "authors": [
      "Weiran Yao",
      "Yuewen Sun",
      "Alex Ho",
      "Changyin Sun",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05428"
  },
  {
    "id": "arXiv:2110.05431",
    "title": "On the invertibility of a voice privacy system using embedding  alignement",
    "abstract": "This paper explores various attack scenarios on a voice anonymization system\nusing embeddings alignment techniques. We use Wasserstein-Procrustes (an\nalgorithm initially designed for unsupervised translation) or Procrustes\nanalysis to match two sets of x-vectors, before and after voice anonymization,\nto mimic this transformation as a rotation function. We compute the optimal\nrotation and compare the results of this approximation to the official Voice\nPrivacy Challenge results. We show that a complex system like the baseline of\nthe Voice Privacy Challenge can be approximated by a rotation, estimated using\na limited set of x-vectors. This paper studies the space of solutions for voice\nanonymization within the specific scope of rotations. Rotations being\nreversible, the proposed method can recover up to 62% of the speaker identities\nfrom anonymized embeddings.",
    "descriptor": "",
    "authors": [
      "Pierre Champion",
      "Thomas Thebaud",
      "Ga\u00ebl Le Lan",
      "Anthony Larcher",
      "Denis Jouvet"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.05431"
  },
  {
    "id": "arXiv:2110.05436",
    "title": "A differential approach to detecting projective equivalences and  symmetries of rational 3D curves",
    "abstract": "We present a new approach to detecting projective equivalences and symmetries\nof rational parametric 3D curves. To detect projective equivalences, we first\nderive two projective differential invariants that are also invariant with\nrespect to the change of parameters called M\\\"obius transformations. Given two\nrational curves, we form a system consists of two homogeneous polynomials in\nfour variables using the projective differential invariants. The solution of\nthe system yields the M\\\"obius transformations, each of which corresponds to a\nprojective equivalence. If the input curves are the same, then our method\ndetects the projective symmetries of the input curve. Our method is\nsubstantially faster than methods addressing a similar problem and provides\nsolutions even for the curves with degree up to 24 and coefficients up to 78\ndigits.",
    "descriptor": "",
    "authors": [
      "U\u011fur G\u00f6z\u00fctok",
      "H\u00fcsn\u00fc An\u0131l \u00c7oban",
      "Yasemin Sa\u011f\u0131ro\u011flu"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Computational Geometry (cs.CG)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2110.05436"
  },
  {
    "id": "arXiv:2110.05443",
    "title": "Spatial-temporal V-Net for automatic segmentation and quantification of  right ventricles in gated myocardial perfusion SPECT images",
    "abstract": "Background. Functional assessment of right ventricles (RV) using gated\nmyocardial perfusion single-photon emission computed tomography (MPS) heavily\nrelies on the precise extraction of right ventricular contours. In this paper,\nwe present a new deep learning model integrating both the spatial and temporal\nfeatures in SPECT images to perform the segmentation of RV epicardium and\nendocardium. Methods. By integrating the spatial features from each cardiac\nframe of gated MPS and the temporal features from the sequential cardiac frames\nof the gated MPS, we develop a Spatial-Temporal V-Net (S-T-V-Net) for automatic\nextraction of RV endocardial and epicardial contours. In the S-T-V-Net, a V-Net\nis employed to hierarchically extract spatial features, and convolutional\nlong-term short-term memory (ConvLSTM) units are added to the skip-connection\npathway to extract the temporal features. The input of the S-T-V-Net is an\nECG-gated sequence of the SPECT images and the output is the probability map of\nthe endocardial or epicardial masks. A Dice similarity coefficient (DSC) loss\nwhich penalizes the discrepancy between the model prediction and the ground\ntruth is adopted to optimize the segmentation model. Results. Our segmentation\nmodel was trained and validated on a retrospective dataset with 34 subjects,\nand the cardiac cycle of each subject was divided into 8 gates. The proposed\nST-V-Net achieved a DSC of 0.7924 and 0.8227 for the RV endocardium and\nepicardium, respectively. The mean absolute error, the mean squared error, and\nthe Pearson correlation coefficient of the RV ejection fraction between the\nground truth and the model prediction are 0.0907, 0.0130 and 0.8411.\nConclusion. The results demonstrate that the proposed ST-V-Net is an effective\nmodel for RV segmentation. It has great promise for clinical use in RV\nfunctional assessment.",
    "descriptor": "\nComments: 16 pages, 6 figures\n",
    "authors": [
      "Chen Zhao",
      "Shi Shi",
      "Zhuo He",
      "Cheng Wang",
      "Zhongqiang Zhao",
      "Xinli Li",
      "Yanli Zhou",
      "Weihua Zhou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05443"
  },
  {
    "id": "arXiv:1711.06149",
    "title": "MindID: Person Identification from Brain Waves through Attention-based  Recurrent Neural Network",
    "abstract": "Comments: Published in UbiComp 2018; ACM IMWUT, Vol.2, No. 3, Article No.149, pp 1-23",
    "descriptor": "\nComments: Published in UbiComp 2018; ACM IMWUT, Vol.2, No. 3, Article No.149, pp 1-23\n",
    "authors": [
      "Xiang Zhang",
      "Lina Yao",
      "Salil S. Kanhere",
      "Yunhao Liu",
      "Tao Gu",
      "Kaixuan Chen"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/1711.06149"
  },
  {
    "id": "arXiv:1806.07788",
    "title": "Random Feature Stein Discrepancies",
    "abstract": "Comments: In Proceedings of the 32nd Annual Conference on Neural Information Processing Systems (NeurIPS 2018). Code available at: this https URL",
    "descriptor": "\nComments: In Proceedings of the 32nd Annual Conference on Neural Information Processing Systems (NeurIPS 2018). Code available at: this https URL\n",
    "authors": [
      "Jonathan H. Huggins",
      "Lester Mackey"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1806.07788"
  },
  {
    "id": "arXiv:1810.10982",
    "title": "Fr\u00e9chet Distance Under Translation: Conditional Hardness and an  Algorithm via Offline Dynamic Grid Reachability",
    "abstract": "Comments: Published at TALG",
    "descriptor": "\nComments: Published at TALG\n",
    "authors": [
      "Karl Bringmann",
      "Marvin K\u00fcnnemann",
      "Andr\u00e9 Nusser"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1810.10982"
  },
  {
    "id": "arXiv:1811.00189",
    "title": "Unauthorized AI cannot Recognize Me: Reversible Adversarial Example",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1806.09186",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1806.09186\n",
    "authors": [
      "Jiayang Liu",
      "Weiming Zhang",
      "Kazuto Fukuchi",
      "Youhei Akimoto",
      "Jun Sakuma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1811.00189"
  },
  {
    "id": "arXiv:1811.07806",
    "title": "Pareto Optimization for Subset Selection with Dynamic Cost Constraints",
    "abstract": "Comments: A preliminary version of this article has been presented at the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI 2019)",
    "descriptor": "\nComments: A preliminary version of this article has been presented at the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI 2019)\n",
    "authors": [
      "Vahid Roostapour",
      "Aneta Neumann",
      "Frank Neumann",
      "Tobias Friedrich"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/1811.07806"
  },
  {
    "id": "arXiv:1811.10264",
    "title": "PNS: Population-Guided Novelty Search for Reinforcement Learning in Hard  Exploration Environments",
    "abstract": "Comments: Accepted to IROS 2021",
    "descriptor": "\nComments: Accepted to IROS 2021\n",
    "authors": [
      "Qihao Liu",
      "Yujia Wang",
      "Xiaofeng Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/1811.10264"
  },
  {
    "id": "arXiv:1811.11925",
    "title": "Stochastic Top-$K$ Subset Bandits with Linear Space and Non-Linear  Feedback",
    "abstract": "Comments: 38 pages, 4 figures, 32nd International Conference on Algorithmic Learning Theory",
    "descriptor": "\nComments: 38 pages, 4 figures, 32nd International Conference on Algorithmic Learning Theory\n",
    "authors": [
      "Mridul Agarwal",
      "Vaneet Aggarwal",
      "Christopher J. Quinn",
      "Abhishek K. Umrawal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1811.11925"
  },
  {
    "id": "arXiv:1812.06569",
    "title": "Comparator automata in quantitative verification",
    "abstract": "Comparator automata in quantitative verification",
    "descriptor": "",
    "authors": [
      "Suguman Bansal",
      "Swarat Chaudhuri",
      "Moshe Y. Vardi"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1812.06569"
  },
  {
    "id": "arXiv:1901.08562",
    "title": "Sample Complexity of Estimating the Policy Gradient for Nearly  Deterministic Dynamical Systems",
    "abstract": "Sample Complexity of Estimating the Policy Gradient for Nearly  Deterministic Dynamical Systems",
    "descriptor": "",
    "authors": [
      "Osbert Bastani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1901.08562"
  },
  {
    "id": "arXiv:1901.08568",
    "title": "Algorithms for Fairness in Sequential Decision Making",
    "abstract": "Algorithms for Fairness in Sequential Decision Making",
    "descriptor": "",
    "authors": [
      "Min Wen",
      "Osbert Bastani",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1901.08568"
  },
  {
    "id": "arXiv:1901.08576",
    "title": "Learning Interpretable Models with Causal Guarantees",
    "abstract": "Learning Interpretable Models with Causal Guarantees",
    "descriptor": "",
    "authors": [
      "Carolyn Kim",
      "Osbert Bastani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1901.08576"
  },
  {
    "id": "arXiv:1902.02181",
    "title": "Attention in Natural Language Processing",
    "abstract": "Comments: 18 pages, 8 figures",
    "descriptor": "\nComments: 18 pages, 8 figures\n",
    "authors": [
      "Andrea Galassi",
      "Marco Lippi",
      "Paolo Torroni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1902.02181"
  },
  {
    "id": "arXiv:1905.00531",
    "title": "Recombinator-k-means: An evolutionary algorithm that exploits k-means++  for recombination",
    "abstract": "Comments: 15 pages, 3 figures (1 in main text), 5 tables",
    "descriptor": "\nComments: 15 pages, 3 figures (1 in main text), 5 tables\n",
    "authors": [
      "Carlo Baldassi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1905.00531"
  },
  {
    "id": "arXiv:1906.05173",
    "title": "Multi-local Collaborative AutoEncoder",
    "abstract": "Multi-local Collaborative AutoEncoder",
    "descriptor": "",
    "authors": [
      "Jielei Chu",
      "Hongjun Wang",
      "Jing Liu",
      "Zhiguo Gong",
      "Tianrui Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.05173"
  },
  {
    "id": "arXiv:1908.09422",
    "title": "Feedback linearly extended discrete functions",
    "abstract": "Comments: Accepted on October 4th, 2021 in Journal of Algebra and its Applications (World Scientific Publishing)",
    "descriptor": "\nComments: Accepted on October 4th, 2021 in Journal of Algebra and its Applications (World Scientific Publishing)\n",
    "authors": [
      "Claude Gravel",
      "Daniel Panario"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/1908.09422"
  },
  {
    "id": "arXiv:1909.03580",
    "title": "Extreme Low Resolution Activity Recognition with Confident  Spatial-Temporal Attention Transfer",
    "abstract": "Comments: 12 pages, 9 fugures. 2nd-round review of TIP",
    "descriptor": "\nComments: 12 pages, 9 fugures. 2nd-round review of TIP\n",
    "authors": [
      "Yucai Bai",
      "Qin Zou",
      "Xieyuanli Chen",
      "Lingxi Li",
      "Zhengming Ding",
      "Long Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1909.03580"
  },
  {
    "id": "arXiv:1912.01398",
    "title": "TeaNet: universal neural network interatomic potential inspired by  iterative electronic relaxations",
    "abstract": "Comments: Revision: Add detailed network description",
    "descriptor": "\nComments: Revision: Add detailed network description\n",
    "authors": [
      "So Takamoto",
      "Satoshi Izumi",
      "Ju Li"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1912.01398"
  },
  {
    "id": "arXiv:1912.07168",
    "title": "A Control-Theoretic Perspective on Optimal High-Order Optimization",
    "abstract": "Comments: Accepted by Mathematical Programming Series A; 45 pages",
    "descriptor": "\nComments: Accepted by Mathematical Programming Series A; 45 pages\n",
    "authors": [
      "Tianyi Lin",
      "Michael. I. Jordan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1912.07168"
  },
  {
    "id": "arXiv:1912.12659",
    "title": "Synthesizing Queries via Interactive Sketching",
    "abstract": "Synthesizing Queries via Interactive Sketching",
    "descriptor": "",
    "authors": [
      "Osbert Bastani",
      "Xin Zhang",
      "Armando Solar-Lezama"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/1912.12659"
  },
  {
    "id": "arXiv:2002.07362",
    "title": "MILA: Multi-Task Learning from Videos via Efficient Inter-Frame  Attention",
    "abstract": "Comments: Accepted in ICCV 2021 MTL Workshop",
    "descriptor": "\nComments: Accepted in ICCV 2021 MTL Workshop\n",
    "authors": [
      "Donghyun Kim",
      "Tian Lan",
      "Chuhang Zou",
      "Ning Xu",
      "Bryan A. Plummer",
      "Stan Sclaroff",
      "Jayan Eledath",
      "Gerard Medioni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2002.07362"
  },
  {
    "id": "arXiv:2002.08537",
    "title": "Adaptive Temporal Difference Learning with Linear Function Approximation",
    "abstract": "Adaptive Temporal Difference Learning with Linear Function Approximation",
    "descriptor": "",
    "authors": [
      "Tao Sun",
      "Han Shen",
      "Tianyi Chen",
      "Dongsheng Li"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.08537"
  },
  {
    "id": "arXiv:2002.11664",
    "title": "New Discontinuous Galerkin Algorithms and Analysis for Linear Elasticity  with Symmetric Stress Tensor",
    "abstract": "New Discontinuous Galerkin Algorithms and Analysis for Linear Elasticity  with Symmetric Stress Tensor",
    "descriptor": "",
    "authors": [
      "Qingguo Hong",
      "Jun Hu",
      "Limin Ma",
      "Jinchao Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2002.11664"
  },
  {
    "id": "arXiv:2002.12898",
    "title": "PM2.5-GNN: A Domain Knowledge Enhanced Graph Neural Network For PM2.5  Forecasting",
    "abstract": "Comments: Pre-print version of a ACM SIGSPATIAL 2020 poster [paper](this https URL). The code is available at [Github](this https URL), and the talk is available at [YouTube](this https URL)",
    "descriptor": "\nComments: Pre-print version of a ACM SIGSPATIAL 2020 poster [paper](this https URL). The code is available at [Github](this https URL), and the talk is available at [YouTube](this https URL)\n",
    "authors": [
      "Shuo Wang",
      "Yanran Li",
      "Jiang Zhang",
      "Qingye Meng",
      "Lingwei Meng",
      "Fei Gao"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2002.12898"
  },
  {
    "id": "arXiv:2003.06069",
    "title": "A General Framework for Learning Mean-Field Games",
    "abstract": "Comments: 43 pages, 7 figures. arXiv admin note: substantial text overlap with arXiv:1901.09585",
    "descriptor": "\nComments: 43 pages, 7 figures. arXiv admin note: substantial text overlap with arXiv:1901.09585\n",
    "authors": [
      "Xin Guo",
      "Anran Hu",
      "Renyuan Xu",
      "Junzi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.06069"
  },
  {
    "id": "arXiv:2003.09198",
    "title": "A unified framework for spectral clustering in sparse graphs",
    "abstract": "A unified framework for spectral clustering in sparse graphs",
    "descriptor": "",
    "authors": [
      "Lorenzo Dall'Amico",
      "Romain Couillet",
      "Nicolas Tremblay"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2003.09198"
  },
  {
    "id": "arXiv:2003.09695",
    "title": "POD-Galerkin Model Order Reduction for Parametrized Nonlinear Time  Dependent Optimal Flow Control: an Application to Shallow Water Equations",
    "abstract": "POD-Galerkin Model Order Reduction for Parametrized Nonlinear Time  Dependent Optimal Flow Control: an Application to Shallow Water Equations",
    "descriptor": "",
    "authors": [
      "Maria Strazzullo",
      "Francesco Ballarin",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2003.09695"
  },
  {
    "id": "arXiv:2004.05733",
    "title": "Exponential Upper Bounds for the Runtime of Randomized Search Heuristics",
    "abstract": "Comments: Extended version of a paper that has appeared in the proceedings of PPSN2020",
    "descriptor": "\nComments: Extended version of a paper that has appeared in the proceedings of PPSN2020\n",
    "authors": [
      "Benjamin Doerr"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2004.05733"
  },
  {
    "id": "arXiv:2004.06879",
    "title": "On the Complexity of the Plantinga-Vegter Algorithm",
    "abstract": "Comments: 32 pages, 1 figure. This paper supersedes our earlier conference paper (arXiv:1901.09234). 2nd version: Re-structuring of the paper and correction of typos",
    "descriptor": "\nComments: 32 pages, 1 figure. This paper supersedes our earlier conference paper (arXiv:1901.09234). 2nd version: Re-structuring of the paper and correction of typos\n",
    "authors": [
      "Felipe Cucker",
      "Alperen A. Erg\u00fcr",
      "Josu\u00e9 Tonelli-Cueto"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2004.06879"
  },
  {
    "id": "arXiv:2004.10488",
    "title": "Decentralized Cross-Blockchain Asset Transfers",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Marten Sigwart",
      "Philipp Frauenthaler",
      "Christof Spanring",
      "Michael Sober",
      "Stefan Schulte"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2004.10488"
  },
  {
    "id": "arXiv:2004.11918",
    "title": "Asymptotically Achieving Centralized Rate on the Decentralized Network  MISO Channel",
    "abstract": "Asymptotically Achieving Centralized Rate on the Decentralized Network  MISO Channel",
    "descriptor": "",
    "authors": [
      "Antonio Bazco-Nogueras",
      "Paul de Kerret",
      "David Gesbert",
      "Nicolas Gresset"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2004.11918"
  },
  {
    "id": "arXiv:2004.12427",
    "title": "Cross-Domain Structure Preserving Projection for Heterogeneous Domain  Adaptation",
    "abstract": "Comments: Technical Report",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Qian Wang",
      "Toby P. Breckon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.12427"
  },
  {
    "id": "arXiv:2005.07041",
    "title": "SQuARM-SGD: Communication-Efficient Momentum SGD for Decentralized  Optimization",
    "abstract": "Comments: 58 pages, 8 figures",
    "descriptor": "\nComments: 58 pages, 8 figures\n",
    "authors": [
      "Navjot Singh",
      "Deepesh Data",
      "Jemin George",
      "Suhas Diggavi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.07041"
  },
  {
    "id": "arXiv:2005.07997",
    "title": "Funding Public Projects: A Case for the Nash Product Rule",
    "abstract": "Funding Public Projects: A Case for the Nash Product Rule",
    "descriptor": "",
    "authors": [
      "Florian Brandl",
      "Felix Brandt",
      "Matthias Greger",
      "Dominik Peters",
      "Christian Stricker",
      "Warut Suksompong"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2005.07997"
  },
  {
    "id": "arXiv:2005.13429",
    "title": "Structure Identifiability of an NDS with LFT Parametrized Subsystems",
    "abstract": "Comments: 18 pages",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Tong Zhou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2005.13429"
  },
  {
    "id": "arXiv:2005.13815",
    "title": "Adversarial Classification via Distributional Robustness with  Wasserstein Ambiguity",
    "abstract": "Comments: 32 pages",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Nam Ho-Nguyen",
      "Stephen J. Wright"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.13815"
  },
  {
    "id": "arXiv:2006.01980",
    "title": "On the Equivalence between Online and Private Learnability beyond Binary  Classification",
    "abstract": "Comments: An earlier version of this manuscript claimed an upper bound over the sample complexity that is exponential in the Littlestone dimension. The argument contained a technical mistake, and the current version presents a correction that deteriorates the dependence on the Littlestone dimension from exponential to doubly exponential. arXiv admin note: text overlap with arXiv:2003.00563 by other authors",
    "descriptor": "\nComments: An earlier version of this manuscript claimed an upper bound over the sample complexity that is exponential in the Littlestone dimension. The argument contained a technical mistake, and the current version presents a correction that deteriorates the dependence on the Littlestone dimension from exponential to doubly exponential. arXiv admin note: text overlap with arXiv:2003.00563 by other authors\n",
    "authors": [
      "Young Hun Jung",
      "Baekjin Kim",
      "Ambuj Tewari"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.01980"
  },
  {
    "id": "arXiv:2006.02608",
    "title": "Meta-Model-Based Meta-Policy Optimization",
    "abstract": "Comments: ACML 2021. Video demo: this https URL URL Source code: this https URL",
    "descriptor": "\nComments: ACML 2021. Video demo: this https URL URL Source code: this https URL\n",
    "authors": [
      "Takuya Hiraoka",
      "Takahisa Imagawa",
      "Voot Tangkaratt",
      "Takayuki Osa",
      "Takashi Onishi",
      "Yoshimasa Tsuruoka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.02608"
  },
  {
    "id": "arXiv:2006.05459",
    "title": "Privacy For Free: Wireless Federated Learning Via Uncoded Transmission  With Adaptive Power Control",
    "abstract": "Comments: Published in IEEE Journal on Selected Areas in Communications ( Volume: 39, Issue: 1, Jan. 2021) DOI: 10.1109/JSAC.2020.3036948",
    "descriptor": "\nComments: Published in IEEE Journal on Selected Areas in Communications ( Volume: 39, Issue: 1, Jan. 2021) DOI: 10.1109/JSAC.2020.3036948\n",
    "authors": [
      "Dongzhu Liu",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2006.05459"
  },
  {
    "id": "arXiv:2006.06267",
    "title": "A Generalised Linear Model Framework for $\u03b2$-Variational  Autoencoders based on Exponential Dispersion Families",
    "abstract": "Comments: this https URL",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Robert Sicks",
      "Ralf Korn",
      "Stefanie Schwaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.06267"
  },
  {
    "id": "arXiv:2006.08426",
    "title": "Walking in the Shadow: A New Perspective on Descent Directions for  Constrained Minimization",
    "abstract": "Walking in the Shadow: A New Perspective on Descent Directions for  Constrained Minimization",
    "descriptor": "",
    "authors": [
      "Hassan Mortagy",
      "Swati Gupta",
      "Sebastian Pokutta"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.08426"
  },
  {
    "id": "arXiv:2006.08464",
    "title": "Globally Injective ReLU Networks",
    "abstract": "Comments: 48 pages, 18 figures, submitted to JMLR",
    "descriptor": "\nComments: 48 pages, 18 figures, submitted to JMLR\n",
    "authors": [
      "Michael Puthawala",
      "Konik Kothari",
      "Matti Lassas",
      "Ivan Dokmani\u0107",
      "Maarten de Hoop"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.08464"
  },
  {
    "id": "arXiv:2006.11654",
    "title": "Counterfactually Guided Off-policy Transfer in Clinical Settings",
    "abstract": "Comments: 24 pages (including appendix), 18 figures",
    "descriptor": "\nComments: 24 pages (including appendix), 18 figures\n",
    "authors": [
      "Taylor W. Killian",
      "Marzyeh Ghassemi",
      "Shalmali Joshi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.11654"
  },
  {
    "id": "arXiv:2006.14045",
    "title": "Optimizing Voting Order on Sequential Juries: A Median Voter Theorem and  Beyond",
    "abstract": "Comments: 34 pages and 1 figure",
    "descriptor": "\nComments: 34 pages and 1 figure\n",
    "authors": [
      "Steve Alpern",
      "Bo Chen"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2006.14045"
  },
  {
    "id": "arXiv:2006.15666",
    "title": "Breathing K-Means",
    "abstract": "Comments: 55 pages, 45 figures, Relevant Changes: Algorithm is now better *and* faster than the underlying BKMeans class from scikit-learn. Detailed analysis of parameter m shows that it can be used to balance SSE and CPU time; Parameter theta eliminated. Submitted to JMLR; Implementation: this https URL ; Python package: this https URL",
    "descriptor": "\nComments: 55 pages, 45 figures, Relevant Changes: Algorithm is now better *and* faster than the underlying BKMeans class from scikit-learn. Detailed analysis of parameter m shows that it can be used to balance SSE and CPU time; Parameter theta eliminated. Submitted to JMLR; Implementation: this https URL ; Python package: this https URL\n",
    "authors": [
      "Bernd Fritzke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.15666"
  },
  {
    "id": "arXiv:2007.03812",
    "title": "Robust Multi-Agent Multi-Armed Bandits",
    "abstract": "Robust Multi-Agent Multi-Armed Bandits",
    "descriptor": "",
    "authors": [
      "Daniel Vial",
      "Sanjay Shakkottai",
      "R. Srikant"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.03812"
  },
  {
    "id": "arXiv:2007.07602",
    "title": "Automating the Communication of Cybersecurity Knowledge: Multi-Case  Study",
    "abstract": "Comments: 14 pages, 1 figure, 13th World Conference on Information Security Education",
    "descriptor": "\nComments: 14 pages, 1 figure, 13th World Conference on Information Security Education\n",
    "authors": [
      "Alireza Shojaifar",
      "Samuel A. Fricker",
      "Martin Gwerder"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2007.07602"
  },
  {
    "id": "arXiv:2007.10492",
    "title": "Assessment of COVID-19 hospitalization forecasts from a simplified SIR  model",
    "abstract": "Comments: Paper home page: this https URL",
    "descriptor": "\nComments: Paper home page: this https URL\n",
    "authors": [
      "P.-A. Absil",
      "Ousmane Diao",
      "Mouhamadou Diallo"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2007.10492"
  },
  {
    "id": "arXiv:2007.14110",
    "title": "WaveFuse: A Unified Deep Framework for Image Fusion with Discrete  Wavelet Transform",
    "abstract": "Comments: accepted at The 28th International Conference on Neural Information Processing(ICONIP2021)",
    "descriptor": "\nComments: accepted at The 28th International Conference on Neural Information Processing(ICONIP2021)\n",
    "authors": [
      "Shaolei Liu",
      "Manning Wang",
      "Zhijian Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.14110"
  },
  {
    "id": "arXiv:2007.14268",
    "title": "On the Convergence of Tsetlin Machines for the IDENTITY- and NOT  Operators",
    "abstract": "Comments: 23 pages, 10 figures",
    "descriptor": "\nComments: 23 pages, 10 figures\n",
    "authors": [
      "Xuan Zhang",
      "Lei Jiao",
      "Ole-Christoffer Granmo",
      "Morten Goodwin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.14268"
  },
  {
    "id": "arXiv:2008.11348",
    "title": "Variance-Reduced Splitting Schemes for Monotone Stochastic Generalized  Equations",
    "abstract": "Variance-Reduced Splitting Schemes for Monotone Stochastic Generalized  Equations",
    "descriptor": "",
    "authors": [
      "Shisheng Cui",
      "Uday V. Shanbhag"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.11348"
  },
  {
    "id": "arXiv:2008.13293",
    "title": "Sharp finite-sample concentration of independent variables",
    "abstract": "Sharp finite-sample concentration of independent variables",
    "descriptor": "",
    "authors": [
      "Akshay Balsubramani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.13293"
  },
  {
    "id": "arXiv:2009.01656",
    "title": "An adaptive high-order unfitted finite element method for elliptic  interface problems",
    "abstract": "An adaptive high-order unfitted finite element method for elliptic  interface problems",
    "descriptor": "",
    "authors": [
      "Zhiming Chen",
      "Ke Li",
      "Xueshuang Xiang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2009.01656"
  },
  {
    "id": "arXiv:2009.01974",
    "title": "FedBE: Making Bayesian Model Ensemble Applicable to Federated Learning",
    "abstract": "Comments: Accepted to ICLR 2021; the camera-ready version with code URL",
    "descriptor": "\nComments: Accepted to ICLR 2021; the camera-ready version with code URL\n",
    "authors": [
      "Hong-You Chen",
      "Wei-Lun Chao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.01974"
  },
  {
    "id": "arXiv:2009.02535",
    "title": "A Class of Optimal Structures for Node Computations in Message Passing  Algorithms",
    "abstract": "Comments: Accepted for publication in IEEE Transactions on Information Theory",
    "descriptor": "\nComments: Accepted for publication in IEEE Transactions on Information Theory\n",
    "authors": [
      "Xuan He",
      "Kui Cai",
      "Liang Zhou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2009.02535"
  },
  {
    "id": "arXiv:2009.05753",
    "title": "Decentralized Model-free Loss Minimization in Distribution Grids with  the Use of Inverters",
    "abstract": "Decentralized Model-free Loss Minimization in Distribution Grids with  the Use of Inverters",
    "descriptor": "",
    "authors": [
      "Ilgiz Murzakhanov",
      "Spyros Chatzivasileiadis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2009.05753"
  },
  {
    "id": "arXiv:2009.05986",
    "title": "Oracle-Efficient Regret Minimization in Factored MDPs with Unknown  Structure",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Aviv Rosenberg",
      "Yishay Mansour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.05986"
  },
  {
    "id": "arXiv:2009.07096",
    "title": "Analysis of finite-volume discrete adjoint fields for two-dimensional  compressible Euler flows",
    "abstract": "Analysis of finite-volume discrete adjoint fields for two-dimensional  compressible Euler flows",
    "descriptor": "",
    "authors": [
      "Jacques Peter",
      "Florent Renac",
      "Cl\u00e9ment Labb\u00e9"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2009.07096"
  },
  {
    "id": "arXiv:2009.08058",
    "title": "MultAV: Multiplicative Adversarial Videos",
    "abstract": "Comments: Accepted at IEEE International Conference on Advanced Video and Signal-based Surveillance (AVSS) 2021",
    "descriptor": "\nComments: Accepted at IEEE International Conference on Advanced Video and Signal-based Surveillance (AVSS) 2021\n",
    "authors": [
      "Shao-Yuan Lo",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.08058"
  },
  {
    "id": "arXiv:2009.09590",
    "title": "Generalized Clustering and Multi-Manifold Learning with Geometric  Structure Preservation",
    "abstract": "Generalized Clustering and Multi-Manifold Learning with Geometric  Structure Preservation",
    "descriptor": "",
    "authors": [
      "Lirong Wu",
      "Zicheng Liu",
      "Zelin Zang",
      "Jun Xia",
      "Siyuan Li",
      "Stan. Z Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.09590"
  },
  {
    "id": "arXiv:2009.12231",
    "title": "Low-Complexity High-Performance Cyclic Caching for Large MISO Systems",
    "abstract": "Low-Complexity High-Performance Cyclic Caching for Large MISO Systems",
    "descriptor": "",
    "authors": [
      "MohammadJavad Salehi",
      "Emanuele Parrinello",
      "Seyed Pooya Shariatpanahi",
      "Petros Elia",
      "Antti T\u00f6lli"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2009.12231"
  },
  {
    "id": "arXiv:2010.03855",
    "title": "Dense Relational Image Captioning via Multi-task Triple-Stream Networks",
    "abstract": "Comments: IEEE TPAMI accepted. Journal extension of our CVPR 2019 paper ( arXiv:1903.05942 ). Source code : this https URL",
    "descriptor": "\nComments: IEEE TPAMI accepted. Journal extension of our CVPR 2019 paper ( arXiv:1903.05942 ). Source code : this https URL\n",
    "authors": [
      "Dong-Jin Kim",
      "Tae-Hyun Oh",
      "Jinsoo Choi",
      "In So Kweon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.03855"
  },
  {
    "id": "arXiv:2010.04480",
    "title": "MLQE-PE: A Multilingual Quality Estimation and Post-Editing Dataset",
    "abstract": "MLQE-PE: A Multilingual Quality Estimation and Post-Editing Dataset",
    "descriptor": "",
    "authors": [
      "Marina Fomicheva",
      "Shuo Sun",
      "Erick Fonseca",
      "Chrysoula Zerva",
      "Fr\u00e9d\u00e9ric Blain",
      "Vishrav Chaudhary",
      "Francisco Guzm\u00e1n",
      "Nina Lopatina",
      "Lucia Specia",
      "Andr\u00e9 F. T. Martins"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.04480"
  },
  {
    "id": "arXiv:2010.06791",
    "title": "Generalized Nearest Neighbor Decoding",
    "abstract": "Comments: 30 pages, 8 figures",
    "descriptor": "\nComments: 30 pages, 8 figures\n",
    "authors": [
      "Yizhu Wang",
      "Wenyi Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2010.06791"
  },
  {
    "id": "arXiv:2010.08666",
    "title": "Active Domain Adaptation via Clustering Uncertainty-weighted Embeddings",
    "abstract": "Comments: Published at ICCV 2021. Our code is available at this https URL",
    "descriptor": "\nComments: Published at ICCV 2021. Our code is available at this https URL\n",
    "authors": [
      "Viraj Prabhu",
      "Arjun Chandrasekaran",
      "Kate Saenko",
      "Judy Hoffman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.08666"
  },
  {
    "id": "arXiv:2010.09236",
    "title": "Continual Unsupervised Domain Adaptation for Semantic Segmentation",
    "abstract": "Comments: 13 pages, 5 figures",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "Joonhyuk Kim",
      "Sahng-Min Yoo",
      "Gyeong-Moon Park",
      "Jong-Hwan Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.09236"
  },
  {
    "id": "arXiv:2010.10010",
    "title": "Deterministic Identification Over Fading Channels",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2010.04239",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2010.04239\n",
    "authors": [
      "Mohammad J. Salariseddigh",
      "Uzi Pereg",
      "Holger Boche",
      "Christian Deppe"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2010.10010"
  },
  {
    "id": "arXiv:2010.12184",
    "title": "Towards Fair Knowledge Transfer for Imbalanced Domain Adaptation",
    "abstract": "Towards Fair Knowledge Transfer for Imbalanced Domain Adaptation",
    "descriptor": "",
    "authors": [
      "Taotao Jing",
      "Bingrong Xu",
      "Jingjing Li",
      "Zhengming Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.12184"
  },
  {
    "id": "arXiv:2010.13365",
    "title": "Robustness May Be at Odds with Fairness: An Empirical Study on  Class-wise Accuracy",
    "abstract": "Robustness May Be at Odds with Fairness: An Empirical Study on  Class-wise Accuracy",
    "descriptor": "",
    "authors": [
      "Philipp Benz",
      "Chaoning Zhang",
      "Adil Karjauv",
      "In So Kweon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.13365"
  },
  {
    "id": "arXiv:2010.14672",
    "title": "How Does the Task Landscape Affect MAML Performance?",
    "abstract": "How Does the Task Landscape Affect MAML Performance?",
    "descriptor": "",
    "authors": [
      "Liam Collins",
      "Aryan Mokhtari",
      "Sanjay Shakkottai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.14672"
  },
  {
    "id": "arXiv:2010.15030",
    "title": "Actris 2.0: Asynchronous Session-Type Based Reasoning in Separation  Logic",
    "abstract": "Comments: 60 pages, 24 figures",
    "descriptor": "\nComments: 60 pages, 24 figures\n",
    "authors": [
      "Jonas Kastberg Hinrichsen",
      "Jesper Bengtson",
      "Robbert Krebbers"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2010.15030"
  },
  {
    "id": "arXiv:2011.01516",
    "title": "Quadratic Metric Elicitation for Fairness and Beyond",
    "abstract": "Comments: 40 pages, 9 figures, and 3 tables",
    "descriptor": "\nComments: 40 pages, 9 figures, and 3 tables\n",
    "authors": [
      "Gaurush Hiranandani",
      "Jatin Mathur",
      "Harikrishna Narasimhan",
      "Oluwasanmi Koyejo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.01516"
  },
  {
    "id": "arXiv:2011.03006",
    "title": "Deep-Dup: An Adversarial Weight Duplication Attack Framework to Crush  Deep Neural Network in Multi-Tenant FPGA",
    "abstract": "Deep-Dup: An Adversarial Weight Duplication Attack Framework to Crush  Deep Neural Network in Multi-Tenant FPGA",
    "descriptor": "",
    "authors": [
      "Adnan Siraj Rakin",
      "Yukui Luo",
      "Xiaolin Xu",
      "Deliang Fan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.03006"
  },
  {
    "id": "arXiv:2011.04902",
    "title": "Windowed Backoff Algorithms for WiFi: Theory and Performance under  Batched Arrivals",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:1705.09271",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1705.09271\n",
    "authors": [
      "William C. Anderton",
      "Trisha Chakraborty",
      "Maxwell Young"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2011.04902"
  },
  {
    "id": "arXiv:2011.07221",
    "title": "Deep Interpretable Classification and Weakly-Supervised Segmentation of  Histology Images via Max-Min Uncertainty",
    "abstract": "Comments: 16 pages, 15 figures, under review",
    "descriptor": "\nComments: 16 pages, 15 figures, under review\n",
    "authors": [
      "Soufiane Belharbi",
      "J\u00e9r\u00f4me Rony",
      "Jose Dolz",
      "Ismail Ben Ayed",
      "Luke McCaffrey",
      "Eric Granger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.07221"
  },
  {
    "id": "arXiv:2011.07689",
    "title": "Drone LAMS: A Drone-based Face Detection Dataset with Large Angles and  Many Scenarios",
    "abstract": "Comments: 10 pages, 6 figures,conference or other essential info",
    "descriptor": "\nComments: 10 pages, 6 figures,conference or other essential info\n",
    "authors": [
      "Yi Luo",
      "Siyi Chen",
      "X.-G. Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2011.07689"
  },
  {
    "id": "arXiv:2011.07720",
    "title": "Distributed Bandits: Probabilistic Communication on $d$-regular Graphs",
    "abstract": "Distributed Bandits: Probabilistic Communication on $d$-regular Graphs",
    "descriptor": "",
    "authors": [
      "Udari Madhushani",
      "Naomi Ehrich Leonard"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2011.07720"
  },
  {
    "id": "arXiv:2011.13179",
    "title": "Saliency-based segmentation of dermoscopic images using color  information",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Giuliana Ramella"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.13179"
  },
  {
    "id": "arXiv:2011.13730",
    "title": "Multiple Faults Estimation in Dynamical Systems: Tractable Design and  Performance Bounds",
    "abstract": "Comments: 24 pages, 8 figures",
    "descriptor": "\nComments: 24 pages, 8 figures\n",
    "authors": [
      "Chris van der Ploeg",
      "Mohsen Alirezaei",
      "Nathan van de Wouw",
      "Peyman Mohajerin Esfahani"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2011.13730"
  },
  {
    "id": "arXiv:2011.13752",
    "title": "Adaptive Non-linear Pattern Matching Automata",
    "abstract": "Comments: 31 pages, accepted for FSCD 2020 special issue of LMCS",
    "descriptor": "\nComments: 31 pages, accepted for FSCD 2020 special issue of LMCS\n",
    "authors": [
      "Rick Erkens",
      "Maurice Laveaux"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2011.13752"
  },
  {
    "id": "arXiv:2011.14399",
    "title": "Socioeconomic Impact of Emerging Mobility Markets and Implementation  Strategies",
    "abstract": "Socioeconomic Impact of Emerging Mobility Markets and Implementation  Strategies",
    "descriptor": "",
    "authors": [
      "Ioannis Vasileios Chremos",
      "Andreas A. Malikopoulos"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2011.14399"
  },
  {
    "id": "arXiv:2011.14469",
    "title": "Cyberphysical Security Through Resiliency: A Systems-centric Approach",
    "abstract": "Cyberphysical Security Through Resiliency: A Systems-centric Approach",
    "descriptor": "",
    "authors": [
      "Cody Fleming",
      "Carl Elks",
      "Georgios Bakirtzis",
      "Stephen C. Adams",
      "Bryan Carter",
      "Peter A. Beling",
      "Barry Horowitz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2011.14469"
  },
  {
    "id": "arXiv:2011.14785",
    "title": "S2FGAN: Semantically Aware Interactive Sketch-to-Face Translation",
    "abstract": "S2FGAN: Semantically Aware Interactive Sketch-to-Face Translation",
    "descriptor": "",
    "authors": [
      "Yan Yang",
      "Md Zakir Hossain",
      "Tom Gedeon",
      "Shafin Rahman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.14785"
  },
  {
    "id": "arXiv:2012.00235",
    "title": "Fractal-based Belief Entropy",
    "abstract": "Fractal-based Belief Entropy",
    "descriptor": "",
    "authors": [
      "Qianli Zhou",
      "Yong Deng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2012.00235"
  },
  {
    "id": "arXiv:2012.01382",
    "title": "Analysis of a Decentralised Digital Token Architecture for Public  Transport",
    "abstract": "Comments: 15 pages, 7 figures, 3 tables",
    "descriptor": "\nComments: 15 pages, 7 figures, 3 tables\n",
    "authors": [
      "Oscar King",
      "Geoffrey Goodell"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2012.01382"
  },
  {
    "id": "arXiv:2012.01708",
    "title": "Feature-Based Software Design Pattern Detection",
    "abstract": "Comments: Submitted to the Journal of Systems and Software (JSS)",
    "descriptor": "\nComments: Submitted to the Journal of Systems and Software (JSS)\n",
    "authors": [
      "Najam Nazar",
      "Aldeida Aleti",
      "Yaokun Zheng"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2012.01708"
  },
  {
    "id": "arXiv:2012.01815",
    "title": "SemMT: A Semantic-based Testing Approach for Machine Translation Systems",
    "abstract": "SemMT: A Semantic-based Testing Approach for Machine Translation Systems",
    "descriptor": "",
    "authors": [
      "Jialun Cao",
      "Meiziniu Li",
      "Yeting Li",
      "Ming Wen",
      "Shing-Chi Cheung"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.01815"
  },
  {
    "id": "arXiv:2012.02305",
    "title": "Balanced Reduced-Order Models for Iterative Nonlinear Control of  Large-Scale Systems",
    "abstract": "Balanced Reduced-Order Models for Iterative Nonlinear Control of  Large-Scale Systems",
    "descriptor": "",
    "authors": [
      "Yizhe Huang",
      "Boris Kramer"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2012.02305"
  },
  {
    "id": "arXiv:2012.03174",
    "title": "Counting Substructures with Higher-Order Graph Neural Networks:  Possibility and Impossibility Results",
    "abstract": "Comments: 26 pages, 4 figures",
    "descriptor": "\nComments: 26 pages, 4 figures\n",
    "authors": [
      "Behrooz Tahmasebi",
      "Derek Lim",
      "Stefanie Jegelka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.03174"
  },
  {
    "id": "arXiv:2012.03312",
    "title": "Quantum Dynamics of Optimization Problems",
    "abstract": "Comments: We corrected some errors in the theoretical part of the paper, especially the quantum interpretation part corresponding to the approximation of the objective function. At the same time, we have added some comparative experiments and quantum effect experiments of skeleton algorithms, and hope to publish them in a new paper (arXiv:2106.13927)",
    "descriptor": "\nComments: We corrected some errors in the theoretical part of the paper, especially the quantum interpretation part corresponding to the approximation of the objective function. At the same time, we have added some comparative experiments and quantum effect experiments of skeleton algorithms, and hope to publish them in a new paper (arXiv:2106.13927)\n",
    "authors": [
      "Peng Wang",
      "Gang Xin",
      "Yuwei Jiao"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2012.03312"
  },
  {
    "id": "arXiv:2012.05657",
    "title": "Geometric Adversarial Attacks and Defenses on 3D Point Clouds",
    "abstract": "Comments: 3DV 2021",
    "descriptor": "\nComments: 3DV 2021\n",
    "authors": [
      "Itai Lang",
      "Uriel Kotlicki",
      "Shai Avidan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.05657"
  },
  {
    "id": "arXiv:2012.06475",
    "title": "EventHands: Real-Time Neural 3D Hand Pose Estimation from an Event  Stream",
    "abstract": "Comments: 16 pages, 10 figures, 1 table; project page: this https URL",
    "descriptor": "\nComments: 16 pages, 10 figures, 1 table; project page: this https URL\n",
    "authors": [
      "Viktor Rudnev",
      "Vladislav Golyanik",
      "Jiayi Wang",
      "Hans-Peter Seidel",
      "Franziska Mueller",
      "Mohamed Elgharib",
      "Christian Theobalt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.06475"
  },
  {
    "id": "arXiv:2012.06951",
    "title": "Attentional Biased Stochastic Gradient for Imbalanced Classification",
    "abstract": "Comments: 29pages, 10 figures",
    "descriptor": "\nComments: 29pages, 10 figures\n",
    "authors": [
      "Qi Qi",
      "Yi Xu",
      "Rong Jin",
      "Wotao Yin",
      "Tianbao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.06951"
  },
  {
    "id": "arXiv:2012.09400",
    "title": "Stochastic Compositional Gradient Descent under Compositional  constraints",
    "abstract": "Stochastic Compositional Gradient Descent under Compositional  constraints",
    "descriptor": "",
    "authors": [
      "Srujan Teja Thomdapu",
      "Harshvardhan",
      "Ketan Rajawat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.09400"
  },
  {
    "id": "arXiv:2012.09550",
    "title": "Learned Block-based Hybrid Image Compression",
    "abstract": "Comments: 13 pages, 13 figures, accepted by IEEE Trans. on Circuits and Systems for Video Technology",
    "descriptor": "\nComments: 13 pages, 13 figures, accepted by IEEE Trans. on Circuits and Systems for Video Technology\n",
    "authors": [
      "Yaojun Wu",
      "Xin Li",
      "Zhizheng Zhang",
      "Xin Jin",
      "Zhibo Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.09550"
  },
  {
    "id": "arXiv:2012.11460",
    "title": "SENTRY: Selective Entropy Optimization via Committee Consistency for  Unsupervised Domain Adaptation",
    "abstract": "Comments: Published at ICCV 2021. Code available at this https URL",
    "descriptor": "\nComments: Published at ICCV 2021. Code available at this https URL\n",
    "authors": [
      "Viraj Prabhu",
      "Shivam Khare",
      "Deeksha Kartik",
      "Judy Hoffman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.11460"
  },
  {
    "id": "arXiv:2012.13212",
    "title": "Memory-Efficient Hierarchical Neural Architecture Search for Image  Restoration",
    "abstract": "Comments: 23 pages. Updated experiments and Fixed presentation issues. This is the journal version of arXiv:1909.08228; Code is available at: this https URL",
    "descriptor": "\nComments: 23 pages. Updated experiments and Fixed presentation issues. This is the journal version of arXiv:1909.08228; Code is available at: this https URL\n",
    "authors": [
      "Haokui Zhang",
      "Ying Li",
      "Hao Chen",
      "Chengrong Gong",
      "Zongwen Bai",
      "Chunhua Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.13212"
  },
  {
    "id": "arXiv:2012.13755",
    "title": "Probabilistic 3D Multi-Modal, Multi-Object Tracking for Autonomous  Driving",
    "abstract": "Comments: IEEE International Conference on Robotics and Automation (ICRA) 2021",
    "descriptor": "\nComments: IEEE International Conference on Robotics and Automation (ICRA) 2021\n",
    "authors": [
      "Hsu-kuang Chiu",
      "Jie Li",
      "Rares Ambrus",
      "Jeannette Bohg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2012.13755"
  },
  {
    "id": "arXiv:2012.14406",
    "title": "dalex: Responsible Machine Learning with Interactive Explainability and  Fairness in Python",
    "abstract": "Comments: this https URL",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Hubert Baniecki",
      "Wojciech Kretowicz",
      "Piotr Piatyszek",
      "Jakub Wisniewski",
      "Przemyslaw Biecek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Software Engineering (cs.SE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.14406"
  },
  {
    "id": "arXiv:2012.14580",
    "title": "Synchronization with prescribed transient behavior: Heterogeneous  multi-agent systems under funnel coupling Extended arXiv version",
    "abstract": "Synchronization with prescribed transient behavior: Heterogeneous  multi-agent systems under funnel coupling Extended arXiv version",
    "descriptor": "",
    "authors": [
      "Jin Gyu Lee",
      "Stephan Trenn",
      "Hyungbo Shim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2012.14580"
  },
  {
    "id": "arXiv:2101.02806",
    "title": "Handling Neumann and Robin boundary conditions in a fictitious domain  volume penalization framework",
    "abstract": "Handling Neumann and Robin boundary conditions in a fictitious domain  volume penalization framework",
    "descriptor": "",
    "authors": [
      "Ramakrishnan Thirumalaisamy",
      "Neelesh A. Patankar",
      "Amneet Pal Singh Bhalla"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2101.02806"
  },
  {
    "id": "arXiv:2101.03255",
    "title": "Spending Your Winning Lottery Better After Drawing It",
    "abstract": "Spending Your Winning Lottery Better After Drawing It",
    "descriptor": "",
    "authors": [
      "Ajay Kumar Jaiswal",
      "Haoyu Ma",
      "Tianlong Chen",
      "Ying Ding",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.03255"
  },
  {
    "id": "arXiv:2101.03603",
    "title": "Target Detection and Segmentation in Circular-Scan  Synthetic-Aperture-Sonar Images using Semi-Supervised Convolutional  Encoder-Decoders",
    "abstract": "Comments: Submitted to IEEE Journal of Oceanic Engineering",
    "descriptor": "\nComments: Submitted to IEEE Journal of Oceanic Engineering\n",
    "authors": [
      "Isaac J. Sledge",
      "Matthew S. Emigh",
      "Jonathan L. King",
      "Denton L. Woods",
      "J. Tory Cobb",
      "Jose C. Principe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.03603"
  },
  {
    "id": "arXiv:2101.05917",
    "title": "DiffPD: Differentiable Projective Dynamics",
    "abstract": "Comments: ACM Transactions on Graphics, 2021. Code: this https URL",
    "descriptor": "\nComments: ACM Transactions on Graphics, 2021. Code: this https URL\n",
    "authors": [
      "Tao Du",
      "Kui Wu",
      "Pingchuan Ma",
      "Sebastien Wah",
      "Andrew Spielberg",
      "Daniela Rus",
      "Wojciech Matusik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2101.05917"
  },
  {
    "id": "arXiv:2101.06757",
    "title": "Higher Order Automatic Differentiation of Higher Order Functions",
    "abstract": "Comments: 34 pages, 5 figures, submitted at LMCS 2020. arXiv admin note: substantial text overlap with arXiv:2001.02209",
    "descriptor": "\nComments: 34 pages, 5 figures, submitted at LMCS 2020. arXiv admin note: substantial text overlap with arXiv:2001.02209\n",
    "authors": [
      "Mathieu Huot",
      "Sam Staton",
      "Matthijs V\u00e1k\u00e1r"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2101.06757"
  },
  {
    "id": "arXiv:2101.09744",
    "title": "Classic versus deep learning approaches to address computer vision  challenges",
    "abstract": "Classic versus deep learning approaches to address computer vision  challenges",
    "descriptor": "",
    "authors": [
      "Nati Ofir",
      "Jean-Christophe Nebel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.09744"
  },
  {
    "id": "arXiv:2101.10502",
    "title": "Model-agnostic interpretation by visualization of feature perturbations",
    "abstract": "Model-agnostic interpretation by visualization of feature perturbations",
    "descriptor": "",
    "authors": [
      "Wilson E. Marc\u00edlio-Jr",
      "Danilo M. Eler",
      "Fabr\u00edcio Breve"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.10502"
  },
  {
    "id": "arXiv:2101.12578",
    "title": "Adjusting for Autocorrelated Errors in Neural Networks for Time Series",
    "abstract": "Adjusting for Autocorrelated Errors in Neural Networks for Time Series",
    "descriptor": "",
    "authors": [
      "Fan-Keng Sun",
      "Christopher I. Lang",
      "Duane S. Boning"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2101.12578"
  },
  {
    "id": "arXiv:2102.05449",
    "title": "Adaptive Processor Frequency Adjustment for Mobile Edge Computing with  Intermittent Energy Supply",
    "abstract": "Adaptive Processor Frequency Adjustment for Mobile Edge Computing with  Intermittent Energy Supply",
    "descriptor": "",
    "authors": [
      "Tiansheng Huang",
      "Weiwei Lin",
      "Xiaobin Hong",
      "Xiumin Wang",
      "Qingbo Wu",
      "Rui Li",
      "Ching-Hsien Hsu",
      "Albert Y. Zomaya"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.05449"
  },
  {
    "id": "arXiv:2102.06288",
    "title": "K-Hairstyle: A Large-scale Korean Hairstyle Dataset for Virtual Hair  Editing and Hairstyle Classification",
    "abstract": "Comments: ICIP 2021 final version",
    "descriptor": "\nComments: ICIP 2021 final version\n",
    "authors": [
      "Taewoo Kim",
      "Chaeyeon Chung",
      "Sunghyun Park",
      "Gyojung Gu",
      "Keonmin Nam",
      "Wonzo Choe",
      "Jaesung Lee",
      "Jaegul Choo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.06288"
  },
  {
    "id": "arXiv:2102.06362",
    "title": "A Decentralized Approach Towards Responsible AI in Social Ecosystems",
    "abstract": "A Decentralized Approach Towards Responsible AI in Social Ecosystems",
    "descriptor": "",
    "authors": [
      "Wenjing Chu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2102.06362"
  },
  {
    "id": "arXiv:2102.07007",
    "title": "Bridging Graph Neural Networks and Statistical Relational Learning:  Relational One-Class GCN",
    "abstract": "Comments: 25 pages, 14 figures",
    "descriptor": "\nComments: 25 pages, 14 figures\n",
    "authors": [
      "Devendra Singh Dhami",
      "Siwen Yan",
      "Sriraam Natarajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.07007"
  },
  {
    "id": "arXiv:2102.07835",
    "title": "Topological Graph Neural Networks",
    "abstract": "Topological Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Max Horn",
      "Edward De Brouwer",
      "Michael Moor",
      "Yves Moreau",
      "Bastian Rieck",
      "Karsten Borgwardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.07835"
  },
  {
    "id": "arXiv:2102.07976",
    "title": "A General Descent Aggregation Framework for Gradient-based Bi-level  Optimization",
    "abstract": "Comments: 18 pages",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Risheng Liu",
      "Pan Mu",
      "Xiaoming Yuan",
      "Shangzhi Zeng",
      "Jin Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2102.07976"
  },
  {
    "id": "arXiv:2102.08323",
    "title": "AdEle: An Adaptive Congestion-and-Energy-Aware Elevator Selection for  Partially Connected 3D NoCs",
    "abstract": "Comments: This paper will be published in Proc. IEEE/ACM Design Automation Conference (DAC) 2021",
    "descriptor": "\nComments: This paper will be published in Proc. IEEE/ACM Design Automation Conference (DAC) 2021\n",
    "authors": [
      "Ebadollah Taheri",
      "Ryan G. Kim",
      "Mahdi Nikdast"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Hardware Architecture (cs.AR)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2102.08323"
  },
  {
    "id": "arXiv:2102.08649",
    "title": "A General Framework for the Disintegration of PAC-Bayesian Bounds",
    "abstract": "A General Framework for the Disintegration of PAC-Bayesian Bounds",
    "descriptor": "",
    "authors": [
      "Paul Viallard",
      "Pascal Germain",
      "Amaury Habrard",
      "Emilie Morvant"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.08649"
  },
  {
    "id": "arXiv:2102.09743",
    "title": "Personalized Federated Learning: A Unified Framework and Universal  Optimization Techniques",
    "abstract": "Comments: 65 pages, 5 figures",
    "descriptor": "\nComments: 65 pages, 5 figures\n",
    "authors": [
      "Filip Hanzely",
      "Boxin Zhao",
      "Mladen Kolar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.09743"
  },
  {
    "id": "arXiv:2102.10085",
    "title": "Output-Weighted Sampling for Multi-Armed Bandits with Extreme Payoffs",
    "abstract": "Comments: 14 pages, 5 figures, 1 table",
    "descriptor": "\nComments: 14 pages, 5 figures, 1 table\n",
    "authors": [
      "Yibo Yang",
      "Antoine Blanchard",
      "Themistoklis Sapsis",
      "Paris Perdikaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.10085"
  },
  {
    "id": "arXiv:2102.10297",
    "title": "A novel spectral method for the semi-classical Schr\u00f6dinger equation  based on the Gaussian wave-packet transform",
    "abstract": "Comments: A revised version. An appendix is added to establish estimate (3.15) and (3.20)",
    "descriptor": "\nComments: A revised version. An appendix is added to establish estimate (3.15) and (3.20)\n",
    "authors": [
      "Borui Miao",
      "Giovanni Russo",
      "Zhennan Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2102.10297"
  },
  {
    "id": "arXiv:2102.10517",
    "title": "Multivariable Function for New Complete Complementary Codes With  Arbitrary Lengths",
    "abstract": "Multivariable Function for New Complete Complementary Codes With  Arbitrary Lengths",
    "descriptor": "",
    "authors": [
      "Palash Sarkar",
      "Zilong Liu",
      "Sudhan Majhi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2102.10517"
  },
  {
    "id": "arXiv:2102.12926",
    "title": "Persistent Homology and Graphs Representation Learning",
    "abstract": "Persistent Homology and Graphs Representation Learning",
    "descriptor": "",
    "authors": [
      "Mustafa Hajij",
      "Ghada Zamzmi",
      "Xuanting Cai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Geometry (cs.CG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2102.12926"
  },
  {
    "id": "arXiv:2103.00167",
    "title": "Inferring Unobserved Events in Systems With Shared Resources and Queues",
    "abstract": "Comments: Minor revision of submission to Fundamenta Informatica",
    "descriptor": "\nComments: Minor revision of submission to Fundamenta Informatica\n",
    "authors": [
      "Dirk Fahland",
      "Vadim Denisov",
      "Wil. M.P. van der Aalst"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2103.00167"
  },
  {
    "id": "arXiv:2103.01447",
    "title": "ZeroSARAH: Efficient Nonconvex Finite-Sum Optimization with Zero Full  Gradient Computation",
    "abstract": "Comments: 28 pages",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Zhize Li",
      "Slavom\u00edr Hanzely",
      "Peter Richt\u00e1rik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2103.01447"
  },
  {
    "id": "arXiv:2103.02588",
    "title": "IH-GAN: A Conditional Generative Model for Implicit Surface-Based  Inverse Design of Cellular Structures",
    "abstract": "IH-GAN: A Conditional Generative Model for Implicit Surface-Based  Inverse Design of Cellular Structures",
    "descriptor": "",
    "authors": [
      "Jun Wang",
      "Chen",
      "Daicong Da",
      "Mark Fuge",
      "Rahul Rai"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.02588"
  },
  {
    "id": "arXiv:2103.02835",
    "title": "A Novel Application of Image-to-Image Translation: Chromosome  Straightening Framework by Learning from a Single Image",
    "abstract": "A Novel Application of Image-to-Image Translation: Chromosome  Straightening Framework by Learning from a Single Image",
    "descriptor": "",
    "authors": [
      "Sifan Song",
      "Daiyun Huang",
      "Yalun Hu",
      "Chunxiao Yang",
      "Jia Meng",
      "Fei Ma",
      "Frans Coenen",
      "Jiaming Zhang",
      "Jionglong Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.02835"
  },
  {
    "id": "arXiv:2103.04192",
    "title": "High Perceptual Quality Image Denoising with a Posterior Sampling CGAN",
    "abstract": "High Perceptual Quality Image Denoising with a Posterior Sampling CGAN",
    "descriptor": "",
    "authors": [
      "Guy Ohayon",
      "Theo Adrai",
      "Gregory Vaksman",
      "Michael Elad",
      "Peyman Milanfar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2103.04192"
  },
  {
    "id": "arXiv:2103.04304",
    "title": "Fair-Share Allocations for Agents with Arbitrary Entitlements",
    "abstract": "Fair-Share Allocations for Agents with Arbitrary Entitlements",
    "descriptor": "",
    "authors": [
      "Moshe Babaioff",
      "Tomer Ezra",
      "Uriel Feige"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2103.04304"
  },
  {
    "id": "arXiv:2103.04541",
    "title": "A Reinforcement Learning Based R-Tree for Spatial Data Indexing in  Dynamic Environments",
    "abstract": "A Reinforcement Learning Based R-Tree for Spatial Data Indexing in  Dynamic Environments",
    "descriptor": "",
    "authors": [
      "Tu Gu",
      "Kaiyu Feng",
      "Gao Cong",
      "Cheng Long",
      "Zheng Wang",
      "Sheng Wang"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.04541"
  },
  {
    "id": "arXiv:2103.04807",
    "title": "PyRCN: A Toolbox for Exploration and Application of Reservoir Computing  Networks",
    "abstract": "Comments: Preprint submitted to Engineering Applications of Artificial Intelligence",
    "descriptor": "\nComments: Preprint submitted to Engineering Applications of Artificial Intelligence\n",
    "authors": [
      "Peter Steiner",
      "Azarakhsh Jalalvand",
      "Simon Stone",
      "Peter Birkholz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.04807"
  },
  {
    "id": "arXiv:2103.05456",
    "title": "Extended Tree Search for Robot Task and Motion Planning",
    "abstract": "Extended Tree Search for Robot Task and Motion Planning",
    "descriptor": "",
    "authors": [
      "Tianyu Ren",
      "Georgia Chalvatzaki",
      "Jan Peters"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.05456"
  },
  {
    "id": "arXiv:2103.06535",
    "title": "Calibrated and Partially Calibrated Semi-Generalized Homographies",
    "abstract": "Comments: Accepted to ICCV 2021 and to appear in the conference proceedings",
    "descriptor": "\nComments: Accepted to ICCV 2021 and to appear in the conference proceedings\n",
    "authors": [
      "Snehal Bhayani",
      "Torsten Sattler",
      "Daniel Barath",
      "Patrik Beliansky",
      "Janne Heikkila",
      "Zuzana Kukelova"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.06535"
  },
  {
    "id": "arXiv:2103.07601",
    "title": "Approximating How Single Head Attention Learns",
    "abstract": "Approximating How Single Head Attention Learns",
    "descriptor": "",
    "authors": [
      "Charlie Snell",
      "Ruiqi Zhong",
      "Dan Klein",
      "Jacob Steinhardt"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.07601"
  },
  {
    "id": "arXiv:2103.07655",
    "title": "Lightweight Selective Disclosure for Verifiable Documents on Blockchain",
    "abstract": "Comments: 10 pages, 4 figures, 1 table",
    "descriptor": "\nComments: 10 pages, 4 figures, 1 table\n",
    "authors": [
      "Kenji Saito",
      "Satoki Watanabe"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2103.07655"
  },
  {
    "id": "arXiv:2103.07945",
    "title": "Learning One Representation to Optimize All Rewards",
    "abstract": "Learning One Representation to Optimize All Rewards",
    "descriptor": "",
    "authors": [
      "Ahmed Touati",
      "Yann Ollivier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2103.07945"
  },
  {
    "id": "arXiv:2103.08698",
    "title": "Approximation metatheorems for classes with bounded expansion",
    "abstract": "Comments: 35 pages, no figures; revised the presentation",
    "descriptor": "\nComments: 35 pages, no figures; revised the presentation\n",
    "authors": [
      "Zden\u011bk Dvo\u0159\u00e1k"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2103.08698"
  },
  {
    "id": "arXiv:2103.10189",
    "title": "Learning to Amend Facial Expression Representation via De-albino and  Affinity",
    "abstract": "Learning to Amend Facial Expression Representation via De-albino and  Affinity",
    "descriptor": "",
    "authors": [
      "Jiawei Shi",
      "Songhao Zhu",
      "Zhiwei Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.10189"
  },
  {
    "id": "arXiv:2103.10237",
    "title": "Condenser capacity and hyperbolic perimeter",
    "abstract": "Comments: 35 pages, 19 figures",
    "descriptor": "\nComments: 35 pages, 19 figures\n",
    "authors": [
      "Mohamed M. S. Nasser",
      "Oona Rainio",
      "Matti Vuorinen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.10237"
  },
  {
    "id": "arXiv:2103.10504",
    "title": "UNETR: Transformers for 3D Medical Image Segmentation",
    "abstract": "Comments: Accepted to IEEE Winter Conference on Applications of Computer Vision (WACV) 2022",
    "descriptor": "\nComments: Accepted to IEEE Winter Conference on Applications of Computer Vision (WACV) 2022\n",
    "authors": [
      "Ali Hatamizadeh",
      "Yucheng Tang",
      "Vishwesh Nath",
      "Dong Yang",
      "Andriy Myronenko",
      "Bennett Landman",
      "Holger Roth",
      "Daguang Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.10504"
  },
  {
    "id": "arXiv:2103.11517",
    "title": "Dual Monte Carlo Tree Search",
    "abstract": "Comments: 8 pages, 4 figures",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Prashank Kadam",
      "Ruiyang Xu",
      "Karl Lieberherr"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2103.11517"
  },
  {
    "id": "arXiv:2103.12019",
    "title": "Statistically-Robust Clustering Techniques for Mapping Spatial Hotspots:  A Survey",
    "abstract": "Comments: 39 pages, 5 figures, accepted by ACM Computing Surveys (CSUR)",
    "descriptor": "\nComments: 39 pages, 5 figures, accepted by ACM Computing Surveys (CSUR)\n",
    "authors": [
      "Yiqun Xie",
      "Shashi Shekhar",
      "Yan Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2103.12019"
  },
  {
    "id": "arXiv:2103.12608",
    "title": "DIG: A Turnkey Library for Diving into Graph Deep Learning Research",
    "abstract": "Comments: Accepted by Journal of Machine Learning Research (JMLR)",
    "descriptor": "\nComments: Accepted by Journal of Machine Learning Research (JMLR)\n",
    "authors": [
      "Meng Liu",
      "Youzhi Luo",
      "Limei Wang",
      "Yaochen Xie",
      "Hao Yuan",
      "Shurui Gui",
      "Haiyang Yu",
      "Zhao Xu",
      "Jingtun Zhang",
      "Yi Liu",
      "Keqiang Yan",
      "Haoran Liu",
      "Cong Fu",
      "Bora Oztekin",
      "Xuan Zhang",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.12608"
  },
  {
    "id": "arXiv:2103.12715",
    "title": "Promoting Fairness through Hyperparameter Optimization",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2010.03665",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2010.03665\n",
    "authors": [
      "Andr\u00e9 F. Cruz",
      "Pedro Saleiro",
      "Catarina Bel\u00e9m",
      "Carlos Soares",
      "Pedro Bizarro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.12715"
  },
  {
    "id": "arXiv:2103.14278",
    "title": "Boundary Control of Traffic Congestion Modeled as a Non-stationary  Stochastic Process",
    "abstract": "Boundary Control of Traffic Congestion Modeled as a Non-stationary  Stochastic Process",
    "descriptor": "",
    "authors": [
      "Xun Liu",
      "Hossein Rastgoftar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.14278"
  },
  {
    "id": "arXiv:2103.14675",
    "title": "Synthesis of Compositional Animations from Textual Descriptions",
    "abstract": "Comments: 13 pages, 6 figures, 3 tables. Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021, pp. 1396-1406",
    "descriptor": "\nComments: 13 pages, 6 figures, 3 tables. Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021, pp. 1396-1406\n",
    "authors": [
      "Anindita Ghosh",
      "Noshaba Cheema",
      "Cennet Oguz",
      "Christian Theobalt",
      "Philipp Slusallek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.14675"
  },
  {
    "id": "arXiv:2103.14686",
    "title": "Generalization capabilities of translationally equivariant neural  networks",
    "abstract": "Comments: 28 pages, 20 figures, v3: equivalent to the version published in PRD",
    "descriptor": "\nComments: 28 pages, 20 figures, v3: equivalent to the version published in PRD\n",
    "authors": [
      "Srinath Bulusu",
      "Matteo Favoni",
      "Andreas Ipp",
      "David I. M\u00fcller",
      "Daniel Schuh"
    ],
    "subjectives": [
      "High Energy Physics - Lattice (hep-lat)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.14686"
  },
  {
    "id": "arXiv:2103.14804",
    "title": "LSTM Based Sentiment Analysis for Cryptocurrency Prediction",
    "abstract": "LSTM Based Sentiment Analysis for Cryptocurrency Prediction",
    "descriptor": "",
    "authors": [
      "Xin Huang",
      "Wenbin Zhang",
      "Xuejiao Tang",
      "Mingli Zhang",
      "Jayachander Surbiryala",
      "Vasileios Iosifidis",
      "Zhen Liu",
      "Ji Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.14804"
  },
  {
    "id": "arXiv:2103.15432",
    "title": "Towards High Fidelity Monocular Face Reconstruction with Rich  Reflectance using Self-supervised Learning and Ray Tracing",
    "abstract": "Comments: International Conference on Computer Vision (ICCV 2021)",
    "descriptor": "\nComments: International Conference on Computer Vision (ICCV 2021)\n",
    "authors": [
      "Abdallah Dib",
      "Cedric Thebault",
      "Junghyun Ahn",
      "Philippe-Henri Gosselin",
      "Christian Theobalt",
      "Louis Chevallier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.15432"
  },
  {
    "id": "arXiv:2103.15604",
    "title": "Higher Order Convergent Control Barrier Functions for Leader-Follower  Multi-Agent Systems under STL Tasks",
    "abstract": "Higher Order Convergent Control Barrier Functions for Leader-Follower  Multi-Agent Systems under STL Tasks",
    "descriptor": "",
    "authors": [
      "Maryam Sharifi",
      "Dimos V.Dimarogonas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.15604"
  },
  {
    "id": "arXiv:2104.00818",
    "title": "Deep Learning-based Codebook Design for Code-domain Non-Orthogonal  Multiple Access Approaching Single-User Bit Error Rate Performance",
    "abstract": "Deep Learning-based Codebook Design for Code-domain Non-Orthogonal  Multiple Access Approaching Single-User Bit Error Rate Performance",
    "descriptor": "",
    "authors": [
      "Minsig Han",
      "Hanchang Seo",
      "Ameha Tsegaye Abebe",
      "Chung G. Kang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.00818"
  },
  {
    "id": "arXiv:2104.00931",
    "title": "Assem-VC: Realistic Voice Conversion by Assembling Modern Speech  Synthesis Techniques",
    "abstract": "Assem-VC: Realistic Voice Conversion by Assembling Modern Speech  Synthesis Techniques",
    "descriptor": "",
    "authors": [
      "Kang-wook Kim",
      "Seung-won Park",
      "Junhyeok Lee",
      "Myun-chul Joe"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2104.00931"
  },
  {
    "id": "arXiv:2104.01320",
    "title": "An Empirical Study on Channel Effects for Synthetic Voice Spoofing  Countermeasure Systems",
    "abstract": "Comments: 5 pages, 6 figures, in Proc. INTERSPEECH 2021",
    "descriptor": "\nComments: 5 pages, 6 figures, in Proc. INTERSPEECH 2021\n",
    "authors": [
      "You Zhang",
      "Ge Zhu",
      "Fei Jiang",
      "Zhiyao Duan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2104.01320"
  },
  {
    "id": "arXiv:2104.01769",
    "title": "Procrustean Training for Imbalanced Deep Learning",
    "abstract": "Comments: Accepted to ICCV 2021",
    "descriptor": "\nComments: Accepted to ICCV 2021\n",
    "authors": [
      "Han-Jia Ye",
      "De-Chuan Zhan",
      "Wei-Lun Chao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.01769"
  },
  {
    "id": "arXiv:2104.02012",
    "title": "Graph Neural Networks Based Detection of Stealth False Data Injection  Attacks in Smart Grids",
    "abstract": "Comments: 12 pages, 10 figures, journal",
    "descriptor": "\nComments: 12 pages, 10 figures, journal\n",
    "authors": [
      "Osman Boyaci",
      "Amarachi Umunnakwe",
      "Abhijeet Sahu",
      "Mohammad Rasoul Narimani",
      "Muhammad Ismail",
      "Katherine Davis",
      "Erchin Serpedin"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.02012"
  },
  {
    "id": "arXiv:2104.02429",
    "title": "Fine-Grained Fashion Similarity Prediction by Attribute-Specific  Embedding Learning",
    "abstract": "Comments: Conference paper: arXiv:2002.02814",
    "descriptor": "\nComments: Conference paper: arXiv:2002.02814\n",
    "authors": [
      "Jianfeng Dong",
      "Zhe Ma",
      "Xiaofeng Mao",
      "Xun Yang",
      "Yuan He",
      "Richang Hong",
      "Shouling Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2104.02429"
  },
  {
    "id": "arXiv:2104.03664",
    "title": "Distributed Resource Management in Downlink Cache-Enabled Multi-Cloud  Radio Access Networks",
    "abstract": "Comments: 36 pages, 11 figures; rewritten most sections, typos corrected, references added, added new subsection to results and numerical simulations. A version of this work is due to be submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: 36 pages, 11 figures; rewritten most sections, typos corrected, references added, added new subsection to results and numerical simulations. A version of this work is due to be submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Robert-Jeron Reifert",
      "Alaa Alameer Ahmad",
      "Hayssam Dahrouj",
      "Anas Chaaban",
      "Aydin Sezgin",
      "Tareq Y. Al-Naffouri",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2104.03664"
  },
  {
    "id": "arXiv:2104.03953",
    "title": "SNARF: Differentiable Forward Skinning for Animating Non-Rigid Neural  Implicit Shapes",
    "abstract": "Comments: project page: this https URL",
    "descriptor": "\nComments: project page: this https URL\n",
    "authors": [
      "Xu Chen",
      "Yufeng Zheng",
      "Michael J. Black",
      "Otmar Hilliges",
      "Andreas Geiger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.03953"
  },
  {
    "id": "arXiv:2104.06378",
    "title": "QA-GNN: Reasoning with Language Models and Knowledge Graphs for Question  Answering",
    "abstract": "Comments: NAACL 2021. Code & data available at this https URL",
    "descriptor": "\nComments: NAACL 2021. Code & data available at this https URL\n",
    "authors": [
      "Michihiro Yasunaga",
      "Hongyu Ren",
      "Antoine Bosselut",
      "Percy Liang",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.06378"
  },
  {
    "id": "arXiv:2104.07302",
    "title": "TransferNet: An Effective and Transparent Framework for Multi-hop  Question Answering over Relation Graph",
    "abstract": "Comments: EMNLP 2021",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Jiaxin Shi",
      "Shulin Cao",
      "Lei Hou",
      "Juanzi Li",
      "Hanwang Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.07302"
  },
  {
    "id": "arXiv:2104.07986",
    "title": "Learning to Reconstruct 3D Non-Cuboid Room Layout from a Single RGB  Image",
    "abstract": "Comments: To appear in WACV 2022. The first two author contribute equally. Code is available at this https URL",
    "descriptor": "\nComments: To appear in WACV 2022. The first two author contribute equally. Code is available at this https URL\n",
    "authors": [
      "Cheng Yang",
      "Jia Zheng",
      "Xili Dai",
      "Rui Tang",
      "Yi Ma",
      "Xiaojun Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.07986"
  },
  {
    "id": "arXiv:2104.08200",
    "title": "IndoNLG: Benchmark and Resources for Evaluating Indonesian Natural  Language Generation",
    "abstract": "Comments: Accepted in EMNLP 2021, 10 pages",
    "descriptor": "\nComments: Accepted in EMNLP 2021, 10 pages\n",
    "authors": [
      "Samuel Cahyawijaya",
      "Genta Indra Winata",
      "Bryan Wilie",
      "Karissa Vincentio",
      "Xiaohong Li",
      "Adhiguna Kuncoro",
      "Sebastian Ruder",
      "Zhi Yuan Lim",
      "Syafri Bahar",
      "Masayu Leylia Khodra",
      "Ayu Purwarianti",
      "Pascale Fung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08200"
  },
  {
    "id": "arXiv:2104.08541",
    "title": "TransVG: End-to-End Visual Grounding with Transformers",
    "abstract": "Comments: This paper has been accepted by ICCV2021",
    "descriptor": "\nComments: This paper has been accepted by ICCV2021\n",
    "authors": [
      "Jiajun Deng",
      "Zhengyuan Yang",
      "Tianlang Chen",
      "Wengang Zhou",
      "Houqiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.08541"
  },
  {
    "id": "arXiv:2104.08808",
    "title": "Learn Continually, Generalize Rapidly: Lifelong Knowledge Accumulation  for Few-shot Learning",
    "abstract": "Comments: Camera ready; Accepted at Findings of EMNLP 2021",
    "descriptor": "\nComments: Camera ready; Accepted at Findings of EMNLP 2021\n",
    "authors": [
      "Xisen Jin",
      "Bill Yuchen Lin",
      "Mohammad Rostami",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08808"
  },
  {
    "id": "arXiv:2104.08869",
    "title": "Ranking Structured Objects with Graph Neural Networks",
    "abstract": "Ranking Structured Objects with Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Clemens Damke",
      "Eyke H\u00fcllermeier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.08869"
  },
  {
    "id": "arXiv:2104.09114",
    "title": "Regularity for quasilinear vectorial elliptic systems through an  iterative scheme with numerical applications",
    "abstract": "Comments: Improved presentation and examples",
    "descriptor": "\nComments: Improved presentation and examples\n",
    "authors": [
      "Lukas Koch"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2104.09114"
  },
  {
    "id": "arXiv:2104.09864",
    "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding",
    "abstract": "Comments: more experiments",
    "descriptor": "\nComments: more experiments\n",
    "authors": [
      "Jianlin Su",
      "Yu Lu",
      "Shengfeng Pan",
      "Bo Wen",
      "Yunfeng Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.09864"
  },
  {
    "id": "arXiv:2104.10576",
    "title": "How to Identify and Authenticate Users in Massive Unsourced Random  Access",
    "abstract": "How to Identify and Authenticate Users in Massive Unsourced Random  Access",
    "descriptor": "",
    "authors": [
      "Rados\u0142aw Kotaba",
      "Anders E. Kal\u00f8r",
      "Petar Popovski",
      "Israel Leyva-Mayorga",
      "Beatriz Soret",
      "Maxime Guillaud",
      "Luis G. Ord\u00f3\u00f1ez"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2104.10576"
  },
  {
    "id": "arXiv:2104.11846",
    "title": "Joint Detection and Localization of Stealth False Data Injection Attacks  in Smart Grids using Graph Neural Networks",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Osman Boyaci",
      "Mohammad Rasoul Narimani",
      "Katherine Davis",
      "Muhammad Ismail",
      "Thomas J Overbye",
      "Erchin Serpedin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2104.11846"
  },
  {
    "id": "arXiv:2104.12182",
    "title": "Comparing Hand Gestures and a Gamepad Interface for Locomotion in  Virtual Environments",
    "abstract": "Comments: This manuscript has been submitted to a journal for publication consideration",
    "descriptor": "\nComments: This manuscript has been submitted to a journal for publication consideration\n",
    "authors": [
      "Jingbo Zhao",
      "Ruize An",
      "Ruolin Xu",
      "Banghao Lin"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2104.12182"
  },
  {
    "id": "arXiv:2104.12227",
    "title": "Identifying Offensive Expressions of Opinion in Context",
    "abstract": "Comments: This is an old version",
    "descriptor": "\nComments: This is an old version\n",
    "authors": [
      "Francielle Alves Vargas",
      "Isabelle Carvalho",
      "Fabiana Rodrigues de G\u00f3es"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.12227"
  },
  {
    "id": "arXiv:2104.12265",
    "title": "Contextual Lexicon-Based Approach for Hate Speech and Offensive Language  Detection",
    "abstract": "Comments: This is an old version",
    "descriptor": "\nComments: This is an old version\n",
    "authors": [
      "Francielle Alves Vargas",
      "Fabiana Rodrigues de G\u00f3es",
      "Isabelle Carvalho",
      "Fabr\u00edcio Benevenuto",
      "Thiago Alexandre Salgueiro Pardo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.12265"
  },
  {
    "id": "arXiv:2104.12657",
    "title": "tsrobprep - an R package for robust preprocessing of time series data",
    "abstract": "tsrobprep - an R package for robust preprocessing of time series data",
    "descriptor": "",
    "authors": [
      "Micha\u0142 Narajewski",
      "Jens Kley-Holsteg",
      "Florian Ziel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Mathematical Software (cs.MS)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2104.12657"
  },
  {
    "id": "arXiv:2104.12926",
    "title": "Neuromimetic Control -- A Linear Model Paradigm",
    "abstract": "Comments: 14 pages with 3 figures",
    "descriptor": "\nComments: 14 pages with 3 figures\n",
    "authors": [
      "John Baillieul",
      "Zexin Sun"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.12926"
  },
  {
    "id": "arXiv:2104.12986",
    "title": "Bringing Trimmed Serendipity Methods to Computational Practice in  Firedrake",
    "abstract": "Comments: 19 pages, 7 figures, 3 tables, 2 listings",
    "descriptor": "\nComments: 19 pages, 7 figures, 3 tables, 2 listings\n",
    "authors": [
      "Justin Crum",
      "Cyrus Cheng",
      "David A. Ham",
      "Lawrence Mitchell",
      "Robert C. Kirby",
      "Joshua A. Levine",
      "Andrew Gillette"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Software (cs.MS)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2104.12986"
  },
  {
    "id": "arXiv:2104.15061",
    "title": "Black-box Gradient Attack on Graph Neural Networks: Deeper Insights in  Graph-based Attack and Defense",
    "abstract": "Comments: A new version of this work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: A new version of this work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Haoxi Zhan",
      "Xiaobing Pei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.15061"
  },
  {
    "id": "arXiv:2105.00826",
    "title": "WhatTheWikiFact: Fact-Checking Claims Against Wikipedia",
    "abstract": "Comments: fact-checking, veracity, factuality, stance detection, evidence retrieval, fake news, FEVER, Wikipedia",
    "descriptor": "\nComments: fact-checking, veracity, factuality, stance detection, evidence retrieval, fake news, FEVER, Wikipedia\n",
    "authors": [
      "Anton Chernyavskiy",
      "Dmitry Ilvovsky",
      "Preslav Nakov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.00826"
  },
  {
    "id": "arXiv:2105.00916",
    "title": "MemX: An Attention-Aware Smart Eyewear System for Personalized Moment  Auto-capture",
    "abstract": "Comments: Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT)",
    "descriptor": "\nComments: Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT)\n",
    "authors": [
      "Yuhu Chang",
      "Yingying Zhao",
      "Mingzhi Dong",
      "Yujiang Wang",
      "Yutian Lu",
      "Qin Lv",
      "Robert P. Dick",
      "Tun Lu",
      "Ning Gu",
      "Li Shang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.00916"
  },
  {
    "id": "arXiv:2105.01939",
    "title": "Comparative Analysis of Box-Covering Algorithms for Fractal Networks",
    "abstract": "Comments: The paper has been published in Applied Network Science: this https URL",
    "descriptor": "\nComments: The paper has been published in Applied Network Science: this https URL\n",
    "authors": [
      "P\u00e9ter Tam\u00e1s Kov\u00e1cs",
      "Marcell Nagy",
      "Roland Molontay"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Discrete Mathematics (cs.DM)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.01939"
  },
  {
    "id": "arXiv:2105.01941",
    "title": "Monotonicity-Based Regularization for Shape Reconstruction in Linear  Elasticity",
    "abstract": "Comments: 26 pages, 15 figures",
    "descriptor": "\nComments: 26 pages, 15 figures\n",
    "authors": [
      "Sarah Eberle",
      "Bastian Harrach"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.01941"
  },
  {
    "id": "arXiv:2105.02480",
    "title": "A Simple and Strong Baseline for Universal Targeted Attacks on Siamese  Visual Tracking",
    "abstract": "A Simple and Strong Baseline for Universal Targeted Attacks on Siamese  Visual Tracking",
    "descriptor": "",
    "authors": [
      "Zhenbang Li",
      "Yaya Shi",
      "Jin Gao",
      "Shaoru Wang",
      "Bing Li",
      "Pengpeng Liang",
      "Weiming Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.02480"
  },
  {
    "id": "arXiv:2105.02784",
    "title": "Cyclic Arbitrage in Decentralized Exchange Markets",
    "abstract": "Cyclic Arbitrage in Decentralized Exchange Markets",
    "descriptor": "",
    "authors": [
      "Ye Wang",
      "Yan Chen",
      "Shuiguang Deng",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.02784"
  },
  {
    "id": "arXiv:2105.02961",
    "title": "UVStyle-Net: Unsupervised Few-shot Learning of 3D Style Similarity  Measure for B-Reps",
    "abstract": "Comments: ICCV 2021 main track 13 pages, 20 figures, 5 tables",
    "descriptor": "\nComments: ICCV 2021 main track 13 pages, 20 figures, 5 tables\n",
    "authors": [
      "Peter Meltzer",
      "Hooman Shayani",
      "Amir Khasahmadi",
      "Pradeep Kumar Jayaraman",
      "Aditya Sanghi",
      "Joseph Lambourne"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.02961"
  },
  {
    "id": "arXiv:2105.03863",
    "title": "Towards Theoretical Understandings of Robust Markov Decision Processes:  Sample Complexity and Asymptotics",
    "abstract": "Towards Theoretical Understandings of Robust Markov Decision Processes:  Sample Complexity and Asymptotics",
    "descriptor": "",
    "authors": [
      "Wenhao Yang",
      "Liangyu Zhang",
      "Zhihua Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03863"
  },
  {
    "id": "arXiv:2105.04324",
    "title": "Passivity-based control of mechanical systems with linear damping  identification",
    "abstract": "Comments: Submission for 7th IFAC Workshop on Lagrangian and Hamiltonian Methods for Nonlinear Control. Fixed youtube link",
    "descriptor": "\nComments: Submission for 7th IFAC Workshop on Lagrangian and Hamiltonian Methods for Nonlinear Control. Fixed youtube link\n",
    "authors": [
      "Carmen Chan-Zheng",
      "Pablo Borja",
      "Jacquelien Scherpen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.04324"
  },
  {
    "id": "arXiv:2105.04544",
    "title": "Proximal Causal Learning with Kernels: Two-Stage Estimation and Moment  Restriction",
    "abstract": "Proximal Causal Learning with Kernels: Two-Stage Estimation and Moment  Restriction",
    "descriptor": "",
    "authors": [
      "Afsaneh Mastouri",
      "Yuchen Zhu",
      "Limor Gultchin",
      "Anna Korba",
      "Ricardo Silva",
      "Matt J. Kusner",
      "Arthur Gretton",
      "Krikamol Muandet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04544"
  },
  {
    "id": "arXiv:2105.05192",
    "title": "Digital Building Twins and Blockchain for Performance-Based (Smart)  Contracts",
    "abstract": "Digital Building Twins and Blockchain for Performance-Based (Smart)  Contracts",
    "descriptor": "",
    "authors": [
      "Jens J. Hunhevicz",
      "Mahshid Motie",
      "Daniel M. Hall"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.05192"
  },
  {
    "id": "arXiv:2105.05618",
    "title": "Joint Optimization for RIS-Assisted Wireless Communications: From  Physics and Electromagnetic Perspectives",
    "abstract": "Joint Optimization for RIS-Assisted Wireless Communications: From  Physics and Electromagnetic Perspectives",
    "descriptor": "",
    "authors": [
      "Xin Cheng",
      "Yan Lin",
      "Weiping Shi",
      "Jiayu Li",
      "Cunhua Pan",
      "Feng Shu",
      "Yongpeng Wu",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.05618"
  },
  {
    "id": "arXiv:2105.05887",
    "title": "Black or White but never neutral: How readers perceive identity from  yellow or skin-toned emoji",
    "abstract": "Black or White but never neutral: How readers perceive identity from  yellow or skin-toned emoji",
    "descriptor": "",
    "authors": [
      "Alexander Robertson",
      "Walid Magdy",
      "Sharon Goldwater"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.05887"
  },
  {
    "id": "arXiv:2105.07510",
    "title": "Doc2Dict: Information Extraction as Text Generation",
    "abstract": "Doc2Dict: Information Extraction as Text Generation",
    "descriptor": "",
    "authors": [
      "Benjamin Townsend",
      "Eamon Ito-Fisher",
      "Lily Zhang",
      "Madison May"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.07510"
  },
  {
    "id": "arXiv:2105.08405",
    "title": "Gradient Flows and Nonlinear Power Methods for the Computation of  Nonlinear Eigenfunctions",
    "abstract": "Comments: To appear in Handbook of Numerical Analysis, Numerical Control: Part A, Volume 23",
    "descriptor": "\nComments: To appear in Handbook of Numerical Analysis, Numerical Control: Part A, Volume 23\n",
    "authors": [
      "Leon Bungert",
      "Martin Burger"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Optimization and Control (math.OC)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.08405"
  },
  {
    "id": "arXiv:2105.08488",
    "title": "Unsupervised identification of surgical robotic actions from small non  homogeneous datasets",
    "abstract": "Unsupervised identification of surgical robotic actions from small non  homogeneous datasets",
    "descriptor": "",
    "authors": [
      "Daniele Meli",
      "Paolo Fiorini"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.08488"
  },
  {
    "id": "arXiv:2105.08769",
    "title": "Learning and Information in Stochastic Networks and Queues",
    "abstract": "Comments: review article",
    "descriptor": "\nComments: review article\n",
    "authors": [
      "Neil Walton",
      "Kuang Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.08769"
  },
  {
    "id": "arXiv:2105.09090",
    "title": "Local Aggressive Adversarial Attacks on 3D Point Cloud",
    "abstract": "Local Aggressive Adversarial Attacks on 3D Point Cloud",
    "descriptor": "",
    "authors": [
      "Yiming Sun",
      "Feng Chen",
      "Zhiyu Chen",
      "Mingjie Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.09090"
  },
  {
    "id": "arXiv:2105.10360",
    "title": "Multi-source Learning via Completion of Block-wise Overlapping Noisy  Matrices",
    "abstract": "Multi-source Learning via Completion of Block-wise Overlapping Noisy  Matrices",
    "descriptor": "",
    "authors": [
      "Doudou Zhou",
      "Tianxi Cai",
      "Junwei Lu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2105.10360"
  },
  {
    "id": "arXiv:2105.11137",
    "title": "CFA-Net: Controllable Face Anonymization Network with Identity  Representation Manipulation",
    "abstract": "CFA-Net: Controllable Face Anonymization Network with Identity  Representation Manipulation",
    "descriptor": "",
    "authors": [
      "Tianxiang Ma",
      "Dongze Li",
      "Wei Wang",
      "Jing Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.11137"
  },
  {
    "id": "arXiv:2105.12319",
    "title": "Neural Radiosity",
    "abstract": "Neural Radiosity",
    "descriptor": "",
    "authors": [
      "Saeed Hadadan",
      "Shuhong Chen",
      "Matthias Zwicker"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.12319"
  },
  {
    "id": "arXiv:2105.12584",
    "title": "A Comprehensive Survey on Community Detection with Deep Learning",
    "abstract": "Comments: 29 Pages",
    "descriptor": "\nComments: 29 Pages\n",
    "authors": [
      "Xing Su",
      "Shan Xue",
      "Fanzhen Liu",
      "Jia Wu",
      "Jian Yang",
      "Chuan Zhou",
      "Wenbin Hu",
      "Cecile Paris",
      "Surya Nepal",
      "Di Jin",
      "Quan Z. Sheng",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.12584"
  },
  {
    "id": "arXiv:2105.12824",
    "title": "Huygens' equations and the gradient-flow equations in information  geometry",
    "abstract": "Comments: 20 pages, no figure, submitted to OSID",
    "descriptor": "\nComments: 20 pages, no figure, submitted to OSID\n",
    "authors": [
      "Tatsuaki Wada",
      "Antonio M. Scarfone",
      "Hiroshi Matsuzoe"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistical Mechanics (cond-mat.stat-mech)"
    ],
    "url": "https://arxiv.org/abs/2105.12824"
  },
  {
    "id": "arXiv:2105.12911",
    "title": "Compositional Thinking in Cyberphysical Systems Theory",
    "abstract": "Compositional Thinking in Cyberphysical Systems Theory",
    "descriptor": "",
    "authors": [
      "Georgios Bakirtzis",
      "Eswaran Subrahmanian",
      "Cody H. Fleming"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2105.12911"
  },
  {
    "id": "arXiv:2105.12988",
    "title": "Normative versus strategic accounts of acknowledgment data: the case of  the top-five journals of economics",
    "abstract": "Comments: 46 pages, 5 figures, 5 tables",
    "descriptor": "\nComments: 46 pages, 5 figures, 5 tables\n",
    "authors": [
      "Alberto Baccini",
      "Eugenio Petrovich"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2105.12988"
  },
  {
    "id": "arXiv:2105.14275",
    "title": "Greedy Bayesian Posterior Approximation with Deep Ensembles",
    "abstract": "Greedy Bayesian Posterior Approximation with Deep Ensembles",
    "descriptor": "",
    "authors": [
      "Aleksei Tiulpin",
      "Matthew B. Blaschko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14275"
  },
  {
    "id": "arXiv:2105.14491",
    "title": "How Attentive are Graph Attention Networks?",
    "abstract": "How Attentive are Graph Attention Networks?",
    "descriptor": "",
    "authors": [
      "Shaked Brody",
      "Uri Alon",
      "Eran Yahav"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14491"
  },
  {
    "id": "arXiv:2105.14867",
    "title": "Accurate and Efficient Time Series Matching by Season- and Trend-aware  Symbolic Approximation -- Extended Version Including Additional Evaluation  and Proofs",
    "abstract": "Accurate and Efficient Time Series Matching by Season- and Trend-aware  Symbolic Approximation -- Extended Version Including Additional Evaluation  and Proofs",
    "descriptor": "",
    "authors": [
      "Lars Kegel",
      "Claudio Hartmann",
      "Maik Thiele",
      "Wolfgang Lehner"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2105.14867"
  },
  {
    "id": "arXiv:2105.15186",
    "title": "Fast Policy Extragradient Methods for Competitive Games with Entropy  Regularization",
    "abstract": "Fast Policy Extragradient Methods for Competitive Games with Entropy  Regularization",
    "descriptor": "",
    "authors": [
      "Shicong Cen",
      "Yuting Wei",
      "Yuejie Chi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.15186"
  },
  {
    "id": "arXiv:2106.00110",
    "title": "A Methodology for Exploring Deep Convolutional Features in Relation to  Hand-Crafted Features with an Application to Music Audio Modeling",
    "abstract": "Comments: Code available at this https URL",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Anna K. Yanchenko",
      "Mohammadreza Soltani",
      "Robert J. Ravier",
      "Sayan Mukherjee",
      "Vahid Tarokh"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.00110"
  },
  {
    "id": "arXiv:2106.00329",
    "title": "Consistent Two-Flow Network for Tele-Registration of Point Clouds",
    "abstract": "Comments: Accepted to IEEE TVCG 2021, project page at this https URL",
    "descriptor": "\nComments: Accepted to IEEE TVCG 2021, project page at this https URL\n",
    "authors": [
      "Zihao Yan",
      "Zimu Yi",
      "Ruizhen Hu",
      "Niloy J. Mitra",
      "Daniel Cohen-Or",
      "Hui Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.00329"
  },
  {
    "id": "arXiv:2106.01098",
    "title": "Evaluation Metrics for Graph Generative Models: Problems, Pitfalls, and  Practical Solutions",
    "abstract": "Evaluation Metrics for Graph Generative Models: Problems, Pitfalls, and  Practical Solutions",
    "descriptor": "",
    "authors": [
      "Leslie O'Bray",
      "Max Horn",
      "Bastian Rieck",
      "Karsten Borgwardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.01098"
  },
  {
    "id": "arXiv:2106.01883",
    "title": "Learning High-Precision Bounding Box for Rotated Object Detection via  Kullback-Leibler Divergence",
    "abstract": "Comments: 16 pages, 5 figures, 8 tables, accepted by NeurIPS21, codes are available at this https URL",
    "descriptor": "\nComments: 16 pages, 5 figures, 8 tables, accepted by NeurIPS21, codes are available at this https URL\n",
    "authors": [
      "Xue Yang",
      "Xiaojiang Yang",
      "Jirui Yang",
      "Qi Ming",
      "Wentao Wang",
      "Qi Tian",
      "Junchi Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01883"
  },
  {
    "id": "arXiv:2106.02528",
    "title": "Neural Network Surrogate Models for Absorptivity and Emissivity Spectra  of Multiple Elements",
    "abstract": "Comments: Elsevier Review Format, Double Spaced, 26 pages, 10 figures, 5 tables Michael D. Vander Wal: conceptualization, investigation, writing - original draft, writing - editing and review. Ryan G. McClarren - conceptualization, writing - editing and review. Kelli D. Humbird: conceptualization, writing - editing and review",
    "descriptor": "\nComments: Elsevier Review Format, Double Spaced, 26 pages, 10 figures, 5 tables Michael D. Vander Wal: conceptualization, investigation, writing - original draft, writing - editing and review. Ryan G. McClarren - conceptualization, writing - editing and review. Kelli D. Humbird: conceptualization, writing - editing and review\n",
    "authors": [
      "Michael D. Vander Wal",
      "Ryan G. McClarren",
      "Kelli D. Humbird"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02528"
  },
  {
    "id": "arXiv:2106.02693",
    "title": "Two-Sample Tests that are Safe under Optional Stopping, with an  Application to Contingency Tables",
    "abstract": "Two-Sample Tests that are Safe under Optional Stopping, with an  Application to Contingency Tables",
    "descriptor": "",
    "authors": [
      "Rosanne Turner",
      "Alexander Ly",
      "Peter Gr\u00fcnwald"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2106.02693"
  },
  {
    "id": "arXiv:2106.02927",
    "title": "A Generalized Framework for Joint Dynamic Optimal RF Interface Setting  and Next-Hop Selection in IoT networks with Same Source Requests",
    "abstract": "A Generalized Framework for Joint Dynamic Optimal RF Interface Setting  and Next-Hop Selection in IoT networks with Same Source Requests",
    "descriptor": "",
    "authors": [
      "Monireh Allah Gholi Ghasri",
      "Ali Mohammad Afshin Hemmatyar"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.02927"
  },
  {
    "id": "arXiv:2106.03188",
    "title": "Combinatorial Optimization for Panoptic Segmentation: A Fully  Differentiable Approach",
    "abstract": "Combinatorial Optimization for Panoptic Segmentation: A Fully  Differentiable Approach",
    "descriptor": "",
    "authors": [
      "Ahmed Abbas",
      "Paul Swoboda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.03188"
  },
  {
    "id": "arXiv:2106.03459",
    "title": "Systematic Online Tuning of Multirotor UAVs for Accurate Trajectory  Tracking Under Wind Disturbances and In-Flight Dynamics Changes",
    "abstract": "Systematic Online Tuning of Multirotor UAVs for Accurate Trajectory  Tracking Under Wind Disturbances and In-Flight Dynamics Changes",
    "descriptor": "",
    "authors": [
      "Abdulaziz Y. Alkayas",
      "Mohamad Chehadeh",
      "Abdulla Ayyad",
      "Yahya Zweiri"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.03459"
  },
  {
    "id": "arXiv:2106.03899",
    "title": "Shifting Transformation Learning for Out-of-Distribution Detection",
    "abstract": "Shifting Transformation Learning for Out-of-Distribution Detection",
    "descriptor": "",
    "authors": [
      "Sina Mohseni",
      "Arash Vahdat",
      "Jay Yadawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.03899"
  },
  {
    "id": "arXiv:2106.04217",
    "title": "Dynamic Sparse Training for Deep Reinforcement Learning",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Ghada Sokar",
      "Elena Mocanu",
      "Decebal Constantin Mocanu",
      "Mykola Pechenizkiy",
      "Peter Stone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.04217"
  },
  {
    "id": "arXiv:2106.04258",
    "title": "Interpretable agent communication from scratch (with a generic visual  processor emerging on the side)",
    "abstract": "Comments: Accepted at NeurIPS 2021",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Roberto Dess\u00ec",
      "Eugene Kharitonov",
      "Marco Baroni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.04258"
  },
  {
    "id": "arXiv:2106.04663",
    "title": "Solving Structured Hierarchical Games Using Differential Backward  Induction",
    "abstract": "Solving Structured Hierarchical Games Using Differential Backward  Induction",
    "descriptor": "",
    "authors": [
      "Zun Li",
      "Feiran Jia",
      "Aditya Mate",
      "Shahin Jabbari",
      "Mithun Chakraborty",
      "Milind Tambe",
      "Yevgeniy Vorobeychik"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.04663"
  },
  {
    "id": "arXiv:2106.04693",
    "title": "On the Evolution of Neuron Communities in a Deep Learning Architecture",
    "abstract": "On the Evolution of Neuron Communities in a Deep Learning Architecture",
    "descriptor": "",
    "authors": [
      "Sakib Mostafa",
      "Debajyoti Mondal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.04693"
  },
  {
    "id": "arXiv:2106.04700",
    "title": "Scale Free Adversarial Multi Armed Bandits",
    "abstract": "Scale Free Adversarial Multi Armed Bandits",
    "descriptor": "",
    "authors": [
      "Sudeep Raja Putta",
      "Shipra Agrawal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.04700"
  },
  {
    "id": "arXiv:2106.05194",
    "title": "DIGRAC: Digraph Clustering Based on Flow Imbalance",
    "abstract": "Comments: 36 pages (10 pages for main text, 3 pages for references)",
    "descriptor": "\nComments: 36 pages (10 pages for main text, 3 pages for references)\n",
    "authors": [
      "Yixuan He",
      "Gesine Reinert",
      "Mihai Cucuringu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05194"
  },
  {
    "id": "arXiv:2106.05318",
    "title": "Distributed Mean-Field Density Estimation for Large-Scale Systems",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2009.05366",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2009.05366\n",
    "authors": [
      "Tongjia Zheng",
      "Qing Han",
      "Hai Lin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.05318"
  },
  {
    "id": "arXiv:2106.05424",
    "title": "Fair Disaster Containment via Graph-Cut Problems",
    "abstract": "Fair Disaster Containment via Graph-Cut Problems",
    "descriptor": "",
    "authors": [
      "Michael Dinitz",
      "Aravind Srinivasan",
      "Leonidas Tsepenekas",
      "Anil Vullikanti"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05424"
  },
  {
    "id": "arXiv:2106.05494",
    "title": "Superscalability of the random batch Ewald method",
    "abstract": "Comments: 12 pages, 8 figures; the title of V1 is changed",
    "descriptor": "\nComments: 12 pages, 8 figures; the title of V1 is changed\n",
    "authors": [
      "Jiuyang Liang",
      "Pan Tan",
      "Yue Zhao",
      "Lei Li",
      "Shi Jin",
      "Liang Hong",
      "Zhenli Xu"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2106.05494"
  },
  {
    "id": "arXiv:2106.05517",
    "title": "Learning to Affiliate: Mutual Centralized Learning for Few-shot  Classification",
    "abstract": "Comments: 18 pages",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Yang Liu",
      "Weifeng Zhang",
      "Chao Xiang",
      "Tu Zheng",
      "Deng Cai",
      "Xiaofei He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.05517"
  },
  {
    "id": "arXiv:2106.06153",
    "title": "Towards Understanding Generalization via Decomposing Excess Risk  Dynamics",
    "abstract": "Towards Understanding Generalization via Decomposing Excess Risk  Dynamics",
    "descriptor": "",
    "authors": [
      "Jiaye Teng",
      "Jianhao Ma",
      "Yang Yuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.06153"
  },
  {
    "id": "arXiv:2106.06257",
    "title": "HPO-B: A Large-Scale Reproducible Benchmark for Black-Box HPO based on  OpenML",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Sebastian Pineda Arango",
      "Hadi S. Jomaa",
      "Martin Wistuba",
      "Josif Grabocka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06257"
  },
  {
    "id": "arXiv:2106.06482",
    "title": "Neural Network Modeling of Probabilities for Coding the Octree  Representation of Point Clouds",
    "abstract": "Comments: 6 pages, 3 figures, MMSP 2021 camera-ready",
    "descriptor": "\nComments: 6 pages, 3 figures, MMSP 2021 camera-ready\n",
    "authors": [
      "Emre Can Kaya",
      "Ioan Tabus"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.06482"
  },
  {
    "id": "arXiv:2106.06733",
    "title": "LE-NAS: Learning-based Ensemble with NAS for Dose Prediction",
    "abstract": "LE-NAS: Learning-based Ensemble with NAS for Dose Prediction",
    "descriptor": "",
    "authors": [
      "Yi Lin",
      "Yanfei Liu",
      "Jingguang Liu",
      "Guocai Liu",
      "Kai Ma",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06733"
  },
  {
    "id": "arXiv:2106.07178",
    "title": "A Comprehensive Survey on Graph Anomaly Detection with Deep Learning",
    "abstract": "Comments: 31 pages",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Xiaoxiao Ma",
      "Jia Wu",
      "Shan Xue",
      "Jian Yang",
      "Chuan Zhou",
      "Quan Z. Sheng",
      "Hui Xiong",
      "Leman Akoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07178"
  },
  {
    "id": "arXiv:2106.07677",
    "title": "Planning to Fairly Allocate: Probabilistic Fairness in the Restless  Bandit Setting",
    "abstract": "Comments: 34 pages",
    "descriptor": "\nComments: 34 pages\n",
    "authors": [
      "Christine Herlihy",
      "Aviva Prins",
      "Aravind Srinivasan",
      "John Dickerson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.07677"
  },
  {
    "id": "arXiv:2106.07830",
    "title": "On the Convergence and Calibration of Deep Learning with Differential  Privacy",
    "abstract": "On the Convergence and Calibration of Deep Learning with Differential  Privacy",
    "descriptor": "",
    "authors": [
      "Zhiqi Bu",
      "Hua Wang",
      "Qi Long",
      "Weijie J. Su"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07830"
  },
  {
    "id": "arXiv:2106.08315",
    "title": "Decentralized Local Stochastic Extra-Gradient for Variational  Inequalities",
    "abstract": "Decentralized Local Stochastic Extra-Gradient for Variational  Inequalities",
    "descriptor": "",
    "authors": [
      "Aleksandr Beznosikov",
      "Pavel Dvurechensky",
      "Anastasia Koloskova",
      "Valentin Samokhin",
      "Sebastian U Stich",
      "Alexander Gasnikov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08315"
  },
  {
    "id": "arXiv:2106.08858",
    "title": "Grounding Spatio-Temporal Language with Transformers",
    "abstract": "Comments: Contains main article and supplementaries",
    "descriptor": "\nComments: Contains main article and supplementaries\n",
    "authors": [
      "Tristan Karch",
      "Laetitia Teodorescu",
      "Katja Hofmann",
      "Cl\u00e9ment Moulin-Frier",
      "Pierre-Yves Oudeyer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08858"
  },
  {
    "id": "arXiv:2106.09408",
    "title": "Predicting cognitive scores with graph neural networks through sample  selection learning",
    "abstract": "Comments: Extended discussions in particular of the sample selection method",
    "descriptor": "\nComments: Extended discussions in particular of the sample selection method\n",
    "authors": [
      "Martin Hanik",
      "Mehmet Arif Demirta\u015f",
      "Mohammed Amine Gharsallaoui",
      "Islem Rekik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2106.09408"
  },
  {
    "id": "arXiv:2106.09509",
    "title": "Resurrect3D: An Open and Customizable Platform for Visualizing and  Analyzing Cultural Heritage Artifacts",
    "abstract": "Resurrect3D: An Open and Customizable Platform for Visualizing and  Analyzing Cultural Heritage Artifacts",
    "descriptor": "",
    "authors": [
      "Joshua Romphf",
      "Elias Neuman-Donihue",
      "Gregory Heyworth",
      "Yuhao Zhu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.09509"
  },
  {
    "id": "arXiv:2106.10163",
    "title": "Steerable Partial Differential Operators for Equivariant Neural Networks",
    "abstract": "Comments: 44 pages, 4 figures, code available at this https URL",
    "descriptor": "\nComments: 44 pages, 4 figures, code available at this https URL\n",
    "authors": [
      "Erik Jenner",
      "Maurice Weiler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10163"
  },
  {
    "id": "arXiv:2106.10180",
    "title": "Determining when a truncated generalised Reed-Solomon code is Hermitian  self-orthogonal",
    "abstract": "Determining when a truncated generalised Reed-Solomon code is Hermitian  self-orthogonal",
    "descriptor": "",
    "authors": [
      "Simeon Ball",
      "Ricard Vilar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.10180"
  },
  {
    "id": "arXiv:2106.10370",
    "title": "On the benefits of maximum likelihood estimation for Regression and  Forecasting",
    "abstract": "On the benefits of maximum likelihood estimation for Regression and  Forecasting",
    "descriptor": "",
    "authors": [
      "Pranjal Awasthi",
      "Abhimanyu Das",
      "Rajat Sen",
      "Ananda Theertha Suresh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10370"
  },
  {
    "id": "arXiv:2106.10424",
    "title": "More Efficient Adversarial Imitation Learning Algorithms With Known and  Unknown Transitions",
    "abstract": "More Efficient Adversarial Imitation Learning Algorithms With Known and  Unknown Transitions",
    "descriptor": "",
    "authors": [
      "Tian Xu",
      "Ziniu Li",
      "Yang Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10424"
  },
  {
    "id": "arXiv:2106.11184",
    "title": "The decline of disruptive science and technology",
    "abstract": "The decline of disruptive science and technology",
    "descriptor": "",
    "authors": [
      "Michael Park",
      "Erin Leahey",
      "Russell Funk"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2106.11184"
  },
  {
    "id": "arXiv:2106.11514",
    "title": "Adapting Stepsizes by Momentumized Gradients Improves Optimization and  Generalization",
    "abstract": "Adapting Stepsizes by Momentumized Gradients Improves Optimization and  Generalization",
    "descriptor": "",
    "authors": [
      "Yizhou Wang",
      "Yue Kang",
      "Can Qin",
      "Huan Wang",
      "Yi Xu",
      "Yulun Zhang",
      "Yun Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11514"
  },
  {
    "id": "arXiv:2106.13498",
    "title": "Non-Parametric Neuro-Adaptive Control Subject to Task Specifications",
    "abstract": "Non-Parametric Neuro-Adaptive Control Subject to Task Specifications",
    "descriptor": "",
    "authors": [
      "Christos K. Verginis",
      "Zhe Xu",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.13498"
  },
  {
    "id": "arXiv:2106.13516",
    "title": "Multi-Domain Active Learning: A Comparative Study",
    "abstract": "Multi-Domain Active Learning: A Comparative Study",
    "descriptor": "",
    "authors": [
      "Rui He",
      "Shan He",
      "Ke Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.13516"
  },
  {
    "id": "arXiv:2106.13927",
    "title": "Quantum Dynamics Interpretation of Black-box Optimization",
    "abstract": "Comments: The paper may provide a new quantum perspective for studying the basic search behavior of the intelligence algorithms",
    "descriptor": "\nComments: The paper may provide a new quantum perspective for studying the basic search behavior of the intelligence algorithms\n",
    "authors": [
      "Peng Wang",
      "Gang Xin",
      "Fang Wang",
      "Yuwei Jiao"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.13927"
  },
  {
    "id": "arXiv:2106.14396",
    "title": "Single RGB-D Camera Teleoperation for General Robotic Manipulation",
    "abstract": "Single RGB-D Camera Teleoperation for General Robotic Manipulation",
    "descriptor": "",
    "authors": [
      "Quan Vuong",
      "Yuzhe Qin",
      "Runlin Guo",
      "Xiaolong Wang",
      "Hao Su",
      "Henrik Christensen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.14396"
  },
  {
    "id": "arXiv:2106.16245",
    "title": "How to Train Your MAML to Excel in Few-Shot Classification",
    "abstract": "How to Train Your MAML to Excel in Few-Shot Classification",
    "descriptor": "",
    "authors": [
      "Han-Jia Ye",
      "Wei-Lun Chao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16245"
  },
  {
    "id": "arXiv:2107.00251",
    "title": "$L_p$ Isotonic Regression Algorithms Using an $L_0$ Approach",
    "abstract": "Comments: Remove mistaken mistaken in abstract about unweighted points in $d$-dimensional space. Added multiple references, revised paper to make it more readable",
    "descriptor": "\nComments: Remove mistaken mistaken in abstract about unweighted points in $d$-dimensional space. Added multiple references, revised paper to make it more readable\n",
    "authors": [
      "Quentin F. Stout"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.00251"
  },
  {
    "id": "arXiv:2107.03026",
    "title": "Directed Network Laplacians and Random Graph Models",
    "abstract": "Directed Network Laplacians and Random Graph Models",
    "descriptor": "",
    "authors": [
      "Xue Gong",
      "Desmond John Higham",
      "Konstantinos Zygalakis"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.03026"
  },
  {
    "id": "arXiv:2107.04734",
    "title": "Layer-wise Analysis of a Self-supervised Speech Representation Model",
    "abstract": "Comments: Accepted to ASRU 2021",
    "descriptor": "\nComments: Accepted to ASRU 2021\n",
    "authors": [
      "Ankita Pasad",
      "Ju-Chieh Chou",
      "Karen Livescu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.04734"
  },
  {
    "id": "arXiv:2107.05675",
    "title": "Quality of Service Guarantees for Physical Unclonable Functions",
    "abstract": "Comments: To appear in the IEEE International Workshop on Information Forensics and Security 2021",
    "descriptor": "\nComments: To appear in the IEEE International Workshop on Information Forensics and Security 2021\n",
    "authors": [
      "Onur G\u00fcnl\u00fc",
      "Rafael F. Schaefer",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05675"
  },
  {
    "id": "arXiv:2107.06226",
    "title": "Pessimistic Model-based Offline Reinforcement Learning under Partial  Coverage",
    "abstract": "Comments: We changed the title from the first version",
    "descriptor": "\nComments: We changed the title from the first version\n",
    "authors": [
      "Masatoshi Uehara",
      "Wen Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.06226"
  },
  {
    "id": "arXiv:2107.08031",
    "title": "Is attention to bounding boxes all you need for pedestrian action  prediction?",
    "abstract": "Is attention to bounding boxes all you need for pedestrian action  prediction?",
    "descriptor": "",
    "authors": [
      "Lina Achaji",
      "Julien Moreau",
      "Thibault Fouqueray",
      "Francois Aioun",
      "Francois Charpillet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.08031"
  },
  {
    "id": "arXiv:2107.08621",
    "title": "Face.evoLVe: A High-Performance Face Recognition Library",
    "abstract": "Face.evoLVe: A High-Performance Face Recognition Library",
    "descriptor": "",
    "authors": [
      "Qingzhong Wang",
      "Pengfei Zhang",
      "Haoyi Xiong",
      "Jian Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2107.08621"
  },
  {
    "id": "arXiv:2107.08925",
    "title": "Estimating covariant Lyapunov vectors from data",
    "abstract": "Estimating covariant Lyapunov vectors from data",
    "descriptor": "",
    "authors": [
      "Christoph Martin",
      "Nahal Sharafi",
      "Sarah Hallerberg"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.08925"
  },
  {
    "id": "arXiv:2107.09278",
    "title": "Sequence Model with Self-Adaptive Sliding Window for Efficient Spoken  Document Segmentation",
    "abstract": "Comments: accepted by ASRU 2021",
    "descriptor": "\nComments: accepted by ASRU 2021\n",
    "authors": [
      "Qinglin Zhang",
      "Qian Chen",
      "Yali Li",
      "Jiaqing Liu",
      "Wen Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.09278"
  },
  {
    "id": "arXiv:2107.10467",
    "title": "Improving Blockchain Consistency Bound by Assigning Weights to Random  Blocks",
    "abstract": "Improving Blockchain Consistency Bound by Assigning Weights to Random  Blocks",
    "descriptor": "",
    "authors": [
      "Qing Zhang",
      "Xueping Gong",
      "Huizhong Li",
      "Hao Wu",
      "Jiheng Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.10467"
  },
  {
    "id": "arXiv:2107.10533",
    "title": "CGuard: Efficient Spatial Safety for C",
    "abstract": "CGuard: Efficient Spatial Safety for C",
    "descriptor": "",
    "authors": [
      "Piyus Kedia",
      "Rahul Purandare",
      "Udit Kumar Agarwal",
      "Rishabh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.10533"
  },
  {
    "id": "arXiv:2107.11008",
    "title": "SuperCaustics: Real-time, open-source simulation of transparent objects  for deep learning applications",
    "abstract": "SuperCaustics: Real-time, open-source simulation of transparent objects  for deep learning applications",
    "descriptor": "",
    "authors": [
      "Mehdi Mousavi",
      "Rolando Estrada"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.11008"
  },
  {
    "id": "arXiv:2107.11264",
    "title": "Standardized Max Logits: A Simple yet Effective Approach for Identifying  Unexpected Road Obstacles in Urban-Scene Segmentation",
    "abstract": "Comments: Accepted to ICCV 2021 (Oral Presentation)",
    "descriptor": "\nComments: Accepted to ICCV 2021 (Oral Presentation)\n",
    "authors": [
      "Sanghun Jung",
      "Jungsoo Lee",
      "Daehoon Gwak",
      "Sungha Choi",
      "Jaegul Choo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.11264"
  },
  {
    "id": "arXiv:2107.14758",
    "title": "A scalable and robust vertex-star relaxation for high-order FEM",
    "abstract": "A scalable and robust vertex-star relaxation for high-order FEM",
    "descriptor": "",
    "authors": [
      "Pablo D. Brubeck",
      "Patrick E. Farrell"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.14758"
  },
  {
    "id": "arXiv:2108.00885",
    "title": "Counterexample Classification",
    "abstract": "Counterexample Classification",
    "descriptor": "",
    "authors": [
      "Cole Vick",
      "Eunsuk Kang",
      "Stavros Tripakis"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2108.00885"
  },
  {
    "id": "arXiv:2108.02501",
    "title": "Locally Interpretable One-Class Anomaly Detection for Credit Card Fraud  Detection",
    "abstract": "Comments: 6 pages, 5 figures, 2 tables",
    "descriptor": "\nComments: 6 pages, 5 figures, 2 tables\n",
    "authors": [
      "Tungyu Wu",
      "Youting Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.02501"
  },
  {
    "id": "arXiv:2108.04097",
    "title": "Deep Learning for Embodied Vision Navigation: A Survey",
    "abstract": "Comments: 20 pages",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Fengda Zhu",
      "Yi Zhu",
      "Vincent CS Lee",
      "Xiaodan Liang",
      "Xiaojun Chang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.04097"
  },
  {
    "id": "arXiv:2108.05137",
    "title": "Zero-Shot Day-Night Domain Adaptation with a Physics Prior",
    "abstract": "Comments: ICCV 2021 Oral presentation. Code, datasets and supplementary material: this https URL",
    "descriptor": "\nComments: ICCV 2021 Oral presentation. Code, datasets and supplementary material: this https URL\n",
    "authors": [
      "Attila Lengyel",
      "Sourav Garg",
      "Michael Milford",
      "Jan C. van Gemert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.05137"
  },
  {
    "id": "arXiv:2108.08262",
    "title": "SOME/IP Intrusion Detection using Deep Learning-based Sequential Models  in Automotive Ethernet Networks",
    "abstract": "SOME/IP Intrusion Detection using Deep Learning-based Sequential Models  in Automotive Ethernet Networks",
    "descriptor": "",
    "authors": [
      "Natasha Alkhatib",
      "Hadi Ghauch",
      "Jean-Luc Danger"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.08262"
  },
  {
    "id": "arXiv:2108.09628",
    "title": "DisenKGAT: Knowledge Graph Embedding with Disentangled Graph Attention  Network",
    "abstract": "Comments: CIKM2021",
    "descriptor": "\nComments: CIKM2021\n",
    "authors": [
      "Junkang Wu",
      "Wentao Shi",
      "Xuezhi Cao",
      "Jiawei Chen",
      "Wenqiang Lei",
      "Fuzheng Zhang",
      "Wei Wu",
      "Xiangnan He"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.09628"
  },
  {
    "id": "arXiv:2108.09638",
    "title": "Signed Bipartite Graph Neural Networks",
    "abstract": "Comments: Accepted and to appear at CIKM2021",
    "descriptor": "\nComments: Accepted and to appear at CIKM2021\n",
    "authors": [
      "Junjie Huang",
      "Huawei Shen",
      "Qi Cao",
      "Shuchang Tao",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.09638"
  },
  {
    "id": "arXiv:2108.09795",
    "title": "On a Tverberg graph",
    "abstract": "Comments: v2: 11 pages, 3 figures. Key words: Tverberg's Theorem, perfect matching, blue-red matching, Hamiltonian cycle, alternating cycle, infinite descent, halving lines",
    "descriptor": "\nComments: v2: 11 pages, 3 figures. Key words: Tverberg's Theorem, perfect matching, blue-red matching, Hamiltonian cycle, alternating cycle, infinite descent, halving lines\n",
    "authors": [
      "Olimjoni Pirahmad",
      "Alexandr Polyanskii",
      "Alexey Vasilevskii"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)",
      "Metric Geometry (math.MG)"
    ],
    "url": "https://arxiv.org/abs/2108.09795"
  },
  {
    "id": "arXiv:2108.10531",
    "title": "Unsupervised Depth Completion with Calibrated Backprojection Layers",
    "abstract": "Unsupervised Depth Completion with Calibrated Backprojection Layers",
    "descriptor": "",
    "authors": [
      "Alex Wong",
      "Stefano Soatto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.10531"
  },
  {
    "id": "arXiv:2108.11018",
    "title": "A Scaling Law for Synthetic-to-Real Transfer: How Much Is Your  Pre-training Effective?",
    "abstract": "A Scaling Law for Synthetic-to-Real Transfer: How Much Is Your  Pre-training Effective?",
    "descriptor": "",
    "authors": [
      "Hiroaki Mikami",
      "Kenji Fukumizu",
      "Shogo Murai",
      "Shuji Suzuki",
      "Yuta Kikuchi",
      "Taiji Suzuki",
      "Shin-ichi Maeda",
      "Kohei Hayashi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.11018"
  },
  {
    "id": "arXiv:2108.12102",
    "title": "FOVEA: Foveated Image Magnification for Autonomous Navigation",
    "abstract": "Comments: ICCV 2021. Code can be found on the project page at this https URL",
    "descriptor": "\nComments: ICCV 2021. Code can be found on the project page at this https URL\n",
    "authors": [
      "Chittesh Thavamani",
      "Mengtian Li",
      "Nicolas Cebron",
      "Deva Ramanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.12102"
  },
  {
    "id": "arXiv:2108.13083",
    "title": "An Introduction to Variational Inference",
    "abstract": "Comments: 13 pages, 9 figures",
    "descriptor": "\nComments: 13 pages, 9 figures\n",
    "authors": [
      "Ankush Ganguly",
      "Samuel W. F. Earp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.13083"
  },
  {
    "id": "arXiv:2108.13320",
    "title": "Neural HMMs are all you need (for high-quality attention-free TTS)",
    "abstract": "Comments: 5 pages, 2 figures; submitted to ICASSP 2022",
    "descriptor": "\nComments: 5 pages, 2 figures; submitted to ICASSP 2022\n",
    "authors": [
      "Shivam Mehta",
      "\u00c9va Sz\u00e9kely",
      "Jonas Beskow",
      "Gustav Eje Henter"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2108.13320"
  },
  {
    "id": "arXiv:2108.13976",
    "title": "WarpDrive: Extremely Fast End-to-End Deep Multi-Agent Reinforcement  Learning on a GPU",
    "abstract": "Comments: TL and SS contributed equally. Code is available at this https URL 11 pages, 14 figures",
    "descriptor": "\nComments: TL and SS contributed equally. Code is available at this https URL 11 pages, 14 figures\n",
    "authors": [
      "Tian Lan",
      "Sunil Srinivasa",
      "Huan Wang",
      "Stephan Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2108.13976"
  },
  {
    "id": "arXiv:2108.13987",
    "title": "OARnet: Automated organs-at-risk delineation in Head and Neck CT images",
    "abstract": "OARnet: Automated organs-at-risk delineation in Head and Neck CT images",
    "descriptor": "",
    "authors": [
      "Mumtaz Hussain Soomro",
      "Hamidreza Nourzadeh",
      "Victor Gabriel Leandro Alves",
      "Wookjin Choi",
      "Jeffrey V. Siebers"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2108.13987"
  },
  {
    "id": "arXiv:2109.01135",
    "title": "Sequence-to-Sequence Learning with Latent Neural Grammars",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Yoon Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.01135"
  },
  {
    "id": "arXiv:2109.01860",
    "title": "Spatiotemporal Inconsistency Learning for DeepFake Video Detection",
    "abstract": "Comments: To appear in ACM MM 2021",
    "descriptor": "\nComments: To appear in ACM MM 2021\n",
    "authors": [
      "Zhihao Gu",
      "Yang Chen",
      "Taiping Yao",
      "Shouhong Ding",
      "Jilin Li",
      "Feiyue Huang",
      "Lizhuang Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.01860"
  },
  {
    "id": "arXiv:2109.02069",
    "title": "New Communication Models and Decoding of Maximum Rank Distance Codes",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2105.03115",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2105.03115\n",
    "authors": [
      "Wrya K. Kadir"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2109.02069"
  },
  {
    "id": "arXiv:2109.02096",
    "title": "Timbre Transfer with Variational Auto Encoding and Cycle-Consistent  Adversarial Networks",
    "abstract": "Comments: 12 pages, 3 main figures, 4 tables",
    "descriptor": "\nComments: 12 pages, 3 main figures, 4 tables\n",
    "authors": [
      "Russell Sammut Bonnici",
      "Charalampos Saitis",
      "Martin Benning"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2109.02096"
  },
  {
    "id": "arXiv:2109.02235",
    "title": "Gradient Normalization for Generative Adversarial Networks",
    "abstract": "Comments: Published as a conference paper at ICCV 2021",
    "descriptor": "\nComments: Published as a conference paper at ICCV 2021\n",
    "authors": [
      "Yi-Lun Wu",
      "Hong-Han Shuai",
      "Zhi-Rui Tam",
      "Hong-Yu Chiu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.02235"
  },
  {
    "id": "arXiv:2109.02401",
    "title": "Vision Guided Generative Pre-trained Language Models for Multimodal  Abstractive Summarization",
    "abstract": "Comments: Long Paper Accepted in EMNLP 2021",
    "descriptor": "\nComments: Long Paper Accepted in EMNLP 2021\n",
    "authors": [
      "Tiezheng Yu",
      "Wenliang Dai",
      "Zihan Liu",
      "Pascale Fung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.02401"
  },
  {
    "id": "arXiv:2109.02894",
    "title": "Prescriptive Process Monitoring Under Resource Constraints: A Causal  Inference Approach",
    "abstract": "Prescriptive Process Monitoring Under Resource Constraints: A Causal  Inference Approach",
    "descriptor": "",
    "authors": [
      "Mahmoud Shoush",
      "Marlon Dumas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.02894"
  },
  {
    "id": "arXiv:2109.03866",
    "title": "Learning the hypotheses space from data through a U-curve algorithm",
    "abstract": "Comments: This is work is a merger of arXiv:2001.09532 and arXiv:2001.11578",
    "descriptor": "\nComments: This is work is a merger of arXiv:2001.09532 and arXiv:2001.11578\n",
    "authors": [
      "Diego Marcondes",
      "Adilson Simonis",
      "Junior Barrera"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03866"
  },
  {
    "id": "arXiv:2109.04813",
    "title": "TADA: Taxonomy Adaptive Domain Adaptation",
    "abstract": "Comments: 17 pages, 5 figures, 6 tables",
    "descriptor": "\nComments: 17 pages, 5 figures, 6 tables\n",
    "authors": [
      "Rui Gong",
      "Martin Danelljan",
      "Dengxin Dai",
      "Wenguan Wang",
      "Danda Pani Paudel",
      "Ajad Chhatkuli",
      "Fisher Yu",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04813"
  },
  {
    "id": "arXiv:2109.04947",
    "title": "Tiered Reasoning for Intuitive Physics: Toward Verifiable Commonsense  Language Understanding",
    "abstract": "Comments: Accepted to Findings of EMNLP 2021",
    "descriptor": "\nComments: Accepted to Findings of EMNLP 2021\n",
    "authors": [
      "Shane Storks",
      "Qiaozi Gao",
      "Yichi Zhang",
      "Joyce Chai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04947"
  },
  {
    "id": "arXiv:2109.05019",
    "title": "Spike2Vec: An Efficient and Scalable Embedding Approach for COVID-19  Spike Sequences",
    "abstract": "Spike2Vec: An Efficient and Scalable Embedding Approach for COVID-19  Spike Sequences",
    "descriptor": "",
    "authors": [
      "Sarwan Ali",
      "Murray Patterson"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.05019"
  },
  {
    "id": "arXiv:2109.05478",
    "title": "Single-Read Reconstruction for DNA Data Storage Using Transformers",
    "abstract": "Comments: 9 pages, 6 figures",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Yotam Nahum",
      "Eyar Ben-Tolila",
      "Leon Anavy"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2109.05478"
  },
  {
    "id": "arXiv:2109.06067",
    "title": "Pack Together: Entity and Relation Extraction with Levitated Marker",
    "abstract": "Pack Together: Entity and Relation Extraction with Levitated Marker",
    "descriptor": "",
    "authors": [
      "Deming Ye",
      "Yankai Lin",
      "Maosong Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06067"
  },
  {
    "id": "arXiv:2109.06099",
    "title": "Uniform Generalization Bounds for Overparameterized Neural Networks",
    "abstract": "Uniform Generalization Bounds for Overparameterized Neural Networks",
    "descriptor": "",
    "authors": [
      "Sattar Vakili",
      "Michael Bromberg",
      "Jezabel Garcia",
      "Da-shan Shiu",
      "Alberto Bernacchia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.06099"
  },
  {
    "id": "arXiv:2109.06163",
    "title": "On the Sins of Image Synthesis Loss for Self-supervised Depth Estimation",
    "abstract": "Comments: preprint",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Zhaoshuo Li",
      "Nathan Drenkow",
      "Hao Ding",
      "Andy S. Ding",
      "Alexander Lu",
      "Francis X. Creighton",
      "Russell H. Taylor",
      "Mathias Unberath"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.06163"
  },
  {
    "id": "arXiv:2109.06557",
    "title": "The concept of class invariant in object-oriented programming",
    "abstract": "Comments: Minor update (typos, formatting), 9 Oct.2021",
    "descriptor": "\nComments: Minor update (typos, formatting), 9 Oct.2021\n",
    "authors": [
      "Bertrand Meyer",
      "Alisa Arkadova",
      "Alexander Kogtenkov",
      "Alexandr Naumchev"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.06557"
  },
  {
    "id": "arXiv:2109.06762",
    "title": "Greenformer: Factorization Toolkit for Efficient Deep Neural Networks",
    "abstract": "Greenformer: Factorization Toolkit for Efficient Deep Neural Networks",
    "descriptor": "",
    "authors": [
      "Samuel Cahyawijaya",
      "Genta Indra Winata",
      "Holy Lovenia",
      "Bryan Wilie",
      "Wenliang Dai",
      "Etsuko Ishii",
      "Pascale Fung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06762"
  },
  {
    "id": "arXiv:2109.07785",
    "title": "MHFC: Multi-Head Feature Collaboration for Few-Shot Learning",
    "abstract": "Comments: Accepted by the 29th ACM International Conference on Multimedia (ACMMM) 2021",
    "descriptor": "\nComments: Accepted by the 29th ACM International Conference on Multimedia (ACMMM) 2021\n",
    "authors": [
      "Shuai Shao",
      "Lei Xing",
      "Yan Wang",
      "Rui Xu",
      "Chunyan Zhao",
      "Yan-Jiang Wang",
      "Bao-Di Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07785"
  },
  {
    "id": "arXiv:2109.07945",
    "title": "Lifting 2D Object Locations to 3D by Discounting LiDAR Outliers across  Objects and Views",
    "abstract": "Comments: ICRA 2022 submission",
    "descriptor": "\nComments: ICRA 2022 submission\n",
    "authors": [
      "Robert McCraith",
      "Eldar Insafutdinov",
      "Lukas Neumann",
      "Andrea Vedaldi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07945"
  },
  {
    "id": "arXiv:2109.08717",
    "title": "The Optimization of the Constant Flow Parallel Micropump Using RBF  Neural Network",
    "abstract": "Comments: Accepted to International Conference on Robotics and Automation Engineering (ICRAE), 2021",
    "descriptor": "\nComments: Accepted to International Conference on Robotics and Automation Engineering (ICRAE), 2021\n",
    "authors": [
      "Chenyang Ma",
      "Boyuan Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.08717"
  },
  {
    "id": "arXiv:2109.08789",
    "title": "When Similarity Digest Meets Vector Management System: A Survey on  Similarity Hash Function",
    "abstract": "When Similarity Digest Meets Vector Management System: A Survey on  Similarity Hash Function",
    "descriptor": "",
    "authors": [
      "Zhushou Tang",
      "Lingyi Tang",
      "Keying Tang",
      "Ruoying Tang"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.08789"
  },
  {
    "id": "arXiv:2109.08881",
    "title": "Fast User Adaptation for Human Motion Prediction in Physical Human-Robot  Interaction",
    "abstract": "Comments: To be published in IEEE Robotics and Automation Letters (RA-L)",
    "descriptor": "\nComments: To be published in IEEE Robotics and Automation Letters (RA-L)\n",
    "authors": [
      "Hee-Seung Moon",
      "Jiwon Seo"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.08881"
  },
  {
    "id": "arXiv:2109.08909",
    "title": "Measuring the rogue wave pattern triggered from Gaussian perturbations  by deep learning",
    "abstract": "Comments: 8 pages, 6 figures",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Liwen Zou",
      "XinHang Luo",
      "Delu Zeng",
      "Liming Ling",
      "Li-Chen Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.08909"
  },
  {
    "id": "arXiv:2109.08942",
    "title": "iWave3D: End-to-end Brain Image Compression with Trainable 3-D Wavelet  Transform",
    "abstract": "iWave3D: End-to-end Brain Image Compression with Trainable 3-D Wavelet  Transform",
    "descriptor": "",
    "authors": [
      "Dongmei Xue",
      "Haichuan Ma",
      "Li Li",
      "Dong Liu",
      "Zhiwei Xiong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2109.08942"
  },
  {
    "id": "arXiv:2109.09161",
    "title": "Wav-BERT: Cooperative Acoustic and Linguistic Representation Learning  for Low-Resource Speech Recognition",
    "abstract": "Wav-BERT: Cooperative Acoustic and Linguistic Representation Learning  for Low-Resource Speech Recognition",
    "descriptor": "",
    "authors": [
      "Guolin Zheng",
      "Yubei Xiao",
      "Ke Gong",
      "Pan Zhou",
      "Xiaodan Liang",
      "Liang Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2109.09161"
  },
  {
    "id": "arXiv:2109.09725",
    "title": "Model Bias in NLP -- Application to Hate Speech Classification using  transfer learning techniques",
    "abstract": "Comments: 13 pages, 7 figures",
    "descriptor": "\nComments: 13 pages, 7 figures\n",
    "authors": [
      "Aygul Zagidullina",
      "Georgios Patoulidis",
      "Jonas Bokstaller"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.09725"
  },
  {
    "id": "arXiv:2109.10601",
    "title": "Efficient Context-Aware Network for Abdominal Multi-organ Segmentation",
    "abstract": "Efficient Context-Aware Network for Abdominal Multi-organ Segmentation",
    "descriptor": "",
    "authors": [
      "Fan Zhang",
      "Yu Wang",
      "Hua Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.10601"
  },
  {
    "id": "arXiv:2109.11128",
    "title": "Peg solitaire and Conway's soldiers on infinite graphs",
    "abstract": "Comments: 12 pages, 5 figures; simplified the proof of Theorem 3.1",
    "descriptor": "\nComments: 12 pages, 5 figures; simplified the proof of Theorem 3.1\n",
    "authors": [
      "Valentino Vito"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2109.11128"
  },
  {
    "id": "arXiv:2109.11377",
    "title": "WRENCH: A Comprehensive Benchmark for Weak Supervision",
    "abstract": "Comments: NeurIPS 2021 Datasets and Benchmarks Track",
    "descriptor": "\nComments: NeurIPS 2021 Datasets and Benchmarks Track\n",
    "authors": [
      "Jieyu Zhang",
      "Yue Yu",
      "Yinghao Li",
      "Yujing Wang",
      "Yaming Yang",
      "Mao Yang",
      "Alexander Ratner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.11377"
  },
  {
    "id": "arXiv:2109.11902",
    "title": "Broccoli: Bug localization with the help of text search engines",
    "abstract": "Broccoli: Bug localization with the help of text search engines",
    "descriptor": "",
    "authors": [
      "Benjamin Ledel",
      "Steffen Herbold"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.11902"
  },
  {
    "id": "arXiv:2109.12077",
    "title": "The Mirror Langevin Algorithm Converges with Vanishing Bias",
    "abstract": "The Mirror Langevin Algorithm Converges with Vanishing Bias",
    "descriptor": "",
    "authors": [
      "Ruilin Li",
      "Molei Tao",
      "Santosh S. Vempala",
      "Andre Wibisono"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.12077"
  },
  {
    "id": "arXiv:2109.12459",
    "title": "Two Souls in an Adversarial Image: Towards Universal Adversarial Example  Detection using Multi-view Inconsistency",
    "abstract": "Two Souls in an Adversarial Image: Towards Universal Adversarial Example  Detection using Multi-view Inconsistency",
    "descriptor": "",
    "authors": [
      "Sohaib Kiani",
      "Sana Awan",
      "Chao Lan",
      "Fengjun Li",
      "Bo Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.12459"
  },
  {
    "id": "arXiv:2109.12584",
    "title": "Curb Your Carbon Emissions: Benchmarking Carbon Emissions in Machine  Translation",
    "abstract": "Curb Your Carbon Emissions: Benchmarking Carbon Emissions in Machine  Translation",
    "descriptor": "",
    "authors": [
      "Mirza Yusuf",
      "Praatibh Surana",
      "Gauri Gupta",
      "Krithika Ramesh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.12584"
  },
  {
    "id": "arXiv:2109.12685",
    "title": "Robust Coordination in Networks",
    "abstract": "Comments: 16 pages, 4 figures",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Laura Arditti",
      "Giacomo Como",
      "Fabio Fagnani",
      "Martina Vanelli"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.12685"
  },
  {
    "id": "arXiv:2109.13459",
    "title": "Multiwavelet-based Operator Learning for Differential Equations",
    "abstract": "Comments: 31 pages, 9 figures",
    "descriptor": "\nComments: 31 pages, 9 figures\n",
    "authors": [
      "Gaurav Gupta",
      "Xiongye Xiao",
      "Paul Bogdan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2109.13459"
  },
  {
    "id": "arXiv:2109.13705",
    "title": "Opportunistic Multi-Modal User Authentication for Health-Tracking IoT  Wearables",
    "abstract": "Comments: Accepted to publish in the 5th EAI International Conference on Safety and Security in Internet of Things (SaSeIoT 2021). (The previous version of this paper had an incorrect title due to a mistake. Aside from the title, all contents of this manuscript remain the same and match the version accepted at SaSeIoT 2021)",
    "descriptor": "\nComments: Accepted to publish in the 5th EAI International Conference on Safety and Security in Internet of Things (SaSeIoT 2021). (The previous version of this paper had an incorrect title due to a mistake. Aside from the title, all contents of this manuscript remain the same and match the version accepted at SaSeIoT 2021)\n",
    "authors": [
      "Alexa Muratyan",
      "William Cheung",
      "Sayanton V. Dibbo",
      "Sudip Vhaduri"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.13705"
  },
  {
    "id": "arXiv:2109.14062",
    "title": "Overage and Staleness Metrics for Status Update Systems",
    "abstract": "Overage and Staleness Metrics for Status Update Systems",
    "descriptor": "",
    "authors": [
      "Peng Zou",
      "Jin Zhang",
      "Xianglin Wei",
      "Suresh Subramaniam"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.14062"
  },
  {
    "id": "arXiv:2109.14147",
    "title": "Temporal Clustering with External Memory Network for Disease Progression  Modeling",
    "abstract": "Temporal Clustering with External Memory Network for Disease Progression  Modeling",
    "descriptor": "",
    "authors": [
      "Zicong Zhang",
      "Changchang Yin",
      "Ping Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.14147"
  },
  {
    "id": "arXiv:2109.14579",
    "title": "A secure home automation prototype built on raspberry-pi",
    "abstract": "A secure home automation prototype built on raspberry-pi",
    "descriptor": "",
    "authors": [
      "Arya Tanmay Gupta",
      "Himani Gupta",
      "Muskan Sharma",
      "Priyanka Khanna"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.14579"
  },
  {
    "id": "arXiv:2109.14589",
    "title": "Double framed moduli spaces of quiver representations",
    "abstract": "Comments: 27 pages",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Marco Armenta",
      "Thomas Br\u00fcstle",
      "Souheila Hassoun",
      "Markus Reineke"
    ],
    "subjectives": [
      "Representation Theory (math.RT)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2109.14589"
  },
  {
    "id": "arXiv:2109.14604",
    "title": "Fast B4B: Fast BFT for Blockchains",
    "abstract": "Comments: (\"Patent Pending\")",
    "descriptor": "\nComments: (\"Patent Pending\")\n",
    "authors": [
      "Mohammad M. Jalalzai",
      "Chen Feng",
      "Victoria Lemieux"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.14604"
  },
  {
    "id": "arXiv:2109.14776",
    "title": "Measuring Sentence-Level and Aspect-Level (Un)certainty in Science  Communications",
    "abstract": "Comments: EMNLP 2021 Main Conference",
    "descriptor": "\nComments: EMNLP 2021 Main Conference\n",
    "authors": [
      "Jiaxin Pei",
      "David Jurgens"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2109.14776"
  },
  {
    "id": "arXiv:2109.14844",
    "title": "LIFE: Learning Individual Features for Multivariate Time Series  Prediction with Missing Values",
    "abstract": "LIFE: Learning Individual Features for Multivariate Time Series  Prediction with Missing Values",
    "descriptor": "",
    "authors": [
      "Zhao-Yu Zhang",
      "Shao-Qun Zhang",
      "Yuan Jiang",
      "Zhi-Hua Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.14844"
  },
  {
    "id": "arXiv:2109.14900",
    "title": "Impact of Channel Variation on One-Class Learning for Spoof Detection",
    "abstract": "Impact of Channel Variation on One-Class Learning for Spoof Detection",
    "descriptor": "",
    "authors": [
      "Rohit Arora",
      "Aanchan Mohan",
      "Saket Anand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2109.14900"
  },
  {
    "id": "arXiv:2109.15111",
    "title": "SsAG: Summarization and sparsification of Attributed Graphs",
    "abstract": "SsAG: Summarization and sparsification of Attributed Graphs",
    "descriptor": "",
    "authors": [
      "Muhammad Ahmad",
      "Maham Anwer Beg",
      "Imdadullah Khan",
      "Arif Zaman",
      "Muhammad Asad Khan"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2109.15111"
  },
  {
    "id": "arXiv:2109.15136",
    "title": "Transfer Learning Based Multi-Objective Genetic Algorithm for Dynamic  Community Detection",
    "abstract": "Comments: 40 pages, 11 figures, 8 tables",
    "descriptor": "\nComments: 40 pages, 11 figures, 8 tables\n",
    "authors": [
      "Jungang Zou",
      "Fan Lin",
      "Siyu Gao",
      "Gaoshan Deng",
      "Wenhua Zeng",
      "Gil Alterovitz"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.15136"
  },
  {
    "id": "arXiv:2109.15242",
    "title": "Transferability Estimation for Semantic Segmentation Task",
    "abstract": "Comments: It is a very early draft before the formal paper, so there may exist many typos or descriptions needing to be further improved. We will keep updating this manuscript",
    "descriptor": "\nComments: It is a very early draft before the formal paper, so there may exist many typos or descriptions needing to be further improved. We will keep updating this manuscript\n",
    "authors": [
      "Yang Tan",
      "Yang Li",
      "Shao-Lun Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.15242"
  },
  {
    "id": "arXiv:2109.15317",
    "title": "Unsupervised Few-Shot Action Recognition via Action-Appearance Aligned  Meta-Adaptation",
    "abstract": "Comments: ICCV 2021 (Oral)",
    "descriptor": "\nComments: ICCV 2021 (Oral)\n",
    "authors": [
      "Jay Patravali",
      "Gaurav Mittal",
      "Ye Yu",
      "Fuxin Li",
      "Mei Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.15317"
  },
  {
    "id": "arXiv:2110.00116",
    "title": "#ContextMatters: Advantages and Limitations of Using Machine Learning to  Support Women in Politics",
    "abstract": "Comments: 21 pages, 1 figure. Presented as Policy and Practice, Problem Pitches poster at EAAMO'21",
    "descriptor": "\nComments: 21 pages, 1 figure. Presented as Policy and Practice, Problem Pitches poster at EAAMO'21\n",
    "authors": [
      "Jacqueline Comer",
      "Sam Work",
      "Kory W Mathewson",
      "Lana Cuthbertson",
      "Kasey Machin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.00116"
  },
  {
    "id": "arXiv:2110.00210",
    "title": "Unsupervised Belief Representation Learning in Polarized Networks with  Information-Theoretic Variational Graph Auto-Encoders",
    "abstract": "Unsupervised Belief Representation Learning in Polarized Networks with  Information-Theoretic Variational Graph Auto-Encoders",
    "descriptor": "",
    "authors": [
      "Jinning Li",
      "Huajie Shao",
      "Dachun Sun",
      "Ruijie Wang",
      "Yuchen Yan",
      "Jinyang Li",
      "Shengzhong Liu",
      "Hanghang Tong",
      "Tarek Abdelzaher"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.00210"
  },
  {
    "id": "arXiv:2110.00218",
    "title": "On the Importance of Gradients for Detecting Distributional Shifts in  the Wild",
    "abstract": "Comments: Accepted in NeurIPS 2021",
    "descriptor": "\nComments: Accepted in NeurIPS 2021\n",
    "authors": [
      "Rui Huang",
      "Andrew Geng",
      "Yixuan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.00218"
  },
  {
    "id": "arXiv:2110.00452",
    "title": "SAM: A Self-adaptive Attention Module for Context-Aware Recommendation  System",
    "abstract": "Comments: We find some errors in the article",
    "descriptor": "\nComments: We find some errors in the article\n",
    "authors": [
      "Jiabin Liu",
      "Zheng Wei",
      "Zhengpin Li",
      "Xiaojun Mao",
      "Jian Wang",
      "Zhongyu Wei",
      "Qi Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.00452"
  },
  {
    "id": "arXiv:2110.00539",
    "title": "Applying Differential Privacy to Tensor Completion",
    "abstract": "Comments: We find some errors in the article",
    "descriptor": "\nComments: We find some errors in the article\n",
    "authors": [
      "Zheng Wei",
      "Zhengpin Li",
      "Xiaojun Mao",
      "Jian Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.00539"
  },
  {
    "id": "arXiv:2110.00578",
    "title": "SMATE: Semi-Supervised Spatio-Temporal Representation Learning on  Multivariate Time Series",
    "abstract": "Comments: Accepted by ICDM 2021",
    "descriptor": "\nComments: Accepted by ICDM 2021\n",
    "authors": [
      "Jingwei Zuo",
      "Karine Zeitouni",
      "Yehia Taher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.00578"
  },
  {
    "id": "arXiv:2110.00719",
    "title": "One-Bit Matrix Completion with Differential Privacy",
    "abstract": "Comments: We find some errors in the article",
    "descriptor": "\nComments: We find some errors in the article\n",
    "authors": [
      "Zhengpin Li",
      "Zheng Wei",
      "Xiaojun Mao",
      "Jian Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.00719"
  },
  {
    "id": "arXiv:2110.00755",
    "title": "Explainable Event Recognition",
    "abstract": "Comments: 16 pages, 10 figures, 6 tables",
    "descriptor": "\nComments: 16 pages, 10 figures, 6 tables\n",
    "authors": [
      "Imran Khan",
      "Kashif Ahmad",
      "Namra Gul",
      "Talhat Khan",
      "Nasir Ahmad",
      "Ala Al-Fuqaha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.00755"
  },
  {
    "id": "arXiv:2110.00809",
    "title": "Classifying COVID-19 Spike Sequences from Geographic Location Using Deep  Learning",
    "abstract": "Classifying COVID-19 Spike Sequences from Geographic Location Using Deep  Learning",
    "descriptor": "",
    "authors": [
      "Sarwan Ali",
      "Babatunde Bello",
      "Murray Patterson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2110.00809"
  },
  {
    "id": "arXiv:2110.00918",
    "title": "Does deep learning model calibration improve performance in  class-imbalanced medical image classification?",
    "abstract": "Comments: 34 pages, 21 figures, and 10 tables",
    "descriptor": "\nComments: 34 pages, 21 figures, and 10 tables\n",
    "authors": [
      "Sivaramakrishnan Rajaraman",
      "Prasanth Ganesan",
      "Sameer Antani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.00918"
  },
  {
    "id": "arXiv:2110.00949",
    "title": "Unsupervised paradigm for information extraction from transcripts using  BERT",
    "abstract": "Unsupervised paradigm for information extraction from transcripts using  BERT",
    "descriptor": "",
    "authors": [
      "Aravind Chandramouli",
      "Siddharth Shukla",
      "Neeti Nair",
      "Shiven Purohit",
      "Shubham Pandey",
      "Murali Mohana Krishna Dandu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.00949"
  },
  {
    "id": "arXiv:2110.00957",
    "title": "Graph Representation Learning for Spatial Image Steganalysis",
    "abstract": "Comments: this https URL&hl=en",
    "descriptor": "\nComments: this https URL&hl=en\n",
    "authors": [
      "Qiyun Liu",
      "Hanzhou Wu"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.00957"
  },
  {
    "id": "arXiv:2110.01096",
    "title": "Fast algorithm to identify cluster synchrony through fibration  symmetries in large information-processing networks",
    "abstract": "Comments: 13 pages, 7 figures",
    "descriptor": "\nComments: 13 pages, 7 figures\n",
    "authors": [
      "Higor S. Monteiro",
      "Ian Leifer",
      "Saulo D. S. Reis",
      "Jos\u00e9 S. Andrade, Jr.",
      "Hernan A. Makse"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2110.01096"
  },
  {
    "id": "arXiv:2110.01150",
    "title": "Spiked Covariance Estimation from Modulo-Reduced Measurements",
    "abstract": "Spiked Covariance Estimation from Modulo-Reduced Measurements",
    "descriptor": "",
    "authors": [
      "Elad Romanov",
      "Or Ordentlich"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.01150"
  },
  {
    "id": "arXiv:2110.01177",
    "title": "The Second DiCOVA Challenge: Dataset and performance analysis for  COVID-19 diagnosis using acoustics",
    "abstract": "The Second DiCOVA Challenge: Dataset and performance analysis for  COVID-19 diagnosis using acoustics",
    "descriptor": "",
    "authors": [
      "Neeraj Kumar Sharma",
      "Srikanth Raj Chetupalli",
      "Debarpan Bhattacharya",
      "Debottam Dutta",
      "Pravin Mote",
      "Sriram Ganapathy"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2110.01177"
  },
  {
    "id": "arXiv:2110.01240",
    "title": "A free lunch from ViT:Adaptive Attention Multi-scale Fusion Transformer  for Fine-grained Visual Recognition",
    "abstract": "A free lunch from ViT:Adaptive Attention Multi-scale Fusion Transformer  for Fine-grained Visual Recognition",
    "descriptor": "",
    "authors": [
      "Yuan Zhang",
      "Jian Cao",
      "Ling Zhang",
      "Xiangcheng Liu",
      "Zhiyi Wang",
      "Feng Ling",
      "Weiqian Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.01240"
  },
  {
    "id": "arXiv:2110.01595",
    "title": "Solon: Communication-efficient Byzantine-resilient Distributed Training  via Redundant Gradients",
    "abstract": "Solon: Communication-efficient Byzantine-resilient Distributed Training  via Redundant Gradients",
    "descriptor": "",
    "authors": [
      "Lingjiao Chen",
      "Leshang Chen",
      "Hongyi Wang",
      "Susan Davidson",
      "Edgar Dobriban"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.01595"
  },
  {
    "id": "arXiv:2110.01763",
    "title": "DNSMOS P.835: A Non-Intrusive Perceptual Objective Speech Quality Metric  to Evaluate Noise Suppressors",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2010.15258",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2010.15258\n",
    "authors": [
      "Chandan K A Reddy",
      "Vishak Gopal",
      "Ross Cutler"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.01763"
  },
  {
    "id": "arXiv:2110.01770",
    "title": "Procedure Planning in Instructional Videos via Contextual Modeling and  Model-based Policy Learning",
    "abstract": "Comments: ICCV 2021 Oral",
    "descriptor": "\nComments: ICCV 2021 Oral\n",
    "authors": [
      "Jing Bi",
      "Jiebo Luo",
      "Chenliang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.01770"
  },
  {
    "id": "arXiv:2110.01805",
    "title": "Self-Supervised Learning of Perceptually Optimized Block Motion  Estimates for Video Compression",
    "abstract": "Self-Supervised Learning of Perceptually Optimized Block Motion  Estimates for Video Compression",
    "descriptor": "",
    "authors": [
      "Somdyuti Paul",
      "Andrey Norkin",
      "Alan C. Bovik"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.01805"
  },
  {
    "id": "arXiv:2110.02008",
    "title": "Lifted Reed-Solomon Codes and Lifted Multiplicity Codes",
    "abstract": "Comments: The results on lifted RS codes have partially been presented at the IEEE International Symposium on Information Theory (ISIT) 2020 (arXiv:2001.11981) and parts of the results on lifted multiplicity codes have been presented at the IEEE Information Theory Workshop (ITW) 2020 (arXiv:2008.04717)",
    "descriptor": "\nComments: The results on lifted RS codes have partially been presented at the IEEE International Symposium on Information Theory (ISIT) 2020 (arXiv:2001.11981) and parts of the results on lifted multiplicity codes have been presented at the IEEE Information Theory Workshop (ITW) 2020 (arXiv:2008.04717)\n",
    "authors": [
      "Lukas Holzbaur",
      "Rina Polyanskaya",
      "Nikita Polyanskii",
      "Ilya Vorobyev",
      "Eitan Yaakobi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.02008"
  },
  {
    "id": "arXiv:2110.02102",
    "title": "CARL: A Benchmark for Contextual and Adaptive Reinforcement Learning",
    "abstract": "CARL: A Benchmark for Contextual and Adaptive Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Carolin Benjamins",
      "Theresa Eimer",
      "Frederik Schubert",
      "Andr\u00e9 Biedenkapp",
      "Bodo Rosenhahn",
      "Frank Hutter",
      "Marius Lindauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02102"
  },
  {
    "id": "arXiv:2110.02345",
    "title": "Unsupervised Speech Segmentation and Variable Rate Representation  Learning using Segmental Contrastive Predictive Coding",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2106.02170",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2106.02170\n",
    "authors": [
      "Saurabhchand Bhati",
      "Jes\u00fas Villalba",
      "Piotr \u017belasko",
      "Laureano Moro-Velazquez",
      "Najim Dehak"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.02345"
  },
  {
    "id": "arXiv:2110.02551",
    "title": "A Review of Computer Vision Technologies for Fish Tracking",
    "abstract": "Comments: 24 Pages, 10 Figures, 4 Tables",
    "descriptor": "\nComments: 24 Pages, 10 Figures, 4 Tables\n",
    "authors": [
      "Zhenbo Li",
      "Weiran Li",
      "Fei Li",
      "Meng Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.02551"
  },
  {
    "id": "arXiv:2110.02642",
    "title": "Anomaly Transformer: Time Series Anomaly Detection with Association  Discrepancy",
    "abstract": "Anomaly Transformer: Time Series Anomaly Detection with Association  Discrepancy",
    "descriptor": "",
    "authors": [
      "Jiehui Xu",
      "Haixu Wu",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02642"
  },
  {
    "id": "arXiv:2110.02797",
    "title": "Adversarial Robustness Comparison of Vision Transformer and MLP-Mixer to  CNNs",
    "abstract": "Comments: Code: this https URL",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Philipp Benz",
      "Soomin Ham",
      "Chaoning Zhang",
      "Adil Karjauv",
      "In So Kweon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02797"
  },
  {
    "id": "arXiv:2110.02914",
    "title": "Foolish Crowds Support Benign Overfitting",
    "abstract": "Foolish Crowds Support Benign Overfitting",
    "descriptor": "",
    "authors": [
      "Niladri S. Chatterji",
      "Philip M. Long"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.02914"
  },
  {
    "id": "arXiv:2110.03020",
    "title": "Efficient Methods for Online Multiclass Logistic Regression",
    "abstract": "Efficient Methods for Online Multiclass Logistic Regression",
    "descriptor": "",
    "authors": [
      "Naman Agarwal",
      "Satyen Kale",
      "Julian Zimmert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.03020"
  },
  {
    "id": "arXiv:2110.03103",
    "title": "Lightweight Speech Enhancement in Unseen Noisy and Reverberant  Conditions using KISS-GEV Beamforming",
    "abstract": "Lightweight Speech Enhancement in Unseen Noisy and Reverberant  Conditions using KISS-GEV Beamforming",
    "descriptor": "",
    "authors": [
      "Thomas Bernard",
      "Fran\u00e7ois Grondin"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.03103"
  },
  {
    "id": "arXiv:2110.03170",
    "title": "TreeGCN-ED: Encoding Point Cloud using a Tree-Structured Graph Network",
    "abstract": "TreeGCN-ED: Encoding Point Cloud using a Tree-Structured Graph Network",
    "descriptor": "",
    "authors": [
      "Prajwal Singh",
      "Kaustubh Sadekar",
      "Shanmuganathan Raman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03170"
  },
  {
    "id": "arXiv:2110.03173",
    "title": "Multi-objective Optimization by Learning Space Partitions",
    "abstract": "Multi-objective Optimization by Learning Space Partitions",
    "descriptor": "",
    "authors": [
      "Yiyang Zhao",
      "Linnan Wang",
      "Kevin Yang",
      "Tianjun Zhang",
      "Tian Guo",
      "Yuandong Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.03173"
  },
  {
    "id": "arXiv:2110.03179",
    "title": "HowSumm: A Multi-Document Summarization Dataset Derived from WikiHow  Articles",
    "abstract": "Comments: 8 pages, 4 figures, 5 tables. HowSumm dataset is publicly available at \\url{this https URL}",
    "descriptor": "\nComments: 8 pages, 4 figures, 5 tables. HowSumm dataset is publicly available at \\url{this https URL}\n",
    "authors": [
      "Odellia Boni",
      "Guy Feigenblat",
      "Guy Lev",
      "Michal Shmueli-Scheuer",
      "Benjamin Sznajder",
      "David Konopnicki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.03179"
  },
  {
    "id": "arXiv:2110.03183",
    "title": "Large Scale Audio Understanding without Transformers/ Convolutions/  BERTs/ Mixers/ Attention/ RNNs or ....",
    "abstract": "Comments: ICASPP 2022; Singapore",
    "descriptor": "\nComments: ICASPP 2022; Singapore\n",
    "authors": [
      "Prateek Verma"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.03183"
  },
  {
    "id": "arXiv:2110.03242",
    "title": "On the asymptotical regularization with convex constraints for inverse  problems",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Min Zhong",
      "Wei Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.03242"
  },
  {
    "id": "arXiv:2110.03342",
    "title": "VisualTTS: TTS with Accurate Lip-Speech Synchronization for Automatic  Voice Over",
    "abstract": "Comments: Submitted to ICASSP 2022",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Junchen Lu",
      "Berrak Sisman",
      "Rui Liu",
      "Mingyang Zhang",
      "Haizhou Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.03342"
  },
  {
    "id": "arXiv:2110.03413",
    "title": "Curved Markov Chain Monte Carlo for Network Learning",
    "abstract": "Comments: 12 pages, 5 figures. To appear in Studies in Computational Intelligence: Proceedings of The 10th International Conference on Complex Networks and Their Applications (2021)",
    "descriptor": "\nComments: 12 pages, 5 figures. To appear in Studies in Computational Intelligence: Proceedings of The 10th International Conference on Complex Networks and Their Applications (2021)\n",
    "authors": [
      "John Sigbeku",
      "Emil Saucan",
      "Anthea Monod"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.03413"
  },
  {
    "id": "arXiv:2110.03609",
    "title": "Applying Phonological Features in Multilingual Text-To-Speech",
    "abstract": "Comments: demo webpage: this https URL",
    "descriptor": "\nComments: demo webpage: this https URL\n",
    "authors": [
      "Cong Zhang",
      "Huinan Zeng",
      "Huang Liu",
      "Jiewen Zheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.03609"
  },
  {
    "id": "arXiv:2110.03633",
    "title": "Regression markets and application to energy forecasting",
    "abstract": "Regression markets and application to energy forecasting",
    "descriptor": "",
    "authors": [
      "Pierre Pinson",
      "Liyang Han",
      "Jalal Kazempour"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.03633"
  },
  {
    "id": "arXiv:2110.03761",
    "title": "A simple equivariant machine learning method for dynamics based on  scalars",
    "abstract": "A simple equivariant machine learning method for dynamics based on  scalars",
    "descriptor": "",
    "authors": [
      "Weichi Yao",
      "Kate Storey-Fisher",
      "David W. Hogg",
      "Soledad Villar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03761"
  },
  {
    "id": "arXiv:2110.03765",
    "title": "Food Science Spectroscopy Model Training: Improving Data Efficiency  Using Active Learning and Semi-Supervised Learning",
    "abstract": "Food Science Spectroscopy Model Training: Improving Data Efficiency  Using Active Learning and Semi-Supervised Learning",
    "descriptor": "",
    "authors": [
      "Huanle Zhang",
      "Nicharee Wisuthiphaet",
      "Hemiao Cui",
      "Nitin Nitin",
      "Xin Liu",
      "Qing Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03765"
  },
  {
    "id": "arXiv:2110.03860",
    "title": "Token Pooling in Vision Transformers",
    "abstract": "Token Pooling in Vision Transformers",
    "descriptor": "",
    "authors": [
      "Dmitrii Marin",
      "Jen-Hao Rick Chang",
      "Anurag Ranjan",
      "Anish Prabhu",
      "Mohammad Rastegari",
      "Oncel Tuzel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03860"
  },
  {
    "id": "arXiv:2110.03873",
    "title": "Representation of professions in entertainment media: Insights into  frequency and sentiment trends through computational text analysis",
    "abstract": "Comments: 27 pages, 15 figures",
    "descriptor": "\nComments: 27 pages, 15 figures\n",
    "authors": [
      "Sabyasachee Baruah",
      "Krishna Somandepalli",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03873"
  },
  {
    "id": "arXiv:2110.03887",
    "title": "Environment Aware Text-to-Speech Synthesis",
    "abstract": "Comments: Submitted to ICASSP 2022",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Daxin Tan",
      "Guangyan Zhang",
      "Tan Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.03887"
  },
  {
    "id": "arXiv:2110.03997",
    "title": "Multi Proxy Anchor Loss and Effectiveness of Deep Metric Learning  Performance Metrics",
    "abstract": "Multi Proxy Anchor Loss and Effectiveness of Deep Metric Learning  Performance Metrics",
    "descriptor": "",
    "authors": [
      "Shozo Saeki",
      "Minoru Kawahara",
      "Hirohisa Aman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03997"
  },
  {
    "id": "arXiv:2110.04153",
    "title": "Cross-speaker Emotion Transfer Based on Speaker Condition Layer  Normalization and Semi-Supervised Training in Text-To-Speech",
    "abstract": "Comments: Submitted to ICASSP 2022, 5 pages,2 figures",
    "descriptor": "\nComments: Submitted to ICASSP 2022, 5 pages,2 figures\n",
    "authors": [
      "Pengfei Wu",
      "Junjie Pan",
      "Chenchang Xu",
      "Junhui Zhang",
      "Lin Wu",
      "Xiang Yin",
      "Zejun Ma"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04153"
  }
]
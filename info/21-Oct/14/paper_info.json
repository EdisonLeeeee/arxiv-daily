[
  {
    "id": "arXiv:2110.06209",
    "title": "An Introduction to Automatic Differentiation forMachine Learning",
    "abstract": "Machine learning and neural network models in particular have been improving\nthe state of the art performance on many artificial intelligence related tasks.\nNeural network models are typically implemented using frameworks that perform\ngradient based optimization methods to fit a model to a dataset. These\nframeworks use a technique of calculating derivatives called automatic\ndifferentiation (AD) which removes the burden of performing derivative\ncalculations from the model designer. In this report we describe AD, its\nmotivations, and different implementation approaches. We briefly describe\ndataflow programming as it relates to AD. Lastly, we present example programs\nthat are implemented with Tensorflow and PyTorch, which are two commonly used\nAD frameworks.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Davan Harrison"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Mathematical Software (cs.MS)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2110.06209"
  },
  {
    "id": "arXiv:2110.06211",
    "title": "Diagonalizing Against Polynomial-Time Bounded Turing Machines Via  Nondeterministic Turing Machine",
    "abstract": "The diagonalization technique was invented by Cantor to show that there are\nmore real numbers than algebraic numbers, and is very important in computer\nscience. In this work, we enumerate all polynomial-time deterministic Turing\nmachines and diagonalize over all of them by using an universal\nnondeterministic Turing machine. We obtain that there is a language $L_d$\nrejected by all polynomial-time deterministic Turing machines but accepted by a\nnondeterministic Turing machine.",
    "descriptor": "\nComments: A preliminary report. 7 pages. arXiv admin note: substantial text overlap with arXiv:2110.05942\n",
    "authors": [
      "Tianrong Lin"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.06211"
  },
  {
    "id": "arXiv:2110.06212",
    "title": "Global Convergence of Triangularized Orthogonalization-free Method",
    "abstract": "This paper proves the global convergence of a triangularized\northogonalization-free method (TriOFM). TriOFM, in general, applies a\ntriangularization idea to the gradient of an objective function and removes the\nrotation invariance in minimizers. More precisely, in this paper, the TriOFM\nworks as an eigensolver for sizeable sparse matrices and obtains eigenvectors\nwithout any orthogonalization step. Due to the triangularization, the iteration\nis a discrete-time flow in a non-conservative vector field. The global\nconvergence relies on the stable manifold theorem, whereas the convergence to\nstationary points is proved in detail in this paper. We provide two proofs\ninspired by the noisy power method and the noisy optimization method,\nrespectively.",
    "descriptor": "",
    "authors": [
      "Weiguo Gao",
      "Yingzhou Li",
      "Bichen Lu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.06212"
  },
  {
    "id": "arXiv:2110.06215",
    "title": "A Cross-Platform Benchmark for Interval Computation Libraries",
    "abstract": "Interval computation is widely used to certify computations that use floating\npoint operations to avoid pitfalls related to rounding error introduced by\ninaccurate operations. Despite its popularity and practical benefits, support\nfor interval arithmetic is not standardized nor available in mainstream\nprogramming languages. We propose the first benchmark for interval\ncomputations, coupled with reference solutions computed with exact arithmetic,\nand compare popular C and C++ libraries over different architectures, operating\nsystems, and compilers. The benchmark allows identifying limitations in\nexisting implementations, and provides a reliable guide on which library to use\non each system. We believe that our benchmark will be useful for developers of\nfuture interval libraries, as a way to test the correctness and performance of\ntheir algorithms.",
    "descriptor": "\nComments: 11 pages, 33 figures, 2 tables\n",
    "authors": [
      "Xuan Tang",
      "Zachary Ferguson",
      "Teseo Schneider",
      "Denis Zorin",
      "Shoaib Kamil",
      "Daniele Panozzo"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2110.06215"
  },
  {
    "id": "arXiv:2110.06223",
    "title": "Investigating the Effect of Natural Language Explanations on  Out-of-Distribution Generalization in Few-shot NLI",
    "abstract": "Although neural models have shown strong performance in datasets such as\nSNLI, they lack the ability to generalize out-of-distribution (OOD). In this\nwork, we formulate a few-shot learning setup and examine the effects of natural\nlanguage explanations on OOD generalization. We leverage the templates in the\nHANS dataset and construct templated natural language explanations for each\ntemplate. Although generated explanations show competitive BLEU scores against\ngroundtruth explanations, they fail to improve prediction performance. We\nfurther show that generated explanations often hallucinate information and miss\nkey elements that indicate the label.",
    "descriptor": "\nComments: 8 pages, 4 figures, EMNLPWorkshop on Insights from Negative Results in NLP 2021, data is available at this https URL\n",
    "authors": [
      "Yangqiaoyu Zhou",
      "Chenhao Tan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06223"
  },
  {
    "id": "arXiv:2110.06241",
    "title": "Molecular Graph Generation via Geometric Scattering",
    "abstract": "Graph neural networks (GNNs) have been used extensively for addressing\nproblems in drug design and discovery. Both ligand and target molecules are\nrepresented as graphs with node and edge features encoding information about\natomic elements and bonds respectively. Although existing deep learning models\nperform remarkably well at predicting physicochemical properties and binding\naffinities, the generation of new molecules with optimized properties remains\nchallenging. Inherently, most GNNs perform poorly in whole-graph representation\ndue to the limitations of the message-passing paradigm. Furthermore,\nstep-by-step graph generation frameworks that use reinforcement learning or\nother sequential processing can be slow and result in a high proportion of\ninvalid molecules with substantial post-processing needed in order to satisfy\nthe principles of stoichiometry. To address these issues, we propose a\nrepresentation-first approach to molecular graph generation. We guide the\nlatent representation of an autoencoder by capturing graph structure\ninformation with the geometric scattering transform and apply penalties that\nstructure the representation also by molecular properties. We show that this\nhighly structured latent space can be directly used for molecular graph\ngeneration by the use of a GAN. We demonstrate that our architecture learns\nmeaningful representations of drug datasets and provides a platform for\ngoal-directed drug synthesis.",
    "descriptor": "",
    "authors": [
      "Dhananjay Bhaskar",
      "Jackson D. Grady",
      "Michael A. Perlmutter",
      "Smita Krishnaswamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06241"
  },
  {
    "id": "arXiv:2110.06253",
    "title": "StateAFL: Greybox Fuzzing for Stateful Network Servers",
    "abstract": "Fuzzing network servers is a technical challenge, since the behavior of the\ntarget server depends on its state over a sequence of multiple messages.\nExisting solutions are costly and difficult to use, as they rely on\nmanually-customized artifacts such as protocol models, protocol parsers, and\nlearning frameworks. The aim of this work is to develop a greybox fuzzer for\nnetwork servers that only relies on lightweight analysis of the target program,\nwith no manual customization, in a similar way to what the AFL fuzzer achieved\nfor stateless programs. The proposed fuzzer instruments the target server at\ncompile-time, to insert probes on memory allocations and network I/O\noperations. At run-time, it infers the current protocol state of the target by\nanalyzing snapshots of long-lived memory areas, and incrementally builds a\nprotocol state machine for guiding fuzzing. The experimental results show that\nthe fuzzer can be applied with no manual customization on a large set of\nnetwork servers for popular protocols, and that it can achieve comparable, or\neven better code coverage than customized fuzzing. Moreover, our qualitative\nanalysis shows that states inferred from memory better reflect the server\nbehavior than only using response codes from messages.",
    "descriptor": "\nComments: The tool is available at this https URL\n",
    "authors": [
      "Roberto Natella"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Operating Systems (cs.OS)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.06253"
  },
  {
    "id": "arXiv:2110.06255",
    "title": "Not all noise is accounted equally: How differentially private learning  benefits from large sampling rates",
    "abstract": "Learning often involves sensitive data and as such, privacy preserving\nextensions to Stochastic Gradient Descent (SGD) and other machine learning\nalgorithms have been developed using the definitions of Differential Privacy\n(DP). In differentially private SGD, the gradients computed at each training\niteration are subject to two different types of noise. Firstly, inherent\nsampling noise arising from the use of minibatches. Secondly, additive Gaussian\nnoise from the underlying mechanisms that introduce privacy. In this study, we\nshow that these two types of noise are equivalent in their effect on the\nutility of private neural networks, however they are not accounted for equally\nin the privacy budget. Given this observation, we propose a training paradigm\nthat shifts the proportions of noise towards less inherent and more additive\nnoise, such that more of the overall noise can be accounted for in the privacy\nbudget. With this paradigm, we are able to improve on the state-of-the-art in\nthe privacy/utility tradeoff of private end-to-end CNNs.",
    "descriptor": "\nComments: 2021 IEEE International Workshop on Machine Learning for Signal Processing (MLSP)\n",
    "authors": [
      "Friedrich D\u00f6rmann",
      "Osvald Frisk",
      "Lars N\u00f8rvang Andersen",
      "Christian Fischer Pedersen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.06255"
  },
  {
    "id": "arXiv:2110.06256",
    "title": "On Convergence of Training Loss Without Reaching Stationary Points",
    "abstract": "It is a well-known fact that nonconvex optimization is computationally\nintractable in the worst case. As a result, theoretical analysis of\noptimization algorithms such as gradient descent often focuses on local\nconvergence to stationary points where the gradient norm is zero or negligible.\nIn this work, we examine the disconnect between the existing theoretical\nanalysis of gradient-based algorithms and actual practice. Specifically, we\nprovide numerical evidence that in large-scale neural network training, such as\nin ImageNet, ResNet, and WT103 + TransformerXL models, the Neural Network\nweight variables do not converge to stationary points where the gradient of the\nloss function vanishes. Remarkably, however, we observe that while weights do\nnot converge to stationary points, the value of the loss function converges.\nInspired by this observation, we propose a new perspective based on ergodic\ntheory of dynamical systems. We prove convergence of the distribution of weight\nvalues to an approximate invariant measure (without smoothness assumptions)\nthat explains this phenomenon. We further discuss how this perspective can\nbetter align the theory with empirical observations.",
    "descriptor": "",
    "authors": [
      "Jingzhao Zhang",
      "Haochuan Li",
      "Suvrit Sra",
      "Ali Jadbabaie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06256"
  },
  {
    "id": "arXiv:2110.06257",
    "title": "Causal discovery from conditionally stationary time-series",
    "abstract": "Causal discovery, i.e., inferring underlying cause-effect relationships from\nobservations of a scene or system, is an inherent mechanism in human cognition,\nbut has been shown to be highly challenging to automate. The majority of\napproaches in the literature aiming for this task consider constrained\nscenarios with fully observed variables or data from stationary time-series. In\nthis work we aim for causal discovery in a more general class of scenarios,\nscenes with non-stationary behavior over time. For our purposes we here regard\na scene as a composition objects interacting with each other over time.\nNon-stationarity is modeled as stationarity conditioned on an underlying\nvariable, a state, which can be of varying dimension, more or less hidden given\nobservations of the scene, and also depend more or less directly on these\nobservations. We propose a probabilistic deep learning approach called\nState-Dependent Causal Inference (SDCI) for causal discovery in such\nconditionally stationary time-series data. Results in two different synthetic\nscenarios show that this method is able to recover the underlying causal\ndependencies with high accuracy even in cases with hidden states.",
    "descriptor": "",
    "authors": [
      "Carles Balsells Rodas",
      "Ruibo Tu",
      "Hedvig Kjellstrom"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06257"
  },
  {
    "id": "arXiv:2110.06263",
    "title": "Speech Summarization using Restricted Self-Attention",
    "abstract": "Speech summarization is typically performed by using a cascade of speech\nrecognition and text summarization models. End-to-end modeling of speech\nsummarization models is challenging due to memory and compute constraints\narising from long input audio sequences. Recent work in document summarization\nhas inspired methods to reduce the complexity of self-attentions, which enables\ntransformer models to handle long sequences. In this work, we introduce a\nsingle model optimized end-to-end for speech summarization. We apply the\nrestricted self-attention technique from text-based models to speech models to\naddress the memory and compute constraints. We demonstrate that the proposed\nmodel learns to directly summarize speech for the How-2 corpus of instructional\nvideos. The proposed end-to-end model outperforms the previously proposed\ncascaded model by 3 points absolute on ROUGE. Further, we consider the spoken\nlanguage understanding task of predicting concepts from speech inputs and show\nthat the proposed end-to-end model outperforms the cascade model by 4 points\nabsolute F-1.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Roshan Sharma",
      "Shruti Palaskar",
      "Alan W Black",
      "Florian Metze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.06263"
  },
  {
    "id": "arXiv:2110.06267",
    "title": "Twice regularized MDPs and the equivalence between robustness and  regularization",
    "abstract": "Robust Markov decision processes (MDPs) aim to handle changing or partially\nknown system dynamics. To solve them, one typically resorts to robust\noptimization methods. However, this significantly increases computational\ncomplexity and limits scalability in both learning and planning. On the other\nhand, regularized MDPs show more stability in policy learning without impairing\ntime complexity. Yet, they generally do not encompass uncertainty in the model\ndynamics. In this work, we aim to learn robust MDPs using regularization. We\nfirst show that regularized MDPs are a particular instance of robust MDPs with\nuncertain reward. We thus establish that policy iteration on reward-robust MDPs\ncan have the same time complexity as on regularized MDPs. We further extend\nthis relationship to MDPs with uncertain transitions: this leads to a\nregularization term with an additional dependence on the value function. We\nfinally generalize regularized MDPs to twice regularized MDPs (R${}^2$ MDPs),\ni.e., MDPs with $\\textit{both}$ value and policy regularization. The\ncorresponding Bellman operators enable developing policy iteration schemes with\nconvergence and robustness guarantees. It also reduces planning and learning in\nrobust MDPs to regularized MDPs.",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Esther Derman",
      "Matthieu Geist",
      "Shie Mannor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.06267"
  },
  {
    "id": "arXiv:2110.06268",
    "title": "Stacking Integrators Without Sacrificing the Overshoot in Reset Control  Systems",
    "abstract": "According to the well-known loop-shaping control design approach, the\nsteady-state precision of control systems can be improved by stacking\nintegrators. However, due to the waterbed effect in linear control systems,\nsuch an action will worsen the transient response by increasing overshoot and\ncreating wind-up problems. This paper presents a new architecture for rest\ncontrol systems that can significantly decrease the overshoot and create a\nno-overshoot performance even in presence of stacked integrators. The\nsteady-state analysis of the proposed system will also show that improved\nprecision expected due to stacked integrators can be achieved as well. A\nnumerical simulation study is presented to verify the results and the tuning\nguide presented.",
    "descriptor": "",
    "authors": [
      "Nima Karbasizadeh",
      "S. Hassan HosseinNia"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.06268"
  },
  {
    "id": "arXiv:2110.06269",
    "title": "Real Image Inversion via Segments",
    "abstract": "In this short report, we present a simple, yet effective approach to editing\nreal images via generative adversarial networks (GAN). Unlike previous\ntechniques, that treat all editing tasks as an operation that affects pixel\nvalues in the entire image in our approach we cut up the image into a set of\nsmaller segments. For those segments corresponding latent codes of a generative\nnetwork can be estimated with greater accuracy due to the lower number of\nconstraints. When codes are altered by the user the content in the image is\nmanipulated locally while the rest of it remains unaffected. Thanks to this\nproperty the final edited image better retains the original structures and thus\nhelps to preserve natural look.",
    "descriptor": "\nComments: 7 pages, 10 figures\n",
    "authors": [
      "David Futschik",
      "Michal Luk\u00e1\u010d",
      "Eli Shechtman",
      "Daniel S\u00fdkora"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.06269"
  },
  {
    "id": "arXiv:2110.06270",
    "title": "Toward nonlinear dynamic control over encrypted data for infinite time  horizon",
    "abstract": "Recent studies on encrypted control using homomorphic encryption allow secure\noperation by directly performing computations on encrypted data without\ndecryption. Implementing dynamic controllers on encrypted data presents unique\nchallenges due to limitations on the number of operations on an encrypted\nmessage. Hence, it may not be possible to perform the recursive operations for\nan infinite time horizon. In this note, we demonstrate that it is possible to\nrun a dynamic controller over encrypted data for an infinite time horizon if\nthe output of the controller can be represented as a function of a fixed number\nof previous inputs and outputs. The presented implementation requires\nencryption at both input and output of the plant. We identify a class of\nnonlinear systems that can accommodate the proposed implementation. The\nclosed-loop performance can be guaranteed using the proposed encrypted\ncontroller by ensuring that quantization error is made arbitrarily small with\nappropriate choice of parameters. We show that the proposed method is amenable\nto linear systems (as a subset of the said nonlinear systems) with performance\nguarantees.",
    "descriptor": "\nComments: 3 pages, previously presented at the 21st IFAC World Congress, 2020\n",
    "authors": [
      "Junsoo Kim",
      "Farhad Farokhi",
      "Iman Shames",
      "Hyungbo Shim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.06270"
  },
  {
    "id": "arXiv:2110.06273",
    "title": "Sm\u00e5prat: DialoGPT for Natural Language Generation of Swedish  Dialogue by Transfer Learning",
    "abstract": "Building open-domain conversational systems (or chatbots) that produce\nconvincing responses is a recognized challenge. Recent state-of-the-art (SoTA)\ntransformer-based models for the generation of natural language dialogue have\ndemonstrated impressive performance in simulating human-like, single-turn\nconversations in English. This work investigates, by an empirical study, the\npotential for transfer learning of such models to Swedish language. DialoGPT,\nan English language pre-trained model, is adapted by training on three\ndifferent Swedish language conversational datasets obtained from publicly\navailable sources. Perplexity score (an automated intrinsic language model\nmetric) and surveys by human evaluation were used to assess the performances of\nthe fine-tuned models, with results that indicate that the capacity for\ntransfer learning can be exploited with considerable success. Human evaluators\nasked to score the simulated dialogue judged over 57% of the chatbot responses\nto be human-like for the model trained on the largest (Swedish) dataset. We\nprovide the demos and model checkpoints of our English and Swedish chatbots on\nthe HuggingFace platform for public use.",
    "descriptor": "\nComments: 9 pages, 5 tables, 1 figure\n",
    "authors": [
      "Tosin Adewumi",
      "Nosheen Abid",
      "Maryam Pahlavan",
      "Rickard Br\u00e4nnvall",
      "Sana Sabah Sabry",
      "Foteini Liwicki",
      "Marcus Liwicki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06273"
  },
  {
    "id": "arXiv:2110.06274",
    "title": "LiST: Lite Self-training Makes Efficient Few-shot Learners",
    "abstract": "We present a new method LiST for efficient fine-tuning of large pre-trained\nlanguage models (PLMs) in few-shot learning settings. LiST significantly\nimproves over recent methods that adopt prompt fine-tuning using two key\ntechniques. The first one is the use of self-training to leverage large amounts\nof unlabeled data for prompt-tuning to significantly boost the model\nperformance in few-shot settings. We use self-training in conjunction with\nmeta-learning for re-weighting noisy pseudo-prompt labels. However, traditional\nself-training is expensive as it requires updating all the model parameters\nrepetitively. Therefore, we use a second technique for light-weight fine-tuning\nwhere we introduce a small number of task-specific adapter parameters that are\nfine-tuned during self-training while keeping the PLM encoder frozen. This also\nsignificantly reduces the overall model footprint across several tasks that can\nnow share a common PLM encoder as backbone for inference. Combining the above\ntechniques, LiST not only improves the model performance for few-shot learning\non target domains but also reduces the model memory footprint. We present a\ncomprehensive study on six NLU tasks to validate the effectiveness of LiST. The\nresults show that LiST improves by 35% over classic fine-tuning methods and 6%\nover prompt-tuning with 96% reduction in number of trainable parameters when\nfine-tuned with no more than 30 labeled examples from each target domain.",
    "descriptor": "",
    "authors": [
      "Yaqing Wang",
      "Subhabrata Mukherjee",
      "Xiaodong Liu",
      "Jing Gao",
      "Ahmed Hassan Awadallah",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06274"
  },
  {
    "id": "arXiv:2110.06280",
    "title": "S3PRL-VC: Open-source Voice Conversion Framework with Self-supervised  Speech Representations",
    "abstract": "This paper introduces S3PRL-VC, an open-source voice conversion (VC)\nframework based on the S3PRL toolkit. In the context of recognition-synthesis\nVC, self-supervised speech representation (S3R) is valuable in its potential to\nreplace the expensive supervised representation adopted by state-of-the-art VC\nsystems. Moreover, we claim that VC is a good probing task for S3R analysis. In\nthis work, we provide a series of in-depth analyses by benchmarking on the two\ntasks in VCC2020, namely intra-/cross-lingual any-to-one (A2O) VC, as well as\nan any-to-any (A2A) setting. We also provide comparisons between not only\ndifferent S3Rs but also top systems in VCC2020 with supervised representations.\nSystematic objective and subjective evaluation were conducted, and we show that\nS3R is comparable with VCC2020 top systems in the A2O setting in terms of\nsimilarity, and achieves state-of-the-art in S3R-based A2A VC. We believe the\nextensive analysis, as well as the toolkit itself, contribute to not only the\nS3R community but also the VC community. The codebase is now open-sourced.",
    "descriptor": "\nComments: Submitted to ICASSP 2022. Code available at: this https URL\n",
    "authors": [
      "Wen-Chin Huang",
      "Shu-Wen Yang",
      "Tomoki Hayashi",
      "Hung-Yi Lee",
      "Shinji Watanabe",
      "Tomoki Toda"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.06280"
  },
  {
    "id": "arXiv:2110.06282",
    "title": "The Rich Get Richer: Disparate Impact of Semi-Supervised Learning",
    "abstract": "Semi-supervised learning (SSL) has demonstrated its potential to improve the\nmodel accuracy for a variety of learning tasks when the high-quality supervised\ndata is severely limited. Although it is often established that the average\naccuracy for the entire population of data is improved, it is unclear how SSL\nfares with different sub-populations. Understanding the above question has\nsubstantial fairness implications when these different sub-populations are\ndefined by the demographic groups we aim to treat fairly. In this paper, we\nreveal the disparate impacts of deploying SSL: the sub-population who has a\nhigher baseline accuracy without using SSL (the ``rich\" sub-population) tends\nto benefit more from SSL; while the sub-population who suffers from a low\nbaseline accuracy (the ``poor\" sub-population) might even observe a performance\ndrop after adding the SSL module. We theoretically and empirically establish\nthe above observation for a broad family of SSL algorithms, which either\nexplicitly or implicitly use an auxiliary ``pseudo-label\". Our experiments on a\nset of image and text classification tasks confirm our claims. We discuss how\nthis disparate impact can be mitigated and hope that our paper will alarm the\npotential pitfall of using SSL and encourage a multifaceted evaluation of\nfuture SSL algorithms. Code is available at github.com/UCSC-REAL/Disparate-SSL.",
    "descriptor": "",
    "authors": [
      "Zhaowei Zhu",
      "Tianyi Luo",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06282"
  },
  {
    "id": "arXiv:2110.06283",
    "title": "A Good Representation Detects Noisy Labels",
    "abstract": "Label noise is pervasive in real-world datasets, which encodes wrong\ncorrelation patterns and impairs the generalization of deep neural networks\n(DNNs). It is critical to find efficient ways to detect the corrupted patterns.\nCurrent methods primarily focus on designing robust training techniques to\nprevent DNNs from memorizing corrupted patterns. This approach has two\noutstanding caveats: 1) applying this approach to each individual dataset would\noften require customized training processes; 2) as long as the model is trained\nwith noisy supervisions, overfitting to corrupted patterns is often hard to\navoid, leading to performance drop in detection. In this paper, given good\nrepresentations, we propose a universally applicable and training-free solution\nto detect noisy labels. Intuitively, good representations help define\n``neighbors'' of each training instance, and closer instances are more likely\nto share the same clean label. Based on the neighborhood information, we\npropose two methods: the first one uses ``local voting\" via checking the noisy\nlabel consensuses of nearby representations. The second one is a ranking-based\napproach that scores each instance and filters out a guaranteed number of\ninstances that are likely to be corrupted, again using only representations.\nGiven good (but possibly imperfect) representations that are commonly available\nin practice, we theoretically analyze how they affect the local voting and\nprovide guidelines for tuning neighborhood size. We also prove the worst-case\nerror bound for the ranking-based method. Experiments with both synthetic and\nreal-world label noise demonstrate our training-free solutions are consistently\nand significantly improving over most of the training-based baselines. Code is\navailable at github.com/UCSC-REAL/SimiRep.",
    "descriptor": "",
    "authors": [
      "Zhaowei Zhu",
      "Zihao Dong",
      "Hao Cheng",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06283"
  },
  {
    "id": "arXiv:2110.06287",
    "title": "Real-Time Learning from An Expert in Deep Recommendation Systems with  Marginal Distance Probability Distribution",
    "abstract": "Recommendation systems play an important role in today's digital world. They\nhave found applications in various applications such as music platforms, e.g.,\nSpotify, and movie streaming services, e.g., Netflix. Less research effort has\nbeen devoted to physical exercise recommendation systems. Sedentary lifestyles\nhave become the major driver of several diseases as well as healthcare costs.\nIn this paper, we develop a recommendation system for daily exercise activities\nto users based on their history, profile and similar users. The developed\nrecommendation system uses a deep recurrent neural network with user-profile\nattention and temporal attention mechanisms.\nMoreover, exercise recommendation systems are significantly different from\nstreaming recommendation systems in that we are not able to collect click\nfeedback from the participants in exercise recommendation systems. Thus, we\npropose a real-time, expert-in-the-loop active learning procedure. The active\nlearners calculate the uncertainty of the recommender at each time step for\neach user and ask an expert for a recommendation when the certainty is low. In\nthis paper, we derive the probability distribution function of marginal\ndistance, and use it to determine when to ask experts for feedback. Our\nexperimental results on a mHealth dataset show improved accuracy after\nincorporating the real-time active learner with the recommendation system.",
    "descriptor": "",
    "authors": [
      "Arash Mahyari",
      "Peter Pirolli",
      "Jacqueline A. LeBlanc"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06287"
  },
  {
    "id": "arXiv:2110.06288",
    "title": "Decision-Theoretic Question Generation for Situated Reference  Resolution: An Empirical Study and Computational Model",
    "abstract": "Dialogue agents that interact with humans in situated environments need to\nmanage referential ambiguity across multiple modalities and ask for help as\nneeded. However, it is not clear what kinds of questions such agents should ask\nnor how the answers to such questions can be used to resolve ambiguity. To\naddress this, we analyzed dialogue data from an interactive study in which\nparticipants controlled a virtual robot tasked with organizing a set of tools\nwhile engaging in dialogue with a live, remote experimenter. We discovered a\nnumber of novel results, including the distribution of question types used to\nresolve ambiguity and the influence of dialogue-level factors on the reference\nresolution process. Based on these empirical findings we: (1) developed a\ncomputational model for clarification requests using a decision network with an\nentropy-based utility assignment method that operates across modalities, (2)\nevaluated the model, showing that it outperforms a slot-filling baseline in\nenvironments of varying ambiguity, and (3) interpreted the results to offer\ninsight into the ways that agents can ask questions to facilitate situated\nreference resolution.",
    "descriptor": "\nComments: To be published in the proceedings of the 23rd ACM International Conference on Multimodal Interaction (ICMI) 2021\n",
    "authors": [
      "Felix Gervits",
      "Gordon Briggs",
      "Antonio Roque",
      "Genki A. Kadomatsu",
      "Dean Thurston",
      "Matthias Scheutz",
      "Matthew Marge"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06288"
  },
  {
    "id": "arXiv:2110.06290",
    "title": "Scalable Consistency Training for Graph Neural Networks via  Self-Ensemble Self-Distillation",
    "abstract": "Consistency training is a popular method to improve deep learning models in\ncomputer vision and natural language processing. Graph neural networks (GNNs)\nhave achieved remarkable performance in a variety of network science learning\ntasks, but to date no work has studied the effect of consistency training on\nlarge-scale graph problems. GNNs scale to large graphs by minibatch training\nand subsample node neighbors to deal with high degree nodes. We utilize the\nrandomness inherent in the subsampling of neighbors and introduce a novel\nconsistency training method to improve accuracy. For a target node we generate\ndifferent neighborhood expansions, and distill the knowledge of the average of\nthe predictions to the GNN. Our method approximates the expected prediction of\nthe possible neighborhood samples and practically only requires a few samples.\nWe demonstrate that our training method outperforms standard GNN training in\nseveral different settings, and yields the largest gains when label rates are\nlow.",
    "descriptor": "",
    "authors": [
      "Cole Hawkins",
      "Vassilis N. Ioannidis",
      "Soji Adeshina",
      "George Karypis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06290"
  },
  {
    "id": "arXiv:2110.06292",
    "title": "UCX Programming Interface for Remote Function Injection and Invocation",
    "abstract": "Network library APIs have historically been developed with the emphasis on\ndata movement, placement, and communication semantics. Many communication\nsemantics are available across a large variety of network libraries, such as\nsend-receive, data streaming, put/get/atomic, RPC, active messages, collective\ncommunication, etc. In this work we introduce new compute and data movement\nAPIs that overcome the constraints of the single-program, multiple-data (SPMD)\nprogramming model by allowing users to send binary executable code between\nprocessing elements. Our proof-of-concept implementation of the API is based on\nthe UCX communication framework and leverages the RDMA network for fast compute\nmigration. We envision the API being used to dispatch user functions from a\nhost CPU to a SmartNIC (DPU), computational storage drive (CSD), or remote\nservers. In addition, the API can be used by large-scale irregular applications\n(such as semantic graph analysis), composed of many coordinating tasks\noperating on a data set so big that it has to be stored on many physical\ndevices. In such cases, it may be more efficient to dynamically choose where\ncode runs as the applications progresses.",
    "descriptor": "\nComments: 16 pages, 4 figures, to be published in OpenSHMEM Workshop 2021\n",
    "authors": [
      "Luis E. Pe\u00f1a",
      "Wenbin Lu",
      "Pavel Shamis",
      "Steve Poole"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.06292"
  },
  {
    "id": "arXiv:2110.06295",
    "title": "Localized Persistent Homologies for more Effective Deep Learning",
    "abstract": "Persistent Homologies have been successfully used to increase the performance\nof deep networks trained to detect curvilinear structures and to improve the\ntopological quality of the results. However, existing methods are very global\nand ignore the location of topological features. In this paper, we introduce an\napproach that relies on a new filtration function to account for location\nduring network training. We demonstrate experimentally on 2D images of roads\nand 3D image stacks of neuronal processes that networks trained in this manner\nare better at recovering the topology of the curvilinear structures they\nextract.",
    "descriptor": "",
    "authors": [
      "Doruk Oner",
      "Ad\u00e9lie Garin",
      "Mateusz Kozi\u0144ski",
      "Kathryn Hess",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06295"
  },
  {
    "id": "arXiv:2110.06296",
    "title": "The Role of Permutation Invariance in Linear Mode Connectivity of Neural  Networks",
    "abstract": "In this paper, we conjecture that if the permutation invariance of neural\nnetworks is taken into account, SGD solutions will likely have no barrier in\nthe linear interpolation between them. Although it is a bold conjecture, we\nshow how extensive empirical attempts fall short of refuting it. We further\nprovide a preliminary theoretical result to support our conjecture. Our\nconjecture has implications for lottery ticket hypothesis, distributed\ntraining, and ensemble methods.",
    "descriptor": "",
    "authors": [
      "Rahim Entezari",
      "Hanie Sedghi",
      "Olga Saukh",
      "Behnam Neyshabur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06296"
  },
  {
    "id": "arXiv:2110.06297",
    "title": "Model order reduction for bifurcating phenomena in Fluid-Structure  Interaction problems",
    "abstract": "This work explores the development and the analysis of an efficient reduced\norder model for the study of a bifurcating phenomenon, known as the Coand\\u{a}\neffect, in a multi-physics setting involving fluid and solid media. Taking into\nconsideration a Fluid-Structure Interaction problem, we aim at generalizing\nprevious works towards a more reliable description of the physics involved. In\nparticular, we provide several insights on how the introduction of an elastic\nstructure influences the bifurcating behaviour. We have addressed the\ncomputational burden by developing a reduced order branch-wise algorithm based\non a monolithic Proper Orthogonal Decomposition. We compared different\nconstitutive relations for the solid, and we observed that a nonlinear\nhyper-elastic law delays the bifurcation w.r.t. the standard model, while the\nsame effect is even magnified when considering linear elastic solid.",
    "descriptor": "",
    "authors": [
      "Moaad Khamlich",
      "Federico Pichi",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.06297"
  },
  {
    "id": "arXiv:2110.06303",
    "title": "Orion: Automatic Repair for Network Programs",
    "abstract": "Debugging imperative network programs is a challenging task for developers\nbecause understanding various network modules and complicated data structures\nis typically time-consuming. To address the challenge, this paper presents an\nautomated technique for repairing network programs from unit tests.\nSpecifically, given as input a faulty network program and a set of unit tests,\nour approach localizes the fault through symbolic reasoning, and synthesizes a\npatch such that the repaired program can pass all unit tests. It applies\ndomain-specific abstraction to simplify network data structures and utilizes\nmodular analysis to facilitate function summary reuse for symbolic analysis. We\nimplement the proposed techniques in a tool called Orion and evaluate it on 10\nbenchmarks adapted from real-world software-defined networking controllers. The\nevaluation results demonstrate the effectiveness and efficiency of Orion for\nrepairing network programs.",
    "descriptor": "",
    "authors": [
      "Lei Shi",
      "Yuepeng Wang",
      "Rajeev Alur",
      "Boon Thau Loo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2110.06303"
  },
  {
    "id": "arXiv:2110.06311",
    "title": "Incremental Community Detection in Distributed Dynamic Graph",
    "abstract": "Community detection is an important research topic in graph analytics that\nhas a wide range of applications. A variety of static community detection\nalgorithms and quality metrics were developed in the past few years. However,\nmost real-world graphs are not static and often change over time. In the case\nof streaming data, communities in the associated graph need to be updated\neither continuously or whenever new data streams are added to the graph, which\nposes a much greater challenge in devising good community detection algorithms\nfor maintaining dynamic graphs over streaming data. In this paper, we propose\nan incremental community detection algorithm for maintaining a dynamic graph\nover streaming data. The contributions of this study include (a) the\nimplementation of a Distributed Weighted Community Clustering (DWCC) algorithm,\n(b) the design and implementation of a novel Incremental Distributed Weighted\nCommunity Clustering (IDWCC) algorithm, and (c) an experimental study to\ncompare the performance of our IDWCC algorithm with the DWCC algorithm. We\nvalidate the functionality and efficiency of our framework in processing\nstreaming data and performing large in-memory distributed dynamic graph\nanalytics. The results demonstrate that our IDWCC algorithm performs up to\nthree times faster than the DWCC algorithm for a similar accuracy.",
    "descriptor": "\nComments: BigDataService 2021 best paper award\n",
    "authors": [
      "Tariq Abughofa",
      "Ahmed A.Harby",
      "Haruna Isah",
      "Farhana Zulkernine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.06311"
  },
  {
    "id": "arXiv:2110.06313",
    "title": "Algebra of Data Reconciliation",
    "abstract": "With distributed computing and mobile applications becoming ever more\nprevalent, synchronizing diverging replicas of the same data is a common\nproblem. Reconciliation -- bringing two replicas of the same data structure as\nclose as possible without overriding local changes -- is investigated in an\nalgebraic model. Our approach is to consider two sequences of simple commands\nthat describe the changes in the replicas compared to the original structure,\nand then determine the maximal subsequences of each that can be propagated to\nthe other. The proposed command set is shown to be functionally complete, and\nan update detection algorithm is presented which produces a command sequence\ntransforming the original data structure into the replica while traversing both\nsimultaneously. Syntactical characterization is provided in terms of a\nrewriting system for semantically equivalent command sequences. Algebraic\nproperties of sequence pairs that are applicable to the same data structure are\ninvestigated. Based on these results the reconciliation problem is shown to\nhave a unique maximal solution. In addition, syntactical properties of the\nmaximal solution allows for an efficient algorithm that produces it.",
    "descriptor": "",
    "authors": [
      "Elod P. Csirmaz",
      "Laszlo Csirmaz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.06313"
  },
  {
    "id": "arXiv:2110.06315",
    "title": "On Association between Absolute and Relative Zigzag Persistence",
    "abstract": "Duality results connecting persistence modules for absolute and relative\nhomology provides a fundamental understanding into persistence theory. In this\npaper, we study similar associations in the context of zigzag persistence. Our\nmain finding is a weak duality for the so-called non-repetitive zigzag\nfiltrations in which a simplex is never added again after being deleted. The\ntechnique used to prove the duality for non-zigzag persistence does not extend\nstraightforwardly to our case. Accordingly, taking a different route, we prove\nthe weak duality by converting a non-repetitive filtration to an up-down\nfiltration by a sequence of diamond switches. We then show an application of\nthe weak duality result which gives a near-linear algorithm for computing the\n$p$-th and a subset of the $(p-1)$-th persistence for a non-repetitive zigzag\nfiltration of a simplicial $p$-manifold. Utilizing the fact that a\nnon-repetitive filtration admits an up-down filtration as its canonical form,\nwe further reduce the problem of computing zigzag persistence for\nnon-repetitive filtrations to the problem of computing standard persistence for\nwhich several efficient implementations exist. Our experiment shows that this\nachieves substantial performance gain. Our study also identifies repetitive\nfiltrations as instances that fundamentally distinguish zigzag persistence from\nthe standard persistence.",
    "descriptor": "",
    "authors": [
      "Tamal K. Dey",
      "Tao Hou"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2110.06315"
  },
  {
    "id": "arXiv:2110.06321",
    "title": "Controller-based Energy-Aware Wireless Sensor Network Routing using  Quantum Algorithms",
    "abstract": "Energy efficient routing in wireless sensor networks has attracted attention\nfrom researchers in both academia and industry, most recently motivated by the\nopportunity to use SDN (software defined network)-inspired approaches. These\nproblems are NP-hard, with algorithms needing computation time which scales\nfaster than polynomial in the problem size. Consequently, heuristic algorithms\nare used in practice, which are unable to guarantee optimally. In this short\npaper, we show proof-of-principle for the use of a quantum annealing processor\ninstead of a classical processor, to find optimal or near-optimal solutions\nvery quickly. Our preliminary results for small networks show that this\napproach using quantum computing has great promise and may open the door for\nother significant improvements in the efficacy of network algorithms.",
    "descriptor": "",
    "authors": [
      "Jie Chen",
      "Prasanna Date",
      "Nicholas Chancellor",
      "Mohammed Atiquzzaman",
      "Cormac Sreenan"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.06321"
  },
  {
    "id": "arXiv:2110.06322",
    "title": "A closest point method library for PDEs on surfaces with parallel domain  decomposition solvers and preconditioners",
    "abstract": "The DD-CPM software library provides a set of tools for the discretization\nand solution of problems arising from the closest point method (CPM) for\npartial differential equations on surfaces. The solvers are built on top of the\nwell-known PETSc framework, and are supplemented by custom domain decomposition\n(DD) preconditioners specific to the CPM. These solvers are fully compatible\nwith distributed memory parallelism through MPI. This library is particularly\nwell suited to the solution of elliptic and parabolic equations, including many\nreaction-diffusion equations. The software is detailed herein, and a number of\nsample problems and benchmarks are demonstrated. Finally, the parallel\nscalability is measured.",
    "descriptor": "\nComments: Submitted to ACM Transactions on Mathematical Software\n",
    "authors": [
      "Ian C. T. May",
      "Ronald Haynes",
      "Steven Ruuth"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.06322"
  },
  {
    "id": "arXiv:2110.06323",
    "title": "An Annihilating Filter-Based DOA Estimation for Uniform Linear Array",
    "abstract": "In this paper, we propose a new method to design an annihilating filter (AF)\nfor direction-of-arrival (DOA) estimation of multiple snapshots within an\nuniform linear array. To evaluate the proposed method, we firstly design a DOA\nestimation using multiple signal classification (MUSIC) algorithm, referred to\nas the MUSIC baseline. We then compare the proposed method with the MUSIC\nbaseline in two environmental noise conditions: Only white noise, or both white\nnoise and diffusion. The experimental results highlight two main contributions;\nthe first is to modify conventional MUSIC algorithm for adapting different\nnoise conditions, and the second is to propose an AF-based method that shows\ncompetitive accuracy of arrival angles detected and low complexity compared\nwith the MUSIC baseline.",
    "descriptor": "",
    "authors": [
      "Son Phan",
      "Lam Pham"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.06323"
  },
  {
    "id": "arXiv:2110.06324",
    "title": "PSML: A Multi-scale Time-series Dataset for Machine Learning in  Decarbonized Energy Grids",
    "abstract": "The electric grid is a key enabling infrastructure for the ambitious\ntransition towards carbon neutrality as we grapple with climate change. With\ndeepening penetration of renewable energy resources and electrified\ntransportation, the reliable and secure operation of the electric grid becomes\nincreasingly challenging. In this paper, we present PSML, a first-of-its-kind\nopen-access multi-scale time-series dataset, to aid in the development of\ndata-driven machine learning (ML) based approaches towards reliable operation\nof future electric grids. The dataset is generated through a novel transmission\n+ distribution (T+D) co-simulation designed to capture the increasingly\nimportant interactions and uncertainties of the grid dynamics, containing\nelectric load, renewable generation, weather, voltage and current measurements\nat multiple spatio-temporal scales. Using PSML, we provide state-of-the-art ML\nbaselines on three challenging use cases of critical importance to achieve: (i)\nearly detection, accurate classification and localization of dynamic\ndisturbance events; (ii) robust hierarchical forecasting of load and renewable\nenergy with the presence of uncertainties and extreme events; and (iii)\nrealistic synthetic generation of physical-law-constrained measurement time\nseries. We envision that this dataset will enable advances for ML in dynamic\nsystems, while simultaneously allowing ML researchers to contribute towards\ncarbon-neutral electricity and mobility.",
    "descriptor": "",
    "authors": [
      "Xiangtian Zheng",
      "Nan Xu",
      "Loc Trinh",
      "Dongqi Wu",
      "Tong Huang",
      "S. Sivaranjani",
      "Yan Liu",
      "Le Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06324"
  },
  {
    "id": "arXiv:2110.06326",
    "title": "When Does the Gittins Policy Have Asymptotically Optimal Response Time  Tail?",
    "abstract": "We consider scheduling in the M/G/1 queue with unknown job sizes. It is known\nthat the Gittins policy minimizes mean response time in this setting. However,\nthe behavior of the tail of response time under Gittins is poorly understood,\neven in the large-response-time limit. Characterizing Gittins's asymptotic tail\nbehavior is important because if Gittins has optimal tail asymptotics, then it\nsimultaneously provides optimal mean response time and good tail performance.\nIn this work, we give the first comprehensive account of Gittins's asymptotic\ntail behavior. For heavy-tailed job sizes, we find that Gittins always has\nasymptotically optimal tail. The story for light-tailed job sizes is less\nclear-cut: Gittins's tail can be optimal, pessimal, or in between. To remedy\nthis, we show that a modification of Gittins avoids pessimal tail behavior\nwhile achieving near-optimal mean response time.",
    "descriptor": "",
    "authors": [
      "Ziv Scully",
      "Lucas van Kreveld"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2110.06326"
  },
  {
    "id": "arXiv:2110.06328",
    "title": "Quadrotor going through a window and landing: An image-based visual  servo control approach",
    "abstract": "This paper considers the problem of controlling a quadrotor to go through a\nwindow and land on a planar target, the landing pad, using an Image-Based\nVisual Servo (IBVS) controller that relies on sensing information from two\non-board cameras and an IMU. The maneuver is divided into two stages: crossing\nthe window and landing on the pad. For the first stage, a control law is\nproposed that guarantees that the vehicle will not collide with the wall\ncontaining the window and will go through the window with non-zero velocity\nalong the direction orthogonal to the window, keeping at all times a safety\ndistance with respect to the window edges. For the landing stage, the proposed\ncontrol law ensures that the vehicle achieves a smooth touchdown, keeping at\nall time a positive height above the plane containing the landing pad. For\ncontrol purposes, the centroid vectors provided by the combination of the\nspherical image measurements of a collection of landmarks (corners) for both\nthe window and the landing pad are used as position measurement. The\ntranslational optical flow relative to the wall, window edges, and landing\nplane is used as velocity cue. To achieve the proposed objective, no direct\nmeasurements nor explicit estimate of position or velocity are required.\nSimulation and experimental results are provided to illustrate the performance\nof the presented controller.",
    "descriptor": "",
    "authors": [
      "Zhiqi Tang",
      "Rita Cunha",
      "David Cabecinhas",
      "Tarek Hamel",
      "Carlos Silvestre"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.06328"
  },
  {
    "id": "arXiv:2110.06329",
    "title": "A Reference Governor for linear systems with polynomial constraints",
    "abstract": "The paper considers the application of reference governors to linear\ndiscrete-time systems with constraints given by polynomial inequalities. We\npropose a novel algorithm to compute the maximal output admissible invariant\nset in the case of polynomial constraints. The reference governor solves a\nconstrained nonlinear minimization problem at initialization and then uses a\nbisection algorithm at the subsequent time steps. The effectiveness of the\nmethod is demonstrated by two numerical examples.",
    "descriptor": "",
    "authors": [
      "Laurent Burlion",
      "Rick Schieni",
      "Ilya Kolmanovsky"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.06329"
  },
  {
    "id": "arXiv:2110.06330",
    "title": "Online Trajectory Optimization for Dynamic Aerial Motions of a Quadruped  Robot",
    "abstract": "This work presents a two part framework for online planning and execution of\ndynamic aerial motions on a quadruped robot. Motions are planned via a\ncentroidal momentum-based nonlinear optimization that is general enough to\nproduce rich sets of novel dynamic motions based solely on the user-specified\ncontact schedule and desired launch velocity of the robot. Since this nonlinear\noptimization is not tractable for real-time receding horizon control, motions\nare planned once via nonlinear optimization in preparation of an aerial motion\nand then tracked continuously using a variational-based optimal controller that\noffers robustness to the uncertainties that exist in the real hardware such as\nmodeling error or disturbances. Motion planning typically takes between\n0.05-0.15 seconds, while the optimal controller finds stabilizing feedback\ninputs at 500 Hz. Experimental results on the MIT Mini Cheetah demonstrate that\nthe framework can reliably produce successful aerial motions such as jumps onto\nand off of platforms, spins, flips, barrel rolls, and running jumps over\nobstacles.",
    "descriptor": "\nComments: 6 pages, Accepted to ICRA 2021\n",
    "authors": [
      "Matthew Chignoli",
      "Sangbae Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.06330"
  },
  {
    "id": "arXiv:2110.06331",
    "title": "Exploring Content Based Image Retrieval for Highly Imbalanced Melanoma  Data using Style Transfer, Semantic Image Segmentation and Ensemble Learning",
    "abstract": "Lesion images are frequently taken in open-set settings. Because of this, the\nimage data generated is extremely varied in nature.It is difficult for a\nconvolutional neural network to find proper features and generalise well, as a\nresult content based image retrieval (CBIR) system for lesion images are\ndifficult to build. This paper explores this domain and proposes multiple\nsimilarity measures which uses Style Loss and Dice Coefficient via a novel\nsimilarity measure called I1-Score. Out of the CBIR similarity measures\nproposed, pure style loss approach achieves a remarkable accuracy increase over\ntraditional approaches like Euclidean Distance and Cosine Similarity. The\nI1-Scores using style loss performed better than traditional approaches by a\nsmall margin, whereas, I1-Scores with dice-coefficient faired very poorly. The\nmodel used is trained using ensemble learning for better generalization.",
    "descriptor": "",
    "authors": [
      "Priyam Mehta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06331"
  },
  {
    "id": "arXiv:2110.06332",
    "title": "Distributed Kalman Filters for Relative Formation Control of Mobile  Agents",
    "abstract": "Formation control (FC) of multi-agent plays a critical role in a wide variety\nof fields. In the absence of absolute positioning, agents in FC systems rely on\nrelative position measurements with respect to their neighbors. In distributed\nfilter design literature, relative observation models are comparatively\nunexplored, and in FC literature, uncertainty models are rarely considered. In\nthis article, we aim to bridge the gap between these domains, by exploring\ndistributed filters tailored for relative FC of swarms. We propose\nstatistically robust data models for tracking relative positions of agents in a\nFC network, and subsequently propose optimal Kalman filters for both\ncentralized and distributed scenarios. Our simulations highlight the benefits\nof these estimators, and we identify future research directions based on our\nproposed framework.",
    "descriptor": "\nComments: In submission\n",
    "authors": [
      "Martijn van der Marel",
      "Raj Thilak Rajan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.06332"
  },
  {
    "id": "arXiv:2110.06336",
    "title": "The VLSAT-2 Benchmark Suite",
    "abstract": "This report presents VLSAT-2 (an acronym for \"Very Large Boolean\nSATisfiability problems),the second part of a benchmark suite to be used in\nscientific experiments and softwarecompetitions addressing SAT-solving\nissues.VLSAT-2 contains 100 benchmarks (50 satisfiable and 50 unsatisfiable\nformulas)of increasing complexity, proposed in DIMACS CNF format undera\npermissive Creative Commons license.25% of these benchmarks have been used\nduring the 2020 and 2021 editionsof the International SAT Competition.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2011.11049\n",
    "authors": [
      "Pierre Bouvier",
      "Hubert Garavel"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2110.06336"
  },
  {
    "id": "arXiv:2110.06341",
    "title": "Learning Compact Metrics for MT",
    "abstract": "Recent developments in machine translation and multilingual text generation\nhave led researchers to adopt trained metrics such as COMET or BLEURT, which\ntreat evaluation as a regression problem and use representations from\nmultilingual pre-trained models such as XLM-RoBERTa or mBERT. Yet studies on\nrelated tasks suggest that these models are most efficient when they are large,\nwhich is costly and impractical for evaluation. We investigate the trade-off\nbetween multilinguality and model capacity with RemBERT, a state-of-the-art\nmultilingual language model, using data from the WMT Metrics Shared Task. We\npresent a series of experiments which show that model size is indeed a\nbottleneck for cross-lingual transfer, then demonstrate how distillation can\nhelp addressing this bottleneck, by leveraging synthetic data generation and\ntransferring knowledge from one teacher to multiple students trained on related\nlanguages. Our method yields up to 10.5% improvement over vanilla fine-tuning\nand reaches 92.6% of RemBERT's performance using only a third of its\nparameters.",
    "descriptor": "\nComments: Accepted at EMNLP 2021\n",
    "authors": [
      "Amy Pu",
      "Hyung Won Chung",
      "Ankur P. Parikh",
      "Sebastian Gehrmann",
      "Thibault Sellam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06341"
  },
  {
    "id": "arXiv:2110.06342",
    "title": "Decentralized Connectivity Maintenance for Multi-robot Systems Under  Motion and Sensing Uncertainties",
    "abstract": "Communication connectivity is desirable for safe and efficient operation of\nmulti-robot systems. While decentralized algorithms for connectivity\nmaintenance have been explored in recent literature, the majority of these\nworks do not account for robot motion and sensing uncertainties. These\nuncertainties are inherent in practical robots and result in robots deviating\nfrom their desired positions which could potentially result in a loss of\nconnectivity. In this paper we present a Decentralized Connectivity Maintenance\nalgorithm accounting for robot motion and sensing Uncertainties (DCMU). We\nfirst propose a novel weighted graph definition for the multi-robot system that\naccounts for the aforementioned uncertainties along with realistic connectivity\nconstraints such as line-of-sight connectivity and collision avoidance. Next we\ndesign a decentralized gradient-based controller for connectivity maintenance\nwhere we derive the gradients of our weighted graph edge weights required for\ncomputing the control. Finally, we perform multiple simulations to validate the\nconnectivity maintenance performance of our DCMU algorithm under robot motion\nand sensing uncertainties and show an improvement compared to previous work.",
    "descriptor": "\nComments: Submitted to NAVIGATION: Journal of The Institute of Navigation\n",
    "authors": [
      "Akshay Shetty",
      "Timmy Hussain",
      "Grace Gao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.06342"
  },
  {
    "id": "arXiv:2110.06348",
    "title": "Exact and Bounded Collision Probability for Motion Planning under  Gaussian Uncertainty",
    "abstract": "Computing collision-free trajectories is of prime importance for safe\nnavigation. We present an approach for computing the collision probability\nunder Gaussian distributed motion and sensing uncertainty with the robot and\nstatic obstacle shapes approximated as ellipsoids. The collision condition is\nformulated as the distance between ellipsoids and unlike previous approaches we\nprovide a method for computing the exact collision probability. Furthermore, we\nprovide a tight upper bound that can be computed much faster during online\nplanning. Comparison to other state-of-the-art methods is also provided. The\nproposed method is evaluated in simulation under varying configuration and\nnumber of obstacles.",
    "descriptor": "\nComments: Accepted for publication in the IEEE Robotics and Automation Letters (RA-L)\n",
    "authors": [
      "Antony Thomas",
      "Fulvio Mastrogiovanni",
      "Marco Baglietto"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06348"
  },
  {
    "id": "arXiv:2110.06350",
    "title": "Computing semigroups with error control",
    "abstract": "We develop an algorithm that computes strongly continuous semigroups on\ninfinite-dimensional Hilbert spaces with explicit error control. Given a\ngenerator $A$, a time $t>0$, an arbitrary initial vector $u_0$ and an error\ntolerance $\\epsilon>0$, the algorithm computes $\\exp(tA)u_0$ with error bounded\nby $\\epsilon$. The algorithm is based on a combination of a regularized\nfunctional calculus, suitable contour quadrature rules, and the adaptive\ncomputation of resolvents in infinite dimensions. As a particular case, we show\nthat it is possible, even when only allowing pointwise evaluation of\ncoefficients, to compute, with error control, semigroups on the unbounded\ndomain $L^2(\\mathbb{R}^d)$ that are generated by partial differential operators\nwith polynomially bounded coefficients of locally bounded total variation. For\nanalytic semigroups (and more general Laplace transform inversion), we provide\na quadrature rule whose error decreases like $\\exp(-cN/\\log(N))$ for $N$\nquadrature points, that remains stable as $N\\rightarrow\\infty$, and which is\nalso suitable for infinite-dimensional operators. Numerical examples are given,\nincluding: Schr\\\"odinger and wave equations on the aperiodic Ammann--Beenker\ntiling, complex perturbed fractional diffusion equations on $L^2(\\mathbb{R})$,\nand damped Euler--Bernoulli beam equations.",
    "descriptor": "",
    "authors": [
      "Matthew J. Colbrook"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.06350"
  },
  {
    "id": "arXiv:2110.06354",
    "title": "Tell Me How to Survey: Literature Review Made Simple with Automatic  Reading Path Generation",
    "abstract": "Recent years have witnessed the dramatic growth of paper volumes with plenty\nof new research papers published every day, especially in the area of computer\nscience. How to glean papers worth reading from the massive literature to do a\nquick survey or keep up with the latest advancement about a specific research\ntopic has become a challenging task. Existing academic search engines such as\nGoogle Scholar return relevant papers by individually calculating the relevance\nbetween each paper and query. However, such systems usually omit the\nprerequisite chains of a research topic and cannot form a meaningful reading\npath. In this paper, we introduce a new task named Reading Path Generation\n(RPG) which aims at automatically producing a path of papers to read for a\ngiven query. To serve as a research benchmark, we further propose SurveyBank, a\ndataset consisting of large quantities of survey papers in the field of\ncomputer science as well as their citation relationships. Each survey paper\ncontains key phrases extracted from its title and multi-level reading lists\ninferred from its references. Furthermore, we propose a\ngraph-optimization-based approach for reading path generation which takes the\nrelationship between papers into account. Extensive evaluations demonstrate\nthat our approach outperforms other baselines. A Real-time Reading Path\nGeneration System (RePaGer) has been also implemented with our designed model.\nTo the best of our knowledge, we are the first to target this important\nresearch problem. Our source code of RePaGer system and SurveyBank dataset can\nbe found on here.",
    "descriptor": "\nComments: 16 pages, 12 figures\n",
    "authors": [
      "Jiayuan Ding",
      "Tong Xiang",
      "Zijing Ou",
      "Wangyang Zuo",
      "Ruihui Zhao",
      "Chenghua Lin",
      "Yefeng Zheng",
      "Bang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06354"
  },
  {
    "id": "arXiv:2110.06361",
    "title": "Sub-Terahertz Spatial Statistical MIMO Channel Model for Urban  Microcells at 142 GHz",
    "abstract": "Sixth generation (6G) cellular systems are expected to extend the operational\nrange to sub-Terahertz (THz) frequencies between 100 and 300 GHz due to the\nbroad unexploited spectrum therein. A proper channel model is needed to\naccurately describe spatial and temporal channel characteristics and faithfully\ncreate channel impulse responses at sub-THz frequencies. This paper studies the\nchannel spatial statistics such as the number of spatial clusters and cluster\npower distribution based on recent radio propagation measurements conducted at\n142 GHz in an urban microcell (UMi) scenario. For the 28 measured locations, we\nobserve one to four spatial clusters at most locations. A detailed spatial\nstatistical multiple input multiple output (MIMO) channel generation procedure\nis introduced based on the derived empirical channel statistics. We find that\nbeamforming provides better spectral efficiency than spatial multiplexing in\nthe LOS scenario due to the boresight path, and two spatial streams usually\noffer the highest spectral efficiency at most NLOS locations due to the limited\nnumber of spatial clusters.",
    "descriptor": "\nComments: 6 pages, 7 figures, 2021 IEEE Global Communications Conference\n",
    "authors": [
      "Shihao Ju",
      "Theodore S. Rappaport"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.06361"
  },
  {
    "id": "arXiv:2110.06363",
    "title": "Exploiting Sensor Multiplexing for Covert Channels and Application  Fingerprinting on Mobile Devices",
    "abstract": "Mobile devices often distribute measurements from a single physical sensor to\nmultiple applications using software-based multiplexing. On Android devices,\nthe highest requested sampling frequency is returned to all applications even\nif other applications request measurements at lower frequencies. In this paper,\nwe demonstrate that this design choice exposes practically exploitable\nside-channels based on frequency-key shifting. By carefully modulating sensor\nsampling frequencies in software, we show that unprivileged malicious\napplications can construct reliable spectral covert channels that bypass\nexisting security mechanisms, e.g. Android's permissions framework. Moreover,\nwe present a variant of this technique that allows an unprivileged malicious\nobserver app to fingerprint other device applications and user interactions at\na coarse-grained level. Both techniques do not impose any assumptions beyond\napplication installation and accessing standard mobile services via the Android\nSensors SDK. As such, they open a powerful attack vector that exploits subtle\nyet insecure design choices in mobile sensor stacks.",
    "descriptor": "",
    "authors": [
      "Carlton Shepherd",
      "Jan Kalbantner",
      "Benjamin Semal",
      "Konstantinos Markantonakis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.06363"
  },
  {
    "id": "arXiv:2110.06365",
    "title": "Fast Approximations for Job Shop Scheduling: A Lagrangian Dual Deep  Learning Method",
    "abstract": "The Jobs shop Scheduling Problem (JSP) is a canonical combinatorial\noptimization problem that is routinely solved for a variety of industrial\npurposes. It models the optimal scheduling of multiple sequences of tasks, each\nunder a fixed order of operations, in which individual tasks require exclusive\naccess to a predetermined resource for a specified processing time. The problem\nis NP-hard and computationally challenging even for medium-sized instances.\nMotivated by the increased stochasticity in production chains, this paper\nexplores a deep learning approach to deliver efficient and accurate\napproximations to the JSP. In particular, this paper proposes the design of a\ndeep neural network architecture to exploit the problem structure, its\nintegration with Lagrangian duality to capture the problem constraints, and a\npost-processing optimization to guarantee solution feasibility.The resulting\nmethod, called JSP-DNN, is evaluated on hard JSP instances from the JSPLIB\nbenchmark library. Computational results show that JSP-DNN can produce JSP\napproximations of high quality at negligible computational costs.",
    "descriptor": "",
    "authors": [
      "James Kotary",
      "Ferdinando Fioretto",
      "Pascal Van Hentenryck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06365"
  },
  {
    "id": "arXiv:2110.06366",
    "title": "Time Masking for Temporal Language Models",
    "abstract": "Our world is constantly evolving, and so is the content on the web.\nConsequently, our languages, often said to mirror the world, are dynamic in\nnature. However, most current contextual language models are static and cannot\nadapt to changes over time. In this work, we propose a temporal contextual\nlanguage model called TempoBERT, which uses time as an additional context of\ntexts. Our technique is based on modifying texts with temporal information and\nperforming time masking - specific masking for the supplementary time\ninformation. We leverage our approach for the tasks of semantic change\ndetection and sentence time prediction, experimenting on diverse datasets in\nterms of time, size, genre, and language. Our extensive evaluation shows that\nboth tasks benefit from exploiting time masking.",
    "descriptor": "\nComments: 9 pages, accepted to WSDM 2022\n",
    "authors": [
      "Guy D. Rosin",
      "Ido Guy",
      "Kira Radinsky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06366"
  },
  {
    "id": "arXiv:2110.06367",
    "title": "Voice-assisted Image Labelling for Endoscopic Ultrasound Classification  using Neural Networks",
    "abstract": "Ultrasound imaging is a commonly used technology for visualising patient\nanatomy in real-time during diagnostic and therapeutic procedures. High\noperator dependency and low reproducibility make ultrasound imaging and\ninterpretation challenging with a steep learning curve. Automatic image\nclassification using deep learning has the potential to overcome some of these\nchallenges by supporting ultrasound training in novices, as well as aiding\nultrasound image interpretation in patient with complex pathology for more\nexperienced practitioners. However, the use of deep learning methods requires a\nlarge amount of data in order to provide accurate results. Labelling large\nultrasound datasets is a challenging task because labels are retrospectively\nassigned to 2D images without the 3D spatial context available in vivo or that\nwould be inferred while visually tracking structures between frames during the\nprocedure. In this work, we propose a multi-modal convolutional neural network\n(CNN) architecture that labels endoscopic ultrasound (EUS) images from raw\nverbal comments provided by a clinician during the procedure. We use a CNN\ncomposed of two branches, one for voice data and another for image data, which\nare joined to predict image labels from the spoken names of anatomical\nlandmarks. The network was trained using recorded verbal comments from expert\noperators. Our results show a prediction accuracy of 76% at image level on a\ndataset with 5 different labels. We conclude that the addition of spoken\ncommentaries can increase the performance of ultrasound image classification,\nand eliminate the burden of manually labelling large EUS datasets necessary for\ndeep learning applications.",
    "descriptor": "\nComments: Submitted to IEEE TMI\n",
    "authors": [
      "Ester Bonmati",
      "Yipeng Hu",
      "Alexander Grimwood",
      "Gavin J. Johnson",
      "George Goodchild",
      "Margaret G. Keane",
      "Kurinchi Gurusamy",
      "Brian Davidson",
      "Matthew J. Clarkson",
      "Stephen P. Pereira",
      "Dean C. Barratt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06367"
  },
  {
    "id": "arXiv:2110.06371",
    "title": "Algorithmic Composition by Autonomous Systems with Multiple Time-Scales",
    "abstract": "Dynamic systems have found their use in sound synthesis as well as score\nsynthesis. These levels can be integrated in monolithic autonomous systems in a\nnovel approach to algorithmic composition that shares certain aesthetic\nmotivations with some work with autonomous music systems, such as the search\nfor emergence. We discuss various strategies for achieving variation on\nmultiple time-scales by using slow-fast, hybrid dynamic systems, and\nstatistical feedback. The ideas are illustrated with a case study.",
    "descriptor": "\nComments: 28 pages, 3 figures. Submitted to Divergence Press\n",
    "authors": [
      "Risto Holopainen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2110.06371"
  },
  {
    "id": "arXiv:2110.06372",
    "title": "Data-driven Leak Localization in Water Distribution Networks via  Dictionary Learning and Graph-based Interpolation",
    "abstract": "In this paper, we propose a data-driven leak localization method for water\ndistribution networks (WDNs) which combines two complementary approaches:\ngraph-based interpolation and dictionary classification. The former estimates\nthe complete WDN hydraulic state (i.e., hydraulic heads) from real measurements\nat certain nodes and the network graph. Then, these actual measurements,\ntogether with a subset of valuable estimated states, are used to feed and train\nthe dictionary learning scheme. Thus, the meshing of these two methods is\nexplored, showing that its performance is superior to either approach alone,\neven deriving different mechanisms to increase its resilience to classical\nproblems (e.g., dimensionality, interpolation errors, etc.). The approach is\nvalidated using the L-TOWN benchmark proposed at BattLeDIM2020.",
    "descriptor": "",
    "authors": [
      "Paul Irofti",
      "Luis Romero-Ben",
      "Florin Stoican",
      "Vicen\u00e7 Puig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.06372"
  },
  {
    "id": "arXiv:2110.06373",
    "title": "Enabling Level-4 Autonomous Driving on a Single $1k Off-the-Shelf Card",
    "abstract": "Autonomous driving is of great interest in both research and industry. The\nhigh cost has been one of the major roadblocks that slow down the development\nand adoption of autonomous driving in practice. This paper, for the first-time,\nshows that it is possible to run level-4 (i.e., fully autonomous driving)\nsoftware on a single off-the-shelf card (Jetson AGX Xavier) for less than $1k,\nan order of magnitude less than the state-of-the-art systems, while meeting all\nthe requirements of latency. The success comes from the resolution of some\nimportant issues shared by existing practices through a series of measures and\ninnovations. The study overturns the common perceptions of the computing\nresources required by level-4 autonomous driving, points out a promising path\nfor the industry to lower the cost, and suggests a number of research\nopportunities for rethinking the architecture, software design, and\noptimizations of autonomous driving.",
    "descriptor": "\nComments: under conference review\n",
    "authors": [
      "Hsin-Hsuan Sung",
      "Yuanchao Xu",
      "Jiexiong Guan",
      "Wei Niu",
      "Shaoshan Liu",
      "Bin Ren",
      "Yanzhi Wang",
      "Xipeng Shen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.06373"
  },
  {
    "id": "arXiv:2110.06375",
    "title": "Coupled and Uncoupled Dynamic Mode Decomposition in Multi-Compartmental  Systems with Applications to Epidemiological and Additive Manufacturing  Problems",
    "abstract": "Dynamic Mode Decomposition (DMD) is an unsupervised machine learning method\nthat has attracted considerable attention in recent years owing to its\nequation-free structure, ability to easily identify coherent spatio-temporal\nstructures in data, and effectiveness in providing reasonably accurate\npredictions for certain problems. Despite these successes, the application of\nDMD to certain problems featuring highly nonlinear transient dynamics remains\nchallenging. In such cases, DMD may not only fail to provide acceptable\npredictions but may indeed fail to recreate the data in which it was trained,\nrestricting its application to diagnostic purposes. For many problems in the\nbiological and physical sciences, the structure of the system obeys a\ncompartmental framework, in which the transfer of mass within the system moves\nwithin states. In these cases, the behavior of the system may not be accurately\nrecreated by applying DMD to a single quantity within the system, as proper\nknowledge of the system dynamics, even for a single compartment, requires that\nthe behavior of other compartments is taken into account in the DMD process. In\nthis work, we demonstrate, theoretically and numerically, that, when performing\nDMD on a fully coupled PDE system with compartmental structure, one may recover\nuseful predictive behavior, even when DMD performs poorly when acting\ncompartment-wise. We also establish that important physical quantities, as mass\nconservation, are maintained in the coupled-DMD extrapolation. The mathematical\nand numerical analysis suggests that DMD may be a powerful tool when applied to\nthis common class of problems. In particular, we show interesting numerical\napplications to a continuous delayed-SIRD model for Covid-19, and to a problem\nfrom additive manufacturing considering a nonlinear temperature field and the\nresulting change of material phase from powder, liquid, and solid states.",
    "descriptor": "",
    "authors": [
      "Alex Viguerie",
      "Gabriel F. Barros",
      "Mal\u00fa Grave",
      "Alessandro Reali",
      "Alvaro L.G.A. Coutinho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.06375"
  },
  {
    "id": "arXiv:2110.06376",
    "title": "ALL Dolphins Are Intelligent and SOME Are Friendly: Probing BERT for  Nouns' Semantic Properties and their Prototypicality",
    "abstract": "Large scale language models encode rich commonsense knowledge acquired\nthrough exposure to massive data during pre-training, but their understanding\nof entities and their semantic properties is unclear. We probe BERT (Devlin et\nal., 2019) for the properties of English nouns as expressed by adjectives that\ndo not restrict the reference scope of the noun they modify (as in \"red car\"),\nbut instead emphasise some inherent aspect (\"red strawberry\"). We base our\nstudy on psycholinguistics datasets that capture the association strength\nbetween nouns and their semantic features. We probe BERT using cloze tasks and\nin a classification setting, and show that the model has marginal knowledge of\nthese features and their prevalence as expressed in these datasets. We discuss\nfactors that make evaluation challenging and impede drawing general conclusions\nabout the models' knowledge of noun properties. Finally, we show that when\ntested in a fine-tuning setting addressing entailment, BERT successfully\nleverages the information needed for reasoning about the meaning of\nadjective-noun constructions outperforming previous methods.",
    "descriptor": "\nComments: Accepted to BlackboxNLP 2021\n",
    "authors": [
      "Marianna Apidianaki",
      "Aina Gar\u00ed Soler"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06376"
  },
  {
    "id": "arXiv:2110.06382",
    "title": "A Survey of Open Source User Activity Traces with Applications to User  Mobility Characterization and Modeling",
    "abstract": "The current state-of-the-art in user mobility research has extensively relied\non open-source mobility traces captured from pedestrian and vehicular activity\nthrough a variety of communication technologies as users engage in a wide-range\nof applications, including connected healthcare, localization, social media,\ne-commerce, etc. Most of these traces are feature-rich and diverse, not only in\nthe information they provide, but also in how they can be used and leveraged.\nThis diversity poses two main challenges for researchers and practitioners who\nwish to make use of available mobility datasets. First, it is quite difficult\nto get a bird's eye view of the available traces without spending considerable\ntime looking them up. Second, once they have found the traces, they still need\nto figure out whether the traces are adequate to their needs.\nThe purpose of this survey is three-fold. It proposes a taxonomy to classify\nopen-source mobility traces including their mobility mode, data source and\ncollection technology. It then uses the proposed taxonomy to classify existing\nopen-source mobility traces and finally, highlights three case studies using\npopular publicly available datasets to showcase how our taxonomy can tease out\nfeature sets in traces to help determine their applicability to specific\nuse-cases.",
    "descriptor": "\nComments: 23 pages, 6 pages references\n",
    "authors": [
      "Sinjoni Mukhopadhyay King",
      "Faisal Nawab",
      "Katia Obraczka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.06382"
  },
  {
    "id": "arXiv:2110.06383",
    "title": "Real-time Drift Detection on Time-series Data",
    "abstract": "Practical machine learning applications involving time series data, such as\nfirewall log analysis to proactively detect anomalous behavior, are concerned\nwith real time analysis of streaming data. Consequently, we need to update the\nML models as the statistical characteristics of such data may shift frequently\nwith time. One alternative explored in the literature is to retrain models with\nupdated data whenever the models accuracy is observed to degrade. However,\nthese methods rely on near real time availability of ground truth, which is\nrarely fulfilled. Further, in applications with seasonal data, temporal concept\ndrift is confounded by seasonal variation. In this work, we propose an approach\ncalled Unsupervised Temporal Drift Detector or UTDD to flexibly account for\nseasonal variation, efficiently detect temporal concept drift in time series\ndata in the absence of ground truth, and subsequently adapt our ML models to\nconcept drift for better generalization.",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "Nandini Ramanan",
      "Rasool Tahmasbi",
      "Marjorie Sayer",
      "Deokwoo Jung",
      "Shalini Hemachandran",
      "Claudionor Nunes Coelho Jr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06383"
  },
  {
    "id": "arXiv:2110.06384",
    "title": "AutoNLU: Detecting, root-causing, and fixing NLU model errors",
    "abstract": "Improving the quality of Natural Language Understanding (NLU) models, and\nmore specifically, task-oriented semantic parsing models, in production is a\ncumbersome task. In this work, we present a system called AutoNLU, which we\ndesigned to scale the NLU quality improvement process. It adds automation to\nthree key steps: detection, attribution, and correction of model errors, i.e.,\nbugs. We detected four times more failed tasks than with random sampling,\nfinding that even a simple active learning sampling method on an uncalibrated\nmodel is surprisingly effective for this purpose. The AutoNLU tool empowered\nlinguists to fix ten times more semantic parsing bugs than with prior manual\nprocesses, auto-correcting 65% of all identified bugs.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Pooja Sethi",
      "Denis Savenkov",
      "Forough Arabshahi",
      "Jack Goetz",
      "Micaela Tolliver",
      "Nicolas Scheffer",
      "Ilknur Kabul",
      "Yue Liu",
      "Ahmed Aly"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06384"
  },
  {
    "id": "arXiv:2110.06385",
    "title": "Evaluation of computer networking methods for interaction with remote  robotic systems",
    "abstract": "Use of robotic infrastructures can significantly increase with remote access.\nThis would open up the possibility to use costly equipment without the need to\nbuy them, or to simply access those assets remotely when actual travel is not\npossible or recommended - for example in pandemic times. In this paper we\npresent an analysis of several networking techniques which allow remote\nrobotics operations, alongside with experimental results with distance ranging\nfrom hundreds of meters up to thousands of kilometers.",
    "descriptor": "",
    "authors": [
      "Peter-Newman Messan",
      "Szymon Krupinski",
      "Guillem Vallicrosa",
      "Pere Ridao",
      "Francesco Maurelli"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.06385"
  },
  {
    "id": "arXiv:2110.06386",
    "title": "Fully-simulated Integration of Scamp5d Vision System and Robot Simulator",
    "abstract": "This paper proposed a fully-simulated environment by integrating an on-sensor\nvisual computing device, SCAMP, and CoppeliaSim robot simulator via interface\nand remote API. Within this platform, a mobile robot obstacle avoidance and\ntarget navigation with pre-set barriers is exploited with on-sensor visual\ncomputing, where images are captured in a robot simulator and processed by an\non-sensor processing server after being transferred. We made our developed\nplatform and associated algorithms for mobile robot navigation available\nonline.",
    "descriptor": "\nComments: 6 pages, 13 figures\n",
    "authors": [
      "Wen Fan",
      "Yanan Liu",
      "Yifan Xing"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.06386"
  },
  {
    "id": "arXiv:2110.06388",
    "title": "HETFORMER: Heterogeneous Transformer with Sparse Attention for Long-Text  Extractive Summarization",
    "abstract": "To capture the semantic graph structure from raw text, most existing\nsummarization approaches are built on GNNs with a pre-trained model. However,\nthese methods suffer from cumbersome procedures and inefficient computations\nfor long-text documents. To mitigate these issues, this paper proposes\nHETFORMER, a Transformer-based pre-trained model with multi-granularity sparse\nattentions for long-text extractive summarization. Specifically, we model\ndifferent types of semantic nodes in raw text as a potential heterogeneous\ngraph and directly learn heterogeneous relationships (edges) among nodes by\nTransformer. Extensive experiments on both single- and multi-document\nsummarization tasks show that HETFORMER achieves state-of-the-art performance\nin Rouge F1 while using less memory and fewer parameters.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Ye Liu",
      "Jian-Guo Zhang",
      "Yao Wan",
      "Congying Xia",
      "Lifang He",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06388"
  },
  {
    "id": "arXiv:2110.06389",
    "title": "Amortized Tree Generation for Bottom-up Synthesis Planning and  Synthesizable Molecular Design",
    "abstract": "Molecular design and synthesis planning are two critical steps in the process\nof molecular discovery that we propose to formulate as a single shared task of\nconditional synthetic pathway generation. We report an amortized approach to\ngenerate synthetic pathways as a Markov decision process conditioned on a\ntarget molecular embedding. This approach allows us to conduct synthesis\nplanning in a bottom-up manner and design synthesizable molecules by decoding\nfrom optimized conditional codes, demonstrating the potential to solve both\nproblems of design and synthesis simultaneously. The approach leverages neural\nnetworks to probabilistically model the synthetic trees, one reaction step at a\ntime, according to reactivity rules encoded in a discrete action space of\nreaction templates. We train these networks on hundreds of thousands of\nartificial pathways generated from a pool of purchasable compounds and a list\nof expert-curated templates. We validate our method with (a) the recovery of\nmolecules using conditional generation, (b) the identification of synthesizable\nstructural analogs, and (c) the optimization of molecular structures given\noracle functions relevant to drug discovery.",
    "descriptor": "",
    "authors": [
      "Wenhao Gao",
      "Roc\u00edo Mercado",
      "Connor W. Coley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2110.06389"
  },
  {
    "id": "arXiv:2110.06393",
    "title": "Attention-guided Generative Models for Extractive Question Answering",
    "abstract": "We propose a novel method for applying Transformer models to extractive\nquestion answering (QA) tasks. Recently, pretrained generative\nsequence-to-sequence (seq2seq) models have achieved great success in question\nanswering. Contributing to the success of these models are internal attention\nmechanisms such as cross-attention. We propose a simple strategy to obtain an\nextractive answer span from the generative model by leveraging the decoder\ncross-attention patterns. Viewing cross-attention as an architectural prior, we\napply joint training to further improve QA performance. Empirical results show\nthat on open-domain question answering datasets like NaturalQuestions and\nTriviaQA, our method approaches state-of-the-art performance on both generative\nand extractive inference, all while using much fewer parameters. Furthermore,\nthis strategy allows us to perform hallucination-free inference while\nconferring significant improvements to the model's ability to rerank relevant\npassages.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Peng Xu",
      "Davis Liang",
      "Zhiheng Huang",
      "Bing Xiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.06393"
  },
  {
    "id": "arXiv:2110.06394",
    "title": "Reward-Free Model-Based Reinforcement Learning with Linear Function  Approximation",
    "abstract": "We study the model-based reward-free reinforcement learning with linear\nfunction approximation for episodic Markov decision processes (MDPs). In this\nsetting, the agent works in two phases. In the exploration phase, the agent\ninteracts with the environment and collects samples without the reward. In the\nplanning phase, the agent is given a specific reward function and uses samples\ncollected from the exploration phase to learn a good policy. We propose a new\nprovably efficient algorithm, called UCRL-RFE under the Linear Mixture MDP\nassumption, where the transition probability kernel of the MDP can be\nparameterized by a linear function over certain feature mappings defined on the\ntriplet of state, action, and next state. We show that to obtain an\n$\\epsilon$-optimal policy for arbitrary reward function, UCRL-RFE needs to\nsample at most $\\tilde O(H^5d^2\\epsilon^{-2})$ episodes during the exploration\nphase. Here, $H$ is the length of the episode, $d$ is the dimension of the\nfeature mapping. We also propose a variant of UCRL-RFE using Bernstein-type\nbonus and show that it needs to sample at most $\\tilde O(H^4d(H +\nd)\\epsilon^{-2})$ to achieve an $\\epsilon$-optimal policy. By constructing a\nspecial class of linear Mixture MDPs, we also prove that for any reward-free\nalgorithm, it needs to sample at least $\\tilde \\Omega(H^2d\\epsilon^{-2})$\nepisodes to obtain an $\\epsilon$-optimal policy. Our upper bound matches the\nlower bound in terms of the dependence on $\\epsilon$ and the dependence on $d$\nif $H \\ge d$.",
    "descriptor": "\nComments: 30 pages, 1 figure, 1 table. In NeurIPS 2021\n",
    "authors": [
      "Weitong Zhang",
      "Dongruo Zhou",
      "Quanquan Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06394"
  },
  {
    "id": "arXiv:2110.06395",
    "title": "Robust Neural Regression via Uncertainty Learning",
    "abstract": "Deep neural networks tend to underestimate uncertainty and produce overly\nconfident predictions. Recently proposed solutions, such as MC Dropout and\nSDENet, require complex training and/or auxiliary out-of-distribution data. We\npropose a simple solution by extending the time-tested iterative reweighted\nleast square (IRLS) in generalised linear regression. We use two sub-networks\nto parametrise the prediction and uncertainty estimation, enabling easy\nhandling of complex inputs and nonlinear response. The two sub-networks have\nshared representations and are trained via two complementary loss functions for\nthe prediction and the uncertainty estimates, with interleaving steps as in a\ncooperative game. Compared with more complex models such as MC-Dropout or\nSDE-Net, our proposed network is simpler to implement and more robust\n(insensitive to varying aleatoric and epistemic uncertainty).",
    "descriptor": "",
    "authors": [
      "Akib Mashrur",
      "Wei Luo",
      "Nayyar A. Zaidi",
      "Antonio Robles-Kelly"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06395"
  },
  {
    "id": "arXiv:2110.06396",
    "title": "GridLearn: Multiagent Reinforcement Learning for Grid-Aware Building  Energy Management",
    "abstract": "Increasing amounts of distributed generation in distribution networks can\nprovide both challenges and opportunities for voltage regulation across the\nnetwork. Intelligent control of smart inverters and other smart building energy\nmanagement systems can be leveraged to alleviate these issues. GridLearn is a\nmultiagent reinforcement learning platform that incorporates both building\nenergy models and power flow models to achieve grid level goals, by controlling\nbehind-the-meter resources. This study demonstrates how multi-agent\nreinforcement learning can preserve building owner privacy and comfort while\npursuing grid-level objectives. Building upon the CityLearn framework which\nconsiders RL for building-level goals, this work expands the framework to a\nnetwork setting where grid-level goals are additionally considered. As a case\nstudy, we consider voltage regulation on the IEEE-33 bus network using\ncontrollable building loads, energy storage, and smart inverters. The results\nshow that the RL agents nominally reduce instances of undervoltages and reduce\ninstances of overvoltages by 34%.",
    "descriptor": "",
    "authors": [
      "Aisling Pigott",
      "Constance Crozier",
      "Kyri Baker",
      "Zoltan Nagy"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06396"
  },
  {
    "id": "arXiv:2110.06397",
    "title": "An Overview of Ontologies and Tool Support for COVID-19 Analytics",
    "abstract": "The outbreak of the SARS-CoV-2 pandemic of the new COVID-19 disease (COVID-19\nfor short) demands empowering existing medical, economic, and social emergency\nbackend systems with data analytics capabilities. An impediment in taking\nadvantages of data analytics in these systems is the lack of a unified\nframework or reference model. Ontologies are highlighted as a promising\nsolution to bridge this gap by providing a formal representation of COVID-19\nconcepts such as symptoms, infections rate, contact tracing, and drug\nmodelling. Ontology-based solutions enable the integration of diverse data\nsources that leads to a better understanding of pandemic data, management of\nsmart lockdowns by identifying pandemic hotspots, and knowledge-driven\ninference, reasoning, and recommendations to tackle surrounding issues.",
    "descriptor": "",
    "authors": [
      "Aakash Ahmad",
      "Madhushi Bandara",
      "Mahdi Fahmideh",
      "Henderik A. Proper",
      "Giancarlo Guizzardi",
      "Jeffrey Soar"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2110.06397"
  },
  {
    "id": "arXiv:2110.06399",
    "title": "Dynamic Inference with Neural Interpreters",
    "abstract": "Modern neural network architectures can leverage large amounts of data to\ngeneralize well within the training distribution. However, they are less\ncapable of systematic generalization to data drawn from unseen but related\ndistributions, a feat that is hypothesized to require compositional reasoning\nand reuse of knowledge. In this work, we present Neural Interpreters, an\narchitecture that factorizes inference in a self-attention network as a system\nof modules, which we call \\emph{functions}. Inputs to the model are routed\nthrough a sequence of functions in a way that is end-to-end learned. The\nproposed architecture can flexibly compose computation along width and depth,\nand lends itself well to capacity extension after training. To demonstrate the\nversatility of Neural Interpreters, we evaluate it in two distinct settings:\nimage classification and visual abstract reasoning on Raven Progressive\nMatrices. In the former, we show that Neural Interpreters perform on par with\nthe vision transformer using fewer parameters, while being transferrable to a\nnew task in a sample efficient manner. In the latter, we find that Neural\nInterpreters are competitive with respect to the state-of-the-art in terms of\nsystematic generalization",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Nasim Rahaman",
      "Muhammad Waleed Gondal",
      "Shruti Joshi",
      "Peter Gehler",
      "Yoshua Bengio",
      "Francesco Locatello",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06399"
  },
  {
    "id": "arXiv:2110.06401",
    "title": "Distributed Gaussian Process Mapping for Robot Teams with Time-varying  Communication",
    "abstract": "Multi-agent mapping is a fundamentally important capability for autonomous\nrobot task coordination and execution in complex environments. While successful\nalgorithms have been proposed for mapping using individual platforms,\ncooperative online mapping for teams of robots remains largely a challenge. We\nfocus on probabilistic variants of mapping due to its potential utility in\ndownstream tasks such as uncertainty-aware path-planning. A critical question\nto enabling this capability is how to process and aggregate incrementally\nobserved local information among individual platforms, especially when their\nability to communicate is intermittent. We put forth an Incremental Sparse\nGaussian Process (GP) methodology for multi-robot mapping, where the regression\nis over a truncated signed-distance field (TSDF). Doing so permits each robot\nin the network to track a local estimate of a pseudo-point approximation GP\nposterior and perform weighted averaging of its parameters with those of its\n(possibly time-varying) set of neighbors. We establish conditions on the\npseudo-point representation, as well as communication protocol, such that\nrobots' local GPs converge to the one with globally aggregated information. We\nfurther provide experiments that corroborate our theoretical findings for\nprobabilistic multi-robot mapping.",
    "descriptor": "",
    "authors": [
      "James Di",
      "Ehsan Zobeidi",
      "Alec Koppel",
      "Nikolay Atanasov"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.06401"
  },
  {
    "id": "arXiv:2110.06403",
    "title": "An Analytical Study of a Two-Sided Mobility Game",
    "abstract": "In this paper, we consider a mobility system of travelers and providers, and\npropose a ``mobility game\" to study when a traveler is matched to a provider.\nEach traveler seeks to travel using the services of only one provider, who\nmanages one specific mode of transportation (car, bus, train, bike). The\nservices of each provider are capacitated and can serve up to a fixed number of\ntravelers at any instant of time. Thus, our problem falls under the category of\nmany-to-one assignment problems, where the goal is to find the conditions that\nguarantee the stability of assignments. We formulate a linear program of\nmaximizing the social welfare of travelers and providers and show how it is\nequivalent to the original problem and relate its solutions to stable\nassignments. We also investigate our results under informational asymmetry and\nprovide a ``mechanism\" that elicits the information of travelers and providers.\nFinally, we investigate and validate the advantages of our method by providing\na numerical simulation example.",
    "descriptor": "",
    "authors": [
      "Ioannis Vasileios Chremos",
      "Andreas Malikopoulos"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.06403"
  },
  {
    "id": "arXiv:2110.06407",
    "title": "Efficient Linearizability Checking for Actor-based Systems",
    "abstract": "Recent demand for distributed software had led to a surge in popularity in\nactor-based frameworks. However, even with the stylized message passing model\nof actors, writing correct distributed software is still difficult. We present\nour work on linearizability checking in DS2, an integrated framework for\nspecifying, synthesizing, and testing distributed actor systems. The key\ninsight of our approach is that often subcomponents of distributed actor\nsystems represent common algorithms or data structures (e.g.\\ a distributed\nhash table or tree) that can be validated against a simple sequential model of\nthe system. This makes it easy for developers to validate their concurrent\nactor systems without complex specifications. DS2 automatically explores the\nconcurrent schedules that system could arrive at, and it compares observed\noutput of the system to ensure it is equivalent to what the sequential\nimplementation could have produced. We describe DS2's linearizability checking\nand test it on several concurrent replication algorithms from the literature.\nWe explore in detail how different algorithms for enumerating the model\nschedule space fare in finding bugs in actor systems, and we present our own\nrefinements on algorithms for exploring actor system schedules that we show are\neffective in finding bugs.",
    "descriptor": "\nComments: This article was submitted around Feb 2021 to the journal of \"Software Practice and Experience\" and not yet finished the review process. So they allow us to submit it to one more personal archival service e.g. this one. That is, this is unpublished work yet\n",
    "authors": [
      "Mohammed S. Al-Mahfoudh",
      "Ryan Stutsman",
      "Ganesh Gopalakrishnan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.06407"
  },
  {
    "id": "arXiv:2110.06410",
    "title": "Attributed Graph Modeling with Vertex Replacement Grammars",
    "abstract": "Recent work at the intersection of formal language theory and graph theory\nhas explored graph grammars for graph modeling. However, existing models and\nformalisms can only operate on homogeneous (i.e., untyped or unattributed)\ngraphs. We relax this restriction and introduce the Attributed Vertex\nReplacement Grammar (AVRG), which can be efficiently extracted from\nheterogeneous (i.e., typed, colored, or attributed) graphs. Unlike current\nstate-of-the-art methods, which train enormous models over complicated deep\nneural architectures, the AVRG model is unsupervised and interpretable. It is\nbased on context-free string grammars and works by encoding graph rewriting\nrules into a graph grammar containing graphlets and instructions on how they\nfit together. We show that the AVRG can encode succinct models of input graphs\nyet faithfully preserve their structure and assortativity properties.\nExperiments on large real-world datasets show that graphs generated from the\nAVRG model exhibit substructures and attribute configurations that match those\nfound in the input networks.",
    "descriptor": "\nComments: 9 pages, 2 tables, 10 figures. Accepted as a regular paper at WSDM 2021\n",
    "authors": [
      "Satyaki Sikdar",
      "Neil Shah",
      "Tim Weninger"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.06410"
  },
  {
    "id": "arXiv:2110.06412",
    "title": "Offset-Symmetric Gaussians for Differential Privacy",
    "abstract": "The Gaussian distribution is widely used in mechanism design for differential\nprivacy (DP). Thanks to its sub-Gaussian tail, it significantly reduces the\nchance of outliers when responding to queries. However, it can only provide\napproximate $(\\epsilon, \\delta(\\epsilon))$-DP. In practice, $\\delta(\\epsilon)$\nmust be much smaller than the size of the dataset, which may limit the use of\nthe Gaussian mechanism for large datasets with strong privacy requirements. In\nthis paper, we introduce and analyze a new distribution for use in DP that is\nbased on the Gaussian distribution, but has improved privacy performance. The\nso-called offset-symmetric Gaussian tail (OSGT) distribution is obtained\nthrough using the normalized tails of two symmetric Gaussians around zero.\nConsequently, it can still have sub-Gaussian tail and lend itself to analytical\nderivations. We analytically derive the variance of the OSGT random variable\nand the $\\delta(\\epsilon)$ of the OSGT mechanism. We then numerically show that\nat the same variance, the OSGT mechanism can offer a lower $\\delta(\\epsilon)$\nthan the Gaussian mechanism. We extend the OSGT mechanism to $k$-dimensional\nqueries and derive an easy-to-compute analytical upper bound for its\nzero-concentrated differential privacy (zCDP) performance. We analytically\nprove that at the same variance, the same global query sensitivity and for\nsufficiently large concentration orders $\\alpha$, the OSGT mechanism performs\nbetter than the Gaussian mechanism in terms of zCDP.",
    "descriptor": "",
    "authors": [
      "Parastoo Sadeghi",
      "Mehdi Korki"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.06412"
  },
  {
    "id": "arXiv:2110.06413",
    "title": "3LSAA: A Secure And Privacy-preserving Zero-knowledge-based Data-sharing  Approach Under An Untrusted Environment",
    "abstract": "As data collection and analysis become critical functions for many cloud\napplications, proper data sharing with approved parties is required. However,\nthe traditional data sharing scheme through centralized data escrow servers may\nsacrifice owners' privacy and is weak in security. Mainly, the servers\nphysically own all data while the original data owners have only virtual\nownership and lose actual access control. Therefore, we propose a 3-layer\nSSE-ABE-AES (3LSAA) cryptography-based privacy-protected data-sharing protocol\nbased on the assumption that servers are honest-but-curious. The 3LSAA protocol\nrealizes automatic access control management and convenient file search even if\nthe server is not trustable. Besides achieving data self-sovereignty, our\napproach also improves system usability, eliminates the defects in the\ntraditional SSE and ABE approaches, and provides a local AES key recovery\nmethod for user's availability.",
    "descriptor": "\nComments: 21 pages, 7 figures\n",
    "authors": [
      "Wei-Yi Kuo",
      "Ren-Song Tsay"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.06413"
  },
  {
    "id": "arXiv:2110.06416",
    "title": "MMIU: Dataset for Visual Intent Understanding in Multimodal Assistants",
    "abstract": "In multimodal assistant, where vision is also one of the input modalities,\nthe identification of user intent becomes a challenging task as visual input\ncan influence the outcome. Current digital assistants take spoken input and try\nto determine the user intent from conversational or device context. So, a\ndataset, which includes visual input (i.e. images or videos for the\ncorresponding questions targeted for multimodal assistant use cases, is not\nreadily available. The research in visual question answering (VQA) and visual\nquestion generation (VQG) is a great step forward. However, they do not capture\nquestions that a visually-abled person would ask multimodal assistants.\nMoreover, many times questions do not seek information from external knowledge.\nIn this paper, we provide a new dataset, MMIU (MultiModal Intent\nUnderstanding), that contains questions and corresponding intents provided by\nhuman annotators while looking at images. We, then, use this dataset for intent\nclassification task in multimodal digital assistant. We also experiment with\nvarious approaches for combining vision and language features including the use\nof multimodal transformer for classification of image-question pairs into 14\nintents. We provide the benchmark results and discuss the role of visual and\ntext features for the intent classification task on our dataset.",
    "descriptor": "\nComments: Extended abstract accepted for WeCNLP 2021\n",
    "authors": [
      "Alkesh Patel",
      "Joel Ruben Antony Moniz",
      "Roman Nguyen",
      "Nick Tzou",
      "Hadas Kotek",
      "Vincent Renkens"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06416"
  },
  {
    "id": "arXiv:2110.06418",
    "title": "Stabilizing Dynamical Systems via Policy Gradient Methods",
    "abstract": "Stabilizing an unknown control system is one of the most fundamental problems\nin control systems engineering. In this paper, we provide a simple, model-free\nalgorithm for stabilizing fully observed dynamical systems. While model-free\nmethods have become increasingly popular in practice due to their simplicity\nand flexibility, stabilization via direct policy search has received\nsurprisingly little attention. Our algorithm proceeds by solving a series of\ndiscounted LQR problems, where the discount factor is gradually increased. We\nprove that this method efficiently recovers a stabilizing controller for linear\nsystems, and for smooth, nonlinear systems within a neighborhood of their\nequilibria. Our approach overcomes a significant limitation of prior work,\nnamely the need for a pre-given stabilizing control policy. We empirically\nevaluate the effectiveness of our approach on common control benchmarks.",
    "descriptor": "\nComments: accepted for publication at Neurips 2021\n",
    "authors": [
      "Juan C. Perdomo",
      "Jack Umenberger",
      "Max Simchowitz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06418"
  },
  {
    "id": "arXiv:2110.06419",
    "title": "Federated Natural Language Generation for Personalized Dialogue System",
    "abstract": "Neural conversational models have long suffered from the problem of\ninconsistency and lacking coherent personality. To address the issue,\npersona-based models capturing individual characteristics have been proposed,\nbut they still face the dilemma of model adaption and data privacy. To break\nthis dilemma, we propose a novel Federated Natural Language Generation (FedNLG)\nframework, which learns personalized representations from various dataset on\ndistributed devices, and thus implements the personalized dialogue system\nefficiently and safely. FedNLG first pre-trains parameters of standard neural\nconversational model over a large dialogue corpus, and then fine-tune the model\nparameters and persona embeddings on specific datasets, in a federated manner.\nThus, the model could simultaneously learn the persona embeddings in local\nclients and learn shared model parameters by federated aggregation, which\nachieves accuracyprivacy balance. By conducting extensive experiments, we\ndemonstrate the effectiveness of our model by pre-training model over Cornell\nMovie-Dialogs Corpus and fine-tuning the model over two TV series dataset.",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Yujie Lu",
      "Chao Huang",
      "Huanli Zhan",
      "Yong Zhuang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06419"
  },
  {
    "id": "arXiv:2110.06420",
    "title": "An open question about powers of log(n) in quasi-Monte Carlo",
    "abstract": "The commonly quoted error rate for QMC integration with an infinite low\ndiscrepancy sequence is $O(n^{-1}\\log(n)^d)$. This holds uniformly over $d$\ndimensional integrands of Hardy-Krause variation one when using $n$ evaluation\npoints. Implicit in the rate is that for any sequence of QMC points the\nintegrand can be chosen to depend on $n$. If we have a fixed integrand, should\nwe expect to need those powers of $\\log(n)$ as $n\\to\\infty$? That is, do those\npowers provide a realistic idea of the progress that the algorithm makes as\n$n\\to\\infty$? This paper poses an open question about whether there is any $f$\nand any $(t,d)$-sequence for which the absolute error exceeds a positive\nmultiple of $\\log(n)^r/n$ infinitely often for some $r>1$. For $r=1$, such\nfunctions are known from the discrepancy literature even for $d=1$. An\nempirical search when $d=2$ for integrands designed to exploit known weaknesses\nin certain point sets showed no evidence that $r>1$ is needed. An example with\n$d=3$ and $n$ up to $2^{100}$ appears to require $r>1$. Of course neither of\nthese resolve the open problem.",
    "descriptor": "",
    "authors": [
      "Art B. Owen",
      "Zexin Pan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.06420"
  },
  {
    "id": "arXiv:2110.06421",
    "title": "Revisiting Latent-Space Interpolation via a Quantitative Evaluation  Framework",
    "abstract": "Latent-space interpolation is commonly used to demonstrate the generalization\nability of deep latent variable models. Various algorithms have been proposed\nto calculate the best trajectory between two encodings in the latent space. In\nthis work, we show how data labeled with semantically continuous attributes can\nbe utilized to conduct a quantitative evaluation of latent-space interpolation\nalgorithms, for variational autoencoders. Our framework can be used to\ncomplement the standard qualitative comparison, and also enables evaluation for\ndomains (such as graph) in which the visualization is difficult. Interestingly,\nour experiments reveal that the superiority of interpolation algorithms could\nbe domain-dependent. While normalised interpolation works best for the image\ndomain, spherical linear interpolation achieves the best performance in the\ngraph domain. Next, we propose a simple-yet-effective method to restrict the\nlatent space via a bottleneck structure in the encoder. We find that all\ninterpolation algorithms evaluated in this work can benefit from this\nrestriction. Finally, we conduct interpolation-aware training with the labeled\nattributes, and show that this explicit supervision can improve the\ninterpolation performance.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Lu Mi",
      "Tianxing He",
      "Core Francisco Park",
      "Hao Wang",
      "Yue Wang",
      "Nir Shavit"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06421"
  },
  {
    "id": "arXiv:2110.06423",
    "title": "On the Behaviour of Under-tuned Super-Twisting Sliding Mode Control  Loops",
    "abstract": "This paper investigates the stability properties and performance of\nsuper-twisting sliding-mode control loops subject to periodic perturbations.\nAlthough there exist conditions on the control gains that guarantee finite-time\nstability of the closed-loop system, such conditions are often too restrictive\nfrom a practical standpoint, especially in relation to actuator limitations and\ninduced chatter. Using regularisation and averaging theory, it is proven that\nunder milder conditions for the control gains, the trajectories of the\nperiodically perturbed closed-loop system converge to a stable limit cycle of\nthe same period containing the origin. Additionally, guidelines for selecting\nthe controller gains are provided based on bounds of the closed-loop system\nstates. Finally, the theoretical findings are validated through simulations.",
    "descriptor": "\nComments: Preprint - Submitted to Automatica\n",
    "authors": [
      "Dimitrios Papageorgiou",
      "Christopher Edwards"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.06423"
  },
  {
    "id": "arXiv:2110.06427",
    "title": "Dense Uncertainty Estimation",
    "abstract": "Deep neural networks can be roughly divided into deterministic neural\nnetworks and stochastic neural networks.The former is usually trained to\nachieve a mapping from input space to output space via maximum likelihood\nestimation for the weights, which leads to deterministic predictions during\ntesting. In this way, a specific weights set is estimated while ignoring any\nuncertainty that may occur in the proper weight space. The latter introduces\nrandomness into the framework, either by assuming a prior distribution over\nmodel parameters (i.e. Bayesian Neural Networks) or including latent variables\n(i.e. generative models) to explore the contribution of latent variables for\nmodel predictions, leading to stochastic predictions during testing. Different\nfrom the former that achieves point estimation, the latter aims to estimate the\nprediction distribution, making it possible to estimate uncertainty,\nrepresenting model ignorance about its predictions. We claim that conventional\ndeterministic neural network based dense prediction tasks are prone to\noverfitting, leading to over-confident predictions, which is undesirable for\ndecision making. In this paper, we investigate stochastic neural networks and\nuncertainty estimation techniques to achieve both accurate deterministic\nprediction and reliable uncertainty estimation. Specifically, we work on two\ntypes of uncertainty estimations solutions, namely ensemble based methods and\ngenerative model based methods, and explain their pros and cons while using\nthem in fully/semi/weakly-supervised framework. Due to the close connection\nbetween uncertainty estimation and model calibration, we also introduce how\nuncertainty estimation can be used for deep model calibration to achieve\nwell-calibrated models, namely dense model calibration. Code and data are\navailable at https://github.com/JingZhang617/UncertaintyEstimation.",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Jing Zhang",
      "Yuchao Dai",
      "Mochu Xiang",
      "Deng-Ping Fan",
      "Peyman Moghadam",
      "Mingyi He",
      "Christian Walder",
      "Kaihao Zhang",
      "Mehrtash Harandi",
      "Nick Barnes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06427"
  },
  {
    "id": "arXiv:2110.06430",
    "title": "Random batch particle methods for the homogeneous Landau equation",
    "abstract": "We consider in this paper random batch particle methods for efficiently\nsolving the homogeneous Landau equation in plasma physics. The methods are\nstochastic variations of the particle methods proposed by Carrillo et al. [J.\nComput. Phys.: X 7: 100066, 2020] using the random batch strategy. The\ncollisions only take place inside the small but randomly selected batches so\nthat the computational cost is reduced to $O(N)$ per time step. Meanwhile, our\nmethods can preserve the conservation of mass, momentum, energy and the decay\nof entropy. Several numerical examples are performed to validate our methods.",
    "descriptor": "",
    "authors": [
      "Jos\u00e9 Antonio Carrillo",
      "Shi Jin",
      "Yijia Tang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.06430"
  },
  {
    "id": "arXiv:2110.06435",
    "title": "Dropout Prediction Variation Estimation Using Neuron Activation Strength",
    "abstract": "It is well-known DNNs would generate different prediction results even given\nthe same model configuration and training dataset. As a result, it becomes more\nand more important to study prediction variation, i.e. the variation of the\npredictions on a given input example, in neural network models. Dropout has\nbeen commonly used in various applications to quantify prediction variations.\nHowever, using dropout in practice can be expensive as it requires running\ndropout inference many times to estimate prediction variation.\nIn this paper, we study how to estimate dropout prediction variation in a\nresource-efficient manner. In particular, we demonstrate that we can use neuron\nactivation strength to estimate dropout prediction variation under different\ndropout settings and on a variety of tasks using three large datasets,\nMovieLens, Criteo, and EMNIST. Our approach provides an inference-once\nalternative to estimate dropout prediction variation as an auxiliary task when\nthe main prediction model is served. Moreover, we show that using activation\nstrength features from a subset of neural network layers can be sufficient to\nachieve similar variation estimation performance compared to using activation\nfeatures from all layers. This can provide further resource reduction for\nvariation estimation.",
    "descriptor": "",
    "authors": [
      "Haichao Yu",
      "Zhe Chen",
      "Dong Lin",
      "Gil Shamir",
      "Jie Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06435"
  },
  {
    "id": "arXiv:2110.06436",
    "title": "Non-local Recurrent Regularization Networks for Multi-view Stereo",
    "abstract": "In deep multi-view stereo networks, cost regularization is crucial to achieve\naccurate depth estimation. Since 3D cost volume filtering is usually\nmemory-consuming, recurrent 2D cost map regularization has recently become\npopular and has shown great potential in reconstructing 3D models of different\nscales. However, existing recurrent methods only model the local dependencies\nin the depth domain, which greatly limits the capability of capturing the\nglobal scene context along the depth dimension. To tackle this limitation, we\npropose a novel non-local recurrent regularization network for multi-view\nstereo, named NR2-Net. Specifically, we design a depth attention module to\ncapture non-local depth interactions within a sliding depth block. Then, the\nglobal scene context between different blocks is modeled in a gated recurrent\nmanner. This way, the long-range dependencies along the depth dimension are\ncaptured to facilitate the cost regularization. Moreover, we design a dynamic\ndepth map fusion strategy to improve the algorithm robustness. Our method\nachieves state-of-the-art reconstruction results on both DTU and Tanks and\nTemples datasets.",
    "descriptor": "",
    "authors": [
      "Qingshan Xu",
      "Martin R. Oswald",
      "Wenbing Tao",
      "Marc Pollefeys",
      "Zhaopeng Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06436"
  },
  {
    "id": "arXiv:2110.06439",
    "title": "Statistical CSI-Based Transmission Design for Reconfigurable Intelligent  Surface-aided Massive MIMO Systems with Hardware Impairments",
    "abstract": "We consider a reconfigurable intelligent surface (RIS)-aided massive\nmulti-user multiple-input multiple-output (MIMO) communication system with\ntransceiver hardware impairments (HWIs) and RIS phase noise. Different from the\nexisting contributions, the phase shifts of the RIS are designed based on the\nlong-term angle informations. Firstly, an approximate analytical expression of\nthe uplink achievable rate is derived. Then, we use genetic algorithm (GA) to\nmaximize the sum rate and the minimum date rate. Finally, we show that it is\ncrucial to take HWIs into account when designing the phase shift of RIS.",
    "descriptor": "\nComments: Accepted by IEEE Wireless Communications Letters. Keywords: Reconfigurable Intelligent Surface, Intelligent Reflecting Surface, Massive MIMO, Channel estimation, etc\n",
    "authors": [
      "Jianxin Dai",
      "Feng Zhu",
      "Cunhua Pan",
      "Hong Ren",
      "Kezhi Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.06439"
  },
  {
    "id": "arXiv:2110.06441",
    "title": "Incentive-aware Electric Vehicle Routing Problem: a Bi-level Model and a  Joint Solution Algorithm",
    "abstract": "Fixed pickup and delivery times can strongly limit the performance of freight\ntransportation. Against this backdrop, fleet operators can use compensation\nmechanisms such as monetary incentives to buy delay time from their customers,\nin order to improve the fleet efficiency and ultimately minimize the costs of\noperation. To make the most of such an operational model, the fleet activities\nand the incentives should be jointly optimized accounting for the customers'\nreactions. Against this backdrop, this paper presents an incentive-aware\nelectric vehicle routing scheme in which the fleet operator actively provides\nincentives to the customers in exchange of pickup or delivery time flexibility.\nSpecifically, we first devise a bi-level model whereby the fleet operator\noptimizes the routes and charging schedules of the fleet jointly with an\nincentive rate to reimburse the delivery delays experienced by the customers.\nAt the same time, the customers choose the admissible delays by minimizing a\nmonetarily-weighted combination of the delays minus the reimbursement offered\nby the operator. Second, we tackle the complexity resulting from the bi-level\nand nonlinear problem structure with an equivalent transformation method,\nreformulating the problem as a single-level optimization problem that can be\nsolved with standard mixed-integer linear programming algorithms. We\ndemonstrate the effectiveness of our framework via extensive numerical\nexperiments using VRP-REP data from Belgium. Our results show that by jointly\noptimizing routes and incentives subject to the customers' preferences, the\noperational costs can be reduced by up to 5%, whilst customers can save more\nthan 30% in total delivery fees.",
    "descriptor": "\nComments: Submitted to ACC2022\n",
    "authors": [
      "Canqi Yao",
      "Shibo Chen",
      "Mauro Salazar",
      "Zaiyue Yang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.06441"
  },
  {
    "id": "arXiv:2110.06443",
    "title": "Harnessing the Conditioning Sensorium for Improved Image Translation",
    "abstract": "Multi-modal domain translation typically refers to synthesizing a novel image\nthat inherits certain localized attributes from a 'content' image (e.g. layout,\nsemantics, or geometry), and inherits everything else (e.g. texture, lighting,\nsometimes even semantics) from a 'style' image. The dominant approach to this\ntask is attempting to learn disentangled 'content' and 'style' representations\nfrom scratch. However, this is not only challenging, but ill-posed, as what\nusers wish to preserve during translation varies depending on their goals.\nMotivated by this inherent ambiguity, we define 'content' based on conditioning\ninformation extracted by off-the-shelf pre-trained models. We then train our\nstyle extractor and image decoder with an easy to optimize set of\nreconstruction objectives. The wide variety of high-quality pre-trained models\navailable and simple training procedure makes our approach straightforward to\napply across numerous domains and definitions of 'content'. Additionally it\noffers intuitive control over which aspects of 'content' are preserved across\ndomains. We evaluate our method on traditional, well-aligned, datasets such as\nCelebA-HQ, and propose two novel datasets for evaluation on more complex\nscenes: ClassicTV and FFHQ-Wild. Our approach, Sensorium, enables higher\nquality domain translation for more complex scenes.",
    "descriptor": "",
    "authors": [
      "Cooper Nederhood",
      "Nicholas Kolkin",
      "Deqing Fu",
      "Jason Salavon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06443"
  },
  {
    "id": "arXiv:2110.06446",
    "title": "Improving Graph-based Sentence Ordering with Iteratively Predicted  Pairwise Orderings",
    "abstract": "Dominant sentence ordering models can be classified into pairwise ordering\nmodels and set-to-sequence models. However, there is little attempt to combine\nthese two types of models, which inituitively possess complementary advantages.\nIn this paper, we propose a novel sentence ordering framework which introduces\ntwo classifiers to make better use of pairwise orderings for graph-based\nsentence ordering. Specially, given an initial sentence-entity graph, we first\nintroduce a graph-based classifier to predict pairwise orderings between linked\nsentences. Then, in an iterative manner, based on the graph updated by\npreviously predicted high-confident pairwise orderings, another classifier is\nused to predict the remaining uncertain pairwise orderings. At last, we adapt a\nGRN-based sentence ordering model on the basis of final graph. Experiments on\nfive commonly-used datasets demonstrate the effectiveness and generality of our\nmodel. Particularly, when equipped with BERT and FHDecoder, our model achieves\nstate-of-the-art performance.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Shaopeng Lai",
      "Ante Wang",
      "Fandong Meng",
      "Jie Zhou",
      "Yubin Ge",
      "Jiali Zeng",
      "Junfeng Yao",
      "Degen Huang",
      "Jinsong Su"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06446"
  },
  {
    "id": "arXiv:2110.06448",
    "title": "Reducing the Covariate Shift by Mirror Samples in Cross Domain Alignment",
    "abstract": "Eliminating the covariate shift cross domains is one of the common methods to\ndeal with the issue of domain shift in visual unsupervised domain adaptation.\nHowever, current alignment methods, especially the prototype based or\nsample-level based methods neglect the structural properties of the underlying\ndistribution and even break the condition of covariate shift. To relieve the\nlimitations and conflicts, we introduce a novel concept named (virtual) mirror,\nwhich represents the equivalent sample in another domain. The equivalent sample\npairs, named mirror pairs reflect the natural correspondence of the empirical\ndistributions. Then a mirror loss, which aligns the mirror pairs cross domains,\nis constructed to enhance the alignment of the domains. The proposed method\ndoes not distort the internal structure of the underlying distribution. We also\nprovide theoretical proof that the mirror samples and mirror loss have better\nasymptotic properties in reducing the domain shift. By applying the virtual\nmirror and mirror loss to the generic unsupervised domain adaptation model, we\nachieved consistent superior performance on several mainstream benchmarks.",
    "descriptor": "\nComments: Accept by NeurIPS 2021\n",
    "authors": [
      "Yin Zhao",
      "Minquan Wang",
      "Longjun Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06448"
  },
  {
    "id": "arXiv:2110.06449",
    "title": "Constrained Detecting Arrays: Mathematical Structures for Fault  Identification in Combinatorial Interaction Testing",
    "abstract": "Context: Detecting arrays are mathematical structures aimed at fault\nidentification in combinatorial interaction testing. However, they cannot be\ndirectly applied to systems that have constraints among test parameters. Such\nconstraints are prevalent in real-world systems.\nObjectives: This paper proposes Constrained Detecting Arrays (CDAs), an\nextension of detecting arrays, which can be used for systems with constraints.\nMethods: The paper examines the properties and capabilities of CDAs with\nrigorous arguments. The paper also proposes two algorithms for constructing\nCDAs: One is aimed at generating minimum CDAs and the other is a heuristic\nalgorithm aimed at fast generation of CDAs. The algorithms are evaluated\nthrough experiments using a benchmark dataset.\nResults: Experimental results show that the first algorithm can generate\nminimum CDAs if a sufficiently long generation time is allowed, and the second\nalgorithm can generate minimum or near-minimum CDAs in a reasonable time.\nConclusion: CDAs enhance detecting arrays to be applied to systems with\nconstraints. The two proposed algorithms have different advantages with respect\nto the array size and generation time",
    "descriptor": "",
    "authors": [
      "Hao Jin",
      "Ce Shi",
      "Tatsuhiro Tsuchiya"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.06449"
  },
  {
    "id": "arXiv:2110.06452",
    "title": "\"I need a better description'': An Investigation Into User Expectations  For Differential Privacy",
    "abstract": "Despite recent widespread deployment of differential privacy, relatively\nlittle is known about what users think of differential privacy. In this work,\nwe seek to explore users' privacy expectations related to differential privacy.\nSpecifically, we investigate (1) whether users care about the protections\nafforded by differential privacy, and (2) whether they are therefore more\nwilling to share their data with differentially private systems. Further, we\nattempt to understand (3) users' privacy expectations of the differentially\nprivate systems they may encounter in practice and (4) their willingness to\nshare data in such systems. To answer these questions, we use a series of\nrigorously conducted surveys (n=2424).\nWe find that users care about the kinds of information leaks against which\ndifferential privacy protects and are more willing to share their private\ninformation when the risks of these leaks are less likely to happen.\nAdditionally, we find that the ways in which differential privacy is described\nin-the-wild haphazardly set users' privacy expectations, which can be\nmisleading depending on the deployment. We synthesize our results into a\nframework for understanding a user's willingness to share information with\ndifferentially private systems, which takes into account the interaction\nbetween the user's prior privacy concerns and how differential privacy is\ndescribed.",
    "descriptor": "\nComments: A version of this paper appears in the proceedings of the 28th ACM Conference on Computer and Communications Security (CCS 2021)\n",
    "authors": [
      "Rachel Cummings",
      "Gabriel Kaptchuk",
      "Elissa M. Redmiles"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.06452"
  },
  {
    "id": "arXiv:2110.06455",
    "title": "Seismic Tomography with Random Batch Gradient Reconstruction",
    "abstract": "Seismic tomography solves high-dimensional optimization problems to image\nsubsurface structures of Earth. In this paper, we propose to use random batch\nmethods to construct the gradient used for iterations in seismic tomography.\nSpecifically, we use the frozen Gaussian approximation to compute seismic wave\npropagation, and then construct stochastic gradients by random batch methods.\nThe method inherits the spirit of stochastic gradient descent methods for\nsolving high-dimensional optimization problems. The proposed idea is general in\nthe sense that it does not rely on the usage of the frozen Gaussian\napproximation, and one can replace it with any other efficient wave propagation\nsolvers, e.g., Gaussian beam methods. We prove the convergence of the random\nbatch method in the mean-square sense, and show the numerical performance of\nthe proposed method by two-dimensional and three-dimensional examples of\nwave-equation-based travel-time inversion and full-waveform inversion,\nrespectively.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Yixiao Hu",
      "Lihui Chai",
      "Zhongyi Huang",
      "Xu Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.06455"
  },
  {
    "id": "arXiv:2110.06456",
    "title": "Updating Street Maps using Changes Detected in Satellite Imagery",
    "abstract": "Accurately maintaining digital street maps is labor-intensive. To address\nthis challenge, much work has studied automatically processing geospatial data\nsources such as GPS trajectories and satellite images to reduce the cost of\nmaintaining digital maps. An end-to-end map update system would first process\ngeospatial data sources to extract insights, and second leverage those insights\nto update and improve the map. However, prior work largely focuses on the first\nstep of this pipeline: these map extraction methods infer road networks from\nscratch given geospatial data sources (in effect creating entirely new maps),\nbut do not address the second step of leveraging this extracted information to\nupdate the existing digital map data. In this paper, we first explain why\ncurrent map extraction techniques yield low accuracy when extended to update\nexisting maps. We then propose a novel method that leverages the progression of\nsatellite imagery over time to substantially improve accuracy. Our approach\nfirst compares satellite images captured at different times to identify\nportions of the physical road network that have visibly changed, and then\nupdates the existing map accordingly. We show that our change-based approach\nreduces map update error rates four-fold.",
    "descriptor": "\nComments: SIGSPATIAL 2021\n",
    "authors": [
      "Favyen Bastani",
      "Songtao He",
      "Satvat Jagwani",
      "Mohammad Alizadeh",
      "Hari Balakrishnan",
      "Sanjay Chawla",
      "Sam Madden",
      "Mohammad Amin Sadeghi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06456"
  },
  {
    "id": "arXiv:2110.06458",
    "title": "Stiffness optimisation of graded microstructal configurations using  asymptotic analysis and machine learning",
    "abstract": "The article is aimed to address a combinative use of asymptotic analysis and\nmachine learning, for fast stiffness design of configurations infilled with\nsmoothly-varying graded microstructures. The discussion is conducted in the\ncontext of an improved asymptotic-homogenisation topology optimisation (AHTO\nplus) framework (Zhu et al., 2019). It is demonstrated that machine learning\ncan be employed to represent the key but implicit inter-relationships between\nformulations obtained at different orders from asymptotic analysis. Moreover,\nin the context of microstructural homogenisation, asymptotic analysis helps\noffer a platform for machine learning to release its full potentials in\nfunction representation. Firstly, asymptotic analysis identifies a\ncomputational routine for data acquisition, thus the training data are\nsufficient in theory. Secondly, the number of input arguments for machine\nlearning can be minimised based on the explicit results by asymptotic analysis,\nand the scale of the machine learning model in use is kept small. Thirdly, the\ninput arguments for machine learning are shown to be complete. Then the\nsituation where certain factors affecting the function relationship represented\nby machine learning is avoided. Other issues on incorporating machine learning\ninto the AHTO plus framework, such as ensuring the positive definiteness of the\nhomogenised elasticity tensor and the speeding-up of the associated sensitivity\nanalysis, are also discussed here. Numerical examples show that the use of\nmachine learning in the AHTO plus scheme can bring about an acceleration by two\norders of magnitude, if compared with the existing treatments of using a zoning\nstrategy.",
    "descriptor": "\nComments: 37 pages, 12 figures, 2 tables\n",
    "authors": [
      "Chuang Ma",
      "Dingchuan Xue",
      "Shaoshuai Li",
      "Zhengcheng Zhou",
      "Yichao Zhu",
      "Xu Guo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.06458"
  },
  {
    "id": "arXiv:2110.06459",
    "title": "Learning to Select Historical News Articles for Interaction based Neural  News Recommendation",
    "abstract": "The key to personalized news recommendation is to match the user's interests\nwith the candidate news precisely and efficiently. Most existing approaches\nembed user interests into a representation vector then recommend by comparing\nit with the candidate news vector. In such a workflow, fine-grained matching\nsignals may be lost. Recent studies try to cover that by modeling fine-grained\ninteractions between the candidate news and each browsed news article of the\nuser. Despite the effectiveness improvement, these models suffer from much\nhigher computation costs online. Consequently, it remains a tough issue to take\nadvantage of effective interactions in an efficient way. To address this\nproblem, we proposed an end-to-end Selective Fine-grained Interaction framework\n(SFI) with a learning-to-select mechanism. Instead of feeding all historical\nnews into interaction, SFI can quickly select informative historical news\nw.r.t. the candidate and exclude others from following computations. We empower\nthe selection to be both sparse and automatic, which guarantees efficiency and\neffectiveness respectively. Extensive experiments on the publicly available\ndataset MIND validates the superiority of SFI over the state-of-the-art\nmethods: with only five historical news selected, it can significantly improve\nthe AUC by 2.17% over the state-of-the-art interaction-based models; at the\nsame time, it is four times faster.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Peitian Zhang",
      "Zhicheng Dou",
      "Jing Yao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06459"
  },
  {
    "id": "arXiv:2110.06460",
    "title": "Data-Time Tradeoffs for Optimal k-Thresholding Algorithms in Compressed  Sensing",
    "abstract": "Optimal $k$-thresholding algorithms are a class of sparse signal recovery\nalgorithms that overcome the shortcomings of traditional hard thresholding\nalgorithms caused by the oscillation of the residual function. In this paper,\nwe provide a novel theoretical analysis for the data-time tradeoffs of optimal\n$k$-thresholding algorithms. Both the analysis and numerical results\ndemonstrate that when the number of measurements is small, the algorithms\ncannot converge; when the number of measurements is suitably large, the number\nof measurements required for successful recovery has a negative correlation\nwith the number of iterations and the algorithms can achieve linear\nconvergence. Furthermore, the theory presents that the transition point of the\nnumber of measurements is on the order of $k \\log({en}/{k})$, where $n$ is the\ndimension of the target signal.",
    "descriptor": "\nComments: 12 pages, 2 figures\n",
    "authors": [
      "Jialiang Xu",
      "Xu Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.06460"
  },
  {
    "id": "arXiv:2110.06461",
    "title": "Fake News Detection in Spanish Using Deep Learning Techniques",
    "abstract": "This paper addresses the problem of fake news detection in Spanish using\nMachine Learning techniques. It is fundamentally the same problem tackled for\nthe English language; however, there is not a significant amount of publicly\navailable and adequately labeled fake news in Spanish to effectively train a\nMachine Learning model, similarly to those proposed for the English language.\nTherefore, this work explores different training strategies and architectures\nto establish a baseline for further research in this area. Four datasets were\nused, two in English and two in Spanish, and four experimental schemes were\ntested, including a baseline with classical Machine Learning models, trained\nand validated using a small dataset in Spanish. The remaining schemes include\nstate-of-the-art Deep Learning models trained (or fine-tuned) and validated in\nEnglish, trained and validated in Spanish, and fitted in English and validated\nwith automatic translated Spanish sentences. The Deep Learning architectures\nwere built on top of different pre-trained Word Embedding representations,\nincluding GloVe, ELMo, BERT, and BETO (a BERT version trained on a large corpus\nin Spanish). According to the results, the best strategy was a combination of a\npre-trained BETO model and a Recurrent Neural Network based on LSTM layers,\nyielding an accuracy of up to 80%; nonetheless, a baseline model using a Random\nForest estimator obtained similar outcomes. Additionally, the translation\nstrategy did not yield acceptable results because of the propagation error;\nthere was also observed a significant difference in models performance when\ntrained in English or Spanish, mainly attributable to the number of samples\navailable for each language.",
    "descriptor": "",
    "authors": [
      "Kevin Mart\u00ednez-Gallego",
      "Andr\u00e9s M. \u00c1lvarez-Ortiz",
      "Juli\u00e1n D. Arias-Londo\u00f1o"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06461"
  },
  {
    "id": "arXiv:2110.06467",
    "title": "Dual-branch Attention-In-Attention Transformer for single-channel speech  enhancement",
    "abstract": "Curriculum learning begins to thrive in the speech enhancement area, which\ndecouples the original spectrum estimation task into multiple easier sub-tasks\nto achieve better performance. Motivated by that, we propose a dual-branch\nattention-in-attention transformer dubbed DB-AIAT to handle both coarse- and\nfine-grained regions of the spectrum in parallel. From a complementary\nperspective, a magnitude masking branch is proposed to coarsely estimate the\noverall magnitude spectrum, and simultaneously a complex refining branch is\nelaborately designed to compensate for the missing spectral details and\nimplicitly derive phase information. Within each branch, we propose a novel\nattention-in-attention transformer-based module to replace the conventional\nRNNs and temporal convolutional networks for temporal sequence modeling.\nSpecifically, the proposed attention-in-attention transformer consists of\nadaptive temporal-frequency attention transformer blocks and an adaptive\nhierarchical attention module, aiming to capture long-term temporal-frequency\ndependencies and further aggregate global hierarchical contextual information.\nExperimental results on Voice Bank + DEMAND demonstrate that DB-AIAT yields\nstate-of-the-art performance (e.g., 3.31 PESQ, 94.7% STOI and 10.79dB SSNR)\nover previous advanced systems with a relatively small model size (2.81M).",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Guochen Yu",
      "Andong Li",
      "Yutian Wang",
      "Yinuo Guo",
      "Hui Wang",
      "Chengshi Zheng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.06467"
  },
  {
    "id": "arXiv:2110.06468",
    "title": "Graph-Fraudster: Adversarial Attacks on Graph Neural Network Based  Vertical Federated Learning",
    "abstract": "Graph neural network (GNN) models have achieved great success on graph\nrepresentation learning. Challenged by large scale private data collection from\nuser-side, GNN models may not be able to reflect the excellent performance,\nwithout rich features and complete adjacent relationships. Addressing to the\nproblem, vertical federated learning (VFL) is proposed to implement local data\nprotection through training a global model collaboratively. Consequently, for\ngraph-structured data, it is natural idea to construct VFL framework with GNN\nmodels. However, GNN models are proven to be vulnerable to adversarial attacks.\nWhether the vulnerability will be brought into the VFL has not been studied. In\nthis paper, we devote to study the security issues of GNN based VFL (GVFL),\ni.e., robustness against adversarial attacks. Further, we propose an\nadversarial attack method, named Graph-Fraudster. It generates adversarial\nperturbations based on the noise-added global node embeddings via GVFL's\nprivacy leakage, and the gradient of pairwise node. First, it steals the global\nnode embeddings and sets up a shadow server model for attack generator. Second,\nnoises are added into node embeddings to confuse the shadow server model. At\nlast, the gradient of pairwise node is used to generate attacks with the\nguidance of noise-added node embeddings. To the best of our knowledge, this is\nthe first study of adversarial attacks on GVFL. The extensive experiments on\nfive benchmark datasets demonstrate that Graph-Fraudster performs better than\nthree possible baselines in GVFL. Furthermore, Graph-Fraudster can remain a\nthreat to GVFL even if two possible defense mechanisms are applied. This paper\nreveals that GVFL is vulnerable to adversarial attack similar to centralized\nGNN models.",
    "descriptor": "",
    "authors": [
      "Jinyin Chen",
      "Guohan Huang",
      "Shanqing Yu",
      "Wenrong Jiang",
      "Chen Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06468"
  },
  {
    "id": "arXiv:2110.06470",
    "title": "Control Co-Design for Buoyancy-Controlled MHK Turbine: A Nested  Optimization of Geometry and Spatial-Temporal Path Planning",
    "abstract": "Recent research progress has confirmed that using advanced controls can\nresult in massive increases in energy capture for marine hydrokinetic (MHK)\nenergy systems, including ocean current turbines (OCTs) and wave energy\nconverters (WECs); however, to realize maximum benefits, the controls,\npower-take-off system, and basic structure of the device must all be\nco-designed from early stages. This paper presents an OCT turbine control\nco-design framework, accounting for the plant geometry and spatial-temporal\npath planning to optimize the performance. Developing a control co-design\nframework means that it is now possible to evaluate the effects of changing\nplant geometry on a level playing field when accounting for the OCT plant power\noptimization. The investigated framework evaluates the key design parameters,\nincluding the sizes of the generator, rotor, and variable buoyancy tank in the\nOCT system, and formulates these parameters' effect on the OCT model and\nharnessed power through defining a power-to-weight ratio, subject to the design\nand operational constraints. The control co-design is formulated as a nested\noptimization problem, where the outer loop optimizes the plant geometry and the\ninner loop accounts for the spatial-temporal path planning to optimize the\nharnessed power with respect to the linear model of the OCT system and ocean\ncurrent uncertainties. Compared with a baseline design, results verify the\nefficacy of the proposed framework in co-designing an optimal OCT system to\ngain the maximum power-to-weight ratio.",
    "descriptor": "",
    "authors": [
      "Arezoo Hasankhani",
      "Yufei Tang",
      "Austin Snyder",
      "James VanZwieten",
      "Wei Qiao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.06470"
  },
  {
    "id": "arXiv:2110.06474",
    "title": "ActiveEA: Active Learning for Neural Entity Alignment",
    "abstract": "Entity Alignment (EA) aims to match equivalent entities across different\nKnowledge Graphs (KGs) and is an essential step of KG fusion. Current\nmainstream methods -- neural EA models -- rely on training with seed alignment,\ni.e., a set of pre-aligned entity pairs which are very costly to annotate. In\nthis paper, we devise a novel Active Learning (AL) framework for neural EA,\naiming to create highly informative seed alignment to obtain more effective EA\nmodels with less annotation cost. Our framework tackles two main challenges\nencountered when applying AL to EA: (1) How to exploit dependencies between\nentities within the AL strategy. Most AL strategies assume that the data\ninstances to sample are independent and identically distributed. However,\nentities in KGs are related. To address this challenge, we propose a\nstructure-aware uncertainty sampling strategy that can measure the uncertainty\nof each entity as well as its impact on its neighbour entities in the KG. (2)\nHow to recognise entities that appear in one KG but not in the other KG (i.e.,\nbachelors). Identifying bachelors would likely save annotation budget. To\naddress this challenge, we devise a bachelor recognizer paying attention to\nalleviate the effect of sampling bias. Empirical results show that our proposed\nAL strategy can significantly improve sampling quality with good generality\nacross different datasets, EA models and amount of bachelors.",
    "descriptor": "",
    "authors": [
      "Bing Liu",
      "Harrisen Scells",
      "Guido Zuccon",
      "Wen Hua",
      "Genghong Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06474"
  },
  {
    "id": "arXiv:2110.06475",
    "title": "SAR-Net: A Scenario-Aware Ranking Network for PersonalizedFair  Recommendation in Hundreds of Travel Scenarios",
    "abstract": "The travel marketing platform of Alibaba serves an indispensable role for\nhundreds of different travel scenarios from Fliggy, Taobao, Alipay apps, etc.\nTo provide personalized recommendation service for users visiting different\nscenarios, there are two critical issues to be carefully addressed. First,\nsince the traffic characteristics of different scenarios, it is very\nchallenging to train a unified model to serve all. Second, during the promotion\nperiod, the exposure of some specific items will be re-weighted due to manual\nintervention, resulting in biased logs, which will degrade the ranking model\ntrained using these biased data. In this paper, we propose a novel\nScenario-Aware Ranking Network (SAR-Net) to address these issues. SAR-Net\nharvests the abundant data from different scenarios by learning users'\ncross-scenario interests via two specific attention modules, which leverage the\nscenario features and item features to modulate the user behavior features,\nrespectively. Then, taking the encoded features of previous module as input, a\nscenario-specific linear transformation layer is adopted to further extract\nscenario-specific features, followed by two groups of debias expert networks,\ni.e., scenario-specific experts and scenario-shared experts. They output\nintermediate results independently, which are further fused into the final\nresult by a multi-scenario gating module. In addition, to mitigate the data\nfairness issue caused by manual intervention, we propose the concept of\nFairness Coefficient (FC) to measures the importance of individual sample and\nuse it to reweigh the prediction in the debias expert networks. Experiments on\nan offline dataset covering over 80 million users and 1.55 million travel items\nand an online A/B test demonstrate the effectiveness of our SAR-Net and its\nsuperiority over state-of-the-art methods.",
    "descriptor": "\nComments: Accepted at CIKM 2021\n",
    "authors": [
      "Qijie Shen",
      "Wanjie Tao",
      "Jing Zhang",
      "Hong Wen",
      "Zulong Chen",
      "Quan Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.06475"
  },
  {
    "id": "arXiv:2110.06476",
    "title": "Winning the ICCV'2021 VALUE Challenge: Task-aware Ensemble and Transfer  Learning with Visual Concepts",
    "abstract": "The VALUE (Video-And-Language Understanding Evaluation) benchmark is newly\nintroduced to evaluate and analyze multi-modal representation learning\nalgorithms on three video-and-language tasks: Retrieval, QA, and Captioning.\nThe main objective of the VALUE challenge is to train a task-agnostic model\nthat is simultaneously applicable for various tasks with different\ncharacteristics. This technical report describes our winning strategies for the\nVALUE challenge: 1) single model optimization, 2) transfer learning with visual\nconcepts, and 3) task-aware ensemble. The first and third strategies are\ndesigned to address heterogeneous characteristics of each task, and the second\none is to leverage rich and fine-grained visual information. We provide a\ndetailed and comprehensive analysis with extensive experimental results. Based\non our approach, we ranked first place on the VALUE and QA phases for the\ncompetition.",
    "descriptor": "\nComments: CLVL workshop at ICCV 2021\n",
    "authors": [
      "Minchul Shin",
      "Jonghwan Mun",
      "Kyoung-Woon On",
      "Woo-Young Kang",
      "Gunsoo Han",
      "Eun-Sol Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06476"
  },
  {
    "id": "arXiv:2110.06477",
    "title": "Feudal Reinforcement Learning by Reading Manuals",
    "abstract": "Reading to act is a prevalent but challenging task which requires the ability\nto reason from a concise instruction. However, previous works face the semantic\nmismatch between the low-level actions and the high-level language descriptions\nand require the human-designed curriculum to work properly. In this paper, we\npresent a Feudal Reinforcement Learning (FRL) model consisting of a manager\nagent and a worker agent. The manager agent is a multi-hop plan generator\ndealing with high-level abstract information and generating a series of\nsub-goals in a backward manner. The worker agent deals with the low-level\nperceptions and actions to achieve the sub-goals one by one. In comparison, our\nFRL model effectively alleviate the mismatching between text-level inference\nand low-level perceptions and actions; and is general to various forms of\nenvironments, instructions and manuals; and our multi-hop plan generator can\nsignificantly boost for challenging tasks where multi-step reasoning form the\ntexts is critical to resolve the instructed goals. We showcase our approach\nachieves competitive performance on two challenging tasks, Read to Fight\nMonsters (RTFM) and Messenger, without human-designed curriculum learning.",
    "descriptor": "",
    "authors": [
      "Kai Wang",
      "Zhonghao Wang",
      "Mo Yu",
      "Humphrey Shi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06477"
  },
  {
    "id": "arXiv:2110.06479",
    "title": "Variational and numerical analysis of a $\\mathbf{Q}$-tensor model for  smectic-A liquid crystals",
    "abstract": "We analyse an energy minimisation problem recently proposed for modelling\nsmectic-A liquid crystals. The optimality conditions give a coupled nonlinear\nsystem of partial differential equations, with a second-order equation for the\ntensor-valued nematic order parameter $\\mathbf{Q}$ and a fourth-order equation\nfor the scalar-valued smectic density variation $u$. Our two main results are a\nproof of the existence of solutions to the minimisation problem, and the\nderivation of a priori error estimates for its discretisation using the\n$\\mathcal{C}^0$ interior penalty method. More specifically, optimal rates in\nthe $H^1$ and $L^2$ norms are obtained for $\\mathbf{Q}$, while optimal rates in\na mesh-dependent norm and $L^2$ norm are obtained for $u$. Numerical\nexperiments confirm the rates of convergence.",
    "descriptor": "",
    "authors": [
      "Jingmin Xia",
      "Patrick E. Farrell"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.06479"
  },
  {
    "id": "arXiv:2110.06482",
    "title": "Parallel Deep Neural Networks Have Zero Duality Gap",
    "abstract": "Training deep neural networks is a well-known highly non-convex problem. In\nrecent works, it is shown that there is no duality gap for regularized\ntwo-layer neural networks with ReLU activation, which enables global\noptimization via convex programs. For multi-layer linear networks with vector\noutputs, we formulate convex dual problems and demonstrate that the duality gap\nis non-zero for depth three and deeper networks. However, by modifying the deep\nnetworks to more powerful parallel architectures, we show that the duality gap\nis exactly zero. Therefore, strong convex duality holds, and hence there exist\nequivalent convex programs that enable training deep networks to global\noptimality. We also demonstrate that the weight decay regularization in the\nparameters explicitly encourages low-rank solutions via closed-form\nexpressions. For three-layer non-parallel ReLU networks, we show that strong\nduality holds for rank-1 data matrices, however, the duality gap is non-zero\nfor whitened data matrices. Similarly, by transforming the neural network\narchitecture into a corresponding parallel version, the duality gap vanishes.",
    "descriptor": "",
    "authors": [
      "Yifei Wang",
      "Tolga Ergen",
      "Mert Pilanci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.06482"
  },
  {
    "id": "arXiv:2110.06483",
    "title": "False Negative Distillation and Contrastive Learning for Personalized  Outfit Recommendation",
    "abstract": "Personalized outfit recommendation has recently been in the spotlight with\nthe rapid growth of the online fashion industry. However, recommending outfits\nhas two significant challenges that should be addressed. The first challenge is\nthat outfit recommendation often requires a complex and large model that\nutilizes visual information, incurring huge memory and time costs. One natural\nway to mitigate this problem is to compress such a cumbersome model with\nknowledge distillation (KD) techniques that leverage knowledge from a\npretrained teacher model. However, it is hard to apply existing KD approaches\nin recommender systems (RS) to the outfit recommendation because they require\nthe ranking of all possible outfits while the number of outfits grows\nexponentially to the number of consisting clothing items. Therefore, we propose\na new KD framework for outfit recommendation, called False Negative\nDistillation (FND), which exploits false-negative information from the teacher\nmodel while not requiring the ranking of all candidates. The second challenge\nis that the explosive number of outfit candidates amplifying the data sparsity\nproblem, often leading to poor outfit representation. To tackle this issue,\ninspired by the recent success of contrastive learning (CL), we introduce a CL\nframework for outfit representation learning with two proposed data\naugmentation methods. Quantitative and qualitative experiments on outfit\nrecommendation datasets demonstrate the effectiveness and soundness of our\nproposed methods.",
    "descriptor": "",
    "authors": [
      "Seongjae Kim",
      "Jinseok Seol",
      "Holim Lim",
      "Sang-goo Lee"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.06483"
  },
  {
    "id": "arXiv:2110.06484",
    "title": "Domain Adaptive Semantic Segmentation without Source Data",
    "abstract": "Domain adaptive semantic segmentation is recognized as a promising technique\nto alleviate the domain shift between the labeled source domain and the\nunlabeled target domain in many real-world applications, such as automatic\npilot. However, large amounts of source domain data often introduce significant\ncosts in storage and training, and sometimes the source data is inaccessible\ndue to privacy policies. To address these problems, we investigate domain\nadaptive semantic segmentation without source data, which assumes that the\nmodel is pre-trained on the source domain, and then adapting to the target\ndomain without accessing source data anymore. Since there is no supervision\nfrom the source domain data, many self-training methods tend to fall into the\n``winner-takes-all'' dilemma, where the {\\it majority} classes totally dominate\nthe segmentation networks and the networks fail to classify the {\\it minority}\nclasses. Consequently, we propose an effective framework for this challenging\nproblem with two components: positive learning and negative learning. In\npositive learning, we select the class-balanced pseudo-labeled pixels with\nintra-class threshold, while in negative learning, for each pixel, we\ninvestigate which category the pixel does not belong to with the proposed\nheuristic complementary label selection. Notably, our framework can be easily\nimplemented and incorporated with other methods to further enhance the\nperformance. Extensive experiments on two widely-used synthetic-to-real\nbenchmarks demonstrate our claims and the effectiveness of our framework, which\noutperforms the baseline with a large margin. Code is available at\n\\url{https://github.com/fumyou13/LDBE}.",
    "descriptor": "\nComments: Accepted by ACM Multimedia 2021\n",
    "authors": [
      "Fuming You",
      "Jingjing Li",
      "Lei Zhu",
      "Ke Lu",
      "Zhi Chen",
      "Zi Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06484"
  },
  {
    "id": "arXiv:2110.06485",
    "title": "Communication-Efficient Triangle Counting under Local Differential  Privacy",
    "abstract": "Triangle counting in networks under LDP (Local Differential Privacy) is a\nfundamental task for analyzing connection patterns or calculating a clustering\ncoefficient while strongly protecting sensitive friendships from a central\nserver. In particular, a recent study proposes an algorithm for this task that\nuses two rounds of interaction between users and the server to significantly\nreduce estimation error. However, this algorithm suffers from a prohibitively\nlarge communication cost due to a large noisy graph each user needs to\ndownload.\nIn this work, we propose triangle counting algorithms under LDP with a small\nestimation error and communication cost. We first propose two-round algorithms\nconsisting of edge sampling and carefully selecting edges each user downloads\nso that the estimation error is small. Then we propose a double clipping\ntechnique, which clips the number of edges and then the number of noisy\ntriangles, to significantly reduce the sensitivity of each user's query.\nThrough comprehensive evaluation, we show that our algorithms dramatically\nreduce the communication cost of the existing algorithm, e.g., from 6 hours to\n8 seconds or less at 20 Mbps download rate, while keeping a small estimation\nerror.",
    "descriptor": "\nComments: The first and second authors made equal contribution\n",
    "authors": [
      "Jacob Imola",
      "Takao Murakami",
      "Kamalika Chaudhuri"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.06485"
  },
  {
    "id": "arXiv:2110.06486",
    "title": "Understanding of Emotion Perception from Art",
    "abstract": "Computational modeling of the emotions evoked by art in humans is a\nchallenging problem because of the subjective and nuanced nature of art and\naffective signals. In this paper, we consider the above-mentioned problem of\nunderstanding emotions evoked in viewers by artwork using both text and visual\nmodalities. Specifically, we analyze images and the accompanying text captions\nfrom the viewers expressing emotions as a multimodal classification task. Our\nresults show that single-stream multimodal transformer-based models like MMBT\nand VisualBERT perform better compared to both image-only models and\ndual-stream multimodal models having separate pathways for text and image\nmodalities. We also observe improvements in performance for extreme positive\nand negative emotion classes, when a single-stream model like MMBT is compared\nwith a text-only transformer model like BERT.",
    "descriptor": "\nComments: 5 pages, 5 figures. Accepted at ICCV2021: 4th Workshop on Closing the loop between Vision and Language\n",
    "authors": [
      "Digbalay Bose",
      "Krishna Somandepalli",
      "Souvik Kundu",
      "Rimita Lahiri",
      "Jonathan Gratch",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06486"
  },
  {
    "id": "arXiv:2110.06487",
    "title": "Recent trends in Social Engineering Scams and Case study of Gift Card  Scam",
    "abstract": "Social engineering scams (SES) has been existed since the adoption of the\ntelecommunications by humankind. An earlier version of the scams include\nleveraging premium phone service to charge the consumers and service providers\nbut not limited to. There are variety of techniques being considered to scam\nthe people due to the advancements in digital data access capabilities and\nInternet technology. A lot of research has been done to identify the scammer\nmethodologies and characteristics of the scams. However, the scammers finding\nnew ways to lure the consumers and stealing their financial assets. An example\nwould be a recent circumstance of Covid-19 unemployment, which was used as a\nweapon to scam the US citizens. These scams will not be stopping here, and will\nkeep appearing with new social engineering strategies in the near future. So,\nto better prepare these kind of scams in ever-changing world, we describe the\nrecent trends of various social engineering scams targeting the innocent people\nall over the world, who oversight the consequences of scams,and also give\ndetailed description of recent social engineering scams including Covid scams.\nThe social engineering scan threat model architecture is also proposed to map\nvarious scams. In addition, we discuss the case study of real-time gift card\nscam targeting various enterprise organization customers to steal their money\nand put the organization reputation in stake. We also provide recommendations\nto internet users for not falling a victim of social engineering scams. In the\nend, we provide insights on how to prepare/respond to the social engineering\nscams by following the security incident detection and response life cycle in\nenterprises",
    "descriptor": "",
    "authors": [
      "Rajasekhar Chaganti",
      "Bharat Bhushan",
      "Anand Nayyar",
      "Azrour Mourade"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.06487"
  },
  {
    "id": "arXiv:2110.06488",
    "title": "The Convex Geometry of Backpropagation: Neural Network Gradient Flows  Converge to Extreme Points of the Dual Convex Program",
    "abstract": "We study non-convex subgradient flows for training two-layer ReLU neural\nnetworks from a convex geometry and duality perspective. We characterize the\nimplicit bias of unregularized non-convex gradient flow as convex\nregularization of an equivalent convex model. We then show that the limit\npoints of non-convex subgradient flows can be identified via primal-dual\ncorrespondence in this convex optimization problem. Moreover, we derive a\nsufficient condition on the dual variables which ensures that the stationary\npoints of the non-convex objective are the KKT points of the convex objective,\nthus proving convergence of non-convex gradient flows to the global optimum.\nFor a class of regular training data distributions such as orthogonal separable\ndata, we show that this sufficient condition holds. Therefore, non-convex\ngradient flows in fact converge to optimal solutions of a convex optimization\nproblem. We present numerical results verifying the predictions of our theory\nfor non-convex subgradient descent.",
    "descriptor": "",
    "authors": [
      "Yifei Wang",
      "Mert Pilanci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.06488"
  },
  {
    "id": "arXiv:2110.06490",
    "title": "Dict-BERT: Enhancing Language Model Pre-training with Dictionary",
    "abstract": "Pre-trained language models (PLMs) aim to learn universal language\nrepresentations by conducting self-supervised training tasks on large-scale\ncorpora. Since PLMs capture word semantics in different contexts, the quality\nof word representations highly depends on word frequency, which usually follows\na heavy-tailed distributions in the pre-training corpus. Therefore, the\nembeddings of rare words on the tail are usually poorly optimized. In this\nwork, we focus on enhancing language model pre-training by leveraging\ndefinitions of the rare words in dictionaries (e.g., Wiktionary). To\nincorporate a rare word definition as a part of input, we fetch its definition\nfrom the dictionary and append it to the end of the input text sequence. In\naddition to training with the masked language modeling objective, we propose\ntwo novel self-supervised pre-training tasks on word and sentence-level\nalignment between input text sequence and rare word definitions to enhance\nlanguage modeling representation with dictionary. We evaluate the proposed\nDict-BERT model on the language understanding benchmark GLUE and eight\nspecialized domain benchmark datasets. Extensive experiments demonstrate that\nDict-BERT can significantly improve the understanding of rare words and boost\nmodel performance on various NLP downstream tasks.",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Wenhao Yu",
      "Chenguang Zhu",
      "Yuwei Fang",
      "Donghan Yu",
      "Shuohang Wang",
      "Yichong Xu",
      "Michael Zeng",
      "Meng Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06490"
  },
  {
    "id": "arXiv:2110.06494",
    "title": "Music Source Separation with Deep Equilibrium Models",
    "abstract": "While deep neural network-based music source separation (MSS) is very\neffective and achieves high performance, its model size is often a problem for\npractical deployment. Deep implicit architectures such as deep equilibrium\nmodels (DEQ) were recently proposed, which can achieve higher performance than\ntheir explicit counterparts with limited depth while keeping the number of\nparameters small. This makes DEQ also attractive for MSS, especially as it was\noriginally applied to sequential modeling tasks in natural language processing\nand thus should in principle be also suited for MSS. However, an investigation\nof a good architecture and training scheme for MSS with DEQ is needed as the\ncharacteristics of acoustic signals are different from those of natural\nlanguage data. Hence, in this paper we propose an architecture and training\nscheme for MSS with DEQ. Starting with the architecture of Open-Unmix (UMX), we\nreplace its sequence model with DEQ. We refer to our proposed method as\nDEQ-based UMX (DEQ-UMX). Experimental results show that DEQ-UMX performs better\nthan the original UMX while reducing its number of parameters by 30%.",
    "descriptor": "",
    "authors": [
      "Yuichiro Koyama",
      "Naoki Murata",
      "Stefan Uhlich",
      "Giorgio Fabbro",
      "Shusuke Takahashi",
      "Yuki Mitsufuji"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.06494"
  },
  {
    "id": "arXiv:2110.06495",
    "title": "Cross-lingual COVID-19 Fake News Detection",
    "abstract": "The COVID-19 pandemic poses a great threat to global public health.\nMeanwhile, there is massive misinformation associated with the pandemic which\nadvocates unfounded or unscientific claims. Even major social media and news\noutlets have made an extra effort in debunking COVID-19 misinformation, most of\nthe fact-checking information is in English, whereas some unmoderated COVID-19\nmisinformation is still circulating in other languages, threatening the health\nof less-informed people in immigrant communities and developing countries. In\nthis paper, we make the first attempt to detect COVID-19 misinformation in a\nlow-resource language (Chinese) only using the fact-checked news in a\nhigh-resource language (English). We start by curating a Chinese real&fake news\ndataset according to existing fact-checking information. Then, we propose a\ndeep learning framework named CrossFake to jointly encode the cross-lingual\nnews body texts and capture the news content as much as possible. Empirical\nresults on our dataset demonstrate the effectiveness of CorssFake under the\ncross-lingual setting and it also outperforms several monolingual and\ncross-lingual fake news detectors. The dataset is available at\nhttps://github.com/YingtongDou/CrossFake.",
    "descriptor": "\nComments: Accepted by SDM at ICDM, data is available at this https URL\n",
    "authors": [
      "Jiangshu Du",
      "Yingtong Dou",
      "Congying Xia",
      "Limeng Cui",
      "Jing Ma",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06495"
  },
  {
    "id": "arXiv:2110.06500",
    "title": "Differentially Private Fine-tuning of Language Models",
    "abstract": "We give simpler, sparser, and faster algorithms for differentially private\nfine-tuning of large-scale pre-trained language models, which achieve the\nstate-of-the-art privacy versus utility tradeoffs on many standard NLP tasks.\nWe propose a meta-framework for this problem, inspired by the recent success of\nhighly parameter-efficient methods for fine-tuning. Our experiments show that\ndifferentially private adaptations of these approaches outperform previous\nprivate algorithms in three important dimensions: utility, privacy, and the\ncomputational and memory cost of private training. On many commonly studied\ndatasets, the utility of private models approaches that of non-private models.\nFor example, on the MNLI dataset we achieve an accuracy of $87.8\\%$ using\nRoBERTa-Large and $83.5\\%$ using RoBERTa-Base with a privacy budget of\n$\\epsilon = 6.7$. In comparison, absent privacy constraints, RoBERTa-Large\nachieves an accuracy of $90.2\\%$. Our findings are similar for natural language\ngeneration tasks. Privately fine-tuning with DART, GPT-2-Small, GPT-2-Medium,\nGPT-2-Large, and GPT-2-XL achieve BLEU scores of 38.5, 42.0, 43.1, and 43.8\nrespectively (privacy budget of $\\epsilon = 6.8,\\delta=$ 1e-5) whereas the\nnon-private baseline is $48.1$. All our experiments suggest that larger models\nare better suited for private fine-tuning: while they are well known to achieve\nsuperior accuracy non-privately, we find that they also better maintain their\naccuracy when privacy is introduced.",
    "descriptor": "",
    "authors": [
      "Da Yu",
      "Saurabh Naik",
      "Arturs Backurs",
      "Sivakanth Gopi",
      "Huseyin A. Inan",
      "Gautam Kamath",
      "Janardhan Kulkarni",
      "Yin Tat Lee",
      "Andre Manoel",
      "Lukas Wutschitz",
      "Sergey Yekhanin",
      "Huishuai Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06500"
  },
  {
    "id": "arXiv:2110.06501",
    "title": "Spatial Data Augmentation with Simulated Room Impulse Responses for  Sound Event Localization and Detection",
    "abstract": "Recording and annotating real sound events for a sound event localization and\ndetection (SELD) task is time consuming, and data augmentation techniques are\noften favored when the amount of data is limited. However, how to augment the\nspatial information in a dataset, including unlabeled directional interference\nevents, remains an open research question. Furthermore, directional\ninterference events make it difficult to accurately extract spatial\ncharacteristics from target sound events. To address this problem, we propose\nan impulse response simulation framework (IRS) that augments spatial\ncharacteristics using simulated room impulse responses (RIR). RIRs\ncorresponding to a microphone array assumed to be placed in various rooms are\naccurately simulated, and the source signals of the target sound events are\nextracted from a mixture. The simulated RIRs are then convolved with the\nextracted source signals to obtain an augmented multi-channel training dataset.\nEvaluation results obtained using the TAU-NIGENS Spatial Sound Events 2021\ndataset show that the IRS contributes to improving the overall SELD\nperformance. Additionally, we conducted an ablation study to discuss the\ncontribution and need for each component within the IRS.",
    "descriptor": "",
    "authors": [
      "Yuichiro Koyama",
      "Kazuhide Shigemi",
      "Masafumi Takahashi",
      "Kazuki Shimada",
      "Naoya Takahashi",
      "Emiru Tsunoo",
      "Shusuke Takahashi",
      "Yuki Mitsufuji"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.06501"
  },
  {
    "id": "arXiv:2110.06502",
    "title": "Efficient domain adaptation of language models in ASR systems using  Prompt-tuning",
    "abstract": "Automatic Speech Recognition (ASR) systems have found their use in numerous\nindustrial applications in very diverse domains. Since domain-specific systems\nperform better than their generic counterparts on in-domain evaluation, the\nneed for memory and compute-efficient domain adaptation is obvious.\nParticularly, adapting parameter-heavy transformer-based language models used\nfor rescoring ASR hypothesis is challenging. In this work, we overcome the\nproblem using prompt-tuning, a methodology that trains a small number of domain\ntoken embedding parameters to prime a transformer-based LM to a particular\ndomain. With just a handful of extra parameters per domain, we achieve much\nbetter perplexity scores over the baseline of using an unadapted LM. Despite\nbeing parameter-efficient, these improvements are comparable to those of\nfully-fine-tuned models with hundreds of millions of parameters. We replicate\nour findings in perplexity numbers to Word Error Rate in a domain-specific ASR\nsystem for one such domain.",
    "descriptor": "\nComments: WeCNLP accepted version\n",
    "authors": [
      "Saket Dingliwal",
      "Ashish Shenoy",
      "Sravan Bodapati",
      "Ankur Gandhe",
      "Ravi Teja Gadde",
      "Katrin Kirchhoff"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06502"
  },
  {
    "id": "arXiv:2110.06506",
    "title": "Myerson value of directed hypergraphs",
    "abstract": "In this paper, we consider a directed hypergraph as cooperative network, and\ndefine the Myerson value for directed hypergraphs. We prove the axiomatization\nof the Myerson value, namely strong component efficiency and fairness.\nMoreover, we modified the concept of safety defined by Li-Shan, and proved the\ncondition about the safety of the hyperedge with respect to the Myerson value\nfor directed hypergraphs.",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Taiki Yamada"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.06506"
  },
  {
    "id": "arXiv:2110.06507",
    "title": "Perception Point: Identifying Critical Learning Periods in Speech for  Bilingual Networks",
    "abstract": "Recent studies in speech perception have been closely linked to fields of\ncognitive psychology, phonology, and phonetics in linguistics. During\nperceptual attunement, a critical and sensitive developmental trajectory has\nbeen examined in bilingual and monolingual infants where they can best\ndiscriminate common phonemes. In this paper, we compare and identify these\ncognitive aspects on deep neural-based visual lip-reading models. We conduct\nexperiments on the two most extensive public visual speech recognition datasets\nfor English and Mandarin. Through our experimental results, we observe a strong\ncorrelation between these theories in cognitive psychology and our unique\nmodeling. We inspect how these computational models develop similar phases in\nspeech perception and acquisitions.",
    "descriptor": "\nComments: 9 pages, 6 figures, 2 tables\n",
    "authors": [
      "Anuj Saraswat",
      "Mehar Bhatia",
      "Yaman Kumar Singla",
      "Changyou Chen",
      "Rajiv Ratn Shah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06507"
  },
  {
    "id": "arXiv:2110.06508",
    "title": "Efficiency in the Serverless Cloud Computing Paradigm: A Survey Study",
    "abstract": "Serverless computing along with Function-as-a-Service (FaaS) are forming a\nnew computing paradigm that is anticipated to found the next generation of\ncloud systems. The popularity of this paradigm is due to offering a highly\ntransparent infrastructure that enables user applications to scale in the\ngranularity of their functions. Since these often small and single-purpose\nfunctions are managed on shared computing resources behind the scene, a great\npotential for computational reuse and approximate computing emerges that if\nunleashed, can remarkably improve the efficiency of serverless cloud systems --\nboth from the user's QoS and system's (energy consumption and incurred cost)\nperspectives. Accordingly, the goal of this survey study is to, first, unfold\nthe internal mechanics of the serverless computing and, second, explore the\nscope for efficiency within this paradigm via studying function reuse and\napproximation approaches and discussing the pros and cons of each one. Next, we\noutline potential future research directions within this paradigm that can\neither unlock new use cases or make the paradigm more efficient.",
    "descriptor": "",
    "authors": [
      "Chavit Denninnart",
      "Mohsen Amini Salehi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.06508"
  },
  {
    "id": "arXiv:2110.06509",
    "title": "Learning Stable Koopman Embeddings",
    "abstract": "In this paper, we present a new data-driven method for learning stable models\nof nonlinear systems. Our model lifts the original state space to a\nhigher-dimensional linear manifold using Koopman embeddings. Interestingly, we\nprove that every discrete-time nonlinear contracting model can be learnt in our\nframework. Another significant merit of the proposed approach is that it allows\nfor unconstrained optimization over the Koopman embedding and operator jointly\nwhile enforcing stability of the model, via a direct parameterization of stable\nlinear systems, greatly simplifying the computations involved. We validate our\nmethod on a simulated system and analyze the advantages of our parameterization\ncompared to alternatives.",
    "descriptor": "",
    "authors": [
      "Fletcher Fan",
      "Bowen Yi",
      "David Rye",
      "Guodong Shi",
      "Ian R. Manchester"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.06509"
  },
  {
    "id": "arXiv:2110.06510",
    "title": "The Dawn of Quantum Natural Language Processing",
    "abstract": "In this paper, we discuss the initial attempts at boosting understanding\nhuman language based on deep-learning models with quantum computing. We\nsuccessfully train a quantum-enhanced Long Short-Term Memory network to perform\nthe parts-of-speech tagging task via numerical simulations. Moreover, a\nquantum-enhanced Transformer is proposed to perform the sentiment analysis\nbased on the existing dataset.",
    "descriptor": "",
    "authors": [
      "Riccardo Di Sipio",
      "Jia-Hong Huang",
      "Samuel Yen-Chi Chen",
      "Stefano Mangini",
      "Marcel Worring"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06510"
  },
  {
    "id": "arXiv:2110.06512",
    "title": "MedNet: Pre-trained Convolutional Neural Network Model for the Medical  Imaging Tasks",
    "abstract": "Deep Learning (DL) requires a large amount of training data to provide\nquality outcomes. However, the field of medical imaging suffers from the lack\nof sufficient data for properly training DL models because medical images\nrequire manual labelling carried out by clinical experts thus the process is\ntime-consuming, expensive, and error-prone. Recently, transfer learning (TL)\nwas introduced to reduce the need for the annotation procedure by means of\ntransferring the knowledge performed by a previous task and then fine-tuning\nthe result using a relatively small dataset. Nowadays, multiple classification\nmethods from medical imaging make use of TL from general-purpose pre-trained\nmodels, e.g., ImageNet, which has been proven to be ineffective due to the\nmismatch between the features learned from natural images (ImageNet) and those\nmore specific from medical images especially medical gray images such as\nX-rays. ImageNet does not have grayscale images such as MRI, CT, and X-ray. In\nthis paper, we propose a novel DL model to be used for addressing\nclassification tasks of medical imaging, called MedNet. To do so, we aim to\nissue two versions of MedNet. The first one is Gray-MedNet which will be\ntrained on 3M publicly available gray-scale medical images including MRI, CT,\nX-ray, ultrasound, and PET. The second version is Color-MedNet which will be\ntrained on 3M publicly available color medical images including histopathology,\ntaken images, and many others. To validate the effectiveness MedNet, both\nversions will be fine-tuned to train on the target tasks of a more reduced set\nof medical images. MedNet performs as the pre-trained model to tackle any\nreal-world application from medical imaging and achieve the level of\ngeneralization needed for dealing with medical imaging tasks, e.g.\nclassification. MedNet would serve the research community as a baseline for\nfuture research.",
    "descriptor": "\nComments: 6 Pages\n",
    "authors": [
      "Laith Alzubaidi",
      "J. Santamar\u00eda",
      "Mohamed Manoufali",
      "Beadaa Mohammed",
      "Mohammed A. Fadhel",
      "Jinglan Zhang",
      "Ali H.Al-Timemy",
      "Omran Al-Shamma",
      "Ye Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06512"
  },
  {
    "id": "arXiv:2110.06513",
    "title": "Benchmarking the Robustness of Spatial-Temporal Models Against  Corruptions",
    "abstract": "The state-of-the-art deep neural networks are vulnerable to common\ncorruptions (e.g., input data degradations, distortions, and disturbances\ncaused by weather changes, system error, and processing). While much progress\nhas been made in analyzing and improving the robustness of models in image\nunderstanding, the robustness in video understanding is largely unexplored. In\nthis paper, we establish a corruption robustness benchmark, Mini Kinetics-C and\nMini SSV2-C, which considers temporal corruptions beyond spatial corruptions in\nimages. We make the first attempt to conduct an exhaustive study on the\ncorruption robustness of established CNN-based and Transformer-based\nspatial-temporal models. The study provides some guidance on robust model\ndesign and training: Transformer-based model performs better than CNN-based\nmodels on corruption robustness; the generalization ability of spatial-temporal\nmodels implies robustness against temporal corruptions; model corruption\nrobustness (especially robustness in the temporal domain) enhances with\ncomputational cost and model capacity, which may contradict the current trend\nof improving the computational efficiency of models. Moreover, we find the\nrobustness intervention for image-related tasks (e.g., training models with\nnoise) may not work for spatial-temporal models.",
    "descriptor": "\nComments: Accepted to NeurIPs 2021 Dataset and Benchmark Track. Our codes are available on this https URL\n",
    "authors": [
      "Chenyu Yi",
      "SIYUAN YANG",
      "Haoliang Li",
      "Yap-peng Tan",
      "Alex Kot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06513"
  },
  {
    "id": "arXiv:2110.06520",
    "title": "Impacts of Device Caching of Content Fractions on Expected Content  Quality",
    "abstract": "This paper explores caching of fractions of a video content, not caching of\nan entire content, to increase the expected video quality. We first show that\nthe highest-quality content is better to be cached and propose the caching\npolicy of video chunks having different qualities. Our caching policy utilizes\nthe characteristics of video contents that video files can be encoded into\nmultiple versions with different qualities, each file consists of many chunks,\nand chunks can have different qualities. Extensive performance evaluations are\nconducted to show that caching of content fractions, rather than an entire\ncontent, can improve the expected video quality especially when the channel\nconditions is sufficiently good to cooperate with nearby BS or helpers.",
    "descriptor": "\nComments: 5 pages, 5 figures, (will be) submitted to IEEE Wireless Communications Letter\n",
    "authors": [
      "Dongjae Kim",
      "Minseok Choi"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.06520"
  },
  {
    "id": "arXiv:2110.06523",
    "title": "User Experiences Oriented Sightseeing Spot Recommendation",
    "abstract": "POI recommendation is a key task in tourism information systems. However, in\ncontrast to conventional point of interest (POI) recommender systems, the\navailable data is extremely sparse; most tourist visit a few sightseeing spots\nonce and most of these spots have no check-in data from new tourists. Most\nconventional systems rank sightseeing spots based on their popularity,\nreputations, and category-based similarities with users' preferences. They do\nnot clarify what users can experience in these spots, which makes it difficult\nto meet diverse tourism needs. To this end, in this work, we propose a\nmechanism to recommend POIs to tourists. Our mechanism include two components:\none is a probabilistic model that reveals the user behaviors in tourism; the\nother is a pseudo rating mechanism to handle the cold-start issue in POIs\nrecommendations. We carried out extensive experiments with two datasets\ncollected from Flickr. The experimental results demonstrate that our methods\nare superior to the state-of-the-art methods in both the recommendation\nperformances (precision, recall and F-measure) and fairness. The experimental\nresults also validate the robustness of the proposed methods, i.e., our methods\ncan handle well the issue of data sparsity.",
    "descriptor": "\nComments: 16 pages, 10 figures\n",
    "authors": [
      "Kun Yi",
      "Ryu Yamagishi",
      "Taishan Li",
      "Zhengyang Bai",
      "Qiang Ma"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.06523"
  },
  {
    "id": "arXiv:2110.06525",
    "title": "Automatic DJ Transitions with Differentiable Audio Effects and  Generative Adversarial Networks",
    "abstract": "A central task of a Disc Jockey (DJ) is to create a mixset of mu-sic with\nseamless transitions between adjacent tracks. In this paper, we explore a\ndata-driven approach that uses a generative adversarial network to create the\nsong transition by learning from real-world DJ mixes. In particular, the\ngenerator of the model uses two differentiable digital signal processing\ncomponents, an equalizer (EQ) and a fader, to mix two tracks selected by a data\ngeneration pipeline. The generator has to set the parameters of the EQs and\nfader in such away that the resulting mix resembles real mixes created by\nhumanDJ, as judged by the discriminator counterpart. Result of a listening test\nshows that the model can achieve competitive results compared with a number of\nbaselines.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Bo-Yu Chen",
      "Wei-Han Hsu",
      "Wei-Hsiang Liao",
      "Marco A. Mart\u00ednez Ram\u00edrez",
      "Yuki Mitsufuji",
      "Yi-Hsuan Yang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.06525"
  },
  {
    "id": "arXiv:2110.06526",
    "title": "Practice Problems for Hardware Engineers",
    "abstract": "This book is to help undergraduate and graduate students of electrical and\ncomputer engineering disciplines with their job interviews. It may also be used\nas a practice resource while taking courses in VLSI, logic and computer\narchitecture design. The first edition consists of more than 200 problems and\ntheir solutions which the author has used in his VLSI, logic, and architectures\ncourses while teaching at USC. The author wishes this book to be available to\nstudents and engineers free of charge, subject to the copyright policy on page\n3.",
    "descriptor": "\nComments: 177 pages, Amazon Publishing, 1st Edition\n",
    "authors": [
      "Shahin Nazarian"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2110.06526"
  },
  {
    "id": "arXiv:2110.06529",
    "title": "Power Consumption of Video-Decoders on Various Android Devices",
    "abstract": "The critical constraint of mobile devices is a limited battery life that is\nsignificantly reduced during video playback. The power efficiency of video\nplayback mainly depends on the used compression standard, video-decoder, and\ndevice model. We propose a software-based method to estimate the power\nconsumption of video-decoders on various Android devices. Experiments on two\ndevices of the same model show a small variation of the power playback\nconsumption and a lack of dependence between the power consumption and the\nbattery level. We have implemented an automatic system that includes the VEQE\nAndroid application to measure the power consumption of decoders and a server\nto collect the power metrics. Our system has collected power-consumption and\ndecoding-speed dataset for video-decoders of six standards (AV1, HEVC, VP9,\nH.264, VP8, and MPEG-4) operating on 285 devices, representing 147 models. We\ndemonstrate some slices of the created dataset: the top 30 models and\nvideo-decoders in terms of power efficiency for playback and for decoding only,\nas well as video-decoder ratings by power consumption and decoding speed for a\ngiven device model.",
    "descriptor": "\nComments: For more details about mobile video-decoders ranking, see this https URL\n",
    "authors": [
      "Roman Kazantsev",
      "Dmitriy Vatolin"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.06529"
  },
  {
    "id": "arXiv:2110.06530",
    "title": "Reducing Information Bottleneck for Weakly Supervised Semantic  Segmentation",
    "abstract": "Weakly supervised semantic segmentation produces pixel-level localization\nfrom class labels; however, a classifier trained on such labels is likely to\nfocus on a small discriminative region of the target object. We interpret this\nphenomenon using the information bottleneck principle: the final layer of a\ndeep neural network, activated by the sigmoid or softmax activation functions,\ncauses an information bottleneck, and as a result, only a subset of the\ntask-relevant information is passed on to the output. We first support this\nargument through a simulated toy experiment and then propose a method to reduce\nthe information bottleneck by removing the last activation function. In\naddition, we introduce a new pooling method that further encourages the\ntransmission of information from non-discriminative regions to the\nclassification. Our experimental evaluations demonstrate that this simple\nmodification significantly improves the quality of localization maps on both\nthe PASCAL VOC 2012 and MS COCO 2014 datasets, exhibiting a new\nstate-of-the-art performance for weakly supervised semantic segmentation. The\ncode is available at: https://github.com/jbeomlee93/RIB.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Jungbeom Lee",
      "Jooyoung Choi",
      "Jisoo Mok",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06530"
  },
  {
    "id": "arXiv:2110.06532",
    "title": "SMS: An Efficient Source Model Selection Framework for Model Reuse",
    "abstract": "With the explosive increase of big data, training a Machine Learning (ML)\nmodel becomes a computation-intensive workload, which would take days or even\nweeks. Thus, model reuse has received attention in the ML community, where it\nis called transfer learning. Transfer learning avoids training a new model from\nscratch by transferring knowledge from a source task to a target task. Existing\ntransfer learning methods mostly focus on how to improve the performance of the\ntarget task through a specific source model, but assume that the source model\nis given. As many source models are available, it is difficult for data\nscientists to select the best source model for the target task manually. Hence,\nhow to efficiently select a suitable source model for model reuse is still an\nunsolved problem.\nIn this paper, we propose SMS, an effective, efficient and flexible source\nmodel selection framework. SMS is effective even when source and target\ndatasets have significantly different data labels, is flexible to support\nsource models with any type of structure, and is efficient to avoid any\ntraining process. For each source model, SMS first vectorizes the samples in\nthe target dataset into soft labels by directly applying this model to the\ntarget dataset, then uses Gaussian distributions to fit the clusters of soft\nlabels, and finally measures its distinguishing ability using Gaussian\nmixture-based metric. Moreover, we present an improved SMS (I-SMS), which\ndecreases the output number of source model. I-SMS can significantly reduce the\nselection time while retaining the selection performance of SMS. Extensive\nexperiments on a range of practical model reuse workloads demonstrate the\neffectiveness and efficiency of SMS.",
    "descriptor": "",
    "authors": [
      "Minjun Zhao",
      "Lu Chen",
      "Keyu Yang",
      "Yuntao Du",
      "Yunjun Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.06532"
  },
  {
    "id": "arXiv:2110.06533",
    "title": "EventBERT: A Pre-Trained Model for Event Correlation Reasoning",
    "abstract": "Event correlation reasoning infers whether a natural language paragraph\ncontaining multiple events conforms to human common sense. For example, \"Andrew\nwas very drowsy, so he took a long nap, and now he is very alert\" is sound and\nreasonable. In contrast, \"Andrew was very drowsy, so he stayed up a long time,\nnow he is very alert\" does not comply with human common sense. Such reasoning\ncapability is essential for many downstream tasks, such as script reasoning,\nabductive reasoning, narrative incoherence, story cloze test, etc. However,\nconducting event correlation reasoning is challenging due to a lack of large\namounts of diverse event-based knowledge and difficulty in capturing\ncorrelation among multiple events. In this paper, we propose EventBERT, a\npre-trained model to encapsulate eventuality knowledge from unlabeled text.\nSpecifically, we collect a large volume of training examples by identifying\nnatural language paragraphs that describe multiple correlated events and\nfurther extracting event spans in an unsupervised manner. We then propose three\nnovel event- and correlation-based learning objectives to pre-train an event\ncorrelation model on our created training corpus. Empirical results show\nEventBERT outperforms strong baselines on four downstream tasks, and achieves\nSoTA results on most of them. Besides, it outperforms existing pre-trained\nmodels by a large margin, e.g., 6.5~23%, in zero-shot learning of these tasks.",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Yucheng Zhou",
      "Xiubo Geng",
      "Tao Shen",
      "Guodong Long",
      "Daxin Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06533"
  },
  {
    "id": "arXiv:2110.06534",
    "title": "Simple Attention Module based Speaker Verification with Iterative noisy  label detection",
    "abstract": "Recently, the attention mechanism such as squeeze-and-excitation module (SE)\nand convolutional block attention module (CBAM) has achieved great success in\ndeep learning-based speaker verification system. This paper introduces an\nalternative effective yet simple one, i.e., simple attention module (SimAM),\nfor speaker verification. The SimAM module is a plug-and-play module without\nextra modal parameters. In addition, we propose a noisy label detection method\nto iteratively filter out the data samples with a noisy label from the training\ndata, considering that a large-scale dataset labeled with human annotation or\nother automated processes may contain noisy labels. Data with the noisy label\nmay over parameterize a deep neural network (DNN) and result in a performance\ndrop due to the memorization effect of the DNN. Experiments are conducted on\nVoxCeleb dataset. The speaker verification model with SimAM achieves the 0.675%\nequal error rate (EER) on VoxCeleb1 original test trials. Our proposed\niterative noisy label detection method further reduces the EER to 0.643%.",
    "descriptor": "\nComments: submitted to ICASSP2022\n",
    "authors": [
      "Xiaoyi Qin",
      "Na Li",
      "Chao Weng",
      "Dan Su",
      "Ming Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.06534"
  },
  {
    "id": "arXiv:2110.06536",
    "title": "NeurIPS 2021 Competition IGLU: Interactive Grounded Language  Understanding in a Collaborative Environment",
    "abstract": "Human intelligence has the remarkable ability to quickly adapt to new tasks\nand environments. Starting from a very young age, humans acquire new skills and\nlearn how to solve new tasks either by imitating the behavior of others or by\nfollowing provided natural language instructions. To facilitate research in\nthis direction, we propose \\emph{IGLU: Interactive Grounded Language\nUnderstanding in a Collaborative Environment}.\nThe primary goal of the competition is to approach the problem of how to\nbuild interactive agents that learn to solve a task while provided with\ngrounded natural language instructions in a collaborative environment.\nUnderstanding the complexity of the challenge, we split it into sub-tasks to\nmake it feasible for participants.\nThis research challenge is naturally related, but not limited, to two fields\nof study that are highly relevant to the NeurIPS community: Natural Language\nUnderstanding and Generation (NLU/G) and Reinforcement Learning (RL).\nTherefore, the suggested challenge can bring two communities together to\napproach one of the important challenges in AI. Another important aspect of the\nchallenge is the dedication to perform a human-in-the-loop evaluation as a\nfinal evaluation for the agents developed by contestants.",
    "descriptor": "",
    "authors": [
      "Julia Kiseleva",
      "Ziming Li",
      "Mohammad Aliannejadi",
      "Shrestha Mohanty",
      "Maartje ter Hoeve",
      "Mikhail Burtsev",
      "Alexey Skrynnik",
      "Artem Zholus",
      "Aleksandr Panov",
      "Kavya Srinet",
      "Arthur Szlam",
      "Yuxuan Sun",
      "Katja Hofmann",
      "Michel Galley",
      "Ahmed Awadallah"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06536"
  },
  {
    "id": "arXiv:2110.06537",
    "title": "Well-classified Examples are Underestimated in Classification with Deep  Neural Networks",
    "abstract": "The conventional wisdom behind learning deep classification models is to\nfocus on bad-classified examples and ignore well-classified examples that are\nfar from the decision boundary. For instance, when training with cross-entropy\nloss, examples with higher likelihoods (i.e., well-classified examples)\ncontribute smaller gradients in back-propagation. However, we theoretically\nshow that this common practice hinders representation learning, energy\noptimization, and the growth of margin. To counteract this deficiency, we\npropose to reward well-classified examples with additive bonuses to revive\ntheir contribution to learning. This counterexample theoretically addresses\nthese three issues. We empirically support this claim by directly verify the\ntheoretical results or through the significant performance improvement with our\ncounterexample on diverse tasks, including image classification, graph\nclassification, and machine translation. Furthermore, this paper shows that\nbecause our idea can solve these three issues, we can deal with complex\nscenarios, such as imbalanced classification, OOD detection, and applications\nunder adversarial attacks.",
    "descriptor": "",
    "authors": [
      "Guangxiang Zhao",
      "Wenkai Yang",
      "Xuancheng Ren",
      "Lei Li",
      "Xu Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06537"
  },
  {
    "id": "arXiv:2110.06539",
    "title": "On Covariate Shift of Latent Confounders in Imitation and Reinforcement  Learning",
    "abstract": "We consider the problem of using expert data with unobserved confounders for\nimitation and reinforcement learning. We begin by defining the problem of\nlearning from confounded expert data in a contextual MDP setup. We analyze the\nlimitations of learning from such data with and without external reward, and\npropose an adjustment of standard imitation learning algorithms to fit this\nsetup. We then discuss the problem of distribution shift between the expert\ndata and the online environment when the data is only partially observable. We\nprove possibility and impossibility results for imitation learning under\narbitrary distribution shift of the missing covariates. When additional\nexternal reward is provided, we propose a sampling procedure that addresses the\nunknown shift and prove convergence to an optimal solution. Finally, we\nvalidate our claims empirically on challenging assistive healthcare and\nrecommender system simulation tasks.",
    "descriptor": "",
    "authors": [
      "Guy Tennenholtz",
      "Assaf Hallak",
      "Gal Dalal",
      "Shie Mannor",
      "Gal Chechik",
      "Uri Shalit"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.06539"
  },
  {
    "id": "arXiv:2110.06541",
    "title": "Collaborative Radio SLAM for Multiple Robots based on WiFi Fingerprint  Similarity",
    "abstract": "Simultaneous Localization and Mapping (SLAM) enables autonomous robots to\nnavigate and execute their tasks through unknown environments. However,\nperforming SLAM in large environments with a single robot is not efficient, and\nvisual or LiDAR-based SLAM requires feature extraction and matching algorithms,\nwhich are computationally expensive. In this paper, we present a collaborative\nSLAM approach with multiple robots using the pervasive WiFi radio signals. A\ncentralized solution is proposed to optimize the trajectory based on the\nodometry and radio fingerprints collected from multiple robots. To improve the\nlocalization accuracy, a novel similarity model is introduced that combines\nreceived signal strength (RSS) and detection likelihood of an access point\n(AP). We perform extensive experiments to demonstrate the effectiveness of the\nproposed similarity model and collaborative SLAM framework.",
    "descriptor": "\nComments: Accepted by 2021 IEEE International Conference on Robotics and Biomimetics, Sanya, China\n",
    "authors": [
      "Ran Liu",
      "Zhenghong Qin",
      "Hua Zhang",
      "Billy Pik Lik Lau",
      "Khairuldanial Ismail",
      "Achala Athukorala",
      "Chau Yuen",
      "Yong Liang Guan",
      "U-Xuan Tan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.06541"
  },
  {
    "id": "arXiv:2110.06543",
    "title": "EIHW-MTG DiCOVA 2021 Challenge System Report",
    "abstract": "This paper aims to automatically detect COVID-19 patients by analysing the\nacoustic information embedded in coughs. COVID-19 affects the respiratory\nsystem, and, consequently, respiratory-related signals have the potential to\ncontain salient information for the task at hand. We focus on analysing the\nspectrogram representations of coughing samples with the aim to investigate\nwhether COVID-19 alters the frequency content of these signals. Furthermore,\nthis work also assesses the impact of gender in the automatic detection of\nCOVID-19. To extract deep learnt representations of the spectrograms, we\ncompare the performance of a cough-specific, and a Resnet18 pre-trained\nConvolutional Neural Network (CNN). Additionally, our approach explores the use\nof contextual attention, so the model can learn to highlight the most relevant\ndeep learnt features extracted by the CNN. We conduct our experiments on the\ndataset released for the Cough Sound Track of the DiCOVA 2021 Challenge. The\nbest performance on the test set is obtained using the Resnet18 pre-trained CNN\nwith contextual attention, which scored an Area Under the Curve (AUC) of 70.91\nat 80% sensitivity.",
    "descriptor": "",
    "authors": [
      "Adria Mallol-Ragolta",
      "Helena Cuesta",
      "Emilia G\u00f3mez",
      "Bj\u00f6rn W. Schuller"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.06543"
  },
  {
    "id": "arXiv:2110.06550",
    "title": "Saliency Detection via Global Context Enhanced Feature Fusion and Edge  Weighted Loss",
    "abstract": "UNet-based methods have shown outstanding performance in salient object\ndetection (SOD), but are problematic in two aspects. 1) Indiscriminately\nintegrating the encoder feature, which contains spatial information for\nmultiple objects, and the decoder feature, which contains global information of\nthe salient object, is likely to convey unnecessary details of non-salient\nobjects to the decoder, hindering saliency detection. 2) To deal with ambiguous\nobject boundaries and generate accurate saliency maps, the model needs\nadditional branches, such as edge reconstructions, which leads to increasing\ncomputational cost. To address the problems, we propose a context fusion\ndecoder network (CFDN) and near edge weighted loss (NEWLoss) function. The CFDN\ncreates an accurate saliency map by integrating global context information and\nthus suppressing the influence of the unnecessary spatial information. NEWLoss\naccelerates learning of obscure boundaries without additional modules by\ngenerating weight maps on object boundaries. Our method is evaluated on four\nbenchmarks and achieves state-of-the-art performance. We prove the\neffectiveness of the proposed method through comparative experiments.",
    "descriptor": "\nComments: 4 pages, 5 figures\n",
    "authors": [
      "Chaewon Park",
      "Minhyeok Lee",
      "MyeongAh Cho",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06550"
  },
  {
    "id": "arXiv:2110.06553",
    "title": "Transformers for EEG Emotion Recognition",
    "abstract": "Electroencephalogram (EEG) can objectively reflect emotional state and\nchanges. However, the transmission mechanism of EEG in the brain and its\ninternal relationship with emotion are still ambiguous to human beings. This\npaper presents a novel approach to EEG emotion recognition built exclusively on\nself-attention over the spectrum, space, and time dimensions to explore the\ncontribution of different EEG electrodes and temporal slices to specific\nemotional states. Our method, named EEG emotion Transformer (EeT), adapts the\nconventional Transformer architecture to EEG signals by enabling spatiospectral\nfeature learning directly from the sequences of EEG signals. Our experimental\nresults demonstrate that \"joint attention\" where temporal and spatial attention\nare applied simultaneously within each block, leads to the best emotion\nrecognition accuracy among the design choices. In addition, compared with other\ncompetitive methods, the proposed method achieves state-of-art results on SEED\nand SEED-IV datasets.",
    "descriptor": "",
    "authors": [
      "Jiyao Liu",
      "Li Zhang",
      "Hao Wu",
      "Huan Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.06553"
  },
  {
    "id": "arXiv:2110.06554",
    "title": "Towards Mixed-Precision Quantization of Neural Networks via Constrained  Optimization",
    "abstract": "Quantization is a widely used technique to compress and accelerate deep\nneural networks. However, conventional quantization methods use the same\nbit-width for all (or most of) the layers, which often suffer significant\naccuracy degradation in the ultra-low precision regime and ignore the fact that\nemergent hardware accelerators begin to support mixed-precision computation.\nConsequently, we present a novel and principled framework to solve the\nmixed-precision quantization problem in this paper. Briefly speaking, we first\nformulate the mixed-precision quantization as a discrete constrained\noptimization problem. Then, to make the optimization tractable, we approximate\nthe objective function with second-order Taylor expansion and propose an\nefficient approach to compute its Hessian matrix. Finally, based on the above\nsimplification, we show that the original problem can be reformulated as a\nMultiple-Choice Knapsack Problem (MCKP) and propose a greedy search algorithm\nto solve it efficiently. Compared with existing mixed-precision quantization\nworks, our method is derived in a principled way and much more computationally\nefficient. Moreover, extensive experiments conducted on the ImageNet dataset\nand various kinds of network architectures also demonstrate its superiority\nover existing uniform and mixed-precision quantization approaches.",
    "descriptor": "\nComments: accepted by ICCV 2021\n",
    "authors": [
      "Weihan Chen",
      "Peisong Wang",
      "Jian Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06554"
  },
  {
    "id": "arXiv:2110.06556",
    "title": "Communication-Efficient Online Federated Learning Framework for  Nonlinear Regression",
    "abstract": "Federated learning (FL) literature typically assumes that each client has a\nfixed amount of data, which is unrealistic in many practical applications. Some\nrecent works introduced a framework for online FL (Online-Fed) wherein clients\nperform model learning on streaming data and communicate the model to the\nserver; however, they do not address the associated communication overhead. As\na solution, this paper presents a partial-sharing-based online federated\nlearning framework (PSO-Fed) that enables clients to update their local models\nusing continuous streaming data and share only portions of those updated models\nwith the server. During a global iteration of PSO-Fed, non-participant clients\nhave the privilege to update their local models with new data. Here, we\nconsider a global task of kernel regression, where clients use a random Fourier\nfeatures-based kernel LMS on their data for local learning. We examine the mean\nconvergence of the PSO-Fed for kernel regression. Experimental results show\nthat PSO-Fed can achieve competitive performance with a significantly lower\ncommunication overhead than Online-Fed.",
    "descriptor": "\nComments: 5 pages, 2 figures, conference\n",
    "authors": [
      "Vinay Chakravarthi Gogineni",
      "Stefan Werner",
      "Yih-Fang Huang",
      "Anthony Kuh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.06556"
  },
  {
    "id": "arXiv:2110.06557",
    "title": "High-order gas-kinetic scheme for radiation hydrodynamics in  equilibrium-diffusion limit",
    "abstract": "In this paper, a high-order gas-kinetic scheme is developed for the equation\nof radiation hydrodynamics in equilibrium-diffusion limit which describes the\ninteraction between matter and radiation. To recover RHE, the\nBhatnagar-Gross-Krook (BGK) model with modified equilibrium state is\nconsidered. In the equilibrium-diffusion limit, the time scales of radiation\ndiffusion and hydrodynamic part are different, and it will make the time step\nvery small for the fully explicit scheme. An implicit-explicit (IMEX) scheme is\napplied, in which the hydrodynamic part is treated explicitly and the radiation\ndiffusion is treated implicitly. For the hydrodynamics part, a time dependent\ngas distribution function can be constructed by the integral solution of\nmodified BGK equation, and the time dependent numerical fluxes can be obtained\nby taking moments of gas distribution function. For the radiation diffusion\nterm, the nonlinear generalized minimal residual (GMRES) method is used. To\nachieve the temporal accuracy, a two-stage method is developed, which is an\nextension of two-stage method for hyperbolic conservation law. For the spatial\naccuracy, the multidimensional weighted essential non-oscillation (WENO) scheme\nis used for the spatial reconstruction. A variety of numerical tests are\nprovided for the performance of current scheme, including the order of accuracy\nand robustness.",
    "descriptor": "\nComments: In this paper, a high-order gas-kinetic scheme is developed for the equation of radiation hydrodynamics in equilibrium-diffusion limit which describes the interaction between matter and radiation\n",
    "authors": [
      "Yaqing Yang",
      "Liang Pan",
      "Wenjun Sun"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.06557"
  },
  {
    "id": "arXiv:2110.06558",
    "title": "LENS: Localization enhanced by NeRF synthesis",
    "abstract": "Neural Radiance Fields (NeRF) have recently demonstrated photo-realistic\nresults for the task of novel view synthesis. In this paper, we propose to\napply novel view synthesis to the robot relocalization problem: we demonstrate\nimprovement of camera pose regression thanks to an additional synthetic dataset\nrendered by the NeRF class of algorithm. To avoid spawning novel views in\nirrelevant places we selected virtual camera locations from NeRF internal\nrepresentation of the 3D geometry of the scene. We further improved\nlocalization accuracy of pose regressors using synthesized realistic and\ngeometry consistent images as data augmentation during training. At the time of\npublication, our approach improved state of the art with a 60% lower error on\nCambridge Landmarks and 7-scenes datasets. Hence, the resulting accuracy\nbecomes comparable to structure-based methods, without any architecture\nmodification or domain adaptation constraints. Since our method allows almost\ninfinite generation of training data, we investigated limitations of camera\npose regression depending on size and distribution of data used for training on\npublic benchmarks. We concluded that pose regression accuracy is mostly bounded\nby relatively small and biased datasets rather than capacity of the pose\nregression model to solve the localization task.",
    "descriptor": "\nComments: Accepted at CoRL 2021\n",
    "authors": [
      "Arthur Moreau",
      "Nathan Piasco",
      "Dzmitry Tsishkou",
      "Bogdan Stanciulescu",
      "Arnaud de La Fortelle"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.06558"
  },
  {
    "id": "arXiv:2110.06559",
    "title": "Infinitely Divisible Noise in the Low Privacy Regime",
    "abstract": "Federated learning, in which training data is distributed among users and\nnever shared, has emerged as a popular approach to privacy-preserving machine\nlearning. Cryptographic techniques such as secure aggregation are used to\naggregate contributions, like a model update, from all users. A robust\ntechnique for making such aggregates differentially private is to exploit\ninfinite divisibility of the Laplace distribution, namely, that a Laplace\ndistribution can be expressed as a sum of i.i.d. noise shares from a Gamma\ndistribution, one share added by each user.\nHowever, Laplace noise is known to have suboptimal error in the low privacy\nregime for $\\varepsilon$-differential privacy, where $\\varepsilon > 1$ is a\nlarge constant. In this paper we present the first infinitely divisible noise\ndistribution for real-valued data that achieves $\\varepsilon$-differential\nprivacy and has expected error that decreases exponentially with $\\varepsilon$.",
    "descriptor": "",
    "authors": [
      "Rasmus Pagh",
      "Nina Mesing Stausholm"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.06559"
  },
  {
    "id": "arXiv:2110.06560",
    "title": "Simple or Complex? Complexity-Controllable Question Generation with Soft  Templates and Deep Mixture of Experts Model",
    "abstract": "The ability to generate natural-language questions with controlled complexity\nlevels is highly desirable as it further expands the applicability of question\ngeneration. In this paper, we propose an end-to-end neural\ncomplexity-controllable question generation model, which incorporates a mixture\nof experts (MoE) as the selector of soft templates to improve the accuracy of\ncomplexity control and the quality of generated questions. The soft templates\ncapture question similarity while avoiding the expensive construction of actual\ntemplates. Our method introduces a novel, cross-domain complexity estimator to\nassess the complexity of a question, taking into account the passage, the\nquestion, the answer and their interactions. The experimental results on two\nbenchmark QA datasets demonstrate that our QG model is superior to\nstate-of-the-art methods in both automatic and manual evaluation. Moreover, our\ncomplexity estimator is significantly more accurate than the baselines in both\nin-domain and out-domain settings.",
    "descriptor": "\nComments: Accepted to Findings of EMNLP 2021\n",
    "authors": [
      "Sheng Bi",
      "Xiya Cheng",
      "Yuan-Fang Li",
      "Lizhen Qu",
      "Shirong Shen",
      "Guilin Qi",
      "Lu Pan",
      "Yinlin Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06560"
  },
  {
    "id": "arXiv:2110.06562",
    "title": "Unsupervised Object Learning via Common Fate",
    "abstract": "Learning generative object models from unlabelled videos is a long standing\nproblem and required for causal scene modeling. We decompose this problem into\nthree easier subtasks, and provide candidate solutions for each of them.\nInspired by the Common Fate Principle of Gestalt Psychology, we first extract\n(noisy) masks of moving objects via unsupervised motion segmentation. Second,\ngenerative models are trained on the masks of the background and the moving\nobjects, respectively. Third, background and foreground models are combined in\na conditional \"dead leaves\" scene model to sample novel scene configurations\nwhere occlusions and depth layering arise naturally. To evaluate the individual\nstages, we introduce the Fishbowl dataset positioned between complex real-world\nscenes and common object-centric benchmarks of simplistic objects. We show that\nour approach allows learning generative models that generalize beyond the\nocclusions present in the input videos, and represent scenes in a modular\nfashion that allows sampling plausible scenes outside the training distribution\nby permitting, for instance, object numbers or densities not observed in the\ntraining set.",
    "descriptor": "",
    "authors": [
      "Matthias Tangemann",
      "Steffen Schneider",
      "Julius von K\u00fcgelgen",
      "Francesco Locatello",
      "Peter Gehler",
      "Thomas Brox",
      "Matthias K\u00fcmmerer",
      "Matthias Bethge",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06562"
  },
  {
    "id": "arXiv:2110.06564",
    "title": "Deep Superpixel-based Network for Blind Image Quality Assessment",
    "abstract": "The goal in a blind image quality assessment (BIQA) model is to simulate the\nprocess of evaluating images by human eyes and accurately assess the quality of\nthe image. Although many approaches effectively identify degradation, they do\nnot fully consider the semantic content in images resulting in distortion. In\norder to fill this gap, we propose a deep adaptive superpixel-based network,\nnamely DSN-IQA, to assess the quality of image based on multi-scale and\nsuperpixel segmentation. The DSN-IQA can adaptively accept arbitrary scale\nimages as input images, making the assessment process similar to human\nperception. The network uses two models to extract multi-scale semantic\nfeatures and generate a superpixel adjacency map. These two elements are united\ntogether via feature fusion to accurately predict image quality. Experimental\nresults on different benchmark databases demonstrate that our algorithm is\nhighly competitive with other approaches when assessing challenging authentic\nimage databases. Also, due to adaptive deep superpixel-based network, our model\naccurately assesses images with complicated distortion, much like the human\neye.",
    "descriptor": "",
    "authors": [
      "Guangyi Yang",
      "Yang Zhan.",
      "Yuxuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06564"
  },
  {
    "id": "arXiv:2110.06565",
    "title": "Duality Temporal-channel-frequency Attention Enhanced Speaker  Representation Learning",
    "abstract": "The use of channel-wise attention in CNN based speaker representation\nnetworks has achieved remarkable performance in speaker verification (SV). But\nthese approaches do simple averaging on time and frequency feature maps before\nchannel-wise attention learning and ignore the essential mutual interaction\namong temporal, channel as well as frequency scales. To address this problem,\nwe propose the Duality Temporal-Channel-Frequency (DTCF) attention to\nre-calibrate the channel-wise features with aggregation of global context on\ntemporal and frequency dimensions. Specifically, the duality attention -\ntime-channel (T-C) attention as well as frequency-channel (F-C) attention -\naims to focus on salient regions along the T-C and F-C feature maps that may\nhave more considerable impact on the global context, leading to more\ndiscriminative speaker representations. We evaluate the effectiveness of the\nproposed DTCF attention on the CN-Celeb and VoxCeleb datasets. On the CN-Celeb\nevaluation set, the EER/minDCF of ResNet34-DTCF are reduced by 0.63%/0.0718\ncompared with those of ResNet34-SE. On VoxCeleb1-O, VoxCeleb1-E and VoxCeleb1-H\nevaluation sets, the EER/minDCF of ResNet34-DTCF achieve 0.36%/0.0263,\n0.39%/0.0382 and 0.74%/0.0753 reductions compared with those of ResNet34-SE.",
    "descriptor": "",
    "authors": [
      "Li Zhang",
      "Qing Wang",
      "Lei Xie"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.06565"
  },
  {
    "id": "arXiv:2110.06568",
    "title": "One to Multiple Mapping Dual Learning: Learning Multiple Sources from  One Mixed Signal",
    "abstract": "Single channel blind source separation (SCBSS) refers to separate multiple\nsources from a mixed signal collected by a single sensor. The existing methods\nfor SCBSS mainly focus on separating two sources and have weak generalization\nperformance. To address these problems, an algorithm is proposed in this paper\nto separate multiple sources from a mixture by designing a parallel dual\ngenerative adversarial Network (PDualGAN) that can build the relationship\nbetween a mixture and the corresponding multiple sources to realize\none-to-multiple cross-domain mapping. This algorithm can be applied to any\nmixed model such as linear instantaneous mixed model and convolutional mixed\nmodel. Besides, one-to-multiple datasets are created which including the\nmixtures and corresponding sources for this study. The experiment was carried\nout on four different datasets and tested with signals mixed in different\nproportions. Experimental results show that the proposed algorithm can achieve\nhigh performance in peak signal-to-noise ratio (PSNR) and correlation, which\noutperforms state-of-the-art algorithms.",
    "descriptor": "",
    "authors": [
      "Ting Liu",
      "Wenwu Wang",
      "Xiaofei Zhang",
      "Zhenyin Gong",
      "Yina Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.06568"
  },
  {
    "id": "arXiv:2110.06571",
    "title": "Hyperspectral 3D Mapping of Underwater Environments",
    "abstract": "Hyperspectral imaging has been increasingly used for underwater survey\napplications over the past years. As many hyperspectral cameras work as\npush-broom scanners, their use is usually limited to the creation of\nphoto-mosaics based on a flat surface approximation and by interpolating the\ncamera pose from dead-reckoning navigation. Yet, because of drift in the\nnavigation and the mostly wrong flat surface assumption, the quality of the\nobtained photo-mosaics is often too low to support adequate analysis.In this\npaper we present an initial method for creating hyperspectral 3D\nreconstructions of underwater environments. By fusing the data gathered by a\nclassical RGB camera, an inertial navigation system and a hyperspectral\npush-broom camera, we show that the proposed method creates highly accurate 3D\nreconstructions with hyperspectral textures. We propose to combine techniques\nfrom simultaneous localization and mapping, structure-from-motion and 3D\nreconstruction and advantageously use them to create 3D models with\nhyperspectral texture, allowing us to overcome the flat surface assumption and\nthe classical limitation of dead-reckoning navigation.",
    "descriptor": "\nComments: ICCV'21 - Computer Vision in the Ocean Workshop\n",
    "authors": [
      "Maxime Ferrera",
      "Aur\u00e9lien Arnaubec",
      "Klemen Istenic",
      "Nuno Gracias",
      "Touria Bajjouk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.06571"
  },
  {
    "id": "arXiv:2110.06592",
    "title": "Life is not black and white -- Combining Semi-Supervised Learning with  fuzzy labels",
    "abstract": "The required amount of labeled data is one of the biggest issues in deep\nlearning. Semi-Supervised Learning can potentially solve this issue by using\nadditional unlabeled data. However, many datasets suffer from variability in\nthe annotations. The aggregated labels from these annotation are not consistent\nbetween different annotators and thus are considered fuzzy. These fuzzy labels\nare often not considered by Semi-Supervised Learning. This leads either to an\ninferior performance or to higher initial annotation costs in the complete\nmachine learning development cycle. We envision the incorporation of fuzzy\nlabels into Semi-Supervised Learning and give a proof-of-concept of the\npotential lower costs and higher consistency in the complete development cycle.\nAs part of our concept, we discuss current limitations, futures research\nopportunities and potential broad impacts.",
    "descriptor": "\nComments: Accepted at LWDA 21: Lernen, Wissen, Daten, Analysen September 2021, Munich, Germany\n",
    "authors": [
      "Lars Schmarje",
      "Reinhard Koch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06592"
  },
  {
    "id": "arXiv:2110.06595",
    "title": "Refcat: The Internet Archive Scholar Citation Graph",
    "abstract": "As part of its scholarly data efforts, the Internet Archive (IA) releases a\nfirst version of a citation graph dataset, named refcat, derived from scholarly\npublications and additional data sources. It is composed of data gathered by\nthe fatcat cataloging project (the catalog that underpins IA Scholar), related\nweb-scale crawls targeting primary and secondary scholarly outputs, as well as\nmetadata from the Open Library project and Wikipedia. This first version of the\ngraph consists of over 1.3B citations. We release this dataset under a CC0\nPublic Domain Dedication, accessible through Internet Archive. The source code\nused for the derivation process, including exact and fuzzy citation matching,\nis released under an MIT license. The goal of this report is to describe\nbriefly the current contents and the derivation of the dataset.",
    "descriptor": "",
    "authors": [
      "Martin Czygan",
      "Helge Holzmann",
      "Bryan Newbold"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2110.06595"
  },
  {
    "id": "arXiv:2110.06598",
    "title": "Enhanced Sequential Covariance Intersection Fusion",
    "abstract": "This paper is concerned with the sequential covariance intersection (CI)\nfusion problem that the fusion result is independent of fusion structure\nincluding the fusion order and the number of estimates fused in each sequential\nfusion. An enhanced sequential CI fusion is first developed to better meet the\npractical requirements as compared with the existing batch and sequential CI\nfusion. Meanwhile, it is proved that the enhanced sequential CI fusion ensures\nthe fusion estimate and covariance are unbiased and consistent. Notice that the\nfusion structure of the enhanced sequential CI fusion is unpredictable in\npractice, which may have negative impacts on the fusion performance. To this\nend, a weighting fusion criterion with analytical form is further proposed, and\ncan be depicted by different formulas when choosing different performance\nindexes. For this criterion, it is proved that the fusion results are not\naffected by the fusion structure, and thus the fusion performance can be\nguaranteed. Finally, simulation examples are utilized to demonstrate the\neffectiveness and advantages of the proposed methods.",
    "descriptor": "\nComments: 7 pages,11 figures\n",
    "authors": [
      "Zhongyao Hu",
      "Bo Chen",
      "Wen-An Zhang",
      "Li Yu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.06598"
  },
  {
    "id": "arXiv:2110.06601",
    "title": "Vibration-Based Condition Monitoring By Ensemble Deep Learning",
    "abstract": "Vibration-based techniques are among the most common condition monitoring\napproaches. With the advancement of computers, these approaches have also been\nimproved such that recently, these approaches in conjunction with deep learning\nmethods attract attention among researchers. This is mostly due to the nature\nof the deep learning method that could facilitate the monitoring procedure by\nintegrating the feature extraction, feature selection, and classification steps\ninto one automated step. However, this can be achieved at the expense of\nchallenges in designing the architecture of a deep learner, tuning its\nhyper-parameters. Moreover, it sometimes gives low generalization capability.\nAs a remedy to these problems, this study proposes a framework based on\nensemble deep learning methodology. The framework was initiated by creating a\npool of Convolutional neural networks (CNN). To create diversity to the CNNs,\nthey are fed by frequency responses which are passed through different\nfunctions. As the next step, proper CNNs are selected based on an information\ncriterion to be used for fusion. The fusion is then carried out by improved\nDempster-Shafer theory. The proposed framework is applied to real test data\ncollected from Equiax Polycrystalline Nickel alloy first-stage turbine blades\nwith complex geometry.",
    "descriptor": "",
    "authors": [
      "Vahid Yaghoubi",
      "Liangliang Cheng",
      "Wim Van Paepegem",
      "Mathias Keremans"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.06601"
  },
  {
    "id": "arXiv:2110.06607",
    "title": "THOMAS: Trajectory Heatmap Output with learned Multi-Agent Sampling",
    "abstract": "In this paper, we propose THOMAS, a joint multi-agent trajectory prediction\nframework allowing for efficient and consistent prediction of multi-agent\nmulti-modal trajectories. We present a unified model architecture for fast and\nsimultaneous agent future heatmap estimation leveraging hierarchical and sparse\nimage generation. We demonstrate that heatmap output enables a higher level of\ncontrol on the predicted trajectories compared to vanilla multi-modal\ntrajectory regression, allowing to incorporate additional constraints for\ntighter sampling or collision-free predictions in a deterministic way. However,\nwe also highlight that generating scene-consistent predictions goes beyond the\nmere generation of collision-free trajectories. We therefore propose a\nlearnable trajectory recombination model that takes as input a set of predicted\ntrajectories for each agent and outputs its consistent reordered recombination.\nWe report our results on the Interaction multi-agent prediction challenge and\nrank $1^{st}$ on the online test leaderboard.",
    "descriptor": "",
    "authors": [
      "Thomas Gilles",
      "Stefano Sabatini",
      "Dzmitry Tsishkou",
      "Bogdan Stanciulescu",
      "Fabien Moutarde"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.06607"
  },
  {
    "id": "arXiv:2110.06609",
    "title": "MSP: Multi-Stage Prompting for Making Pre-trained Language Models Better  Translators",
    "abstract": "Pre-trained language models have recently been shown to be able to perform\ntranslation without finetuning via prompting. Inspired by these findings, we\nstudy improving the performance of pre-trained language models on translation\ntasks, where training neural machine translation models is the current de facto\napproach. We present Multi-Stage Prompting, a simple and lightweight approach\nfor better adapting pre-trained language models to translation tasks. To make\npre-trained language models better translators, we divide the translation\nprocess via pre-trained language models into three separate stages: the\nencoding stage, the re-encoding stage, and the decoding stage. During each\nstage, we independently apply different continuous prompts for allowing\npre-trained language models better adapting to translation tasks. We conduct\nextensive experiments on low-, medium-, and high-resource translation tasks.\nExperiments show that our method can significantly improve the translation\nperformance of pre-trained language models.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Zhixing Tan",
      "Xiangwen Zhang",
      "Shuo Wang",
      "Yang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06609"
  },
  {
    "id": "arXiv:2110.06612",
    "title": "Exploring Dense Retrieval for Dialogue Response Selection",
    "abstract": "Recent research on dialogue response selection has been mainly focused on\nselecting a proper response from a pre-defined small set of candidates using\nsophisticated neural models. Due to their heavy computational overhead, they\nare unable to select responses from a large candidate pool. In this study, we\npresent a solution to directly select proper responses from a large corpus or\neven a nonparallel corpus that only consists of unpaired sentences, using a\ndense retrieval model. We extensively test our proposed approach under two\nexperiment settings: (i) re-rank experiment that aims to rank a small set of\npre-defined candidates; (ii) full-rank experiment where the target is to\ndirectly select proper responses from a full candidate pool that may contain\nmillions of candidates. For re-rank setting, the superiority is quite\nsurprising given its simplicity. For full-rank setting, we can emphasize that\nwe are the first to do such evaluation. Moreover, human evaluation results show\nthat increasing the size of nonparallel corpus leads to further improvement of\nour model performance\\footnote{All our source codes, models and other related\nresources are publically available at\n\\url{https://github.com/gmftbyGMFTBY/SimpleReDial-v1}.",
    "descriptor": "\nComments: 14 pages, 2 figures, 10 tables\n",
    "authors": [
      "Tian Lan",
      "Deng Cai",
      "Yan Wang",
      "Yixuan Su",
      "Xian-Ling Mao",
      "Heyan Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06612"
  },
  {
    "id": "arXiv:2110.06615",
    "title": "CLIP4Caption: CLIP for Video Caption",
    "abstract": "Video captioning is a challenging task since it requires generating sentences\ndescribing various diverse and complex videos. Existing video captioning models\nlack adequate visual representation due to the neglect of the existence of gaps\nbetween videos and texts. To bridge this gap, in this paper, we propose a\nCLIP4Caption framework that improves video captioning based on a CLIP-enhanced\nvideo-text matching network (VTM). This framework is taking full advantage of\nthe information from both vision and language and enforcing the model to learn\nstrongly text-correlated video features for text generation. Besides, unlike\nmost existing models using LSTM or GRU as the sentence decoder, we adopt a\nTransformer structured decoder network to effectively learn the long-range\nvisual and language dependency. Additionally, we introduce a novel ensemble\nstrategy for captioning tasks. Experimental results demonstrate the\neffectiveness of our method on two datasets: 1) on MSR-VTT dataset, our method\nachieved a new state-of-the-art result with a significant gain of up to 10% in\nCIDEr; 2) on the private test data, our method ranking 2nd place in the ACM MM\nmultimedia grand challenge 2021: Pre-training for Video Understanding\nChallenge. It is noted that our model is only trained on the MSR-VTT dataset.",
    "descriptor": "",
    "authors": [
      "Mingkang Tang",
      "Zhanyu Wang",
      "Zhenhua Liu",
      "Fengyun Rao",
      "Dian Li",
      "Xiu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06615"
  },
  {
    "id": "arXiv:2110.06620",
    "title": "Maximizing Efficiency of Language Model Pre-training for Learning  Representation",
    "abstract": "Pre-trained language models in the past years have shown exponential growth\nin model parameters and compute time. ELECTRA is a novel approach for improving\nthe compute efficiency of pre-trained language models (e.g. BERT) based on\nmasked language modeling (MLM) by addressing the sample inefficiency problem\nwith the replaced token detection (RTD) task. Our work proposes adaptive early\nexit strategy to maximize the efficiency of the pre-training process by\nrelieving the model's subsequent layers of the need to process latent features\nby leveraging earlier layer representations. Moreover, we evaluate an initial\napproach to the problem that has not succeeded in maintaining the accuracy of\nthe model while showing a promising compute efficiency by thoroughly\ninvestigating the necessity of the generator module of ELECTRA.",
    "descriptor": "\nComments: Published in KSC 2020\n",
    "authors": [
      "Junmo Kang",
      "Suwon Shin",
      "Jeonghwan Kim",
      "Jaeyoung Jo",
      "Sung-Hyon Myaeng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06620"
  },
  {
    "id": "arXiv:2110.06623",
    "title": "SSSNET: Semi-Supervised Signed Network Clustering",
    "abstract": "Node embeddings are a powerful tool in the analysis of networks; yet, their\nfull potential for the important task of node clustering has not been fully\nexploited. In particular, most state-of-the-art methods generating node\nembeddings of signed networks focus on link sign prediction, and those that\npertain to node clustering are usually not graph neural network (GNN) methods.\nHere, we introduce a novel probabilistic balanced normalized cut loss for\ntraining nodes in a GNN framework for semi-supervised signed network\nclustering, called SSSNET. The method is end-to-end in combining embedding\ngeneration and clustering without an intermediate step; it has node clustering\nas main focus, with an emphasis on polarization effects arising in networks.\nThe main novelty of our approach is a new take on the role of social balance\ntheory for signed network embeddings. The standard heuristic for justifying the\ncriteria for the embeddings hinges on the assumption that \"an enemy's enemy is\na friend\". Here, instead, a neutral stance is assumed on whether or not the\nenemy of an enemy is a friend. Experimental results on various data sets,\nincluding a synthetic signed stochastic block model, a polarized version of it,\nand real-world data at different scales, demonstrate that SSSNET can achieve\ncomparable or better results than state-of-the-art spectral clustering methods,\nfor a wide range of noise and sparsity levels. SSSNET complements existing\nmethods through the possibility of including exogenous information, in the form\nof node-level features or labels.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Yixuan He",
      "Gesine Reinert",
      "Songchao Wang",
      "Mihai Cucuringu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06623"
  },
  {
    "id": "arXiv:2110.06624",
    "title": "Identification of Metallic Objects using Spectral Magnetic  Polarizability Tensor Signatures: Object Classification",
    "abstract": "The early detection of terrorist threat objects, such as guns and knives,\nthrough improved metal detection, has the potential to reduce the number of\nattacks and improve public safety and security. To achieve this, there is\nconsiderable potential to use the fields applied and measured by a metal\ndetector to discriminate between different shapes and different metals since,\nhidden within the field perturbation, is object characterisation information.\nThe magnetic polarizability tensor (MPT) offers an economical characterisation\nof metallic objects and its spectral signature provides additional object\ncharacterisation information. The MPT spectral signature can be determined from\nmeasurements of the induced voltage over a range frequencies in a metal\nsignature for a hidden object. With classification in mind, it can also be\ncomputed in advance for different threat and non-threat objects. In the\narticle, we evaluate the performance of probabilistic and non-probabilistic\nmachine learning algorithms, trained using a dictionary of computed MPT\nspectral signatures, to classify objects for metal detection. We discuss the\nimportances of using appropriate features and selecting an appropriate\nalgorithm depending on the classification problem being solved and we present\nnumerical results for a range of practically motivated metal detection\nclassification problems.",
    "descriptor": "",
    "authors": [
      "B.A. Wilson",
      "P.D. Ledger",
      "W.R.B. Lionheart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.06624"
  },
  {
    "id": "arXiv:2110.06628",
    "title": "Oriented Feature Alignment for Fine-grained Object Recognition in  High-Resolution Satellite Imagery",
    "abstract": "Oriented object detection in remote sensing images has made great progress in\nrecent years. However, most of the current methods only focus on detecting\ntargets, and cannot distinguish fine-grained objects well in complex scenes. In\nthis technical report, we analyzed the key issues of fine-grained object\nrecognition, and use an oriented feature alignment network (OFA-Net) to achieve\nhigh-performance fine-grained oriented object recognition in optical remote\nsensing images. OFA-Net achieves accurate object localization through a rotated\nbounding boxes refinement module. On this basis, the boundary-constrained\nrotation feature alignment module is applied to achieve local feature\nextraction, which is beneficial to fine-grained object classification. The\nsingle model of our method achieved mAP of 46.51\\% in the GaoFen competition\nand won 3rd place in the ISPRS benchmark with the mAP of 43.73\\%.",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Qi Ming",
      "Junjie Song",
      "Zhiqiang Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06628"
  },
  {
    "id": "arXiv:2110.06629",
    "title": "Detection Software Content Failures Using Dynamic Execution Information",
    "abstract": "Modern software systems become too complex to be tested and validated.\nDetecting software partial failures in complex systems at runtime assist to\nhandle software unintended behaviors, avoiding catastrophic software failures\nand improving software runtime availability. These detection techniques aim to\nfind the manifestation of faults before they finally lead to unavoidable\nfailures, thus supporting following runtime fault tolerant techniques. We\nreview the state of the art articles and find that the content failures account\nfor the majority of all kinds of software failures, but its detection methods\nare rarely studied. In this work, we propose a novel failure detection\nindicator based on the software runtime dynamic execution information for\nsoftware content failures. The runtime information is recorded during software\nexecution, then transformed to a measure named runtime entropy and finally fed\ninto machine learning models. The machine learning models are built to classify\nthe intended and unintended behaviors of the objected software systems. A\nseries of controlled experiments on several open source projects are conducted\nto prove the feasibility of the method. We also evaluate the accuracy of\nmachine learning models built in this work.",
    "descriptor": "",
    "authors": [
      "Shiyi Kong",
      "Minyan Lu",
      "Jun Ai",
      "Shuguang Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.06629"
  },
  {
    "id": "arXiv:2110.06630",
    "title": "Fuzzy Overclustering: Semi-Supervised Classification of Fuzzy Labels  with Overclustering and Inverse Cross-Entropy",
    "abstract": "Deep learning has been successfully applied to many classification problems\nincluding underwater challenges. However, a long-standing issue with deep\nlearning is the need for large and consistently labeled datasets. Although\ncurrent approaches in semi-supervised learning can decrease the required amount\nof annotated data by a factor of 10 or even more, this line of research still\nuses distinct classes. For underwater classification, and uncurated real-world\ndatasets in general, clean class boundaries can often not be given due to a\nlimited information content in the images and transitional stages of the\ndepicted objects. This leads to different experts having different opinions and\nthus producing fuzzy labels which could also be considered ambiguous or\ndivergent. We propose a novel framework for handling semi-supervised\nclassifications of such fuzzy labels. It is based on the idea of overclustering\nto detect substructures in these fuzzy labels. We propose a novel loss to\nimprove the overclustering capability of our framework and show the benefit of\noverclustering for fuzzy labels. We show that our framework is superior to\nprevious state-of-the-art semi-supervised methods when applied to real-world\nplankton data with fuzzy labels. Moreover, we acquire 5 to 10\\% more consistent\npredictions of substructures.",
    "descriptor": "\nComments: Source code: this https URL Datasets: this https URL arXiv admin note: substantial text overlap with arXiv:2012.01768\n",
    "authors": [
      "Lars Schmarje",
      "Johannes Br\u00fcnger",
      "Monty Santarossa",
      "Simon-Martin Schr\u00f6der",
      "Rainer Kiko",
      "Reinhard Koch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06630"
  },
  {
    "id": "arXiv:2110.06632",
    "title": "Unsupervised Representation Learning for 3D Point Cloud Data",
    "abstract": "Though a number of point cloud learning methods have been proposed to handle\nunordered points, most of them are supervised and require labels for training.\nBy contrast, unsupervised learning of point cloud data has received much less\nattention to date. In this paper, we propose a simple yet effective approach\nfor unsupervised point cloud learning. In particular, we identify a very useful\ntransformation which generates a good contrastive version of an original point\ncloud. They make up a pair. After going through a shared encoder and a shared\nhead network, the consistency between the output representations are maximized\nwith introducing two variants of contrastive losses to respectively facilitate\ndownstream classification and segmentation. To demonstrate the efficacy of our\nmethod, we conduct experiments on three downstream tasks which are 3D object\nclassification (on ModelNet40 and ModelNet10), shape part segmentation (on\nShapeNet Part dataset) as well as scene segmentation (on S3DIS). Comprehensive\nresults show that our unsupervised contrastive representation learning enables\nimpressive outcomes in object classification and semantic segmentation. It\ngenerally outperforms current unsupervised methods, and even achieves\ncomparable performance to supervised methods. Our source codes will be made\npublicly available.",
    "descriptor": "",
    "authors": [
      "Jincen Jiang",
      "Xuequan Lu",
      "Wanli Ouyang",
      "Meili Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2110.06632"
  },
  {
    "id": "arXiv:2110.06634",
    "title": "End-to-end translation of human neural activity to speech with a  dual-dual generative adversarial network",
    "abstract": "In a recent study of auditory evoked potential (AEP) based brain-computer\ninterface (BCI), it was shown that, with an encoder-decoder framework, it is\npossible to translate human neural activity to speech (T-CAS). However, current\nencoder-decoder-based methods achieve T-CAS often with a two-step method where\nthe information is passed between the encoder and decoder with a shared\ndimension reduction vector, which may result in a loss of information. A\npotential approach to this problem is to design an end-to-end method by using a\ndual generative adversarial network (DualGAN) without dimension reduction of\npassing information, but it cannot realize one-to-one signal-to-signal\ntranslation (see Fig.1 (a) and (b)). In this paper, we propose an end-to-end\nmodel to translate human neural activity to speech directly, create a new\nelectroencephalogram (EEG) datasets for participants with good attention by\ndesign a device to detect participants' attention, and introduce a dual-dual\ngenerative adversarial network (Dual-DualGAN) (see Fig. 1 (c) and (d)) to\naddress an end-to-end translation of human neural activity to speech (ET-CAS)\nproblem by group labelling EEG signals and speech signals, inserting a\ntransition domain to realize cross-domain mapping. In the transition domain,\nthe transition signals are cascaded by the corresponding EEG and speech signals\nin a certain proportion, which can build bridges for EEG and speech signals\nwithout corresponding features, and realize one-to-one cross-domain\nEEG-to-speech translation. The proposed method can translate word-length and\nsentence-length sequences of neural activity to speech. Experimental evaluation\nhas been conducted to show that the proposed method significantly outperforms\nstate-of-the-art methods on both words and sentences of auditory stimulus.",
    "descriptor": "\nComments: 12 pages, 13 figures\n",
    "authors": [
      "Yina Guo",
      "Xiaofei Zhang",
      "Zhenying Gong",
      "Anhong Wang",
      "Wenwu Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2110.06634"
  },
  {
    "id": "arXiv:2110.06635",
    "title": "ADOP: Approximate Differentiable One-Pixel Point Rendering",
    "abstract": "We present a novel point-based, differentiable neural rendering pipeline for\nscene refinement and novel view synthesis. The input are an initial estimate of\nthe point cloud and the camera parameters. The output are synthesized images\nfrom arbitrary camera poses. The point cloud rendering is performed by a\ndifferentiable renderer using multi-resolution one-pixel point rasterization.\nSpatial gradients of the discrete rasterization are approximated by the novel\nconcept of ghost geometry. After rendering, the neural image pyramid is passed\nthrough a deep neural network for shading calculations and hole-filling. A\ndifferentiable, physically-based tonemapper then converts the intermediate\noutput to the target image. Since all stages of the pipeline are\ndifferentiable, we optimize all of the scene's parameters i.e. camera model,\ncamera pose, point position, point color, environment map, rendering network\nweights, vignetting, camera response function, per image exposure, and per\nimage white balance. We show that our system is able to synthesize sharper and\nmore consistent novel views than existing approaches because the initial\nreconstruction is refined during training. The efficient one-pixel point\nrasterization allows us to use arbitrary camera models and display scenes with\nwell over 100M points in real time.",
    "descriptor": "",
    "authors": [
      "Darius R\u00fcckert",
      "Linus Franke",
      "Marc Stamminger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.06635"
  },
  {
    "id": "arXiv:2110.06636",
    "title": "Unique on Facebook: Formulation and Evidence of (Nano)targeting  Individual Users with non-PII Data",
    "abstract": "The privacy of an individual is bounded by the ability of a third party to\nreveal their identity. Certain data items such as a passport ID or a mobile\nphone number may be used to uniquely identify a person. These are referred to\nas Personal Identifiable Information (PII) items. Previous literature has also\nreported that, in datasets including millions of users, a combination of\nseveral non-PII items (which alone are not enough to identify an individual)\ncan uniquely identify an individual within the dataset. In this paper, we\ndefine a data-driven model to quantify the number of interests from a user that\nmake them unique on Facebook. To the best of our knowledge, this represents the\nfirst study of individuals' uniqueness at the world population scale. Besides,\nusers' interests are actionable non-PII items that can be used to define ad\ncampaigns and deliver tailored ads to Facebook users. We run an experiment\nthrough 21 Facebook ad campaigns that target three of the authors of this paper\nto prove that, if an advertiser knows enough interests from a user, the\nFacebook Advertising Platform can be systematically exploited to deliver ads\nexclusively to a specific user. We refer to this practice as nanotargeting.\nFinally, we discuss the harmful risks associated with nanotargeting such as\npsychological persuasion, user manipulation, or blackmailing, and provide\neasily implementable countermeasures to preclude attacks based on nanotargeting\ncampaigns on Facebook.",
    "descriptor": "\nComments: 16 pages, 12 figures, 4 tables\n",
    "authors": [
      "Jos\u00e9 Gonz\u00e1lez-Caba\u00f1as",
      "\u00c1ngel Cuevas",
      "Rub\u00e9n Cuevas",
      "Juan L\u00f3pez-Fern\u00e1ndez",
      "David Garc\u00eda"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.06636"
  },
  {
    "id": "arXiv:2110.06637",
    "title": "Knowledge Graph-enhanced Sampling for Conversational Recommender System",
    "abstract": "The traditional recommendation systems mainly use offline user data to train\noffline models, and then recommend items for online users, thus suffering from\nthe unreliable estimation of user preferences based on sparse and noisy\nhistorical data. Conversational Recommendation System (CRS) uses the\ninteractive form of the dialogue systems to solve the intrinsic problems of\ntraditional recommendation systems. However, due to the lack of contextual\ninformation modeling, the existing CRS models are unable to deal with the\nexploitation and exploration (E&E) problem well, resulting in the heavy burden\non users. To address the aforementioned issue, this work proposes a contextual\ninformation enhancement model tailored for CRS, called Knowledge Graph-enhanced\nSampling (KGenSam). KGenSam integrates the dynamic graph of user interaction\ndata with the external knowledge into one heterogeneous Knowledge Graph (KG) as\nthe contextual information environment. Then, two samplers are designed to\nenhance knowledge by sampling fuzzy samples with high uncertainty for obtaining\nuser preferences and reliable negative samples for updating recommender to\nachieve efficient acquisition of user preferences and model updating, and thus\nprovide a powerful solution for CRS to deal with E&E problem. Experimental\nresults on two real-world datasets demonstrate the superiority of KGenSam with\nsignificant improvements over state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Mengyuan Zhao",
      "Xiaowen Huang",
      "Lixi Zhu",
      "Jitao Sang",
      "Jian Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06637"
  },
  {
    "id": "arXiv:2110.06639",
    "title": "When saliency goes off on a tangent: Interpreting Deep Neural Networks  with nonlinear saliency maps",
    "abstract": "A fundamental bottleneck in utilising complex machine learning systems for\ncritical applications has been not knowing why they do and what they do, thus\npreventing the development of any crucial safety protocols. To date, no method\nexist that can provide full insight into the granularity of the neural\nnetwork's decision process. In the past, saliency maps were an early attempt at\nresolving this problem through sensitivity calculations, whereby dimensions of\na data point are selected based on how sensitive the output of the system is to\nthem. However, the success of saliency maps has been at best limited, mainly\ndue to the fact that they interpret the underlying learning system through a\nlinear approximation. We present a novel class of methods for generating\nnonlinear saliency maps which fully account for the nonlinearity of the\nunderlying learning system. While agreeing with linear saliency maps on simple\nproblems where linear saliency maps are correct, they clearly identify more\nspecific drivers of classification on complex examples where nonlinearities are\nmore pronounced. This new class of methods significantly aids interpretability\nof deep neural networks and related machine learning systems. Crucially, they\nprovide a starting point for their more broad use in serious applications,\nwhere 'why' is equally important as 'what'.",
    "descriptor": "",
    "authors": [
      "Jan Rosenzweig",
      "Zoran Cvetkovic",
      "Ivana Rosenzweig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06639"
  },
  {
    "id": "arXiv:2110.06640",
    "title": "Detecting Slag Formations with Deep Convolutional Neural Networks",
    "abstract": "We investigate the ability to detect slag formations in images from inside a\nGrate-Kiln system furnace with two deep convolutional neural networks. The\nconditions inside the furnace cause occasional obstructions of the camera view.\nOur approach suggests dealing with this problem by introducing a convLSTM-layer\nin the deep convolutional neural network. The results show that it is possible\nto achieve sufficient performance to automate the decision of timely\ncountermeasures in the industrial operational setting. Furthermore, the\naddition of the convLSTM-layer results in fewer outlying predictions and a\nlower running variance of the fraction of detected slag in the image time\nseries.",
    "descriptor": "\nComments: 15 pages, 6 figures, to be published in the proceedings of DAGM German Conference on Pattern Recognition 2021\n",
    "authors": [
      "Christian von Koch",
      "William Anz\u00e9n",
      "Max Fischer",
      "Raazesh Sainudiin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06640"
  },
  {
    "id": "arXiv:2110.06648",
    "title": "Robotic Autonomous Trolley Collection with Progressive Perception and  Nonlinear Model Predictive Control",
    "abstract": "Autonomous mobile manipulation robots that can collect trolleys are widely\nused to liberate human resources and fight epidemics. Most prior robotic\ntrolley collection solutions only detect trolleys with 2D poses or are merely\nbased on specific marks and lack the formal design of planning algorithms. In\nthis paper, we present a novel mobile manipulation system with applications in\nluggage trolley collection. The proposed system integrates a compact hardware\ndesign and a progressive perception and planning framework, enabling the system\nto efficiently and robustly collect trolleys in dynamic and complex\nenvironments. For the perception, we first develop a 3D trolley detection\nmethod that combines object detection and keypoint estimation. Then, a docking\nprocess in a short distance is achieved with an accurate point cloud plane\ndetection method and a novel manipulator design. On the planning side, we\nformulate the robot's motion planning under a nonlinear model predictive\ncontrol framework with control barrier functions to improve obstacle avoidance\ncapabilities while maintaining the target in the sensors' field of view at\nclose distances. We demonstrate our design and framework by deploying the\nsystem on actual trolley collection tasks, and their effectiveness and\nrobustness are experimentally validated.",
    "descriptor": "\nComments: Submitted to the 2022 International Conference on Robotics and Automation (ICRA 2022)\n",
    "authors": [
      "Anxing Xiao",
      "Hao Luan",
      "Ziqi Zhao",
      "Yue Hong",
      "Jieting Zhao",
      "Jiankun Wang",
      "Max Q.-H. Meng"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.06648"
  },
  {
    "id": "arXiv:2110.06649",
    "title": "Optimal Beamwidth and Altitude for Maximal Uplink Coverage in Satellite  Networks",
    "abstract": "Dense satellite constellations recently emerged as a prominent solution to\ncomplementing terrestrial networks in attaining true global coverage. As such,\nanalytic optimization techniques can be adopted to rapidly maximize the\nbenefits of such satellite networks. The paper presents a framework that relies\non two primary tuning parameters to optimize the uplink performance; (i) the\nconstellation altitude and (ii) the satellite antenna beamwidth. The framework\nleverages tools from stochastic geometry to derive analytical models that\nformulate a parametric uplink coverage problem which also includes user traffic\ndemand as an input. This allows operators to devise uplink expansion strategies\nto cater for expanding user demand. The framework demonstrates that fine-tuning\nof these parameters can significantly enhance the network capacity. We show\nthat the optimization of random constellations provides a close match to that\nof practical satellite constellations such as Walker-delta and Walker-star.",
    "descriptor": "",
    "authors": [
      "Bassel Al Homssi",
      "Akram Al-Hourani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.06649"
  },
  {
    "id": "arXiv:2110.06650",
    "title": "Multistage linguistic conditioning of convolutional layers for speech  emotion recognition",
    "abstract": "In this contribution, we investigate the effectiveness of deep fusion of text\nand audio features for categorical and dimensional speech emotion recognition\n(SER). We propose a novel, multistage fusion method where the two information\nstreams are integrated in several layers of a deep neural network (DNN), and\ncontrast it with a single-stage one where the streams are merged in a single\npoint. Both methods depend on extracting summary linguistic embeddings from a\npre-trained BERT model, and conditioning one or more intermediate\nrepresentations of a convolutional model operating on log-Mel spectrograms.\nExperiments on the widely used IEMOCAP and MSP-Podcast databases demonstrate\nthat the two fusion methods clearly outperform a shallow (late) fusion baseline\nand their unimodal constituents, both in terms of quantitative performance and\nqualitative behaviour. Our accompanying analysis further reveals a hitherto\nunexplored role of the underlying dialogue acts on unimodal and bimodal SER,\nwith different models showing a biased behaviour across different acts.\nOverall, our multistage fusion shows better quantitative performance,\nsurpassing all alternatives on most of our evaluations. This illustrates the\npotential of multistage fusion in better assimilating text and audio\ninformation.",
    "descriptor": "",
    "authors": [
      "Andreas Triantafyllopoulos",
      "Uwe Reichel",
      "Shuo Liu",
      "Stephan Huber",
      "Florian Eyben",
      "Bj\u00f6rn W. Schuller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06650"
  },
  {
    "id": "arXiv:2110.06651",
    "title": "MDERank: A Masked Document Embedding Rank Approach for Unsupervised  Keyphrase Extraction",
    "abstract": "Keyphrases are phrases in a document providing a concise summary of core\ncontent, helping readers to understand what the article is talking about in a\nminute. However, existing unsupervised works are not robust enough to handle\nvarious types of documents owing to the mismatch of sequence length for\ncomparison. In this paper, we propose a novel unsupervised keyword extraction\nmethod by leveraging the BERT-based model to select and rank candidate\nkeyphrases with a MASK strategy. In addition, we further enhance the model,\ndenoted as Keyphrases Extraction BERT (KPEBERT), via designing a compatible\nself-supervised task and conducting a contrast learning. We conducted extensive\nexperimental evaluation to demonstrate the superiority and robustness of the\nproposed method as well as the effectiveness of KPEBERT.",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "Linhan Zhang",
      "Qian Chen",
      "Wen Wang",
      "Chong Deng",
      "Shiliang Zhang",
      "Bing Li",
      "Wei Wang",
      "Xin Cao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06651"
  },
  {
    "id": "arXiv:2110.06654",
    "title": "State of Security and Privacy Practices of Top Websites in the East  African Community (EAC)",
    "abstract": "Growth in technology has resulted in the large-scale collection and\nprocessing of Personally Identifiable Information by organizations that run\ndigital services such as websites, which led to the emergence of new\nlegislation to regulate PII collection and processing by organizations.\nSubsequently, several African countries have recently started enacting new data\nprotection regulations due to recent technological innovations. However, there\nis little information about the security and privacy practices of top websites\nserving content to EAC citizens. We, therefore, analyze the website operators'\npatterns in terms of third-party tracking, security of data transmission,\ncookie information, and privacy policies for 169 top EAC website operators\nusing WebXray, OpenSSL, and Alexa top websites API. Our results show that only\n75 percent of the analyzed websites have a privacy policy in place. Out of\nthis, only 16 percent of the third-party tracking companies that track users on\na particular website are disclosed in the site's privacy policy statements\nwhich means that users don not have a way of knowing which third parties\ncollect data about them when they visit a website. Such privacy policies take\ntime to read and are difficult to understand; on average, it takes a college\ngraduate to comprehend the policy and a user spends 12 minutes to read the\npolicy. Additionally, most third-party tracking on EAC websites is related to\nadvertisement and belongs to companies outside the EAC. This means that EAC\nlawmakers need to enact suitable laws to ensure that people's privacy is\nprotected as the rate of technology adoption continues to increase.",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Abdirahman Mohamed",
      "Christopher Dare",
      "Ayobami Esther Olanrewaju",
      "Mercyleen Tanui",
      "Fonyuy Boris Lami"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.06654"
  },
  {
    "id": "arXiv:2110.06656",
    "title": "Parameterized Complexity of Minimum Membership Dominating Set",
    "abstract": "Given a graph $G=(V,E)$ and an integer $k$, the Minimum Membership Dominating\nSet (MMDS) problem seeks to find a dominating set $S \\subseteq V$ of $G$ such\nthat for each $v \\in V$, $|N[v] \\cap S|$ is at most $k$. We investigate the\nparameterized complexity of the problem and obtain the following results about\nMMDS:\nW[1]-hardness of the problem parameterized by the pathwidth (and thus,\ntreewidth) of the input graph.\nW[1]-hardness parameterized by $k$ on split graphs.\nAn algorithm running in time $2^{\\mathcal{O}(\\textbf{vc})}\n|V|^{\\mathcal{O}(1)}$, where $\\textbf{vc}$ is the size of a minimum-sized\nvertex cover of the input graph.\nAn ETH-based lower bound showing that the algorithm mentioned in the previous\nitem is optimal.",
    "descriptor": "",
    "authors": [
      "Akanksha Agrawal",
      "Pratibha Choudhary",
      "N. S. Narayanaswamy",
      "K. K. Nisha",
      "Vijayaragunathan Ramamoorthi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.06656"
  },
  {
    "id": "arXiv:2110.06657",
    "title": "SmashEx: Smashing SGX Enclaves Using Exceptions",
    "abstract": "Exceptions are a commodity hardware functionality which is central to\nmulti-tasking OSes as well as event-driven user applications. Normally, the OS\nassists the user application by lifting the semantics of exceptions received\nfrom hardware to program-friendly user signals and exception handling\ninterfaces. However, can exception handlers work securely in user enclaves,\nsuch as those enabled by Intel SGX, where the OS is not trusted by the enclave\ncode?\nIn this paper, we introduce a new attack called SmashEx which exploits the\nOS-enclave interface for asynchronous exceptions in SGX. It demonstrates the\nimportance of a fundamental property of safe atomic execution that is required\non this interface. In the absence of atomicity, we show that asynchronous\nexception handling in SGX enclaves is complicated and prone to re-entrancy\nvulnerabilities. Our attacks do not assume any memory errors in the enclave\ncode, side channels, or application-specific logic flaws. We concretely\ndemonstrate exploits that cause arbitrary disclosure of enclave private memory\nand code-reuse (ROP) attacks in the enclave. We show reliable exploits on two\nwidely-used SGX runtimes, Intel SGX SDK and Microsoft Open Enclave, running\nOpenSSL and cURL libraries respectively. We tested a total of 14 frameworks,\nincluding Intel SGX SDK and Microsoft Open Enclave, 10 of which are vulnerable.\nWe discuss how the vulnerability manifests on both SGX1-based and SGX2-based\nplatforms. We present potential mitigation and long-term defenses for SmashEx.",
    "descriptor": "\nComments: Accepted to ACM CCS 2021\n",
    "authors": [
      "Jinhua Cui",
      "Jason Zhijingcheng Yu",
      "Shweta Shinde",
      "Prateek Saxena",
      "Zhiping Cai"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.06657"
  },
  {
    "id": "arXiv:2110.06661",
    "title": "A Primer on Near-Field Beamforming for Arrays and Reconfigurable  Intelligent Surfaces",
    "abstract": "Wireless communication systems have almost exclusively operated in the\nfar-field of antennas and antenna arrays, which is conventionally characterized\nby having propagation distances beyond the Fraunhofer distance. This is natural\nsince the Fraunhofer distance is normally only a few wavelengths. With the\nadvent of active arrays and passive reconfigurable intelligent surfaces (RIS)\nthat are physically large, it is plausible that the transmitter or receiver is\nlocated in between the Fraunhofer distance of the individual array/surface\nelements and the Fraunhofer distance of the entire array. An RIS then can be\nconfigured to reflect the incident waveform towards a point in the radiative\nnear-field of the surface, resulting in a beam with finite depth, or as a\nconventional angular beam with infinity focus, which only results in\namplification in the far-field. To understand when these different options are\nviable, an accurate characterization of the near-field behaviors is necessary.\nIn this paper, we revisit the motivation and approximations behind the\nFraunhofer distance and show that it is not the right metric for determining\nwhen near-field focusing is possible. We obtain the distance range where\nfinite-depth beamforming is possible and the distance where the beamforming\ngain tapers off.",
    "descriptor": "\nComments: 8 pages, 9 figures, To appear on the Asilomar Conference on Signals, Systems, and Computers, 2021\n",
    "authors": [
      "Emil Bj\u00f6rnson",
      "\u00d6zlem Tugfe Demir",
      "Luca Sanguinetti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.06661"
  },
  {
    "id": "arXiv:2110.06663",
    "title": "Tutorial on Deep Learning for Human Activity Recognition",
    "abstract": "Activity recognition systems that are capable of estimating human activities\nfrom wearable inertial sensors have come a long way in the past decades. Not\nonly have state-of-the-art methods moved away from feature engineering and have\nfully adopted end-to-end deep learning approaches, best practices for setting\nup experiments, preparing datasets, and validating activity recognition\napproaches have similarly evolved. This tutorial was first held at the 2021 ACM\nInternational Symposium on Wearable Computers (ISWC'21) and International Joint\nConference on Pervasive and Ubiquitous Computing (UbiComp'21). The tutorial,\nafter a short introduction in the research field of activity recognition,\nprovides a hands-on and interactive walk-through of the most important steps in\nthe data pipeline for the deep learning of human activities. All presentation\nslides shown during the tutorial, which also contain links to all code\nexercises, as well as the link of the GitHub page of the tutorial can be found\non: https://mariusbock.github.io/dl-for-har",
    "descriptor": "\nComments: 6 pages, 2 figures, held at the 2021 ACM International Symposium on Wearable Computers (ISWC'21) and International Joint Conference on Pervasive and Ubiquitous Computing (UbiComp'21), Sept, 2021\n",
    "authors": [
      "Marius Bock",
      "Alexander Hoelzemann",
      "Michael Moeller",
      "Kristof Van Laerhoven"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06663"
  },
  {
    "id": "arXiv:2110.06671",
    "title": "Cardiac Electrophysiology Meshfree Modeling through the Mixed  Collocation Method",
    "abstract": "We present the meshfree Mixed Collocation Method (MCM) to solve the\nmonodomain model for numerical simulation of cardiac electrophysiology. We\napply MCM to simulate cardiac electrical propagation in 2D tissue sheets and 3D\ntissue slabs as well as in realistic large-scale biventricular anatomies.\nCapitalizing on the meshfree property of MCM, we introduce an immersed grid\napproach for automated generation of nodes in the modeled cardiac domains. We\ndemonstrate that MCM solutions are in agreement with FEM solutions, thus\nconfirming their suitability for simulation of cardiac electrophysiology both\nin healthy and disease conditions, such as left-bundle-branch block (LBBB) and\nmyocardial infarction. Despite the fact that the computational time for MCM\ncalculations is longer than for FEM, its efficiency in dealing with domains\npresenting irregularity, nonlinearity and discontinuity make MCM a promising\nalternative for heart's electrical investigations.",
    "descriptor": "\nComments: 13 pages, 6 figures, Under review version\n",
    "authors": [
      "Konstantinos A. Mountris",
      "Esther Pueyo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.06671"
  },
  {
    "id": "arXiv:2110.06672",
    "title": "The deep generative decoder: Using MAP estimates of representations",
    "abstract": "A deep generative model is characterized by a representation space, its\ndistribution, and a neural network mapping the representation to a distribution\nover vectors in feature space. Common methods such as variational autoencoders\n(VAEs) apply variational inference for training the neural network, but\noptimizing these models is often non-trivial. The encoder adds to the\ncomplexity of the model and introduces an amortization gap and the quality of\nthe variational approximation is usually unknown. Additionally, the balance of\nthe loss terms of the objective function heavily influences performance.\nTherefore, we argue that it is worthwhile to investigate a much simpler\napproximation which finds representations and their distribution by maximizing\nthe model likelihood via back-propagation. In this approach, there is no\nencoder, and we therefore call it a Deep Generative Decoder (DGD). Using the\nCIFAR10 data set, we show that the DGD is easier and faster to optimize than\nthe VAE, achieves more consistent low reconstruction errors of test data, and\nalleviates the problem of balancing the reconstruction and distribution loss\nterms. Although the model in its simple form cannot compete with\nstate-of-the-art image generation approaches, it obtains better image\ngeneration scores than the variational approach on the CIFAR10 data. We\ndemonstrate on MNIST data how the use of a Gaussian mixture with priors can\nlead to a clear separation of classes in a 2D representation space, and how the\nDGD can be used with labels to obtain a supervised representation.",
    "descriptor": "",
    "authors": [
      "Viktoria Schuster",
      "Anders Krogh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06672"
  },
  {
    "id": "arXiv:2110.06674",
    "title": "Truthful AI: Developing and governing AI that does not lie",
    "abstract": "In many contexts, lying -- the use of verbal falsehoods to deceive -- is\nharmful. While lying has traditionally been a human affair, AI systems that\nmake sophisticated verbal statements are becoming increasingly prevalent. This\nraises the question of how we should limit the harm caused by AI \"lies\" (i.e.\nfalsehoods that are actively selected for). Human truthfulness is governed by\nsocial norms and by laws (against defamation, perjury, and fraud). Differences\nbetween AI and humans present an opportunity to have more precise standards of\ntruthfulness for AI, and to have these standards rise over time. This could\nprovide significant benefits to public epistemics and the economy, and mitigate\nrisks of worst-case AI futures.\nEstablishing norms or laws of AI truthfulness will require significant work\nto: (1) identify clear truthfulness standards; (2) create institutions that can\njudge adherence to those standards; and (3) develop AI systems that are\nrobustly truthful.\nOur initial proposals for these areas include: (1) a standard of avoiding\n\"negligent falsehoods\" (a generalisation of lies that is easier to assess); (2)\ninstitutions to evaluate AI systems before and after real-world deployment; and\n(3) explicitly training AI systems to be truthful via curated datasets and\nhuman interaction.\nA concerning possibility is that evaluation mechanisms for eventual\ntruthfulness standards could be captured by political interests, leading to\nharmful censorship and propaganda. Avoiding this might take careful attention.\nAnd since the scale of AI speech acts might grow dramatically over the coming\ndecades, early truthfulness standards might be particularly important because\nof the precedents they set.",
    "descriptor": "",
    "authors": [
      "Owain Evans",
      "Owen Cotton-Barratt",
      "Lukas Finnveden",
      "Adam Bales",
      "Avital Balwit",
      "Peter Wills",
      "Luca Righetti",
      "William Saunders"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06674"
  },
  {
    "id": "arXiv:2110.06679",
    "title": "EditVAE: Unsupervised Part-Aware Controllable 3D Point Cloud Shape  Generation",
    "abstract": "This paper tackles the problem of parts-aware point cloud generation. Unlike\nexisting works which require the point cloud to be segmented into parts a\npriori, our parts-aware editing and generation is performed in an unsupervised\nmanner. We achieve this with a simple modification of the Variational\nAuto-Encoder which yields a joint model of the point cloud itself along with a\nschematic representation of it as a combination of shape primitives. In\nparticular, we introduce a latent representation of the point cloud which can\nbe decomposed into a disentangled representation for each part of the shape.\nThese parts are in turn disentangled into both a shape primitive and a point\ncloud representation, along with a standardising transformation to a canonical\ncoordinate system. The dependencies between our standardising transformations\npreserve the spatial dependencies between the parts in a manner which allows\nmeaningful parts-aware point cloud generation and shape editing. In addition to\nthe flexibility afforded by our disentangled representation, the inductive bias\nintroduced by our joint modelling approach yields the state-of-the-art\nexperimental results on the ShapeNet dataset.",
    "descriptor": "",
    "authors": [
      "Shidi Li",
      "Miaomiao Liu",
      "Christian Walder"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06679"
  },
  {
    "id": "arXiv:2110.06682",
    "title": "Color Counting for Fashion, Art, and Design",
    "abstract": "Color modelling and extraction is an important topic in fashion, art, and\ndesign. Recommender systems, color-based retrieval, decorating, and fashion\ndesign can benefit from color extraction tools. Research has shown that\nmodeling color so that it can be automatically analyzed and / or extracted is a\ndifficult task. Unlike machines, color perception, although very subjective, is\nmuch simpler for humans. That being said, the first step in color modeling is\nto estimate the number of colors in the item / object. This is because color\nmodels can take advantage of the number of colors as the seed for better\nmodelling, e.g., to make color extraction further deterministic. We aim in this\nwork to develop and test models that can count the number of colors of clothing\nand other items. We propose a novel color counting method based on cumulative\ncolor histogram, which stands out among other methods. We compare the method we\npropose with other methods that utilize exhaustive color search that uses\nGaussian Mixture Models (GMMs) and K-Means as bases for scoring the optimal\nnumber of colors, in addition to another method that relies on deep learning\nmodels. Unfortunately, the GMM, K-Means, and Deep Learning models all fail to\naccurately capture the number of colors. Our proposed method can provide the\ncolor baseline that can be used in AI-based fashion applications, and can also\nfind applications in other areas, for example, interior design. To the best of\nour knowledge, this work is the first of its kind that addresses the problem of\ncolor-counting machine.",
    "descriptor": "",
    "authors": [
      "Mohammed Al-Rawi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06682"
  },
  {
    "id": "arXiv:2110.06685",
    "title": "Plugging Self-Supervised Monocular Depth into Unsupervised Domain  Adaptation for Semantic Segmentation",
    "abstract": "Although recent semantic segmentation methods have made remarkable progress,\nthey still rely on large amounts of annotated training data, which are often\ninfeasible to collect in the autonomous driving scenario. Previous works\nusually tackle this issue with Unsupervised Domain Adaptation (UDA), which\nentails training a network on synthetic images and applying the model to real\nones while minimizing the discrepancy between the two domains. Yet, these\ntechniques do not consider additional information that may be obtained from\nother tasks. Differently, we propose to exploit self-supervised monocular depth\nestimation to improve UDA for semantic segmentation. On one hand, we deploy\ndepth to realize a plug-in component which can inject complementary geometric\ncues into any existing UDA method. We further rely on depth to generate a large\nand varied set of samples to Self-Train the final model. Our whole proposal\nallows for achieving state-of-the-art performance (58.8 mIoU) in the GTA5->CS\nbenchmark benchmark. Code is available at\nhttps://github.com/CVLAB-Unibo/d4-dbst.",
    "descriptor": "\nComments: Accepted at WACV 2022\n",
    "authors": [
      "Adriano Cardace",
      "Luca De Luigi",
      "Pierluigi Zama Ramirez",
      "Samuele Salti",
      "Luigi Di Stefano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06685"
  },
  {
    "id": "arXiv:2110.06688",
    "title": "DeepVecFont: Synthesizing High-quality Vector Fonts via Dual-modality  Learning",
    "abstract": "Automatic font generation based on deep learning has aroused a lot of\ninterest in the last decade. However, only a few recently-reported approaches\nare capable of directly generating vector glyphs and their results are still\nfar from satisfactory. In this paper, we propose a novel method, DeepVecFont,\nto effectively resolve this problem. Using our method, for the first time,\nvisually-pleasing vector glyphs whose quality and compactness are both\ncomparable to human-designed ones can be automatically generated. The key idea\nof our DeepVecFont is to adopt the techniques of image synthesis, sequence\nmodeling and differentiable rasterization to exhaustively exploit the\ndual-modality information (i.e., raster images and vector outlines) of vector\nfonts. The highlights of this paper are threefold. First, we design a\ndual-modality learning strategy which utilizes both image-aspect and\nsequence-aspect features of fonts to synthesize vector glyphs. Second, we\nprovide a new generative paradigm to handle unstructured data (e.g., vector\nglyphs) by randomly sampling plausible synthesis results to get the optimal one\nwhich is further refined under the guidance of generated structured data (e.g.,\nglyph images). Finally, qualitative and quantitative experiments conducted on a\npublicly-available dataset demonstrate that our method obtains high-quality\nsynthesis results in the applications of vector font generation and\ninterpolation, significantly outperforming the state of the art.",
    "descriptor": "\nComments: SIGGRAPH Asia 2021 Technical Paper. Code: this https URL ; Homepage: this https URL\n",
    "authors": [
      "Yizhi Wang",
      "Zhouhui Lian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.06688"
  },
  {
    "id": "arXiv:2110.06694",
    "title": "Joint Optimization of Beam-Hopping Design and NOMA-Assisted Transmission  for Flexible Satellite Systems",
    "abstract": "Next-generation satellite systems require more flexibility in resource\nmanagement such that available radio resources can be dynamically allocated to\nmeet time-varying and non-uniform traffic demands. Considering potential\nbenefits of beam hopping (BH) and non-orthogonal multiple access (NOMA), we\nexploit the time-domain flexibility in multi-beam satellite systems by\noptimizing BH design, and enhance the power-domain flexibility via NOMA. In\nthis paper, we investigate the synergy and mutual influence of beam hopping and\nNOMA. We jointly optimize power allocation, beam scheduling, and\nterminal-timeslot assignment to minimize the gap between requested traffic\ndemand and offered capacity. In the solution development, we formally prove the\nNP-hardness of the optimization problem. Next, we develop a bounding scheme to\ntightly gauge the global optimum and propose a suboptimal algorithm to enable\nefficient resource assignment. Numerical results demonstrate the benefits of\ncombining NOMA and BH, and validate the superiority of the proposed BH-NOMA\nschemes over benchmarks.",
    "descriptor": "",
    "authors": [
      "Anyue Wang",
      "Lei Lei",
      "Eva Lagunas",
      "Ana I. Perez-Neira",
      "Symeon Chatzinotas",
      "Bjorn Ottersten"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.06694"
  },
  {
    "id": "arXiv:2110.06696",
    "title": "Mengzi: Towards Lightweight yet Ingenious Pre-trained Models for Chinese",
    "abstract": "Although pre-trained models (PLMs) have achieved remarkable improvements in a\nwide range of NLP tasks, they are expensive in terms of time and resources.\nThis calls for the study of training more efficient models with less\ncomputation but still ensures impressive performance. Instead of pursuing a\nlarger scale, we are committed to developing lightweight yet more powerful\nmodels trained with equal or less computation and friendly to rapid deployment.\nThis technical report releases our pre-trained model called Mengzi, which\nstands for a family of discriminative, generative, domain-specific, and\nmultimodal pre-trained model variants, capable of a wide range of language and\nvision tasks. Compared with public Chinese PLMs, Mengzi is simple but more\npowerful. Our lightweight model has achieved new state-of-the-art results on\nthe widely-used CLUE benchmark with our optimized pre-training and fine-tuning\ntechniques. Without modifying the model architecture, our model can be easily\nemployed as an alternative to existing PLMs. Our sources are available at\nhttps://github.com/Langboat/Mengzi.",
    "descriptor": "",
    "authors": [
      "Zhuosheng Zhang",
      "Hanqing Zhang",
      "Keming Chen",
      "Yuhang Guo",
      "Jingyun Hua",
      "Yulong Wang",
      "Ming Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06696"
  },
  {
    "id": "arXiv:2110.06697",
    "title": "Semantic Image Fusion",
    "abstract": "Image fusion methods and metrics for their evaluation have conventionally\nused pixel-based or low-level features. However, for many applications, the aim\nof image fusion is to effectively combine the semantic content of the input\nimages. This paper proposes a novel system for the semantic combination of\nvisual content using pre-trained CNN network architectures. Our proposed\nsemantic fusion is initiated through the fusion of the top layer feature map\noutputs (for each input image)through gradient updating of the fused image\ninput (so-called image optimisation). Simple \"choose maximum\" and \"local\nmajority\" filter based fusion rules are utilised for feature map fusion. This\nprovides a simple method to combine layer outputs and thus a unique framework\nto fuse single-channel and colour images within a decomposition pre-trained for\nclassification and therefore aligned with semantic fusion. Furthermore, class\nactivation mappings of each input image are used to combine semantic\ninformation at a higher level. The developed methods are able to give\nequivalent low-level fusion performance to state of the art methods while\nproviding a unique architecture to combine semantic information from multiple\nimages.",
    "descriptor": "\nComments: 10 pages, 3 figures and 2 tables. To be submitted to IEEE Transactions on Image Processing\n",
    "authors": [
      "P.R. Hill",
      "D.R. Bull"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06697"
  },
  {
    "id": "arXiv:2110.06703",
    "title": "Expert-driven Trace Clustering with Instance-level Constraints",
    "abstract": "Within the field of process mining, several different trace clustering\napproaches exist for partitioning traces or process instances into similar\ngroups. Typically, this partitioning is based on certain patterns or similarity\nbetween the traces, or driven by the discovery of a process model for each\ncluster. The main drawback of these techniques, however, is that their\nsolutions are usually hard to evaluate or justify by domain experts. In this\npaper, we present two constrained trace clustering techniques that are capable\nto leverage expert knowledge in the form of instance-level constraints. In an\nextensive experimental evaluation using two real-life datasets, we show that\nour novel techniques are indeed capable of producing clustering solutions that\nare more justifiable without a substantial negative impact on their quality.",
    "descriptor": "",
    "authors": [
      "Pieter De Koninck",
      "Klaas Nelissen",
      "Seppe vanden Broucke",
      "Bart Baesens",
      "Monique Snoeck",
      "Jochen De Weerdt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06703"
  },
  {
    "id": "arXiv:2110.06707",
    "title": "Singer separation for karaoke content generation",
    "abstract": "Due to the rapid development of deep learning, we can now successfully\nseparate singing voice from mono audio music. However, this separation can only\nextract human voices from other musical instruments, which is undesirable for\nkaraoke content generation applications that only require the separation of\nlead singers. For this karaoke application, we need to separate the music\ncontaining male and female duets into two vocals, or extract a single lead\nvocal from the music containing vocal harmony. For this reason, we propose in\nthis article to use a singer separation system, which generates karaoke content\nfor one or two separated lead singers. In particular, we introduced three\nmodels for the singer separation task and designed an automatic model selection\nscheme to distinguish how many lead singers are in the song. We also collected\na large enough data set, MIR-SingerSeparation, which has been publicly released\nto advance the frontier of this research. Our singer separation is most\nsuitable for sentimental ballads and can be directly applied to karaoke content\ngeneration. As far as we know, this is the first singer-separation work for\nreal-world karaoke applications.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Hsuan-Yu Chen",
      "Xuanjun Chen",
      "Jyh-Shing Roger Jang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.06707"
  },
  {
    "id": "arXiv:2110.06717",
    "title": "On the Parameter Combinations That Matter and on Those That do Not",
    "abstract": "We present a data-driven approach to characterizing nonidentifiability of a\nmodel's parameters and illustrate it through dynamic kinetic models. By\nemploying Diffusion Maps and their extensions, we discover the minimal\ncombinations of parameters required to characterize the dynamic output\nbehavior: a set of effective parameters for the model. Furthermore, we use\nConformal Autoencoder Neural Networks, as well as a kernel-based Jointly Smooth\nFunction technique, to disentangle the redundant parameter combinations that do\nnot affect the output behavior from the ones that do. We discuss the\ninterpretability of our data-driven effective parameters and demonstrate the\nutility of the approach both for behavior prediction and parameter estimation.\nIn the latter task, it becomes important to describe level sets in parameter\nspace that are consistent with a particular output behavior. We validate our\napproach on a model of multisite phosphorylation, where a reduced set of\neffective parameters, nonlinear combinations of the physical ones, has\npreviously been established analytically.",
    "descriptor": "\nComments: 37 pages, 16 figures, 3 tables\n",
    "authors": [
      "Nikolaos Evangelou",
      "Noah J. Wichrowski",
      "George A. Kevrekidis",
      "Felix Dietrich",
      "Mahdi Kooshkbaghi",
      "Sarah McFann",
      "Ioannis G. Kevrekidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.06717"
  },
  {
    "id": "arXiv:2110.06723",
    "title": "The Computerized Classification of Micro-Motions in the Hand using  Waveforms from Mobile Phone",
    "abstract": "Our hands reveal important information such as the pulsing of our veins which\nhelp us determine the blood pressure, tremors indicative of motor control, or\nneurodegenerative disorders such as Essential Tremor or Parkinson's disease.\nThe Computerized Classification of Micro-Motions in the hand using waveforms\nfrom mobile phone videos is a novel method that uses Eulerian Video\nMagnification, Skeletonization, Heatmapping, and the kNN machine learning model\nto detect the micro-motions in the human hand, synthesize their waveforms, and\nclassify these. The pre-processing is achieved by using Eulerian Video\nMagnification, Skeletonization, and Heat-mapping to magnify the micro-motions,\nlandmark essential features of the hand, and determine the extent of motion,\nrespectively. Following pre-processing, the visible motions are manually\nlabeled by appropriately grouping pixels to represent a particular label\ncorrectly. These labeled motions of the pixels are converted into waveforms.\nFinally, these waveforms are classified into four categories - hand or finger\nmovements, vein movement, background motion, and movement of the rest of the\nbody due to respiration using the kNN model. The final accuracy obtained was\naround 92 percent.",
    "descriptor": "\nComments: 10 pages, 25 figures\n",
    "authors": [
      "Ranjani Ramesh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06723"
  },
  {
    "id": "arXiv:2110.06724",
    "title": "On Networks Over Finite Rings",
    "abstract": "A (control) network over a finite ring is proposed. Using semi-tensor product\n(STP) of matrices, a set of algebraic equations are provided to verify whether\na finite set with two binary operators is a ring. It is then shown that the\nSTP-based technique developed for logical (control) networks are applicable to\n(control) networks over finite rings. The sub-(control) network over an ideal\nof the bearing ring is revealed. Then the product ring is proposed and the\n(control) network over product ring is investigated. As a key result, the\ndecomposition theorem, called the Decomposition Principle (DP), is proposed,\nwhich shows a (control) network over a product ring is decomposable into\nsub-(control)networks over each factor rings, which makes the (control)\nproperties of a network can be revealed by its factor sub-networks over factor\nrings. Using DP, the control problems of a control network are investigated via\nits sub control networks. Particularly, using DP, the control of linear\nnetworks over product rings is discussed in detail. Finally, the representation\ntheorem is presented, which shows that each (control) network over a finite set\ncan be expressed as a (control) network over a product ring.",
    "descriptor": "",
    "authors": [
      "Daizhan Cheng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.06724"
  },
  {
    "id": "arXiv:2110.06725",
    "title": "Diversity of Skills and Collective Intelligence in GitHub",
    "abstract": "A common assumption suggests that individuals tend to work with others who\nare similar to them. However, studies on team working and ability of the group\nto solve complex problems highlight that diversity plays a critical role during\ncollaboration, allowing for the diffusion of information. In this paper, we\ninvestigate the patterns behind the connections among GitHub users in Open\nSource communities. To this end, we use Social Network Analysis and\nSelf-Organizing Maps as the similarity measure. Analysis of textual artifacts\nreveals the roles of those connections. We find that diversity of skills plays\nan essential role in the creation of links among users who exchange information\n(e.g., in issues, comments, and following networks). The connections in\nnetworks related to actual coding are established among users with similar\ncharacteristics. Users who differ from the owner of the repository report bugs,\nproblems and ask for help more often than the similar ones.",
    "descriptor": "",
    "authors": [
      "Dorota Celi\u0144ska-Kopczy\u0144ska"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.06725"
  },
  {
    "id": "arXiv:2110.06726",
    "title": "Scalable Anytime Algorithms for Learning Formulas in Linear Temporal  Logic",
    "abstract": "Linear temporal logic (LTL) is a specification language for finite sequences\n(called traces) widely used in program verification, motion planning in\nrobotics, process mining, and many other areas. We consider the problem of\nlearning LTL formulas for classifying traces; despite a growing interest of the\nresearch community, existing solutions suffer from two limitations: they do not\nscale beyond small formulas, and they may exhaust computational resources\nwithout returning any result. We introduce a new algorithm addressing both\nissues: our algorithm is able to construct formulas an order of magnitude\nlarger than previous methods, and it is anytime, meaning that it in most cases\nsuccessfully outputs a formula, albeit possibly not of minimal size. We\nevaluate the performances of our algorithm using an open source implementation\nagainst publicly available benchmarks.",
    "descriptor": "",
    "authors": [
      "Ritam Raha",
      "Rajarshi Roy",
      "Nathana\u00ebl Fijalkow",
      "Daniel Neider"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06726"
  },
  {
    "id": "arXiv:2110.06730",
    "title": "RelationRS: Relationship Representation Network for Object Detection in  Aerial Images",
    "abstract": "Object detection is a basic and important task in the field of aerial image\nprocessing and has gained much attention in computer vision. However, previous\naerial image object detection approaches have insufficient use of scene\nsemantic information between different regions of large-scale aerial images. In\naddition, complex background and scale changes make it difficult to improve\ndetection accuracy. To address these issues, we propose a relationship\nrepresentation network for object detection in aerial images (RelationRS): 1)\nFirstly, multi-scale features are fused and enhanced by a dual relationship\nmodule (DRM) with conditional convolution. The dual relationship module learns\nthe potential relationship between features of different scales and learns the\nrelationship between different scenes from different patches in a same\niteration. In addition, the dual relationship module dynamically generates\nparameters to guide the fusion of multi-scale features. 2) Secondly, The\nbridging visual representations module (BVR) is introduced into the field of\naerial images to improve the object detection effect in images with complex\nbackgrounds. Experiments with a publicly available object detection dataset for\naerial images demonstrate that the proposed RelationRS achieves a\nstate-of-the-art detection performance.",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Zhiming Liu",
      "Xuefei Zhang",
      "Chongyang Liu",
      "Hao Wang",
      "Chao Sun",
      "Bin Li",
      "Weifeng Sun",
      "Pu Huang",
      "Qingjun Li",
      "Yu Liu",
      "Haipeng Kuang",
      "Jihong Xiu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06730"
  },
  {
    "id": "arXiv:2110.06733",
    "title": "Systematic Inequalities in Language Technology Performance across the  World's Languages",
    "abstract": "Natural language processing (NLP) systems have become a central technology in\ncommunication, education, medicine, artificial intelligence, and many other\ndomains of research and development. While the performance of NLP methods has\ngrown enormously over the last decade, this progress has been restricted to a\nminuscule subset of the world's 6,500 languages. We introduce a framework for\nestimating the global utility of language technologies as revealed in a\ncomprehensive snapshot of recent publications in NLP. Our analyses involve the\nfield at large, but also more in-depth studies on both user-facing technologies\n(machine translation, language understanding, question answering,\ntext-to-speech synthesis) as well as more linguistic NLP tasks (dependency\nparsing, morphological inflection). In the process, we (1) quantify disparities\nin the current state of NLP research, (2) explore some of its associated\nsocietal and academic factors, and (3) produce tailored recommendations for\nevidence-based policy making aimed at promoting more global and equitable\nlanguage technologies.",
    "descriptor": "",
    "authors": [
      "Dami\u00e1n Blasi",
      "Antonios Anastasopoulos",
      "Graham Neubig"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06733"
  },
  {
    "id": "arXiv:2110.06735",
    "title": "A Time Encoding approach to training Spiking Neural Networks",
    "abstract": "While Spiking Neural Networks (SNNs) have been gaining in popularity, it\nseems that the algorithms used to train them are not powerful enough to solve\nthe same tasks as those tackled by classical Artificial Neural Networks (ANNs).\nIn this paper, we provide an extra tool to help us understand and train SNNs by\nusing theory from the field of time encoding. Time encoding machines (TEMs) can\nbe used to model integrate-and-fire neurons and have well-understood\nreconstruction properties. We will see how one can take inspiration from the\nfield of TEMs to interpret the spike times of SNNs as constraints on the SNNs'\nweight matrices. More specifically, we study how to train one-layer SNNs by\nsolving a set of linear constraints, and how to train two-layer SNNs by\nleveraging the all-or-none and asynchronous properties of the spikes emitted by\nSNNs. These properties of spikes result in an alternative to backpropagation\nwhich is not possible in the case of simultaneous and graded activations as in\nclassical ANNs.",
    "descriptor": "\nComments: 5 pages, 5 figures, submitted to IEEE ICASSP 2022\n",
    "authors": [
      "Karen Adam"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.06735"
  },
  {
    "id": "arXiv:2110.06736",
    "title": "Collaborative Semantic Aggregation and Calibration for Separated Domain  Generalization",
    "abstract": "Domain generalization (DG) aims to learn from multiple known source domains a\nmodel that can generalize well to unknown target domains. The existing DG\nmethods usually rely on shared multi-source data fusion for generalizable model\ntraining. However, tremendous data is distributed across lots of places\nnowadays that can not be shared due to privacy policies, especially in some\ncrucial areas like finance and medical care. A dilemma is thus raised between\nreal-world data privacy protection and simultaneous multi-source semantic\nlearning with the shared data. In this paper, we investigate a separated domain\ngeneralization task with separated source datasets that can only be used\nlocally, which is vital for real-world privacy protection. We propose a novel\nsolution called Collaborative Semantic Aggregation and Calibration (CSAC) to\nenable this challenging task. To fully absorb multi-source semantic information\nwhile avoiding unsafe data fusion, we first conduct data-free semantic\naggregation by fusing the models trained on the separated domains\nlayer-by-layer. To address semantic dislocation caused by domain shift, we\nfurther design cross-layer semantic calibration with an attention mechanism to\nalign each semantic level and enhance domain invariance. We unify multi-source\nsemantic learning and alignment in a collaborative way by repeating the\nsemantic aggregation and calibration alternately, keeping each dataset\nlocalized, and privacy is thus carefully protected. Extensive experiments show\nthe significant performance of our method in addressing this challenging task,\nwhich is even comparable to the previous DG methods with shared data.",
    "descriptor": "",
    "authors": [
      "Junkun Yuan",
      "Xu Ma",
      "Defang Chen",
      "Kun Kuang",
      "Fei Wu",
      "Lanfen Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06736"
  },
  {
    "id": "arXiv:2110.06741",
    "title": "Dynamical Wasserstein Barycenters for Time-series Modeling",
    "abstract": "Many time series can be modeled as a sequence of segments representing\nhigh-level discrete states, such as running and walking in a human activity\napplication. Flexible models should describe the system state and observations\nin stationary ``pure-state'' periods as well as transition periods between\nadjacent segments, such as a gradual slowdown between running and walking.\nHowever, most prior work assumes instantaneous transitions between pure\ndiscrete states. We propose a dynamical Wasserstein barycentric (DWB) model\nthat estimates the system state over time as well as the data-generating\ndistributions of pure states in an unsupervised manner. Our model assumes each\npure state generates data from a multivariate normal distribution, and\ncharacterizes transitions between states via displacement-interpolation\nspecified by the Wasserstein barycenter. The system state is represented by a\nbarycentric weight vector which evolves over time via a random walk on the\nsimplex. Parameter learning leverages the natural Riemannian geometry of\nGaussian distributions under the Wasserstein distance, which leads to improved\nconvergence speeds. Experiments on several human activity datasets show that\nour proposed DWB model accurately learns the generating distribution of pure\nstates while improving state estimation for transition periods compared to the\ncommonly used linear interpolation mixture models.",
    "descriptor": "\nComments: To appear at Neurips 2021\n",
    "authors": [
      "Kevin C. Cheng",
      "Shuchin Aeron",
      "Michael C. Hughes",
      "Eric L. Miller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06741"
  },
  {
    "id": "arXiv:2110.06742",
    "title": "A Review of the Deep Sea Treasure problem as a Multi-Objective  Reinforcement Learning Benchmark",
    "abstract": "In this paper, the authors investigate the Deep Sea Treasure (DST) problem as\nproposed by Vamplew et al. Through a number of proofs, the authors show the\noriginal DST problem to be quite basic, and not always representative of\npractical Multi-Objective Optimization problems. In an attempt to bring theory\ncloser to practice, the authors propose an alternative, improved version of the\nDST problem, and prove that some of the properties that simplify the original\nDST problem no longer hold. The authors also provide a reference implementation\nand perform a comparison between their implementation, and other existing\nopen-source implementations of the problem. Finally, the authors also provide a\ncomplete Pareto-front for their new DST problem.",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Thomas Cassimon",
      "Reinout Eyckerman",
      "Siegfried Mercelis",
      "Steven Latr\u00e9",
      "Peter Hellinckx"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06742"
  },
  {
    "id": "arXiv:2110.06744",
    "title": "Masader: Metadata Sourcing for Arabic Text and Speech Data Resources",
    "abstract": "The NLP pipeline has evolved dramatically in the last few years. The first\nstep in the pipeline is to find suitable annotated datasets to evaluate the\ntasks we are trying to solve. Unfortunately, most of the published datasets\nlack metadata annotations that describe their attributes. Not to mention, the\nabsence of a public catalogue that indexes all the publicly available datasets\nrelated to specific regions or languages. When we consider low-resource\ndialectical languages, for example, this issue becomes more prominent. In this\npaper we create \\textit{Masader}, the largest public catalogue for Arabic NLP\ndatasets, which consists of 200 datasets annotated with 25 attributes.\nFurthermore, We develop a metadata annotation strategy that could be extended\nto other languages. We also make remarks and highlight some issues about the\ncurrent status of Arabic NLP datasets and suggest recommendations to address\nthem.",
    "descriptor": "",
    "authors": [
      "Zaid Alyafeai",
      "Maraim Masoud",
      "Mustafa Ghaleb",
      "Maged S. Al-shaibani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06744"
  },
  {
    "id": "arXiv:2110.06750",
    "title": "The perception of Architectural Smells in industrial practice",
    "abstract": "Architectural Technical Debt (ATD) is considered as the most significant type\nof TD in industrial practice. In this study, we interview 21 software engineers\nand architects to investigate a specific type of ATD, namely architectural\nsmells (AS). Our goal is to understand the phenomenon of AS better and support\npractitioners to better manage it and researchers to offer relevant support.\nThe findings of this study provide insights on how practitioners perceive AS\nand how they introduce them, the maintenance and evolution issues they\nexperienced and associated to the presence of AS, and what practices and tools\nthey adopt to manage AS.",
    "descriptor": "\nComments: Submitted and accepted to IEEE Software special issue on Technical Debt. This is a preprint\n",
    "authors": [
      "Darius Sas",
      "Ilaria Pigazzini",
      "Paris Avgeriou",
      "Francesca Arcelli Fontana"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.06750"
  },
  {
    "id": "arXiv:2110.06751",
    "title": "Improving the sample-efficiency of neural architecture search with  reinforcement learning",
    "abstract": "Designing complex architectures has been an essential cogwheel in the\nrevolution deep learning has brought about in the past decade. When solving\ndifficult problems in a datadriven manner, a well-tried approach is to take an\narchitecture discovered by renowned deep learning scientists as a basis (e.g.\nInception) and try to apply it to a specific problem. This might be sufficient,\nbut as of now, achieving very high accuracy on a complex or yet unsolved task\nrequires the knowledge of highly-trained deep learning experts. In this work,\nwe would like to contribute to the area of Automated Machine Learning (AutoML),\nspecifically Neural Architecture Search (NAS), which intends to make deep\nlearning methods available for a wider range of society by designing neural\ntopologies automatically. Although several different approaches exist (e.g.\ngradient-based or evolutionary algorithms), our focus is on one of the most\npromising research directions, reinforcement learning. In this scenario, a\nrecurrent neural network (controller) is trained to create problem-specific\nneural network architectures (child). The validation accuracies of the child\nnetworks serve as a reward signal for training the controller with\nreinforcement learning. The basis of our proposed work is Efficient Neural\nArchitecture Search (ENAS), where parameter sharing is applied among the child\nnetworks. ENAS, like many other RL-based algorithms, emphasize the learning of\nchild networks as increasing their convergence result in a denser reward signal\nfor the controller, therefore significantly reducing training times. The\ncontroller was originally trained with REINFORCE. In our research, we propose\nto modify this to a more modern and complex algorithm, PPO, which has\ndemonstrated to be faster and more stable in other environments. Then, we\nbriefly discuss and evaluate our results.",
    "descriptor": "",
    "authors": [
      "Attila Nagy",
      "\u00c1bel Boros"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06751"
  },
  {
    "id": "arXiv:2110.06753",
    "title": "Learning Meta Pattern for Face Anti-Spoofing",
    "abstract": "Face Anti-Spoofing (FAS) is essential to secure face recognition systems and\nhas been extensively studied in recent years. Although deep neural networks\n(DNNs) for the FAS task have achieved promising results in intra-dataset\nexperiments with similar distributions of training and testing data, the DNNs'\ngeneralization ability is limited under the cross-domain scenarios with\ndifferent distributions of training and testing data. To improve the\ngeneralization ability, recent hybrid methods have been explored to extract\ntask-aware handcrafted features (e.g., Local Binary Pattern) as discriminative\ninformation for the input of DNNs. However, the handcrafted feature extraction\nrelies on experts' domain knowledge, and how to choose appropriate handcrafted\nfeatures is underexplored. To this end, we propose a learnable network to\nextract Meta Pattern (MP) in our learning-to-learn framework. By replacing\nhandcrafted features with the MP, the discriminative information from MP is\ncapable of learning a more generalized model. Moreover, we devise a two-stream\nnetwork to hierarchically fuse the input RGB image and the extracted MP by\nusing our proposed Hierarchical Fusion Module (HFM). We conduct comprehensive\nexperiments and show that our MP outperforms the compared handcrafted features.\nAlso, our proposed method with HFM and the MP can achieve state-of-the-art\nperformance on two different domain generalization evaluation benchmarks.",
    "descriptor": "\nComments: Submitted to IEEE T-IFS. Haoliang Li is the corresponding author\n",
    "authors": [
      "Rizhao Cai",
      "Zhi Li",
      "Renjie Wan",
      "Haoliang Li",
      "Yongjian Hu",
      "Alex Chichung Kot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.06753"
  },
  {
    "id": "arXiv:2110.06754",
    "title": "The springback penalty for robust signal recovery",
    "abstract": "We propose a new penalty, named as the springback penalty, for constructing\nmodels to recover an unknown signal from incomplete and inaccurate\nmeasurements. Mathematically, the springback penalty is a weakly convex\nfunction, and it bears various theoretical and computational advantages of both\nthe benchmark convex $\\ell_1$ penalty and many of its non-convex surrogates\nthat have been well studied in the literature. For the recovery model using the\nspringback penalty, we establish the exact and stable recovery theory for both\nsparse and nearly sparse signals, respectively, and derive an easily\nimplementable difference-of-convex algorithm. In particular, we show its\ntheoretical superiority to some existing models with a sharper recovery bound\nfor some scenarios where the level of measurement noise is large or the amount\nof measurements is limited, and demonstrate its numerical robustness regardless\nof varying coherence of the sensing matrix. Because of its theoretical\nguarantee of recovery with severe measurements, computational tractability, and\nnumerical robustness for ill-conditioned sensing matrices, the springback\npenalty is particularly favorable for the scenario where the incomplete and\ninaccurate measurements are collected by coherence-hidden or -static sensing\nhardware.",
    "descriptor": "\nComments: 24 pages, 6 figures\n",
    "authors": [
      "Congpei An",
      "Hao-Ning Wu",
      "Xiaoming Yuan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.06754"
  },
  {
    "id": "arXiv:2110.06758",
    "title": "HEDP: A Method for Early Forecasting Software Defects based on Human  Error Mechanisms",
    "abstract": "As the primary cause of software defects, human error is the key to\nunderstanding, and perhaps to predicting and avoiding them. Little research has\nbeen done to predict defects on the basis of the cognitive errors that cause\nthem. This paper proposes an approach to predicting software defects through\nknowledge about the cognitive mechanisms of human errors. Our theory is that\nthe main process behind a software defect is that an error-prone scenario\ntriggers human error modes, which psychologists have observed to recur across\ndiverse activities. Software defects can then be predicted by identifying such\nscenarios, guided by this knowledge of typical error modes. The proposed idea\nemphasizes predicting the exact location and form of a possible defect. We\nconducted two case studies to demonstrate and validate this approach, with 55\nprogrammers in a programming competition and 5 analysts serving as the users of\nthe approach. We found it impressive that the approach was able to predict, at\nthe requirement phase, the exact locations and forms of 7 out of the 22 (31.8%)\nspecific types of defects that were found in the code. The defects predicted\ntended to be common defects: their occurrences constituted 75.7% of the total\nnumber of defects in the 55 developed programs; each of them was introduced by\nat least two persons. The fraction of the defects introduced by a programmer\nthat were predicted was on average (over all programmers) 75%. Furthermore,\nthese predicted defects were highly persistent through the debugging process.\nIf the prediction had been used to successfully prevent these defects, this\ncould have saved 46.2% of the debugging iterations. This excellent capability\nof forecasting the exact locations and forms of possible defects at the early\nphases of software development recommends the approach for substantial benefits\nto defect prevention and early detection.",
    "descriptor": "\nComments: 30 pages, 5 figures, and 17 tables\n",
    "authors": [
      "Fuqun Huang",
      "Lorenzo Strigini"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.06758"
  },
  {
    "id": "arXiv:2110.06764",
    "title": "Contact-timing and Trajectory Optimization for 3D Jumping on Quadruped  Robots",
    "abstract": "Performing highly agile acrobatic motions with a long flight phase requires\nperfect timing, high accuracy, and coordination of the whole body motion. To\naddress these challenges, this paper presents a unified timing and trajectory\noptimization framework for legged robots performing aggressive 3D jumping. In\nour approach, we firstly utilize an effective optimization framework using\nsimplified rigid body dynamics to solve for contact timings and a reference\ntrajectory of the robot body. The solution of this module is then used to\nformulate a whole-body trajectory optimization based on the full nonlinear\ndynamics of the robot. This combination allows us to effectively optimize for\ncontact timings while guaranteeing the accuracy of the jumping trajectory that\ncan be realized in the hardware. We validate the efficiency of the proposed\nframework on the A1 robot model for various 3D jumping tasks such as\ndouble-backflips and double barrel roll off the high altitude of 2m and 0.8m\nrespectively. Experimental validation was also successfully conducted for\ndifferent 3D jumping motions such as barrel roll from a box or diagonal jumps.",
    "descriptor": "\nComments: 7 pages, 11 figures\n",
    "authors": [
      "Chuong Nguyen",
      "Quan Nguyen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.06764"
  },
  {
    "id": "arXiv:2110.06766",
    "title": "Next-Best-View Estimation based on Deep Reinforcement Learning for  Active Object Classification",
    "abstract": "The presentation and analysis of image data from a single viewpoint are often\nnot sufficient to solve a task. Several viewpoints are necessary to obtain more\ninformation. The $\\textit{next-best-view}$ problem attempts to find the optimal\nviewpoint with the greatest information gain for the underlying task. In this\nwork, a robot arm holds an object in its end-effector and searches for a\nsequence of next-best-view to explicitly identify the object. We use Soft\nActor-Critic (SAC), a method of deep reinforcement learning, to learn these\nnext-best-views for a specific set of objects. The evaluation shows that an\nagent can learn to determine an object pose to which the robot arm should move\nan object. This leads to a viewpoint that provides a more accurate prediction\nto distinguish such an object from other objects better. We make the code\npublicly available for the scientific community and for reproducibility under\n$\\href{https://github.com/ckorbach/nbv_rl}{\\text{this https link}}$.",
    "descriptor": "\nComments: 9 pages, 11 figures, 4 tables, preprint, $\\href{this https URL}{\\text{Github Repository}}$\n",
    "authors": [
      "Christian Korbach",
      "Markus D. Solbach",
      "Raphael Memmesheimer",
      "Dietrich Paulus",
      "John K. Tsotsos"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06766"
  },
  {
    "id": "arXiv:2110.06773",
    "title": "Leveraging Automated Unit Tests for Unsupervised Code Translation",
    "abstract": "With little to no parallel data available for programming languages,\nunsupervised methods are well-suited to source code translation. However, the\nmajority of unsupervised machine translation approaches rely on\nback-translation, a method developed in the context of natural language\ntranslation and one that inherently involves training on noisy inputs.\nUnfortunately, source code is highly sensitive to small changes; a single token\ncan result in compilation failures or erroneous programs, unlike natural\nlanguages where small inaccuracies may not change the meaning of a sentence. To\naddress this issue, we propose to leverage an automated unit-testing system to\nfilter out invalid translations, thereby creating a fully tested parallel\ncorpus. We found that fine-tuning an unsupervised model with this filtered data\nset significantly reduces the noise in the translations so-generated,\ncomfortably outperforming the state-of-the-art for all language pairs studied.\nIn particular, for Java $\\to$ Python and Python $\\to$ C++ we outperform the\nbest previous methods by more than 16% and 24% respectively, reducing the error\nrate by more than 35%.",
    "descriptor": "",
    "authors": [
      "Baptiste Roziere",
      "Jie M. Zhang",
      "Francois Charton",
      "Mark Harman",
      "Gabriel Synnaeve",
      "Guillaume Lample"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06773"
  },
  {
    "id": "arXiv:2110.06775",
    "title": "Using UAVs for vehicle tracking and collision risk assessment at  intersections",
    "abstract": "Assessing collision risk is a critical challenge to effective traffic safety\nmanagement. The deployment of unmanned aerial vehicles (UAVs) to address this\nissue has shown much promise, given their wide visual field and movement\nflexibility. This research demonstrates the application of UAVs and V2X\nconnectivity to track the movement of road users and assess potential\ncollisions at intersections. The study uses videos captured by UAVs. The\nproposed method combines deep-learning based tracking algorithms and\ntime-to-collision tasks. The results not only provide beneficial information\nfor vehicle's recognition of potential crashes and motion planning but also\nprovided a valuable tool for urban road agencies and safety management\nengineers.",
    "descriptor": "\nComments: Under review for presentation at TRB 2022 Annual Meeting\n",
    "authors": [
      "Shuya Zong",
      "Sikai Chen",
      "Majed Alinizzi",
      "Yujie Li",
      "Samuel Labi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.06775"
  },
  {
    "id": "arXiv:2110.06786",
    "title": "Optical-Flow-Reuse-Based Bidirectional Recurrent Network for Space-Time  Video Super-Resolution",
    "abstract": "In this paper, we consider the task of space-time video super-resolution\n(ST-VSR), which simultaneously increases the spatial resolution and frame rate\nfor a given video. However, existing methods typically suffer from difficulties\nin how to efficiently leverage information from a large range of neighboring\nframes or avoiding the speed degradation in the inference using deformable\nConvLSTM strategies for alignment. % Some recent LSTM-based ST-VSR methods have\nachieved promising results. To solve the above problem of the existing methods,\nwe propose a coarse-to-fine bidirectional recurrent neural network instead of\nusing ConvLSTM to leverage knowledge between adjacent frames. Specifically, we\nfirst use bi-directional optical flow to update the hidden state and then\nemploy a Feature Refinement Module (FRM) to refine the result. Since we could\nfully utilize a large range of neighboring frames, our method leverages local\nand global information more effectively. In addition, we propose an optical\nflow-reuse strategy that can reuse the intermediate flow of adjacent frames,\nwhich considerably reduces the computation burden of frame alignment compared\nwith existing LSTM-based designs. Extensive experiments demonstrate that our\noptical-flow-reuse-based bidirectional recurrent network(OFR-BRN) is superior\nto the state-of-the-art methods both in terms of accuracy and efficiency.",
    "descriptor": "",
    "authors": [
      "Yuantong Zhang",
      "Huairui Wang",
      "Zhenzhong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06786"
  },
  {
    "id": "arXiv:2110.06790",
    "title": "On-line feasible wrench polytope evaluation based on human  musculoskeletal models: an iterative convex hull method",
    "abstract": "Many recent human-robot collaboration strategies, such as Assist-As-Needed\n(AAN), are promoting humancentered robot control, where the robot continuously\nadapts its assistance level based on the real-time need of its human\ncounterpart. One of the fundamental assumptions of these approaches is the\nability to measure or estimate the physical capacity of humans in real-time. In\nthis work, we propose an algorithm for the feasibility set analysis of a\ngeneric class of linear algebra problems. This novel iterative convex-hull\nmethod is applied to the determination of the feasible Cartesian wrench\npolytope associated to a musculoskeletal model of the human upper limb. The\nmethod is capable of running in real-time and allows the user to define the\ndesired estimation accuracy. The algorithm performance analysis shows that the\nexecution time has near-linear relationship to the considered number of\nmuscles, as opposed to the exponential relationship of the conventional\nmethods. Finally, real-time robot control application of the algorithm is\ndemonstrated in a Collaborative carrying experiment, where a human operator and\na Franka Emika Panda robot jointly carry a 7kg object. The robot is controlled\nin accordance to the AAN paradigm maintaining the load carried by the human\noperator at 30% of its carrying capacity.",
    "descriptor": "",
    "authors": [
      "Antun Skuric",
      "Vincent Padois",
      "Nasser Rezzoug",
      "David Daney"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.06790"
  },
  {
    "id": "arXiv:2110.06794",
    "title": "The Layout Generation Algorithm of Graphic Design Based on  Transformer-CVAE",
    "abstract": "Graphic design is ubiquitous in people's daily lives. For graphic design, the\nmost time-consuming task is laying out various components in the interface.\nRepetitive manual layout design will waste a lot of time for professional\ngraphic designers. Existing templates are usually rudimentary and not suitable\nfor most designs, reducing efficiency and limiting creativity. This paper\nimplemented the Transformer model and conditional variational autoencoder\n(CVAE) to the graphic design layout generation task. It proposed an end-to-end\ngraphic design layout generation model named LayoutT-CVAE. We also proposed\nelement disentanglement and feature-based disentanglement strategies and\nintroduce new graphic design principles and similarity metrics into the model,\nwhich significantly increased the controllability and interpretability of the\ndeep model. Compared with the existing state-of-art models, the layout\ngenerated by ours performs better on many metrics.",
    "descriptor": "\nComments: 6 pages, 3 figures CONF SPML accept\n",
    "authors": [
      "Mengxi Guo",
      "Dangqing Huang",
      "Xiaodong Xie"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06794"
  },
  {
    "id": "arXiv:2110.06800",
    "title": "SGD-X: A Benchmark for Robust Generalization in Schema-Guided Dialogue  Systems",
    "abstract": "Zero/few-shot transfer to unseen services is a critical challenge in\ntask-oriented dialogue research. The Schema-Guided Dialogue (SGD) dataset\nintroduced a paradigm for enabling models to support an unlimited number of\nservices without additional data collection or re-training through the use of\nschemas. Schemas describe service APIs in natural language, which models\nconsume to understand the services they need to support. However, the impact of\nthe choice of language in these schemas on model performance remains\nunexplored. We address this by releasing SGD-X, a benchmark for measuring the\nrobustness of dialogue systems to linguistic variations in schemas. SGD-X\nextends the SGD dataset with crowdsourced variants for every schema, where\nvariants are semantically similar yet stylistically diverse. We evaluate two\ndialogue state tracking models on SGD-X and observe that neither generalizes\nwell across schema variations, measured by joint goal accuracy and a novel\nmetric for measuring schema sensitivity. Furthermore, we present a simple\nmodel-agnostic data augmentation method to improve schema robustness and\nzero-shot generalization to unseen services.",
    "descriptor": "",
    "authors": [
      "Harrison Lee",
      "Raghav Gupta",
      "Abhinav Rastogi",
      "Yuan Cao",
      "Bin Zhang",
      "Yonghui Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06800"
  },
  {
    "id": "arXiv:2110.06802",
    "title": "Identification of Attack-Specific Signatures in Adversarial Examples",
    "abstract": "The adversarial attack literature contains a myriad of algorithms for\ncrafting perturbations which yield pathological behavior in neural networks. In\nmany cases, multiple algorithms target the same tasks and even enforce the same\nconstraints. In this work, we show that different attack algorithms produce\nadversarial examples which are distinct not only in their effectiveness but\nalso in how they qualitatively affect their victims. We begin by demonstrating\nthat one can determine the attack algorithm that crafted an adversarial\nexample. Then, we leverage recent advances in parameter-space saliency maps to\nshow, both visually and quantitatively, that adversarial attack algorithms\ndiffer in which parts of the network and image they target. Our findings\nsuggest that prospective adversarial attacks should be compared not only via\ntheir success rates at fooling models but also via deeper downstream effects\nthey have on victims.",
    "descriptor": "",
    "authors": [
      "Hossein Souri",
      "Pirazh Khorramshahi",
      "Chun Pong Lau",
      "Micah Goldblum",
      "Rama Chellappa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06802"
  },
  {
    "id": "arXiv:2110.06803",
    "title": "Learn to Ignore: Domain Adaptation for Multi-Site MRI Analysis",
    "abstract": "Limited availability of large image datasets is a major issue in the\ndevelopment of accurate and generalizable machine learning methods in medicine.\nThe limitations in the amount of data are mainly due to the use of different\nacquisition protocols, different hardware, and data privacy. At the same time,\ntraining a classification model on a small dataset leads to a poor\ngeneralization quality of the model. To overcome this issue, a combination of\nvarious image datasets of different provenance is often used, e.g., multi-site\nstudies. However, if an additional dataset does not include all classes of the\ntask, the learning of the classification model can be biased to the device or\nplace of acquisition.\nThis is especially the case for Magnetic Resonance (MR) images, where\ndifferent MR scanners introduce a bias that limits the performance of the\nmodel. In this paper, we present a novel method that learns to ignore the\nscanner-related features present in the images, while learning features\nrelevant for the classification task. We focus on a real-world scenario, where\nonly a small dataset provides images of all classes. We exploit this\ncircumstance by introducing specific additional constraints on the latent\nspace, which lead the focus on disease-related rather than scanner-specific\nfeatures. Our method Learn to Ignore outperforms state-of-the-art domain\nadaptation methods on a multi-site MRI dataset on a classification task between\nMultiple Sclerosis patients and healthy subjects.",
    "descriptor": "",
    "authors": [
      "Julia Wolleb",
      "Robin Sandk\u00fchler",
      "Muhamed Barakovic",
      "Athina Papadopoulou",
      "Nouchine Hadjikhani",
      "\u00d6zg\u00fcr Yaldizli",
      "Jens Kuhle",
      "Cristina Granziera",
      "Philippe C. Cattin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06803"
  },
  {
    "id": "arXiv:2110.06804",
    "title": "A comprehensive review of Binary Neural Network",
    "abstract": "Binary Neural Network (BNN) method is an extreme application of convolutional\nneural network (CNN) parameter quantization. As opposed to the original CNN\nmethods which employed floating-point computation with full-precision weights\nand activations, BBN uses 1-bit activations and weights. With BBNs, a\nsignificant amount of storage, network complexity and energy consumption can be\nreduced, and neural networks can be implemented more efficiently in embedded\napplications. Unfortunately, binarization causes severe information loss. A gap\nstill exists between full-precision CNN models and their binarized\ncounterparts. The recent developments in BNN have led to a lot of algorithms\nand solutions that have helped address this issue. This article provides a full\noverview of recent developments in BNN. The present paper focuses exclusively\non 1-bit activations and weights networks, as opposed to previous surveys in\nwhich low-bit works are mixed in. In this paper, we conduct a complete\ninvestigation of BNN's development from their predecessors to the latest BNN\nalgorithms and techniques, presenting a broad design pipeline, and discussing\neach module's variants. Along the way, this paper examines BNN (a) purpose:\ntheir early successes and challenges; (b) BNN optimization: selected\nrepresentative works that contain key optimization techniques; (c) deployment:\nopen-source frameworks for BNN modeling and development; (d) terminal:\nefficient computing architectures and devices for BNN and (e) applications:\ndiverse applications with BNN. Moreover, this paper discusses potential\ndirections and future research opportunities for the latest BNN algorithms and\ntechniques, presents a broad design pipeline, and discusses each module's\nvariants.",
    "descriptor": "",
    "authors": [
      "Chunyu Yuan",
      "Sos S. Agaian"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2110.06804"
  },
  {
    "id": "arXiv:2110.06805",
    "title": "Assisting News Media Editors with Cohesive Visual Storylines",
    "abstract": "Creating a cohesive, high-quality, relevant, media story is a challenge that\nnews media editors face on a daily basis. This challenge is aggravated by the\nflood of highly relevant information that is constantly pouring onto the\nnewsroom. To assist news media editors in this daunting task, this paper\nproposes a framework to organize news content into cohesive, high-quality,\nrelevant visual storylines. First, we formalize, in a nonsubjective manner, the\nconcept of visual story transition. Leveraging it, we propose four graph-based\nmethods of storyline creation, aiming for global story cohesiveness. These were\ncreated and implemented to take full advantage of existing graph algorithms,\nensuring their correctness and good computational performance. They leverage a\nstrong ensemble-based estimator which was trained to predict story transition\nquality based on both the semantic and visual features present in the pair of\nimages under scrutiny. A user study covered a total of 28 curated stories about\nsports and cultural events. Experiments showed that (i) visual transitions in\nstorylines can be learned with a quality above 90%, and (ii) the proposed graph\nmethods can produce cohesive storylines with quality in the range of 88% to\n96%.",
    "descriptor": "\nComments: Accepted at ACM Multimedia 2021\n",
    "authors": [
      "Gon\u00e7alo Marcelino",
      "David Semedo",
      "Andr\u00e9 Mour\u00e3o",
      "Saverio Blasi",
      "Marta Mrak",
      "Jo\u00e3o Magalh\u00e3es"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2110.06805"
  },
  {
    "id": "arXiv:2110.06806",
    "title": "Simulation Based Probabilistic Risk Assessment (SIMPRA): Risk Based  Design",
    "abstract": "The classical approach to design a system is based on a deterministic\nperspective where the assumption is that the system and its environment are\nfully predictable, and their behaviour is completely known to the designer.\nAlthough this approach may work fairly well for regular design problems, it is\nnot satisfactory for the design of highly sensitive and complex systems where\nsignificant resources and even lives are at risk. In addition it can results in\nextra costs of over-designing for the sake of safety and reliability. In this\npaper, a risk-based design framework using Simulation Based Probabilistic Risk\nAssessment (SIMPRA) methodology is proposed. SIMPRA allows the designer to use\nthe knowledge that can be expected to exist at the design stage to identify how\ndeviations can occur; and then apply these high-level scenarios to a rich\nsimulation model of the system to generate detailed scenarios and identify the\nprobability and consequences of these scenarios. SIMPRA has three main modules\nincluding Simulator, Planner and Scheduler, and it approach is much more\nefficient in covering the large space of possible scenarios as compared with,\nfor example, biased Monte Carlo simulations because of the Planner module which\nuses engineering knowledge to guide the simulation process. The value-added of\nthis approach is that it enables the designer to observe system behaviour under\nmany different conditions. This process will lead to a risk-informed design in\nwhich the risk of negative consequences is either eliminated entirely or\nreduced to an acceptable range. For illustrative purposes, an earth observation\nsatellite system example is introduced.",
    "descriptor": "",
    "authors": [
      "Hamed S Nejad",
      "Tarannom Parhizkar",
      "Ali Mosleh"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.06806"
  },
  {
    "id": "arXiv:2110.06809",
    "title": "Trust Calibration and Trust Respect: A Method for Building Team Cohesion  in Human Robot Teams",
    "abstract": "Recent advances in the areas of human-robot interaction (HRI) and robot\nautonomy are changing the world. Today robots are used in a variety of\napplications. People and robots work together in human autonomous teams (HATs)\nto accomplish tasks that, separately, cannot be easily accomplished. Trust\nbetween robots and humans in HATs is vital to task completion and effective\nteam cohesion. For optimal performance and safety of human operators in HRI,\nhuman trust should be adjusted to the actual performance and reliability of the\nrobotic system. The cost of poor trust calibration in HRI, is at a minimum, low\nperformance, and at higher levels it causes human injury or critical task\nfailures. While the role of trust calibration is vital to team cohesion it is\nalso important for a robot to be able to assess whether or not a human is\nexhibiting signs of mistrust due to some other factor such as anger,\ndistraction or frustration. In these situations the robot chooses not to\ncalibrate trust, instead the robot chooses to respect trust. The decision to\nrespect trust is determined by the robots knowledge of whether or not a human\nshould trust the robot based on its actions(successes and failures) and its\nfeedback to the human. We show that the feedback in the form of trust\ncalibration cues(TCCs) can effectively change the trust level in humans. This\ninformation is potentially useful in aiding a robot it its decision to respect\ntrust.",
    "descriptor": "\nComments: Presented at AI-HRI symposium as part of AAAI-FSS 2021 (arXiv:2109.10836)\n",
    "authors": [
      "Russell Perkins",
      "Zahra Rezaei Khavas",
      "Paul Robinette"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.06809"
  },
  {
    "id": "arXiv:2110.06816",
    "title": "A Framework for Verification of Wasserstein Adversarial Robustness",
    "abstract": "Machine learning image classifiers are susceptible to adversarial and\ncorruption perturbations. Adding imperceptible noise to images can lead to\nsevere misclassifications of the machine learning model. Using $L_p$-norms for\nmeasuring the size of the noise fails to capture human similarity perception,\nwhich is why optimal transport based distance measures like the Wasserstein\nmetric are increasingly being used in the field of adversarial robustness.\nVerifying the robustness of classifiers using the Wasserstein metric can be\nachieved by proving the absence of adversarial examples (certification) or\nproving their presence (attack). In this work we present a framework based on\nthe work by Levine and Feizi, which allows us to transfer existing\ncertification methods for convex polytopes or $L_1$-balls to the Wasserstein\nthreat model. The resulting certification can be complete or incomplete,\ndepending on whether convex polytopes or $L_1$-balls were chosen. Additionally,\nwe present a new Wasserstein adversarial attack that is projected gradient\ndescent based and which has a significantly reduced computational burden\ncompared to existing attack approaches.",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Tobias Wegel",
      "Felix Assion",
      "David Mickisch",
      "Florens Gre\u00dfner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06816"
  },
  {
    "id": "arXiv:2110.06817",
    "title": "Optical Character Recognition of 19th Century Classical Commentaries:  the Current State of Affairs",
    "abstract": "Together with critical editions and translations, commentaries are one of the\nmain genres of publication in literary and textual scholarship, and have a\ncentury-long tradition. Yet, the exploitation of thousands of digitized\nhistorical commentaries was hitherto hindered by the poor quality of Optical\nCharacter Recognition (OCR), especially on commentaries to Greek texts. In this\npaper, we evaluate the performances of two pipelines suitable for the OCR of\nhistorical classical commentaries. Our results show that Kraken + Ciaconna\nreaches a substantially lower character error rate (CER) than Tesseract/OCR-D\non commentary sections with high density of polytonic Greek text (average CER\n7% vs. 13%), while Tesseract/OCR-D is slightly more accurate than Kraken +\nCiaconna on text sections written predominantly in Latin script (average CER\n8.2% vs. 8.4%). As part of this paper, we also release GT4HistComment, a small\ndataset with OCR ground truth for 19th classical commentaries and Pogretra, a\nlarge collection of training data and pre-trained models for a wide variety of\nancient Greek typefaces.",
    "descriptor": "",
    "authors": [
      "Matteo Romanello",
      "Sven Najem-Meyer",
      "Bruce Robertson"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06817"
  },
  {
    "id": "arXiv:2110.06821",
    "title": "Leveraging redundancy in attention with Reuse Transformers",
    "abstract": "Pairwise dot product-based attention allows Transformers to exchange\ninformation between tokens in an input-dependent way, and is key to their\nsuccess across diverse applications in language and vision. However, a typical\nTransformer model computes such pairwise attention scores repeatedly for the\nsame sequence, in multiple heads in multiple layers. We systematically analyze\nthe empirical similarity of these scores across heads and layers and find them\nto be considerably redundant, especially adjacent layers showing high\nsimilarity. Motivated by these findings, we propose a novel architecture that\nreuses attention scores computed in one layer in multiple subsequent layers.\nExperiments on a number of standard benchmarks show that reusing attention\ndelivers performance equivalent to or better than standard transformers, while\nreducing both compute and memory usage.",
    "descriptor": "",
    "authors": [
      "Srinadh Bhojanapalli",
      "Ayan Chakrabarti",
      "Andreas Veit",
      "Michal Lukasik",
      "Himanshu Jain",
      "Frederick Liu",
      "Yin-Wen Chang",
      "Sanjiv Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06821"
  },
  {
    "id": "arXiv:2110.06823",
    "title": "A Speaker-Aware Learning Framework for Improving Multi-turn Dialogue  Coherence",
    "abstract": "This paper presents a novel open-domain dialogue generation framework\nemphasizing the differentiation of speakers in multi-turn conversations.\nDiffering from prior work that solely relies on the content of conversation\nhistory to generate a response, we argue that capturing relative social\nrelations among utterances (i.e., generated by either the same speaker or\ndifferent persons) benefits the machine capturing fine-grained context\ninformation from a conversation history to improve context coherence in the\ngenerated response. Given that, we propose a speaker-aware framework, named\nParallel Hierarchical Attentive Encoder-Decoder (PHAED), that aims to model\neach utterance with the awareness of its speaker and contextual associations\nwith the same speaker's previous messages. Specifically, in a conversation\ninvolving two speakers, we regard the utterances from one speaker as responses\nand those from the other as queries. After understanding queries via our\nencoder with inner-query and inter-query encodings, our decoder reuses the\nhidden states of previously generated responses to generate a new response. Our\nempirical results show that PHAED outperforms the state-of-the-art in both\nautomatic and human evaluations. Furthermore, our ablation study shows that\ndialogue models with speaker tokens can generally decrease the possibility of\ngenerating non-coherent responses regarding the conversation context.",
    "descriptor": "",
    "authors": [
      "Zihao Wang",
      "Ming Jiang",
      "Junli Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06823"
  },
  {
    "id": "arXiv:2110.06827",
    "title": "NoisyActions2M: A Multimedia Dataset for Video Understanding from Noisy  Labels",
    "abstract": "Deep learning has shown remarkable progress in a wide range of problems.\nHowever, efficient training of such models requires large-scale datasets, and\ngetting annotations for such datasets can be challenging and costly. In this\nwork, we explore the use of user-generated freely available labels from web\nvideos for video understanding. We create a benchmark dataset consisting of\naround 2 million videos with associated user-generated annotations and other\nmeta information. We utilize the collected dataset for action classification\nand demonstrate its usefulness with existing small-scale annotated datasets,\nUCF101 and HMDB51. We study different loss functions and two pretraining\nstrategies, simple and self-supervised learning. We also show how a network\npretrained on the proposed dataset can help against video corruption and label\nnoise in downstream datasets. We present this as a benchmark dataset in noisy\nlearning for video understanding. The dataset, code, and trained models will be\npublicly available for future research.",
    "descriptor": "\nComments: Accepted at ACM Multimedia Asia 2021\n",
    "authors": [
      "Mohit Sharma",
      "Raj Patra",
      "Harshal Desai",
      "Shruti Vyas",
      "Yogesh Rawat",
      "Rajiv Ratn Shah"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06827"
  },
  {
    "id": "arXiv:2110.06829",
    "title": "Towards a fully RL-based Market Simulator",
    "abstract": "We present a new financial framework where two families of RL-based agents\nrepresenting the Liquidity Providers and Liquidity Takers learn simultaneously\nto satisfy their objective. Thanks to a parametrized reward formulation and the\nuse of Deep RL, each group learns a shared policy able to generalize and\ninterpolate over a wide range of behaviors. This is a step towards a fully\nRL-based market simulator replicating complex market conditions particularly\nsuited to study the dynamics of the financial market under various scenarios.",
    "descriptor": "\nComments: Published at ICAIF'21: ACM International Conference on AI in Finance\n",
    "authors": [
      "Leo Ardon",
      "Nelson Vadori",
      "Thomas Spooner",
      "Mengda Xu",
      "Jared Vann",
      "Sumitra Ganesh"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2110.06829"
  },
  {
    "id": "arXiv:2110.06830",
    "title": "CONetV2: Efficient Auto-Channel Size Optimization for CNNs",
    "abstract": "Neural Architecture Search (NAS) has been pivotal in finding optimal network\nconfigurations for Convolution Neural Networks (CNNs). While many methods\nexplore NAS from a global search-space perspective, the employed optimization\nschemes typically require heavy computational resources. This work introduces a\nmethod that is efficient in computationally constrained environments by\nexamining the micro-search space of channel size. In tackling channel-size\noptimization, we design an automated algorithm to extract the dependencies\nwithin different connected layers of the network. In addition, we introduce the\nidea of knowledge distillation, which enables preservation of trained weights,\nadmist trials where the channel sizes are changing. Further, since the standard\nperformance indicators (accuracy, loss) fail to capture the performance of\nindividual network components (providing an overall network evaluation), we\nintroduce a novel metric that highly correlates with test accuracy and enables\nanalysis of individual network layers. Combining dependency extraction,\nmetrics, and knowledge distillation, we introduce an efficient searching\nalgorithm, with simulated annealing inspired stochasticity, and demonstrate its\neffectiveness in finding optimal architectures that outperform baselines by a\nlarge margin.",
    "descriptor": "",
    "authors": [
      "Yi Ru Wang",
      "Samir Khaki",
      "Weihang Zheng",
      "Mahdi S. Hosseini",
      "Konstantinos N. Plataniotis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06830"
  },
  {
    "id": "arXiv:2110.06831",
    "title": "Safe Driving via Expert Guided Policy Optimization",
    "abstract": "When learning common skills like driving, beginners usually have domain\nexperts standing by to ensure the safety of the learning process. We formulate\nsuch learning scheme under the Expert-in-the-loop Reinforcement Learning where\na guardian is introduced to safeguard the exploration of the learning agent.\nWhile allowing the sufficient exploration in the uncertain environment, the\nguardian intervenes under dangerous situations and demonstrates the correct\nactions to avoid potential accidents. Thus ERL enables both exploration and\nexpert's partial demonstration as two training sources. Following such a\nsetting, we develop a novel Expert Guided Policy Optimization (EGPO) method\nwhich integrates the guardian in the loop of reinforcement learning. The\nguardian is composed of an expert policy to generate demonstration and a switch\nfunction to decide when to intervene. Particularly, a constrained optimization\ntechnique is used to tackle the trivial solution that the agent deliberately\nbehaves dangerously to deceive the expert into taking over. Offline RL\ntechnique is further used to learn from the partial demonstration generated by\nthe expert. Safe driving experiments show that our method achieves superior\ntraining and test-time safety, outperforms baselines with a substantial margin\nin sample efficiency, and preserves the generalizabiliy to unseen environments\nin test-time. Demo video and source code are available at:\nhttps://decisionforce.github.io/EGPO/",
    "descriptor": "",
    "authors": [
      "Zhenghao Peng",
      "Quanyi Li",
      "Chunxiao Liu",
      "Bolei Zhou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.06831"
  },
  {
    "id": "arXiv:2110.06832",
    "title": "Demonstrator Game Showcasing Indoor Positioning via BLE Signal Strength",
    "abstract": "For a non-technical audience, new concepts from computer science and\nengineering are often hard to grasp. In order to introduce a general audience\nto topics related to Industry 4.0, we designed and developed a demonstrator\ngame. The Who-wants-to-be-a-millionaire?-style quiz game lets the player\nexperience indoor positioning based on Bluetooth signal strength firsthand. We\nfound that such an interactive game demonstrator can function as a\nconversation-opener and is useful in helping introduce concepts relevant for\nmany future jobs.",
    "descriptor": "\nComments: Accepted for publication at the IEEE 17th International Conference on Mobility, Sensing and Networking (IEEE MSN 2021)\n",
    "authors": [
      "Felix Beierle",
      "Hai Dinh-Tuan",
      "Yong Wu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.06832"
  },
  {
    "id": "arXiv:2110.06836",
    "title": "CasSeqGCN: Combining Network Structure and Temporal Sequence to Predict  Information Cascades",
    "abstract": "One important task in the study of information cascade is to predict the\nfuture recipients of a message given its past spreading trajectory. While the\nnetwork structure serves as the backbone of the spreading, an accurate\nprediction can hardly be made without the knowledge of the dynamics on the\nnetwork. The temporal information in the spreading sequence captures many\nhidden features, but predictions based on sequence alone have their\nlimitations. Recent efforts start to explore the possibility of combining both\nthe network structure and the temporal feature for a more accurate prediction.\nNevertheless, it is still a challenge to efficiently and optimally associate\nthese two interdependent factors. Here, we propose a new end-to-end prediction\nmethod CasSeqGCN in which the structure and temporal feature are simultaneously\ntaken into account. A cascade is divided into multiple snapshots which record\nthe network topology and the state of nodes. The graph convolutional network\n(GCN) is used to learn the representation of a snapshot. The dynamic routing\nand the long short-term memory (LSTM) model are used to aggregate node\nrepresentation and extract temporal information. CasSeqGCN predicts the future\ncascade size more accurately compared with other state-of-art baseline methods.\nThe ablation study demonstrates that the improvement mainly comes from the\ndesign of the input and the GCN layer. Taken together, our method confirms the\nbenefit of combining the structural and temporal features in cascade\nprediction, which not only brings new insights but can also serve as a useful\nbaseline method for future studies.",
    "descriptor": "",
    "authors": [
      "Yansong Wang",
      "Xiaomeng Wang",
      "Rados\u0142aw Michalski",
      "Yijun Ran",
      "Tao Jia"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.06836"
  },
  {
    "id": "arXiv:2110.06838",
    "title": "Full-stack Comparison of Channel Models for Networks Above 100 GHz in an  Indoor Scenario",
    "abstract": "The Sixth Generation (6G) of mobile networks is expected to use carrier\nfrequencies in the spectrum above 100 GHz, to satisfy the demands for higher\ndata rates and bandwidth of future digital applications. The development of\nnetworking solutions at such high frequencies is challenged by the harsh\npropagation environment, and by the need for directional communications and\nsignal processing at high data rates. A fundamental step in defining and\ndeveloping wireless networks above 100 GHz is given by an accurate performance\nevaluation. For simulations, this strongly depends on the accuracy of the\nmodeling of the channel and of the interaction with the higher layers of the\nstack. This paper introduces the implementation of two recently proposed\nchannel models (based on ray tracing and on a fully stochastic model) for the\n140 GHz band for the ns-3 TeraSim module, which enables simulation of macro\nwireless networks in the sub-terahertz and terahertz spectrum. We also compare\nthe two channel models with full-stack simulations in an indoor scenario,\nhighlighting differences and similarities in how they interact with the\nprotocol stack and antenna model of TeraSim.",
    "descriptor": "\nComments: Amir Ashtari Gargari, Michele Polese, Michele Zorzi. 2022. Full-stack Comparison of Channel Models for Networks Above 100 GHz in an Indoor Scenario. In 5th ACM Workshop on Millimeter-Wave and Terahertz Networks and Sensing Systems (mmNets '21), January 31-February 4, 2022, New Orleans, LA, USA. ACM, New York, NY, USA, 6 pages\n",
    "authors": [
      "Amir Ashtari Gargari",
      "Michele Polese",
      "Michele Zorzi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.06838"
  },
  {
    "id": "arXiv:2110.06839",
    "title": "The algebra of row monomial matrices",
    "abstract": "We consider an algebra with non-standard operations on the class of row\nmonomial matrices (having one unit and rest of zeros in every row).\nThe class of row monomial matrices is closed under multiplication, but not\nclosed under ordinary matrix addition.\nThe most significant difference between the algebra of row monomial matrices\nand linear algebra is the summation operation, with respect to which the class\nof row monomial matrices is closed.\nThe operation of summation in the algebra can be considered also as an\nalgebra of subsets of any set. The class of subsets of given set is closed\nunder considered operation of summation.\nThe deterministic finite automaton (DFA) can be presented by a complete\nunderlying graph of the automaton with edges labelled by letters of an\nalphabet. In particular, the set of states of the automaton might be\nconsidered.\nRow monomial matrices can be induced by words in the alphabet of labels on\nedges of underlying graph of DFA and present a mapping of the set of states.\nThe algebra under consideration plays an important role in the study of DFA,\nespecially for synchronizing automata.",
    "descriptor": "\nComments: 8 pages, no figures. arXiv admin note: substantial text overlap with arXiv:2003.06177, arXiv:1904.07694, arXiv:1405.2435\n",
    "authors": [
      "A.N. Trahtman"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.06839"
  },
  {
    "id": "arXiv:2110.06841",
    "title": "On Language Model Integration for RNN Transducer based Speech  Recognition",
    "abstract": "The mismatch between an external language model (LM) and the implicitly\nlearned internal LM (ILM) of RNN-Transducer (RNN-T) can limit the performance\nof LM integration such as simple shallow fusion. A Bayesian interpretation\nsuggests to remove this sequence prior as ILM correction. In this work, we\nstudy various ILM correction-based LM integration methods formulated in a\ncommon RNN-T framework. We provide a decoding interpretation on two major\nreasons for performance improvement with ILM correction, which is further\nexperimentally verified with detailed analysis. We also propose an exact-ILM\ntraining framework by extending the proof given in the hybrid autoregressive\ntransducer, which enables a theoretical justification for other ILM approaches.\nSystematic comparison is conducted for both in-domain and cross-domain\nevaluation on the Librispeech and TED-LIUM Release 2 corpora, respectively. Our\nproposed exact-ILM training can further improve the best ILM method.",
    "descriptor": "\nComments: submitted to ICASSP2022\n",
    "authors": [
      "Wei Zhou",
      "Zuoyun Zheng",
      "Ralf Schl\u00fcter",
      "Hermann Ney"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.06841"
  },
  {
    "id": "arXiv:2110.06843",
    "title": "Compositional Generalization in Dependency Parsing",
    "abstract": "Compositionality, or the ability to combine familiar units like words into\nnovel phrases and sentences, has been the focus of intense interest in\nartificial intelligence in recent years. To test compositional generalization\nin semantic parsing, Keysers et al. (2020) introduced Compositional Freebase\nQueries (CFQ). This dataset maximizes the similarity between the test and train\ndistributions over primitive units, like words, while maximizing the compound\ndivergence: the dissimilarity between test and train distributions over larger\nstructures, like phrases. Dependency parsing, however, lacks a compositional\ngeneralization benchmark. In this work, we introduce a gold-standard set of\ndependency parses for CFQ, and use this to analyze the behavior of a\nstate-of-the art dependency parser (Qi et al., 2020) on the CFQ dataset. We\nfind that increasing compound divergence degrades dependency parsing\nperformance, although not as dramatically as semantic parsing performance.\nAdditionally, we find the performance of the dependency parser does not\nuniformly degrade relative to compound divergence, and the parser performs\ndifferently on different splits with the same compound divergence. We explore a\nnumber of hypotheses for what causes the non-uniform degradation in dependency\nparsing performance, and identify a number of syntactic structures that drive\nthe dependency parser's lower performance on the most challenging splits.",
    "descriptor": "\nComments: 8 pages 7 figures\n",
    "authors": [
      "Emily Goodwin",
      "Siva Reddy",
      "Timothy J. O'Donnell",
      "Dzmitry Bahdanau"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06843"
  },
  {
    "id": "arXiv:2110.06847",
    "title": "Ousiometrics and Telegnomics: The essence of meaning conforms to a  two-dimensional powerful-weak and dangerous-safe framework with diverse  corpora presenting a safety bias",
    "abstract": "We define `ousiometrics' to be the study of essential meaning in whatever\ncontext that meaningful signals are communicated, and `telegnomics' as the\nstudy of remotely sensed knowledge. From work emerging through the middle of\nthe 20th century, the essence of meaning has become generally accepted as being\nwell captured by the three orthogonal dimensions of evaluation, potency, and\nactivation (EPA). By re-examining first types and then tokens for the English\nlanguage, and through the use of automatically annotated histograms --\n`ousiograms' -- we find here that: 1. The essence of meaning conveyed by words\nis instead best described by a compass-like power-danger (PD) framework, and 2.\nAnalysis of a disparate collection of large-scale English language corpora --\nliterature, news, Wikipedia, talk radio, and social media -- shows that natural\nlanguage exhibits a systematic bias toward safe, low danger words -- a\nreinterpretation of the Pollyanna principle's positivity bias for written\nexpression. To help justify our choice of dimension names and to help address\nthe problems with representing observed ousiometric dimensions by bipolar\nadjective pairs, we introduce and explore `synousionyms' and `antousionyms' --\nousiometric counterparts of synonyms and antonyms. We further show that the PD\nframework revises the circumplex model of affect as a more general model of\nstate of mind. Finally, we use our findings to construct and test a prototype\n`ousiometer', a telegnomic instrument that measures ousiometric time series for\ntemporal corpora. We contend that our power-danger ousiometric framework\nprovides a complement for entropy-based measurements, and may be of value for\nthe study of a wide variety of communication across biological and artificial\nlife.",
    "descriptor": "\nComments: 34 pages (28 page main manuscript, 6 page appendix), 14 figures (8 main, 6 appendix), 4 tables\n",
    "authors": [
      "P. S. Dodds",
      "T. Alshaabi",
      "M. I. Fudolig",
      "J. W. Zimmerman",
      "J. Lovato",
      "S. Beaulieu",
      "J. R. Minot",
      "M. V. Arnold",
      "A. J. Reagan",
      "C. M. Danforth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.06847"
  },
  {
    "id": "arXiv:2110.06848",
    "title": "Decoupled Contrastive Learning",
    "abstract": "Contrastive learning (CL) is one of the most successful paradigms for\nself-supervised learning (SSL). In a principled way, it considers two augmented\n``views'' of the same image as positive to be pulled closer, and all other\nimages negative to be pushed further apart. However, behind the impressive\nsuccess of CL-based techniques, their formulation often relies on\nheavy-computation settings, including large sample batches, extensive training\nepochs, etc. We are thus motivated to tackle these issues and aim at\nestablishing a simple, efficient, and yet competitive baseline of contrastive\nlearning. Specifically, we identify, from theoretical and empirical studies, a\nnoticeable negative-positive-coupling (NPC) effect in the widely used\ncross-entropy (InfoNCE) loss, leading to unsuitable learning efficiency with\nrespect to the batch size. Indeed the phenomenon tends to be neglected in that\noptimizing infoNCE loss with a small-size batch is effective in solving easier\nSSL tasks. By properly addressing the NPC effect, we reach a decoupled\ncontrastive learning (DCL) objective function, significantly improving SSL\nefficiency. DCL can achieve competitive performance, requiring neither large\nbatches in SimCLR, momentum encoding in MoCo, or large epochs. We demonstrate\nthe usefulness of DCL in various benchmarks, while manifesting its robustness\nbeing much less sensitive to suboptimal hyperparameters. Notably, our approach\nachieves $66.9\\%$ ImageNet top-1 accuracy using batch size 256 within 200\nepochs pre-training, outperforming its baseline SimCLR by $5.1\\%$. With further\noptimized hyperparameters, DCL can improve the accuracy to $68.2\\%$. We believe\nDCL provides a valuable baseline for future contrastive learning-based SSL\nstudies.",
    "descriptor": "\nComments: 19 pages, 4 figures\n",
    "authors": [
      "Chun-Hsiao Yeh",
      "Cheng-Yao Hong",
      "Yen-Chi Hsu",
      "Tyng-Luh Liu",
      "Yubei Chen",
      "Yann LeCun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06848"
  },
  {
    "id": "arXiv:2110.06850",
    "title": "Boosting the Certified Robustness of L-infinity Distance Nets",
    "abstract": "Recently, Zhang et al. (2021) developed a new neural network architecture\nbased on $\\ell_\\infty$-distance functions, which naturally possesses certified\nrobustness by its construction. Despite the excellent theoretical properties,\nthe model so far can only achieve comparable performance to conventional\nnetworks. In this paper, we significantly boost the certified robustness of\n$\\ell_\\infty$-distance nets through a careful analysis of its training process.\nIn particular, we show the $\\ell_p$-relaxation, a crucial way to overcome the\nnon-smoothness of the model, leads to an unexpected large Lipschitz constant at\nthe early training stage. This makes the optimization insufficient using hinge\nloss and produces sub-optimal solutions. Given these findings, we propose a\nsimple approach to address the issues above by using a novel objective function\nthat combines a scaled cross-entropy loss with clipped hinge loss. Our\nexperiments show that using the proposed training strategy, the certified\naccuracy of $\\ell_\\infty$-distance net can be dramatically improved from 33.30%\nto 40.06% on CIFAR-10 ($\\epsilon=8/255$), meanwhile significantly outperforming\nother approaches in this area. Such a result clearly demonstrates the\neffectiveness and potential of $\\ell_\\infty$-distance net for certified\nrobustness.",
    "descriptor": "",
    "authors": [
      "Bohang Zhang",
      "Du Jiang",
      "Di He",
      "Liwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06850"
  },
  {
    "id": "arXiv:2110.06851",
    "title": "Fast Posterior Estimation of Cardiac Electrophysiological Model  Parameters via Bayesian Active Learning",
    "abstract": "Probabilistic estimation of cardiac electrophysiological model parameters\nserves an important step towards model personalization and uncertain\nquantification. The expensive computation associated with these model\nsimulations, however, makes direct Markov Chain Monte Carlo (MCMC) sampling of\nthe posterior probability density function (pdf) of model parameters\ncomputationally intensive. Approximated posterior pdfs resulting from replacing\nthe simulation model with a computationally efficient surrogate, on the other\nhand, have seen limited accuracy. In this paper, we present a Bayesian active\nlearning method to directly approximate the posterior pdf function of cardiac\nmodel parameters, in which we intelligently select training points to query the\nsimulation model in order to learn the posterior pdf using a small number of\nsamples. We integrate a generative model into Bayesian active learning to allow\napproximating posterior pdf of high-dimensional model parameters at the\nresolution of the cardiac mesh. We further introduce new acquisition functions\nto focus the selection of training points on better approximating the shape\nrather than the modes of the posterior pdf of interest. We evaluated the\npresented method in estimating tissue excitability in a 3D cardiac\nelectrophysiological model in a range of synthetic and real-data experiments.\nWe demonstrated its improved accuracy in approximating the posterior pdf\ncompared to Bayesian active learning using regular acquisition functions, and\nsubstantially reduced computational cost in comparison to existing standard or\naccelerated MCMC sampling.",
    "descriptor": "",
    "authors": [
      "Md Shakil Zaman",
      "Jwala Dhamala",
      "Pradeep Bajracharya",
      "John L. Sapp",
      "B. Milan Horacek",
      "Katherine C. Wu",
      "Natalia A. Trayanova",
      "Linwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06851"
  },
  {
    "id": "arXiv:2110.06852",
    "title": "Morphosyntactic Tagging with Pre-trained Language Models for Arabic and  its Dialects",
    "abstract": "We present state-of-the-art results on morphosyntactic tagging across\ndifferent varieties of Arabic using fine-tuned pre-trained transformer language\nmodels. Our models consistently outperform existing systems in Modern Standard\nArabic and all the Arabic dialects we study, achieving 2.6% absolute\nimprovement over the previous state-of-the-art in Modern Standard Arabic, 2.8%\nin Gulf, 1.6% in Egyptian, and 7.0% in Levantine. We explore different training\nsetups for fine-tuning pre-trained transformer language models, including\ntraining data size, the use of external linguistic resources, and the use of\nannotated data from other dialects in a low-resource scenario. Our results show\nthat strategic fine-tuning using datasets from other high-resource dialects is\nbeneficial for a low-resource dialect. Additionally, we show that high-quality\nmorphological analyzers as external linguistic resources are beneficial\nespecially in low-resource settings.",
    "descriptor": "",
    "authors": [
      "Go Inoue",
      "Salam Khalifa",
      "Nizar Habash"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06852"
  },
  {
    "id": "arXiv:2110.06853",
    "title": "Attentive and Contrastive Learning for Joint Depth and Motion Field  Estimation",
    "abstract": "Estimating the motion of the camera together with the 3D structure of the\nscene from a monocular vision system is a complex task that often relies on the\nso-called scene rigidity assumption. When observing a dynamic environment, this\nassumption is violated which leads to an ambiguity between the ego-motion of\nthe camera and the motion of the objects. To solve this problem, we present a\nself-supervised learning framework for 3D object motion field estimation from\nmonocular videos. Our contributions are two-fold. First, we propose a two-stage\nprojection pipeline to explicitly disentangle the camera ego-motion and the\nobject motions with dynamics attention module, called DAM. Specifically, we\ndesign an integrated motion model that estimates the motion of the camera and\nobject in the first and second warping stages, respectively, controlled by the\nattention module through a shared motion encoder. Second, we propose an object\nmotion field estimation through contrastive sample consensus, called CSAC,\ntaking advantage of weak semantic prior (bounding box from an object detector)\nand geometric constraints (each object respects the rigid body motion model).\nExperiments on KITTI, Cityscapes, and Waymo Open Dataset demonstrate the\nrelevance of our approach and show that our method outperforms state-of-the-art\nalgorithms for the tasks of self-supervised monocular depth estimation, object\nmotion segmentation, monocular scene flow estimation, and visual odometry.",
    "descriptor": "\nComments: ICCV 2021\n",
    "authors": [
      "Seokju Lee",
      "Francois Rameau",
      "Fei Pan",
      "In So Kweon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.06853"
  },
  {
    "id": "arXiv:2110.06862",
    "title": "Model hierarchies and higher-order discretisation of time-dependent  thin-film free boundary problems with dynamic contact angle",
    "abstract": "We present a mathematical and numerical framework for thin-film fluid flows\nover planar surfaces including dynamic contact angles. In particular, we\nprovide algorithmic details and an implementation of higher-order spatial and\ntemporal discretisation of the underlying free boundary problem using the\nfinite element method. The corresponding partial differential equation is based\non a thermodynamic consistent energetic variational formulation of the problem\nusing the free energy and viscous dissipation in the bulk, on the surface, and\nat the moving contact line. Model hierarchies for limits of strong and weak\ncontact line dissipation are established, implemented and studied. We analyze\nthe performance of the numerical algorithm and investigate the impact of the\ndynamic contact angle on the evolution of two benchmark problems:\ngravity-driven sliding droplets and the instability of a ridge.",
    "descriptor": "\nComments: 24 pages, 11 Figures\n",
    "authors": [
      "Dirk Peschka",
      "Luca Heltai"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.06862"
  },
  {
    "id": "arXiv:2110.06863",
    "title": "Improving Users' Mental Model with Attention-directed Counterfactual  Edits",
    "abstract": "In the domain of Visual Question Answering (VQA), studies have shown\nimprovement in users' mental model of the VQA system when they are exposed to\nexamples of how these systems answer certain Image-Question (IQ) pairs. In this\nwork, we show that showing controlled counterfactual image-question examples\nare more effective at improving the mental model of users as compared to simply\nshowing random examples. We compare a generative approach and a retrieval-based\napproach to show counterfactual examples. We use recent advances in generative\nadversarial networks (GANs) to generate counterfactual images by deleting and\ninpainting certain regions of interest in the image. We then expose users to\nchanges in the VQA system's answer on those altered images. To select the\nregion of interest for inpainting, we experiment with using both\nhuman-annotated attention maps and a fully automatic method that uses the VQA\nsystem's attention values. Finally, we test the user's mental model by asking\nthem to predict the model's performance on a test counterfactual image. We note\nan overall improvement in users' accuracy to predict answer change when shown\ncounterfactual explanations. While realistic retrieved counterfactuals\nobviously are the most effective at improving the mental model, we show that a\ngenerative approach can also be equally effective.",
    "descriptor": "\nComments: Accepted for publication in Applied AI Letters\n",
    "authors": [
      "Kamran Alipour",
      "Arijit Ray",
      "Xiao Lin",
      "Michael Cogswell",
      "Jurgen P. Schulze",
      "Yi Yao",
      "Giedrius T. Burachas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.06863"
  },
  {
    "id": "arXiv:2110.06864",
    "title": "ByteTrack: Multi-Object Tracking by Associating Every Detection Box",
    "abstract": "Multi-object tracking (MOT) aims at estimating bounding boxes and identities\nof objects in videos. Most methods obtain identities by associating detection\nboxes whose scores are higher than a threshold. The objects with low detection\nscores, e.g. occluded objects, are simply thrown away, which brings\nnon-negligible true object missing and fragmented trajectories. To solve this\nproblem, we present a simple, effective and generic association method, called\nBYTE, tracking BY associaTing Every detection box instead of only the high\nscore ones. For the low score detection boxes, we utilize their similarities\nwith tracklets to recover true objects and filter out the background\ndetections. We apply BYTE to 9 different state-of-the-art trackers and achieve\nconsistent improvement on IDF1 score ranging from 1 to 10 points. To put\nforwards the state-of-the-art performance of MOT, we design a simple and strong\ntracker, named ByteTrack. For the first time, we achieve 80.3 MOTA, 77.3 IDF1\nand 63.1 HOTA on the test set of MOT17 with 30 FPS running speed on a single\nV100 GPU. The source code, pre-trained models with deploy versions and\ntutorials of applying to other trackers are released at\n\\url{https://github.com/ifzhang/ByteTrack}.",
    "descriptor": "",
    "authors": [
      "Yifu Zhang",
      "Peize Sun",
      "Yi Jiang",
      "Dongdong Yu",
      "Zehuan Yuan",
      "Ping Luo",
      "Wenyu Liu",
      "Xinggang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06864"
  },
  {
    "id": "arXiv:2110.06865",
    "title": "Semantic Role Labeling as Dependency Parsing: Exploring Latent Tree  Structures Inside Arguments",
    "abstract": "Semantic role labeling is a fundamental yet challenging task in the NLP\ncommunity. Recent works of SRL mainly fall into two lines:1) BIO-based and 2)\nspan-based. Despite effectiveness, they share some intrinsic drawbacks of not\nexplicitly considering internal argument structures, which may potentially\nhinder the model's expressiveness. To remedy this, we propose to reduce SRL to\na dependency parsing task and regard the flat argument spans as latent\nsubtrees. In particular, we equip our formulation with a novel span-constrained\nTreeCRF model to make tree structures span-aware, and further extend it to the\nsecond-order case. Experiments on CoNLL05 and CoNLL12 benchmarks reveal that\nthe results of our methods outperform all previous works and achieve the\nstate-of-the-art.",
    "descriptor": "",
    "authors": [
      "Yu Zhang",
      "Qingrong Xia",
      "Shilin Zhou",
      "Yong Jiang",
      "Zhenghua Li",
      "Guohong Fu",
      "Min Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06865"
  },
  {
    "id": "arXiv:2110.06870",
    "title": "Architecture of a Junkyard Datacenter",
    "abstract": "It requires significant energy to manufacture and deploy computational\ndevices. Traditional discussions of the energy-efficiency of compute measure\noperational energy, i.e.\\ how many FLOPS in a 50\\,MW datacenter. However, if we\nconsider the true lifetime energy use of modern devices, the majority actually\ncomes not from runtime use but from manufacture and deployment. In this paper,\nthen, we suggest that perhaps the most climate-impactful action we can take is\nto extend the service lifetime of existing compute.\nWe design two new metrics to measure how to balance continued service of\nolder devices with the superlinear runtime improvements of newer machines. The\nfirst looks at carbon per raw compute, amortized across the operation and\nmanufacture of devices. The second considers use of components beyond compute,\nsuch as batteries or radios in smartphone platforms. We use these metrics to\nredefine device service lifetime in terms of carbon efficiency. We then realize\na real-world ``junkyard datacenter'' made up of Nexus 4 and Nexus 5 phones,\nwhich are nearly a decade past their official end-of-life dates. This new-old\ndatacenter is able to nearly match and occasionally exceed modern cloud compute\nofferings.",
    "descriptor": "",
    "authors": [
      "Jennifer Switzer",
      "Ryan Kastner",
      "Pat Pannuto"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.06870"
  },
  {
    "id": "arXiv:2110.06871",
    "title": "Two-argument activation functions learn soft XOR operations like  cortical neurons",
    "abstract": "Neurons in the brain are complex machines with distinct functional\ncompartments that interact nonlinearly. In contrast, neurons in artificial\nneural networks abstract away this complexity, typically down to a scalar\nactivation function of a weighted sum of inputs. Here we emulate more\nbiologically realistic neurons by learning canonical activation functions with\ntwo input arguments, analogous to basal and apical dendrites. We use a\nnetwork-in-network architecture where each neuron is modeled as a multilayer\nperceptron with two inputs and a single output. This inner perceptron is shared\nby all units in the outer network. Remarkably, the resultant nonlinearities\nreliably produce soft XOR functions, consistent with recent experimental\nobservations about interactions between inputs in human cortical neurons. When\nhyperparameters are optimized, networks with these nonlinearities learn faster\nand perform better than conventional ReLU nonlinearities with matched parameter\ncounts, and they are more robust to natural and adversarial perturbations.",
    "descriptor": "",
    "authors": [
      "Kijung Yoon",
      "Emin Orhan",
      "Juhyun Kim",
      "Xaq Pitkow"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06871"
  },
  {
    "id": "arXiv:2110.06874",
    "title": "Automated Essay Scoring Using Transformer Models",
    "abstract": "Automated essay scoring (AES) is gaining increasing attention in the\neducation sector as it significantly reduces the burden of manual scoring and\nallows ad hoc feedback for learners. Natural language processing based on\nmachine learning has been shown to be particularly suitable for text\nclassification and AES. While many machine-learning approaches for AES still\nrely on a bag-of-words (BOW) approach, we consider a transformer-based approach\nin this paper, compare its performance to a logistic regression model based on\nthe BOW approach and discuss their differences. The analysis is based on 2,088\nemail responses to a problem-solving task, that were manually labeled in terms\nof politeness. Both transformer models considered in that analysis outperformed\nwithout any hyper-parameter tuning the regression-based model. We argue that\nfor AES tasks such as politeness classification, the transformer-based approach\nhas significant advantages, while a BOW approach suffers from not taking word\norder into account and reducing the words to their stem. Further, we show how\nsuch models can help increase the accuracy of human raters, and we provide a\ndetailed instruction on how to implement transformer-based models for one's own\npurpose.",
    "descriptor": "\nComments: 18 pages, 1 figure, 5 tables; for the associated source code, see this https URL\n",
    "authors": [
      "Sabrina Ludwig",
      "Christian Mayer",
      "Christopher Hansen",
      "Kerstin Eilers",
      "Steffen Brandt"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06874"
  },
  {
    "id": "arXiv:2110.06875",
    "title": "The core of housing markets from an agent's perspective: Is it worth  sprucing up your home?",
    "abstract": "We study housing markets as introduced by Shapley and Scarf (1974). We\ninvestigate the computational complexity of various questions regarding the\nsituation of an agent $a$ in a housing market $H$: we show that it is\n$\\mathsf{NP}$-hard to find an allocation in the core of $H$ where (i) $a$\nreceives a certain house, (ii) $a$ does not receive a certain house, or (iii)\n$a$ receives a house other than her own. We prove that the core of housing\nmarkets respects improvement in the following sense: given an allocation in the\ncore of $H$ where agent $a$ receives a house $h$, if the value of the house\nowned by $a$ increases, then the resulting housing market admits an allocation\nwhere $a$ receives either $h$, or a house that she prefers to $h$; moreover,\nsuch an allocation can be found efficiently. We further show an analogous\nresult in the Stable Roommates setting by proving that stable matchings in a\none-sided market also respect improvement.",
    "descriptor": "\nComments: 27 pages, 6 figures\n",
    "authors": [
      "Ildik\u00f3 Schlotter",
      "P\u00e9ter Bir\u00f3",
      "Tam\u00e1s Fleiner"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.06875"
  },
  {
    "id": "arXiv:2110.06877",
    "title": "A Review on Human Pose Estimation",
    "abstract": "The phenomenon of Human Pose Estimation (HPE) is a problem that has been\nexplored over the years, particularly in computer vision. But what exactly is\nit? To answer this, the concept of a pose must first be understood. Pose can be\ndefined as the arrangement of human joints in a specific manner. Therefore, we\ncan define the problem of Human Pose Estimation as the localization of human\njoints or predefined landmarks in images and videos. There are several types of\npose estimation, including body, face, and hand, as well as many aspects to it.\nThis paper will cover them, starting with the classical approaches to HPE to\nthe Deep Learning based models.",
    "descriptor": "",
    "authors": [
      "Rohit Josyula",
      "Sarah Ostadabbas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06877"
  },
  {
    "id": "arXiv:2110.06880",
    "title": "A Survey of Online Auction Mechanism Design Using Deep Learning  Approaches",
    "abstract": "Online auction has been very widespread in the recent years. Platform\nadministrators are working hard to refine their auction mechanisms that will\ngenerate high profits while maintaining a fair resource allocation. With the\nadvancement of computing technology and the bottleneck in theoretical\nframeworks, researchers are shifting gears towards online auction designs using\ndeep learning approaches. In this article, we summarized some common deep\nlearning infrastructures adopted in auction mechanism designs and showed how\nthese architectures are evolving. We also discussed how researchers are\ntackling with the constraints and concerns in the large and dynamic industrial\nsettings. Finally, we pointed out several currently unresolved issues for\nfuture directions.",
    "descriptor": "",
    "authors": [
      "Zhanhao Zhang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06880"
  },
  {
    "id": "arXiv:2110.06881",
    "title": "EPROACH: A Population Vaccination Game for Strategic Information Design  to Enable Responsible COVID Reopening",
    "abstract": "The COVID-19 lockdowns have created a significant socioeconomic impact on our\nsociety. In this paper, we propose a population vaccination game framework,\ncalled EPROACH, to design policies for reopenings that guarantee post-opening\npublic health safety. In our framework, a population of players decides whether\nto vaccinate or not based on the public and private information they receive.\nThe reopening is captured by the switching of the game state. The insights\nobtained from our framework include the appropriate vaccination coverage\nthreshold for safe-reopening and information-based methods to incentivize\nindividual vaccination decisions. In particular, our framework bridges the\nmodeling of the strategic behaviors of the populations and the spreading of\ninfectious diseases. This integration enables finding the threshold which\nguarantees a disease-free epidemic steady state under the population's Nash\nequilibrium vaccination decisions. The equilibrium vaccination decisions depend\non the information received by the agents. It makes the steady-state epidemic\nseverity controllable through information. We find out that the externalities\ncreated by reopening lead to the coordination of the rational players in the\npopulation and result in a unique Nash equilibrium. We use numerical\nexperiments to corroborate the results and illustrate the design of public\ninformation for responsible reopening.",
    "descriptor": "\nComments: 8 pages, 2 figures\n",
    "authors": [
      "Shutian Liu",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.06881"
  },
  {
    "id": "arXiv:2110.06884",
    "title": "ConditionalQA: A Complex Reading Comprehension Dataset with Conditional  Answers",
    "abstract": "We describe a Question Answering (QA) dataset that contains complex questions\nwith conditional answers, i.e. the answers are only applicable when certain\nconditions apply. We call this dataset ConditionalQA. In addition to\nconditional answers, the dataset also features: (1) long context documents with\ninformation that is related in logically complex ways; (2) multi-hop questions\nthat require compositional logical reasoning; (3) a combination of extractive\nquestions, yes/no questions, questions with multiple answers, and\nnot-answerable questions; (4) questions asked without knowing the answers. We\nshow that ConditionalQA is challenging for many of the existing QA models,\nespecially in selecting answer conditions. We believe that this dataset will\nmotivate further research in answering complex questions over long documents.\nData and leaderboard are publicly available at\n\\url{https://github.com/haitian-sun/ConditionalQA}.",
    "descriptor": "",
    "authors": [
      "Haitian Sun",
      "William W. Cohen",
      "Ruslan Salakhutdinov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06884"
  },
  {
    "id": "arXiv:2110.06886",
    "title": "Sim2Ls: FAIR simulation workflows and data",
    "abstract": "Just like the scientific data they generate, simulation workflows for\nresearch should be findable, accessible, interoperable, and reusable (FAIR).\nHowever, while significant progress has been made towards FAIR data, the\nmajority of science and engineering workflows used in research remain poorly\ndocumented and often unavailable, involving ad hoc scripts and manual steps,\nhindering reproducibility and stifling progress. We introduce Sim2Ls\n(pronounced simtools) and the Sim2L Python library that allow developers to\ncreate and share end-to-end computational workflows with well-defined and\nverified inputs and outputs. The Sim2L library makes Sim2Ls, their\nrequirements, and their services discoverable, verifies inputs and outputs, and\nautomatically stores results in a globally-accessible simulation cache and\nresults database. This simulation ecosystem is available in nanoHUB, an open\nplatform that also provides publication services for Sim2Ls, a computational\nenvironment for developers and users, and the hardware to execute runs and\nstore results at no cost. We exemplify the use of Sim2Ls using two applications\nand discuss best practices towards FAIR simulation workflows and associated\ndata.",
    "descriptor": "\nComments: 23 pages, 5 figures\n",
    "authors": [
      "Martin Hunt",
      "Steven Clark",
      "Daniel Mejia",
      "Saaketh Desai",
      "Alejandro Strachan"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2110.06886"
  },
  {
    "id": "arXiv:2110.06890",
    "title": "Extending Environments To Measure Self-Reflection In Reinforcement  Learning",
    "abstract": "We consider an extended notion of reinforcement learning in which the\nenvironment can simulate the agent and base its outputs on the agent's\nhypothetical behavior. Since good performance usually requires paying attention\nto whatever things the environment's outputs are based on, we argue that for an\nagent to achieve on-average good performance across many such extended\nenvironments, it is necessary for the agent to self-reflect. Thus, an agent's\nself-reflection ability can be numerically estimated by running the agent\nthrough a battery of extended environments. We are simultaneously releasing an\nopen-source library of extended environments to serve as proof-of-concept of\nthis technique. As the library is first-of-kind, we have avoided the difficult\nproblem of optimizing it. Instead we have chosen environments with interesting\nproperties. Some seem paradoxical, some lead to interesting thought\nexperiments, some are even suggestive of how self-reflection might have evolved\nin nature. We give examples and introduce a simple transformation which\nexperimentally seems to increase self-reflection.",
    "descriptor": "\nComments: 24 pages, 2 tables\n",
    "authors": [
      "Samuel Allen Alexander",
      "Michael Castaneda",
      "Kevin Compher",
      "Oscar Martinez"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06890"
  },
  {
    "id": "arXiv:2110.06892",
    "title": "TAG: Toward Accurate Social Media Content Tagging with a Concept Graph",
    "abstract": "Although conceptualization has been widely studied in semantics and knowledge\nrepresentation, it is still challenging to find the most accurate concept\nphrases to characterize the main idea of a text snippet on the fast-growing\nsocial media. This is partly attributed to the fact that most knowledge bases\ncontain general terms of the world, such as trees and cars, which do not have\nthe defining power or are not interesting enough to social media app users.\nAnother reason is that the intricacy of natural language allows the use of\ntense, negation and grammar to change the logic or emphasis of language, thus\nconveying completely different meanings. In this paper, we present TAG, a\nhigh-quality concept matching dataset consisting of 10,000 labeled pairs of\nfine-grained concepts and web-styled natural language sentences, mined from the\nopen-domain social media. The concepts we consider represent the trending\ninterests of online users. Associated with TAG is a concept graph of these\nfine-grained concepts and entities to provide the structural context\ninformation. We evaluate a wide range of popular neural text matching models as\nwell as pre-trained language models on TAG, and point out their insufficiency\nto tag social media content with the most appropriate concept. We further\npropose a novel graph-graph matching method that demonstrates superior\nabstraction and generalization performance by better utilizing both the\nstructural context in the concept graph and logic interactions between semantic\nunits in the sentence via syntactic dependency parsing. We open-source both the\nTAG dataset and the proposed methods to facilitate further research.",
    "descriptor": "",
    "authors": [
      "Jiuding Yang",
      "Weidong Guo",
      "Bang Liu",
      "Yakun Yu",
      "Chaoyue Wang",
      "Jinwen Luo",
      "Linglong Kong",
      "Di Niu",
      "Zhen Wen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06892"
  },
  {
    "id": "arXiv:2110.06893",
    "title": "Newer is not always better: Rethinking transferability metrics, their  peculiarities, stability and performance",
    "abstract": "Fine-tuning of large pre-trained image and language models on small\ncustomized datasets has become increasingly popular for improved prediction and\nefficient use of limited resources. Fine-tuning requires identification of best\nmodels to transfer-learn from and quantifying transferability prevents\nexpensive re-training on all of the candidate models/tasks pairs. We show that\nthe statistical problems with covariance estimation drive the poor performance\nof H-score [Bao et al., 2019] -- a common baseline for newer metrics -- and\npropose shrinkage-based estimator. This results in up to 80% absolute gain in\nH-score correlation performance, making it competitive with the\nstate-of-the-art LogME measure by You et al. [2021]. Our shrinkage-based\nH-score is 3-55 times faster to compute compared to LogME. Additionally, we\nlook into a less common setting of target (as opposed to source) task\nselection. We identify previously overlooked problems in such settings with\ndifferent number of labels, class-imbalance ratios etc. for some recent metrics\ne.g., LEEP [Nguyen et al., 2020] that resulted in them being misrepresented as\nleading measures. We propose a correction and recommend measuring correlation\nperformance against relative accuracy in such settings. We also outline the\ndifficulties of comparing feature-dependent metrics, both supervised (e.g.\nH-score) and unsupervised measures (e.g., Maximum Mean Discrepancy [Long et\nal., 2015]), across source models/layers with different feature embedding\ndimension. We show that dimensionality reduction methods allow for meaningful\ncomparison across models and improved performance of some of these measures. We\ninvestigate performance of 14 different supervised and unsupervised metrics and\ndemonstrate that even unsupervised metrics can identify the leading models for\ndomain adaptation. We support our findings with ~65,000 (fine-tuning trials)\nexperiments.",
    "descriptor": "",
    "authors": [
      "Shibal Ibrahim",
      "Natalia Ponomareva",
      "Rahul Mazumder"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06893"
  },
  {
    "id": "arXiv:2110.06894",
    "title": "Audio-Visual Scene-Aware Dialog and Reasoning using Audio-Visual  Transformers with Joint Student-Teacher Learning",
    "abstract": "In previous work, we have proposed the Audio-Visual Scene-Aware Dialog (AVSD)\ntask, collected an AVSD dataset, developed AVSD technologies, and hosted an\nAVSD challenge track at both the 7th and 8th Dialog System Technology\nChallenges (DSTC7, DSTC8). In these challenges, the best-performing systems\nrelied heavily on human-generated descriptions of the video content, which were\navailable in the datasets but would be unavailable in real-world applications.\nTo promote further advancements for real-world applications, we proposed a\nthird AVSD challenge, at DSTC10, with two modifications: 1) the human-created\ndescription is unavailable at inference time, and 2) systems must demonstrate\ntemporal reasoning by finding evidence from the video to support each answer.\nThis paper introduces the new task that includes temporal reasoning and our new\nextension of the AVSD dataset for DSTC10, for which we collected\nhuman-generated temporal reasoning data. We also introduce a baseline system\nbuilt using an AV-transformer, which we released along with the new dataset.\nFinally, this paper introduces a new system that extends our baseline system\nwith attentional multimodal fusion, joint student-teacher learning (JSTL), and\nmodel combination techniques, achieving state-of-the-art performances on the\nAVSD datasets for DSTC7, DSTC8, and DSTC10. We also propose two temporal\nreasoning methods for AVSD: one attention-based, and one based on a time-domain\nregion proposal network.",
    "descriptor": "\nComments: this https URL and this https URL\n",
    "authors": [
      "Ankit P. Shah",
      "Shijie Geng",
      "Peng Gao",
      "Anoop Cherian",
      "Takaaki Hori",
      "Tim K. Marks",
      "Jonathan Le Roux",
      "Chiori Hori"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06894"
  },
  {
    "id": "arXiv:2110.06897",
    "title": "Machine Learning For Elliptic PDEs: Fast Rate Generalization Bound,  Neural Scaling Law and Minimax Optimality",
    "abstract": "In this paper, we study the statistical limits of deep learning techniques\nfor solving elliptic partial differential equations (PDEs) from random samples\nusing the Deep Ritz Method (DRM) and Physics-Informed Neural Networks (PINNs).\nTo simplify the problem, we focus on a prototype elliptic PDE: the\nSchr\\\"odinger equation on a hypercube with zero Dirichlet boundary condition,\nwhich has wide application in the quantum-mechanical systems. We establish\nupper and lower bounds for both methods, which improves upon concurrently\ndeveloped upper bounds for this problem via a fast rate generalization bound.\nWe discover that the current Deep Ritz Methods is sub-optimal and propose a\nmodified version of it. We also prove that PINN and the modified version of DRM\ncan achieve minimax optimal bounds over Sobolev spaces. Empirically, following\nrecent work which has shown that the deep model accuracy will improve with\ngrowing training sets according to a power law, we supply computational\nexperiments to show a similar behavior of dimension dependent power law for\ndeep PDE solvers.",
    "descriptor": "",
    "authors": [
      "Yiping Lu",
      "Haoxuan Chen",
      "Jianfeng Lu",
      "Lexing Ying",
      "Jose Blanchet"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06897"
  },
  {
    "id": "arXiv:2110.06900",
    "title": "Dominant Mixed Feedback Design for Stable Oscillations",
    "abstract": "We present a design framework to induce stable oscillations through mixed\nfeedback control. We provide conditions on the feedback gain and on the balance\nbetween positive and negative feedback contributions to guarantee robust\noscillations. Using linear matrix inequalities, we later derive a systematic\ndesign for robustness to bounded dynamic uncertainties and for passive\ninterconnections. The results of the paper provide a system-theoretic\njustification to several observations from system biology and neuroscience\npointing at the mixed feedback as a fundamental enabler for robust\noscillations. Our results are illustrated through a distributed electrical\ncircuit mimicking (simplified) neural dynamics.",
    "descriptor": "",
    "authors": [
      "Weiming Che",
      "Fulvio Forni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.06900"
  },
  {
    "id": "arXiv:2110.06901",
    "title": "A Survey on Deep Learning for Skeleton-Based Human Animation",
    "abstract": "Human character animation is often critical in entertainment content\nproduction, including video games, virtual reality or fiction films. To this\nend, deep neural networks drive most recent advances through deep learning and\ndeep reinforcement learning. In this article, we propose a comprehensive survey\non the state-of-the-art approaches based on either deep learning or deep\nreinforcement learning in skeleton-based human character animation. First, we\nintroduce motion data representations, most common human motion datasets and\nhow basic deep models can be enhanced to foster learning of spatial and\ntemporal patterns in motion data. Second, we cover state-of-the-art approaches\ndivided into three large families of applications in human animation pipelines:\nmotion synthesis, character control and motion editing. Finally, we discuss the\nlimitations of the current state-of-the-art methods based on deep learning\nand/or deep reinforcement learning in skeletal human character animation and\npossible directions of future research to alleviate current limitations and\nmeet animators' needs.",
    "descriptor": "\nComments: 32 pages, 10 figures, 4 tables, to be published in COMPUTER GRAPHICS Forum (CGF)\n",
    "authors": [
      "L. Mourot",
      "L. Hoyet",
      "F. Le Clerc",
      "Fran\u00e7ois Schnitzler",
      "Pierre Hellier"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.06901"
  },
  {
    "id": "arXiv:2110.06904",
    "title": "Traceback of Data Poisoning Attacks in Neural Networks",
    "abstract": "In adversarial machine learning, new defenses against attacks on deep\nlearning systems are routinely broken soon after their release by more powerful\nattacks. In this context, forensic tools can offer a valuable complement to\nexisting defenses, by tracing back a successful attack to its root cause, and\noffering a path forward for mitigation to prevent similar attacks in the\nfuture.\nIn this paper, we describe our efforts in developing a forensic traceback\ntool for poison attacks on deep neural networks. We propose a novel iterative\nclustering and pruning solution that trims \"innocent\" training samples, until\nall that remains is the set of poisoned data responsible for the attack. Our\nmethod clusters training samples based on their impact on model parameters,\nthen uses an efficient data unlearning method to prune innocent clusters. We\nempirically demonstrate the efficacy of our system on three types of\ndirty-label (backdoor) poison attacks and three types of clean-label poison\nattacks, across domains of computer vision and malware classification. Our\nsystem achieves over 98.4% precision and 96.8% recall across all attacks. We\nalso show that our system is robust against four anti-forensics measures\nspecifically designed to attack it.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Shawn Shan",
      "Arjun Nitin Bhagoji",
      "Haitao Zheng",
      "Ben Y. Zhao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06904"
  },
  {
    "id": "arXiv:2110.06905",
    "title": "Teaching Models new APIs: Domain-Agnostic Simulators for Task Oriented  Dialogue",
    "abstract": "We demonstrate that large language models are able to simulate Task Oriented\nDialogues in novel domains, provided only with an API implementation and a list\nof goals. We show these simulations can formulate online, automatic metrics\nthat correlate well with human evaluations. Furthermore, by checking for\nwhether the User's goals are met, we can use simulation to repeatedly generate\ntraining data and improve the quality of simulations themselves. With no human\nintervention or domain-specific training data, our simulations bootstrap\nend-to-end models which achieve a 37\\% error reduction in previously unseen\ndomains. By including as few as 32 domain-specific conversations, bootstrapped\nmodels can match the performance of a fully-supervised model with $10\\times$\nmore data. To our knowledge, this is the first time simulations have been shown\nto be effective at bootstrapping models without explicitly requiring any\ndomain-specific training data, rule-engineering, or humans-in-the-loop.",
    "descriptor": "",
    "authors": [
      "Moya Chen",
      "Paul A. Crook",
      "Stephen Roller"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06905"
  },
  {
    "id": "arXiv:2110.06906",
    "title": "PER-ETD: A Polynomially Efficient Emphatic Temporal Difference Learning  Method",
    "abstract": "Emphatic temporal difference (ETD) learning (Sutton et al., 2016) is a\nsuccessful method to conduct the off-policy value function evaluation with\nfunction approximation. Although ETD has been shown to converge asymptotically\nto a desirable value function, it is well-known that ETD often encounters a\nlarge variance so that its sample complexity can increase exponentially fast\nwith the number of iterations. In this work, we propose a new ETD method,\ncalled PER-ETD (i.e., PEriodically Restarted-ETD), which restarts and updates\nthe follow-on trace only for a finite period for each iteration of the\nevaluation parameter. Further, PER-ETD features a design of the logarithmical\nincrease of the restart period with the number of iterations, which guarantees\nthe best trade-off between the variance and bias and keeps both vanishing\nsublinearly. We show that PER-ETD converges to the same desirable fixed point\nas ETD, but improves the exponential sample complexity of ETD to be\npolynomials. Our experiments validate the superior performance of PER-ETD and\nits advantage over ETD.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Ziwei Guan",
      "Tengyu Xu",
      "Yingbin Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06906"
  },
  {
    "id": "arXiv:2110.06912",
    "title": "OPEn: An Open-ended Physics Environment for Learning Without a Task",
    "abstract": "Humans have mental models that allow them to plan, experiment, and reason in\nthe physical world. How should an intelligent agent go about learning such\nmodels? In this paper, we will study if models of the world learned in an\nopen-ended physics environment, without any specific tasks, can be reused for\ndownstream physics reasoning tasks. To this end, we build a benchmark\nOpen-ended Physics ENvironment (OPEn) and also design several tasks to test\nlearning representations in this environment explicitly. This setting reflects\nthe conditions in which real agents (i.e. rolling robots) find themselves,\nwhere they may be placed in a new kind of environment and must adapt without\nany teacher to tell them how this environment works. This setting is\nchallenging because it requires solving an exploration problem in addition to a\nmodel building and representation learning problem. We test several existing\nRL-based exploration methods on this benchmark and find that an agent using\nunsupervised contrastive learning for representation learning, and\nimpact-driven learning for exploration, achieved the best results. However, all\nmodels still fall short in sample efficiency when transferring to the\ndownstream tasks. We expect that OPEn will encourage the development of novel\nrolling robot agents that can build reusable mental models of the world that\nfacilitate many tasks.",
    "descriptor": "\nComments: IROS 2021. Project page: this http URL\n",
    "authors": [
      "Chuang Gan",
      "Abhishek Bhandwaldar",
      "Antonio Torralba",
      "Joshua B. Tenenbaum",
      "Phillip Isola"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06912"
  },
  {
    "id": "arXiv:2110.06914",
    "title": "What Happens after SGD Reaches Zero Loss? --A Mathematical Framework",
    "abstract": "Understanding the implicit bias of Stochastic Gradient Descent (SGD) is one\nof the key challenges in deep learning, especially for overparametrized models,\nwhere the local minimizers of the loss function $L$ can form a manifold.\nIntuitively, with a sufficiently small learning rate $\\eta$, SGD tracks\nGradient Descent (GD) until it gets close to such manifold, where the gradient\nnoise prevents further convergence. In such a regime, Blanc et al. (2020)\nproved that SGD with label noise locally decreases a regularizer-like term, the\nsharpness of loss, $\\mathrm{tr}[\\nabla^2 L]$. The current paper gives a general\nframework for such analysis by adapting ideas from Katzenberger (1991). It\nallows in principle a complete characterization for the regularization effect\nof SGD around such manifold -- i.e., the \"implicit bias\" -- using a stochastic\ndifferential equation (SDE) describing the limiting dynamics of the parameters,\nwhich is determined jointly by the loss function and the noise covariance. This\nyields some new results: (1) a global analysis of the implicit bias valid for\n$\\eta^{-2}$ steps, in contrast to the local analysis of Blanc et al. (2020)\nthat is only valid for $\\eta^{-1.6}$ steps and (2) allowing arbitrary noise\ncovariance. As an application, we show with arbitrary large initialization,\nlabel noise SGD can always escape the kernel regime and only requires\n$O(\\kappa\\ln d)$ samples for learning an $\\kappa$-sparse overparametrized\nlinear model in $\\mathbb{R}^d$ (Woodworth et al., 2020), while GD initialized\nin the kernel regime requires $\\Omega(d)$ samples. This upper bound is minimax\noptimal and improves the previous $\\tilde{O}(\\kappa^2)$ upper bound (HaoChen et\nal., 2020).",
    "descriptor": "\nComments: 45 pages, 1 figure\n",
    "authors": [
      "Zhiyuan Li",
      "Tianhao Wang",
      "Sanjeev Arora"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06914"
  },
  {
    "id": "arXiv:2110.06915",
    "title": "Object-Region Video Transformers",
    "abstract": "Evidence from cognitive psychology suggests that understanding\nspatio-temporal object interactions and dynamics can be essential for\nrecognizing actions in complex videos. Therefore, action recognition models are\nexpected to benefit from explicit modeling of objects, including their\nappearance, interaction, and dynamics. Recently, video transformers have shown\ngreat success in video understanding, exceeding CNN performance. Yet, existing\nvideo transformer models do not explicitly model objects. In this work, we\npresent Object-Region Video Transformers (ORViT), an \\emph{object-centric}\napproach that extends video transformer layers with a block that directly\nincorporates object representations. The key idea is to fuse object-centric\nspatio-temporal representations throughout multiple transformer layers. Our\nORViT block consists of two object-level streams: appearance and dynamics. In\nthe appearance stream, an ``Object-Region Attention'' element applies\nself-attention over the patches and \\emph{object regions}. In this way, visual\nobject regions interact with uniform patch tokens and enrich them with\ncontextualized object information. We further model object dynamics via a\nseparate ``Object-Dynamics Module'', which captures trajectory interactions,\nand show how to integrate the two streams. We evaluate our model on standard\nand compositional action recognition on Something-Something V2, standard action\nrecognition on Epic-Kitchen100 and Diving48, and spatio-temporal action\ndetection on AVA. We show strong improvement in performance across all tasks\nand datasets considered, demonstrating the value of a model that incorporates\nobject representations into a transformer architecture. For code and pretrained\nmodels, visit the project page at https://roeiherz.github.io/ORViT/.",
    "descriptor": "\nComments: Tech report\n",
    "authors": [
      "Roei Herzig",
      "Elad Ben-Avraham",
      "Karttikeya Mangalam",
      "Amir Bar",
      "Gal Chechik",
      "Anna Rohrbach",
      "Trevor Darrell",
      "Amir Globerson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06915"
  },
  {
    "id": "arXiv:2110.06917",
    "title": "Extracting Dynamical Models from Data",
    "abstract": "The FJet approach is introduced for determining the underlying model of a\ndynamical system. It borrows ideas from the fields of Lie symmetries as applied\nto differential equations (DEs), and numerical integration (such as\nRunge-Kutta). The technique can be considered as a way to use machine learning\n(ML) to derive a numerical integration scheme. The technique naturally\novercomes the \"extrapolation problem\", which is when ML is used to extrapolate\na model beyond the time range of the original training data. It does this by\ndoing the modeling in the phase space of the system, rather than over the time\ndomain. When modeled with a type of regression scheme, it's possible to\naccurately determine the underlying DE, along with parameter dependencies.\nIdeas from the field of Lie symmetries applied to ordinary DEs are used to\ndetermine constants of motion, even for damped and driven systems. These\nstatements are demonstrated on three examples: a damped harmonic oscillator, a\ndamped pendulum, and a damped, driven nonlinear oscillator (Duffing\noscillator). In the model for the Duffing oscillator, it's possible to treat\nthe external force in a manner reminiscent of a Green's function approach.\nAlso, in the case of the undamped harmonic oscillator, the FJet approach\nremains stable approximately $10^9$ times longer than $4$th-order Runge-Kutta.",
    "descriptor": "\nComments: 34 pages, 20 figures\n",
    "authors": [
      "Michael F. Zimmer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06917"
  },
  {
    "id": "arXiv:2110.06918",
    "title": "Salient Phrase Aware Dense Retrieval: Can a Dense Retriever Imitate a  Sparse One?",
    "abstract": "Despite their recent popularity and well known advantages, dense retrievers\nstill lag behind sparse methods such as BM25 in their ability to reliably match\nsalient phrases and rare entities in the query. It has been argued that this is\nan inherent limitation of dense models. We disprove this claim by introducing\nthe Salient Phrase Aware Retriever (SPAR), a dense retriever with the lexical\nmatching capacity of a sparse model. In particular, we show that a dense\nretriever {\\Lambda} can be trained to imitate a sparse one, and SPAR is built\nby augmenting a standard dense retriever with {\\Lambda}. When evaluated on five\nopen-domain question answering datasets and the MS MARCO passage retrieval\ntask, SPAR sets a new state of the art for dense and sparse retrievers and can\nmatch or exceed the performance of more complicated dense-sparse hybrid\nsystems.",
    "descriptor": "",
    "authors": [
      "Xilun Chen",
      "Kushal Lakhotia",
      "Barlas O\u011fuz",
      "Anchit Gupta",
      "Patrick Lewis",
      "Stan Peshterliev",
      "Yashar Mehdad",
      "Sonal Gupta",
      "Wen-tau Yih"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06918"
  },
  {
    "id": "arXiv:2110.06920",
    "title": "Semantics-aware Attention Improves Neural Machine Translation",
    "abstract": "The integration of syntactic structures into Transformer machine translation\nhas shown positive results, but to our knowledge, no work has attempted to do\nso with semantic structures. In this work we propose two novel parameter-free\nmethods for injecting semantic information into Transformers, both rely on\nsemantics-aware masking of (some of) the attention heads. One such method\noperates on the encoder, through a Scene-Aware Self-Attention (SASA) head.\nAnother on the decoder, through a Scene-Aware Cross-Attention (SACrA) head. We\nshow a consistent improvement over the vanilla Transformer and syntax-aware\nmodels for four language pairs. We further show an additional gain when using\nboth semantic and syntactic structures in some language pairs.",
    "descriptor": "",
    "authors": [
      "Aviv Slobodkin",
      "Leshem Choshen",
      "Omri Abend"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.06920"
  },
  {
    "id": "arXiv:2110.06922",
    "title": "DETR3D: 3D Object Detection from Multi-view Images via 3D-to-2D Queries",
    "abstract": "We introduce a framework for multi-camera 3D object detection. In contrast to\nexisting works, which estimate 3D bounding boxes directly from monocular images\nor use depth prediction networks to generate input for 3D object detection from\n2D information, our method manipulates predictions directly in 3D space. Our\narchitecture extracts 2D features from multiple camera images and then uses a\nsparse set of 3D object queries to index into these 2D features, linking 3D\npositions to multi-view images using camera transformation matrices. Finally,\nour model makes a bounding box prediction per object query, using a set-to-set\nloss to measure the discrepancy between the ground-truth and the prediction.\nThis top-down approach outperforms its bottom-up counterpart in which object\nbounding box prediction follows per-pixel depth estimation, since it does not\nsuffer from the compounding error introduced by a depth prediction model.\nMoreover, our method does not require post-processing such as non-maximum\nsuppression, dramatically improving inference speed. We achieve\nstate-of-the-art performance on the nuScenes autonomous driving benchmark.",
    "descriptor": "\nComments: Accepted to CORL 2021\n",
    "authors": [
      "Yue Wang",
      "Vitor Guizilini",
      "Tianyuan Zhang",
      "Yilun Wang",
      "Hang Zhao",
      "Justin Solomon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.06922"
  },
  {
    "id": "arXiv:2110.06923",
    "title": "Object DGCNN: 3D Object Detection using Dynamic Graphs",
    "abstract": "3D object detection often involves complicated training and testing\npipelines, which require substantial domain knowledge about individual\ndatasets. Inspired by recent non-maximum suppression-free 2D object detection\nmodels, we propose a 3D object detection architecture on point clouds. Our\nmethod models 3D object detection as message passing on a dynamic graph,\ngeneralizing the DGCNN framework to predict a set of objects. In our\nconstruction, we remove the necessity of post-processing via object confidence\naggregation or non-maximum suppression. To facilitate object detection from\nsparse point clouds, we also propose a set-to-set distillation approach\ncustomized to 3D detection. This approach aligns the outputs of the teacher\nmodel and the student model in a permutation-invariant fashion, significantly\nsimplifying knowledge distillation for the 3D detection task. Our method\nachieves state-of-the-art performance on autonomous driving benchmarks. We also\nprovide abundant analysis of the detection model and distillation framework.",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Yue Wang",
      "Justin Solomon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.06923"
  },
  {
    "id": "arXiv:1007.4375",
    "title": "Quantitative spectral analysis of electromagnetic scattering. I: $ L^2$  and Hilbert-Schmidt norm bounds",
    "abstract": "We perform quantitative spectral analysis on the Born equation, an integral\nequation for electromagnetic scattering that descends from the Maxwell\nequations. We establish norm bounds for the Green operator associated with the\nBorn equation, thereby providing numerical tools for error estimates of the\nBorn approximation to light scattering problems.",
    "descriptor": "\nComments: 30 pages, 2 TikZ figures. Upgraded from part of arXiv:0911.4540v1 and arXiv:1007.4375v2, with tighter bounds on norms. (The remaining subsets of arXiv:0911.4540v1 and arXiv:1007.4375v2 are abridged into arXiv:0911.4540v4.)\n",
    "authors": [
      "Yajun Zhou"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Numerical Analysis (math.NA)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/1007.4375"
  },
  {
    "id": "arXiv:1807.11296",
    "title": "Relative kinematics of an anchorless network",
    "abstract": "Estimating the location of N coordinates in a P dimensional Euclidean space\nfrom pairwise distances (or proximity measurements), is a principal challenge\nin a wide variety of fields. Conventionally, when localizing a static network\nof immobile nodes, non-linear dimensional reduction techniques are applied on\nthe measured Euclidean distance matrix (EDM) to obtain the relative coordinates\nupto a rotation and translation. In this article, we focus on an anchorless\nnetwork of mobile nodes, where the distance measurements between the mobile\nnodes are time-varying in nature. Furthermore, in an anchorless network the\nabsolute knowledge of any node positions, motion or reference frame is absent.\nWe derive a novel data model which relates the time-varying EDMs to the\ntime-varying relative positions of an anchorless network. Using this data\nmodel, we estimate the relative position, relative velocity and higher order\nderivatives, which are collectively termed as the relative kinematics of the\nanchorless network. The derived data model is inherently ill-posed, however can\nbe solved using certain relative immobility constraints. We propose elegant\nclosed form solutions to recursively estimate the relative kinematics of the\nnetwork. For the sake of completeness, estimators are also proposed to find the\nabsolute kinematics of the nodes, given known reference anchors. Cramer-Rao\nbounds are derived for the new data model and simulations are performed to\nanalyze the performance of the proposed solutions.",
    "descriptor": "\nComments: In submission, Elsevier signal processing\n",
    "authors": [
      "Raj Thilak Rajan",
      "Geert Leus",
      "Alle-Jan van der Veen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/1807.11296"
  },
  {
    "id": "arXiv:2110.06092",
    "title": "Quantitative spectral analysis of electromagnetic scattering. II:  Evolution semigroups and non-perturbative solutions",
    "abstract": "We carry out quantitative studies on the Green operator $ \\hat{\\mathscr G}$\nassociated with the Born equation, an integral equation that models\nelectromagnetic scattering, building the strong stability of the evolution\nsemigroup $\\{\\exp(-i\\tau\\hat{\\mathscr G})|\\tau\\geq0\\} $ on polynomial\ncompactness and the Arendt-Batty-Lyubich-V\\~u theorem. The strongly-stable\nevolution semigroup inspires our proposal of a non-perturbative method to solve\nthe light scattering problem and improve the Born approximation.",
    "descriptor": "\nComments: 22 pages, 3 TikZ figures. Continuation of arXiv:1007.4375v3. Updated from Chapter 5 and Appendix D in this https URL\n",
    "authors": [
      "Yajun Zhou"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Numerical Analysis (math.NA)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2110.06092"
  },
  {
    "id": "arXiv:2110.06244",
    "title": "Congruence properties of combinatorial sequences via Walnut and the  Rowland-Yassawi-Zeilberger automaton",
    "abstract": "Certain famous combinatorial sequences, such as the Catalan numbers and the\nMotzkin numbers, when taken modulo a prime power, can be computed by finite\nautomata. Many theorems about such sequences can therefore be proved using\nWalnut, which is an implementation of a decision procedure for proving various\nproperties of automatic sequences. In this paper we explore some results (old\nand new) that can be proved using this method.",
    "descriptor": "\nComments: 14 pages, 12 figures\n",
    "authors": [
      "Narad Rampersad",
      "Jeffrey Shallit"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2110.06244"
  },
  {
    "id": "arXiv:2110.06298",
    "title": "Domain Generalization via Domain-based Covariance Minimization",
    "abstract": "Researchers have been facing a difficult problem that data generation\nmechanisms could be influenced by internal or external factors leading to the\ntraining and test data with quite different distributions, consequently\ntraditional classification or regression from the training set is unable to\nachieve satisfying results on test data. In this paper, we address this\nnontrivial domain generalization problem by finding a central subspace in which\ndomain-based covariance is minimized while the functional relationship is\nsimultaneously maximally preserved. We propose a novel variance measurement for\nmultiple domains so as to minimize the difference between conditional\ndistributions across domains with solid theoretical demonstration and supports,\nmeanwhile, the algorithm preserves the functional relationship via maximizing\nthe variance of conditional expectations given output. Furthermore, we also\nprovide a fast implementation that requires much less computation and smaller\nmemory for large-scale matrix operations, suitable for not only domain\ngeneralization but also other kernel-based eigenvalue decompositions. To show\nthe practicality of the proposed method, we compare our methods against some\nwell-known dimension reduction and domain generalization techniques on both\nsynthetic data and real-world applications. We show that for small-scale\ndatasets, we are able to achieve better quantitative results indicating better\ngeneralization performance over unseen test datasets. For large-scale problems,\nthe proposed fast implementation maintains the quantitative performance but at\na substantially lower computational cost.",
    "descriptor": "",
    "authors": [
      "Anqi Wu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06298"
  },
  {
    "id": "arXiv:2110.06304",
    "title": "Generalized Time Domain Velocity Vector",
    "abstract": "We introduce and analyze Generalized Time Domain Velocity Vector (GTVV), an\nextension of the previously presented acoustic multipath footprint extracted\nfrom the Ambisonic recordings. GTVV is better adapted to adverse acoustic\nconditions, and enables efficient parameter estimation of multiple plane wave\ncomponents in the recorded multichannel mixture. Experiments on simulated data\nconfirm the predicted theoretical advantages of these new spatio-temporal\nfeatures.",
    "descriptor": "\nComments: Submitted\n",
    "authors": [
      "Sr\u0111an Kiti\u0107",
      "J\u00e9r\u00f4me Daniel"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.06304"
  },
  {
    "id": "arXiv:2110.06305",
    "title": "An enumeration of 1-perfect ternary codes",
    "abstract": "We study codes with parameters of the ternary Hamming $(n,3^{n-m},3)$ code,\ni.e., ternary $1$-perfect codes. The rank of the code is defined as the\ndimension of its affine span. We characterize ternary $1$-perfect codes of rank\n$n-m+1$, count their number, and prove that all such codes can be obtained from\neach other by a sequence of two-coordinate switchings. We enumerate ternary\n$1$-perfect codes of length $13$ obtained by concatenation from codes of\nlengths $9$ and $4$; we find that there are $93241327$ equivalence classes of\nsuch codes. Keywords: perfect codes, ternary codes, concatenation.",
    "descriptor": "",
    "authors": [
      "Denis S. Krotov"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.06305"
  },
  {
    "id": "arXiv:2110.06306",
    "title": "Fine-grained style control in Transformer-based Text-to-speech Synthesis",
    "abstract": "In this paper, we present a novel architecture to realize fine-grained style\ncontrol on the transformer-based text-to-speech synthesis (TransformerTTS).\nSpecifically, we model the speaking style by extracting a time sequence of\nlocal style tokens (LST) from the reference speech. The existing content\nencoder in TransformerTTS is then replaced by our designed cross-attention\nblocks for fusion and alignment between content and style. As the fusion is\nperformed along with the skip connection, our cross-attention block provides a\ngood inductive bias to gradually infuse the phoneme representation with a given\nstyle. Additionally, we prevent the style embedding from encoding linguistic\ncontent by randomly truncating LST during training and using wav2vec 2.0\nfeatures. Experiments show that with fine-grained style control, our system\nperforms better in terms of naturalness, intelligibility, and style\ntransferability. Our code and samples are publicly available.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Li-Wei Chen",
      "Alexander Rudnicky"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.06306"
  },
  {
    "id": "arXiv:2110.06309",
    "title": "Exploring Wav2vec 2.0 fine-tuning for improved speech emotion  recognition",
    "abstract": "While wav2vec 2.0 has been proposed for speech recognition (ASR), it can also\nbe used for speech emotion recognition (SER); its performance can be\nsignificantly improved using different fine-tuning strategies. Two baseline\nmethods, vanilla fine-tuning (V-FT) and task adaptive pretraining (TAPT) are\nfirst presented. We show that V-FT is able to outperform state-of-the-art\nmodels on the IEMOCAP dataset. TAPT, an existing NLP fine-tuning strategy,\nfurther improves the performance on SER. We also introduce a novel fine-tuning\nmethod termed P-TAPT, which modifies the TAPT objective to learn contextualized\nemotion representations. Experiments show that P-TAPT performs better than TAPT\nespecially under low-resource settings. Compared to prior works in this\nliterature, our top-line system achieved a 7.4% absolute improvement on\nunweighted accuracy (UA) over the state-of-the-art performance on IEMOCAP. Our\ncode is publicly available.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Li-Wei Chen",
      "Alexander Rudnicky"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.06309"
  },
  {
    "id": "arXiv:2110.06325",
    "title": "As Easy as ABC: Adaptive Binning Coincidence Test for Uniformity Testing",
    "abstract": "We consider the problem of uniformity testing of Lipschitz continuous\ndistributions with bounded support. The alternative hypothesis is a composite\nset of Lipschitz continuous distributions that are at least $\\varepsilon$ away\nin $\\ell_1$ distance from the uniform distribution. We propose a sequential\ntest that adapts to the unknown distribution under the alternative hypothesis.\nReferred to as the Adaptive Binning Coincidence (ABC) test, the proposed\nstrategy adapts in two ways. First, it partitions the set of alternative\ndistributions into layers based on their distances to the uniform distribution.\nIt then sequentially eliminates the alternative distributions layer by layer in\ndecreasing distance to the uniform, and subsequently takes advantage of\nfavorable situations of a distant alternative by exiting early. Second, it\nadapts, across layers of the alternative distributions, the resolution level of\nthe discretization for computing the coincidence statistic. The farther away\nthe layer is from the uniform, the coarser the discretization is needed for\neliminating/exiting this layer. It thus exits both early in the detection\nprocess and quickly by using a lower resolution to take advantage of favorable\nalternative distributions. The ABC test builds on a novel sequential\ncoincidence test for discrete distributions, which is of independent interest.\nWe establish the sample complexity of the proposed tests as well as a lower\nbound.",
    "descriptor": "",
    "authors": [
      "Sudeep Salgia",
      "Qing Zhao",
      "Lang Tong"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06325"
  },
  {
    "id": "arXiv:2110.06339",
    "title": "Natural Computational Architectures for Cognitive Info-Communication",
    "abstract": "Recent comprehensive overview of 40 years of research in cognitive\narchitectures, (Kotseruba and Tsotsos 2020), evaluates modelling of the core\ncognitive abilities in humans, but only marginally addresses biologically\nplausible approaches based on natural computation. This mini review presents a\nset of perspectives and approaches which have shaped the development of\nbiologically inspired computational models in the recent past that can lead to\nthe development of biologically more realistic cognitive architectures. For\ndescribing continuum of natural cognitive architectures, from basal cellular to\nhuman-level cognition, we use evolutionary info-computational framework, where\nnatural/ physical/ morphological computation leads to evolution of increasingly\ncomplex cognitive systems. Forty years ago, when the first cognitive\narchitectures have been proposed, understanding of cognition, embodiment and\nevolution was different. So was the state of the art of information physics,\nbioinformatics, information chemistry, computational neuroscience, complexity\ntheory, self-organization, theory of evolution, information and computation.\nNovel developments support a constructive interdisciplinary framework for\ncognitive architectures in the context of computing nature, where interactions\nbetween constituents at different levels of organization lead to\ncomplexification of agency and increased cognitive capacities. We identify\nseveral important research questions for further investigation that can\nincrease understanding of cognition in nature and inspire new developments of\ncognitive technologies. Recently, basal cell cognition attracted a lot of\ninterest for its possible applications in medicine, new computing technologies,\nas well as micro- and nanorobotics.",
    "descriptor": "",
    "authors": [
      "Gordana Dodig-Crnkovic"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06339"
  },
  {
    "id": "arXiv:2110.06340",
    "title": "A novel framework based on deep learning and ANOVA feature selection  method for diagnosis of COVID-19 cases from chest X-ray Images",
    "abstract": "The new coronavirus (known as COVID-19) was first identified in Wuhan and\nquickly spread worldwide, wreaking havoc on the economy and people's everyday\nlives. Fever, cough, sore throat, headache, exhaustion, muscular aches, and\ndifficulty breathing are all typical symptoms of COVID-19. A reliable detection\ntechnique is needed to identify affected individuals and care for them in the\nearly stages of COVID-19 and reduce the virus's transmission. The most\naccessible method for COVID-19 identification is RT-PCR; however, due to its\ntime commitment and false-negative results, alternative options must be sought.\nIndeed, compared to RT-PCR, chest CT scans and chest X-ray images provide\nsuperior results. Because of the scarcity and high cost of CT scan equipment,\nX-ray images are preferable for screening. In this paper, a pre-trained\nnetwork, DenseNet169, was employed to extract features from X-ray images.\nFeatures were chosen by a feature selection method (ANOVA) to reduce\ncomputations and time complexity while overcoming the curse of dimensionality\nto improve predictive accuracy. Finally, selected features were classified by\nXGBoost. The ChestX-ray8 dataset, which was employed to train and evaluate the\nproposed method. This method reached 98.72% accuracy for two-class\nclassification (COVID-19, healthy) and 92% accuracy for three-class\nclassification (COVID-19, healthy, pneumonia).",
    "descriptor": "",
    "authors": [
      "Hamid Nasiri",
      "Seyyed Ali Alavi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06340"
  },
  {
    "id": "arXiv:2110.06356",
    "title": "Poncelet Parabola Pirouettes",
    "abstract": "Using graphical simulation, we observe the motion of parabolas inscribed and\ncircumscribed about certain Poncelet triangle families. In doing so one is\nsurprised by the fact that most parabolas' key objects such as vertex,\ndirectrix, focus, perspector, polar triangle, etc., will often sweep (or\nenvelop) surprisingly simple curves, such as lines, circles, points, etc. We\nrevisit some three-dozen such curious observations. Since most are without\nproof we very much welcome reader contributions.",
    "descriptor": "\nComments: 18 pages, 19 figures\n",
    "authors": [
      "Dan Reznik"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Computational Geometry (cs.CG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.06356"
  },
  {
    "id": "arXiv:2110.06357",
    "title": "Tangent Space and Dimension Estimation with the Wasserstein Distance",
    "abstract": "We provide explicit bounds on the number of sample points required to\nestimate tangent spaces and intrinsic dimensions of (smooth, compact) Euclidean\nsubmanifolds via local principal component analysis. Our approach directly\nestimates covariance matrices locally, which simultaneously allows estimating\nboth the tangent spaces and the intrinsic dimension of a manifold. The key\narguments involve a matrix concentration inequality, a Wasserstein bound for\nflattening a manifold, and a Lipschitz relation for the covariance matrix with\nrespect to the Wasserstein distance.",
    "descriptor": "",
    "authors": [
      "Uzu Lim",
      "Vidit Nanda",
      "Harald Oberhauser"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06357"
  },
  {
    "id": "arXiv:2110.06369",
    "title": "Robust Performance Analysis of Source-Seeking Dynamics with Integral  Quadratic Constraints",
    "abstract": "We analyze the performance of source-seeking dynamics involving either a\nsingle vehicle or multiple flocking-vehicles embedded in an underlying strongly\nconvex scalar field with gradient based forcing terms. For multiple vehicles\nunder flocking dynamics embedded in quadratic fields, we show that the dynamics\nof the center of mass are equivalent to the dynamics of a single agent. We\nleverage the recently developed framework of $\\alpha$-integral quadratic\nconstraints (IQCs) to obtain convergence rate estimates. We first present a\nderivation of \\textit{hard} Zames-Falb (ZF) $\\alpha$-IQCs involving general\nnon-causal multipliers based on purely time-domain arguments and show that a\nparameterization of the ZF multiplier, suggested in the literature for the\nstandard version of the ZF IQCs, can be adapted to the $\\alpha$-IQCs setting to\nobtain quasi-convex programs for estimating convergence rates. Owing to the\ntime-domain arguments, we can seamlessly extend these results to linear\nparameter varying (LPV) vehicles possibly opening the doors to non-linear\nvehicle models with quasi-LPV representations. We illustrate the theoretical\nresults on a linear time invariant (LTI) model of a quadrotor, a non-minimum\nphase LTI plant and two LPV examples which show a clear benefit of using\ngeneral non-causal dynamic multipliers to drastically reduce conservatism.",
    "descriptor": "",
    "authors": [
      "Adwait Datar",
      "Herbert Werner"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.06369"
  },
  {
    "id": "arXiv:2110.06381",
    "title": "Meta Learning Low Rank Covariance Factors for Energy-Based Deterministic  Uncertainty",
    "abstract": "Numerous recent works utilize bi-Lipschitz regularization of neural network\nlayers to preserve relative distances between data instances in the feature\nspaces of each layer. This distance sensitivity with respect to the data aids\nin tasks such as uncertainty calibration and out-of-distribution (OOD)\ndetection. In previous works, features extracted with a distance sensitive\nmodel are used to construct feature covariance matrices which are used in\ndeterministic uncertainty estimation or OOD detection. However, in cases where\nthere is a distribution over tasks, these methods result in covariances which\nare sub-optimal, as they may not leverage all of the meta information which can\nbe shared among tasks. With the use of an attentive set encoder, we propose to\nmeta learn either diagonal or diagonal plus low-rank factors to efficiently\nconstruct task specific covariance matrices. Additionally, we propose an\ninference procedure which utilizes scaled energy to achieve a final predictive\ndistribution which can better separate OOD data, and is well calibrated under a\ndistributional dataset shift.",
    "descriptor": "",
    "authors": [
      "Jeffrey Ryan Willette",
      "Hae Beom Lee",
      "Juho Lee",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06381"
  },
  {
    "id": "arXiv:2110.06390",
    "title": "Learning ground states of quantum Hamiltonians with graph networks",
    "abstract": "Solving for the lowest energy eigenstate of the many-body Schrodinger\nequation is a cornerstone problem that hinders understanding of a variety of\nquantum phenomena. The difficulty arises from the exponential nature of the\nHilbert space which casts the governing equations as an eigenvalue problem of\nexponentially large, structured matrices. Variational methods approach this\nproblem by searching for the best approximation within a lower-dimensional\nvariational manifold. In this work we use graph neural networks to define a\nstructured variational manifold and optimize its parameters to find high\nquality approximations of the lowest energy solutions on a diverse set of\nHeisenberg Hamiltonians. Using graph networks we learn distributed\nrepresentations that by construction respect underlying physical symmetries of\nthe problem and generalize to problems of larger size. Our approach achieves\nstate-of-the-art results on a set of quantum many-body benchmark problems and\nworks well on problems whose solutions are not positive-definite. The discussed\ntechniques hold promise of being a useful tool for studying quantum many-body\nsystems and providing insights into optimization and implicit modeling of\nexponentially-sized objects.",
    "descriptor": "\nComments: 19 pages, 9 figures\n",
    "authors": [
      "Dmitrii Kochkov",
      "Tobias Pfaff",
      "Alvaro Sanchez-Gonzalez",
      "Peter Battaglia",
      "Bryan K. Clark"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06390"
  },
  {
    "id": "arXiv:2110.06398",
    "title": "CovXR: Automated Detection of COVID-19 Pneumonia in Chest X-Rays through  Machine Learning",
    "abstract": "Coronavirus disease 2019 (COVID-19) is the highly contagious illness caused\nby severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The standard\ndiagnostic testing procedure for COVID-19 is testing a nasopharyngeal swab for\nSARS-CoV-2 nucleic acid using a real-time polymerase chain reaction (PCR),\nwhich can take multiple days to provide a diagnosis. Another widespread form of\ntesting is rapid antigen testing, which has a low sensitivity compared to PCR,\nbut is favored for its quick diagnosis time of usually 15-30 minutes. Patients\nwho test positive for COVID-19 demonstrate diffuse alveolar damage in 87% of\ncases. Machine learning has proven to have advantages in image classification\nproblems with radiology. In this work, we introduce CovXR as a machine learning\nmodel designed to detect COVID-19 pneumonia in chest X-rays (CXR). CovXR is a\nconvolutional neural network (CNN) trained on over 4,300 chest X-rays. The\nperformance of the model is measured through accuracy, F1 score, sensitivity,\nand specificity. The model achieves an accuracy of 95.5% and an F1 score of\n0.954. The sensitivity is 93.5% and specificity is 97.5%. With accuracy above\n95% and F1 score above 0.95, CovXR is highly accurate in predicting COVID-19\npneumonia on CXRs. The model achieves better accuracy than prior work and uses\na unique approach to identify COVID-19 pneumonia. CovXR is highly accurate in\nidentifying COVID-19 on CXRs of patients with a PCR confirmed positive\ndiagnosis and provides much faster results than PCR tests.",
    "descriptor": "\nComments: 6 pages, 7 figures\n",
    "authors": [
      "Vishal Shenoy",
      "Sachin B. Malik"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06398"
  },
  {
    "id": "arXiv:2110.06400",
    "title": "CyTran: Cycle-Consistent Transformers for Non-Contrast to Contrast CT  Translation",
    "abstract": "We propose a novel approach to translate unpaired contrast computed\ntomography (CT) scans to non-contrast CT scans and the other way around.\nSolving this task has two important applications: (i) to automatically generate\ncontrast CT scans for patients for whom injecting contrast substance is not an\noption, and (ii) to enhance alignment between contrast and non-contrast CT by\nreducing the differences induced by the contrast substance before registration.\nOur approach is based on cycle-consistent generative adversarial convolutional\ntransformers, for short, CyTran. Our neural model can be trained on unpaired\nimages, due to the integration of a cycle-consistency loss. To deal with\nhigh-resolution images, we design a hybrid architecture based on convolutional\nand multi-head attention layers. In addition, we introduce a novel data set,\nColtea-Lung-CT-100W, containing 3D triphasic lung CT scans (with a total of\n37,290 images) collected from 100 female patients. Each scan contains three\nphases (non-contrast, early portal venous, and late arterial), allowing us to\nperform experiments to compare our novel approach with state-of-the-art methods\nfor image style transfer. Our empirical results show that CyTran outperforms\nall competing methods. Moreover, we show that CyTran can be employed as a\npreliminary step to improve a state-of-the-art medical image alignment method.\nWe release our novel model and data set as open source at:\nhttps://github.com/ristea/cycle-transformer.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Nicolae-Catalin Ristea",
      "Andreea-Iuliana Miron",
      "Olivian Savencu",
      "Mariana-Iuliana Georgescu",
      "Nicolae Verga",
      "Fahad Shahbaz Khan",
      "Radu Tudor Ionescu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06400"
  },
  {
    "id": "arXiv:2110.06428",
    "title": "All-neural beamformer for continuous speech separation",
    "abstract": "Continuous speech separation (CSS) aims to separate overlapping voices from a\ncontinuous influx of conversational audio containing an unknown number of\nutterances spoken by an unknown number of speakers. A common application\nscenario is transcribing a meeting conversation recorded by a microphone array.\nPrior studies explored various deep learning models for time-frequency mask\nestimation, followed by a minimum variance distortionless response (MVDR)\nfilter to improve the automatic speech recognition (ASR) accuracy. The\nperformance of these methods is fundamentally upper-bounded by MVDR's spatial\nselectivity. Recently, the all deep learning MVDR (ADL-MVDR) model was proposed\nfor neural beamforming and demonstrated superior performance in a target speech\nextraction task using pre-segmented input. In this paper, we further adapt\nADL-MVDR to the CSS task with several enhancements to enable end-to-end neural\nbeamforming. The proposed system achieves significant word error rate reduction\nover a baseline spectral masking system on the LibriCSS dataset. Moreover, the\nproposed neural beamformer is shown to be comparable to a state-of-the-art\nMVDR-based system in real meeting transcription tasks, including AMI, while\nshowing potentials to further simplify the runtime implementation and reduce\nthe system latency with frame-wise processing.",
    "descriptor": "\nComments: 5 pages, 3 figures, 2 tables\n",
    "authors": [
      "Zhuohuang Zhang",
      "Takuya Yoshioka",
      "Naoyuki Kanda",
      "Zhuo Chen",
      "Xiaofei Wang",
      "Dongmei Wang",
      "Sefik Emre Eskimez"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.06428"
  },
  {
    "id": "arXiv:2110.06434",
    "title": "DeepA: A Deep Neural Analyzer For Speech And Singing Vocoding",
    "abstract": "Conventional vocoders are commonly used as analysis tools to provide\ninterpretable features for downstream tasks such as speech synthesis and voice\nconversion. They are built under certain assumptions about the signals\nfollowing signal processing principle, therefore, not easily generalizable to\ndifferent audio, for example, from speech to singing. In this paper, we propose\na deep neural analyzer, denoted as DeepA - a neural vocoder that extracts F0\nand timbre/aperiodicity encoding from the input speech that emulate those\ndefined in conventional vocoders. Therefore, the resulting parameters are more\ninterpretable than other latent neural representations. At the same time, as\nthe deep neural analyzer is learnable, it is expected to be more accurate for\nsignal reconstruction and manipulation, and generalizable from speech to\nsinging. The proposed neural analyzer is built based on a variational\nautoencoder (VAE) architecture. We show that DeepA improves F0 estimation over\nthe conventional vocoder (WORLD). To our best knowledge, this is the first\nstudy dedicated to the development of a neural framework for extracting\nlearnable vocoder-like parameters.",
    "descriptor": "\nComments: Accepted to ASRU 2021\n",
    "authors": [
      "Sergey Nikonorov",
      "Berrak Sisman",
      "Mingyang Zhang",
      "Haizhou Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.06434"
  },
  {
    "id": "arXiv:2110.06440",
    "title": "SDR -- Medium Rare with Fast Computations",
    "abstract": "We revisit the widely used bss eval metrics for source separation with an eye\nout for performance. We propose a fast algorithm fixing shortcomings of\npublicly available implementations. First, we show that the metrics are fully\nspecified by the squared cosine of just two angles between estimate and\nreference subspaces. Second, large linear systems are involved. However, they\nare structured, and we apply a fast iterative method based on conjugate\ngradient descent. The complexity of this step is thus reduced by a factor\nquadratic in the distortion filter size used in bss eval, usually 512. In\nexperiments, we assess speed and numerical accuracy. Not only is the loss of\naccuracy due to the approximate solver acceptable for most applications, but\nthe speed-up is up to two orders of magnitude in some, not so extreme, cases.\nWe confirm that our implementation can train neural networks, and find that\nlonger distortion filters may be beneficial.",
    "descriptor": "\nComments: 5 pages, 3 figures, 2 tables. Submitted to ICASSP 2022\n",
    "authors": [
      "Robin Scheibler"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.06440"
  },
  {
    "id": "arXiv:2110.06451",
    "title": "Maximum Entropy Differential Dynamic Programming",
    "abstract": "In this paper, we present a novel maximum entropy formulation of the\nDifferential Dynamic Programming algorithm and derive two variants using\nunimodal and multimodal value functions parameterizations. By combining the\nmaximum entropy Bellman equations with a particular approximation of the cost\nfunction, we are able to obtain a new formulation of Differential Dynamic\nProgramming which is able to escape from local minima via exploration with a\nmultimodal policy. To demonstrate the efficacy of the proposed algorithm, we\nprovide experimental results using four systems on tasks that are represented\nby cost functions with multiple local minima and compare them against vanilla\nDifferential Dynamic Programming. Furthermore, we discuss connections with\nprevious work on the linearly solvable stochastic control framework and its\nextensions in relation to compositionality.",
    "descriptor": "\nComments: Submitted to ICRA 2022. Supplementary video available at this https URL\n",
    "authors": [
      "Oswin So",
      "Ziyi Wang",
      "Evangelos A. Theodorou"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.06451"
  },
  {
    "id": "arXiv:2110.06465",
    "title": "Breaking the Dilemma of Medical Image-to-image Translation",
    "abstract": "Supervised Pix2Pix and unsupervised Cycle-consistency are two modes that\ndominate the field of medical image-to-image translation. However, neither\nmodes are ideal. The Pix2Pix mode has excellent performance. But it requires\npaired and well pixel-wise aligned images, which may not always be achievable\ndue to respiratory motion or anatomy change between times that paired images\nare acquired. The Cycle-consistency mode is less stringent with training data\nand works well on unpaired or misaligned images. But its performance may not be\noptimal. In order to break the dilemma of the existing modes, we propose a new\nunsupervised mode called RegGAN for medical image-to-image translation. It is\nbased on the theory of \"loss-correction\". In RegGAN, the misaligned target\nimages are considered as noisy labels and the generator is trained with an\nadditional registration network to fit the misaligned noise distribution\nadaptively. The goal is to search for the common optimal solution to both\nimage-to-image translation and registration tasks. We incorporated RegGAN into\na few state-of-the-art image-to-image translation methods and demonstrated that\nRegGAN could be easily combined with these methods to improve their\nperformances. Such as a simple CycleGAN in our mode surpasses latest NICEGAN\neven though using less network parameters. Based on our results, RegGAN\noutperformed both Pix2Pix on aligned data and Cycle-consistency on misaligned\nor unpaired data. RegGAN is insensitive to noises which makes it a better\nchoice for a wide range of scenarios, especially for medical image-to-image\ntranslation tasks in which well pixel-wise aligned data are not available",
    "descriptor": "",
    "authors": [
      "Lingke Kong",
      "Chenyu Lian",
      "Detian Huang",
      "Zhenjiang Li",
      "Yanle Hu",
      "Qichao Zhou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06465"
  },
  {
    "id": "arXiv:2110.06516",
    "title": "2D Multi-Class Model for Gray and White Matter Segmentation of the  Cervical Spinal Cord at 7T",
    "abstract": "The spinal cord (SC), which conveys information between the brain and the\nperipheral nervous system, plays a key role in various neurological disorders\nsuch as multiple sclerosis (MS) and amyotrophic lateral sclerosis (ALS), in\nwhich both gray matter (GM) and white matter (WM) may be impaired. While\nautomated methods for WM/GM segmentation are now largely available, these\ntechniques, developed for conventional systems (3T or lower) do not necessarily\nperform well on 7T MRI data, which feature finer details, contrasts, but also\ndifferent artifacts or signal dropout.\nThe primary goal of this study is thus to propose a new deep learning model\nthat allows robust SC/GM multi-class segmentation based on ultra-high\nresolution 7T T2*-w MR images. The second objective is to highlight the\nrelevance of implementing a specific data augmentation (DA) strategy, in\nparticular to generate a generic model that could be used for multi-center\nstudies at 7T.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Nilser J. Laines Medina",
      "Charley Gros",
      "Julien Cohen-Adad",
      "Virginie Callot",
      "Arnaud Le Troter"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06516"
  },
  {
    "id": "arXiv:2110.06527",
    "title": "Sub-Setting Algorithm for Training Data Selection in Pattern Recognition",
    "abstract": "Modern pattern recognition tasks use complex algorithms that take advantage\nof large datasets to make more accurate predictions than traditional algorithms\nsuch as decision trees or k-nearest-neighbor better suited to describe simple\nstructures. While increased accuracy is often crucial, less complexity also has\nvalue. This paper proposes a training data selection algorithm that identifies\nmultiple subsets with simple structures. A learning algorithm trained on such a\nsubset can classify an instance belonging to the subset with better accuracy\nthan the traditional learning algorithms. In other words, while existing\npattern recognition algorithms attempt to learn a global mapping function to\nrepresent the entire dataset, we argue that an ensemble of simple local\npatterns may better describe the data. Hence the sub-setting algorithm\nidentifies multiple subsets with simple local patterns by identifying similar\ninstances in the neighborhood of an instance. This motivation has similarities\nto that of gradient boosted trees but focuses on the explainability of the\nmodel that is missing for boosted trees. The proposed algorithm thus balances\naccuracy and explainable machine learning by identifying a limited number of\nsubsets with simple structures. We applied the proposed algorithm to the\ninternational stroke dataset to predict the probability of survival. Our\nbottom-up sub-setting algorithm performed on an average 15% better than the\ntop-down decision tree learned on the entire dataset. The different decision\ntrees learned on the identified subsets use some of the previously unused\nfeatures by the whole dataset decision tree, and each subset represents a\ndistinct population of data.",
    "descriptor": "\nComments: The manuscript was submitted to IEEE Transactions on Information Theory on 12th October 2021\n",
    "authors": [
      "AGaurav Arwade",
      "Sigurdur Olafsson"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06527"
  },
  {
    "id": "arXiv:2110.06546",
    "title": "A Melody-Unsupervision Model for Singing Voice Synthesis",
    "abstract": "Recent studies in singing voice synthesis have achieved high-quality results\nleveraging advances in text-to-speech models based on deep neural networks. One\nof the main issues in training singing voice synthesis models is that they\nrequire melody and lyric labels to be temporally aligned with audio data. The\ntemporal alignment is a time-exhausting manual work in preparing for the\ntraining data. To address the issue, we propose a melody-unsupervision model\nthat requires only audio-and-lyrics pairs without temporal alignment in\ntraining time but generates singing voice audio given a melody and lyrics input\nin inference time. The proposed model is composed of a phoneme classifier and a\nsinging voice generator jointly trained in an end-to-end manner. The model can\nbe fine-tuned by adjusting the amount of supervision with temporally aligned\nmelody labels. Through experiments in melody-unsupervision and semi-supervision\nsettings, we compare the audio quality of synthesized singing voice. We also\nshow that the proposed model is capable of being trained with speech audio and\ntext labels but can generate singing voice in inference time.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Soonbeom Choi",
      "Juhan Nam"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.06546"
  },
  {
    "id": "arXiv:2110.06579",
    "title": "Spectral theory for Maxwell's equations at the interface of a  metamaterial. Part II: Limiting absorption, limiting amplitude principles and  interface resonance",
    "abstract": "This paper is concerned with the time-dependent Maxwell's equations for a\nplane interface between a negative material described by the Drude model and\nthe vacuum, which fill, respectively, two complementary half-spaces. In a first\npaper, we have constructed a generalized Fourier transform which diagonalizes\nthe Hamiltonian that represents the propagation of transverse electric waves.\nIn this second paper, we use this transform to prove the limiting absorption\nand limiting amplitude principles, which concern, respectively, the behavior of\nthe resolvent near the continuous spectrum and the long time response of the\nmedium to a time-harmonic source of prescribed frequency. This paper also\nunderlines the existence of an interface resonance which occurs when there\nexists a particular frequency characterized by a ratio of permittivities and\npermeabilities equal to $-1$ across the interface. At this frequency, the\nresponse of the system to a harmonic forcing term blows up linearly in time.\nSuch a resonance is unusual for wave problem in unbounded domains and\ncorresponds to a non-zero embedded eigenvalue of infinite multiplicity of the\nunderlying operator. This is the time counterpart of the ill-posdness of the\ncorresponding harmonic problem.",
    "descriptor": "\nComments: 64 pages, 4 figures\n",
    "authors": [
      "Maxence Cassier",
      "Christophe Hazard",
      "Patrick Joly"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Mathematical Physics (math-ph)",
      "Numerical Analysis (math.NA)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.06579"
  },
  {
    "id": "arXiv:2110.06581",
    "title": "Averting A Crisis In Simulation-Based Inference",
    "abstract": "We present extensive empirical evidence showing that current Bayesian\nsimulation-based inference algorithms are inadequate for the falsificationist\nmethodology of scientific inquiry. Our results collected through months of\nexperimental computations show that all benchmarked algorithms -- (S)NPE,\n(S)NRE, SNL and variants of ABC -- may produce overconfident posterior\napproximations, which makes them demonstrably unreliable and dangerous if one's\nscientific goal is to constrain parameters of interest. We believe that failing\nto address this issue will lead to a well-founded trust crisis in\nsimulation-based inference. For this reason, we argue that research efforts\nshould now consider theoretical and methodological developments of conservative\napproximate inference algorithms and present research directions towards this\nobjective. In this regard, we show empirical evidence that ensembles are\nconsistently more reliable.",
    "descriptor": "",
    "authors": [
      "Joeri Hermans",
      "Arnaud Delaunoy",
      "Fran\u00e7ois Rozet",
      "Antoine Wehenkel",
      "Gilles Louppe"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06581"
  },
  {
    "id": "arXiv:2110.06591",
    "title": "Lifting couplings in Wasserstein spaces",
    "abstract": "This paper makes mathematically precise the idea that conditional\nprobabilities are analogous to path liftings in geometry.\nThe idea of lifting is modelled in terms of the category-theoretic concept of\na lens, which can be interpreted as a consistent choice of arrow liftings. The\ncategory we study is the one of probability measures over a given standard\nBorel space, with morphisms given by the couplings, or transport plans.\nThe geometrical picture is even more apparent once we equip the arrows of the\ncategory with weights, which one can interpret as \"lengths\" or \"costs\", forming\na so-called weighted category, which unifies several concepts of category\ntheory and metric geometry.\nIndeed, we show that the weighted version of a lens is tightly connected to\nthe notion of submetry in geometry.\nEvery weighted category gives rise to a pseudo-quasimetric space via\noptimization over the arrows. In particular, Wasserstein spaces can be obtained\nfrom the weighted categories of probability measures and their couplings, with\nthe weight of a coupling given by its cost.\nIn this case, conditionals allow one to form weighted lenses, which one can\ninterpret as \"lifting transport plans, while preserving their cost\".",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Paolo Perrone"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Logic in Computer Science (cs.LO)",
      "Metric Geometry (math.MG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2110.06591"
  },
  {
    "id": "arXiv:2110.06593",
    "title": "Clustering-Based Interpretation of Deep ReLU Network",
    "abstract": "Amongst others, the adoption of Rectified Linear Units (ReLUs) is regarded as\none of the ingredients of the success of deep learning. ReLU activation has\nbeen shown to mitigate the vanishing gradient issue, to encourage sparsity in\nthe learned parameters, and to allow for efficient backpropagation. In this\npaper, we recognize that the non-linear behavior of the ReLU function gives\nrise to a natural clustering when the pattern of active neurons is considered.\nThis observation helps to deepen the learning mechanism of the network; in\nfact, we demonstrate that, within each cluster, the network can be fully\nrepresented as an affine map. The consequence is that we are able to recover an\nexplanation, in the form of feature importance, for the predictions done by the\nnetwork to the instances belonging to the cluster. Therefore, the methodology\nwe propose is able to increase the level of interpretability of a fully\nconnected feedforward ReLU neural network, downstream from the fitting phase of\nthe model, without altering the structure of the network. A simulation study\nand the empirical application to the Titanic dataset, show the capability of\nthe method to bridge the gap between the algorithm optimization and the human\nunderstandability of the black box deep ReLU networks.",
    "descriptor": "",
    "authors": [
      "Nicola Picchiotti",
      "Marco Gori"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06593"
  },
  {
    "id": "arXiv:2110.06596",
    "title": "Logic Constraints to Feature Importances",
    "abstract": "In recent years, Artificial Intelligence (AI) algorithms have been proven to\noutperform traditional statistical methods in terms of predictivity, especially\nwhen a large amount of data was available. Nevertheless, the \"black box\" nature\nof AI models is often a limit for a reliable application in high-stakes fields\nlike diagnostic techniques, autonomous guide, etc. Recent works have shown that\nan adequate level of interpretability could enforce the more general concept of\nmodel trustworthiness. The basic idea of this paper is to exploit the human\nprior knowledge of the features' importance for a specific task, in order to\ncoherently aid the phase of the model's fitting. This sort of \"weighted\" AI is\nobtained by extending the empirical loss with a regularization term encouraging\nthe importance of the features to follow predetermined constraints. This\nprocedure relies on local methods for the feature importance computation, e.g.\nLRP, LIME, etc. that are the link between the model weights to be optimized and\nthe user-defined constraints on feature importance. In the fairness area,\npromising experimental results have been obtained for the Adult dataset. Many\nother possible applications of this model agnostic theoretical framework are\ndescribed.",
    "descriptor": "",
    "authors": [
      "Nicola Picchiotti",
      "Marco Gori"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06596"
  },
  {
    "id": "arXiv:2110.06610",
    "title": "Metaparametric Neural Networks for Survival Analysis",
    "abstract": "Survival analysis is a critical tool for the modelling of time-to-event data,\nsuch as life expectancy after a cancer diagnosis or optimal maintenance\nscheduling for complex machinery. However, current neural network models\nprovide an imperfect solution for survival analysis as they either restrict the\nshape of the target probability distribution or restrict the estimation to\npre-determined times. As a consequence, current survival neural networks lack\nthe ability to estimate a generic function without prior knowledge of its\nstructure. In this article, we present the metaparametric neural network\nframework that encompasses existing survival analysis methods and enables their\nextension to solve the aforementioned issues. This framework allows survival\nneural networks to satisfy the same independence of generic function estimation\nfrom the underlying data structure that characterizes their regression and\nclassification counterparts. Further, we demonstrate the application of the\nmetaparametric framework using both simulated and large real-world datasets and\nshow that it outperforms the current state-of-the-art methods in (i) capturing\nnonlinearities, and (ii) identifying temporal patterns, leading to more\naccurate overall estimations whilst placing no restrictions on the underlying\nfunction structure.",
    "descriptor": "",
    "authors": [
      "Fabio Luis de Mello",
      "J Mark Wilkinson",
      "Visakan Kadirkamanathan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06610"
  },
  {
    "id": "arXiv:2110.06641",
    "title": "Dictionary Learning with Convex Update (ROMD)",
    "abstract": "Dictionary learning aims to find a dictionary under which the training data\ncan be sparsely represented, and it is usually achieved by iteratively applying\ntwo stages: sparse coding and dictionary update. Typical methods for dictionary\nupdate focuses on refining both dictionary atoms and their corresponding sparse\ncoefficients by using the sparsity patterns obtained from sparse coding stage,\nand hence it is a non-convex bilinear inverse problem. In this paper, we\npropose a Rank-One Matrix Decomposition (ROMD) algorithm to recast this\nchallenge into a convex problem by resolving these two variables into a set of\nrank-one matrices. Different from methods in the literature, ROMD updates the\nwhole dictionary at a time using convex programming. The advantages hence\ninclude both convergence guarantees for dictionary update and faster\nconvergence of the whole dictionary learning. The performance of ROMD is\ncompared with other benchmark dictionary learning algorithms. The results show\nthe improvement of ROMD in recovery accuracy, especially in the cases of high\nsparsity level and fewer observation data.",
    "descriptor": "",
    "authors": [
      "Cheng Cheng",
      "Wei Dai"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06641"
  },
  {
    "id": "arXiv:2110.06691",
    "title": "Diverse Audio Captioning via Adversarial Training",
    "abstract": "Audio captioning aims at generating natural language descriptions for audio\nclips automatically. Existing audio captioning models have shown promising\nimprovement in recent years. However, these models are mostly trained via\nmaximum likelihood estimation (MLE),which tends to make captions generic,\nsimple and deterministic. As different people may describe an audio clip from\ndifferent aspects using distinct words and grammars, we argue that an audio\ncaptioning system should have the ability to generate diverse captions for a\nfixed audio clip and across similar audio clips. To address this problem, we\npropose an adversarial training framework for audio captioning based on a\nconditional generative adversarial network (C-GAN), which aims at improving the\nnaturalness and diversity of generated captions. Unlike processing data of\ncontinuous values in a classical GAN, a sentence is composed of discrete tokens\nand the discrete sampling process is non-differentiable. To address this issue,\npolicy gradient, a reinforcement learning technique, is used to back-propagate\nthe reward to the generator. The results show that our proposed model can\ngenerate more diverse captions, as compared to state-of-the-art methods.",
    "descriptor": "\nComments: 5 pages, 1 figure, submitted to ICASSP 2022\n",
    "authors": [
      "Xinhao Mei",
      "Xubo Liu",
      "Jianyuan Sun",
      "Mark D. Plumbley",
      "Wenwu Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.06691"
  },
  {
    "id": "arXiv:2110.06700",
    "title": "iRiSC: Iterative Risk Sensitive Control for Nonlinear Systems with  Imperfect Observations",
    "abstract": "This work addresses the problem of risk-sensitive control for nonlinear\nsystems with imperfect state observations, extending results for the linear\ncase. In particular, we derive an algorithm that can compute local solutions\nwith computational complexity similar to the iterative linear quadratic\nregulator algorithm. The proposed algorithm introduces feasibility gaps to\nallow the initialization with non-feasible trajectories. Moreover, an\napproximation for the expectation of the general nonlinear cost is proposed to\nenable an iterative line search solution to the planning problem. The optimal\nestimator is also derived along with the controls minimizing the general\nstochastic nonlinear cost. Finally extensive simulations are carried out to\nshow the increased robustness the proposed framework provides when compared to\nthe risk neutral iLQG counter part. To the author's best knowledge, this is the\nfirst algorithm that computes risk aware optimal controls that are a function\nof both the process noise and measurement uncertainty.",
    "descriptor": "\nComments: 8 pages, 5 figures, 3 tables\n",
    "authors": [
      "Bilal Hammoud",
      "Armand Jordana",
      "Ludovic Righetti"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.06700"
  },
  {
    "id": "arXiv:2110.06737",
    "title": "Easy-plane spin Hall nano-oscillators as spiking neurons for  neuromorphic computing",
    "abstract": "We show analytically using a macrospin approximation that easy-plane spin\nHall nano-oscillators excited by a spin-current polarized perpendicularly to\nthe easy-plane have phase dynamics analogous to that of Josephson junctions.\nSimilarly to Josephson junctions, they can reproduce the spiking behavior of\nbiological neurons that is appropriate for neuromorphic computing. We perform\nmicromagnetic simulations of such oscillators realized in the nano-constriction\ngeometry and show that the easy-plane spiking dynamics is preserved in an\nexperimentally feasible architecture. Finally we simulate two elementary neural\nnetwork blocks that implement operations essential for neuromorphic computing.\nFirst, we show that output spikes energies from two neurons can be summed and\ninjected into a following layer neuron and second, we demonstrate that outputs\ncan be multiplied by synaptic weights implemented by locally modifying the\nanisotropy.",
    "descriptor": "\nComments: 9 pages, 11 figures\n",
    "authors": [
      "Danijela Markovi\u0107",
      "Matthew W. Daniels",
      "Pankaj Sethi",
      "Andrew D. Kent",
      "Mark D. Stiles",
      "Julie Grollier"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2110.06737"
  },
  {
    "id": "arXiv:2110.06740",
    "title": "Transform and Bitstream Domain Image Classification",
    "abstract": "Classification of images within the compressed domain offers significant\nbenefits. These benefits include reduced memory and computational requirements\nof a classification system. This paper proposes two such methods as a proof of\nconcept: The first classifies within the JPEG image transform domain (i.e. DCT\ntransform data); the second classifies the JPEG compressed binary bitstream\ndirectly. These two methods are implemented using Residual Network CNNs and an\nadapted Vision Transformer. Top-1 accuracy of approximately 70% and 60% were\nachieved using these methods respectively when classifying the Caltech C101\ndatabase. Although these results are significantly behind the state of the art\nfor classification for this database (~95%), it illustrates the first time\ndirect bitstream image classification has been achieved. This work confirms\nthat direct bitstream image classification is possible and could be utilised in\na first pass database screening of a raw bitstream (within a wired or wireless\nnetwork) or where computational, memory and bandwidth requirements are severely\nrestricted.",
    "descriptor": "\nComments: 7 pages, 3 figures, one table\n",
    "authors": [
      "P.R. Hill",
      "D.R. Bull"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06740"
  },
  {
    "id": "arXiv:2110.06763",
    "title": "Efficient Estimation in NPIV Models: A Comparison of Various Neural  Networks-Based Estimators",
    "abstract": "We investigate the computational performance of Artificial Neural Networks\n(ANNs) in semi-nonparametric instrumental variables (NPIV) models of high\ndimensional covariates that are relevant to empirical work in economics. We\nfocus on efficient estimation of and inference on expectation functionals (such\nas weighted average derivatives) and use optimal criterion-based procedures\n(sieve minimum distance or SMD) and novel efficient score-based procedures\n(ES). Both these procedures use ANN to approximate the unknown function. Then,\nwe provide a detailed practitioner's recipe for implementing these two classes\nof estimators. This involves the choice of tuning parameters both for the\nunknown functions (that include conditional expectations) but also for the\nchoice of estimation of the optimal weights in SMD and the Riesz representers\nused with the ES estimators. Finally, we conduct a large set of Monte Carlo\nexperiments that compares the finite-sample performance in complicated designs\nthat involve a large set of regressors (up to 13 continuous), and various\nunderlying nonlinearities and covariate correlations. Some of the takeaways\nfrom our results include: 1) tuning and optimization are delicate especially as\nthe problem is nonconvex; 2) various architectures of the ANNs do not seem to\nmatter for the designs we consider and given proper tuning, ANN methods perform\nwell; 3) stable inferences are more difficult to achieve with ANN estimators;\n4) optimal SMD based estimators perform adequately; 5) there seems to be a gap\nbetween implementation and approximation theory. Finally, we apply ANN NPIV to\nestimate average price elasticity and average derivatives in two demand\nexamples.",
    "descriptor": "",
    "authors": [
      "Jiafeng Che",
      "Xiaohong Chen",
      "Elie Tamer"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.06763"
  },
  {
    "id": "arXiv:2110.06765",
    "title": "libdlr: Efficient imaginary time calculations using the discrete Lehmann  representation",
    "abstract": "We introduce libdlr, a library implementing the recently introduced discrete\nLehmann representation (DLR) of imaginary time Green's functions. The DLR basis\nconsists of a collection of exponentials chosen by the interpolative\ndecomposition to ensure stable and efficient recovery of Green's functions from\nimaginary time or Matsbuara frequency samples. The library provides subroutines\nto build the DLR basis and grids, and to carry out various standard operations.\nThe simplicity of the DLR makes it straightforward to incorporate into existing\ncodes as a replacement for less efficient representations of imaginary time\nGreen's functions, and libdlr is intended to facilitate this process. libdlr is\nwritten in Fortran, and contains a Python module pydlr.",
    "descriptor": "",
    "authors": [
      "Jason Kaye",
      "Hugo U. R. Strand"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Mathematical Software (cs.MS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.06765"
  },
  {
    "id": "arXiv:2110.06777",
    "title": "Incremental Ensemble Gaussian Processes",
    "abstract": "Belonging to the family of Bayesian nonparametrics, Gaussian process (GP)\nbased approaches have well-documented merits not only in learning over a rich\nclass of nonlinear functions, but also in quantifying the associated\nuncertainty. However, most GP methods rely on a single preselected kernel\nfunction, which may fall short in characterizing data samples that arrive\nsequentially in time-critical applications. To enable {\\it online} kernel\nadaptation, the present work advocates an incremental ensemble (IE-) GP\nframework, where an EGP meta-learner employs an {\\it ensemble} of GP learners,\neach having a unique kernel belonging to a prescribed kernel dictionary. With\neach GP expert leveraging the random feature-based approximation to perform\nonline prediction and model update with {\\it scalability}, the EGP meta-learner\ncapitalizes on data-adaptive weights to synthesize the per-expert predictions.\nFurther, the novel IE-GP is generalized to accommodate time-varying functions\nby modeling structured dynamics at the EGP meta-learner and within each GP\nlearner. To benchmark the performance of IE-GP and its dynamic variant in the\nadversarial setting where the modeling assumptions are violated, rigorous\nperformance analysis has been conducted via the notion of regret, as the norm\nin online convex optimization. Last but not the least, online unsupervised\nlearning for dimensionality reduction is explored under the novel IE-GP\nframework. Synthetic and real data tests demonstrate the effectiveness of the\nproposed schemes.",
    "descriptor": "",
    "authors": [
      "Qin Lu",
      "Georgios V. Karanikolas",
      "Georgios B. Giannakis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06777"
  },
  {
    "id": "arXiv:2110.06780",
    "title": "Spatially constrained direction dependent calibration",
    "abstract": "Direction dependent calibration of widefield radio interferometers estimates\nthe systematic errors along multiple directions in the sky. This is necessary\nbecause with most systematic errors that are caused by effects such as the\nionosphere or the receiver beam shape, there is significant spatial variation.\nFortunately, there is some deterministic behavior of these variations in most\nsituations. We enforce this underlying smooth spatial behavior of systematic\nerrors as an additional constraint onto spectrally constrained direction\ndependent calibration. Using both analysis and simulations, we show that this\nadditional spatial constraint improves the performance of multi-frequency\ndirection dependent calibration.",
    "descriptor": "",
    "authors": [
      "Sarod Yatawatta"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.06780"
  },
  {
    "id": "arXiv:2110.06787",
    "title": "Adapting to Dynamic LEO-B5G Systems: Meta-Critic Learning Based  Efficient Resource Scheduling",
    "abstract": "Low earth orbit (LEO) satellite-assisted communications have been considered\nas one of key elements in beyond 5G systems to provide wide coverage and\ncost-efficient data services. Such dynamic space-terrestrial topologies impose\nexponential increase in the degrees of freedom in network management. In this\npaper, we address two practical issues for an over-loaded LEO-terrestrial\nsystem. The first challenge is how to efficiently schedule resources to serve\nthe massive number of connected users, such that more data and users can be\ndelivered/served. The second challenge is how to make the algorithmic solution\nmore resilient in adapting to dynamic wireless environments.To address them, we\nfirst propose an iterative suboptimal algorithm to provide an offline\nbenchmark. To adapt to unforeseen variations, we propose an enhanced\nmeta-critic learning algorithm (EMCL), where a hybrid neural network for\nparameterization and the Wolpertinger policy for action mapping are designed in\nEMCL. The results demonstrate EMCL's effectiveness and fast-response\ncapabilities in over-loaded systems and in adapting to dynamic environments\ncompare to previous actor-critic and meta-learning methods.",
    "descriptor": "\nComments: 12 pages, 9 figures\n",
    "authors": [
      "Yaxiong Yuan",
      "Lei lei",
      "Thang X. Vu",
      "Zheng Chang",
      "Symeon Chatzinotas",
      "Sumei Sun"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06787"
  },
  {
    "id": "arXiv:2110.06840",
    "title": "The Straddling Gates Problem in Multi-partite Quantum Systems",
    "abstract": "It is well known that an arbitrary $n$-qubit quantum state $|\\Psi\\rangle$ can\nbe prepared with $\\Theta(2^n)$ two-qubit gates. In this work, we investigate\nthe task in a \"straddling gates\" scenario: consider $n$ qubits divided equally\ninto two sets and gates within each set are free; what is the least cost of\ntwo-qubit gates straddling the sets (also known as the \"binding complexity\")\nfor preparing an arbitrary quantum state, assuming no ancilla qubits allowed?\nIn this work, we give an algorithm that fulfills the task with $O(n^2 2^{n/2})$\nstraddling gates, which nearly matches the lower bound to a lower order factor.\nWe then prove any $U(2^n)$ decomposition requires no more than $O(2^{n})$\nstraddling gates. This resolves an open problem posed by Vijay Balasubramanian,\nwho was motivated by the \"Complexity=Volume\" conjecture in AdS/CFT theory.\nFurthermore, we extend our discussion to multi-partite systems, define a novel\nbinding complexity class, the \"Schmidt decomposable\" states, and give a circuit\nconstruction explanation for its unique property. Lastly, we reveal binding\ncomplexity's significance, comparing it to Von Neumann entropy as an\nentanglement measure.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Yuxuan Zhang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2110.06840"
  },
  {
    "id": "arXiv:2110.06866",
    "title": "Bayesian logistic regression for online recalibration and revision of  risk prediction models with performance guarantees",
    "abstract": "After deploying a clinical prediction model, subsequently collected data can\nbe used to fine-tune its predictions and adapt to temporal shifts. Because\nmodel updating carries risks of over-updating/fitting, we study online methods\nwith performance guarantees. We introduce two procedures for continual\nrecalibration or revision of an underlying prediction model: Bayesian logistic\nregression (BLR) and a Markov variant that explicitly models distribution\nshifts (MarBLR). We perform empirical evaluation via simulations and a\nreal-world study predicting COPD risk. We derive \"Type I and II\" regret bounds,\nwhich guarantee the procedures are non-inferior to a static model and\ncompetitive with an oracle logistic reviser in terms of the average loss. Both\nprocedures consistently outperformed the static model and other online logistic\nrevision methods. In simulations, the average estimated calibration index\n(aECI) of the original model was 0.828 (95%CI 0.818-0.938). Online\nrecalibration using BLR and MarBLR improved the aECI, attaining 0.265 (95%CI\n0.230-0.300) and 0.241 (95%CI 0.216-0.266), respectively. When performing more\nextensive logistic model revisions, BLR and MarBLR increased the average AUC\n(aAUC) from 0.767 (95%CI 0.765-0.769) to 0.800 (95%CI 0.798-0.802) and 0.799\n(95%CI 0.797-0.801), respectively, in stationary settings and protected against\nsubstantial model decay. In the COPD study, BLR and MarBLR dynamically combined\nthe original model with a continually-refitted gradient boosted tree to achieve\naAUCs of 0.924 (95%CI 0.913-0.935) and 0.925 (95%CI 0.914-0.935), compared to\nthe static model's aAUC of 0.904 (95%CI 0.892-0.916). Despite its simplicity,\nBLR is highly competitive with MarBLR. MarBLR outperforms BLR when its prior\nbetter reflects the data. BLR and MarBLR can improve the transportability of\nclinical prediction models and maintain their performance over time.",
    "descriptor": "",
    "authors": [
      "Jean Feng",
      "Alexej Gossmann",
      "Berkman Sahiner",
      "Romain Pirracchio"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.06866"
  },
  {
    "id": "arXiv:2110.06898",
    "title": "Representing Matrices Using Algebraic ZX-calculus",
    "abstract": "Elementary matrices play an important role in linear algebra applications. In\nthis paper, we represent all the elementary matrices of size 2^m\\times 2^m\nusing algebraic ZX-calculus. Then we show their properties on inverses and\ntranspose using rewriting rules of ZX-calculus. As a consequence, we are able\nto depict any matrices of size 2^m\\times 2^n by string diagrams without resort\nto a diagrammatic normal form for matrices as shown in [Wang 2020]. By doing so\nwe pave the way towards visualising by string diagrams important matrix\ntechnologies deployed in AI especially machine learning.",
    "descriptor": "\nComments: 24 pages, lots of diagrams\n",
    "authors": [
      "Quanlong Wang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06898"
  },
  {
    "id": "arXiv:2110.06909",
    "title": "Reinforcement Learning for Standards Design",
    "abstract": "Communications standards are designed via committees of humans holding\nrepeated meetings over months or even years until consensus is achieved. This\nincludes decisions regarding the modulation and coding schemes to be supported\nover an air interface. We propose a way to \"automate\" the selection of the set\nof modulation and coding schemes to be supported over a given air interface and\nthereby streamline both the standards design process and the ease of extending\nthe standard to support new modulation schemes applicable to new higher-level\napplications and services. Our scheme involves machine learning, whereby a\nconstructor entity submits proposals to an evaluator entity, which returns a\nscore for the proposal. The constructor employs reinforcement learning to\niterate on its submitted proposals until a score is achieved that was\npreviously agreed upon by both constructor and evaluator to be indicative of\nsatisfying the required design criteria (including performance metrics for\ntransmissions over the interface).",
    "descriptor": "",
    "authors": [
      "Shahrukh Khan Kasi",
      "Sayandev Mukherjee",
      "Lin Cheng",
      "Bernardo A. Huberman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.06909"
  },
  {
    "id": "arXiv:2110.06910",
    "title": "On the Double Descent of Random Features Models Trained with SGD",
    "abstract": "We study generalization properties of random features (RF) regression in high\ndimensions optimized by stochastic gradient descent (SGD). In this regime, we\nderive precise non-asymptotic error bounds of RF regression under both constant\nand adaptive step-size SGD setting, and observe the double descent phenomenon\nboth theoretically and empirically. Our analysis shows how to cope with\nmultiple randomness sources of initialization, label noise, and data sampling\n(as well as stochastic gradients) with no closed-form solution, and also goes\nbeyond the commonly-used Gaussian/spherical data assumption. Our theoretical\nresults demonstrate that, with SGD training, RF regression still generalizes\nwell for interpolation learning, and is able to characterize the double descent\nbehavior by the unimodality of variance and monotonic decrease of bias.\nBesides, we also prove that the constant step-size SGD setting incurs no loss\nin convergence rate when compared to the exact minimal-norm interpolator, as a\ntheoretical justification of using SGD in practice.",
    "descriptor": "\nComments: 37 pages, 2 figures\n",
    "authors": [
      "Fanghui Liu",
      "Johan A.K. Suykens",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06910"
  },
  {
    "id": "arXiv:2110.06924",
    "title": "Duality for Normal Lattice Expansions and Sorted, Residuated Frames with  Relations",
    "abstract": "We revisit the problem of Stone duality for lattices with various\nquasioperators, first studied in [14], presenting a fresh duality result. The\nnew result is an improvement over that of [14] in two important respects.\nFirst, the axiomatization of frames in [14] was rather cumbersome and it is now\nsimplified, partly by incorporating Gehrke's proposal [8] of section stability\nfor relations. Second, morphisms are redefined so as to preserve Galois stable\n(and co-stable) sets and we rely for this, partly again, on Goldblatt's [11]\nrecently proposed definition of bounded morphisms for polarities, though we\nneed to strengthen the definition in order to get a Stone duality result.\nIn studying the dual algebraic structures associated to polarities with\nrelations we demonstrate that stable/co-stable set operators result as the\nGalois closure of the restriction of classical (though sorted) image operators\ngenerated by the frame relations to Galois stable/co-stable sets. This provides\na proof, at the representation level, that non-distributive logics can be\nviewed as fragments of sorted, residuated (poly)modal logics, a research\ndirection initiated in [16,17].",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2109.11597\n",
    "authors": [
      "Chrysafis",
      "Hartonas"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.06924"
  },
  {
    "id": "arXiv:1712.05310",
    "title": "Quantifying over Boolean announcements",
    "abstract": "Quantifying over Boolean announcements",
    "descriptor": "",
    "authors": [
      "Hans van Ditmarsch",
      "Tim French"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/1712.05310"
  },
  {
    "id": "arXiv:1805.05585",
    "title": "A combined GDM--ELLAM--MMOC scheme for advection dominated PDEs",
    "abstract": "A combined GDM--ELLAM--MMOC scheme for advection dominated PDEs",
    "descriptor": "",
    "authors": [
      "Hanz Martin Cheng",
      "J\u00e9r\u00f4me Droniou",
      "Kim-Ngan Le"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1805.05585"
  },
  {
    "id": "arXiv:1904.11532",
    "title": "Decision Forest: A Nonparametric Approach to Modeling Irrational Choice",
    "abstract": "Comments: The paper is forthcoming in Management Science (accepted on July 25, 2021)",
    "descriptor": "\nComments: The paper is forthcoming in Management Science (accepted on July 25, 2021)\n",
    "authors": [
      "Yi-Chun Chen",
      "Velibor V. Mi\u0161i\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1904.11532"
  },
  {
    "id": "arXiv:1904.11883",
    "title": "Robust Graph Data Learning via Latent Graph Convolutional Representation",
    "abstract": "Robust Graph Data Learning via Latent Graph Convolutional Representation",
    "descriptor": "",
    "authors": [
      "Bo Jiang",
      "Ziyan Zhang",
      "Bin Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1904.11883"
  },
  {
    "id": "arXiv:1909.09505",
    "title": "Redirection Controller Using Reinforcement Learning",
    "abstract": "Comments: 16 pages, 12 figures, IEEE Access early access",
    "descriptor": "\nComments: 16 pages, 12 figures, IEEE Access early access\n",
    "authors": [
      "Yuchen Chang",
      "Keigo Matsumoto",
      "Takuji Narumi",
      "Tomohiro Tanikawa",
      "Michitaka Hirose"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/1909.09505"
  },
  {
    "id": "arXiv:1910.04091",
    "title": "Learning with minibatch Wasserstein : asymptotic and gradient properties",
    "abstract": "Learning with minibatch Wasserstein : asymptotic and gradient properties",
    "descriptor": "",
    "authors": [
      "Kilian Fatras",
      "Younes Zine",
      "R\u00e9mi Flamary",
      "R\u00e9mi Gribonval",
      "Nicolas Courty"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1910.04091"
  },
  {
    "id": "arXiv:1910.06482",
    "title": "Heterogeneous multiscale methods for rough-wall laminar viscous flow",
    "abstract": "Heterogeneous multiscale methods for rough-wall laminar viscous flow",
    "descriptor": "",
    "authors": [
      "Sean Carney",
      "Bj\u00f6rn Engquist"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1910.06482"
  },
  {
    "id": "arXiv:1910.12802",
    "title": "Model-Free Mean-Field Reinforcement Learning: Mean-Field MDP and  Mean-Field Q-Learning",
    "abstract": "Model-Free Mean-Field Reinforcement Learning: Mean-Field MDP and  Mean-Field Q-Learning",
    "descriptor": "",
    "authors": [
      "Ren\u00e9 Carmona",
      "Mathieu Lauri\u00e8re",
      "Zongjun Tan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1910.12802"
  },
  {
    "id": "arXiv:1911.01095",
    "title": "A Discontinuous Galerkin method for Shock Capturing using a mixed  high-order and sub-grid low-order approximation space",
    "abstract": "A Discontinuous Galerkin method for Shock Capturing using a mixed  high-order and sub-grid low-order approximation space",
    "descriptor": "",
    "authors": [
      "Per-Olof Persson",
      "Benjamin Stamm"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1911.01095"
  },
  {
    "id": "arXiv:2001.07417",
    "title": "Explaining Data-Driven Decisions made by AI Systems: The Counterfactual  Approach",
    "abstract": "Explaining Data-Driven Decisions made by AI Systems: The Counterfactual  Approach",
    "descriptor": "",
    "authors": [
      "Carlos Fern\u00e1ndez-Lor\u00eda",
      "Foster Provost",
      "Xintian Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2001.07417"
  },
  {
    "id": "arXiv:2002.11650",
    "title": "Contextual Search in the Presence of Irrational Agents",
    "abstract": "Comments: Compared to the first version titled \"Corrupted Multidimensional Binary Search: Learning in the Presence of Irrational Agents\", this version provides a broader scope of behavioral models of irrationality, specifies how the results apply to different loss functions, and discusses the power and limitations of additional algorithmic approaches",
    "descriptor": "\nComments: Compared to the first version titled \"Corrupted Multidimensional Binary Search: Learning in the Presence of Irrational Agents\", this version provides a broader scope of behavioral models of irrationality, specifies how the results apply to different loss functions, and discusses the power and limitations of additional algorithmic approaches\n",
    "authors": [
      "Akshay Krishnamurthy",
      "Thodoris Lykouris",
      "Chara Podimata",
      "Robert Schapire"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)",
      "General Economics (econ.GN)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.11650"
  },
  {
    "id": "arXiv:2003.05554",
    "title": "Linear-time inference for Gaussian Processes on one dimension",
    "abstract": "Comments: Accepted to JMLR",
    "descriptor": "\nComments: Accepted to JMLR\n",
    "authors": [
      "Jackson Loper",
      "David Blei",
      "John P. Cunningham",
      "Liam Paninski"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2003.05554"
  },
  {
    "id": "arXiv:2003.08707",
    "title": "Integer Ring Sieve for Constructing Compact QC-LDPC Codes with Girths 8,  10, and 12",
    "abstract": "Integer Ring Sieve for Constructing Compact QC-LDPC Codes with Girths 8,  10, and 12",
    "descriptor": "",
    "authors": [
      "Alireza Tasdighi",
      "Emmanuel Boutillon"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Group Theory (math.GR)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2003.08707"
  },
  {
    "id": "arXiv:2004.02945",
    "title": "Objectness-Aware Few-Shot Semantic Segmentation",
    "abstract": "Objectness-Aware Few-Shot Semantic Segmentation",
    "descriptor": "",
    "authors": [
      "Yinan Zhao",
      "Brian Price",
      "Scott Cohen",
      "Danna Gurari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2004.02945"
  },
  {
    "id": "arXiv:2004.10356",
    "title": "Quantifying With Only Positive Training Data",
    "abstract": "Quantifying With Only Positive Training Data",
    "descriptor": "",
    "authors": [
      "Denis dos Reis",
      "Marc\u00edlio de Souto",
      "Elaine de Sousa",
      "Gustavo Batista"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.10356"
  },
  {
    "id": "arXiv:2005.05547",
    "title": "List homomorphism problems for signed graphs",
    "abstract": "Comments: various changes + rewritten section on path- and cycle-separable graphs based on a new conference submission (split possible in future)",
    "descriptor": "\nComments: various changes + rewritten section on path- and cycle-separable graphs based on a new conference submission (split possible in future)\n",
    "authors": [
      "Jan Bok",
      "Richard Brewster",
      "Tom\u00e1s Feder",
      "Pavol Hell",
      "Nikola Jedli\u010dkov\u00e1"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2005.05547"
  },
  {
    "id": "arXiv:2005.08777",
    "title": "Sparse Signal Recovery from Phaseless Measurements via Hard Thresholding  Pursuit",
    "abstract": "Sparse Signal Recovery from Phaseless Measurements via Hard Thresholding  Pursuit",
    "descriptor": "",
    "authors": [
      "Jian-Feng Cai",
      "Jingzhi Li",
      "Xiliang Lu",
      "Juntao You"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2005.08777"
  },
  {
    "id": "arXiv:2007.04755",
    "title": "Generalized Few-Shot Video Classification with Video Retrieval and  Feature Generation",
    "abstract": "Comments: Accepted by TPAMI in October, 2021",
    "descriptor": "\nComments: Accepted by TPAMI in October, 2021\n",
    "authors": [
      "Yongqin Xian",
      "Bruno Korbar",
      "Matthijs Douze",
      "Lorenzo Torresani",
      "Bernt Schiele",
      "Zeynep Akata"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2007.04755"
  },
  {
    "id": "arXiv:2007.05975",
    "title": "A Graph Symmetrisation Bound on Channel Information Leakage under  Blowfish Privacy",
    "abstract": "Comments: 11 pages, 5 figures; accepted to IEEE Transactions on Information Theory",
    "descriptor": "\nComments: 11 pages, 5 figures; accepted to IEEE Transactions on Information Theory\n",
    "authors": [
      "Tobias Edwards",
      "Benjamin I. P. Rubinstein",
      "Zuhe Zhang",
      "Sanming Zhou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.05975"
  },
  {
    "id": "arXiv:2007.06367",
    "title": "Fast approximation by periodic kernel-based lattice-point interpolation  with application in uncertainty quantification",
    "abstract": "Comments: 37 pages, 5 figures",
    "descriptor": "\nComments: 37 pages, 5 figures\n",
    "authors": [
      "Vesa Kaarnioja",
      "Yoshihito Kazashi",
      "Frances Y. Kuo",
      "Fabio Nobile",
      "Ian H. Sloan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2007.06367"
  },
  {
    "id": "arXiv:2007.07164",
    "title": "On a combinatorial generation problem of Knuth",
    "abstract": "On a combinatorial generation problem of Knuth",
    "descriptor": "",
    "authors": [
      "Arturo Merino",
      "Ond\u0159ej Mi\u010dka",
      "Torsten M\u00fctze"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2007.07164"
  },
  {
    "id": "arXiv:2007.12131",
    "title": "BSL-1K: Scaling up co-articulated sign language recognition using  mouthing cues",
    "abstract": "Comments: Appears in: European Conference on Computer Vision 2020 (ECCV 2020). 28 pages",
    "descriptor": "\nComments: Appears in: European Conference on Computer Vision 2020 (ECCV 2020). 28 pages\n",
    "authors": [
      "Samuel Albanie",
      "G\u00fcl Varol",
      "Liliane Momeni",
      "Triantafyllos Afouras",
      "Joon Son Chung",
      "Neil Fox",
      "Andrew Zisserman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2007.12131"
  },
  {
    "id": "arXiv:2007.15562",
    "title": "Down-step statistics in generalized Dyck paths",
    "abstract": "Down-step statistics in generalized Dyck paths",
    "descriptor": "",
    "authors": [
      "Andrei Asinowski",
      "Benjamin Hackl",
      "Sarah J. Selkirk"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2007.15562"
  },
  {
    "id": "arXiv:2008.07185",
    "title": "CROW: Code Diversification for WebAssembly",
    "abstract": "CROW: Code Diversification for WebAssembly",
    "descriptor": "",
    "authors": [
      "Javier Cabrera Arteaga",
      "Orestis Malivitsis",
      "Oscar Vera P\u00e9rez",
      "Benoit Baudry",
      "Martin Monperrus"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2008.07185"
  },
  {
    "id": "arXiv:2008.12843",
    "title": "Defensive Cost-Benefit Analysis of Smart Grid Digital Functionalities",
    "abstract": "Defensive Cost-Benefit Analysis of Smart Grid Digital Functionalities",
    "descriptor": "",
    "authors": [
      "Jim Stright",
      "Peter Cheetham",
      "Charalambos Konstantinou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2008.12843"
  },
  {
    "id": "arXiv:2009.04909",
    "title": "Disjunctive Delimited Control",
    "abstract": "Comments: New version of paper is available at: arXiv:2108.02972",
    "descriptor": "\nComments: New version of paper is available at: arXiv:2108.02972\n",
    "authors": [
      "Alexander Vandenbroucke",
      "Tom Schrijvers"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2009.04909"
  },
  {
    "id": "arXiv:2009.07714",
    "title": "Calibrating Self-supervised Monocular Depth Estimation",
    "abstract": "Calibrating Self-supervised Monocular Depth Estimation",
    "descriptor": "",
    "authors": [
      "Robert McCraith",
      "Lukas Neumann",
      "Andrea Vedaldi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.07714"
  },
  {
    "id": "arXiv:2009.11958",
    "title": "Event-Driven Receding Horizon Control for Distributed Estimation in  Network Systems",
    "abstract": "Comments: Submitted to IEEE Transactions on Automatic Control",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Automatic Control\n",
    "authors": [
      "Shirantha Welikala",
      "Christos G. Cassandras"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2009.11958"
  },
  {
    "id": "arXiv:2010.01498",
    "title": "A Chirplet Transform-based Mode Retrieval Method for Multicomponent  Signals with Crossover Instantaneous Frequencies",
    "abstract": "A Chirplet Transform-based Mode Retrieval Method for Multicomponent  Signals with Crossover Instantaneous Frequencies",
    "descriptor": "",
    "authors": [
      "Lin Li",
      "Ningning Han",
      "Qingtang Jiang",
      "Charles K. Chui"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2010.01498"
  },
  {
    "id": "arXiv:2010.07899",
    "title": "Abstract Congruence Criteria for Weak Bisimilarity",
    "abstract": "Abstract Congruence Criteria for Weak Bisimilarity",
    "descriptor": "",
    "authors": [
      "Stelios Tsampas",
      "Christian Williams",
      "Andreas Nuyts",
      "Dominique Devriese",
      "Frank Piessens"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2010.07899"
  },
  {
    "id": "arXiv:2010.11638",
    "title": "\"It is just a flu\": Assessing the Effect of Watch History on YouTube's  Pseudoscientific Video Recommendations",
    "abstract": "Comments: To appear at the 16th International Conference on Web and Social Media (ICWSM 2022). Please cite the ICWSM version",
    "descriptor": "\nComments: To appear at the 16th International Conference on Web and Social Media (ICWSM 2022). Please cite the ICWSM version\n",
    "authors": [
      "Kostantinos Papadamou",
      "Savvas Zannettou",
      "Jeremy Blackburn",
      "Emiliano De Cristofaro",
      "Gianluca Stringhini",
      "Michael Sirivianos"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2010.11638"
  },
  {
    "id": "arXiv:2010.15963",
    "title": "Deep Jump Learning for Off-Policy Evaluation in Continuous Treatment  Settings",
    "abstract": "Deep Jump Learning for Off-Policy Evaluation in Continuous Treatment  Settings",
    "descriptor": "",
    "authors": [
      "Hengrui Cai",
      "Chengchun Shi",
      "Rui Song",
      "Wenbin Lu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.15963"
  },
  {
    "id": "arXiv:2011.06244",
    "title": "A Fine-grained Data Set and Analysis of Tangling in Bug Fixing Commits",
    "abstract": "Comments: Status: Accepted at Empirical Software Engineering",
    "descriptor": "\nComments: Status: Accepted at Empirical Software Engineering\n",
    "authors": [
      "Steffen Herbold",
      "Alexander Trautsch",
      "Benjamin Ledel",
      "Alireza Aghamohammadi",
      "Taher Ahmed Ghaleb",
      "Kuljit Kaur Chahal",
      "Tim Bossenmaier",
      "Bhaveet Nagaria",
      "Philip Makedonski",
      "Matin Nili Ahmadabadi",
      "Kristof Szabados",
      "Helge Spieker",
      "Matej Madeja",
      "Nathaniel Hoy",
      "Valentina Lenarduzzi",
      "Shangwen Wang",
      "Gema Rodr\u00edguez-P\u00e9rez",
      "Ricardo Colomo-Palacios",
      "Roberto Verdecchia",
      "Paramvir Singh",
      "Yihao Qin",
      "Debasish Chakroborti",
      "Willard Davis",
      "Vijay Walunj",
      "Hongjun Wu",
      "Diego Marcilio",
      "Omar Alam",
      "Abdullah Aldaeej",
      "Idan Amit",
      "Burak Turhan",
      "Simon Eismann",
      "Anna-Katharina Wickert",
      "Ivano Malavolta",
      "Matus Sulir",
      "Fatemeh Fard",
      "Austin Z. Henley",
      "Stratos Kourtzanidis",
      "Eray Tuzun",
      "Christoph Treude",
      "Simin Maleki Shamasbi",
      "Ivan Pashchenko",
      "Marvin Wyrich",
      "James Davis",
      "Alexander Serebrenik",
      "Ella Albrecht",
      "Ethem Utku Aktas"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2011.06244"
  },
  {
    "id": "arXiv:2011.12649",
    "title": "Neural Representations for Modeling Variation in Speech",
    "abstract": "Comments: Submitted to Journal of Phonetics",
    "descriptor": "\nComments: Submitted to Journal of Phonetics\n",
    "authors": [
      "Martijn Bartelds",
      "Wietse de Vries",
      "Faraz Sanal",
      "Caitlin Richter",
      "Mark Liberman",
      "Martijn Wieling"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2011.12649"
  },
  {
    "id": "arXiv:2011.12720",
    "title": "Omni: Automated Ensemble with Unexpected Models against Adversarial  Evasion Attack",
    "abstract": "Comments: Submitted to EMSE",
    "descriptor": "\nComments: Submitted to EMSE\n",
    "authors": [
      "Rui Shu",
      "Tianpei Xia",
      "Laurie Williams",
      "Tim Menzies"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.12720"
  },
  {
    "id": "arXiv:2011.14303",
    "title": "A Probabilistic Higher-order Fixpoint Logic",
    "abstract": "A Probabilistic Higher-order Fixpoint Logic",
    "descriptor": "",
    "authors": [
      "Yo Mitani",
      "Naoki Kobayashi",
      "Takeshi Tsukada"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2011.14303"
  },
  {
    "id": "arXiv:2012.06993",
    "title": "Joint Hardware Design and Capacity Analysis for Intelligent Reflecting  Surface Enabled Terahertz MIMO Communications",
    "abstract": "Joint Hardware Design and Capacity Analysis for Intelligent Reflecting  Surface Enabled Terahertz MIMO Communications",
    "descriptor": "",
    "authors": [
      "Xinying Ma",
      "Zhi Chen",
      "Longfei Yan",
      "Chong Han",
      "Qiye Wen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Emerging Technologies (cs.ET)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2012.06993"
  },
  {
    "id": "arXiv:2012.12641",
    "title": "Negation in Cognitive Reasoning",
    "abstract": "Comments: 19 pages, 5 figures, 4 tables, extended version",
    "descriptor": "\nComments: 19 pages, 5 figures, 4 tables, extended version\n",
    "authors": [
      "Claudia Schon",
      "Sophie Siebert",
      "Frieder Stolzenburg"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.12641"
  },
  {
    "id": "arXiv:2012.15461",
    "title": "Closed-Form Minkowski Sums of Convex Bodies with Smooth Positively  Curved Boundaries",
    "abstract": "Comments: 24 pages, 9 figures",
    "descriptor": "\nComments: 24 pages, 9 figures\n",
    "authors": [
      "Sipu Ruan",
      "Gregory S. Chirikjian"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Computational Geometry (cs.CG)",
      "Graphics (cs.GR)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2012.15461"
  },
  {
    "id": "arXiv:2101.03308",
    "title": "A Reconfigurable Convolution-in-Pixel CMOS Image Sensor Architecture",
    "abstract": "A Reconfigurable Convolution-in-Pixel CMOS Image Sensor Architecture",
    "descriptor": "",
    "authors": [
      "Ruibing Song",
      "Kejie Huang",
      "Zongsheng Wang",
      "Haibin Shen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.03308"
  },
  {
    "id": "arXiv:2101.07140",
    "title": "Specifying and Interpreting Reinforcement Learning Policies through  Simulatable Machine Learning",
    "abstract": "Specifying and Interpreting Reinforcement Learning Policies through  Simulatable Machine Learning",
    "descriptor": "",
    "authors": [
      "Pradyumna Tambwekar",
      "Andrew Silva",
      "Nakul Gopalan",
      "Matthew Gombolay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2101.07140"
  },
  {
    "id": "arXiv:2101.08490",
    "title": "Estimating Average Treatment Effects via Orthogonal Regularization",
    "abstract": "Estimating Average Treatment Effects via Orthogonal Regularization",
    "descriptor": "",
    "authors": [
      "Tobias Hatt",
      "Stefan Feuerriegel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2101.08490"
  },
  {
    "id": "arXiv:2101.11189",
    "title": "Arbitrary-Oriented Ship Detection through Center-Head Point Extraction",
    "abstract": "Comments: Accepted by IEEE Transactions on Geoscience and Remote Sensing (TGRS)",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Geoscience and Remote Sensing (TGRS)\n",
    "authors": [
      "Feng Zhang",
      "Xueying Wang",
      "Shilin Zhou",
      "Yingqian Wang",
      "Yi Hou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.11189"
  },
  {
    "id": "arXiv:2101.12704",
    "title": "Federated Learning over Wireless Device-to-Device Networks: Algorithms  and Convergence Analysis",
    "abstract": "Comments: 46 pages, 9 figures, to appear in IEEE J. Sel. Areas Commun",
    "descriptor": "\nComments: 46 pages, 9 figures, to appear in IEEE J. Sel. Areas Commun\n",
    "authors": [
      "Hong Xing",
      "Osvaldo Simeone",
      "Suzhi Bi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2101.12704"
  },
  {
    "id": "arXiv:2102.01163",
    "title": "Visual Framing of Science Conspiracy Videos: Integrating Machine  Learning with Communication Theories to Study the Use of Color and Brightness",
    "abstract": "Visual Framing of Science Conspiracy Videos: Integrating Machine  Learning with Communication Theories to Study the Use of Color and Brightness",
    "descriptor": "",
    "authors": [
      "Kaiping Chen",
      "Sang Jung Kim",
      "Qiantong Gao",
      "Sebastian Raschka"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.01163"
  },
  {
    "id": "arXiv:2102.03044",
    "title": "Smart Proofs via Smart Contracts: Succinct and Informative Mathematical  Derivations via Decentralized Markets",
    "abstract": "Comments: 45 pages, 12 figures",
    "descriptor": "\nComments: 45 pages, 12 figures\n",
    "authors": [
      "Sylvain Carr\u00e9",
      "Franck Gabriel",
      "Cl\u00e9ment Hongler",
      "Gustavo Lacerda",
      "Gloria Capano"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computation and Language (cs.CL)",
      "Logic in Computer Science (cs.LO)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2102.03044"
  },
  {
    "id": "arXiv:2102.07007",
    "title": "A Statistical Relational Approach to Learning Distance-based GCNs",
    "abstract": "Comments: 8 pages, 5 figures, 4 tables; accepted to STARAI workshop",
    "descriptor": "\nComments: 8 pages, 5 figures, 4 tables; accepted to STARAI workshop\n",
    "authors": [
      "Devendra Singh Dhami",
      "Siwen Yan",
      "Sriraam Natarajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.07007"
  },
  {
    "id": "arXiv:2102.08173",
    "title": "About Weighted Random Sampling in Preferential Attachment Models",
    "abstract": "About Weighted Random Sampling in Preferential Attachment Models",
    "descriptor": "",
    "authors": [
      "Giorgos Stamatelatos",
      "Pavlos S. Efraimidis"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2102.08173"
  },
  {
    "id": "arXiv:2102.09490",
    "title": "Mean-Based Trace Reconstruction over Oblivious Synchronization Channels",
    "abstract": "Comments: 18 pages",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Mahdi Cheraghchi",
      "Joseph Downs",
      "Jo\u00e3o Ribeiro",
      "Alexandra Veliche"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2102.09490"
  },
  {
    "id": "arXiv:2102.09583",
    "title": "Encoding Frequency Constraints in Preventive Unit Commitment Using Deep  Learning with Region-of-Interest Active Sampling",
    "abstract": "Encoding Frequency Constraints in Preventive Unit Commitment Using Deep  Learning with Region-of-Interest Active Sampling",
    "descriptor": "",
    "authors": [
      "Yichen Zhang",
      "Hantao Cui",
      "Jianzhe Liu",
      "Feng Qiu",
      "Tianqi Hong",
      "Rui Yao",
      "Fangxing Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.09583"
  },
  {
    "id": "arXiv:2102.10226",
    "title": "ALMA: Alternating Minimization Algorithm for Clustering Mixture  Multilayer Network",
    "abstract": "ALMA: Alternating Minimization Algorithm for Clustering Mixture  Multilayer Network",
    "descriptor": "",
    "authors": [
      "Xing Fan",
      "Marianna Pensky",
      "Feng Yu",
      "Teng Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2102.10226"
  },
  {
    "id": "arXiv:2102.13027",
    "title": "A Survey of RDF Stores & SPARQL Engines for Querying Knowledge Graphs",
    "abstract": "Comments: This version adds 15 more systems, more details on approaches for processing property paths, as well as some other minor changes",
    "descriptor": "\nComments: This version adds 15 more systems, more details on approaches for processing property paths, as well as some other minor changes\n",
    "authors": [
      "Waqas Ali",
      "Muhammad Saleem",
      "Bin Yao",
      "Aidan Hogan",
      "Axel-Cyrille Ngonga Ngomo"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2102.13027"
  },
  {
    "id": "arXiv:2103.03125",
    "title": "Advances in Multi-turn Dialogue Comprehension: A Survey",
    "abstract": "Advances in Multi-turn Dialogue Comprehension: A Survey",
    "descriptor": "",
    "authors": [
      "Zhuosheng Zhang",
      "Hai Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2103.03125"
  },
  {
    "id": "arXiv:2103.03571",
    "title": "Cycle Self-Training for Domain Adaptation",
    "abstract": "Cycle Self-Training for Domain Adaptation",
    "descriptor": "",
    "authors": [
      "Hong Liu",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.03571"
  },
  {
    "id": "arXiv:2103.03716",
    "title": "Golem: An algorithm for robust experiment and process optimization",
    "abstract": "Comments: 37 pages, 25 figures; additional experiments, expanded discussions and references",
    "descriptor": "\nComments: 37 pages, 25 figures; additional experiments, expanded discussions and references\n",
    "authors": [
      "Matteo Aldeghi",
      "Florian H\u00e4se",
      "Riley J. Hickman",
      "Isaac Tamblyn",
      "Al\u00e1n Aspuru-Guzik"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2103.03716"
  },
  {
    "id": "arXiv:2103.06376",
    "title": "Functional Collection Programming with Semi-Ring Dictionaries",
    "abstract": "Functional Collection Programming with Semi-Ring Dictionaries",
    "descriptor": "",
    "authors": [
      "Amir Shaikhha",
      "Mathieu Huot",
      "Jaclyn Smith",
      "Dan Olteanu"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.06376"
  },
  {
    "id": "arXiv:2103.06406",
    "title": "Distributed Principal Subspace Analysis for Partitioned Big Data:  Algorithms, Analysis, and Implementation",
    "abstract": "Comments: 16 pages; Final accepted version; To appear in IEEE Transactions on Signal and Information Processing Over Networks",
    "descriptor": "\nComments: 16 pages; Final accepted version; To appear in IEEE Transactions on Signal and Information Processing Over Networks\n",
    "authors": [
      "Arpita Gang",
      "Bingqing Xiang",
      "Waheed U. Bajwa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2103.06406"
  },
  {
    "id": "arXiv:2103.11783",
    "title": "Various variational approximations of quantum dynamics",
    "abstract": "Comments: 27 pages",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Caroline Lasser",
      "Chunmei Su"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.11783"
  },
  {
    "id": "arXiv:2103.12692",
    "title": "Benign Overfitting of Constant-Stepsize SGD for Linear Regression",
    "abstract": "Comments: 56 pages, 2 figures. A short version is accepted at the 34th Annual Conference on Learning Theory (COLT 2021)",
    "descriptor": "\nComments: 56 pages, 2 figures. A short version is accepted at the 34th Annual Conference on Learning Theory (COLT 2021)\n",
    "authors": [
      "Difan Zou",
      "Jingfeng Wu",
      "Vladimir Braverman",
      "Quanquan Gu",
      "Sham M. Kakade"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.12692"
  },
  {
    "id": "arXiv:2103.14699",
    "title": "SkyQuery: An Aerial Drone Video Sensing Platform",
    "abstract": "Comments: Onward! 2021",
    "descriptor": "\nComments: Onward! 2021\n",
    "authors": [
      "Favyen Bastani",
      "Songtao He",
      "Ziwen Jiang",
      "Osbert Bastani",
      "Sam Madden"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2103.14699"
  },
  {
    "id": "arXiv:2103.15584",
    "title": "Busy-Quiet Video Disentangling for Video Classification",
    "abstract": "Busy-Quiet Video Disentangling for Video Classification",
    "descriptor": "",
    "authors": [
      "Guoxi Huang",
      "Adrian G. Bors"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.15584"
  },
  {
    "id": "arXiv:2103.15718",
    "title": "von Mises-Fisher Loss: An Exploration of Embedding Geometries for  Supervised Learning",
    "abstract": "Comments: ICCV 2021",
    "descriptor": "\nComments: ICCV 2021\n",
    "authors": [
      "Tyler R. Scott",
      "Andrew C. Gallagher",
      "Michael C. Mozer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.15718"
  },
  {
    "id": "arXiv:2103.16317",
    "title": "Deep Regression on Manifolds: A 3D Rotation Case Study",
    "abstract": "Comments: Oral presentation at 3DV 2021",
    "descriptor": "\nComments: Oral presentation at 3DV 2021\n",
    "authors": [
      "Romain Br\u00e9gier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.16317"
  },
  {
    "id": "arXiv:2104.02939",
    "title": "OpenGAN: Open-Set Recognition via Open Data Generation",
    "abstract": "Comments: ICCV 2021 Best Paper Honorable Mention",
    "descriptor": "\nComments: ICCV 2021 Best Paper Honorable Mention\n",
    "authors": [
      "Shu Kong",
      "Deva Ramanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.02939"
  },
  {
    "id": "arXiv:2104.05485",
    "title": "Predicting Pedestrian Crossing Intention with Feature Fusion and  Spatio-Temporal Attention",
    "abstract": "Comments: Submitted to IEEE Transactions on Intelligent Vehicles",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Intelligent Vehicles\n",
    "authors": [
      "Dongfang Yang",
      "Haolin Zhang",
      "Ekim Yurtsever",
      "Keith Redmill",
      "\u00dcmit \u00d6zg\u00fcner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.05485"
  },
  {
    "id": "arXiv:2104.05608",
    "title": "Equivariant geometric learning for digital rock physics: estimating  formation factor and effective permeability tensors from Morse graph",
    "abstract": "Equivariant geometric learning for digital rock physics: estimating  formation factor and effective permeability tensors from Morse graph",
    "descriptor": "",
    "authors": [
      "Chen Cai",
      "Nikolaos Vlassis",
      "Lucas Magee",
      "Ran Ma",
      "Zeyu Xiong",
      "Bahador Bahmani",
      "Teng-Fong Wong",
      "Yusu Wang",
      "WaiChing Sun"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.05608"
  },
  {
    "id": "arXiv:2104.07980",
    "title": "Performance Comparison Between A Simple Full-Duplex Multi-Antenna Relay  And A Passive Intelligent Reflecting Surface",
    "abstract": "Performance Comparison Between A Simple Full-Duplex Multi-Antenna Relay  And A Passive Intelligent Reflecting Surface",
    "descriptor": "",
    "authors": [
      "Armin Bazrafkan",
      "Marija Poposka",
      "Zoran Hadzi-Velkov",
      "Nikola Zlatanov"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2104.07980"
  },
  {
    "id": "arXiv:2104.08161",
    "title": "Back to Square One: Artifact Detection, Training and Commonsense  Disentanglement in the Winograd Schema",
    "abstract": "Comments: Accepted to EMNLP 2021",
    "descriptor": "\nComments: Accepted to EMNLP 2021\n",
    "authors": [
      "Yanai Elazar",
      "Hongming Zhang",
      "Yoav Goldberg",
      "Dan Roth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08161"
  },
  {
    "id": "arXiv:2104.09323",
    "title": "Sequential Deconfounding for Causal Inference with Unobserved  Confounders",
    "abstract": "Sequential Deconfounding for Causal Inference with Unobserved  Confounders",
    "descriptor": "",
    "authors": [
      "Tobias Hatt",
      "Stefan Feuerriegel"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.09323"
  },
  {
    "id": "arXiv:2104.10146",
    "title": "Linear PDE with Constant Coefficients",
    "abstract": "Comments: 31 pages, 1 figure",
    "descriptor": "\nComments: 31 pages, 1 figure\n",
    "authors": [
      "Rida Ait El Manssour",
      "Marc H\u00e4rk\u00f6nen",
      "Bernd Sturmfels"
    ],
    "subjectives": [
      "Commutative Algebra (math.AC)",
      "Symbolic Computation (cs.SC)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2104.10146"
  },
  {
    "id": "arXiv:2104.11914",
    "title": "EXplainable Neural-Symbolic Learning (X-NeSyL) methodology to fuse deep  learning representations with expert knowledge graphs: the MonuMAI cultural  heritage use case",
    "abstract": "EXplainable Neural-Symbolic Learning (X-NeSyL) methodology to fuse deep  learning representations with expert knowledge graphs: the MonuMAI cultural  heritage use case",
    "descriptor": "",
    "authors": [
      "Natalia D\u00edaz-Rodr\u00edguez",
      "Alberto Lamas",
      "Jules Sanchez",
      "Gianni Franchi",
      "Ivan Donadello",
      "Siham Tabik",
      "David Filliat",
      "Policarpo Cruz",
      "Rosana Montes",
      "Francisco Herrera"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2104.11914"
  },
  {
    "id": "arXiv:2104.13754",
    "title": "Can crowdsourcing rescue the social marketplace of ideas?",
    "abstract": "Comments: Under Review - revision 2",
    "descriptor": "\nComments: Under Review - revision 2\n",
    "authors": [
      "Taha Yasseri",
      "Filippo Menczer"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2104.13754"
  },
  {
    "id": "arXiv:2104.13764",
    "title": "Segmentation-Based Bounding Box Generation for Omnidirectional  Pedestrian Detection",
    "abstract": "Comments: Pre-print submitted to Journal of Multimedia Tools and Applications",
    "descriptor": "\nComments: Pre-print submitted to Journal of Multimedia Tools and Applications\n",
    "authors": [
      "Masato Tamura",
      "Tomoaki Yoshinaga"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.13764"
  },
  {
    "id": "arXiv:2104.13921",
    "title": "Open-vocabulary Object Detection via Vision and Language Knowledge  Distillation",
    "abstract": "Open-vocabulary Object Detection via Vision and Language Knowledge  Distillation",
    "descriptor": "",
    "authors": [
      "Xiuye Gu",
      "Tsung-Yi Lin",
      "Weicheng Kuo",
      "Yin Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.13921"
  },
  {
    "id": "arXiv:2104.14873",
    "title": "Robust joint registration of multiple stains and MRI for multimodal 3D  histology reconstruction: Application to the Allen human brain atlas",
    "abstract": "Comments: Medical Image Analysis (Accepted on 07/10/2021). 22 pages, 11 figures,",
    "descriptor": "\nComments: Medical Image Analysis (Accepted on 07/10/2021). 22 pages, 11 figures,\n",
    "authors": [
      "Adri\u00e0 Casamitjana",
      "Marco Lorenzi",
      "Sebastiano Ferraris",
      "Loc Peter",
      "Marc Modat",
      "Allison Stevens",
      "Bruce Fischl",
      "Tom Vercauteren",
      "Juan Eugenio Iglesias"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.14873"
  },
  {
    "id": "arXiv:2105.00108",
    "title": "Explaining a Series of Models by Propagating Shapley Values",
    "abstract": "Explaining a Series of Models by Propagating Shapley Values",
    "descriptor": "",
    "authors": [
      "Hugh Chen",
      "Scott M. Lundberg",
      "Su-In Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.00108"
  },
  {
    "id": "arXiv:2105.00329",
    "title": "ECNNs: Ensemble Learning Methods for Improving Planar Grasp Quality  Estimation",
    "abstract": "Comments: Accepted in: 2021 IEEE International Conference on Robotics and Automation (ICRA)",
    "descriptor": "\nComments: Accepted in: 2021 IEEE International Conference on Robotics and Automation (ICRA)\n",
    "authors": [
      "Fadi Alladkani",
      "James Akl",
      "Berk Calli"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.00329"
  },
  {
    "id": "arXiv:2105.00931",
    "title": "GridToPix: Training Embodied Agents with Minimal Supervision",
    "abstract": "Comments: Project page: this https URL ; last two authors contributed equally",
    "descriptor": "\nComments: Project page: this https URL ; last two authors contributed equally\n",
    "authors": [
      "Unnat Jain",
      "Iou-Jen Liu",
      "Svetlana Lazebnik",
      "Aniruddha Kembhavi",
      "Luca Weihs",
      "Alexander Schwing"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2105.00931"
  },
  {
    "id": "arXiv:2105.02544",
    "title": "SGG: Learning to Select, Guide, and Generate for Keyphrase Generation",
    "abstract": "Comments: 10 pages, 4 figures, accepted by NAACL2021",
    "descriptor": "\nComments: 10 pages, 4 figures, accepted by NAACL2021\n",
    "authors": [
      "Jing Zhao",
      "Junwei Bao",
      "Yifan Wang",
      "Youzheng Wu",
      "Xiaodong He",
      "Bowen Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.02544"
  },
  {
    "id": "arXiv:2105.05991",
    "title": "Improving Code Autocompletion with Transfer Learning",
    "abstract": "Improving Code Autocompletion with Transfer Learning",
    "descriptor": "",
    "authors": [
      "Wen Zhou",
      "Seohyun Kim",
      "Vijayaraghavan Murali",
      "Gareth Ari Aye"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.05991"
  },
  {
    "id": "arXiv:2105.07508",
    "title": "Abstraction, Validation, and Generalization for Explainable Artificial  Intelligence",
    "abstract": "Abstraction, Validation, and Generalization for Explainable Artificial  Intelligence",
    "descriptor": "",
    "authors": [
      "Scott Cheng-Hsin Yang",
      "Tomas Folke",
      "Patrick Shafto"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.07508"
  },
  {
    "id": "arXiv:2105.08708",
    "title": "A Spatial Logic for a Simplicial Complex Model",
    "abstract": "A Spatial Logic for a Simplicial Complex Model",
    "descriptor": "",
    "authors": [
      "Michele Loreti",
      "Michela Quadrini"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.08708"
  },
  {
    "id": "arXiv:2105.09987",
    "title": "Temporal convolutional networks predict dynamic oxygen uptake response  from wearable sensors across exercise intensities",
    "abstract": "Temporal convolutional networks predict dynamic oxygen uptake response  from wearable sensors across exercise intensities",
    "descriptor": "",
    "authors": [
      "Robert Amelard",
      "Eric T Hedge",
      "Richard L Hughson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.09987"
  },
  {
    "id": "arXiv:2105.10130",
    "title": "Convergence of a spatial semi-discretization for a backward semilinear  stochastic parabolic equation",
    "abstract": "Convergence of a spatial semi-discretization for a backward semilinear  stochastic parabolic equation",
    "descriptor": "",
    "authors": [
      "Binjie Li",
      "Xiaoping Xie"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.10130"
  },
  {
    "id": "arXiv:2105.12954",
    "title": "Better Regularization for Sequential Decision Spaces: Fast Convergence  Rates for Nash, Correlated, and Team Equilibria",
    "abstract": "Comments: Extended version of the EC21 conference version",
    "descriptor": "\nComments: Extended version of the EC21 conference version\n",
    "authors": [
      "Gabriele Farina",
      "Christian Kroer",
      "Tuomas Sandholm"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.12954"
  },
  {
    "id": "arXiv:2105.13389",
    "title": "GPS-Based Geolocation of Consumer IP Addresses",
    "abstract": "GPS-Based Geolocation of Consumer IP Addresses",
    "descriptor": "",
    "authors": [
      "James Saxon",
      "Nick Feamster"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.13389"
  },
  {
    "id": "arXiv:2106.01262",
    "title": "End-To-End Deep Learning-Based Adaptation Control for Frequency-Domain  Adaptive System Identification",
    "abstract": "End-To-End Deep Learning-Based Adaptation Control for Frequency-Domain  Adaptive System Identification",
    "descriptor": "",
    "authors": [
      "Thomas Haubner",
      "Andreas Brendel",
      "Walter Kellermann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.01262"
  },
  {
    "id": "arXiv:2106.02026",
    "title": "Breaking the Cubic Barrier for (Unweighted) Tree Edit Distance",
    "abstract": "Comments: Accepted to FOCS'21",
    "descriptor": "\nComments: Accepted to FOCS'21\n",
    "authors": [
      "Xiao Mao"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.02026"
  },
  {
    "id": "arXiv:2106.02542",
    "title": "Heterogeneous Wasserstein Discrepancy for Incomparable Distributions",
    "abstract": "Heterogeneous Wasserstein Discrepancy for Incomparable Distributions",
    "descriptor": "",
    "authors": [
      "Mokhtar Z. Alaya",
      "Gilles Gasso",
      "Maxime Berar",
      "Alain Rakotomamonjy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02542"
  },
  {
    "id": "arXiv:2106.03352",
    "title": "The Power of Exploiter: Provable Multi-Agent RL in Large State Spaces",
    "abstract": "The Power of Exploiter: Provable Multi-Agent RL in Large State Spaces",
    "descriptor": "",
    "authors": [
      "Chi Jin",
      "Qinghua Liu",
      "Tiancheng Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.03352"
  },
  {
    "id": "arXiv:2106.05194",
    "title": "DIGRAC: Digraph Clustering Based on Flow Imbalance",
    "abstract": "Comments: 36 pages (10 pages for main text, 3 pages for references)",
    "descriptor": "\nComments: 36 pages (10 pages for main text, 3 pages for references)\n",
    "authors": [
      "Yixuan He",
      "Gesine Reinert",
      "Mihai Cucuringu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05194"
  },
  {
    "id": "arXiv:2106.05390",
    "title": "Optimizing Reusable Knowledge for Continual Learning via Metalearning",
    "abstract": "Optimizing Reusable Knowledge for Continual Learning via Metalearning",
    "descriptor": "",
    "authors": [
      "Julio Hurtado",
      "Alain Raymond-Saez",
      "Alvaro Soto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.05390"
  },
  {
    "id": "arXiv:2106.06770",
    "title": "What can linearized neural networks actually say about generalization?",
    "abstract": "Comments: 18 pages, 16 figures",
    "descriptor": "\nComments: 18 pages, 16 figures\n",
    "authors": [
      "Guillermo Ortiz-Jim\u00e9nez",
      "Seyed-Mohsen Moosavi-Dezfooli",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06770"
  },
  {
    "id": "arXiv:2106.06946",
    "title": "Boosting Randomized Smoothing with Variance Reduced Classifiers",
    "abstract": "Boosting Randomized Smoothing with Variance Reduced Classifiers",
    "descriptor": "",
    "authors": [
      "Mikl\u00f3s Z. Horv\u00e1th",
      "Mark Niklas M\u00fcller",
      "Marc Fischer",
      "Martin Vechev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06946"
  },
  {
    "id": "arXiv:2106.09917",
    "title": "Envy-freeness and Relaxed Stability for Lower-Quotas : A Parameterized  Perspective",
    "abstract": "Comments: 14 pages, 2 figures. fullpage used, improved presentation of results, stronger kernelization result for MAXRSM",
    "descriptor": "\nComments: 14 pages, 2 figures. fullpage used, improved presentation of results, stronger kernelization result for MAXRSM\n",
    "authors": [
      "Girija Limaye"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.09917"
  },
  {
    "id": "arXiv:2106.10234",
    "title": "Dual-view Molecule Pre-training",
    "abstract": "Comments: Add new results of retrosynthesis",
    "descriptor": "\nComments: Add new results of retrosynthesis\n",
    "authors": [
      "Jinhua Zhu",
      "Yingce Xia",
      "Tao Qin",
      "Wengang Zhou",
      "Houqiang Li",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10234"
  },
  {
    "id": "arXiv:2106.11299",
    "title": "Boundary Graph Neural Networks for 3D Simulations",
    "abstract": "Boundary Graph Neural Networks for 3D Simulations",
    "descriptor": "",
    "authors": [
      "Andreas Mayr",
      "Sebastian Lehner",
      "Arno Mayrhofer",
      "Christoph Kloss",
      "Sepp Hochreiter",
      "Johannes Brandstetter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11299"
  },
  {
    "id": "arXiv:2106.14020",
    "title": "An Improved Physical ZKP for Nonogram",
    "abstract": "Comments: This paper has appeared at COCOA 2021",
    "descriptor": "\nComments: This paper has appeared at COCOA 2021\n",
    "authors": [
      "Suthee Ruangwises"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.14020"
  },
  {
    "id": "arXiv:2106.15780",
    "title": "Constructing the space of valuations of a quasi-Polish space as a space  of ideals",
    "abstract": "Constructing the space of valuations of a quasi-Polish space as a space  of ideals",
    "descriptor": "",
    "authors": [
      "Matthew de Brecht"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "General Topology (math.GN)"
    ],
    "url": "https://arxiv.org/abs/2106.15780"
  },
  {
    "id": "arXiv:2106.16209",
    "title": "S2C2 -- An orthogonal method for Semi-Supervised Learning on ambiguous  labels",
    "abstract": "S2C2 -- An orthogonal method for Semi-Supervised Learning on ambiguous  labels",
    "descriptor": "",
    "authors": [
      "Lars Schmarje",
      "Monty Santarossa",
      "Simon-Martin Schr\u00f6der",
      "Claudius Zelenka",
      "Rainer Kiko",
      "Jenny Stracke",
      "Nina Volkmann",
      "Reinhard Koch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16209"
  },
  {
    "id": "arXiv:2107.00088",
    "title": "Inverse Design of Grating Couplers Using the Policy Gradient Method from  Reinforcement Learning",
    "abstract": "Comments: Main Document: 14 pages, 4 figures; Supplementary Document: 6 pages, 2 figures",
    "descriptor": "\nComments: Main Document: 14 pages, 4 figures; Supplementary Document: 6 pages, 2 figures\n",
    "authors": [
      "Sean Hooten",
      "Raymond G. Beausoleil",
      "Thomas Van Vaerenbergh"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2107.00088"
  },
  {
    "id": "arXiv:2107.00594",
    "title": "Pretext Tasks selection for multitask self-supervised speech  representation learning",
    "abstract": "Pretext Tasks selection for multitask self-supervised speech  representation learning",
    "descriptor": "",
    "authors": [
      "Salah Zaiem",
      "Titouan Parcollet",
      "Slim Essid"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.00594"
  },
  {
    "id": "arXiv:2107.01318",
    "title": "A study of CNN capacity applied to Left Venticle Segmentation in Cardiac  MRI",
    "abstract": "A study of CNN capacity applied to Left Venticle Segmentation in Cardiac  MRI",
    "descriptor": "",
    "authors": [
      "Marcelo Toledo",
      "Daniel Lima",
      "Jos\u00e9 Krieger",
      "Marco Gutierrez"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.01318"
  },
  {
    "id": "arXiv:2107.02621",
    "title": "Energy Consumption of Deep Generative Audio Models",
    "abstract": "Comments: 5 pages, 2 figures, ICASSP 2022",
    "descriptor": "\nComments: 5 pages, 2 figures, ICASSP 2022\n",
    "authors": [
      "Constance Douwes",
      "Philippe Esling",
      "Jean-Pierre Briot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.02621"
  },
  {
    "id": "arXiv:2107.03487",
    "title": "A Framework of High-Stakes Algorithmic Decision-Making for the Public  Sector Developed through a Case Study of Child-Welfare",
    "abstract": "A Framework of High-Stakes Algorithmic Decision-Making for the Public  Sector Developed through a Case Study of Child-Welfare",
    "descriptor": "",
    "authors": [
      "Devansh Saxena",
      "Karla Badillo-Urquiola",
      "Pamela Wisniewski",
      "Shion Guha"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.03487"
  },
  {
    "id": "arXiv:2107.06317",
    "title": "Inverse Contextual Bandits: Learning How Behavior Evolves over Time",
    "abstract": "Inverse Contextual Bandits: Learning How Behavior Evolves over Time",
    "descriptor": "",
    "authors": [
      "Alihan H\u00fcy\u00fck",
      "Daniel Jarrett",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.06317"
  },
  {
    "id": "arXiv:2107.07576",
    "title": "Real-Time Face Recognition System for Remote Employee Tracking",
    "abstract": "Comments: Accepted in International Conference on Big Data, IoT and Machine Learning (BIM 2021)",
    "descriptor": "\nComments: Accepted in International Conference on Big Data, IoT and Machine Learning (BIM 2021)\n",
    "authors": [
      "Mohammad Sabik Irbaz",
      "MD Abdullah Al Nasim",
      "Refat E Ferdous"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.07576"
  },
  {
    "id": "arXiv:2107.11381",
    "title": "TargetNet: Functional microRNA Target Prediction with Deep Neural  Networks",
    "abstract": "Comments: This article has been accepted for publication in Bioinformatics published by Oxford University Press",
    "descriptor": "\nComments: This article has been accepted for publication in Bioinformatics published by Oxford University Press\n",
    "authors": [
      "Seonwoo Min",
      "Byunghan Lee",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.11381"
  },
  {
    "id": "arXiv:2108.02327",
    "title": "PI3NN: Out-of-distribution-aware prediction intervals from three neural  networks",
    "abstract": "PI3NN: Out-of-distribution-aware prediction intervals from three neural  networks",
    "descriptor": "",
    "authors": [
      "Siyan Liu",
      "Pei Zhang",
      "Dan Lu",
      "Guannan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.02327"
  },
  {
    "id": "arXiv:2108.03742",
    "title": "Reduced-Order Multiscale Modeling of Plastic Deformations in 3D Cast  Metallic Alloys with Spatially Varying Microstructures",
    "abstract": "Reduced-Order Multiscale Modeling of Plastic Deformations in 3D Cast  Metallic Alloys with Spatially Varying Microstructures",
    "descriptor": "",
    "authors": [
      "Shiguang Deng",
      "Carl Soderhjelm",
      "Diran Apelian",
      "Ramin Bostanabad"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.03742"
  },
  {
    "id": "arXiv:2108.05077",
    "title": "Mining the Benefits of Two-stage and One-stage HOI Detection",
    "abstract": "Comments: Accepted by NeurIPS 2021",
    "descriptor": "\nComments: Accepted by NeurIPS 2021\n",
    "authors": [
      "Aixi Zhang",
      "Yue Liao",
      "Si Liu",
      "Miao Lu",
      "Yongliang Wang",
      "Chen Gao",
      "Xiaobo Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.05077"
  },
  {
    "id": "arXiv:2108.05421",
    "title": "Seismic wave propagation and inversion with Neural Operators",
    "abstract": "Seismic wave propagation and inversion with Neural Operators",
    "descriptor": "",
    "authors": [
      "Yan Yang",
      "Angela F. Gao",
      "Jorge C. Castellanos",
      "Zachary E. Ross",
      "Kamyar Azizzadenesheli",
      "Robert W. Clayton"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.05421"
  },
  {
    "id": "arXiv:2108.05762",
    "title": "Multimodal analysis of the predictability of hand-gesture properties",
    "abstract": "Comments: 10 pages, 7 figures",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Taras Kucherenko",
      "Rajmund Nagy",
      "Michael Neff",
      "Hedvig Kjellstr\u00f6m",
      "Gustav Eje Henter"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2108.05762"
  },
  {
    "id": "arXiv:2108.06130",
    "title": "Semantic Answer Similarity for Evaluating Question Answering Models",
    "abstract": "Comments: Trained model: this https URL",
    "descriptor": "\nComments: Trained model: this https URL\n",
    "authors": [
      "Julian Risch",
      "Timo M\u00f6ller",
      "Julian Gutsch",
      "Malte Pietsch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2108.06130"
  },
  {
    "id": "arXiv:2108.06181",
    "title": "Detecting socially interacting groups using f-formation: A survey of  taxonomy, methods, datasets, applications, challenges, and future research  directions",
    "abstract": "Comments: Preprint submitted for Review",
    "descriptor": "\nComments: Preprint submitted for Review\n",
    "authors": [
      "Hrishav Bakul Barua",
      "Theint Haythi Mg",
      "Pradip Pramanick",
      "Chayan Sarkar"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.06181"
  },
  {
    "id": "arXiv:2108.06314",
    "title": "A Dataset for Answering Time-Sensitive Questions",
    "abstract": "Comments: Accepted to NeurIPS21 (dataset track), it contains 10 pages of main text and appendix",
    "descriptor": "\nComments: Accepted to NeurIPS21 (dataset track), it contains 10 pages of main text and appendix\n",
    "authors": [
      "Wenhu Chen",
      "Xinyi Wang",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.06314"
  },
  {
    "id": "arXiv:2108.07845",
    "title": "ARCH++: Animation-Ready Clothed Human Reconstruction Revisited",
    "abstract": "Comments: ICCV 2021",
    "descriptor": "\nComments: ICCV 2021\n",
    "authors": [
      "Tong He",
      "Yuanlu Xu",
      "Shunsuke Saito",
      "Stefano Soatto",
      "Tony Tung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2108.07845"
  },
  {
    "id": "arXiv:2108.09836",
    "title": "Probabilistic computing with p-bits",
    "abstract": "Probabilistic computing with p-bits",
    "descriptor": "",
    "authors": [
      "Jan Kaiser",
      "Supriyo Datta"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2108.09836"
  },
  {
    "id": "arXiv:2108.09992",
    "title": "Learned Image Coding for Machines: A Content-Adaptive Approach",
    "abstract": "Comments: Fig 4 correction",
    "descriptor": "\nComments: Fig 4 correction\n",
    "authors": [
      "Nam Le",
      "Honglei Zhang",
      "Francesco Cricri",
      "Ramin Ghaznavi-Youvalari",
      "Hamed Rezazadegan Tavakoli",
      "Esa Rahtu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.09992"
  },
  {
    "id": "arXiv:2108.10046",
    "title": "Discovering Spatial Relationships by Transformers for Domain  Generalization",
    "abstract": "Discovering Spatial Relationships by Transformers for Domain  Generalization",
    "descriptor": "",
    "authors": [
      "Cuicui Kang",
      "Karthik Nandakumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.10046"
  },
  {
    "id": "arXiv:2108.12026",
    "title": "Semantic-Based Self-Critical Training For Question Generation",
    "abstract": "Comments: 5 pages, 1 figure",
    "descriptor": "\nComments: 5 pages, 1 figure\n",
    "authors": [
      "Lo\u00efc",
      "Kwate Dassi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.12026"
  },
  {
    "id": "arXiv:2108.12113",
    "title": "Subjective Learning for Open-Ended Data",
    "abstract": "Subjective Learning for Open-Ended Data",
    "descriptor": "",
    "authors": [
      "Tianren Zhang",
      "Yizhou Jiang",
      "Xin Su",
      "Shangqi Guo",
      "Feng Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.12113"
  },
  {
    "id": "arXiv:2108.12581",
    "title": "Influence-Based Reinforcement Learning for Intrinsically-Motivated  Agents",
    "abstract": "Comments: 14 pages, 5 figures, 6 Tables",
    "descriptor": "\nComments: 14 pages, 5 figures, 6 Tables\n",
    "authors": [
      "Ammar Fayad",
      "Majd Ibrahim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.12581"
  },
  {
    "id": "arXiv:2108.13264",
    "title": "Deep Reinforcement Learning at the Edge of the Statistical Precipice",
    "abstract": "Comments: NeurIPS 2021 (Oral). Website: this https URL",
    "descriptor": "\nComments: NeurIPS 2021 (Oral). Website: this https URL\n",
    "authors": [
      "Rishabh Agarwal",
      "Max Schwarzer",
      "Pablo Samuel Castro",
      "Aaron Courville",
      "Marc G. Bellemare"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.13264"
  },
  {
    "id": "arXiv:2108.13910",
    "title": "A manifold learning perspective on representation learning: Learning  decoder and representations without an encoder",
    "abstract": "A manifold learning perspective on representation learning: Learning  decoder and representations without an encoder",
    "descriptor": "",
    "authors": [
      "Viktoria Schuster",
      "Anders Krogh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13910"
  },
  {
    "id": "arXiv:2109.00428",
    "title": "Combining reconstruction and edge detection in computed tomography",
    "abstract": "Combining reconstruction and edge detection in computed tomography",
    "descriptor": "",
    "authors": [
      "J\u00fcrgen Frikel",
      "Simon G\u00f6ppel",
      "Markus Haltmeier"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.00428"
  },
  {
    "id": "arXiv:2109.01745",
    "title": "A realistic approach to generate masked faces applied on two novel  masked face recognition data sets",
    "abstract": "Comments: Accepted at NeurIPS 2021",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Tudor Mare",
      "Georgian Duta",
      "Mariana-Iuliana Georgescu",
      "Adrian Sandru",
      "Bogdan Alexe",
      "Marius Popescu",
      "Radu Tudor Ionescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.01745"
  },
  {
    "id": "arXiv:2109.02752",
    "title": "Training Deep Networks from Zero to Hero: avoiding pitfalls and going  beyond",
    "abstract": "Comments: Extended version of SIBGRAPI 2021 Tutorial Paper",
    "descriptor": "\nComments: Extended version of SIBGRAPI 2021 Tutorial Paper\n",
    "authors": [
      "Moacir Antonelli Ponti",
      "Fernando Pereira dos Santos",
      "Leo Sampaio Ferraz Ribeiro",
      "Gabriel Biscaro Cavallari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.02752"
  },
  {
    "id": "arXiv:2109.03137",
    "title": "NumGPT: Improving Numeracy Ability of Generative Pre-trained Models",
    "abstract": "Comments: 8 pages, 3 figures",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Zhihua Jin",
      "Xin Jiang",
      "Xingbo Wang",
      "Qun Liu",
      "Yong Wang",
      "Xiaozhe Ren",
      "Huamin Qu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03137"
  },
  {
    "id": "arXiv:2109.03975",
    "title": "Where Did You Learn That From? Surprising Effectiveness of Membership  Inference Attacks Against Temporally Correlated Data in Deep Reinforcement  Learning",
    "abstract": "Where Did You Learn That From? Surprising Effectiveness of Membership  Inference Attacks Against Temporally Correlated Data in Deep Reinforcement  Learning",
    "descriptor": "",
    "authors": [
      "Maziar Gomrokchi",
      "Susan Amin",
      "Hossein Aboutalebi",
      "Alexander Wong",
      "Doina Precup"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.03975"
  },
  {
    "id": "arXiv:2109.06561",
    "title": "Beyond Distributed Subgraph Detection: Induced Subgraphs, Multicolored  Problems and Graph Parameters",
    "abstract": "Beyond Distributed Subgraph Detection: Induced Subgraphs, Multicolored  Problems and Graph Parameters",
    "descriptor": "",
    "authors": [
      "Janne H. Korhonen",
      "Amir Nikabadi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.06561"
  },
  {
    "id": "arXiv:2109.07833",
    "title": "Does External Knowledge Help Explainable Natural Language Inference?  Automatic Evaluation vs. Human Ratings",
    "abstract": "Comments: BlackboxNLP @ EMNLP2021",
    "descriptor": "\nComments: BlackboxNLP @ EMNLP2021\n",
    "authors": [
      "Hendrik Schuff",
      "Hsiu-Yu Yang",
      "Heike Adel",
      "Ngoc Thang Vu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.07833"
  },
  {
    "id": "arXiv:2109.08029",
    "title": "Image Captioning for Effective Use of Language Models in Knowledge-Based  Visual Question Answering",
    "abstract": "Comments: Under review. 11 pages with 3 figures",
    "descriptor": "\nComments: Under review. 11 pages with 3 figures\n",
    "authors": [
      "Ander Salaberria",
      "Gorka Azkune",
      "Oier Lopez de Lacalle",
      "Aitor Soroa",
      "Eneko Agirre"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.08029"
  },
  {
    "id": "arXiv:2109.08229",
    "title": "Policy Choice and Best Arm Identification: Comments on \"Adaptive  Treatment Assignment in Experiments for Policy Choice\"",
    "abstract": "Policy Choice and Best Arm Identification: Comments on \"Adaptive  Treatment Assignment in Experiments for Policy Choice\"",
    "descriptor": "",
    "authors": [
      "Kaito Ariu",
      "Masahiro Kato",
      "Junpei Komiyama",
      "Kenichiro McAlinn",
      "Chao Qin"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2109.08229"
  },
  {
    "id": "arXiv:2109.08937",
    "title": "Efficient Hybrid Transformer: Learning Global-local Context for Urban  Scene Segmentation",
    "abstract": "Efficient Hybrid Transformer: Learning Global-local Context for Urban  Scene Segmentation",
    "descriptor": "",
    "authors": [
      "Libo Wang",
      "Shenghui Fang",
      "Ce Zhang",
      "Rui Li",
      "Chenxi Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.08937"
  },
  {
    "id": "arXiv:2109.09425",
    "title": "Clustering in Recurrent Neural Networks for Micro-Segmentation using  Spending Personality",
    "abstract": "Clustering in Recurrent Neural Networks for Micro-Segmentation using  Spending Personality",
    "descriptor": "",
    "authors": [
      "Charl Maree",
      "Christian W. Omlin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.09425"
  },
  {
    "id": "arXiv:2109.10255",
    "title": "Multi-Task Learning with Sentiment, Emotion, and Target Detection to  Recognize Hate Speech and Offensive Language",
    "abstract": "Comments: publication at FIRE 2021 as system description paper in the HASOC-FIRE shared task on hate speech and offensive language detection",
    "descriptor": "\nComments: publication at FIRE 2021 as system description paper in the HASOC-FIRE shared task on hate speech and offensive language detection\n",
    "authors": [
      "Flor Miriam Plaza-del-Arco",
      "Sercan Halat",
      "Sebastian Pad\u00f3",
      "Roman Klinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.10255"
  },
  {
    "id": "arXiv:2109.11752",
    "title": "Internal Feedback in Biological Control: Diversity, Delays, and Standard  Theory",
    "abstract": "Comments: Submitted to 2022 ACC; Companion paper to arXiv:2110.05029, arXiv:2109.11757; Version updates: author + content changes, T.J.S., G.C., E.S.H., N.K. and their contributions have migrated to to arXiv:2110.05029",
    "descriptor": "\nComments: Submitted to 2022 ACC; Companion paper to arXiv:2110.05029, arXiv:2109.11757; Version updates: author + content changes, T.J.S., G.C., E.S.H., N.K. and their contributions have migrated to to arXiv:2110.05029\n",
    "authors": [
      "Josefin Stenberg",
      "Jing Shuang Li",
      "Anish A. Sarma",
      "John C. Doyle"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2109.11752"
  },
  {
    "id": "arXiv:2109.11757",
    "title": "Internal Feedback in Biological Control: Locality and System Level  Synthesis",
    "abstract": "Comments: Submitted to 2022 ACC; Companion paper to arXiv:2110.05029, arXiv:2109.11752; Version updates: author change (J. C. D. has been consulted), additional material + figures",
    "descriptor": "\nComments: Submitted to 2022 ACC; Companion paper to arXiv:2110.05029, arXiv:2109.11752; Version updates: author change (J. C. D. has been consulted), additional material + figures\n",
    "authors": [
      "Jing Shuang Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2109.11757"
  },
  {
    "id": "arXiv:2109.12473",
    "title": "Statically Bounded-Memory Delayed Sampling for Probabilistic Streams",
    "abstract": "Statically Bounded-Memory Delayed Sampling for Probabilistic Streams",
    "descriptor": "",
    "authors": [
      "Eric Atkinson",
      "Guillaume Baudart",
      "Louis Mandel",
      "Charles Yuan",
      "Michael Carbin"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2109.12473"
  },
  {
    "id": "arXiv:2109.12591",
    "title": "Joint magnitude estimation and phase recovery using Cycle-in-Cycle GAN  for non-parallel speech enhancement",
    "abstract": "Comments: Submitted to ICASSP 2022 (5 pages)",
    "descriptor": "\nComments: Submitted to ICASSP 2022 (5 pages)\n",
    "authors": [
      "Guochen Yu",
      "Andong Li",
      "Yutian Wang",
      "Yinuo Guo",
      "Chengshi Zheng",
      "Hui Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2109.12591"
  },
  {
    "id": "arXiv:2109.12664",
    "title": "BigBFT: A Multileader Byzantine Fault Tolerance Protocol for High  Throughput",
    "abstract": "Comments: 11",
    "descriptor": "\nComments: 11\n",
    "authors": [
      "Salem Alqahtani",
      "Murat Demirbas"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.12664"
  },
  {
    "id": "arXiv:2109.13662",
    "title": "DeepPSL: End-to-end perception and reasoning with applications to zero  shot learning",
    "abstract": "DeepPSL: End-to-end perception and reasoning with applications to zero  shot learning",
    "descriptor": "",
    "authors": [
      "Nigel P. Duffy",
      "Sai Akhil Puranam",
      "Sridhar Dasaratha",
      "Karmvir Singh Phogat",
      "Sunil Reddy Tiyyagura"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.13662"
  },
  {
    "id": "arXiv:2109.14299",
    "title": "Greedy algorithms for learning via exponential-polynomial splines",
    "abstract": "Greedy algorithms for learning via exponential-polynomial splines",
    "descriptor": "",
    "authors": [
      "Rosanna Campagna",
      "Stefano De Marchi",
      "Emma Perracchione",
      "Gabriele Santin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.14299"
  },
  {
    "id": "arXiv:2110.00046",
    "title": "SpliceOut: A Simple and Efficient Audio Augmentation Method",
    "abstract": "SpliceOut: A Simple and Efficient Audio Augmentation Method",
    "descriptor": "",
    "authors": [
      "Arjit Jain",
      "Pranay Reddy Samala",
      "Deepak Mittal",
      "Preethi Jyoti",
      "Maneesh Singh"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.00046"
  },
  {
    "id": "arXiv:2110.00329",
    "title": "Student Helping Teacher: Teacher Evolution via Self-Knowledge  Distillation",
    "abstract": "Student Helping Teacher: Teacher Evolution via Self-Knowledge  Distillation",
    "descriptor": "",
    "authors": [
      "Zheng Li",
      "Xiang Li",
      "Lingfeng Yang",
      "Jian Yang",
      "Zhigeng Pan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.00329"
  },
  {
    "id": "arXiv:2110.00452",
    "title": "SAM: A Self-adaptive Attention Module for Context-Aware Recommendation  System",
    "abstract": "Comments: We have fixed the format issue in the previous version. 10 pages, 1 figure",
    "descriptor": "\nComments: We have fixed the format issue in the previous version. 10 pages, 1 figure\n",
    "authors": [
      "Jiabin Liu",
      "Zheng Wei",
      "Zhengpin Li",
      "Xiaojun Mao",
      "Jian Wang",
      "Zhongyu Wei",
      "Qi Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.00452"
  },
  {
    "id": "arXiv:2110.00539",
    "title": "Applying Differential Privacy to Tensor Completion",
    "abstract": "Comments: We have fixed the format issue in the previous version. 17 pages, 4 figures",
    "descriptor": "\nComments: We have fixed the format issue in the previous version. 17 pages, 4 figures\n",
    "authors": [
      "Zheng Wei",
      "Zhengpin Li",
      "Xiaojun Mao",
      "Jian Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.00539"
  },
  {
    "id": "arXiv:2110.00954",
    "title": "Adaptive Real-Time Grid Operation via Online Feedback Optimization with  Sensitivity Estimation",
    "abstract": "Adaptive Real-Time Grid Operation via Online Feedback Optimization with  Sensitivity Estimation",
    "descriptor": "",
    "authors": [
      "Miguel Picallo",
      "Lukas Ortmann",
      "Saverio Bolognani",
      "Florian D\u00f6rfler"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.00954"
  },
  {
    "id": "arXiv:2110.00976",
    "title": "LexGLUE: A Benchmark Dataset for Legal Language Understanding in English",
    "abstract": "Comments: 9 pages, LexGLUE benchmark is available at: this https URL Code is available at: this https URL",
    "descriptor": "\nComments: 9 pages, LexGLUE benchmark is available at: this https URL Code is available at: this https URL\n",
    "authors": [
      "Ilias Chalkidis",
      "Abhik Jana",
      "Dirk Hartung",
      "Michael Bommarito",
      "Ion Androutsopoulos",
      "Daniel Martin Katz",
      "Nikolaos Aletras"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.00976"
  },
  {
    "id": "arXiv:2110.01776",
    "title": "An Ample Approach to Data and Modeling",
    "abstract": "Comments: 33 pages, 24 figures. A working manuscript",
    "descriptor": "\nComments: 33 pages, 24 figures. A working manuscript\n",
    "authors": [
      "Luciano da F. Costa"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.01776"
  },
  {
    "id": "arXiv:2110.02291",
    "title": "FedDQ: Communication-Efficient Federated Learning with Descending  Quantization",
    "abstract": "Comments: Submitted to ICASSP 2022",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Linping Qu",
      "Shenghui Song",
      "Chi-Ying Tsui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02291"
  },
  {
    "id": "arXiv:2110.03070",
    "title": "Robust Generalized Method of Moments: A Finite Sample Viewpoint",
    "abstract": "Comments: 24 pages, 1 figure",
    "descriptor": "\nComments: 24 pages, 1 figure\n",
    "authors": [
      "Dhruv Rohatgi",
      "Vasilis Syrgkanis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03070"
  },
  {
    "id": "arXiv:2110.03251",
    "title": "A Cough-based deep learning framework for detecting COVID-19",
    "abstract": "Comments: COVID-19, ICASSP-2022, DiCOVA",
    "descriptor": "\nComments: COVID-19, ICASSP-2022, DiCOVA\n",
    "authors": [
      "Hoang Van Truong",
      "Lam Pham"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.03251"
  },
  {
    "id": "arXiv:2110.03374",
    "title": "Model Adaptation: Historical Contrastive Learning for Unsupervised  Domain Adaptation without Source Data",
    "abstract": "Comments: Preliminary version release",
    "descriptor": "\nComments: Preliminary version release\n",
    "authors": [
      "Jiaxing Huang",
      "Dayan Guan",
      "Aoran Xiao",
      "Shijian Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03374"
  },
  {
    "id": "arXiv:2110.03861",
    "title": "QTN-VQC: An End-to-End Learning framework for Quantum Neural Networks",
    "abstract": "QTN-VQC: An End-to-End Learning framework for Quantum Neural Networks",
    "descriptor": "",
    "authors": [
      "Jun Qi",
      "Chao-Han Huck Yang",
      "Pin-Yu Chen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.03861"
  },
  {
    "id": "arXiv:2110.03882",
    "title": "ModeRNN: Harnessing Spatiotemporal Mode Collapse in Unsupervised  Predictive Learning",
    "abstract": "ModeRNN: Harnessing Spatiotemporal Mode Collapse in Unsupervised  Predictive Learning",
    "descriptor": "",
    "authors": [
      "Zhiyu Yao",
      "Yunbo Wang",
      "Haixu Wu",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03882"
  },
  {
    "id": "arXiv:2110.03888",
    "title": "M6-10T: A Sharing-Delinking Paradigm for Efficient Multi-Trillion  Parameter Pretraining",
    "abstract": "Comments: 14 pages, 4 figures",
    "descriptor": "\nComments: 14 pages, 4 figures\n",
    "authors": [
      "Junyang Lin",
      "An Yang",
      "Jinze Bai",
      "Chang Zhou",
      "Le Jiang",
      "Xianyan Jia",
      "Ang Wang",
      "Jie Zhang",
      "Yong Li",
      "Wei Lin",
      "Jingren Zhou",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.03888"
  },
  {
    "id": "arXiv:2110.04276",
    "title": "Offline Meta-Reinforcement Learning for Industrial Insertion",
    "abstract": "Offline Meta-Reinforcement Learning for Industrial Insertion",
    "descriptor": "",
    "authors": [
      "Tony Z. Zhao",
      "Jianlan Luo",
      "Oleg Sushkov",
      "Rugile Pevceviciute",
      "Nicolas Heess",
      "Jon Scholz",
      "Stefan Schaal",
      "Sergey Levine"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.04276"
  },
  {
    "id": "arXiv:2110.04367",
    "title": "Hybrid Random Features",
    "abstract": "Hybrid Random Features",
    "descriptor": "",
    "authors": [
      "Krzysztof Choromanski",
      "Haoxian Chen",
      "Han Lin",
      "Yuanzhe Ma",
      "Arijit Sehanobish",
      "Deepali Jain",
      "Michael S Ryoo",
      "Jake Varley",
      "Andy Zeng",
      "Valerii Likhosherstov",
      "Dmitry Kalashnikov",
      "Vikas Sindhwani",
      "Adrian Weller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04367"
  },
  {
    "id": "arXiv:2110.04371",
    "title": "DispersedLedger: High-Throughput Byzantine Consensus on Variable  Bandwidth Networks",
    "abstract": "Comments: NSDI '22",
    "descriptor": "\nComments: NSDI '22\n",
    "authors": [
      "Lei Yang",
      "Seo Jin Park",
      "Mohammad Alizadeh",
      "Sreeram Kannan",
      "David Tse"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.04371"
  },
  {
    "id": "arXiv:2110.04400",
    "title": "HydraSum -- Disentangling Stylistic Features in Text Summarization using  Multi-Decoder Models",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Tanya Goyal",
      "Nazneen Fatema Rajani",
      "Wenhao Liu",
      "Wojciech Kry\u015bci\u0144ski"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04400"
  },
  {
    "id": "arXiv:2110.04983",
    "title": "Understanding the Safety Requirements for Learning-based Power Systems  Operations",
    "abstract": "Comments: In submission",
    "descriptor": "\nComments: In submission\n",
    "authors": [
      "Yize Chen",
      "Daniel Arnold",
      "Yuanyuan Shi",
      "Sean Peisert"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.04983"
  },
  {
    "id": "arXiv:2110.05096",
    "title": "Density-Based Clustering with Kernel Diffusion",
    "abstract": "Density-Based Clustering with Kernel Diffusion",
    "descriptor": "",
    "authors": [
      "Chao Zheng",
      "Yingjie Chen",
      "Chong Chen",
      "Jianqiang Huang",
      "Xian-Sheng Hua"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05096"
  },
  {
    "id": "arXiv:2110.05204",
    "title": "CLIP4Caption ++: Multi-CLIP for Video Caption",
    "abstract": "Comments: 4 pages, VALUE Challenge 2021 captioning task chamionship solution",
    "descriptor": "\nComments: 4 pages, VALUE Challenge 2021 captioning task chamionship solution\n",
    "authors": [
      "Mingkang Tang",
      "Zhanyu Wang",
      "Zhaoyang Zeng",
      "Fengyun Rao",
      "Dian Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05204"
  },
  {
    "id": "arXiv:2110.05335",
    "title": "From FPGAs to Obfuscated eASICs: Design and Security Trade-offs",
    "abstract": "Comments: The results for the paper are given on the following link: this https URL",
    "descriptor": "\nComments: The results for the paper are given on the following link: this https URL\n",
    "authors": [
      "Zain Ul Abideen",
      "Tiago Diadami Perez",
      "Samuel Pagliarini"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2110.05335"
  },
  {
    "id": "arXiv:2110.05342",
    "title": "Semi-Autoregressive Image Captioning",
    "abstract": "Comments: ACM MM2021 Oral",
    "descriptor": "\nComments: ACM MM2021 Oral\n",
    "authors": [
      "Xu Yan",
      "Zhengcong Fei",
      "Zekang Li",
      "Shuhui Wang",
      "Qingming Huang",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05342"
  },
  {
    "id": "arXiv:2110.05743",
    "title": "Program Transfer and Ontology Awareness for Semantic Parsing in KBQA",
    "abstract": "Program Transfer and Ontology Awareness for Semantic Parsing in KBQA",
    "descriptor": "",
    "authors": [
      "Shulin Cao",
      "Jiaxin Shi",
      "Zijun Yao",
      "Lei Hou",
      "Juanzi Li",
      "Jinghui Xiao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05743"
  },
  {
    "id": "arXiv:2110.05748",
    "title": "SEPP: Similarity Estimation of Predicted Probabilities for Defending and  Detecting Adversarial Text",
    "abstract": "Comments: PACLIC 35 (2021) (Oral)",
    "descriptor": "\nComments: PACLIC 35 (2021) (Oral)\n",
    "authors": [
      "Hoang-Quoc Nguyen-Son",
      "Seira Hidano",
      "Kazuhide Fukushima",
      "Shinsaku Kiyomoto"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05748"
  },
  {
    "id": "arXiv:2110.05896",
    "title": "LaoPLM: Pre-trained Language Models for Lao",
    "abstract": "LaoPLM: Pre-trained Language Models for Lao",
    "descriptor": "",
    "authors": [
      "Nankai Lin",
      "Yingwen Fu",
      "Chuwei Chen",
      "Ziyu Yang",
      "Shengyi Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05896"
  },
  {
    "id": "arXiv:2110.05909",
    "title": "Rescoring Sequence-to-Sequence Models for Text Line Recognition with  CTC-Prefixes",
    "abstract": "Comments: 15 pages, 6 tables, 3 figures",
    "descriptor": "\nComments: 15 pages, 6 tables, 3 figures\n",
    "authors": [
      "Christoph Wick",
      "Jochen Z\u00f6llner",
      "Tobias Gr\u00fcning"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.05909"
  },
  {
    "id": "arXiv:2110.06006",
    "title": "Robust Glare Detection: Review, Analysis, and Dataset Release",
    "abstract": "Robust Glare Detection: Review, Analysis, and Dataset Release",
    "descriptor": "",
    "authors": [
      "Mahdi Abolfazli Esfahani",
      "Han Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.06006"
  },
  {
    "id": "arXiv:2110.06166",
    "title": "Game Theory for Adversarial Attacks and Defenses",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Shorya Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.06166"
  },
  {
    "id": "arXiv:2110.06172",
    "title": "Complexity of optimizing over the integers",
    "abstract": "Complexity of optimizing over the integers",
    "descriptor": "",
    "authors": [
      "Amitabh Basu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.06172"
  }
]